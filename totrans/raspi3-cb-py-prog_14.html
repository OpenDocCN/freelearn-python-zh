<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Can I Recommend a Movie for You?</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Euclidean distance score computation</li>
<li>Pearson correlation score computation</li>
<li>How to find similar users in the dataset</li>
<li>How to develop a movie recommendation module</li>
<li>Application of recommender systems</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>Movie recommendations are used to predict movies for users based on their interests. The content in the database is filtered and an appropriate movie is recommended for the user. Having the appropriate movie recommended increases the probability of the user purchasing the movie. Collaborative filtering is used to build the movie recommendation system. It considers the behavior of the current user in the past. It also considers the ratings given by my other users. Collaborative filtering involves finding and computing the Euclidean distance, Pearson correlation, and finding similar users in the dataset.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Computing the Euclidean distance score</h1>
                </header>
            
            <article>
                
<p>The first step in building a recommendation engine includes finding similar users in the database. The Euclidean distance score is one of the measures to find similarities.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>NumPy (Numerical Python) needs to be installed on Raspberry Pi 3 to calculate Euclidean distance. Readers can install <kbd>numpy</kbd> by typing the following command in the Raspberry Pi 3 Terminal:</p>
<pre><strong>sudo apt-get -y install python-numpy</strong> </pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>We will create a new Python file and import the following packages into it:</li>
</ol>
<pre style="padding-left: 60px">import json 
import numpy as np  </pre>
<ol start="2">
<li>To calculate the Euclidean score between two users, we will define a new function. Let's check the presence of the users in the database:</li>
</ol>
<pre style="padding-left: 60px"># The following code will return the Euclidean distance score between user1 and user2: 
 
def euclidean_dist_score(dataset, FirstUser, SecondUser): 
  if FirstUser not in dataset: 
    raiseTypeError('User ' + FirstUser + ' not present in the dataset') 
  if SecondUser not in dataset: 
    raiseTypeError('User ' + SecondUser + ' not present in the dataset') </pre>
<ol start="3">
<li>We will now extract the movies that have been rated by both users. Then we will compute the score:</li>
</ol>
<pre style="padding-left: 60px">  # Movies rated by both FirstUser and SecondUser 
  Both_User_rated = {} 
  for element in dataset[FirstUser]: 
    if element in dataset[SecondUser]: 
      Both_User_rated[element] = 1</pre>
<ol start="4">
<li>No movies in common indicates no similarities between the first and second user. (otherwise unable to compute the ratings in database):</li>
</ol>
<pre style="padding-left: 60px">  # Score 0 indicate no common movies 
  if len(Both_User_rated) == 0: 
    return 0</pre>
<ol start="5">
<li>If the ratings are common, calculate the sum of the squared differences, compute the square root of the result obtained, and then normalize it. The score will now be between zero and one:</li>
</ol>
<pre style="padding-left: 60px">  SquareDifference = [] 
  for element in dataset[FirstUser]: 
    if element in dataset[SecondUser]: 
      SquareDifference.append(np.square(dataset[FirstUser][element] - 
dataset[SecondUser][element]))    
  return 1 / (1 + np.sqrt(np.sum(SquareDifference))) </pre>
<p style="padding-left: 60px">If both user ratings are same, then sum of squared differences will be a small value. Therefore, the score will be high. This the aim here.</p>
<ol start="6">
<li>We will name our data file <kbd>movie_rates.json</kbd>. We will now load it:</li>
</ol>
<pre style="padding-left: 60px">if __name__=='__main__': 
  data_file = 'movie_rates.json' 
  with open(data_file, 's') as m: 
    data = json.loads(m.read()) </pre>
<ol start="7">
<li>Let's calculate the Euclidean distance score for two random users:</li>
</ol>
<pre style="padding-left: 60px">FirstUser = 'Steven Ferndndes' 
SecondUser = 'Ramesh Nayak' 
print "nEuclidean score:" 
print euclidean_dist_score(data, FirstUser, SecondUser) </pre>
<ol start="8">
<li>The preceding code will print the Euclidean distance score in the Terminal:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-585 image-border" src="Images/a5f2a1de-a34e-4a95-865b-2f2ef667ab03.png" style="width:39.00em;height:4.33em;" width="468" height="52"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Readers can refer to the article <em>Similarity and recommender systems</em> to learn how Euclidean distance works:</p>
<p><a href="http://www.inf.ed.ac.uk/teaching/courses/inf2b/learnnotes/inf2b-learn-note02-2up.pdf" target="_blank">http://www.inf.ed.ac.uk/teaching/courses/inf2b/learnnotes/inf2b-learn-note02-2up.pdf</a></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Readers can refer to the article <em>Comparison of various metrics used in collaborative filtering for recommendation system</em> to learn more about various metrics used in recommendation systems:</p>
<p><a href="http://ieeexplore.ieee.org/document/7346670/" target="_blank">http://ieeexplore.ieee.org/document/7346670/</a></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>Quick Guide to Build a Recommendation Engine in Python</em>:</li>
</ul>
<p style="padding-left: 60px"><a href="https://www.analyticsvidhya.com/blog/2016/06/quick-guide-build-recommendation-engine-python/" target="_blank"><span class="URLPACKT">https://www.analyticsvidhya.com/blog/2016/06/quick-guide-build-recommendation-engine-python/</span></a></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Computing a Pearson correlation score</h1>
                </header>
            
            <article>
                
<p>Euclidean distance assumes that the sample points are distributed about the sample mean in a spherical manner, which is not always true. Hence, the Pearson correlation score is used instead of the Euclidean distance score. The computation of the Pearson correlation score is explained next.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>We will create a new Python file and import the following packages:</li>
</ol>
<pre style="padding-left: 60px">import json 
import numpy as np</pre>
<ol start="2">
<li>To calculate the Pearson correlation score between two users, we will define a new function. Let's check the presence of the users in the database:</li>
</ol>
<pre style="padding-left: 60px"># Returns the Pearson correlation score between user1 and user2 
def pearson _dist_score(dataset, FirstUser, SecondUser): 
  if FirstUser not in dataset: 
    raise TypeError('User ' + FirstUser + ' not present in the dataset') 
  if SecondUser not in dataset: 
    raise TypeError('User ' + SecondUser + ' not present in the dataset') </pre>
<ol start="3">
<li>We will now extract the movies that have been rated by both users:</li>
</ol>
<pre style="padding-left: 60px">  # Movies rated by both FirstUser and SecondUser 
  Both_User_rated = {} 
  for item in dataset[FirstUser]: 
    if item in dataset[SecondUser]: 
      both_User_rated[element] = 1 
  rating_number= len(both_User_rated) 
 </pre>
<ol start="4">
<li>No movies in common indicates no similarities between the first and second user; hence, we return zero:</li>
</ol>
<pre style="padding-left: 60px">  # Score 0 indicate no common movies 
  if rating_number == 0: 
    return 0 </pre>
<ol start="5">
<li>Calculate the sum of squared values of common movie ratings:</li>
</ol>
<pre style="padding-left: 60px">  # Calculate the sum of ratings of all the common preferences 
  FirstUser_sum= np.sum([dataset[FirstUser][ element] for item in both_User_rated]) 
  SecondUser_sum=np.sum([dataset[SecondUser][element] for item in both_User_rated]) </pre>
<ol start="6">
<li>Calculate the sum of squared ratings of all the common movie ratings:</li>
</ol>
<pre style="padding-left: 60px">  # Calculate the sum of squared ratings of all the common preferences 
  FirstUser_squared_sum = np.sum([np.square(dataset[FirstUser][element]) for element in 
both_User_rated]) 
  SecondUser_squared_sum= np.sum([np.square(dataset[SecondUser][element]) for element inboth_User_rated])</pre>
<ol start="7">
<li>Now, calculate the sum of the products:</li>
</ol>
<pre style="padding-left: 60px">  # Calculate the sum of products of the common ratings 
  sum_product = np.sum([dataset[FirstUser][element] * dataset[SecondUser][element] for item inboth_User_rated]) </pre>
<ol start="8">
<li>Calculate the various variables required to calculate the Pearson correlation score:</li>
</ol>
<pre style="padding-left: 60px">  # Pearson correlation calculation 
  PSxy = sum_product - (FirstUser_sum* SecondUser_sum/rating_number) 
  PSxx = FirstUser_squared_sum- np.square(FirstUser_sum) / <a>rating_number</a> 
  PSyy = SecondUser_squared_sum - np.square(<a>SecondUser_sum</a>) / rating_number 
 </pre>
<ol start="9">
<li>We need to take care of the issue where the denominator becomes zero:</li>
</ol>
<pre style="padding-left: 60px">  if PSxx * PSyy == 0: 
    return 0 </pre>
<ol start="10">
<li>Return the Pearson correlation score:</li>
</ol>
<pre style="padding-left: 60px">  return PSxy / np.sqrt(PSxx * PSyy) </pre>
<ol start="11">
<li>Define the <kbd>main</kbd> function and calculate the Pearson correlation score between the two users:</li>
</ol>
<pre style="padding-left: 60px">if __name__=='__main__': 
  data_file = 'movie_rates.json' 
  with open(data_file, 's') as m: 
    data = json.loads(m.read()) 
    FirstUser = 'StevenFerndndes' 
    SecondUser = 'Rameshnayak' 
    print "nPearson score:" 
    print pearson _dist_score(data, FirstUser, SecondUser) </pre>
<ol start="12">
<li>The preceding code will print the Pearson correlation in the Terminal:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-586 image-border" src="Images/30f978bd-988b-413c-bca1-ce94c0910ca6.png" style="width:39.08em;height:4.50em;" width="469" height="54"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Readers can refer to <em>Pearson Correlation Coefficient - Simple Tutorial</em> to learn how the Pearson correlation coefficient is calculated:<a href="https://www.spss-tutorials.com/pearson-correlation-coefficient/"><br/>
<span class="URLPACKT">https://www.spss-tutorials.com/pearson-correlation-coefficient/</span><br/></a></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Readers can refer to two different variants of Pearson Correlation Coefficient here:</p>
<ul>
<li>Correlation Coefficient: Simple Definition, Formula, Easy Steps:</li>
</ul>
<p style="padding-left: 60px"><a href="http://www.statisticshowto.com/how-to-compute-pearsons-correlation-coefficients/" target="_blank">http://www.statisticshowto.com/how-to-compute-pearsons-correlation-coefficients/</a></p>
<ul>
<li>A new user similarity model to improve the accuracy of collaborative filtering:</li>
</ul>
<p style="padding-left: 60px"><a href="http://www.sciencedirect.com/science/article/pii/S0950705113003560" target="_blank">http://www.sciencedirect.com/science/article/pii/S0950705113003560</a></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>The new similarity measure based on user preference models for collaborative filtering</em>:</li>
</ul>
<p style="padding-left: 60px"><a href="http://ieeexplore.ieee.org/document/7279353/"><span class="URLPACKT">http://ieeexplore.ieee.org/document/7279353/</span><br/></a></p>
<ul>
<li><em>Application of artificial immune systems combines collaborative filtering in movie recommendation system</em>:</li>
</ul>
<p style="padding-left: 60px"><a href="http://ieeexplore.ieee.org/document/6846855/"><span class="URLPACKT">http://ieeexplore.ieee.org/document/6846855/</span><br/></a></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Finding similar users in the dataset</h1>
                </header>
            
            <article>
                
<p>Finding similar users in the dataset is a critical step in movie recommendations, and this process is explained next.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>We will create a new Python file and import the following packages:</li>
</ol>
<pre style="padding-left: 60px">import json 
import numpy as np 
from pearson _dist_score import pearson _dist_score 
 </pre>
<ol start="2">
<li>First, define a function for the input user that will find the similar users. For this, three arguments are needed: the number of similar users, the input user, and the database. Check whether the user is present in the database. If they are present, calculate the Pearson correlation score between the users present in the database and the input user:</li>
</ol>
<pre style="padding-left: 60px"># Finds a specified number of users who are similar to the input user 
  def search_similar_user (dataset, input_user, users_number): 
    if input_user not in dataset: 
      raiseTypeError('User ' + input_user + ' not present in the dataset') 
      # Calculate Pearson scores for all the users 
      scores = np.array([[x, pearson _dist_score(dataset,   input_user, i)] for i in dataset if 
user != i]) </pre>
<ol start="3">
<li>Now sort the obtained scores in descending order:</li>
</ol>
<pre style="padding-left: 60px">       # Based on second column, sort the score 
       sorted_score= np.argsort(scores[:, 1]) 
       # Sorting in decreasing order (highest score first) 
       dec_sorted_score= sorted_score[::-1] </pre>
<ol start="4">
<li>We will pick the first <kbd>k</kbd> scores:</li>
</ol>
<pre style="padding-left: 60px">      # Pick top 'k' elements  
      top_q= dec_sorted_score[0:users_number] 
    return scores[top_q]</pre>
<ol start="5">
<li>We define the <kbd>main</kbd> function and load the input database:</li>
</ol>
<pre style="padding-left: 60px">if __name__=='__main__': 
  data_file = ''movie_rates.json' 
  with open(data_file, 's') as m: 
    data = json.loads(m.read()) </pre>
<ol start="6">
<li>We find three similar users:</li>
</ol>
<pre style="padding-left: 60px">user = 'JohnCarson' 
print "nUsers similar to " + input_user + ":n" 
similar_one = search_similar_user(data, input_user, 3) 
print "input_usertttSimilarity scoren" 
 
for element in similar_one: 
  print element[0], 'tt', round(float(element[1]), 2) </pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>Recommendation for Movies and Stars Using YAGO and IMDB</em>:</li>
</ul>
<p style="padding-left: 60px"><a href="http://ieeexplore.ieee.org/document/5474144/"><span class="URLPACKT">http://ieeexplore.ieee.org/document/5474144/</span><br/></a></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Developing a movie recommendation module</h1>
                </header>
            
            <article>
                
<p>We are now ready to build the movie recommendation engine. We will use all the functionalities that we built in the previous recipes. Let's see how it can be done.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>We will create a new Python file and import the following packages:</li>
</ol>
<pre style="padding-left: 60px">import json 
import numpy as np 
from euclidean_score import euclidean_score 
from pearson_score import pearson_score 
from search_similar_user import search_similar_user</pre>
<ol start="2">
<li>For movie recommendations for a given user, we will define a function first. We now check whether the user already exists:</li>
</ol>
<pre style="padding-left: 60px"># Generate recommendations for a given user 
def recommendation_generated(dataset, user): 
if user not in dataset: 
raiseTypeError('User ' + user + ' not present in the dataset') </pre>
<ol start="3">
<li>Compute the person score for the present user:</li>
</ol>
<pre style="padding-left: 60px">sumofall_scores= {} 
identical_sums= {} 
for u in [x for x in dataset if x != user]: 
identical_score= pearson_score(dataset, user, u) 
if identical_score&lt;= 0: 
continue </pre>
<ol start="4">
<li>Find the movies that have not been rated by the user:</li>
</ol>
<pre style="padding-left: 60px">for element in [x for x in dataset[u] if x not in dataset[user] or 
dataset[user][x] == 0]: 
sumofall_scores.update({item: dataset[u][item] * identical_sums}) 
identical_sums.update({item: identical_score}) </pre>
<ol start="5">
<li>What if the user has seen all the movies in the dataset? Then there will be no recommendations:</li>
</ol>
<pre style="padding-left: 60px">if len(sumofall_scores) == 0: 
return ['No recommendations possible'] </pre>
<ol start="6">
<li>We now have a list of these scores. Let's create a normalized list of movie ranks:</li>
</ol>
<pre style="padding-left: 60px"># Create the normalized list 
rank_of_movie= np.array([[total/ identical_sums[element], element] 
for element, total in sumofall_scores.element()]) </pre>
<ol start="7">
<li>Based on the score, sort the list in descending order:</li>
</ol>
<pre style="padding-left: 60px"># Based on first column, sort in decreasing order 
rank_of_movie = rank_of_movie[np.argsort(rank_of_movie[:, 0])[::-1]]</pre>
<ol start="8">
<li>We are finally ready to extract the movie recommendations:</li>
</ol>
<pre style="padding-left: 60px"># Recommended movies needs to be extracted 
recommended = [movie for _, movie in movie_ranks] 
return recommended </pre>
<ol start="9">
<li>Define the <kbd>main</kbd> function and load the dataset:</li>
</ol>
<pre style="padding-left: 60px">if __name__=='__main__': 
data_file = rating_of_miovie.json' 
with open(data_file, 'r') as f: 
data = json.loads(f.read()) </pre>
<ol start="10">
<li>Let's generate recommendations for <kbd>Steven Ferndndes</kbd>:</li>
</ol>
<pre style="padding-left: 60px">user = ' Steven Ferndndes ' 
print "nRecommendations for " + user + ":" 
movies = recommendation_generated(data, user) 
for i, movie in enumerate(movies): 
print str(i+1) + '. ' + movie </pre>
<ol start="11">
<li>The user <kbd>Ramesh Nayak</kbd> has watched all the movies. Therefore, if we try to generate recommendations for him, it should display zero recommendations:</li>
</ol>
<pre style="padding-left: 60px">user = ' Ramesh Nayak ' 
print "nRecommendations for " + user + ":" 
movies = recommendation_generated(data, user) 
for i, movie in enumerate(movies): 
print str(i+1) + '. ' + movie  </pre>
<ol start="12">
<li>The preceding code will print the movie recommendations in the Terminal:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="Images/9d848d89-f60e-4711-bd19-865f25758bed.png" style="width:36.92em;height:10.00em;" width="487" height="132"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>Recommender systems explained</em>:</li>
</ul>
<p style="padding-left: 60px"><a href="https://medium.com/recombee-blog/recommender-systems-explained-d98e8221f468"><span class="URLPACKT">https://medium.com/recombee-blog/recommender-systems-explained-d98e8221f468</span><br/></a></p>
<ul>
<li><em>Recommendation System Algorithms</em>:</li>
</ul>
<p style="padding-left: 60px"><a href="https://blog.statsbot.co/recommendation-system-algorithms-ba67f39ac9a3"><span class="URLPACKT">https://blog.statsbot.co/recommendation-system-algorithms-ba67f39ac9a3</span><br/></a></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Applications of recommender systems</h1>
                </header>
            
            <article>
                
<p>Recommender systems are currently used in various fields. They play a very prominent role and are utilized in a variety of areas including music, movies, books, news, search queries, social tags, research articles, and products in general. There are also recommender systems for restaurants, experts, collaborators, financial services, jokes, garments, Twitter pages, and life insurance.</p>


            </article>

            
        </section>
    </div>



  </body></html>