<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Getting Started with Parallel Computing and Python</span></h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="koboSpan" id="kobo.2.1">The </span><em><span class="koboSpan" id="kobo.3.1">parallel</span></em><span class="koboSpan" id="kobo.4.1"> and </span><em><span class="koboSpan" id="kobo.5.1">distributed computing</span></em><span class="koboSpan" id="kobo.6.1"> models are based on the simultaneous use of different processing units for program execution. </span><span class="koboSpan" id="kobo.6.2">Although the</span><span><span class="koboSpan" id="kobo.7.1"> </span></span><span class="koboSpan" id="kobo.8.1">distinction between parallel and distributed computing is very thin, one of the possible definitions associates the parallel calculation model with the shared memory calculation model, and the distributed calculation model with the message passing model.</span></p>
<p class="mce-root"><span class="koboSpan" id="kobo.9.1">From this point onward, we will use the term </span><em><span class="koboSpan" id="kobo.10.1">parallel computing</span></em><span class="koboSpan" id="kobo.11.1"> to refer to both parallel and distributed calculation models.</span></p>
<p><span class="koboSpan" id="kobo.12.1">The next sections</span><span><span class="koboSpan" id="kobo.13.1"> </span></span><span class="koboSpan" id="kobo.14.1">provide an overview of parallel programming architectures and programming models. </span><span class="koboSpan" id="kobo.14.2">These concepts are useful for inexperienced programmers who are approaching parallel programming techniques for the first time. </span><span class="koboSpan" id="kobo.14.3">Moreover, it can be a basic reference for experienced programmers. </span><span class="koboSpan" id="kobo.14.4">The dual characterization of parallel systems is also presented. </span><span class="koboSpan" id="kobo.14.5">The first characterization is based on the system architecture, while the second characterization is based on parallel programming paradigms.</span></p>
<p><span class="koboSpan" id="kobo.15.1">The chapter ends with a brief introduction to the</span><span><span class="koboSpan" id="kobo.16.1"> </span></span><span class="koboSpan" id="kobo.17.1">Python</span><em><span><span class="koboSpan" id="kobo.18.1"> </span></span></em><span class="koboSpan" id="kobo.19.1">programming language. </span><span class="koboSpan" id="kobo.19.2">The characteristics of the language, ease of use and learning, and the extensibility and richness of software libraries and applications make Python a valuable tool for any application, and also for parallel computing. </span><span class="koboSpan" id="kobo.19.3">The concepts of threads and processes are introduced in relation to their use in the language.</span></p>
<p><span class="koboSpan" id="kobo.20.1">In this chapter, we will cover the following recipes:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.21.1">Why do we need parallel computing?</span></li>
<li><span class="koboSpan" id="kobo.22.1">Flynn's taxonomy</span></li>
<li><span class="koboSpan" id="kobo.23.1">Memory organization</span></li>
<li><span class="koboSpan" id="kobo.24.1">Parallel programming models</span></li>
<li><span class="koboSpan" id="kobo.25.1">Evaluating performance</span></li>
<li><span class="koboSpan" id="kobo.26.1">Introducing Python</span></li>
<li><span class="koboSpan" id="kobo.27.1">Python and parallel programming</span></li>
<li><span class="koboSpan" id="kobo.28.1">Introducing processes and threads</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Why do we need parallel computing?</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The growth in computing power made available by modern computers has resulted in us facing computational problems of increasing complexity in relatively short time frames. </span><span class="koboSpan" id="kobo.2.2">Until the early 2000s, complexity was dealt with by increasing the number of transistors as well as the clock frequency of single-processor systems, which reached peaks of 3.5-4 GHz. </span><span class="koboSpan" id="kobo.2.3">However, the increase in the number of transistors causes the exponential increase of the power dissipated by the processors themselves. </span><span class="koboSpan" id="kobo.2.4">In essence, there is, therefore, a physical limitation that prevents further improvement in the performance of single-processor systems.</span></p>
<p><span class="koboSpan" id="kobo.3.1">For this reason, in recent years, microprocessor manufacturers have focused their attention on </span><em><span class="koboSpan" id="kobo.4.1">multi-core</span></em><span class="koboSpan" id="kobo.5.1"> systems. </span><span class="koboSpan" id="kobo.5.2">These are based on a core of several physical processors that share the same memory, thus bypassing the problem of dissipated power described earlier. </span><span class="koboSpan" id="kobo.5.3">In recent years, </span><em><span class="koboSpan" id="kobo.6.1">quad-core</span></em><span class="koboSpan" id="kobo.7.1"> and </span><em><span class="koboSpan" id="kobo.8.1">octa-core</span></em><span class="koboSpan" id="kobo.9.1"> systems have also become standard on normal desktop and laptop configurations.</span></p>
<p><span class="koboSpan" id="kobo.10.1">On the other hand, such a significant change in hardware has also resulted in an evolution of software structure, which has always been designed to be executed sequentially on a single processor. </span><span class="koboSpan" id="kobo.10.2">To take advantage of the greater computational resources made available by increasing the number of processors, the existing software must be redesigned in a form appropriate to the parallel structure of the CPU, so as to obtain greater efficiency through the simultaneous execution of the single units of several parts of the same program.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Flynn's taxonomy</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Flynn's taxonomy is a system for classifying computer architectures. </span><span class="koboSpan" id="kobo.2.2">It is based on two main concepts:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.3.1">Instruction flow</span></strong><span class="koboSpan" id="kobo.4.1">: A system with </span><em><span class="koboSpan" id="kobo.5.1">n</span></em> <span><span class="koboSpan" id="kobo.6.1">CPU has</span></span> <em><span class="koboSpan" id="kobo.7.1">n</span></em> <span><span class="koboSpan" id="kobo.8.1">program counters and, therefore,</span></span><span class="koboSpan" id="kobo.9.1"> </span><em><span class="koboSpan" id="kobo.10.1">n </span></em><span><span class="koboSpan" id="kobo.11.1">instructions flows</span></span><span><span class="koboSpan" id="kobo.12.1">. This corresponds to a program counter.</span></span></li>
<li><strong><span class="koboSpan" id="kobo.13.1">Data flow</span></strong><span class="koboSpan" id="kobo.14.1">: A program that calculates a function on a list of data has a data flow. </span><span class="koboSpan" id="kobo.14.2">The program that calculates the same function on several different lists of data has more data flows. </span><span><span class="koboSpan" id="kobo.15.1">This is made up of a set of operands.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.16.1">As the instruction and data flows are independent, there are four categories of parallel machines: </span><strong><span class="koboSpan" id="kobo.17.1">Single Instruction Single Data</span></strong><span class="koboSpan" id="kobo.18.1"> (</span><strong><span class="koboSpan" id="kobo.19.1">SISD</span></strong><span class="koboSpan" id="kobo.20.1">), </span><strong><span class="koboSpan" id="kobo.21.1">Single Instruction Multiple Data</span></strong><span class="koboSpan" id="kobo.22.1"> (</span><strong><span class="koboSpan" id="kobo.23.1">SIMD</span></strong><span class="koboSpan" id="kobo.24.1">), </span><strong><span class="koboSpan" id="kobo.25.1">Multiple Instruction Single Data</span></strong><span class="koboSpan" id="kobo.26.1"> (</span><strong><span class="koboSpan" id="kobo.27.1">MISD</span></strong><span class="koboSpan" id="kobo.28.1">), and </span><strong><span class="koboSpan" id="kobo.29.1">Multiple Instruction Multiple Data</span></strong><span class="koboSpan" id="kobo.30.1"> (</span><strong><span class="koboSpan" id="kobo.31.1">MIMD</span></strong><span class="koboSpan" id="kobo.32.1">):</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.33.1"><img src="assets/315c390f-4c31-4a69-811e-5696dff064d1.png" style="width:42.75em;height:14.83em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.34.1">Flynn's taxonomy</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Single Instruction Single Data (SISD)</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The SISD computing system is like the von Neumann machine, which is a uniprocessor machine. </span><span class="koboSpan" id="kobo.2.2">As you can see in </span><em><span class="koboSpan" id="kobo.3.1">Flynn's taxonomy</span></em><span class="koboSpan" id="kobo.4.1"> diagram, it executes a single instruction that operates on a single data stream. </span><span class="koboSpan" id="kobo.4.2">In SISD, machine instructions are processed sequentially.</span></p>
<p><span class="koboSpan" id="kobo.5.1">In a clock cycle, the CPU executes the following operations:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.6.1">Fetch</span></strong><span class="koboSpan" id="kobo.7.1">: The CPU fetches the data and instructions from a memory area, which is called a </span><em><span class="koboSpan" id="kobo.8.1">register</span></em><span class="koboSpan" id="kobo.9.1">.</span></li>
<li><strong><span class="koboSpan" id="kobo.10.1">Decode</span></strong><span class="koboSpan" id="kobo.11.1">: The CPU decodes the instructions.</span></li>
<li><strong><span class="koboSpan" id="kobo.12.1">Execute</span></strong><span class="koboSpan" id="kobo.13.1">: The instruction is carried out on the data. </span><span class="koboSpan" id="kobo.13.2">The result of the operation is stored in another register.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.14.1">Once the execution stage is complete, the CPU sets itself to begin another CPU cycle:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.15.1"><img src="assets/8d131bb3-cd52-4f51-969c-8c836a394f89.png" style="width:14.50em;height:10.50em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.16.1">The fetch, decode, and execute cycle</span></div>
<p><span class="koboSpan" id="kobo.17.1">The algorithms that run on this type of computer are sequential (or serial) since they do not contain any parallelism. </span><span class="koboSpan" id="kobo.17.2">An example of a SISD computer is a hardware system with a single CPU.</span></p>
<p><span class="koboSpan" id="kobo.18.1">The main elements of these architectures (namely, von Neumann architectures) are as follows:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.19.1">Central memory unit</span></strong><span class="koboSpan" id="kobo.20.1">: This is used to store both instructions and program data.</span></li>
<li><strong><span class="koboSpan" id="kobo.21.1">CPU</span></strong><span class="koboSpan" id="kobo.22.1">: This is used to get the instruction and/or data from the memory unit, which decodes the instructions and sequentially implements them.</span></li>
<li><strong><span class="koboSpan" id="kobo.23.1">The I/O system</span></strong><span class="koboSpan" id="kobo.24.1">: This refers to the input and output data of the program.</span></li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"><span><span class="koboSpan" id="kobo.25.1">Conventional single-processor computers are classified as SISD systems:</span></span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.26.1"><img src="assets/1a6b6929-c4c4-41bb-96ae-2ec6b2aea55d.png" style="width:37.50em;height:19.92em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span><span class="koboSpan" id="kobo.27.1">The SISD architecture schema</span></span></div>
<p><span class="koboSpan" id="kobo.28.1"> </span></p>
<p class="mce-root"><span><span class="koboSpan" id="kobo.29.1">The following diagram specifically shows which areas of a CPU are </span></span><span><span class="koboSpan" id="kobo.30.1">used</span></span><span><span class="koboSpan" id="kobo.31.1"> in the stages of fetch, decode, and execute:</span></span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.32.1"><img src="assets/9ceec645-0aa1-4c90-97a7-cba9f8eb5031.png" style="width:35.33em;height:22.58em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.33.1">CPU components in the fetch-decode-execute phase</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Multiple Instruction Single Data (MISD)</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In this model, </span><em><span class="koboSpan" id="kobo.3.1">n</span></em><span class="koboSpan" id="kobo.4.1"> processors, each with their own control unit, share a single memory unit. </span><span class="koboSpan" id="kobo.4.2">In each clock cycle, the data received from the memory is processed by all processors simultaneously, each in accordance with the instructions received from its control unit.</span></p>
<p><span class="koboSpan" id="kobo.5.1">In this case, the parallelism (instruction-level parallelism) is obtained by performing several operations on the same piece of data. </span><span class="koboSpan" id="kobo.5.2">The types of problems that can be solved efficiently in these architectures are rather special, such as data encryption. </span><span class="koboSpan" id="kobo.5.3">For this reason, the MISD </span><span><span class="koboSpan" id="kobo.6.1">computer has not found</span></span><span class="koboSpan" id="kobo.7.1"> space in the commercial sector. </span><span class="koboSpan" id="kobo.7.2">MISD computers are more of an intellectual exercise than a practical configuration.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Single Instruction Multiple Data (SIMD)</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">A SIMD computer consists of </span><em><span class="koboSpan" id="kobo.3.1">n</span></em><span class="koboSpan" id="kobo.4.1"> identical processors, each with their own local memory, where it is possible to store data. </span><span class="koboSpan" id="kobo.4.2">All processors work under the control of a single instruction stream. </span><span class="koboSpan" id="kobo.4.3">In addition to this, there are </span><em><span class="koboSpan" id="kobo.5.1">n</span></em><span class="koboSpan" id="kobo.6.1"> data streams, one for each processor. </span><span class="koboSpan" id="kobo.6.2">The processors work simultaneously on each step and execute the same instructions, but on different data elements. </span><span class="koboSpan" id="kobo.6.3">This is an example of data-level parallelism.</span></p>
<p><span class="koboSpan" id="kobo.7.1">The SIMD architectures are much more versatile than MISD architectures. </span><span class="koboSpan" id="kobo.7.2">Numerous problems covering a wide range of applications can be solved by parallel algorithms on SIMD computers. </span><span class="koboSpan" id="kobo.7.3">Another interesting feature is that the algorithms for these computers are relatively easy to design, analyze, and implement. </span><span class="koboSpan" id="kobo.7.4">The limitation is that only the problems that can be divided into a number of subproblems (which are all identical, each of which will then be solved simultaneously through the same set of instructions) can be addressed with the SIMD computer.</span></p>
<p><span class="koboSpan" id="kobo.8.1">With the supercomputer developed according to this paradigm, we must mention the </span><em><span class="koboSpan" id="kobo.9.1">Connection Machine</span></em><span class="koboSpan" id="kobo.10.1"> (Thinking Machine, </span><span><span class="koboSpan" id="kobo.11.1">1985</span></span><span class="koboSpan" id="kobo.12.1">) and </span><em><span class="koboSpan" id="kobo.13.1">MPP</span></em><span class="koboSpan" id="kobo.14.1"> (NASA, 1983).</span></p>
<p><span class="koboSpan" id="kobo.15.1">As we will see in </span><a href="1ea5f8e3-bc1e-4d48-8ffe-d96ed8d56259.xhtml"><span class="koboSpan" id="kobo.16.1">Chapter 6</span></a><span class="koboSpan" id="kobo.17.1">, </span><em><span class="koboSpan" id="kobo.18.1">Distributed Python</span></em><span class="koboSpan" id="kobo.19.1">, and </span><a href="c043f263-c2f1-40ce-a390-c0999635225c.xhtml"><span class="koboSpan" id="kobo.20.1">Chapter 7</span></a><span class="koboSpan" id="kobo.21.1">, </span><em><span class="koboSpan" id="kobo.22.1">Cloud Computing</span></em><span class="koboSpan" id="kobo.23.1">, the advent of modern graphics cards (GPUs), built with many SIMD-embedded units, has led to the more widespread use of this computational paradigm.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Multiple Instruction Multiple Data (MIMD)</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">This class of parallel computers is the most general and most powerful class, according to Flynn's classification. </span><span class="koboSpan" id="kobo.2.2">This contains </span><em><span class="koboSpan" id="kobo.3.1">n</span></em><span class="koboSpan" id="kobo.4.1"> processors, </span><em><span class="koboSpan" id="kobo.5.1">n</span></em><span class="koboSpan" id="kobo.6.1"> instruction streams, and </span><em><span class="koboSpan" id="kobo.7.1">n</span></em><span class="koboSpan" id="kobo.8.1"> data streams. </span><span class="koboSpan" id="kobo.8.2">Each processor has its own control unit and local memory, which makes MIMD architectures more computationally powerful than SIMD architectures.</span></p>
<p><span class="koboSpan" id="kobo.9.1">Each processor operates under the control of a flow of instructions issued by its own control unit. </span><span class="koboSpan" id="kobo.9.2">Therefore, the processors can potentially run different programs with different data, which allows them to solve subproblems that are different and can be a part of a single larger problem. In MIMD, the architecture is achieved with the help of the parallelism level with threads and/or processes. </span><span class="koboSpan" id="kobo.9.3">This also means that the processors usually operate asynchronously. </span></p>
<p><span class="koboSpan" id="kobo.10.1">Nowadays, this architecture is applied to many PCs, supercomputers, and computer networks. </span><span class="koboSpan" id="kobo.10.2">However, there is a counter that you need to consider: asynchronous algorithms are difficult to design, analyze, and implement:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.11.1"><img src="assets/f3fa5a98-1a89-4d76-a8af-c25a376c1ac8.png" style="width:33.50em;height:20.00em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.12.1">The SIMD architecture (A) and the MIMD architecture (B)</span></div>
<p><span class="koboSpan" id="kobo.13.1">Flynn's taxonomy can be extended by considering that SIMD machines can be divided into two subgroups:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.14.1">Numerical supercomputers</span></li>
<li><span class="koboSpan" id="kobo.15.1">Vectorial machines</span></li>
</ul>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.16.1">On the other hand, MIMD can be divided into machines that have a shared memory</span><em><span class="koboSpan" id="kobo.17.1"> </span></em><span class="koboSpan" id="kobo.18.1">and those that have a distributed memory.</span></p>
<p><span class="koboSpan" id="kobo.19.1">Indeed the next section focuses on this last aspect of the organization of the memory of MIMD machines.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Memory organization</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Another aspect that we need to consider in order to evaluate parallel architectures is memory organization, or rather, the way in which data is accessed. </span><span class="koboSpan" id="kobo.2.2">No matter how fast the processing unit is, if memory cannot maintain and provide instructions and data at a sufficient speed, then there will be no improvement in performance.</span></p>
<p><span class="koboSpan" id="kobo.3.1">The main problem that we need to overcome to make the response time of memory compatible with the speed of the processor is the memory cycle time, which is defined as the time that has elapsed between two successive operations. </span><span class="koboSpan" id="kobo.3.2">The cycle time of the processor is typically much shorter than the cycle time of memory.</span></p>
<p><span class="koboSpan" id="kobo.4.1">When a processor initiates a transfer to or from memory, the processor's resources will remain occupied for the entire duration of the memory cycle; furthermore, during this period, no other device (for example, I/O controller, processor, or even the processor that made the request) will be able to use the memory due to the transfer in progress:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.5.1"><img src="assets/d56ae362-cff1-4d47-97aa-78419437b2b7.png" style="width:43.00em;height:13.08em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.6.1">Memory organization in the MIMD architecture</span></div>
<p><span class="koboSpan" id="kobo.7.1">Solutions to the problem of memory </span><span><span class="koboSpan" id="kobo.8.1">access have </span></span><span class="koboSpan" id="kobo.9.1">resulted in a dichotomy of MIMD architectures. </span><span class="koboSpan" id="kobo.9.2">The first type of system, known as the </span><em><span class="koboSpan" id="kobo.10.1">shared memory</span></em><span class="koboSpan" id="kobo.11.1"> system, has high virtual memory and all processors have equal access to data and instructions in this memory. </span><span class="koboSpan" id="kobo.11.2">The other type of system is the </span><em><strong><span class="koboSpan" id="kobo.12.1">distributed memory</span></strong></em><span class="koboSpan" id="kobo.13.1"> model, wherein each processor has local memory that is not accessible to other processors.</span></p>
<p><span><span class="koboSpan" id="kobo.14.1">What distinguishes memory shared by distributed memory is the management of memory access, which is performed by the processing unit; this distinction is very important for programmers because it determines how different parts of a parallel program must communicate.</span></span></p>
<p><span><span class="koboSpan" id="kobo.15.1">In particular, a distributed memory machine must make copies of shared data in each local memory. </span><span class="koboSpan" id="kobo.15.2">These copies are created by sending a message containing the data to be shared from one processor to another. </span><span class="koboSpan" id="kobo.15.3">A drawback of this memory organization is that, sometimes, these messages can be very large and take a relatively long time to transfer, while in a shared memory system, there is no exchange of messages, and the main problem lies in synchronizing access to shared resources.</span></span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Shared memory</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The schema of a shared memory multiprocessor system is shown in the following diagram. </span><span class="koboSpan" id="kobo.2.2">The physical connections here are quite simple:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.3.1"><img src="assets/0f53e868-04c0-4493-9b33-f9be28089ca2.png" style="width:28.42em;height:11.58em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.4.1">Shared memory architecture schema</span></div>
<p><span class="koboSpan" id="kobo.5.1">Here, the bus structure allows an arbitrary number of devices (</span><strong><span class="koboSpan" id="kobo.6.1">CPU</span></strong><span class="koboSpan" id="kobo.7.1"> + </span><strong><span class="koboSpan" id="kobo.8.1">C</span></strong><strong><span class="koboSpan" id="kobo.9.1">ache</span></strong><span class="koboSpan" id="kobo.10.1"> in the preceding diagram) that share the same channel (</span><strong><span class="koboSpan" id="kobo.11.1">Main Memory</span></strong><span class="koboSpan" id="kobo.12.1">, as shown in the preceding diagram). </span><span class="koboSpan" id="kobo.12.2">The bus protocols were originally designed to allow a single processor and one or more disks or tape controllers to communicate through the shared memory here.</span></p>
<div class="packt_tip"><span class="koboSpan" id="kobo.13.1">Each processor has been associated with cache memory, as it is assumed that the probability that a processor needs to have data or instructions present in the local memory is very high.</span></div>
<p><span class="koboSpan" id="kobo.14.1">The problem occurs when a processor modifies data stored in the memory system that is simultaneously used by other processors. </span><span class="koboSpan" id="kobo.14.2">The new value will pass from the processor cache that has been changed to the shared memory. </span><span class="koboSpan" id="kobo.14.3">Later, however, it must also be passed to all the other processors, so that they do not work with the obsolete value. </span><span class="koboSpan" id="kobo.14.4">This problem is known as the problem of </span><em><span class="koboSpan" id="kobo.15.1">cache coherency</span></em><span class="koboSpan" id="kobo.16.1">—a special case of the problem of memory consistency, which requires hardware implementations that can handle concurrency issues and synchronization, similar to that of thread programming.</span></p>
<p><span class="koboSpan" id="kobo.17.1">The main features of shared memory systems are as follows:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.18.1">The memory is the same for all processors. </span><span class="koboSpan" id="kobo.18.2">For example, all the processors associated with the same data structure will work with the same logical memory addresses, thus accessing the same memory locations.</span></li>
<li><span class="koboSpan" id="kobo.19.1">The synchronization is obtained by reading the tasks of various processors and allowing the shared memory. </span><span class="koboSpan" id="kobo.19.2">In fact, the processors can only access one memory at a time.</span></li>
<li><span class="koboSpan" id="kobo.20.1">A shared memory location must not be changed from a task while another task accesses it.</span></li>
<li><span class="koboSpan" id="kobo.21.1">Sharing data between tasks is fast. </span><span class="koboSpan" id="kobo.21.2">The time required to communicate is the time that one of them takes to read a single location (depending on the speed of memory access).</span></li>
</ul>
<p><span class="koboSpan" id="kobo.22.1">The memory access in shared memory systems is as follows:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.23.1">Uniform Memory Access</span></strong><span class="koboSpan" id="kobo.24.1"> (</span><strong><span class="koboSpan" id="kobo.25.1">UMA</span></strong><span class="koboSpan" id="kobo.26.1">): The fundamental characteristic of this system is the access time to the memory that is constant for each processor and for any area of memory. </span><span class="koboSpan" id="kobo.26.2">For this reason, these systems are also called </span><strong><span class="koboSpan" id="kobo.27.1">Symmetric Multiprocessors</span></strong><span class="koboSpan" id="kobo.28.1"> (</span><strong><span class="koboSpan" id="kobo.29.1">SMPs</span></strong><span class="koboSpan" id="kobo.30.1">). </span><span class="koboSpan" id="kobo.30.2">They are relatively simple to implement, but not very scalable. </span><span class="koboSpan" id="kobo.30.3">The coder is responsible for the management of the synchronization by inserting appropriate controls, semaphores, locks, and more in the program that manages resources.</span></li>
<li><strong><span class="koboSpan" id="kobo.31.1">Non-Uniform Memory Access</span></strong><span class="koboSpan" id="kobo.32.1"> (</span><strong><span class="koboSpan" id="kobo.33.1">NUMA</span></strong><span class="koboSpan" id="kobo.34.1">): These architectures divide the memory into high-speed access area that is assigned to each processor, and also, a common area for the data exchange, with slower access. </span><span class="koboSpan" id="kobo.34.2">These systems are also called </span><strong><span class="koboSpan" id="kobo.35.1">Distributed Shared Memory</span></strong><span class="koboSpan" id="kobo.36.1"> (</span><strong><span class="koboSpan" id="kobo.37.1">DSM</span></strong><span class="koboSpan" id="kobo.38.1">) systems. </span><span class="koboSpan" id="kobo.38.2">They are very scalable, but complex to develop.</span></li>
<li><strong><span class="koboSpan" id="kobo.39.1">No Remote Memory Access</span></strong><span class="koboSpan" id="kobo.40.1"> (</span><strong><span class="koboSpan" id="kobo.41.1">NoRMA</span></strong><span class="koboSpan" id="kobo.42.1">): The memory is physically distributed among the processors (local memory). </span><span class="koboSpan" id="kobo.42.2">All local memories are private and can only access the local processor. </span><span class="koboSpan" id="kobo.42.3">The communication between the processors is through a communication protocol used for exchanging messages, which is known as the </span><em><span class="koboSpan" id="kobo.43.1">message-passing protocol</span></em><span class="koboSpan" id="kobo.44.1">.</span></li>
<li><strong><span class="koboSpan" id="kobo.45.1">Cache-Only Memory Architecture</span></strong><span class="koboSpan" id="kobo.46.1"> (</span><strong><span class="koboSpan" id="kobo.47.1">COMA</span></strong><span class="koboSpan" id="kobo.48.1">): These systems are equipped with only cached memories. </span><span class="koboSpan" id="kobo.48.2">While analyzing NUMA architectures, it was noticed that this architecture kept the local copies of the data in the cache and that this data was stored as duplicates in the main memory. </span><span class="koboSpan" id="kobo.48.3">This architecture removes duplicates and keeps only the cached memories; the memory is physically distributed among the processors (local memory). </span><span class="koboSpan" id="kobo.48.4">All local memories are private and can only access the local processor. </span><span class="koboSpan" id="kobo.48.5">The communication between the processors i</span><span><span class="koboSpan" id="kobo.49.1">s also through the message-passing protocol.</span></span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Distributed memory</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In a system with distributed memory, the memory is associated with each processor and a processor is only able to address its own memory. </span><span class="koboSpan" id="kobo.2.2">Some authors refer to this type of system as a multicomputer, reflecting the fact that the elements of the system are, themselves, small and complete systems of a processor and memory, as you can see in the following diagram:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.3.1"><img src="assets/edbcb72a-7807-4dba-97da-a1e69af3c29d.png" style="width:43.42em;height:13.92em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.4.1">The distributed memory architecture schema</span></div>
<p><span class="koboSpan" id="kobo.5.1">This kind of organization has several advantages:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.6.1">There are no conflicts at the level of the communication bus or switch. </span><span class="koboSpan" id="kobo.6.2">Each processor can use the full bandwidth of their own local memory without any interference from other processors.</span></li>
<li><span class="koboSpan" id="kobo.7.1">The lack of a common bus means that there is no intrinsic limit to the number of processors. </span><span class="koboSpan" id="kobo.7.2">The size of the system is only limited by the network used to connect the processors.</span></li>
<li><span class="koboSpan" id="kobo.8.1">There are no problems with cache coherency. </span><span class="koboSpan" id="kobo.8.2">Each processor is responsible for its own data and does not have to worry about upgrading any copies.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.9.1">The main disadvantage is that communication between processors is more difficult to implement. </span><span class="koboSpan" id="kobo.9.2">If a processor requires data in the memory of another processor, then the two processors should not necessarily exchange messages via the message-passing protocol. </span><span class="koboSpan" id="kobo.9.3">This introduces two sources of slowdown: to build and send a message from one processor to another takes time, and also, any processor should be stopped in order to manage the messages received from other processors. </span><span class="koboSpan" id="kobo.9.4">A program designed to work on a distributed memory machine must be organized as a set of independent tasks that communicate via messages:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.10.1"><img src="assets/6174b7b7-c606-48e1-a585-3412e6d542c7.png" style="width:28.75em;height:14.08em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.11.1">Basic message passing</span></div>
<p><span class="koboSpan" id="kobo.12.1">The main features of distributed memory systems are as follows:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.13.1">Memory is physically distributed between processors; each local memory is directly accessible only by its processor.</span></li>
<li><span class="koboSpan" id="kobo.14.1">Synchronization is achieved by moving data (even if it's just the message itself) between processors (communication).</span></li>
<li><span class="koboSpan" id="kobo.15.1">The subdivision of data in the local memories affects the performance of the machine—it is essential to make subdivisions accurate, so as to minimize the communication between the CPUs. </span><span class="koboSpan" id="kobo.15.2">In addition to this, the processor that coordinates these operations of decomposition and composition must effectively communicate with the processors that operate on the individual parts of data structures.</span></li>
<li><span class="koboSpan" id="kobo.16.1">The message-passing protocol is used so that the CPUs can communicate with each other through the exchange of data packets. </span><span class="koboSpan" id="kobo.16.2">The messages are discrete units of information, in the sense that they have a well-defined identity, so it is always possible to distinguish them from each other.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Massively Parallel Processing (MPP)</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">MPP machines are composed of hundreds of processors (which can be as large as hundreds of thousands of processors in some machines) that are connected by a communication network. </span><span class="koboSpan" id="kobo.2.2">The fastest computers in the world are based on these architectures; some examples of these architecture </span><span><span class="koboSpan" id="kobo.3.1">systems</span></span><span class="koboSpan" id="kobo.4.1"> are Earth Simulator, Blue Gene, ASCI White, ASCI Red, and ASCI Purple and Red Storm.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Clusters of workstations</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">These processing systems are based on classical computers that are connected by communication networks. </span><span class="koboSpan" id="kobo.2.2">Computational clusters fall into this classification.</span></p>
<p><span class="koboSpan" id="kobo.3.1">In a cluster architecture, we define a node as a single computing unit that takes part in the cluster. </span><span class="koboSpan" id="kobo.3.2">For the user, the cluster is fully transparent—all the hardware and software complexity is masked and data and applications are made accessible as if they were all from a single node.</span></p>
<p><span class="koboSpan" id="kobo.4.1">Here, we've identified three types of clusters:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.5.1">Fail-over cluster</span></strong><span class="koboSpan" id="kobo.6.1">: In this, the node's activity is continuously monitored, and when one stops working, another machine takes over the charge of those activities. </span><span class="koboSpan" id="kobo.6.2">The aim is to ensure a continuous service due to the redundancy of the architecture.</span></li>
<li><strong><span class="koboSpan" id="kobo.7.1">Load balancing cluster</span></strong><span class="koboSpan" id="kobo.8.1">: In this system, a job request is sent to the node that has less activity. </span><span class="koboSpan" id="kobo.8.2">This ensures that less time is taken to process the job.</span></li>
<li><strong><span class="koboSpan" id="kobo.9.1">High-performance computing cluster</span></strong><span class="koboSpan" id="kobo.10.1">: In this, each node is configured to provide extremely high performance. </span><span class="koboSpan" id="kobo.10.2">The process is also divided into multiple jobs on multiple nodes. </span><span class="koboSpan" id="kobo.10.3">The jobs are parallelized and will be distributed to different machines.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Heterogeneous architectures</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The introduction of GPU accelerators in the homogeneous world of supercomputing has changed the nature of how supercomputers are both used and programmed now. </span><span class="koboSpan" id="kobo.2.2">Despite the high performance offered by GPUs, they cannot be considered as an autonomous processing unit as they should always be accompanied by a combination of CPUs. </span><span class="koboSpan" id="kobo.2.3">The programming paradigm, therefore, is very simple: the CPU takes control and computes in a serial manner, assigning tasks t</span><span><span class="koboSpan" id="kobo.3.1">o the graphics accelerator </span></span><span class="koboSpan" id="kobo.4.1">that are, computationally, very expensive and have a high degree of parallelism.</span></p>
<p><span class="koboSpan" id="kobo.5.1">The communication between a CPU and a GPU can take place, not only through the use of a high-speed bus but also through the sharing of a single area of memory for both physical or virtual memory. </span><span class="koboSpan" id="kobo.5.2">In fact, in the case where both the devices are not equipped with their own memory areas, it is possible to refer to a common memory area using the software libraries provided by the various programming models, such as </span><em><span class="koboSpan" id="kobo.6.1">CUDA</span></em><span class="koboSpan" id="kobo.7.1"> and </span><em><span class="koboSpan" id="kobo.8.1">OpenCL</span></em><span class="koboSpan" id="kobo.9.1">.</span></p>
<p><span class="koboSpan" id="kobo.10.1">These architectures are called </span><em><span class="koboSpan" id="kobo.11.1">heterogeneous architectures</span></em><span class="koboSpan" id="kobo.12.1">, wherein applications can create data structures in a single address space and send a job to the device hardware, which is appropriate for the resolution of the task. </span><span class="koboSpan" id="kobo.12.2">Several processing tasks can operate safely in the same regions to avoid data consistency problems, thanks to the atomic operations.</span></p>
<p><span class="koboSpan" id="kobo.13.1">So, despite the fact that the CPU and GPU do not seem to work efficiently together, with the use of this new architecture, we can optimize their interaction with, and the performance of, parallel applications:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.14.1"><img src="assets/46dac58e-d70e-4177-bc35-1018279093a9.png" style="width:59.17em;height:30.33em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.15.1">The heterogeneous architecture schema</span></div>
<p class="mce-root"><span class="koboSpan" id="kobo.16.1">In the following section, we introduce the main parallel programming models</span><span><span><span class="koboSpan" id="kobo.17.1">.</span></span></span></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Parallel programming models</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Parallel programming models exist as an abstraction of hardware and memory architectures. </span><span class="koboSpan" id="kobo.2.2">In fact, these models are not specific and do not refer to any particular types of machines or memory architectures. </span><span class="koboSpan" id="kobo.2.3">They can be implemented (at least theoretically) on any kind of machines. </span><span class="koboSpan" id="kobo.2.4">Compared to the previous subdivisions, these programming models are made at a higher level and represent the way in which the software must be implemented to perform parallel computation. </span><span class="koboSpan" id="kobo.2.5">Each model has its own way of sharing information with other processors in order to access memory and divide the work.</span></p>
<p><span class="koboSpan" id="kobo.3.1">In absolute terms, no one model is better than the other. </span><span class="koboSpan" id="kobo.3.2">Therefore, the best solution to be applied will depend very much on the problem that a programmer should address and resolve. </span><span class="koboSpan" id="kobo.3.3">The most widely used models for parallel programming are as follows:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.4.1">Shared memory model</span></li>
<li><span class="koboSpan" id="kobo.5.1">Multithread model</span></li>
<li><span class="koboSpan" id="kobo.6.1">Distributed memory/message passing model</span></li>
<li><span class="koboSpan" id="kobo.7.1">Data-parallel model</span></li>
</ul>
<p><span class="koboSpan" id="kobo.8.1">In this recipe, we will give you an overview of these models.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Shared memory model</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In this model, tasks share a single memory area in which we can read and write asynchronously. </span><span class="koboSpan" id="kobo.2.2">There are mechanisms that allow the coder to control the access to the shared memory; for example, locks or semaphores. </span><span class="koboSpan" id="kobo.2.3">This model offers the advantage that the coder does not have to clarify the communication between tasks. </span><span class="koboSpan" id="kobo.2.4">An important disadvantage, in terms of performance, is that it becomes more difficult to understand and manage data locality. </span><span class="koboSpan" id="kobo.2.5">This refers to keeping data local to the processor that works on conserving memory access, cache refreshes, and bus traffic that occurs when multiple processors use the same data.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Multithread model</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In this model, a process can have multiple flows of execution. </span><span class="koboSpan" id="kobo.2.2">For example, a sequential part is created and, subsequently, a series of tasks are created that can be executed in parallel. </span><span class="koboSpan" id="kobo.2.3">Usually, this type of model is used on shared memory architectures. </span><span class="koboSpan" id="kobo.2.4">So, it will be very important for us to manage the synchronization between threads, as they operate on shared memory, and the programmer must prevent multiple threads from updating the same locations at the same time.</span></p>
<p><span class="koboSpan" id="kobo.3.1">The current-generation CPUs are multithreaded in software and hardware. </span><strong><span class="koboSpan" id="kobo.4.1">POSIX</span></strong><span class="koboSpan" id="kobo.5.1"> (short for </span><strong><span><span class="koboSpan" id="kobo.6.1">Portable Operating System Interface</span></span></strong><span class="koboSpan" id="kobo.7.1">) threads are classic examples of the implementation of multithreading on software. </span><span class="koboSpan" id="kobo.7.2">Intel's Hyper-Threading technology implements multithreading on hardware by switching between two threads when one is stalled or waiting on I/O. </span><span class="koboSpan" id="kobo.7.3">Parallelism can be achieved from this model, even if the data alignment is nonlinear.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Message passing model</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The message passing model is usually applied in cases where each processor has its own memory (distributed memory system). </span><span class="koboSpan" id="kobo.2.2">More tasks can reside on the same physical machine or on an arbitrary number of machines. </span><span class="koboSpan" id="kobo.2.3">The coder is responsible for determining the parallelism and data exchange that occurs through the messages, and it is necessary to request and call a library of functions within the code.</span></p>
<p><span class="koboSpan" id="kobo.3.1">Some of the examples have been around since the 1980s, but only in the mid-1990s was a standardized model </span><span><span class="koboSpan" id="kobo.4.1">created</span></span><span class="koboSpan" id="kobo.5.1">, leading to a de facto standard called a </span><strong><span class="koboSpan" id="kobo.6.1">Message Passing Interface </span></strong><span class="koboSpan" id="kobo.7.1">(</span><strong><span class="koboSpan" id="kobo.8.1">MPI</span></strong><span class="koboSpan" id="kobo.9.1">).</span></p>
<p><span class="koboSpan" id="kobo.10.1">The MPI model is </span><span><span class="koboSpan" id="kobo.11.1">clearly </span></span><span class="koboSpan" id="kobo.12.1">designed with distributed memory, but being models of parallel programming, a multiplatform model can also be used with a shared memory machine:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.13.1"><img src="assets/bd5deb5a-ea45-42d8-ba4e-b7852b6e0fcd.png" style="width:35.75em;height:20.67em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.14.1">Message passing paradigm model</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Data-parallel model</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In this model, we have more tasks that operate on the same data structure, but each task operates on a different portion of data. </span><span class="koboSpan" id="kobo.2.2">In the shared memory architecture, all tasks have access to data through shared memory and distributed memory architectures, where the data structure is divided and resides in the local memory of each task.</span></p>
<p><span class="koboSpan" id="kobo.3.1">To implement this model, a coder must develop a program that specifies the distribution and alignment of data; for example, the current-generation GPUs are highly operational only if data (</span><strong><span class="koboSpan" id="kobo.4.1">Task</span></strong> <strong><span class="koboSpan" id="kobo.5.1">1</span></strong><span class="koboSpan" id="kobo.6.1">, </span><strong><span class="koboSpan" id="kobo.7.1">Task</span></strong> <strong><span class="koboSpan" id="kobo.8.1">2</span></strong><span class="koboSpan" id="kobo.9.1">, </span><strong><span class="koboSpan" id="kobo.10.1">Task</span></strong> <strong><span class="koboSpan" id="kobo.11.1">3</span></strong><span class="koboSpan" id="kobo.12.1">) is aligned, as shown in the following diagram:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.13.1"><img src="assets/93cf041f-f65b-46e5-b36d-59d4ed537910.png" style="width:42.92em;height:20.58em;"/></span></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span class="koboSpan" id="kobo.14.1">The data-parallel paradigm model</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Designing a parallel program</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The design of algorithms that exploit parallelism is based on a series of operations, which must be carried out for the program to perform the job correctly without producing partial or erroneous results. </span><span class="koboSpan" id="kobo.2.2">The macro operations that must be carried out for a correct parallelization of an algorithm are as follows:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.3.1">Task decomposition</span></li>
<li><span class="koboSpan" id="kobo.4.1">Task assignment</span></li>
<li><span class="koboSpan" id="kobo.5.1">Agglomeration</span></li>
<li><span class="koboSpan" id="kobo.6.1">Mapping</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Task decomposition</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In this first phase, the software program is split into tasks or a set of instructions that can then be executed on different processors to implement parallelism. </span><span class="koboSpan" id="kobo.2.2">To perform this subdivision, two methods are used:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.3.1">Domain decomposition</span></strong><span class="koboSpan" id="kobo.4.1">: Here, the data of the problems is decomposed. </span><span class="koboSpan" id="kobo.4.2">The application is common to all the processors that work on different portions of data. </span><span class="koboSpan" id="kobo.4.3">This methodology is used when we have a large amount of data that must be processed.</span></li>
<li><strong><span class="koboSpan" id="kobo.5.1">Functional decomposition</span></strong><span class="koboSpan" id="kobo.6.1">: In this case, the problem is split into tasks, where each task will perform a particular operation on all the available data.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Task assignment</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In this step, the mechanism by which the tasks will be distributed among the various processes is specified. </span><span class="koboSpan" id="kobo.2.2">This phase is very important because it establishes the distribution of workload among the various processors. </span><span class="koboSpan" id="kobo.2.3">Load balancing is crucial here; in fact, all processors must work with continuity, avoiding being in an idle state for a long time.</span></p>
<p><span class="koboSpan" id="kobo.3.1">To perform this, the coder takes into account the possible heterogeneity of the system that tries to assign more tasks to better-performing processors. </span><span class="koboSpan" id="kobo.3.2">Finally, for greater efficiency of parallelization, it is necessary to limit communication as much as possible between processors, as they are often the source of slowdowns and consumption of resources.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Agglomeration</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Agglomeration is the process of combining smaller tasks with larger ones in order to improve performance. </span><span class="koboSpan" id="kobo.2.2">If the previous two stages of the design process partitioned the problem into a number of tasks that greatly exceed the number of processors available, and if the computer is not specifically designed to handle a huge number of small tasks (some architectures, such as GPUs, handle this fine and indeed benefit from running millions, or even billions, of tasks), then the design can turn out to be highly inefficient.</span></p>
<p><span class="koboSpan" id="kobo.3.1">Commonly, this is because tasks have to be communicated to the processor or thread so that they compute the said task. </span><span class="koboSpan" id="kobo.3.2">Most communications have costs that are disproportionate to the amount of data transferred, but also incur a fixed cost for every communication operation (such as the latency, which is inherent in setting up a TCP connection). </span><span class="koboSpan" id="kobo.3.3">If the tasks are too small, then this fixed cost can easily make the design inefficient.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Mapping</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In the mapping stage of the parallel algorithm design process, we specify where each task is to be executed. </span><span class="koboSpan" id="kobo.2.2">The goal is to minimize the total execution time. </span><span class="koboSpan" id="kobo.2.3">Here, you must often make trade-offs, as the two main strategies often conflict with each other:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.3.1">The tasks that communicate frequently should be placed in the same processor to increase locality.</span></li>
<li><span class="koboSpan" id="kobo.4.1">The tasks that can be executed concurrently should be placed in different processors to enhance concurrency.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.5.1">This is known as the </span><em><span class="koboSpan" id="kobo.6.1">mapping problem</span></em><span class="koboSpan" id="kobo.7.1">, and it is known to be </span><strong><span class="koboSpan" id="kobo.8.1">NP-complete</span></strong><span class="koboSpan" id="kobo.9.1">. </span><span class="koboSpan" id="kobo.9.2">As such, no polynomial-time solutions to the problem in the general case exist. </span><span class="koboSpan" id="kobo.9.3">For tasks of equal size and tasks with easily identified communication patterns, the mapping is straightforward (we can also perform agglomeration here to combine tasks that map to the same processor). </span><span class="koboSpan" id="kobo.9.4">However, if the tasks have communication patterns that are hard to predict or the amount of work varies per task, then it is hard to design an efficient mapping and agglomeration scheme.</span></p>
<p><span class="koboSpan" id="kobo.10.1">For these types of problems, load balancing algorithms can be used to identify agglomeration and mapping strategies during runtime. </span><span class="koboSpan" id="kobo.10.2">The hardest problems are those in which the amount of communication or the number of tasks changes during the execution of the program. </span><span class="koboSpan" id="kobo.10.3">For these kinds of problems, dynamic load balancing algorithms can be used, which run periodically during the execution.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Dynamic mapping</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Numerous load balancing algorithms exist for a variety of problems:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.3.1">Global algorithms</span></strong><span class="koboSpan" id="kobo.4.1">: These require global knowledge of the computation being performed, which often adds a lot of overhead.</span></li>
<li><strong><span class="koboSpan" id="kobo.5.1">Local algorithms</span></strong><span class="koboSpan" id="kobo.6.1">: These rely only on information that is local to the task in question, which reduces overhead compared to global algorithms, but they are usually worse at finding optimal agglomeration and mapping.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.7.1">However, the reduced overhead may reduce the execution time, even though the mapping is worse by itself. </span><span class="koboSpan" id="kobo.7.2">If the tasks rarely communicate other than at the start and end of the execution, then a task-scheduling algorithm is often used, which simply maps tasks to processors as they become idle. </span><span class="koboSpan" id="kobo.7.3">In a task-scheduling algorithm, a task pool is maintained. </span><span class="koboSpan" id="kobo.7.4">Tasks are placed in this pool and are taken from it by workers.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.8.1">There are three common approaches in this model:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.9.1">Manager/worker: </span></strong><span class="koboSpan" id="kobo.10.1">This is the basic dynamic mapping scheme in which all the workers connect to a centralized manager. </span><span class="koboSpan" id="kobo.10.2">The manager repeatedly sends tasks to the workers and collects the results. </span><span class="koboSpan" id="kobo.10.3">This strategy is probably the best for a relatively small number of processors. </span><span class="koboSpan" id="kobo.10.4">The basic strategy can be improved by fetching tasks in advance so that communication and computation overlap each other.</span></li>
<li><strong><span class="koboSpan" id="kobo.11.1">Hierarchical manager/worker</span></strong><span class="koboSpan" id="kobo.12.1">: This is the variant of a manager/worker that has a semi-distributed layout. </span><span class="koboSpan" id="kobo.12.2">Workers are split into groups, each with their own manager. </span><span class="koboSpan" id="kobo.12.3">These group managers communicate with the central manager (and possibly among themselves as well), while workers request tasks from the group managers. </span><span class="koboSpan" id="kobo.12.4">This spreads the load among several managers and can, as such, handle a larger number of processors if all workers request tasks from the same manager.</span></li>
<li><strong><span class="koboSpan" id="kobo.13.1">Decentralize</span></strong><span class="koboSpan" id="kobo.14.1">: In this scheme, everything is decentralized. </span><span class="koboSpan" id="kobo.14.2">Each processor maintains its own task pool and communicates with the other processors in order to request tasks. </span><span class="koboSpan" id="kobo.14.3">How the processors choose other processors to request tasks varies and is determined on the basis of the problem.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Evaluating the performance of a parallel program</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The development of parallel programming created the need for performance metrics in order to decide whether its use is convenient or not. </span><span class="koboSpan" id="kobo.2.2">Indeed, the focus of parallel computing is to solve large problems in a relatively short period of time. </span><span class="koboSpan" id="kobo.2.3">The factors contributing to this objective are, for example, the type of hardware used, the degree of parallelism of the problem, and the parallel programming model adopted. </span><span class="koboSpan" id="kobo.2.4">To facilitate this, the analysis of basic concepts was introduced, which compares the parallel algorithm obtained from the original sequence.</span></p>
<p><span class="koboSpan" id="kobo.3.1">The performance is achieved by analyzing and quantifying the number of threads and/or the number of processes used. </span><span class="koboSpan" id="kobo.3.2">To analyze this, let's </span><span><span class="koboSpan" id="kobo.4.1">introduce </span></span><span class="koboSpan" id="kobo.5.1">a few performance indexes:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.6.1">Speedup</span></strong></li>
<li><strong><span class="koboSpan" id="kobo.7.1">Efficiency</span></strong></li>
<li><strong><span class="koboSpan" id="kobo.8.1">Scaling</span></strong></li>
</ul>
<p><span class="koboSpan" id="kobo.9.1">The limitations of parallel computation are introduced by </span><strong><span class="koboSpan" id="kobo.10.1">Amdahl</span></strong><span class="koboSpan" id="kobo.11.1">'s law. </span><span class="koboSpan" id="kobo.11.2">To evaluate the </span><em><span class="koboSpan" id="kobo.12.1">degree of efficiency</span></em><span class="koboSpan" id="kobo.13.1"> of the parallelization of a sequential algorithm, we have </span><strong><span class="koboSpan" id="kobo.14.1">Gustafson</span></strong><span class="koboSpan" id="kobo.15.1">'s law.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Speedup</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The </span><strong><span class="koboSpan" id="kobo.3.1">speedup</span></strong><span class="koboSpan" id="kobo.4.1"> is the measure that displays the benefit of solving a problem in parallel. </span><span class="koboSpan" id="kobo.4.2">It is defined as the ratio of the time taken to solve a problem on a single processing element (</span><em><span class="koboSpan" id="kobo.5.1">Ts</span></em><span class="koboSpan" id="kobo.6.1">) to the time required to solve the same problem on </span><em><span class="koboSpan" id="kobo.7.1">p</span></em><span class="koboSpan" id="kobo.8.1"> identical processing elements (</span><em><span class="koboSpan" id="kobo.9.1">Tp</span></em><span class="koboSpan" id="kobo.10.1">).</span></p>
<p><span class="koboSpan" id="kobo.11.1">We denote speedup as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.12.1"> </span><span class="koboSpan" id="kobo.13.1"><img class="fm-editor-equation" src="assets/d06f79cc-0130-4c88-9669-be45342198b8.png" style="width:3.42em;height:2.33em;"/></span></p>
<p><span class="koboSpan" id="kobo.14.1">We have a linear speedup, where if </span><em><span class="koboSpan" id="kobo.15.1">S=p</span></em><span class="koboSpan" id="kobo.16.1">, then it means that the speed of execution increases with the number of processors. </span><span class="koboSpan" id="kobo.16.2">Of course, this is an ideal case. </span><span class="koboSpan" id="kobo.16.3">While the speedup is absolute when </span><em><span class="koboSpan" id="kobo.17.1">Ts</span></em><span class="koboSpan" id="kobo.18.1"> is the execution time of the best sequential algorithm, the speedup is relative when </span><em><span class="koboSpan" id="kobo.19.1">Ts</span></em><span class="koboSpan" id="kobo.20.1"> is the execution time of the parallel algorithm for a single processor.</span></p>
<p><span class="koboSpan" id="kobo.21.1">Let's recap these conditions:</span></p>
<ul>
<li><em><span class="koboSpan" id="kobo.22.1">S = p</span></em><span class="koboSpan" id="kobo.23.1"> is a linear or ideal speedup.</span></li>
<li><em><span class="koboSpan" id="kobo.24.1">S &lt; p</span></em><span class="koboSpan" id="kobo.25.1"> is a real speedup.</span></li>
<li><em><span class="koboSpan" id="kobo.26.1">S &gt; p</span></em><span class="koboSpan" id="kobo.27.1"> is a superlinear speedup.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Efficiency</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In an ideal world, a parallel system with </span><em><span class="koboSpan" id="kobo.3.1">p</span></em><span class="koboSpan" id="kobo.4.1"> processing elements can give us a speedup that is equal to </span><em><span class="koboSpan" id="kobo.5.1">p</span></em><span class="koboSpan" id="kobo.6.1">. </span><span class="koboSpan" id="kobo.6.2">However, this is very rarely achieved. </span><span class="koboSpan" id="kobo.6.3">Usually, some time is wasted in either idling or communicating. </span><span class="koboSpan" id="kobo.6.4">Efficiency is a measure of how much of the execution time a processing element puts toward doing useful work, given as a fraction of the time spent.</span></p>
<p class="CDPAlignLeft CDPAlign"><span class="koboSpan" id="kobo.7.1">We denote it by </span><em><span class="koboSpan" id="kobo.8.1">E</span></em><span class="koboSpan" id="kobo.9.1"> and can define it as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.10.1"> </span><span class="koboSpan" id="kobo.11.1"><img class="fm-editor-equation" src="assets/a51cb8a0-063e-4177-a8e3-caa123753d53.png" style="width:6.58em;height:2.50em;"/></span></p>
<p class="CDPAlignLeft CDPAlign"><span class="koboSpan" id="kobo.12.1">The algorithms with linear speedup have a value of </span><em><span class="koboSpan" id="kobo.13.1">E = 1</span></em><span class="koboSpan" id="kobo.14.1">. </span><span class="koboSpan" id="kobo.14.2">In other cases, they have the value of </span><em><span class="koboSpan" id="kobo.15.1">E</span></em><span class="koboSpan" id="kobo.16.1"> is less than </span><em><span class="koboSpan" id="kobo.17.1">1</span></em><span class="koboSpan" id="kobo.18.1">. </span><span class="koboSpan" id="kobo.18.2">The three cases are identified as follows:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.19.1">When </span><em><span class="koboSpan" id="kobo.20.1">E = 1</span></em><span class="koboSpan" id="kobo.21.1">, it is a linear case.</span></li>
<li><span class="koboSpan" id="kobo.22.1">When </span><em><span class="koboSpan" id="kobo.23.1">E &lt; 1</span></em><span class="koboSpan" id="kobo.24.1">, it is a real case.</span></li>
<li><span class="koboSpan" id="kobo.25.1">When </span><em><span class="koboSpan" id="kobo.26.1">E &lt;&lt; 1</span></em><span class="koboSpan" id="kobo.27.1">, it is a problem that is parallelizable with low efficiency.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Scaling</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Scaling is defined as the ability to be efficient on a parallel machine. </span><span class="koboSpan" id="kobo.2.2">It identifies the computing power (speed of execution) in proportion to the number of processors. </span><span class="koboSpan" id="kobo.2.3">By increasing the size of the problem and, at the same time, the number of processors, there will be no loss in terms of performance.</span></p>
<p><span class="koboSpan" id="kobo.3.1">The scalable system, depending on the increments of the different factors, may maintain the same efficiency or improve it.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Amdahl's law</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Amdahl's law is a widely used law that is used to design processors and parallel algorithms. </span><span class="koboSpan" id="kobo.2.2">It states that the maximum speedup that can be achieved is limited by the serial component of the program:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.3.1"><img class="fm-editor-equation" src="assets/d0ef21cb-ef7a-401d-990a-5a3b45325d05.png" style="width:4.92em;height:2.33em;"/></span><span class="koboSpan" id="kobo.4.1"> </span></p>
<div class="packt_tip"><em><span class="koboSpan" id="kobo.5.1">1 – P</span></em><span class="koboSpan" id="kobo.6.1"> denotes the serial component (not parallelized) of a program.</span></div>
<p><span class="koboSpan" id="kobo.7.1">This means that, for example, if a program in which 90% of the code can be made parallel, but 10% must remain serial, then the maximum achievable speedup is 9, even for an infinite number of processors.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Gustafson's law</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Gustafson's law states the following:</span></p>
<p style="padding-left: 210px"><span class="koboSpan" id="kobo.3.1"><img class="fm-editor-equation" src="assets/5b33302b-8561-4073-a6df-09072923e8f5.png" style="width:8.58em;height:1.08em;"/></span></p>
<p><span class="koboSpan" id="kobo.4.1">Here, as we indicated in the equation the following applies:</span></p>
<ul>
<li><em><span class="koboSpan" id="kobo.5.1">P</span></em><span class="koboSpan" id="kobo.6.1"> is the </span><em><span class="koboSpan" id="kobo.7.1">number of processors.</span></em></li>
<li><em><span class="koboSpan" id="kobo.8.1">S</span></em><span class="koboSpan" id="kobo.9.1"> is the </span><em><span class="koboSpan" id="kobo.10.1">speedup</span></em><span class="koboSpan" id="kobo.11.1"> factor.</span></li>
<li><em><span class="koboSpan" id="kobo.12.1">α</span></em><span class="koboSpan" id="kobo.13.1"> is the </span><em><span class="koboSpan" id="kobo.14.1">non-parallelizable fraction</span></em><span class="koboSpan" id="kobo.15.1"> of any parallel process.</span></li>
</ul>
<p><span><span class="koboSpan" id="kobo.16.1">G</span></span><span class="koboSpan" id="kobo.17.1">ustafson's law is in cont</span><em><span class="koboSpan" id="kobo.18.1">rast</span></em><span class="koboSpan" id="kobo.19.1"> to Amdahl's law, which, as we described, assumes that the overall workload of a program does not change with respect to the number of processors.</span></p>
<p><span class="koboSpan" id="kobo.20.1">In fact, Gustafson's law suggests that programmers first set the </span><em><span class="koboSpan" id="kobo.21.1">time</span></em><span class="koboSpan" id="kobo.22.1"> allowed for solving a problem in parallel and then based on that (that is time) </span><em><span class="koboSpan" id="kobo.23.1">to size</span></em><span class="koboSpan" id="kobo.24.1"> the problem. </span><span class="koboSpan" id="kobo.24.2">Therefore, the </span><em><span class="koboSpan" id="kobo.25.1">faster</span></em><span class="koboSpan" id="kobo.26.1"> the parallel system is, the </span><em><span class="koboSpan" id="kobo.27.1">greater</span></em><span class="koboSpan" id="kobo.28.1"> the problems that can be solved over the same period of time. </span></p>
<p><span class="koboSpan" id="kobo.29.1">The effect of Gustafson's law was to direct the objectives of computer research towards the selection or reformulation of problems in such a way that the solution of a larger problem would still be possible in the same amount of time. </span><span class="koboSpan" id="kobo.29.2">Furthermore, this law redefines the concept of </span><em><span class="koboSpan" id="kobo.30.1">efficiency</span></em><span class="koboSpan" id="kobo.31.1"> as a need </span><em><span class="koboSpan" id="kobo.32.1">to reduce at least the sequential part</span></em><span class="koboSpan" id="kobo.33.1"> of a program, despite the </span><em><span class="koboSpan" id="kobo.34.1">increase in workload</span></em><span class="koboSpan" id="kobo.35.1">.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Introducing Python</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Python is a powerful, dynamic, and interpreted programming language that is used in a wide variety of applications. </span><span class="koboSpan" id="kobo.2.2">Some of its features are as follows:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.3.1">A clear and readable syntax.</span></li>
<li><span class="koboSpan" id="kobo.4.1">A very extensive standard library, where, through additional software modules, we can add data types, functions, and objects.</span></li>
<li><span class="koboSpan" id="kobo.5.1">Easy-to-learn rapid development and debugging. </span><span class="koboSpan" id="kobo.5.2">Developing Python code in Python can be up to 10 times faster than in C/C++ code. </span><span class="koboSpan" id="kobo.5.3">The code can also work as a prototype and then translated into C/C ++.</span></li>
<li><span class="koboSpan" id="kobo.6.1">Exception-based error handling.</span></li>
<li><span class="koboSpan" id="kobo.7.1">A strong introspection functionality.</span></li>
<li><span class="koboSpan" id="kobo.8.1">The richness of documentation and a software community.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.9.1">Python can be seen as a glue language. </span><span class="koboSpan" id="kobo.9.2">Using Python, better applications can be developed because different kinds of coders can work together on a project. </span><span class="koboSpan" id="kobo.9.3">For example, when building a scientific application, C/C++ programmers can implement efficient numerical algorithms, while scientists on the same project can write Python programs that test and use those algorithms. </span><span class="koboSpan" id="kobo.9.4">Scientists don't have to learn a low-level programming language and C/C++ programmers don't need to understand the science involved.</span></p>
<div class="packt_infobox">
<p><span class="koboSpan" id="kobo.10.1">You can read more about this from </span><a href="https://www.python.org/doc/essays/omg-darpa-mcc-position"><span class="koboSpan" id="kobo.11.1">https://www.python.org/doc/essays/omg-darpa-mcc-position</span></a><span class="koboSpan" id="kobo.12.1">.</span></p>
</div>
<p><span><span class="koboSpan" id="kobo.13.1">Let's take a look at some examples of very basic code to get an idea of the features of Python.</span></span></p>
<div class="packt_infobox"><span class="koboSpan" id="kobo.14.1">The following section can be a refresher for most of you. </span><span class="koboSpan" id="kobo.14.2">We will use these techniques practically in </span><a href="c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml"><span class="koboSpan" id="kobo.15.1">Chapter 2</span></a><span class="koboSpan" id="kobo.16.1">, </span><em><span class="koboSpan" id="kobo.17.1">Thread-Based Parallelism</span></em><span class="koboSpan" id="kobo.18.1">, and </span><a href="5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml" target="_blank"><span class="koboSpan" id="kobo.19.1">Chapter 3</span></a><span class="koboSpan" id="kobo.20.1">, </span><em><span class="koboSpan" id="kobo.21.1">Process-Based Parallelism</span></em><span class="koboSpan" id="kobo.22.1">.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Help functions</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The Python interpreter already provides a valid help system. </span><span class="koboSpan" id="kobo.2.2">If you want to know how to use an object, then just type </span><kbd><span class="koboSpan" id="kobo.3.1">help(object)</span></kbd><span class="koboSpan" id="kobo.4.1">.</span></p>
<p><span class="koboSpan" id="kobo.5.1">Let's see, for example, how to use the </span><kbd><span class="koboSpan" id="kobo.6.1">help</span></kbd><span class="koboSpan" id="kobo.7.1"> function on integer </span><kbd><span class="koboSpan" id="kobo.8.1">0</span></kbd><span class="koboSpan" id="kobo.9.1">:</span></p>
<pre><strong><span class="koboSpan" id="kobo.10.1">&gt;&gt;&gt; help(0)</span></strong><br/><strong><span class="koboSpan" id="kobo.11.1">Help on int object:</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.12.1">class int(object)</span></strong><br/><strong><span class="koboSpan" id="kobo.13.1"> | int(x=0) -&gt; integer</span></strong><br/><strong><span class="koboSpan" id="kobo.14.1"> | int(x, base=10) -&gt; integer</span></strong><br/><strong><span class="koboSpan" id="kobo.15.1"> | </span></strong><br/><strong><span class="koboSpan" id="kobo.16.1"> | Convert a number or string to an integer, or return 0 if no </span><br/><span class="koboSpan" id="kobo.17.1"> | arguments</span></strong><strong><span class="koboSpan" id="kobo.18.1"> are given. </span><span class="koboSpan" id="kobo.18.2">If x is a number, return x.__int__(). </span><span class="koboSpan" id="kobo.18.3">For </span><br/><span class="koboSpan" id="kobo.19.1"> | floating point </span></strong><strong><span class="koboSpan" id="kobo.20.1">numbers, this truncates towards zero.</span></strong><br/><strong><span class="koboSpan" id="kobo.21.1"> | </span></strong><br/><strong><span class="koboSpan" id="kobo.22.1"> | If x is not a number or if base is given, then x must be a string,</span></strong><br/><strong><span class="koboSpan" id="kobo.23.1"> | bytes, or bytearray instance representing an integer literal in the</span></strong><br/><strong><span class="koboSpan" id="kobo.24.1"> | given base. </span><span class="koboSpan" id="kobo.24.2">The literal can be preceded by '+' or '-' and be</span><br/><span class="koboSpan" id="kobo.25.1"> | surrounded </span></strong><strong><span class="koboSpan" id="kobo.26.1">by whitespace. </span><span class="koboSpan" id="kobo.26.2">The base defaults to 10. </span><span class="koboSpan" id="kobo.26.3">Valid bases are 0 </span><br/><span class="koboSpan" id="kobo.27.1"> | and 2-36.</span></strong><br/><strong><span class="koboSpan" id="kobo.28.1"> | Base 0 means to interpret the base from the string as an integer </span><br/><span class="koboSpan" id="kobo.29.1"> | literal.</span></strong><br/><strong><span class="koboSpan" id="kobo.30.1">&gt;&gt;&gt; int('0b100', base=0)</span></strong></pre>
<p><span class="koboSpan" id="kobo.31.1">The description of the </span><kbd><span class="koboSpan" id="kobo.32.1">int</span></kbd><span class="koboSpan" id="kobo.33.1"> object is followed by a list of methods that are applicable to it. </span><span class="koboSpan" id="kobo.33.2">The first five methods are as follows:</span></p>
<pre><strong><span class="koboSpan" id="kobo.34.1"> | Methods defined here:</span></strong><br/><strong><span class="koboSpan" id="kobo.35.1"> | </span></strong><br/><strong><span class="koboSpan" id="kobo.36.1"> | __abs__(self, /)</span></strong><br/><strong><span class="koboSpan" id="kobo.37.1"> | abs(self)</span></strong><br/><strong><span class="koboSpan" id="kobo.38.1"> | </span></strong><br/><strong><span class="koboSpan" id="kobo.39.1"> | __add__(self, value, /)</span></strong><br/><strong><span class="koboSpan" id="kobo.40.1"> | Return self+value.</span></strong><br/><strong><span class="koboSpan" id="kobo.41.1"> | </span></strong><br/><strong><span class="koboSpan" id="kobo.42.1"> | __and__(self, value, /)</span></strong><br/><strong><span class="koboSpan" id="kobo.43.1"> | Return self&amp;value.</span></strong><br/><strong><span class="koboSpan" id="kobo.44.1"> | </span></strong><br/><strong><span class="koboSpan" id="kobo.45.1"> | __bool__(self, /)</span></strong><br/><strong><span class="koboSpan" id="kobo.46.1"> | self != 0</span></strong><br/><strong><span class="koboSpan" id="kobo.47.1"> | </span></strong><br/><strong><span class="koboSpan" id="kobo.48.1"> | __ceil__(...)</span></strong><br/><strong><span class="koboSpan" id="kobo.49.1"> | Ceiling of an Integral returns itself.</span></strong></pre>
<p><span class="koboSpan" id="kobo.50.1">Also useful is </span><kbd><span class="koboSpan" id="kobo.51.1">dir(object)</span></kbd><span class="koboSpan" id="kobo.52.1">, which lists the methods available for an object:</span></p>
<pre><strong><span class="koboSpan" id="kobo.53.1">&gt;&gt;&gt; dir(float)</span></strong><br/><strong><span class="koboSpan" id="kobo.54.1">['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes']</span></strong></pre>
<p><span class="koboSpan" id="kobo.55.1">Finally, the relevant documentation for an object is provided by the </span><kbd><span class="koboSpan" id="kobo.56.1">.__doc__</span></kbd><span class="koboSpan" id="kobo.57.1"> function, as shown in the following example:</span></p>
<pre><strong><span class="koboSpan" id="kobo.58.1">&gt;&gt;&gt; abs.__doc__</span></strong><br/><strong><span class="koboSpan" id="kobo.59.1">'Return the absolute value of the argument.'</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Syntax</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Python doesn't adopt statement terminators, and code blocks are specified through indentation. </span><span class="koboSpan" id="kobo.2.2">Statements that expect an indentation level must end in a colon (</span><kbd><span class="koboSpan" id="kobo.3.1">:</span></kbd><span class="koboSpan" id="kobo.4.1">). </span><span class="koboSpan" id="kobo.4.2">This leads to the following:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.5.1">The Python code is clearer and more readable.</span></li>
<li><span class="koboSpan" id="kobo.6.1">The program structure always coincides with that of the indentation.</span></li>
<li><span class="koboSpan" id="kobo.7.1">The style of indentation is uniform in any listing.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.8.1">Bad indentation can lead to errors.</span></p>
<p><span class="koboSpan" id="kobo.9.1">The following example shows how to use the </span><kbd><span class="koboSpan" id="kobo.10.1">if</span></kbd><span class="koboSpan" id="kobo.11.1"> construct:</span></p>
<pre><span class="koboSpan" id="kobo.12.1">print("first print")</span><br/><span class="koboSpan" id="kobo.13.1">if condition:</span><br/><span class="koboSpan" id="kobo.14.1">    print(“second print”)</span><br/><span class="koboSpan" id="kobo.15.1">print(“third print”)</span></pre>
<p><span class="koboSpan" id="kobo.16.1">In this example, we can see the following:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.17.1">The following statements: </span><kbd><span class="koboSpan" id="kobo.18.1">print("first print")</span></kbd><span class="koboSpan" id="kobo.19.1">, </span><kbd><span class="koboSpan" id="kobo.20.1">if condition:</span></kbd><span class="koboSpan" id="kobo.21.1">, </span><kbd><span class="koboSpan" id="kobo.22.1">print("third print")</span></kbd><span class="koboSpan" id="kobo.23.1"> have the same indentation level and are always executed.</span></li>
<li><span class="koboSpan" id="kobo.24.1">After the </span><kbd><span class="koboSpan" id="kobo.25.1">if</span></kbd><span class="koboSpan" id="kobo.26.1"> statement, there is a block of code with a higher indentation level, which includes the </span><kbd><span class="koboSpan" id="kobo.27.1">print ("second print")</span></kbd><span class="koboSpan" id="kobo.28.1"> </span><span><span class="koboSpan" id="kobo.29.1">statement.</span></span></li>
<li><span class="koboSpan" id="kobo.30.1">If the condition of </span><kbd><span class="koboSpan" id="kobo.31.1">if</span></kbd><span class="koboSpan" id="kobo.32.1"> is true, then the </span><kbd><span class="koboSpan" id="kobo.33.1">print ("second print")</span></kbd><span class="koboSpan" id="kobo.34.1"> statement is executed.</span></li>
<li><span class="koboSpan" id="kobo.35.1">If the condition of </span><kbd><span class="koboSpan" id="kobo.36.1">if</span></kbd><span class="koboSpan" id="kobo.37.1"> is false, then the </span><kbd><span class="koboSpan" id="kobo.38.1">print ("second print")</span></kbd><span class="koboSpan" id="kobo.39.1"> statement is not executed.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.40.1">It is, therefore, very important to pay attention to indentation because it is always evaluated in the program parsing process.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Comments</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Comments start with the hash sign (</span><kbd><span class="koboSpan" id="kobo.3.1">#</span></kbd><span class="koboSpan" id="kobo.4.1">) and are on a single line:</span></p>
<pre><strong><span class="koboSpan" id="kobo.5.1"># single line comment</span></strong></pre>
<p class="mce-root"><span class="koboSpan" id="kobo.6.1">Multi-line strings are used for multi-line comments:</span></p>
<pre class="mce-root"><strong><span class="koboSpan" id="kobo.7.1">""" first line of a multi-line comment</span></strong><br/><strong><span class="koboSpan" id="kobo.8.1">second line of a multi-line comment."""</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Assignments</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Assignments are made with the equals symbol (</span><kbd><span class="koboSpan" id="kobo.3.1">=</span></kbd><span class="koboSpan" id="kobo.4.1">). </span><span class="koboSpan" id="kobo.4.2">For equality tests, the same amount (</span><kbd><span class="koboSpan" id="kobo.5.1">==</span></kbd><span class="koboSpan" id="kobo.6.1">) is used. </span><span class="koboSpan" id="kobo.6.2">You can increase and decrease a value using the </span><kbd><span class="koboSpan" id="kobo.7.1">+=</span></kbd><span class="koboSpan" id="kobo.8.1"> and </span><kbd><span class="koboSpan" id="kobo.9.1">-=</span></kbd><span class="koboSpan" id="kobo.10.1"> operators, followed by an addendum. </span><span class="koboSpan" id="kobo.10.2">This works with many types of data, including strings. </span><span class="koboSpan" id="kobo.10.3">You can assign and use multiple variables on the same line.</span></p>
<p><span class="koboSpan" id="kobo.11.1">Some examples are as follows:</span></p>
<pre><strong><span class="koboSpan" id="kobo.12.1">&gt;&gt;&gt; variable = 3</span></strong><br/><strong><span class="koboSpan" id="kobo.13.1">&gt;&gt;&gt; variable += 2</span></strong><br/><strong><span class="koboSpan" id="kobo.14.1">&gt;&gt;&gt; variable</span></strong><br/><strong><span class="koboSpan" id="kobo.15.1">5</span></strong><br/><strong><span class="koboSpan" id="kobo.16.1">&gt;&gt;&gt; variable -= 1</span></strong><br/><strong><span class="koboSpan" id="kobo.17.1">&gt;&gt;&gt; variable</span></strong><br/><strong><span class="koboSpan" id="kobo.18.1">4</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.19.1">&gt;&gt;&gt; _string_ = "Hello"</span></strong><br/><strong><span class="koboSpan" id="kobo.20.1">&gt;&gt;&gt; _string_ += " Parallel Programming CookBook Second Edition!"</span></strong><br/><strong><span class="koboSpan" id="kobo.21.1">&gt;&gt;&gt; print (_string_) </span></strong><br/><strong><span class="koboSpan" id="kobo.22.1">Hello Parallel Programming CookBook Second Edition!</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Data types</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The most significant structures in Python are </span><em><span class="koboSpan" id="kobo.3.1">lists</span></em><span class="koboSpan" id="kobo.4.1">, </span><em><span class="koboSpan" id="kobo.5.1">tuples</span></em><span class="koboSpan" id="kobo.6.1">,</span><em><span class="koboSpan" id="kobo.7.1"> </span></em><span class="koboSpan" id="kobo.8.1">and </span><em><span class="koboSpan" id="kobo.9.1">dictionaries</span></em><span class="koboSpan" id="kobo.10.1">. </span><span class="koboSpan" id="kobo.10.2">Sets have been integrated into Python since version 2.5 (the previous versions are available in the </span><kbd><span class="koboSpan" id="kobo.11.1">sets</span></kbd><span class="koboSpan" id="kobo.12.1"> library):</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.13.1">Lists</span></strong><span class="koboSpan" id="kobo.14.1">: These are similar to one-dimensional arrays, but you can create lists that contain other lists.</span></li>
<li><strong><span class="koboSpan" id="kobo.15.1">Dictionaries</span></strong><span class="koboSpan" id="kobo.16.1">: These are arrays that contain key pairs and values (hash tables).</span></li>
<li><strong><span class="koboSpan" id="kobo.17.1">Tuples</span></strong><span class="koboSpan" id="kobo.18.1">: These are immutable mono-dimensional objects.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.19.1">Arrays can be of any type, so you can mix variables such as integers and strings into your lists, dictionaries and tuples.</span></p>
<p><span class="koboSpan" id="kobo.20.1">The index of the first object in any type of array is always zero. </span><span class="koboSpan" id="kobo.20.2">Negative indexes are allowed and count from the end of the array; </span><kbd><span class="koboSpan" id="kobo.21.1">-1</span></kbd><span class="koboSpan" id="kobo.22.1"> indicates the last element of the array:</span></p>
<pre><span class="koboSpan" id="kobo.23.1">#let's play with lists</span><br/><span class="koboSpan" id="kobo.24.1">list_1 = [1, ["item_1", "item_1"], ("a", "tuple")]</span><br/><span class="koboSpan" id="kobo.25.1">list_2 = ["item_1", -10000, 5.01]</span><br/><br/><strong><span class="koboSpan" id="kobo.26.1">&gt;&gt;&gt; list_1</span></strong><br/><strong><span class="koboSpan" id="kobo.27.1">[1, ['item_1', 'item_1'], ('a', 'tuple')]</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.28.1">&gt;&gt;&gt; list_2</span></strong><br/><strong><span class="koboSpan" id="kobo.29.1">['item_1', -10000, 5.01]</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.30.1">&gt;&gt;&gt; list_1[2]</span></strong><br/><strong><span class="koboSpan" id="kobo.31.1">('a', 'tuple')</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.32.1">&gt;&gt;&gt;list_1[1][0]</span></strong><br/><strong><span class="koboSpan" id="kobo.33.1">['item_1', 'item_1']</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.34.1">&gt;&gt;&gt; list_2[0]</span></strong><br/><strong><span class="koboSpan" id="kobo.35.1">item_1</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.36.1">&gt;&gt;&gt; list_2[-1]</span></strong><br/><strong><span class="koboSpan" id="kobo.37.1">5.01</span></strong><br/><br/><span class="koboSpan" id="kobo.38.1">#build a dictionary </span><br/><span class="koboSpan" id="kobo.39.1">dictionary = {"Key 1": "item A", "Key 2": "item B", 3: 1000}</span><br/><strong><span class="koboSpan" id="kobo.40.1">&gt;&gt;&gt; dictionary </span></strong><br/><strong><span class="koboSpan" id="kobo.41.1">{'Key 1': 'item A', 'Key 2': 'item B', 3: 1000} </span></strong><br/><br/><strong><span class="koboSpan" id="kobo.42.1">&gt;&gt;&gt; dictionary["Key 1"] </span></strong><br/><strong><span class="koboSpan" id="kobo.43.1">item A</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.44.1">&gt;&gt;&gt; dictionary["Key 2"]</span></strong><br/><strong><span class="koboSpan" id="kobo.45.1">-1</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.46.1">&gt;&gt;&gt; dictionary[3]</span></strong><br/><strong><span class="koboSpan" id="kobo.47.1">1000</span></strong></pre>
<p><span class="koboSpan" id="kobo.48.1">You can get an array range using the colon (</span><kbd><span class="koboSpan" id="kobo.49.1">:</span></kbd><span class="koboSpan" id="kobo.50.1">):</span></p>
<pre><span class="koboSpan" id="kobo.51.1">list_3 = ["Hello", "Ruvika", "how" , "are" , "you?"] </span><br/><strong><span class="koboSpan" id="kobo.52.1">&gt;&gt;&gt; list_3[0:6] </span></strong><br/><strong><span class="koboSpan" id="kobo.53.1">['Hello', 'Ruvika', 'how', 'are', 'you?'] </span></strong><br/><br/><strong><span class="koboSpan" id="kobo.54.1">&gt;&gt;&gt; list_3[0:1]</span></strong><br/><strong><span class="koboSpan" id="kobo.55.1">['Hello']</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.56.1">&gt;&gt;&gt; list_3[2:6]</span></strong><br/><strong><span class="koboSpan" id="kobo.57.1">['how', 'are', 'you?']</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Strings</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Python strings are indicated using either the single (</span><kbd><span class="koboSpan" id="kobo.3.1">'</span></kbd><span class="koboSpan" id="kobo.4.1">) or double (</span><kbd><span class="koboSpan" id="kobo.5.1">"</span></kbd><span class="koboSpan" id="kobo.6.1">) quotation mark and they are allowed to use one notation within a string delimited by the other:</span></p>
<pre><strong><span class="koboSpan" id="kobo.7.1">&gt;&gt;&gt; example = "she loves ' giancarlo"</span></strong><br/><strong><span class="koboSpan" id="kobo.8.1">&gt;&gt;&gt; example</span></strong><br/><strong><span class="koboSpan" id="kobo.9.1">"she loves ' giancarlo"</span></strong></pre>
<p><span class="koboSpan" id="kobo.10.1">On multiple lines, they are enclosed in triple (or three single) quotation marks (</span><kbd><span class="koboSpan" id="kobo.11.1">'''</span></kbd><span class="koboSpan" id="kobo.12.1"> multi-line string </span><kbd><span class="koboSpan" id="kobo.13.1">'''</span></kbd><span class="koboSpan" id="kobo.14.1">):</span></p>
<pre><strong><span class="koboSpan" id="kobo.15.1">&gt;&gt;&gt; _string_='''I am a </span></strong><br/><strong><span class="koboSpan" id="kobo.16.1">multi-line </span></strong><br/><strong><span class="koboSpan" id="kobo.17.1">string'''</span></strong><br/><strong><span class="koboSpan" id="kobo.18.1">&gt;&gt;&gt; _string_</span></strong><br/><strong><span class="koboSpan" id="kobo.19.1">'I am a \nmulti-line\nstring'</span></strong></pre>
<p><span class="koboSpan" id="kobo.20.1">Python also supports Unicode; just use the </span><kbd><span class="koboSpan" id="kobo.21.1">u "This is a unicode string"</span></kbd><span class="koboSpan" id="kobo.22.1"> </span><span><span class="koboSpan" id="kobo.23.1">syntax :</span></span></p>
<pre><strong><span class="koboSpan" id="kobo.24.1">&gt;&gt;&gt; ustring = u"I am unicode string"</span></strong><br/><strong><span class="koboSpan" id="kobo.25.1">&gt;&gt;&gt; ustring</span></strong><br/><strong><span class="koboSpan" id="kobo.26.1">'I am unicode string'</span></strong></pre>
<p><span class="koboSpan" id="kobo.27.1">To enter values in a string, type the </span><kbd><span class="koboSpan" id="kobo.28.1">%</span></kbd><span class="koboSpan" id="kobo.29.1"> operator and a tuple. </span><span class="koboSpan" id="kobo.29.2">Then, each </span><kbd><span class="koboSpan" id="kobo.30.1">%</span></kbd> <span><span class="koboSpan" id="kobo.31.1">operator </span></span><span class="koboSpan" id="kobo.32.1">is replaced by a tuple element, from left to right</span><em><span class="koboSpan" id="kobo.33.1">:</span></em></p>
<pre><strong><span class="koboSpan" id="kobo.34.1">&gt;&gt;&gt; print ("My name is %s !" </span><span class="koboSpan" id="kobo.34.2">% ('Mr. </span><span class="koboSpan" id="kobo.34.3">Wolf'))</span></strong><br/><strong><span class="koboSpan" id="kobo.35.1">My name is Mr. </span><span class="koboSpan" id="kobo.35.2">Wolf!</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Flow control</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Flow control instructions are </span><kbd><span class="koboSpan" id="kobo.3.1">if</span></kbd><span class="koboSpan" id="kobo.4.1">, </span><kbd><span class="koboSpan" id="kobo.5.1">for</span></kbd><span class="koboSpan" id="kobo.6.1">, and </span><kbd><span class="koboSpan" id="kobo.7.1">while</span></kbd><span class="koboSpan" id="kobo.8.1">.</span></p>
<p><span class="koboSpan" id="kobo.9.1">In the next example, we check whether the number is positive, negative, or zero and display the result:</span></p>
<pre><span class="koboSpan" id="kobo.10.1">num = 1</span><br/><br/><span class="koboSpan" id="kobo.11.1">if num &gt; 0:</span><br/><span class="koboSpan" id="kobo.12.1">    print("Positive number")</span><br/><span class="koboSpan" id="kobo.13.1">elif num == 0:</span><br/><span class="koboSpan" id="kobo.14.1">    print("Zero")</span><br/><span class="koboSpan" id="kobo.15.1">else:</span><br/><span class="koboSpan" id="kobo.16.1">    print("Negative number")</span></pre>
<p><span class="koboSpan" id="kobo.17.1">The following code block finds the sum of all the numbers stored in a list, using a </span><kbd><span class="koboSpan" id="kobo.18.1">for</span></kbd><span class="koboSpan" id="kobo.19.1"> loop:</span></p>
<pre><span class="koboSpan" id="kobo.20.1">numbers = [6, 6, 3, 8, -3, 2, 5, 44, 12]</span><br/><span class="koboSpan" id="kobo.21.1">sum = 0</span><br/><span class="koboSpan" id="kobo.22.1">for val in numbers:</span><br/><span class="koboSpan" id="kobo.23.1">    sum = sum+val</span><br/><span class="koboSpan" id="kobo.24.1">print("The sum is", sum)</span></pre>
<p><span class="koboSpan" id="kobo.25.1">We will execute the </span><kbd><span class="koboSpan" id="kobo.26.1">while</span></kbd><span class="koboSpan" id="kobo.27.1"> loop to iterate the code until the condition result is true. </span><span class="koboSpan" id="kobo.27.2">We will use this loop over the </span><kbd><span class="koboSpan" id="kobo.28.1">for</span></kbd><span class="koboSpan" id="kobo.29.1"> loop since we are unaware of the number of iterations that will result in the code. </span><span class="koboSpan" id="kobo.29.2">In this example, we use </span><kbd><span class="koboSpan" id="kobo.30.1">while</span></kbd><span class="koboSpan" id="kobo.31.1"> to add natural numbers up to </span><em><span class="koboSpan" id="kobo.32.1">sum = 1+2+3+...+n</span></em><span class="koboSpan" id="kobo.33.1">:</span></p>
<pre><span class="koboSpan" id="kobo.34.1">n = 10</span><br/><span class="koboSpan" id="kobo.35.1"># initialize sum and counter</span><br/><span class="koboSpan" id="kobo.36.1">sum = 0</span><br/><span class="koboSpan" id="kobo.37.1">i = 1</span><br/><span class="koboSpan" id="kobo.38.1">while i &lt;= n:</span><br/><span class="koboSpan" id="kobo.39.1">    sum = sum + i</span><br/><span class="koboSpan" id="kobo.40.1">    i = i+1 # update counter</span><br/><br/><span class="koboSpan" id="kobo.41.1"># print the sum</span><br/><span class="koboSpan" id="kobo.42.1">print("The sum is", sum)</span></pre>
<p><span class="koboSpan" id="kobo.43.1">The outputs for the preceding three examples are as follows:</span></p>
<pre><strong><span class="koboSpan" id="kobo.44.1">Positive number</span></strong><br/><strong><span class="koboSpan" id="kobo.45.1">The sum is 83</span></strong><br/><strong><span class="koboSpan" id="kobo.46.1">The sum is 55</span></strong><br/><strong><span class="koboSpan" id="kobo.47.1">&gt;&gt;&gt;</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Functions</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Python functions are declared with the </span><kbd><span class="koboSpan" id="kobo.3.1">def</span></kbd><span class="koboSpan" id="kobo.4.1"> </span><span><span class="koboSpan" id="kobo.5.1">keyword:</span></span></p>
<pre><span class="koboSpan" id="kobo.6.1">def my_function():</span><br/><span class="koboSpan" id="kobo.7.1">    print("this is a function")</span></pre>
<p class="mce-root"><span><span class="koboSpan" id="kobo.8.1">To run a function, use the function name, followed by parentheses, as follows:</span></span></p>
<pre><strong><span class="koboSpan" id="kobo.9.1">&gt;&gt;&gt; my_function()</span></strong><br/><strong><span class="koboSpan" id="kobo.10.1">this is a function</span></strong></pre>
<p><span class="koboSpan" id="kobo.11.1">Parameters must be specified after the function name, inside the parentheses:</span></p>
<pre><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.12.1">def</span></span><span class="koboSpan" id="kobo.13.1"> my_function(x):</span><br/><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.14.1">    print</span></span><span class="koboSpan" id="kobo.15.1">(x * </span><span class="pythonstringcolor"><span class="koboSpan" id="kobo.16.1">1234</span></span><span class="koboSpan" id="kobo.17.1">)</span><br/><br/><strong><span class="koboSpan" id="kobo.18.1">&gt;&gt;&gt; my_function(7)</span></strong><br/><strong><span class="koboSpan" id="kobo.19.1">8638</span></strong></pre>
<p><span class="koboSpan" id="kobo.20.1">Multiple parameters must be separated with a comma:</span></p>
<pre><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.21.1">def</span></span><span class="koboSpan" id="kobo.22.1"> my_function(x,y):</span><br/><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.23.1">    print</span></span><span class="koboSpan" id="kobo.24.1">(x*</span><span class="pythonstringcolor"><span class="koboSpan" id="kobo.25.1">5+ 2*y</span></span><span class="koboSpan" id="kobo.26.1">)</span><br/><br/><strong><span class="koboSpan" id="kobo.27.1">&gt;&gt;&gt; my_function(7,9)</span></strong><br/><strong><span class="koboSpan" id="kobo.28.1">53</span></strong></pre>
<p><span class="koboSpan" id="kobo.29.1">Use the equals sign to define a default parameter. </span><span class="koboSpan" id="kobo.29.2">If you call the function without the parameter, then the default value will be used:</span></p>
<pre><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.30.1">def</span></span><span class="koboSpan" id="kobo.31.1"> my_function(x,y=10):</span><br/><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.32.1">    print</span></span><span class="koboSpan" id="kobo.33.1">(x*</span><span class="pythonstringcolor"><span class="koboSpan" id="kobo.34.1">5+ 2*y</span></span><span class="koboSpan" id="kobo.35.1">)</span><br/><br/><strong><span class="koboSpan" id="kobo.36.1">&gt;&gt;&gt; my_function(1)</span></strong><br/><strong><span class="koboSpan" id="kobo.37.1">25</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.38.1">&gt;&gt;&gt; my_function(1,100)</span></strong><br/><strong><span class="koboSpan" id="kobo.39.1">205</span></strong></pre>
<p class="mce-root"><span class="koboSpan" id="kobo.40.1">The parameters of a function can be of any type of data </span><span><span class="koboSpan" id="kobo.41.1">(such as string, number, list, and</span></span><span class="koboSpan" id="kobo.42.1"> dictionary)</span><span><span class="koboSpan" id="kobo.43.1">.</span></span><span><span class="koboSpan" id="kobo.44.1"> Here, the following list, </span></span><kbd><span class="koboSpan" id="kobo.45.1">lcities</span></kbd><span class="koboSpan" id="kobo.46.1">, </span><span><span class="koboSpan" id="kobo.47.1">is used as a parameter for </span></span><kbd><span><span class="koboSpan" id="kobo.48.1">my_function</span></span></kbd><span><span class="koboSpan" id="kobo.49.1">:</span></span></p>
<pre><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.50.1">def</span></span><span><span class="koboSpan" id="kobo.51.1"> my_function(cities):</span></span><br/><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.52.1">    for</span></span><span><span class="koboSpan" id="kobo.53.1"> x </span></span><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.54.1">in</span></span><span><span class="koboSpan" id="kobo.55.1"> cities:</span></span><br/><span class="pythonkeywordcolor"><span class="koboSpan" id="kobo.56.1">        print</span></span><span><span class="koboSpan" id="kobo.57.1">(x)</span></span><br/><br/><strong><span class="koboSpan" id="kobo.58.1">&gt;&gt;&gt; lcities=["Napoli","Mumbai","Amsterdam"]</span></strong><br/><strong><span class="koboSpan" id="kobo.59.1">&gt;&gt;&gt; my_function(lcities)</span></strong><br/><strong><span class="koboSpan" id="kobo.60.1">Napoli</span></strong><br/><strong><span class="koboSpan" id="kobo.61.1">Mumbai</span></strong><br/><strong><span class="koboSpan" id="kobo.62.1">Amsterdam</span></strong></pre>
<p><span class="koboSpan" id="kobo.63.1">Use the </span><kbd><span class="koboSpan" id="kobo.64.1">return</span></kbd><span class="koboSpan" id="kobo.65.1"> statement to return a value from a function:</span></p>
<pre><span><span class="koboSpan" id="kobo.66.1">def my_function(x,y):</span><br/></span><span><span class="koboSpan" id="kobo.67.1">    return x*y</span></span><strong><span><br/><br/></span><span><span class="koboSpan" id="kobo.68.1">&gt;&gt;&gt; my_function(6,29)</span></span><span><br/></span><span><span class="koboSpan" id="kobo.69.1">174</span></span><span> </span></strong></pre>
<p><span class="koboSpan" id="kobo.70.1">Python supports an interesting syntax that allows you to define small, single-line functions on the fly. </span><span class="koboSpan" id="kobo.70.2">Derived from the Lisp programming language, these lambda functions can be used wherever a function is required.</span></p>
<p><span class="koboSpan" id="kobo.71.1">An example of a lambda function, </span><kbd><span class="koboSpan" id="kobo.72.1">functionvar</span></kbd><span class="koboSpan" id="kobo.73.1">, is shown as follows:</span></p>
<pre><span class="koboSpan" id="kobo.74.1"># lambda definition equivalent to def f(x): return x + 1</span><br/><br/><span class="koboSpan" id="kobo.75.1">functionvar = lambda x: x * 5</span><br/><strong><span class="koboSpan" id="kobo.76.1">&gt;&gt;&gt; print(functionvar(10))</span></strong><br/><strong><span class="koboSpan" id="kobo.77.1">50</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Classes</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Python supports multiple inheritances of classes. </span><span class="koboSpan" id="kobo.2.2">Conventionally </span><span><span class="koboSpan" id="kobo.3.1">(not a language rule)</span></span><span class="koboSpan" id="kobo.4.1">, private variables and methods are declared by being preceded with two underscores (</span><kbd><span class="koboSpan" id="kobo.5.1">__</span></kbd><span class="koboSpan" id="kobo.6.1">). </span><span class="koboSpan" id="kobo.6.2">We can assign arbitrary attributes (properties) to the instances of a class, as shown in the following example:</span></p>
<pre><span class="koboSpan" id="kobo.7.1">class FirstClass:</span><br/><span class="koboSpan" id="kobo.8.1">    common_value = 10</span><br/><span class="koboSpan" id="kobo.9.1">    def __init__ (self):</span><br/><span class="koboSpan" id="kobo.10.1">        self.my_value = 100</span><br/><span class="koboSpan" id="kobo.11.1">    def my_func (self, arg1, arg2):</span><br/><span class="koboSpan" id="kobo.12.1">        return self.my_value*arg1*arg2</span><br/><br/><span class="koboSpan" id="kobo.13.1"># Build a first instance</span><br/><strong><span class="koboSpan" id="kobo.14.1">&gt;&gt;&gt; first_instance = FirstClass()</span></strong><br/><strong><span class="koboSpan" id="kobo.15.1">&gt;&gt;&gt; first_instance.my_func(1, 2)</span></strong><br/><strong><span class="koboSpan" id="kobo.16.1">200</span></strong><br/><br/><span class="koboSpan" id="kobo.17.1"># Build a second instance of FirstClass</span><br/><strong><span class="koboSpan" id="kobo.18.1">&gt;&gt;&gt; second_instance = FirstClass()</span></strong><br/><br/><span class="koboSpan" id="kobo.19.1">#check the common values for both the instances</span><br/><strong><span class="koboSpan" id="kobo.20.1">&gt;&gt;&gt; first_instance.common_value</span></strong><br/><strong><span class="koboSpan" id="kobo.21.1">10</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.22.1">&gt;&gt;&gt; second_instance.common_value</span></strong><br/><strong><span class="koboSpan" id="kobo.23.1">10</span></strong><br/><br/><span class="koboSpan" id="kobo.24.1">#Change common_value for the first_instance</span><br/><strong><span class="koboSpan" id="kobo.25.1">&gt;&gt;&gt; first_instance.common_value = 1500</span></strong><br/><strong><span class="koboSpan" id="kobo.26.1">&gt;&gt;&gt; first_instance.common_value</span></strong><br/><strong><span class="koboSpan" id="kobo.27.1">1500</span></strong><br/><br/><span class="koboSpan" id="kobo.28.1">#As you can note the common_value for second_instance is not changed</span><br/><strong><span class="koboSpan" id="kobo.29.1">&gt;&gt;&gt; second_instance.common_value</span></strong><br/><strong><span class="koboSpan" id="kobo.30.1">10</span></strong><br/><br/><br/><span class="koboSpan" id="kobo.31.1"># SecondClass inherits from FirstClass. </span><br/><span class="koboSpan" id="kobo.32.1"># multiple inheritance is declared as follows:</span><br/><span class="koboSpan" id="kobo.33.1"># class SecondClass (FirstClass1, FirstClass2, FirstClassN)</span><br/><br/><span class="koboSpan" id="kobo.34.1">class SecondClass (FirstClass):</span><br/><span class="koboSpan" id="kobo.35.1">    # The "self" argument is passed automatically</span><br/><span class="koboSpan" id="kobo.36.1">    # and refers to the class's instance</span><br/><span class="koboSpan" id="kobo.37.1">    def __init__ (self, arg1):</span><br/><span class="koboSpan" id="kobo.38.1">        self.my_value = 764</span><br/><span class="koboSpan" id="kobo.39.1">        print (arg1)</span><br/><br/><strong><span class="koboSpan" id="kobo.40.1">&gt;&gt;&gt; first_instance = SecondClass ("hello PACKT!!!!")</span></strong><br/><strong><span class="koboSpan" id="kobo.41.1">hello PACKT!!!!</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.42.1">&gt;&gt;&gt; first_instance.my_func (1, 2)</span></strong><br/><strong><span class="koboSpan" id="kobo.43.1">1528</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Exceptions</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Exceptions in Python are managed with </span><kbd><span class="koboSpan" id="kobo.3.1">try-except</span></kbd><span class="koboSpan" id="kobo.4.1"> blocks (</span><kbd><span class="koboSpan" id="kobo.5.1">exception_name</span></kbd><span class="koboSpan" id="kobo.6.1">):</span></p>
<pre><span class="koboSpan" id="kobo.7.1">def one_function():</span><br/><span class="koboSpan" id="kobo.8.1">     try:</span><br/><span class="koboSpan" id="kobo.9.1">         # Division by zero causes one exception</span><br/><span class="koboSpan" id="kobo.10.1">         10/0</span><br/><span class="koboSpan" id="kobo.11.1">     except ZeroDivisionError:</span><br/><span class="koboSpan" id="kobo.12.1">         print("Oops, error.")</span><br/><span class="koboSpan" id="kobo.13.1">     else:</span><br/><span class="koboSpan" id="kobo.14.1">         # There was no exception, we can continue.</span><br/><span class="koboSpan" id="kobo.15.1">         pass</span><br/><span class="koboSpan" id="kobo.16.1">     finally:</span><br/><span class="koboSpan" id="kobo.17.1">         # This code is executed when the block</span><br/><span class="koboSpan" id="kobo.18.1">         # try..except is already executed and all exceptions</span><br/><span class="koboSpan" id="kobo.19.1">         # have been managed, even if a new one occurs</span><br/><span class="koboSpan" id="kobo.20.1">         # exception directly in the block.</span><br/><span class="koboSpan" id="kobo.21.1">         print("We finished.")</span><br/><br/><strong><span class="koboSpan" id="kobo.22.1">&gt;&gt;&gt; one_function()</span></strong><br/><strong><span class="koboSpan" id="kobo.23.1">Oops, error.</span></strong><br/><strong><span class="koboSpan" id="kobo.24.1">We finished</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Importing libraries</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">External libraries are imported with </span><kbd><span class="koboSpan" id="kobo.3.1">import [library name]</span></kbd><span class="koboSpan" id="kobo.4.1">. </span><span class="koboSpan" id="kobo.4.2">Alternatively, you can use the </span><kbd><span class="koboSpan" id="kobo.5.1">from [library name] import [function name]</span></kbd> <span><span class="koboSpan" id="kobo.6.1">syntax </span></span><span class="koboSpan" id="kobo.7.1">to import a specific function. </span><span class="koboSpan" id="kobo.7.2">Here is an example:</span></p>
<pre><span class="koboSpan" id="kobo.8.1">import random</span><br/><span class="koboSpan" id="kobo.9.1">randomint = random.randint(1, 101)</span><br/><br/><strong><span class="koboSpan" id="kobo.10.1">&gt;&gt;&gt; print(randomint)</span></strong><br/><strong><span class="koboSpan" id="kobo.11.1">65</span></strong><br/><br/><span class="koboSpan" id="kobo.12.1">from random import randint</span><br/><span class="koboSpan" id="kobo.13.1">randomint = random.randint(1, 102)</span><br/><br/><strong><span class="koboSpan" id="kobo.14.1">&gt;&gt;&gt; print(randomint)</span></strong><br/><strong><span class="koboSpan" id="kobo.15.1">46</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Managing files</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">To allow us to interact with the filesystem, Python provides us with the built-in </span><kbd><span class="koboSpan" id="kobo.3.1">open</span></kbd><span class="koboSpan" id="kobo.4.1"> </span><span><span class="koboSpan" id="kobo.5.1">function.</span></span><span class="koboSpan" id="kobo.6.1"> This function can be invoked to open a file and return an object file. </span><span class="koboSpan" id="kobo.6.2">The latter allows us to perform various operations on the file, such as reading and writing. </span><span class="koboSpan" id="kobo.6.3">When we have finished interacting with the file, we must finally remember to close it by using the </span><kbd><span class="koboSpan" id="kobo.7.1">file.close</span></kbd><span class="koboSpan" id="kobo.8.1"> method:</span></p>
<pre><strong><span class="koboSpan" id="kobo.9.1">&gt;&gt;&gt; f = open ('test.txt', 'w') # open the file for writing</span></strong><br/><strong><span class="koboSpan" id="kobo.10.1">&gt;&gt;&gt; f.write ('first line of file \ n') # write a line in file</span></strong><br/><strong><span class="koboSpan" id="kobo.11.1">&gt;&gt;&gt; f.write ('second line of file \ n') # write another line in file</span></strong><br/><strong><span class="koboSpan" id="kobo.12.1">&gt;&gt;&gt; f.close () # we close the file</span></strong><br/><strong><span class="koboSpan" id="kobo.13.1">&gt;&gt;&gt; f = open ('test.txt') # reopen the file for reading</span></strong><br/><strong><span class="koboSpan" id="kobo.14.1">&gt;&gt;&gt; content = f.read () # read all the contents of the file</span></strong><br/><strong><span class="koboSpan" id="kobo.15.1">&gt;&gt;&gt; print (content)</span></strong><br/><strong><span class="koboSpan" id="kobo.16.1">first line of the file</span></strong><br/><strong><span class="koboSpan" id="kobo.17.1">second line of the file</span></strong><br/><strong><span class="koboSpan" id="kobo.18.1">&gt;&gt;&gt; f.close () # close the file</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">List comprehensions</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">List comprehensions are a powerful tool for creating and manipulating lists. </span><span class="koboSpan" id="kobo.2.2">They consist of an expression that is followed by a </span><kbd><span class="koboSpan" id="kobo.3.1">for</span></kbd><span class="koboSpan" id="kobo.4.1"> clause and then followed by zero, or more, </span><kbd><span class="koboSpan" id="kobo.5.1">if</span></kbd><span class="koboSpan" id="kobo.6.1"> clauses. </span><span class="koboSpan" id="kobo.6.2">The syntax for list comprehensions is simply the following:</span></p>
<pre><span class="koboSpan" id="kobo.7.1">[expression for item in list]</span></pre>
<p><span class="koboSpan" id="kobo.8.1">Then, perform the following:</span></p>
<pre><span class="koboSpan" id="kobo.9.1">#list comprehensions using strings</span><br/><strong><span class="koboSpan" id="kobo.10.1">&gt;&gt;&gt; list_comprehension_1 = [ x for x in 'python parallel programming cookbook!' </span><span class="koboSpan" id="kobo.10.2">]</span></strong><br/><strong><span class="koboSpan" id="kobo.11.1">&gt;&gt;&gt; print( list_comprehension_1)</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.12.1">['p', 'y', 't', 'h', 'o', 'n', ' ', 'p', 'a', 'r', 'a', 'l', 'l', 'e', 'l', ' ', 'p', 'r', 'o', 'g', 'r', 'a', 'm', 'm', 'i', 'n', 'g', ' ', 'c', 'o', 'o', 'k', 'b', 'o', 'o', 'k', '!']</span></strong><br/><br/><span class="koboSpan" id="kobo.13.1">#list comprehensions using numbers</span><br/><strong><span class="koboSpan" id="kobo.14.1">&gt;&gt;&gt; l1 = [1,2,3,4,5,6,7,8,9,10]</span></strong><br/><strong><span class="koboSpan" id="kobo.15.1">&gt;&gt;&gt; list_comprehension_2 = [ x*10 for x in l1 ]</span></strong><br/><strong><span class="koboSpan" id="kobo.16.1">&gt;&gt;&gt; print( list_comprehension_2)</span></strong><br/><br/><strong><span class="koboSpan" id="kobo.17.1">[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Running Python scripts</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">To execute a Python script, simply invoke the Python interpreter followed by the script name, in this case, </span><kbd><span class="koboSpan" id="kobo.3.1">my_pythonscript.py</span></kbd><span class="koboSpan" id="kobo.4.1">. </span><span class="koboSpan" id="kobo.4.2">Or, if we are in a different working directory, then use </span><span><span class="koboSpan" id="kobo.5.1">its full address</span></span><span class="koboSpan" id="kobo.6.1">:</span></p>
<pre><strong><span class="koboSpan" id="kobo.7.1">&gt; python my_pythonscript.py</span><br/></strong></pre>
<div class="packt_infobox"><span class="koboSpan" id="kobo.8.1">From now on, for every invocation of a Python script, we will use the preceding notation; that is, </span><kbd><span class="koboSpan" id="kobo.9.1">python</span></kbd><span class="koboSpan" id="kobo.10.1">, followed by </span><kbd><span class="koboSpan" id="kobo.11.1">script_name.py</span></kbd><span class="koboSpan" id="kobo.12.1">, assuming that the directory from which the Python interpreter is launched is the one where the script to be execu</span><em><span class="koboSpan" id="kobo.13.1">ted</span></em><span class="koboSpan" id="kobo.14.1"> resides.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Installing Python packages using pip</span></h1>
                </header>
            
            <article>
                
<p><kbd><span class="koboSpan" id="kobo.2.1">pip</span></kbd><span class="koboSpan" id="kobo.3.1"> is a tool that allows us to search, download, and install Python packages found on the Python Package Index, which is a repository that contains tens of thousands of packages written in Python</span><span><span class="koboSpan" id="kobo.4.1">.</span></span><span class="koboSpan" id="kobo.5.1"> This also allows us to manage the packages we have already downloaded, allowing us to update or remove them.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Installing pip</span></h1>
                </header>
            
            <article>
                
<p><kbd><span class="koboSpan" id="kobo.2.1">pip</span></kbd><span class="koboSpan" id="kobo.3.1"> is already included in Python versions ≥ 3.4 and ≥ 2.7.9. </span><span class="koboSpan" id="kobo.3.2">To check whether this tool is already installed, we can run the following command:</span></p>
<pre><strong><span class="koboSpan" id="kobo.4.1">C:\&gt;pip</span></strong></pre>
<p><span class="koboSpan" id="kobo.5.1"> If </span><kbd><span class="koboSpan" id="kobo.6.1">pip</span></kbd><span class="koboSpan" id="kobo.7.1"> is already installed, then this command will show us the installed version.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Updating pip</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">It is also recommended to check that the </span><kbd><span class="koboSpan" id="kobo.3.1">pip</span></kbd><span class="koboSpan" id="kobo.4.1"> version you are using is always up to date. </span><span class="koboSpan" id="kobo.4.2">To update it, we can use the following command:</span></p>
<pre><strong><span class="koboSpan" id="kobo.5.1"> C:\&gt;pip install -U pip</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Using pip</span></h1>
                </header>
            
            <article>
                
<p><kbd><span class="koboSpan" id="kobo.2.1">pip</span></kbd><span class="koboSpan" id="kobo.3.1"> supports a series of commands that allow us, </span><span><span class="koboSpan" id="kobo.4.1">among other things,</span></span><span class="koboSpan" id="kobo.5.1"> to </span><em><span class="koboSpan" id="kobo.6.1">search, download, install, update,</span></em><span class="koboSpan" id="kobo.7.1"> and </span><em><span class="koboSpan" id="kobo.8.1">remove</span></em><span class="koboSpan" id="kobo.9.1"> packages.</span></p>
<p><span class="koboSpan" id="kobo.10.1">To install </span><kbd><span><span class="koboSpan" id="kobo.11.1">PACKAGE</span></span></kbd><span class="koboSpan" id="kobo.12.1">, just run the following command:</span></p>
<pre><strong><span class="koboSpan" id="kobo.13.1">C:\&gt;pip install PACKAGE</span><br/></strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Introducing Python parallel programming</span></h1>
                </header>
            
            <article>
                
<p><span><span class="koboSpan" id="kobo.2.1">Python provides many libraries and frameworks that facilitate high-performance computations. </span><span class="koboSpan" id="kobo.2.2">However, doing parallel programming with Python can be quite insidious due to the </span><strong><span class="koboSpan" id="kobo.3.1">Global Interpreter Lock</span></strong></span><span><span class="koboSpan" id="kobo.4.1"> (</span><strong><span class="koboSpan" id="kobo.5.1">GIL</span></strong></span><span><span class="koboSpan" id="kobo.6.1">). </span></span></p>
<p><span class="koboSpan" id="kobo.7.1">In fact, the most widespread and widely used Python interpreter, </span><strong><span class="koboSpan" id="kobo.8.1">CPython</span></strong><span class="koboSpan" id="kobo.9.1">, is developed in the C programming language. </span><span class="koboSpan" id="kobo.9.2">The CPython interpreter needs GIL for thread-safe operations. </span><span class="koboSpan" id="kobo.9.3">The use of GIL implies that you will encounter a global lock when you attempt to access any Python objects contained within threads. </span><span class="koboSpan" id="kobo.9.4">And only one</span><span><span class="koboSpan" id="kobo.10.1"> thread at a time can acquire the lock for a Python object or C API.</span></span><span class="koboSpan" id="kobo.11.1"> </span></p>
<p><span class="koboSpan" id="kobo.12.1">Fortunately, things are not so serious, because, outside the realm of GIL, we can freely use parallelism. </span><span class="koboSpan" id="kobo.12.2">This category includes all the topics that we will discuss in the next chapters, including multiprocessing, distributed computing, and GPU computing.</span></p>
<p><span class="koboSpan" id="kobo.13.1">So, Python is not really multithreaded. </span><span class="koboSpan" id="kobo.13.2">But what is a thread? </span><span class="koboSpan" id="kobo.13.3">What is a process? </span><span class="koboSpan" id="kobo.13.4">In the following sections, we will introduce these two fundamental concepts and how they are addressed by the Python programming language.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Processes and threads</span></h1>
                </header>
            
            <article>
                
<p><em><span class="koboSpan" id="kobo.2.1">Threads</span></em><span class="koboSpan" id="kobo.3.1"> can be compared to light processes, in the sense that they offer advantages similar to those of processes, without, however, requiring the typical communication techniques of processes. </span><span class="koboSpan" id="kobo.3.2">Threads allow you to divide the main control flow of a program into multiple concurrently running control streams. Processes, by contrast, have their </span><em><span class="koboSpan" id="kobo.4.1">own</span></em> <em><span class="koboSpan" id="kobo.5.1">addressing space</span></em><span class="koboSpan" id="kobo.6.1"> and their own resources</span><em><span class="koboSpan" id="kobo.7.1">.</span></em><span class="koboSpan" id="kobo.8.1"> It follows that communication between parts of code running on different processes can only take place through appropriate management mechanisms, including pipes, code FIFO, mailboxes, shared memory areas, and message passing. </span><span class="koboSpan" id="kobo.8.2">Threads, on the other hand, allow the creation of concurrent parts of the program, in which each part can access the same address space, variables, and constants.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.9.1">The following table summarizes the main differences between threads and processes:</span></p>
<table style="border-collapse: collapse;width: 90%" border="1">
<thead>
<tr>
<td><strong><span class="koboSpan" id="kobo.10.1">Threads</span></strong></td>
<td>
<p><strong><span class="koboSpan" id="kobo.11.1">Processes</span></strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td><span class="koboSpan" id="kobo.12.1">Share memory.</span></td>
<td>
<p><span class="koboSpan" id="kobo.13.1">Do not share memory.</span></p>
</td>
</tr>
<tr>
<td>
<p><span class="koboSpan" id="kobo.14.1">Start/change are computationally less expensive.</span></p>
</td>
<td>
<p><span class="koboSpan" id="kobo.15.1">Start/change are computationally expensive.</span></p>
</td>
</tr>
<tr>
<td>
<p><span class="koboSpan" id="kobo.16.1">Require fewer resources (light processes).</span></p>
</td>
<td><span class="koboSpan" id="kobo.17.1">Require more computational resources.</span></td>
</tr>
<tr>
<td>
<p><span class="koboSpan" id="kobo.18.1">Need synchronization mechanisms to handle data correctly.</span></p>
</td>
<td>
<p><span class="koboSpan" id="kobo.19.1">No memory synchronization is required.</span></p>
</td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.20.1"> </span></p>
<p><span class="koboSpan" id="kobo.21.1">After this brief introduction, we can finally show how processes and threads operate.</span></p>
<p><span class="koboSpan" id="kobo.22.1">In particular, we want to compare the serial, multithread, and multiprocess execution times of the following function, </span><span><kbd><span class="koboSpan" id="kobo.23.1">do_something</span></kbd></span><span class="koboSpan" id="kobo.24.1">, which performs some basic calculations, including building a list of integers selected randomly (a </span><kbd><span class="koboSpan" id="kobo.25.1">do_something.py</span></kbd><span class="koboSpan" id="kobo.26.1"> </span><span><span class="koboSpan" id="kobo.27.1">file)</span></span><span class="koboSpan" id="kobo.28.1">:</span></p>
<pre><span class="koboSpan" id="kobo.29.1">import random</span><br/><br/><span class="koboSpan" id="kobo.30.1">def do_something(count, out_list):</span><br/><span class="koboSpan" id="kobo.31.1">  for i in range(count):</span><br/><span class="koboSpan" id="kobo.32.1">    out_list.append(random.random())</span></pre>
<p><span class="koboSpan" id="kobo.33.1">Next, there is the serial (</span><kbd><span class="koboSpan" id="kobo.34.1">serial_test.py</span></kbd><span class="koboSpan" id="kobo.35.1">) implementation. Let's start with the relevant imports:</span></p>
<pre style="padding-left: 60px"><span class="koboSpan" id="kobo.36.1">from do_something import *</span><br/><span class="koboSpan" id="kobo.37.1">import time </span></pre>
<p><span class="koboSpan" id="kobo.38.1">Note the importing of the module time, which will be used to evaluate the execution time, in this instance, and the serial implementation of the </span><kbd><span class="koboSpan" id="kobo.39.1">do_something</span></kbd><span class="koboSpan" id="kobo.40.1"> </span><span><span class="koboSpan" id="kobo.41.1">function.</span></span><span class="koboSpan" id="kobo.42.1"> </span><kbd><span class="koboSpan" id="kobo.43.1">size</span></kbd><span class="koboSpan" id="kobo.44.1"> of the list to build is equal to </span><kbd><span class="koboSpan" id="kobo.45.1">10000000</span></kbd><span class="koboSpan" id="kobo.46.1">, while the </span><kbd><span class="koboSpan" id="kobo.47.1">do_something</span></kbd><span class="koboSpan" id="kobo.48.1"> function will be executed </span><kbd><span class="koboSpan" id="kobo.49.1">10</span></kbd><span class="koboSpan" id="kobo.50.1"> times:</span></p>
<pre style="padding-left: 60px"><span class="koboSpan" id="kobo.51.1">if __name__ == "__main__":</span><br/><span class="koboSpan" id="kobo.52.1">    start_time = time.time()</span><br/><span class="koboSpan" id="kobo.53.1">    size = 10000000 </span><br/><span class="koboSpan" id="kobo.54.1">    n_exec = 10</span><br/><span class="koboSpan" id="kobo.55.1">    for i in range(0, exec):</span><br/><span class="koboSpan" id="kobo.56.1">        out_list = list()</span><br/><span class="koboSpan" id="kobo.57.1">        do_something(size, out_list)</span><br/>       <br/><span class="koboSpan" id="kobo.58.1">    print ("List processing complete.")</span><br/><span class="koboSpan" id="kobo.59.1">    end_time = time.time()</span><br/><span class="koboSpan" id="kobo.60.1">    print("serial time=", end_time - start_time)   </span></pre>
<p><span class="koboSpan" id="kobo.61.1">Next, we have the multithreaded implementation (</span><kbd><span class="koboSpan" id="kobo.62.1">multithreading_test.py</span></kbd><span class="koboSpan" id="kobo.63.1">).</span></p>
<p><span class="koboSpan" id="kobo.64.1">Import the relevant libraries:</span></p>
<pre style="padding-left: 60px"><span class="koboSpan" id="kobo.65.1">from do_something import *</span><br/><span class="koboSpan" id="kobo.66.1">import time</span><br/><span class="koboSpan" id="kobo.67.1">import threading</span></pre>
<p><span class="koboSpan" id="kobo.68.1">Note the import of the </span><kbd><span class="koboSpan" id="kobo.69.1">threading</span></kbd><span class="koboSpan" id="kobo.70.1"> module in order to operate with the multithreading capabilities of Python.</span></p>
<p><span class="koboSpan" id="kobo.71.1">Here, there is the multithreading execution of the </span><kbd><span class="koboSpan" id="kobo.72.1">do_something</span></kbd><span class="koboSpan" id="kobo.73.1"> function. </span><span class="koboSpan" id="kobo.73.2">We will not comment in-depth on the instructions in the following code, as they will be discussed in more detail in </span><a href="c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml"><span class="koboSpan" id="kobo.74.1">Chapter 2</span></a><span class="koboSpan" id="kobo.75.1">, </span><em><span class="koboSpan" id="kobo.76.1">Thread-Based Parallelism</span></em><span class="koboSpan" id="kobo.77.1">.</span></p>
<p><span class="koboSpan" id="kobo.78.1">However, it should be noted in this case, too, that the length of the list is obviously the same as in the serial case, </span><kbd><span class="koboSpan" id="kobo.79.1">size = 10000000</span></kbd><span class="koboSpan" id="kobo.80.1">, while the number of threads defined is 10, </span><kbd><span class="koboSpan" id="kobo.81.1">threads = 10</span></kbd><span class="koboSpan" id="kobo.82.1">, which is also the number of times the </span><kbd><span class="koboSpan" id="kobo.83.1">do_something</span></kbd><span class="koboSpan" id="kobo.84.1"> function must be executed:</span></p>
<pre><span class="koboSpan" id="kobo.85.1">if __name__ == "__main__":</span><br/><span class="koboSpan" id="kobo.86.1">    start_time = time.time()</span><br/><span class="koboSpan" id="kobo.87.1">    size = 10000000</span><br/><span class="koboSpan" id="kobo.88.1">    threads = 10 </span><br/><span class="koboSpan" id="kobo.89.1">    jobs = []</span><br/><span class="koboSpan" id="kobo.90.1">    for i in range(0, threads):</span></pre>
<p><span class="koboSpan" id="kobo.91.1">Note also the construction of the single thread, through the </span><kbd><span class="koboSpan" id="kobo.92.1">threading.Thread</span></kbd><span class="koboSpan" id="kobo.93.1"> method:</span></p>
<pre style="padding-left: 60px"><span class="koboSpan" id="kobo.94.1">out_list = list()</span><br/><span class="koboSpan" id="kobo.95.1">thread = threading.Thread(target=list_append(size,out_list))</span><br/><span class="koboSpan" id="kobo.96.1">jobs.append(thread)</span></pre>
<p><span class="koboSpan" id="kobo.97.1">The sequence of cycles in which we start executing threads and then stop them immediately afterwards is as follows:</span></p>
<pre><span class="koboSpan" id="kobo.98.1">    for j in jobs:</span><br/><span class="koboSpan" id="kobo.99.1">        j.start()</span><br/><span class="koboSpan" id="kobo.100.1">    for j in jobs:</span><br/><span class="koboSpan" id="kobo.101.1">        j.join()</span><br/><br/><span class="koboSpan" id="kobo.102.1">    print ("List processing complete.")</span><br/><span class="koboSpan" id="kobo.103.1">    end_time = time.time()</span><br/><span class="koboSpan" id="kobo.104.1">    print("multithreading time=", end_time - start_time)</span></pre>
<p><span class="koboSpan" id="kobo.105.1">Finally, there is the multiprocessing implementation (</span><kbd><span class="koboSpan" id="kobo.106.1">multiprocessing_test.py</span></kbd><span class="koboSpan" id="kobo.107.1">).</span></p>
<p><span class="koboSpan" id="kobo.108.1">We start by importing the necessary modules and, in particular, the </span><kbd><span class="koboSpan" id="kobo.109.1">multiprocessing</span></kbd><span class="koboSpan" id="kobo.110.1"> library, whose features will be explained in-depth in </span><a href="5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml"><span class="koboSpan" id="kobo.111.1">Chapter 3</span></a><span class="koboSpan" id="kobo.112.1">, </span><em><span class="koboSpan" id="kobo.113.1">Process-Based Parallelism</span></em><span class="koboSpan" id="kobo.114.1">:</span></p>
<pre><span class="koboSpan" id="kobo.115.1">from do_something import *</span><br/><span class="koboSpan" id="kobo.116.1">import time</span><br/><span class="koboSpan" id="kobo.117.1">import multiprocessing</span></pre>
<p><span class="koboSpan" id="kobo.118.1">As in the previous cases, the length of the list to build, the size, and the execution number of the </span><kbd><span class="koboSpan" id="kobo.119.1">do_something</span></kbd><span class="koboSpan" id="kobo.120.1"> function remain the same (</span><kbd><span class="koboSpan" id="kobo.121.1">procs = 10</span></kbd><span class="koboSpan" id="kobo.122.1">):</span></p>
<pre><span class="koboSpan" id="kobo.123.1">if __name__ == "__main__":</span><br/><span class="koboSpan" id="kobo.124.1">    start_time = time.time()</span><br/><span class="koboSpan" id="kobo.125.1">    size = 10000000 </span><br/><span class="koboSpan" id="kobo.126.1">    procs = 10 </span><br/><span class="koboSpan" id="kobo.127.1">    jobs = []</span><br/><span class="koboSpan" id="kobo.128.1">    for i in range(0, procs):</span><br/><span class="koboSpan" id="kobo.129.1">        out_list = list()</span></pre>
<p><span class="koboSpan" id="kobo.130.1">Here, the implementation of a single process through the </span><kbd><span class="koboSpan" id="kobo.131.1">multiprocessing.Process</span></kbd><span class="koboSpan" id="kobo.132.1"> method call is affected as follows:</span></p>
<pre><span class="koboSpan" id="kobo.133.1">        process = multiprocessing.Process\</span><br/><span class="koboSpan" id="kobo.134.1">                  (target=do_something,args=(size,out_list))</span><br/><span class="koboSpan" id="kobo.135.1">        jobs.append(process)</span></pre>
<p><span class="koboSpan" id="kobo.136.1">Next, the sequence of cycles in which we start executing processes and then stop them immediately afterwards is executed as follows:</span></p>
<pre><span class="koboSpan" id="kobo.137.1">    for j in jobs:</span><br/><span class="koboSpan" id="kobo.138.1">        j.start()</span><br/><br/><span class="koboSpan" id="kobo.139.1">    for j in jobs:</span><br/><span class="koboSpan" id="kobo.140.1">        j.join()</span><br/><br/><span class="koboSpan" id="kobo.141.1">    print ("List processing complete.")</span><br/><span class="koboSpan" id="kobo.142.1">    end_time = time.time()</span><br/><span class="koboSpan" id="kobo.143.1">    print("multiprocesses time=", end_time - start_time)</span></pre>
<p><span class="koboSpan" id="kobo.144.1">Then, we open the command shell and run the three functions described previously. </span></p>
<p><span class="koboSpan" id="kobo.145.1">Go to the folder where the functions have been copied and then type the following:</span></p>
<pre><strong><span class="koboSpan" id="kobo.146.1">&gt; python serial_test.py</span></strong></pre>
<p><span class="koboSpan" id="kobo.147.1">The result, obtained on a machine with the following features—CPU Intel i7/8 GB of RAM, is as follows:</span></p>
<pre><strong><span class="koboSpan" id="kobo.148.1">List processing complete.</span></strong><br/><strong><span class="koboSpan" id="kobo.149.1">serial time= 25.428767204284668</span></strong></pre>
<p><span class="koboSpan" id="kobo.150.1">In the case of the </span><kbd><span class="koboSpan" id="kobo.151.1">multithreading</span></kbd><span class="koboSpan" id="kobo.152.1"> implementation, we have the following:</span></p>
<pre><strong><span class="koboSpan" id="kobo.153.1">&gt; python multithreading_test.py</span></strong></pre>
<p><span><span class="koboSpan" id="kobo.154.1">The output is as follows:</span></span></p>
<pre><strong><span class="koboSpan" id="kobo.155.1">List processing complete.</span></strong><br/><strong><span class="koboSpan" id="kobo.156.1">multithreading time= 26.168917179107666</span></strong></pre>
<p><span class="koboSpan" id="kobo.157.1">Finally, there is the </span><strong><span class="koboSpan" id="kobo.158.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.159.1"> implementation:</span></p>
<pre><strong><span class="koboSpan" id="kobo.160.1">&gt; python multiprocessing_test.py</span></strong></pre>
<p><span class="koboSpan" id="kobo.161.1">Its result is as follows:</span></p>
<pre><strong><span class="koboSpan" id="kobo.162.1">List processing complete.</span></strong><br/><strong><span class="koboSpan" id="kobo.163.1">multiprocesses time= 18.929869890213013</span></strong></pre>
<p class="CDPAlignLeft CDPAlign"><span class="koboSpan" id="kobo.164.1">As can be seen, the results of the serial implementation (that is, using </span><kbd><span class="koboSpan" id="kobo.165.1">serial_test.py</span></kbd><span class="koboSpan" id="kobo.166.1">) are similar to those obtained with the implementation of multithreading (using </span><kbd><span class="koboSpan" id="kobo.167.1">multithreading_test.py</span></kbd><span class="koboSpan" id="kobo.168.1">) where the threads are essentially launched one after the other, giving precedence to the one over the other until the end, while we have benefits in terms of execution times using the Python multiprocessing capability (using </span><kbd><span class="koboSpan" id="kobo.169.1">multiprocessing_test.py</span></kbd><span class="koboSpan" id="kobo.170.1">).</span></p>


            </article>

            
        </section>
    </body></html>