- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Connecting to a Relational Database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our previous applications have only used Python collections to hold data records
    instead of persistent data stores. This setup causes data wiping whenever the
    **Uvicorn** server restarts because these collections only store the data in *volatile
    memory*, such as **RAM**. From this chapter onward, we will be applying data persistency
    to avoid data loss and provide a platform to manage our records, even when the
    server is in shutdown mode.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will focus on different **Object Relational Mappers** (**ORMs**)
    that can efficiently manage clients’ data using objects and a relational database.
    Object-relational mapping is a technique where SQL statements for **Creating***,*
    **Reading***,* **Updating** *and* **Deleting** (**CRUD**) are implemented and
    executed in an object-oriented programming approach. ORM requires all relationships
    or tables to be mapped to their corresponding entity or model classes to avoid
    tightly coupled connections to the database platform. And these model classes
    are the ones that are used to connect to the database.
  prefs: []
  type: TYPE_NORMAL
- en: Aside from introducing ORM, this chapter will also discuss a design pattern
    called **Command and Query Responsibility Segregation** (**CQRS**), which can
    help resolve conflicts between read and write ORM transactions at the domain level.
    CQRS can help minimize the running time spent by read and write SQL transactions
    to improve the overall performance of the application over time compared to the
    data modeling approach.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the main objective of this chapter is to prove that the FastAPI framework
    supports all popular ORMs to provide applications with backend database access,
    which it does by using popular relational database management systems, and apply
    optimization to CRUD transactions using the CQRS design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing for database connectivity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating synchronous CRUD transactions using *SQLAlchemy*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing asynchronous CRUD transactions using *SQLAlchemy*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using *GINO* for asynchronous CRUD transactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Pony ORM for the repository layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the repository using Peewee
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the CQRS design pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The application prototype that’s been created for this chapter is called *fitness
    club management system*; it caters to membership and gym fitness operations. This
    prototype has administration, membership, class management, and attendance modules
    that utilize a `ch05a` and `ch05b` projects.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing for database connectivity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let us consider some application-related concerns before we start discussing
    database connectivity in FastAPI:'
  prefs: []
  type: TYPE_NORMAL
- en: First, all the application prototypes from this chapter onward will be using
    PostgreSQL as the sole relational DBMS. We can download its installer from [https://www.enterprisedb.com/downloads/postgres-postgresql-downloads](https://www.enterprisedb.com/downloads/postgres-postgresql-downloads).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Second, the *fitness club management system* prototype has an existing database
    called `fcms` with six tables, namely `signup`, `login`, `profile_members`, `profile_trainers`,
    `attendance_member`, and `gym_class`. All these tables, along with their metadata
    and relationships, can be seen in the following diagram:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.1 – The fcms tables'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.1_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.1 – The fcms tables
  prefs: []
  type: TYPE_NORMAL
- en: The project folder contains a script called `fcms_postgres.sql` that installs
    all these schemas.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve installed the latest version of PostgreSQL and run the `fcms`
    script file, let us learn about SQLAlchemy, the most widely used ORM library in
    the Python arena.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will compare and contrast the features of different Python ORMs.
    With this experimental setup, each project will have a multitude of database connectivity,
    which is against the convention of having a single piece of database connectivity
    per project.
  prefs: []
  type: TYPE_NORMAL
- en: Creating CRUD transactions using SQLAlchemy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**SQLAlchemy** is the most popular ORM library and can establish communication
    between any Python-based application and database platform. It is reliable because
    it is continuously updated and tested to be efficient, high-performing, and accurate
    with its SQL reads and writes.'
  prefs: []
  type: TYPE_NORMAL
- en: This ORM is a boilerplated interface that aims to create a database-agnostic
    data layer that can connect to any database engine. But compared to other ORMs,
    SQLAlchemy is DBA-friendly because it can generate optimized native SQL statements.
    When it comes to formulating its queries, it only requires Python functions and
    expressions to pursue the CRUD operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start using SQLAlchemy, check whether you have the module installed
    in your system by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If SQLAlchemy is not in the list, install it using the `pip` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Currently, the version being used while developing the *fitness club management
    system* app is *1.4*.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the database driver
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'SQLAlchemy will not work without the required database driver. It is mandatory
    to install the `psycopg2` dialect since the database of choice is PostgreSQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Psycopg2 is a *DB API 2.0-c*ompliant PostgreSQL driver that does connection
    pooling and can work with multi-threaded FastAPI applications. This wrapper or
    dialect is also essential in building synchronous CRUD transactions for our application.
    Once it’s been installed, we can start looking at SQLAlchemy’s database configuration
    details. All the code related to SQLAlchemy can be found in the `ch05a` project.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the database connection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To connect to any database, SQLAlchemy requires an engine that manages the
    connection pooling and the installed dialect. The `create_engine()` function from
    the `sqlalchemy` module is the source of the engine object. But to successfully
    derive it, `create_engine()` requires a database URL string to be configured.
    This URL string contains the *database name*, *the database API driver*, the *account
    credentials*, the *IP address* of the database server, and its *port*. The following
    script shows how to create the engine that will be used in our *fitness club management
    system* prototype:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`engine` is a global object and must be created only once in the entire application.
    Its first database connection happens right after the first SQL transaction of
    the application because it follows the *lazy initialization* design pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, `engine` in the previous script is essential for creating the ORM
    session that will be used by SQLAlchemy to execute CRUD transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the session factory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All CRUD transactions in SQLAlchemy are driven by *sessions*. Each session manages
    a group of database "writes" and "reads," and it checks whether to execute them
    or not. For instance, it maintains a group of inserted, updated, and deleted objects,
    checks whether the changes are valid, and then coordinates with the SQLAlchemy
    core to pursue the changes to the database if all transactions have been validated.
    It follows the behavior of the *Unit of Work* design pattern. SQLAlchemy relies
    on sessions for data consistency and integrity.
  prefs: []
  type: TYPE_NORMAL
- en: 'But before we create a session, the data layer needs a session factory that
    is bound to the derived engine. The ORM has a `sessionmaker()`directive from the
    `sqlalchemy.orm` module, which requires the `engine` object. The following script
    shows how to invoke `sessionmaker()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Apart from engine binding, we also need to set the session’s `autocommit` property
    to `False` to impose `commit()` and `rollback()` transactions. The application
    should be the one to flush all changes to the database, so we need to set its
    `autoflush` feature to `False` as well.
  prefs: []
  type: TYPE_NORMAL
- en: Applications can create more than one session through the `SessionFactory()`
    call, but having one session per `APIRouter` is recommended.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Base class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we need to set up the `Base` class, which is crucial in mapping model
    classes to database tables. Although SQLAlchemy can create tables at runtime,
    we opted to utilize an existing schema definition for our prototype. Now, this
    `Base` class must be subclassed by the model classes so that the mapping to the
    tables will happen once the server starts. The following script shows how straightforward
    it is to set up this component:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Invoking the `declarative_base()` function is the easiest way of creating the
    `Base` class rather than creating `registry()` to call `generate_base()`, which
    can also provide us with the `Base` class.
  prefs: []
  type: TYPE_NORMAL
- en: Note that all these configurations are part of the `/db_config/sqlalchemy_connect.py`
    module of the prototype. They are bundled into one module since they are crucial
    in building the SQLAlchemy repository. But before we implement the CRUD transactions,
    we need to create the model layer using the `Base` class.
  prefs: []
  type: TYPE_NORMAL
- en: Building the model layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The model classes of SQLAlchemy have all been placed in the `/models/data/sqlalchemy_models.py`
    file of the fitness club project folder. If `BaseModel` is important to API request
    models, the `Base` class is essential in building the data layer. It is imported
    from the configuration file to define SQLAlchemy entities or models. The following
    code is from the module script, which shows how we can create model class definitions
    in SQLAlchemy ORM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `Signup` class is a sample of a SQLAlchemy model because it inherits the
    `Base` class’s properties. It is a mapped class because all its attributes are
    reflections of the column metadata of its physical table schema counterpart. The
    model has a `primary_key` property set to `True` because SQLAlchemy recommends
    each table schema have at least one primary key. The rest of the `Column` objects
    are mapped to column metadata that’s non-primary but can be *unique* or *indexed*.
    Each model class inherits the `__tablename__` property, which sets the name of
    the mapped table.
  prefs: []
  type: TYPE_NORMAL
- en: Most importantly, we need to ensure that the data type of the class attribute
    matches the column type of its column counterpart in the table schema. The column
    attribute must have the same name as the column counterpart. Otherwise, we need
    to specify the actual column name in the first argument of the `Column` class,
    as shown in the `username` and `password` columns of `Signup`. But most of the
    time, we must always make sure they are the same to avoid confusion.
  prefs: []
  type: TYPE_NORMAL
- en: Mapping table relationships
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SQLAlchemy strongly supports different types of parent-child or associative
    table relationships. Model classes involved in the relationship require the `relationship()`
    directive from the `sqlalchemy.orm` module to be utilized to establish one-to-many
    or one-to-one relationships among model classes. This directive creates a reference
    from the parent to the child class using some foreign key indicated in the table
    schema definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'A child model class uses the `ForeignKey` construct in its foreign key column
    object to link the model class to its parent’s reference key column object. This
    directive indicates that the values in this column should be within the values
    stored in the parent table’s reference column. The `ForeignKey` directive applies
    to both the primary and non-primary `Column` objects. The following model class
    defines a sample column relationship in our database schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This `Login` model is linked to two children, `Profile_Trainers` and `Profile_Members`,
    based on its configuration. Both child models have the `ForeignKey` directive
    in their `id` column objects, as shown in the following model definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `relationship()` directive is the sole directive for creating table relationships.
    We need to specify some of its parameters, such as the *name of the child model
    class* and the *backreference specification*. The `back_populates` parameter refers
    to the complementary attribute names of the related model classes. This indicates
    the rows that need to be fetched using some relationship loading technique during
    join query transactions. The `backref` parameter can also be used instead of `back_populates`.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, `relationship()` can return either a `List` or scalar object,
    depending on the relationship type. If it is a *one-to-one type*, the parent class
    should set the `useList` parameter to `False` to indicate that it will return
    a scalar value. Otherwise, it will select a list of records from the child table.
    The previous `Login` class definition shows that `Profile_Trainers` and `Profile_Members`
    hold a one-to-one relationship with `Login` because `Login` sets its `uselist`
    to `False`. On the other hand, the model relationship between `Profile_Members`
    and `Attendance_Member` is a *one-to-many* type because `uselist` is set to `True`
    by default, as shown by the following definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: While setting the model relationships, we must also consider the *relationship
    loading type* that these related model classes will be using during the join query
    transactions. We specify this detail in the `lazy` parameter of `relationship()`,
    which is assigned to `select` by default. This is because SQLAlchemy uses a lazy
    loading technique by default in retrieving join queries. However, you can modify
    it to use `joined` (`lazy="joined"`), `subquery` (`lazy="subquery"`), `select
    in` (`lazy="selectin"`), `raise` (`lazy="raise"`), or `no` (`lazy="no"`) loading.
    Among the options, the `joined` approach is better for *INNER JOIN* transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the repository layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the SQLAlchemy ORM, creating the repository layer requires the *model classes*
    and a `Session` object. The `Session` object, derived from the `SessionFactory()`directive,
    establishes all the communication to the database and manages all the model objects
    before the `commit()` or `rollback()` transaction. When it comes to the queries,
    the `Session` entity stores the result set of records in a data structure called
    an *identity map*, which maintains the unique identity of each data record using
    the primary keys.
  prefs: []
  type: TYPE_NORMAL
- en: All repository transactions are *stateless*, which means the session is automatically
    closed after loading the model objects for insert, update, and delete transactions
    when the database issues a `commit()` or `rollback()` operation. We import the
    `Session` class from the `sqlalchemy.orm` module.
  prefs: []
  type: TYPE_NORMAL
- en: Building the CRUD transactions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, we can start building the repository layer of the fitness club application
    since we have already satisfied the requirements to build the CRUD transactions.
    The following `SignupRepository` class is the blueprint that will show us how
    to *insert*, *update*, *delete*, and *retrieve* record(s) to/from the `signup`
    table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'So far, `insert_signup()` is the most accurate way of persisting records to
    the `signup` table using SQLAlchemy. `Session` has an `add()` method, which we
    can invoke to add all record objects to the table, and a `commit()` transaction
    to finally flush all the new records into the database. The `flush()` method of
    `Session` is sometimes used instead of `commit()` to pursue the insertion and
    close `Session`, but most developers often use the latter. Note that the `signup`
    table contains all the gym members and trainers who want to gain access to the
    system. Now, the next script implements update record transaction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `update_signup()` provides a short, straightforward, and robust solution
    to updating a record in SQLAlchemy. Another possible solution is to query the
    record through `self.sess.query(Signup).filter(Signup.id == id).first()`, replace
    the attribute values of the retrieved object with the new values from the `details`
    dictionary, and then invoke `commit()`. This way is acceptable, but it takes three
    steps rather than calling the `update()` method after `filter()`, which only takes
    one. Next script is an implementation of a delete record transaction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, `delete_signup()` follows the strategy of `update_signup()`,
    which uses `filter()` first before `delete()` is called. Another way of implementing
    this is to retrieve the object using `sess.query()` again and pass the retrieved
    object as an argument to the `Session` object’s `delete(obj)`, which is a different
    function. Always remember to invoke `commit()` to flush the changes. Now, the
    following script shows how to implement the query transactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Moreover, `SignupRepository` also highlights multiple and single records being
    retrieved in many forms. The `Session` object has a `query()` method, which requires
    *model class(es)* or *model column names* as argument(s). The function argument
    performs the record retrieval with column projection. For instance, the given
    `get_all_signup()` selects all signup records with all the columns projected in
    the result. If we want to include only `username` and `password`, we can write
    our query as `sess.query(Signup.username, Signup.password)`, just like in the
    given `get_all_signup_where()`. This `query()` method also shows how to manage
    constraints using the `filter()` method with the appropriate conditional expressions.
    Filtering always comes after column projection.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the `Session` object has an `order_by()` method that takes
    column names as parameters. It is performed last in the series of query transactions,
    before the result is extracted. The given sample, `get_all_signup_sorted_desc()`,
    sorts all `Signup` objects in descending order by `username`.
  prefs: []
  type: TYPE_NORMAL
- en: The last portion of the `query()` builder returns the result of the transactions,
    whether it is a list of records or a single record. The `all()` function ends
    the query statement that returns multiple records, while `first()`, `scalar()`,
    `one()`, or `one_or_none()` can be applied if the result is a single row. In `get_signup()`,
    `one_or_none()` is utilized to raise an exception when no record is returned.
    For SQLAlchemy’s query transactions, all these functions can close the `Session`
    object. The repository classes for SQLAlchemy are in the `ch05a` folder’s `/repository/sqlalchemy/signup.py`
    module script file.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the JOIN queries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For all the ORMs supported by FastAPI, only SQLAlchemy implements join queries
    pragmatically and functionally, just like how we implemented the previous CRUD
    transactions. We used almost all of the methods we need to create joins previously
    except for `join()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us look at `LoginMemberRepository`, which shows how we can create a join
    query statement in SQLAlchemy with model classes in *one-to-one relationships*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`join_login_members()` shows the conventional way of creating *JOIN* queries.
    This solution requires passing the parent and child classes as query parameters
    and overriding the `ON` condition through the `filter()` method. The parent model
    class must come first in the column projection before the child class in the `query()`
    builder to extract the preferred result.'
  prefs: []
  type: TYPE_NORMAL
- en: Another way is to use the `select_from()` function instead of `query()` to distinguish
    the parent class from the child. This approach is more appropriate for a *one-to-one*
    relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, `MemberAttendanceRepository` showcases the *one-to-many*
    relationship between the `Profile_Members` and `Attendance_Member` model classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '`join_member_attendance()` shows the use of the `join()` method in building
    the *INNER JOIN* queries between `Profile_Members` and `Attendance_Member`. `filter()`
    is not needed anymore to build the `ON` condition because `join()` automatically
    detects and recognizes the `relationship()` parameters and the `ForeignKey` constructs
    defined at the beginning. But if there are other additional constraints, `filter()`
    can always be invoked, but only after the `join()` method.'
  prefs: []
  type: TYPE_NORMAL
- en: The `outer_join_member()` repository method implements an *OUTER JOIN* query
    from the one-to-many relationship. The `outerjoin()` method will extract all `Profile_Members`
    records mapped to their corresponding `Attendance_Member` or return `null` if
    there are none.
  prefs: []
  type: TYPE_NORMAL
- en: Running the transactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let us apply these repository transactions to the administration-related
    API services of our application. Instead of using collections to store all the
    records, we will be utilizing the ORM’s transactions to manage the data using
    PostgreSQL. First, we need to import the essential components required by the
    repository, such as `SessionFactory`, the repository class, and the `Signup` model
    class. APIs such as `Session` and other `typing` APIs can only be part of the
    implementation for type hints.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following script shows a portion of the administrator’s API services highlighting
    the insertion and retrieval services for new access registration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we need to create the `Session` instance through `SessionFactory()`,
    which we derived from `sessionmaker()`, since the repository layer is dependent
    on the session. In our application, a `sess_db()` custom generator is used to
    open and destroy the `Session` instance. It is injected into the API service methods
    to tell the `Session` instance to proceed with instantiating `SignupRepository`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Once instantiated, the repository can provide record insertion through `insert_signup()`,
    which inserts the `Signup` record. Another of its methods is `get_all_signup()`,
    which retrieves all login accounts for approval:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Both the `get_signup()` and `list_signup()` services have a `request_model`
    of the `SignupReq` type, which determines the expected output of the APIs. But
    as you may have noticed, `get_signup()` returns the `Signup` object, while `list_signup()`
    returns a list of `Signup` records. How is that possible? If `request_model` is
    used to capture the query result of the SQLAlchemy query transactions, the `BaseModel`
    class or request model must include a nested `Config` class with its `orm_mode`
    set to `True`. This built-in configuration enables type mapping and validation
    of `BaseModel` for the SQLAlchemy model types used by the repository, before all
    the record objects are filtered and stored in the request models. More information
    about the `response_model` parameter can be found in [*Chapter 1*](B17975_01.xhtml#_idTextAnchor014),
    *Setting Up FastAPI for Starters*.
  prefs: []
  type: TYPE_NORMAL
- en: '`SignupReq`, which is used by the query services of our application, is defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The script shows how `orm_mode` is enabled using the equals sign (`=`) rather
    than the typical colon symbol (`:`), which means `orm_mode` is a configuration
    detail and not part of the class attribute.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, using SQLAlchemy for the repository layer is systematic and procedural.
    It is easy to map and synchronize the model classes with the schema definitions.
    Establishing relationships through the model classes is handy and predictable.
    Although there are lots of APIs and directives involved, it is still the most
    widely supported library for domain modeling and repository construction. Its
    documentation ([https://docs.sqlalchemy.org/en/14/](https://docs.sqlalchemy.org/en/14/))
    is complete and informative enough to guide developers regarding the different
    API classes and methods.
  prefs: []
  type: TYPE_NORMAL
- en: Another feature of SQLAlchemy that’s loved by many is its capability to generate
    table schemas at the application level.
  prefs: []
  type: TYPE_NORMAL
- en: Creating tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Usually, SQLAlchemy works with the table schemas that have already been generated
    by the database administrator. In this project, the ORM setup started with designing
    the domain model classes before mapping them to the actual tables. But SQLAlchemy
    can auto-create table schemas at runtime for the FastAPI platform, which may be
    helpful during the testing or prototyping stage of the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sqlalchemy` module has a `Table()` directive that can create a table object
    with the essential column metadata using the `Column()` method, which we used
    in the mapping. The following is a sample script that shows how the ORM creates
    the signup table at the application level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Part of the schema definition is `MetaData()`, a registry that contains the
    necessary methods for generating the tables. When all the schema definitions are
    signed off, the `create_all()` method of the `MetaData()` instance is executed
    with the engine to create the tables. This process may sound straightforward,
    but we seldom pursue this DDL feature of SQLAlchemy in projects at the production
    stage.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us explore how SQLAlchemy can be used to create asynchronous CRUD transactions
    for asynchronous API services.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing async CRUD transactions using SQLAlchemy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From version 1.4, SQLAlchemy supports `Session` object. Our `ch05b` project
    showcases the asynchronous side of SQLAlchemy.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the asyncio-compliant database drivers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we begin setting up the database configuration, we need to install the
    following asyncio-compliant drivers: `aiopg` and `asyncpg`. First, we need to
    install `aiopg`, a library that will assist with any asynchronous access to PostgreSQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we must install `asyncpg`, which helps build PostgreSQL asynchronous
    transactions through Python’s AsyncIO framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This driver is a *non-database API-compliant* driver because it runs on top
    of the AsyncIO environment instead of the database API specification for synchronous
    database transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the database’s connection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After installing the necessary drivers, we can derive the database engine through
    the application’s `create_async_engine()` method, which creates an asynchronous
    version of SQLAlchemy’s `Engine`, known as `AsyncEngine`. This method has parameters
    to set such as `future`, which can enable a variety of asynchronous features during
    CRUD transactions when set to `True`. Also, it has an `echo` parameter that can
    provide us with the generated SQL queries in the server log at runtime. But the
    most essential is the database URL, which now reflects the asynchronous database
    access through calling the `asyncpg` protocol. The following is the complete script
    for the asynchronous connection to the PostgreSQL database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The additional `"+asyncpg"` detail in `DB_URL` indicates that `psycopg2` will
    no longer be the core database driver for PostgreSQL; instead, `asyncpg` will
    be used. This detail enables `AsyncEngine` to utilize `asyncpg` to establish the
    connection to the database. Omitting this detail will instruct the engine to recognize
    the `psycopg2` database API driver, which will cause problems during the CRUD
    transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the session factory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like in the synchronous version, the `sessionmaker()` directive is utilized
    to create the session factory with some new parameters set to enable `AsyncSession`.
    First, its `expire_on_commit` parameter is set to `False` to make that model instances
    and its attribute values accessible for the duration of the transaction, even
    after calling `commit()`. Unlike in the synchronous environment, all entity classes
    and their column objects are still accessible by other processes, even after transaction
    commit. Then, its `class_` parameter bears the class name `AsyncSession`, the
    entity that will take control of the CRUD transactions. Of course, `sessionmaker()`
    still needs the engine for `AsyncConnection` and its underlying asynchronous context
    managers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following script shows how the session factory is derived using the `sessionmaker()`
    directive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The full configuration for the asynchronous SQLAlchemy database connection can
    be found in the `/db_config/sqlalchemy_async_connect.py` module script file. Let
    us now create the model layer.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Base class and the model layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating the `Base` class using `declarative_base()` and creating the model
    classes using `Base` is the same as what we did in the synchronous version. No
    additional parameters are needed to build the data layer for the asynchronous
    repository transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Building the repository layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Implementing asynchronous CRUD transactions is entirely different from implementing
    synchronous ones. The ORM supports the use of the `execute()` method of the `AsyncConnection`
    API to run some of the built-in ORM core methods, namely `update()`, `delete()`,
    and `insert()`. When it comes to query transactions, the new `select()` directive
    from the `sqlalchemy.future` module is used instead of the core `select()` method.
    And since `execute()` is an `async` method, this requires that all repository
    transactions are `async` too to apply the *Async/Await* design pattern. The following
    `AttendanceRepository` uses the asynchronous type of SQLAlchemy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The given *asynchronous* `insert_attendance()` method in the preceding script
    shows the use of the `insert()` directive in creating an attendance log for a
    gym member. First, we need to pass the model class name to `insert()` to let the
    session know what table to access for the transaction. Afterward, it emits the
    `values()` method to project all the column values for insertion. Lastly, we need
    to call the `execute()` method to run the final `insert()` statement and automatically
    commit the changes since we didn’t turn off the `autocommit` parameter of `sessionmaker()`
    during the configuration. Do not forget to invoke `await` before running the asynchronous
    method because everything runs on top of the AsyncIO platform this time.
  prefs: []
  type: TYPE_NORMAL
- en: Also, you have the option to add some additional execution details before running
    `execute()`. One of these options is `synchronize_session`, which tells the session
    to always synchronize the model attribute values and the updated values from the
    database using the `fetch` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Almost the same procedure is applied to the `update_attendance()` and `delete_attendance()`
    methods. We can run them through `execute()` and nothing else:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: When it comes to queries, the repository class contains `get_all_attendance()`,
    which retrieves all the attendance records, and `get_attendance()`, which retrieves
    the attendance log of a particular member through its `id`. Constructing the `select()`
    method is a straightforward and pragmatic task since it is similar to writing
    a native `SELECT` statement in SQL development. First, the method needs to know
    what columns to project, and then it caters to some constraints if there are any.
    Then, it needs the `execute()` method to run the query asynchronously and extract
    the `Query` object. The resulting `Query` object has a `scalars()` method, which
    we can call to retrieve the list of records. Do not forget to close the session
    by calling the `all()` method.
  prefs: []
  type: TYPE_NORMAL
- en: '`check_attendance()`, on the other hand, uses the `scalar()` method of the
    `Query` object to retrieve one record: a specific attendance. Aside from record
    retrieval, `scalar()` also closes the session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The repository classes for the asynchronous SQLAlchemy can be found in the `/repository/sqlalchemy/attendance.py`
    module script file. Now, let us apply these asynchronous transactions to pursue
    some attendance monitoring services for our fitness gym application.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The `**` operator in `update_attendance()` is a Python operator overload that
    converts a dictionary into `kwargs`. Thus, the result of `**details` is a `kwargs`
    argument for the `values()` method of the `select()` directive.
  prefs: []
  type: TYPE_NORMAL
- en: Running the CRUD transactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There two big differences between AsyncIO-driven SQLAlchemy and the database
    API-compliant option when creating the `Session` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: First, `AsyncSession`, which was created by the `AsyncSessionFactory()` directive,
    needs an asynchronous `with` context manager because of the connection’s `AsyncEngine`,
    which needs to be closed after every `commit()` transaction. Closing the session
    factory is not part of the procedure in the synchronous ORM version.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, after its creation, `AsyncSession` will only start executing all the
    CRUD transactions when the service calls its `begin()` method. The main reason
    is that `AsyncSession` can be closed and needs to be closed once the transaction
    has been executed. That is why another asynchronous context manager is used to
    manage `AsyncSession`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows the `APIRouter` script, which implements the services
    for monitoring gym member attendance using the asynchronous `AttendanceRepository`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The preceding script shows no direct parameter passing between the repository
    class and the `AsyncSession` instance. The session must comply with the two context
    managers before it becomes a working one. This syntax is valid under *SQLAlchemy
    1.4*, which may undergo some changes in the future with SQLAlchemy’s next releases.
  prefs: []
  type: TYPE_NORMAL
- en: Other ORM platforms that have been created for asynchronous transactions are
    easier to use. One of these is **GINO**.
  prefs: []
  type: TYPE_NORMAL
- en: Using GINO for async transactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GINO**, which stands for **GINO Is Not ORM**, is a lightweight asynchronous
    ORM that runs on top of an SQLAlchemy Core and AsyncIO environment. All its APIs
    are asynchronous-ready so that you can build contextual database connections and
    transactions. It has built-in *JSONB* support so that it can convert its results
    into JSON objects. But there is one catch: GINO only supports PostgreSQL databases.'
  prefs: []
  type: TYPE_NORMAL
- en: While creating the gym fitness project, the only available stable GINO version
    is 1.0.1, which requires *SQLAlchemy 1.3*. Therefore, installing GINO will automatically
    uninstall *SQLAlchemy 1.4*, thus adding the GINO repository to the `ch05a` project
    to avoid any conflicts with the async version of SQLAlchemy.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following command to install the latest version of GINO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Installing the database driver
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since the only RDBMS it supports is PostgreSQL, you only need to install `asyncpg`
    using the `pip` command.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing the database connection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'No other APIs are needed to open a connection to the database except for the
    `Gino` directive. We need to instantiate the class to start building the domain
    layer. The `Gino` class can be imported from the ORM’s `gino` module, as shown
    by the following script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Its instance is like a façade that controls all database transactions. It starts
    by establishing a database connection once it’s been provided with the correct
    PostgreSQL administrator credentials. The full GINO database connectivity script
    can be found in the `/db_config/gino_connect.py` script file. Let us now build
    the model layer.
  prefs: []
  type: TYPE_NORMAL
- en: Building the model layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The model class definition in GINO has similarities with SQLAlchemy when it
    comes to structuring, column metadata, and even the existence of the `__tablename__`
    property. The only difference is the superclass type because GINO uses the `Model`
    class from the database reference instance’s `db`. The following script shows
    how the `Signup` domain model is mapped to the `signup` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Like in SQLAlchemy, the `__tablename__` property is mandatory for all model
    classes to indicate their mapped table schema. When defining the column metadata,
    the `db` object has a `Column` directive that can set properties such as the *column
    type*, *primary key*, *unique*, *default*, *nullable*, and *index*. The column
    types also come from the `db` reference object, and these types are also the same
    for SQLAlchemy – that is, `String`, `Integer`, `Date`, `Time`, `Unicode`, and
    `Float`.
  prefs: []
  type: TYPE_NORMAL
- en: And just in case the name of the model attribute does not match the column name,
    the `Column` directive has its first parameter register the name of the actual
    column and maps it to the model attributes. The `username` and `password` columns
    are example cases of mapping the class attributes to the table’s column names.
  prefs: []
  type: TYPE_NORMAL
- en: Mapping table relationships
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At the time of writing, GINO only supports the *many-to-one relationship* by
    default. The `db` reference object has a `ForeignKey` directive, which establishes
    a foreign key relationship with the parent model. It just needs the actual reference
    key column and table name of the parent table to pursue the mapping. Setting the
    `ForeignKey` property in the `Column` object of the child model class is enough
    configuration to perform a *LEFT OUTER JOIN* to retrieve all the child records
    of the parent mode class. GINO has no `relationship()` function to address more
    details regarding how to fetch the child records of the parent model class. However,
    it has built-in loaders to automatically determine the foreign key and perform
    a many-to-one join query afterward. A perfect setup for this join query is the
    relationship configuration between the `Profile_Trainers` and `Gym_Class` model
    classes, as shown in the following script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We will have to make some changes if we need to build a query that will deal
    with a *one-to-many* or a *one-to-one relationship*. For the *LEFT OUTER JOIN*
    query to work, the parent model class must have a `set` collection defined to
    contain all the child records during join queries involving one-to-many relationships.
    For a *one-to-one relationship*, the parent only needs to instantiate the child
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This *set collection* or *child object* must be instantiated in the parent’s
    `__init__()` to be accessed by the ORM’s loader through the *children* or *child*
    `@property`, respectively. Using `@property` is the only way to manage joined
    records.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the existence of the loader APIs is proof that GINO does not support
    the automated relationship that SQLAlchemy has. If we want to deviate from its
    core setup, Python programming is needed to add some features not supported by
    the platform, such as the one-to-many setup between `Profile_Members` and `Gym_Class`,
    and between `Login` and `Profile_Members`/`Profile_Trainers`. In the previous
    script, notice the inclusion of a constructor and the custom `children` Python
    property in `Profile_Members`, as well as the custom `child` property in `Login`.
    This is because GINO only has a built-in `parent` property.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the domain models of GINO in the `/models/data/gino_models.py`
    script.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '`@property` is a Python decorator that’s used to implement a getter/setter
    in a class. This hides an instance variable from the accessor and exposes its
    *getter* and *setter* property *fields*. Using `@property` is one way to implement
    the *encapsulation* principle in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the CRUD transactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us consider the following `TrainerRepository`, which manages trainer profiles.
    Its `insert_trainer()` method shows the conventional way of implementing insert
    transactions. GINO requires its model class to call `create()`, an inherited method
    from the `db` reference object. All the column values are passed to the `create()`
    method through named parameters or as a bundle using `kwargs` before the record
    object is persisted. But GINO allows another insert option that uses the instance
    of the model derived by injecting column values into its constructor. The created
    instance has a method called `create()` that inserts the record object without
    requiring any parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '`update_trainer()` highlights how GINO updates table records. Based on the
    script, updating the table in the GINO way involves doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: First, it requires the `get()` class method of the model class to retrieve the
    record object with the `id` primary key.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Second, the extracted record has an instance method called `update()` that
    will automatically modify the mapped row with the new data specified in its `kwargs`
    argument. The `apply()` method will commit the changes and close the transaction:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Another option is to use the SQLAlchemy `ModelClass.update.values(ModelClass).where(expression)`
    clause, which, when applied to `update_trainer()`, will give us this final statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Its `delete_trainer()` also follows the same approach as the GINO *update*
    transaction. This transaction is a two-step process, and the last step requires
    calling the `delete()` instance method of the extracted record object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, `TrainerRepository` has two methods, `get_member()` and
    `get_all_member()`, which show how GINO constructs query statements:'
  prefs: []
  type: TYPE_NORMAL
- en: The former retrieves a specific record object using its primary key through
    the `get()` class method of the model class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The latter uses the `gino` extension of `query` to utilize the `all()` method,
    which retrieves the records:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'But what translates database rows into model objects in a query’s execution
    is the built-in loader of GINO. If we expand further on the solution presented
    in `get_all_member()`, this will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In the GINO ORM, all queries utilize `ModelLoader` to load each database record
    into a model object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: If the normal query requires `ModelLoader`, what is needed for the *JOIN* query
    transactions? GINO has no automated support for table relationships, and creating
    *JOIN* queries is impossible without `ModelLoader`. The `join_classes_trainer()`
    method implements a *one-to-many* query for `Profile_Trainers` and `Gym_Class`.
    The `distinct(Gym_Class.id).load(parent=Profile_Trainers)` clause in the query
    creates a `ModelLoader` for `GymClass`, which will merge and load the `Profile_Trainers`
    parent record into its child `Gym_Class`. `join_member_classes()` creates *one-to-many*
    joins, while `distinct(Profile_Members.id).load(add_child=Gym_Class)` creates
    a `ModelLoader` to build the set of `Gym_Class` records, as per the `Profile_Members`
    parent.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the *many-to-one* relationship of `Gym_Class` and `Profile_Members`
    uses the `load()` function of `Profile_Member`, which is a different approach
    to matching the `Gym_Class` child records to `Profile_Members`. The following
    joined query is the opposite of the *one-to-many* setup because the `Gym_Class`
    records here are on the left-hand side while the profiles are on the right:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: So, the loader plays an important role in building queries in GINO, especially
    joins. Although it makes query building difficult, it still gives flexibility
    to many complex queries.
  prefs: []
  type: TYPE_NORMAL
- en: All the repository classes for GINO can be found in the `/repository/gino/trainers.py`
    script.
  prefs: []
  type: TYPE_NORMAL
- en: Running the CRUD transactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For our repositories to run in the `APIRouter` module, we need to open the
    database connection by binding the `db` reference object to the actual database
    through `DB_URL`. It is ideal to use a dependable function for the binding procedure
    because the easier form of rolling out is done through `APIRouter` injection.
    The following script shows how to set up this database binding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The `list_trainers()` and `update_trainer()` REST services shown in the preceding
    code are some services of our *fitness club* application that will successfully
    run `TrainerRepository` after injecting `sess_db()` into `APIRouter`. GINO does
    not ask for many details when establishing the connection to PostgreSQL except
    for `DB_URL`. Always specify the `asyncpg` dialect in the URL because it is the
    only driver that’s supported by GINO as a synchronous ORM.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'GINO and SQLAlchemy have the same approach to creating a table schema at the
    framework level. Both require the `MetaData` and `Column` directives for building
    the `Table` definitions. Then, an asynchronous function is preferred to derive
    the engine using the `create_engine()` method with our `DB_URL`. Like in SQLAlchemy,
    this engine plays a crucial role in building the tables through `create_all()`,
    but this time, it uses GINO’s `GinoSchemaVisitor` instance. The following script
    shows the complete implementation of how tables are generated in GINO using the
    AsyncIO platform:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: As stated in SQLAlchemy, performing DDL transactions such as schema auto-generation
    at the start is optional because it may cause FastAPI’s performance to degrade,
    and even some conflicts in the existing database schema.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let us explore another ORM that requires custom Python coding: **Pony
    ORM**.'
  prefs: []
  type: TYPE_NORMAL
- en: Using Pony ORM for the repository layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pony ORM relies on Python syntax for building the model classes and repository
    transactions. This ORM only uses Python data types such as `int`, `str`, and `float`,
    as well as class types to implement model definitions. It applies Python `lambda`
    expressions to establish CRUD transactions, especially when mapping table relationships.
    Also, Pony heavily supports JSON conversion of record objects when reading records.
    On the other hand, Pony can cache the query objects, which provides faster performance
    than the others. The code for Pony ORM can be found in the `ch05a` project.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use Pony, we need to install it using `pip`. This is because it is a third-party
    platform:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Installing the database driver
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since Pony is an ORM designed to build synchronous transactions, we will need
    the `psycopg2` PostgreSQL driver. We can install it using the `pip` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Creating the database’s connectivity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The approach to establishing database connectivity in Pony is simple and declarative.
    It only needs the `Database` directive from the `pony.orm` module to be instantiated
    to connect to the database using the correct database credentials. The following
    script is used in the *fitness club* prototype:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the first parameter of the constructor is the *database dialect*,
    followed by `kwargs`, which contains all the details about the connection. The
    full configuration can be found in the `/db_config/pony_connect.py` script file.
    Now, let us create Pony's model classes.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the model classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The created database object, `db`, is the only component needed to define a
    Pony *entity*, a term that refers to a model class. It has an `Entity` attribute,
    which is used to subclass each model class to provide the `_table_` attribute,
    which is responsible for the *table-entity* mapping. All entity instances are
    bound to `db` and mapped to the tables. The following script shows how the `Signup`
    class becomes an entity of the model layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The `pony.orm` module contains `Required`, `Optional`, `PrimaryKey`, or `Set`
    directives, which are used to create column attributes. Since each entity must
    have a primary key, `PrimaryKey` is used to define the column attribute of the
    entity. If the class has no primary key, Pony ORM will implicitly generate an
    `id` primary for the entity with the following definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, the `Set` directive indicates relationships between entities.
    All these directives have a mandatory attribute column type, which declares the
    column value type in Python syntax (for example, `int`, `str`, `float`, `date`,
    or `time`) or any class type. Other column attributes include `auto`, `max_len`,
    `index`, `unique`, `nullable`, `default`, and `column`. Now, let us establish
    a relationship between model classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The given `Login` class has two additional attributes, `trainers` and `members`,
    which serve as reference keys to the `Profile_Trainers` and `Profile_Members`
    models, respectively. In turn, these child entities have their respective class
    attributes pointing back at the `Login` model, establishing a relationship. These
    column attributes and their reference-foreign keys relationship must match the
    physical database schema. The following code shows examples of Pony’s child model
    classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Defining the relationship attributes depends on the relationship type between
    the two entities. Attributes should be defined as *Optional(parent)*-*Required(child)*
    or *Optional(parent)*-*Optional(child)* if the relationship type is one-to-one.
    For one-to-many, attributes should be defined as *Set(parent)*-*Required(child)*.
    Finally, for many-to-one, the attributes must be defined as *Set(parent)*-*Set(child)*.
  prefs: []
  type: TYPE_NORMAL
- en: '`Login` has a one-to-one relationship with `Profile_Members`, which explains
    the use of the `Optional` attribute to point to the `id` key of `Profile_Members`.
    The primary keys are always the reference keys in this relationship for Pony.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the `Profile_Trainers` model has a one-to-many setup with
    `Profile_Members`, which explains why the `trainer_id` attribute of the former
    uses the `Required` directive to point to the `Set` attribute `members` of the
    latter. Sometimes, the framework requires backreference through the directive’s
    `reverse` parameter. The preceding code also depicts the same scenario between
    the `Profile_Members` and `Gym_Class` models, where the `gclass` attribute of
    `Profile_Members` is declared as a `Set` collection that contains all the enrolled
    gym classes of the member. The reference key can be a primary key or just a typical
    class attribute in this relationship. The following snippet shows the blueprint
    of the `Gym_Class` model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Unlike in other ORMs, Pony needs `generate_mapping()` to be executed to realize
    all the entity mappings to the actual tables. The method is an instance method
    of the `db` instance that must appear in the last part of the module script, as
    shown in the previous snippet, where `Gym_Class` was the last Pony model class
    to be defined. All the Pony model classes can be found in the `/models/data/pony_models.py`
    script file.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we can create Pony entities manually or digitally using *Pony ORM
    ER Diagram Editor*, which we can access at [https://editor.ponyorm.com/](https://editor.ponyorm.com/).
    The editor can provide us with both free and commercial accounts. Let us now implement
    the CRUD transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the CRUD transactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'CRUD transactions in Pony are session-driven. But unlike SQLAlchemy, its repository
    classes do not require injecting `db_session` into the repository constructor.
    Each transaction in Pony will not work without `db_session`. The following code
    shows a repository class that implements all the transactions needed to manage
    a list of gym members:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'In Pony, inserting a record means instantiating the model class with the injected
    record values. An example is `insert_member()`, which inserts a profile by instantiating
    the `Profile_Members` model with the injected membership details. However, the
    case is different when updating records, as shown in the following script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Updating a record in Pony, which is implemented in the `update_member()` script,
    means retrieving the record object through *indexing* using its `id`. The retrieved
    object is automatically converted into a JSON-able object since Pony has built-in
    support for JSON. Then, the new values of those attributes are overwritten as
    they must be changed. This *UPDATE* transaction is, again, within the bounds of
    `db_session`, thus automatically refreshing the record(s) after the overwrites.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, `delete_member()` of the repository class shows the same
    approach with *UPDATE*, except that a `delete()` class method is invoked right
    after retrieving the object record. The following is the script for this operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The delete transaction is also `db_session` bound, so invoking `delete()` automatically
    refreshes the table. The following code shows Pony’s implementation for query
    transactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '`get_member()` retrieves a single record using the `get()` class method, which
    requires a `lambda` expression in its parameter. Since `Login` has a one-to-one
    relationship with `Profile_Members`, first, we must extract the `Login` record
    of the member and use the `login` object to fetch the record through the `get()`
    helper function of the `Profile_Members` entity. This approach is also applicable
    to other entities with other entity relationships. Now, `get_all_member()` retrieves
    a result set using the `select()` method. The `select()` method can also utilize
    a lambda expression if there are constraints in the retrieval operation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pony model classes have the `get()` and `select()` methods, which both return
    `Query` objects that FastAPI cannot process directly. So, we need an ORM-friendly
    `Pydantic` model to extract the final entities from these `Query` objects. Like
    in SQLAlchemy, a `ModelBase` class with a nested `Config` class is required to
    retrieve the records from the `Query` object. The nested class must configure
    `orm_mode` to `True`. If relationship mappings are involved, the request model
    must also declare the attributes involved in the relationship and their corresponding
    child object converters. The method converters, decorated by Pydantic’s `@validator`,
    are automatically called by Pony to interpret and validate the `Query` objects
    into JSON-able components such as `List` or entity objects. The following code
    shows the request model that’s used to extract the records from `select()` through
    list comprehension and the `Profile_Member dict` object from `get()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The presence of the `gclass_set_to_list ()` and `trainer_object_to_map()` converts
    in `ProfileMembersReq` enables data to be populated to the child objects in the
    `gclass` and `trainer_id` attributes, respectively. These additional features
    indicate why executing `select()` can already retrieve the *INNER JOIN* queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build *LEFT JOIN* query transactions, the ORM has a built-in directive called
    `left_join()`, which is used to extract the `Query` object bearing the *LEFT JOIN*
    raw objects through a Python generator. The following code shows another repository
    class that showcases the use of `left_join()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: All the repository classes can be found in the `/repository/pony/members.py`
    script file.
  prefs: []
  type: TYPE_NORMAL
- en: Now, what makes Pony faster is that it uses an *identity map*, which contains
    all the record objects that have been retrieved from every single query transaction.
    The ORM applies the *Identity Map* design pattern to apply its caching mechanism
    to make read and write executions fast. It only requires memory management and
    monitoring to avoid memory leak problems in complex and huge applications.
  prefs: []
  type: TYPE_NORMAL
- en: Running the repository transactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since `db_session` is already managed internally, no additional requirements
    will be needed from Pony for the `APIRouter` script to run the repository transactions.
    The repository classes are directly accessed and instantiated in each of the APIs
    to access the CRUD transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the tables are non-existent yet, Pony can generate those tables through its
    entity classes. This DDL transaction is enabled when the `create_tables` parameter
    of the `generate_mapping()` method of `db` is set to `True`.
  prefs: []
  type: TYPE_NORMAL
- en: For the most compact and simplest ORM in terms of syntax, we have **Peewee**.
  prefs: []
  type: TYPE_NORMAL
- en: Building the repository using Peewee
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Among the different ORMs, Peewee is the simplest and smallest in terms of ORM
    features and APIs. The framework is easy to understand and use; it is not comprehensive,
    but it has intuitive ORM syntax. Its strength is in building and executing query
    transactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Peewee is not designed for asynchronous platforms, but it can work with them
    by using some async-related libraries that it supports. We need to install at
    least *Python 3.7* for Peewee to work with FastAPI, an asynchronous framework.
    To install Peewee, we need to execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Installing the database driver
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The ORM needs `psycopg2` as the PostgreSQL database driver. We can install
    it using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Creating the database connection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For Peewee to work with FastAPI, we must build a multi-threading mechanism
    where Peewee can cater to more than one request transaction on the same thread,
    and per request can do more executions simultaneously using different local threads.
    This customized multi-threading component, which can be created using the `ContextVar`
    class, bridges Peewee to the FastAPI platform. But for Peewee to utilize these
    threads, we also need to customize its `_ConnectionState` with the newly created
    threading state, `db_state`. The following code shows how `db_state` and a custom
    `_ConnectionState` can be derived:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'To apply the new `db_state` and `_ConnectionState` classes, cited in the preceding
    code as `PeeweeConnectionState`, we need to open the database connection through
    the `Database` class. Peewee has several variations of the `Database` class, depending
    on the type of database the application will choose to connect to. Since we will
    be using PostgreSQL, `PostgresqlDatabase` is the correct class to initialize with
    all the necessary database details. After establishing the connection, the `db`
    instance will have a `_state` attribute that will point to the `PeeweeConnectionState`
    instance. The following snippet shows how to connect to our *fitness gym* database’s
    `fcms` using the database credentials:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code also emphasizes that the default state of the database connection
    must be replaced with a non-blocking one that can work with the FastAPI platform.
    This configuration can be found in the `/db_config/peewee_connect.py` script file.
    Let us now build Peewee's model layer.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the tables and the domain layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Peewee prefers *auto-generating tables* based on its model classes, unlike
    other ORMs. Peewee recommends *reverse engineering*, where tables are created
    rather than only being mapped to existing tables. Letting the application generate
    the tables lessens the hassle of establishing relationships and primary keys.
    This ORM is unique because it has an "implied" approach to creating primary keys
    and foreign keys. The following script shows how Peewee model classes are defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: We can’t see any primary keys in the model classes presented because the Peewee
    engine will create them during its schema auto-generation. The physical foreign
    key column and the model attribute will have the same name derived from its model
    name, with the `modelname_id` pattern in lowercase form. If we insist on adding
    the primary key for the model, a conflict will occur, making Peewee dysfunctional.
    We must let Peewee create the physical tables from the model classes to avoid
    this mishap.
  prefs: []
  type: TYPE_NORMAL
- en: All model classes inherit properties from the `Model` directive of the ORM.
    It also has column directives such as `IntegerField`, `FloatField`, `DateField`,
    and `TimeField` for defining the column attributes of the model classes. Moreover,
    each domain class has a nested `Meta` class, which registers the references to
    `database` and `db_table`, which is mapped to the model class. Other properties
    that we can set here are `primary_key`, `indexes`, and `constraints`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only problem in having this auto-generation is when creating table relationships.
    Linking the foreign key attributes of the child classes to the non-existent primary
    keys of the parent classes is difficult before auto-generation. For instance,
    the following `Profile_Trainers` model implies a *many-to-one* relationship with
    the `Login` class, which is only defined by the `ForeignKeyField` directive with
    the `trainer` backreference attribute and not by the `login_id` foreign key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The `login_id` column that’s generated after auto-generation can be seen in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – The generated profile_trainers schema'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.2_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.2 – The generated profile_trainers schema
  prefs: []
  type: TYPE_NORMAL
- en: 'Foreign key attributes are declared using the `ForeignKeyField` directive,
    which accepts at least three crucial parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: The parent model’s name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `backref` parameter, which references the child record (if in a *one-to-one*
    relationship) or a set of child objects (if in a *one-to-many* or *many-to-one*
    relationship)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `unique` parameter, which indicates a *one-to-one* relationship when set
    to `True` or `False` otherwise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After defining all the models, including their relationships, we need to call
    the following methods from Peewee’s `db` instance for the table mapping to occur:'
  prefs: []
  type: TYPE_NORMAL
- en: '`connect()` to establish the connection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create_tables()` to pursue the schema generation based on its list of model
    classes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following script shows a snapshot of the class definitions, including the
    call to the two `db` methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, we need to set the `safe` parameter of `create_tables()` to `True`
    so that Peewee will only perform schema auto-generation once during the initial
    server startup of the application. All the model classes for the Peewee ORM can
    be found in the `/models/data/peewee_models.py` script file. Now, let us implement
    the repository layer.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the CRUD transactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creating the asynchronous connection and building the model layer for the application
    in the Peewee ORM is tricky, but implementing its repository layer is straightforward.
    All the method operations are entirely derived from its model classes. For instance,
    `insert_login()`, which is shown in the following snippet, shows how the `create()`
    static method of `Login` takes the login details for record insertion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: This method can be re-implemented to perform bulk inserts, but Peewee has an
    alternative way to pursue multiple insertions through its `insert_many()` class
    method. Using `insert_many()` requires more accurate column details for mapping
    multiple schema values. It also needs an invocation of the `execute()` method
    to perform all the bulk insertions and close the operation afterward.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, the `update()` class method requires the `execute()` method after
    filtering the record that needs updating using the `id` primary key. This is shown
    in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'When it comes to record deletion, `delete_login()` shows the easy approach
    – that is, by using `delete_by_id()`. But the ORM has another way, which is to
    retrieve the record object using the `get()` class method – for example, `Login.get(Login.id
    == id)` – and eventually delete the record through the `delete_instance()` instance
    method of the record object. The following `delete_login()` transaction shows
    how to utilize the `delete_by_id()` class method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The following scripts, which are for `get_all_login()` and `get_login()`, highlight
    how Peewee retrieves records from the database. Peewee uses its `get()` class
    method to retrieve a single record using the primary key; the same method was
    applied to its *UPDATE* transaction in the previous code snippet. Similarly, Peewee
    uses a class method to extract multiple records, but this time, it uses the `select()`
    method. The resulting object can’t be encoded by FastAPI unless it’s contained
    in the `List` collection, which serializes the rows of data into a list of JSON-able
    objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, the following repository classes show how to create *JOIN*
    queries using its `join()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '`join_login_trainers()` of `LoginTrainersRepository` builds the *INNER JOIN*
    query of the `Profile_Trainers` and `Login` objects. The leftmost model indicated
    in the parameter of the `Profile_Trainers` object’s `select()` directive is the
    parent model type, followed by its child model class in a *one-to-one* relationship.
    The `select()` directive emits the `join()` method with the model class type,
    which indicates the type of records that belong to the right-hand side of the
    query. The *ON* condition(s) and the foreign key constraints are optional but
    can be declared explicitly by adding the `on` and `join_type` attributes of the
    `join()` construct. An example of this query is `outer_join_member_gym()` of `MemberGymClassesRepository`,
    which implements a *LEFT OUTER JOIN* of `Profile_Members` and `Gym_Class` using
    the `LEFT_OUTER` option of the `join_type` attribute of `join()`.'
  prefs: []
  type: TYPE_NORMAL
- en: Joins in Peewee also need the `list()` collection to serialize the retrieved
    records. All the repository classes for Peewee can be found in the `/repository/peewee/login.py`
    script.
  prefs: []
  type: TYPE_NORMAL
- en: Running the CRUD transaction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since Peewee’s database connection is set at the model layer, no additional
    requirements are required for `APIRouter` or `FastAPI` to run the CRUD transactions.
    API services can easily access all the repository classes without calling methods
    or directives from the `db` instance.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have experimented with popular ORMs to integrate a relational database
    into the FastAPI framework. If applying an ORM is not enough for a microservice
    architecture, we can utilize some design patterns that can further refine the
    CRUD performance, such as **CQRS**.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the CQRS design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CQRS is a microservice design pattern responsible for segregating query transactions
    (*reads*) from the insert, update, and delete operations (*writes*). The separation
    of these two groups lessens the cohesion access to these transactions, which provides
    less traffic and faster performance, especially when the application becomes complex.
    Moreover, this design pattern creates a loose-coupling feature between the API
    services and the repository layer, which gives us an advantage if there are several
    turnovers and changes in the repository layers.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the handler interfaces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To pursue CQRS, we need to create the two interfaces that define the query
    and the command transactions. The following code shows the interfaces that will
    identify the *read* and *write* transactions for `Profile_Trainers`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Here, `IQueryHandler` and `ICommandHandler` are informal interfaces because
    Python does not have an actual definition of an interface.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the command and query classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we need to implement the command and query classes. The command serves
    as an instruction to pursue the *write* transactions. It also carries the state
    of the result after they have been executed. On the other hand, the query instructs
    the *read* transaction to retrieve record(s) from the database and contain the
    result afterward. Both components are serializable classes with *getter/setter*
    attributes. The following code shows the script for `ProfileTrainerCommand`, which
    uses Python’s `@property` attribute to store the state of the *INSERT* execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: The `details` property will store all the column values of the trainer’s profile
    record that need to be persisted.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following script implements a sample *query* class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: The constructor of `ProfileTrainerListQuery` prepares a dictionary object that
    will contain all the retrieved records after the query transaction has been executed.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the command and query handlers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will be using our previous interfaces to define the command and query handlers.
    Note that the command handler accesses and executes the repository to execute
    the *write* transactions, while the query handler processes the *read* transactions.
    These handlers serve as the façade between the API services and the repository
    layer. The following code shows the script for `AddTrainerCommandHandler`, which
    manages the *INSERT* transaction for the trainer’s profile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: The handler depends on `ProfileTrainerCommand` for the record values that are
    crucial to the asynchronous execution of its `handle()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following script shows a sample implementation for a query handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Query handlers return their *query* to the services and not the actual values.
    The `handle()` method of `ListTrainerQueryHandler` returns `ProfileTrainerListQuery`,
    which contains the list of records from the *read* transaction. This mechanism
    is one of the main objectives of applying CQRS to microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the handlers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CQRS, aside from managing the friction between the *read* and *write* executions,
    does not allow the API services to interact directly with the execution of CRUD
    transactions. Moreover, it streamlines and simplifies the access of the CRUD transactions
    by assigning only the handler that’s needed by a particular service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following script shows how `AddTrainerCommand` is only directly associated
    with the `add_trainer()` service and how `LisTrainerQueryHandler` is only directly
    associated with the `list_trainers()` service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: We can identify transactions that are accessed frequently in `APIRouter` through
    CQRS. It helps us find which transactions need performance tuning and focus, which
    can help us avoid performance issues when the amount of access increases. When
    it comes to enhancement and upgrades, the design pattern can help developers find
    what domain to prioritize because of the separation of aspects in the repository
    layer. Generally, it offers flexibility to the application when its business processes
    need to be revamped. All the CQRS-related scripts can be found in the `/cqrs/`
    project folder.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applying ORM always has advantages and disadvantages for any application. It
    can bloat the application with so many configurations and layers of components,
    and it can even slow down the application if not managed well. But ORM, in general,
    can help optimize query development by simplifying the constructs by using its
    APIs and eliminating unimportant repetitive SQL scripts. Overall, it can reduce
    the time and cost of software development compared to using `cursor` from `psycopg2`.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, four Python ORMs were used, studied, and experimented with
    to help FastAPI create its repository layer. First, there is *SQLAlchemy*, which
    provides a boilerplated approach to creating standard and asynchronous data persistency
    and query operations. Then, there is *GINO*, which uses the AsyncIO environment
    to implement asynchronous CRUD transactions with its handy syntax. Also, there
    is *Pony*, the most Pythonic among the ORMs presented because it uses hardcore
    Python code to build its repository transactions. Lastly, there is *Peewee*, known
    for its concise syntax but tricky composition for the asynchronous database connection
    and CRUD transactions. Each ORM has its strengths and weaknesses, but all provide
    a logical solution rather than applying brute-force and native SQL.
  prefs: []
  type: TYPE_NORMAL
- en: If the ORM needs fine-tuning, we can add some degree of optimization by using
    data-related design patterns such as CQRS, which minimizes friction between the
    "read" and "write" CRUD transactions.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter has highlighted the flexibility of FastAPI when utilizing ORMs
    to establish a connection to a relational database such as PostgreSQL. But what
    if we use a NoSQL database such as MongoDB to store information? Will FastAPI
    perform with the same level of performance when performing CRUD to and from MongoDB?
    The next chapter will discuss various solutions for integrating FastAPI into MongoDB.
  prefs: []
  type: TYPE_NORMAL
