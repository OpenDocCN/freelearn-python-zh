<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Web Scraping with Python Requests and BeautifulSoup"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Web Scraping with Python Requests and BeautifulSoup</h1></div></div></div><p>We have become experts in how to communicate with the Web through <code class="literal">Requests</code>. Everything progressed flamboyantly while working with the APIs. However, there are some conditions where we need to be aware of API folklore.</p><p>The first thing that concerns us is not all web services have built an API for the sake of their third-party customers. Also, there is no statute that the API should be maintained perfectly. Even tech giants such as Google, Facebook, and Twitter tend to change their APIs abruptly without prior notice. So, it's better to understand that it is not always the API that comes to the rescue when we are looking for some vital information from a web resource.</p><p>The concept of <span class="strong"><strong>web scraping</strong></span> stands as a savior when we really turn imperative to access some information <a class="indexterm" id="id195"/>from a web resource that does not maintain an API. In this chapter, we will discuss tricks of the trade to extract information from web resources by following all the principles of web scraping.</p><p>Before we begin, let's get to know some important concepts that will help us to reach our goal. Take a look at the response content format of a request, which will introduce us to a particular type of data:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; import requests</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; r = requests.get("http://en.wikipedia.org/wiki/List_of_algorithms")</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; r</strong></span>
<span class="strong"><strong>&lt;Response [200]&gt;</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; r.text</strong></span>
<span class="strong"><strong>u'&lt;!DOCTYPE html&gt;\n&lt;html lang="en" dir="ltr" class="client-nojs"&gt;\n&lt;head&gt;\n&lt;meta charset="UTF-8" /&gt;\n&lt;title&gt;List of algorithms - Wikipedia, the free encyclopedia&lt;/title&gt;\n...</strong></span>
</pre></div><p>In the preceding example, the response content is rendered in the form of semistructured data, which is represented using HTML tags; this in turn helps us to access the information about the different sections of a web page individually.</p><p>Now, let's get to know the different types of data that the Web generally deals with.</p><div class="section" title="Types of data"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec49"/>Types of data</h1></div></div></div><p>In most cases, we deal <a class="indexterm" id="id196"/>with three types of data when working with web sources. They are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Structured data</li><li class="listitem" style="list-style-type: disc">Unstructured data</li><li class="listitem" style="list-style-type: disc">Semistructured Data</li></ul></div><div class="section" title="Structured data"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec43"/>Structured data</h2></div></div></div><p>Structured data is <a class="indexterm" id="id197"/>a type of data that exists in an organized form. Normally, structured data has a predefined format and it is machine readable. Each piece of <a class="indexterm" id="id198"/>data that lies in structured data has a relation with every other data as a specific format is imposed on it. This makes it easier and faster to access different parts of data. The structured data type helps in mitigating redundant data while dealing with huge amounts of data.</p><p>Databases always contain structured data, and SQL techniques can be used to access data from them. We can regard census records as an example of structured data. They contain information about the date of birth, gender, place, income, and so on, of the people of a country.</p></div><div class="section" title="Unstructured data"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec44"/>Unstructured data</h2></div></div></div><p>In contrast to <a class="indexterm" id="id199"/>structured data, unstructured data either misses out on a <a class="indexterm" id="id200"/>standard format or stays unorganized even though a specific format is imposed on it. Due to this reason, it becomes difficult to deal with different parts of the data. Also, it turns into a tedious task. To handle unstructured data, different techniques such as text analytics, Natural Language Processing (NLP), and data mining are used. Images, scientific data, text-heavy content (such as newspapers, health records, and so on), come under the unstructured data type.</p></div><div class="section" title="Semistructured data"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec45"/>Semistructured data</h2></div></div></div><p>Semistructured data <a class="indexterm" id="id201"/>is a type of data that follows an <a class="indexterm" id="id202"/>irregular trend or has a structure which changes rapidly. This data can be a self described one, it uses tags and other markers to establish a semantic relationship <a class="indexterm" id="id203"/>among the elements of the data. Semistructured data <a class="indexterm" id="id204"/>may contain information that is transferred from<a class="indexterm" id="id205"/> different sources. <span class="strong"><strong>Scraping</strong></span> is the technique that is used to extract information from this type of data. The information available on the Web is a perfect example of semistructured data.</p></div></div></div>
<div class="section" title="What is web scraping?"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec50"/>What is web scraping?</h1></div></div></div><p>In simple words, web scraping is the process of extracting desired data from a web resource. This <a class="indexterm" id="id206"/>method involves different procedures such as interacting with the web resource, choosing the appropriate data, obtaining information from the data, and converting the data to the desired format. With all the previous methods considered, a major spotlight will be thrown on the process of pulling the required data from the semistructured data.</p><div class="section" title="Dos and don'ts of web scraping"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec46"/>Dos and don'ts of web scraping</h2></div></div></div><p>Scraping a web<a class="indexterm" id="id207"/> resource is not always welcomed by the owners. Some companies put a restriction on using bots against them. It's etiquette to follow certain rules while scraping. The following are the dos and don'ts of web scraping:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Do refer to the terms and conditions</strong></span>: The first thing that should come to our mind before we begin scraping is terms and conditions. Do visit the website's terms and conditions page and get to know whether they prohibit scraping from their site. If so, it's better to back off.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Don't bombard the server with a lot of requests</strong></span>: Every website runs on a server that can serve only a specific amount of workload. It is equivalent to being rude if we bombard the server with lots of requests in a specific span of time, which may result in sever breakdown. Wait for some time between requests instead of bombarding the server with too many requests at once.<div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note09"/>Note</h3><p>Some sites put a restriction on the maximum number of requests processed per minute and will ban the request sender's IP address if this is not adhered to.</p></div></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Do track the web resource from time to time</strong></span>: A website doesn't always stay the same. According to its usability and the requirement of users, they tend to change from time to time. If any alteration has taken place in the website, our code to scrape may fail. Do remember to track the changes made to the site, modify the scrapper script, and scrape accordingly.</li></ul></div></div><div class="section" title="Predominant steps to perform web scraping"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec47"/>Predominant steps to perform web scraping</h2></div></div></div><p>Generally, the<a class="indexterm" id="id208"/> process of web scraping requires the use of different tools<a class="indexterm" id="id209"/> and libraries such as the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Chrome DevTools or FireBug Add-on</strong></span>: This can be used to pinpoint the pieces of<a class="indexterm" id="id210"/> information in an HTML/XML page.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>HTTP libraries</strong></span>: These <a class="indexterm" id="id211"/>can be used to interact with the server and to pull a response document. An example of this is <code class="literal">python-requests</code>.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Web scraping tools</strong></span>: These<a class="indexterm" id="id212"/> are used to pull data from a semistructured document. Examples include <code class="literal">BeautifulSoup</code> or <code class="literal">Scrappy</code>.</li></ul></div><p>The overall <a class="indexterm" id="id213"/>picture of web scraping can be observed in the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Identify the URL(s) of the web resource to perform the web scraping task.</li><li class="listitem">Use your favorite HTTP client/library to pull the semistructured document.</li><li class="listitem">Before extracting the desired data, discover the pieces of data that are in semistructured format.</li><li class="listitem">Utilize a web scraping tool to parse the acquired semistructured document into a more structured one.</li><li class="listitem">Draw the desired data that we are hoping to use. That's all, we are done!</li></ol></div></div></div>
<div class="section" title="Key web scraping tasks"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec51"/>Key web scraping tasks</h1></div></div></div><p>While pulling the <a class="indexterm" id="id214"/>required data from a semistructured document, we perform various tasks. The following are the basic tasks that we adopt for scraping:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Searching a semistructured document:</strong></span> Accessing a particular element or a specific <a class="indexterm" id="id215"/>type of element in a document can be accomplished using its <code class="literal">tag</code> name and <code class="literal">tag</code> attributes, such as <code class="literal">id</code>, <code class="literal">class</code>, and so on.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Navigating within a semistructured document</strong></span>: We can navigate through a web<a class="indexterm" id="id216"/> document to pull different types of data in four ways, which are navigating down, navigating sideways, navigating up, and navigating back and forth. We can get to know more about these in detail later in this chapter.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Modifying a semistructured document:</strong></span> By modifying the <code class="literal">tag</code> name or the <code class="literal">tag</code> attributes <a class="indexterm" id="id217"/>of a document, we can streamline and pull the required data.</li></ul></div></div>
<div class="section" title="What is BeautifulSoup?"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec52"/>What is BeautifulSoup?</h1></div></div></div><p>The <code class="literal">BeautifulSoup</code> library is a simple yet powerful web scraping library. It has the capability to<a class="indexterm" id="id218"/> extract the desired data when provided with an HTML or XML document. It is charged with some superb methods, which help us to perform web scraping tasks effortlessly.</p><div class="section" title="Document parsers"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec48"/>Document parsers</h2></div></div></div><p>Document parsers <a class="indexterm" id="id219"/>aid us in parsing and serializing the <a class="indexterm" id="id220"/>semistructured documents that are written using HTML5, lxml, or any other markup language. By default, <code class="literal">BeautifulSoup</code> has Python's standard <code class="literal">HTMLParser</code> object. If we are dealing with different types of documents, such as HTML5 and lxml, we need to install them explicitly.</p><p>In this chapter, our prime focus will be laid only on particular parts of the library, which help us to understand the techniques to develop a practical scraping bot that we will build at the end of this chapter.</p></div><div class="section" title="Installation"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec49"/>Installation</h2></div></div></div><p>Installing <code class="literal">BeautifulSoup</code> is<a class="indexterm" id="id221"/> pretty straightforward. We can use <code class="literal">pip</code> to install it with ease:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>$ pip install beautifulsoup4</strong></span>
</pre></div><p>Whenever we intend to scrape a web resource using <code class="literal">BeautifulSoup</code>, we need to create a <code class="literal">BeautifulSoup</code> object for it. The following are the commands to do this:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; from bs4 import BeautifulSoup</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; soup = BeautifulSoup(&lt;HTML_DOCUMENT_STRING&gt;)</strong></span>
</pre></div></div><div class="section" title="Objects in BeautifulSoup"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec50"/>Objects in BeautifulSoup</h2></div></div></div><p>The <code class="literal">BeautifulSoup</code> object<a class="indexterm" id="id222"/> parses the given HTML/XML document and converts it into a tree of Python objects, which are discussed in the following sections.</p><div class="section" title="Tags"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec01"/>Tags</h3></div></div></div><p>The word "tag" represents an HTML/XML tag in the provided document. Each <code class="literal">tag</code> object has a name<a class="indexterm" id="id223"/> and a lot of attributes and methods. The following example showcases the way to deal with a <code class="literal">tag</code> object:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; from bs4 import BeautifulSoup</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; soup = BeautifulSoup("&lt;h1 id='message'&gt;Hello, Requests!&lt;/h1&gt;")</strong></span>
</pre></div><p>In order to access the type, name, and attributes of the <code class="literal">BeautifulSoup</code> object, with <code class="literal">soup</code>, that we created in the preceding example, use the following commands:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">For accessing the <code class="literal">tag type</code>:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; tag = soup.h1</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; type(tag)</strong></span>
<span class="strong"><strong>&lt;class 'bs4.element.Tag'&gt;</strong></span>
</pre></div></li><li class="listitem" style="list-style-type: disc">For accessing the <code class="literal">tag name</code>:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; tag.name</strong></span>
<span class="strong"><strong>'h1'</strong></span>
</pre></div></li><li class="listitem" style="list-style-type: disc">For accessing the <code class="literal">tag</code> attribute (<code class="literal">'id'</code> in the given html string)<div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; tag['id']</strong></span>
<span class="strong"><strong>'message'</strong></span>
</pre></div></li></ul></div></div><div class="section" title="BeautifulSoup"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec02"/>BeautifulSoup</h3></div></div></div><p>The object that <a class="indexterm" id="id224"/>gets created when we intend to scrape a web resource is called a <code class="literal">BeautifulSoup</code> object. Put simply, it is the complete document that we are planning to scrape. This can be done using the following commands:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; from bs4 import BeautifulSoup</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; soup = BeautifulSoup("&lt;h1 id='message'&gt;Hello, Requests!&lt;/h1&gt;") &gt;&gt;&gt; type(soup)</strong></span>
<span class="strong"><strong>&lt;class 'bs4.BeautifulSoup'&gt;</strong></span>
</pre></div></div><div class="section" title="NavigableString"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec03"/>NavigableString</h3></div></div></div><p>A <code class="literal">NavigableString</code> object<a class="indexterm" id="id225"/> represents the contents of <code class="literal">tag</code>. We use the <code class="literal">.string</code> attribute of the <code class="literal">tag</code> object to access it:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; tag.string</strong></span>
<span class="strong"><strong>u'Hello, Requests!'</strong></span>
</pre></div></div><div class="section" title="Comments"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec04"/>Comments</h3></div></div></div><p>The <code class="literal">comment</code> object<a class="indexterm" id="id226"/> illustrates the comment part of the web document. The following lines of code exemplify a <code class="literal">comment</code> object:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup = BeautifulSoup("&lt;p&gt;&lt;!-- This is comment --&gt;&lt;/p&gt;")</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; comment = soup.p.string</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; type(comment)</strong></span>
<span class="strong"><strong>&lt;class 'bs4.element.Comment'&gt;</strong></span>
</pre></div></div></div><div class="section" title="Web scraping tasks related to BeautifulSoup"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec51"/>Web scraping tasks related to BeautifulSoup</h2></div></div></div><p>As cited in the<a class="indexterm" id="id227"/> previous section of <span class="emphasis"><em>Key web scraping tasks</em></span>, <code class="literal">BeautifulSoup</code> always follows those basic tasks in the process of web scraping. We can get to know these tasks in detail with the help of a practical example, using an HTML document. We will be using the following HTML document that is <code class="literal">scraping_example.html</code>, as an example through out the chapter:</p><div class="informalexample"><pre class="programlisting">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
  &lt;head&gt;
    &lt;meta charset="UTF-8" /&gt;
    &lt;title&gt;
      Chapter 6 - Web Scrapping with Python Requests and BeatuifulSoup
    &lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class="surveys"&gt;
      &lt;div class="survey" id="1"&gt;
        &lt;p class="question"&gt;
          &lt;a href="/surveys/1"&gt;Are you from India?&lt;/a&gt;
        &lt;/p&gt;
        &lt;ul class="responses"&gt;
          &lt;li class="response"&gt;Yes - &lt;span class="score"&gt;21&lt;/span&gt;
          &lt;/li&gt;
          &lt;li class="response"&gt;No - &lt;span class="score"&gt;19&lt;/span&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/div&gt;
      &lt;div class="survey" id="2"&gt;
        &lt;p class="question"&gt;
          &lt;a href="/surveys/2"&gt;Have you ever seen the rain?&lt;/a&gt;
        &lt;/p&gt;
        &lt;ul class="responses"&gt;
          &lt;li class="response"&gt;Yes - &lt;span class="score"&gt;40&lt;/span&gt;
          &lt;/li&gt;
          &lt;li class="response"&gt;No - &lt;span class="score"&gt;0&lt;/span&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/div&gt;
      &lt;div class="survey" id="3"&gt;
        &lt;p class="question"&gt;
          &lt;a href="/surveys/1"&gt;Do you like grapes?&lt;/a&gt;
        &lt;/p&gt;
        &lt;ul class="responses"&gt;
          &lt;li class="response"&gt;Yes - &lt;span class="score"&gt;34&lt;/span&gt;
          &lt;/li&gt;
          &lt;li class="response"&gt;No - &lt;span class="score"&gt;6&lt;/span&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre></div><p>To give a crystal clear <a class="indexterm" id="id228"/>understanding of the preceding web document, we showcased it as a document tree. The following diagram represents the preceding HTML document:</p><div class="mediaobject"><img alt="Web scraping tasks related to BeautifulSoup" src="graphics/B03661_06_01.jpg"/></div><p>When we create the <code class="literal">BeautifulSoup</code> object for the previously shown web document, it will result in a tree of Python objects.</p><p>To perform<a class="indexterm" id="id229"/> different tasks with the previous document, <code class="literal">scraping_example.html</code>, we need to create a <code class="literal">BeautifulSoup</code> object. To create it, open the Python shell and run the following commands:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; from bs4 import BeautifulSoup</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; soup = BeautifulSoup(open("scraping_example.html"))</strong></span>
</pre></div><p>From now, we will use the preceding <code class="literal">BeautifulSoup</code> object to execute different tasks. Let's perform the web scraping tasks on the <code class="literal">scraping_example.html</code> document and get an overall idea on all the tasks.</p></div><div class="section" title="Searching the tree"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec52"/>Searching the tree</h2></div></div></div><p>To identify the <a class="indexterm" id="id230"/>different tags in an HTML/XML document, we need to search the whole document. In similar situations, we can use <code class="literal">BeautifulSoup</code> methods such as <code class="literal">find</code>, <code class="literal">find_all</code>, and so on.</p><p>Here is the syntax to search the whole document to identify the tags:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">find(name, attributes, recursive, text, **kwargs)</code><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">name</code>: This is the first occurring tag name that appears in the process of discovery. It can be a string, a regular expression, a list, a function, or the value <code class="literal">True</code>.</li></ul></div></li><li class="listitem" style="list-style-type: disc"><code class="literal">find_all(name, attributes, recursive, text, limit, **kwargs)</code><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">name</code>: This is used to access specific types of tags with their name. It can be a string, a regular expression, a list, a function, or the value <code class="literal">True</code>.</li><li class="listitem" style="list-style-type: disc"><code class="literal">limit</code>: This is the maximum number of results in the output.</li></ul></div></li></ul></div><p>The common attributes for the preceding two methods are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">attributes</code>: These are the attributes of an HTML/XML tag.</li><li class="listitem" style="list-style-type: disc"><code class="literal">recursive</code>: This takes a Boolean value. If it is set to <code class="literal">True</code>, the <code class="literal">BeautifulSoup</code> library checks all the children of a specific tag. Vice versa, if it is set to <code class="literal">false</code>, the <code class="literal">BeautifulSoup</code> library checks the child at the next level only.</li><li class="listitem" style="list-style-type: disc"><code class="literal">text</code>: This parameter identifies tags that consist of the string content.</li></ul></div><div class="section" title="Navigating within the tree"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec05"/>Navigating within the tree</h3></div></div></div><p>Different tasks <a class="indexterm" id="id231"/>are involved in navigating the document tree with the <code class="literal">Beautifulsoup4</code> module; they are discussed in the following section.</p><div class="section" title="Navigating down"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec01"/>Navigating down</h4></div></div></div><p>We can access a<a class="indexterm" id="id232"/> particular element's data by moving down in a document. If we consider the document tree in the previous figure, we can access different elements by moving downward from the top element—<code class="literal">html</code>.</p><p>Every element can be accessed using its <code class="literal">tag</code> name. Here is a way to access the contents of the <code class="literal">html</code> attribute:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; soup.html
&lt;html lang="en"&gt;
...
...
&lt;/html&gt;</pre></div><p>Here are the ways in which we can access the elements of the preceding document tree by navigating down. In order to access the <code class="literal">title</code> element, we should go from top to bottom, that is, from <code class="literal">html</code> to <code class="literal">head</code> and from <code class="literal">head</code> to <code class="literal">title</code>, as shown in the following command:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup.html.head.title</strong></span>
<span class="strong"><strong>&lt;title&gt;Chapter 6 - Web Scraping with Python Requests and BeatuifulSoup&lt;/title&gt;</strong></span>
</pre></div><p>Similarly, you can access the <code class="literal">meta</code> element, as shown in the following command:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup.html.head.meta</strong></span>
<span class="strong"><strong>&lt;meta charset="utf-8"/&gt;</strong></span>
</pre></div></div><div class="section" title="Navigating sideways"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec02"/>Navigating sideways</h4></div></div></div><p>To access the<a class="indexterm" id="id233"/> siblings in a document tree, we should navigate sideways. The <code class="literal">BeautifulSoup</code> library provides various <code class="literal">tag</code> object properties such as <code class="literal">.next_sibling</code>, <code class="literal">.previous_sibling</code>, <code class="literal">.next_siblings</code>, and <code class="literal">.previous_siblings</code>.</p><p>If you look at the preceding diagram containing the document tree, the different siblings at different levels of the tree, when navigated sideways, are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">head</code> and <code class="literal">body</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">div1</code>, <code class="literal">div2</code>, and <code class="literal">div3</code></li></ul></div><p>In the document tree, the <code class="literal">head</code> tag is the first child of <code class="literal">html</code>, and <code class="literal">body</code> is the next child of <code class="literal">html</code>. In order to access the children of the <code class="literal">html</code> tag, we can use its <code class="literal">children</code> property:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; for child in soup.html.children:</strong></span>
<span class="strong"><strong>...     print child.name</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>head</strong></span>
<span class="strong"><strong>body</strong></span>
</pre></div><p>To access the<a class="indexterm" id="id234"/> next sibling of <code class="literal">head</code> element we can use <code class="literal">.find_next_sibling</code>:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup.head.find_next_sibling()</strong></span>
<span class="strong"><strong>&lt;body&gt;</strong></span>
<span class="strong"><strong>    &lt;div class="surveys"&gt;</strong></span>
<span class="strong"><strong>        .</strong></span>
<span class="strong"><strong>        .</strong></span>
<span class="strong"><strong>        .</strong></span>
<span class="strong"><strong>    &lt;/div&gt;</strong></span>
<span class="strong"><strong>&lt;/body&gt;</strong></span>
</pre></div><p>To access the previous sibling of <code class="literal">body</code>, we can use <code class="literal">.find_previous_sibling</code>:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup.body.find_previous_sibling</strong></span>
<span class="strong"><strong>&lt;head&gt;&lt;meta charset="utf-8"/&gt;&lt;title&gt;... &lt;/title&gt;&lt;/head&gt;</strong></span>
</pre></div></div><div class="section" title="Navigating up"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec03"/>Navigating up</h4></div></div></div><p>We can access a<a class="indexterm" id="id235"/> particular element's parent by moving toward the top of the document tree. The <code class="literal">BeautifulSoup</code> library provides two properties—<code class="literal">.parent</code> and <code class="literal">.parents</code>—to access the first parent of the <code class="literal">tag</code> element and all its ancestors, respectively.</p><p>Here is an example:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup.div.parent.name</strong></span>
<span class="strong"><strong>'body'</strong></span>

<span class="strong"><strong>&gt;&gt;&gt; for parent in soup.div.parents:</strong></span>
<span class="strong"><strong>...     print parent.name</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>body</strong></span>
<span class="strong"><strong>html</strong></span>
<span class="strong"><strong>[document]</strong></span>
</pre></div></div><div class="section" title="Navigating back and forth"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec04"/>Navigating back and forth</h4></div></div></div><p>To access the<a class="indexterm" id="id236"/> previously parsed element, we navigate back in the node of a tree, and to access the immediate element that gets parsed next, we navigate forward in the node of a tree. To deal with this, the <code class="literal">tag</code> object provides the <code class="literal">.find_previous_element</code> and <code class="literal">.find_next_element</code> properties, as shown in the following example:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup.head.find_previous().name</strong></span>
<span class="strong"><strong>'html'</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; soup.head.find_next().name</strong></span>
<span class="strong"><strong>'meta'</strong></span>
</pre></div></div></div></div><div class="section" title="Modifying the Tree"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec53"/>Modifying the Tree</h2></div></div></div><p>The BeautifulSoup library also <a class="indexterm" id="id237"/>facilitates us to make changes to the web document according to our requirements. We can alter a tag's properties using its attributes, such as the <code class="literal">.name</code>, <code class="literal">.string</code>, and <code class="literal">.append()</code> method. We can also add new tags and strings to an existing tag with the help of the <code class="literal">.new_string()</code> and <code class="literal">.new_tag()</code> methods. There are also other methods, such as <code class="literal">.insert()</code>, <code class="literal">.insert_before()</code>, <code class="literal">.insert_after()</code>, and so on, to make various modifications to the document tree.</p><p>Here is an example of changing the <code class="literal">title</code> tag's <code class="literal">.string</code> attribute:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Before modifying the <code class="literal">title</code> tag the title contents are:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup.title.string</strong></span>
<span class="strong"><strong>u'Chapter 6 - Web Scrapping with Python Requests and BeatuifulSoup'</strong></span>
</pre></div></li><li class="listitem" style="list-style-type: disc">This is the way to modify the contents of a <code class="literal">title</code> tag:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup.title.string = 'Web Scrapping with Python Requests and BeatuifulSoup by Balu and Rakhi'</strong></span>
</pre></div></li><li class="listitem" style="list-style-type: disc">After the modifications the contents of the <code class="literal">tilte</code> tag looks like this:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; soup.title.string</strong></span>
<span class="strong"><strong>u'Web Scrapping with Python Requests and BeatuifulSoup by Balu and Rakhi'</strong></span>
</pre></div></li></ul></div></div></div>
<div class="section" title="Building a web scraping bot &#x2013; a practical example"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec53"/>Building a web scraping bot – a practical example</h1></div></div></div><p>At this point <a class="indexterm" id="id238"/>of time, our minds got enlightened with all sorts of clues to scrape the Web. With all the information acquired, let's look at a practical example. Now, we will create a web scraping bot, which will pull a list of words from a web resource and store them in a JSON file.</p><p>Let's turn on the scraping mode!</p><div class="section" title="The web scraping bot"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec54"/>The web scraping bot</h2></div></div></div><p>Here, the <a class="indexterm" id="id239"/>web scraping bot is an automated script that has the capability to extract words from a website named majortests.com. This website consists of various <a class="indexterm" id="id240"/>tests and <span class="strong"><strong>Graduate Record Examinations</strong></span> (<span class="strong"><strong>GRE</strong></span>) word lists. With this web scraping bot, we will scrape the previously mentioned website and create a list of GRE words and their meanings in a JSON file.</p><p>The following<a class="indexterm" id="id241"/> image is the sample page of the website that we are going to scrape:</p><div class="mediaobject"><img alt="The web scraping bot" src="graphics/B03661_06_03.jpg"/></div><p>Before we kick<a class="indexterm" id="id242"/> start the scraping process, let's revise the dos and don't of web scraping as mentioned in the initial part of the chapter. Believe it or not they will definitely leave us in peace:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Do refer to the terms and conditions</strong></span>: Yes, before scraping majortests.com, refer to the terms and conditions of the site and obtain the necessary legal permissions to scrape it.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Don't bombard the server with a lot of requests</strong></span>: Keeping this in mind, for every request that we are going to send to the website, a delay has been instilled using Python's <code class="literal">time.sleep</code> function.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Do track the web resource from time to time</strong></span>: We ensured that the code runs perfectly with the website that is running on the server. Do check the site once before starting to scrape, so that it won't break the code. This can be made possible by running some unit tests, which conform to the structure we expected.</li></ul></div><p>Now, let's start the implementation by following the steps to scrape that we discussed previously.</p><div class="section" title="Identifying the URL or URLs"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec06"/>Identifying the URL or URLs</h3></div></div></div><p>The first step in <a class="indexterm" id="id243"/>web scraping is to identify the URL or a list of URLs that will result in the required resources. In this case, our intent is to find all the URLs that result in the expected list of GRE words. The following is the list of the URLs of the sites that we are going to scrape:</p><p>
<a class="ulink" href="http://www.majortests.com/gre/wordlist_01">http://www.majortests.com/gre/wordlist_01</a>, </p><p>
<a class="ulink" href="http://www.majortests.com/gre/wordlist_02">http://www.majortests.com/gre/wordlist_02</a>, </p><p>
<a class="ulink" href="http://www.majortests.com/gre/wordlist_03">http://www.majortests.com/gre/wordlist_03</a>, and so on</p><p>Our aim is to scrape words from nine such URLs, for which we found a common pattern. This will help us to crawl all of them. The common URL pattern for all those URLs is written using Python's <code class="literal">string</code> object, as follows:</p><p>
<code class="literal">http://www.majortests.com/gre/wordlist_0%d</code>
</p><p>In our implementation, we defined a method called <code class="literal">generate_urls</code>, which will generate the required list of URLs using the preceding URL string. The following snippet demonstrates the process in a Python shell:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; START_PAGE, END_PAGE = 1, 10</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; URL = "http://www.majortests.com/gre/wordlist_0%d"</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; def generate_urls(url, start_page, end_page):</strong></span>
<span class="strong"><strong>...     urls = []</strong></span>
<span class="strong"><strong>...     for page in range(start_page, end_page):</strong></span>
<span class="strong"><strong>...         urls.append(url % page)</strong></span>
<span class="strong"><strong>...     return urls</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; generate_urls(URL, START_PAGE, END_PAGE)</strong></span>
<span class="strong"><strong>['http://www.majortests.com/gre/wordlist_01', 'http://www.majortests.com/gre/wordlist_02', 'http://www.majortests.com/gre/wordlist_03', 'http://www.majortests.com/gre/wordlist_04', 'http://www.majortests.com/gre/wordlist_05', 'http://www.majortests.com/gre/wordlist_06', 'http://www.majortests.com/gre/wordlist_07', 'http://www.majortests.com/gre/wordlist_08', 'http://www.majortests.com/gre/wordlist_09']</strong></span>
</pre></div></div><div class="section" title="Using an HTTP client"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec07"/>Using an HTTP client</h3></div></div></div><p>We will <a class="indexterm" id="id244"/>use the <code class="literal">requests</code> module as an HTTP client to get the web resources:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; import requests</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; def get_resource(url):</strong></span>
<span class="strong"><strong>...     return requests.get(url)</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; get_resource("http://www.majortests.com/gre/wordlist_01")</strong></span>
<span class="strong"><strong>&lt;Response [200]&gt;</strong></span>
</pre></div><p>In the <a class="indexterm" id="id245"/>preceding code, the <code class="literal">get_resource</code> function takes <code class="literal">url</code> as an argument and uses the <code class="literal">requests</code> module to get the resource.</p></div><div class="section" title="Discovering the pieces of data to scrape"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec08"/>Discovering the pieces of data to scrape</h3></div></div></div><p>Now, it is time<a class="indexterm" id="id246"/> to analyze and classify the contents of the web page. The content in this context is a list of words with their definitions. In order to identify the elements of the words and their definitions, we used Chrome DevTools. The perceived information of the elements (HTML elements) can help us to identify the word and its definition, which can be used in the process of scraping.</p><p>To carry this out open the URL (<a class="ulink" href="http://www.majortests.com/gre/wordlist_01">http://www.majortests.com/gre/wordlist_01</a>) in the Chrome browser and access the <span class="strong"><strong>Inspect element</strong></span> option by right-clicking on the web page:</p><div class="mediaobject"><img alt="Discovering the pieces of data to scrape" src="graphics/B03661_06_02.jpg"/></div><p>From the<a class="indexterm" id="id247"/> preceding image, we can identify the structure of the word list, which appears in the following manner:</p><div class="informalexample"><pre class="programlisting">&lt;div class="grid_9 alpha"&gt;
  &lt;h3&gt;Group 1&lt;/h3&gt;
  &lt;a name="1"&gt;&lt;/a&gt;
  &lt;table class="wordlist"&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;th&gt;Abhor&lt;/th&gt;
        &lt;td&gt;hate&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;th&gt;Bigot&lt;/th&gt;
        &lt;td&gt;narrow-minded, prejudiced person&lt;/td&gt;
      &lt;/tr&gt;
      ...
      ...
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/div&gt;</pre></div><p>By looking at the<a class="indexterm" id="id248"/> parts of the previously referred to web page, we can interpret the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Each web page consists of a word list</li><li class="listitem" style="list-style-type: disc">Every word list has many word groups that are defined in the same <code class="literal">div</code> tag</li><li class="listitem" style="list-style-type: disc">All the words in a word group are described in a table having the class attribute—<code class="literal">wordlist</code></li><li class="listitem" style="list-style-type: disc">Each and every table row (<code class="literal">tr</code>) in the table represents a word and its definition using the <code class="literal">th</code> and <code class="literal">td</code> tags, respectively</li></ul></div></div><div class="section" title="Utilizing a web scraping tool"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec09"/>Utilizing a web scraping tool</h3></div></div></div><p>Let's use <code class="literal">BeautifulSoup4</code> as a web scraping tool to parse the obtained web page contents that <a class="indexterm" id="id249"/>we received using the <code class="literal">requests</code> module in one of the previous steps. By following the preceding interpretations, we can direct <code class="literal">BeautifulSoup</code> to access the required content of the web page and deliver it as an object:</p><div class="informalexample"><pre class="programlisting">def make_soup(html_string):
    return BeautifulSoup(html_string)</pre></div><p>In the preceding lines of code, the <code class="literal">make_soup</code> method takes the <code class="literal">html</code> content in the form of a string and returns a <code class="literal">BeautifulSoup</code> object.</p></div><div class="section" title="Drawing the desired data"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec10"/>Drawing the desired data</h3></div></div></div><p>The <code class="literal">BeautifulSoup</code> object that we obtained in the previous step is used to extract the required words<a class="indexterm" id="id250"/> and their definitions from it. Now, with the methods available in the <code class="literal">BeautifulSoup</code> object, we can navigate through the obtained HTML response, and then we can extract the list of words and their definitions:</p><div class="informalexample"><pre class="programlisting">def get_words_from_soup(soup):
    words = {}

    for count, wordlist_table in enumerate(
    soup.find_all(class_='wordlist')):

        title = "Group %d" % (count + 1)

        new_words = {}
        for word_entry in wordlist_table.find_all('tr'):
            new_words[word_entry.th.text] = word_entry.td.text

        words[title] = new_words

    return words</pre></div><p>In the preceding lines of code, <code class="literal">get_words_from_soup</code> takes a <code class="literal">BeautifulSoup</code> object and then looks<a class="indexterm" id="id251"/> for all the words contained in the <code class="literal">wordlists</code> class using the instance's <code class="literal">find_all()</code> method, and then returns a dictionary of words.</p><p>The dictionary of words obtained previously will be saved in a JSON file using the following <code class="literal">helper</code> method:</p><div class="informalexample"><pre class="programlisting">def save_as_json(data, output_file):
    """ Writes the given data into the specified output file"""
    with open(output_file, 'w') as outfile:
        json.dump(data, outfile)</pre></div><p>On the whole, the process can be depicted in the following program:</p><div class="informalexample"><pre class="programlisting">import json
import time

import requests

from bs4 import BeautifulSoup

START_PAGE, END_PAGE, OUTPUT_FILE = 1, 10, 'words.json'

# Identify the URL
URL = "http://www.majortests.com/gre/wordlist_0%d"


def generate_urls(url, start_page, end_page):
    """
    This method takes a 'url' and returns a generated list of url strings

        params: a 'url', 'start_page' number and 'end_page' number
        return value: a list of generated url strings
    """
    urls = []
    for page in range(start_page, end_page):
        urls.append(url % page)
    return urls



def get_resource(url):
    """
    This method takes a 'url' and returns a 'requests.Response' object

        params: a 'url'
        return value: a 'requests.Response' object
    """
    return requests.get(url)


def make_soup(html_string):
    """
    This method takes a 'html string' and returns a 'BeautifulSoup' object

        params: html page contents as a string
        return value: a 'BeautifulSoup' object
    """
    return BeautifulSoup(html_string)


def get_words_from_soup(soup):

    """
    This method extracts word groups from a given 'BeautifulSoup' object

        params: a BeautifulSoup object to extract data
        return value: a dictionary of extracted word groups
    """

    words = {}
    count = 0

    for wordlist_table in soup.find_all(class_='wordlist'):

        count += 1
        title = "Group %d" % count

        new_words = {}
        for word_entry in wordlist_table.find_all('tr'):
            new_words[word_entry.th.text] = word_entry.td.text

        words[title] = new_words
        print " - - Extracted words from %s" % title

    return words


def save_as_json(data, output_file):
    """ Writes the given data into the specified output file"""
            json.dump(data, open(output_file, 'w'))


def scrapper_bot(urls):
    """
    Scrapper bot:
        params: takes a list of urls

        return value: a dictionary of word lists containing
                      different word groups
    """

    gre_words = {}
    for url in urls:

        print "Scrapping %s" % url.split('/')[-1]

        # step 1

        # get a 'url'

        # step 2
        html = requets.get(url)

        # step 3
        # identify the desired pieces of data in the url using Browser tools

        #step 4
        soup = make_soup(html.text)

        # step 5
        words = get_words_from_soup(soup)

        gre_words[url.split('/')[-1]] = words

        print "sleeping for 5 seconds now"
        time.sleep(5)

    return gre_words

if __name__ == '__main__':

    urls = generate_urls(URL, START_PAGE, END_PAGE+1)

    gre_words = scrapper_bot(urls)

    save_as_json(gre_words, OUTPUT_FILE)</pre></div><p>Here is <a class="indexterm" id="id252"/>the content of the <code class="literal">words.json</code> file:</p><div class="informalexample"><pre class="programlisting">{"wordlist_04":
    {"Group 10":
        {"Devoured": "greedily eaten/consumed",
         "Magnate": "powerful businessman",
         "Cavalcade": "procession of vehicles",
         "Extradite": "deport from one country back to the home...
    .
    .
    .
}</pre></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec54"/>Summary</h1></div></div></div><p>In this chapter, you learned about different types of data that we encountered with web sources and tweaked some ideas. We came to know about the need for web scraping, the legal issues, and the goodies that it offers. Then, we jumped deep into web scraping tasks and their potential. You learned about a new library called <code class="literal">BeautifulSoup</code>, and its ins and outs, with examples.</p><p>We came to know the capabilities of <code class="literal">BeautifulSoup</code> in depth and worked on some examples to get a clear idea on it. At last, we created a practical scraping bot by applying the knowledge that we gained from the previous sections, which enlightened us with an experience to scrape a website in real time.</p><p>In the next chapter, you will learn about  the Flask microframework and we will build an application using it by following the best practices.</p></div></body></html>