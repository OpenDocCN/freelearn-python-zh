["```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter - 4\n# This program is optimized for Python 2.7.\n# It may run on any other version with/without modifications.\n\nimport argparse\nimport httplib\n\nREMOTE_SERVER_HOST = 'www.python.org'\nREMOTE_SERVER_PATH = '/'\n\nclass HTTPClient:\n\n  def __init__(self, host):\n    self.host = host\n\n  def fetch(self, path):\n    http = httplib.HTTP(self.host)\n\n    # Prepare header\n    http.putrequest(\"GET\", path)\n    http.putheader(\"User-Agent\", __file__)\n    http.putheader(\"Host\", self.host)\n    http.putheader(\"Accept\", \"*/*\")\n    http.endheaders()\n\n    try:\n      errcode, errmsg, headers = http.getreply()\n\n    except Exception, e:\n      print \"Client failed error code: %s message:%s headers:%s\" \n%(errcode, errmsg, headers)\n    else: \n      print \"Got homepage from %s\" %self.host \n\n    file = http.getfile()\n    return file.read()\n\nif __name__ == \"__main__\":\n  parser = argparse.ArgumentParser(description='HTTP Client \nExample')\n  parser.add_argument('--host', action=\"store\", dest=\"host\",  \ndefault=REMOTE_SERVER_HOST)\n  parser.add_argument('--path', action=\"store\", dest=\"path\",  \ndefault=REMOTE_SERVER_PATH)\n  given_args = parser.parse_args() \n  host, path = given_args.host, given_args.path\n  client = HTTPClient(host)\n  print client.fetch(path)\n```", "```py\n$  python 4_1_download_data.py --host=www.python.org \nGot homepage from www.python.org\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n<html  xml:lang=\"en\" lang=\"en\">\n\n<head>\n <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\" />\n <title>Python Programming Language &ndash; Official Website</title>\n....\n\n```", "```py\n$ python 4_1_download_data.py --host='www.python.org' --path='/not-\nexist'\nGot homepage from www.python.org\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n<html  xml:lang=\"en\" lang=\"en\">\n<head>\n <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\" />\n <title>Page Not Found</title>\n <meta name=\"keywords\" content=\"Page Not Found\" />\n <meta name=\"description\" content=\"Page Not Found\" />\n\n```", "```py\n$ python -m SimpleHTTPServer 8080\n\n```", "```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter - 4\n# This program is optimized for Python 2.7.\n# It may run on any other version with/without modifications.\n\nimport argparse\nimport sys\nfrom BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer\n\nDEFAULT_HOST = '127.0.0.1'\nDEFAULT_PORT = 8800\n\nclass RequestHandler(BaseHTTPRequestHandler):\n  \"\"\" Custom request handler\"\"\"\n\n  def do_GET(self):\n    \"\"\" Handler for the GET requests \"\"\"\n    self.send_response(200)\n    self.send_header('Content-type','text/html')\n    self.end_headers()\n    # Send the message to browser\n    self.wfile.write(\"Hello from server!\")\n\nclass CustomHTTPServer(HTTPServer):\n  \"A custom HTTP server\"\n  def __init__(self, host, port):\n    server_address = (host, port)\n    HTTPServer.__init__(self, server_address, RequestHandler)\n\ndef run_server(port):\n  try:\n    server= CustomHTTPServer(DEFAULT_HOST, port)\n    print \"Custom HTTP server started on port: %s\" % port\n    server.serve_forever()\n  except Exception, err:\n    print \"Error:%s\" %err\n  except KeyboardInterrupt:\n    print \"Server interrupted and is shutting down...\"\n    server.socket.close()\n\nif __name__ == \"__main__\":\n  parser = argparse.ArgumentParser(description='Simple HTTP Server \nExample')\n  parser.add_argument('--port', action=\"store\", dest=\"port\", \ntype=int, default=DEFAULT_PORT)\n  given_args = parser.parse_args() \n  port = given_args.port\n  run_server(port)\n```", "```py\n$ python 4_2_simple_http_server.py --port=8800\nCustom HTTP server started on port: 8800\nlocalhost - - [18/Apr/2013 13:39:33] \"GET / HTTP/1.1\" 200 -\nlocalhost - - [18/Apr/2013 13:39:33] \"GET /favicon.ico HTTP/1.1\" 200 \n\n```", "```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter - 4\n# This program is optimized for Python 2.7.\n# It may run on any other version with/without modifications.\n\nimport cookielib \nimport urllib\nimport urllib2\n\nID_USERNAME = 'id_username'\nID_PASSWORD = 'id_password'\nUSERNAME = 'you@email.com'\nPASSWORD = 'mypassword'\nLOGIN_URL = 'https://bitbucket.org/account/signin/?next=/'\nNORMAL_URL = 'https://bitbucket.org/'\n\ndef extract_cookie_info():\n  \"\"\" Fake login to a site with cookie\"\"\"\n  # setup cookie jar\n  cj = cookielib.CookieJar()\n  login_data = urllib.urlencode({ID_USERNAME : USERNAME, \n  ID_PASSWORD : PASSWORD})\n  # create url opener\n  opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))\n  resp = opener.open(LOGIN_URL, login_data)\n\n  # send login info \n  for cookie in cj:\n    print \"----First time cookie: %s --> %s\" %(cookie.name, \ncookie.value)\n    print \"Headers: %s\" %resp.headers\n\n  # now access without any login info\n  resp = opener.open(NORMAL_URL)\n  for cookie in cj:\n    print \"++++Second time cookie: %s --> %s\" %(cookie.name, \ncookie.value)\n\n  print \"Headers: %s\" %resp.headers\n\nif __name__ == '__main__':\n  extract_cookie_info()\n```", "```py\n$ python 4_3_extract_cookie_information.py \n----First time cookie: bb_session --> aed58dde1228571bf60466581790566d\nHeaders: Server: nginx/1.2.4\nDate: Sun, 05 May 2013 15:13:56 GMT\nContent-Type: text/html; charset=utf-8\nContent-Length: 21167\nConnection: close\nX-Served-By: bitbucket04\nContent-Language: en\nX-Static-Version: c67fb01467cf\nExpires: Sun, 05 May 2013 15:13:56 GMT\nVary: Accept-Language, Cookie\nLast-Modified: Sun, 05 May 2013 15:13:56 GMT\nX-Version: 14f9c66ad9db\nETag: \"3ba81d9eb350c295a453b5ab6e88935e\"\nX-Request-Count: 310\nCache-Control: max-age=0\nSet-Cookie: bb_session=aed58dde1228571bf60466581790566d; expires=Sun, 19-May-2013 15:13:56 GMT; httponly; Max-Age=1209600; Path=/; secure\n\nStrict-Transport-Security: max-age=2592000\nX-Content-Type-Options: nosniff\n\n++++Second time cookie: bb_session --> aed58dde1228571bf60466581790566d\nHeaders: Server: nginx/1.2.4\nDate: Sun, 05 May 2013 15:13:57 GMT\nContent-Type: text/html; charset=utf-8\nContent-Length: 36787\nConnection: close\nX-Served-By: bitbucket02\nContent-Language: en\nX-Static-Version: c67fb01467cf\nVary: Accept-Language, Cookie\nX-Version: 14f9c66ad9db\nX-Request-Count: 97\nStrict-Transport-Security: max-age=2592000\nX-Content-Type-Options: nosniff\n\n```", "```py\n$ pip install requests\n\n```", "```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter – 4\n# This program is optimized for Python 2.7.\n# It may run on any other version with/without modifications.\n\nimport requests\nimport urllib\nimport urllib2\n\nID_USERNAME = 'signup-user-name'\nID_EMAIL = 'signup-user-email'\nID_PASSWORD = 'signup-user-password'\nUSERNAME = 'username'\nEMAIL = 'you@email.com'\nPASSWORD = 'yourpassword'\nSIGNUP_URL = 'https://twitter.com/account/create'\n\ndef submit_form():\n    \"\"\"Submit a form\"\"\"\n    payload = {ID_USERNAME : USERNAME,\n               ID_EMAIL    :  EMAIL,\n               ID_PASSWORD : PASSWORD,}\n\n    # make a get request\n    resp = requests.get(SIGNUP_URL)\n    print \"Response to GET request: %s\" %resp.content\n\n    # send POST request\n    resp = requests.post(SIGNUP_URL, payload)\n    print \"Headers from a POST request response: %s\" %resp.headers\n    #print \"HTML Response: %s\" %resp.read()\n\nif __name__ == '__main__':\n    submit_form()\n```", "```py\n$ python 4_4_submit_web_form.py \nResponse to GET request: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<hash>\n <error>This method requires a POST.</error>\n <request>/account/create</request>\n</hash>\n\nHeaders from a POST request response: {'status': '200 OK', 'content-\nlength': '21064', 'set-cookie': '_twitter_sess=BAh7CD--\nd2865d40d1365eeb2175559dc5e6b99f64ea39ff; domain=.twitter.com; \npath=/; HttpOnly', 'expires': 'Tue, 31 Mar 1981 05:00:00 GMT', \n'vary': 'Accept-Encoding', 'last-modified': 'Sun, 05 May 2013 \n15:59:27 GMT', 'pragma': 'no-cache', 'date': 'Sun, 05 May 2013 \n15:59:27 GMT', 'x-xss-protection': '1; mode=block', 'x-transaction': \n'a4b425eda23b5312', 'content-encoding': 'gzip', 'strict-transport-\nsecurity': 'max-age=631138519', 'server': 'tfe', 'x-mid': \n'f7cde9a3f3d111310427116adc90bf3e8c95e868', 'x-runtime': '0.09969', \n'etag': '\"7af6f92a7f7b4d37a6454caa6094071d\"', 'cache-control': 'no-\ncache, no-store, must-revalidate, pre-check=0, post-check=0', 'x-\nframe-options': 'SAMEORIGIN', 'content-type': 'text/html; \ncharset=utf-8'}\n\n```", "```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter - 4\n# This program is optimized for Python 2.7.\n# It may run on any other version with/without modifications.\n\nimport urllib\n\nURL = 'https://www.github.com'\nPROXY_ADDRESS = \"165.24.10.8:8080\" \n\nif __name__ == '__main__':\n  resp = urllib.urlopen(URL, proxies = {\"http\" : PROXY_ADDRESS})\n  print \"Proxy server returns response headers: %s \" \n%resp.headers\n```", "```py\n$ python 4_5_proxy_web_request.py \nProxy server returns response headers: Server: GitHub.com\nDate: Sun, 05 May 2013 16:16:04 GMT\nContent-Type: text/html; charset=utf-8\nConnection: close\nStatus: 200 OK\nCache-Control: private, max-age=0, must-revalidate\nStrict-Transport-Security: max-age=2592000\nX-Frame-Options: deny\nSet-Cookie: logged_in=no; domain=.github.com; path=/; expires=Thu, 05-May-2033 16:16:04 GMT; HttpOnly\nSet-Cookie: _gh_sess=BAh7...; path=/; expires=Sun, 01-Jan-2023 00:00:00 GMT; secure; HttpOnly\nX-Runtime: 8\nETag: \"66fcc37865eb05c19b2d15fbb44cd7a9\"\nContent-Length: 10643\nVary: Accept-Encoding\n\n```", "```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter - 4\n# This program is optimized for Python 2.7.\n# It may run on any other version with/without modifications.\nimport argparse\nimport httplib\nimport urlparse\nimport re\nimport urllib\n\nDEFAULT_URL = 'http://www.python.org'\nHTTP_GOOD_CODES =  [httplib.OK, httplib.FOUND, httplib.MOVED_PERMANENTLY]\n\ndef get_server_status_code(url):\n  \"\"\"\n  Download just the header of a URL and\n  return the server's status code.\n  \"\"\"\n  host, path = urlparse.urlparse(url)[1:3] \n  try:\n    conn = httplib.HTTPConnection(host)\n    conn.request('HEAD', path)\n    return conn.getresponse().status\n    except StandardError:\n  return None\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser(description='Example HEAD \nRequest')\n  parser.add_argument('--url', action=\"store\", dest=\"url\", \ndefault=DEFAULT_URL)\n  given_args = parser.parse_args() \n  url = given_args.url\n  if get_server_status_code(url) in HTTP_GOOD_CODES:\n    print \"Server: %s status is OK: \" %url\n  else:\n    print \"Server: %s status is NOT OK!\" %url\n```", "```py\n$ python 4_6_checking_webpage_with_HEAD_request.py \nServer: http://www.python.org status is OK!\n$ python 4_6_checking_webpage_with_HEAD_request.py --url=http://www.zytho.org\nServer: http://www.zytho.org status is NOT OK!\n\n```", "```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter – 4\n# This program is optimized for Python 2.7.\n# It may run on any other version with/without modifications.\n\nimport urllib2\n\nBROWSER = 'Mozilla/5.0 (Windows NT 5.1; rv:20.0) Gecko/20100101 \nFirefox/20.0'\nURL = 'http://www.python.org'\n\ndef spoof_firefox():\n  opener = urllib2.build_opener()\n  opener.addheaders = [('User-agent', BROWSER)]\n  result = opener.open(URL)\n  print \"Response headers:\"\n  for header in  result.headers.headers:\n    print \"\\t\",header\n\nif __name__ == '__main__':\n  spoof_firefox()\n```", "```py\n$ python 4_7_spoof_mozilla_firefox_in_client_code.py \nResponse headers:\n Date: Sun, 05 May 2013 16:56:36 GMT\n Server: Apache/2.2.16 (Debian)\n Last-Modified: Sun, 05 May 2013 00:51:40 GMT\n ETag: \"105800d-5280-4dbedfcb07f00\"\n Accept-Ranges: bytes\n Content-Length: 21120\n Vary: Accept-Encoding\n Connection: close\n Content-Type: text/html\n\n```", "```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter - 4\n# This program is optimized for Python 2.7.\n# It may run on any other version with/without modifications.\nimport argparse\nimport string\nimport os\nimport sys\nimport gzip\nimport cStringIO\nfrom BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer\n\nDEFAULT_HOST = '127.0.0.1'\nDEFAULT_PORT = 8800\nHTML_CONTENT = \"\"\"<html><body><h1>Compressed Hello  World!</h1></body></html>\"\"\"\n\nclass RequestHandler(BaseHTTPRequestHandler):\n  \"\"\" Custom request handler\"\"\"\n\n  def do_GET(self):\n    \"\"\" Handler for the GET requests \"\"\"\n    self.send_response(200)\n    self.send_header('Content-type','text/html')\n    self.send_header('Content-Encoding','gzip')\n\n    zbuf = self.compress_buffer(HTML_CONTENT)\n    sys.stdout.write(\"Content-Encoding: gzip\\r\\n\")\n    self.send_header('Content-Length',len(zbuf))\n    self.end_headers()\n\n  # Send the message to browser\n    zbuf = self.compress_buffer(HTML_CONTENT)\n    sys.stdout.write(\"Content-Encoding: gzip\\r\\n\")\n    sys.stdout.write(\"Content-Length: %d\\r\\n\" % (len(zbuf)))\n    sys.stdout.write(\"\\r\\n\")\n    self.wfile.write(zbuf)\n  return\n\n  def compress_buffer(self, buf):\n    zbuf = cStringIO.StringIO()\n    zfile = gzip.GzipFile(mode = 'wb',  fileobj = zbuf, \ncompresslevel = 6)\n    zfile.write(buf)\n    zfile.close()\n    return zbuf.getvalue()\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser(description='Simple HTTP Server \nExample')\n  parser.add_argument('--port', action=\"store\", dest=\"port\", \ntype=int, default=DEFAULT_PORT)\n  given_args = parser.parse_args() \n  port = given_args.port\n  server_address =  (DEFAULT_HOST, port)\n  server = HTTPServer(server_address, RequestHandler)\n  server.serve_forever()\n```", "```py\n$ python 4_8_http_compression.py \nlocalhost - - [22/Feb/2014 12:01:26] \"GET / HTTP/1.1\" 200 -\nContent-Encoding: gzip\nContent-Encoding: gzip\nContent-Length: 71\nlocalhost - - [22/Feb/2014 12:01:26] \"GET /favicon.ico HTTP/1.1\" 200 -\nContent-Encoding: gzip\nContent-Encoding: gzip\nContent-Length: 71\n\n```", "```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter - 4\n# This program is optimized for Python 2.7.# It may run on any other version with/without modifications.\n\nimport urllib, os\nTARGET_URL = 'http://python.org/ftp/python/2.7.4/'\nTARGET_FILE = 'Python-2.7.4.tgz'\n\nclass CustomURLOpener(urllib.FancyURLopener):\n  \"\"\"Override FancyURLopener to skip error 206 (when a\n    partial file is being sent)\n  \"\"\"\n  def http_error_206(self, url, fp, errcode, errmsg, headers, \ndata=None):\n    pass\n\n  def resume_download():\n    file_exists = False\n    CustomURLClass = CustomURLOpener()\n  if os.path.exists(TARGET_FILE):\n    out_file = open(TARGET_FILE,\"ab\")\n    file_exists = os.path.getsize(TARGET_FILE)\n    #If the file exists, then only download the unfinished part\n    CustomURLClass.addheader(\"Download range\",\"bytes=%s-\" % \n(file_exists))\n  else:\n    out_file = open(TARGET_FILE,\"wb\")\n\n  web_page = CustomURLClass.open(TARGET_URL + TARGET_FILE)\n\n  #If the file exists, but we already have the whole thing, don't \ndownload again\n  if int(web_page.headers['Content-Length']) == file_exists:\n    loop = 0\n    print \"File already downloaded!\"\n\n  byte_count = 0\n  while True:\n    data = web_page.read(8192)\n    if not data:\n      break\n    out_file.write(data)\n    byte_count = byte_count + len(data)\n\n  web_page.close()\n  out_file.close()\n\n  for k,v in web_page.headers.items():\n    print k, \"=\",v\n  print \"File copied\", byte_count, \"bytes from\", web_page.url\n\nif __name__ == '__main__':\n  resume_download()\n```", "```py\n$   python 4_9_http_fail_over_client.py\ncontent-length = 14489063\ncontent-encoding = x-gzip\naccept-ranges = bytes\nconnection = close\nserver = Apache/2.2.16 (Debian)\nlast-modified = Sat, 06 Apr 2013 14:16:10 GMT\ncontent-range = bytes 0-14489062/14489063\netag = \"1748016-dd15e7-4d9b1d8685e80\"\ndate = Tue, 07 May 2013 12:51:31 GMT\ncontent-type = application/x-tar\nFile copied 14489063 bytes from http://python.org/ftp/python/2.7.4/Python-2.7.4.tgz\n\n```", "```py\n#!/usr/bin/env python\n# Python Network Programming Cookbook -- Chapter - 4\n# This program is optimized for Python 2.7.\n# It may run on any other version with/without modifications.\n# Requires pyOpenSSL and SSL packages installed\n\nimport socket, os\nfrom SocketServer import BaseServer\nfrom BaseHTTPServer import HTTPServer\nfrom SimpleHTTPServer import SimpleHTTPRequestHandler\nfrom OpenSSL import SSL\n\nclass SecureHTTPServer(HTTPServer):\n  def __init__(self, server_address, HandlerClass):\n    BaseServer.__init__(self, server_address, HandlerClass)\n    ctx = SSL.Context(SSL.SSLv23_METHOD)\n    fpem = 'server.pem' # location of the server private key and \nthe server certificate\n    ctx.use_privatekey_file (fpem)\n    ctx.use_certificate_file(fpem)\n    self.socket = SSL.Connection(ctx, \nsocket.socket(self.address_family, self.socket_type))\n    self.server_bind()\n    self.server_activate()\n\nclass SecureHTTPRequestHandler(SimpleHTTPRequestHandler):\n  def setup(self):\n    self.connection = self.request\n    self.rfile = socket._fileobject(self.request, \"rb\", \nself.rbufsize)\n    self.wfile = socket._fileobject(self.request, \"wb\", \nself.wbufsize)\n\n  def run_server(HandlerClass = SecureHTTPRequestHandler,\n    ServerClass = SecureHTTPServer):\n    server_address = ('', 4443) # port needs to be accessible by \nuser\n    server = ServerClass(server_address, HandlerClass)\n    running_address = server.socket.getsockname()\n    print \"Serving HTTPS Server on %s:%s ...\" \n%(running_address[0], running_address[1])\n    server.serve_forever()\n\nif __name__ == '__main__':\n  run_server()\n```", "```py\n$ python 4_10_https_server.py \nServing HTTPS Server on 0.0.0.0:4443 ...\n\n```"]