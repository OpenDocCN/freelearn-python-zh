- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices and Containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until now, we have been developing the complete application as one block
    of code (usually known as a **monolith**), which is typically designed, tested,
    and deployed as a single unit. Scaling also occurs in a similar manner, where
    either the whole application is scaled or not. However, as the application grows
    in size, it is natural to want to break the monolith into smaller chunks that
    can be separately managed and scaled. A solution to this is microservices. This
    chapter is all about microservices, and we will look at a few methodologies for
    creating and managing them.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices comprise a method of developing and architecting software applications
    as a collection of multiple loosely coupled services. These services are designed
    and developed to help build single-function modules that have clear and fine-grained
    interfaces. The benefit of this modularity, if designed and architected properly,
    is that the overall application becomes easier to understand, develop, maintain,
    and test. Multiple small autonomous teams can work in parallel on multiple microservices,
    so the time to develop and deliver an application is effectively reduced. Each
    microservice can now be deployed and scaled separately, which allows for less
    downtime and cost-effective scaling since only the high-traffic services can be
    scaled based on predefined criteria. Other services can operate as usual.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will start with some of the common terminologies that you might
    hear whenever microservices are talked about – that is, containers and Docker.
    First, we will look at how to deploy a Flask application using Docker containers.
    Then, we will look at how multiple containers are scaled and managed effectively
    using Kubernetes, which is one of the best container orchestration tools available.
    Then, we will look at how to create fully-managed microservices using some cloud
    platforms such as **AWS Lambda** and **GCP Cloud Run**. Finally, we will look
    at how to stitch everything together into a seamless deployment pipeline using
    **GitHub Actions**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Containerization with Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating containers with Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Going serverless with Google Cloud Run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous deployment with GitHub Actions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containerization with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A container can be thought of as a standardized package of code that is needed
    to run the application and all its dependencies, which allows the application
    to run uniformly across multiple environments and platforms. **Docker** is a tool
    that allows for a standard and easy method of creating, distributing, deploying,
    and running applications using containers.
  prefs: []
  type: TYPE_NORMAL
- en: Docker is essentially a virtualization software, but instead of visualizing
    the whole operating system, it allows the application to use the underlying host
    OS and requires applications to package additional dependencies and components
    as needed. This makes Docker container images very lightweight and easy to distribute.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step is to install Docker. Docker’s installation steps vary in terms
    of the operating system you use. The detailed steps for each operating system
    can be found at [https://docs.docker.com/install/](https://docs.docker.com/install/).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Docker is a fast-evolving software and has had multiple major releases in the
    last few years, where a lot of older releases have been deprecated. I would suggest
    that you always read the documentation thoroughly to avoid installing any legacy
    versions of Docker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once Docker has been successfully installed, head over to the Terminal and
    run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command is used to list all the running containers. If it runs
    without any errors and shows a row of headers that start with `CONTAINER ID`,
    then Docker has been successfully installed.
  prefs: []
  type: TYPE_NORMAL
- en: Information
  prefs: []
  type: TYPE_NORMAL
- en: Different versions of Docker, whether old or current, have been called Docker
    Toolbox, Docker Machine, Docker Engine, Docker Desktop, and so on. These names
    will appear multiple times across the documentation and other resources on the
    internet. There is a great probability that these might change or evolve in the
    future as well. For the sake of simplicity, I will just call everything **Docker**.
  prefs: []
  type: TYPE_NORMAL
- en: 'A more fun way to verify the Docker installation would be to try out a `hello-world`
    container. Just run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command should give you the following output. It lists the steps
    that Docker took to execute this command. I recommend reading through this:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 12.1 – Testing D\uFEFFocker](img/B19111_12_1.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – Testing Docker
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will start with the catalog application from the *Managing and monitoring
    application performance with New Relic* recipe from [*Chapter 11*](B19111_11.xhtml#_idTextAnchor610):'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step toward creating a container is to create an image for it. A
    Docker image can easily be created in a scripted manner by creating a file named
    `Dockerfile`. This file contains the steps that Docker needs to perform to build
    an image for our application’s container. A basic `Dockerfile` for our application
    would be as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Each line in the preceding file is a command that is executed in a linear top-down
    approach. `FROM` specifies the base container image over which the new image for
    our application container will be built. I have taken the base image as `python:3`,
    which is a Linux image with `Python 3.11` installed.
  prefs: []
  type: TYPE_NORMAL
- en: Information
  prefs: []
  type: TYPE_NORMAL
- en: The `python:3` Docker base images come with `Python 3.11` pre-installed at the
    time of writing this book. This will change over time.
  prefs: []
  type: TYPE_NORMAL
- en: '`WORKDIR` indicates the default directory where the application will be installed.
    I have set it to `/usr/src/app`. Any commands that are run after this will be
    executed from inside this folder.'
  prefs: []
  type: TYPE_NORMAL
- en: '`COPY` simply copies the files specified on the local machine to the container
    filesystem. I have copied `requirements.txt` to `/usr/src/app`.'
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by `RUN`, which executes the command provided. Here, we have
    installed all the requirements from `requirements.txt` using `pip`. Then, I simply
    copied all the files from my current local folder, which is essentially my application
    root folder, to `/usr/src/app`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, an `ENTRYPOINT` is defined that indicates the default `CMD` command,
    which should be run when a container is started. Here, I have simply run my application
    by running `python run.py`.
  prefs: []
  type: TYPE_NORMAL
- en: Information
  prefs: []
  type: TYPE_NORMAL
- en: A Dockerfile provides many other keywords, all of which can be used to create
    powerful scripts. Refer to [https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple ways of running the application, as outlined in [*Chapter
    11*](B19111_11.xhtml#_idTextAnchor610), *Deployment and Post-Deployment*. I would
    urge you to use those methods while dockerizing the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the Dockerfile to run, you must have a `requirements.txt` file in your
    application’s root folder. If you don’t have one, you can simply generate a `requirements.txt`
    file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following is my `requirements.txt` file. I encourage you to generate your
    own instead of using the one that follows because the Python package versions
    will evolve and you will want to use the latest and most relevant ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: If you have `mod_wsgi` in your `requirements.txt` file, you can remove it from
    the file unless you specifically want to run your application in a Docker container
    using `Apache`. `mod_wsgi` is an OS-specific package and the OS on your development
    machine might not match that on the Docker image, which would lead to installation
    failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'A small change needs to be made to `run.py`, after which it will look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: I have added the `host` parameter to `app.run`. This allows the application
    to be accessed outside the Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: 'The creation of `Dockerfile` is followed by building a Docker container image,
    which can then be run like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we asked Docker to build an image using the Dockerfile at the same location.
    The `-t` argument sets the name/tag for the image that will be built. The final
    argument is a dot (`.`), which indicates that everything in the current folder
    needs to be packaged in the build. This command might take a while to process
    when it’s run for the first time because it will download the base image and then
    all of our application dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check the created image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, run this image to create a container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**92a7ee37e044cf59196f5ec4472d9ffb540c7f48ee3f4f1e5f978f7f93b301ba**'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have asked Docker to run the container using the commands that were
    specified in the `Dockerfile` at the bottom. The `-d` argument asks Docker to
    run the container in detached mode in the background; otherwise, it will block
    control to the current shell window. `-p` maps the port from the host machine
    to the Docker container port. This means that we have asked Docker to map port
    `8000` on the local machine to port `8000` on the container. `8000` is the port
    on which we are running our Flask app (see `run.py`). The last argument is the
    name of the container image, which is a combination of `REPOSITORY` and `TAG`,
    as indicated by the `docker images` command. Alternatively, you can just provide
    an `IMAGE ID`.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Head over to your browser and open `http://localhost:8000/` to see the application
    running.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, run `docker ps` again to see the details of the running container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can learn more about Dockerfiles at [https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The definition of a container by Docker can be read at [https://www.docker.com/resources/what-container](https://www.docker.com/resources/what-container).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can read about microservices in general at [https://en.wikipedia.org/wiki/Microservices](https://en.wikipedia.org/wiki/Microservices).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the first articles on microservices by Martin Fowler can be found at
    [https://martinfowler.com/articles/microservices.html](https://martinfowler.com/articles/microservices.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating containers with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker containers are pretty easy and powerful, as we saw from the previous
    recipe, but without a strong container orchestration system, managing containers
    can become pretty intensive. **Kubernetes** (also written as **K8s**) is an open
    source container orchestration system that automates the management, deployment,
    and scaling of containerized applications. It was originally developed at Google
    and, over the years, has become the most popular container orchestration software.
    It is widely available across all major cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we will see how we can leverage Kubernetes to automate the deployment
    and scaling of our application container, which we created in the previous recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is packaged along with the newer versions of the Docker Desktop installation
    and works in a pretty straightforward manner. However, we will be using **minikube**,
    which is a standard distribution that’s provided by Kubernetes itself. It’s quite
    popular and good for getting started. For this recipe, I will use Minikube, which
    will allow a single-node Kubernetes cluster to be run inside a VM on our local
    machine. You can choose to use other distributions of Kubernetes; refer to [https://kubernetes.io/docs/setup/](https://kubernetes.io/docs/setup/)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: To install Minikube, follow the instructions outlined at [https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)
    for your operating system.
  prefs: []
  type: TYPE_NORMAL
- en: Information
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is a huge topic that spans multiple dimensions. There are multiple
    books dedicated just to Kubernetes, and many more are being written. In this recipe,
    we will cover a very basic implementation of Kubernetes, just to get you acquainted
    with it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to understand how a local Kubernetes cluster can be created
    and used:'
  prefs: []
  type: TYPE_NORMAL
- en: 'After Minikube has been installed, create a Minikube cluster on your local
    machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, the preceding command downloads a bunch of images to set up
    and run Minikube, which creates a VM on your local machine. After creating a VM
    using these images, a simple Kubernetes cluster with only one node will be launched.
    This process might take a bit of time when it’s run for the first time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Minikube provides a browser dashboard view as well. This can be initiated by
    running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Visit the URL mentioned in the output of the preceding command to view the dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: In Kubernetes, containers are deployed in pods, where a pod can be defined as
    a group of one or more containers that are tied together for sharing resources
    and networking. In this recipe, we will have only one container inside a pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever a deployment is created using Minikube, it will look for the Docker
    image on some cloud-based registries such as Docker Hub or Google Cloud Registry,
    or something custom. For this recipe, we intend to make a deployment using a local
    Docker image. Therefore, we will run the following command, which sets the `docker`
    environment to `minikube docker`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, rebuild the Docker image using the preceding `docker` environment set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For more details on building Docker images, refer to the previous recipe, *Containerization
    with Docker*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, create a file named `cookbook-deployment.yaml` in your application root
    folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this file, we created a deployment named `cookbook-recipe`, which uses the
    `cookbook:latest` image. Take note of `imagePullPolicy`, which is set to `Never`
    – this signifies that kubectl should not try to fetch the image from online Docker
    repositories (such as Docker Hub or **Google Container Registry** (**GCR**); instead,
    it should always search for this image locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, `apply` the preceding file to create a Kubernetes deployment using kubectl:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can verify and get the status of the deployment that’s been created by
    running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Check the values for the `READY`, `UP-TO-DATE`, and `AVAILABLE` columns. These
    values represent the number of replicas of our application in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our application is now running but is currently not accessible outside the
    cluster. To expose the application outside the Kubernetes cluster, create a `LoadBalancer`
    type service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The deployment that we created in the last step exposed our application on port
    `8000`, which was internal to the cluster. The preceding command has exposed this
    internal `8000` port to any random port that can be accessed outside the cluster
    and hence via a browser.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To open the application in a browser, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 12.2 – Service deployed using Kubernetes](img/B19111_12_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Service deployed using Kubernetes
  prefs: []
  type: TYPE_NORMAL
- en: Running the preceding command will open the application in a browser on a random
    port, such as `58764`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scaling a deployment is very easy with Kubernetes. It is as simple as running
    a single command. By doing this, the application will be replicated in multiple
    pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, look at the status of deployment again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Check the replica values in the `READY`, `UP-TO-DATE`, and `AVAILABLE` columns,
    which will have increased from `1` to `3`.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can look at the YAML configurations that Kubernetes automatically creates
    for the deployment and service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is the config for the service. You can choose to create/save
    and `apply` this config (instead of specifying configuration values in command
    lines) just like we did earlier for the deployment in *Step 5*.
  prefs: []
  type: TYPE_NORMAL
- en: Information
  prefs: []
  type: TYPE_NORMAL
- en: What I have shown in this recipe is a very basic implementation of Kubernetes.
    The purpose of this is to get you acquainted with Kubernetes. This recipe does
    not intend to be a production-grade implementation. Ideally, the config files
    need to be created, and then the overall Kubernetes deployment can be built around
    them. I would urge you to build on the knowledge from this recipe and strive toward
    production-grade techniques with Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To learn more, check out the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: Start getting to know about Kubernetes at [https://kubernetes.io/docs/concepts/overview/](https://kubernetes.io/docs/concepts/overview/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The basics of Kubernetes are available at [https://kubernetes.io/docs/tutorials/kubernetes-basics/](https://kubernetes.io/docs/tutorials/kubernetes-basics/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Minikube tutorial can be followed at [https://kubernetes.io/docs/tutorials/hello-minikube/](https://kubernetes.io/docs/tutorials/hello-minikube/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can learn about the details of Minikube’s installation at [https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The complete Kubernetes documentation can be found at [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Going serverless with Google Cloud Run
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Serverless computing** is a cloud computing model where the cloud provider
    runs the server and dynamically manages the allocation of machine resources by
    scaling the resources up or down, depending on the consumption. Pricing is done
    based on the actual resources that are used. It also simplifies the overall process
    of deploying code, and it becomes relatively easy to maintain different executions
    for different environments, such as development, testing, staging, and production.
    These properties of serverless computing make this model a perfect candidate for
    developing and deploying tons of microservices without worrying about managing
    the overhead.'
  prefs: []
  type: TYPE_NORMAL
- en: Trivia
  prefs: []
  type: TYPE_NORMAL
- en: Why is this model called “serverless” even though there is a server involved?
  prefs: []
  type: TYPE_NORMAL
- en: Even though there is a server involved that hosts your application and serves
    the requests coming into your application, the lifespan of the server is as small
    as a single request. So, you can think of a server as something that lives to
    serve a single request. Hence, the lifespan of a server is typically in milliseconds.
  prefs: []
  type: TYPE_NORMAL
- en: As Google explains, **Cloud Run** is a managed compute platform that lets you
    run containers directly on top of Google’s scalable infrastructure. Also, since
    Google Cloud provides loads of other services with which Cloud Run integrates
    very well, it allows us to build full-featured applications without a lot of moving
    parts from different cloud vendors.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this recipe, I will interchangeably use the terms **Google Cloud**,
    **Google Cloud Platform**, and **GCP**.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Deploying with serverless tools allows developers to focus more on writing code
    rather than worrying about the infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before you can deploy with Cloud Run, you need to set up the `gcloud` CLI on
    your machine from where you would deploy your application to Cloud Run. Go through
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, create an account on Google Cloud Platform. Head over to [https://console.cloud.google.com/getting-started](https://console.cloud.google.com/getting-started)
    and create a new account if you don’t already have one. Then, create a project
    under which you will deploy your application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you’ve created your account, make sure you have a billing account activated.
    Even though you will not be charged for the use case of this recipe, Google mandates
    you to have a billing account activated and linked to your project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, install the `gcloud` CLI. This is highly OS-specific, so look for appropriate
    instructions here: [https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `gcloud` CLI uses Python versions 3.5 to 3.9 for its installation. If you
    have a later version of Python such as 3.10 or 3.11, you don’t need to worry about
    it as `gcloud` will download its own Python version and create a virtual environment
    for itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the `gcloud` installation is done, run the following command to initialize
    `gcloud` and go over some basic settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The execution of this command will ask you for some details, such as which GCP
    account you would want to use to link to your `gcloud` CLI. On a desktop, it will
    open a browser and ask you to log into your GCP account. Make sure the user who
    logs in has enough permissions to deploy to Cloud Run. For this recipe, the `owner`
    permission should handle everything.
  prefs: []
  type: TYPE_NORMAL
- en: Then, you will be asked about the GCP project that you want to use.
  prefs: []
  type: TYPE_NORMAL
- en: You can always change this configuration by running the same command again.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: After setting up and initializing `gcloud`, the next step is to create and upload
    the container of your application to GCR. You can also use other container registries
    such as Docker Hub, but that is outside the scope of this recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Run expects the application to run on port `8080`. So, update your `run.py`
    to run on `8080` instead of `8000` or `5000` like we have done so far in this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command from the root of your application where your `Dockerfile`
    is located:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command created a Docker container using `Dockerfile`. Then,
    it uploaded the Docker container to GCR at the path provided in the command. On
    successful execution, you will get a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – GCR image creation](img/B19111_12_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – GCR image creation
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, use the image you created to deploy your application to Cloud Run. Run
    the following command for the same:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This command will ask for a region of deployment if one hasn’t been set already;
    then, it will take a few minutes to deploy the application successfully to Cloud
    Run. Once done, it will provide the Service URL on which the application can be
    accessed. See the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Fig\uFEFFure 12.4 – Deployment on Cloud Run](img/B19111_12_4.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – Deployment on Cloud Run
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To check whether the application deployment is successful and is running as
    expected, open the Service URL provided, as shown in the previous screenshot.
    It should open the application home page.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To learn more, check out the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about Cloud Run at [https://cloud.google.com/run/docs/overview/what-is-cloud-run](https://cloud.google.com/run/docs/overview/what-is-cloud-run).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are other serverless tools and platforms such as Serverless, Zappa, AWS
    Beanstalk, AWS Lambda, and others. I urge you to explore them on your own. The
    underlying concept remains the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous deployment with GitHub Actions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuous deployment is a deployment strategy that enables the deployment and
    release of software to its relevant environment (production, in most cases) whenever
    there is a committed code change. Usually, this is preceded by automated test
    cases; when those pass, the code is deployed automatically.
  prefs: []
  type: TYPE_NORMAL
- en: '**GitHub Actions** is a continuous deployment platform provided by GitHub that
    allows you to trigger workflows on certain actions (such as code commit/merge/pull
    request). These workflows can be used to deploy to your choice of cloud provider.
    The best thing about GitHub Actions is that it integrates seamlessly with GitHub.'
  prefs: []
  type: TYPE_NORMAL
- en: Other tools can be used to perform continuous deployment but I will be focusing
    on GitHub Actions because it is one of the easiest ones to understand and adopt.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe, I am assuming that you have a GitHub account and know the basics
    of managing code and repositories on GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will be building upon the application from the previous recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two steps need to be done to get ready for this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: In the previous recipe, the authentication step for Google Cloud was performed
    during `gcloud init`, where you were asked to log in to GCP. But when deploying
    from GitHub Actions, you won’t have this liberty; hence, you need to create a
    service account on Google Cloud that has permission to create a container image
    on GCR and then deploy it to Cloud Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To create a service account, head over to your GCP console and open **IAM &
    Admin**. Next, create a service account and give it relevant permissions/roles.
    To test this recipe, **owner** permission should do. Once you have created and
    configured a service account, it should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19111_12_5.png)Figure 12.5 – Service account on GCP'
  prefs: []
  type: TYPE_NORMAL
- en: Download the service account file in JSON format when given the option. It cannot
    be downloaded again.
  prefs: []
  type: TYPE_NORMAL
- en: Next, configure your GitHub repository so that it stores secrets that will be
    read when the deployment runs. Head over to your GitHub repository by going to
    `RUN_PROJECT` and `RUN_SA_KEY`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`RUN_PROJECT` is the project ID of your GCP project, while `RUN_SA_KEY` is
    the content of the service account JSON file that you downloaded in the previous
    step:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6 – GitHub repository secrets](img/B19111_12_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – GitHub repository secrets
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, create a file called `.github/workflows/main.yml` in your application’s
    root folder. Make sure the path for the file is created properly. You will need
    to create two folders called `.github` and `workflows` inside it, followed by
    the `main.yml` file in the latter. The following is the content of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'In this file, first, we specified the branch on which the GitHub action is
    triggered on code push. Then, we have some environment variables that will be
    used in the next steps in the file. A job named `Setup, Build,` `and Deploy` is
    then created that specifies the operating system, which is Ubuntu in our case.
    The job consists of four steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Checkout**: Checks out code from the GitHub branch that was specified earlier.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`gcloud` and authenticates using the service account credentials file.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`gcloud submit`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Deploy the image to Cloud Run**: Deploys the Docker image created in the
    preceding step to Cloud Run.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, just commit and push your code to the relevant branch.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When the code is pushed to GitHub on the correct branch, the GitHub action
    is triggered. A successful GitHub action looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7 – Successful GitHub action execution](img/B19111_12_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 – Successful GitHub action execution
  prefs: []
  type: TYPE_NORMAL
- en: To see your application running, copy the service URL, as shown in the preceding
    screenshot, and open it in your browser.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: If you have followed this book since the beginning, this recipe would be a good
    place to think about how all the major pieces fall into place to complete the
    puzzle. We learned about creating a Flask application, then built more complexity
    into it, which was followed by unit test cases and, last but not least, deployment.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we automated deployment on code commits known as **continuous
    deployment**.
  prefs: []
  type: TYPE_NORMAL
- en: You can also modify your GitHub workflow to run test cases before building the
    image and exit on failure. This is called **continuous integration**.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can read more about GitHub Actions at [https://docs.github.com/en/actions/deployment/about-deployments/deploying-with-github-actions](https://docs.github.com/en/actions/deployment/about-deployments/deploying-with-github-actions).
  prefs: []
  type: TYPE_NORMAL
