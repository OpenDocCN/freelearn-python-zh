- en: Chapter 8. Putting It All into Practice
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章. 知识应用
- en: Welcome to the last chapter of the book. If you've made it this far, you've
    gone over several optimization techniques, both specific to the Python programming
    language and generic ones applicable to other similar technologies.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到本书的最后一章。如果你已经走到这一步，你已经了解了几个优化技术，这些技术既适用于Python编程语言，也适用于其他类似技术。
- en: You've also read about tools for profiling and visualizing those results. We
    also delved into one specific use case for Python, which is number crunching for
    scientific purposes. You learned about the tools that allow you to optimize the
    performance of your code.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你还阅读了关于配置文件和可视化这些结果的工具。我们还深入探讨了Python的一个特定用例，即用于科学目的的数值计算。你了解了允许你优化代码性能的工具。
- en: In this final chapter, we'll go over one practical use case that covers all
    the technologies we covered in the earlier chapters (remember that some of the
    tools we've seen are alternatives, so using all of them is not really a good plan).
    We will write an initial version of the code, measure its performance, and then
    go through the optimization process to finally rewrite the code and measure the
    performance again.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后，我们将讨论一个实际用例，该用例涵盖了我们在前面章节中介绍的所有技术（记住，我们看到的某些工具是替代品，所以同时使用所有这些工具并不是一个好的计划）。我们将编写代码的初始版本，测量其性能，然后进行优化过程，最终重写代码并再次测量性能。
- en: The problem to solve
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要解决的问题
- en: Before we even start thinking about writing the initial version of our code,
    we need to understand the problem we're trying to solve.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们甚至开始考虑编写代码的初始版本之前，我们需要理解我们试图解决的问题。
- en: Given the scope of the book, a full-blown application might be too big an undertaking,
    so we'll focus on a small task. It'll give us better control over what we want
    to do, and we won't run the risk of having too many things to optimize at the
    same time.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到本书的范围，一个完整的应用程序可能是一项过于庞大的任务，因此我们将专注于一个小任务。这将使我们更好地控制我们想要做的事情，并且我们不会面临同时优化太多事物的风险。
- en: 'To keep things interesting, we''ll split the problem into the following two
    parts:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持趣味性，我们将问题分为以下两个部分：
- en: '**Part 1**: This will take care of finding the data we want to process. It
    won''t just be a dataset we download from some given URL. Instead, we''ll scrape
    it from the Web.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一部分**：这将负责找到我们想要处理的数据。这不仅仅是从某个给定的URL下载的数据集。相反，我们将从网络中抓取它。'
- en: '**Part 2**: This will focus on processing the data obtained after solving the
    first part of the problem. In this step, we may perform the most CPU-intensive
    computations and calculate some statistics from the data gathered.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第二部分**：这将专注于处理解决问题的第一部分后获得的数据。在这一步中，我们可能需要进行最耗CPU的计算，并从收集到的数据中计算一些统计数据。'
- en: In both cases, we'll create an initial version of the code that solves the problem
    without taking performance into account. Afterwards, we'll analyze each solution
    individually and try to improve them as much as we can.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们将创建一个不考虑性能的代码初始版本来解决问题。之后，我们将单独分析每个解决方案，并尽可能改进它们。
- en: Getting data from the Web
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从网络获取数据
- en: The site we'll scrape is **Science Fiction & Fantasy** ([http://scifi.stackexchange.com/](http://scifi.stackexchange.com/)).
    The site is dedicated to answering questions about sci-fi and fantasy topics.
    It is much like StackOverflow but meant for sci-fi and fantasy geeks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要抓取的网站是**科幻与奇幻**([http://scifi.stackexchange.com/](http://scifi.stackexchange.com/))。该网站致力于回答关于科幻和奇幻主题的问题。它类似于StackOverflow，但专为科幻和奇幻爱好者设计。
- en: To be more specific, we'll want to scrape the list of latest questions. For
    each question, we'll get the page with the question's text and all the available
    answers. After all the scraping and parsing is done, we'll save the relevant information
    in the JSON format for easier postprocessing.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们希望抓取最新问题的列表。对于每个问题，我们将获取包含问题文本和所有可用答案的页面。在所有抓取和解析完成后，我们将以JSON格式保存相关信息，以便于后续处理。
- en: 'Remember that we''ll deal with HTML pages. However, we don''t want that. We
    want to strip away all HTML code and save only the following items:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们将处理HTML页面。然而，我们不想这样做。我们希望移除所有HTML代码，只保存以下项目：
- en: The question's title
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题的标题
- en: The question's author
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题的作者
- en: The question's body (the actual text of the question)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题的正文（问题的实际文本）
- en: The body of the answers (if there are any)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案的正文（如果有）
- en: The answer's author
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案的作者
- en: With this information, we'll be able to do some interesting postprocessing and
    get some relevant statistics (more on that in a minute).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些信息，我们将能够进行一些有趣的后处理并获取一些相关的统计数据（稍后详细介绍）。
- en: 'Here is a quick example of how the output of this script should look:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个此脚本输出应该看起来怎样的快速示例：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This script will take care of saving all the information into one single JSON
    file, which will be predefined inside its code.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本将负责将所有信息保存到一个单独的JSON文件中，该文件将在其代码中预先定义。
- en: 'We''ll try to keep the initial version of both scripts simple. This means using
    the least amount of modules. In this case, the main list of modules will be as
    follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试保持两个脚本的初始版本简单。这意味着使用最少的模块。在这种情况下，主要的模块列表如下：
- en: '**Beautiful Soup** ([http://www.crummy.com/software/BeautifulSoup/](http://www.crummy.com/software/BeautifulSoup/)):
    This is used to parse the HTML files, mainly because it provides a full parsing
    API, automatic encoding detection (which, if you''ve being in this business long
    enough, you''ve probably come to hate) and the ability to use selectors to traverse
    the parsed tree.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Beautiful Soup** ([http://www.crummy.com/software/BeautifulSoup/](http://www.crummy.com/software/BeautifulSoup/))：这个库用于解析HTML文件，主要是因为它提供了一个完整的解析API，自动编码检测（如果你在这个行业工作的时间足够长，你可能已经讨厌这种自动编码检测了）以及使用选择器遍历解析树的能力。'
- en: '**Requests** ([http://docs.python-requests.org/en/latest/](http://docs.python-requests.org/en/latest/)):
    This is used to make HTTP requests. Although Python already provides the required
    modules for this, this module simplifies the API and provides a more Pythonic
    way of handling this task.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Requests** ([http://docs.python-requests.org/en/latest/](http://docs.python-requests.org/en/latest/))：这个库用于发起HTTP请求。尽管Python已经提供了完成此任务所需的模块，但此模块简化了API，并提供了一种更Pythonic的方式来处理这个任务。'
- en: 'You can install both modules using the `pip` command-line tool:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`pip`命令行工具安装这两个模块：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following screenshot shows an example of the pages we''ll be scraping and
    parsing in order to get the data:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示了我们将抓取和解析以获取数据的页面示例：
- en: '![Getting data from the Web](img/B02088_08_01.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![从网络获取数据](img/B02088_08_01.jpg)'
- en: Postprocessing the data
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据后处理
- en: 'The second script will take care of reading the JSON-encoded file and getting
    some stats out of it. Since we want to make it interesting, we won''t limit ourselves
    to just counting the number of questions per user (although we will get this stat
    as well). We''ll also calculate the following elements:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个脚本将负责读取JSON编码的文件并从中获取一些统计数据。由于我们希望使其变得有趣，我们不会仅仅限制于统计每个用户的问题数量（尽管我们也会获取这个统计数据）。我们还将计算以下元素：
- en: Top ten users with most questions
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提问最多的前十位用户
- en: Top ten users with most answers
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回答最多的前十位用户
- en: Most common topics asked about
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最常见的问题主题
- en: The shortest answer
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最短的回答
- en: Top ten most common phrases
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最常见的十个短语
- en: Top ten most answered questions
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回答最多的前十道问题
- en: Since this book's main topic is performance and not **Natural Language Processing**
    (**NLP**), we will not delve into the details of the small amount of NLP that
    this script will have. Instead, we'll just limit ourselves to improving the performance
    based on what we've seen so far about Python.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书的主要主题是性能而不是**自然语言处理**（**NLP**），我们不会深入探讨此脚本将涉及到的少量NLP细节。相反，我们将仅限于根据我们迄今为止对Python的了解来提高性能。
- en: The only non-built-in module we'll use in the first version of this script is
    **NLTK** ([http://www.nltk.org](http://www.nltk.org)) to handle all the NLP functionalities.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在此脚本的第一版本中，我们将使用的唯一非内置模块是**NLTK** ([http://www.nltk.org](http://www.nltk.org))，用于处理所有的NLP功能。
- en: The initial code base
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始代码库
- en: Let's now list all of the code that we'll optimize in future, based on the earlier
    description.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来列出所有将在未来优化的代码，基于之前的描述。
- en: 'The first of the following points is quite simple: a single file script that
    takes care of scraping and saving in JSON format like we discussed earlier. The
    flow is simple, and the order is as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的第一个点相当简单：一个单文件脚本，负责抓取和以我们之前讨论的JSON格式保存。流程简单，顺序如下：
- en: It will query the list of questions page by page.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将逐页查询问题列表。
- en: For each page, it will gather the question's links.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每一页，它将收集问题的链接。
- en: Then, for each link, it will gather the information listed from the previous
    points.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，对于每个链接，它将收集之前列出的信息。
- en: It will move on to the next page and start over again.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将转到下一页并重新开始。
- en: It will finally save all of the data into a JSON file.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它最终将所有数据保存到一个JSON文件中。
- en: 'The code is as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码如下：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: By looking at the preceding code, you'll notice that we kept our promise. Right
    now, we're only using the proposed external modules, plus the JSON module, which
    comes built-in with Python.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看前面的代码，你会注意到我们遵守了承诺。目前，我们只使用了建议的外部模块，以及内置在 Python 中的 JSON 模块。
- en: 'The second script, on the other hand, is split into two, mainly for organizational
    purposes:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，第二个脚本被分成两部分，主要是为了组织目的：
- en: '`analyzer.py`: This file contains the main code. It takes care of loading the
    JSON file into a `dict` structure and performs a series of calculations.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`analyzer.py`：此文件包含主要代码。它负责将 JSON 文件加载到 `dict` 结构中，并执行一系列计算。'
- en: '`visualizer.py`: This file simply contains a set of functions used to visualize
    the different results from the analyzer.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visualizer.py`：此文件仅包含用于可视化分析器不同结果的函数集。'
- en: 'Let''s now take a look at the code in both these files. The first set of functions
    will be the utility functions used to sanitize the data, load it into memory,
    and so on:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看这两个文件中的代码。第一组函数将是用于清理数据、将其加载到内存中等的功能：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following set of functions are the ones that actually performs the *counting*
    of data and gets the statistics we want by analyzing the JSON in different ways:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下一系列函数是实际执行 *计数* 数据并通过对 JSON 进行不同方式的分析来获取我们想要的统计信息的函数：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following code shows how to use the functions declared earlier and display
    their results. It all boils down to three steps:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了如何使用之前声明的函数并显示其结果。这一切都归结为三个步骤：
- en: It loads the JSON into memory.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将 JSON 数据加载到内存中。
- en: It processes the data and saves the results into a dictionary.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它处理数据并将结果保存到字典中。
- en: It goes over that dictionary to display the results.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它遍历该字典以显示结果。
- en: 'The preceding steps are performed in the following code:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码执行了前面的步骤：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The code in the following file is merely used to format the output in a human-friendly
    way:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文件中的代码仅用于以人类友好的方式格式化输出：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Analyzing the code
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析代码
- en: Analyzing the code will be done in two steps, just like we've being doing so
    far. For each project, we'll profile the code, get the numbers, consider our optimization
    alternatives, and then refactor and measure the code's performance again.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 分析代码将分为两个步骤，就像我们之前所做的那样。对于每个项目，我们将分析代码，获取数字，考虑我们的优化选择，然后再次重构和测量代码的性能。
- en: Note
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: As the process described earlier can lead to several iterations of profiling—refactoring—profiling
    again, we'll limit the steps to the final results. However, keep in mind that
    this process is long and takes time.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述的过程可能导致多次配置文件分析——重构——再次分析，我们将步骤限制在最终结果上。然而，请记住，这个过程是漫长的，需要花费时间。
- en: Scraper
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 抓取器
- en: To start off the optimization process, let's first get some measurements so
    that we can compare our changes with them.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始优化过程，我们首先需要获取一些测量数据，这样我们就可以将我们的更改与它们进行比较。
- en: An easy-to-get number is the total time spent during the program's execution
    (in our example, and to keep things simple, we're limiting the total number of
    pages to query to 20).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一个容易得到的数字是程序执行期间所花费的总时间（在我们的例子中，为了简单起见，我们将查询的总页数限制为 20）。
- en: 'Simply using the `time` command-line tool, we can get that number:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 只需简单地使用 `time` 命令行工具，我们就可以得到这个数字：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following screenshot shows that we have 7 minutes and 30 seconds to scrape
    and parse the 20 pages of questions, which translate into a 3 MB JSON file:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示，我们有 7 分钟 30 秒的时间抓取和解析 20 页的问题，这相当于一个 3 MB 的 JSON 文件：
- en: '![Scraper](img/B02088_08_02.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![抓取器](img/B02088_08_02.jpg)'
- en: The scraper script is essentially an IO-bound loop that pulls data from the
    Internet with a minimum amount of processing. So, the first and most logical optimization
    we can spot here is the lack of parallelization of the requests. Since our code
    is not really CPU-bound, we can safely use the multithreading module (refer to
    [Chapter 5](ch05.html "Chapter 5. Multithreading versus Multiprocessing"), *Multithreading
    versus Multiprocessing*) and get an interesting speed boost with minimum effort.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 抓取脚本基本上是一个 I/O 密集型循环，以最小的处理从互联网上拉取数据。因此，我们可以在这里看到的第一个也是最有逻辑的优化是我们请求的缺乏并行化。由于我们的代码并不是真正
    CPU 密集型的，我们可以安全地使用多线程模块（参考第 5 章 [Multithreading versus Multiprocessing](ch05.html
    "第 5 章。多线程与多进程")），并以最小的努力获得有趣的加速效果。
- en: 'Just to clarify what we''re going to be doing, the following diagram shows
    the current status of the scraper script:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了澄清我们将要做什么，以下图表显示了抓取脚本当前的状态：
- en: '![Scraper](img/B02088_08_03.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![Scraper](img/B02088_08_03.jpg)'
- en: We're spending most of our running time on I/O operations, more specifically
    on the HTTP requests we're doing to get the list of questions and each question's
    page.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的大部分运行时间都花在了I/O操作上，更具体地说，是我们为了获取问题列表和每个问题的页面而进行的HTTP请求。
- en: 'As we''ve seen earlier, I/O operations can be parallelized easily using the
    multithreading module. So, we will transform our script so it resembles as shown
    in the following diagram:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，可以使用多线程模块轻松并行化I/O操作。因此，我们将转换我们的脚本，使其类似于以下图示：
- en: '![Scraper](img/B02088_08_04.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![Scraper](img/B02088_08_04.jpg)'
- en: 'Now, let''s look at the actual optimized code. We''ll first look at the `ThreadManager`
    class, which will take care of centralizing the configuration of the threads as
    well as the status of the entire parallel process:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看实际的优化代码。我们首先看看`ThreadManager`类，它将负责集中管理线程的配置以及整个并行过程的状态：
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following functions take care of scraping the information from a page using
    `BeatifulSoup`, either by getting the lists of pages or getting the actual information
    for each question:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数负责使用`BeautifulSoup`从页面抓取信息，无论是获取页面列表还是获取每个问题的实际信息：
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The highlighted code in the preceding snippet shows the main change done to
    the initial script. Instead of starting at page 1 and moving forward one by one,
    we're starting a preconfigured number of threads (using the `threading.Thread`
    class directly) that will call our `get_question_page` function in parallel. All
    we had to do was pass in that function as the target of each new thread.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码中突出显示的部分显示了最初脚本所做的主要更改。我们不是从第1页开始逐页前进，而是启动一个预配置的线程数量（直接使用`threading.Thread`类），这些线程将并行调用我们的`get_question_page`函数。我们唯一需要做的就是将那个函数作为每个新线程的目标。
- en: After that, we also needed a way to centralize the configuration parameters
    and the temporary results from each thread. For that, we created the `ThreadManager`
    class.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们还需要一种方法来集中管理配置参数和每个线程的临时结果。为此，我们创建了`ThreadManager`类。
- en: 'With this change, we go from the 7 minutes mark all the way down to 2 minutes
    13 seconds, as shown in the following screenshot:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个改变，我们的时间从7分钟标记下降到2分13秒，如下面的截图所示：
- en: '![Scraper](img/B02088_08_05.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![Scraper](img/B02088_08_05.jpg)'
- en: Tweaking the number of threads, for instance, might lead to even better numbers,
    but the main improvement is already there.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 调整线程数量，例如，可能会带来更好的数字，但主要的改进已经实现。
- en: Analyzer
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析器
- en: 'The code for the analyzer script is different compared to the scraper. Instead
    of having a heavy I/O-bound script, we have the opposite: a CPU-bound one. It
    does very little I/O, mainly to read the input file and output the results. So,
    we will focus on measuring in more detail.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 与抓取器相比，分析器的代码有所不同。我们不是有一个重I/O绑定的脚本，而是相反：一个CPU绑定的脚本。它进行的I/O操作非常少，主要是读取输入文件和输出结果。因此，我们将更详细地关注测量。
- en: 'Let''s first get some basic measurements so that we know where we stand:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先进行一些基本测量，以便我们知道我们的位置：
- en: '![Analyzer](img/B02088_08_06.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![Analyzer](img/B02088_08_06.jpg)'
- en: The preceding screenshot shows the output of the `time` command-line utility.
    So now that we have a base number to work with, we know we need to get the execution
    time lower than 3.5 seconds.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图显示了`time`命令行工具的输出。因此，现在我们有一个基数可以工作，我们知道我们需要将执行时间降低到3.5秒以下。
- en: 'The first approach would be to use `cProfile` and start getting some numbers
    from the inside of our code. This should help us get a general overview of our
    program to start understanding where our pain points are. The output looks like
    the following screenshot:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法将是使用`cProfile`并从代码内部开始获取一些数字。这应该有助于我们获得程序的一般概述，从而开始了解我们的痛点在哪里。输出看起来像以下截图：
- en: '![Analyzer](img/B02088_08_07.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![Analyzer](img/B02088_08_07.jpg)'
- en: 'There are two areas of interest in the preceding screenshot:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图中有两个感兴趣的区域：
- en: On the left-hand side, we can see the functions and how much time they consume.
    Pay attention to how most of the list is composed of external functions, mainly
    from the `nltk` module (the first two are just consumers of the others below,
    so they don't really matter).
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在左侧，我们可以看到函数及其消耗的时间。请注意，列表的大部分由外部函数组成，主要是来自`nltk`模块的函数（前两个只是下面其他函数的消费者，所以它们并不真正重要）。
- en: On the right-hand side, the **Callee Map** looks way too complex to interpret
    it (quite apart from the fact that again, most of the functions listed there aren't
    from our code, but from the libraries we're using).
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在右侧，**调用者映射**看起来非常复杂，难以解释（更不用说，其中列出的大多数函数都不是来自我们的代码，而是来自我们使用的库）。
- en: 'With that being said, it looks like improving our code directly is not going
    to be a simple task. Instead, we might want to go on another route: since we''re
    doing a lot of counting, we might benefit from typed code. So, let''s try our
    hand at using Cython.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，直接改进我们的代码似乎不会是一件简单的事情。相反，我们可能想要走另一条路：既然我们在做很多计数，我们可能从使用类型化代码中受益。所以，让我们尝试使用Cython。
- en: 'An initial analysis using the Cython command-line utility shows that most of
    our code can''t directly be translated into C, as shown in the following screenshot:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Cython命令行工具进行初步分析显示，我们的大部分代码不能直接翻译成C语言，如下面的截图所示：
- en: '![Analyzer](img/B02088_08_08.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![Analyzer](img/B02088_08_08.jpg)'
- en: The preceding screenshot shows a portion of the analysis of our code. We can
    clearly see the darker lines filling most of the screen, showing that most of
    our code can't be directly translated into C. Sadly, this is because we're dealing
    with a complex object in most of our functions, so there isn't much we can do
    about it.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张截图显示了我们对代码分析的一部分。我们可以清楚地看到，大部分屏幕被较深的线条填充，这表明我们的大部分代码不能直接翻译成C语言。遗憾的是，这是因为我们在大多数函数中处理的是复杂对象，所以我们对此无能为力。
- en: 'Still, simply by compiling our code with Cython, we get much better results.
    So, let''s take a look at how we need to modify the source so that we can compile
    it with Cython. The first file is basically the same as the original analyzer
    with the changes highlighted in the code and minus the actual function calls,
    as we''re now turning it into an external library:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，仅仅通过使用Cython编译我们的代码，我们就得到了更好的结果。所以，让我们看看我们需要如何修改源代码，以便我们可以使用Cython编译它。第一个文件基本上与原始分析器相同，代码中的更改被突出显示，并且没有实际的功能调用，因为我们现在正在将其转换为外部库：
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following file is the one that takes care of setting everything up for
    Cython to compile our code, we''ve seen this code before (refer to [Chapter 6](ch06.html
    "Chapter 6. Generic Optimization Options"), *Generic Optimization Options*):'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文件是负责为Cython编译我们的代码设置一切所需的文件，我们之前已经见过这段代码（参考[第6章](ch06.html "第6章。通用优化选项")，*通用优化选项*）：
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The last file is the one that uses our new external library by importing the
    compiled module. The file calls on the `load_json_data` and `analyze_data` methods
    and, finally, uses the visualizer module to format the output:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个文件是使用我们新导入的编译模块的外部库的文件。该文件调用`load_json_data`和`analyze_data`方法，并最终使用可视化模块来格式化输出：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding code can be compiled using the following line:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码可以使用以下行进行编译：
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, by running the `analyzer-use-cython.py` script, we will get the following
    execution time:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过运行`analyzer-use-cython.py`脚本，我们将得到以下执行时间：
- en: '![Analyzer](img/B02088_08_09.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![Analyzer](img/B02088_08_09.jpg)'
- en: The time went down from 3.5 to 1.3 seconds. This is quite an improvement from
    simply reorganizing of our code and compiling it using Cython, like we saw in
    [Chapter 6](ch06.html "Chapter 6. Generic Optimization Options"), *Generic Optimization
    Options*. This simple compilation can produce great results.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 时间从3.5秒下降到1.3秒。这比仅仅重新组织我们的代码并使用Cython编译（如我们在[第6章](ch06.html "第6章。通用优化选项")中看到的）有了相当大的改进。这种简单的编译可以产生很好的结果。
- en: The code can be further broken down and rewritten to remove most of the need
    for complex structures, thus allowing us to declare the primitive types for all
    variables. We could even try to remove `nltk` and use some NLP library written
    in C, such as OpenNLP ([http://opennlp.sourceforge.net/projects.html](http://opennlp.sourceforge.net/projects.html)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 代码可以被进一步分解和重写，以消除对复杂结构的绝大部分需求，从而允许我们为所有变量声明原始类型。我们甚至可以尝试移除`nltk`并使用一些用C语言编写的NLP库，例如OpenNLP
    ([http://opennlp.sourceforge.net/projects.html](http://opennlp.sourceforge.net/projects.html))。
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: You've reached the end of the chapter and, with it, the end of this book. The
    examples provided in this last chapter are meant to show how a random piece of
    code can be analyzed and improved using the techniques shown in the previous chapters.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经到达了本章的结尾，也是这本书的结尾。本章提供的例子旨在展示如何使用前几章中介绍的技术来分析和改进随机的一段代码。
- en: As not all techniques are compatible with each other, not all of them were applicable
    here. However, we were able to see how some of them work, more specifically, multithreading,
    profiling with `cProfile` and `kcachegrind`, and finally, compilation with Cython.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 由于并非所有技术都相互兼容，因此并非所有技术都适用于此处。然而，我们能够看到其中一些技术是如何工作的，更具体地说，是多线程、使用`cProfile`和`kcachegrind`进行性能分析，以及最终使用Cython进行编译。
- en: Thank you for reading and, hopefully, enjoying the book!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您阅读，并希望您能享受这本书！
