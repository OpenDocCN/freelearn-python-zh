- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Multiprocessing – When a Single CPU Core Is Not Enough
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多进程 – 当单个CPU核心不够用时
- en: In the previous chapter, we discussed `asyncio`, which can use the `threading`
    and `multiprocessing` modules but mainly uses single-thread/single-process parallelization.
    In this chapter, we will see how we can directly use multiple threads or processes
    to speed up our code and what caveats to keep in mind. This chapter can actually
    be seen as an extension to the list of performance tips.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了`asyncio`，它可以使用`threading`和`multiprocessing`模块，但主要使用单线程/单进程并行化。在本章中，我们将看到如何直接使用多个线程或进程来加速我们的代码，以及需要注意的注意事项。实际上，本章可以被视为性能技巧列表的扩展。
- en: The `threading` module makes it possible to run code in parallel in a single
    process. This makes `threading` very useful for I/O-related tasks such as reading/writing
    files or network communication, but a useless option for slow and heavy calculations,
    which is where the `multiprocessing` module shines.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '`threading`模块使得在单个进程中并行运行代码成为可能。这使得`threading`对于与I/O相关的任务（如读写文件或网络通信）非常有用，但对于缓慢且计算量大的任务则不是一个有用的选项，这正是`multiprocessing`模块大放异彩的地方。'
- en: With the `multiprocessing` module, you can run code in multiple processes, which
    means you can run code on multiple CPU cores, multiple processors, or even on
    multiple computers. This is an easy way to work around the **Global Interpreter
    Lock** (**GIL**) that was discussed in *Chapter 12*, *Performance – Tracking and
    Reducing Your Memory and CPU Usage.*
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`multiprocessing`模块，你可以在多个进程中运行代码，这意味着你可以在多个CPU核心、多个处理器或甚至多台计算机上运行代码。这是绕过在*第12章*，*性能
    – 跟踪和减少你的内存和CPU使用*中讨论的**全局解释器锁**（**GIL**）的一种简单方法。
- en: The `multiprocessing` module has a fairly easy-to-use interface with many convenience
    features, but the `threading` module is rather basic and requires you to manually
    create and manage the threads. For this, we also have the `concurrent.futures`
    module, which offers a simple way of executing a list of tasks either through
    threads or processes. This interface is also partially comparable to the `asyncio`
    features we saw in the previous chapter.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块提供了一个相对容易使用的接口，具有许多便利功能，但`threading`模块相对基础，需要你手动创建和管理线程。为此，我们还有`concurrent.futures`模块，它提供了一种简单的方法来执行一系列任务，无论是通过线程还是进程。此接口也与我们在上一章中看到的`asyncio`功能部分可比。'
- en: 'To summarize, this chapter covers:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本章涵盖了：
- en: The Global Interpreter Lock (GIL)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全局解释器锁（GIL）
- en: Multithreading versus multiprocessing
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多线程与多进程的比较
- en: Locking, deadlocks, and thread safety
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锁定、死锁和线程安全
- en: Data sharing and synchronization between processes
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程间的数据共享和同步
- en: Choosing between multithreading, multiprocessing, and single-threading
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多线程、多进程和单线程之间进行选择
- en: Hyper-threading versus physical cores
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超线程与物理核心的比较
- en: Remote multiprocessing with `multiprocessing` and `ipyparallel`
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`multiprocessing`和`ipyparallel`进行远程多进程
- en: The Global Interpreter Lock (GIL)
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全局解释器锁（GIL）
- en: The GIL has been mentioned in this book several times already, but we have not
    really covered it in detail and it really does need a bit more explanation before
    we continue with this chapter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: GIL（全局解释器锁）在本书中已经被提及多次，但我们并没有对其进行详细讲解，它确实需要更多的解释才能继续本章的内容。
- en: In short, the name already explains what it does. It is a global lock for the
    Python interpreter so it can only execute a single statement at once. A **lock**
    or **mutex** (**mutual exclusion**) in parallel computing is a synchronization
    primitive that can block parallel execution. With a lock, you can make sure that
    nobody can touch your variable while you are working on it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，名称已经解释了它的功能。它是一个Python解释器的全局锁，因此它一次只能执行一个语句。在并行计算中，**锁**或**互斥锁**（**互斥**）是一种同步原语，可以阻止并行执行。有了锁，你可以确保在你工作时没有人可以触摸你的变量。
- en: Python offers several types of synchronization primitives, such as `threading.Lock`
    and `threading.Semaphore`. These are covered in more detail in the *Sharing data
    between threads and processes* section of this chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Python提供了几种类型的同步原语，如`threading.Lock`和`threading.Semaphore`。这些内容在本章的*线程和进程间共享数据*部分有更详细的介绍。
- en: That means that even with the `threading` module, you are still only executing
    a single Python statement at the same time. So, when it comes to pure Python code,
    your multithreaded solutions will **always** be slower than single-threaded solutions
    because `threading` introduces some synchronization overhead while not offering
    any benefit for that scenario.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着即使使用`threading`模块，你同时也只能执行一个Python语句。因此，当涉及到纯Python代码时，你的多线程解决方案**总是**会比单线程解决方案慢，因为`threading`引入了一些同步开销，而在这种情况下并没有提供任何好处。
- en: Let’s continue with some more in-depth information about the GIL.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续深入了解GIL的更多信息。
- en: The use of multiple threads
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多线程的使用
- en: Since the GIL only allows a single Python statement to be executed at the same
    time, what point does threading have? The effectiveness greatly depends on your
    goal. Similar to the `asyncio` examples in *Chapter 13*, `threading` can give
    you a lot of benefit if you are waiting for external resources.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GIL只允许同时执行一个Python语句，那么线程有什么用呢？其有效性很大程度上取决于你的目标。类似于第13章中的`asyncio`示例，如果你正在等待外部资源，`threading`可以给你带来很多好处。
- en: For example, if you are trying to fetch a webpage, open a file (remember that
    the `aiofiles` module actually uses threads), or if you want to execute something
    periodically, `threading` can work great.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你正在尝试获取一个网页，打开一个文件（记住`aiofiles`模块实际上使用线程），或者如果你想定期执行某些操作，`threading`可以非常有效。
- en: When writing a new application, I would generally recommend that you make it
    ready for `asyncio` if there is even a small chance of becoming I/O-limited in
    the future. Rewriting for `asyncio` at a later time can be a huge amount of work.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当编写一个新应用程序时，如果将来有即使是微小的可能性成为I/O受限，我通常会建议你让它准备好使用`asyncio`。在以后的时间重新编写以适应`asyncio`可能是一项巨大的工作量。
- en: 'There are several advantages to `asyncio` over `threading`:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio`相对于`threading`有几个优点：'
- en: '`asyncio` is generally faster than threading because you don’t have any thread
    synchronization overhead.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`asyncio`通常比线程更快，因为你没有线程同步开销。'
- en: Since `asyncio` is normally single-threaded, you don’t have to worry about thread
    safety (more about thread safety later in the chapter).
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于`asyncio`通常是单线程的，你不必担心线程安全问题（关于线程安全的内容将在本章后面详细介绍）。
- en: Why do we need the GIL?
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们为什么需要GIL？
- en: The GIL is currently an essential part of the CPython interpreter because it
    makes sure that memory management is always consistent.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: GIL目前是CPython解释器的一个基本组成部分，因为它确保内存管理始终是一致的。
- en: To explain how this works, we need to know a bit about how the CPython interpreter
    manages its memory.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释这是如何工作的，我们需要了解一些关于CPython解释器如何管理其内存的信息。
- en: 'Within CPython, the memory management system and garbage collection system
    rely on reference counting. This means that CPython counts how many names you
    have linked to a value. If you have a line of Python like this: `a = SomeObject()`,
    that means that this instance of `SomeObject` has 1 reference, namely, `a`. If
    we were to do `b = a`, the reference count would increase to 2\. When the reference
    count reaches 0, the variable will be deleted by the garbage collector when it
    runs.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在CPython中，内存管理系统和垃圾回收系统依赖于引用计数。这意味着CPython会计算你有多少个名称链接到一个值。如果你有一行Python代码像这样：`a
    = SomeObject()`，这意味着这个`SomeObject`实例有1个引用，即`a`。如果我们执行`b = a`，引用计数将增加到2。当引用计数达到0时，变量将在垃圾回收器运行时被删除。
- en: You can check the number of references using `sys.getrefcount(variable)`. You
    should note that the call to `sys.getrefcount()` increases your reference count
    by 1, so if it returns 2, the actual number is 1.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`sys.getrefcount(variable)`来检查引用的数量。你应该注意，对`sys.getrefcount()`的调用会增加你的引用计数1，所以如果它返回2，实际的数量是1。
- en: As the GIL makes sure that only a single Python statement can be executed simultaneously,
    you can never have issues where multiple bits of code manipulate memory at the
    same time, or where memory is being released to the system that is not actually
    free.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GIL确保同时只能执行一个Python语句，你永远不会遇到多个代码块同时操作内存的问题，或者内存被释放到实际上并未空闲的系统。
- en: If the reference counter is not correctly managed, this could easily result
    in memory leaks or a crashing Python interpreter. Remember the segmentation faults
    we saw in *Chapter 11*, *Debugging – Solving the Bugs?* That is what could easily
    happen without the GIL, and it would instantly kill your Python interpreter.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果引用计数器没有正确管理，这很容易导致内存泄漏或Python解释器崩溃。记得我们在*第11章*，*调试 – 解决错误*中看到的段错误？这就是没有GIL时可能发生的事情，它将立即杀死你的Python解释器。
- en: Why do we still have the GIL?
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们为什么仍然有GIL？
- en: 'When Python was initially created, many operating systems didn’t even have
    a concept of threading, and all common processors only had a single core. Long
    story short, there are two main reasons for the GIL:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当Python最初被创建时，许多操作系统甚至没有线程的概念，所有常见的处理器都只有一个核心。简而言之，GIL存在有两个主要原因：
- en: There was initially no point in creating a complex solution that would handle
    threading
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始时，创建一个处理线程的复杂解决方案并没有什么意义
- en: The GIL is a really simple solution for a very complex problem
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GIL是一个针对非常复杂问题的简单解决方案
- en: Luckily, it seems that is not the end of the discussion. Recently (May 2021),
    Guido van Rossum came out of retirement and he has plans to address the GIL limitations
    by creating sub-interpreters for threads. How this will work out in practice remains
    to be seen, of course, but the ambitious plan is to make CPython 3.15 about 5
    times faster than CPython 3.10, which would be an amazing performance increase.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这似乎并不是讨论的终点。最近（2021年5月），吉多·范罗苏姆（Guido van Rossum）从退休状态中复出，他计划通过为线程创建子解释器来解决GIL的限制。当然，如何在实践中实现这一点还有待观察，但雄心勃勃的计划是将CPython
    3.15的速度提升到CPython 3.10的5倍，这将是一个惊人的性能提升。
- en: Now that we know when the GIL limits CPython threads, let’s look at how we can
    create and use multiple threads and processes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道GIL限制了CPython线程，让我们看看我们如何创建和使用多个线程和进程。
- en: Multiple threads and processes
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程和多进程
- en: The `multiprocessing` module was introduced in Python 2.6, and it has been a
    game changer when it comes to working with multiple processes in Python. Specifically,
    it has made it rather easy to work around the limitations of the GIL because each
    process has its own GIL.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块在Python 2.6中被引入，它在处理Python中的多个进程方面是一个游戏规则的改变。具体来说，它使得绕过GIL的限制变得相当容易，因为每个进程都有自己的GIL。'
- en: The usage of the `multiprocessing` module is largely similar to the `threading`
    module, but it has several really useful extra features that make much more sense
    with multiple processes. Alternatively, you can also use it with `concurrent.futures.ProcessPoolExecutor`,
    which has an interface nearly identical to `concurrent.futures.ThreadPoolExecutor`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块的使用在很大程度上与`threading`模块相似，但它有几个非常有用的额外功能，这些功能在多进程中使用时更有意义。或者，你也可以使用`concurrent.futures.ProcessPoolExecutor`，它的接口几乎与`concurrent.futures.ThreadPoolExecutor`相同。'
- en: These similarities mean that in many cases you can simply swap out the modules
    and your code will keep running as expected. Don’t be fooled, however; while threads
    can still use the same memory objects and only have thread safety and deadlocks
    to worry about, multiple processes also have these issues and introduce several
    other issues when it comes to sharing memory, objects, and results.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些相似之处意味着在许多情况下，你可以简单地替换模块，你的代码仍然会按预期运行。然而，不要被误导；尽管线程仍然可以使用相同的内存对象，并且只需要担心线程安全和死锁，但多个进程也存在这些问题，并且在共享内存、对象和结果时还会引入其他问题。
- en: In either case, dealing with parallel code comes with caveats. This is also
    why code that uses multiple threads or processes has the reputation of being difficult
    to work with. Many of these issues are not as daunting as they might seem; if
    you follow a few rules, that is.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，处理并行代码都伴随着注意事项。这也是为什么使用多个线程或进程的代码有难以工作的声誉。许多这些问题并不像看起来那么可怕；如果你遵循一些规则，那就是了。
- en: Before we continue with the example code, you should be aware that it is critically
    important to have your code in an `if` `__name__ == '__main__'` block when using
    `multiprocessing`. When the `multiprocessing` module launches the extra Python
    processes, it will execute the same Python script, so without using this block
    you will end up with an infinite loop of starting processes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续示例代码之前，你应该意识到，在使用`multiprocessing`时，将你的代码放在`if __name__ == '__main__'`块中至关重要。当`multiprocessing`模块启动额外的Python进程时，它将执行相同的Python脚本，所以如果不使用这个块，你将陷入无限循环的启动进程。
- en: 'Within this section, we are going to cover:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍：
- en: Basic examples using `threading`, `multiprocessing`, and `concurrent.futures`
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `threading`、`multiprocessing` 和 `concurrent.futures` 的基本示例
- en: Cleanly exiting threads and processes
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清洁退出线程和进程
- en: Batch processing
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批处理
- en: Sharing memory between processes
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在进程间共享内存
- en: Thread safety
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程安全性
- en: Deadlocks
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 死锁
- en: Thread-local variables
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程局部变量
- en: Several of these, such as race conditions and locking, are not exclusive to
    threading and could be interesting for `multiprocessing` as well.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些，如竞态条件和锁定，不仅限于线程，对`multiprocessing`也可能很有趣。
- en: Basic examples
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本示例
- en: 'To create threads and processes, we have several options:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建线程和进程，我们有几种选择：
- en: '`concurrent.futures`: An easy-to-use interface for running functions in either
    threads or processes, similar to `asyncio`'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`concurrent.futures`：一个易于使用的接口，用于在线程或进程中运行函数，类似于`asyncio`'
- en: '`threading`: An interface for creating threads directly'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threading`：一个用于直接创建线程的接口'
- en: '`multiprocessing`: An interface with many utility and convenience functions
    to create and manage multiple Python processes'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multiprocessing`：一个具有许多实用和便利函数的接口，用于创建和管理多个Python进程'
- en: Let’s look at an example of each one.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看每个示例。
- en: concurrent.futures
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: concurrent.futures
- en: 'Let’s start with a basic example of the `concurrent.futures` module. In this
    example, we run two timer jobs that run and print in parallel:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从`concurrent.futures`模块的基本示例开始。在这个例子中，我们运行了两个并行运行和打印的计时器任务：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Before we execute the code, let’s see what we did here. First, we created a
    `timer` function that runs `time.sleep(interval)` and does that `steps` times.
    Before sleeping, it prints the `name` and the current `step` so we can easily
    see what is happening.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们执行代码之前，让我们看看我们在这里做了什么。首先，我们创建了一个`timer`函数，该函数运行`time.sleep(interval)`并执行`steps`次。在休眠之前，它打印出`name`和当前的`step`，这样我们就可以轻松地看到发生了什么。
- en: Then, we create an `executor` using `concurrent.futures.ThreadPoolExecutor`
    to execute the functions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`concurrent.futures.ThreadPoolExecutor`创建一个`executor`来执行函数。
- en: Lastly, we submit the functions we want to execute with their respective arguments
    to start both of the threads. In between starting them, we sleep a very short
    time so our output in this example is consistent. If we were to execute the code
    without the `time.sleep(0.1)`, the output order would be random because sometimes
    `a` would be faster and other times `b` would be faster.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将要执行的函数及其相应的参数提交以启动两个线程。在启动它们之间，我们休眠了很短的时间，所以在这个例子中我们的输出是一致的。如果我们不执行`time.sleep(0.1)`，输出顺序将是随机的，因为有时`a`会更快，而有时`b`会更快。
- en: The main reason for including the tiny sleep is testing. All of the code in
    this book is available on GitHub ([https://github.com/mastering-python/code_2](https://github.com/mastering-python/code_2))
    and is automatically tested.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 包含短暂休眠的主要原因是测试。本书中的所有代码都可在GitHub上找到（[https://github.com/mastering-python/code_2](https://github.com/mastering-python/code_2)），并且会自动进行测试。
- en: 'Now when executing this script, we get the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在当我们执行这个脚本时，我们得到以下结果：
- en: '[PRE1]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As expected, they run right next to each other, but due to the tiny `time.sleep(0.1)`
    we added, the results are consistently interleaved. In this case we started the
    `ThreadPoolExecutor` with the default arguments, which results in threads without
    specific names and an automatically calculated thread count.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，它们紧挨着运行，但由于我们添加了微小的`time.sleep(0.1)`，结果是一致地交织在一起。在这种情况下，我们使用默认参数启动了`ThreadPoolExecutor`，这导致没有特定名称的线程和自动计算的线程数。
- en: The thread count depends on the Python version. Up to Python 3.8, the number
    of workers was equal to the number of hyper-threaded CPU cores in the machine
    multiplied by 5\. So, if your machine has 2 cores with hyper-threading enabled,
    it would result in 4 cores * 5 = 20 threads. With a 64-core machine, that would
    result in 320 threads, which would probably incur more synchronization overhead
    than benefits.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 线程数取决于Python版本。在Python 3.8之前，工作进程的数量等于机器中超线程CPU核心的数量乘以5。因此，如果你的机器有2个启用超线程的核心，那么结果将是4个核心
    * 5 = 20个线程。对于64核的机器，这将导致320个线程，这可能会产生比好处更多的同步开销。
- en: For Python 3.8 and above, this has been changed to `min(32, cores + 4)`, which
    should be enough to always have at least 5 threads for I/O operations but not
    so much that it uses large amounts of resources on machines with many cores. For
    the same `64`-core machine, this would still be capped at `32` threads.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Python 3.8及以上版本，这已被更改为`min(32, cores + 4)`，这应该足以始终至少有5个线程用于I/O操作，但不会太多以至于在多核机器上使用大量资源。对于相同的`64`核机器，这仍然限制在`32`个线程。
- en: In the case of the `ProcessPoolExecutor`, the number of processor cores including
    hyper-threading will be used. That means that if your processor has 4 cores with
    hyper-threading enabled, you will get a default of 8 processes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `ProcessPoolExecutor` 的情况下，将使用包括超线程在内的处理器核心数。这意味着如果您的处理器有4个核心并且启用了超线程，您将默认获得8个进程。
- en: Naturally, the traditional `threading` module is still a good option and offers
    a bit more control while still having an easy-to-use interface.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，传统的 `threading` 模块仍然是一个不错的选择，它提供了更多的控制，同时仍然拥有易于使用的接口。
- en: Before Python 3, the `thread` module was also available as a low-level API to
    threads. This module is still available but renamed to `_thread`. Internally,
    both `concurrent.futures.ThreadPoolExecutor` and `threading` are still using it,
    but you should generally have no need to access it directly.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python 3之前，`thread` 模块也作为线程的低级API可用。此模块仍然可用，但已重命名为 `_thread`。在内部，`concurrent.futures.ThreadPoolExecutor`
    和 `threading` 都仍然使用它，但您通常不需要直接访问它。
- en: threading
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: threading
- en: 'Now we will look at how to recreate the `concurrent.futures` example using
    the `threading` module:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看看如何使用 `threading` 模块重新创建 `concurrent.futures` 的示例：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `timer` function is identical to the previous example, so no difference
    there. The execution, however, is a bit different.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`timer` 函数与前面的示例相同，所以这里没有差异。但是，执行方式略有不同。'
- en: In this case we create the threads by instantiating `threading.Thread()` directly,
    but inheriting `threading.Thread` is also an option, as we will see in the next
    example. The arguments to the `target` function can be given by passing an `args`
    and/or `kwargs` argument, but these are optional if you have no need for them
    or if you have prefilled them using `functools.partial`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们通过直接实例化 `threading.Thread()` 来创建线程，但继承 `threading.Thread` 也是一个选项，正如我们将在下一个示例中看到的。可以传递
    `args` 和/或 `kwargs` 参数来提供 `target` 函数的参数，但如果您不需要它们或者已经使用 `functools.partial` 填充了它们，则这些参数是可选的。
- en: With the earlier example, we created a `ThreadPoolExecutor()` that creates a
    bunch of threads and runs the functions on those threads. With this example, we
    are explicitly creating the threads to run a single function and exit as soon
    as the function is done. This is mostly useful for long-running backgrounded threads
    as this method requires setting up and tearing down a thread for each function.
    Generally, the overhead of starting a thread is very little, but it depends on
    your Python interpreter (CPython, PyPy, and so on) and your operating system.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们创建了一个 `ThreadPoolExecutor()`，它会创建许多线程并在这些线程上运行函数。在这个示例中，我们明确创建线程来运行单个函数并在函数完成后退出。这对于长时间运行的背景线程非常有用，因为这个方法需要为每个函数设置和拆除线程。通常，启动线程的开销非常小，但它取决于您的Python解释器（CPython、PyPy等）和操作系统。
- en: 'Now for the same example, but inheriting `threading.Thread` instead of a declarative
    call to `threading.Thread()`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在对于相同的示例，但继承 `threading.Thread` 而不是对 `threading.Thread()` 的声明性调用：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The code is roughly the same as the procedural version where we called `threading.Thread()`
    directly, but there are two critical differences that you need to be aware of:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 代码大致与直接调用 `threading.Thread()` 的过程式版本相同，但有两大关键差异您需要注意：
- en: '`name` is a reserved attribute for `threading.Thread`. On Linux/Unix machines
    your process manager (for instance, `top`) can display this name instead of `/usr/bin/python3`.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name` 是 `threading.Thread` 的一个保留属性。在Linux/Unix机器上，您的进程管理器（例如，`top`）可以显示此名称而不是
    `/usr/bin/python3`。'
- en: The default target function is `run()`. Be careful to override the `run()` method
    instead of the `start()` method, otherwise your code will *not* execute in a separate
    thread but will execute like a regular function call when you call `start()` instead.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认的目标函数是 `run()`。请小心覆盖 `run()` 方法而不是 `start()` 方法，否则当您调用 `start()` 时，您的代码将*不会*在单独的线程中执行，而将像常规函数调用一样执行。
- en: The procedural and class-based versions use the exact same API internally and
    are equally powerful, so choosing between them comes down to personal preference
    only.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 过程式和基于类的版本在内部使用完全相同的API，并且同样强大，因此选择它们主要取决于个人偏好。
- en: multiprocessing
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: multiprocessing
- en: 'Lastly, we can recreate the earlier timer scripts using `multiprocessing` as
    well. First with the procedural call to `multiprocessing.Process()`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们也可以使用 `multiprocessing` 来重新创建早期的定时器脚本。首先是通过 `multiprocessing.Process()`
    的过程调用：
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The code looks effectively the same with a few minor changes. Instead of `threading.Thread`
    we used `multiprocessing.Process`, and we have to run the code from an `if __name__
    == '__main__'` block. Beyond that, both the code and execution are the same in
    this simple example.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 代码看起来几乎相同，只有一些小的变化。我们使用了`multiprocessing.Process`而不是`threading.Thread`，并且我们必须从`if
    __name__ == '__main__'`块中运行代码。除此之外，在这个简单的例子中，代码和执行都是相同的。
- en: 'Lastly, for completeness, let’s look at the class-based version as well:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了完整性，让我们也看看基于类的版本：
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Once again, we are required to use the `if __name__ == '__main__'` block. But
    beyond that, the code is virtually identical to the `threading` version. As was
    the case with `threading`, choosing between the procedural and class-based style
    depends only on your personal preference.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我们必须使用`if __name__ == '__main__'`块。但除此之外，代码与`threading`版本几乎相同。就像`threading`一样，选择过程式和基于类的风格仅取决于你个人的偏好。
- en: Now that we know how to start threads and processes, let’s look at how we can
    cleanly shut them down again.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何启动线程和进程，让我们看看我们如何可以干净地关闭它们。
- en: Cleanly exiting long-running threads and processes
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清理退出长时间运行的线程和进程
- en: 'The `threading` module is mostly useful for long-running threads that handle
    an external resource. Some example scenarios:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`threading`模块主要用于处理外部资源的长时间运行的线程。一些示例场景：'
- en: When creating a server and you want to keep listening for new connections
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当创建服务器并希望持续监听新的连接
- en: When connecting to HTTP WebSockets and you need the connection to stay open
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当连接到HTTP WebSockets并且需要保持连接打开时
- en: When you need to periodically save your changes
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你需要定期保存你的更改
- en: Naturally, these scenarios can also use `multiprocessing`, but `threading` is
    often more convenient, as we will see later.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，这些场景也可以使用`multiprocessing`，但`threading`通常更方便，我们将在后面看到。
- en: At some point you might need to shut the thread down from **outside** of the
    thread; during the exit of your main script, for example. Waiting for a thread
    that is exiting by itself is trivial; the only thing you need to do is `future.result()`
    or `some_thread.join(timeout=...)` and you are done. The harder part is telling
    a thread to shut itself down and run the cleanup while it’s still doing something.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时候，你可能需要从**外部**关闭线程；例如，在主脚本的退出过程中。等待自行退出的线程是微不足道的；你需要做的只是`future.result()`或`some_thread.join(timeout=...)`，然后你就完成了。更困难的部分是告诉线程自行关闭并在它仍在做某事时运行清理。
- en: 'The only real solution for this issue, which applies if you are lucky, is a
    simple `while` loop that keeps running until you give a stop signal like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的唯一真正的方法，如果你幸运的话，是一个简单的`while`循环，它会一直运行，直到你给出停止信号，如下所示：
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This code uses `threading.Event()` as a flag to tell the thread to exit when
    needed. While you can use a `bool` instead of `threading.Event()` with the current
    CPython interpreter, there is no guarantee for this to work with future Python
    versions and/or other types of interpreters. The reason this is currently safe
    for CPython is that, due to the GIL, all Python operations are effectively single-threaded.
    That’s why threads are useful for waiting for external resources, but have a negative
    effect on the performance of your Python code.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用`threading.Event()`作为标志来告诉线程在需要时退出。虽然你可以使用`bool`代替`threading.Event()`与当前的CPython解释器一起使用，但无法保证这将在未来的Python版本和/或其他类型的解释器中工作。目前这之所以对CPython来说是安全的，是因为由于GIL，所有Python操作实际上都是单线程的。这就是为什么线程对于等待外部资源很有用，但会对你的Python代码的性能产生负面影响。
- en: Additionally, if you were to translate this code to multiprocessing, you could
    simply replace `threading.Event()` with `multiprocessing.Event()` and it should
    keep working with no other changes, assuming you are not interacting with external
    variables. With multiple Python processes, you are no longer protected by the
    single GIL so you need to be more careful when modifying variables. More about
    this topic in the *Sharing data between threads and processes* section later in
    this chapter.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果你要将此代码翻译成多进程，你可以简单地用`multiprocessing.Event()`替换`threading.Event()`，并且它应该在没有其他更改的情况下继续工作，假设你没有与外部变量交互。在多个Python进程中，你不再受到单个GIL的保护，因此在修改变量时需要更加小心。关于这个话题的更多内容将在本章后面的*线程和进程间共享数据*部分中介绍。
- en: Now that we have the `stop` event, we can run `stop.set()` so the thread knows
    when to exit and will do so after the maximum of 0.1 seconds’ sleep.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了`stop`事件，我们可以运行`stop.set()`，这样线程就知道何时退出，并在最多0.1秒的睡眠后退出。
- en: 'This is the ideal scenario: to have a loop where the loop condition is checked
    regularly and the loop interval is your maximum thread shutdown delay. What happens
    if the thread is busy doing some operation and doesn’t check the `while` condition?
    As you might suspect, setting the `stop` event is useless in those scenarios and
    you need a more powerful method to exit the thread.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个理想的场景：有一个循环，循环条件会定期检查，循环间隔是你的最大线程关闭延迟。如果线程正忙于执行某些操作而没有检查`while`条件会发生什么？正如你可能猜到的，在这些场景中设置`stop`事件是无用的，你需要一个更强大的方法来退出线程。
- en: 'To handle this scenario, you have a few options:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这种场景，你有几种选择：
- en: Avoid the issue entirely by using `asyncio` or `multiprocessing` instead. In
    terms of performance, `asyncio` is your best option by far, but `multiprocessing`
    can work as well if your code is suitable.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用`asyncio`或`multiprocessing`来完全避免这个问题。在性能方面，`asyncio`无疑是你的最佳选择，但如果你的代码适合，`multiprocessing`也可以工作得很好。
- en: Make the thread a daemon thread by setting `your_thread.daemon = True` *before*
    starting the thread. This will automatically kill the thread when the main process
    exits so it is not a graceful shutdown. You can still add a teardown using the
    `atexit` module.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在启动线程之前将`your_thread.daemon = True`设置为守护线程。这样，当主进程退出时，线程会自动终止，因此这不是一个优雅的关闭。你仍然可以使用`atexit`模块添加拆卸。
- en: Kill the thread from the outside by either telling your operating system to
    send a terminate/kill signal or by raising an exception within the thread from
    the main thread. You might be tempted to go for this method, but I would strongly
    recommend against it. Not only is it unreliable, but it can cause your entire
    Python interpreter to crash, so it really is not an option you should ever consider.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过告诉操作系统发送终止/杀死信号或在主线程中从线程内部抛出异常来从外部杀死线程。你可能想尝试这种方法，但我强烈建议不要这样做。这不仅不可靠，还可能导致你的整个Python解释器崩溃，所以这绝对不是你应该考虑的选项。
- en: We have already seen how to use `asyncio` in the previous chapter, so let’s
    look at how we can terminate with `multiprocessing`. Before we start, however,
    you should note that the same limitations that apply to `threading` also largely
    apply to `multiprocessing`. While `multiprocessing` does have a built-in solution
    for terminating processes as opposed to threading, it is still not a clean method
    and it won’t (reliably) run your exit handlers, `finally` clauses, and so on.
    This means you should *always* try an event first, but use `multiprocessing.Event`
    instead of `threading.Event`, of course.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在上一章中看到了如何使用`asyncio`，所以让我们看看我们如何使用`multiprocessing`来终止。然而，在我们开始之前，你应该注意，适用于`threading`的限制在很大程度上也适用于`multiprocessing`。虽然`multiprocessing`确实有一个内置的终止进程的解决方案，与线程不同，但这仍然不是一个干净的方法，它也不会（可靠地）运行你的退出处理程序、`finally`子句等。这意味着你应该*始终*首先尝试一个事件，但当然使用`multiprocessing.Event`而不是`threading.Event`。
- en: 'To illustrate how we can forcefully terminate or kill a thread (while risking
    memory corruption):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明我们如何强制终止或杀死一个线程（同时冒着内存损坏的风险）：
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In this example, we first try a regular `terminate()`, which sends a `SIGTERM`
    signal on Unix machines and `TerminateProcess()` on Windows. If that does not
    work, we try again with a `kill()`, which sends a `SIGKILL` on Unix and does not
    currently have a Windows equivalent, so on Windows the `kill()` and `terminate()`
    methods behave the same way and both effectively kill the process without teardown.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们首先尝试一个常规的`terminate()`，它在Unix机器上发送`SIGTERM`信号，在Windows上是`TerminateProcess()`。如果那不起作用，我们再次尝试使用`kill()`，它在Unix上发送`SIGKILL`信号，目前在Windows上没有等效的信号，所以在Windows上`kill()`和`terminate()`方法的行为相同，并且两者都有效地终止了进程而没有进行拆卸。
- en: Batch processing using concurrent.futures
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用`concurrent.futures`进行批处理
- en: Starting threads or processes in a fire-and-forget fashion is easy enough, as
    we have seen in the prior examples. However, often, you want to spin up several
    threads or processes and wait until they have all finished.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在先前的例子中所见，以“点火并忘记”的方式启动线程或进程是足够简单的。然而，通常，你想要启动几个线程或进程，并等待它们全部完成。
- en: This is a case where `concurrent.futures` and `multiprocessing` really shine.
    They allow you to call `executor.map()` or `pool.map()` very similarly to how
    we saw in *Chapter 5*, *Functional Programming – Readability Versus Brevity*.
    Effectively, you only need to create a list of items to process, call the `[executor/pool].map()`
    function, and you are done. You could build something similar with the `threading`
    module if you are looking for a fun challenge, but there is little use for it
    otherwise.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个`concurrent.futures`和`multiprocessing`真正闪耀的案例。它们允许您以与我们在第5章中看到的方式非常相似地调用`executor.map()`或`pool.map()`，即*第五章*，*函数式编程
    – 可读性与简洁性之间的权衡*。实际上，您只需要创建一个要处理的项目列表，调用`[executor/pool].map()`函数，就完成了。如果您想找点乐子，可以使用`threading`模块构建类似的东西，但除此之外，它的用途很少。
- en: 'To give our system a test, let’s get some information about a hostname that
    should use the system DNS resolving system. Since that queries an external resource,
    we should expect nice results when using threading, right? Well... let’s give
    it a try and have a look:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的系统，让我们获取一些关于应该使用系统DNS解析系统的主机名的信息。由于它查询外部资源，我们使用线程时应该期待良好的结果，对吧？好吧...让我们试一试，看看结果如何：
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Let’s analyze this code. First, we have the `getaddrinfo()` function, which
    attempts to fetch some info about a hostname through your operating system, an
    external resource that could benefit from multiple threads.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下这段代码。首先，我们有一个`getaddrinfo()`函数，它尝试通过您的操作系统获取关于主机名的一些信息，这是一个可能从多线程中受益的外部资源。
- en: Second, we have the `benchmark()` function, which uses multiple threads for
    the `map()` if `threads` is set to a number above 1\. If not, it goes for the
    regular `map()`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，我们有一个`benchmark()`函数，如果`threads`设置为大于1的数字，它将使用多个线程进行`map()`。如果没有，它将使用常规的`map()`。
- en: 'Lastly, we execute the benchmarks for `1`, `10`, `50`, and `100` threads where
    `1` is the regular non-threaded approach. So how much can threads help us here?
    This test strongly depends on your computer, operating system, network, etc.,
    so your results may be different, but this is what happened on my OS X machine
    using CPython 3.10:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们对`1`、`10`、`50`和`100`个线程进行了基准测试，其中`1`是常规的非线程方法。那么线程能帮我们多少呢？这个测试强烈依赖于您的计算机、操作系统、网络等，所以您的结果可能会有所不同，但这是我使用CPython
    3.10在我的OS X机器上发生的情况：
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Did you expect those results? While `1` thread is indeed slower than `10` threads
    and `50` threads, at `100` we are clearly seeing the diminishing returns and the
    overhead of having `100` threads. Also, the benefit of using multiple threads
    is rather limited here due to `socket.getaddrinfo()` being pretty fast.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您期待这些结果吗？虽然`1`个线程确实比`10`个线程和`50`个线程慢，但在`100`个线程时，我们明显看到了收益递减和拥有`100`个线程的开销。此外，由于`socket.getaddrinfo()`相当快，使用多线程的好处在这里相当有限。
- en: 'If we were to read a whole bunch of files from a slow networked filesystem
    or if we were to use it to fetch multiple webpages in parallel, we would see a
    much larger difference. That immediately shows the downside of threading: it only
    gives you a benefit if the external resource is slow enough to warrant the synchronization
    overhead. With a fast external resource, you are likely to experience slowdowns
    instead because the GIL becomes the bottleneck. CPython can only execute a single
    statement at once so that can quickly become problematic.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从慢速网络文件系统读取大量文件，或者如果我们用它来并行获取多个网页，我们会看到更大的差异。这立即显示了线程的缺点：它只有在外部资源足够慢，以至于同步开销是合理的时才会带来好处。对于快速的外部资源，您可能会遇到减速，因为全局解释器锁（GIL）成为了瓶颈。CPython一次只能执行一个语句，这可能会迅速变成问题。
- en: When it comes to performance, you should always run a benchmark to see what
    works best for your case, especially when it comes to thread count. As you saw
    in the earlier example, more is not always better and the 100-thread version is
    many times slower than even the single-threaded version.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到性能时，您应该始终运行基准测试以查看最适合您情况的方法，尤其是在线程数量方面。正如您在早期示例中看到的，更多并不总是更好，100线程版本比单线程版本慢得多。
- en: 'So, what if we try the same using processes instead of threads? For brevity,
    we will skip the actual code since we effectively only need to swap out `concurrent.futures.ThreadPoolExecutor()`
    with `concurrent.futures.ProcessPoolExecutor()` and we are done. The tested code
    can be found on GitHub if you are interested. When we execute that code, we get
    these results:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果我们尝试使用进程而不是线程来执行相同的操作会怎样呢？为了简洁起见，我们将跳过实际的代码，因为我们实际上只需要将 `concurrent.futures.ThreadPoolExecutor()`
    替换为 `concurrent.futures.ProcessPoolExecutor()`，然后我们就完成了。如果你感兴趣，测试的代码可以在 GitHub
    上找到。当我们执行这段代码时，我们得到以下结果：
- en: '[PRE10]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you can see, we got universally slower results when using multiple processes.
    While multiprocessing can offer a lot of benefit when the GIL or a single CPU
    core is the limit, the overhead can cost you performance in other scenarios.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，当我们使用多个进程时，我们得到了普遍较慢的结果。虽然多进程在 GIL 或单个 CPU 核心是限制时可以提供很多好处，但开销可能会在其他场景中影响你的性能。
- en: Batch processing using multiprocessing
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用多进程进行批量处理
- en: 'In the previous section, we saw how we can use `concurrent.futures` to do batch
    processing. You might be wondering why we would want to use `multiprocessing`
    directly if `concurrent.futures` can handle it for us. The reason is rather simple:
    `concurrent.futures` is an easy-to-use and very simple interface to both `threading`
    and `multiprocessing`, but `multiprocessing` offers several advanced options that
    can be very convenient and can even help your performance in some scenarios.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到了如何使用 `concurrent.futures` 进行批量处理。你可能想知道为什么我们想要直接使用 `multiprocessing`，而不是
    `concurrent.futures` 可以为我们处理它。原因相当简单：`concurrent.futures` 是一个易于使用且非常简单的接口，用于 `threading`
    和 `multiprocessing`，但 `multiprocessing` 提供了几个高级选项，这些选项可以非常方便，甚至可以在某些场景中帮助提高你的性能。
- en: 'In the previous examples we only saw `multiprocessing.Process`, which is the
    process analog to `threading.Thread`. In this case, however, we will be using
    `multiprocessing.Pool`, which creates a process pool very similar to the `concurrent.futures`
    executors but offers several additional features:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的例子中，我们只看到了 `multiprocessing.Process`，它是 `threading.Thread` 的进程类似物。然而，在这种情况下，我们将使用
    `multiprocessing.Pool`，它创建了一个与 `concurrent.futures` 执行器非常相似的进程池，但提供了几个额外的功能：
- en: '`map_async(func, iterable, [..., callback, ...])`'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`map_async(func, iterable, [..., callback, ...])`'
- en: The `map_async()` method is similar to the `map()` method in `concurrent.futures`,
    but instead of blocking it returns a list of `AsyncResult` objects so you can
    fetch the results when you need them.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`map_async()` 方法与 `concurrent.futures` 中的 `map()` 方法相似，但它返回一个 `AsyncResult`
    对象的列表，这样你就可以在你需要的时候获取结果。'
- en: '`imap(func, iterable[, chunksize])`'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imap(func, iterable[, chunksize])`'
- en: The `imap()` method is effectively the generator version of `map()`. It works
    in roughly the same way, but it doesn’t preload the items from the iterable so
    you can safely process large iterables if needed. This can be *much* faster if
    you need to process many items.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`imap()` 方法实际上是 `map()` 的生成器版本。它的工作方式大致相同，但它不会预先加载可迭代对象中的项，因此如果你需要，可以安全地处理大型可迭代对象。如果你需要处理许多项，这可以
    *大大* 提高速度。'
- en: '`imap_unordered(func, iterable[, chunksize])`'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imap_unordered(func, iterable[, chunksize])`'
- en: The `imap_unordered()` method is effectively the same as `imap()` except that
    it returns the results as soon as they are processed, which can improve performance
    even further. If the order of your results is of no importance to you, give it
    a try as it can make your code even faster.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`imap_unordered()` 方法实际上与 `imap()` 相同，但它会在处理完结果后立即返回结果，这可以进一步提高性能。如果你的结果顺序不重要，可以尝试一下，因为它可以使你的代码更快。'
- en: '`starmap(func, iterable[, chunksize])`'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`starmap(func, iterable[, chunksize])`'
- en: The `starmap()` method is very similar to the `map()` method, but supports multiple
    arguments by passing them like `*args`. If you were to run `starmap(function,
    [(1, 2), (3, 4)])`, the `starmap()` method would call `function(1, 2)` and `function(3,
    4)`. This can be really useful in conjunction with `zip()` to combine several
    lists of arguments.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`starmap()` 方法与 `map()` 方法非常相似，但通过像 `*args` 这样的方式支持多个参数。如果你要运行 `starmap(function,
    [(1, 2), (3, 4)])`，`starmap()` 方法将调用 `function(1, 2)` 和 `function(3, 4)`。这在与 `zip()`
    结合使用时可以非常实用，以组合多个参数列表。'
- en: '`starmap_async(func, iterable, [..., callback, ...])`'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`starmap_async(func, iterable, [..., callback, ...])`'
- en: As you can imagine, `starmap_async()` is effectively the non-blocking `starmap()`
    method, but it returns a list of `AsyncResult` objects so you can fetch them at
    your convenience.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所想，`starmap_async()` 实际上是非阻塞的 `starmap()` 方法，但它返回一个 `AsyncResult` 对象的列表，这样你就可以在你方便的时候获取它们。
- en: 'The usage of `multiprocessing.Pool()` is largely analogous to `concurrent.future.SomeExecutor()`
    beyond the extra methods mentioned above. Depending on your scenario, it can be
    slower, a similar speed, or faster than `concurrent.futures`, so always make sure
    to benchmark for your specific use case. This little bit of benchmark code should
    give you a nice starting point:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.Pool()`的使用在很大程度上类似于`concurrent.future.SomeExecutor()`，除了上面提到的额外方法之外。根据你的场景，它可能比`concurrent.futures`慢，速度相似，或者更快，所以总是确保为你的特定用例进行基准测试。以下这段基准代码应该会给你一个很好的起点：'
- en: '[PRE11]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'On my machine, this gives the following results:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的机器上，这给出了以下结果：
- en: '[PRE12]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Before I benchmarked this, I was not expecting `concurrent.futures` to be that
    much faster in some cases and that much slower in other cases. Analyzing these
    results, you can see that processing 1,000 items with `concurrent.futures` took
    more time than processing 10,000 items with multiprocessing in this particular
    case. Similarly, for 100 items the `multiprocessing` module was nearly twice as
    slow. Naturally, every run yields different results and there is not a single
    option that will perform well for every scenario, but it is something to keep
    in mind.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在我进行基准测试之前，我没有预料到`concurrent.futures`在某些情况下会快得多，而在其他情况下会慢得多。分析这些结果，你可以看到，使用`concurrent.futures`处理1,000个项目比在这个特定情况下使用多进程处理10,000个项目花费的时间要多。同样，对于100个项目，`multiprocessing`模块几乎慢了两倍。自然地，每次运行都会产生不同的结果，并且没有单一的选项会在每种情况下都表现良好，但这是需要记住的。
- en: Now that we know how to run our code in multiple threads or processes, let’s
    look at how we can safely share data between the threads/processes.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何在多个线程或进程中运行我们的代码，让我们看看我们如何安全地在线程/进程之间共享数据。
- en: Sharing data between threads and processes
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线程和进程之间共享数据
- en: 'Data sharing is really the most difficult part about multiprocessing, multithreading,
    and distributed programming in general: which data to pass along, which data to
    share, and which data to skip. The theory is really simple, however: whenever
    possible, don’t transfer any data, don’t share any data, and keep everything local.
    This is essentially the **functional programming** paradigm, which is why functional
    programming mixes really well with multiprocessing. In practice, regrettably,
    this is simply not always possible. The `multiprocessing` library has several
    options to share data, but internally they break down to two different options:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 数据共享实际上是关于多进程、多线程以及一般分布式编程中最困难的部分：要传递哪些数据，要共享哪些数据，以及要跳过哪些数据。然而，理论实际上非常简单：尽可能不要传输任何数据，不要共享任何数据，并保持一切局部。这本质上就是**函数式编程**范式，这也是为什么函数式编程与多进程结合得如此之好的原因。在实践中，遗憾的是，这并不总是可能的。`multiprocessing`库提供了几个共享数据的选择，但内部它们归结为两种不同的选项：
- en: '**Shared memory**: This is by far the fastest solution since it has very little
    overhead, but it can only be used for immutable types and is restricted to a select
    few types and custom objects that are created through `multiprocessing.sharedctypes`.
    This is a fantastic solution if you only need to store primitive types such as
    `int`, `float`, `bool`, `str`, `bytes`, and/or fixed-sized lists or dicts (where
    the children are primitives).'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享内存**：这是迄今为止最快的解决方案，因为它几乎没有开销，但它只能用于不可变类型，并且仅限于通过`multiprocessing.sharedctypes`创建的少数几种类型和自定义对象。如果你只需要存储原始类型，如`int`、`float`、`bool`、`str`、`bytes`以及/或固定大小的列表或字典（其中子项是原始类型），这是一个极好的解决方案。'
- en: '`multiprocessing.Manager`: The `Manager` classes offer a host of different
    options for storing and synchronizing data, such as locks, semaphores, queues,
    lists, dicts, and several others. If it can be pickled, it can work with a manager.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multiprocessing.Manager`：`Manager`类提供了一系列存储和同步数据的选择，例如锁、信号量、队列、列表、字典等。如果可以序列化，就可以与`Manager`一起使用。'
- en: 'For threading, the solution is even easier: all memory is shared so, by default,
    all objects are available from every thread. There is an exception called a thread-local
    variable, which we will see later.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线程，解决方案甚至更简单：所有内存都是共享的，因此默认情况下，所有对象都可以从每个线程中访问。有一个例外称为线程局部变量，我们稍后会看到。
- en: Sharing memory brings its own caveats, however, as we will see in the *Thread
    safety* section in the case of `threading`. Since multiple threads and/or processes
    can write to the same piece of memory at the same time, this is an inherently
    risky operation. At best, your changes can become lost due to conflicting writes;
    at worst, your memory could become corrupted, which could even result in a crashing
    interpreter. Luckily, Python is pretty good at protecting you, so if you are not
    doing anything too exotic you do not have to worry about crashing your interpreter.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，共享内存有其自身的注意事项，正如我们将在“线程安全”部分看到的那样，在`threading`的情况下。由于多个线程和/或进程可以同时写入同一块内存，这是一个固有的风险操作。最坏的情况是，您的更改可能会因为冲突的写入而丢失；最坏的情况是，您的内存可能会损坏，这甚至可能导致解释器崩溃。幸运的是，Python在保护您方面做得相当不错，所以如果您没有做任何太特别的事情，您不必担心解释器崩溃。
- en: Shared memory between processes
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进程间的共享内存
- en: 'Python offers several different structures to make memory sharing between processes
    a safe operation:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Python提供了几种不同的结构来确保进程间内存共享的安全性：
- en: '`multiprocessing.Value`'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multiprocessing.Value`'
- en: '`multiprocessing.Array`'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multiprocessing.Array`'
- en: '`multiprocessing.shared_memory.SharedMemory`'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multiprocessing.shared_memory.SharedMemory`'
- en: '`multiprocessing.shared_memory.ShareableList`'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multiprocessing.shared_memory.ShareableList`'
- en: Let’s dive into a few of these types to demonstrate how to use them.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解这些类型中的一些，以演示如何使用它们。
- en: For sharing primitive values, you can use `multiprocessing.Value` and `multiprocessing.Array`.
    These are essentially the same, but with `Array` you can store multiple values
    whereas `Value` is just a single value. As arguments, these expect a typecode
    identical to how the `array` module works in Python, which means they map to C
    types. This results in `d` as a double (floating point) number, `i` as a signed
    integer, `b` as a signed char, etc.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 对于共享原始值，您可以使用`multiprocessing.Value`和`multiprocessing.Array`。它们基本上是相同的，但`Array`可以存储多个值，而`Value`只是一个单个值。作为参数，它们期望一个与Python中`array`模块工作方式相同的typecode，这意味着它们映射到C类型。这导致`d`是一个双精度（浮点）数字，`i`是一个有符号整数，`b`是一个有符号字符等。
- en: 'For more options, look at the documentation for the `array` module: [https://docs.python.org/3/library/array.html](https://docs.python.org/3/library/array.html).'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更多选项，请查看`array`模块的文档：[https://docs.python.org/3/library/array.html](https://docs.python.org/3/library/array.html)。
- en: For more advanced types, you can take a look at the `multiprocessing.sharedctypes`
    module, which is also where the `Value` and `Array` classes originate from.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更高级的类型，您可以查看`multiprocessing.sharedctypes`模块，这也是`Value`和`Array`类起源的地方。
- en: 'Both `multiprocessing.Value` and `multiprocessing.Array` are not difficult
    to use, but they do not feel very Pythonic to me:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.Value`和`multiprocessing.Array`都不难使用，但它们在我看来并不非常Pythonic：'
- en: '[PRE13]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: If you need to share memory and performance is important to you, feel free to
    use them. If possible, however, I would avoid them (or sharing memory at all if
    possible) as the usage is clunky at best.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要共享内存并且性能对您来说很重要，请随意使用它们。然而，如果可能的话，我建议您避免使用它们（或者在可能的情况下避免共享内存），因为其使用起来至少是笨拙的。
- en: 'The `multiprocessing.shared_memory.SharedMemory` object is similar to the `Array`
    but it is a lower-level structure. It offers you an interface to read/write to
    an optionally **named** block of memory so you can access it from other processes
    by name as well. Additionally, when you are done using it you *must* call `unlink()`
    to release the memory:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.shared_memory.SharedMemory`对象类似于`Array`，但它是一个更低级的结构。它为您提供了一个接口，可以读写一个可选的**命名**内存块，这样您也可以通过名称从其他进程访问它。此外，当您使用完毕后，*必须*调用`unlink()`来释放内存：'
- en: '[PRE14]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As we can see in this example, the first call had a `create=True` parameter
    to ask the operating system for memory. Only after that (and before calling `unlink()`)
    can we reference the block from other (or the same) processes.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如此例所示，第一次调用有一个`create=True`参数，用于请求操作系统内存。只有在那时（并且在调用`unlink()`之前），我们才能从其他（或相同的）进程引用该块。
- en: Once again it is not the most Pythonic interface, but it can be effective for
    sharing memory. Since the name is optional and automatically generated otherwise,
    you could omit it from the creation of the shared memory block and read it back
    from `share_a.name`. Also, like the `Array` and `Value` objects, this too has
    a fixed size and cannot be grown without replacing it.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这并不是最Pythonic的接口，但它可以有效地共享内存。由于名称是可选的，否则会自动生成，因此您可以在创建共享内存块时省略它，并从`share_a.name`读取它。同样，像`Array`和`Value`对象一样，它也有一个固定的大小，不能在不替换它的情况下增长。
- en: 'Lastly, we have the `multiprocessing.shared_memory.ShareableList` object. While
    this object is slightly more convenient than `Array` and `SharedMemory` since
    it allows you to be flexible with types (i.e. `item[0]` could be a `str` and `item[1]`
    could be an `int`), it is still a hard-to-use interface and it does not allow
    you to resize it. While you can change the type for the items, you cannot resize
    the object, so swapping out a number with a larger string will not work. At least
    its usage is more Pythonic than the other options:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有 `multiprocessing.shared_memory.ShareableList` 对象。虽然这个对象比 `Array` 和 `SharedMemory`
    略为方便，因为它允许你灵活地处理类型（例如，`item[0]` 可以是 `str`，而 `item[1]` 可以是 `int`），但它仍然是一个难以使用的接口，并且不允许你调整大小。虽然你可以更改项目类型，但不能调整对象的大小，所以用较大的字符串替换数字将不起作用。至少它的使用比其他选项更符合
    Python 风格：
- en: '[PRE15]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Seeing all of these options for sharing memory between processes, should you
    be using them? Yes, if you need high performance, that is.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到这些进程间共享内存的选项后，你应该使用它们吗？是的，如果你需要高性能的话。
- en: It should be a good indication of why it is best to keep memory local with parallel
    processing, however. Sharing memory between processes is a complicated problem
    to solve. Even with these methods, which are the fastest and least complicated
    available, it is a bit of a pain already.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该是一个很好的迹象，为什么在并行处理中最好保持内存局部化。进程间共享内存是一个复杂的问题。即使有这些方法，它们是最快且最简单的，但仍然有点麻烦。
- en: 'So, how much performance impact does memory sharing have? Let’s run a few benchmarks
    to see the difference between sharing a variable and returning it for post-processing.
    First, the version that does not use shared memory as a performance base:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，内存共享对性能的影响有多大？让我们运行一些基准测试来看看共享变量和返回变量进行后处理之间的差异。首先，不使用共享内存作为性能基准的版本：
- en: '[PRE16]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `triangle_number_local()` function calculates the sum of all numbers up
    to and including `n` and returns it, similar to a factorial function but with
    addition instead.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`triangle_number_local()` 函数计算从 `n` 到包括 `n` 在内的所有数字之和，并返回它，类似于阶乘函数，但使用加法代替。'
- en: The `bench_local()` function calls the `triangle_number_local()` function `count`
    times and stores the results. After that, we `sum()` those results to verify the
    output.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`bench_local()` 函数调用 `triangle_number_local()` 函数 `count` 次，并存储结果。之后，我们使用 `sum()`
    函数来验证输出。'
- en: 'Now let’s look at the version using shared memory:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看使用共享内存的版本：
- en: '[PRE17]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In this case we have created a `Shared` class as a namespace to store the shared
    variable, but a `global` variable would also be an option.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们创建了一个 `Shared` 类作为命名空间来存储共享变量，但使用全局变量也是一个选项。
- en: To make sure the shared variable is available, we need to send it along to all
    workers in the `pool` using an `initializer` method argument.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保共享变量可用，我们需要使用 `initializer` 方法参数将其发送到 `pool` 中的所有工作进程。
- en: Additionally, as the `+=` operation is not atomic (not a single operation, since
    it does *fetch, add, set*), we need to make sure to lock the variable using the
    `get_lock()` method.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于 `+=` 操作不是原子的（不是一个单一的操作，因为它需要 *fetch, add, set*），我们需要确保使用 `get_lock()`
    方法锁定变量。
- en: The *Thread safety* section later in this chapter goes into more detail about
    when locking is and is not needed.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 本章后面的 *线程安全* 部分将更详细地介绍何时需要锁定以及何时不需要。
- en: 'To run the benchmarks, we use the following code:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行基准测试，我们使用以下代码：
- en: '[PRE18]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now when executing this, we see the reason for not sharing memory if possible:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在当我们执行这个操作时，我们看到如果不共享内存会更好：
- en: '[PRE19]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The code using shared memory is roughly 8 times slower, which makes sense because
    my machine has 8 cores. Since the shared memory example spends most of its time
    with locking/unlocking (which can only be done by one process at the same time),
    we have effectively made the code run on a single core again.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 使用共享内存的代码大约慢了 8 倍，这是有道理的，因为我的机器有 8 个核心。由于共享内存示例的大部分时间都花在锁定/解锁（只能由一个进程同时执行）上，我们实际上使代码再次在单个核心上运行。
- en: I should point out that this is pretty much the worst-case scenario for shared
    memory. Since all the functions do is write to the shared variable, most of the
    time is spent locking and unlocking the variables. If you were to do actual processing
    in the function and only write the results, it would be much better already.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我应该指出，这几乎是共享内存的最坏情况。由于所有函数所做的只是写入共享变量，大部分时间都花在锁定和解锁变量上。如果你在函数中实际进行处理，并且只写入结果，那会好得多。
- en: 'You might be curious about how we could rewrite this example the right way
    while still using shared variables. In this case it is rather easy, but this largely
    depends on your specific use case and this might not work for you:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能好奇我们如何正确地重写这个示例，同时仍然使用共享变量。在这种情况下，这相当简单，但这在很大程度上取决于你的具体用例，这可能不适合你：
- en: '[PRE20]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This code runs almost as fast as the `bench_local()` function. As a rule of
    thumb, just remember to reduce the number of locks and writes as much as possible.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的运行速度几乎与 `bench_local()` 函数一样快。作为一个经验法则，只需记住尽可能减少锁的数量和写入次数。
- en: Sharing data between processes using managers
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 使用管理器在进程间共享数据
- en: 'Now that we have seen how we can directly share memory to get the best performance
    possible, let’s look at a far more convenient and much more flexible solution:
    the `multiprocessing.Manager` class.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了如何直接共享内存以获得最佳性能，让我们看看一个更方便、更灵活的解决方案：`multiprocessing.Manager` 类。
- en: Whereas shared memory restricted us to primitive types, with a `Manager` we
    can share anything that can be pickled in a very easy way if we are willing to
    sacrifice a little bit of performance. The mechanism it uses is very different,
    though; it connects through a network connection. The huge advantage of this method
    is that you can even use this across multiple devices (which we will see later
    in this chapter).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 与共享内存限制我们只能使用原始类型相比，如果我们愿意牺牲一点性能，使用 `Manager` 我们可以非常容易地共享任何可以被序列化的东西。它使用的机制非常不同；它通过网络连接连接。这种方法的一个巨大优势是，你甚至可以在多个设备上使用它（我们将在本章后面看到）。
- en: 'The `Manager` itself is not an object you will use much, though you will probably
    use the objects provided by the `Manager`. The list is plentiful so we will only
    cover a few in detail, but you can always look at the Python documentation for
    the current list of options: [https://docs.python.org/3/library/multiprocessing.html#managers](https://docs.python.org/3/library/multiprocessing.html#managers).'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`Manager` 本身不是你经常使用的对象，尽管你可能会使用 `Manager` 提供的对象。列表很多，所以我们只详细说明其中的一些，但你总是可以查看
    Python 文档以获取当前选项列表：[https://docs.python.org/3/library/multiprocessing.html#managers](https://docs.python.org/3/library/multiprocessing.html#managers)。'
- en: 'One of the most convenient options for sharing data with `multiprocessing`
    is the `multiprocessing.Namespace` object. The `Namespace` object behaves very
    similarly to a regular object, with the difference being that it can be accessed
    as a shared memory object from all processes. As long as your objects can be pickled,
    you can use them as attributes of a `Namespace` instance. To illustrate the usage
    of the `Namespace`:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 `multiprocessing` 共享数据时，最方便的选项之一是 `multiprocessing.Namespace` 对象。`Namespace`
    对象的行为与常规对象非常相似，区别在于它可以作为共享内存对象从所有进程中访问。只要你的对象可以被序列化，你就可以将它们用作 `Namespace` 实例的属性。为了说明
    `Namespace` 的用法：
- en: '[PRE21]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As you can see in this example, you can simply set the attributes of `namespace`
    as you would expect from regular objects, but they are shared between all processes.
    Since the locking now happens through network sockets, the overhead is even larger
    than with shared memory, so only write data when you must. Directly translating
    the earlier shared memory example to use a `Namespace` and explicit `Lock` (a
    `Namespace` does not have a `get_lock()` method) yields the following code:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，你可以像对待常规对象一样简单地设置 `namespace` 的属性，但它们在所有进程之间是共享的。由于锁定现在是通过网络套接字进行的，所以开销甚至比共享内存还要大，所以只有在必须时才写入数据。将早期的共享内存示例直接转换为使用
    `Namespace` 和显式的 `Lock`（`Namespace` 没有提供 `get_lock()` 方法）会产生以下代码：
- en: '[PRE22]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As with the shared memory example, this is a really inefficient case because
    we are locking for each iteration of the loop, and it really shows. While the
    local version took about 0.6 seconds and the shared memory version took about
    4 seconds, this version takes a whopping 90 seconds for effectively the same operation.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 与共享内存示例一样，这是一个非常低效的情况，因为我们为循环的每次迭代都进行了锁定，这一点非常明显。虽然本地版本大约需要0.6秒，共享内存版本大约需要4秒，但这个版本在实际上相同的操作中却需要惊人的90秒。
- en: 'Once again, we can easily speed it up by reducing the time spent in the synchronized/locked
    code:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我们可以通过减少在同步/锁定代码中花费的时间来轻松提高速度：
- en: '[PRE23]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'When benchmarking this version with the same benchmark code as before, we can
    see that it is still much slower than the 0.6 seconds we got with the local version:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用之前相同的基准代码对这一版本进行基准测试时，我们可以看到它仍然比本地版本得到的0.6秒慢得多：
- en: '[PRE24]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: That being said, at least this is much more acceptable than the 90 seconds we
    would get otherwise.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，这至少比我们原本可能得到的90秒要可接受得多。
- en: Why are these locks so incredibly slow? For a proper lock to be set, all the
    parties need to agree that the data is locked, which is a process that takes time.
    That simple fact slows down execution much more than most people would expect.
    The server/process that runs the `Manager` needs to confirm to the client that
    it has the lock; only once that has been done can the client read, write, and
    release the lock again.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这些锁如此慢？为了设置一个合适的锁，所有各方都需要同意数据被锁定，这是一个需要时间的过程。这个简单的事实比大多数人预期的要慢得多。运行`Manager`的服务器/进程需要向客户端确认它已经获得了锁；只有完成这一步后，客户端才能读取、写入并再次释放锁。
- en: On a regular hard disk setup, database servers aren’t able to handle more than
    about 10 transactions per second *on the same row* due to locking and disk latency.
    Using lazy file syncing, SSDs, and a battery-backed RAID cache, that performance
    can be increased to handle, perhaps, 100 transactions per second on the same row.
    These are simple hardware limitations; because you have multiple processes trying
    to write to a single target, you need to synchronize the actions between the processes,
    and that takes a lot of time.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规的硬盘设置中，由于锁定和磁盘延迟，数据库服务器无法处理每秒超过大约10次*同一行*的事务。使用懒同步文件、SSD和电池备份的RAID缓存，这种性能可以提高，以处理，也许，每秒100次同一行的事务。这些都是简单的硬件限制；因为你有多个进程试图写入单个目标，你需要同步进程之间的操作，这需要花费很多时间。
- en: Even with the fastest hardware available, synchronization can lock all the processes
    and produce enormous slowdowns, so if at all possible, try to avoid sharing data
    between multiple processes. Put simply, if all the processes are constantly reading
    and writing from/to the same object, it is generally faster to use a single process
    instead because the locking will effectively restrict you to a single process
    anyway.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 即使有最快的硬件，同步也可能锁定所有进程并产生巨大的减速，所以如果可能的话，尽量减少在多个进程之间共享数据。简单来说，如果所有进程都在不断从/向同一对象读取和写入，那么通常使用单个进程更快，因为锁定实际上会有效地限制你只能使用单个进程。
- en: Redis, one of the fastest data storage systems available, was fully single-threaded
    for over a decade until 2020 because the locking overhead was not worth the benefit.
    Even the current threaded version is effectively a collection of single-threaded
    servers with their own memory space to avoid locking.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Redis，这是可用的最快的数据存储系统之一，直到2020年一直完全单线程超过十年，因为锁定开销不值得其带来的好处。即使是当前的线程版本，实际上也是一组具有自己内存空间的单线程服务器，以避免锁定。
- en: Thread safety
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程安全
- en: When working with threads or processes, you need to be aware that you might
    not be the only one modifying a variable at some point in time. There are many
    scenarios where this will not be an issue and often you are lucky and it won’t
    affect you, but when it does it can cause bugs that are extremely difficult to
    debug.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 当与线程或进程一起工作时，你需要意识到你可能在某个时间点不是唯一修改变量的人。有许多场景中这不会成为问题，而且通常你很幸运，它不会影响你，但一旦发生，它可能会引起极其难以调试的错误。
- en: 'As an example, imagine having two bits of code incrementing a number at the
    same time and imagine what could go wrong. Initially, let’s assume the value is
    10\. With multiple threads, this could result in the following sequence:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象有两个代码块同时增加一个数字，想象一下可能会出错的情况。最初，让我们假设值是10。在多个线程的情况下，这可能会导致以下序列：
- en: Two threads fetch the number to local memory to increment. It is currently 10
    for both.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个线程将数字取到本地内存中增加。目前对两个都是10。
- en: Both threads increment the number in their local memory to 11.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个线程将它们本地内存中的数字增加到11。
- en: Both threads write the number back from local memory (which is 11 for both)
    to the global one, so the global number is now 11.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个线程都将数字从本地内存（对两个都是11）写回全局内存，所以全局数字现在是11。
- en: Since both threads fetched the number at the same time, one overwrote the increment
    of the other with its own increment. So instead of incrementing twice, you now
    have a variable that was only incremented once.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 由于两个线程同时获取了数字，一个线程用它的增加覆盖了另一个线程的增加。所以，你现在的变量只增加了一次，而不是增加两次。
- en: In many cases, the current GIL implementation in CPython will protect you from
    these issues when using `threading`, but you should never take that protection
    for granted and make sure to protect your variables if multiple threads might
    update your variable at the same time.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，CPython中当前的GIL实现会在使用`threading`时保护你免受这些问题的影响，但你绝不应该把这个保护当作理所当然，并确保在多个线程可能同时更新你的变量时保护你的变量。
- en: 'Perhaps an actual code example might make the scenario a bit clearer:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 可能一个实际的代码示例可以使场景更加清晰：
- en: '[PRE25]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As you can see, the `increment` function stores `counter` in a temporary variable,
    prints it, and writes to `counter` after adding 1 to it. This example is admittedly
    a bit contrived because you would normally do `counter += 1` instead, which reduces
    the odds of unexpected behaviour, but even in that case you have no guarantee
    that your results are correct.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`increment`函数将`counter`存储在一个临时变量中，打印它，并在将其加1后写入`counter`。这个例子显然是有点牵强的，因为你通常会做`counter
    += 1`，这样可以减少意外行为的发生，但即使在这种情况下，你也没有保证你的结果是正确的。
- en: 'To illustrate the output of this script:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个脚本的输出：
- en: '[PRE26]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Why did we end up with 13 at the end? Pure luck really. Some of my attempts
    resulted in 15, some in 11, and others in 14\. That’s what makes thread safety
    issues so incredibly hard to debug; in a complicated codebase, it can be really
    hard to figure out what is causing the bug and you cannot reliably reproduce the
    issue.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么最后结果是13？纯粹是运气。我的一些尝试结果是15，一些是11，还有一些是14。这就是线程安全问题如此难以调试的原因；在一个复杂的代码库中，很难找出导致错误的真正原因，而且你无法可靠地重现这个问题。
- en: When experiencing strange and hard-to-explain errors in a system using multiple
    threads/processes, make sure to see if they also occur when running single-threaded.
    Mistakes like these are easily made and can easily be introduced by third-party
    code that was not meant to be thread-safe.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 当在多线程/多进程系统中遇到奇怪且难以解释的错误时，确保查看它们在单线程运行时是否也会发生。这样的错误很容易犯，并且很容易被引入第三方代码，而这些代码并不是为了线程安全而设计的。
- en: 'To make your code thread-safe, you have a few different options:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 要使你的代码线程安全，你有几种不同的选择：
- en: This might seem obvious, but if you don’t update shared variables from multiple
    threads/processes in parallel then there is nothing to worry about.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这可能看起来很明显，但如果你不并行地从多个线程/进程更新共享变量，那么就没有什么好担心的。
- en: Use atomic operations when modifying your variables. An atomic operation is
    one that executes in a single instruction so no conflicts could ever arise. For
    example, incrementing a number could be an atomic operation where the fetching,
    incrementing, and updating happens in a single instruction.Within Python, an increment
    is usually done with `counter += 1` which is actually a shorthand for `counter
    = counter + 1`. Can you see the issue here? Instead of incrementing `counter`
    internally, Python will write a new value to the variable `counter`, which means
    it is not an atomic operation.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在修改你的变量时使用原子操作。原子操作是在单个指令中执行的，因此永远不会出现冲突。例如，增加一个数字可以是原子操作，其中获取、增加和更新都在单个指令中完成。在Python中，增加通常使用`counter
    += 1`来完成，这实际上是一个`counter = counter + 1`的缩写。你能看到这里的问题吗？Python不会在内部增加`counter`，而是会将新的值写入变量`counter`，这意味着它不是原子操作。
- en: Use locks to protect your variables.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用锁来保护你的变量。
- en: 'Knowing these options for thread-safe code, you might be wondering which operations
    are thread-safe and which aren’t. Luckily, Python does have some documentation
    about the issue, and I would strongly recommend looking at it as this is prone
    to change in the future: [https://docs.python.org/3/faq/library.html#what-kinds-of-global-value-mutation-are-thread-safe](https://docs.python.org/3/faq/library.html#what-kinds-of-global-value-mutation-are-thread-safe).'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这些线程安全代码的选项后，你可能想知道哪些操作是线程安全的，哪些不是。幸运的是，Python确实有一些关于这个问题的文档，我强烈建议你查看它，因为将来可能会发生变化：[https://docs.python.org/3/faq/library.html#what-kinds-of-global-value-mutation-are-thread-safe](https://docs.python.org/3/faq/library.html#what-kinds-of-global-value-mutation-are-thread-safe)。
- en: 'For the current CPython versions (at least CPython 3.10 and below) where the
    GIL is protecting us, we can assume these operations to be atomic and therefore
    thread-safe:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 对于当前的CPython版本（至少是CPython 3.10及以下版本），由于GIL在保护我们，我们可以假设这些操作是原子的，因此是线程安全的：
- en: '[PRE27]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'These are not atomic and not thread-safe:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这些不是原子的，也不是线程安全的：
- en: '[PRE28]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'What could we do to make `i = i + 1` thread-safe? The most obvious solution
    is to use our own lock, similar to the GIL:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做些什么来使`i = i + 1`线程安全？最明显的解决方案是使用我们自己的锁，类似于GIL：
- en: '[PRE29]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: As you can see, with a lock we can protect the updates for a variable easily.
    I should note that even though we used a `global` variable in this case, the same
    limitation applies for the attributes of class instances and other variables as
    well.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们可以很容易地使用锁来保护变量的更新。我应该指出，尽管我们在这个例子中使用了`global`变量，但同样的限制也适用于类实例的属性和其他变量。
- en: Naturally, this all applies to `multiprocessing` as well, with the subtle difference
    that variables are not shared by default with multiple processes, so you need
    to do something to explicitly cause an issue. Having said that, the earlier shared
    memory and `Manager` examples break immediately if you remove the locks from them.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 自然，这同样适用于`多进程`，细微的区别在于变量在默认情况下不会在多个进程间共享，因此你需要做些事情来明确地引发问题。话虽如此，如果你从这些先前的共享内存和`Manager`示例中移除锁，它们会立即崩溃。
- en: Deadlocks
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 死锁
- en: 'Now that you know how to update your variables in a thread-safe manner, you
    might be hoping that we are done with threading limitations. Unfortunately, the
    opposite is true. The locks we used to make our variable updates thread-safe can
    actually introduce another issue that can be even more devious to solve: **deadlocks**.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何以线程安全的方式更新变量，你可能希望我们已经解决了线程的限制。不幸的是，事实正好相反。我们用来使变量更新线程安全的锁实际上可能引入另一个问题，这个问题可能更加难以解决：**死锁**。
- en: 'A deadlock can occur when threads or processes are holding a lock while waiting
    for another thread/process to release a lock. In some cases, you can even have
    a thread/process that is waiting for itself. To illustrate, let’s assume that
    we have locks `a` and `b` and two different threads. Now the following occurs:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 当线程或进程在等待另一个线程/进程释放锁的同时持有锁时，可能会发生死锁。在某些情况下，甚至可能有一个线程/进程正在等待自己。为了说明这一点，让我们假设我们有锁`a`和`b`以及两个不同的线程。现在发生以下情况：
- en: Thread 0 locks `a`
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程0锁定`a`
- en: Thread 1 locks `b`
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程1锁定`b`
- en: Thread 0 waits for lock `b`
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程0等待锁`b`
- en: Thread 1 waits for lock `a`
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程1等待锁`a`
- en: Now thread 1 is waiting for thread 0 to finish, and vice versa. Neither will
    ever finish because they are waiting for each other.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，线程1正在等待线程0完成，反之亦然。它们都不会完成，因为它们在互相等待。
- en: 'To illustrate this scenario:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个场景：
- en: '[PRE30]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The code is relatively straightforward but warrants at least some explanation.
    As previously discussed, the `thread_0` function locks `a` first and `b` after
    and `thread_1` does this in the reverse order. This is what causes the deadlock;
    they will each wait for the other to finish. To be sure we actually reach the
    deadlock in this example, we have a small sleep to make sure `thread_0` does not
    finish before `thread_1` starts. In real-world scenarios, you would have some
    code in that bit that would take time as well.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 代码相对简单，但至少需要一些解释。如前所述，`thread_0`函数首先锁定`a`，然后是`b`，而`thread_1`则按相反的顺序进行。这就是导致死锁的原因；它们会各自等待对方完成。为了确保我们在这个例子中确实达到了死锁，我们有一个小的休眠，以确保`thread_0`在`thread_1`开始之前不会完成。在现实世界的场景中，你会在那段代码中放入一些需要花费时间的代码。
- en: How can we resolve locking issues like these? Locking strategies and resolving
    these issues could easily fill a chapter by themselves and there are several different
    types of locking problems and solutions. You could even have a livelock problem
    where both threads are attempting to resolve the deadlock problem at the same
    time with the same method, causing them to also wait for each other but with constantly
    changing locks.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何解决这类锁定问题？锁定策略和解决这些问题可以单独填满一章，并且有几种不同的锁定问题和解决方案。甚至可能存在一个活锁问题，其中两个线程都在尝试用相同的方法解决死锁问题，导致它们也互相等待，但锁却在不断变化。
- en: An easy way to visualize a livelock is to think of a narrow part of a road where
    two cars are approaching from opposite sides. Both cars would attempt to drive
    at the same time and both would back off when they notice that the other car is
    moving. Repeat that and you have a livelock.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 要可视化活锁，可以想象一条狭窄的道路，两辆车从相反方向驶来。两辆车都会试图同时驾驶，并在注意到对方车辆移动时退后。重复这个过程，你就得到了一个活锁。
- en: 'In general, there are several strategies that you can employ to avoid deadlocks:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你可以采用几种策略来避免死锁：
- en: Deadlocks can only occur when you have multiple locks, so if your code only
    ever acquires a single lock at the same time, no problems can occur.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 死锁只能在有多个锁的情况下发生，所以如果你的代码每次只获取一个锁，就不会有问题发生。
- en: Try to keep the lock section small so there is less chance of accidentally adding
    another lock within that block. This can also help performance because a lock
    can make your parallel code essentially single-threaded again.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽量保持锁的部分小，这样就不太可能意外地在那个块中添加另一个锁。这也可以帮助性能，因为锁可以使你的并行代码再次变成单线程。
- en: This is probably the most important tip for fixing deadlocks. *Always have a
    consistent locking order.* If you always lock in the same order, you can never
    have deadlocks. Let’s explain how this helps:With the earlier example and the
    two locks `a` and `b`, the problem occurred because thread 0 was waiting for `b`
    and thread 1 was waiting for `a`.If they both had attempted to lock `a` first
    and `b` after, we never would have reached the deadlock state because one of the
    threads would lock `a` and that would cause the other thread to stall long before
    `b` could ever be locked.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这可能是解决死锁最重要的提示。*始终保持一致的锁定顺序。* 如果你总是以相同的顺序锁定，你就永远不会遇到死锁。让我们解释一下这如何帮助：在先前的例子和两个锁`a`和`b`中，问题发生是因为线程0正在等待`b`，而线程1正在等待`a`。如果它们都尝试先锁定`a`然后是`b`，我们就永远不会达到死锁状态，因为其中一个线程会锁定`a`，这会导致另一个线程在`b`被锁定之前就长时间停滞。
- en: Thread-local variables
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程局部变量
- en: 'We have seen how to lock variables so only a single thread can modify a variable
    simultaneously. We have also seen how we can prevent deadlocks while using locks.
    What if we want to give a thread a separate global variable? That is where `threading.local`
    comes in: it gives you a context specifically for your current thread. This can
    be useful for database connections, for example; you probably want to give each
    thread its own database connection, but having to pass around the connection is
    inconvenient, so a global variable or connection manager is a much more convenient
    option.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何锁定变量，使得只有一个线程可以同时修改一个变量。我们也看到了在使用锁时如何防止死锁。如果我们想给一个线程提供一个独立的全局变量呢？这就是`threading.local`发挥作用的地方：它为你的当前线程提供了一个特定的上下文。例如，对于数据库连接来说，你可能希望每个线程都有自己的数据库连接，但传递连接很不方便，所以全局变量或连接管理器是一个更方便的选择。
- en: This section does not apply to `multiprocessing`, since variables are not automatically
    shared between processes. A forked process can inherit the variables from the
    parent, however, so care must be taken to explicitly initialize non-shared resources.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这个部分不适用于`multiprocessing`，因为变量不会在进程之间自动共享。然而，一个派生的进程可以继承父进程的变量，因此必须小心显式初始化非共享资源。
- en: 'Let’s illustrate the usage of thread-local variables with a small example:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个简单的例子来说明线程局部变量的用法：
- en: '[PRE31]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This example is largely the same as the thread-safety example, but instead of
    having a global `counter` variable, we are now using `threading.local()` as a
    context to set the `counter` variable to. We are also using an extra feature of
    the `concurrent.futures.ThreadPoolExecutor` here, the `initializer` function.
    Since a thread-local variable only exists within that thread and is not automatically
    copied to other threads, all threads (including the main thread) need to have
    `counter` set separately. Without setting it, we would get an `AttributeError`.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子在很大程度上与线程安全示例相同，但我们现在使用`threading.local()`作为上下文来设置`counter`变量，而不是使用全局的`counter`变量。在这里，我们还使用了`concurrent.futures.ThreadPoolExecutor`的一个额外功能，即`initializer`函数。由于线程局部变量只存在于那个线程中，并且不会自动复制到其他线程，所以所有线程（包括主线程）都需要单独设置`counter`。如果没有设置它，我们会得到一个`AttributeError`。
- en: 'When running the code, we can see that all threads are independently updating
    their variables instead of the completely mixed version we saw in the thread-safety
    example:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行代码时，我们可以看到所有线程都在独立地更新它们的变量，而不是我们在线程安全示例中看到的完全混合的版本：
- en: '[PRE32]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: If possible, I would always recommend returning variables from a thread or appending
    them to a post-processing queue and never updating a global variable or global
    state because it is faster and less error-prone. Using thread-local variables
    can really help you in these cases to make sure you have only one instance of
    a connection or collection class.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，我总是建议从一个线程返回变量或将它们追加到后处理队列中，而不是更新全局变量或全局状态，因为这更快且更不容易出错。在这些情况下使用线程局部变量真的可以帮助你确保只有一个连接或集合类的实例。
- en: Now that we know how to share (or stop sharing) variables, it is time to learn
    about the advantages and disadvantages of using threads as opposed to processes.
    We should have a basic grasp of memory management with threads and processes now.
    With all of these options, what should we choose and why?
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何共享（或停止共享）变量，是时候了解使用线程而不是进程的优点和缺点了。我们现在应该对线程和进程的内存管理有一个基本的了解。有了所有这些选项，我们应该选择哪一个，为什么？
- en: Processes, threads, or a single thread?
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进程、线程，还是单线程？
- en: Now that we know how to use `multiprocessing`, `threading` and `concurrent.futures`,
    which should you choose for your case?
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何使用`multiprocessing`、`threading`和`concurrent.futures`，对于你的情况，你应该选择哪一个？
- en: Since `concurrent.futures` implements both `threading,` and `multiprocessing`,
    you can mentally exchange `threading` in this section with `concurrent.futures.ThreadPoolExecutor`.
    The same goes for `multiprocessing` and `concurrent.futures.ProcessPoolExecutor`,
    of course.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`concurrent.futures`实现了`threading`和`multiprocessing`，你可以在这个部分心理上将`threading`替换为`concurrent.futures.ThreadPoolExecutor`。当然，对于`multiprocessing`和`concurrent.futures.ProcessPoolExecutor`也是同样的道理。
- en: When we consider the choice between single-threaded, multithreaded, and multiprocess,
    there are multiple factors that we can consider.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑单线程、多线程和多进程之间的选择时，有多个因素我们可以考虑。
- en: The first and most important question you should ask yourself is whether you
    really need to use `threading` or `multiprocessing`. Often, code is fast enough
    and you should ask yourself if the cost of dealing with the potential side effects
    of memory sharing and such is worth it. Not only does writing code become more
    complicated when parallel processing is involved, but the complexity of debugging
    is multiplied as well.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该问自己的第一个也是最重要的问题是，你是否真的需要使用`threading`或`multiprocessing`。通常，代码已经足够快，你应该问问自己处理内存共享等潜在副作用的开销是否值得。不仅当涉及到并行处理时编写代码变得更加复杂，调试的复杂性也会随之增加。
- en: Second, you should ask yourself what is limiting your performance. If the limitation
    is external I/O, then it could be useful to use `asyncio` or `threading` to handle
    that, but it is still no guarantee.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，你应该问问自己是什么限制了你的表现。如果限制是外部I/O，那么使用`asyncio`或`threading`来处理可能会有所帮助，但这并不能保证。
- en: For example, if you are reading a bunch of files from a slow hard disk, threading
    might not even help you. If the hard disk is the limiting factor, it will not
    become faster no matter what you try. So before you rewrite your entire codebase
    to function with `threading`, make sure to test if your solution has any chance
    of working.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你正在从慢速硬盘读取大量文件，线程可能甚至帮不上忙。如果硬盘是限制因素，无论你尝试什么，它都不会变快。所以在你重写整个代码库以使用`threading`之前，确保测试你的解决方案是否有任何成功的可能性。
- en: Assuming that your I/O bottleneck can be alleviated, then you still have the
    choice of `asyncio` versus `threading`. Since `asyncio` is the fastest of the
    available options, I would opt for that solution if it works with your codebase,
    but using `threading` is not a bad option either, of course.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的I/O瓶颈可以得到缓解，那么你仍然可以选择`asyncio`与`threading`之间的选择。由于`asyncio`是所有可用选项中最快的，如果它与你的代码库兼容，我会选择这个解决方案，但当然使用`threading`也不是一个坏的选择。
- en: If the GIL is your bottleneck due to heavy calculations from your Python code,
    then `multiprocessing` can help you a lot. But even in those cases, `multiprocessing`
    is not your only option; for many slow processes, it can also help to employ fast
    libraries such as `numpy`.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 如果由于Python代码中的大量计算，GIL是你的瓶颈，那么`multiprocessing`可以帮到你很多。但即使在那些情况下，`multiprocessing`也不是你的唯一选择；对于许多慢速过程，使用快速库如`numpy`也可能有所帮助。
- en: I am a great fan of the `multiprocessing` library and it is one of the easiest
    implementations of multiprocess code that I have seen so far, but it still comes
    with several caveats such as more difficult memory management and deadlocks, as
    we have seen. So always consider if you actually need the solution and if your
    problem is suitable for multiprocessing. If a large portion of code is written
    using functional programming it can be really easy to implement; if you need to
    interact with a lot of external resources, such as databases, it can be really
    difficult to implement.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我非常喜爱`multiprocessing`库，它是迄今为止我见过的最简单的多进程代码实现之一，但它仍然伴随着一些需要注意的问题，比如更复杂的内存管理和死锁，正如我们所看到的。所以始终考虑你是否真的需要这个解决方案，以及你的问题是否适合多进程。如果大部分代码是用函数式编程编写的，那么实现起来可能非常简单；如果你需要与大量外部资源，如数据库，进行交互，那么实现起来可能非常困难。
- en: threading versus concurrent.futures
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`threading`与`concurrent.futures`'
- en: When given the choice, should you use `threading` or `concurrent.futures`? In
    my opinion, it depends on what you are trying to do.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 当您有选择时，您应该使用`threading`还是`concurrent.futures`？在我看来，这取决于您想要做什么。
- en: 'The advantages of `threading` over `concurrent.futures` are:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '`threading`相对于`concurrent.futures`的优势是：'
- en: We can specify the name of the thread explicitly, which can be seen in the task
    manager on many operating systems.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以显式指定线程的名称，这在许多操作系统的任务管理器中可以看到。
- en: We can explicitly create and start a long-running thread for a function instead
    of relying on the availability within a thread pool.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以显式创建并启动一个长时间运行的线程来执行一个函数，而不是依赖于线程池中的可用性。
- en: 'If your scenario allows you to choose, I believe you should use `concurrent.futures`
    instead of `threading` for the following reasons:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的场景允许您选择，我相信您应该使用`concurrent.futures`而不是`threading`，以下是一些原因：
- en: With `concurrent.futures` you can switch between threads and processes by using
    `concurrent.futures.ProcessPoolExecutor` instead of `concurrent.futures.ThreadPoolExecutor`.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`concurrent.futures`，您可以通过使用`concurrent.futures.ProcessPoolExecutor`而不是`concurrent.futures.ThreadPoolExecutor`在线程和进程之间切换。
- en: With `concurrent.futures` you have the `map()` method to easily batch-process
    a list of items without having the (potential) overhead of setting up and shutting
    down the thread.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`concurrent.futures`，您有`map()`方法可以轻松批量处理项目列表，而无需设置和关闭线程的（潜在）开销。
- en: The `concurrent.futures.Future` objects as returned by the `concurrent.futures`
    methods allow for fine-grained control of the results and the handling.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`concurrent.futures`方法返回的`concurrent.futures.Future`对象允许对结果和处理的细粒度控制。'
- en: multiprocessing versus concurrent.futures
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`multiprocessing`与`concurrent.futures`'
- en: When it comes to multiprocessing, I think the `concurrent.futures` interface
    adds much less benefit than it does in the case of threading, especially since
    `multiprocessing.Pool` essentially offers you a nearly identical interface to
    `concurrent.futures.ProcessPoolExecutor`.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到多进程时，我认为`concurrent.futures`接口相比线程提供的优势要少得多，尤其是`multiprocessing.Pool`基本上提供了与`concurrent.futures.ProcessPoolExecutor`几乎相同的接口。
- en: 'The advantages of `multiprocessing` over `concurrent.futures` are:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`相对于`concurrent.futures`的优势是：'
- en: Many advanced mapping methods such as `imap_unordered` and `starmap`.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多高级映射方法，如`imap_unordered`和`starmap`。
- en: More control over the pool (i.e. `terminate()`, `close()`).
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对池有更多控制（即`terminate()`、`close()`）。
- en: It can be used across multiple machines.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以在多台机器上使用。
- en: You can manually specify the startup method (`fork`, `spawn`, or `forkserver`),
    which gives you control over how variables are copied from the parent process.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以手动指定启动方法（`fork`、`spawn`或`forkserver`），这使您能够控制变量从父进程复制的方式。
- en: You can choose the Python interpreter. Using `multiprocessing.set_executable()`,
    you could run a Python 3.10 pool while running Python 3.9 for the main process.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以选择Python解释器。使用`multiprocessing.set_executable()`，您可以在运行Python 3.9的主进程的同时运行Python
    3.10的进程池。
- en: 'The advantages of `concurrent.futures` over `multiprocessing` are:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '`concurrent.futures`相对于`multiprocessing`的优势是：'
- en: You can easily switch to the `concurrent.futures.ThreadPoolExecutor.`
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以轻松切换到`concurrent.futures.ThreadPoolExecutor`。
- en: The returned `Future` objects allow for more fine-grained control over the result
    handling when compared to the `AsyncResult` objects `multiprocessing` uses.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与`multiprocessing`使用的`AsyncResult`对象相比，返回的`Future`对象允许对结果处理进行更细粒度的控制。
- en: Personally, I prefer `multiprocessing` if you have no need for compatibility
    with `threads` because of the advanced mapping methods.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 个人而言，如果您不需要与`threads`兼容的映射方法，我更倾向于使用`multiprocessing`。
- en: Hyper-threading versus physical CPU cores
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超线程与物理CPU核心
- en: Hyper-threading is a technology that offers extra virtual CPU cores to your
    physical cores. The idea is that, because these virtual CPU cores have separate
    caches and other resources, you can more efficiently switch between multiple tasks.
    If you task-switch between two heavy processes, the CPU won’t have to unload/reload
    all caches. When it comes to actual CPU instruction processing, however, it will
    not help you.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 超线程是一种技术，它为物理核心提供额外的虚拟CPU核心。其理念是，由于这些虚拟CPU核心有独立的缓存和其他资源，您可以在多个任务之间更有效地切换。如果您在两个重负载进程之间进行任务切换，CPU就不必卸载/重新加载所有缓存。然而，当涉及到实际的CPU指令处理时，它并不会帮助您。
- en: 'When you truly maximize CPU usage, it is generally better to only use the physical
    processor count. To demonstrate how this affects the performance, we will run
    a simple test with several process counts. Since my processor has `8` cores (`16`
    if you include hyper-threading), we will run it with `1`, `2`, `4`, `8`, `16`,
    and `32` processes to demonstrate how it affects the performance:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 当你真正最大化CPU使用时，通常最好只使用物理处理器数量。为了展示这如何影响性能，我们将使用几个进程数运行一个简单的测试。由于我的处理器有 `8` 个核心（如果包括超线程则是
    `16` 个），我们将使用 `1`、`2`、`4`、`8`、`16` 和 `32` 个进程来展示它如何影响性能：
- en: '[PRE33]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To keep the processor busy, we are using a `while` loop from `n` to `0` in
    the `busy_wait()` function. For the benchmarking, we are using a `multiprocessing.Pool()`
    instance with the given number of processes and running `busy_wait(100000)` 128
    times:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让处理器保持忙碌，我们在 `busy_wait()` 函数中使用从 `n` 到 `0` 的 `while` 循环。对于基准测试，我们使用具有给定进程数的
    `multiprocessing.Pool()` 实例，并运行 `busy_wait(100000)` 128 次：
- en: '[PRE34]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As you can see, with my `8`-`c`ore CPU with hyper-threading enabled, the version
    with `8` threads is obviously the fastest. Even though the operating system task
    manager shows `16` cores, it is not always faster to utilize more than the `8`
    physical cores. Additionally, due to the boosting behavior of modern processors,
    you can see that using `8` processors is only `3.4` times faster than the single-threaded
    variant, as opposed to the expected `8`-`t`imes speedup.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在我的启用超线程的 `8` 核心CPU上，具有 `8` 线程的版本显然是最快的。尽管操作系统任务管理器显示 `16` 个核心，但使用超过 `8`
    个物理核心并不总是更快的。此外，由于现代处理器的提升行为，你可以看到使用 `8` 个处理器仅比单线程版本快 `3.4` 倍，而不是预期的 `8` 倍加速。
- en: This illustrates the problem with hyper-threading when heavily loading the processor
    with instructions. As soon as the single processes actually use 100% of a CPU
    core, the task switching between the processes actually reduces performance. Since
    there are only `8` physical cores, the other processes have to fight to get something
    done on the processor cores. Don’t forget that other processes on the system and
    the operating system itself will also consume a bit of processing power.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这说明了在用指令大量加载处理器时超线程的问题。一旦单个进程实际上使用了CPU核心的100%，进程之间的任务切换实际上会降低性能。由于只有 `8` 个物理核心，其他进程必须争夺在处理器核心上完成一些事情。别忘了系统上的其他进程以及操作系统本身也会消耗一些处理能力。
- en: If you are truly pressed for performance with a CPU-bound problem then matching
    the physical CPU cores is often the best solution, but if locking is a bottleneck,
    then a single thread can be faster than any multithreaded solution due to CPU
    boosting behavior.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你确实因为CPU密集型问题而迫切需要性能，那么匹配物理CPU核心通常是最佳解决方案，但如果锁定是瓶颈，那么由于CPU提升行为，单线程可能比任何多线程解决方案都快。
- en: If you do not expect to maximize all cores all the time, then I recommend not
    passing the `processes` parameter to `multiprocessing.Pool()`, which causes it
    to default to `os.cpu_count()`, which returns all cores including hyper-threaded
    ones.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你预期不会一直最大化所有核心，那么我建议不要将 `processes` 参数传递给 `multiprocessing.Pool()`，这将使其默认为
    `os.cpu_count()`，它返回所有核心，包括超线程核心。
- en: 'It all depends on your use case, however, and the only way to know for certain
    is to test for your specific scenario. As a rule of thumb, I recommend the following:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这完全取决于你的用例，而确定唯一的方法是测试你的特定场景。作为一个经验法则，我建议以下做法：
- en: Disk I/O bound? A single process is most likely your best bet.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 磁盘I/O受限？单个进程可能是最佳选择。
- en: CPU bound? The number of physical CPU cores is your best bet.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU受限？物理CPU核心的数量是你的最佳选择。
- en: Network I/O bound? Start with the defaults and tune if needed. This is one of
    the few cases where 128 threads on an 8-core processor can still be useful.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络I/O受限？从默认值开始，如有需要则调整。这是在8核心处理器上仍然可以使用128线程的少数情况之一。
- en: No obvious bound but many (hundreds of) parallel processes are needed? Perhaps
    you should try `asyncio` instead of `multiprocessing`.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有明显的限制，但需要许多（数百个）并行过程？也许你应该尝试使用 `asyncio` 而不是 `multiprocessing`。
- en: Note that the creation of multiple processes is not free in terms of memory
    and open files; while you could have a nearly unlimited number of coroutines,
    this is not the case for processes. Depending on your operating system configuration,
    you could reach the maximum open files limit long before you even reach 100 processes,
    and even if you reach those numbers, CPU scheduling will be your bottleneck instead.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，创建多个进程在内存和打开的文件方面并不是免费的；虽然你可以有几乎无限的协程数量，但对于进程来说并非如此。根据你的操作系统配置，你可能在达到100个进程之前就达到最大打开文件限制，即使你达到了这些数字，CPU调度也将成为你的瓶颈。
- en: 'So what should we do if our CPU cores are not enough? Simple: use more CPU
    cores. Where do we get those? Multiple computers! It is time to graduate to distributed
    computing.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的CPU核心不够用，我们应该怎么做？简单：使用更多的CPU核心。我们从哪里得到这些核心？多台计算机！是时候过渡到分布式计算了。
- en: Remote processes
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 远程进程
- en: So far, we have only executed our scripts on multiple local processors, but
    we can actually expand this much further. Using the `multiprocessing` library,
    it’s actually very easy to execute jobs on remote servers, but the documentation
    is currently still a bit cryptic. There are actually a few ways of executing processes
    in a distributed way, but the most obvious one isn’t the easiest one. The `multiprocessing.connection`
    module has both the `Client` and `Listener` classes, which facilitate secure communication
    between the clients and servers in a simple way.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只在多个本地处理器上执行了我们的脚本，但实际上我们可以做得更多。使用 `multiprocessing` 库，实际上在远程服务器上执行作业非常容易，但目前的文档仍然有些晦涩。实际上有几种方式可以以分布式的方式执行进程，但最明显的方法并不是最容易的方法。`multiprocessing.connection`
    模块提供了 `Client` 和 `Listener` 类，它们以简单的方式促进了客户端和服务器之间的安全通信。
- en: Communication is not the same as process management and queue management, however;
    those features require some extra effort. The `multiprocessing` library is still
    a bit bare in this regard, but it’s most certainly possible given a few different
    processes.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 通信与进程管理和队列管理并不相同；这些功能需要额外的努力。`multiprocessing` 库在这方面仍然比较简单，但只要有几个不同的进程，这绝对是可能的。
- en: Distributed processing using multiprocessing
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用多进程的分布式处理
- en: 'We will start with a module containing a few constants that should be shared
    between all clients and the server, so the secret password and the hostname of
    the server are available to all. In addition to that, we will add our prime calculation
    functions, which we will be using later. The imports in the following modules
    will expect this file to be stored as `T_17_remote_multiprocessing/constants.py,`
    but feel free to call it anything you like as long as the imports and references
    keep working:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个模块开始，其中包含一些应该由所有客户端和服务器共享的常量，这样秘密密码和服务器的主机名就可以对所有客户端和服务器可用。除此之外，我们还将添加我们的素数计算函数，这些函数我们稍后会用到。以下模块中的导入将期望此文件存储为
    `T_17_remote_multiprocessing/constants.py`，但只要你确保导入和引用正常工作，你可以随意命名：
- en: '[PRE35]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next up, we define the functions that need to be available to both the server
    and the client. We will store this as `T_17_remote_multiprocessing/functions.py`:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义需要供服务器和客户端都可用到的函数。我们将将其存储为 `T_17_remote_multiprocessing/functions.py`：
- en: '[PRE36]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now it’s time to create the actual server that links the functions and the
    job queue. We will store this as `T_17_remote_multiprocessing/server.py`:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候创建实际的连接函数和作业队列的服务器了。我们将将其存储为 `T_17_remote_multiprocessing/server.py`：
- en: '[PRE37]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: After creating the server, we need to have a client script that sends the jobs.
    You could use a single script for both sending and processing, but to keep things
    sensible we will use separate scripts.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建服务器之后，我们需要有一个客户端脚本来发送作业。你可以使用单个脚本进行发送和处理，但为了保持逻辑清晰，我们将使用单独的脚本。
- en: 'The following script will add `0` to `999` to the queue for processing. We
    will store this as `T_17_remote_multiprocessing/submitter.py`:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本将把 `0` 到 `999` 添加到队列中进行处理。我们将将其存储为 `T_17_remote_multiprocessing/submitter.py`：
- en: '[PRE38]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Lastly, we need to create a client to actually process the queue. We will store
    this as `T_17_remote_multiprocessing/client.py`:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要创建一个客户端来实际处理队列。我们将将其存储为 `T_17_remote_multiprocessing/client.py`：
- en: '[PRE39]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: From the preceding code, you can see how we pass along functions; the manager
    allows the registering of functions and classes that can be called from the clients
    as well. With that, we pass along a queue from the multiprocessing class, which
    is safe for both multithreading and multiprocessing.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，您可以看到我们如何传递函数；管理器允许注册可以从客户端调用的函数和类。有了这个，我们就传递了一个来自多进程类的队列，这个队列对多线程和多进程都是安全的。
- en: 'Now we need to start the processes themselves. First, the server that keeps
    on running:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要启动进程本身。首先，持续运行的服务器：
- en: '[PRE40]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'After that, run the producer to generate the prime generation requests:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，运行生产者以生成素数生成请求：
- en: '[PRE41]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now we can run multiple clients on multiple machines to get the first 1,000
    primes. Since these clients now print the first 1,000 primes, the output is a
    bit too lengthy to show here, but you can simply run this in parallel multiple
    times or on multiple machines to generate your output:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在多台机器上运行多个客户端以获取前 1,000 个素数。由于这些客户端现在正在打印前 1,000 个素数，输出有点太长，无法在此显示，但您可以简单地并行多次运行或在多台机器上运行以生成您的输出：
- en: '[PRE42]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Instead of printing, you can use queues or pipes to send the output to a different
    process if you’d like. As you can see, though, it’s still a bit of work to process
    things in parallel and it requires some code synchronization to work. There are
    a few alternatives available, such as **Redis**, **ØMQ**, **Celery**, **Dask**,
    and **IPython Parallel**. Which of these is the best and most suitable depends
    on your use case. If you are simply looking for processing tasks on multiple CPUs,
    then `multiprocessing`, Dask, and IPython Parallel are probably your best choices.
    If you are looking for background processing and/or easy offloading to multiple
    machines, then ØMQ and Celery are better choices.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想将输出发送到不同的进程，您可以使用队列或管道代替打印。但是，如您所见，并行处理事物仍然需要一些工作，并且需要一些代码同步才能工作。有几个替代方案可用，例如
    **Redis**、**ØMQ**、**Celery**、**Dask** 和 **IPython Parallel**。哪个是最好的和最适合取决于您的用例。如果您只是想处理多个
    CPU 上的任务，那么 `multiprocessing`、Dask 和 IPython Parallel 可能是您最好的选择。如果您正在寻找后台处理和/或轻松地将任务卸载到多台机器上，那么
    ØMQ 和 Celery 是更好的选择。
- en: Distributed processing using Dask
  id: totrans-341
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Dask 进行分布式处理
- en: The Dask library is quickly becoming the standard for distributed Python execution.
    It has very tight integration with many scientific Python libraries such as NumPy
    and Pandas, making parallel execution in many cases completely transparent. These
    libraries are covered in detail in *Chapter 15*, *Scientific Python and Plotting*.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 库正在迅速成为分布式 Python 执行的标准。它与许多科学 Python 库（如 NumPy 和 Pandas）有非常紧密的集成，使得在许多情况下并行执行完全透明。这些库在
    *第 15 章*，*科学 Python 和绘图* 中有详细的介绍。
- en: The Dask library provides an easy parallel interface that can execute single-threaded,
    use multiple threads, use multiple processes, and even use multiple machines.
    As long as you keep the data-sharing limitations of multiple threads, processes,
    and machines in mind, you can easily switch between them to see which performs
    best for your use case.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 库提供了一个易于使用的并行接口，可以执行单线程、使用多个线程、使用多个进程，甚至使用多台机器。只要您牢记多线程、进程和多台机器的数据共享限制，您就可以轻松地在它们之间切换，以查看哪个最适合您的用例。
- en: Installing Dask
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 Dask
- en: 'The Dask library consists of multiple packages and you might not need all of
    them. Broadly speaking, the `Dask` package is only the core, and we can choose
    from several extras, which can be installed through `pip install dask[extra]`:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 库由多个包组成，您可能不需要所有这些包。总的来说，`Dask` 包只是核心，我们可以从几个附加功能中选择，这些可以通过 `pip install
    dask[extra]` 安装：
- en: '`array`: Adds an array interface similar to `numpy.ndarray`. Internally, these
    structures consist of multiple `numpy.ndarray` instances spread across your Dask
    cluster for easy parallel processing.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`array`：添加了一个类似于 `numpy.ndarray` 的数组接口。内部，这些结构由多个 `numpy.ndarray` 实例组成，分布在您的
    Dask 集群中，以便于并行处理。'
- en: '`dataframe`: Similar to the array interface, this is a collection of `pandas.DataFrame`
    objects.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataframe`：类似于数组接口，这是一个 `pandas.DataFrame` 对象的集合。'
- en: '`diagnostics`: Adds profilers, progress bars, and even a fully interactive
    dashboard with live information about the currently running jobs.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`diagnostics`：添加了分析器、进度条，甚至一个完全交互式的仪表板，可以实时显示当前运行作业的信息。'
- en: '`distributed`: Packages needed for running Dask across multiple systems instead
    of locally only.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distributed`：运行 Dask 在多个系统上而不是仅本地所需的包。'
- en: '`complete`: All of the above extras.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`complete`：所有上述附加功能。'
- en: 'For the demonstrations in this chapter, we will need to install at least the
    `distributed` extra, so you need to run either:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章的演示，我们需要至少安装`distributed`扩展，因此您需要运行以下之一：
- en: '[PRE43]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Or:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 或者：
- en: '[PRE44]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: If you are playing around with Jupyter notebooks, the progress bars in the `diagnostics`
    extra also have Jupyter support, which can be useful.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用Jupyter笔记本进行实验，`diagnostics`扩展中的进度条也支持Jupyter，这可能很有用。
- en: Basic example
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本示例
- en: 'Let’s start with a basic example of executing some code via Dask without explicitly
    setting up a cluster. To illustrate how this can help performance, we will be
    using a `busy-wait` loop to maximize CPU load.In this case, we will be using the
    `dask.distributed` submodule, which has an interface quite similar to `concurrent.futures`:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从执行一些代码的基本示例开始，通过Dask而不显式设置集群。为了说明这如何有助于性能，我们将使用`busy-wait`循环来最大化CPU负载。在这种情况下，我们将使用`dask.distributed`子模块，它有一个与`concurrent.futures`非常相似的接口：
- en: '[PRE45]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The code is mostly straightforward, but there are a few small caveats to look
    at. First of all, when submitting the task to Dask, you need to tell Dask that
    it is an impure function.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 代码大部分都很直接，但有一些小细节需要注意。首先，当将任务提交给Dask时，您需要告诉Dask它是一个不纯的函数。
- en: If you recall from *Chapter 5*, *Functional Programming – Readability Versus
    Brevity*, a pure function in functional programming is one that has no side effects;
    its output is consistent and only depends on the input. A function returning a
    random value is impure because repeated calls return different results.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得*第5章*，*函数式编程 – 可读性与简洁性之间的权衡*，函数式编程中的纯函数是没有副作用的一个；其输出是一致的，并且只依赖于输入。返回随机值的函数是不纯的，因为重复调用会返回不同的结果。
- en: Dask will automatically cache the results in the case of pure functions. If
    you have two identical calls, Dask will only execute the function once.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 对于纯函数，Dask会自动缓存结果。如果您有两个相同的调用，Dask只会执行一次函数。
- en: To queue the tasks, we need to use a function such as `client.map()` or `client.submit()`.
    These work in a very similar way to `executor.submit()` in the case of `concurrent.futures`.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 为了排队任务，我们需要使用`client.map()`或`client.submit()`等函数。这些函数在`concurrent.futures`的情况下与`executor.submit()`非常相似。
- en: Lastly, we need to fetch the results from the futures. This can be done by calling
    `future.result()`, or in batch by using `client.gather(futures)`. Once again,
    very similar to `concurrent.futures`.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要从未来中获取结果。这可以通过调用`future.result()`或批量使用`client.gather(futures)`来完成。再次强调，这与`concurrent.futures`非常相似。
- en: To make the code a bit more flexible, we made the number of tasks configurable
    so it runs in a reasonable amount of time on your system. If you have a much slower
    or much faster system, you will want to adjust this to get useful results.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使代码更加灵活，我们使任务数量可配置，以便在您的系统上合理的时间内运行。如果您有一个速度慢得多或快得多的系统，您可能需要调整它以获得有用的结果。
- en: 'When we execute the script, we get the following results:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们执行脚本时，我们得到以下结果：
- en: '[PRE46]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: That is how easily you can execute some code across all of your CPU cores. Naturally,
    we can also test in single-threaded or distributed mode; the only part we need
    to vary is how we initialize `distributed.Client()`.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是您如何轻松地在所有CPU核心上执行一些代码。当然，我们也可以在单线程或分布式模式下进行测试；我们唯一需要改变的是如何初始化`distributed.Client()`。
- en: Running a single thread
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单线程运行
- en: 'Let’s run the same code but in single-threaded mode:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以单线程模式运行相同的代码：
- en: '[PRE47]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Now if we run it, we can see that Dask was definitely using multiple processes
    before:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果我们运行它，我们可以看到Dask确实在之前使用了多个进程：
- en: '[PRE48]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: This can be useful for debugging thread-safety issues. If the issues still persist
    in single-threaded mode, thread safety is probably not your issue.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于调试线程安全问题很有用。如果问题在单线程模式下仍然存在，那么线程安全问题可能不是你的问题。
- en: Distributed execution across multiple machines
  id: totrans-374
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在多台机器上分布式执行
- en: 'For a much more impressive feat, let’s run the code on multiple machines at
    the same time. To run Dask on multiple systems simultaneously, there are many
    deployment options available:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现更令人印象深刻的成就，让我们同时运行多台机器上的代码。要同时运行Dask，有许多可用的部署选项：
- en: Manual setup using the `dask-scheduler` and `dask-worker` commands
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`dask-scheduler`和`dask-worker`命令进行手动设置
- en: Automatic deployment over SSH using the `dask-ssh` command
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`dask-ssh`命令通过SSH自动部署
- en: Deployment straight to an existing compute cluster running Kubernetes, Hadoop,
    and others
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接部署到运行Kubernetes、Hadoop等现有计算集群
- en: Deployment to cloud providers such as Amazon, Google, and Microsoft Azure
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将应用程序部署到云服务提供商，如亚马逊、谷歌和微软Azure
- en: In this case, we are going to use `dask-scheduler` since it’s the solution that
    you can run on pretty much any machine that can run Python.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用`dask-scheduler`，因为它是在几乎任何可以运行Python的机器上运行的解决方案。
- en: Note that you can encounter errors if the Dask versions and dependencies are
    not in sync, so updating to the latest version before starting is a good idea.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果Dask版本和依赖项不匹配，可能会遇到错误，因此在开始之前更新到最新版本是一个好主意。
- en: 'First, we start the `dask-scheduler`:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们启动`dask-scheduler`：
- en: '[PRE49]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Once you have the `dask-scheduler` running, it will also host the dashboard
    mentioned above, which shows the current status: `http://localhost:8787/status`.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦`dask-scheduler`启动，它也将托管上面提到的仪表板，显示当前状态：`http://localhost:8787/status`。
- en: 'Now we can run the `dask-worker` processes on all machines that need to participate:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在所有需要参与的计算机上运行`dask-worker`进程：
- en: '[PRE50]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: With the `--nprocs` parameter, you can set the number of processes to start.
    With `auto`, it is set to the number of CPU cores including hyper-threading. When
    set to a positive number, it will start that exact number of processes; when set
    to a negative number the number is added to the number of CPU cores.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`--nprocs`参数，你可以设置要启动的进程数。设置为`auto`时，它将设置为包括超线程在内的CPU核心数。当设置为正数时，它将启动该确切数量的进程；当设置为负数时，该数值将添加到CPU核心数。
- en: 'Your dashboard screen and the console should show all of the connected clients
    now. It’s time to run our script again, but distributed this time:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 你的仪表板屏幕和控制台现在应该显示所有已连接的客户端。现在是时候再次运行我们的脚本了，但这次是分布式运行：
- en: '[PRE51]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'That’s the only thing we need to do: configure where the scheduler is running.
    Note that we could also connect from other machines using the IP or hostname instead.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们需要做的唯一一件事：配置调度器运行的位置。注意，我们也可以使用IP地址或主机名从其他机器连接。
- en: 'Let’s run it and see if it became any faster:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行它并看看它是否变得更快：
- en: '[PRE52]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Wow, that’s quite a difference! Instead of the `20` per second we could do in
    single-threaded mode or the `71` per second we could do in multiple-process mode,
    we can now process `405` of these tasks per second. As you can see, it also took
    very little effort to set up.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，这真是一个很大的区别！在单线程模式下我们每秒可以做`20`个任务，或者在多进程模式下每秒可以做`71`个任务，而现在我们每秒可以处理`405`个这样的任务。正如你所见，设置起来也非常简单。
- en: The Dask library has many more options to increase efficiency, limit memory,
    prioritize work, and more. We didn’t even cover the combining of tasks by chaining
    them or running a `reduce` on bundled results. I can strongly recommend considering
    Dask if your code could benefit from running on multiple systems at the same time.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: Dask库有许多更多选项来提高效率、限制内存、优先处理工作等等。我们甚至还没有涵盖通过链式连接任务或对捆绑结果运行`reduce`来组合任务。如果你的代码可以从同时在多个系统上运行中受益，我强烈建议考虑使用Dask。
- en: Distributed processing using ipyparallel
  id: totrans-395
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ipyparallel进行分布式处理
- en: The IPython Parallel module, similar to Dask, makes it possible to process code
    on multiple computers at the same time. It should be noted that you can run Dask
    on top of `ipyparallel`. The library supports more features than you are likely
    to need, but the basic usage is important to know just in case you need to do
    heavy calculations that can benefit from multiple computers.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: IPython Parallel模块与Dask类似，使得同时处理多台计算机上的代码成为可能。需要注意的是，你可以在`ipyparallel`之上运行Dask。该库支持比你可能需要的更多功能，但基本用法在需要执行可以受益于多台计算机的繁重计算时很重要。
- en: 'First, let’s start by installing the latest `ipyparallel` package and all the
    IPython components:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们安装最新的`ipyparallel`包和所有IPython组件：
- en: '[PRE53]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Especially on Windows, it might be easier to install IPython using Anaconda
    instead, as it includes binaries for many science, math, engineering, and data
    analysis packages. To get a consistent installation, the Anaconda installer is
    also available for OS X and Linux systems.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是在Windows上，使用Anaconda安装IPython可能更容易，因为它包括许多科学、数学、工程和数据分析包的二进制文件。为了获得一致的安装，Anaconda安装程序也适用于OS
    X和Linux系统。
- en: 'Secondly, we need a cluster configuration. Technically, this is optional, but
    since we are going to create a distributed IPython cluster, it is much more convenient
    to configure everything using a specific profile:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们需要一个集群配置。技术上，这是可选的，但既然我们打算创建一个分布式IPython集群，使用特定的配置文件来配置一切将更加方便：
- en: '[PRE54]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: These configuration files contain a huge number of options, so I recommend searching
    for a specific section instead of walking through them. A quick listing gave me
    about 2,500 lines of configuration in total for these five files. The filenames
    already provide hints about the purpose of the configuration files, but we’ll
    walk through the files explaining their purpose and some of the most important
    settings.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 这些配置文件包含大量的选项，所以我建议搜索特定的部分而不是逐个查看。快速列出这五个文件的总配置行数约为2,500行。文件名已经提供了关于配置文件用途的提示，但我们将通过解释它们的目的和一些最重要的设置来遍历这些文件。
- en: ipython_config.py
  id: totrans-403
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipython_config.py
- en: 'This is the generic IPython configuration file; you can customize pretty much
    everything about your IPython shell here. It defines how your shell should look,
    which modules should be loaded by default, whether or not to load a GUI, and quite
    a bit more. For the purpose of this chapter, it’s not all that important, but
    it’s definitely worth a look if you’re going to use IPython more often. One of
    the things you can configure here is the automatic loading of extensions, such
    as `line_profiler` and `memory_profiler` discussed in *Chapter 12*, *Performance
    – Tracking and Reducing Your Memory and CPU Usage*. For example:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通用的IPython配置文件；你几乎可以在这里自定义IPython shell的任何内容。它定义了你的shell应该如何看起来，默认应该加载哪些模块，是否加载GUI，以及更多。对于本章的目的来说，这并不是特别重要，但如果你打算更频繁地使用IPython，它绝对值得一看。你可以在这里配置的一些事情包括自动加载扩展，例如在第12章中讨论的`line_profiler`和`memory_profiler`。例如：
- en: '[PRE55]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: ipython_kernel_config.py
  id: totrans-406
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipython_kernel_config.py
- en: This file configures your IPython kernel and allows you to overwrite/extend
    `ipython_config.py`. To understand its purpose, it’s important to know what an
    IPython kernel is. The kernel, in this context, is the program that runs and introspects
    the code. By default, this is `IPyKernel`, which is a regular Python interpreter,
    but there are also other options such as `IRuby` or `IJavascript` to run Ruby
    or JavaScript respectively.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件配置你的IPython内核，并允许你覆盖/扩展`ipython_config.py`。为了理解其目的，了解IPython内核是什么很重要。在这个上下文中，内核是运行和检查代码的程序。默认情况下，这是`IPyKernel`，它是一个常规的Python解释器，但还有其他选项，如`IRuby`或`IJavascript`，分别用于运行Ruby或JavaScript。
- en: One of the more useful options is the possibility of configuring the listening
    port(s) and IP addresses for the kernel. By default, the ports are all set to
    use a random number, but it is important to note that if someone else has access
    to the same machine while you are running your kernel, they will be able to connect
    to your IPython kernel, which can be dangerous on shared machines.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个更有用的选项是配置内核的监听端口和IP地址。默认情况下，端口都设置为使用随机数，但重要的是要注意，如果你在运行内核时有人可以访问同一台机器，他们可以连接到你的IPython内核，这在共享机器上可能是危险的。
- en: ipcontroller_config.py
  id: totrans-409
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipcontroller_config.py
- en: '`ipcontroller` is the master process of your IPython cluster. It controls the
    engines and the distribution of tasks and takes care of tasks such as logging.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '`ipcontroller`是IPython集群的主进程。它控制引擎和任务的分配，并负责诸如日志记录等任务。'
- en: The most important parameter in terms of performance is the `TaskScheduler`
    setting. By default, the `c.TaskScheduler.scheme_name` setting is set to use the
    Python LRU scheduler, but depending on your workload, others such as `leastload`
    and `weighted` might be better. If you have to process so many tasks on such a
    large cluster that the scheduler becomes the bottleneck, there is also the `plainrandom`
    scheduler, which works surprisingly well if all your machines have similar specs
    and the tasks have similar durations.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能方面最重要的参数是`TaskScheduler`设置。默认情况下，`c.TaskScheduler.scheme_name`设置被设置为使用Python
    LRU调度器，但根据你的工作负载，其他如`leastload`和`weighted`可能更好。如果你必须在一个如此大的集群上处理如此多的任务，以至于调度器成为瓶颈，还有一个`plainrandom`调度器，如果所有机器的规格相似且任务持续时间相似，它的工作效果出奇地好。
- en: For the purpose of our test, we will set the IP of the controller to `*`, which
    means that *all* IP addresses will be accepted and that every network connection
    will be accepted. If you are in an unsafe environment/network and/or don’t have
    any firewalls that allow you to selectively enable certain IP addresses, then
    this method is *not* recommended! In such cases, I recommend launching through
    more secure options, such as `SSHEngineSetLauncher` or `WindowsHPCEngineSetLauncher`,
    instead.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 为了我们的测试目的，我们将控制器的IP设置为`*`，这意味着将接受*所有*IP地址，并且接受每个网络连接。如果您处于不安全的环境/网络中，并且/或者没有允许您选择性地启用某些IP地址的防火墙，那么这种方法*不推荐使用*！在这种情况下，我建议通过更安全的选择启动，例如`SSHEngineSetLauncher`或`WindowsHPCEngineSetLauncher`。
- en: 'Assuming your network is indeed safe, set the factory IP to all the local addresses:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您的网络确实安全，将工厂IP设置为所有本地地址：
- en: '[PRE56]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Now start the controller:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 现在启动控制器：
- en: '[PRE57]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Pay attention to the files that were written to the security directory of the
    profile directory. They contain the authentication information that is used by
    `ipengine` to find and connect to the `ipcontroller`, such as the encryption keys
    and port information.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意写入配置目录安全目录的文件。它们包含`ipengine`用于查找和连接到`ipcontroller`的认证信息，例如加密密钥和端口信息。
- en: ipengine_config.py
  id: totrans-418
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipengine_config.py
- en: '`ipengine` is the actual worker process. These processes run the actual calculations,
    so to speed up the processing you will need these on as many machines as you have
    available. You probably won’t need to change this file, but it can be useful if
    you want to configure centralized logging or need to change the working directory.
    Generally, you don’t want to start the `ipengine` process manually since you will
    most likely want to launch multiple processes per computer. That’s where our next
    command comes in, the `ipcluster` command.'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '`ipengine`是实际的工作进程。这些进程运行实际的计算，因此为了加快处理速度，您需要在尽可能多的机器上运行这些进程。您可能不需要更改此文件，但如果您想配置集中式日志记录或需要更改工作目录，它可能很有用。通常，您不希望手动启动`ipengine`进程，因为您很可能会希望每台计算机启动多个进程。这就是我们下一个命令`ipcluster`的作用所在。'
- en: ipcluster_config.py
  id: totrans-420
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipcluster_config.py
- en: The `ipcluster` command is actually just an easy shorthand to start a combination
    of `ipcontroller` and `ipengine` at the same time. For a simple local processing
    cluster, I recommend using this, but when starting a distributed cluster, it can
    be useful to have the control that the separate use of `ipcontroller` and `ipengine`
    offers. In most cases the command offers enough options, so you might have no
    need for the separate commands.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '`ipcluster`命令实际上是一个简单的快捷方式，用于同时启动`ipcontroller`和`ipengine`的组合。对于简单的本地处理集群，我建议使用这个命令，但在启动分布式集群时，使用`ipcontroller`和`ipengine`分别使用可以提供更好的控制。在大多数情况下，该命令提供了足够多的选项，因此您可能不需要单独的命令。'
- en: The most important configuration option is `c.IPClusterEngines.engine_launcher_class`,
    as this controls the communication method between the engines and the controller.
    Along with that, it is also the most important component for secure communication
    between the processes. By default it’s set to `ipyparallel.apps.launcher.LocalControllerLauncher`,
    which is designed for local processes, but `ipyparallel.apps.launcher.SSHEngineSetLauncher`
    is also an option if you want to use SSH to communicate with the clients. Alternatively,
    there is `ipyparallel.apps.launcher.WindowsHPCEngineSetLauncher` for Windows HPC.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的配置选项是`c.IPClusterEngines.engine_launcher_class`，因为它控制着引擎和控制器之间的通信方法。此外，它也是进程之间安全通信最重要的组件。默认情况下，它设置为`ipyparallel.apps.launcher.LocalControllerLauncher`，这是为本地进程设计的，但如果您想使用SSH与客户端通信，`ipyparallel.apps.launcher.SSHEngineSetLauncher`也是一个选项。另外，还有`ipyparallel.apps.launcher.WindowsHPCEngineSetLauncher`用于Windows
    HPC。
- en: Before we can create the cluster on all machines, we need to transfer the configuration
    files. Your options are to transfer all the files or to simply transfer the files
    in your IPython profile’s `security` directory.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以在所有机器上创建集群之前，我们需要传输配置文件。您的选择是传输所有文件，或者简单地传输IPython配置文件`security`目录中的文件。
- en: 'Now it’s time to start the cluster. Since we already started the `ipcontroller`
    separately, we only need to start the engines. On the local machine, we simply
    need to start it, but the other machines don’t have the configuration yet. One
    option is copying the entire IPython profile directory, but the only file that
    really needs copying is `security/ipcontroller-engine.json`; after creating the
    profile using the profile creation command, that is. So unless you are going to
    copy the entire IPython profile directory, you need to execute the profile creation
    command again:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'After that, simply copy the `ipcontroller-engine.json` file and you’re done.
    Now we can start the actual engines:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Note that the `4` here was chosen for a quad-core processor, but any number
    would do. The default will use the number of logical processor cores, but depending
    on the workload it might be better to match the number of physical processor cores
    instead.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can run some parallel code from our IPython shell. To demonstrate the
    performance difference, we will use a simple sum of all the numbers from 0 to
    10,000,000\. Not an extremely heavy task, but when performed 10 times in succession,
    a regular Python interpreter takes a while:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'This time however, to illustrate the difference, we will run it 100 times to
    demonstrate how fast a distributed cluster is. Note that this is with only a three-machine
    cluster, but it’s still quite a bit faster:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'More fun, however, is the definition of parallel functions in `ipyparallel`.
    With just a simple decorator, a function is marked as parallel:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The `ipyparallel` library offers many more useful features, but that is outside
    the scope of this book. Even though `ipyparallel` is a separate entity from the
    rest of Jupyter/IPython, it does integrate well, which makes combining them easy
    enough.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: While preparing for multiple threads and/or multiple processes is less invasive
    than preparing for `asyncio` is, it still requires a bit of thought if you have
    to pass or share variables. So, this is really a question of how difficult you
    want to make it for yourself.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: See if you can make an echo server and client as separate processes.Even though
    we did not cover `multiprocessing.Pipe()`, I trust you can work with it regardless.
    It can be created through `a, b = multiprocessing.Pipe()` and you can use it with
    `[a/b].send()` and `[a/b].recv()`.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: Read all files in a directory and sum the size of the files by reading each
    file using `threading` and `multiprocessing`, or `concurrent.futures` if you want
    an easier exercise. If you want an extra challenge, walk through the directories
    recursively by letting the thread/process queue new items while running.
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a pool of workers that keeps waiting for items to be queued through `multiprocessing.Queue()`.
    Bonus points if you make it a safe RPC (remote procedure call) type operation.
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply your functional programming skills and calculate something in a parallel
    way. Perhaps parallel sorting?
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these exercises are unfortunately still easy compared to what you can
    experience in the wild. If you really want a challenge, start applying these techniques
    (especially memory sharing) to your existing or new projects and hope (or not)
    that you run into a real challenge.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 与您在野外可能遇到的情况相比，所有这些练习仍然很遗憾地很简单。如果您真的想挑战自己，开始将这些技术（特别是内存共享）应用到您现有的或新项目中，并希望（或不是）遇到真正的挑战。
- en: 'Example answers for these exercises can be found on GitHub: [https://github.com/mastering-python/exercises](Chapter_14.xhtml).
    You are encouraged to submit your own solutions and learn about alternative solutions
    from others.'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习的示例答案可以在 GitHub 上找到：[https://github.com/mastering-python/exercises](Chapter_14.xhtml)。我们鼓励您提交自己的解决方案，并从他人的替代方案中学习。
- en: Summary
  id: totrans-444
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: 'We have covered many different topics in this chapter, so let’s summarize them:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了众多不同的主题，所以让我们总结一下：
- en: What the Python GIL is, why we need it, and how we can work around it
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python GIL 是什么，为什么我们需要它，以及我们如何绕过它
- en: When to use threads, when to use processes, and when to use `asyncio`
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何时使用线程，何时使用进程，以及何时使用 `asyncio`
- en: Running code in parallel threads using `threading` and `concurrent.futures`
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `threading` 和 `concurrent.futures` 在并行线程中运行代码
- en: Running code in parallel processes using `multiprocessing` and `concurrent.futures`
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `multiprocessing` 和 `concurrent.futures` 在并行进程中运行代码
- en: Running code distributed across multiple machines
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多台机器上运行分布式代码
- en: Sharing data between threads and processes
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线程和进程之间共享数据
- en: Thread safety
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程安全
- en: Deadlocks
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 死锁
- en: The most important lesson you can learn from this chapter is that the synchronization
    of data between threads and processes is *really slow*. Whenever possible, you
    should only send data to the function and return once it is done, with nothing
    in between. Even in that case, if you can send less data, send less data. If possible,
    keep your calculations and data local.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从本章中学到的最重要的课程是线程和进程之间数据同步**真的非常慢**。只要可能，您应该只向函数发送数据，并在完成时返回，中间不发送任何数据。即使在那种情况下，如果您可以发送更少的数据，请发送更少的数据。如果可能，请保持您的计算和数据本地化。
- en: In the next chapter, we will learn about scientific Python libraries and plotting.
    These libraries can help you perform difficult calculations and data processing
    in record time. These libraries are mostly highly optimized for performance and
    go great together with multiprocessing or the Dask library.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习关于科学 Python 库和绘图的内容。这些库可以帮助您在创纪录的时间内执行困难的计算和数据处理。这些库大多数都高度优化性能，与多进程或
    Dask 库配合得很好。
- en: Join our community on Discord
  id: totrans-456
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers: [https://discord.gg/QMzJenHuJf](https://discord.gg/QMzJenHuJf)'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：[https://discord.gg/QMzJenHuJf](https://discord.gg/QMzJenHuJf)
- en: '![](img/QR_Code156081100001293319171.png)'
  id: totrans-458
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code156081100001293319171.png)'
