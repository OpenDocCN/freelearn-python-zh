<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-16"><a id="_idTextAnchor015"/>1</h1>
<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/>Setting Up Our System for Development</h1>
<p>The aim of this book is to provide a blueprint for a web app running in a production environment and utilizing as many industrial best practices as possible. To do this, we will build a working to-do app, codenamed Tozo, that allows users to track a list of tasks. You can see the finished app in <em class="italic">Figure 1.1</em>:</p>
<div><div><img alt="Figure 1.1: The to-do app we’ll build in this book" height="526" src="img/B18727_01_01.jpg" width="704"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1: The to-do app we’ll build in this book</p>
<p>While the aim is to build a working to-do app, we’ll focus on features that are useful to any app, with much of the functionality and many of the techniques being the same as in the app built here. For example, users will need to log in, change their password, and so on. Therefore, my hope is that you can take this blueprint, remove the small amount of specific to-do code, and build your own app.</p>
<p>In this chapter, we will take a new machine without any tooling and set it up for development. We’ll also set up systems to develop and test the app automatically. Specifically, we’ll install a system package manager and use it to install the various language runtimes and tooling before setting up a remote repository and activating continuous integration. By the end of this chapter, you’ll have everything you need to be able to focus solely on developing the app. This means that you will be able to quickly build and test the features you need in your app for your users. </p>
<p>So, in this chapter, we will cover the following topics:</p>
<ul>
<li>Aiming for fast development</li>
<li>Setting up our system</li>
<li>Installing Python for backend development</li>
<li>Installing NodeJS for frontend development</li>
<li>Installing Terraform for infrastructure development</li>
<li>Installing PostgreSQL for database development</li>
<li>Adopting a collaborative development process using GitHub</li>
</ul>
<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/>Technical requirements</h1>
<p>I’ve built the app described in this book and you can use it by visiting the following link: <a href="https://tozo.dev">https://tozo.dev</a>. The code is also available at <a href="https://github.com/pgjones/tozo">https://github.com/pgjones/tozo</a> (feel free to use that code or the code in this book under the MIT license).</p>
<p>I’m going to assume you have a working knowledge of TypeScript and Python, as these are the languages we’ll use to write the app. However, we’re going to avoid any esoteric language features and I hope the code is easily understandable. I’m also going to assume you are happy using the command line, rather than focusing on GUI instructions, as most tooling is optimized for command-line usage, and this is something that should be advantageous.</p>
<p>To follow the development in this chapter, use the companion repository at <a href="https://github.com/pgjones/tozo">https://github.com/pgjones/tozo</a> and see the commits between the <code>r1-ch1-start</code> and <code>r1-ch1-end</code> tags.</p>
<h1 id="_idParaDest-19"><a id="_idTextAnchor018"/>Aiming for fast development</h1>
<p>Before we start setting up our system to build the to-do app, it’s important to understand what we are aiming<a id="_idIndexMarker000"/> for when building any app, which is to solve our customer’s needs by shipping solutions as quickly as possible. This means that we must understand their needs, translate them into working code, and crucially, deploy the solution with confidence that it works as expected. </p>
<p>When we are developing an app, the shorter the time between making a change to the code and being able to run and see the effect of the change, the better. This is why we will run all of the code locally, with auto-reloading enabled; this should mean that any change we make is testable in our local browser within a few seconds.</p>
<p class="callout-heading">Hot/auto-reloading</p>
<p class="callout">In development, we ideally want any changes we make to the code to take effect immediately so that we can check that the changes have the desired effect. This feature is called hot or auto-reloading<a id="_idIndexMarker001"/> and is active with the React and Quart development servers we are using in this book.</p>
<p>I also like to use tooling to help speed up development and gain confidence that the code works as expected. This tooling should run as frequently as possible, ideally as part of an automated process. I have split this tooling into auto-formatting, linting, and testing categories.</p>
<h2 id="_idParaDest-20"><a id="_idTextAnchor019"/>Auto-formatting the code</h2>
<p>The format and style of code matter as a different style<a id="_idIndexMarker002"/> to the one you are used to will take longer for you to understand. This will mean more bugs as you spend more of your time comprehending the style rather than logic. Also, while you can be consistent, almost everyone has a different preferred style, and I’ve found that these preferences change over time.</p>
<p>In the past, I’ve used tooling to check the styling and report on any inconsistencies. This is helpful but wasteful as every inconsistency<a id="_idIndexMarker003"/> must be fixed manually. Fortunately, most languages now have an official, or dominant, <strong class="bold">auto-formatter</strong> that both defines a style and changes all of the code to match it. Using the most popular auto-formatter means that most developers will recognize your code.</p>
<p>We’ll aim to set up our tooling so that there are auto-formatters for as much of the code as possible.</p>
<h2 id="_idParaDest-21"><a id="_idTextAnchor020"/>Linting the code</h2>
<p>I think of <strong class="bold">linting</strong> in two parts: type<a id="_idIndexMarker004"/> checking and static<a id="_idIndexMarker005"/> analysis. Type checking<a id="_idIndexMarker006"/> requires that we include types when writing the code. I use type hinting, or typed languages, where possible, as this catches a large number of the errors I typically make. Typing also helps document the code, meaning that it makes it clear what objects (types) are expected. While typing costs more effort to write, I think it easily pays off in bugs avoided. Therefore, checking the typing should be our first aim of linting.</p>
<p>The second part, static analysis, allows linters to look for potential<a id="_idIndexMarker007"/> issues in naming, usage of functions, possible bugs, security issues, and unused code, and to flag code that is too complex or poorly constructed. These linters are a very low-cost sanity check as they are quick and easy to run and give few false issues (positives).</p>
<h2 id="_idParaDest-22"><a id="_idTextAnchor021"/>Testing the code</h2>
<p>While linting<a id="_idIndexMarker008"/> will identify bugs and issues with the code, it cannot detect logical issues where correctly written code does the wrong thing. To identify these, we need to write tests that check that the execution of the code results in the expected output. Therefore, it is important that we write tests as we write the code, especially when we discover bugs. We will focus on writing tests that provide an easy way to test that the app works as expected.</p>
<p class="callout-heading">Test coverage</p>
<p class="callout">Test coverage is used to measure how much of the code<a id="_idIndexMarker009"/> has been tested by the test suite. This is typically done by measuring the ratio of lines executed by the tests to the total lines of code. I find this metric unhelpful as it focuses on lines executed rather than use cases that matter to the user. Therefore, I’d encourage you to focus on testing the use cases you think your users require. However, if you’d like to measure coverage this way, you can install <code>pytest-cov</code> using <code>pdm</code>.</p>
<p>Using auto-formatters, linters, and a testing suite allows us to develop with greater confidence and therefore speed, which in turn means a better experience for our users. However, in order to use these tools, we will first need to set up our system effectively.</p>
<h1 id="_idParaDest-23"><a id="_idTextAnchor022"/>Setting up our system</h1>
<p>To effectively develop<a id="_idIndexMarker010"/> our app, we will need to be able to develop and<a id="_idIndexMarker011"/> run it. This means we will need tooling to manage changes to the code, test and check the app for errors, and run it. This tooling can be installed via a system package manager, of which there are many choices depending on your operating system. I recommend<a id="_idIndexMarker012"/> that you install Homebrew on Linux (https://linuxbrew.sh) and macOS (https://brew.sh), or Scoop (<a href="https://scoop.sh">https://scoop.sh</a>) on Windows. I’ll show<a id="_idIndexMarker013"/> both <code>brew</code> and <code>scoop</code> commands<a id="_idIndexMarker014"/> in this book, but you should only use the command that works on your operating system.</p>
<p>You will also need a code editor to write the code in and a browser to run the app. I recommend<a id="_idIndexMarker015"/> that you install VS Code (<a href="https://code.visualstudio.com">https://code.visualstudio.com</a>) and Chrome (<a href="https://www.google.com/chrome">https://www.google.com/chrome</a>) via the directions given<a id="_idIndexMarker016"/> on their websites. With these tools installed, we can now consider how we’ll manage the code.</p>
<h2 id="_idParaDest-24"><a id="_idTextAnchor023"/>Managing the code</h2>
<p>As we develop our app, we will<a id="_idIndexMarker017"/> inevitably make mistakes and want to return to the previous working version. You may also want to share the code with others, or just keep a backup for yourself. This<a id="_idIndexMarker018"/> is why we need to manage the code via a <strong class="bold">version control</strong> system. While there are many different version control systems, the majority<a id="_idIndexMarker019"/> in this industry use git (<a href="https://git-scm.com">https://git-scm.com</a>). It can be installed via<a id="_idIndexMarker020"/> the system package manager<a id="_idIndexMarker021"/> as follows:</p>
<pre>brew install git
scoop install git</pre>
<p class="callout-heading">Using git</p>
<p class="callout">This book can be completed<a id="_idIndexMarker022"/> using <code>git add</code> to add files to the repository, <code>git commit</code> to create commits, and <code>git push</code> to update the remote repository. I consider these to be the basic git commands. However, git can still be very confusing to use, and you may end up with your repository in a mess. It does get easier with practice and there is plenty of help online. You can always delete your local repository and start again from the remote version (as I have done many times before).</p>
<p>Now we have git<a id="_idIndexMarker023"/> installed, let’s set the author information<a id="_idIndexMarker024"/> as follows:</p>
<pre class="source-code">
git config --global user.name "<strong class="bold">Phil Jones</strong>"
git config --global user.email "<strong class="bold">pgjones@tozo.dev</strong>"</pre>
<p>The highlighted values should be changed to your name and email address.</p>
<p>Next, we can create a repository for our code by creating a directory called <em class="italic">tozo</em> and running the following command within it:</p>
<pre>git init .</pre>
<p>This will create a <em class="italic">.git</em> directory that can be safely ignored. This results in the following project structure: </p>
<pre class="source-code">
tozo
└── .git</pre>
<p>As we develop, we will want git to ignore certain files and paths. We will do this by creating <em class="italic">.gitignore</em> files that list the filenames and file paths that we do not want to be part of our repository.</p>
<p class="callout-heading">Writing good commits</p>
<p class="callout">The history of changes <a id="_idIndexMarker025"/>stored by git can serve as an excellent companion document for your code if git is used well. This is something that won’t seem advantageous at the start, but after a year of development, it will be something you’ll sorely miss if you hadn’t done it from the beginning. So, I strongly recommend you write good commits.</p>
<p class="callout">A good commit contains a single atomic change to the code. This means it is focused (doesn’t combine different changes into one commit) and that it is complete (every commit leaves the code working). </p>
<p class="callout">A good commit<a id="_idIndexMarker026"/> is also well described and reasoned. This means the commit message explains why the change has been made. This contextual information is invaluable as it will be forgotten quickly and is often required to understand the code.</p>
<p>With git<a id="_idIndexMarker027"/> installed, we can start<a id="_idIndexMarker028"/> committing changes; however, we should establish how we intend to combine changes, which, in my opinion, should be done by rebasing. </p>
<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/>Rebasing rather than merging</h2>
<p>As I pu<a id="_idTextAnchor025"/>t a lot of value on the git commit history, I recommend using rebases<a id="_idIndexMarker029"/> rather than merges when combining changes. The former will move local new commits on top of any remote changes, rewriting and leaving a linear clear history, whereas the latter will introduce a merge commit. To make this change, run the following code:</p>
<pre>git config --global pull.rebase true</pre>
<p>We’ve now set up our system with a package manager and version control. Next, we can install the specific tooling we need for the various aspects of the app.</p>
<h1 id="_idParaDest-26"><a id="_idTextAnchor026"/>Installing Python for backend development</h1>
<p>There are a variety<a id="_idIndexMarker030"/> of languages that are suitable<a id="_idIndexMarker031"/> for backend development, and any would be a fine choice for your app. In this book, I’ve chosen to use Python as I find that the code is more accessible and easier to follow than other languages. </p>
<p>As we will be writing the backend for our app in <strong class="bold">Python</strong>, we will need to have it installed locally. While you may have a Python version already installed, I’d recommend you use the one installed by the system package manager, as follows:</p>
<pre>brew install python
scoop install python</pre>
<p>The package manager<a id="_idIndexMarker032"/> we’ve used so far doesn’t know how to install<a id="_idIndexMarker033"/> and manage Python packages, so we also need another package manager. There are many choices in Python, and I think PDM is the best. PDM can be installed with the system package manager on Linux and macOS systems, as follows:</p>
<pre>brew install pdm</pre>
<p>For Windows systems, it can be installed by running the following commands:</p>
<pre>scoop bucket add frostming https://github.com/frostming/scoop-frostming.git
scoop install pdm</pre>
<p>We’ll keep the backend code separate in a backend folder, so please create a <em class="italic">backend</em> folder at the top level of the project with the following folder structure:</p>
<pre class="source-code">
tozo
└── backend
    ├── src
    │   └── backend
    └── tests</pre>
<p>Next, we need to inform git that there are files that we don’t want to be tracked in the repository and hence it should ignore them by adding the following to <em class="italic">backend/.gitignore</em>:</p>
<pre class="source-code">
/__pypackages__
/.mypy_cache
.pdm.toml
.pytest_cache
.venv
*.pyc</pre>
<p>For PDM to manage our project, we need to run the following command in the <em class="italic">backend</em> directory:</p>
<pre>pdm init</pre>
<p>When prompted, you should choose<a id="_idIndexMarker034"/> the Python version installed using<a id="_idIndexMarker035"/> the system package manager earlier.</p>
<p>We can now focus on the specific Python tooling for fast development.</p>
<h2 id="_idParaDest-27"><a id="_idTextAnchor027"/>Formatting the code</h2>
<p>Python does not have an official format<a id="_idIndexMarker036"/> or formatter; however, <code>black</code> is the de facto formatter for code and <code>isort</code> is the de facto formatter for imports. We can add both to our project by running the following command in the <em class="italic">backend</em> directory:</p>
<pre>pdm add --dev black isort</pre>
<p class="callout-heading">The dev flag</p>
<p class="callout">We use the <code>--dev</code> flag here as these tools are only required for developing the backend and therefore do not need to be installed when running in production.</p>
<p><code>black</code> and <code>isort</code> require the following configuration to work well together. This should be added to the end of the <em class="italic">backend/pyproject.toml</em> file (you may have to change the <code>target-version</code> if you are using a version of Python other than 3.10) as follows:</p>
<pre class="source-code">
[tool.black]  
target-version = ["py310"] 
[tool.isort]
profile = "black"</pre>
<p>The following commands will run <code>black</code> and <code>isort</code> on our code in the <em class="italic">src</em> and <em class="italic">tests</em> folders:</p>
<pre class="source-code">
pdm run black src tests
pdm run isort src tests</pre>
<p>We’ll be using Jinja templates for emails sent by our app. While these templates are code, they are not Python and hence require a different formatter. Thankfully, <code>djhtml</code> can be used to format the templates and is added by running the following command in the <em class="italic">backend</em> folder: </p>
<pre>pdm add --dev djhtml</pre>
<p>The following command will run <code>djhtml</code> on our template code:</p>
<pre>djhtml src/backend/templates --tabwidth 2 --check</pre>
<p>We’ve now installed <a id="_idIndexMarker037"/>the tooling we need to format the code in the backend. Next, we can install the tooling we need to lint the code.</p>
<h2 id="_idParaDest-28"><a id="_idTextAnchor028"/>Linting the code</h2>
<p>Python supports type<a id="_idIndexMarker038"/> hints that describe the expected types of variables, functions, and so on. We’ll use type hints and tooling to check that we haven’t introduced any type-related bugs. The most popular type checking tool for Python is <code>mypy</code>. It is installed by running the following command in the <em class="italic">backend</em> directory:</p>
<pre>pdm add --dev mypy</pre>
<p>The following command will run <code>mypy</code> over the backend code:</p>
<pre>pdm run mypy src/backend/ tests/</pre>
<p>With <code>mypy</code> helping us find type errors, we can add <code>Flake8</code> to help us find other bugs. <code>Flake8</code> is installed with <code>pdm</code> as follows:</p>
<pre>pdm add --dev flake8</pre>
<p><code>Flake8</code> must be configured to work with <code>black</code> and <code>mypy</code> by adding the following to <em class="italic">backend/setup.cfg</em>:</p>
<pre class="source-code">
[flake8] 
max-line-length = 88
extend-ignore = E203</pre>
<p><code>Flake8</code> is used by running the following command:</p>
<pre>pdm run flake8 src/ tests/</pre>
<p>There is another type<a id="_idIndexMarker039"/> of bug that we can use tooling to help us find, and these are related to security. A good example would be checking for a SQL injection vulnerability. Bandit is another linter that helps identify these bugs, and it is installed by running the following command in the <em class="italic">backend</em> directory:</p>
<pre>pdm add --dev bandit</pre>
<p>Bandit only needs to lint the <code>src</code> code as the test code does not run during production. To run Bandit over the <code>src</code> code, the following command is used:</p>
<pre>pdm run bandit -r src/</pre>
<p class="callout-heading">Bandit ModuleNotFoundErrors</p>
<p class="callout">Bandit<a id="_idIndexMarker040"/> may fail to run with the error <code>ModuleNotFoundError: No module named ‘pkg_resources’</code>. If this happens, then run <code>pdm add --dev setuptools</code> to add the missing module.</p>
<p>We now have tooling looking for bugs, but we can also add tooling to look for unused code. This is helpful as code can often be forgotten during refactoring, leaving files that are much more complex to read and understand than they should be. I like to use <code>vulture</code> to find unused code, and it is installed by running the following command in the <em class="italic">backend</em> directory:</p>
<pre>pdm add --dev vulture</pre>
<p>Unfortunately, <code>vulture</code> can report false positives, so I like to configure it to be 100% confident when reporting issues by adding the following configuration to <em class="italic">backend/pyproject.toml</em>:</p>
<pre class="source-code">
[tool.vulture]
min_confidence = 100</pre>
<p>Like Bandit, it is best <a id="_idIndexMarker041"/>to run <code>vulture</code> over the <code>src</code> code only (not the tests) via the following command:</p>
<pre>pdm run vulture src/</pre>
<p>Now, let’s look at what we need to test the code.</p>
<h2 id="_idParaDest-29"><a id="_idTextAnchor029"/>Testing the code</h2>
<p>Python has <code>unittest</code> as part of its<a id="_idIndexMarker042"/> standard library, however, I think using <code>pytest</code> is superior. <code>pytest</code> is very feature-rich and allows for very simple and clear tests, such as the following small example that tests that a simple addition is correct:</p>
<pre class="source-code">
def test_addition():
    assert 1 + 1 == 2</pre>
<p><code>pytest</code> requires the <code>pytest-asyncio</code> plugin to test async code, and they are both installed with <code>pdm</code> as follows:</p>
<pre>pdm add --dev pytest pytest-asyncio </pre>
<p><code>pytest</code> is best configured to show local variables on test failure as this makes it much easier to understand why the test is failing. In addition, the <code>asyncio</code> mode should be set to <code>auto</code> to make writing async tests easier. The following configuration should be placed in <em class="italic">backend/pyproject.toml</em>:</p>
<pre class="source-code">
[tool.pytest.ini_options]
addopts = "--showlocals"
asyncio_mode = "auto"
pythonpath = ["src"]</pre>
<p>To run the tests, <code>pytest</code> is invoked with the <code>tests</code> path as follows: </p>
<pre>pdm run pytest tests</pre>
<p>Now that we’ve installed all of the tooling, we need some simple commands to run it. </p>
<h2 id="_idParaDest-30"><a id="_idTextAnchor030"/>Scripting the commands</h2>
<p>We’ve added a lot of useful tooling<a id="_idIndexMarker043"/> to our project; however, each one had a different unique command that we’d have to remember. This is something we can simplify by making use of PDM’s scripting feature as it can be used to map PDM commands to the required commands. We will add the following three PDM scripting commands: </p>
<ul>
<li><code>pdm run format</code> to run the formatting tooling and format the code</li>
<li><code>pdm run lint</code> to run the linting tooling and lint the code</li>
<li><code>pdm run test</code> to run the tests</li>
</ul>
<p>PDM’s scripting requires these script commands to be added to the <em class="italic">backend/pyproject.toml</em> file as follows:</p>
<pre class="source-code">
[tool.pdm.scripts]
format-black = "black src/ tests/"
format-djhtml = "djhtml src/backend/templates -t 2 --in-place"
format-isort = "isort src tests"
format = {composite = ["format-black", "format-djhtml", "format-isort"]}
lint-bandit = "bandit -r src/"
lint-black = "black --check --diff src/ tests/"
lint-djhtml = "djhtml src/backend/templates -t 2 --check"
lint-flake8 = "flake8 src/ tests/"
lint-isort = "isort --check --diff src tests"
lint-mypy = "mypy src/backend tests"
lint-vulture = "vulture src"
lint = {composite = ["lint-bandit", "lint-black", "lint-djhtml", "lint-flake8", "lint-isort", "lint-mypy", "lint-vulture"]}
test = "pytest tests/"</pre>
<p>With the backend tooling<a id="_idIndexMarker044"/> in place and accessible via easy-to-remember commands, we can now do the same for the frontend.</p>
<h1 id="_idParaDest-31"><a id="_idTextAnchor031"/>Installing NodeJS for frontend development</h1>
<p>As we want our app<a id="_idIndexMarker045"/> to run in the browser, we will need to write<a id="_idIndexMarker046"/> the frontend in JavaScript or a language that compiles to it. There are many good choices, but I’ve chosen to use <strong class="bold">TypeScript</strong> as it is JavaScript with the addition<a id="_idIndexMarker047"/> of typing (as in, it is the same basic language). This means it is close to the required runtime language and has the additional safety and documentation from the typing.</p>
<p>As we will be writing the frontend in TypeScript, we will need <strong class="bold">NodeJS</strong> installed to compile TypeScript to the JavaScript that will run in the browser. NodeJS is best installed with the system package manager as follows:</p>
<pre>brew install node
scoop install nodejs</pre>
<p>Unlike Python, where we installed a specific package manager, NodeJS comes with one called <code>npm</code>. We’ll use <code>npm</code> to manage the frontend dependencies and tooling. <code>npm</code> also includes the <code>npx</code> tool that we will use to run one-off scripts.</p>
<p>As with the backend, we’ll separate the frontend code into a frontend folder. Then, we’ll use the <code>create-react-app</code> tool in this new folder to set everything up by running the following command in the project directory:</p>
<pre>npx create-react-app frontend --template typescript</pre>
<p>It should give the following folder structure:</p>
<pre class="source-code">
tozo
└── frontend
    ├── node_modules
    ├── public
    └── src</pre>
<p>Of the files also installed, only the <em class="italic">frontend/package.json</em>, <em class="italic">frontend/package-lock.json</em>, <em class="italic">frontend/tsconfig.json</em>, <em class="italic">frontend/.gitignore</em>, <em class="italic">frontend/src/react-app-env.d.ts</em>, and <em class="italic">frontend/public/index.xhtml</em> files matter<a id="_idIndexMarker048"/> at the moment, so you<a id="_idIndexMarker049"/> can delete or adapt the other files as you’d like.</p>
<p>We can now focus on the specific NodeJS tooling for fast development.</p>
<h2 id="_idParaDest-32"><a id="_idTextAnchor032"/>Formatting the code</h2>
<p>TypeScript does<a id="_idIndexMarker050"/> not have an official format/formatter; however, Prettier is the de facto formatter. We should add it to the project as a development dependency by running the following command in the <em class="italic">frontend</em> directory:</p>
<pre>npm install --save-dev prettier</pre>
<p class="callout-heading">The --save-dev flag</p>
<p class="callout">We use the <code>--save-dev</code> flag here as these tools are only required<a id="_idIndexMarker051"/> to develop the frontend, and therefore do not need to be installed when running in production.</p>
<p>By default, Prettier does not add trailing commas, which is different from the style used in Python. To be consistent and therefore not have to think about this, Prettier can be configured by adding the following section to <em class="italic">frontend/package.json</em>:</p>
<pre class="source-code">
"prettier": {
  "trailingComma": "all" 
}</pre>
<p>The following command will then run Prettier over our code:</p>
<pre>npx prettier --parser typescript --write "src/**/*.{ts,tsx}"</pre>
<p>We’ve now installed the tooling to format the code and we can focus on the tooling to lint it.</p>
<h2 id="_idParaDest-33"><a id="_idTextAnchor033"/>Linting the code</h2>
<p>In the preceding<a id="_idIndexMarker052"/> section, we required a linter to type check our Python code, however, as we are using TypeScript, we do not need to install anything extra to type check. However, we can install linters to check for other bugs; the de facto linter for TypeScript and JavaScript is <code>eslint</code>, which is installed by running the following command in the <em class="italic">frontend</em> directory:</p>
<pre>npm install --save-dev eslint </pre>
<p>By default, <code>eslint</code> is not compatible with Prettier; fortunately, the <code>eslint-config-prettier</code> package configures <code>eslint</code> to be compatible. It is installed by running the following command in the <em class="italic">frontend</em> directory:</p>
<pre>npm install --save-dev eslint-config-prettier</pre>
<p>As with the backend, we should order our imports using <code>eslint-plugin-import</code>, which is installed with <code>npm</code> as follows:</p>
<pre>npm install --save-dev eslint-plugin-import</pre>
<p>These linters are then configured by replacing the existing <code>eslintConfig</code> section with the following in <em class="italic">frontend/package.json</em>:</p>
<pre class="source-code">
"eslintConfig": {
  "extends": [
<strong class="bold">    "react-app",</strong>
<strong class="bold">    "react-app/jest",</strong>
    "plugin:import/errors",
    "plugin:import/warnings",
    "plugin:import/typescript",
    "prettier"
  ]
}</pre>
<p>The highlighted lines will already be present.</p>
<p><code>eslint</code> can be run over our code via the following command:</p>
<pre>npx eslint "src/**/*.{ts,tsx}"</pre>
<p><code>eslint</code> can also fix some of the issues it identifies via the use of the <code>--fix</code> flag as follows:</p>
<pre>npx eslint --fix "src/**/*.{ts,tsx}"</pre>
<p>We’ve now installed the tooling to lint the code<a id="_idIndexMarker053"/> and we can focus on the tooling to test it.</p>
<h2 id="_idParaDest-34"><a id="_idTextAnchor034"/>Testing the code</h2>
<p>The <code>create-react-app</code> tool used earlier also installed<a id="_idIndexMarker054"/> a test runner called Jest, which we can invoke <a id="_idIndexMarker055"/>by running the following:</p>
<pre>npm run test</pre>
<p>Jest allows for tests to be written using an <code>expect</code> syntax, as shown in the following example:</p>
<pre class="source-code">
test('addition', () =&gt; {
  expect(1 + 1).toBe(2);
});</pre>
<p>With the testing tooling present, we can focus on analyzing the built bundle.</p>
<h2 id="_idParaDest-35"><a id="_idTextAnchor035"/>Analyzing the bundle</h2>
<p>The frontend code will be delivered <a id="_idIndexMarker056"/>as bundles (in chunks) to the user. These bundles, especially the main bundle, should be small so that the user isn’t waiting too long for the code to be downloaded. To check the bundle size and analyze what is included in each bundle, I use <code>source-map-explorer</code>, which is installed by running the following command in the <em class="italic">frontend</em> directory:</p>
<pre>npm install --save-dev source-map-explorer</pre>
<p>Before we can analyze the bundle sizes, we first need to build them by running the following command:</p>
<pre>npm run build</pre>
<p>Then, we can analyze them via this command:</p>
<pre>npx source-map-explorer build/static/js/*.js</pre>
<p>The output from the preceding command is shown in <em class="italic">Figure 1.2</em>:</p>
<div><div><img alt="Figure 1.2: The output from source-map-explorer showing that the main bundle is 141 KB " height="340" src="img/Figure_1.2_NEW.jpg" width="1140"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2: The output from source-map-explorer showing that the main bundle is 141 KB</p>
<p>Each bundle should<a id="_idIndexMarker057"/> be as small as possible, with a good rule of thumb being that bundles should be split when the bundle exceeds 1 MB. We’ll find that we need to do this when we add a password complexity analyzer to the frontend in <a href="B18727_04.xhtml#_idTextAnchor111"><em class="italic">Chapter 4</em></a>, <em class="italic">Creating a Reusable Frontend with React</em>.</p>
<h2 id="_idParaDest-36"><a id="_idTextAnchor036"/>Scripting the commands</h2>
<p>To match the backend, we want to add<a id="_idIndexMarker058"/> the following commands:</p>
<ul>
<li><code>npm run analyze</code> to run the bundle analyzer</li>
<li><code>npm run format</code> to run the formatting tooling and format the code</li>
<li><code>npm run lint</code> to run the linting tooling</li>
<li><code>npm run test</code> to run the tests</li>
</ul>
<p>As <code>npm run test</code> is already present, we only need to add the other three. This is done by adding the following to the <code>scripts</code> section in <em class="italic">frontend/package.json</em>:</p>
<pre class="source-code">
"scripts": {
  "analyze": "npm run build &amp;&amp; source-map-explorer \"build/static/js/*.js\"",
  "format": "eslint --fix \"src/**/*.{ts,tsx}\" &amp;&amp; prettier --parser typescript --write \"src/**/*.{ts,tsx}\"",
  "lint": " eslint \"src/**/*.{ts,tsx}\" &amp;&amp; prettier --parser typescript --list-different  \"src/**/*.{ts,tsx}\"",
<strong class="bold">  "start": "react-scripts start",</strong>
<strong class="bold">  "build": "react-scripts build",</strong>
<strong class="bold">  "test": "react-scripts test",</strong>
<strong class="bold">  "eject": "react-scripts eject"</strong>
}</pre>
<p>The highlighted lines will already be present in the section.</p>
<p>With the frontend tooling<a id="_idIndexMarker059"/> in place and accessible via the easy-to-remember commands, we can now do the same for the infrastructure. </p>
<h1 id="_idParaDest-37"><a id="_idTextAnchor037"/>Installing Terraform for infrastructure development</h1>
<p>We’ll need to create and manage<a id="_idIndexMarker060"/> remote infrastructure, starting<a id="_idIndexMarker061"/> with a remote repository that we will use to develop the app with other developers or to simply backup our code. This remote infrastructure could be created manually, f<a id="_idTextAnchor038"/>or example, using GitHub’s web interface. However, by using an Infrastructure as a Code tool, we can record all of the changes we make, and then if anything goes wrong, we can rerun our code and restore everything to a known state.</p>
<p>I find <strong class="bold">Terraform</strong> to be the best tool to manage infrastructure, which we can install as follows:</p>
<pre>brew install terraform
scoop install terraform</pre>
<p>With Terraform installed, we can create a folder within our repository for the infrastructure code as follows:</p>
<pre>mkdir infrastructure</pre>
<p>Our repository should now have the following structure:</p>
<pre class="source-code">
tozo
├── backend
├── frontend
└── infrastructure</pre>
<p>As with the backend<a id="_idIndexMarker062"/> and frontend, we’ll need to install tooling<a id="_idIndexMarker063"/> to help development. In addition, for the infrastructure, we’ll need tooling to manage secrets.</p>
<h2 id="_idParaDest-38"><a id="_idTextAnchor039"/>Managing secrets</h2>
<p>To allow Terraform<a id="_idIndexMarker064"/> to manage our infrastructure, we will need<a id="_idIndexMarker065"/> to provide passwords, keys, and other secrets. These secrets will need to be stored (and used) in a secure fashion – simply storing passwords in plain text in the repository is a common way to be hacked. We will instead encrypt the secrets and store the encrypted file in the repository. This means we’ll have to keep the encryption key secret, which I recommend you do by using a password manager such as BitWarden.</p>
<p>To encrypt the secrets, we can use <code>ansible-vault</code>, which is installed using the Python package manager, <code>pip</code>, as follows:</p>
<pre>pip install ansible-vault</pre>
<p class="callout-heading">pip or PDM</p>
<p class="callout">pip<a id="_idIndexMarker066"/> is a tool for installing packages, whereas PDM<a id="_idIndexMarker067"/> is a project management tool. As we don’t have an infrastructure project to manage, it makes more sense to use pip to install <code>ansible-vault</code>. However, this is the only time we’ll directly use pip.</p>
<p>To configure <code>ansible-vault</code>, we need to provide the encryption key. To do so, add your encryption key to <em class="italic">infrastructure/.ansible-vault</em> and inform Ansible that it is stored there by adding the following to <em class="italic">infrastructure/ansible.cfg</em>:</p>
<pre class="source-code">
[defaults]
vault_password_file = .ansible-vault</pre>
<p>We’ll need to encrypt<a id="_idIndexMarker068"/> two files: Terraform’s state, <code>terraform.tfstate</code>, and our collection<a id="_idIndexMarker069"/> of secret variables, <code>secrets.auto.tfvars</code>. The commands to do so are the following:</p>
<pre class="source-code">
ansible-vault encrypt secrets.auto.tfvars --output=secrets.auto.tfvars.vault 
ansible-vault encrypt terraform.tfstate --output=terraform.tfstate.vault</pre>
<p>We will also need to decrypt these files, which is done via the following commands:</p>
<pre class="source-code">
ansible-vault decrypt secrets.auto.tfvars.vault --output=secrets.auto.tfvars 
ansible-vault decrypt terraform.tfstate.vault --output=terraform.tfstate</pre>
<p>To ensure that the password file, encrypted files, and general Terraform autogenerated files aren’t considered part of the repository, the following should be added to <em class="italic">infrastructure/.gitignore</em>:</p>
<pre class="source-code">
.ansible-vault 
secrets.auto.tfvars
terraform.tfstate 
*.backup 
.terraform.lock.hcl 
.terraform/</pre>
<p>Terraform is now set up and ready to use, which means we can focus on the development tooling.</p>
<h2 id="_idParaDest-39"><a id="_idTextAnchor040"/>Formatting, linting, and testing the code</h2>
<p>Terraform comes<a id="_idIndexMarker070"/> with a built-in formatter, which is invoked via the following command:</p>
<pre>terraform fmt</pre>
<p>This formatter also supports a check mode to use when linting, as follows:</p>
<pre>terraform fmt --check=true</pre>
<p>Terraform also comes with a tool to lint<a id="_idIndexMarker071"/> your code, as follows:</p>
<pre>terraform validate</pre>
<p>Testing<a id="_idIndexMarker072"/> Terraform code is harder as almost all of the code depends on an interaction with a third-party service. Instead, I find running and checking that the output makes sense to be the only way to test what the code will do. Terraform will provide an output of what it plans to do by running the following command:</p>
<pre>terraform plan</pre>
<p>This is all we need to install and set up to manage all of the infrastructure we’ll install in this book. We can now focus on the database.</p>
<h1 id="_idParaDest-40"><a id="_idTextAnchor041"/>Installing PostgreSQL for database development</h1>
<p>Our app will need to store<a id="_idIndexMarker073"/> data (the to-dos) in a structured form, which makes a database<a id="_idIndexMarker074"/> an ideal choice. This database will need to be running locally to allow us to develop with it, so we need to install it. The database I prefer is <strong class="bold">PostgreSQL</strong>, which is a SQL-based relational database. I prefer it as it is very widely supported, and very powerful. </p>
<p>PostgreSQL is installed using the system package manager as follows:</p>
<pre>brew install postgres
scoop install postgresql</pre>
<p>If using <code>brew</code>, you will likely need to start <code>postgresql</code> as a service that runs in the background, as follows:</p>
<pre>brew services start postgresql</pre>
<p>In addition, when using <code>brew</code>, we need to create a superuser, which by convention is called <em class="italic">postgres</em>. This user is created<a id="_idIndexMarker075"/> with the following command:</p>
<pre>createuser -s postgres</pre>
<p>However, with <code>scoop</code>, you will have to start the PostgreSQL database whenever you wish to use it with the following command:</p>
<pre>pg_ctl start</pre>
<p>With the addition<a id="_idIndexMarker076"/> of the database tooling, we have all<a id="_idIndexMarker077"/> of the local tooling we need to develop our app. This means we can focus on the remote tooling, a GitHub repository.</p>
<h1 id="_idParaDest-41"><a id="_idTextAnchor042"/>Adopting a collaborative development process  using GitHub</h1>
<p>While you may be working<a id="_idIndexMarker078"/> on your own, it is good practice to adopt<a id="_idIndexMarker079"/> a development process that allows others to collaborate and one that ensures that the code is always ready to be deployed to production. We will achieve both aims by using a remote repository and <strong class="bold">Continuous Integration</strong> (<strong class="bold">CI</strong>).</p>
<p>A remote repository acts as a backup for all your code and makes it much easier to set up CI (testing, linting, and so on). We’ll use GitHub as I find it to have all the features needed, although other platforms, such as GitLab, are also valid and commonly used in the industry.</p>
<p>Rather than creating the repository through GitHub’s UI, we’ll use Terraform as set up earlier. To do so, we’ll first need a personal access token from GitHub, as explained at <a href="https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token">https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token</a>. The token will need the <code>repo</code>, <code>workflow</code>, and <code>delete_repo</code> scopes. This token is a secret and hence best placed in <em class="italic">infrastructure/secrets.auto.tfvars</em> and encrypted as described earlier in the <em class="italic">Managing secrets</em> section. The code should be placed into <em class="italic">infrastructure/secrets.auto.tfvars</em> as follows (replace <code>abc1234</code> with your token):</p>
<pre>github_token = "abc1234"</pre>
<p>Terraform itself does<a id="_idIndexMarker080"/> not know how to interact<a id="_idIndexMarker081"/> with GitHub, which means that we need to install the GitHub provider to do so. This is done by adding the following code to <em class="italic">infrastructure/main.tf</em>:</p>
<pre class="source-code">
terraform {
  required_providers {
    github = {
      source  = "integrations/github"
      version = "~&gt; 4.0"
    }
  }
  required_version = "&gt;=1.0"
}</pre>
<p>With the provider present, we can describe the repository we would like to exist by adding the following code to <em class="italic">infrastructure/github.tf</em>:</p>
<pre class="source-code">
variable "github_token" {
  sensitive = true
}
 
provider "github" {
  token = var.github_token
}
 
resource "github_repository" "tozo" {
  name       = "tozo"
  visibility = "private"
}</pre>
<p>Finally, to actually create the repository, we need to initialize and apply Terraform as follows:</p>
<pre class="source-code">
terraform init 
terraform apply</pre>
<p>We should now set up <code>git</code> so that it knows<a id="_idIndexMarker082"/> about the remote<a id="_idIndexMarker083"/> repository. To do this, we’ll need the correct path, which will depend on your GitHub account name and the name of your project. As my GitHub account name is <em class="italic">pgjones</em> and this project is called <em class="italic">tozo</em>, the path is <em class="italic">pgjones/tozo</em>, making the following command:</p>
<pre>git remote add origin git@github.com:pgjones/tozo.git</pre>
<p>To have our local branch track the remote <code>origin</code> <code>main</code> branch, run the following command:</p>
<pre>git push --set-upstream origin main </pre>
<p>To push our local changes on our <code>main</code> branch to the remote <code>feature</code> branch, run the following command:</p>
<pre>git push origin main:feature</pre>
<p>To pull the remote <code>main</code> branch to update our local branch, run the following command:</p>
<pre>git pull origin main</pre>
<p>Most in this industry operate a development workflow based on merge (pull) requests, which we’ll also adopt. This workflow consists of the following steps:</p>
<ol>
<li>Develop a feature locally consisting of as few commits as makes sense (small changes). </li>
<li>Push the feature to a remote <code>feature</code> branch.</li>
<li>Open a merge request based on that branch.</li>
<li>Review the merge request, merging it to the <code>main</code> branch only if CI passes.</li>
<li>Pull the latest <code>main</code> branch and repeat.</li>
</ol>
<p>With<a id="_idIndexMarker084"/> the repository created, we can now<a id="_idIndexMarker085"/> look at adding CI. </p>
<h2 id="_idParaDest-42"><a id="_idTextAnchor043"/>Adding continuous integration</h2>
<p>GitHub provides<a id="_idIndexMarker086"/> a CI system called Actions<a id="_idIndexMarker087"/> that has a free tier, which<a id="_idIndexMarker088"/> we’ll use. To start, we need to create the following folder structure:</p>
<pre class="source-code">
tozo
└── .github
    └── workflows</pre>
<p>Now we can configure a workflow that runs jobs on every change to the <code>main</code> branch and every merge request by adding the following code to <em class="italic">.github/workflows/ci.yml</em>: </p>
<pre class="source-code">
name: CI
 
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
 
jobs:</pre>
<p>This allows<a id="_idIndexMarker089"/> us to add jobs for the infrastructure, backend, and<a id="_idIndexMarker090"/> frontend.</p>
<h2 id="_idParaDest-43"><a id="_idTextAnchor044"/>Adding CI for the infrastructure code</h2>
<p>We previously set up<a id="_idIndexMarker091"/> the commands to format<a id="_idIndexMarker092"/> and lint the infrastructure code as follows:</p>
<pre class="source-code">
terraform fmt --check=true
terraform validate</pre>
<p>To have these run as part of CI, we need to add the following job to the <em class="italic">.github/workflows/ci.yml</em> file within the <code>jobs</code> section:</p>
<pre class="source-code">
  infrastructure:
    runs-on: ubuntu-latest
 
    steps:
      - name: Install Terraform
        run: |
          sudo apt-get update &amp;&amp; sudo apt-get install -y gnupg             software-properties-common curl
          curl -fsSL https://apt.releases.hashicorp.com/gpg |             sudo apt-key add -
          sudo apt-add-repository "deb [arch=amd64] https://            apt.releases.hashicorp.com $(lsb_release -cs) main"
          sudo apt-get update &amp;&amp; sudo apt-get install terraform
      - uses: actions/checkout@v3
 
      - name: Initialise Terraform
        run: terraform init
 
      - name: Check the formatting
        run: terraform fmt --check=true --recursive
 
      - name: Validate the code
        run: terraform validate</pre>
<p>We can<a id="_idIndexMarker093"/> now add a job for the backend<a id="_idIndexMarker094"/> code.</p>
<h2 id="_idParaDest-44"><a id="_idTextAnchor045"/>Adding CI for the backend code</h2>
<p>We previously set up<a id="_idIndexMarker095"/> the commands to format, lint, and test the backend<a id="_idIndexMarker096"/> code as follows:</p>
<pre class="source-code">
pdm run format
pdm run lint
pdm run test</pre>
<p>To have these run as part of CI, we will need to have a database service running as well, as the tests run against the database. Fortunately, GitHub supports PostgreSQL database services by running a PostgreSQL database alongside the CI job. We can make use of this database service and run the commands by adding the following job to the <code>jobs</code> section in <em class="italic">.github/workflows/ci.yml</em>:</p>
<pre class="source-code">
  backend:
    runs-on: ubuntu-late<a id="_idTextAnchor046"/>st
 
    container: python:3.10.1-slim-bullseye
 
    services:
      postgres:
        image: postgres
        env:
          POSTGRES_DB: tozo_test
          POSTGRES_USER: tozo
          POSTGRES_PASSWORD<a id="_idTextAnchor047"/>: tozo
          POSTGRES_HOST_AUTH_METHOD: "trust"
        options: &gt;-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    defaults:
      run:
        working-directory: backend
 
    env:
      TOZO_QUART_DB_DATABASE_URL: "postgresql://tozo:tozo@        postgres:5432/tozo_test"
 
    steps:
      - uses: actions/checkout@v3
 
      - name: Install system dep<a id="_idTextAnchor048"/>endencies
        run: apt-get update &amp;&amp; apt-get install -y postgresql           postgresql-contrib
 
      - name: Initialise dependencies
        run: |
          pip install pdm
          pdm install
 
      - name: Linting
        run: pdm run lint
 
      - name: Testing
        run: pdm run test</pre>
<p>We can<a id="_idIndexMarker097"/> now add a job <a id="_idIndexMarker098"/>for the frontend code.</p>
<h2 id="_idParaDest-45"><a id="_idTextAnchor049"/>Adding CI for the frontend code</h2>
<p>We previously set up the<a id="_idIndexMarker099"/> commands to format, lint, test, and build<a id="_idIndexMarker100"/> the frontend code as follows:</p>
<pre class="source-code">
npm run format
npm run lint
npm run test
npm run build</pre>
<p>We can make use of the service and run the commands by adding the following job to the <code>jobs</code> section of <em class="italic">.github/workflows/ci.yml</em>:</p>
<pre class="source-code">
  frontend:
    runs-on: ubuntu-latest
 
    defaults:
      run:
        working-directory: frontend
 
    steps:
      - name: Use Node.js
        uses: actions/setup-node@v2
        with:
          node-version: '18'
 
      - uses: actions/checkout@v3
 
      - name: Initialise dependencies
        run: npm ci --cache .npm --prefer-offline
      - name: Check formatting
        run: npm run format
 
      - name: Linting
        run: npm run lint
 
      - name: Testing
        run: npm run test
 
      - name: Build
        run: npm run build </pre>
<p>We now have everything<a id="_idIndexMarker101"/> we need in place to start developing<a id="_idIndexMarker102"/> our app. The folder structure at this stage is as follows:</p>
<pre class="source-code">
tozo
├── .github
│   └── workflows
├── backend
│   ├── src
│   │   └── backend
│   └── tests
├── frontend
│   ├── public
│   └── src
└── infrastructure</pre>
<p>We now have all of our checks running on every change to the <code>main</code> branch and for every pull request. This should ensure that our code remains at a high quality and alert us to any issues that may otherwise be missed.</p>
<h1 id="_idParaDest-46"><a id="_idTextAnchor050"/>Summary</h1>
<p>In this chapter, we set up all of the tooling we need to develop our app. We started by installing a system package manager, which we then used to install and set up git. With git, we created our local repository and started to commit code. We installed Python, NodeJS, Terraform, and the tooling required to format, lint, and test the code. Finally, we used Terraform to create and set up a remote GitHub repository with working CI, ensuring that our code is automatically checked on every change.</p>
<p>The tooling we’ve installed in this chapter is required to develop the app described in the following chapters. It will also allow you to do so quickly, as the tooling will help you quickly identify issues and errors with the code. </p>
<p>In the next chapter, we’ll start developing the backend of our app, with the focus being on setting up the app framework and extensions that support the features we want, for example, authentication.</p>
<h1 id="_idParaDest-47"><a id="_idTextAnchor051"/>Further reading</h1>
<p>It is often useful to switch versions of Python and NodeJS to test the app before upgrading it. To do this, I’d recommend <code>pyenv</code> (https://github.com/pyenv/pyenv) and <code>n</code> (https://github.com/tj/n) for Python and NodeJS, respectively.</p>
</div>
</div>

<div><div><h1 id="_idParaDest-48"><a id="_idTextAnchor052"/>Part 2 Building a To-Do App </h1>
<p>Now, we will build a fully functional to-do tracking application using Quart and React. The app will include many common features, such as authentication, user management, styled pages, and forms. </p>
<p>This part consists of the following chapters:</p>
<ul>
<li><a href="B18727_02.xhtml#_idTextAnchor053"><em class="italic">Chapter 2</em></a>, <em class="italic">Creating a Reusable Backend with Quart</em> </li>
<li><a href="B18727_03.xhtml#_idTextAnchor076"><em class="italic">Chapter 3</em></a>, <em class="italic">Building the API</em></li>
<li><a href="B18727_04.xhtml#_idTextAnchor111"><em class="italic">Chapter 4</em></a>, <em class="italic">Creating a Reusable Frontend with React</em></li>
<li><a href="B18727_05.xhtml#_idTextAnchor138"><em class="italic">Chapter 5</em></a>, <em class="italic">Building the Single-Page App</em></li>
</ul>
</div>
</div></body></html>