- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Containers for Network Engineers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computer hardware virtualization has revolutionized and changed the way we approach
    infrastructure. Gone are the days when we must dedicate hardware to a single host
    and operating system. We now have the option to share precious hardware such as
    CPU, memory, and disk space with multiple virtual machines, each with its own
    operating system and applications. Because software executed on these virtual
    machines is separated from the underlying hardware resources, we are free to allocate
    a different combination of hardware resources to virtual machines based on their
    specific needs. Nowadays, it is hard to imagine a world without virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: As much as virtual machines are great for application building, they do take
    a while to build, spin up, and, ultimately, tear down. The reason is that the
    virtualization technology associated with virtual machines completely simulates
    the actual hardware for which the hardware is indistinguishable from the guest
    virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: 'The question might now be: is there a way to speed up the life cycle of applications
    with even more virtualization? The answer is yes, with the help of containers.'
  prefs: []
  type: TYPE_NORMAL
- en: Containers and virtual machines are similar in that they both allow sharing
    of computing resources amongst different isolated applications. The difference
    is that virtual machines are abstracted at the Hypervisor level, whereas containers
    are abstracted within the operating system by a container engine. Containers are
    often referred to as OS-level virtualization.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B18403_05_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1: Virtual Machine and Container Comparison (source: https://www.atlassian.com/microservices/cloud-computing/containers-vs-vms)'
  prefs: []
  type: TYPE_NORMAL
- en: In a full virtual machine, we can install different operating systems, such
    as Windows and Linux. Because container virtualization is being handled by the
    operating system, each container will have the same operating system. However,
    the application and its associated resources will be isolated and run independently
    of each other. The container engine will separate the configuration, software
    bundle, and libraries from each container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Container virtualization is not new; **Linux containers** (**LXC**), Solaris
    containers, Docker, and Podman are examples of such implementation. In this chapter,
    we will look at the most popular container technology today, Docker. We will discuss
    the following topics related to Docker containers:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker overview
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building Python applications with Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container networking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers in the network engineering field
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker and Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will be using containers for some of the technologies we will learn in this
    book; this is a good place to start getting familiar with containers.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by looking at a high-level overview of Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker is a set of products and tools that supports the delivery of containers.
    It was started by the company dotCloud in 2008 (renamed to Docker, Inc. in 2013).
    The set of tools includes the container technology of Docker, the container engine
    called Docker Engine, the cloud-based repository of containers called Docker Hub,
    and the desktop graphical user interface software called Docker Desktop.
  prefs: []
  type: TYPE_NORMAL
- en: Docker has two versions, **Docker Community Edition** (**Docker-CE**) and **Docker
    Enterprise Edition** (**Docker-EE**). Docker-CE is a free and open-source platform
    based on the Apache 2.0 license, while Docker-EE is a premium version geared toward
    enterprises. When the term “Docker” is mentioned in this book, we are referring
    to the Community Edition.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three main components in a Docker container environment:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Building and Development: These include the tools used to build a container,
    including the CLI commands, the images, and the repositories where we get the
    various base images. In Docker, we use a Dockerfile to specify most of the building
    steps for a container.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Docker Engine: This is the daemon running in the background. We can use the
    Docker command to manage the daemon.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Container Orchestration: During development, we will typically use `Docker-compose`
    from Docker to manage a multi-container environment. In production, a common tool
    is a Google-originated tool called Kubernetes ([https://kubernetes.io/](https://kubernetes.io/)).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the next section, we will discuss the advantages of Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many advantages of Docker. We will summarize some of them here:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker containers are fast to deploy and destroy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Containers reset gracefully. The containers are transient and ephemeral, leaving
    no residual artifacts when restarted. This leaves a clean state whenever a new
    container is spawned.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is self-contained and deterministic. Containers are often delivered with
    configuration files with instructions on how the container can be rebuilt. We
    can be sure each container image is built in the same way.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It allows seamless integration between application development and DevOps. Because
    of the advantages stated above, many companies have deployed. Docker images directly
    in the production environment. The container can be reproduced exactly as the
    developer intended and tested into production.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have a general understanding of Docker, it is time to build our
    first Python applications in a Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: Building Python applications in Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Docker container is a very popular way to build Python applications.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Of course, we will need to install Docker to start using it. We will follow
    DigitalOcean’s excellent installation guide for Ubuntu 22.04 ([https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-22-04](https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-22-04)).
    If you are using other versions of the Linux distribution, you can simply use
    the drop-down menu from the documentation to pick a different version. For installation
    on Mac or Windows, my recommendation would be to install Docker Desktop ([https://docs.docker.com/desktop/](https://docs.docker.com/desktop/)).
    It will include the Docker Engine, CLI client, and GUI application.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: There are some optional but useful post-installation steps for Linux at [https://docs.docker.com/engine/install/linux-postinstall/](https://docs.docker.com/engine/install/linux-postinstall/).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check the status of our Docker installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will see how we can build a Python application in Docker
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: Useful Docker commands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will need to use some commands to build, run, and test our containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more Docker CLI references, check out the documentation: [https://docs.docker.com/engine/reference/run/](https://docs.docker.com/engine/reference/run/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the commands we will be using in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker run`: `docker run` is used to specify the image to derive the container
    from (by default, it is Docker Hub), network settings, name, and other settings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker container ls`: lists the containers; by default, it only lists currently
    running containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker exec`: runs a command on a running container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker network`: used when we need to manage Docker networks, such as to create,
    list, and remove Docker networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker image`: manages Docker images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many more CLI commands, but these are enough to get us started. For
    a complete reference, check out the link provided in the information box.
  prefs: []
  type: TYPE_NORMAL
- en: Building hello world
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step is to make sure we have reachability to Docker Hub to retrieve
    an image. To do so, Docker provides a very simple `hello-world` app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the various steps the Docker client needed to do to display the
    message. We can display the Docker processes that ran:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the `hello-world` image information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now we can build our first Python application.
  prefs: []
  type: TYPE_NORMAL
- en: Building our application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by thinking about what we will build. Since we built a few Ansible
    playbooks in the last chapter, how about we containerize the `ios_config_backup.yml`
    playbook so we can share this with other team members?
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create a new folder to keep all the files together. If you recall,
    for us to build a Docker image, there is a special file called a Dockerfile. We
    will also create such a file in the directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We will also copy the *host_vars* folder, *ansible.cfg*, *hosts*, and *ios_config_backup.yml*
    files into this folder. We should also make sure the playbook runs as expected
    before we build the Docker container from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker builds itself in a layered fashion, starting with a base image. In the
    Dockerfile, we will specify the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The lines starting with a “#” mark are comments, just like in Python. The `FROM`
    keyword specifies the base image we will retrieve from the default Docker Hub.
    All the official Ubuntu images can be found on the site, [https://hub.docker.com/_/ubuntu](https://hub.docker.com/_/ubuntu).
    In the `ENV` statement, we specified no need for interactive prompts.
  prefs: []
  type: TYPE_NORMAL
- en: The Dockerfile reference can be viewed at [https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us build this image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The `build` command builds from the Dockerfile in the local directory while
    tagging the final image to be `ansible-docker` with version 0.1\. Once completed,
    we can view the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If we need to remove an image before the rebuild, we can delete the image with
    “`docker rmi <image id>`.”
  prefs: []
  type: TYPE_NORMAL
- en: 'We can start the container based on the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'It will drop us into the bash shell prompt, and the container will stop itself
    once we exit. In order for it to run in a detached mode, we will need to start
    it with a `"-d"` flag. Let’s go ahead and delete the container and recreate it
    with the flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Remember to substitute your container ID. A nice shortcut to delete all containers
    in one setting is `docker rm -f $(docker ps -a -q)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The container now runs in detached mode, and we can execute an interactive
    prompt on the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can go ahead and stop the container, then delete it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We will introduce a few more Dockerfile commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `RUN` command executes the shell commands as if we were typing them in the
    shell. We can specify the working directory as `/app` on the container, then copy
    everything in the current working directory (`host_vars`, hosts, playbook, etc.)
    to the `/app` directory on the remote container.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We will keep the same tag, but if we would like to make it a new release, we
    can always tag it as `v0.2`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will launch the container again and execute the `ansible-playbook`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the container is launched, we can start and stop via the hostname:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations on working through the complete container workflow! This might
    not seem much now, but it is a big step. The steps might seem a bit foreign now,
    but don’t worry, they will become more familiar as we get more practice under
    our belt.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing Docker images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last step will be to share the container images. One way to do it would
    be to tar zip the directory and share the file. Another way is to push the image
    to a repository accessible to whoever needs access. Docker Hub is one of the most
    popular repositories, but many others exist. They generally offer several different
    subscription price tiers.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B18403_05_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2: Docker Hub Pricing (source: [https://www.docker.com/pricing/](https://www.docker.com/pricing/))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides sharing the container image, having an accessible repository is crucial
    in a DevOps **CI/CD** (**Continuous Integration/Continuous Delivery**) process.
    For example, we might be checking in the code with an automated build and test
    process. Once all the validation test passes, we can automatically push the image
    to the repository and deploy it to production. We will create a private repository
    on Docker Hub:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B18403_05_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.3: Docker Hub Repository'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we will log in via the Docker CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Then we can tag the existing image following the remote repository, then push
    toward it. Notice in the output below that the destination tag name matches the
    repository name on Docker Hub. This allows flexibility in local naming while conforming
    to the remote team naming conventions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Once the image finishes uploading, we can access the image and we can use it
    directly or use it as a base image in another Dockerfile.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B18403_05_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4: New Uploaded Image'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see how to coordinate multi-container setup locally
    during development.
  prefs: []
  type: TYPE_NORMAL
- en: Container orchestration with Docker-compose
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Modern applications often have interdependencies with each other. For example,
    for a web application, we usually have a “stack” of applications. The popular
    LAMP stack is an acronym denoting Linux, Apache, MySQL, and PHP/Python to specify
    the components required to deliver a web application. In the world of Docker,
    we can use docker-compose ([https://docs.docker.com/compose/](https://docs.docker.com/compose/))
    to specify how multiple containers should be built and run simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have installed Docker Desktop for Mac or Windows, docker-compose is
    already included. In the Linux environment, docker-compose needs to be installed
    separately. We will follow DigitalOcean’s guide for docker-compose ([https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-compose-on-ubuntu-22-04](https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-compose-on-ubuntu-22-04)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Docker-compose uses a YAML file named `docker-compose.yml` to construct the
    environment. There are lots of knobs to specify different service dependencies,
    persistent volumes, and opening public ports. Let’s put together a simple example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is what the file specifies:'
  prefs: []
  type: TYPE_NORMAL
- en: The file specifies two services, `ansible` and `db`. Each of the services is
    similar to the `docker run` commands.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `ansible` service builds with the current Dockerfile in the current working
    directory named `dockerfile`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We map the host port 5434 to the container port 5434\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We specify two environmental variables for the Postgres database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We use a volume named `db` so that the database information written is persisted
    in the volume.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For more information on Docker-compose, please visit [https://docs.docker.com/compose/](https://docs.docker.com/compose/).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can run the combined service with the *docker-compose* command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The services are launched concurrently. We can then tear down both services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We have only built simple applications thus far in the book. This might make
    more sense when we learn about building a Web API later in the book. For now,
    it is good to consider how we can launch multiple containers via docker-compose.
  prefs: []
  type: TYPE_NORMAL
- en: As network engineers, it would be interesting to know how networking is done
    in a Docker environment. That is the subject of the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Container networking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Container networking is not an easy topic to cover because of its scope and
    the number of technologies it touches. The space spans from Linux networking,
    how the particular type of Linux (Ubuntu, Red Hat, etc.) implements networking,
    to Docker’s implementation of networking. Adding to the complexity is the fact
    that Docker is a fast-moving project, and many third-party plugins are available.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will stick to the basics of the networking options offered
    by Docker by default. We will then briefly explain the options of overlay, Macvlan,
    and network plugins.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we launch a container, it can reach the internet by default. Let’s do
    a quick test by launching an Ubuntu container and attaching to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the host has a private IP different from our host’s IP. It can also
    reach the Ubuntu repository to install software as well as ping the outside network.
    How does it do that? By default, Docker created three types of networks: `bridge`,
    `host`, and `none`. Let’s launch a second Terminal window while keeping the host
    running in the first Terminal window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The *none* network option is straightforward. It disables all networking and
    makes the container sit on a network island by itself. This leaves us with the
    `bridge` and `host` options. By default, Docker puts the host in the bridge network,
    `docker0`, with a **virtual Ethernet** (**veth**) interface ([https://man7.org/linux/man-pages/man4/veth.4.html](https://man7.org/linux/man-pages/man4/veth.4.html))
    to allow it to communicate to the internet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: If we launch another container, we will see an additional veth interface created
    and put into the same bridge group. By default, they can communicate with each
    other.
  prefs: []
  type: TYPE_NORMAL
- en: Container host network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can also share the host network with the container. Let’s start an Ubuntu
    container in the host network. We will also install Python 3.10 and other software
    packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If we check now, we can see the container now shares the same IP as the host
    network. We can create a simple HTML page and start the Python3 built-in web server
    on the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If we open up the IP address with port 8000 in a browser, we can see the page
    we created!
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B18403_05_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.5: Index Page of Container Host'
  prefs: []
  type: TYPE_NORMAL
- en: If you have a firewall on your host (such as iptables or ufw) turned on, make
    sure to open up port 8000 so you can see the page.
  prefs: []
  type: TYPE_NORMAL
- en: The host network option is useful when we need to expose containers for public
    service.
  prefs: []
  type: TYPE_NORMAL
- en: Custom bridge network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can also create custom bridge networks and group containers together. We
    will create the network first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now assign the containers to the custom bridge network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The host is now in its custom bridge network. It has network access to the
    public internet and other containers in the same bridge network. If we want to
    expose a particular port to a container in the custom bridge network, we can use
    the `–publish` option to map the port to the `local host`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We can remove the network via the `docker network rm`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The custom network option is great for developing multi-container projects that
    need isolation from each other. Up to this point, we have been looking at networking
    options in a single host. In the next section, we will see the options for inter-host
    communication between containers.
  prefs: []
  type: TYPE_NORMAL
- en: Other container network options
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we look closely at the `docker` `network` `ls` output, we can see the columns
    of `driver` and `scope`. Docker’s network subsystem is pluggable, using drivers.
    The core networking functions were provided by the default drivers of `bridge`,
    `host`, and `none`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other notable drivers are listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Overlay: The overlay network creates a distributed network among multiple Docker
    daemon hosts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Macvlan: The macvlan network option is meant for applications needing to be
    directly connected to the physical network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Third-party network plugins: We can install third-party network plugins ([https://hub.docker.com/search?q=&type=plugin)](https://hub.docker.com/search?q=&type=plugin))
    for additional features. For example, the vSphere-storage plugin ([https://hub.docker.com/r/vmware/vsphere-storage-for-docker](https://hub.docker.com/r/vmware/vsphere-storage-for-docker))
    enables customers to address persistent storage requirements for containers in
    a vSphere environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overlay network driver is probably the option we will need to use beyond
    the development stage. It is meant to handle the routing of the packets to and
    from the Docker daemon host and the correct destination container. For example,
    an overlay ingress network would handle the incoming traffic and load balance
    to the correct container. Due to its complexity, this is typically handled by
    the orchestration tool of choice, such as Swarm or Kubernetes. If we use a public
    cloud provider, such as Google Kubernetes Engine, they might even handle this
    overlay network for us.
  prefs: []
  type: TYPE_NORMAL
- en: Containers in the network engineering field
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Container technologies are transforming how infrastructure is built in modern
    days. We now have an additional layer of abstraction we can use to overcome limitations
    on physical space, power, cooling, and other factors. This is especially true
    of the need to move toward more environmentally-friendly data centers.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many new challenges and opportunities associated with the new container-based
    world:'
  prefs: []
  type: TYPE_NORMAL
- en: Networking in the container world. As we saw in the last section, there are
    lots of options that exist when it comes to networking in containers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DevOps. One of the challenges when trying to implement DevOps practices in network
    engineering is the lack of options for flexible, virtualized network devices.
    Containers can potentially solve that problem if we can virtualize our network
    along with the hosts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lab and Testing. If we can virtualize our network via container images, this
    makes lab and testing much easier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will discuss DevOps in *Chapter 12*, *Continuous Integration with**GitLab*;
    in the next section, we will look at a new way to test and run containerized network
    operating systems.
  prefs: []
  type: TYPE_NORMAL
- en: Containerlab
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Containerlab ([https://containerlab.dev/](https://containerlab.dev/)) is a
    way to run containerized network operating systems. It is a project started by
    the team at Nokia led by Roman Dodin ([https://twitter.com/ntdvps](https://twitter.com/ntdvps)).
    The team is also responsible for developing **SR Linux** (**Service Router Linux**),
    an open **network operating system** (**NOS**). Although born out of Nokia, Containerlab
    has multi-vendor support with Arista cEOS, Azure SONiC, Juniper cRPD, and many
    others. Let’s do a quick example to illustrate the workflow of Containerlab. To
    install, we can follow the installation steps ([https://containerlab.dev/install/](https://containerlab.dev/install/))
    for Debian-based systems. To isolate the installation, we can create a new directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We will define a `clab` file to define the topology, image, and starting configurations.
    There are several example labs under `/etc/containerlab/lab-examples/`. We will
    use the two-node lab example ([https://github.com/srl-labs/containerlab/blob/main/lab-examples/srl02/srl2.cfg](https://github.com/srl-labs/containerlab/blob/main/lab-examples/srl02/srl2.cfg))
    with two SR Linux devices connected over an Ethernet interface. Since SR Linux
    container images can be downloaded over a public repository, this will save us
    the step of needing to download the container image separately. We will call this
    lab topology `srl02.clab.yml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'As indicated in the file, the topology consists of nodes and links. The nodes
    are the NOS systems, while the links define how they are connected. The two device
    configuration files are vendor-specific, in this case, SR Linux configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now launch the lab with `containerlab` `deploy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Technically, we do not need the `—topo` option to specify a topology. Containerlab
    will look for an `*.clab.y*ml` topology file by default. However, I find it a
    good practice to specify a topology file in case we have several topology files
    in the same directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'If successful, we will see the device information. The device names are in
    the format of `clab-{ lab name }-{ device name }`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We can access the device via `ssh` to the device; the default username and
    passwords are both `admin`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'A directory is created with the associated files for the lab:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also see there is an additional bridge network created with the two
    veth interfaces connected to the bridge network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We can tear down the lab with the `containerlab destroy` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: I don’t know about you, but Containerlab is the easiest way to launch a networking
    lab that I have seen. With more vendor support, it might one day become the only
    lab and testing software we need for network testing.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will briefly discuss the relationship between Docker
    and Kubernetes with a very brief overview of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Docker and Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen, Docker images and orchestration can be done with the tools
    provided by the Docker community. However, it is almost impossible to think about
    Docker containers without Kubernetes. This is because when it comes to container
    orchestration, Kubernetes is becoming the de facto standard in doing so. There
    is not enough space to cover Kubernetes in this chapter, but because of its strong
    ties to container orchestration, we should at least know the basics about Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes ([https://kubernetes.io/](https://kubernetes.io/)) was originally
    developed by Google, but the project is now managed by the Cloud Native Computing
    Foundation. It is an open-source container orchestration system that automatically
    deploys, scales, and manages containers. The project was well-received by the
    community right from the beginning since it had a proven track record of scale
    with Google’s internal usage.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes uses a master as the controlling unit that manages worker nodes to
    deploy containers. Each worker node can have one or more pods, which are the smallest
    units of units in Kubernetes. The pods are where the containers will be deployed.
    When the containers are deployed, they are generally grouped into different types
    of sets spread across the pods.
  prefs: []
  type: TYPE_NORMAL
- en: Most public cloud providers (AWS, Azure, Google, and DigitalOcean) offer managed
    Kubernetes clusters that users can try. The Kubernetes documentation ([https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/))
    also offers many tutorials for step-by-step guides to learn more about the technology.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about container virtualization. Containers are similar
    to virtual machines in their ability to isolate computing resources but different
    in the sense that they are lightweight and fast to deploy.
  prefs: []
  type: TYPE_NORMAL
- en: We saw how to use Docker containers to build Python applications and docker-compose
    to build multi-container applications on a single host.
  prefs: []
  type: TYPE_NORMAL
- en: Later in the chapter, we learned how networks are constructed with Docker containers
    by using the default bridge, custom bridges, and host options. Containers can
    also help with network operating system testing using the Containerlab project.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at how we can use Python in network security.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book community
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To join our community for this book – where you can share feedback, ask questions
    to the author, and learn about new releases – follow the QR code below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/networkautomationcommunity](https://packt.link/networkautomationcommunity)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code2903617220506617062.png)'
  prefs: []
  type: TYPE_IMG
