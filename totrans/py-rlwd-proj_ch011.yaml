- en: Chapter 7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data Inspection Features
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three broad kinds of data domains: cardinal, ordinal, and nominal.
    The first project in this chapter will guide you through the inspection of cardinal
    data; values like weights, measures, and durations where the data is continuous,
    as well as counts where the data is discrete. The second project will guide reasoners
    through the inspection of ordinal data involving things like dates, where order
    matters, but the data isn’t a proper measurement; it’s more of a code or designator.
    The nominal data is a code that happens to use digits but doesn’t represent numeric
    values. The third project will cover the more complex case of matching keys between
    separate data sources.'
  prefs: []
  type: TYPE_NORMAL
- en: An inspection notebook is required when looking at new data. It’s a great place
    to keep notes and lessons learned. It’s helpful when diagnosing problems that
    arise in a more mature analysis pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover a number of skills related to data inspection techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: Essential notebook data inspection features using Python expressions, extended
    from the previous chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `statistics` module for examining cardinal data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `collections.Counter` class for examining ordinal and nominal data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some additional `collections.Counter` for matching primary and foreign keys.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the Ancombe’s Quartet example data set used in *Chapters 3*, *4*, and *5*,
    both of the attribute values are cardinal data. It’s a helpful data set for some
    of the inspections, but we’ll need to look at some other data sets for later projects
    in this chapter. We’ll start by looking at some inspection techniques for cardinal
    data. Readers who are focused on other data sets will need to discern which attributes
    represent cardinal data.
  prefs: []
  type: TYPE_NORMAL
- en: '7.1 Project 2.2: Validating cardinal domains — measures, counts, and durations'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A great deal of data is cardinal in nature. Cardinal numbers are used to count
    things, like elements of a set. The concept can be generalized to include real
    numbers representing a weight or a measure.
  prefs: []
  type: TYPE_NORMAL
- en: 'A very interesting data set is available here: [https://www.kaggle.com/datasets/rtatman/iris-dataset-json-version](https://www.kaggle.com/datasets/rtatman/iris-dataset-json-version).
    This contains samples with numerous measurements of the pistils and stamen of
    different species of flowers. The measurements are identifiable because the unit,
    mm, is provided.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another interesting data set is available here: [https://datahub.io/core/co2-ppm](https://datahub.io/core/co2-ppm).
    This contains data with measurements of CO2 levels measured with units of ppm,
    parts per million.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to distinguish counts and measures from numbers that are only used
    to rank or order things, which are called ordinal numbers. Also, number-like data
    is sometimes only a code. US postal codes, for example, are merely strings of
    digits; they aren’t proper numeric values. We’ll look at these numeric values
    in [*Project 2.3: Validating text and codes — nominal data and ordinal* *numbers*](#x1-1710002).'
  prefs: []
  type: TYPE_NORMAL
- en: Since this is an inspection notebook, the primary purpose is only to understand
    the range of values for cardinal data. A deeper analysis will come later. For
    now, we want a notebook that demonstrates the data is complete and consistent,
    and can be used for further processing.
  prefs: []
  type: TYPE_NORMAL
- en: In the event an enterprise is using data contracts, this notebook will demonstrate
    compliance with the data contract. With data contracts, the focus may shift slightly
    from showing “some data that is not usable” to showing “data found to be non-compliant
    with the contract.” In cases where the contract is inadequate for the analytical
    consumer, the notebook may shift further to show “compliant data that’s not useful.”
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start with a description of the kinds of cells to add to an inspection
    notebook. After that, we’ll about the architectural approach and wrap up with
    a detailed list of deliverables.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.1 Description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This project’s intent is to inspect raw data to understand if it is actually
    cardinal data. In some cases, floating-point values may have been used to represent
    nominal data; the data appears to be a measurement but is actually a code.
  prefs: []
  type: TYPE_NORMAL
- en: Spreadsheet software tends to transform all data into floating-point numbers;
    many data items may look like cardinal data.
  prefs: []
  type: TYPE_NORMAL
- en: One example is US Postal Codes, which are strings of digits, but may be transformed
    into numeric values by a spreadsheet.
  prefs: []
  type: TYPE_NORMAL
- en: Another example is bank account numbers, which — while very long — can be converted
    into floating-point numbers. A floating-point value uses 8 bytes of storage, but
    will comfortably represent about 15 decimal digits. While this is a net saving
    in storage, it is a potential confusion of data types and there is a (small) possibility
    of having an account number altered by floating-point truncation rules.
  prefs: []
  type: TYPE_NORMAL
- en: The user experience is a Jupyter Lab notebook that can be used to examine the
    data, show some essential features of the raw data values, and confirm that the
    data really does appear to be cardinal.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several common sub-varieties of cardinal data:'
  prefs: []
  type: TYPE_NORMAL
- en: Counts; represented by integer values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Currency and other money-related values. These are often decimal values, and
    the `float` type is likely to be a bad idea.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duration values. These are often measured in days, hours, and minutes, but represent
    a time interval or a “delta” applied to a point in time. These can be normalized
    to seconds or days and represented by a float value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More general measures are not in any of the previous categories. These are often
    represented by floating-point values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What’s important for this project is to have an overview of the data. Later
    projects will look at cleaning and converting the data for further use. This notebook
    is only designed to preview and inspect the data.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll look at general measures first since the principles apply to counts and
    durations. Currency, as well as duration, values are a bit more complicated and
    we’ll look at them separately. Date-time stamps are something we’ll look at in
    the next project since they’re often thought of as ordinal data, not cardinal.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.2 Approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This project is based on the initial inspection notebook from [*Chapter** 6*](ch010.xhtml#x1-1460006),
    [*Project* *2.1: Data Inspection Notebook*](ch010.xhtml#x1-1460006). Some of the
    essential cell content will be reused in this notebook. We’ll add components to
    the components shown in the earlier chapter – specifically, the `samples_iter()`
    function to iterate over samples in an open file. This feature will be central
    to working with the raw data.'
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we suggested avoiding conversion functions. When starting
    down the path of inspecting data, it’s best to assume nothing and look at the
    text values first.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some common patterns in the source data values:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The values appear to be all numeric values. The `int()` or `float()` function
    works on all of the values. There are two sub-cases here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of the values seem to be proper counts or measures in some expected range.
    This is ideal.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A few “outlier” values are present. These are values that seem to be outside
    the expected range of values.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Some of the values are not valid numbers. They may be empty strings, or a code
    line “NULL”, “None”, or “N/A”.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Numeric outlier values can be measurement errors or an interesting phenomenon
    buried in the data. Outlier values can also be numeric code values indicating
    a known missing or otherwise unusable value for a sample. In the example of the
    CO2 data, there are outlier values of −99*.*99 parts per million, which encode
    a specific kind of missing data situation.
  prefs: []
  type: TYPE_NORMAL
- en: Many data sets will be accompanied by metadata to explain the domain of values,
    including non-numeric values, as well as the numeric codes in use. Some enterprise
    data sources will not have complete or carefully explained metadata. This means
    an analyst needs to ask questions to locate the root cause for non-numeric values
    or special codes that appear in cardinal data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first question — *are all the values numeric?* — can be handled with code
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The idea is to apply a conversion function, commonly `int()` or `float()`, but
    `decimal.Decimal()` may be useful for currency data or other data with a fixed
    number of decimal places. If the conversion function fails, the exceptional data
    is preserved in a mapping showing the counts.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’re encouraged to try this with a sequence of strings like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This kind of test case will let you see how this function works with good (and
    bad) data. It can help to transform the test case into a docstring, and include
    it in the function definition.
  prefs: []
  type: TYPE_NORMAL
- en: If the result of the `non_numeric()` function is an empty dictionary, then the
    lack of non-numeric data means all of the data is numeric.
  prefs: []
  type: TYPE_NORMAL
- en: The test function is provided first to follow the pattern of higher-order functions
    like `map()` and `filter()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'A variation on this function can be used as a numeric filter to pass the numeric
    values and reject the non-numeric values. This would look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This function will silently reject the values that cannot be converted. The
    net effect of omitting the data is to create a NULL that does not participate
    in further computations. An alternative may be to replace invalid values with
    default values. An even more complicated choice is to interpolate a replacement
    value using adjacent values. Omitting samples may have a significant impact on
    the statistical measures used in later stages of processing. This `numeric_filter()`
    function permits the use of other statistical functions to locate outliers.
  prefs: []
  type: TYPE_NORMAL
- en: For data with good documentation or a data contract, outlier values like −99*.*99
    are easy to spot. For data without good documentation, a statistical test might
    be more appropriate. See [https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm](https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm)
    for details on approaches to locating outliers.
  prefs: []
  type: TYPE_NORMAL
- en: One approach suitable for small data sets is to use a median-based Z-score.
    We’ll dive into an algorithm that is built on a number of common statistical measures.
    This will involve computing the median using a function available in the built-in
    `statistics` package.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on basic statistics for data analytics, see *Statistics
    for Data* *Science*.
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.packtpub.com/product/statistics-for-data-science/9781788290678](https://www.packtpub.com/product/statistics-for-data-science/9781788290678).'
  prefs: []
  type: TYPE_NORMAL
- en: The conventional Z-score for a sample, *Z*[i], is based on the mean, *Ȳ*, and
    the standard deviation, *σ*[Y] . It’s computed as *Z*[i] = ![Yi−Y¯- σY](img/file33.jpg).
    It measures how many standard deviations a value lies from the mean. Parallel
    with this is the idea of a median-based Z-score, *M*[i]. The median-based Z-score
    uses the median, *Ỹ*, and the median absolute deviation, MAD[Y] .
  prefs: []
  type: TYPE_NORMAL
- en: This is computed as *M*[i] = ![-Yi−Y˜- MADY](img/file34.jpg). This measures
    how many “MAD” units a value lies from the median of the samples.
  prefs: []
  type: TYPE_NORMAL
- en: The MAD is the median of the absolute values of deviations from the median.
    It requires computing an overall median, *Ỹ*, then computing all the deviations
    from the overall median, *Y* [i] −*Ỹ*. From this sequence of deviations from the
    median, the median value is selected to locate a central value for all of the
    median absolute deviations. This is computed as MAD[Y] = median(|*Y* [i] −*Ỹ*|).
  prefs: []
  type: TYPE_NORMAL
- en: The filter based on *M*[i] looks for any absolute value of the deviation from
    MAD[Y] that’s greater than 3*.*5, |*M*[i]| *>* 3*.*5\. These samples are possible
    outliers because their absolute deviation from the median is suspiciously large.
  prefs: []
  type: TYPE_NORMAL
- en: 'To be complete, here’s a cell to read the source data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This can be followed with a cell to compute the median and the median absolute
    deviation. The median computation can be done with the `statistics` module. The
    deviations can then be computed with a generator, and the median absolute deviation
    computed from the generator. The cell looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The value of `y_text` is a generator that will extract the values mapped to
    the `’y’` key in each of the raw data samples in the NDJSON file. From these text
    values, the value of `y` is computed by applying the `numeric_filter()` function.
  prefs: []
  type: TYPE_NORMAL
- en: It’s sometimes helpful to show that `len(y)`` ==`` len(y_text)` to demonstrate
    that all values are numeric. In some data sets, the presence of non-numeric data
    might be a warning that there are deeper problems.
  prefs: []
  type: TYPE_NORMAL
- en: The value of `m_y` is the median of the `y` values. This is used to compute
    the MAD value as the median of the absolute deviations from the median. This median
    absolute deviation provides an expected range around the median.
  prefs: []
  type: TYPE_NORMAL
- en: The `outliers_y` computation uses a generator expression to compute the median-based
    Z-score, and then keep only those scores that are more than 3.5 MADs from the
    median.
  prefs: []
  type: TYPE_NORMAL
- en: The data in Series IV of Anscombe’s Quartet seems to suffer from an even more
    complicated outlier problem. While the ”x” attribute has a potential outlier,
    the ”y” attribute’s MAD is zero. This means more than half the ”y” attribute values
    are the same. This single value is the median, and the difference from the median
    will be zero for most of the samples.
  prefs: []
  type: TYPE_NORMAL
- en: This anomaly would become an interesting part of the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with currency and related values
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most currencies around the world use a fixed number of decimal places. The United
    States, for example, uses exactly two decimal places for money. These are decimal
    values; the `float` type is almost always the wrong type for these values.
  prefs: []
  type: TYPE_NORMAL
- en: Python has a `decimal` module with a `Decimal` type, which must be used for
    currency.
  prefs: []
  type: TYPE_NORMAL
- en: Do not use `float` for currency or anything used in currency-related computations.
  prefs: []
  type: TYPE_NORMAL
- en: Tax rates, discount rates, interest rates, and other money-related fields are
    also decimal values. They’re often used with currency values, and computations
    must be done using decimal arithmetic rules.
  prefs: []
  type: TYPE_NORMAL
- en: When we multiply `Decimal` values together, the results may have additional
    digits to the right of the decimal place. This requires applying rounding rules
    to determine how to round or truncate the extra digits. The rules are essential
    to getting the correct results. The `float` type `round()` function may not do
    this properly. The `decimal` module includes a wide variety of rounding and truncating
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Consider an item with a price of $12.99 in a locale that charges a sales tax
    of 6.25% on each purchase. This is not a tax amount of $0.811875\. The tax amount
    must be rounded; there are many, many rounding rules in common use by accountants.
    It’s essential to know which rule is required to compute the correct result.
  prefs: []
  type: TYPE_NORMAL
- en: Because the underlying assumption behind currency is decimal computation, the
    `float` should never be used for currency amounts.
  prefs: []
  type: TYPE_NORMAL
- en: This can be a problem when spreadsheet data is involved. Spreadsheet software
    generally uses `float` values with complex formatting rules to produce correct-looking
    answers. This can lead to odd-looking values in a CSV extract like 12*.*999999997
    for an attribute that should have currency values.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, currency may be decorated with currency symbols like $, £, or
    €. There may also be separator characters thrown in, depending on the locale.
    For the US locale, this can mean stray ”,” characters may be present in large
    numbers.
  prefs: []
  type: TYPE_NORMAL
- en: The ways currency values may have text decoration suggest the conversion function
    used by a `non_numeric()` or `numeric_filter()` function will have to be somewhat
    more sophisticated than the simple use of the `Decimal` class.
  prefs: []
  type: TYPE_NORMAL
- en: Because of these kinds of anomalies, data inspection is a critical step in data
    acquisition and analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with intervals or durations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Some date will include duration data in the form `"12:34"`, meaning 12 hours
    and 34 minutes. This looks exactly like a time of day. In some cases, it might
    have the form `12h`` 34m`, which is a bit easier to parse. Without metadata to
    explain if an attribute is a duration or a time of day, this may be impossible
    to understand.
  prefs: []
  type: TYPE_NORMAL
- en: For durations, it’s helpful to represent the values as a single, common time
    unit. Seconds are a popular choice. Days are another common choice.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a cell with a given string, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Given this string, we can create a cell to compute the duration in seconds
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This will compute a duration, `sec`, of 45,240 seconds from the source time
    as text, `time_text`. The final expression `sec` in a Jupyter notebook cell will
    display this variable’s value to confirm the computation worked. This cardinal
    value computation works out elegantly.
  prefs: []
  type: TYPE_NORMAL
- en: For formatting purposes, the inverse computation can be helpful. A floating-point
    value like 45,240 can be converted back into a sequence of integers, like (12,
    34, 0), which can be formatted as ”12:34” or ”12h 34m 0s”.
  prefs: []
  type: TYPE_NORMAL
- en: 'It might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This will produce the string `12:34` from the value of seconds given in the
    `sec` variable. The final expression `text` in a cell will display the computed
    value to help confirm the cell works.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to normalize duration strings and complex-looking times into
    a single float value.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve looked at some of the tricky cardinal data fields, we can look
    at the notebook as a whole. In the next section, we’ll look at refactoring the
    notebook to create a useful module.
  prefs: []
  type: TYPE_NORMAL
- en: Extract notebook functions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The computation of ordinary Z-scores and median-based Z-scores are similar
    in several ways. Here are some common features we might want to extract:'
  prefs: []
  type: TYPE_NORMAL
- en: Extracting the center and variance. This might be the mean and standard deviation,
    using the `statistics` module. Or it might be the median and MAD.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a function to compute Z-scores from the mean or median.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the `filter()` function to locate outliers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When looking at data with a large number of attributes, or looking at a large
    number of related data sets, it’s helpful to write these functions first in the
    notebook. Once they’ve been debugged, they can be cut from the notebook and collected
    into a separate module. The notebook can then be modified to import the functions,
    making it easier to reuse these functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the source data is pushed into a dictionary with string keys, it becomes
    possible to consider functions that work across a sequence of key values. We might
    have cells that look like the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This will analyze all of the columns named in the surrounding `for` statement.
    In this example, the x and y column names are provided as the collection of columns
    to analyze. The result is a small table of values with the column name, the raw
    data size, the filtered data size, and the median of the filtered data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea of a collection of descriptive statistics suggests a class to hold
    these. We might add the following dataclass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The class definition includes a class method to build instances of this class
    from a collection of raw values. Putting the instance builder into the class definition
    makes it slightly easier to add additional inspection attributes and the functions
    needed to compute those attributes. A function that builds `AttrSummary` instances
    can be used to summarize the attributes of a data set. This function might look
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This kind of function makes it possible to reuse inspection code for a number
    of attributes in a complicated data set. After looking at the suggested technical
    approach, we’ll turn to the deliverables for this project.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.3 Deliverables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This project has the following deliverables:'
  prefs: []
  type: TYPE_NORMAL
- en: A `requirements-dev.txt` file that identifies the tools used, usually `jupyterlab==3.5.3`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation in the `docs` folder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit tests for any new changes to the modules in use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any new application modules with code to be used by the inspection notebook.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A notebook to inspect the attributes that appear to have cardinal data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This project will require a `notebooks` directory. See [*List of deliverables*](ch005.xhtml#x1-260003)
    for some more information on this structure.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll look at a few of these deliverables in a little more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Inspection module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You are encouraged to refactor functions like `samples_iter()`, `non_numeric()`,
    and `numeric_filter()` into a separate module. Additionally, the `AttrSummary`
    class and the closely related `summary_iter()` function are also good candidates
    for being moved to a separate module with useful inspection classes and functions.
  prefs: []
  type: TYPE_NORMAL
- en: Notebooks can be refactored to import these classes and functions from a separate
    module.
  prefs: []
  type: TYPE_NORMAL
- en: It’s easiest to throw this module into the `notebooks` folder to make it easier
    to access. An alternative is to include the `src` directory on the `PYTHONPATH`
    environment variable, making it available to the Jupyter Lab session.
  prefs: []
  type: TYPE_NORMAL
- en: Another alternative is to create an IPython profile with the `ipython`` profile`` create`
    command at the terminal prompt. This will create a `~/.ipython/profile_default`
    directory with the default configuration files in it. Adding a `startup` folder
    permits including scripts that will add the `src` directory to the `sys.path`
    list of places to look for modules.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://ipython.readthedocs.io/en/stable/interactive/tutorial.html#startup-files](https://ipython.readthedocs.io/en/stable/interactive/tutorial.html#startup-files).
  prefs: []
  type: TYPE_NORMAL
- en: Unit test cases for the module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The various functions were refactored from a notebook to create a separate module
    need unit tests. In many cases, the functions will have doctest examples; the
    notebook as a whole will have a doctest cell.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, an extra option in the **pytest** command will execute these tests,
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `--doctest-modules` option will look for the doctest examples and execute
    them.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative is to use the Python `doctest` command directly.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: It is, of course, essential to test the code extracted from the notebook to
    be sure it works properly and can be trusted.
  prefs: []
  type: TYPE_NORMAL
- en: This revised and expanded inspection notebook lets an analyst inspect unknown
    data sources to confirm values are likely to be cardinal numbers, for example,
    measures or counts. Using a filter function can help locate invalid or other anomalous
    text. Some statistical techniques can help to locate outlying values.
  prefs: []
  type: TYPE_NORMAL
- en: In the next project, we’ll look at non-cardinal data. This includes nominal
    data (i.e., strings of digits that aren’t numbers), and ordinal values that represent
    ranking or ordering positions.
  prefs: []
  type: TYPE_NORMAL
- en: '7.2 Project 2.3: Validating text and codes — nominal data and ordinal numbers'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 7.2.1 Description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous project ([*Project 2.2: Validating cardinal domains — measures,*
    *counts, and durations*](#x1-1620001)), we looked at attributes that contained
    cardinal data – measures and counts. We also need to look at ordinal and nominal
    data. Ordinal data is generally used to provide ranks and ordering. Nominal data
    is best thought of as codes made up of strings of digits. Values like US postal
    codes and bank account numbers are nominal data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When we look at the **CO****2** **PPM — Trends in Atmospheric Carbon** **Dioxide**
    data set, available at [https://datahub.io/core/co2-ppm](https://datahub.io/core/co2-ppm),
    it has dates that are provided in two forms: as a `year-month-day` string and
    as a decimal number. The decimal number positions the first day of the month within
    the year as a whole.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s instructive to use ordinal day numbers to compute unique values for each
    date and compare these with the supplied ”Decimal Date” value. An integer day
    number may be more useful than the decimal date value because it avoids truncation
    to three decimal places.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, many of the data sets available from [https://berkeleyearth.org/data/](https://berkeleyearth.org/data/)
    contain complicated date and time values. Looking at the source data, [https://berkeleyearth.org/archive/source-files/](https://berkeleyearth.org/archive/source-files/)
    has data sets with nominal values to encode precipitation types or other details
    of historical weather. For even more data, see [https://www.ncdc.noaa.gov/cdo-web/](https://www.ncdc.noaa.gov/cdo-web/).
    All of these datasets have dates in a variety of formats.
  prefs: []
  type: TYPE_NORMAL
- en: What’s important for this project is to get an overview of the data that involves
    dates and nominal code values. Later projects will look at cleaning and converting
    the data for further use. This notebook is only designed to preview and inspect
    the data. It is used to demonstrate the data is complete and consistent and can
    be used for further processing.
  prefs: []
  type: TYPE_NORMAL
- en: Dates and times
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A date, time, and the combined date-time value represent a specific point in
    time, sometimes called a timestamp. Generally, these are modeled by Python `datetime`
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: A date in isolation can generally be treated as a `datetime` with a time of
    midnight. A time in isolation is often part of a date stated elsewhere in the
    data or assumed from context. Ideally, a date-time value has been broken into
    separate columns of data for no good reason and can be combined. In other cases,
    the data might be a bit more difficult to track down. For example, a log file
    as a whole might have an implied date — because each log file starts at midnight
    UTC — and the time values must be combined with the (implied) log’s date.
  prefs: []
  type: TYPE_NORMAL
- en: Date-time values are quite complex and rich with strange quirks. To keep the
    Gregorian calendar aligned with the positions of stars, and the Moon, leap days
    are added periodically. The `datetime` library in Python is the best way to work
    with the calendar.
  prefs: []
  type: TYPE_NORMAL
- en: It’s generally a bad idea to do any date-time computation outside the `datetime`
    package.
  prefs: []
  type: TYPE_NORMAL
- en: Home-brewed date computations are difficult to implement correctly.
  prefs: []
  type: TYPE_NORMAL
- en: The `toordinal()` function of a `datetime.datetime` object provides a clear
    relationship between dates and an ordinal number that can be used to put dates
    into order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because months are irregular, there are several common kinds of date computations:'
  prefs: []
  type: TYPE_NORMAL
- en: A date plus or minus a duration given in months. The day of the month is generally
    preserved, except in the unusual case of February 29, 30, or 31, where ad hoc
    rules will apply.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A date plus or minus a duration given in days or weeks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These kinds of computations can result in dates in a different year. For month-based
    computations, an ordinal month value needs to be computed from the date. Given
    a date, *d*, with a year, *d.y*, and a month *d.m*, the ordinal month, *m*[o],
    is *d.y* × 12 + *d.m* − 1\. After a computation, the `divmod()` function will
    recover the year and month of the result. Note that months are generally numbered
    from 1, but the ordinal month computation numbers months from zero. This leads
    to a −1 when creating an ordinal month from a date, and a +1 when creating a date
    from an ordinal month. As noted above, when the resulting month is February, something
    needs to be done to handle the exceptional case of trying to build a possibly
    invalid date with a day number that’s invalid in February of the given year.
  prefs: []
  type: TYPE_NORMAL
- en: For day- or week-based computations, the `toordinal()` function and `fromordinal()`
    functions will work correctly to order and compute differences between dates.
  prefs: []
  type: TYPE_NORMAL
- en: All calendar computations must be done using ordinal values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Either use the built-in `toordinal()` method of a `datetime` object, or compute
    an ordinal month number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply duration offsets to the ordinal value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Either use the built-in `fromordinal()` class method of the `datetime` class,
    or use the `divmod()` function to compute the year and month of the ordinal month
    number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For some developers, the use of ordinal numbers for dates can feel complicated.
    Using `if` statements to decide if an offset from a date is in a different year
    is less reliable and requires more extensive edge-case testing. Using an expression
    like `year,`` month`` =`` divmod(date,`` 12)` is much easier to test.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll look at time and the problem of local time.
  prefs: []
  type: TYPE_NORMAL
- en: Time values, local time, and UTC time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Local time is subject to a great deal of complex-seeming rules, particularly
    in the US. Some countries have a single time zone, simplifying what constitutes
    local time. In the US, however, each county decides which timezone it belongs
    to, leading to very complex situations that don’t necessarily follow US state
    borders.
  prefs: []
  type: TYPE_NORMAL
- en: Some countries (the US and Europe, as well as a scattering of other places)
    offset the time (generally, but not universally by one hour) for part of the year.
    The rules are not necessarily nationwide; Canada, Mexico, Australia, and Chile
    have regions that don’t have daylight savings time offsets. The Navajo nation
    — surrounded by the state of Arizona in the US — doesn’t switch its clocks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rules are here: [https://data.iana.org/time-zones/tz-link.html](https://data.iana.org/time-zones/tz-link.html).
    This is part of the Python `datetime` library and is already available in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: This complexity makes use of the **universal coordinated time** (**UTC**) imperative.
  prefs: []
  type: TYPE_NORMAL
- en: Local times should be converted into UTC for analysis purposes.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://www.rfc-editor.org/rfc/rfc3339](https://www.rfc-editor.org/rfc/rfc3339)
    for time formats that can include a local-time offset.
  prefs: []
  type: TYPE_NORMAL
- en: UTC can be converted back into local time to be displayed to users.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.2 Approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dates and times often have bewildering formats. This is particularly true in
    the US, where dates are often written as numbers in month/day/year format. Using
    year/month/day puts the values in order of significance. Using day/month/year
    is the reverse order of significance. The US ordering is simply strange.
  prefs: []
  type: TYPE_NORMAL
- en: This makes it difficult to do inspections on completely unknown data without
    any metadata to explain the serialization format. A date like 01/02/03 could mean
    almost anything.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, a survey of many date-like values will reveal a field with a
    range of 1-12 and another field with a range of 1-31, permitting analysts to distinguish
    between the month and day. The remaining field can be taken as a truncated year.
  prefs: []
  type: TYPE_NORMAL
- en: In cases where there is not enough data to make a positive identification of
    month or day, other clues will be needed. Ideally, there’s metadata to define
    the date format.
  prefs: []
  type: TYPE_NORMAL
- en: The `datetime.strptime()` function can be used to parse dates when the format(s)
    are known. Until the date format is known, the data must be used cautiously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are two Python modules that can help parse dates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://pypi.org/project/dateparser/](https://pypi.org/project/dateparser/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://pypi.org/project/python-dateutil/](https://pypi.org/project/python-dateutil/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to carefully inspect the results of date parsing to be sure the
    results are sensible. There are some confounding factors.
  prefs: []
  type: TYPE_NORMAL
- en: Years, for example, can be provided as two or four digits. For example, when
    dealing with old data, it’s important to note the use of two-digit encoding schemes.
    For a few years prior to 2000, the year of date might have been given as a complicated
    two-digit transformation. In one scheme, values from 0 to 29 meant years 2000
    to 2029\. Values from 30 to 99 meant years 1930 to 1999\. These rules were generally
    ad hoc, and different enterprises may have used different year encodings.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, leap seconds have been added to the calendar a few times as a
    way to keep the clocks aligned with planetary motion. Unlike leap years, these
    are the result of ongoing research by astronomers, and are not defined by the
    way leap years are defined.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://www.timeanddate.com/time/leapseconds.html](https://www.timeanddate.com/time/leapseconds.html)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: The presence of a leap second means that a timestamp like `1972-06-30T23:59:60`
    is valid. The 60 value for seconds represents the additional leap second. As of
    this book’s initial publication, there were 26 leap seconds, all added on June
    30 or December 31 of a given year. These values are rare but valid.
  prefs: []
  type: TYPE_NORMAL
- en: Nominal data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Nominal data is not numeric but may consist of strings of digits, leading to
    possible sources of confusion and — in some cases — useless data conversions.
    While nominal data should be treated as text, it’s possible for a spreadsheet
    to treat US Postal ZIP codes as numbers and truncate the leading zeroes. For example,
    North Adams, MA, has a ZIP code of 01247\. A spreadsheet might lose the leading
    zero, making the code 1247.
  prefs: []
  type: TYPE_NORMAL
- en: While it’s generally best to treat nominal data as text, it may be necessary
    to reformat ZIP codes, account numbers, or part numbers to restore the leading
    zeroes. This can be done in a number of ways; perhaps the best is to use f-strings
    to pad values on the left with leading ”0” characters. An expression like `f"{zip:0>5s}"`
    creates a string from the `zip` value using a format of `0>5s`. This format has
    a padding character, `0`, a padding rule of `>`, and a target size of `5`. The
    final character `s` is the type of data expected; in this case, a string.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative is something like `(5*"0"`` +`` zip)[-5:]` to pad a given `zip`
    value to 5 positions. This prepends zeroes and then takes the right-most five
    characters. It doesn’t seem as elegant as an f-string but can be more flexible.
  prefs: []
  type: TYPE_NORMAL
- en: Extend the data inspection module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the previous project, [*Project 2.2: Validating cardinal domains — measures,*
    *counts, and durations*](#x1-1620001), we considered adding a module with some
    useful functions to examine cardinal data. We can also add functions for ordinal
    and nominal data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a given problem domain, the date parsing can be defined as a separate,
    small function. This can help to avoid the complicated-looking `strptime()` function.
    In many cases, there are only a few date formats, and a parsing function can try
    the alternatives. It might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This function has three date formats that it attempts to use to convert the
    data. If none of the formats match the data, a `ValueError` exception is raised.
  prefs: []
  type: TYPE_NORMAL
- en: For rank ordering data and codes, a notebook cell can rely on a `collections.Counter`
    instance to get the domain of values. More sophisticated processing is not required
    for simple numbers and nominal codes.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.3 Deliverables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This project has the following deliverables:'
  prefs: []
  type: TYPE_NORMAL
- en: A `requirements-dev.txt` file that identifies the tools used, usually `jupyterlab==3.5.3`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation in the `docs` folder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit tests for any new changes to the modules in use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any new application modules with code to be used by the inspection notebook.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A notebook to inspect the attributes that appear to have ordinal or nominal
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The project directory structure suggested in [*Chapter** 1*](ch005.xhtml#x1-170001),
    [*Project Zero: A Template* *for Other Projects*](ch005.xhtml#x1-170001) mentions
    a `notebooks` directory. See [*List of deliverables*](ch005.xhtml#x1-260003) for
    some more information. For this project, the notebook directory is needed.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll look at a few of these deliverables in a little more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Revised inspection module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Functions for date conversions and cleaning up nominal data can be written in
    a separate module. Or they can be developed in a notebook, and then moved to the
    inspection module. As we noted in the [*Description*](#x1-1720001) section, this
    project’s objective is to support the inspection of the data and the identification
    of special cases, data anomalies, and outlier values.
  prefs: []
  type: TYPE_NORMAL
- en: Later, we can look at refactoring these functions into a more formal and complete
    data cleansing module. This project’s goal is to inspect the data and write some
    useful functions for the inspection process. This will create seeds to grow a
    more complete solution.
  prefs: []
  type: TYPE_NORMAL
- en: Unit test cases
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Date parsing is — perhaps — one of the more awkwardly complicated problems.
    While we often think we’ve seen all of the source data formats, some small changes
    to upstream applications can lead to unexpected changes for data analysis purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Every time there’s a new date format, it becomes necessary to expand the unit
    tests with the bad data, and then adjust the parser to handle the bad data. This
    can lead to a surprisingly large number of date-time examples.
  prefs: []
  type: TYPE_NORMAL
- en: When confronted with a number of very similar cases, the `pytest` parameterized
    fixtures are very handy. These fixtures provide a number of examples of a test
    case.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fixture might look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Each of the example values is a two-tuple with input text and the expected `datetime`
    object. This pair of values can be decomposed by the test case.
  prefs: []
  type: TYPE_NORMAL
- en: 'A test that uses this fixture full of examples might look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This kind of test structure permits us to add new formats as they are discovered.
    The test cases in the `EXAMPLES` variable are easy to expand with additional formats
    and special cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve looked at inspecting cardinal, ordinal, and nominal data, we
    can turn to a more specialized form of nominal data: key values used to follow
    references between separate data sets.'
  prefs: []
  type: TYPE_NORMAL
- en: '7.3 Project 2.4: Finding reference domains'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In many cases, data is decomposed to avoid repetition. In [*Chapter** 5*](ch009.xhtml#x1-1140005),
    [*Data* *Acquisition Features: SQL Database*](ch009.xhtml#x1-1140005), we touched
    on the idea of normalization to decompose data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, consider the data sets in this directory: [https://www.ncei.noaa.gov/pub/data/paleo/historical/northamerica/usa/new-england/](https://www.ncei.noaa.gov/pub/data/paleo/historical/northamerica/usa/new-england/)'
  prefs: []
  type: TYPE_NORMAL
- en: There are three separate files. Here’s what we see when we visit the web page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the index of the `/pub/data/paleo/historical/northamerica/usa/new-england`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Last modified** | **Size** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Parent Directory |  | - |  |'
  prefs: []
  type: TYPE_TB
- en: '| new-england-oldweather-data.txt | 2014-01-30 13:02 | 21M |  |'
  prefs: []
  type: TYPE_TB
- en: '| readme-new-england-oldweather.txt | 2014-01-29 19:22 | 9.6K |  |'
  prefs: []
  type: TYPE_TB
- en: '| town-summary.txt | 2014-01-29 18:51 | 34K |  |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: The `readme-new-england-oldweather.txt` file has descriptions of a number of
    codes and their meanings used in the main data set. The ”readme” file provides
    a number of mappings from keys to values. The keys are used in the massive ”oldweather-data”
    file to reduce the repetition of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'These mappings include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The Temperature Code Key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Precipitation Type Key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Precipitation Amount key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Snowfall Amount key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Like Values Code key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Pressure Code Key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Sky Cover Key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Sky Classification Key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Location Code Key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a rather complex decomposition of primary data into coded values.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.1 Description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In cases where data is decomposed or normalized, we need to confirm that references
    between items are valid. Relationships are often one-way — a sample will have
    a reference to an item in another collection of data. For example, a climate record
    may have a reference to ”Town Id” (TWID) with a value like `NY26`. A second data
    set with the ”location code key” provides detailed information on the definition
    of the `NY26` town ID. There’s no reverse reference from the location code data
    set to all of the climate records for that location.
  prefs: []
  type: TYPE_NORMAL
- en: We often depict this relationship as an ERD. For example, [*Figure 7.1*](#7.1)*.*
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1: A Normalized Relationship ](img/file35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: A Normalized Relationship'
  prefs: []
  type: TYPE_NORMAL
- en: A number of weather data records refer to a single location definition.
  prefs: []
  type: TYPE_NORMAL
- en: The database designers will call the Location’s “TWID” attribute a **primary**
    **key**. The WeatherData’s ID attribute is called a **foreign key**; it’s a primary
    key for a different class of entities. These are often abbreviated as PK and FK.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two closely related questions about the relationship between entities:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the *cardinality* of the relationship? This must be viewed from both
    directions. How many primary key entities have relationships with foreign key
    entities? How many foreign key entities have a relationship with a primary key
    entity?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the *optionality* of the relationship? Again, we must ask this in both
    directions. Must a primary entity have any foreign key references? Must the foreign
    key item have a primary key reference?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While a large number of combinations are possible, there are a few common patterns.
  prefs: []
  type: TYPE_NORMAL
- en: The mandatory many-to-one relationship. This is exemplified by the historical
    weather data. Many weather data records must refer to a single location definition.
    There are two common variants. In one case, a location **must** have one or more
    weather records. The other common variant may have locations without any weather
    data that refers to the location.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An optional one-to-one relationship. This isn’t in the weather data example,
    but we may have invoices with payments and invoices without payments. The relationship
    is one-to-one, but a payment may not exist yet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A many-to-many relationship. An example of a many-to-many relationship is a
    product entity that has a number of features. Features are reused between products.
    This requires a separate many-to-many association table to track the relationship
    links.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This leads to the following two detailed inspections:'
  prefs: []
  type: TYPE_NORMAL
- en: The domain of primary key values. For example, the “TWID” attribute of each
    location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The domain of the foreign key values. For example, the ID attribute of each
    weather data record.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If these two sets are identical, we can be sure the foreign keys all have matching
    primary keys. We can count the number of rows that share a foreign key to work
    out the cardinality (and the optionality) of the relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the two sets are not identical, we have to determine which set has the extra
    rows. Let’s call the two sets *P* and *F*. Further, we know that *P**≠**F*. There
    are a number of scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P* ⊃ *F*: This means there are some primary keys without any foreign keys.
    If the relationship is optional, then, there’s no problem. The *P*∖*F* is the
    set of unused entities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*F* ⊂ *P*: This means there are foreign keys that do not have an associated
    primary key. This situation may be a misunderstanding of the key attributes, or
    it may mean data is missing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What’s important for this project is to have an overview of key values and their
    relationship. This notebook is only designed to preview and inspect the data.
    It is used to demonstrate the data is complete and consistent, and can be used
    for further processing.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll look at how we can build cells in a notebook to compare
    the keys and determine the cardinality of the relationships.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.2 Approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To work with data sets like [https://www.ncei.noaa.gov/pub/data/paleo/historical/northamerica/usa/new-england/](https://www.ncei.noaa.gov/pub/data/paleo/historical/northamerica/usa/new-england/)
    we’ll need to compare keys.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will lead to two kinds of data summarization cells in an inspection notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing primary keys in a `Counter` object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarizing foreign key references to those primary keys, also using a `Counter`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the `Counter` summaries are available, then the `.keys()` method will have
    the distinct primary or foreign key values. This can be transformed into a Python
    `set` object, permitting elegant comparison, subset checking, and set subtraction
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll look at the programming to collect key values and references to keys first.
    Then, we’ll look at summaries that are helpful.
  prefs: []
  type: TYPE_NORMAL
- en: Collect and compare keys
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The core inspection tool is the `collections.Counter` class. Let’s assume we
    have done two separate data acquisition steps. The first extracted the location
    definitions from the `readme-new-england-oldweather.txt` file. The second converted
    all of the `new-england-oldweather-data.txt` weather data records into a separate
    file.
  prefs: []
  type: TYPE_NORMAL
- en: The inspection notebook can load the location definitions and gather the values
    of the `TWID` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: 'One cell for loading the key definitions might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'A cell for inspecting the definitions of the town keys might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This creates the `town_id_set` variable with a set of IDs in use. The values
    of the `town_id_counts` variable are the number of location definitions for each
    ID. Since this is supposed to be a primary key, it should have only a single instance
    of each value.
  prefs: []
  type: TYPE_NORMAL
- en: The data with references to the town keys may be much larger than the definitions
    of the keys. In some cases, it’s not practical to load all the data into memory,
    and instead, the inspection needs to work with summaries of selected columns.
  prefs: []
  type: TYPE_NORMAL
- en: For this example, that means a `list` object is **not** created with the weather
    data. Instead, a generator expression is used to extract a relevant column, and
    this generator is then used to build the final summary `Counter` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rows of data with references to the foreign keys might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the `weather_id_count` summary has been created, the following cell can
    compute the domain of key references like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: It’s important to note that this example emphatically does *not* create a list
    of individual weather report samples. That would be a lot of data jammed into
    memory at one time. Instead, this example uses a generator expression to extract
    the `’ID’` attribute from each row. These values are used to populate the `weather_id_count`
    variable. This is used to extract the set of IDs in use in the weather reports.
  prefs: []
  type: TYPE_NORMAL
- en: Since we have two sets, we can use Python’s set operations to compare the two.
    Ideally, a cell can assert that `weather_id_set`` ==`` town_id_set`. If the two
    are not equal, then the set subtraction operation can be used to locate anomalous
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Summarize keys counts
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The first summary is the comparison of primary keys to foreign keys. If the
    two sets don’t match, the list of missing foreign keys may be helpful for locating
    the root cause of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the range of counts for a foreign key provides some hints as to
    its cardinality and optionality. When a primary key has no foreign key values
    referring to it, the relationship appears optional. This should be confirmed by
    reading the metadata descriptions. The lower and upper bounds on the foreign key
    counts provide the range of the cardinality. Does this range make sense? Are there
    any hints in the metadata about the cardinality?
  prefs: []
  type: TYPE_NORMAL
- en: 'The example data source for this project includes a file with summary counts.
    The `town-summary.txt` file has four columns: “STID”, “TWID”, “YEAR”, and “Records”.
    The “STID” is from the location definitions; it’s the US state. The “TWID” is
    the town ID. The “YEAR” is from the weather data; it’s the year of the report.
    Finally, the “Records” attribute is the count of weather reports for a given location
    and year.'
  prefs: []
  type: TYPE_NORMAL
- en: The Town ID and Year form a logical pair of values that can be used to build
    a `collections.Counter` object. To fully reproduce this table, though, the location
    definitions are needed to map a Town ID, “TWID,” to the associated state, “STID.”
  prefs: []
  type: TYPE_NORMAL
- en: While it’s also possible to decompose the “TWID” key to extract the state information
    from the first two characters, this is not a good design alternative. This composite
    key is an uncommon kind of key design. It’s considerably more common for primary
    keys to be atomic with no internal information available. A good design treats
    the key as an opaque identifier and looks up the state information in the associated
    location definition table from the `readme` file.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.3 Deliverables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This project has the following deliverables:'
  prefs: []
  type: TYPE_NORMAL
- en: A `requirements-dev.txt` file that identifies the tools used, usually `jupyterlab==3.5.3`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation in the `docs` folder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit tests for any new changes to the modules in use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any new application modules with code to be used by the inspection notebook.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A notebook to inspect the attributes that appear to have foreign or primary
    keys.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The project directory structure suggested in [*Chapter** 1*](ch005.xhtml#x1-170001),
    [*Project Zero: A Template* *for Other Projects*](ch005.xhtml#x1-170001) mentions
    a `notebooks` directory. See [*List of deliverables*](ch005.xhtml#x1-260003) for
    some more information. For this project, the notebook directory is needed.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll look at a few of these deliverables in a little more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Revised inspection module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The functions for examining primary and foreign keys can be written in a separate
    module. It’s often easiest to develop these in a notebook first. There can be
    odd discrepancies that arise because of misunderstandings. Once the key examination
    works, it can be moved to the inspection module. As we noted in the [*Description*](#x1-1720001),
    this project’s objective is to support the inspection of the data and the identification
    of special cases, data anomalies, and outlier values.
  prefs: []
  type: TYPE_NORMAL
- en: Unit test cases
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'It’s often helpful to create test cases for the most common varieties of key
    problems: primary keys with no foreign keys and foreign keys with no primary keys.
    These complications don’t often arise with readily available, well-curated data
    sets; they often arise with enterprise data with incomplete documentation.'
  prefs: []
  type: TYPE_NORMAL
- en: This can lead to rather lengthy fixtures that contain two collections of source
    objects. It doesn’t take many rows of data to reveal a missing key; two rows of
    data are enough to show a key that’s present and a row with a missing key.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also essential to keep these test cases separate from test cases for cardinal
    data processing, and ordinal data conversions. Since keys are a kind of nominal
    data, a key cardinality check may be dependent on a separate function to clean
    damaged key values.
  prefs: []
  type: TYPE_NORMAL
- en: For example, real data may require a step to add leading zeroes to account numbers
    before they can be checked against a list of transactions to find transactions
    for the account. These two operations on account number keys need to be built
    — and tested — in isolation. The data cleanup application can combine the two
    functions. For now, they are separate concerns with separate test cases.
  prefs: []
  type: TYPE_NORMAL
- en: Revised notebook to use the refactored inspection model
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A failure to resolve foreign keys is a chronic problem in data acquisition
    applications. This is often due to a wide variety of circumstances, and there’s
    no single process for data inspection. This means a notebook can have a spectrum
    of information in it. We might see any of the following kinds of cells:'
  prefs: []
  type: TYPE_NORMAL
- en: A cell explaining the sets of keys match, and the data is likely usable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A cell explaining some primary keys have no foreign key data. This may include
    a summary of this subset of samples, separate from samples that have foreign key
    references.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A cell explaining some foreign keys that have no primary key. These may may
    reflect errors in the data. It may reflect a more complex relationship between
    keys. It may reflect a more complicated data model. It may reflect missing data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In all cases, an extra cell with some markdown explaining the results is necessary.
    In the future, you will be grateful because in the past, you left an explanation
    of an anomaly in your notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter expanded on the core features of the inspection notebook. We looked
    at handling cardinal data (measures and counts), ordinal data (dates and ranks),
    and nominal data (codes like account numbers).
  prefs: []
  type: TYPE_NORMAL
- en: Our primary objective was to get a complete view of the data, prior to formalizing
    our analysis pipeline. A secondary objective was to leave notes for ourselves
    on outliers, anomalies, data formatting problems and other complications. A pleasant
    consequence of this effort is to be able to write some functions that can be used
    downstream to clean and normalize the data we’ve found.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting in [*Chapter** 9*](ch013.xhtml#x1-2080009), [*Project 3.1: Data Cleaning
    Base Application*](ch013.xhtml#x1-2080009), we’ll look at refactoring these inspection
    functions to create a complete and automated data cleaning and normalization application.
    That application will be based on the lessons learned while creating inspection
    notebooks.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll look at one more lesson that’s often learned from
    the initial inspection. We often discover the underlying schema behind multiple,
    diverse sources of data. We’ll look at formalizing the schema definition via JSONSchema,
    and using the schema to validate data.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5 Extras
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here are some ideas for you to add to the projects in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.1 Markdown cells with dates and data source information
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A minor feature of an inspection notebook is some identification of the date,
    time, and source of the data. It’s sometimes clear from the context what the data
    source is; there may, for example, be an obvious path to the data.
  prefs: []
  type: TYPE_NORMAL
- en: However, in many cases, it’s not perfectly clear what file is being inspected
    or how it was acquired. As a general solution, any processing application should
    produce a log. In some cases, a metadata file can include the details of the processing
    steps.
  prefs: []
  type: TYPE_NORMAL
- en: This additional metadata on the source and processing steps can be helpful when
    reviewing a data inspection notebook or sharing a preliminary inspection of data
    with others. In many cases, this extra data is pasted into ordinary markdown cells.
    In other cases, this data may be the result of scanning a log file for key `INFO`
    lines that summarize processing.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.2 Presentation materials
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A common request is to tailor a presentation to users or peers to explain a
    new source of data, or explain anomalies found in existing data sources. These
    presentations often involve an online meeting or in-person meeting with some kind
    of “slide deck” that emphasizes the speaker’s points.
  prefs: []
  type: TYPE_NORMAL
- en: Proprietary tools like Keynote or PowerPoint are common for these slide decks.
  prefs: []
  type: TYPE_NORMAL
- en: A better choice is to organize a notebook carefully and export it as `reveal.js`
    slides.
  prefs: []
  type: TYPE_NORMAL
- en: The RISE extension for Jupyter is popular for this. See [https://rise.readthedocs.io/en/stable/](https://rise.readthedocs.io/en/stable/).
  prefs: []
  type: TYPE_NORMAL
- en: Having a notebook that is **also** the slide presentation for business owners
    and users provide a great deal of flexibility. Rather than copying and pasting
    to move data from an inspection notebook to PowerPoint (or Keynote), we only need
    to make sure each slide has a few key points about the data. If the slide has
    a data sample, it’s only a few rows, which provide supporting evidence for the
    speaker’s remarks.
  prefs: []
  type: TYPE_NORMAL
- en: In many enterprises, these presentations are shared widely. It can be beneficial
    to make sure the data in the presentation comes directly from the source and is
    immune to copy-paste errors and omissions.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.3 JupyterBook or Quarto for even more sophisticated output
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In some cases, a preliminary inspection of data may involve learning a lot of
    lessons about the data sources, encoding schemes, missing data, and relationships
    between data sets. This information often needs to be organized and published.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a number of ways to disseminate lessons learned about data:'
  prefs: []
  type: TYPE_NORMAL
- en: Share the notebooks. For some communities of users, the interactive nature of
    a notebook invites further exploration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Export the notebook for publication. One choice is to create a PDF that can
    be shared. Another choice is to create RST, Markdown, or LaTeX and use a publishing
    pipeline to build a final, shareable document.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a tool like Jupyter{Book} to formalize the publication of a shareable document.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Quarto to publish a final, shareable document.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Jupyter{Book}, see [https://jupyterbook.org/en/stable/intro.html](https://jupyterbook.org/en/stable/intro.html).
    The larger “Executable{Books}” project ( [https://executablebooks.org/en/latest/tools.html](https://executablebooks.org/en/latest/tools.html))
    describes the collection of Python-related tools, including Myst-NB, Sphinx, and
    some related Sphinx themes. The essential ingredient is using Sphinx to control
    the final publication.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Quarto, see [https://quarto.org](https://quarto.org). This is somewhat
    more tightly integrated: it requires a single download of the Quarto CLI. The
    Quarto tool leverages Pandoc to produce a final, elegant, ready-to-publish file.'
  prefs: []
  type: TYPE_NORMAL
- en: You are encouraged to look at ways to elevate the shared notebook to an elegant
    report that can be widely shared.
  prefs: []
  type: TYPE_NORMAL
