- en: Chapter 8. More Advanced Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 7](ch07.html "Chapter 7. Basic Function Definitions"), *Basic Function
    Definitions*, we looked at the core features of defining a function which returns
    a single result. Even functions with an implicit `return` statement at the end
    of the suite of statements, or a function with a `return` statement that has no
    expression, return a result: the `None` object is the default return value. In
    this chapter, we''ll look at functions which generate multiple results. A generator
    function defines an iterable: it can be used with a `for` statement. This means
    that the generator doesn''t produce a single object with all of the items in the
    result; instead it produces each item of the result separately.'
  prefs: []
  type: TYPE_NORMAL
- en: Python offers generator expressions and comprehensions which complement the
    idea of generator functions. We can write simple expressions that represent a
    sequence of values which is generated one item at a time. We can use generator
    expressions to create `list`, `set`, or `dict` objects via a comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: We'll review the `for` statement and its relationship with iterable data. This
    will help us understand how generator functions work. We'll also look at some
    functions which work as well with collection objects as with generator functions.
    This includes built-in reduction functions such as `max()`, `min()`, and `sum()`.
    It also includes higher-order functions such as `map()`, `filter()`, `functools.reduce()`,
    and the functions of the `itertools` module.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will skim over some concepts of functional programming. An entire
    book could be written about functional programming in Python. See [https://www.packtpub.com/application-development/functional-python-programming](https://www.packtpub.com/application-development/functional-python-programming)
    for more information. We'll focus on the essentials.
  prefs: []
  type: TYPE_NORMAL
- en: Using the for statement with iterable collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python allows us to use the `for` statement with any kind of collection. We
    can write a statement like `for x in coll` to process `list`, `set`, or the keys
    of a `dict`. This works because all of the Python collections have common abstract
    base classes, defined in the `collections.abc` module.
  prefs: []
  type: TYPE_NORMAL
- en: This works via a common feature of the base classes, `Sequence`, `Set`, and
    `Mapping`. The `Iterable` mix in the class is part of each class definition. The
    implementation of this abstraction is our guarantee that all of the built-in collections
    will cooperate with the `for` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s open up the internals to see how it works. We''ll use this compound
    `for` statement as a concrete example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Conceptually, this compound statement starts with something very much like
    this assignment: `coll_i=iter(coll)`. This will get an iterator object for the
    `coll` collection. This `iter()` function will leverage the special method `__iter__()`
    to produce the iterator object. We can summarize how this works with a simple
    rule: if the variable `coll` doesn''t reference a proper collection, a `TypeError`
    exception will be raised.'
  prefs: []
  type: TYPE_NORMAL
- en: Given the resulting iterator object, `coll_i`, the `for` statement can then
    evaluate `x=next(coll_i)` to get each item from the iterator. This will leverage
    the special method `coll_i.__next__()` to produce an item from the original collection.
  prefs: []
  type: TYPE_NORMAL
- en: If the evaluation of `next(coll_i)` returns an item, this is assigned to `x`
    and the suite of statements is executed with this value bound to the `x` variable.
    We'll see the value of `x` printed.
  prefs: []
  type: TYPE_NORMAL
- en: If `next(coll_i)` raises a `StopIteration` exception, the underlying collection
    is out of items, and the loop will finish normally. In the case of any another
    exception being raised, this simply propagates according to the standard exception
    rules. (We'll look at exceptions in [Chapter 9](ch09.html "Chapter 9. Exceptions"),
    *Exceptions*.)
  prefs: []
  type: TYPE_NORMAL
- en: Iterators and iterable collections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A collection is iterable when it implements the `__iter__()` special method.
    Almost universally, this means that it will be a subclass of the `Iterable` class
    defined in the `collections.abc` module. The presence of this special method means
    that evaluating `iter()` on a collection object will return an iterator object.
  prefs: []
  type: TYPE_NORMAL
- en: The iterator for a collection must implement the `__next__()` and `__iter__()`
    special methods. Generally, an iterator object implements the `__iter__()` method
    by returning itself as the result. Having this tautological redundancy available
    means that we can not only create an explicit iterator but also provide the iterator
    to a `for` statement without causing an exception; the `for` statement's processing
    can evaluate `iter(object)` without the overheads of checking to see if the object
    is already an iterator.
  prefs: []
  type: TYPE_NORMAL
- en: What if we have a sequence of items which has a header that we'd like to ignore?
    This often happens when a source data file includes a heading line that must be
    processed separately. We can leverage an explicit iterator object to discard items
    from a sequential collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'We might write something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we've created an iterator, `source_iter`, based on a source
    collection or generator, unimaginatively named `source`. When we evaluated `next(source_iter)`,
    we consumed the first item from the collection, which we then assigned to the
    `heading` variable. We can then use the iterator object in the `for` statement
    to consume the rest of the items in that iterator.
  prefs: []
  type: TYPE_NORMAL
- en: 'In effect, the preceding example is nearly identical to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This second example actually makes a shallow copy of the source collection and
    assigns this copy to the `rest` variable. We've nearly doubled the amount of memory
    used. For a small list, this doesn't matter. For a larger collection, this can
    become a problem.
  prefs: []
  type: TYPE_NORMAL
- en: If the source is an open file or a generator based on an open file, materializing
    the data in the `rest` collection could be impossible. Files too big to fit into
    memory are part of their own unique problem, sometimes called "big data". Using
    the `iter()` function explicitly allows us to avoid the risky attempt to create
    a large collection that may not fit in memory.
  prefs: []
  type: TYPE_NORMAL
- en: Consequences and next steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are three important consequences to the way a `for` statement uses `coll_i=
    iter(x)` and `x=next(coll_i)`:'
  prefs: []
  type: TYPE_NORMAL
- en: We can write generator expressions which implicitly have the required interface
    to work as an `Iterable` class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python gives us a way to write generator functions which will work as an `Iterable`
    class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can create our own classes which implement the special method names required
    to implement the `Iterable` abstract base class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll start by writing generator expressions. We can use these to create `list`,
    `set`, and mapping "comprehensions." A **comprehension** is an expression that
    defines the contents of a collection.
  prefs: []
  type: TYPE_NORMAL
- en: We'll look at writing generator functions. The `yield` statement changes the
    semantics of a function from being "simple" (or "ordinary") to being a generator.
  prefs: []
  type: TYPE_NORMAL
- en: While class definitions are the subject of [Chapter 11](ch11.html "Chapter 11. Class
    Definitions"), *Class Definitions*, we won't dig deeply into how we can create
    our own unique collections. Python already offers so many collections that defining
    our own is not really necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Using generator expressions and comprehensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can think of simple generator expressions as an operator with three operands.
    The syntax for these three operands parallels the `for` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We specify an *expression* which is evaluated for each value assigned to a *target*
    variable from a *source*. There are more complex generators, which we'll look
    at later.
  prefs: []
  type: TYPE_NORMAL
- en: Generator expressions can be used freely in Python. They can be used anywhere
    in a sequence or a collection that is meaningful.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s important to note that a generator expression is lazy, or "non-strict."
    It doesn''t actually calculate anything until some consuming operation demands
    values from it. To see this, we can try to evaluate a generator expression at
    the REPL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Python tells us only that we've created a generator object. Since we didn't
    write an expression to consume the values, all we saw was the object, passively
    waiting to be evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The best way to explore a generator expression is to apply a function, such
    as `list()` or `tuple()`, that will consume the generator''s values and build
    a collection object from them. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the `tuple()` function consumed values from the generator object
    and created a `tuple` object from those values. Rather than display the generator
    object, the REPL shows us the `tuple` which was created from the generated values.
  prefs: []
  type: TYPE_NORMAL
- en: We can use generator expressions for a wide variety of processing. There are
    several patterns in the `itertools` module.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of generator expressions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generator expressions have a few limitations. The most obvious limitation is
    that some language features are only available as Python statements. If we need
    to perform exception handling, context management, or exiting a loop early via
    a `break` statement, we can't write a generator expression. We have to resort
    to writing a complete generator function.
  prefs: []
  type: TYPE_NORMAL
- en: 'A less obvious limitation is that a generator expression behaves very much
    like a sequence. But it can only do that trick once. After the generator terminates
    the first time, it behaves like an empty sequence every time it''s referenced
    after that. Here''s a concrete example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we assigned a generator expression to a variable, `x`. When
    we compute `sum(x)`, the `sum()` function consumes all of the values produced
    by the generator expression: the sum is 400 in this example. Once we''ve used
    the generator, it is still valid, but it no longer generates values. All subsequent
    evaluations of `sum(x)` will produce 0.'
  prefs: []
  type: TYPE_NORMAL
- en: There's no special exception to warn us that we're reusing an iterator that
    has already been exhausted. In some cases, a program may appear broken because
    we're using a generator expression instead of a `list` or `tuple` sequence. The
    fix is almost always to convert the generator into a `tuple` object so that it
    can be used twice. We can change to `x= tuple(2*x+1 for x in range(20))` to see
    the difference.
  prefs: []
  type: TYPE_NORMAL
- en: When working with a generator function or expression, `iter(some_function)`
    will return the generator object because it is an iterator. In the case of a collection
    object, `iter(some_collection)` will create an iterator object that has a reference
    to the collection. The result will be a distinct object. A function can use `iter(param)
    is iter(param)` to detect the difference between a generator function and a concrete
    collection.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, we might include the statement `assert iter(param) is not iter(param),
    "Collection object required"` to raise an exception if a generator function is
    provided as an argument to a function which traverses a collection more than once.
  prefs: []
  type: TYPE_NORMAL
- en: Using multiple loops and conditions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The body of a generator can include multiple `for` clauses. This allows us
    to iterate over multiple dimensions. We can write expressions like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The generator expression has two `for` clauses: `for s in ''♣♦♥♠''` and `for
    r in range(1,14)`. It''s clear from the results that the `for` clause on the right
    executes most frequently. This follows the nesting rules we''d see if we rewrote
    this as nested `for` statements. The `for` clause on the right is like an innermost
    `for` statement.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, the body of a generator can include `if` clauses. These can be
    used to filter values created by the `for` clauses. Here''s an example of conditional
    processing in a generator expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the expression is just the target variable, `x`. The source
    is `range(36)`, numbers that include zero and 35\. We've included an `if` clause
    that will pass only those values which are multiples of five or seven. All other
    values will be rejected. In order to see a result, we collected the values from
    the generator into a `list` object.
  prefs: []
  type: TYPE_NORMAL
- en: Writing comprehensions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can leverage a variation of the generator expression to create `list`, `set`,
    or `dict` objects. These are called comprehensions, and represent tangible objects,
    built from lazy generators.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some simple examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The first example uses the `[]` to create a `list` comprehension. This will
    create a list of odd values from one to nine. The second example uses `{}` to
    create a `set` comprehension. This will be a set based on multiples of five or
    seven.
  prefs: []
  type: TYPE_NORMAL
- en: The third example creates a `dict` comprehension. The `{}` are used to bracket
    the expression. The use of the `:` character to separate key and value distinguishes
    a `dict` comprehension from a `set` comprehension. This dictionary provides a
    mapping from values of *n*.
  prefs: []
  type: TYPE_NORMAL
- en: This last example could be used as an optimization for a deeply-nested expression.
    Looking up a value in a mapping is faster than repeatedly recalculating. Using
    the `@lru_cache` decorator gives similar performance benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Defining generator functions with the yield statement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A generator function has properties similar to a generator expression. Rather
    than a single expression, a generator function is a full Python function. It has
    all of the features of the functions described in [Chapter 7](ch07.html "Chapter 7. Basic
    Function Definitions"), *Basic Function Definitions*. It has the additional characteristic
    of being an iterator, capable of generating a sequence of items.
  prefs: []
  type: TYPE_NORMAL
- en: When we use a `yield` statement, the semantics of the function are changed.
    Without a `yield`, a function will return a single value. With a `yield` statement,
    a function will behave like an iterator, providing multiple values to a consumer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of a generator function that applies a range of values to
    a model to compute a domain of results. We''ll apply the model to a sequence of
    input values to compute the results for each input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This `model_iter()` function accepts a single argument, `until`, which is the
    number of values generated by this function. The body of the function includes
    a `for` statement which will set the `n` variable to values defined by the `range()`
    object.
  prefs: []
  type: TYPE_NORMAL
- en: The essential feature of this function is the `yield` statement. Each value
    created by the `yield` statement will be part of the sequence of items emitted
    by this statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s one way to use this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we've collected the results into a single `list` object. Creating
    a `list` object is just one of the many things we can do. We could just as easily
    sum the results of the model to compute the mean value for the given range.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we provided the results of the `model_iter()` generator to
    the `sum()` function. This avoids building a large collection of results. The
    `sum()` function will consume all of the values yielded by the generator function.
    We can process thousands or millions of values with this kind of construct because
    a large `list` or `set` is not materialized in memory. Only the individual items
    are processed.
  prefs: []
  type: TYPE_NORMAL
- en: Using the higher-order functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A function which accepts a function as an argument, or returns a function as
    a result, is called a **higher-order function**. Python has a number of higher-order
    functions. The most commonly-used of these functions are `map()`, `filter()`,
    and `sorted()`. The `itertools` module contains numerous additional higher-order
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: The `map()` and `filter()` functions are generators; their results must be consumed.
    Both of them apply a function to a collection of values. In the case of `map()`,
    the results of the function are yielded. In the case of `filter()`, if the result
    of the function is true, the original value is yielded.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how we can apply a very simple function—so simple we coded it as a
    lambda—to a sequence of values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The function is just an expression, `2*x**2-2`. We've applied this function
    to values given by the `range()` object. The result is a generator, and we need
    to consume the values. We've used `list()` to create a collection that we can
    print. The values are the result of applying the given function to each value
    in the source collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how we can apply a simple logical test to a sequence of values using
    `filter()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We've defined a simple function as a lambda; the function, `n%5==0 or n%7==0`,
    is true for multiples of five or seven. We've applied that filter to values produced
    by a `range()` object. The result includes only the values for which the given
    function is `True`. All other values are rejected.
  prefs: []
  type: TYPE_NORMAL
- en: We used a `list` comprehension to gather the values into a `list` object. This
    `list` comprehension did no calculation and no filtering, so it's equivalent to
    `list(fb)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can implement the simple versions of `map()` and `filter()` using generator
    expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`map(function, iterable)` is the same as `(function(x) for x in iterable)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`filter(function, iterable)` is the same as `(x for x in iterable if function(x))`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `map()` function can handle additional iterables, providing more sophistication
    than the generator expression.
  prefs: []
  type: TYPE_NORMAL
- en: The `sorted()` function is similar to `map()` and `filter()`. The `sorted()`
    function follows a different design pattern for its parameters. The `map()` and
    `filter()` functions accept a function first, followed by an item to process.
    The `sorted()` function accepts an item to sort first, and an optional function
    which defines the keys on which to sort, as well as an optional reverse Boolean
    value used to reverse the sense of the key comparisons. We'll look at sorted in
    detail in the *Three ways to sort a sequence* section later.
  prefs: []
  type: TYPE_NORMAL
- en: The `itertools` module contains a large number of generator functions that can
    be combined to create sophisticated processing. For more information on how this
    module works, the book, *Functional Python Programming*, *Steven Lott*, *Packt
    Publishing*, devotes two chapters to the subject ([https://www.packtpub.com/application-development/functional-python-programming](https://www.packtpub.com/application-development/functional-python-programming)).
  prefs: []
  type: TYPE_NORMAL
- en: Writing our own higher-order functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Perhaps the simplest kind of higher-order function is based on a generator expression.
    Since a generator expression is lazy, its behavior is more like a function than
    an object which contains relevant data. A function which returns a generator relies
    on some other piece of programming to actually consume the data which is yielded
    by the generator.
  prefs: []
  type: TYPE_NORMAL
- en: A common file input requirement is to strip trailing punctuation and ignore
    blank lines. We'll assume a language which follows the Python rule for comments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of a function that returns a generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We've broken down the processing into four separate generator functions. The
    result of the function is the fourth of these generators, but this depends on
    the others to yield its results. Since generators are lazy, no processing happens
    until a function or statement consumes the data yielded by the generator. We must
    use the result of this function with a `for` statement or a `list()` or `tuple()`
    function to consume the data.
  prefs: []
  type: TYPE_NORMAL
- en: When a consuming process iterates over the result of this function, it will
    receive individual lines of text from the `non_empty` generator expression. The
    `non_empty` generator filters the lines created by the `decommented` generator
    expression. The `decommented` generator in turn relies on the `partitioned` and
    `stripped` generator expressions to remove comments and whitespace.
  prefs: []
  type: TYPE_NORMAL
- en: What's important here is that the pipeline of processing is the return value
    from the `text_cleaner()` function. This function does not process any data. This
    function returns a generator expression that will process some data.
  prefs: []
  type: TYPE_NORMAL
- en: Each of these generators can be also rewritten to use `map()` or `filter()`.
    We'll leave that as an exercise for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `text_cleaner()` function like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We've created some text with comments and data. The format of the data appears
    to be `name=value` settings. The `text_cleaner()` function isn't sensitive to
    the format of the data, only to the presence of comments and whitespace. We applied
    the `splitlines()` function to make the block of text behave like a file.
  prefs: []
  type: TYPE_NORMAL
- en: The result of `text_cleaner()` is a function which strips away comments, leading
    and trailing spaces, and leaves us with just the meaningful content of the file.
    In this example, we used a `for` statement to consume the data yielded by the
    generator function.
  prefs: []
  type: TYPE_NORMAL
- en: This can be part of a more complex process that uses these `name=value` lines
    as configuration parameters.
  prefs: []
  type: TYPE_NORMAL
- en: What's important about generator functions is that they are completely lazy.
    They don't create giant data structures in memory. They process the minimum amount
    of data to satisfy the consumer's requests. This reduces overheads. Additionally,
    each generator can be kept relatively simple, allowing an expressive composition
    to be built from simple pieces.
  prefs: []
  type: TYPE_NORMAL
- en: Using the built-in reductions – max, min, and reduce
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have two other built-in higher-order functions that can accept functions
    as arguments. These can be characterized as reductions: they reduce a collection
    of values to a single value. There''s a third built-in reduction, sum, but it''s
    not a proper higher-order function: we can''t tailor its operation by plugging
    in a function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `max()` and `min()` reductions follow the design pattern for the `sorted()`
    function: they accept an iterable object first, and they can be customized with
    an optional key function. We''ll show the default behavior first, then we''ll
    show how to customize this with the key function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In the first example, the string objects were compared using string comparison.
    This leads to the anomaly of seeing `"21"` appear to be less than `"3"`. In fact,
    a string beginning with `"2"` is sorted before a string beginning with `"3"`,
    but this may not be what the program needs to show as output.
  prefs: []
  type: TYPE_NORMAL
- en: In the second example, we provided the `int()` function for min to use when
    comparing items. This means that the strings are compared as integers, not as
    strings. This selects `"3"` as the string with the minimal integer value.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we did not write `min(data, key=int())`. We're not evaluating the
    `int` function. We're providing the `int` function as an object which the `min()`
    function will use.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, there's a generic `functools.reduce()` function which can be used
    to build new kinds of reductions. This function accepts a two-valued function,
    an iterable and an initial value. It can compute a wide variety of reductions.
  prefs: []
  type: TYPE_NORMAL
- en: Three ways to sort a sequence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python offers us three common approaches to the general problem of sorting a
    `list` of complex items.
  prefs: []
  type: TYPE_NORMAL
- en: We can sort with the `sorted()` generator function. This will duplicate an object
    as part of sorting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can sort a list with its `sort()` method and a key function. This will mutate
    the `list` into the requested order.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can create an intermediate sequence of objects which can be sorted easily.
    This is sometimes called the **wrap-sort-unwrap** design pattern.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to look at each of these in some detail, we need a collection of complex
    objects which we can sort. We'll use a simple dataset based on a case study in
    the *NIST Engineering Statistics Handbook*, section 7.1.6\. See [http://www.itl.nist.gov/div898/handbook](http://www.itl.nist.gov/div898/handbook)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve got metrics data that—after a little re-organization and cleanup—looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We have a list-of-list structure with 90 pairs. Since the date strings are formatted
    nicely as `yyyy-mm-dd`, we can easily sort this into date order using the `sorted(data)`
    function, or the `data.sort()` method. Note that `sorted(data)` will create a
    duplicate of the `data` object. The `data.sort()` method will mutate the `data`
    object in place.
  prefs: []
  type: TYPE_NORMAL
- en: How can we put the data into order by count? We can apply a key function to
    the `sorted()` function or `sort()` method. We'll look at these first. As an alternative,
    we can use the wrap-sort-unwrap design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Sorting via a key function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Putting the metrics data into order by count requires us to use a function which
    will change the way items are compared. In this case, we need a more complex key
    function that does two things. It must select the second item of each two item
    data points, and it must convert the second item to a proper integer value.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can sort by count using either of these examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Both examples use a lambda that performs the integer conversion of the second
    item in each two-item list. The first example updates the data object. The second
    example creates a new object which is a clone of the data object, put into order.
  prefs: []
  type: TYPE_NORMAL
- en: Sorting via wrapping and unwrapping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The wrap-sort-unwrap design pattern can be done with a pair of generator expressions.
    The first will create two-tuples from each original piece of data. The first item
    in each new two-tuple is the proper sort key. The second generator will select
    the second item from each of those two-tuples to recover the original object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The whole sequence looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the first step, we turned each piece of original data into a two-tuple of
    `(sort key, original item)`. We've used a `list` comprehension to create a new
    object that we can sort, leaving the original object undisturbed. Once we've done
    this, the default sort operation works correctly. Once the data is sorted, we
    can recover the original items easily. In this case, we created yet another list
    object using a `list` comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: 'In both cases, we can tweak this slightly to the `map()` function instead of
    with generator expressions. For example, we can wrap items using `map(lambda item:
    (int(item[1]), item), data)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the `map()` function is a generator: it''s lazy. A `list` comprehension
    consumes data and creates a tangible object. We can''t easily switch from `list`
    to generator with a simple copy-and-paste. We''ll need to either create a `list`
    object from the map generator, or use `sorted()`, which creates a `list` from
    a generator.'
  prefs: []
  type: TYPE_NORMAL
- en: The wrap-sort-unwrap is often used when the wrap function is quite complex.
    We might have a generator which performs database lookups, file merges, or extremely
    complex calculations as part of the ordering. In these cases, a simple lambda
    might be difficult to write.
  prefs: []
  type: TYPE_NORMAL
- en: Functional programming design patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The presence of higher-order functions in Python allows us to leverage a great
    many functional programming design patterns. To learn more about these design
    patterns, a good place to start is the `itertools` module. The functions in this
    module provide many examples of how we can write simple functions that do sophisticated
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, we can use some of the features in the `functools` module. This
    contains the general-purpose `reduce()` function. It also contains some functions
    that can help us write decorators. A decorator, as we''ll see in [Chapter 13](ch13.html
    "Chapter 13. Metaprogramming and Decorators"), *Metaprogramming and Decorators*,
    is another kind of higher-order function: it''s a function that modifies the definition
    of an original function. This is another aspect of functional programming.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most importantly, we have two ways to approach algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: We can process items in large collections of data, creating additional collections
    that are copies, subsets, or transformations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can process items by iterating through a large collection of data as if we're
    creating additional collections. Instead of actually creating copies, subsets,
    or transformations, we can use iterators, filter functions, and mapping functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we have alternatives, we can choose a variation that is succinct and expressive.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've seen a number of the advanced features of functions.
    We've looked at the essential generator expression and how this is used as part
    of a comprehension. A `list` comprehension assembles a `list` from the generated
    values. Similarly, a `set` comprehension creates a `set`. A dictionary comprehension
    creates a `dict` structure from the keys and values in a generator expression.
  prefs: []
  type: TYPE_NORMAL
- en: We've looked at using the `yield` statement to create a generator function.
    This allows us to use all of the various Python statement features when creating
    a generator. Since a generator is iterable, it works with a `for` loop so that
    we can write a simple loop to process multiple values created by an iterator.
  prefs: []
  type: TYPE_NORMAL
- en: We've also looked at higher-order functions. These are functions which take
    functions as arguments or produce functions as a result. With higher-order functions,
    we can refactor our algorithms into functions that can be combined to create the
    desired behavior.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 9](ch09.html "Chapter 9. Exceptions"), *Exceptions*, we'll look
    at how Python raises exceptions, how we can capture those exceptions, and what
    kind of exceptional processing we need to write.
  prefs: []
  type: TYPE_NORMAL
