["```py\n$ tree -A\n.\n├── guiscrape.py\n├── scrape.py\n└── simple_server\n ├── img\n │   ├── owl-alcohol.png\n │   ├── owl-book.png\n │   ├── owl-books.png\n │   ├── owl-ebook.jpg\n │   └── owl-rose.jpeg\n ├── index.html\n └── serve.sh\n\n```", "```py\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head><title>Cool Owls!</title></head>\n  <body>\n    <h1>Welcome to my owl gallery</h1>\n    <div>\n      <img src=\"img/strong>\" height=\"128\" />\n      <img src=\"img/strong>\" height=\"128\" />\n      <img src=\"img/strong>\" height=\"128\" />\n      <img src=\"img/strong>\" height=\"128\" />\n      <img src=\"img/strong>\" height=\"128\" />\n    </div>\n    <p>Do you like my owls?</p>\n  </body>\n</html>\n```", "```py\n$ python -m http.server 8000\nServing HTTP on 0.0.0.0 port 8000 ...\n127.0.0.1 - - [31/Aug/2015 16:11:10] \"GET / HTTP/1.1\" 200 -\n\n```", "```py\n$ ./serve.sh\n\n```", "```py\nimport argparse\nimport base64\nimport json\nimport os\nfrom bs4 import BeautifulSoup\nimport requests\n```", "```py\n$ pip freeze | egrep -i \"soup|requests\"\nbeautifulsoup4==4.4.0\nrequests==2.7.0\n\n```", "```py\n$ pip install beautifulsoup4 requests\n\n```", "```py\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(\n        description='Scrape a webpage.')\n    parser.add_argument(\n        '-t',\n        '--type',\n        choices=['all', 'png', 'jpg'],\n        default='all',\n        help='The image type we want to scrape.')\n    parser.add_argument(\n        '-f',\n        '--format',\n        choices=['img', 'json'],\n        default='img',\n        help='The format images are saved to.')\n    parser.add_argument(\n        'url',\n        help='The URL we want to scrape for images.')\n    args = parser.parse_args()\n    scrape(args.url, args.format, args.type)\n```", "```py\n$ python scrape.py -h\nusage: scrape.py [-h] [-t {all,png,jpg}] [-f {img,json}] url\n\n```", "```py\nScrape a webpage.\n\npositional arguments:\n url                   The URL we want to scrape for images.\n\noptional arguments:\n -h, --help            show this help message and exit\n -t {all,png,jpg}, --type {all,png,jpg}\n The image type we want to scrape.\n -f {img,json}, --format {img,json}\n The format images are saved to.\n\n```", "```py\n$ python scrape.py http://localhost:8000\n$ python scrape.py -t png http://localhost:8000\n$ python scrape.py --type=jpg -f json http://localhost:8000\n\n```", "```py\ndef scrape(url, format_, type_):\n    try:\n        page = requests.get(url)\n    except requests.RequestException as rex:\n        print(str(rex))\n    else:\n        soup = BeautifulSoup(page.content, 'html.parser')\n        images = _fetch_images(soup, url)\n        images = _filter_images(images, type_)\n        _save(images, format_)\n\ndef _fetch_images(soup, base_url):\n    images = []\n    for img in soup.findAll('img'):\n        src = img.get('src')\n        img_url = (\n            '{base_url}/{src}'.format(\n                base_url=base_url, src=src))\n        name = img_url.split('/')[-1]\n        images.append(dict(name=name, url=img_url))\n    return images\n\ndef _filter_images(images, type_):\n    if type_ == 'all':\n        return images\n    ext_map = {\n        'png': ['.png'],\n        'jpg': ['.jpg', '.jpeg'],\n    }\n    return [\n        img for img in images\n        if _matches_extension(img['name'], ext_map[type_])\n    ]\n\ndef _matches_extension(filename, extension_list):\n    name, extension = os.path.splitext(filename.lower())\n    return extension in extension_list\n\ndef _save(images, format_):\n    if images:\n        if format_ == 'img':\n            _save_images(images)\n        else:\n            _save_json(images)\n        print('Done')\n    else:\n        print('No images to save.')\n\ndef _save_images(images):\n    for img in images:\n        img_data = requests.get(img['url']).content\n        with open(img['name'], 'wb') as f:\n            f.write(img_data)\n\ndef _save_json(images):\n    data = {}\n    for img in images:\n        img_data = requests.get(img['url']).content\n        b64_img_data = base64.b64encode(img_data)\n        str_img_data = b64_img_data.decode('utf-8')\n        data[img['name']] = str_img_data\n\n    with open('images.json', 'w') as ijson:\n        ijson.write(json.dumps(data))\n```", "```py\n[{'url': 'http://localhost:8000/img/owl-alcohol.png', 'name': 'owl-alcohol.png'}, {'url': 'http://localhost:8000/img/owl-book.png', 'name': 'owl-book.png'}, ...]\n\n```", "```py\n{\n \"owl-ebook.jpg\": \"/9j/4AAQSkZJRgABAQEAMQAxAAD/2wBDAAEBAQ...\n \"owl-book.png\": \"iVBORw0KGgoAAAANSUhEUgAAASwAAAEbCAYAAAB...\n \"owl-books.png\": \"iVBORw0KGgoAAAANSUhEUgAAASwAAAElCAYAAA...\n \"owl-alcohol.png\": \"iVBORw0KGgoAAAANSUhEUgAAASwAAAEICAYA...\n \"owl-rose.jpeg\": \"/9j/4AAQSkZJRgABAQEANAA0AAD/2wBDAAEBAQ...\n}\n\n```", "```py\n$ python -m tkinter\n\n```", "```py\nfrom tkinter import *\nfrom tkinter import ttk, filedialog, messagebox\nimport base64\nimport json\nimport os\nfrom bs4 import BeautifulSoup\nimport requests\n```", "```py\nif __name__ == \"__main__\":\n    _root = Tk()\n    _root.title('Scrape app')\n```", "```py\n    _mainframe = ttk.Frame(_root, padding='5 5 5 5')\n    _mainframe.grid(row=0, column=0, sticky=(E, W, N, S))\n```", "```py\n    _url_frame = ttk.LabelFrame(\n        _mainframe, text='URL', padding='5 5 5 5')\n    _url_frame.grid(row=0, column=0, sticky=(E, W))\n    _url_frame.columnconfigure(0, weight=1)\n    _url_frame.rowconfigure(0, weight=1)\n```", "```py\n    _url = StringVar()\n    _url.set('http://localhost:8000')\n    _url_entry = ttk.Entry(\n        _url_frame, width=40, textvariable=_url)\n    _url_entry.grid(row=0, column=0, sticky=(E, W, S, N), padx=5)\n    _fetch_btn = ttk.Button(\n        _url_frame, text='Fetch info', command=fetch_url)\n    _fetch_btn.grid(row=0, column=1, sticky=W, padx=5)\n```", "```py\n    _img_frame = ttk.LabelFrame(\n        _mainframe, text='Content', padding='9 0 0 0')\n    _img_frame.grid(row=1, column=0, sticky=(N, S, E, W))\n```", "```py\n    _images = StringVar()\n    _img_listbox = Listbox(\n        _img_frame, listvariable=_images, height=6, width=25)\n    _img_listbox.grid(row=0, column=0, sticky=(E, W), pady=5)\n    _scrollbar = ttk.Scrollbar(\n        _img_frame, orient=VERTICAL, command=_img_listbox.yview)\n    _scrollbar.grid(row=0, column=1, sticky=(S, N), pady=6)\n    _img_listbox.configure(yscrollcommand=_scrollbar.set)\n```", "```py\n    _radio_frame = ttk.Frame(_img_frame)\n    _radio_frame.grid(row=0, column=2, sticky=(N, S, W, E))\n```", "```py\n    _choice_lbl = ttk.Label(\n        _radio_frame, text=\"Choose how to save images\")\n    _choice_lbl.grid(row=0, column=0, padx=5, pady=5)\n    _save_method = StringVar()\n    _save_method.set('img')\n    _img_only_radio = ttk.Radiobutton(\n        _radio_frame, text='As Images', variable=_save_method,\n        value='img')\n    _img_only_radio.grid(\n        row=1, column=0, padx=5, pady=2, sticky=W)\n    _img_only_radio.configure(state='normal')\n    _json_radio = ttk.Radiobutton(\n        _radio_frame, text='As JSON', variable=_save_method,\n        value='json')\n    _json_radio.grid(row=2, column=0, padx=5, pady=2, sticky=W)\n```", "```py\n    _scrape_btn = ttk.Button(\n        _mainframe, text='Scrape!', command=save)\n    _scrape_btn.grid(row=2, column=0, sticky=E, pady=5)\n```", "```py\n    _status_frame = ttk.Frame(\n        _root, relief='sunken', padding='2 2 2 2')\n    _status_frame.grid(row=1, column=0, sticky=(E, W, S))\n    _status_msg = StringVar()\n    _status_msg.set('Type a URL to start scraping...')\n    _status = ttk.Label(\n        _status_frame, textvariable=_status_msg, anchor=W)\n    _status.grid(row=0, column=0, sticky=(E, W))\n```", "```py\n _root.mainloop()\n\n```", "```py\nconfig = {}\n\ndef fetch_url():\n    url = _url.get()\n    config['images'] = []\n    _images.set(())   # initialized as an empty tuple\n    try:\n        page = requests.get(url)\n    except requests.RequestException as rex:\n        _sb(str(rex))\n    else:\n        soup = BeautifulSoup(page.content, 'html.parser')\n        images = fetch_images(soup, url)\n        if images:\n            _images.set(tuple(img['name'] for img in images))\n            _sb('Images found: {}'.format(len(images)))\n        else:\n            _sb('No images found')\n        config['images'] = images\n\ndef fetch_images(soup, base_url):\n    images = []\n    for img in soup.findAll('img'):\n        src = img.get('src')\n        img_url = (\n            '{base_url}/{src}'.format(base_url=base_url, src=src))\n        name = img_url.split('/')[-1]\n        images.append(dict(name=name, url=img_url))\n    return images\n```", "```py\ndef save():\n    if not config.get('images'):\n        _alert('No images to save')\n        return\n\n    if _save_method.get() == 'img':\n        dirname = filedialog.askdirectory(mustexist=True)\n        _save_images(dirname)\n    else:\n        filename = filedialog.asksaveasfilename(\n            initialfile='images.json',\n            filetypes=[('JSON', '.json')])\n        _save_json(filename)\n\ndef _save_images(dirname):\n    if dirname and config.get('images'):\n        for img in config['images']:\n            img_data = requests.get(img['url']).content\n            filename = os.path.join(dirname, img['name'])\n            with open(filename, 'wb') as f:\n                f.write(img_data)\n        _alert('Done')\n\ndef _save_json(filename):\n    if filename and config.get('images'):\n        data = {}\n        for img in config['images']:\n            img_data = requests.get(img['url']).content\n            b64_img_data = base64.b64encode(img_data)\n            str_img_data = b64_img_data.decode('utf-8')\n            data[img['name']] = str_img_data\n\n        with open(filename, 'w') as ijson:\n            ijson.write(json.dumps(data))\n        _alert('Done')\n```", "```py\ndef _sb(msg):\n    _status_msg.set(msg)\n\ndef _alert(msg):\n    messagebox.showinfo(message=msg)\n```", "```py\nwith open('images.json', 'r') as f:\n    data = json.loads(f.read())\n\nfor (name, b64val) in data.items():\n    with open(name, 'wb') as f:\n        f.write(base64.b64decode(b64val))\n```"]