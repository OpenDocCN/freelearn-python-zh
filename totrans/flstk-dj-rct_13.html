<html><head></head><body>
		<div><h1 id="_idParaDest-238" class="chapter-number"><a id="_idTextAnchor252"/>13</h1>
			<h1 id="_idParaDest-239"><a id="_idTextAnchor253"/>Dockerizing the Django Project</h1>
			<p>In the previous chapter, we learned more about software <a id="_idTextAnchor254"/>deployment, and we <a id="_idTextAnchor255"/>deployed the Django application on an AWS server. However, we came across issues such as poor preparation of the project for deployment, violation of some security issues, and deployment and development configuration.</p>
			<p>In this chapter, we will learn how to use Docker on the Django backend and configure environment variables. We will also configure the database on a web server called <strong class="bold">NGINX</strong> using <strong class="bold">Docker</strong>. Here are the big sections of the chapter:</p>
			<ul>
				<li>What is Docker?</li>
				<li>Dockerizing the Django application</li>
				<li>Using Docker Compose for multiple containers</li>
				<li>Configuring environment variables in Django</li>
				<li>Writing NGINX configuration</li>
			</ul>
			<h1 id="_idParaDest-240"><a id="_idTextAnchor256"/>Technical requirements</h1>
			<p>For this chapter, you will need to have Docker and Docker Compose installed on your machine. The Docker official documentation has a well-documented process for the installation on any OS platform. You can check it out at <a href="https://docs.docker.com/engine/install/">https://docs.docker.com/engine/install/</a>.</p>
			<p>The code written in this chapter can also be found at <a href="https://github.com/PacktPublishing/Full-stack-Django-and-React/tree/chap13">https://github.com/PacktPublishing/Full-stack-Django-and-React/tree/chap13</a>.</p>
			<h1 id="_idParaDest-241"><a id="_idTextAnchor257"/>What is Docker?</h1>
			<p>Before defining what <strong class="bold">Docker</strong> is, we <a id="_idIndexMarker750"/>must understand what<a id="_idTextAnchor258"/> a container is and its importance in today’s tech ecosystem. To make it simple, a container is a standard unit of software that packages up the software and all of its required dependencies so that the software <a id="_idIndexMarker751"/>or the application can run quickly and reliably from one machine to another, whether the environment or the OS. </p>
			<p>An interesting definition from Solomon Hykes at the 2013 <em class="italic">PyCon</em> talk is: containers are “<em class="italic">self-contained units of software you can deliver from a server over there to a server over there, from your laptop to EC2 to a bare-metal giant server, and it will run in the same way because it is isolated at the process level and has its own </em><em class="italic">file system</em>.”</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Containerization is different from virtualization. Virtualization enables teams to run multiple operating systems <a id="_idIndexMarker752"/>on the same hardware, while containerization allows teams <a id="_idIndexMarker753"/>to deploy multiple applications using the same operating system on single hardware with their own images and dependencies.</p>
			<p>Great, right? Remember at the beginning of this book when we had to make configurations and installations depending on the OS mostly for the Python executable, the Postgres server, and different commands to create and activate a virtual environment? Using Docker, we can have a single configuration for a container, and this configuration can run the same on any machine. Docker ensures that your application can be executed in any environment. Then, we can say that Docker is a software platform for building, developing, and developing applications inside containers. It has the following advantages:</p>
			<ul>
				<li><strong class="bold">Minimalistic and portable</strong>: Compared to <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>) that require complete copies <a id="_idIndexMarker754"/>of an OS, the application, and the dependencies, which <a id="_idIndexMarker755"/>can take a lot of space, a Docker container requires less storage because the image used comes with <strong class="bold">megabytes</strong> (<strong class="bold">MB</strong>) in size. This makes them fast to boot and easily portable even on small devices such as Raspberry Pi-embedded computers.</li>
				<li><strong class="bold">Docker containers are scalable</strong>: Because they are lightweight, developers or DevOps can launch a lot of services based on containers and easily control the scaling using tools such as Kubernetes.</li>
				<li><strong class="bold">Docker containers are secure</strong>: Applications inside Docker containers are running isolated <a id="_idIndexMarker756"/>from each other. Thus, a container can’t check the processes running in another container.</li>
			</ul>
			<p>With a better understanding of what Docker is, we can now move on to integrate Docker into the Django application.</p>
			<h1 id="_idParaDest-242"><a id="_idTextAnchor259"/>Dockerizing the Django application</h1>
			<p>In the precedent section, we defined Docker and its advantages. I<a id="_idTextAnchor260"/>n this section, we will configure Docker <a id="_idIndexMarker757"/>with the Django application. This will help you understand better how Docker works under the hood.</p>
			<h2 id="_idParaDest-243"><a id="_idTextAnchor261"/>Adding a Docker image</h2>
			<p>A characteristic of <a id="_idIndexMarker758"/>projects that use Docker is the presence <a id="_idIndexMarker759"/>of files called <strong class="bold">Dockerfiles</strong> in the project. A Dockerfile is a text document that <a id="_idIndexMarker760"/>contains all the commands necessary <a id="_idIndexMarker761"/>to assemble a Docker image. A Docker image is a read-only template with instructions to create a Docker container.</p>
			<p>Creating an image with a Dockerfile is the most popular way to go as you only need to enter the instructions you will require to set up an environment, install the package, make migrations, and a lot more. This is what m<a id="_idTextAnchor262"/>akes Docker very portable. For example, in the case of our Django application, we will write the Dockerfile based on an existing image for Python <code>3.10</code> based on the popular Alpine Linux project (<a href="https://alpinelinux.org/">https://alpinelinux.org/</a>). This image has <a id="_idIndexMarker762"/>been chosen because of its<a id="_idTextAnchor263"/> small size, equal to 5 MB. Inside the Dockerfile, we will also add commands to install Python and Postgres dependencies, and we will further add commands to install packages. Let’s get started with the steps:</p>
			<ol>
				<li>Start by creating a new file at the root of the Django project called <code>Dockerfile</code> and adding the first line:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Dockerfile</p>
			<pre class="source-code">
FROM python:3.10-alpine
# pull official base image</pre>
			<p>Most of your <code>Dockerfile</code> will start with this line. Here, we are telling Docker which image to use to buil<a id="_idTextAnchor264"/>d o<a id="_idTextAnchor265"/>ur image. The <code>python:3.10-alpine</code> image is stored in what is called a Docker registry. This is a storage and distribution syste<a id="_idTextAnchor266"/>m for Docker images, and you can find the most popular one online, called Docker Hub, at <a href="https://hub.docker.com/">https://hub.docker.com/</a>.</p>
			<ol>
				<li value="2">Next, let’s set the working directory. This directory will contain the code of the running Django project:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Dockerfile</p>
			<pre class="source-code">
WORKDIR /app</pre>
			<ol>
				<li value="3">As the Django <a id="_idIndexMarker763"/>application uses Postgres as a <a id="_idIndexMarker764"/>database, add the required dependencies for Postgres and Pillow to our Docker image:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Dockerfile</p>
			<pre class="source-code">
# install psycopg2 dependencies
RUN apk update \
    &amp;&amp; apk add postgresql-dev gcc python3-dev musl-dev
    jpeg-dev zlib-dev</pre>
			<ol>
				<li value="4">Then, install the Python dependencies after making a copy of the <code>requirements.txt</code> file in the <code>/app</code> working directory:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Dockerfile</p>
			<pre class="source-code">
# install python dependencies
COPY requirements.txt /app/requirements.txt
RUN pip install --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt</pre>
			<ol>
				<li value="5">After that, copy over the whole project itself:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Dockerfile</p>
			<pre class="source-code">
# add app
COPY . .</pre>
			<ol>
				<li value="6">And finally, expose <a id="_idIndexMarker765"/>port <code>8000</code> of the container for access to the other <a id="_idIndexMarker766"/>applications or the machine, run the migrations, and start the Django server:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Dockerfile</p>
			<pre class="source-code">
EXPOSE 8000
CMD ["python", "manage.py", "migrate"]
CMD ["python", "manage.py", "runserver",<a id="_idTextAnchor267"/> "0.0.0.0:8000"]</pre>
			<p>The <code>Dockerfile</code> file will have the following final code:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Dockerfile</p>
			<pre class="source-code">
# pull official base image
FROM python:3.10-alpine
# set work directory
WORKDIR /app
# set environment variables
ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1
# install psycopg2 dependencies
RUN apk update \
   &amp;&amp; apk add postgresql-dev gcc python3-dev musl-dev
# install python dependencies
COPY requirements.txt /app/requirements.txt
RUN pip install --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt
# copy project
COPY . .
EXPOSE 8000
CMD ["python", "manage.py", "migrate"]
CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]</pre>
			<p>We have just written the steps to build an image for the Django application. Let’s build the image with the following command.</p>
			<pre class="console">
docker build -t django-postagram .</pre>
			<p>The preceding command <a id="_idIndexMarker767"/>uses the <code>Dockerfile</code> to build a new container image—that’s <a id="_idIndexMarker768"/>why we have a dot (<code>.</code>) at the end of the command. It tells Docker to look for the <code>Dockerfile</code> in the current directory. The <code>-t</code> flag is used to tag the container image. Then, we are building an image with the <code>django-backend</code> tag using the <code>Dockerfile</code> we have written. Once the image is built, we can now run the application in the container by running the following command:</p>
			<pre class="console">
docker run --name django-postagram -d -p 8000:8000 django-postagram:latest</pre>
			<p>Let’s describe the preceding command:</p>
			<ul>
				<li><code>--name</code> will set the name of the Docker container</li>
				<li><code>-d</code> makes the image run in detached mode, meaning that it can run in the background</li>
				<li><code>django-postagram</code> specifies the name of the image to use</li>
			</ul>
			<p>After typing the preceding command, you can check the running container with the following command:</p>
			<pre class="console">
docker container ps</pre>
			<p>You will have a similar output:</p>
			<div><div><img src="img/Figure_13.1_B18821.jpg" alt="Figure 13.1 – Listing Docker containers on the machine"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.1 – Listing Docker containers on the machine</p>
			<p>The container is created, but it looks <a id="_idIndexMarker769"/>like it’s not working well. In your <a id="_idIndexMarker770"/>browser, go to <code>http://localhost:8000</code>, and you will notice that the browser returns a page with an error. Let’s check the logs for the <code>django-postagram</code> container:</p>
			<pre class="source-code">
docker logs --details django-postagram</pre>
			<p>The command will output in the terminal what is happening inside the container. You will have a similar output to this:</p>
			<div><div><img src="img/Figure_13.2_B18821.jpg" alt="Figure 13.2 – Logs for django-postagram container"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.2 – Logs for the django-postagram container</p>
			<p>Well, that’s quite normal. The container is running on its own network and doesn’t have direct access to the host machine network.</p>
			<p>In the previous chapter, we added services for NGINX and Postgres and made the configurations. We need to <a id="_idIndexMarker771"/>also do the same with <code>Dockerfiles</code> for NGINX and Postgres. And let’s be honest: it starts to become a little bit much. Imagine adding a Flask service, a Celery service, or even another database. Depending on the <em class="italic">number n</em> of components of your system, you will need <code>n Dock<a id="_idTextAnchor268"/>erfiles</code>. This is not interesting, but thankfully, Docker provides a simple solution for that called Docker Compose. Let’s explore it more.</p>
			<h1 id="_idParaDest-244"><a id="_idTextAnchor269"/>Using Docker Compose for multiple containers</h1>
			<p>Docker Compose is a tool <a id="_idIndexMarker773"/>developed and created by the Docker team to help <a id="_idIndexMarker774"/>define configurations for multi-container applications. Using Docker Compose, we just need to create a YAML file to define the services and the command to start each service. It also supports configurations such as container name, environment setting, volume, and a lot more, and once the YAML file is written, you just need a command to build the images and spin all the services.</p>
			<p>Let’s understand the key difference between a Dockerfile and Docker Compose: a Dockerfile describes how to build the image and run the container, while Docker Compose is used to run Docker containers. At the end of the day, Docker Compose still uses Docker under the hood, and you will—most of the time—need at least a Dockerfile. Let’s integrate Docker Compose into our workflow.</p>
			<h2 id="_idParaDest-245"><a id="_idTextAnchor270"/>Writing the docker-compose.yaml file</h2>
			<p>Before writing the YAML file, we will have to make some changes to the <code>Dockerfile</code>. As we will be <a id="_idIndexMarker775"/>launching the Django server from the <code>docker-compose</code> file, we can remove the li<a id="_idTextAnchor271"/>nes where we expose the port, run the migrations, and start the server. Inside the <code>Dockerfile</code>, remove the following lines of code:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Dockerfile</p>
			<pre class="source-code">
<strong class="bold">EXPOSE 8000</strong>
<strong class="bold">CMD ["python", "manage.py", "migrate"]</strong>
<strong class="bold">CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]</strong></pre>
			<p>Once it’s done, create a new file called <code>docker-compose.yaml</code> at the root of the project. Make <a id="_idIndexMarker776"/>sure that the <code>docker-compose.yaml</code> file and the <code>Dockerfile</code> are in the same directory. The <code>docker-compose.yaml</code> file will describe the services of the backend application. We will need to write three services:</p>
			<ul>
				<li><strong class="bold">NGINX</strong>: We are using NGINX as the web server. Thankfully, there is an official image available <a id="_idIndexMarker777"/>we can use to write quick configurations.</li>
				<li><strong class="bold">Postgres</strong>: There is also <a id="_idIndexMarker778"/>an official image available for Postgres. We will just need to add environment variables for the database user<a id="_idTextAnchor272"/>.</li>
				<li><code>django-backend</code>: This is the backend application we have created. We will use the <code>Dockerfile</code> so that Docker Compose will build the image for this service.</li>
			</ul>
			<p>Let’s start writing the <code>docker-compose.yaml</code> file by adding the NGINX service first:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">docker-compose.yaml</p>
			<pre class="source-code">
version: '3.8'
services:
 nginx:
   container_name: postagram_web
   restart: always
   image: nginx:latest
   volumes:
     - ./nginx.conf:/etc/nginx/conf.d/default.conf
     - uploads_volume:/app/uploads
   ports:
     - "80:80"
   depends_on:
     - api</pre>
			<p>Let’s see what is going on in the preceding code because the other services will follow a similar con<a id="_idTextAnchor273"/>figuration. The first <a id="_idIndexMarker779"/>line sets the file format we are using, so it is not related to Docker Compose, just to YAML.</p>
			<p>After that, we are adding a service called <code>nginx</code>:</p>
			<ul>
				<li><code>container_name</code> represents, well, the name of the container.</li>
				<li><code>restart</code> defines the container restart policy. In this case, the container is always restarted if it fails.</li>
			</ul>
			<p>Concerning the restart policies for a container, you can also have:</p>
			<ul>
				<li><code>no</code>: Containers will not restart automatically</li>
				<li><code>on-failure[:max-retries]</code>: Restart the container if it exits with a nonzero exit code and provides a maximum number of attempts for the Docker daemon to restart the container</li>
				<li><code>unless-stopped</code>: Always restart the container unless it was stopped arbitrarily or by the Docker daemon</li>
			</ul>
			<ul>
				<li><code>image</code>: This tells Docker Compose to use the latest NGINX image available on Docker Hub.</li>
				<li><code>volumes</code> are a way of persisting data generated and used by Docker containers. If a Docker container is deleted or re<a id="_idTextAnchor274"/>moved, all its content will vanish forever. This is not ideal if you have files such as logs, images, video, or anything you want to persist somewhere because every time you remove a container, this data will vanish. Here is the syntax: <code>/host/path:/container/path</code>.</li>
				<li><code>ports</code>: Connection requests coming from the host port <code>80</code> are redirected to the container port <code>80</code>. Here is the syntax: <code>host_port:container_port</code>.</li>
				<li><code>depends_on</code>: This tells Docker Compose to wait for some services to start before starting the service. In our case, we are waiting for the Django API to start before starting the NGINX server.</li>
			</ul>
			<p>Great! Next, let’s add the <a id="_idIndexMarker780"/>service configuration for the Postgres service:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">docker-compose.yaml</p>
			<pre class="source-code">
db:
 container_name: postagram_db
 image: postgres:14.3-alpine
 env_file: .env
 volumes:
   - postgres_data:/var/lib/postgresql/data/</pre>
			<p>We have new parameters here called <code>env_file</code> which specifies the path to the environment file that will be used to create the database and the user, and set the password. Let’s finally add the Django API service:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">docker-compose.yaml</p>
			<pre class="source-code">
api:
 container_name: postagram_api
 build: .
 restart: always
 env_file: .env
 ports:
   - "8000:8000"
 command: &gt;
   sh -c "python manage.py migrate --no-input &amp;&amp; gunicorn
          CoreRoot.wsgi:application --bind 0.0.0.0:8000"
 volumes:
  - .:/app
  - uploads_volume:/app/uploads
 depends_on:
  - db</pre>
			<p>The build parameter in the Docker Compose file tells Docker Compose where to look for the <code>Dockerfile</code>. In our case, the <code>Dockerfile</code> is in the current directory. Docker Compose allows you to have a <code>command</code> parameter. Here, we are running migrations and starting the Django ser<a id="_idTextAnchor275"/>ver using Gunicorn, which is new. <code>gunicorn</code> is a Python <code>gunicorn</code>? Most web <a id="_idIndexMarker781"/>ap<a id="_idTextAnchor276"/>plications run with an Apache server, so <code>gunicorn</code> is basically designed to run web applications built with Python. </p>
			<p>You <a id="_idIndexMarker782"/>can install the package in your current Python environment by running the following command:</p>
			<pre class="console">
pip install gunicorn</pre>
			<p>But you will need to put the dependency in the <code>requirements.txt</code> file so that it can be preset in the Docker image:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">requirements.txt</p>
			<pre class="source-code">
gunicorn==20.1.0</pre>
			<p>Finally, we need to declare at the end of the file the volumes used:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">docker-compose.yaml</p>
			<pre class="source-code">
volumes:
 uploads_volume:
 postgres_data:</pre>
			<p>And we have just written a <code>docker-compose.yaml</code> file. As we are going to use environment <a id="_idIndexMarker783"/>variables in the project, let’s update some variables in the <code>settings.py</code> file.</p>
			<h1 id="_idParaDest-246"><a id="_idTextAnchor277"/>Configuring environment variables in Django</h1>
			<p>It is a bad habit to <a id="_idIndexMarker784"/>have sensitive information about <a id="_idIndexMarker785"/>your application available in the code. This is the case for the <code>SECRET_KEY</code> setting and the database settings in the <code>settings.py</code> file of the project. It is quite bad because we have pushed the code to GitHub. Let’s correct this.</p>
			<p>An environment variable is a variable whose value is set outside the running code of the program. With Python, you can read files from a <code>.env</code> file. We will use the <code>os</code> library to write the configurations. So, first, create a <code>.env</code> file at the root of the Django project and add the following content:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">.env</p>
			<pre class="source-code">
SECRET_KEY=foo
DATABASE_NAME=coredb
DATABASE_USER=core
DATABASE_PASSWORD=wCh29&amp;HE&amp;T83
DATABASE_HOST=postagram_db
DATABASE_PORT=5432
POSTGRES_USER=core
POSTGRES_PASSWORD=wCh29&amp;HE&amp;T83
POSTGRES_DB=coredb
ENV=DEV
DJANGO_ALLOWED_HOSTS=127.0.0.1,localhost</pre>
			<p class="callout-heading">Important note</p>
			<p class="callout"><code>SECRET_KEY</code> is an important variable for your Django project, so you need to ensure that you have a long and <a id="_idIndexMarker786"/>complicated chain of characters as the value. You can visit <a href="https://djecrety.ir/">https://djecrety.ir/</a> to generate a new chain of characters.</p>
			<p>The next step is to install a package to help you manage environment variables. The package is called <code>python-dotenv</code>, and it helps Python developers read environment variables from <code>.env</code> files <a id="_idIndexMarker787"/>and set them as environment <a id="_idIndexMarker788"/>variables. If you are going to run the project again on your machine, then add the package to your actual Python environment with the following command:</p>
			<pre class="console">
pip install python-dotenv</pre>
			<p>And finally, add the package to the <code>requirements.txt</code> file so that it c<a id="_idTextAnchor278"/>an be installed in the Docker image. Here’s a look at the <code>requirements.txt</code> file:</p>
			<pre class="source-code">
Django==4.0.1
psycopg2-binary==2.9.3
djangorestframework==3.13.1
django-filter==21.1
pillow==9.0.0
djangorestframework-simplejwt==5.0.0
drf-nested-routers==0.93.4
pytest-django==4.5.2
django-cors-headers==3.11.0
python-dotenv==0.20.0
gunicorn==20.1.0</pre>
			<p>Once the installation of the <code>python-dotenv</code> package is done, we need to write some code in the <code>CoreRoot/settings.py</code> file. In this file, we will import the <code>python-dotenv</code> package and modify the syntax of some settings so that it can support environment variables’ reading:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">CoreRoot/settings.py</p>
			<pre class="source-code">
from dotenv import load_dotenv
load_dotenv()</pre>
			<p>Let’s rewrite the values of variables such as <code>SECRET_KEY</code>, <code>DEBUG</code>, <code>ALLOWED_HOSTS</code>, and <code>ENV</code>:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">CoreRoot/settings.py</p>
			<pre class="source-code">
<strong class="bold">ENV = os.environ.get("ENV")</strong>
# SECURITY WARNING: keep the secret key used in production secret!
<strong class="bold">SECRET_KEY = os.environ.get(</strong>
<strong class="bold">   "SECRET_KEY", default=</strong>
<strong class="bold">     "qkl+xdr8aimpf-&amp;x(mi7)dwt^-q77aji#j*d#02-5usa32r9!y"</strong>
<strong class="bold">)</strong>
# SECURITY WARNING: don't run with debug turned on in production!
<strong class="bold">DEBUG = False if ENV == "PROD" else True</strong>
<strong class="bold">ALLOWED_HOSTS = os.environ.get("DJANGO_ALLOWED_HOSTS", default="*").split(",")</strong></pre>
			<p>The <code>os</code> package provides an <a id="_idIndexMarker789"/>object to retrieve environment <a id="_idIndexMarker790"/>variables from the user machine. After <code>python-dotenv</code> has forced the loading of the environment variables, we use <code>os.environ</code> to read the values from the <code>.env</code> file. Let’s finally add the configuration for the <code>DATABASES</code> setting:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">CoreRoot/settings.py</p>
			<pre class="source-code">
DATABASES = {
   "default": {
       "ENGINE": "django.db.backends.postgresql_psycopg2",
       "NAME": os.getenv("DATABASE_NAME", "coredb"),
       "USER": os.getenv("DATABASE_USER", "core"),
       "PASSWORD": os.getenv("DATABASE_PASSWORD",
                             "wCh29&amp;HE&amp;T83"),
       "HOST": os.environ.get("DATABASE_HOST",
                              "localhost"),
       "PORT": os.getenv("DATABASE_PORT", "5432"),
   }
}</pre>
			<p>Great! We are done <a id="_idIndexMarker791"/>configuring the environment variables <a id="_idIndexMarker792"/>in the <code>settings.py</code> file. We can now move on to write the configurations for N<a id="_idTextAnchor279"/>GINX.</p>
			<h1 id="_idParaDest-247"><a id="_idTextAnchor280"/>Writing NGINX configuration</h1>
			<p>NGINX requires some configuration from our side. If there is a request on the HTTP port of the machine (by default <code>80</code>), it <a id="_idTextAnchor281"/>should redirect the requests to port <code>8000</code> of the running Django <a id="_idIndexMarker793"/>application. Put simply, we will write a reverse proxy. A proxy is an intermediary process that takes an HTTP request from a client, passes the request to one or many other servers, waits for a response from those servers, and sends back a response to the client.</p>
			<p>By using this process, we can forward <a id="_idTextAnchor282"/>a request on the HTTP port <code>80</code> to port <code>8000</code> of the Django server.</p>
			<p>At the root of the project, create a new file called <code>nginx.conf</code>. Then, let’s define the upstream server where HTTP requests will be redirected to:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">nginx.conf</p>
			<pre class="source-code">
upstream webapp {
   server postagram_api:8000;
}</pre>
			<p>The preceding code follows the simple syntax shown next:</p>
			<pre class="source-code">
upstream upstream_name {
   server host:PORT;
}</pre>
			<p class="callout-heading">Important note</p>
			<p class="callout">Docker allows you to refer to the container’s host with the <code>defined</code> container name. In the NGINX file, we are using <code>postagram_api</code> instead of the IP address of the container, which can change, and for the database, we are using <code>postagram_db</code>.</p>
			<p>The next step is to <a id="_idIndexMarker794"/>declare the configuration for the HTTP server:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">nginx.conf</p>
			<pre class="source-code">
server {
   listen 80;
   server_name localhost;
   location / {
       proxy_pass http://webapp;
       proxy_set_header X-Forwarded-For
         $proxy_add_x_forwarded_for;
       proxy_set_header Host $host;
       proxy_redirect off;
   }
   location /media/ {
    alias /app/uploads/;
   }
}</pre>
			<p>In the server configuration, we first set the port of the server. In the preceding code, we are using port <code>80</code>. Next, we <a id="_idIndexMarker795"/>are defining locations. A location in NGINX is a block that tells NGINX how to process the request from a certain URL:</p>
			<ul>
				<li>A request on the <code>/</code> URL is redirected to the web app upstream</li>
				<li>A request on the <code>/media/</code> URL is redirected to the <code>uploads</code> folder to serve files</li>
			</ul>
			<p>With the NGINX configuration ready, we can now launch the containers.</p>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor283"/>Launching the Docker containers</h2>
			<p>Let’s launch the <a id="_idIndexMarker796"/>Docker containers. As we are now using Docker Compose to orchestrate containers, let’s use the following command to build and start the containers:</p>
			<pre class="console">
docker compose up -d –build</pre>
			<p>This command will spin up all the containers defined in the <code>docker-compose.yaml</code> file. Let’s describe the command options:</p>
			<ul>
				<li><code>up</code>: This builds, recreates, and starts containers</li>
				<li><code>-d</code>: This is used to detach, meaning that we are running the containers in the background</li>
				<li><code>—build</code>: This flag tells Docker Compose to build the images before starting the containers</li>
			</ul>
			<p>After the build is done, open your browser at <code>http://localhost</code>, and you should see the following:</p>
			<div><div><img src="img/Figure_13.3_B18821.jpg" alt="Figure 13.3 – Dockerized Django application"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.3 – Dockerized Django application</p>
			<p>We have successfully containerized the Django application using Docker. It is also possible to execute commands inside containers, and right now, we can start by running a test suite inside the <code>postagram_api</code> container:</p>
			<pre class="console">
docker compose exec -T api pytest</pre>
			<p>The syntax to execute a command in a Docker container is to first call the <code>exec</code> command followed <a id="_idIndexMarker797"/>by the <code>–T</code> parameter to disable <code>pseudo-tty</code> allocation. This means that the command being run inside the container will not be attached to a terminal. Finally, you can add the container service name, followed by the command you want to execute in the container.</p>
			<p>We are one step closer to the deployment of AWS using <strong class="bold">Docker</strong>, but we need to automate it. In the next chapter, we will configure the project with GitHub Actions to automate deployment on the AWS server.</p>
			<h1 id="_idParaDest-249"><a id="_idTextAnchor284"/>Summary</h1>
			<p>In this chapter, we have learned how to dockerize a Django application. We started by looking into Docker and its use in the development of modern applications. We also learned how to build a Docker image and run a container using this image—this introduced us to some limitations of Dockerization using Dockerfiles. This led us to learn more about Docker Compose and how it can help us manage multiple containers with just one configuration file. This in turn directed us to configure a database and an NGINX web server with Docker to launch the Postagram API.</p>
			<p>In the next chapter, we will configure the project for automatic deployment on AWS but also carry out regression checks using the tests we have written.</p>
			<h1 id="_idParaDest-250"><a id="_idTextAnchor285"/>Questions</h1>
			<ol>
				<li value="1">What is Docker?</li>
				<li>What is Docker Compose?</li>
				<li>What is the difference between Docker and Docker Compose?</li>
				<li>What is the difference between containerization and virtualization?</li>
				<li>What is an environment variable?</li>
			</ol>
		</div>
		<div><div></div>
		</div>
	</body></html>