<html><head></head><body>
<section id="chapter-14-the-multiprocessing-threading-and-concurrent.futures-modules" class="level2 chapterHead" data-number="0.18">&#13;
<h2 class="chapterHead" data-number="0.18"><span class="titlemark"> 14</span><br/>&#13;
<span id="x1-28300014"/>The Multiprocessing, Threading, and Concurrent.Futures Modules</h2>&#13;
<p>When we eliminate the complexities of shared state and design around pure functions with non-strict processing, we can leverage concurrency and parallelism to improve performance. In this chapter, we’ll look at some of the multiprocessing and multithreading techniques that are available to us. Python library packages become particularly helpful when applied to algorithms designed from a functional viewpoint.</p>&#13;
<p>The central idea here is to distribute a functional program across several threads within a process or across several processes in a CPU. If we’ve created a sensible functional design, we can avoid complex interactions among application components; we have functions that accept argument values and produce results. This is an ideal structure for a process or a thread.</p>&#13;
<p>In this chapter, we’ll focus on several topics:</p>&#13;
<ul>&#13;
<li><p>The general idea of functional programming and concurrency.</p></li>&#13;
<li><p>What concurrency really means when we consider cores, CPUs, and OS-level concurrency and parallelism. It’s important to note that concurrency won’t magically make a bad algorithm faster.</p></li>&#13;
<li><p>Using the built-in <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures</code></span></span> modules. These modules allow a number of parallel execution techniques. The external <span class="obeylines-h"><span class="verb"><code class="inlineCode">dask</code></span></span> package can do much of this as well.</p></li>&#13;
</ul>&#13;
<p>We’ll focus on process-level parallelism more than multithreading. Using process parallelism allows us to completely ignore<span id="dx1-283001"/> Python’s <span class="keyWord">Global Interpreter Lock</span> (<span class="keyWord">GIL</span>).</p>&#13;
<div id="tcolobox-286" class="infobox note">&#13;
&#13;
&#13;
<p>For more information on Python’s GIL, see <a href="https://docs.python.org/3/glossary.html#term-global-interpreter-lock">https://docs.python.org/3/glossary.html#term-global-interpreter-lock</a>. Also see <a href="https://peps.python.org/pep-0684/">https://peps.python.org/pep-0684/</a> for a proposal to alter the way the GIL operates. Additionally, see <a href="https://github.com/colesbury/nogil">https://github.com/colesbury/nogil</a> for a project that proposes a way to remove the GIL entirely.</p>&#13;
&#13;
</div>&#13;
&#13;
<p>The GIL is very much part of Python 3.10, meaning some kinds of compute-intensive multithreading won’t show significant speedups.</p>&#13;
<p>We’ll focus on concurrency throughout the chapter. Concurrent work is interleaved, distinct from parallel work, which requires multiple cores or multiple processors. We don’t want to dig too deeply into the nuanced distinctions between concurrency and parallelism. Our focus is on leveraging a functional approach, more than exploring all of the ways work can be accomplished in a modern CPU with a multi-processing OS. <span id="x1-283002r287"/></p>&#13;
<section id="functional-programming-and-concurrency" class="level3 sectionHead" data-number="0.18.1">&#13;
<h3 class="sectionHead" data-number="0.18.1"><span class="titlemark">14.1 </span> <span id="x1-2840001"/>Functional programming and concurrency</h3>&#13;
<p>The most effective concurrent processing occurs when there are no dependencies among the tasks being performed. The biggest difficulty in developing concurrent (or parallel) programming is the complications arising from coordinating updates to shared resources, where tasks depend on a common resource.</p>&#13;
<p>When following functional design patterns, we tend to avoid stateful programs. A functional design should minimize or eliminate concurrent updates to shared objects. If we can design software where lazy, non-strict evaluation is central, we can also design software where concurrent evaluation is helpful. In some cases, parts of an application can have an <span class="keyWord">embarrassingly parallel</span><span id="dx1-284001"/> design, where most of the work can be done concurrently with few or no interactions among computations. Mappings and filterings, in particular, benefit from parallel processing; reductions typically can’t be done in parallel.</p>&#13;
<p>The frameworks we’ll focus on all make use of an essential <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> function to allocate work to multiple workers in a pool. This fits nicely with the higher-order functional design we’ve been looking at throughout this book. If we’ve built our application with a particular focus on the <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> function, then partitioning the work into processes or threads should not involve a breaking change. <span id="x1-284002r294"/></p>&#13;
</section>&#13;
<section id="what-concurrency-really-means" class="level3 sectionHead" data-number="0.18.2">&#13;
<h3 class="sectionHead" data-number="0.18.2"><span class="titlemark">14.2 </span> <span id="x1-2850002"/>What concurrency really means</h3>&#13;
<p>In a small computer, with a single processor<span id="dx1-285001"/> and a single core, all evaluations are serialized through the one and only core of the processor. The OS will interleave multiple processes and multiple threads through clever time-slicing arrangements to make it appear as if things are happening concurrently.</p>&#13;
<p>On a computer with multiple CPUs or multiple cores in a single CPU, there can be some actual parallel processing of CPU instructions. All other concurrency is simulated through time slicing at the OS level. A macOS X laptop can have 200 concurrent processes that share the CPU; this is many more processes than the number of available cores. From this, we can see that OS time slicing is responsible for most of the apparently concurrent behavior of the system as a whole. <span id="x1-285002r291"/></p>&#13;
<section id="the-boundary-conditions" class="level4 subsectionHead" data-number="0.18.2.1">&#13;
<h4 class="subsectionHead" data-number="0.18.2.1"><span class="titlemark">14.2.1 </span> <span id="x1-2860001"/>The boundary conditions</h4>&#13;
<p>Let’s consider a hypothetical<span id="dx1-286001"/> algorithm that has a complexity described by <span class="keyWord">O</span>(<span class="italic">n</span><sup><span class="cmr-8">2</span></sup>). This generally means two nested <span class="obeylines-h"><span class="verb"><code class="inlineCode">for</code></span></span> statements, each of which is processing <span class="cmti-10x-x-109">n </span>items. Let’s assume the inner <span class="obeylines-h"><span class="verb"><code class="inlineCode">for</code></span></span> statement’s body involves 1,000 Python operation codes. When processing 10,000 objects, this could execute 100 billion Python operations. We can call this the essential processing<span id="dx1-286002"/> budget. We can try to allocate as many processes and threads as we feel might be helpful, but the processing budget can’t change.</p>&#13;
<p>The individual CPython bytecodes—the internal implementation of Python statements and expressions—don’t all share a single, uniform execution time. However, a long-term average on a macOS X laptop shows that we can expect about 60 MB of bytecode operations to be executed per second. This means that our 100 billion bytecode operation could take about 1,666 seconds, or 28 minutes.</p>&#13;
<p>If we have a dual-processor, four-core computer, then we might cut the elapsed time to 25% of the original total: about 7 minutes. This presumes that we can partition the work into four (or more) independent OS processes.</p>&#13;
<p>The important consideration here is that the overall budget of 100 billion bytecodes can’t be changed. Concurrency won’t magically reduce the workload. It can only change the schedule to perhaps reduce the elapsed time to execute all those bytecodes.</p>&#13;
<p>Switching to a better algorithm with a complexity of <span class="keyWord">O</span>(<span class="italic">n</span>log <span class="italic">n</span>) can reduce the workload dramatically. We need to measure the actual speedup to determine the impact; the following example includes a number of assumptions. Instead of doing 10<span class="italic">,</span>000<sup><span class="cmr-8">2</span></sup> iterations, we may only do 10<span class="italic">,</span>000log 10<span class="italic">,</span>000 <span class="cmsy-10x-x-109">≈ </span>132<span class="italic">,</span>877 iterations, dropping from 100 billion operations to a number on the order of 133 thousand operations. This could be as small as <img src="../Images/file128.jpg" class="frac" data-align="middle" alt="7100-"/> of the original time. Concurrency can’t provide the kind of dramatic improvements that algorithm change will have. <span id="x1-286003r296"/></p>&#13;
</section>&#13;
<section id="sharing-resources-with-process-or-threads" class="level4 subsectionHead" data-number="0.18.2.2">&#13;
<h4 class="subsectionHead" data-number="0.18.2.2"><span class="titlemark">14.2.2 </span> <span id="x1-2870002"/>Sharing resources with process or threads</h4>&#13;
<p>The OS assures us there is little or no interaction<span id="dx1-287001"/> between processes. When creating an application where multiple processes must interact, a common OS resource must be explicitly shared. This can be a common file, a shared-memory object, or a semaphore with a shared state between the processes. Processes are inherently independent; interaction among them is the exception, not the rule.</p>&#13;
<p>Multiple threads, in contrast, are part of a single process; all threads of a process generally share resources, with one special case. Thread-local memory can be freely used without interference from other threads. Outside thread-local memory, operations that write to memory can set the internal<span id="dx1-287002"/> state of the process in a potentially unpredictable order. One thread can overwrite the results of another thread. A technique for mutually exclusive access—often a form of locking—<span class="cmti-10x-x-109">must </span>be used to avoid problems. As noted previously, the overall sequence of instruction from concurrent threads and processes are generally interleaved among the cores in an unpredictable order. With this concurrency comes the possibility of destructive updates to shared variables and the need for mutually exclusive access.</p>&#13;
<p>The existence of concurrent object updates can create havoc when trying to design multithreaded applications. Locking is one way to avoid concurrent writes to shared objects. Avoiding shared objects in general is another viable design technique. The second technique—avoiding writes to shared objects—is often also applicable to functional programming.</p>&#13;
<p>In CPython, the GIL is used to ensure that OS thread scheduling will not interfere with the internals of maintaining Python data structures. In effect, the GIL changes the granularity of scheduling from machine instructions to groups of Python virtual machine operations.</p>&#13;
<p>Pragmatically, the performance impact of the GIL on a wide variety of application types is often negligible. For the most part, compute-intensive applications tend to see the largest impact from GIL scheduling. I/O-intensive applications see little impact because the threads spend more time waiting for I/O to complete. A far greater impact on performance comes from the fundamental inherent complexity of the algorithm being implemented. <span id="x1-287003r297"/></p>&#13;
</section>&#13;
<section id="where-benefits-will-accrue" class="level4 subsectionHead" data-number="0.18.2.3">&#13;
<h4 class="subsectionHead" data-number="0.18.2.3"><span class="titlemark">14.2.3 </span> <span id="x1-2880003"/>Where benefits will accrue</h4>&#13;
<p>A program that does a great deal of calculation and relatively little I/O will not see much benefit from concurrent<span id="dx1-288001"/> processing on a single core. If a calculation has a budget of 28 minutes of computation, then interleaving the operations in different ways won’t have a dramatic impact. Using eight cores for parallel computation may cut the time by approximately one-eighth. The actual time savings depend on the OS and language overheads, which are difficult to predict.</p>&#13;
<p>When a calculation involves a great deal of I/O, then interleaving CPU processing while waiting for I/O requests to complete can <span class="cmti-10x-x-109">dramatically </span>improve performance. The idea is to do computations on some pieces of data while waiting for the OS to complete the I/O of other pieces of data. Because I/O generally involves a great deal of waiting, an eight-core processor can interleave the work from dozens (or hundreds) of concurrent I/O requests.</p>&#13;
<p>Concurrency is a core principle<span id="dx1-288002"/> behind Linux. If we couldn’t do computation while waiting for I/O, then our computer would freeze while waiting for each network request to finish. A website download would involve waiting for the initial HTML and then waiting for each individual graphic to arrive. All the while, the keyboard, mouse, and display would not work.</p>&#13;
<p>Here are two approaches to designing applications that interleave computation and I/O:</p>&#13;
<ul>&#13;
<li><p>We can create a pipeline of processing stages. An individual item must move through all of the stages where it is read, filtered, computed, aggregated, and written. The idea of multiple concurrent stages means there will be distinct data objects in each stage. Time slicing among the stages will allow computation and I/O to be interleaved.</p></li>&#13;
<li><p>We can create a pool of concurrent workers, each of which performs all of the processing for a data item. The data items are assigned to workers in the pool and the results are collected from the workers.</p></li>&#13;
</ul>&#13;
<p>The differences between these approaches aren’t crisp. It’s common to create a hybrid mixture where one stage of a pipeline involves a pool of workers to make that stage as fast as the other stages. There are some formalisms that make it somewhat easier to design concurrent programs. The <span class="keyWord">Communicating</span> <span class="keyWord">Sequential Processes </span>(<span class="keyWord">CSP</span>) paradigm<span id="dx1-288003"/> can help design message-passing applications. Packages such as <span class="obeylines-h"><span class="verb"><code class="inlineCode">pycsp</code></span></span> can be used to add CSP formalisms to Python.</p>&#13;
<div id="tcolobox-287" class="packt_tip">&#13;
&#13;
&#13;
<p>I/O-intensive programs often gain the most dramatic benefits from concurrent processing. The idea is to interleave I/O and processing. CPU-intensive programs will see smaller benefits from concurrent processing.</p>&#13;
&#13;
</div>&#13;
<p><span id="x1-288004r295"/></p>&#13;
</section>&#13;
</section>&#13;
<section id="using-multiprocessing-pools-and-tasks" class="level3 sectionHead" data-number="0.18.3">&#13;
<h3 class="sectionHead" data-number="0.18.3"><span class="titlemark">14.3 </span> <span id="x1-2890003"/>Using multiprocessing pools and tasks</h3>&#13;
<p>Python’s <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> package<span id="dx1-289001"/> introduces the concept of a <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object. A <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object contains<span id="dx1-289002"/> a number of worker processes and expects these processes to be executed concurrently. This package allows OS scheduling and time slicing to interleave execution of multiple processes. The intention is to keep the overall system as busy as possible.</p>&#13;
<p>To make the most of this capability, we need to decompose our application into components for which non-strict, concurrent execution is beneficial. The overall application must be built from discrete tasks that can be processed in an indefinite order.</p>&#13;
<p>An application that gathers data from the internet through web scraping, for example, is often optimized through concurrent processing. A number of individual processes can be waiting for the data to download, while others are performing the scraping operation on data that’s been received. We can create a <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object of several identical workers, which implement the website scraping. Each worker is assigned tasks in the form of URLs to be analyzed. Multiple workers waiting for downloads have little processing overhead. The workers with completely downloaded pages, on the other hand, can perform the real work of extracting data from the content.</p>&#13;
<p>An application that analyzes multiple log files is also a good candidate for concurrent processing. We can create a <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object of analytical workers. We can assign each log file to a worker; this allows reading and analysis to proceed concurrently among the various workers in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object. Each individual worker will be performing both I/O and computation. However, some workers can be analyzing while other workers are waiting for I/O to complete.</p>&#13;
<p>Because the benefits depend on difficult-to-predict timing for input and output operations, multiprocessing always involves experimentation. Changing the pool size and measuring elapsed time is an essential part of implementing concurrent applications. <span id="x1-289003r298"/></p>&#13;
<section id="processing-many-large-files" class="level4 subsectionHead" data-number="0.18.3.1">&#13;
<h4 class="subsectionHead" data-number="0.18.3.1"><span class="titlemark">14.3.1 </span> <span id="x1-2900001"/>Processing many large files</h4>&#13;
<p>Here is an example<span id="dx1-290001"/> of a multiprocessing<span id="dx1-290002"/> application. We’ll parse <span class="keyWord">Common Log</span> <span class="keyWord">Format </span>(<span class="keyWord">CLF</span>) lines in web log files. This is the generally used format for web server access logs. The lines tend to be long, but look like the following when wrapped to the book’s margins:</p>&#13;
<pre id="listing-280" class="lstlisting"><code>99.49.32.197 - - [01/Jun/2012:22:17:54 -0400] "GET /favicon.ico\\ &#13;
HTTP/1.1" 200 894 "-" "Mozilla/5.0 (Windows NT 6.0)\\ &#13;
AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.52\\ &#13;
Safari/536.5"</code></pre>&#13;
<p>We often have large numbers of files that we’d like to analyze. The presence of many independent files means that concurrency will have some benefit for our scraping process. Some workers will be waiting for data, while others can be doing the compute-intensive portion of the work.</p>&#13;
<p>We’ll decompose the analysis into two broad areas of functionality. The first phase of processing is the essential parsing of the log files to gather the relevant pieces of information. We’ll further decompose the parsing phase into four stages. They are as follows:</p>&#13;
<ol>&#13;
<li><div id="x1-290008x1">&#13;
<p>All the lines from multiple source log files are read.</p>&#13;
</div></li>&#13;
<li><div id="x1-290010x2">&#13;
<p>Then, we create simple <span class="obeylines-h"><span class="verb"><code class="inlineCode">NamedTuple</code></span></span> objects from the lines of log entries in a collection of files.</p>&#13;
</div></li>&#13;
<li><div id="x1-290012x3">&#13;
<p>The details of more complex fields such as dates and URLs are parsed separately.</p>&#13;
</div></li>&#13;
<li><div id="x1-290014x4">&#13;
<p>Uninteresting paths from the logs are rejected, leaving the interesting paths for further processing.</p>&#13;
</div></li>&#13;
</ol>&#13;
<p>Once past the parsing phase, we can perform a large number of analyses. For our purposes in demonstrating the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> module, we’ll look at a simple analysis to count occurrences of specific paths.</p>&#13;
<p>The first portion is reading from the source files. Python’s use of file iterators will translate into lower-level OS requests for the buffering of data. Each OS request means that the process must wait for the data to become available.</p>&#13;
<p>Clearly, we want to interleave the other operations so that they are not all waiting for I/O to complete. The operations<span id="dx1-290015"/> can be imagined to form a spectrum, from processing individual rows to processing whole files. We’ll look at interleaving whole files first, as this is relatively simple to implement.</p>&#13;
<p>The functional design for parsing Apache CLF files can look as follows:</p>&#13;
<pre id="listing-281" class="lstlisting"><code>data = path_filter( &#13;
    access_detail_iter( &#13;
        access_iter( &#13;
            local_gzip(filename))))</code></pre>&#13;
<p>This function decomposes the larger parsing problem into a number of functions. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> function reads rows from locally cached GZIP files. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_iter()</code></span></span> function creates a <span class="obeylines-h"><span class="verb"><code class="inlineCode">NamedTuple</code></span></span> object for each row in the access log. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_detail_iter()</code></span></span> function expands on some of the more difficult-to-parse fields. Finally, the <span class="obeylines-h"><span class="verb"><code class="inlineCode">path_filter()</code></span></span> function discards some paths and file extensions that aren’t of much analytical value.</p>&#13;
<p>It can help to visualize this kind of design as a shell-like pipeline of processing, as shown here:</p>&#13;
<pre id="listing-282" class="lstlisting"><code>(local_gzip(filename) | access_iter &#13;
    | access_detail_iter | path_filter) &gt;data</code></pre>&#13;
<p>This uses borrows the shell notation of a pipe (<span class="obeylines-h"><span class="verb"/></span>—) to pass data from process to process. Python doesn’t have this operator, directly.</p>&#13;
<p>Pragmatically, we can use the <span class="obeylines-h"><span class="verb"><code class="inlineCode">toolz</code></span></span> module to define this pipeline:</p>&#13;
<pre id="listing-283" class="lstlisting"><code>from toolz.functoolz import pipe &#13;
 &#13;
data = pipe(filename, &#13;
    local_gzip, &#13;
    access_iter, &#13;
    access_detail_iter, &#13;
    path_filter &#13;
)</code></pre>&#13;
<p>For more on the <span class="obeylines-h"><span class="verb"><code class="inlineCode">toolz</code></span></span> module, see <a href="Chapter_11.xhtml#x1-23500011"><span class="cmti-10x-x-109">Chapter</span><span class="cmti-10x-x-109"> 11</span></a>, <a href="Chapter_11.xhtml#x1-23500011"><span class="cmti-10x-x-109">The Toolz Package</span></a>.</p>&#13;
<p>We’ll focus on designing these four functions<span id="dx1-290030"/> that process data in stages. The idea is to interleave intensive processing with waiting for I/O to finish. <span id="x1-290031r300"/></p>&#13;
</section>&#13;
<section id="parsing-log-files-gathering-the-rows" class="level4 subsectionHead" data-number="0.18.3.2">&#13;
<h4 class="subsectionHead" data-number="0.18.3.2"><span class="titlemark">14.3.2 </span> <span id="x1-2910002"/>Parsing log files – gathering the rows</h4>&#13;
<p>Here is the first stage in parsing<span id="dx1-291001"/> a large number of files: reading each file and producing a simple sequence<span id="dx1-291002"/> of lines. As the log files are saved in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">.gzip</code></span></span> format, we need to open each file with the <span class="obeylines-h"><span class="verb"><code class="inlineCode">gzip.open()</code></span></span> function.</p>&#13;
<p>The following <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> function reads lines from locally cached files:</p>&#13;
<pre id="listing-284" class="lstlisting"><code>from collections.abc import Iterator &#13;
import gzip &#13;
from pathlib import Path &#13;
 &#13;
import sys &#13;
def local_gzip(zip_path: Path) -&gt; Iterator[str]: &#13;
    with gzip.open(zip_path, "rb") as log_file: &#13;
        yield from ( &#13;
            line.decode(’us-ascii’).rstrip() &#13;
            for line in log_file &#13;
        )</code></pre>&#13;
<p>The function iterates through all lines of a file. We’ve created a composite function that encapsulates the details of opening a log file compressed with the <span class="obeylines-h"><span class="verb"><code class="inlineCode">.gzip</code></span></span> format, breaking a file into a sequence of lines, and stripping the newline (<span class="obeylines-h"><span class="verb"><code class="inlineCode">\n</code></span></span>) characters.</p>&#13;
<p>Additionally, this function also encapsulates a non-standard encoding for the files. Instead of Unicode, encoded in a standard format like UTF-8 or UTF-16, the files are encoded in old US-ASCII. This is very similar to UTF-8. In order to be sure the log entries are read properly, the exact encoding is supplied.</p>&#13;
<p>This function<span id="dx1-291014"/> is a close fit with the way the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> module works. We can create a worker pool and map tasks (such as <span class="obeylines-h"><span class="verb"><code class="inlineCode">.gzip</code></span></span> file reading) to the pool of processes. If we do this, we can read these files in parallel; the open file objects will be part of separate processes, and the resource consumption<span id="dx1-291015"/> and wait time will be managed by the OS.</p>&#13;
<p>An extension to this design can include a second function to transfer files from the web host using SFTP or a RESTful API if one is available. As the files are collected from the web server, they can be analyzed using the <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> function.</p>&#13;
<p>The results of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> function are used by the <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_iter()</code></span></span> function to create named tuples for each row in the source file that describes file access by the web server. <span id="x1-291016r301"/></p>&#13;
</section>&#13;
<section id="parsing-log-lines-into-named-tuples" class="level4 subsectionHead" data-number="0.18.3.3">&#13;
<h4 class="subsectionHead" data-number="0.18.3.3"><span class="titlemark">14.3.3 </span> <span id="x1-2920003"/>Parsing log lines into named tuples</h4>&#13;
<p>Once we have access<span id="dx1-292001"/> to all of the lines of each log file, we can extract details of the access that’s described. We’ll use a regular expression to decompose the line. From there, we can build a <span class="obeylines-h"><span class="verb"><code class="inlineCode">NamedTuple</code></span></span> object.</p>&#13;
<p>Each individual access can be summarized as a subclass of <span class="obeylines-h"><span class="verb"><code class="inlineCode">NamedTuple</code></span></span>, as follows:</p>&#13;
<pre id="listing-285" class="lstlisting"><code>from typing import NamedTuple, Optional, cast &#13;
import re &#13;
 &#13;
class Access(NamedTuple): &#13;
    host: str &#13;
    identity: str &#13;
    user: str &#13;
    time: str &#13;
    request: str &#13;
    status: str &#13;
    bytes: str &#13;
    referer: str &#13;
    user_agent: str &#13;
 &#13;
    @classmethod &#13;
    def create(cls: type, line: str) -&gt; Optional["Access"]: &#13;
        format_pat = re.compile( &#13;
            r"(?P&lt;host&gt;[\d\.]+)\s+" &#13;
            r"(?P&lt;identity&gt;\S+)\s+" &#13;
            r"(?P&lt;user&gt;\S+)\s+" &#13;
            r"\[(?P&lt;time&gt;.+?)\]\s+" &#13;
            r’"(?P&lt;request&gt;.+?)"\s+’ &#13;
            r"(?P&lt;status&gt;\d+)\s+" &#13;
            r"(?P&lt;bytes&gt;\S+)\s+" &#13;
            r’"(?P&lt;referer&gt;.*?)"\s+’ &#13;
            r’"(?P&lt;user_agent&gt;.+?)"\s*’ &#13;
            ) &#13;
        if match := format_pat.match(line): &#13;
            return cast(Access, cls(**match.groupdict())) &#13;
        return None</code></pre>&#13;
<p>The method for building<span id="dx1-292032"/> an <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> object, <span class="obeylines-h"><span class="verb"><code class="inlineCode">create()</code></span></span>, from the source text contains a lengthy regular expression to parse lines in a CLF file. This is quite complex, but we can use a <span class="keyWord">railroad diagram</span><span id="dx1-292033"/> to help simplify it. The following image shows the various elements and how they’re identified by the regular expression:</p>&#13;
<div class="minipage">&#13;
<p><img src="../Images/file129.jpg" alt="hd.hsinisunus[tat]srarssdssbnbsrarsuausoiopdodpsospimnimpeneptaitapyoypenepsnspsgsaeneaeneaeyeaquyquatgtatntafeyfeaeyeatitcn-ncr-rcceecuiuce-ecrrcrrctetistieseessestsessseeeeaaetptpttprrggyayaaeecccnneeett"/> <span id="x1-292034r1"/> <span id="x1-292035"/></p>&#13;
<span class="id">Figure 14.1: </span><span class="content">Regular expression diagram for parsing log files </span>&#13;
</div>&#13;
<p>This diagram shows the sequence<span id="dx1-292036"/> of clauses in the regular expression. Each rectangular box represents a named capture group. For example, <span class="obeylines-h"><span class="verb"><code class="inlineCode">(?P&lt;host&gt;[\d\.]+)</code></span></span> is a group named <span class="obeylines-h"><span class="verb"><code class="inlineCode">host</code></span></span>. The ovals and circles are classes of characters (e.g., digit) or specific characters (e.g., <span class="obeylines-h"><span class="verb"><code class="inlineCode">.</code></span></span>) that comprise the contents of the capture group.</p>&#13;
<p>We used this regular expression to break each row into a dictionary of nine individual data elements. The use of <span class="obeylines-h"><span class="verb"><code class="inlineCode">[]</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">"</code></span></span> to delimit complex fields such as the <span class="obeylines-h"><span class="verb"><code class="inlineCode">time</code></span></span>, <span class="obeylines-h"><span class="verb"><code class="inlineCode">request</code></span></span>, <span class="obeylines-h"><span class="verb"><code class="inlineCode">referer</code></span></span>, and <span class="obeylines-h"><span class="verb"><code class="inlineCode">user_agent</code></span></span> parameters can be handled elegantly by transforming the text into a <span class="obeylines-h"><span class="verb"><code class="inlineCode">NamedTuple</code></span></span> object.</p>&#13;
<div id="tcolobox-288" class="packt_tip">&#13;
&#13;
&#13;
<p>We’ve taken pains to ensure that the <span class="obeylines-h"><span class="verb"><code class="inlineCode">NamedTuple</code></span></span> field names match the regular expression group names in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">(?P&lt;name&gt;)</code></span></span> constructs for each portion of the record. By making sure the names match, we can very easily transform the parsed dictionary into a tuple for further processing. This means we’ve spelled <span class="cmti-10x-x-109">referrer</span> wrong to fit with the RFC documentation.</p>&#13;
&#13;
</div>&#13;
<p>Here is the <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_iter()</code></span></span> function, which requires each file to be represented as an iterator over the lines of the file:</p>&#13;
<pre id="listing-286" class="lstlisting"><code>from collections.abc import Iterator &#13;
 &#13;
def access_iter(source_iter: Iterator[str]) -&gt; Iterator[Access]: &#13;
    for line in source_iter: &#13;
        if access := Access.create(line): &#13;
            yield access</code></pre>&#13;
<p>The output from the <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> function is a sequence<span id="dx1-292043"/> of strings. The outer sequence is based on the lines from individual log files. If the line matches the given pattern, it’s a file access of some kind. We can create an <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> instance from the dictionary of text parsed by the regular expression. Non-matching lines are quietly discarded.</p>&#13;
<p>The essential design pattern here is to build an immutable object from the results of a parsing function. In this case, the parsing function is a regular expression matcher. Other kinds of parsing can also fit this design pattern.</p>&#13;
<p>There are some alternative ways to do this. For example, here’s a function that applies <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">filter()</code></span></span>:</p>&#13;
<pre id="listing-287" class="lstlisting"><code>def access_iter_2(source_iter: Iterator[str]) -&gt; Iterator[Access]: &#13;
    return filter( &#13;
        None, &#13;
        map( &#13;
            Access.create, &#13;
            source_iter &#13;
        ) &#13;
    )</code></pre>&#13;
<p>This <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_iter_2()</code></span></span> function transforms the output from the <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> function into a sequence of <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> instances. In this case, we apply the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access.create()</code></span></span> function to the string iterator that results from reading<span id="dx1-292052"/> a collection of files. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">filter()</code></span></span> function removes any <span class="obeylines-h"><span class="verb"><code class="inlineCode">None</code></span></span> objects from the result of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> function.</p>&#13;
<p>Our point here is to show that we have a number of functional styles for parsing files. In <a href="Chapter_04.xhtml#x1-740004"><span class="cmti-10x-x-109">Chapter</span><span class="cmti-10x-x-109"> 4</span></a>, <a href="Chapter_04.xhtml#x1-740004"><span class="cmti-10x-x-109">Working with Collections</span></a>, we looked at very simple parsing. Here, we’re performing more complex parsing, using a variety of techniques. <span id="x1-292053r302"/></p>&#13;
</section>&#13;
<section id="parsing-additional-fields-of-an-access-object" class="level4 subsectionHead" data-number="0.18.3.4">&#13;
<h4 class="subsectionHead" data-number="0.18.3.4"><span class="titlemark">14.3.4 </span> <span id="x1-2930004"/>Parsing additional fields of an Access object</h4>&#13;
<p>The initial <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> object created previously<span id="dx1-293001"/> doesn’t decompose some inner elements in the nine fields that comprise an access log line. We’ll parse those items separately from the overall decomposition into high-level fields. Doing these parsing operations separately makes each stage of processing simpler. It also allows us to replace one small part of the overall process without breaking the general approach to analyzing logs.</p>&#13;
<p>The resulting object from the next stage of parsing will be a <span class="obeylines-h"><span class="verb"><code class="inlineCode">NamedTuple</code></span></span> subclass, <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span>, which wraps the original <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> tuple. It will have some additional fields for the details parsed separately:</p>&#13;
<pre id="listing-288" class="lstlisting"><code>from typing import NamedTuple, Optional &#13;
import datetime &#13;
import urllib.parse &#13;
 &#13;
class AccessDetails(NamedTuple): &#13;
    access: Access &#13;
    time: datetime.datetime &#13;
    method: str &#13;
    url: urllib.parse.ParseResult &#13;
    protocol: str &#13;
    referrer: urllib.parse.ParseResult &#13;
    agent: dict[str, str] &#13;
 &#13;
    @classmethod &#13;
    def create(cls: type, access: Access) -&gt; "AccessDetails": &#13;
          meth, url, protocol = parse_request(access.request) &#13;
          return AccessDetails( &#13;
              access=access, &#13;
              time=parse_time(access.time), &#13;
              method=meth, &#13;
              url=urllib.parse.urlparse(url), &#13;
              protocol=protocol, &#13;
              referrer=urllib.parse.urlparse(access.referer), &#13;
              agent=parse_agent(access.user_agent) &#13;
          )</code></pre>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">access</code></span></span> attribute is the original<span id="dx1-293027"/> <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> object, a collection of simple strings. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">time</code></span></span> attribute is the parsed <span class="obeylines-h"><span class="verb"><code class="inlineCode">access.time</code></span></span> string. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">method</code></span></span>, <span class="obeylines-h"><span class="verb"><code class="inlineCode">url</code></span></span>, and <span class="obeylines-h"><span class="verb"><code class="inlineCode">protocol</code></span></span> attributes come from decomposing the <span class="obeylines-h"><span class="verb"><code class="inlineCode">access.request</code></span></span> field. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">referrer</code></span></span> attribute is a parsed URL.</p>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">agent</code></span></span> attribute can also be broken down into fine-grained fields. The rules are quite complex, and we’ve decided that a dictionary mapping names to their associated values will be good enough.</p>&#13;
<p>Here are the three detail-level parsers for the fields to be decomposed:</p>&#13;
<pre id="listing-289" class="lstlisting"><code>from typing import Optional &#13;
import datetime &#13;
import re &#13;
 &#13;
def parse_request(request: str) -&gt; tuple[str, str, str]: &#13;
    words = request.split() &#13;
    return words[0], ’ ’.join(words[1:-1]), words[-1] &#13;
 &#13;
def parse_time(ts: str) -&gt; datetime.datetime: &#13;
    return datetime.datetime.strptime( &#13;
        ts, "%d/%b/%Y:%H:%M:%S %z" &#13;
    ) &#13;
 &#13;
def parse_agent(user_agent: str) -&gt; dict[str, str]: &#13;
    agent_pat = re.compile( &#13;
        r"(?P&lt;product&gt;\S*?)\s+" &#13;
        r"\((?P&lt;system&gt;.*?)\)\s*" &#13;
        r"(?P&lt;platform_details_extensions&gt;.*)" &#13;
    ) &#13;
 &#13;
    if agent_match := agent_pat.match(user_agent): &#13;
        return agent_match.groupdict() &#13;
    return {}</code></pre>&#13;
<p>We’ve written three parsers<span id="dx1-293051"/> for the HTTP request, the time stamp, and the user agent information. The request value in a log is usually a three-word string such as <span class="obeylines-h"><span class="verb"><code class="inlineCode">GET</code><code class="inlineCode"> /some</code></span></span> <span class="obeylines-h"><span class="verb"><code class="inlineCode">/path</code><code class="inlineCode"> HTTP/1.1</code></span></span>. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">parse_request()</code></span></span> function extracts these three space-separated values. In the unlikely event that the path has spaces in it, we’ll extract the first word and the last word as the method and protocol; all the remaining words are part of the path.</p>&#13;
<p>Time parsing is delegated to the <span class="obeylines-h"><span class="verb"><code class="inlineCode">datetime</code></span></span> module. We’ve provided the proper format in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">parse_time()</code></span></span> function.</p>&#13;
<p>Parsing the user agent is challenging. There are many variations; we’ve chosen a common one for the <span class="obeylines-h"><span class="verb"><code class="inlineCode">parse_agent()</code></span></span> function. If the user agent text matches the given regular expression, we’ll use the attributes of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">AgentDetails</code></span></span> class. If the user agent information doesn’t match the regular expression, we’ll use the <span class="obeylines-h"><span class="verb"><code class="inlineCode">None</code></span></span> value instead. The original text will be available in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> object in either case.</p>&#13;
<p>We’ll use these three parsers to build <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> instances from the given <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> objects. The main body of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_detail_iter()</code></span></span> function looks like this:</p>&#13;
<pre id="listing-290" class="lstlisting"><code>from collections.abc import Iterable, Iterator &#13;
 &#13;
def access_detail_iter( &#13;
    access_iter: Iterable[Access] &#13;
) -&gt; Iterator[AccessDetails]: &#13;
    for access in access_iter: &#13;
        yield AccessDetails.create(access)</code></pre>&#13;
<p>We’ve used a similar design pattern to the previous <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_iter()</code></span></span> function. A new object is built from the results of parsing<span id="dx1-293059"/> some input object. The new <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> object will wrap the previous <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> object. This technique allows us to use immutable objects, yet still contains more refined information.</p>&#13;
<p>This function is essentially a mapping from an <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> object to a sequence of <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> objects. Here’s an alternative design using the <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> high-level function:</p>&#13;
<pre id="listing-291" class="lstlisting"><code>from collections.abc import Iterable, Iterator &#13;
 &#13;
def access_detail_iter_2( &#13;
    access_iter: Iterable[Access] &#13;
) -&gt; Iterator[AccessDetails]: &#13;
    return map(AccessDetails.create, access_iter)</code></pre>&#13;
<p>As we move forward, we’ll see that this variation fits in nicely with the way the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> module works.</p>&#13;
<p>In an object-oriented programming<span id="dx1-293066"/> environment, these additional parsers might be method functions or properties of a class definition. The advantage of an object-oriented design with lazy parsing methods is that items aren’t parsed unless they’re needed. This particular functional design parses everything, assuming that it’s going to be used.</p>&#13;
<p>It’s possible to create a lazy functional design. It can rely on the three parser functions to extract and parse the various elements from a given <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> object as needed. Rather than using the <span class="obeylines-h"><span class="verb"><code class="inlineCode">details.time</code></span></span> attribute, we’d use the <span class="obeylines-h"><span class="verb"><code class="inlineCode">parse_time(access.time)</code></span></span> function. The syntax is longer, but it ensures that the attribute is only parsed as needed. We could also make it a property that preserves the original syntax. We’ve left this as an exercise for the reader. <span id="x1-293067r304"/></p>&#13;
</section>&#13;
<section id="filtering-the-access-details" class="level4 subsectionHead" data-number="0.18.3.5">&#13;
<h4 class="subsectionHead" data-number="0.18.3.5"><span class="titlemark">14.3.5 </span> <span id="x1-2940005"/>Filtering the access details</h4>&#13;
<p>We’ll look at several<span id="dx1-294001"/> filters for the <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> objects. The first is a collection of filters that reject a lot of overhead files that are rarely interesting. The second filter will be part of the analysis functions, which we’ll look at later.</p>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">path_filter()</code></span></span> function is a combination of three functions:</p>&#13;
<ul>&#13;
<li><p>Exclude empty paths</p></li>&#13;
<li><p>Exclude some specific filenames</p></li>&#13;
<li><p>Exclude files that have a given extension</p></li>&#13;
</ul>&#13;
<p>A flexible design can define each test as a separate first-class, filter-style function. For example, we might have a function such as the following to handle empty paths:</p>&#13;
<pre id="listing-292" class="lstlisting"><code>def non_empty_path(detail: AccessDetails) -&gt; bool: &#13;
    path = detail.url.path.split(’/’) &#13;
    return any(path)</code></pre>&#13;
<p>This function ensures that the path contains a name. We can write similar tests for the <span class="obeylines-h"><span class="verb"><code class="inlineCode">non_excluded_names()</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">non_excluded_ext()</code></span></span> functions. Names like <span class="obeylines-h"><span class="verb"><code class="inlineCode">favicon.ico</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">robots.txt</code></span></span> need to be excluded. Similarly, extensions like <span class="obeylines-h"><span class="verb"><code class="inlineCode">.js</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">.css</code></span></span> need to be excluded as well. We’ve left these two additional filters as exercises for the reader.</p>&#13;
<p>The entire sequence of <span class="obeylines-h"><span class="verb"><code class="inlineCode">filter()</code></span></span> functions will look like this:</p>&#13;
<pre id="listing-293" class="lstlisting"><code>def path_filter( &#13;
    access_details_iter: Iterable[AccessDetails] &#13;
) -&gt; Iterable[AccessDetails]: &#13;
    non_empty = filter(non_empty_path, access_details_iter) &#13;
    nx_name = filter(non_excluded_names, non_empty) &#13;
    nx_ext = filter(non_excluded_ext, nx_name) &#13;
    yield from nx_ext</code></pre>&#13;
<p>This style of stacked filters has the advantage of being slightly easier to expand when we add new filter criteria.</p>&#13;
<div id="tcolobox-289" class="packt_tip">&#13;
&#13;
&#13;
<p>The use of generator functions (such as the <span class="obeylines-h"><span class="verb"><code class="inlineCode">filter()</code></span></span> function) means that we aren’t creating large intermediate objects. Each of the intermediate variables, <span class="obeylines-h"><span class="verb"><code class="inlineCode">non_empty</code></span></span>, <span class="obeylines-h"><span class="verb"><code class="inlineCode">nx_name</code></span></span>, and <span class="obeylines-h"><span class="verb"><code class="inlineCode">nx_ext</code></span></span>, is a proper lazy generator function; no processing is done until the data is consumed by a client process.</p>&#13;
&#13;
</div>&#13;
<p>While elegant, this suffers from inefficiency<span id="dx1-294012"/> because each function will need to parse the path in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> object. In order to make this more efficient, we could wrap a <span class="obeylines-h"><span class="verb"><code class="inlineCode">path.split(’/’)</code></span></span> function with the <span class="obeylines-h"><span class="verb"><code class="inlineCode">@cache</code></span></span> decorator. An alternative is to split the path on the <span class="obeylines-h"><span class="verb"><code class="inlineCode">/</code></span></span> characters, and save the list in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> object. <span id="x1-294013r305"/></p>&#13;
</section>&#13;
<section id="analyzing-the-access-details" class="level4 subsectionHead" data-number="0.18.3.6">&#13;
<h4 class="subsectionHead" data-number="0.18.3.6"><span class="titlemark">14.3.6 </span> <span id="x1-2950006"/>Analyzing the access details</h4>&#13;
<p>We’ll look at two analysis<span id="dx1-295001"/> functions that we can use to filter and analyze the individual <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> objects. The first function will filter the data and pass only specific paths. The second function will summarize the occurrences of each distinct path.</p>&#13;
<p>We’ll define a small <span class="obeylines-h"><span class="verb"><code class="inlineCode">book_in_path()</code></span></span> function and combine this with the built-in <span class="obeylines-h"><span class="verb"><code class="inlineCode">filter()</code></span></span> function to apply the function to the details. Here is the composite <span class="obeylines-h"><span class="verb"><code class="inlineCode">book_filter()</code></span></span> function:</p>&#13;
<pre id="listing-294" class="lstlisting"><code>from collections.abc import Iterable, Iterator &#13;
 &#13;
def book_filter( &#13;
    access_details_iter: Iterable[AccessDetails] &#13;
) -&gt; Iterator[AccessDetails]: &#13;
    def book_in_path(detail: AccessDetails) -&gt; bool: &#13;
        path = tuple( &#13;
            item &#13;
            for item in detail.url.path.split(’/’) &#13;
            if item &#13;
        ) &#13;
        return path[0] == ’book’ and len(path) &gt; 1 &#13;
    return filter(book_in_path, access_details_iter)</code></pre>&#13;
<p>We’ve defined a rule, through the <span class="obeylines-h"><span class="verb"><code class="inlineCode">book_in_path()</code></span></span> function, which we’ll apply to each <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> object. If the path has at least two components and the first component of the path is <span class="obeylines-h"><span class="verb"><code class="inlineCode">’book’</code></span></span>, then we’re interested<span id="dx1-295015"/> in these objects. All other <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> objects can be quietly rejected.</p>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">reduce_book_total()</code></span></span> function is the final reduction that we’re interested in:</p>&#13;
<pre id="listing-295" class="lstlisting"><code>from collections import Counter &#13;
 &#13;
def reduce_book_total( &#13;
    access_details_iter: Iterable[AccessDetails] &#13;
) -&gt; dict[str, int]: &#13;
    counts: Counter[str] = Counter( &#13;
        detail.url.path for detail in access_details_iter &#13;
    ) &#13;
    return counts</code></pre>&#13;
<p>This function will produce a <span class="obeylines-h"><span class="verb"><code class="inlineCode">Counter()</code></span></span> object that shows the frequency of each path in an <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> object. In order to focus on a particular set of paths, we’ll use the <span class="obeylines-h"><span class="verb"><code class="inlineCode">reduce_total(book_filter(details))</code></span></span> expression. This provides a summary of only items that are passed by the given filter.</p>&#13;
<p>Because <span class="obeylines-h"><span class="verb"><code class="inlineCode">Counter</code></span></span> objects can be applied to a wide variety of types, a type hint is required to provide a narrow specification. In this case, the hint is <span class="obeylines-h"><span class="verb"><code class="inlineCode">dict[str,</code><code class="inlineCode"> int]</code></span></span> to show the <span class="keyWord">mypy </span>tool that string representations of paths will be counted. <span id="x1-295025r306"/></p>&#13;
</section>&#13;
<section id="the-complete-analysis-process" class="level4 subsectionHead" data-number="0.18.3.7">&#13;
<h4 class="subsectionHead" data-number="0.18.3.7"><span class="titlemark">14.3.7 </span> <span id="x1-2960007"/>The complete analysis process</h4>&#13;
<p>Here is the composite <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function that digests<span id="dx1-296001"/> a collection of log files:</p>&#13;
<pre id="listing-296" class="lstlisting"><code>def analysis(log_path: Path) -&gt; dict[str, int]: &#13;
    """Count book chapters in a given log""" &#13;
    details = access_detail_iter( &#13;
        access_iter( &#13;
            local_gzip(log_path))) &#13;
    books = book_filter(path_filter(details)) &#13;
    totals = reduce_book_total(books) &#13;
    return totals</code></pre>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function uses the <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> function to work with a single path. It applies a stack of parsing functions, <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_detail_iter()</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_iter()</code></span></span>, to create an iterable sequence of <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> objects. It then applies a stack of filters to exclude paths that aren’t interesting. Finally, it applies a reduction<span id="dx1-296010"/> to a sequence of <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> objects. The result is a <span class="obeylines-h"><span class="verb"><code class="inlineCode">Counter</code></span></span> object that shows the frequency of access for certain paths.</p>&#13;
<p>A sample collection of saved <span class="obeylines-h"><span class="verb"><code class="inlineCode">.gzip</code></span></span> format log files totals about 51 MB. Processing the files serially with this function takes over 140 seconds. Can we do better using concurrent processing? <span id="x1-296011r299"/></p>&#13;
</section>&#13;
</section>&#13;
<section id="using-a-multiprocessing-pool-for-concurrent-processing" class="level3 sectionHead" data-number="0.18.4">&#13;
<h3 class="sectionHead" data-number="0.18.4"><span class="titlemark">14.4 </span> <span id="x1-2970004"/>Using a multiprocessing pool for concurrent processing</h3>&#13;
<p>One elegant way to make<span id="dx1-297001"/> use of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> module is to create a processing <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object and assign work to the various workers in that pool. We will depend on the OS to interleave execution among the various processes. If each of the processes has a mixture of I/O and computation, we should be able to ensure that our processor (and disk) are kept very busy. When processes are waiting for the I/O to complete, other processes can do their computations. When an I/O operation finishes, the process waiting for this will be ready to run and can compete with others for processing time.</p>&#13;
<p>The recipe for mapping work to a separate process looks like this:</p>&#13;
<pre id="listing-297" class="lstlisting"><code>def demo_mp(root: Path = SAMPLE_DATA, pool_size: int | None = None) -&gt; None: &#13;
    pool_size = ( &#13;
        multiprocessing.cpu_count() if pool_size is None &#13;
        else pool_size &#13;
    ) &#13;
    combined: Counter[str] = Counter() &#13;
    with multiprocessing.Pool(pool_size) as workers: &#13;
        file_iter = list(root.glob(LOG_PATTERN)) &#13;
        results_iter = workers.imap_unordered(analysis, file_iter) &#13;
        for result in results_iter: &#13;
            combined.update(result) &#13;
    print(combined)</code></pre>&#13;
<p>This function<span id="dx1-297014"/> creates a <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object with separate worker processes and assigns this <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object to the <span class="obeylines-h"><span class="verb"><code class="inlineCode">workers</code></span></span> variable. We then map the analytical function, <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis</code></span></span>, to an iterable queue of work to be done using the pool of processes. Each process in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">workers</code></span></span> pool gets assigned items from the iterable queue. In this case, the queue is the result of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">root.glob(LOG_PATTERN)</code></span></span> attribute, which is a sequence of file names.</p>&#13;
<p>As each worker completes the <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function and returns a result, the parent process that created the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object can collect those results. This allows us to create several concurrently built <span class="obeylines-h"><span class="verb"><code class="inlineCode">Counter</code></span></span> objects and to merge them into a single, composite result.</p>&#13;
<p>If we start <span class="italic">p </span>processes in the pool, our overall application will include <span class="italic">p </span>+ 1 processes. There will be one parent process and <span class="italic">p </span>children. This often works out well because the parent process will have little to do after the subprocess pools are started. Generally, the workers will be assigned to separate CPUs (or cores) and the parent will share a CPU with one of the children in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object.</p>&#13;
<div id="tcolobox-290" class="packt_tip">&#13;
&#13;
&#13;
<p>The ordinary Linux parent/child process rules apply to the subprocesses created by this module. If the parent crashes without properly collecting the final status from the child processes, then zombie processes can be left running. For this reason, a process <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object is also a context manager. When we use a pool through the <span class="obeylines-h"><span class="verb"><code class="inlineCode">with</code></span></span> statement, at the end of the context, the children are properly collected.</p>&#13;
&#13;
</div>&#13;
<p>By default, a <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object will have a number of workers based on the value of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing.cpu_count()</code></span></span> function. This number is often optimal, and simply using the <span class="obeylines-h"><span class="verb"><code class="inlineCode">with</code><code class="inlineCode"> multiprocessing.Pool()</code><code class="inlineCode"> as</code><code class="inlineCode"> workers</code></span></span>: attribute might be sufficient.</p>&#13;
<p>In some cases, it can help to have more workers than CPUs. This might be true when each worker has I/O-intensive processing. Having many worker processes waiting for I/O to complete can improve the overall runtime of an application.</p>&#13;
<p>If a given <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object has <span class="cmti-10x-x-109">p </span>workers, this mapping<span id="dx1-297015"/> can cut the processing time to almost <img src="../Images/file130.jpg" class="frac" data-align="middle" alt="1 p"/> of the time required to process all of the logs serially. Pragmatically, there is some overhead involved with communication between the parent and child processes in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object. These overheads will limit the effectiveness of subdividing the work into very small concurrent pieces.</p>&#13;
<p>The multiprocessing <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object has several map-like methods to allocate work to a pool. We’ll look at <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span>, <span class="obeylines-h"><span class="verb"><code class="inlineCode">imap()</code></span></span>, <span class="obeylines-h"><span class="verb"><code class="inlineCode">imap_unordered()</code></span></span>, and <span class="obeylines-h"><span class="verb"><code class="inlineCode">starmap()</code></span></span>. Each of these is a variation on the common theme of assigning a function to a pool of processes and mapping data items to that function. Additionally, there are two async variants: <span class="obeylines-h"><span class="verb"><code class="inlineCode">map_async()</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">starmap_async()</code></span></span>. These functions differ in the details of allocating work and collecting results:</p>&#13;
<ul>&#13;
<li><p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">map(function,</code><code class="inlineCode"> iterable)</code></span></span> method allocates<span id="dx1-297016"/> items from the iterable to each worker in the pool. The finished results are collected in the order they were allocated to the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object so that order is preserved.</p></li>&#13;
<li><p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">imap(function,</code><code class="inlineCode"> iterable)</code></span></span> method<span id="dx1-297017"/> is lazier than <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span>. By default, it sends each individual item from the iterable to the next available worker. This might involve more communication overhead. For this reason, a chunk size larger than 1 is suggested.</p></li>&#13;
<li><p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">imap_unordered(function,</code><code class="inlineCode"> iterable)</code></span></span> method<span id="dx1-297018"/> is similar to the <span class="obeylines-h"><span class="verb"><code class="inlineCode">imap()</code></span></span> method, but the order of the results is not preserved. Allowing the mapping to be processed out of order means that, as each process finishes, the results are collected.</p></li>&#13;
<li><p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">starmap(function,</code><code class="inlineCode"> iterable)</code></span></span> method<span id="dx1-297019"/> is similar to the <span class="obeylines-h"><span class="verb"><code class="inlineCode">itertools.starmap()</code></span></span> function. Each item in the iterable must be a tuple; the tuple is passed to the function using the * modifier so that each value of the tuple becomes a positional argument value. In effect, it’s performing <span class="obeylines-h"><span class="verb"><code class="inlineCode">function(*iterable[0])</code></span></span>, <span class="obeylines-h"><span class="verb"><code class="inlineCode">function(*iterable[1])</code></span></span>, and so on.</p></li>&#13;
</ul>&#13;
<p>The two <span class="obeylines-h"><span class="verb"><code class="inlineCode">_async</code></span></span> variants don’t simply return a result; they return an <span class="obeylines-h"><span class="verb"><code class="inlineCode">AsyncResult</code></span></span> object. This object has some status information. We can, for example, see if the work has been completed in general, or if it has been completed without an exception. The most important method of an <span class="obeylines-h"><span class="verb"><code class="inlineCode">AsyncResult</code></span></span> object is the <span class="obeylines-h"><span class="verb"><code class="inlineCode">.get()</code></span></span> method, which interrogates the worker for the result.</p>&#13;
<p>This extra complexity<span id="dx1-297020"/> works well when the duration of processing is highly variable. We can collect results from workers as the results become available. The behavior for the non-<span class="obeylines-h"><span class="verb"><code class="inlineCode">_async</code></span></span> variants is to collect results in the order the work was started, preserving the order of the original source data for the map-like operation.</p>&#13;
<p>Here is the <span class="obeylines-h"><span class="verb"><code class="inlineCode">map_async()</code></span></span> variant of the preceding mapping theme:</p>&#13;
<pre id="listing-298" class="lstlisting"><code>def demo_mp_async(root: Path = SAMPLE_DATA, pool_size: int | None = None) -&gt; None: &#13;
    pool_size = ( &#13;
        multiprocessing.cpu_count() if pool_size is None &#13;
        else pool_size &#13;
    ) &#13;
    combined: Counter[str] = Counter() &#13;
    with multiprocessing.Pool(pool_size) as workers: &#13;
        file_iter = root.glob(LOG_PATTERN) &#13;
        results = workers.map_async(analysis, file_iter) &#13;
        for result in results.get(): &#13;
            combined.update(result) &#13;
    print(combined)</code></pre>&#13;
<p>We’ve created a <span class="obeylines-h"><span class="verb"><code class="inlineCode">Counter()</code></span></span> function that we’ll use to consolidate the results from each worker in the pool. We created a pool of subprocesses based on the number of available CPUs, and used the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object as a context manager. We then mapped our <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function to each file in our file-matching pattern. The resulting <span class="obeylines-h"><span class="verb"><code class="inlineCode">Counter</code></span></span> objects from the <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function are combined into a single resulting counter.</p>&#13;
<p>This version took about 68 seconds to analyze a batch of log files. The time to analyze the logs was cut dramatically using several concurrent<span id="dx1-297033"/> processes. The single-process baseline time was 150 seconds. Other experiments need to be run with larger pool sizes to determine how many workers are required to make the system as busy as possible.</p>&#13;
<p>We’ve created a two-tiered map-reduce process with the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> module’s <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool.map_async()</code></span></span> function. The first tier was the <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function, which performed a map-reduce on a single log file. We then consolidated these reductions in a higher-level reduce operation. <span id="x1-297034r307"/></p>&#13;
<section id="using-apply-to-make-a-single-request" class="level4 subsectionHead" data-number="0.18.4.1">&#13;
<h4 class="subsectionHead" data-number="0.18.4.1"><span class="titlemark">14.4.1 </span> <span id="x1-2980001"/>Using apply() to make a single request</h4>&#13;
<p>In addition to the map-like variants, a pool<span id="dx1-298001"/> also has an <span class="obeylines-h"><span class="verb"><code class="inlineCode">apply(function,</code><code class="inlineCode"> *args,</code><code class="inlineCode"> **kw)</code></span></span> method that we can use to pass one value to the worker pool. We can see that the various <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> methods are really a <span class="obeylines-h"><span class="verb"><code class="inlineCode">for</code></span></span> statement wrapped around the <span class="obeylines-h"><span class="verb"><code class="inlineCode">apply()</code></span></span> method. We can, for example, use the following command to process a number of files:</p>&#13;
<pre id="listing-299" class="lstlisting"><code>list( &#13;
    workers.apply(analysis, f) &#13;
    for f in SAMPLE_DATA.glob(LOG_PATTERN) &#13;
)</code></pre>&#13;
<p>It’s not clear, for our purposes, that this is a significant improvement. Almost everything we need to do can be expressed as a <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> function. <span id="x1-298006r309"/></p>&#13;
</section>&#13;
<section id="more-complex-multiprocessing-architectures" class="level4 subsectionHead" data-number="0.18.4.2">&#13;
<h4 class="subsectionHead" data-number="0.18.4.2"><span class="titlemark">14.4.2 </span> <span id="x1-2990002"/>More complex multiprocessing architectures</h4>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> package supports<span id="dx1-299001"/> a wide variety of architectures. We can create multiprocessing structures that span multiple servers and provide formal authentication techniques to create a necessary level of security. We can pass objects from process to process using queues and pipes. We can share memory between processes. We can also share lower-level locks between processes as a way to synchronize access to shared resources such as files.</p>&#13;
<p>Most of these architectures involve explicitly managing states among several working processes. Using locks and shared memory, in particular, is imperative in nature and doesn’t fit in well with a functional programming approach.</p>&#13;
<p>We can, with some care, treat queues and pipes in a functional manner. Our objective is to decompose a design into producer and consumer functions. A <span class="keyWord">producer</span><span id="dx1-299002"/> can create objects and insert them into a queue. A <span class="keyWord">consumer</span><span id="dx1-299003"/> will take objects out of a queue and process them, perhaps putting intermediate results into another queue. This creates a network of concurrent processors and the workload is distributed among these various processes.</p>&#13;
<p>This design technique has some advantages when designing a complex application server. The various subprocesses can exist for the entire life of the server, handling individual requests concurrently. <span id="x1-299004r310"/></p>&#13;
</section>&#13;
<section id="using-the-concurrent.futures-module" class="level4 subsectionHead" data-number="0.18.4.3">&#13;
<h4 class="subsectionHead" data-number="0.18.4.3"><span class="titlemark">14.4.3 </span> <span id="x1-3000003"/>Using the concurrent.futures module</h4>&#13;
<p>In addition to the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> package, we can also make use of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures</code></span></span> module. This also provides<span id="dx1-300001"/> a way to map data to a concurrent pool of threads or processes. The module API is relatively simple and similar in many ways to the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing.Pool()</code></span></span> function’s interface.</p>&#13;
<p>Here is an example to show how similar they are:</p>&#13;
<pre id="listing-300" class="lstlisting"><code>def demo_cf_threads(root: Path = SAMPLE_DATA, pool_size: int = 4) -&gt; None: &#13;
    pattern = "*itmaybeahack.com*.gz" &#13;
    combined: Counter[str] = Counter() &#13;
    with futures.ProcessPoolExecutor(max_workers=pool_size) &#13;
            as workers: &#13;
        file_iter = root.glob(LOG_PATTERN) &#13;
        for result in workers.map(analysis, file_iter): &#13;
            combined.update(result) &#13;
    print(combined)</code></pre>&#13;
<p>The most significant<span id="dx1-300011"/> change between the preceding example and the previous examples is that we’re using an instance of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures.ProcessPoolExecutor</code></span></span> object instead of a <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing.Pool</code></span></span> object. The essential design pattern is to map the <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function to the list of filenames using the pool of available workers. The resulting <span class="obeylines-h"><span class="verb"><code class="inlineCode">Counter</code></span></span> objects are consolidated to create a final result.</p>&#13;
<p>The performance of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures</code></span></span> module is nearly identical to the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> module. <span id="x1-300012r311"/></p>&#13;
</section>&#13;
<section id="using-concurrent.futures-thread-pools" class="level4 subsectionHead" data-number="0.18.4.4">&#13;
<h4 class="subsectionHead" data-number="0.18.4.4"><span class="titlemark">14.4.4 </span> <span id="x1-3010004"/>Using concurrent.futures thread pools</h4>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures</code></span></span> module offers<span id="dx1-301001"/> a second kind of executor that we can use in our applications. Instead of creating a <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures.ProcessPoolExecutor</code></span></span> object, we can use the <span class="obeylines-h"><span class="verb"><code class="inlineCode">ThreadPoolExecutor</code></span></span> object. This will create a pool of threads within a single process.</p>&#13;
<p>The syntax for thread pools is almost identical to using a <span class="obeylines-h"><span class="verb"><code class="inlineCode">ProcessPoolExecutor</code></span></span> object. The performance, however, can be remarkably different. CPU-intensive processing doesn’t often show improvement in a multi-threaded environment because there’s no computation while waiting for I/O to complete. Processing that is I/O-intensive can benefit from multi-threading.</p>&#13;
<p>Using sample log files and a small four-core laptop running macOS X, these are the kinds of results that indicate the difference between threads that share I/O resources and processes:</p>&#13;
<ul>&#13;
<li><p>Using the <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures</code></span></span> thread pool, the elapsed time was 168 seconds</p></li>&#13;
<li><p>Using a process pool, the elapsed time was 68 seconds</p></li>&#13;
</ul>&#13;
<p>In both cases, the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> object’s size was <span class="obeylines-h"><span class="verb"><code class="inlineCode">4</code></span></span>. The single-process and single-thread baseline time was 150 seconds; adding threads made processing run more slowly. This result is typical of programs doing a great deal of computation<span id="dx1-301002"/> with relatively little waiting for input and output. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">multithreading</code></span></span> module is often more appropriate for the following kinds of applications:</p>&#13;
<ul>&#13;
<li><p>User interfaces where threads are idle for long periods of time, while waiting for the person to move the mouse or touch the screen</p></li>&#13;
<li><p>Web servers where threads are idle while waiting for data to transfer from a large, fast server through a network to a (relatively) slow client</p></li>&#13;
<li><p>Web clients that extract data from multiple web servers, especially where these clients must wait for data to percolate through a network</p></li>&#13;
</ul>&#13;
<p>It’s important to benchmark and measure performance. <span id="x1-301003r312"/></p>&#13;
</section>&#13;
<section id="using-the-threading-and-queue-modules" class="level4 subsectionHead" data-number="0.18.4.5">&#13;
<h4 class="subsectionHead" data-number="0.18.4.5"><span class="titlemark">14.4.5 </span> <span id="x1-3020005"/>Using the threading and queue modules</h4>&#13;
<p>The Python <span class="obeylines-h"><span class="verb"><code class="inlineCode">threading</code></span></span> package<span id="dx1-302001"/> involves a number of constructs helpful for building imperative applications. This module is not focused on writing functional applications. We can make use of thread-safe queues in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">queue</code></span></span> module to pass objects from thread to thread.</p>&#13;
<p>A queue<span id="dx1-302002"/> permits safe data sharing. Since the queue processing<span id="dx1-302003"/> involves using OS services, it can also mean applications using queues may observe less interference from the GIL.</p>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">threading</code></span></span> module<span id="dx1-302004"/> doesn’t have a simple way of distributing work to various threads. The API isn’t ideally suited to functional programming.</p>&#13;
<p>As with the more primitive features of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> module, we can try to conceal the stateful and imperative nature of locks and queues. It seems easier, however, to make use of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">ThreadPoolExecutor</code></span></span> method in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures</code></span></span> module. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">ThreadPoolExecutor.map()</code></span></span> method provides us with a very pleasant interface to concurrently process the elements of a collection.</p>&#13;
<p>The use of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> function primitive to allocate work seems to fit nicely with our functional programming expectations. For this reason, it’s best to focus on the <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures</code></span></span> module as the most accessible way to write concurrent functional programs. <span id="x1-302005r313"/></p>&#13;
</section>&#13;
<section id="using-async-functions" class="level4 subsectionHead" data-number="0.18.4.6">&#13;
<h4 class="subsectionHead" data-number="0.18.4.6"><span class="titlemark">14.4.6 </span> <span id="x1-3030006"/>Using async functions</h4>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">asyncio</code></span></span> module<span id="dx1-303001"/> helps us work with <span class="obeylines-h"><span class="verb"><code class="inlineCode">async</code></span></span> functions to—perhaps—better interleave processing and computation. It’s important<span id="dx1-303002"/> to understand that <span class="obeylines-h"><span class="verb"><code class="inlineCode">async</code></span></span> processing leverages the <span class="obeylines-h"><span class="verb"><code class="inlineCode">threading</code></span></span> model. This means that it can effectively interleave waiting for I/O with computation. It does not effectively interleave pure computation.</p>&#13;
<p>In order to make use of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">asyncio</code></span></span> module, we need to do the following four things:</p>&#13;
<ol>&#13;
<li><div id="x1-303004x1">&#13;
<p>Add the <span class="obeylines-h"><span class="verb"><code class="inlineCode">async</code></span></span> keyword to our various parsing and filtering functions to make them <span class="keyWord">coroutines</span>.</p>&#13;
</div></li>&#13;
<li><div id="x1-303006x2">&#13;
<p>Add <span class="obeylines-h"><span class="verb"><code class="inlineCode">await</code></span></span> keywords to collect results from one coroutine before passing them to another coroutine.</p>&#13;
</div></li>&#13;
<li><div id="x1-303008x3">&#13;
<p>Create an overall event loop to coordinate the <span class="obeylines-h"><span class="verb"><code class="inlineCode">async</code></span></span>/<span class="obeylines-h"><span class="verb"><code class="inlineCode">await</code></span></span> processing among the coroutines.</p>&#13;
</div></li>&#13;
<li><div id="x1-303010x4">&#13;
<p>Create a thread pool to handle file reading.</p>&#13;
</div></li>&#13;
</ol>&#13;
<p>The first three steps listed above don’t involve deep complexity. The <span class="obeylines-h"><span class="verb"><code class="inlineCode">asyncio</code></span></span> module helps us create tasks to parse each file, and then run the collection of tasks. The event loop ensures that coroutines will pause at the <span class="obeylines-h"><span class="verb"><code class="inlineCode">await</code></span></span> statements to collect results. It also ensures coroutines with available data are eligible to process. The interleaving of the coroutines happens in a single thread. As noted previously, the number of bytecode operations is not magically made smaller by changing the order of execution.</p>&#13;
<p>The tricky part of this is dealing with input and output operations that are <span class="cmti-10x-x-109">not</span> part of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">asyncio</code></span></span> module. Specifically, reading and writing local files is not part of <span class="obeylines-h"><span class="verb"><code class="inlineCode">asyncio</code></span></span>. Any time we attempt to read (or write) a file, the operating system request could <span class="keyWord">block </span>waiting for the operation to complete. Unless this blocking request is in a separate thread, it stops the event loop, and stops all of Python’s cleverly interleaved coroutine processing. See <a href="https://docs.python.org/3/library/asyncio-eventloop.html#id14">https://docs.python.org/3/library/asyncio-eventloop.html#id14</a> for more information on using a thread pool.</p>&#13;
<p>To work with local files, we would need to use a <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures.ThreadPoolExecutor</code></span></span> object to manage<span id="dx1-303011"/> the file input and output operations. This will allocate the work to threads outside the main event loop. Consequently, a design for local file processing based on <span class="obeylines-h"><span class="verb"><code class="inlineCode">async</code></span></span>/<span class="obeylines-h"><span class="verb"><code class="inlineCode">await</code></span></span> will not be dramatically better than one using <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures</code></span></span> directly.</p>&#13;
<p>For network servers and complex clients, the <span class="obeylines-h"><span class="verb"><code class="inlineCode">asyncio</code></span></span> module can make the application very responsive to a user’s inputs. The fine-grained switching among the coroutines within a thread works best when most of the coroutines are waiting for data. <span id="x1-303012r314"/></p>&#13;
</section>&#13;
<section id="designing-concurrent-processing" class="level4 subsectionHead" data-number="0.18.4.7">&#13;
<h4 class="subsectionHead" data-number="0.18.4.7"><span class="titlemark">14.4.7 </span> <span id="x1-3040007"/>Designing concurrent processing</h4>&#13;
<p>From a functional programming<span id="dx1-304001"/> perspective, we’ve seen three ways to use the <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> function concept applied to data items concurrently. We can use any one of the following:</p>&#13;
<ul>&#13;
<li><p><span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing.Pool</code></span></span></p></li>&#13;
<li><p><span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures.ProcessPoolExecutor</code></span></span></p></li>&#13;
<li><p><span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures.ThreadPoolExecutor</code></span></span></p></li>&#13;
</ul>&#13;
<p>These are almost identical in the way we interact with them; all three of these process pools support variations of a <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> method that applies a function to items of an iterable collection. This fits in elegantly with other functional programming techniques. The performance of each pool may be different because of the nature of concurrent threads versus concurrent processes.</p>&#13;
<p>As we stepped through the design, our log analysis application decomposed into two overall areas:</p>&#13;
<ul>&#13;
<li><p>The lower-level parsing: This is generic parsing that will be used by almost any log analysis application</p></li>&#13;
<li><p>The higher-level analysis application: This is more specific filtering and reduction focused on our application’s needs</p></li>&#13;
</ul>&#13;
<p>The lower-level parsing can be decomposed into four stages:</p>&#13;
<ol>&#13;
<li><div id="x1-304003x1">&#13;
<p>Reading all the lines from multiple source log files. This was the <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> mapping from file name to a sequence of lines.</p>&#13;
</div></li>&#13;
<li><div id="x1-304005x2">&#13;
<p>Creating named tuples from the lines of log entries in a collection of files. This was the <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_iter()</code></span></span> mapping from text lines to <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> objects.</p>&#13;
</div></li>&#13;
<li><div id="x1-304007x3">&#13;
<p>Parsing the details of more complex fields such as dates and URLs. This was the <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_detail_iter()</code></span></span> mapping from <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> objects to <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> objects.</p>&#13;
</div></li>&#13;
<li><div id="x1-304009x4">&#13;
<p>Rejecting uninteresting paths from the logs. We can also think of this as passing only the interesting paths. This was more of a filter than a map operation. This was a collection of filters bundled into the <span class="obeylines-h"><span class="verb"><code class="inlineCode">path_filter()</code></span></span> function.</p>&#13;
</div></li>&#13;
</ol>&#13;
<p>We defined an overall <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function that parsed and analyzed a given log file. It applied the higher-level filter and reduction to the results of the lower-level parsing. It can also work with a wildcard collection of files.</p>&#13;
<p>Given the number of mappings<span id="dx1-304010"/> involved, we can see several ways to decompose this problem into work designed to use a pool of threads or processes. Each mapping is an opportunity for concurrent processing. Here are some of the mappings we can consider as design alternatives:</p>&#13;
<ul>&#13;
<li><p>Map the <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function to individual files. We used this as a consistent example throughout this chapter.</p></li>&#13;
<li><p>Refactor the <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> function out of the overall <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function. This refactoring permits mapping a revised <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function to the results of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">local_gzip()</code></span></span> function.</p></li>&#13;
<li><p>Refactor the <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_iter(local_gzip(pattern))</code></span></span> function out of the overall <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function. This revised <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function can be applied via <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> to the iterable sequence of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> objects.</p></li>&#13;
<li><p>Refactor the <span class="obeylines-h"><span class="verb"><code class="inlineCode">access_detail_iter(access_iter(local_gzip(pattern)))</code></span></span> function into two separate iterables. This permits using <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> to apply one function to create <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetail</code></span></span> objects. A separate, higher-level filter and reduction against the iterable sequence of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetail</code></span></span> objects can be a separate process.</p></li>&#13;
<li><p>We can also refactor the lower-level parsing into a function to keep it separate from the higher-level analysis. We can map the analysis filter and reduction against the output from the lower-level parsing.</p></li>&#13;
</ul>&#13;
<p>All of these are relatively simple methods to restructure the example application. The benefit of using functional programming techniques is that each part of the overall process can be defined as a mapping, a filter, or a reduction. This makes it practical to consider different architectures to locate an optimal design.</p>&#13;
<p>In this case, however, we need to distribute the I/O processing to as many CPUs or cores as we have available. Most of these potential<span id="dx1-304011"/> refactorings will perform all of the I/O in the parent process; these will only distribute the computation portions of the work to multiple concurrent processes with little resulting benefit. Because of these, we want to focus on the mappings, as these distribute the I/O to as many cores as possible.</p>&#13;
<p>It’s often important to minimize the amount of data being passed from process to process. In this example, we provided just short filename strings to each worker process. The resulting <span class="obeylines-h"><span class="verb"><code class="inlineCode">Counter</code></span></span> object was considerably smaller than the 10 MB of compressed detail data in each log file.</p>&#13;
<p>It’s also essential to run benchmarking experiments to confirm the actual timing between computation, input, and output. This information is essential to uncover optimal allocation of resources, and a design that better balances computation against waiting for I/O to complete.</p>&#13;
<p>The following table contains some preliminary results:</p>&#13;
<div class="center">&#13;
<div class="tabular">&#13;
<table id="TBL-11" class="tabular">&#13;
<tbody>&#13;
<tr class="odd hline">&#13;
<td><hr/>&#13;
</td>&#13;
<td><hr/>&#13;
</td>&#13;
</tr>&#13;
<tr id="TBL-11-1-" class="even" style="vertical-align:baseline;">&#13;
<td id="TBL-11-1-1" class="td11" style="text-align: left; white-space: nowrap;"><span class="keyWord">Approach </span></td>&#13;
<td id="TBL-11-1-2" class="td11" style="text-align: right; white-space: nowrap;"><span class="keyWord">Duration </span></td>&#13;
</tr>&#13;
<tr id="TBL-11-2-" class="odd" style="vertical-align:baseline;">&#13;
<td id="TBL-11-2-1" class="td11" style="text-align: left; white-space: nowrap;"><span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures/threadpool</code></span></span></td>&#13;
<td id="TBL-11-2-2" class="td11" style="text-align: right; white-space: nowrap;">106.58s</td>&#13;
</tr>&#13;
<tr id="TBL-11-3-" class="even" style="vertical-align:baseline;">&#13;
<td id="TBL-11-3-1" class="td11" style="text-align: left; white-space: nowrap;"><span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures/processpool</code></span></span></td>&#13;
<td id="TBL-11-3-2" class="td11" style="text-align: right; white-space: nowrap;">40.81s</td>&#13;
</tr>&#13;
<tr id="TBL-11-4-" class="odd" style="vertical-align:baseline;">&#13;
<td id="TBL-11-4-1" class="td11" style="text-align: left; white-space: nowrap;"><span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing/imap_unordered</code></span></span></td>&#13;
<td id="TBL-11-4-2" class="td11" style="text-align: right; white-space: nowrap;">27.26s</td>&#13;
</tr>&#13;
<tr id="TBL-11-5-" class="even" style="vertical-align:baseline;">&#13;
<td id="TBL-11-5-1" class="td11" style="text-align: left; white-space: nowrap;"><span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing/map_async</code></span></span></td>&#13;
<td id="TBL-11-5-2" class="td11" style="text-align: right; white-space: nowrap;">27.45s</td>&#13;
</tr>&#13;
<tr class="odd hline">&#13;
<td><hr/>&#13;
</td>&#13;
<td><hr/>&#13;
</td>&#13;
</tr>&#13;
<tr id="TBL-11-6-" class="even" style="vertical-align:baseline;">&#13;
<td id="TBL-11-6-1" class="td11" style="text-align: left; white-space: nowrap;"/>&#13;
<td/>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div>&#13;
</div>&#13;
<p>We can see that a thread pool doesn’t permit any useful serialization of the work. This is not unexpected, and provides a kind of worst-case benchmark.</p>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures/processpool</code></span></span> row shows the time with 4 workers. This variant used the <span class="obeylines-h"><span class="verb"><code class="inlineCode">map()</code></span></span> to parcel requests to the workers. The need to process the work and collect the results in a specific order may have caused relatively slow processing.</p>&#13;
<p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> modules used the default<span id="dx1-304012"/> number of cores, which is 8 for the computer being used. The time was cut almost to <img src="../Images/file131.jpg" class="frac" data-align="middle" alt="1 4"/> the baseline time. In order to make better use of the available processors, it might make sense to further decompose the processing to create batches of lines for analysis, and have separate worker pools for analysis and file parsing. Because the workloads are very difficult to predict, a flexible, functional design allows the restructuring of the work, searching for a way to maximize CPU use. <span id="x1-304013r308"/></p>&#13;
</section>&#13;
</section>&#13;
<section id="summary-13" class="level3 sectionHead" data-number="0.18.5">&#13;
<h3 class="sectionHead" data-number="0.18.5"><span class="titlemark">14.5 </span> <span id="x1-3050005"/>Summary</h3>&#13;
<p>In this chapter, we’ve looked at two ways to support the concurrent processing of multiple pieces of data:</p>&#13;
<ul>&#13;
<li><p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> module: Specifically, the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Pool</code></span></span> class and the various kinds of mappings available to a pool of workers.</p></li>&#13;
<li><p>The <span class="obeylines-h"><span class="verb"><code class="inlineCode">concurrent.futures</code></span></span> module: Specifically, the <span class="obeylines-h"><span class="verb"><code class="inlineCode">ProcessPoolExecutor</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">ThreadPoolExecutor</code></span></span> classes. These classes also support a mapping that will distribute work among workers that are threads or processes.</p></li>&#13;
</ul>&#13;
<p>We’ve also noted some alternatives that don’t seem to fit in well with functional programming. There are numerous other features of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">multiprocessing</code></span></span> module, but they’re not a good fit with functional design. Similarly, the <span class="obeylines-h"><span class="verb"><code class="inlineCode">threading</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">queue</code></span></span> modules can be used to build multithreaded applications, but the features aren’t a good fit with functional programs.</p>&#13;
<p>In the next chapter, we’ll look at how we can apply functional programming techniques to build web service applications. The idea of HTTP can be summarized as <span class="obeylines-h"><span class="verb"><code class="inlineCode">response</code><code class="inlineCode"> =</code></span></span> <span class="obeylines-h"><span class="verb"><code class="inlineCode">httpd(request)</code></span></span>. When the HTTP processing is stateless, this seems to be a perfect match for functional design.</p>&#13;
<p>Adding stateful cookies to this is analogous to providing a response value which is expected as an argument to a later request. We can think of it as <span class="lstinline"><span style="color:#000000"><code class="inlineCode">response</code></span><span style="color:#000000"><code class="inlineCode">,</code></span><span style="color:#000000"> </span><span style="color:#000000"><code class="inlineCode">cookie</code></span><span style="color:#000000"> </span><span style="color:#000000"><code class="inlineCode">=</code></span><span style="color:#000000"> </span><span style="color:#000000"><code class="inlineCode">httpd</code></span><span style="color:#000000"><code class="inlineCode">(</code></span><span style="color:#000000"><code class="inlineCode">request</code></span><span style="color:#000000"><code class="inlineCode">,</code></span><span style="color:#000000"> </span><span style="color:#000000"><code class="inlineCode">cookie</code></span><span style="color:#000000"><code class="inlineCode">)</code></span></span>, where the cookie object is opaque to the client. <span id="x1-305001r316"/></p>&#13;
</section>&#13;
<section id="exercises-13" class="level3 sectionHead" data-number="0.18.6">&#13;
<h3 class="sectionHead" data-number="0.18.6"><span class="titlemark">14.6 </span> <span id="x1-3060006"/>Exercises</h3>&#13;
<p>This chapter’s exercises are based on code available from Packt Publishing on GitHub. See <a href="https://github.com/PacktPublishing/Functional-Python-Programming-3rd-Edition" class="url">https://github.com/PacktPublishing/Functional-Python-Programming-3rd-Edition</a>.</p>&#13;
<p>In some cases, the reader will notice that the code provided on GitHub includes partial solutions to some of the exercises. These serve as hints, allowing the reader to explore alternative solutions.</p>&#13;
<p>In many cases, exercises will need unit test cases to confirm they actually solve the problem. These are often identical to the unit test cases already provided in the GitHub repository. The reader should replace the book’s example function name with their own solution to confirm that it works. <span id="x1-306001r315"/></p>&#13;
<section id="lazy-parsing" class="level4 subsectionHead" data-number="0.18.6.1">&#13;
<h4 class="subsectionHead" data-number="0.18.6.1"><span class="titlemark">14.6.1 </span> <span id="x1-3070001"/>Lazy parsing</h4>&#13;
<p>In the <a href="#x1-2930004"><span class="cmti-10x-x-109">Parsing additional fields of an Access object</span></a> section, we looked at a function that did the initial decomposition of a <span class="keyWord">Common Log File </span>(<span class="keyWord">CLF</span>) line into an initial set of easy-to-separate fields.</p>&#13;
<p>We then applied three separate functions to parse the details of the timestamp, request, the time, and the user agent information. These three functions were applied eagerly, decomposing these three fields, even if they were never used for further analysis.</p>&#13;
<p>There are two commonly-used ways to implement <span class="cmti-10x-x-109">lazy </span>parsing of these fields:</p>&#13;
<ul>&#13;
<li><p>Rather than parse the text to create a <span class="obeylines-h"><span class="verb"><code class="inlineCode">details.time</code></span></span> attribute, we can define a <span class="obeylines-h"><span class="verb"><code class="inlineCode">parse_time()</code></span></span> method to parse the <span class="obeylines-h"><span class="verb"><code class="inlineCode">access.time</code></span></span> value. The syntax is longer, but it ensures that the attribute is only parsed as needed.</p></li>&#13;
<li><p>Once we have this function, we can make it into a property.</p></li>&#13;
</ul>&#13;
<p>First, redefine a new <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access_Details</code></span></span> class to use three separate methods to parse the complex fields.</p>&#13;
<p>Once this works, make these methods into properties to provide values as if they had been parsed eagerly. Make sure the new property method names match the original attribute names in the class shown earlier.</p>&#13;
<p>To compare the performance, we need to know how often these additional property parsing methods are used. Two simple assumptions are 100% of the time and 0% of the time. To compare the two designs, we’ll need some statistical summary functions that work with the <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access_Details</code></span></span> objects.</p>&#13;
<p>Create a function that fetches the values of all attributes, to compute a number of histograms, for example. Create another that uses only the status value to compute a histogram of status only. Compare the performance of the two <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access_Details</code></span></span> class variants and the two analytic approaches to see which is faster. The expectation is that lazy parsing will be faster. The question is ”how much faster?” <span id="x1-307001r318"/></p>&#13;
</section>&#13;
<section id="filter-access-path-details" class="level4 subsectionHead" data-number="0.18.6.2">&#13;
<h4 class="subsectionHead" data-number="0.18.6.2"><span class="titlemark">14.6.2 </span> <span id="x1-3080002"/>Filter access path details</h4>&#13;
<p>In the <a href="#x1-2940005"><span class="cmti-10x-x-109">Filtering the access details</span></a> section of this chapter, we showed a function to exclude empty paths from further analysis.</p>&#13;
<p>We can write similar test functions for the <span class="obeylines-h"><span class="verb"><code class="inlineCode">non_excluded_names()</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">non_excluded_ext()</code></span></span> functions. Names like <span class="obeylines-h"><span class="verb"><code class="inlineCode">’favicon.ico’</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">’robots.txt’</code></span></span> need to be excluded. Similarly, extensions like <span class="obeylines-h"><span class="verb"><code class="inlineCode">’.js’</code></span></span> and <span class="obeylines-h"><span class="verb"><code class="inlineCode">’.css’</code></span></span> need to be excluded, also.</p>&#13;
<p>Write these two functions to complete the implementation of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">path_filter()</code></span></span> function. These require some unit test cases, as does the overall <span class="obeylines-h"><span class="verb"><code class="inlineCode">path_filter()</code></span></span> function that exploits three separate path function filters.</p>&#13;
<p>All of these functions work with a decomposed path name. Is it sensible to try to write a single, complex function for all three operations? Does it make more sense to decompose the three separate rules and combine them through an overall path filtering function? <span id="x1-308001r319"/></p>&#13;
</section>&#13;
<section id="add-cache-decorators" class="level4 subsectionHead" data-number="0.18.6.3">&#13;
<h4 class="subsectionHead" data-number="0.18.6.3"><span class="titlemark">14.6.3 </span> <span id="x1-3090003"/>Add @cache decorators</h4>&#13;
<p>The implementation of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">path_filter()</code></span></span> function applies three separate filters. Each filter function will parse the path in the <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> object. In order to make this more efficient, it can help to wrap lower-level parsing, like a <span class="obeylines-h"><span class="verb"><code class="inlineCode">path.split(’/’)</code></span></span> function, with the <span class="obeylines-h"><span class="verb"><code class="inlineCode">@cache</code></span></span> decorator.</p>&#13;
<p>Write (or rewrite) these three filter functions to make use of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">@cache</code></span></span> decorator.</p>&#13;
<p>Be sure to compare performance of the filter functions with caching and without caching. This can be challenging because when we use a simple <span class="obeylines-h"><span class="verb"><code class="inlineCode">@cache</code></span></span> decorator, the original, uncached function is no longer available.</p>&#13;
<p>If, on the other hand, we use something like <span class="obeylines-h"><span class="verb"><code class="inlineCode">func_c</code><code class="inlineCode"> =</code><code class="inlineCode"> cache(func)</code></span></span>, we can preserve both the original (uncached) function and the counterpart with caching. See <a href="Chapter_12.xhtml#x1-25000012"><span class="cmti-10x-x-109">Chapter</span><span class="cmti-10x-x-109"> 12</span></a>, <a href="Chapter_12.xhtml#x1-25000012"><span class="cmti-10x-x-109">Decorator Design Techniques</span></a>, for more on how this works. Doing this lets us gather timing data for cached and uncached implementations. <span id="x1-309001r320"/></p>&#13;
</section>&#13;
<section id="create-sample-data" class="level4 subsectionHead" data-number="0.18.6.4">&#13;
<h4 class="subsectionHead" data-number="0.18.6.4"><span class="titlemark">14.6.4 </span> <span id="x1-3100004"/>Create sample data</h4>&#13;
<p>The design shown uses a mapping from filenames to summary counts. Each file is processed concurrently by a pool of workers. In order to determine if this is optimal, it’s essential to have a high volume of data to measure performance.</p>&#13;
<p>For a lightly-used website, the log files can average about 10 Mb per month. Write a Python script to generate synthetic log rows in batches averaging about 10 Mb per file. Using simplistic random strings isn’t the best approach because the application design expects that the request path will have a recognizable pattern. This requires some care to generate synthetic data that fits the expected pattern.</p>&#13;
<p>The application to create synthetic data needs some unit test cases. The overall analysis application is the final acceptance test case: does the analysis application identify the data patterns built into the synthetic rows of log entries? <span id="x1-310001r321"/></p>&#13;
</section>&#13;
<section id="change-the-pipeline-structure" class="level4 subsectionHead" data-number="0.18.6.5">&#13;
<h4 class="subsectionHead" data-number="0.18.6.5"><span class="titlemark">14.6.5 </span> <span id="x1-3110005"/>Change the pipeline structure</h4>&#13;
<p>For a lightly-used website, the log files can average about 10 Mb per month. Using Python 3.10 on a MacBook Pro, each file takes about 16 seconds to process. A collection of six 10 Mb files has a worst-case performance of 96 seconds. On a computer with over six cores, the best case would be 16 seconds.</p>&#13;
<p>The design shown in this chapter allocates each file to a separate worker.</p>&#13;
<p>Is this the right level of granularity? It’s impossible to know without exploring alternatives. This requires sample data files created by the previous exercise. Consider implementing alternative designs and comparing throughput. Here are some suggested alternatives:</p>&#13;
<ul>&#13;
<li><p>Create two pools of workers: one pool reads files and returns lines in blocks of 1,024. The second pool of workers comprises the bulk of the <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function. This second pool has workers to parse each line in a block to create an <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> object, create an <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> object, apply the filters, and summarize the results. This leads to two tiers of mapping to pass work from the parsing workers to the analysis workers.</p></li>&#13;
<li><p>Decompose the 10 Mb log files into smaller sizes. Write an application to read a log file and write new files, each of which is limited to 4,096 individual log entries. Apply the analysis application to this larger collection of small files instead of the smaller collection of the original large log files.</p></li>&#13;
<li><p>Decompose the <span class="obeylines-h"><span class="verb"><code class="inlineCode">analysis()</code></span></span> function to use three separate pools of workers. One pool parses files and returns blocks of <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> objects. Another pool transforms <span class="obeylines-h"><span class="verb"><code class="inlineCode">Access</code></span></span> objects into <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> objects. The third pool of workers applies filters and summarizes the <span class="obeylines-h"><span class="verb"><code class="inlineCode">AccessDetails</code></span></span> objects.</p></li>&#13;
</ul>&#13;
<p>Summarize the results of using distinct processing pipelines to analyze large volumes of data. <span id="x1-311001r293"/></p>&#13;
</section>&#13;
</section>&#13;
</section>&#13;
</body></html>