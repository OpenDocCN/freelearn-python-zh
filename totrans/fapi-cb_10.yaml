- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Integrating FastAPI with other Python Libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will delve into the process of expanding the capabilities
    of **FastAPI** by integrating it with other **Python** libraries. By harnessing
    the power of external tools and libraries, you can enhance the functionality of
    your FastAPI applications and unlock new possibilities for creating dynamic and
    feature-rich web services.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, you will learn how to integrate FastAPI with a diverse
    range of Python libraries, each serving a different purpose and offering unique
    functionalities. From taking advantage of advanced natural language processing
    capabilities with **Cohere** and **LangChain** to integrating real-time communication
    features with **gRPC** and **GraphQL**, you will discover how to harness the full
    potential of FastAPI in conjunction with other popular Python tools.
  prefs: []
  type: TYPE_NORMAL
- en: By integrating FastAPI with other Python libraries, you will be able to build
    sophisticated web applications that go beyond simple **REST APIs**. Whether you
    are developing a chatbot powered by natural language processing or integrating
    **machine learning** (**ML**) models for intelligent decision-making, the possibilities
    are endless.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be equipped with the knowledge and skills
    to effectively leverage external tools and resources, enabling you to build sophisticated
    and feature-rich APIs that meet the needs of your users.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter includes the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Integrating FastAPI with gRPC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting FastAPI with GraphQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using ML models with Joblib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating FastAPI with Cohere
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating FastAPI with LangChain
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To follow the recipes in this chapter, it is important to have a good understanding
    of FastAPI. Additionally, since this chapter demonstrates how to integrate FastAPI
    with external libraries, having a basic knowledge of each library can be beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: However, we will provide external links for you to review any of the concepts
    that are used in the recipes. You can also refer back to this chapter whenever
    you need to integrate a technology with FastAPI.
  prefs: []
  type: TYPE_NORMAL
- en: The code used in the chapter is hosted on GitHub at [https://github.com/PacktPublishing/FastAPI-Cookbook/tree/main/Chapter10](https://github.com/PacktPublishing/FastAPI-Cookbook/tree/main/Chapter10).
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended to set up a virtual environment for the project in the project
    root folder to efficiently manage dependencies and maintain project isolation.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each recipe, you can install all the dependencies at once within your virtual
    environment by using the `requirements.txt` file provided in the GitHub repository
    in the following project folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Let’s start delving into this recipe and discovering the potential of coupling
    FastAPI with external libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating FastAPI with gRPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: gRPC is a high-performance, open source universal **Remote Procedure Call**
    (**RPC**) framework originally developed by Google. It is designed to be efficient,
    lightweight, and interoperable across different programming languages and platforms.
    Integrating FastAPI with gRPC allows you to leverage the power of RPC for building
    efficient, scalable, and maintainable APIs.
  prefs: []
  type: TYPE_NORMAL
- en: The recipe will show how to build a gateway between a REST client and a gRPC
    server by using FastAPI.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To follow the recipe, it can be beneficial to have some previous knowledge of
    protocol buffers. You can have a look at the official documentation at [https://protobuf.dev/overview/](https://protobuf.dev/overview/).
  prefs: []
  type: TYPE_NORMAL
- en: Also, we will use the proto3 version to define the `.proto` files. You can check
    the language guide at [https://protobuf.dev/programming-guides/proto3/](https://protobuf.dev/programming-guides/proto3/).
  prefs: []
  type: TYPE_NORMAL
- en: We will create a dedicated root project folder for the recipe called `grpc_gateway`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside from `fastapi` and `uvicorn`, you also need to install the `grpcio` and
    `grpcio-tools` packages . You can do this by using the `requirements.txt` file
    provided in the GitHub repository in your environment or by explicitly specifying
    the packages with the `pip` command in your environment as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Before starting with the recipe, let’s build a basic gRPC server with one method
    that takes a message from the client and sends back a message as well by following
    these steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the root project let’s create a `grpcserver.proto` file containing the
    definition of our server as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the same file, we will define the `Message` and `MessageResponse` messages
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: From the `.proto` file we have just created, we can automatically generate the
    Python code necessary to integrate the service and gRPC client as well with a
    proto compiler.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, from the command line terminal, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let’s write a script to run the gRPC server. Let’s create a file called
    `grpc_server.py` and define the server class as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then we will define the function to run the server on the localhost on port
    `50015` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then close the script by running the `serve` function into the event loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This is all we need to build the gRPC server. Now we can run the script from
    the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything has been set up correctly you will see the following log message
    on the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: With the gRPC server running, we can now create our gateway by leveraging FastAPI.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will create a FastAPI application with one `GET /grpc` endpoint that will
    take a message as a parameter, forward the request to the gRPC server, and return
    the message from the gRPC server to the client. Let’s go through the following
    steps to build a basic gateway application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the project root folder, let’s create a folder called `app` with a `main.py`
    module containing the server as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let’s create the response class schema with Pydantic that will reflect
    the `MessageResponse` proto class as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then we will initialize the `grpc_channel`object, which is an abstraction layer
    for gRPC calls containing the gRPC service URL, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can create our endpoint as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once we have created our FastAPI application, let’s spin up the server from
    the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Open the interactive documentation at `http://localhost:8000/docs` and you will
    see the new endpoint that will take a message parameter and return the response
    from the gRPC server. If you try to call it, you will also see the log message
    for the call on the gRPC server terminal.
  prefs: []
  type: TYPE_NORMAL
- en: You have successfully set up a REST-gRPC gateway by using FastAPI!
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have created a gateway that supports Unary RPC, which is a simple RPC that
    resembles a normal function call. It involves sending a single request, which
    is defined in the `.proto` file, to the server and receiving a single response
    back from the server. However, there are various types of RPC implementations
    available that allow for the streaming of messages from the client to the server
    or from the server to the client, as well as ones that allow for bidirectional
    communication.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a REST gateway using FastAPI is a relatively easy task. For more information
    on how to implement different types of gRPC in Python, you can refer to the following
    article: [https://www.velotio.com/engineering-blog/grpc-implementation-using-python](https://www.velotio.com/engineering-blog/grpc-implementation-using-python).
    Once you have mastered these concepts, you can easily integrate them into FastAPI
    and build a complete gateway for gRPC services.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can dive deeper into protocol buffer and how you can use it in Python code
    in the official documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Protocol Buffer Python Generated* *Code*: [https://protobuf.dev/reference/python/python-generated/](https://protobuf.dev/reference/python/python-generated/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You check more on how to implement gRPC in Python code at the gRPC official
    documentation page:'
  prefs: []
  type: TYPE_NORMAL
- en: '*gRPC Python* *Tutorial*: [https://grpc.io/docs/languages/python/basics/](https://grpc.io/docs/languages/python/basics/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Also, have a look at the examples on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '*gRPC Python GitHub* *Examples*: [https://github.com/grpc/grpc/tree/master/examples/python](https://github.com/grpc/grpc/tree/master/examples/python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting FastAPI with GraphQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GraphQL is a query language for APIs and a runtime for executing queries. It
    provides an efficient, powerful, and flexible alternative to traditional REST
    APIs by allowing clients to specify exactly what data they need. Integrating FastAPI
    with GraphQL enables you to build APIs that are highly customizable and capable
    of handling complex data requirements. In this recipe, we will see how to connect
    FastAPI with GraphQL to query a user database, allowing you to create GraphQL
    schemas, define resolvers, and expose a GraphQL endpoint in your FastAPI application.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To follow the recipe, it can be beneficial to ensure you already have some basic
    knowledge about GraphQL. You can have a look at the official documentation at
    [https://graphql.org/learn/](https://graphql.org/learn/).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the GitHub repository folder of this chapter, there is a folder named `graphql`,
    which we will consider as the root project folder. To implement GraphQL, we will
    be utilizing the Strawberry library. Please ensure that you have it installed
    in your environment along with FastAPI. You can install it by using the `requirements.txt`
    file located in the project root of the repository or by using the `pip` command
    by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Once the installation is complete, we can start the recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s create a basic GraphQL endpoint that retrieves users from a specific country
    in a database. Let’s do it through the following steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a `database.py` module containing a list of users that we will
    use as a database source. Define the `User` class as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can then write a `users_db` object, which will be a list of `User` class
    objects, or copy the one from the respective `database.py` file on the GitHub
    repository at [https://raw.githubusercontent.com/PacktPublishing/FastAPI-Cookbook/main/Chapter10/graphql/database.py](https://raw.githubusercontent.com/PacktPublishing/FastAPI-Cookbook/main/Chapter10/graphql/database.py).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It will look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will use this list as a database for our simple query.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In a separate module called `graphql_utils.py`, we will define the query. But
    first, let’s define the model returned by the query as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then we will define the query as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The query takes a country as an argument and returns all the users for the country.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, in the same file, let’s create the GraphQL schema with the FastAPI router:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The last line will create a `fastapi.Router` instance that will handle the endpoint.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s finalize the endpoint by adding the router to the main FastAPI instance
    in a separate `main.py` module as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We added the endpoint to the FastAPI instance and defined the `/``graphql` path.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is all you need to setup a GraphQl endpoint within FastAPI.
  prefs: []
  type: TYPE_NORMAL
- en: 'To explore the potential of the endpoint, let’s run the server from the command
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '{'
  prefs: []
  type: TYPE_NORMAL
- en: 'users(country: "USA") {'
  prefs: []
  type: TYPE_NORMAL
- en: username
  prefs: []
  type: TYPE_NORMAL
- en: country
  prefs: []
  type: TYPE_NORMAL
- en: phoneNumber
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '{'
  prefs: []
  type: TYPE_NORMAL
- en: '"data": {'
  prefs: []
  type: TYPE_NORMAL
- en: '"users": ['
  prefs: []
  type: TYPE_NORMAL
- en: '{'
  prefs: []
  type: TYPE_NORMAL
- en: '"username": "user1",'
  prefs: []
  type: TYPE_NORMAL
- en: '"country": "USA",'
  prefs: []
  type: TYPE_NORMAL
- en: '"phoneNumber": "1234567890"'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: ']'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: $ pip install fastapi[all] joblib scikit-learn
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: $ pip install huggingface_hub
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: from fastapi import FastAPI
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from contextlib import asynccontextmanager
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ml_model = {}
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: REPO_ID = "AWeirdDev/human-disease-prediction"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: FILENAME = "sklearn_model.joblib"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '@asynccontextmanager'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'async def lifespan(app: FastAPI):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ml_model["doctor"] = joblib.load(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: hf_hub_download(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: repo_id=REPO_ID, filename=FILENAME
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: yield
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ml_model.clear()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: app = FastAPI(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: title="AI Doctor",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: lifespan=lifespan
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from pydantic import create_model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from app.utils import symptoms_list
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: query_parameters = {
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'symp: (bool, False)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: for symp in symptoms_list[:10]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Symptoms = create_model(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"Symptoms", **query_params'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '@app.get("/diagnosis")'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: async def get_diagnosis(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'symptoms: Annotated[Symptoms, Depends()],'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: array = [
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: int(value)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: for _, value in symptoms.model_dump().items()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ']'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: array.extend(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '# adapt array to the model''s input shape'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[0] * (len(symptoms_list) - len(array))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: len(symptoms_list)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: diseases = ml_model["doctor"].predict([array])
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return {
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"diseases": [disease for disease in diseases]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ uvicorn app.main:app
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: COHERE_API_KEY="your-cohere-api-key"
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: $ pip install -r requirements.txt
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: $ pip install fastapi uvicorn cohere python-dotenv
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: from dotenv import load_dotenv
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: load_dotenv()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: SYSTEM_MESSAGE = (
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"You are a skilled Italian top chef "'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"expert in Italian cuisine tradition "'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"that suggest the best recipes unveiling "'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"tricks and tips from Grandma''s Kitchen"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"shortly and concisely."'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from cohere import AsyncClient
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: client = AsyncClient()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from cohere import ChatMessage
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from cohere.core.api_error import ApiError
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from fastapi import HTTPException
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: async def generate_chat_completion(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: user_query=" ", messages=[]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ') -> str:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'try:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: response = await client.chat(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: message=user_query,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: model="command-r-plus",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: preamble=SYSTEM_MESSAGE,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: chat_history=messages,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: messages.extend(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '['
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ChatMessage(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: role="USER", message=user_query
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ),
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ChatMessage(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: role="CHATBOT",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: message=response.text,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ),
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ']'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return response.text
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'except ApiError as e:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: raise HTTPException(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: status_code=e.status_code, detail=e.body
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from contextlib import asynccontextmanager
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from fastapi import FastAPI
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '@asynccontextmanager'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'async def lifespan(app: FastAPI):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'yield {"messages": []}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: app = FastAPI(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: title="Chef Cuisine Chatbot App",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: lifespan=lifespan,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from typing import Annotated
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from fastapi import Body, Request
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from handlers import generate_chat_completion
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '@app.post("/query")'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: async def query_chat_bot(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'request: Request,'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'query: Annotated[str, Body(min_length=1)],'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ') -> str:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: answer = await generate_chat_completion(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: query, request.state.messages
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return answer
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ uvicorn main:app
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '"Hello, could you suggest a quick recipe for lunch to be prepared in less than
    one hour?"'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: $ pip install fastapi uvicorn python-dotenv
  prefs: []
  type: TYPE_NORMAL
- en: $ pip install langchain
  prefs: []
  type: TYPE_NORMAL
- en: $ pip install langchain-community langchain-cohere
  prefs: []
  type: TYPE_NORMAL
- en: $ pip install chromadb unstructured
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'template: str = """'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You are a customer support Chatbot.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You assist users with general inquiries
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and technical issues.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You will answer to the question:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{question}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your answer will only be based on the knowledge
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: of the context below you are trained on.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '-----------'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{context}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '-----------'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: if you don't know the answer,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: you will ask the user
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: to rephrase the question or
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: redirect the user the support@ecotech.com
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: always be friendly and helpful
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: at the end of the conversation,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ask the user if they are satisfied
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: with the answer if yes,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: say goodbye and end the conversation
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"""'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from langchain.prompts import (
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: SystemMessagePromptTemplate,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: system_message_prompt = (
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: SystemMessagePromptTemplate.from_template(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: template
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from langchain.prompts import (
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: HumanMessagePromptTemplate,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: human_message_prompt = (
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: HumanMessagePromptTemplate.from_template(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: template="{question}",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from langchain.prompts import ChatPromptTemplate
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: chat_prompt_template = (
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ChatPromptTemplate.from_messages(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[system_message_prompt, human_message_prompt]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from langchain.text_splitter import (
  prefs: []
  type: TYPE_NORMAL
- en: CharacterTextSplitter,
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: from langchain_core.documents.base import Document
  prefs: []
  type: TYPE_NORMAL
- en: from langchain_community.document_loaders import (
  prefs: []
  type: TYPE_NORMAL
- en: DirectoryLoader,
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: from langchain_community.vectorstores import Chroma
  prefs: []
  type: TYPE_NORMAL
- en: async def load_documents(
  prefs: []
  type: TYPE_NORMAL
- en: 'db: Chroma,'
  prefs: []
  type: TYPE_NORMAL
- en: '):'
  prefs: []
  type: TYPE_NORMAL
- en: text_splitter = CharacterTextSplitter(
  prefs: []
  type: TYPE_NORMAL
- en: chunk_size=100, chunk_overlap=0
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: raw_documents = DirectoryLoader(
  prefs: []
  type: TYPE_NORMAL
- en: '"docs", "*.txt"'
  prefs: []
  type: TYPE_NORMAL
- en: ).load()
  prefs: []
  type: TYPE_NORMAL
- en: chunks = text_splitter.split_documents(
  prefs: []
  type: TYPE_NORMAL
- en: raw_documents
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: await db.aadd_documents(chunks)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: def get_context(
  prefs: []
  type: TYPE_NORMAL
- en: 'user_query: str, db: Chroma'
  prefs: []
  type: TYPE_NORMAL
- en: ') -> str:'
  prefs: []
  type: TYPE_NORMAL
- en: docs = db.similarity_search(user_query)
  prefs: []
  type: TYPE_NORMAL
- en: return "\n\n".join(
  prefs: []
  type: TYPE_NORMAL
- en: doc.page_content for doc in docs
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: from dotenv import load_dotenv
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: load_dotenv()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from langchain_cohere import ChatCohere
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: model = ChatCohere(model="command-r-plus")
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from langchain.schema import StrOutputParser
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from prompting import chat_prompt_template
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: chain = (
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: chat_prompt_template | model | StrOutputParser()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from contextlib import asynccontextmanager
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from fastapi import FastAPI
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from langchain_cohere import CohereEmbeddings
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from langchain_community.vectorstores import Chroma
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from documents import load_documents
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '@asynccontextmanager'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'async def lifespan(app: FastAPI):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: db = Chroma(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: embedding_function=CohereEmbeddings()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: await load_documents(db)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'yield {"db": db}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: app = FastAPI(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: title="Ecotech AI Assistant",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: lifespan=lifespan
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from typing import Annotated
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from fastapi import Body, Request
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from documents import get_context
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: from model import chain
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '@app.post("/message")'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: async def query_assistant(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'request: Request,'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'question: Annotated[str, Body()],'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ') -> str:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: context = get_context(question, request.state.db)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: response = await chain.ainvoke(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"question": question,'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"context": context,'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return response
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ uvicorn main:app
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '"What is the capital of Belgium ?"'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '"I apologize, but I cannot answer that question as it is outside of my knowledge
    base. I am an FAQ chatbot trained to answer specific questions related to EcoTech
    Electronics, including our product compatibility with smart home systems, international
    shipping costs, and promotions for first-time customers. If you have any questions
    related to these topics, I''d be happy to help! Otherwise, for general inquiries,
    you can reach out to our support team at support@ecotech.com. Is there anything
    else I can assist you with today regarding EcoTech Electronics?"'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '"What kind of payments do you accept?"'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '"We want to make sure your shopping experience with us is as smooth and secure
    as possible. For online purchases, we currently accept major credit cards: Visa,
    Mastercard, and American Express. You also have the option to pay through PayPal,
    which offers an additional layer of security and convenience. \n\nThese payment
    methods are integrated into our straightforward online checkout process, ensuring
    a quick and efficient transaction. \n\nAre there any specific payment methods
    you are interested in using, or do you have any further questions about our accepted
    forms of payment? We want to ensure your peace of mind and a great overall experience
    shopping with us. \n\nAre you satisfied with the answer?"'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
