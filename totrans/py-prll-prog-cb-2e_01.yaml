- en: Getting Started with Parallel Computing and Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用并行计算和Python
- en: The *parallel* and *distributed computing* models are based on the simultaneous
    use of different processing units for program execution. Although the distinction
    between parallel and distributed computing is very thin, one of the possible definitions
    associates the parallel calculation model with the shared memory calculation model,
    and the distributed calculation model with the message passing model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*并行*和*分布式计算*模型基于同时使用不同的处理单元来执行程序。尽管并行计算和分布式计算之间的区别非常微妙，其中一种可能的定义将并行计算模型与共享内存计算模型相关联，将分布式计算模型与消息传递模型相关联。'
- en: From this point onward, we will use the term *parallel computing* to refer to
    both parallel and distributed calculation models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们将使用术语*并行计算*来指代并行和分布式计算模型。
- en: The next sections provide an overview of parallel programming architectures
    and programming models. These concepts are useful for inexperienced programmers
    who are approaching parallel programming techniques for the first time. Moreover,
    it can be a basic reference for experienced programmers. The dual characterization
    of parallel systems is also presented. The first characterization is based on
    the system architecture, while the second characterization is based on parallel
    programming paradigms.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下几节提供了并行编程架构和编程模型的概述。这些概念对于第一次接触并行编程技术的经验不足的程序员来说很有用。此外，它也可以作为经验丰富的程序员的基本参考。并行系统的双重特征也被介绍。第一种特征基于系统架构，而第二种特征基于并行编程范式。
- en: The chapter ends with a brief introduction to the Pythonprogramming language.
    The characteristics of the language, ease of use and learning, and the extensibility
    and richness of software libraries and applications make Python a valuable tool
    for any application, and also for parallel computing. The concepts of threads
    and processes are introduced in relation to their use in the language.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章以对Python编程语言的简要介绍结束。该语言的特点、易用性和学习性，以及软件库和应用的扩展性和丰富性使Python成为任何应用的宝贵工具，也是并行计算的宝贵工具。线程和进程的概念在它们在语言中的应用中被介绍。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下食谱：
- en: Why do we need parallel computing?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们为什么需要并行计算？
- en: Flynn's taxonomy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 飞利浦分类法
- en: Memory organization
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存组织
- en: Parallel programming models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行编程模型
- en: Evaluating performance
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估性能
- en: Introducing Python
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Python
- en: Python and parallel programming
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python和并行编程
- en: Introducing processes and threads
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍进程和线程
- en: Why do we need parallel computing?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们为什么需要并行计算？
- en: The growth in computing power made available by modern computers has resulted
    in us facing computational problems of increasing complexity in relatively short
    time frames. Until the early 2000s, complexity was dealt with by increasing the
    number of transistors as well as the clock frequency of single-processor systems,
    which reached peaks of 3.5-4 GHz. However, the increase in the number of transistors
    causes the exponential increase of the power dissipated by the processors themselves.
    In essence, there is, therefore, a physical limitation that prevents further improvement
    in the performance of single-processor systems.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现代计算机提供的计算能力的增长导致我们在相对较短的时间内面临越来越复杂的计算问题。直到2000年代初，复杂性是通过增加晶体管的数量以及单处理器系统的时钟频率来处理的，这些系统的峰值达到了3.5-4
    GHz。然而，晶体管数量的增加导致了处理器本身功耗的指数级增长。本质上，因此存在一个物理限制，阻止了单处理器系统性能的进一步改进。
- en: For this reason, in recent years, microprocessor manufacturers have focused
    their attention on *multi-core* systems. These are based on a core of several
    physical processors that share the same memory, thus bypassing the problem of
    dissipated power described earlier. In recent years, *quad-core* and *octa-core*
    systems have also become standard on normal desktop and laptop configurations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在近年来，微处理器制造商将注意力集中在*多核*系统上。这些系统基于几个物理处理器共享相同内存的核心，从而绕过了之前描述的功耗问题。近年来，*四核*和*八核*系统也已成为普通桌面和笔记本电脑配置的标准。
- en: On the other hand, such a significant change in hardware has also resulted in
    an evolution of software structure, which has always been designed to be executed
    sequentially on a single processor. To take advantage of the greater computational
    resources made available by increasing the number of processors, the existing
    software must be redesigned in a form appropriate to the parallel structure of
    the CPU, so as to obtain greater efficiency through the simultaneous execution
    of the single units of several parts of the same program.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，这种重大的硬件变化也导致了软件结构的演变，软件结构一直是设计为在单个处理器上顺序执行的。为了利用增加处理器数量所提供的更多计算资源，现有的软件必须重新设计成适合
    CPU 并行结构的适当形式，以便通过同时执行同一程序的多个部分的单个单元来获得更高的效率。
- en: Flynn's taxonomy
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 飞利浦的分类法
- en: 'Flynn''s taxonomy is a system for classifying computer architectures. It is
    based on two main concepts:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 飞利浦的分类法是一个用于分类计算机架构的系统。它基于两个主要概念：
- en: '**Instruction flow**: A system with *n* CPU has *n* program counters and, therefore, *n *instructions
    flows. This corresponds to a program counter.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指令流**：一个拥有 *n* 个 CPU 的系统有 *n* 个程序计数器，因此有 *n* 个指令流。这对应于一个程序计数器。'
- en: '**Data flow**: A program that calculates a function on a list of data has a
    data flow. The program that calculates the same function on several different
    lists of data has more data flows. This is made up of a set of operands.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据流**：一个计算数据列表上函数的程序有一个数据流。计算多个不同数据列表上相同函数的程序有更多的数据流。这由一组操作数组成。'
- en: 'As the instruction and data flows are independent, there are four categories
    of parallel machines: **Single Instruction Single Data** (**SISD**), **Single
    Instruction Multiple Data** (**SIMD**), **Multiple Instruction Single Data** (**MISD**),
    and **Multiple Instruction Multiple Data** (**MIMD**):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于指令和数据流是独立的，因此有四种并行机类别：**单指令单数据**（**SISD**）、**单指令多数据**（**SIMD**）、**多指令单数据**（**MISD**）和**多指令多数据**（**MIMD**）：
- en: '![](img/315c390f-4c31-4a69-811e-5696dff064d1.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/315c390f-4c31-4a69-811e-5696dff064d1.png)'
- en: Flynn's taxonomy
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 飞利浦的分类法
- en: Single Instruction Single Data (SISD)
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单指令单数据（SISD）
- en: The SISD computing system is like the von Neumann machine, which is a uniprocessor
    machine. As you can see in *Flynn's taxonomy* diagram, it executes a single instruction
    that operates on a single data stream. In SISD, machine instructions are processed
    sequentially.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: SISD 计算系统类似于冯·诺伊曼机器，这是一种单处理器机器。正如你在 *Flynn's taxonomy* 图中可以看到的，它执行一个操作单个数据流的指令。在
    SISD 中，机器指令是顺序处理的。
- en: 'In a clock cycle, the CPU executes the following operations:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个时钟周期内，CPU 执行以下操作：
- en: '**Fetch**: The CPU fetches the data and instructions from a memory area, which
    is called a *register*.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**取指令**：CPU 从一个内存区域取数据和指令，这个区域称为**寄存器**。'
- en: '**Decode**: The CPU decodes the instructions.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码**：CPU 解码指令。'
- en: '**Execute**: The instruction is carried out on the data. The result of the
    operation is stored in another register.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行**：指令在数据上执行。操作的结果存储在另一个寄存器中。'
- en: 'Once the execution stage is complete, the CPU sets itself to begin another
    CPU cycle:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦执行阶段完成，CPU 将自己设置为开始另一个 CPU 周期：
- en: '![](img/8d131bb3-cd52-4f51-969c-8c836a394f89.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8d131bb3-cd52-4f51-969c-8c836a394f89.png)'
- en: The fetch, decode, and execute cycle
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 取指令、解码和执行周期
- en: The algorithms that run on this type of computer are sequential (or serial)
    since they do not contain any parallelism. An example of a SISD computer is a
    hardware system with a single CPU.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这类计算机上运行的算法是顺序的（或串行的），因为它们不包含任何并行性。SISD 计算机的一个例子是具有单个 CPU 的硬件系统。
- en: 'The main elements of these architectures (namely, von Neumann architectures)
    are as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些架构的主要元素（即冯·诺伊曼架构）如下：
- en: '**Central memory unit**: This is used to store both instructions and program
    data.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中央存储单元**：用于存储指令和程序数据。'
- en: '**CPU**: This is used to get the instruction and/or data from the memory unit,
    which decodes the instructions and sequentially implements them.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CPU**：这是用来从内存单元获取指令和/或数据，它解码指令并依次执行它们。'
- en: '**The I/O system**: This refers to the input and output data of the program.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**I/O 系统**：这指的是程序的输入和输出数据。'
- en: 'Conventional single-processor computers are classified as SISD systems:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的单处理器计算机被归类为 SISD 系统：
- en: '![](img/1a6b6929-c4c4-41bb-96ae-2ec6b2aea55d.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a6b6929-c4c4-41bb-96ae-2ec6b2aea55d.png)'
- en: The SISD architecture schema
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: SISD 架构方案
- en: 'The following diagram specifically shows which areas of a CPU are used in the
    stages of fetch, decode, and execute:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 下图具体显示了CPU在取指、解码和执行阶段所使用的区域：
- en: '![](img/9ceec645-0aa1-4c90-97a7-cba9f8eb5031.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9ceec645-0aa1-4c90-97a7-cba9f8eb5031.png)'
- en: CPU components in the fetch-decode-execute phase
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 取指-解码-执行阶段的CPU组件
- en: Multiple Instruction Single Data (MISD)
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多指令单数据（MISD）
- en: In this model, *n* processors, each with their own control unit, share a single
    memory unit. In each clock cycle, the data received from the memory is processed
    by all processors simultaneously, each in accordance with the instructions received
    from its control unit.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，*n*个处理器，每个都有自己的控制单元，共享一个单一的内存单元。在每个时钟周期，从内存接收到的数据由所有处理器同时处理，每个处理器根据其控制单元接收到的指令进行处理。
- en: In this case, the parallelism (instruction-level parallelism) is obtained by
    performing several operations on the same piece of data. The types of problems
    that can be solved efficiently in these architectures are rather special, such
    as data encryption. For this reason, the MISD computer has not found space in
    the commercial sector. MISD computers are more of an intellectual exercise than
    a practical configuration.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，通过在相同的数据上执行多个操作来获得并行性（指令级并行性）。在这些架构中可以有效地解决的问题类型相当特殊，例如数据加密。因此，MISD计算机在商业领域没有找到空间。MISD计算机更多的是一种智力练习，而不是实际配置。
- en: Single Instruction Multiple Data (SIMD)
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单指令多数据（SIMD）
- en: A SIMD computer consists of *n* identical processors, each with their own local
    memory, where it is possible to store data. All processors work under the control
    of a single instruction stream. In addition to this, there are *n* data streams,
    one for each processor. The processors work simultaneously on each step and execute
    the same instructions, but on different data elements. This is an example of data-level
    parallelism.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个SIMD计算机由*n*个相同的处理器组成，每个处理器都有自己的局部内存，可以存储数据。所有处理器在单个指令流的控制下工作。此外，还有*n*个数据流，每个处理器一个。处理器在每一步同时工作，执行相同的指令，但针对不同的数据元素。这是一个数据级并行的例子。
- en: The SIMD architectures are much more versatile than MISD architectures. Numerous
    problems covering a wide range of applications can be solved by parallel algorithms
    on SIMD computers. Another interesting feature is that the algorithms for these
    computers are relatively easy to design, analyze, and implement. The limitation
    is that only the problems that can be divided into a number of subproblems (which
    are all identical, each of which will then be solved simultaneously through the
    same set of instructions) can be addressed with the SIMD computer.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: SIMD架构比MISD架构更灵活。SIMD计算机上的并行算法可以解决广泛应用的众多问题。另一个有趣的特点是，这些计算机的算法相对容易设计、分析和实现。局限性在于，只有那些可以分解为多个子问题（这些子问题都是相同的，每个子问题将通过同一组指令同时解决）的问题才能用SIMD计算机解决。
- en: With the supercomputer developed according to this paradigm, we must mention
    the *Connection Machine* (Thinking Machine, 1985) and *MPP* (NASA, 1983).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这种范例开发的超级计算机，我们必须提到*连接机*（思考机器，1985）和*MPP*（NASA，1983）。
- en: As we will see in [Chapter 6](1ea5f8e3-bc1e-4d48-8ffe-d96ed8d56259.xhtml), *Distributed
    Python*, and [Chapter 7](c043f263-c2f1-40ce-a390-c0999635225c.xhtml), *Cloud Computing*,
    the advent of modern graphics cards (GPUs), built with many SIMD-embedded units,
    has led to the more widespread use of this computational paradigm.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在[第6章](1ea5f8e3-bc1e-4d48-8ffe-d96ed8d56259.xhtml)“分布式Python”和[第7章](c043f263-c2f1-40ce-a390-c0999635225c.xhtml)“云计算”中看到的，现代图形卡（GPU）的出现，这些图形卡由许多SIMD嵌入式单元构建，导致了这种计算范例的更广泛使用。
- en: Multiple Instruction Multiple Data (MIMD)
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多指令多数据（MIMD）
- en: This class of parallel computers is the most general and most powerful class,
    according to Flynn's classification. This contains *n* processors, *n* instruction
    streams, and *n* data streams. Each processor has its own control unit and local
    memory, which makes MIMD architectures more computationally powerful than SIMD
    architectures.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 根据弗林分类，这类并行计算机是最通用和最强大的，它包含*n*个处理器、*n*个指令流和*n*个数据流。每个处理器都有自己的控制单元和局部内存，这使得MIMD架构比SIMD架构在计算上更强大。
- en: Each processor operates under the control of a flow of instructions issued by
    its own control unit. Therefore, the processors can potentially run different
    programs with different data, which allows them to solve subproblems that are
    different and can be a part of a single larger problem. In MIMD, the architecture
    is achieved with the help of the parallelism level with threads and/or processes.
    This also means that the processors usually operate asynchronously.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 每个处理器在其控制单元发出的指令流的控制下运行。因此，处理器可以潜在地运行不同的程序，使用不同的数据，这使得它们可以解决不同且可以是单个更大问题一部分的子问题。在MIMD中，通过线程和/或进程的并行级别来实现架构。这也意味着处理器通常以异步方式运行。
- en: 'Nowadays, this architecture is applied to many PCs, supercomputers, and computer
    networks. However, there is a counter that you need to consider: asynchronous
    algorithms are difficult to design, analyze, and implement:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这种架构已应用于许多个人电脑、超级计算机和计算机网络。然而，你需要考虑的一个反例是：异步算法难以设计、分析和实现：
- en: '![](img/f3fa5a98-1a89-4d76-a8af-c25a376c1ac8.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3fa5a98-1a89-4d76-a8af-c25a376c1ac8.png)'
- en: The SIMD architecture (A) and the MIMD architecture (B)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: SIMD架构（A）和MIMD架构（B）
- en: 'Flynn''s taxonomy can be extended by considering that SIMD machines can be
    divided into two subgroups:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过考虑SIMD机器可以分为两个子组，Flynn的分类法可以扩展：
- en: Numerical supercomputers
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值超级计算机
- en: Vectorial machines
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量机
- en: On the other hand, MIMD can be divided into machines that have a shared memoryand
    those that have a distributed memory.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，MIMD可以分为具有共享内存的机器和具有分布式内存的机器。
- en: Indeed the next section focuses on this last aspect of the organization of the
    memory of MIMD machines.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，下一节将重点介绍MIMD机器内存组织的最后一个方面。
- en: Memory organization
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存组织
- en: Another aspect that we need to consider in order to evaluate parallel architectures
    is memory organization, or rather, the way in which data is accessed. No matter
    how fast the processing unit is, if memory cannot maintain and provide instructions
    and data at a sufficient speed, then there will be no improvement in performance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估并行架构，我们需要考虑的另一个方面是内存组织，或者说数据访问的方式。无论处理单元有多快，如果内存不能以足够的速度维护和提供指令和数据，那么性能就不会有所提高。
- en: The main problem that we need to overcome to make the response time of memory
    compatible with the speed of the processor is the memory cycle time, which is
    defined as the time that has elapsed between two successive operations. The cycle
    time of the processor is typically much shorter than the cycle time of memory.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要克服的主要问题，使内存的响应时间与处理器的速度相匹配，是内存周期时间，它定义为两次连续操作之间经过的时间。处理器的周期时间通常比内存的周期时间短得多。
- en: 'When a processor initiates a transfer to or from memory, the processor''s resources
    will remain occupied for the entire duration of the memory cycle; furthermore,
    during this period, no other device (for example, I/O controller, processor, or
    even the processor that made the request) will be able to use the memory due to
    the transfer in progress:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理器启动对内存的传输时，处理器的资源将在整个内存周期内保持占用；此外，在此期间，由于正在进行的传输，没有任何其他设备（例如，I/O控制器、处理器或甚至请求该资源的处理器）能够使用内存：
- en: '![](img/d56ae362-cff1-4d47-97aa-78419437b2b7.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d56ae362-cff1-4d47-97aa-78419437b2b7.png)'
- en: Memory organization in the MIMD architecture
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: MIMD架构中的内存组织
- en: Solutions to the problem of memory access have resulted in a dichotomy of MIMD
    architectures. The first type of system, known as the *shared memory* system,
    has high virtual memory and all processors have equal access to data and instructions
    in this memory. The other type of system is the ***distributed memory*** model,
    wherein each processor has local memory that is not accessible to other processors.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 解决内存访问问题的解决方案导致了MIMD架构的二分法。第一种系统，称为*共享内存*系统，具有高虚拟内存，所有处理器都可以平等地访问该内存中的数据和指令。另一种系统是***分布式内存***模型，其中每个处理器都有本地内存，其他处理器无法访问。
- en: What distinguishes memory shared by distributed memory is the management of
    memory access, which is performed by the processing unit; this distinction is
    very important for programmers because it determines how different parts of a
    parallel program must communicate.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式内存共享内存的特点是内存访问的管理，这由处理单元执行；这种区别对于程序员来说非常重要，因为它决定了并行程序的不同部分必须如何通信。
- en: In particular, a distributed memory machine must make copies of shared data
    in each local memory. These copies are created by sending a message containing
    the data to be shared from one processor to another. A drawback of this memory
    organization is that, sometimes, these messages can be very large and take a relatively
    long time to transfer, while in a shared memory system, there is no exchange of
    messages, and the main problem lies in synchronizing access to shared resources.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，分布式内存机器必须在每个本地内存中复制共享数据。这些副本是通过从一个处理器向另一个处理器发送包含要共享的数据的消息来创建的。这种内存组织的缺点是，有时这些消息可以非常大，并且需要相对较长的时间来传输，而在共享内存系统中，没有消息交换，主要问题在于同步访问共享资源。
- en: Shared memory
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享内存
- en: 'The schema of a shared memory multiprocessor system is shown in the following
    diagram. The physical connections here are quite simple:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了共享内存多处理器系统的架构。这里的物理连接相当简单：
- en: '![](img/0f53e868-04c0-4493-9b33-f9be28089ca2.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0f53e868-04c0-4493-9b33-f9be28089ca2.png)'
- en: Shared memory architecture schema
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 共享内存架构图
- en: Here, the bus structure allows an arbitrary number of devices (**CPU** + **C****ache**
    in the preceding diagram) that share the same channel (**Main Memory**, as shown
    in the preceding diagram). The bus protocols were originally designed to allow
    a single processor and one or more disks or tape controllers to communicate through
    the shared memory here.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，总线结构允许任意数量的设备（如图中所示的前一个图中**CPU** + **Cache**）共享相同的通道（**主内存**，如图中所示的前一个图）。总线协议最初是为了允许单个处理器和一台或多台磁盘或磁带控制器通过这里的共享内存进行通信而设计的。
- en: Each processor has been associated with cache memory, as it is assumed that
    the probability that a processor needs to have data or instructions present in
    the local memory is very high.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 每个处理器都关联了缓存内存，因为假设处理器需要将数据或指令保留在本地内存中的概率非常高。
- en: The problem occurs when a processor modifies data stored in the memory system
    that is simultaneously used by other processors. The new value will pass from
    the processor cache that has been changed to the shared memory. Later, however,
    it must also be passed to all the other processors, so that they do not work with
    the obsolete value. This problem is known as the problem of *cache coherency*—a
    special case of the problem of memory consistency, which requires hardware implementations
    that can handle concurrency issues and synchronization, similar to that of thread
    programming.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理器修改其他处理器同时使用的内存系统中存储的数据时，问题就出现了。新的值将从已更改的处理器缓存传递到共享内存。然而，稍后它还必须传递给所有其他处理器，以便它们不与过时的值一起工作。这个问题被称为*缓存一致性*问题——这是内存一致性问题的特例，它需要能够处理并发问题和同步的硬件实现，类似于线程编程。
- en: 'The main features of shared memory systems are as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 共享内存系统的主要特点如下：
- en: The memory is the same for all processors. For example, all the processors associated
    with the same data structure will work with the same logical memory addresses,
    thus accessing the same memory locations.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有处理器的内存都是相同的。例如，所有与相同数据结构相关的处理器都将使用相同的逻辑内存地址，从而访问相同的内存位置。
- en: The synchronization is obtained by reading the tasks of various processors and
    allowing the shared memory. In fact, the processors can only access one memory
    at a time.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过读取各种处理器的任务并允许共享内存来获得同步。实际上，处理器一次只能访问一个内存。
- en: A shared memory location must not be changed from a task while another task
    accesses it.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在另一个任务访问它时，共享内存位置不得从任务中更改。
- en: Sharing data between tasks is fast. The time required to communicate is the
    time that one of them takes to read a single location (depending on the speed
    of memory access).
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任务之间共享数据非常快。所需通信的时间是其中一个任务读取单个位置所需的时间（取决于内存访问的速度）。
- en: 'The memory access in shared memory systems is as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 共享内存系统中的内存访问如下：
- en: '**Uniform Memory Access** (**UMA**): The fundamental characteristic of this
    system is the access time to the memory that is constant for each processor and
    for any area of memory. For this reason, these systems are also called **Symmetric
    Multiprocessors** (**SMPs**). They are relatively simple to implement, but not
    very scalable. The coder is responsible for the management of the synchronization
    by inserting appropriate controls, semaphores, locks, and more in the program
    that manages resources.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统一内存访问**（**UMA**）：该系统的基本特征是每个处理器和任何内存区域的访问时间都是恒定的。因此，这些系统也被称为**对称多处理器**（**SMPs**）。它们相对容易实现，但可扩展性不强。程序员负责通过在管理资源的程序中插入适当的控制、信号量、锁等来管理同步。'
- en: '**Non-Uniform Memory Access** (**NUMA**): These architectures divide the memory
    into high-speed access area that is assigned to each processor, and also, a common
    area for the data exchange, with slower access. These systems are also called
    **Distributed Shared Memory** (**DSM**) systems. They are very scalable, but complex
    to develop.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非统一内存访问**（**NUMA**）：这些架构将内存划分为分配给每个处理器的**高速访问区域**，以及用于数据交换的**公共区域**，访问速度较慢。这些系统也被称为**分布式共享内存**（**DSM**）系统。它们可扩展性很强，但开发复杂。'
- en: '**No Remote Memory Access** (**NoRMA**): The memory is physically distributed
    among the processors (local memory). All local memories are private and can only
    access the local processor. The communication between the processors is through
    a communication protocol used for exchanging messages, which is known as the *message-passing
    protocol*.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无远程内存访问**（**NoRMA**）：内存物理上分布在处理器之间（本地内存）。所有本地内存都是私有的，只能访问本地处理器。处理器之间的通信是通过用于交换消息的通信协议进行的，这被称为**消息传递协议**。'
- en: '**Cache-Only Memory Architecture** (**COMA**): These systems are equipped with
    only cached memories. While analyzing NUMA architectures, it was noticed that
    this architecture kept the local copies of the data in the cache and that this
    data was stored as duplicates in the main memory. This architecture removes duplicates
    and keeps only the cached memories; the memory is physically distributed among
    the processors (local memory). All local memories are private and can only access
    the local processor. The communication between the processors is also through
    the message-passing protocol.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅缓存内存架构**（**COMA**）：这些系统只配备了缓存内存。在分析NUMA架构时，注意到这种架构将数据的本地副本存储在缓存中，并且这些数据在主内存中以副本的形式存储。这种架构消除了副本，只保留缓存内存；内存物理上分布在处理器之间（本地内存）。所有本地内存都是私有的，只能访问本地处理器。处理器之间的通信也是通过消息传递协议进行的。'
- en: Distributed memory
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式内存
- en: 'In a system with distributed memory, the memory is associated with each processor
    and a processor is only able to address its own memory. Some authors refer to
    this type of system as a multicomputer, reflecting the fact that the elements
    of the system are, themselves, small and complete systems of a processor and memory,
    as you can see in the following diagram:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有分布式内存的系统中，内存与每个处理器相关联，处理器只能访问其自己的内存。一些作者将这种类型的系统称为多计算机，反映了系统元素本身是小型且完整的处理器和内存系统的事实，如下面的图所示：
- en: '![](img/edbcb72a-7807-4dba-97da-a1e69af3c29d.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/edbcb72a-7807-4dba-97da-a1e69af3c29d.png)'
- en: The distributed memory architecture schema
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式内存架构方案
- en: 'This kind of organization has several advantages:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这种组织方式有几个优点：
- en: There are no conflicts at the level of the communication bus or switch. Each
    processor can use the full bandwidth of their own local memory without any interference
    from other processors.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在通信总线或交换机层面没有冲突。每个处理器都可以使用其本地内存的全部带宽，而不会受到其他处理器的干扰。
- en: The lack of a common bus means that there is no intrinsic limit to the number
    of processors. The size of the system is only limited by the network used to connect
    the processors.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有公共总线意味着处理器数量的内在限制。系统的规模仅受连接处理器的网络大小限制。
- en: There are no problems with cache coherency. Each processor is responsible for
    its own data and does not have to worry about upgrading any copies.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有缓存一致性方面的问题。每个处理器负责其自己的数据，不必担心升级任何副本。
- en: 'The main disadvantage is that communication between processors is more difficult
    to implement. If a processor requires data in the memory of another processor,
    then the two processors should not necessarily exchange messages via the message-passing
    protocol. This introduces two sources of slowdown: to build and send a message
    from one processor to another takes time, and also, any processor should be stopped
    in order to manage the messages received from other processors. A program designed
    to work on a distributed memory machine must be organized as a set of independent
    tasks that communicate via messages:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 主要缺点是处理器之间的通信更难实现。如果一个处理器需要另一个处理器的内存中的数据，那么这两个处理器不一定要通过消息传递协议交换消息。这引入了两个减速源：从一个处理器向另一个处理器构建和发送消息需要时间，而且，任何处理器都应该停止以管理从其他处理器接收到的消息。设计用于在分布式内存机器上工作的程序必须组织成一组独立任务，这些任务通过消息进行通信：
- en: '![](img/6174b7b7-c606-48e1-a585-3412e6d542c7.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6174b7b7-c606-48e1-a585-3412e6d542c7.png)'
- en: Basic message passing
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 基本消息传递
- en: 'The main features of distributed memory systems are as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式内存系统的主要特点如下：
- en: Memory is physically distributed between processors; each local memory is directly
    accessible only by its processor.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存在处理器之间物理分布；每个本地内存只能由其处理器直接访问。
- en: Synchronization is achieved by moving data (even if it's just the message itself)
    between processors (communication).
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在处理器之间移动数据（即使只是消息本身）来实现同步。
- en: The subdivision of data in the local memories affects the performance of the
    machine—it is essential to make subdivisions accurate, so as to minimize the communication
    between the CPUs. In addition to this, the processor that coordinates these operations
    of decomposition and composition must effectively communicate with the processors
    that operate on the individual parts of data structures.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据在本地内存中的细分会影响机器的性能——确保细分准确是至关重要的，以便最小化CPU之间的通信。此外，协调这些分解和组合操作的处理器必须有效地与操作数据结构各个部分的处理器进行通信。
- en: The message-passing protocol is used so that the CPUs can communicate with each
    other through the exchange of data packets. The messages are discrete units of
    information, in the sense that they have a well-defined identity, so it is always
    possible to distinguish them from each other.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用消息传递协议，以便CPU可以通过交换数据包相互通信。消息是离散的信息单元，从它们有明确的身份这一意义上说，它们总是可以相互区分。
- en: Massively Parallel Processing (MPP)
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大规模并行处理（MPP）
- en: MPP machines are composed of hundreds of processors (which can be as large as
    hundreds of thousands of processors in some machines) that are connected by a
    communication network. The fastest computers in the world are based on these architectures;
    some examples of these architecture systems are Earth Simulator, Blue Gene, ASCI
    White, ASCI Red, and ASCI Purple and Red Storm.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: MPP机器由数百个处理器（在某些机器中，处理器数量可以高达数十万个）组成，这些处理器通过通信网络连接。世界上最快的计算机基于这些架构；这些架构系统的例子包括地球模拟器、蓝基因、ASCI
    White、ASCI Red、ASCI Purple和Red Storm。
- en: Clusters of workstations
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作站集群
- en: These processing systems are based on classical computers that are connected
    by communication networks. Computational clusters fall into this classification.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些处理系统基于通过通信网络连接的经典计算机。计算集群属于这一分类。
- en: In a cluster architecture, we define a node as a single computing unit that
    takes part in the cluster. For the user, the cluster is fully transparent—all
    the hardware and software complexity is masked and data and applications are made
    accessible as if they were all from a single node.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群架构中，我们将节点定义为参与集群的单个计算单元。对于用户来说，集群是完全透明的——所有硬件和软件的复杂性都被掩盖，数据和应用程序都可以像来自单个节点一样访问。
- en: 'Here, we''ve identified three types of clusters:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经确定了三种类型的集群：
- en: '**Fail-over cluster**: In this, the node''s activity is continuously monitored,
    and when one stops working, another machine takes over the charge of those activities.
    The aim is to ensure a continuous service due to the redundancy of the architecture.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**故障转移集群**：在这种情况下，节点的活动会持续监控，当某个节点停止工作时，另一台机器将接管这些活动的责任。目的是通过架构的冗余确保连续的服务。'
- en: '**Load balancing cluster**: In this system, a job request is sent to the node
    that has less activity. This ensures that less time is taken to process the job.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡集群**：在这个系统中，任务请求被发送到活动较少的节点。这确保了处理任务所需的时间更少。'
- en: '**High-performance computing cluster**: In this, each node is configured to
    provide extremely high performance. The process is also divided into multiple
    jobs on multiple nodes. The jobs are parallelized and will be distributed to different
    machines.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高性能计算集群**：在这个集群中，每个节点都配置为提供极高的性能。过程也被划分为多个节点上的多个任务。任务被并行化，并将被分配到不同的机器上。'
- en: Heterogeneous architectures
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异构架构
- en: 'The introduction of GPU accelerators in the homogeneous world of supercomputing
    has changed the nature of how supercomputers are both used and programmed now.
    Despite the high performance offered by GPUs, they cannot be considered as an
    autonomous processing unit as they should always be accompanied by a combination
    of CPUs. The programming paradigm, therefore, is very simple: the CPU takes control
    and computes in a serial manner, assigning tasks to the graphics accelerator that
    are, computationally, very expensive and have a high degree of parallelism.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在同构的超级计算世界中引入GPU加速器已经改变了超级计算机的使用和编程的本质。尽管GPU提供了高性能，但它们不能被视为一个自主的处理单元，因为它们应该始终伴随着CPU的组合。因此，编程范式非常简单：CPU接管控制并以串行方式计算，将计算成本高且具有高度并行性的任务分配给图形加速器。
- en: The communication between a CPU and a GPU can take place, not only through the
    use of a high-speed bus but also through the sharing of a single area of memory
    for both physical or virtual memory. In fact, in the case where both the devices
    are not equipped with their own memory areas, it is possible to refer to a common
    memory area using the software libraries provided by the various programming models,
    such as *CUDA* and *OpenCL*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: CPU和GPU之间的通信不仅可以通过使用高速总线进行，还可以通过共享物理或虚拟内存的单个区域进行。实际上，在两种设备都没有配备自己的内存区域的情况下，可以使用由各种编程模型（如*CUDA*和*OpenCL*）提供的软件库来引用一个公共内存区域。
- en: These architectures are called *heterogeneous architectures*, wherein applications
    can create data structures in a single address space and send a job to the device
    hardware, which is appropriate for the resolution of the task. Several processing
    tasks can operate safely in the same regions to avoid data consistency problems,
    thanks to the atomic operations.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些架构被称为*异构架构*，其中应用程序可以在单个地址空间中创建数据结构，并将任务发送到设备硬件，这对于任务的解决是合适的。由于原子操作，几个处理任务可以在同一区域安全地运行，以避免数据一致性问题的发生。
- en: 'So, despite the fact that the CPU and GPU do not seem to work efficiently together,
    with the use of this new architecture, we can optimize their interaction with,
    and the performance of, parallel applications:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管CPU和GPU看起来似乎没有高效地协同工作，但使用这种新的架构，我们可以优化它们与并行应用程序的交互以及性能：
- en: '![](img/46dac58e-d70e-4177-bc35-1018279093a9.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/46dac58e-d70e-4177-bc35-1018279093a9.png)'
- en: The heterogeneous architecture schema
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 异构架构方案
- en: In the following section, we introduce the main parallel programming models.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍主要的并行编程模型。
- en: Parallel programming models
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行编程模型
- en: Parallel programming models exist as an abstraction of hardware and memory architectures.
    In fact, these models are not specific and do not refer to any particular types
    of machines or memory architectures. They can be implemented (at least theoretically)
    on any kind of machines. Compared to the previous subdivisions, these programming
    models are made at a higher level and represent the way in which the software
    must be implemented to perform parallel computation. Each model has its own way
    of sharing information with other processors in order to access memory and divide
    the work.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 并行编程模型作为硬件和内存架构的抽象而存在。实际上，这些模型并不特定，也不指向任何特定的机器或内存架构。它们可以在任何类型的机器上实现（至少在理论上）。与之前的细分相比，这些编程模型在更高的层面上进行，代表了软件必须以何种方式实现以执行并行计算。每个模型都有其与其它处理器共享信息的方式，以便访问内存并分配工作。
- en: 'In absolute terms, no one model is better than the other. Therefore, the best
    solution to be applied will depend very much on the problem that a programmer
    should address and resolve. The most widely used models for parallel programming
    are as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 从绝对意义上讲，没有一种模型比另一种更好。因此，最佳解决方案将非常依赖于程序员应该解决和解决的问题。最广泛使用的并行编程模型如下：
- en: Shared memory model
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享内存模型
- en: Multithread model
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多线程模型
- en: Distributed memory/message passing model
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式内存/消息传递模型
- en: Data-parallel model
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据并行模型
- en: In this recipe, we will give you an overview of these models.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将为您概述这些模型。
- en: Shared memory model
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享内存模型
- en: In this model, tasks share a single memory area in which we can read and write
    asynchronously. There are mechanisms that allow the coder to control the access
    to the shared memory; for example, locks or semaphores. This model offers the
    advantage that the coder does not have to clarify the communication between tasks.
    An important disadvantage, in terms of performance, is that it becomes more difficult
    to understand and manage data locality. This refers to keeping data local to the
    processor that works on conserving memory access, cache refreshes, and bus traffic
    that occurs when multiple processors use the same data.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，任务共享一个单一的内存区域，我们可以异步地读取和写入。有机制允许编码者控制对共享内存的访问；例如，锁或信号量。这种模型的优势在于编码者不必明确任务间的通信。从性能的角度来看，一个重要的缺点是它变得难以理解和管理数据局部性。这指的是将数据保留在处理器的本地，以节省内存访问、缓存刷新和当多个处理器使用相同数据时发生的总线流量。
- en: Multithread model
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程模型
- en: In this model, a process can have multiple flows of execution. For example,
    a sequential part is created and, subsequently, a series of tasks are created
    that can be executed in parallel. Usually, this type of model is used on shared
    memory architectures. So, it will be very important for us to manage the synchronization
    between threads, as they operate on shared memory, and the programmer must prevent
    multiple threads from updating the same locations at the same time.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，一个进程可以有多个执行流。例如，创建一个顺序部分，随后创建一系列可以并行执行的任务。通常，这种类型的模型用于共享内存架构。因此，对于我们来说，管理线程之间的同步非常重要，因为它们在共享内存上操作，程序员必须防止多个线程同时更新同一位置。
- en: The current-generation CPUs are multithreaded in software and hardware. **POSIX**
    (short for **Portable Operating System Interface**) threads are classic examples
    of the implementation of multithreading on software. Intel's Hyper-Threading technology
    implements multithreading on hardware by switching between two threads when one
    is stalled or waiting on I/O. Parallelism can be achieved from this model, even
    if the data alignment is nonlinear.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 当代CPU在软件和硬件层面都支持多线程。**POSIX**（即**可移植操作系统接口**）线程是软件层面实现多线程的典型例子。英特尔Hyper-Threading技术通过在某个线程停滞或等待I/O时切换到另一个线程，在硬件层面实现多线程。即使数据对齐是非线性的，从这个模型中也可以实现并行性。
- en: Message passing model
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息传递模型
- en: The message passing model is usually applied in cases where each processor has
    its own memory (distributed memory system). More tasks can reside on the same
    physical machine or on an arbitrary number of machines. The coder is responsible
    for determining the parallelism and data exchange that occurs through the messages,
    and it is necessary to request and call a library of functions within the code.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递模型通常应用于每个处理器都有自己的内存（分布式内存系统）的情况。更多的任务可以驻留在同一台物理机器上或任意数量的机器上。编码者负责确定通过消息发生的并行性和数据交换，并且需要在代码中请求和调用函数库。
- en: Some of the examples have been around since the 1980s, but only in the mid-1990s
    was a standardized model created, leading to a de facto standard called a **Message
    Passing Interface **(**MPI**).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一些例子自1980年代以来就存在，但直到1990年代中期才创建了一个标准化的模型，从而产生了被称为**消息传递接口**（**MPI**）的事实上的标准。
- en: 'The MPI model is clearly designed with distributed memory, but being models
    of parallel programming, a multiplatform model can also be used with a shared
    memory machine:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: MPI模型显然是为分布式内存设计的，但作为并行编程的模型，多平台模型也可以与共享内存机器一起使用：
- en: '![](img/bd5deb5a-ea45-42d8-ba4e-b7852b6e0fcd.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/bd5deb5a-ea45-42d8-ba4e-b7852b6e0fcd.png)'
- en: Message passing paradigm model
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递范式模型
- en: Data-parallel model
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据并行模型
- en: In this model, we have more tasks that operate on the same data structure, but
    each task operates on a different portion of data. In the shared memory architecture,
    all tasks have access to data through shared memory and distributed memory architectures,
    where the data structure is divided and resides in the local memory of each task.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在此模型中，我们拥有更多在相同数据结构上操作的任务，但每个任务操作的是数据的不同部分。在共享内存架构中，所有任务都通过共享内存和分布式内存架构访问数据，其中数据结构被分割并驻留在每个任务的本地内存中。
- en: 'To implement this model, a coder must develop a program that specifies the
    distribution and alignment of data; for example, the current-generation GPUs are
    highly operational only if data (**Task** **1**, **Task** **2**, **Task** **3**)
    is aligned, as shown in the following diagram:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现此模型，编码者必须开发一个程序，该程序指定了数据的分布和对齐；例如，当前一代GPU只有在数据（**任务** **1**、**任务** **2**、**任务**
    **3**）对齐时才能高效运行，如下面的图所示：
- en: '![](img/93cf041f-f65b-46e5-b36d-59d4ed537910.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/93cf041f-f65b-46e5-b36d-59d4ed537910.png)'
- en: The data-parallel paradigm model
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行范式模型
- en: Designing a parallel program
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计并行程序
- en: 'The design of algorithms that exploit parallelism is based on a series of operations,
    which must be carried out for the program to perform the job correctly without
    producing partial or erroneous results. The macro operations that must be carried
    out for a correct parallelization of an algorithm are as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 利用并行性的算法设计基于一系列操作，这些操作必须执行，以便程序能够正确执行任务而不会产生部分或错误的结果。为了正确并行化一个算法，必须执行以下宏观操作：
- en: Task decomposition
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务分解
- en: Task assignment
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务分配
- en: Agglomeration
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚合
- en: Mapping
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 映射
- en: Task decomposition
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务分解
- en: 'In this first phase, the software program is split into tasks or a set of instructions
    that can then be executed on different processors to implement parallelism. To
    perform this subdivision, two methods are used:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个第一阶段，软件程序被分割成任务或一组指令，然后可以在不同的处理器上执行以实现并行化。为了执行这种细分，使用了两种方法：
- en: '**Domain decomposition**: Here, the data of the problems is decomposed. The
    application is common to all the processors that work on different portions of
    data. This methodology is used when we have a large amount of data that must be
    processed.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**域分解**：在此，问题的数据被分解。该应用对所有在数据的不同部分上工作的处理器都是通用的。当我们必须处理大量数据时，我们使用这种方法。'
- en: '**Functional decomposition**: In this case, the problem is split into tasks,
    where each task will perform a particular operation on all the available data.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**功能分解**：在这种情况下，问题被分割成任务，每个任务将对所有可用数据进行特定的操作。'
- en: Task assignment
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务分配
- en: In this step, the mechanism by which the tasks will be distributed among the
    various processes is specified. This phase is very important because it establishes
    the distribution of workload among the various processors. Load balancing is crucial
    here; in fact, all processors must work with continuity, avoiding being in an
    idle state for a long time.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，指定了任务将在各个进程之间如何分配的机制。这一阶段非常重要，因为它建立了不同处理器之间的工作负载分配。负载均衡在这里至关重要；实际上，所有处理器都必须连续工作，避免长时间处于空闲状态。
- en: To perform this, the coder takes into account the possible heterogeneity of
    the system that tries to assign more tasks to better-performing processors. Finally,
    for greater efficiency of parallelization, it is necessary to limit communication
    as much as possible between processors, as they are often the source of slowdowns
    and consumption of resources.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行此操作，编码者会考虑到系统可能的异构性，并尝试将更多任务分配给性能更好的处理器。最后，为了提高并行化的效率，有必要尽可能减少处理器之间的通信，因为它们往往是减速和资源消耗的来源。
- en: Agglomeration
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚合
- en: Agglomeration is the process of combining smaller tasks with larger ones in
    order to improve performance. If the previous two stages of the design process
    partitioned the problem into a number of tasks that greatly exceed the number
    of processors available, and if the computer is not specifically designed to handle
    a huge number of small tasks (some architectures, such as GPUs, handle this fine
    and indeed benefit from running millions, or even billions, of tasks), then the
    design can turn out to be highly inefficient.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合是将较小的任务与较大的任务结合起来的过程，以提高性能。如果设计过程的先前两个阶段将问题分割成远超过可用处理器数量的任务，并且如果计算机没有专门设计来处理大量的小任务（一些架构，如GPU，处理这些任务很好，并且确实从运行数百万甚至数十亿的任务中受益），那么设计可能会非常低效。
- en: Commonly, this is because tasks have to be communicated to the processor or
    thread so that they compute the said task. Most communications have costs that
    are disproportionate to the amount of data transferred, but also incur a fixed
    cost for every communication operation (such as the latency, which is inherent
    in setting up a TCP connection). If the tasks are too small, then this fixed cost
    can easily make the design inefficient.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这是因为任务需要传达给处理器或线程，以便它们计算所述任务。大多数通信的成本与传输的数据量不成比例，但每次通信操作（如设置TCP连接时固有的延迟）都会产生固定成本。如果任务太小，那么这种固定成本很容易使设计变得低效。
- en: Mapping
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 映射
- en: 'In the mapping stage of the parallel algorithm design process, we specify where
    each task is to be executed. The goal is to minimize the total execution time.
    Here, you must often make trade-offs, as the two main strategies often conflict
    with each other:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行算法设计过程的映射阶段，我们指定每个任务将在何处执行。目标是使总执行时间最小化。在这里，你通常必须做出权衡，因为两种主要策略往往相互冲突：
- en: The tasks that communicate frequently should be placed in the same processor
    to increase locality.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该将频繁通信的任务放置在同一处理器中，以增加局部性。
- en: The tasks that can be executed concurrently should be placed in different processors
    to enhance concurrency.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该将可以并发执行的任务放置在不同的处理器中，以增强并发性。
- en: This is known as the *mapping problem*, and it is known to be **NP-complete**.
    As such, no polynomial-time solutions to the problem in the general case exist.
    For tasks of equal size and tasks with easily identified communication patterns,
    the mapping is straightforward (we can also perform agglomeration here to combine
    tasks that map to the same processor). However, if the tasks have communication
    patterns that are hard to predict or the amount of work varies per task, then
    it is hard to design an efficient mapping and agglomeration scheme.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为*映射问题*，并且已知它是**NP完全**的。因此，在一般情况下，不存在该问题的多项式时间解。对于大小相等且具有易于识别的通信模式的任务，映射是直接的（我们也可以在这里进行聚簇，以将映射到同一处理器的任务组合在一起）。然而，如果任务的通信模式难以预测或每个任务的工作量不同，那么设计一个有效的映射和聚簇方案就很难。
- en: For these types of problems, load balancing algorithms can be used to identify
    agglomeration and mapping strategies during runtime. The hardest problems are
    those in which the amount of communication or the number of tasks changes during
    the execution of the program. For these kinds of problems, dynamic load balancing
    algorithms can be used, which run periodically during the execution.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这类问题，可以在运行时使用负载均衡算法来识别聚簇和映射策略。最困难的问题是那些在程序执行过程中通信量或任务数量发生变化的问题。对于这类问题，可以使用动态负载均衡算法，这些算法在执行期间定期运行。
- en: Dynamic mapping
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态映射
- en: 'Numerous load balancing algorithms exist for a variety of problems:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于各种问题，存在许多负载均衡算法：
- en: '**Global algorithms**: These require global knowledge of the computation being
    performed, which often adds a lot of overhead.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局算法**：这些算法需要全局了解正在进行的计算，这通常会增加很多开销。'
- en: '**Local algorithms**: These rely only on information that is local to the task
    in question, which reduces overhead compared to global algorithms, but they are
    usually worse at finding optimal agglomeration and mapping.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地算法**：这些算法仅依赖于与所讨论任务局部相关的信息，与全局算法相比，这降低了开销，但它们通常在寻找最佳聚簇和映射方面表现较差。'
- en: However, the reduced overhead may reduce the execution time, even though the
    mapping is worse by itself. If the tasks rarely communicate other than at the
    start and end of the execution, then a task-scheduling algorithm is often used,
    which simply maps tasks to processors as they become idle. In a task-scheduling
    algorithm, a task pool is maintained. Tasks are placed in this pool and are taken
    from it by workers.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，降低开销可能会减少执行时间，尽管映射本身可能更差。如果任务很少在执行的开始和结束时进行通信，那么通常会使用任务调度算法，该算法简单地将任务映射到空闲的处理器。在任务调度算法中，维护一个任务池。任务被放置在这个池中，并由工作者从池中取出。
- en: 'There are three common approaches in this model:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中有三种常见的方法：
- en: '**Manager/worker: **This is the basic dynamic mapping scheme in which all the
    workers connect to a centralized manager. The manager repeatedly sends tasks to
    the workers and collects the results. This strategy is probably the best for a
    relatively small number of processors. The basic strategy can be improved by fetching
    tasks in advance so that communication and computation overlap each other.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理/工作员**：这是所有工作员连接到一个集中式管理员的基动态映射方案。管理员反复向工作员发送任务并收集结果。这种策略可能适用于相对较少的处理器。通过提前获取任务，可以改进基本策略，以便通信和计算重叠。'
- en: '**Hierarchical manager/worker**: This is the variant of a manager/worker that
    has a semi-distributed layout. Workers are split into groups, each with their
    own manager. These group managers communicate with the central manager (and possibly
    among themselves as well), while workers request tasks from the group managers.
    This spreads the load among several managers and can, as such, handle a larger
    number of processors if all workers request tasks from the same manager.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分层管理/工作员**：这是具有半分布式布局的管理员/工作员变体。工作员被分成组，每组都有自己的管理员。这些组管理员与中央管理员（以及可能彼此之间）通信，而工作员从组管理员那里请求任务。这样可以在几个管理员之间分散负载，并且可以处理更多的处理器，如果所有工作员都从同一个管理员那里请求任务。'
- en: '**Decentralize**: In this scheme, everything is decentralized. Each processor
    maintains its own task pool and communicates with the other processors in order
    to request tasks. How the processors choose other processors to request tasks
    varies and is determined on the basis of the problem.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**去中心化**：在这个方案中，一切都是去中心化的。每个处理器维护自己的任务池，并与其他处理器通信以请求任务。处理器如何选择其他处理器来请求任务各不相同，并且基于问题来确定。'
- en: Evaluating the performance of a parallel program
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估并行程序的性能
- en: The development of parallel programming created the need for performance metrics
    in order to decide whether its use is convenient or not. Indeed, the focus of
    parallel computing is to solve large problems in a relatively short period of
    time. The factors contributing to this objective are, for example, the type of
    hardware used, the degree of parallelism of the problem, and the parallel programming
    model adopted. To facilitate this, the analysis of basic concepts was introduced,
    which compares the parallel algorithm obtained from the original sequence.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 并行编程的发展产生了对性能指标的需求，以便决定其使用是否方便。事实上，并行计算的重点是在相对较短的时间内解决大型问题。有助于实现这一目标的因素包括，例如，使用的硬件类型、问题的并行程度以及采用的并行编程模型。为了便于此，引入了基本概念的分析，它比较了从原始序列获得的并行算法。
- en: 'The performance is achieved by analyzing and quantifying the number of threads
    and/or the number of processes used. To analyze this, let''s introduce a few performance
    indexes:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析和量化使用的线程数和/或进程数来实现性能。为了分析这一点，让我们引入一些性能指标：
- en: '**Speedup**'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加速**'
- en: '**Efficiency**'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**'
- en: '**Scaling**'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展性**'
- en: The limitations of parallel computation are introduced by **Amdahl**'s law.
    To evaluate the *degree of efficiency* of the parallelization of a sequential
    algorithm, we have **Gustafson**'s law.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 并行计算的局限性是由**阿姆达尔定律**引入的。为了评估顺序算法并行化的**效率程度**，我们有**古斯塔夫森定律**。
- en: Speedup
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加速
- en: The **speedup** is the measure that displays the benefit of solving a problem
    in parallel. It is defined as the ratio of the time taken to solve a problem on
    a single processing element (*Ts*) to the time required to solve the same problem
    on *p* identical processing elements (*Tp*).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速**是显示并行解决问题益处的度量。它定义为在单个处理元素（*Ts*）上解决问题所需的时间与在 *p* 个相同处理元素（*Tp*）上解决问题所需时间的比率。'
- en: 'We denote speedup as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如下表示加速：
- en: '![](img/d06f79cc-0130-4c88-9669-be45342198b8.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d06f79cc-0130-4c88-9669-be45342198b8.png)'
- en: We have a linear speedup, where if *S=p*, then it means that the speed of execution
    increases with the number of processors. Of course, this is an ideal case. While
    the speedup is absolute when *Ts* is the execution time of the best sequential
    algorithm, the speedup is relative when *Ts* is the execution time of the parallel
    algorithm for a single processor.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个线性加速，如果 *S=p*，这意味着执行速度会随着处理器数量的增加而增加。当然，这是一个理想的情况。当 *Ts* 是最佳顺序算法的执行时间时，加速是绝对的；当
    *Ts* 是单个处理器的并行算法的执行时间时，加速是相对的。
- en: 'Let''s recap these conditions:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾这些条件：
- en: '*S = p* is a linear or ideal speedup.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*S = p* 是线性或理想加速。'
- en: '*S < p* is a real speedup.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*S < p* 是一个真实加速。'
- en: '*S > p* is a superlinear speedup.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*S > p* 是一个超线性加速。'
- en: Efficiency
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 效率
- en: In an ideal world, a parallel system with *p* processing elements can give us
    a speedup that is equal to *p*. However, this is very rarely achieved. Usually,
    some time is wasted in either idling or communicating. Efficiency is a measure
    of how much of the execution time a processing element puts toward doing useful
    work, given as a fraction of the time spent.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个理想的世界里，具有 *p* 个处理单元的并行系统可以给我们一个等于 *p* 的加速。然而，这很少实现。通常，一些时间浪费在空闲或通信上。效率是衡量处理单元将多少执行时间用于有用工作的度量，表示为所花费时间的分数。
- en: 'We denote it by *E* and can define it as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用 *E* 来表示它，并可以如下定义：
- en: '![](img/a51cb8a0-063e-4177-a8e3-caa123753d53.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a51cb8a0-063e-4177-a8e3-caa123753d53.png)'
- en: 'The algorithms with linear speedup have a value of *E = 1*. In other cases,
    they have the value of *E* is less than *1*. The three cases are identified as
    follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 具有线性加速的算法其值为 *E = 1*。在其他情况下，它们的值小于 *1*。以下是对三种情况进行的识别：
- en: When *E = 1*, it is a linear case.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 *E = 1* 时，这是一个线性情况。
- en: When *E < 1*, it is a real case.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 *E < 1* 时，这是一个真实情况。
- en: When *E << 1*, it is a problem that is parallelizable with low efficiency.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 *E << 1* 时，这是一个低效率可并行化的问题。
- en: Scaling
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规模化
- en: Scaling is defined as the ability to be efficient on a parallel machine. It
    identifies the computing power (speed of execution) in proportion to the number
    of processors. By increasing the size of the problem and, at the same time, the
    number of processors, there will be no loss in terms of performance.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 规模化定义为在并行机器上保持效率的能力。它按处理器数量比例识别计算能力（执行速度）。通过增加问题的大小和同时增加处理器数量，在性能方面将不会有所损失。
- en: The scalable system, depending on the increments of the different factors, may
    maintain the same efficiency or improve it.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展的系统，根据不同因素的增量，可能保持相同的效率或提高效率。
- en: Amdahl's law
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阿姆达尔定律
- en: 'Amdahl''s law is a widely used law that is used to design processors and parallel
    algorithms. It states that the maximum speedup that can be achieved is limited
    by the serial component of the program:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 阿姆达尔定律是一个广泛使用的定律，用于设计处理器和并行算法。它指出，可以达到的最大加速比受程序串行部分限制：
- en: '![](img/d0ef21cb-ef7a-401d-990a-5a3b45325d05.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0ef21cb-ef7a-401d-990a-5a3b45325d05.png)'
- en: '*1 – P* denotes the serial component (not parallelized) of a program.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '*1 – P* 表示程序中（未并行化）的串行部分。'
- en: This means that, for example, if a program in which 90% of the code can be made
    parallel, but 10% must remain serial, then the maximum achievable speedup is 9,
    even for an infinite number of processors.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，例如，如果一个程序中90%的代码可以并行化，但10%必须保持串行，那么即使对于无限数量的处理器，最大可达到的加速比也是9。
- en: Gustafson's law
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 古斯塔夫森定律
- en: 'Gustafson''s law states the following:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 古斯塔夫森定律表述如下：
- en: '![](img/5b33302b-8561-4073-a6df-09072923e8f5.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b33302b-8561-4073-a6df-09072923e8f5.png)'
- en: 'Here, as we indicated in the equation the following applies:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，正如我们在方程中指出的，以下适用：
- en: '*P* is the *number of processors.*'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P* 是 *处理器数量*。'
- en: '*S* is the *speedup* factor.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*S* 是 *加速* 因子。'
- en: '*α* is the *non-parallelizable fraction* of any parallel process.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*α* 是任何并行过程中 *不可并行化部分*。'
- en: Gustafson's law is in cont*rast* to Amdahl's law, which, as we described, assumes
    that the overall workload of a program does not change with respect to the number
    of processors.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 古斯塔夫森定律与阿姆达尔定律形成对比，正如我们描述的那样，阿姆达尔定律假设程序的整体工作量不会随着处理器数量的增加而改变。
- en: In fact, Gustafson's law suggests that programmers first set the *time* allowed
    for solving a problem in parallel and then based on that (that is time) *to size*
    the problem. Therefore, the *faster* the parallel system is, the *greater* the
    problems that can be solved over the same period of time.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，古斯塔夫森定律建议程序员首先设定并行解决一个问题的 *时间*，然后基于这个（即时间）*来调整*问题的大小。因此，并行系统越快，在相同的时间内可以解决的问题就越多。
- en: The effect of Gustafson's law was to direct the objectives of computer research
    towards the selection or reformulation of problems in such a way that the solution
    of a larger problem would still be possible in the same amount of time. Furthermore,
    this law redefines the concept of *efficiency* as a need *to reduce at least the
    sequential part* of a program, despite the *increase in workload*.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 古斯塔夫森定律的影响是将计算机研究的目标指向选择或重新表述问题，以便在相同的时间内解决更大的问题仍然是可能的。此外，该定律重新定义了 *效率* 的概念，即需要
    *至少减少程序中的顺序部分*，尽管 *工作量增加*。
- en: Introducing Python
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Python
- en: 'Python is a powerful, dynamic, and interpreted programming language that is
    used in a wide variety of applications. Some of its features are as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Python是一种强大、动态和解释型编程语言，广泛应用于各种应用。其一些特性如下：
- en: A clear and readable syntax.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清晰且易于阅读的语法。
- en: A very extensive standard library, where, through additional software modules,
    we can add data types, functions, and objects.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个非常广泛的标准库，通过额外的软件模块，我们可以添加数据类型、函数和对象。
- en: Easy-to-learn rapid development and debugging. Developing Python code in Python
    can be up to 10 times faster than in C/C++ code. The code can also work as a prototype
    and then translated into C/C ++.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于学习的快速开发和调试。在Python中开发Python代码可以比在C/C++代码中快10倍。代码也可以作为原型，然后翻译成C/C++。
- en: Exception-based error handling.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于异常的错误处理。
- en: A strong introspection functionality.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强大的内省功能。
- en: The richness of documentation and a software community.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档的丰富性和软件社区。
- en: Python can be seen as a glue language. Using Python, better applications can
    be developed because different kinds of coders can work together on a project.
    For example, when building a scientific application, C/C++ programmers can implement
    efficient numerical algorithms, while scientists on the same project can write
    Python programs that test and use those algorithms. Scientists don't have to learn
    a low-level programming language and C/C++ programmers don't need to understand
    the science involved.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Python可以被视为一种粘合语言。使用Python，可以开发出更好的应用程序，因为不同类型的程序员可以一起在项目上工作。例如，在构建科学应用时，C/C++程序员可以实现高效的数值算法，而同一项目中的科学家可以编写Python程序来测试和使用这些算法。科学家不必学习低级编程语言，C/C++程序员也不需要理解涉及的科学。
- en: You can read more about this from [https://www.python.org/doc/essays/omg-darpa-mcc-position](https://www.python.org/doc/essays/omg-darpa-mcc-position).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[https://www.python.org/doc/essays/omg-darpa-mcc-position](https://www.python.org/doc/essays/omg-darpa-mcc-position)了解更多相关信息。
- en: Let's take a look at some examples of very basic code to get an idea of the
    features of Python.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些非常基本的代码示例，以了解Python的功能。
- en: The following section can be a refresher for most of you. We will use these
    techniques practically in [Chapter 2](c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml), *Thread-Based
    Parallelism*, and [Chapter 3](5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml), *Process-Based
    Parallelism*.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分可以成为大多数人的复习资料。我们将在第2章[基于线程的并行性](c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml)和第3章[基于进程的并行性](5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml)中实际使用这些技术。
- en: Help functions
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 帮助函数
- en: The Python interpreter already provides a valid help system. If you want to
    know how to use an object, then just type `help(object)`.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: Python解释器已经提供了一个有效的帮助系统。如果您想了解如何使用一个对象，只需键入`help(object)`。
- en: 'Let''s see, for example, how to use the `help` function on integer `0`:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们看看如何使用`help`函数在整数`0`上：
- en: '[PRE0]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The description of the `int` object is followed by a list of methods that are
    applicable to it. The first five methods are as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`对象的描述后面跟着一个适用于它的方法列表。前五种方法如下：'
- en: '[PRE1]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Also useful is `dir(object)`, which lists the methods available for an object:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 同样有用的是`dir(object)`，它列出了对象可用的方法：
- en: '[PRE2]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, the relevant documentation for an object is provided by the `.__doc__`
    function, as shown in the following example:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对象的相应文档由`.__doc__`函数提供，如下例所示：
- en: '[PRE3]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Syntax
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语法
- en: 'Python doesn''t adopt statement terminators, and code blocks are specified
    through indentation. Statements that expect an indentation level must end in a
    colon (`:`). This leads to the following:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: Python不采用语句终止符，代码块通过缩进来指定。需要缩进级别的语句必须以冒号（`:`）结尾。这导致以下情况：
- en: The Python code is clearer and more readable.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python代码更清晰、更易于阅读。
- en: The program structure always coincides with that of the indentation.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序结构始终与缩进一致。
- en: The style of indentation is uniform in any listing.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何列表中的缩进风格都是统一的。
- en: Bad indentation can lead to errors.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 错误的缩进可能导致错误。
- en: 'The following example shows how to use the `if` construct:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了如何使用`if`构造：
- en: '[PRE4]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In this example, we can see the following:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们可以看到以下内容：
- en: 'The following statements: `print("first print")`, `if condition:`, `print("third
    print")` have the same indentation level and are always executed.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下语句：`print("first print")`，`if condition:`，`print("third print")`具有相同的缩进级别，并且总是被执行。
- en: After the `if` statement, there is a block of code with a higher indentation
    level, which includes the `print ("second print")` statement.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`if`语句之后，有一个更高缩进级别的代码块，其中包含`print ("second print")`语句。
- en: If the condition of `if` is true, then the `print ("second print")` statement
    is executed.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`if`的条件为真，则执行`print ("second print")`语句。
- en: If the condition of `if` is false, then the `print ("second print")` statement
    is not executed.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`if`的条件为假，则不执行`print ("second print")`语句。
- en: It is, therefore, very important to pay attention to indentation because it
    is always evaluated in the program parsing process.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，注意缩进非常重要，因为在程序解析过程中始终会评估缩进。
- en: Comments
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注释
- en: 'Comments start with the hash sign (`#`) and are on a single line:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 注释以井号（`#`）开头，并且位于单行上：
- en: '[PRE5]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Multi-line strings are used for multi-line comments:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 多行字符串用于多行注释：
- en: '[PRE6]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Assignments
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 赋值
- en: Assignments are made with the equals symbol (`=`). For equality tests, the same
    amount (`==`) is used. You can increase and decrease a value using the `+=` and
    `-=` operators, followed by an addendum. This works with many types of data, including
    strings. You can assign and use multiple variables on the same line.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 使用等号（`=`）进行赋值。对于相等性测试，使用相同的量（`==`）。你可以使用`+=`和`-=`运算符增加和减少一个值，后面跟一个附加项。这适用于许多数据类型，包括字符串。你可以在同一行上赋值和使用多个变量。
- en: 'Some examples are as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 一些例子如下：
- en: '[PRE7]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Data types
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据类型
- en: 'The most significant structures in Python are *lists*, *tuples*,and *dictionaries*.
    Sets have been integrated into Python since version 2.5 (the previous versions
    are available in the `sets` library):'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: Python中最显著的结构是*列表*、*元组*和*字典*。集合自Python 2.5版本以来已集成（旧版本可在`sets`库中找到）：
- en: '**Lists**: These are similar to one-dimensional arrays, but you can create
    lists that contain other lists.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列表**：这些类似于一维数组，但你可以创建包含其他列表的列表。'
- en: '**Dictionaries**: These are arrays that contain key pairs and values (hash
    tables).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**字典**：这些是包含键值对的数组（哈希表）。'
- en: '**Tuples**: These are immutable mono-dimensional objects.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元组**：这些是不可变的单维对象。'
- en: Arrays can be of any type, so you can mix variables such as integers and strings
    into your lists, dictionaries and tuples.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 数组可以是任何类型，因此你可以将整数和字符串等变量混合到你的列表、字典和元组中。
- en: 'The index of the first object in any type of array is always zero. Negative
    indexes are allowed and count from the end of the array; `-1` indicates the last
    element of the array:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 任何类型数组的第一个对象的索引始终为零。允许使用负索引，并从数组的末尾开始计数；`-1`表示数组的最后一个元素：
- en: '[PRE8]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can get an array range using the colon (`:`):'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用冒号（`:`）获取数组范围：
- en: '[PRE9]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Strings
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字符串
- en: 'Python strings are indicated using either the single (`''`) or double (`"`)
    quotation mark and they are allowed to use one notation within a string delimited
    by the other:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Python字符串使用单引号（`'`）或双引号（`"`）表示，并且可以在由另一个分隔的字符串中使用一种表示法：
- en: '[PRE10]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'On multiple lines, they are enclosed in triple (or three single) quotation
    marks (`''''''` multi-line string `''''''`):'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在多行中，它们被三重引号（或三个单引号）包围（`'''`多行字符串`'''`）：
- en: '[PRE11]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Python also supports Unicode; just use the `u "This is a unicode string"` syntax
    :'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Python也支持Unicode；只需使用`u "This is a unicode string"`语法：
- en: '[PRE12]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To enter values in a string, type the `%` operator and a tuple. Then, each `%`
    operator is replaced by a tuple element, from left to right*:*
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 要在字符串中输入值，请输入`%`运算符和一个元组。然后，每个`%`运算符被从左到右的元组元素替换：*
- en: '[PRE13]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Flow control
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流控制
- en: Flow control instructions are `if`, `for`, and `while`.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 流控制指令是`if`、`for`和`while`。
- en: 'In the next example, we check whether the number is positive, negative, or
    zero and display the result:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个例子中，我们检查数字是正数、负数还是零，并显示结果：
- en: '[PRE14]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following code block finds the sum of all the numbers stored in a list,
    using a `for` loop:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块使用`for`循环找出存储在列表中的所有数字的总和：
- en: '[PRE15]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We will execute the `while` loop to iterate the code until the condition result
    is true. We will use this loop over the `for` loop since we are unaware of the
    number of iterations that will result in the code. In this example, we use `while`
    to add natural numbers up to *sum = 1+2+3+...+n*:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将执行`while`循环，直到条件结果为真来迭代代码。由于我们不知道迭代次数，我们将使用这个循环而不是`for`循环。在这个例子中，我们使用`while`来计算自然数之和`sum
    = 1+2+3+...+n`：
- en: '[PRE16]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The outputs for the preceding three examples are as follows:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 前三个示例的输出如下：
- en: '[PRE17]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Functions
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数
- en: 'Python functions are declared with the `def` keyword:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: Python函数使用`def`关键字声明：
- en: '[PRE18]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To run a function, use the function name, followed by parentheses, as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行一个函数，使用函数名称，后跟括号，如下所示：
- en: '[PRE19]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Parameters must be specified after the function name, inside the parentheses:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 参数必须在函数名之后、括号内指定：
- en: '[PRE20]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Multiple parameters must be separated with a comma:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 多个参数必须用逗号分隔：
- en: '[PRE21]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Use the equals sign to define a default parameter. If you call the function
    without the parameter, then the default value will be used:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 使用等号来定义默认参数。如果你不传递参数调用函数，则将使用默认值：
- en: '[PRE22]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The parameters of a function can be of any type of data (such as string, number,
    list, and dictionary). Here, the following list, `lcities`, is used as a parameter
    for `my_function`:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的参数可以是任何类型的数据（例如字符串、数字、列表和字典）。在这里，以下列表 `lcities` 被用作 `my_function` 的参数：
- en: '[PRE23]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Use the `return` statement to return a value from a function:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `return` 语句从函数返回一个值：
- en: '[PRE24]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Python supports an interesting syntax that allows you to define small, single-line
    functions on the fly. Derived from the Lisp programming language, these lambda
    functions can be used wherever a function is required.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: Python 支持一种有趣的语法，允许你即时定义小型、单行的函数。这些 lambda 函数源自 Lisp 编程语言，可以在需要函数的地方使用。
- en: 'An example of a lambda function, `functionvar`, is shown as follows:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 lambda 函数 `functionvar` 的示例如下所示：
- en: '[PRE25]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Classes
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类
- en: 'Python supports multiple inheritances of classes. Conventionally (not a language
    rule), private variables and methods are declared by being preceded with two underscores
    (`__`). We can assign arbitrary attributes (properties) to the instances of a
    class, as shown in the following example:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: Python 支持类的多重继承。传统上（不是语言规则），私有变量和方法通过在前面加上两个下划线（`__`）来声明。我们可以将任意属性（属性）分配给类的实例，如下例所示：
- en: '[PRE26]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Exceptions
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常
- en: 'Exceptions in Python are managed with `try-except` blocks (`exception_name`):'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: Python 中的异常通过 `try-except` 块（`exception_name`）来管理：
- en: '[PRE27]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Importing libraries
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入库
- en: 'External libraries are imported with `import [library name]`. Alternatively,
    you can use the `from [library name] import [function name]` syntax to import
    a specific function. Here is an example:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `import [library name]` 来导入外部库。或者，你可以使用 `from [library name] import [function
    name]` 语法来导入特定的函数。以下是一个示例：
- en: '[PRE28]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Managing files
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文件管理
- en: 'To allow us to interact with the filesystem, Python provides us with the built-in `open` function. This
    function can be invoked to open a file and return an object file. The latter allows
    us to perform various operations on the file, such as reading and writing. When
    we have finished interacting with the file, we must finally remember to close
    it by using the `file.close` method:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们能够与文件系统交互，Python 提供了内置的 `open` 函数。这个函数可以被调用以打开一个文件并返回一个文件对象。后者允许我们对文件执行各种操作，如读取和写入。当我们完成与文件的交互后，我们必须最后记得使用
    `file.close` 方法来关闭它：
- en: '[PRE29]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: List comprehensions
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列表推导式
- en: 'List comprehensions are a powerful tool for creating and manipulating lists.
    They consist of an expression that is followed by a `for` clause and then followed
    by zero, or more, `if` clauses. The syntax for list comprehensions is simply the
    following:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 列表推导式是创建和操作列表的有力工具。它们由一个表达式组成，后面跟着一个 `for` 子句，然后是一个或多个 `if` 子句。列表推导式的语法很简单，如下所示：
- en: '[PRE30]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, perform the following:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，执行以下操作：
- en: '[PRE31]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Running Python scripts
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行 Python 脚本
- en: 'To execute a Python script, simply invoke the Python interpreter followed by
    the script name, in this case, `my_pythonscript.py`. Or, if we are in a different
    working directory, then use its full address:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行 Python 脚本，只需调用 Python 解释器后跟脚本名称，在这种情况下，`my_pythonscript.py`。或者，如果我们处于不同的工作目录，则使用其完整地址：
- en: '[PRE32]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: From now on, for every invocation of a Python script, we will use the preceding
    notation; that is, `python`, followed by `script_name.py`, assuming that the directory
    from which the Python interpreter is launched is the one where the script to be
    execu*ted* resides.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，对于每次调用 Python 脚本，我们将使用前面的表示法；即，`python` 后跟 `script_name.py`，假设启动 Python
    解释器的目录是脚本要执行的目录。
- en: Installing Python packages using pip
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 pip 安装 Python 包
- en: '`pip` is a tool that allows us to search, download, and install Python packages
    found on the Python Package Index, which is a repository that contains tens of
    thousands of packages written in Python. This also allows us to manage the packages
    we have already downloaded, allowing us to update or remove them.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip` 是一个工具，允许我们搜索、下载和安装在 Python 包索引上找到的 Python 包，该索引是一个包含成千上万用 Python 编写的包的存储库。这也允许我们管理已下载的包，使我们能够更新或删除它们。'
- en: Installing pip
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 pip
- en: '`pip` is already included in Python versions ≥ 3.4 and ≥ 2.7.9\. To check whether
    this tool is already installed, we can run the following command:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip` 已经包含在 Python 版本 ≥ 3.4 和 ≥ 2.7.9 中。要检查此工具是否已安装，我们可以运行以下命令：'
- en: '[PRE33]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: If `pip` is already installed, then this command will show us the installed
    version.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `pip` 已经安装，则此命令将显示已安装的版本。
- en: Updating pip
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新 pip
- en: 'It is also recommended to check that the `pip` version you are using is always
    up to date. To update it, we can use the following command:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 建议检查您所使用的 `pip` 版本是否始终是最新的。要更新它，我们可以使用以下命令：
- en: '[PRE34]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Using pip
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 pip
- en: '`pip` supports a series of commands that allow us, among other things, to *search,
    download, install, update,* and *remove* packages.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip` 支持一系列命令，允许我们执行各种操作，包括 *搜索、下载、安装、更新* 和 *删除* 包。'
- en: 'To install `PACKAGE`, just run the following command:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 `PACKAGE`，只需运行以下命令：
- en: '[PRE35]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Introducing Python parallel programming
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Python 并行编程
- en: Python provides many libraries and frameworks that facilitate high-performance
    computations. However, doing parallel programming with Python can be quite insidious
    due to the **Global Interpreter Lock** (**GIL**).
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: Python 提供了许多库和框架，这些库和框架有助于高性能计算。然而，由于 **全局解释器锁**（**GIL**），使用 Python 进行并行编程可能会相当微妙。
- en: In fact, the most widespread and widely used Python interpreter, **CPython**,
    is developed in the C programming language. The CPython interpreter needs GIL
    for thread-safe operations. The use of GIL implies that you will encounter a global
    lock when you attempt to access any Python objects contained within threads. And
    only one thread at a time can acquire the lock for a Python object or C API.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，最广泛和最常用的 Python 解释器 **CPython** 是用 C 编程语言开发的。CPython 解释器需要 GIL 以进行线程安全操作。使用
    GIL 意味着当您尝试访问线程中包含的任何 Python 对象时，您将遇到全局锁。并且一次只有一个线程可以获取 Python 对象或 C API 的锁。
- en: Fortunately, things are not so serious, because, outside the realm of GIL, we
    can freely use parallelism. This category includes all the topics that we will
    discuss in the next chapters, including multiprocessing, distributed computing,
    and GPU computing.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，事情并没有那么严重，因为，在 GIL 的领域之外，我们可以自由地使用并行性。这一类别包括我们在下一章中将要讨论的所有主题，包括多进程、分布式计算和
    GPU 计算。
- en: So, Python is not really multithreaded. But what is a thread? What is a process?
    In the following sections, we will introduce these two fundamental concepts and
    how they are addressed by the Python programming language.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Python 并非真正的多线程。那么什么是线程？什么是进程？在接下来的章节中，我们将介绍这两个基本概念以及 Python 编程语言如何处理它们。
- en: Processes and threads
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进程和线程
- en: '*Threads* can be compared to light processes, in the sense that they offer
    advantages similar to those of processes, without, however, requiring the typical
    communication techniques of processes. Threads allow you to divide the main control
    flow of a program into multiple concurrently running control streams. Processes,
    by contrast, have their *own* *addressing space* and their own resources*.* It
    follows that communication between parts of code running on different processes
    can only take place through appropriate management mechanisms, including pipes,
    code FIFO, mailboxes, shared memory areas, and message passing. Threads, on the
    other hand, allow the creation of concurrent parts of the program, in which each
    part can access the same address space, variables, and constants.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '*线程* 可以与轻量级进程相比，从某种意义上说，它们提供了与进程类似的优势，但不需要进程的典型通信技术。线程允许您将程序的主要控制流程划分为多个并发运行的控制流。相比之下，进程有自己的
    *地址空间* 和自己的资源。因此，在运行在不同进程上的代码部分之间的通信只能通过适当的管理机制进行，包括管道、代码 FIFO、邮箱、共享内存区域和消息传递。另一方面，线程允许创建程序的并发部分，其中每个部分都可以访问相同的地址空间、变量和常量。'
- en: 'The following table summarizes the main differences between threads and processes:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格总结了线程和进程之间的主要区别：
- en: '| **Threads** | **Processes** |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| **线程** | **进程** |'
- en: '| --- | --- |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Share memory. | Do not share memory. |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 共享内存。 | 不共享内存。 |'
- en: '| Start/change are computationally less expensive. | Start/change are computationally
    expensive. |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 开始/更改计算成本较低。 | 开始/更改计算成本较高。 |'
- en: '| Require fewer resources (light processes). | Require more computational resources.
    |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 需要较少的资源（轻量级进程）。 | 需要更多的计算资源。 |'
- en: '| Need synchronization mechanisms to handle data correctly. | No memory synchronization
    is required. |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 需要同步机制来正确处理数据。 | 不需要内存同步。 |'
- en: After this brief introduction, we can finally show how processes and threads
    operate.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在这简短的介绍之后，我们最终可以展示进程和线程是如何操作的。
- en: 'In particular, we want to compare the serial, multithread, and multiprocess
    execution times of the following function, `do_something`, which performs some
    basic calculations, including building a list of integers selected randomly (a `do_something.py` file):'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是我们想比较以下函数的串行、多线程和多进程执行时间，该函数`do_something`执行一些基本计算，包括构建一个随机选择的整数列表（`do_something.py`文件）：
- en: '[PRE36]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next, there is the serial (`serial_test.py`) implementation. Let''s start with
    the relevant imports:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，是串行（`serial_test.py`）实现。让我们从相关的导入开始：
- en: '[PRE37]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Note the importing of the module time, which will be used to evaluate the execution
    time, in this instance, and the serial implementation of the `do_something` function. `size`
    of the list to build is equal to `10000000`, while the `do_something` function
    will be executed `10` times:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 注意导入模块`time`，它将用于评估执行时间，在本例中，以及`do_something`函数的串行实现。要构建的列表`size`等于`10000000`，而`do_something`函数将被执行`10`次：
- en: '[PRE38]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Next, we have the multithreaded implementation (`multithreading_test.py`).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有多线程实现（`multithreading_test.py`）。
- en: 'Import the relevant libraries:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 导入相关库：
- en: '[PRE39]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note the import of the `threading` module in order to operate with the multithreading
    capabilities of Python.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 注意导入`threading`模块的重要性，以便操作Python的多线程功能。
- en: Here, there is the multithreading execution of the `do_something` function.
    We will not comment in-depth on the instructions in the following code, as they
    will be discussed in more detail in [Chapter 2](c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml), *Thread-Based
    Parallelism*.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，是`do_something`函数的多线程执行。我们不会深入评论以下代码中的指令，因为它们将在[第2章](c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml)中更详细地讨论，*基于线程的并行性*。
- en: 'However, it should be noted in this case, too, that the length of the list
    is obviously the same as in the serial case, `size = 10000000`, while the number
    of threads defined is 10, `threads = 10`, which is also the number of times the
    `do_something` function must be executed:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，也应该注意，在这种情况下，列表的长度显然与串行情况相同，`size = 10000000`，而定义的线程数是10，`threads = 10`，这也是`do_something`函数必须执行的次数：
- en: '[PRE40]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Note also the construction of the single thread, through the `threading.Thread`
    method:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意通过`threading.Thread`方法构建单个线程：
- en: '[PRE41]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The sequence of cycles in which we start executing threads and then stop them
    immediately afterwards is as follows:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们启动线程并立即停止它们的循环序列如下：
- en: '[PRE42]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Finally, there is the multiprocessing implementation (`multiprocessing_test.py`).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，是多进程实现（`multiprocessing_test.py`）。
- en: 'We start by importing the necessary modules and, in particular, the `multiprocessing`
    library, whose features will be explained in-depth in [Chapter 3](5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml),
    *Process-Based Parallelism*:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入必要的模块，特别是`multiprocessing`库，其功能将在[第3章](5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml)中深入解释，*基于进程的并行性*。
- en: '[PRE43]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'As in the previous cases, the length of the list to build, the size, and the
    execution number of the `do_something` function remain the same (`procs = 10`):'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 与前例一样，要构建的列表长度、`do_something`函数的大小和执行次数保持不变（`procs = 10`）：
- en: '[PRE44]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Here, the implementation of a single process through the `multiprocessing.Process`
    method call is affected as follows:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，通过`multiprocessing.Process`方法调用实现单个进程受以下影响：
- en: '[PRE45]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Next, the sequence of cycles in which we start executing processes and then
    stop them immediately afterwards is executed as follows:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，启动进程并立即停止它们的循环序列执行如下：
- en: '[PRE46]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Then, we open the command shell and run the three functions described previously.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们打开命令行并运行前面描述的三个函数。
- en: 'Go to the folder where the functions have been copied and then type the following:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 前往已复制函数的文件夹，然后输入以下内容：
- en: '[PRE47]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The result, obtained on a machine with the following features—CPU Intel i7/8
    GB of RAM, is as follows:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有以下特性的机器上获得的结果——CPU Intel i7/8 GB 的内存，如下所示：
- en: '[PRE48]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'In the case of the `multithreading` implementation, we have the following:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 在`多线程`实现的情况下，我们有以下内容：
- en: '[PRE49]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is as follows:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE50]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Finally, there is the **multiprocessing** implementation:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，是**多进程**的实现：
- en: '[PRE51]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Its result is as follows:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 其结果如下：
- en: '[PRE52]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: As can be seen, the results of the serial implementation (that is, using `serial_test.py`)
    are similar to those obtained with the implementation of multithreading (using
    `multithreading_test.py`) where the threads are essentially launched one after
    the other, giving precedence to the one over the other until the end, while we
    have benefits in terms of execution times using the Python multiprocessing capability
    (using `multiprocessing_test.py`).
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 如所示，串行实现（即使用`serial_test.py`）的结果与使用多线程实现（使用`multithreading_test.py`）获得的结果相似，其中线程实际上是依次启动的，优先考虑一个然后是另一个，直到结束，而我们在使用Python多进程能力（使用`multiprocessing_test.py`）方面获得了执行时间上的好处。
