- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators, Iterators, and Asynchronous Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators are another one of those features that makes Python a peculiar language
    over more traditional ones. In this chapter, we will explore their rationale,
    why they were introduced in the language, and the problems they solve. We will
    also cover how to address problems idiomatically by using generators, and how
    to make our generators (or any iterable, for that matter) Pythonic.
  prefs: []
  type: TYPE_NORMAL
- en: We will understand why iteration (in the form of the iterator pattern) is automatically
    supported in the language. From there, we will take another journey and explore
    how generators became such a fundamental feature of Python in order to support
    other functionality, such as coroutines and asynchronous programming.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goals of this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To create generators that improve the performance of our programs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To study how iterators (and the iterator pattern, in particular) are deeply
    embedded in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To solve problems that involve iteration idiomatically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand how generators work as the basis for coroutines and asynchronous
    programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To explore the syntactic support for coroutines—`yield from`, `await`, and `async`
    `def`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mastering generators will take you a long way in writing idiomatic Python, hence
    the importance of them for this book. In this chapter, we not only study how to
    use generators, but we also explore their internals, in order to deeply understand
    how they work.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The examples in this chapter will work with any version of Python 3.9 on any
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: The code used in this chapter can be found at [https://github.com/PacktPublishing/Clean-Code-in-Python-Second-Edition](https://github.com/PacktPublishing/Clean-Code-in-Python-Second-Edition).
    The instructions are available in the `README` file.
  prefs: []
  type: TYPE_NORMAL
- en: Creating generators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators were introduced in Python a long time ago (PEP-255), with the idea
    of introducing iteration in Python while improving the performance of the program
    (by using less memory) at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of a generator is to create an object that is iterable, and, while
    it's being iterated, will produce the elements it contains, one at a time. The
    main use of generators is to save memory—instead of having a very large list of
    elements in memory, holding everything at once, we have an object that knows how
    to produce each particular element, one at a time, as it is required.
  prefs: []
  type: TYPE_NORMAL
- en: This feature enables lazy computations of heavyweight objects in memory, in
    a similar manner to what other functional programming languages (Haskell, for instance)
    provide. It would even be possible to work with infinite sequences because the
    lazy nature of generators enables such an option.
  prefs: []
  type: TYPE_NORMAL
- en: A first look at generators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's start with an example. The problem at hand now is that we want to process
    a large list of records and get some metrics and indicators over them. Given a
    large dataset with information about purchases, we want to process it in order
    to get the lowest sale, the highest sale, and the average price of a sale.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the simplicity of this example, we will assume a CSV with only two fields,
    in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We are going to create an object that receives all the purchases, and this will
    give us the necessary metrics. We could get some of these values out of the box
    by simply using the `min()` and `max()` built-in functions, but that would require
    iterating all of the purchases more than once, so instead, we are using our custom
    object, which will get these values in a single iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code that will get the numbers for us looks rather simple. It''s just an
    object with a method that will process all the prices in one go, and, at each
    step, will update the value of each particular metric we are interested in. First,
    we will show the first implementation in the following listing, and, later on
    in this chapter (once we have seen more about iteration), we will revisit this
    implementation and get a much better (and more compact) version of it. For now,
    we are settling with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This object will receive all the totals for `purchases` and process the required
    values. Now, we need a function that loads these numbers into something that this
    object can process. Here is the first version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This code works; it loads all the numbers of the file into a list that, when
    passed to our custom object, will produce the numbers we want. It has a performance
    issue, though. If you run it with a rather large dataset, it will take a while
    to complete, and it might even fail if the dataset is large enough to not fit
    into the main memory.
  prefs: []
  type: TYPE_NORMAL
- en: If we take a look at our code that consumes this data, it is processing purchases,
    one at a time, so we might be wondering why our producer fits everything in memory
    at once. It is creating a list where it puts all of the content of the file, but
    we know we can do better.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution is to create a generator. Instead of loading the entire content
    of the file in a list, we will produce the results one at a time. The code will
    now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If you measure the process this time, you will notice that the usage of memory
    has dropped significantly. We can also see how the code looks simpler—there is
    no need to define the list (therefore, there is no need to append to it), and
    the `return` statement has also disappeared.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the `load_purchases` function is a generator function, or simply
    a generator.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, the mere presence of the keyword `yield` in any function makes it
    a generator, and, as a result, when calling it, nothing other than creating an
    instance of the generator will happen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: A generator object is an iterable (we will revisit iterables in more detail
    later on), which means that it can work with `for` loops. Note how we did not
    have to change anything on the consumer code—our statistics processor remained
    the same, with the `for` loop unmodified, after the new implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Working with iterables allows us to create these kinds of powerful abstractions
    that are polymorphic with respect to `for` loops. As long as we keep the iterable
    interface, we can iterate over that object transparently.
  prefs: []
  type: TYPE_NORMAL
- en: What we're exploring in this chapter is another case of idiomatic code that
    blends well with Python itself. In previous chapters, we have seen how we can
    implement our own context managers to connect our objects into with statements,
    or how can we create custom container objects to leverage the `in` operator, or
    booleans for the `if` statement, and so on. Now it's the turn of the `for` operator,
    and for that, we'll create iterators.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before going into the details and nuances of generators, we can take a quick
    look at how generators relate to a concept that we have already seen: comprehensions.
    A generator in the form of a comprehension is called a generator expression, and
    we''ll discuss it briefly in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Generator expressions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generators save a lot of memory, and since they are iterators, they are a convenient
    alternative to other iterables or containers that require more space in memory
    such as lists, tuples, or sets.
  prefs: []
  type: TYPE_NORMAL
- en: Much like these data structures, they can also be defined by comprehension,
    only that they are called a generator expression (there is an ongoing argument
    about whether they should be called generator comprehensions. In this book, we
    will just refer to them by their canonical name, but feel free to use whichever
    you prefer).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same way, we would define a list comprehension. If we replace the square
    brackets with parentheses, we get a generator that results from the expression.
    Generator expressions can also be passed directly to functions that work with
    iterables, such as `sum()` and `max()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Always pass a generator expression, instead of a list comprehension, to functions
    that expect iterables, such as `min()`, `max()`, and `sum()`. This is more efficient
    and Pythonic.
  prefs: []
  type: TYPE_NORMAL
- en: 'What the previous recommendation means is to try to avoid passing lists to
    functions that already work with generators. The example in the next code is something
    you would want to avoid, and favor the approach from the previous listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: And, of course, you can assign a generator expression to a variable and use
    it somewhere else (as with comprehensions). Keep in mind that there is an important
    distinction in this case, because we're talking about generators here. A list
    can be reused and iterated multiple times, but a generator will be exhausted after
    it has been iterated over. For this reason, make sure the result of the expression
    is consumed only once, or you'll get unexpected results.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that generators are exhausted after they're iterated over, because
    they don't hold all the data in memory.
  prefs: []
  type: TYPE_NORMAL
- en: A common approach is to create new generator expressions in the code. This way,
    the first one will be exhausted after is iterated, but then a new one is created.
    Chaining generator expressions this way is useful and helps to save memory as
    well as to make the code more expressive because it's resolving different iterations
    in different steps. One scenario where this is useful is when you need to apply
    multiple filters on an iterable; you can achieve this by using multiple generator
    expressions that act as chained filters.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a new tool in our toolbox (iterators), let's see how we can
    use it to write more idiomatic code.
  prefs: []
  type: TYPE_NORMAL
- en: Iterating idiomatically
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will first explore some idioms that come in handy when we
    have to deal with iteration in Python. These code recipes will help us get a better
    idea of the types of things we can do with generators (especially after we have
    already seen generator expressions), and how to solve typical problems in relation
    to them.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have seen some idioms, we will move on to exploring iteration in Python
    in more depth, analyzing the methods that make iteration possible, and how iterable
    objects work.
  prefs: []
  type: TYPE_NORMAL
- en: Idioms for iteration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are already familiar with the built-in `enumerate()` function that, given
    an iterable, will return another one on which the element is a tuple, whose first
    element is the index of the second one (corresponding to the element in the original
    iterable):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We wish to create a similar object, but in a more low-level fashion; one that
    can simply create an infinite sequence. We want an object that can produce a sequence
    of numbers, from a starting one, without any limits.
  prefs: []
  type: TYPE_NORMAL
- en: 'An object as simple as the following one can do the trick. Every time we call
    this object, we get the next number of the sequence ad infinitum:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on this interface, we would have to use this object by explicitly invoking
    its `next()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'But with this code, we cannot reconstruct the `enumerate()` function as we
    would like to, because its interface does not support being iterated over a regular
    Python `for` loop, which also means that we cannot pass it as a parameter to functions
    that expect something to iterate over. Notice how the following code fails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The problem lies in the fact that `NumberSequence` does not support iteration.
    To fix this, we have to make the object an iterable by implementing the magic
    method `__iter__()`. We have also changed the previous `next()` method, by using
    the `__next__ magic method`, which makes the object an iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This has an advantage—not only can we iterate over the element, but we also
    don''t even need the `.next()` method anymore because having `__next__()` allows
    us to use the `next()` built-in function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This makes use of the iteration protocol. Similar to the context manager protocol
    we have explored in previous chapters, which consists of the `__enter__` and `__exit__`
    methods, this protocol relies on the `__iter__` and `__next__` methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having these protocols in Python has an advantage: everyone that knows Python
    will be familiar with this interface already, so there''s a sort of "standard
    contract." This means, instead of having to define your own methods and agree
    with the team (or any potential reader of the code), that this is the expected
    standard or protocol your code works with (as with our custom `next()` method
    in the first example); Python already provides an interface and has a protocol
    already. We only have to implement it properly.'
  prefs: []
  type: TYPE_NORMAL
- en: The next() function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `next()` built-in function will advance the iterable to its next element
    and return it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If the iterator does not have more elements to produce, the `StopIteration`
    exception is raised:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This exception signals that the iteration is over and that there are no more
    elements to consume.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we wish to handle this case, besides catching the `StopIteration` exception,
    we could provide this function with a default value in its second parameter. Should
    this be provided, it will be the return value in lieu of throwing `StopIteration`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It is advisable to use the default value most of the time, to avoid having exceptions
    at runtime in our programs. If we are absolutely sure that the iterator we're
    dealing with cannot be empty, it's still better to be implicit (and intentional)
    about it, and not rely on side effects of built-in functions (that is, to properly
    assert the case).
  prefs: []
  type: TYPE_NORMAL
- en: The `next()` function can be quite useful in combination with generator expressions,
    in situations where we want to look for the first elements of an iterable that
    meets certain criteria. We'll see examples of this idiom throughout the chapter,
    but the main idea is to use this function instead of creating a list comprehension
    and then taking its first element.
  prefs: []
  type: TYPE_NORMAL
- en: Using a generator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The previous code can be simplified significantly by simply using a generator.
    Generator objects are iterators. This way, instead of creating a class, we can
    define a function that yields the values as needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that from our first definition, the `yield` keyword in the body of
    the function makes it a generator. Because it is a generator, it''s perfectly
    fine to create an infinite loop like this, because, when this generator function
    is called, it will run all the code until the next `yield` statement is reached.
    It will produce its value and suspend there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This difference can be thought of as an analogy of the different ways there
    are to create a decorator, as we explored in the previous chapter (with an object
    of functions). Here as well, we can use a generator function, or an iterable object,
    as in the previous section. Whenever is possible, constructing a generator is
    recommended, because it's syntactically simpler, and therefore easier to understand.
  prefs: []
  type: TYPE_NORMAL
- en: Itertools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Working with iterable objects has the advantage that the code blends better
    with Python itself because iteration is a key component of the language. Besides
    that, we can take full advantage of the `itertools` module (ITER-01). Actually,
    the `sequence()` generator we just created is fairly similar to `itertools.count()`.
    However, there is more we can do.
  prefs: []
  type: TYPE_NORMAL
- en: One of the nicest things about iterators, generators, and itertools is that
    they are composable objects that can be chained together.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, going back to our first example that processed `purchases` in
    order to get some metrics, what if we want to do the same, but only for those
    values over a certain threshold? The naïve approach to solving this problem would
    be to place the condition while iterating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This is not only non-Pythonic, but it's also rigid (and rigidity is a trait
    that denotes bad code). It doesn't handle changes very well. What if the number
    changes now? Do we pass it by parameter? What if we need more than one? What if
    the condition is different (less than, for instance)? Do we pass a `lambda`?
  prefs: []
  type: TYPE_NORMAL
- en: These questions should not be answered by this object, whose sole responsibility
    is to compute a set of well-defined metrics over a stream of purchases represented
    as numbers. And, of course, the answer is no. It would be a huge mistake to make
    such a change (once again, clean code is flexible, and we don't want to make it
    rigid by coupling this object to external factors). These requirements will have
    to be addressed elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: It's better to keep this object independent of its clients. The less responsibility
    this class has, the more useful it will be for more clients, hence enhancing its
    chances of being reused.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of changing this code, we're going to keep it as it is and assume that
    the new data is filtered according to whatever requirements each customer of the
    class has.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, if we wanted to process only the first `10` purchases that amount
    to more than `1000`, we would do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: There is no memory penalization for filtering this way because since they are
    all generators, the evaluation is always lazy. This gives us the power of thinking
    as if we had filtered the entire set at once and then passed it to the object,
    but without actually fitting everything in memory.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind the trade-off mentioned at the beginning of the chapter, between
    memory and CPU usage. While the code might use less memory, it could take up more
    CPU time, but most of the times, this is acceptable, when we have to process lots
    of objects in memory while keeping the code maintainable.
  prefs: []
  type: TYPE_NORMAL
- en: Simplifying code through iterators
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, we will briefly discuss some situations that can be improved with the help
    of iterators, and occasionally the `itertools` module. After discussing each case,
    and its proposed optimization, we will close each point with a corollary.
  prefs: []
  type: TYPE_NORMAL
- en: Repeated iterations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now that we have seen more about iterators, and introduced the `itertools`
    module, we can show you how one of the first examples of this chapter (the one
    for computing statistics about some purchases) can be dramatically simplified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In this example, `itertools.tee` will split the original iterable into three
    new ones. We will use each of these for the different kinds of iterations that
    we require, without needing to repeat three different loops over `purchases`.
  prefs: []
  type: TYPE_NORMAL
- en: The reader can simply verify that if we pass an iterable object as the `purchases`
    parameter, this one is traversed only once (thanks to the `itertools.tee` function
    [TEE]), which was our main requirement. It is also possible to verify how this
    version is equivalent to our original implementation. In this case, there is no
    need to manually raise `ValueError` because passing an empty sequence to the `min()`
    function will do this.
  prefs: []
  type: TYPE_NORMAL
- en: If you are thinking about running a loop over the same object more than once,
    stop and think if `itertools.tee` can be of any help.
  prefs: []
  type: TYPE_NORMAL
- en: The `itertools` module contains many useful functions and nice abstractions
    that come in handy when dealing with iterations in Python. It also contains good
    recipes about how to solve typical iteration problems in an idiomatic fashion.
    As general advice, if you're thinking about how to solve a particular problem
    that involves iteration, go and take a look at this module. Even if the answer
    isn't literally there, it'll be good inspiration.
  prefs: []
  type: TYPE_NORMAL
- en: Nested loops
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In some situations, we need to iterate over more than one dimension, looking
    for a value, and nested loops come as the first idea. When the value is found,
    we need to stop iterating, but the `break` keyword doesn't work entirely because
    we have to escape from two (or more) `for` loops, not just one.
  prefs: []
  type: TYPE_NORMAL
- en: What would be the solution to this? A flag signaling escape? No. Raising an
    exception? No, this would be the same as the flag, but even worse because we know
    that exceptions are not to be used for control flow logic. Moving the code to
    a smaller function and returning it? Close, but not quite.
  prefs: []
  type: TYPE_NORMAL
- en: The answer is, whenever possible, flatten the iteration to a single `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the kind of code we would like to avoid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is a simplified version of it that does not rely on flags to signal
    termination, and has a simpler, more compact structure of iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: It's worth mentioning how the auxiliary generator that was created works as
    an abstraction for the iteration that's required. In this case, we just need to
    iterate over two dimensions, but if we needed more, a different object could handle
    this without the client needing to know about it. This is the essence of the iterator
    design pattern, which, in Python, is transparent, since it supports iterator objects
    automatically, which is the topic covered in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Try to simplify the iteration as much as possible with as many abstractions
    as are required, flattening the loops wherever possible.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, this example serves as inspiration to you to get the idea that we
    can use generators for something more than just saving memory. We can take advantage
    of the iteration as an abstraction. That is, we can create abstractions not only
    by defining classes or functions but also by taking advantage of the syntax of
    Python. In the same way that we have seen how to abstract away some logic behind
    a context manager (so we don't know the details of what happens under the `with`
    statement), we can do the same with iterators (so we can forget the underlying
    logic of a `for` loop).
  prefs: []
  type: TYPE_NORMAL
- en: That's why we will start exploring how the iterator pattern works in Python,
    starting with the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The iterator pattern in Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here, we will take a small detour from generators to understand iteration in
    Python more deeply. Generators are a particular case of iterable objects, but
    iteration in Python goes beyond generators, and being able to create good iterable
    objects will give us the chance to create more efficient, compact, and readable
    code.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous code listings, we have been seeing examples of `iterable` objects
    that are also iterators, because they implement both the `__iter__()` and `__next__()`
    magic methods. While this is fine in general, it's not strictly required that
    they always have to implement both methods, and here we'll show the subtle differences
    between an `iterable` object (one that implements `__iter__`) and an iterator
    (that implements `__next__`).
  prefs: []
  type: TYPE_NORMAL
- en: We also explore other topics related to iterations, such as sequences and container
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: The interface for iteration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An `iterable` is an object that supports iteration, which, at a very high level,
    means that we can run a `for` .. `in` ... loop over it, and it will work without
    any issues. However, `iterable` does not mean the same as iterator.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, an `iterable` is just something we can iterate, and it uses
    an iterator to do so. This means that in the `__iter__` magic method, we would
    like to return an iterator, namely, an object with a `__next__()` method implemented.
  prefs: []
  type: TYPE_NORMAL
- en: An iterator is an object that only knows how to produce a series of values,
    one at a time, when it's being called by the already explored built-in `next()`
    function, while the iterator is not called, it's simply frozen, sitting idly by
    until it's called again for the next value to produce. In this sense, generators
    are iterators.
  prefs: []
  type: TYPE_NORMAL
- en: '| Python concept | Magic method | Considerations |'
  prefs: []
  type: TYPE_TB
- en: '| Iterable | `__iter__` | They work with an iterator to construct the iteration
    logic.These objects can be iterated in a `for` ... `in` ...: loop. |'
  prefs: []
  type: TYPE_TB
- en: '| Iterator | `__next__` | Define the logic for producing values one at a time.The
    `StopIteration` exception signals that the iteration is over.The values can be
    obtained one by one via the built-in `next()` function. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7.1: Iterables and iterators'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we will see an example of an iterator object that is
    not iterable—it only supports invoking its values, one at a time. Here, the name
    `sequence` refers just to a series of consecutive numbers, not to the sequence
    concept in Python, which we will explore later on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we can get the values of the sequence one at a time, but we can''t
    iterate over this object (this is fortunate because it would otherwise result
    in an endless loop):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The error message is clear, as the object doesn't implement `__iter__()`.
  prefs: []
  type: TYPE_NORMAL
- en: Just for explanatory purposes, we can separate the iteration in another object
    (again, it would be enough to make the object implement both `__iter__` and `__next__`,
    but doing so separately will help clarify the distinctive point we're trying to
    make in this explanation).
  prefs: []
  type: TYPE_NORMAL
- en: Sequence objects as iterables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As we have just seen, if an object implements the `__iter__()` magic method,
    it means it can be used in a `for` loop. While this is a great feature, it's not
    the only possible form of iteration we can achieve. When we write a `for` loop,
    Python will try to see if the object we're using implements `__iter__`, and if
    it does, it will use that to construct the iteration, but if it doesn't, there
    are fallback options.
  prefs: []
  type: TYPE_NORMAL
- en: If the object happens to be a sequence (meaning that it implements the `__getitem__()`
    and `__len__()` magic methods), it can also be iterated. If that is the case,
    the interpreter will then provide values in sequence, until the `IndexError` exception
    is raised, which, analogous to the aforementioned `StopIteration`, also signals
    the stop for the iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the sole purpose of illustrating such a behavior, we will run the following
    experiment that shows a sequence object that implements `map()` over a range of
    numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Keep in mind that this example is only designed to illustrate that an object
    such as this one can be iterated with a regular `for` loop. There is a logging
    line placed in the `__getitem__` method to explore what values are passed while
    the object is being iterated, as we can see from the following test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As a word of caution, it's important to highlight that while it is useful to
    know this, it's also a fallback mechanism for when the object doesn't implement
    `__iter__`, so most of the time we'll want to resort to these methods by thinking
    about creating proper sequences, and not just objects we want to iterate over.
  prefs: []
  type: TYPE_NORMAL
- en: When thinking about designing an object for iteration, favor a proper iterable
    object (with `__iter__`), rather than a sequence that can coincidentally also
    be iterated.
  prefs: []
  type: TYPE_NORMAL
- en: Iterables are an important part of Python, not only because of the capabilities
    they offer to us as software engineers, but also because they play a fundamental
    role in the internals of Python.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen in *A brief introduction to asynchronous code* in *Chapter 2*,
    *Pythonic Code*, how to read asynchronous code. Now that we have also explored
    iterators in Python, we can see how these two concepts are related. In particular,
    the next section explores coroutines, and we'll see how iterators are at the core
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The idea of a coroutine is to have a function, whose execution can be suspended
    at a given point in time, to be later resumed. By having this kind of functionality,
    a program might be able to suspend a part of the code, in order to dispatch something
    else for processing, and then come back to this original point to resume.
  prefs: []
  type: TYPE_NORMAL
- en: As we already know, generator objects are iterables. They implement `__iter__()`
    and `__next__()`. This is provided by Python automatically so that when we create
    a generator object function, we get an object that can be iterated or advanced
    through the `next()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Besides this basic functionality, they have more methods so that they can work
    as coroutines (PEP-342). Here, we will explore how generators evolved into coroutines
    to support the basis of asynchronous programming before we go into more detail
    in the next section, where we will explore the new features of Python and the
    syntax that covers programming asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic methods added in PEP-342 to support coroutines are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`.close()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.throw(ex_type[, ex_value[, ex_traceback]])`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.send(value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python takes advantage of generators in order to create coroutines. Because
    generators can naturally suspend, they're a convenient starting point. But generators
    weren't enough as they were originally thought to be, so these methods were added.
    This is because typically, it's not enough to just be able to suspend some part
    of the code; you'd also want to communicate with it (pass data, and signal about
    changes in the context).
  prefs: []
  type: TYPE_NORMAL
- en: By exploring each method in more detail, we'll be able to learn more about the
    internals of coroutines in Python. After this, I'll present another recapitulation
    of how asynchronous programming works, but unlike the one presented in *Chapter
    2*, *Pythonic Code*, this one will relate to the internal concepts we just learned.
  prefs: []
  type: TYPE_NORMAL
- en: The methods of the generator interface
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will explore what each of the aforementioned methods does,
    how it works, and how it is expected to be used. By understanding how to use these methods,
    we will be able to make use of simple coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Later on, we will explore more advanced uses of coroutines, and how to delegate
    to sub-generators (coroutines) in order to refactor code, and how to orchestrate
    different coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: close()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When calling this method, the generator will receive the `GeneratorExit` exception.
    If it's not handled, then the generator will finish without producing any more
    values, and its iteration will stop.
  prefs: []
  type: TYPE_NORMAL
- en: This exception can be used to handle a finishing status. In general, if our
    coroutine does some sort of resource management, we want to catch this exception
    and use that control block to release all resources being held by the coroutine.
    It is similar to using a context manager or placing the code in the `finally`
    block of an exception control, but handling this exception specifically makes
    it more explicit.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we have a coroutine that makes use of a database
    handler object that holds a connection to a database, and runs queries over it,
    streaming data by pages of a fixed length (instead of reading everything that
    is available at once):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'At each call to the generator, it will return `10` rows obtained from the database
    handler, but when we decide to explicitly finish the iteration and call `close()`,
    we also want to close the connection to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Use the `close()` method on generators to perform finishing-up tasks when needed.
  prefs: []
  type: TYPE_NORMAL
- en: This method is intended to be used for resource cleanup, so you'd typically
    use it for manually freeing resources when you couldn't do this automatically
    (for example, if you didn't use a context manager). Next, we'll see how to pass
    exceptions to the generator.
  prefs: []
  type: TYPE_NORMAL
- en: throw(ex_type[, ex_value[, ex_traceback]])
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This method will `throw` the exception at the line where the generator is currently
    suspended. If the generator handles the exception that was sent, the code in that
    particular `except` clause will be called; otherwise, the exception will propagate
    to the caller.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we are modifying the previous example slightly to show the difference
    when we use this method for an exception that is handled by the coroutine, and
    when it''s not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Now, it is a part of the control flow to receive a `CustomException`, and, in
    such a case, the generator will log an informative message (of course, we can
    adapt this according to our business logic on each case), and move on to the next
    `yield` statement, which is the line where the coroutine reads from the database
    and returns that data.
  prefs: []
  type: TYPE_NORMAL
- en: 'This particular example handles all exceptions, but if the last block (except
    `Exception`:) wasn''t there, the result would be that the generator is raised
    at the line where the generator is paused (again, `yield`), and it will propagate
    from there to the caller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: When our exception from the domain was received, the generator continued. However,
    when it received another exception that was not expected, the default block caught
    where we closed the connection to the database and finished the iteration, which
    resulted in the generator being stopped. As we can see from the `StopIteration`
    that was raised, this generator can't be iterated further.
  prefs: []
  type: TYPE_NORMAL
- en: send(value)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous example, we created a simple generator that reads rows from
    a database, and when we wished to finish its iteration, this generator released
    the resources linked to the database. This is a good example of using one of the
    methods that generators provide (`close()`), but there is more we can do.
  prefs: []
  type: TYPE_NORMAL
- en: An obvservation of the generator is that it was reading a fixed number of rows
    from the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'We would like to parametrize that number (`10`) so that we can change it throughout
    different calls. Unfortunately, the `next()` function does not provide us with
    options for that. But luckily, we have `send()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The idea is that we have now made the coroutine able to receive values from
    the caller by means of the `send()` method. This method is the one that actually
    distinguishes a generator from a coroutine because when it's used, it means that
    the `yield` keyword will appear on the right-hand side of the statement, and its
    return value will be assigned to something else.
  prefs: []
  type: TYPE_NORMAL
- en: 'In coroutines, we generally find the `yield` keyword to be used in the following
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '`yield`, in this case, will do two things. It will send `produced` back to
    the caller, which will pick it up on the next round of iteration (after calling
    `next()`, for example), and it will suspend there. At a later point, the caller
    will want to send a value back to the coroutine by using the `send()` method.
    This value will become the result of the `yield` statement, assigned in this case
    to the variable named `receive`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sending values to the coroutine only works when this one is suspended at a
    `yield` statement, waiting for something to produce. For this to happen, the coroutine
    will have to be advanced to that status. The only way to do this is by calling
    `next()` on it. This means that before sending anything to the coroutine, this
    has to be advanced at least once via the `next()` method. Failure to do so will
    result in an exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Always remember to advance a coroutine by calling `next()` before sending any
    values to it.
  prefs: []
  type: TYPE_NORMAL
- en: Back to our example. We are changing the way elements are produced or streamed
    to make it able to receive the length of the records it expects to read from the
    database.
  prefs: []
  type: TYPE_NORMAL
- en: The first time we call `next()`, the generator will advance up to the line containing
    `yield`; it will provide a value to the caller (`None`, as set in the variable),
    and it will suspend there). From there, we have two options. If we choose to advance
    the generator by calling `next()`, the default value of `10` will be used, and
    it will go on with this as usual. This is because calling `next()` is technically
    the same as `send(None)`, but this is covered in the `if` statement that will
    handle the value that we previously set.
  prefs: []
  type: TYPE_NORMAL
- en: If, on the other hand, we decide to provide an explicit value via `send(<value>)`,
    this one will become the result of the `yield` statement, which will be assigned
    to the variable containing the length of the page to use, which, in turn, will
    be used to read from the database.
  prefs: []
  type: TYPE_NORMAL
- en: Successive calls will have this logic, but the important point is that now we
    can dynamically change the length of the data to read in the middle of the iteration,
    at any point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we understand how the previous code works, most Pythonistas would
    expect a simplified version of it (after all, Python is also about brevity and
    clean and compact code):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This version is not only more compact, but it also illustrates the idea better.
    The parentheses around `yield` makes it clearer that it's a statement (think of
    it as if it were a function call), and that we are using the result of it to compare
    it against the previous value.
  prefs: []
  type: TYPE_NORMAL
- en: This works as we expect it does, but we always have to remember to advance the
    coroutine before sending any data to it. If we forget to call the first `next()`,
    we'll get a `TypeError`. This call could be ignored for our purposes because it
    doesn't return anything we'll use.
  prefs: []
  type: TYPE_NORMAL
- en: 'It would be good if we could use the coroutine directly, right after it is
    created, without having to remember to call `next()` the first time, every time
    we are going to use it. Some authors (PYCOOK) devised an interesting decorator
    to achieve this. The idea of this decorator is to advance the coroutine, so the
    following definition works automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind, these are the fundamentals of how coroutines work in Python. By
    following these examples, you'll get an idea of what's actually going on in Python
    when working with coroutines. However, in modern Python, you wouldn't typically
    write these sorts of coroutines by yourself, because there's new syntax available
    (which we have mentioned, but we'll revisit to see how they relate to the ideas
    we have just seen).
  prefs: []
  type: TYPE_NORMAL
- en: Before jumping into the new syntactic capabilities, we need to explore the last
    jump the coroutines took in terms of their added functionality, in order to bridge
    missing gaps. After that, we'll be able to understand the meaning behind each
    keyword and statement used in asynchronous programming.
  prefs: []
  type: TYPE_NORMAL
- en: More advanced coroutines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have a better understanding of coroutines, and we can create simple
    ones to handle small tasks. We can say that these coroutines are, in fact, just
    more advanced generators (and that would be right, coroutines are just fancy generators),
    but, if we actually want to start supporting more complex scenarios, we usually
    have to go for a design that handles many coroutines concurrently, and that requires
    more features.
  prefs: []
  type: TYPE_NORMAL
- en: When handling many coroutines, we find new problems. As the control flow of
    our application becomes more complex, we want to pass values up and down the stack
    (as well as exceptions), be able to capture values from sub-coroutines we might
    call at any level, and finally, schedule multiple coroutines to run toward a common
    goal.
  prefs: []
  type: TYPE_NORMAL
- en: To make things simpler, generators had to be extended once again. That is what
    PEP-380 addressed by changing the semantics of generators so that they can return
    values and by introducing the new `yield from` construction.
  prefs: []
  type: TYPE_NORMAL
- en: Returning values in coroutines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As introduced at the beginning of this chapter, iteration is a mechanism that
    calls `next()` on an iterable object many times until a `StopIteration` exception
    is raised.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have been exploring the iterative nature of generators—we produce
    values one at a time, and, in general, we only care about each value as it's being
    produced at every step of the `for` loop. This is a very logical way of thinking
    about generators, but coroutines have a different idea; even though they are technically
    generators, they weren't conceived with the idea of iteration in mind, but with
    the goal of suspending the execution of code until it's resumed later on.
  prefs: []
  type: TYPE_NORMAL
- en: This is an interesting challenge; when we design a coroutine, we usually care
    more about suspending the state rather than iterating (and iterating a coroutine
    would be an odd case). The challenge lies in that it is easy to mix them both.
    This is because of a technical implementation detail; the support for coroutines
    in Python was built upon generators.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to use coroutines to process some information and suspend its execution,
    it would make sense to think of them as lightweight threads (or green threads,
    as they are called in other platforms). In such a case, it would make sense if
    they could return values, much like calling any other regular function.
  prefs: []
  type: TYPE_NORMAL
- en: But let's remember that generators are not regular functions, so in a generator,
    the construction `value = generator()` will do nothing other than create a generator
    object. What would be the semantics for making a generator return a value? It
    will have to be after the iteration is done.
  prefs: []
  type: TYPE_NORMAL
- en: When a generator returns a value, its iteration is immediately stopped (it can't
    be iterated any further). To preserve the semantics, the `StopIteration` exception
    is still raised, and the value to be returned is stored inside the `exception`
    object. It's the responsibility of the caller to catch it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we are creating a simple generator that produces
    two values and then returns a third. Notice how we have to catch the exception
    in order to get this value, and how it''s stored precisely inside the exception
    under the attribute named `value`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: As we'll see later, this mechanism is used to make coroutines return values.
    Before PEP-380, this didn't make any sense, and any attempt at having a `return`
    statement inside a generator was considered a syntax error. But now, the idea
    is that, when the iteration is over, we want to return a final value, and the
    way to provide it is to store it in the exception being raised at the end of the
    iteration (`StopIteration`). That might not be the cleanest approach, but it's
    completely backward-compatible, as it doesn't change the interface of the generator.
  prefs: []
  type: TYPE_NORMAL
- en: Delegating into smaller coroutines – the 'yield from' syntax
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The previous feature is interesting in the sense that it opens up a lot of new
    possibilities with coroutines (generators), now that they can return values. But
    this feature, by itself, would not be so useful without proper syntax support,
    because catching the returned value this way is a bit cumbersome.
  prefs: []
  type: TYPE_NORMAL
- en: This is one of the main features of the `yield from` syntax. Among other things
    (that we'll review in detail), it can collect the value returned by a sub-generator.
    Remember that we said that returning data in a generator was nice, but that, unfortunately,
    writing statements as `value = generator()` wouldn't work? Well, writing them
    as `value = yield from generator()` would.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest use of yield from
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In its most basic form, the new `yield from` syntax can be used to chain generators
    from nested `for` loops into a single one, which will end up with a single string
    of all the values in a continuous stream.
  prefs: []
  type: TYPE_NORMAL
- en: A canonical example is about creating a function similar to `itertools.chain()`
    from the `standard` library. This is a very nice function because it allows you
    to pass any number of `iterables` and will return them all together in one stream.
  prefs: []
  type: TYPE_NORMAL
- en: 'The naïve implementation might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: It receives a variable number of `iterables`, traverses through all of them,
    and since each value is iterable, it supports a `for... in..` construction, so
    we have another `for` loop to get every value inside each particular iterable,
    which is produced by the caller function.
  prefs: []
  type: TYPE_NORMAL
- en: This might be helpful in multiple cases, such as chaining generators together
    or trying to iterate things that it wouldn't normally be possible to compare in
    one go (such as lists with tuples, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the `yield from` syntax allows us to go further and avoid the nested
    loop because it''s able to produce the values from a sub-generator directly. In
    this case, we could simplify the code like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that for both implementations, the behavior of the generator is exactly
    the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This means that we can use `yield from` over any other iterable, and it will
    work as if the top-level generator (the one the `yield from` is using) were generating
    those values itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'This works with any iterable, and even generator expressions aren''t the exception.
    Now that we''re familiar with its syntax, let''s see how we could write a simple
    generator function that will produce all the powers of a number (for instance,
    if provided with `all_powers(2, 3)`, it will have to produce `2^0`, `2^1`,`...
    2^3`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: While this simplifies the syntax a bit, saving one line of a `for` statement
    isn't a big advantage, and it wouldn't justify adding such a change to the language.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, this is actually just a side effect and the real raison d'être of the
    `yield from` construction is what we are going to explore in the following two
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: Capturing the value returned by a sub-generator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the following example, we have a generator that calls another two nested
    generators, producing values in a sequence. Each one of these nested generators
    returns a value, and we will see how the top-level generator is able to effectively
    capture the return value since it''s calling the internal generators through `yield
    from`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a possible execution of the code in `main` while it''s being iterated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The first line of `main` delegates into the internal generator, and produces
    the values, extracting them directly from it. This is nothing new, as we have
    already seen. Notice, though, how the `sequence()` generator function returns
    the end value, which is assigned in the first line to the variable named `step1`,
    and how this value is correctly used at the start of the following instance of
    that generator.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, this other generator also returns the second end value (`10`), and
    the main generator, in turn, returns the sum of them (`5+10=15`), which is the
    value we see once the iteration has stopped.
  prefs: []
  type: TYPE_NORMAL
- en: We can use `yield from` to capture the last value of a coroutine after it has
    finished its processing.
  prefs: []
  type: TYPE_NORMAL
- en: With this example and the ones presented in the previous section, you can get
    an idea of what the `yield from` construction does in Python. The `yield from`
    construction will take the generator, and forward the iteration of it downstream,
    but once it's done, it'll catch its `StopIteration` exception, get the value of
    it, and return that value to the caller function. The value attribute of the `StopIteration`
    exception becomes the result of the statement.
  prefs: []
  type: TYPE_NORMAL
- en: This is a powerful construction, because in conjunction with the topic of the
    next section (how to send and receive contextual information from a sub-generator),
    this means coroutines can take the shape of something similar to threads.
  prefs: []
  type: TYPE_NORMAL
- en: Sending and receiving data to and from a sub-generator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now, we will see the other nice feature of the `yield from` syntax, which is
    probably what gives it its full power. As we already introduced when we explored
    generators acting as coroutines, we know that we can send values and throw exceptions
    at them, and, in such cases, the coroutine will either receive the value for its
    internal processing, or it will have to handle the exception accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: If we now have a coroutine that delegates into other ones (such as in the previous
    example), we would also like to preserve this logic. Having to do so manually
    would be quite complex (you can take a look at the code described in PEP-380 if
    we didn't have this handled by `yield from` automatically).
  prefs: []
  type: TYPE_NORMAL
- en: In order to illustrate this, let's keep the same top-level generator (main)
    unmodified with respect to the previous example (calling other internal generators),
    but let's modify the internal generators to make them able to receive values and
    handle exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is probably not idiomatic, only for the purposes of showing how this
    mechanism works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will call the `main` coroutine, not only by iterating it, but also
    by providing values and throwing exceptions at it in order to see how they are
    handled inside sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: This example is telling us a lot of different things. Notice how we never send
    values to `sequence`, but only to `main`, and even so, the code that is receiving
    those values is the nested generators. Even though we never explicitly send anything
    to `sequence`, it's receiving the data as it's being passed along by `yield from`.
  prefs: []
  type: TYPE_NORMAL
- en: The `main` coroutine calls two other coroutines internally, producing their
    values, and it will be suspended at a particular point in time in any of those.
    When it's stopped at the first one, we can see the logs telling us that it is
    that instance of the coroutine that received the value we sent. The same happens
    when we throw an exception to it. When the first coroutine finishes, it returns
    the value that was assigned in the variable named `step1`, and passed as input
    for the second coroutine, which will do the same (it will handle the `send()`
    and `throw()` calls, accordingly).
  prefs: []
  type: TYPE_NORMAL
- en: The same happens for the values that each coroutine produces. When we are at
    any given step, the return from calling `send()` corresponds to the value that
    the sub-coroutine (the one that `main` is currently suspended at) has produced.
    When we throw an exception that is being handled, the `sequence` coroutine produces
    the value `OK`, which is propagated to the called coroutine (`main`), and that
    in turn will end up at `main's` caller.
  prefs: []
  type: TYPE_NORMAL
- en: As anticipated, these methods, together with `yield from`, provide us with a
    lot of new functionality (something that can resemble threads). This opens up
    the doors for asynchronous programming, which we will explore next.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the constructions we have seen so far, we can create asynchronous programs
    in Python. This means that we can create programs that have many coroutines, schedule
    them to work in a particular order, and switch between them when they're suspended
    after a `yield from` has been called on each of them.
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage that we can take from this is the possibility of parallelizing
    I/O operations in a non-blocking way. What we would need is a low-level generator
    (usually implemented by a third-party library) that knows how to handle the actual
    I/O while the coroutine is suspended. The idea is for the coroutine to effect
    suspension so that our program can handle another task in the meantime. The way
    the application would retrieve the control back is by means of the `yield from`
    statement, which will suspend and produce a value to the caller (as in the examples
    we saw previously when we used this syntax to alter the control flow of the program).
  prefs: []
  type: TYPE_NORMAL
- en: This is roughly the way asynchronous programming had been working in Python
    for quite a few years, until it was decided that better syntactic support was
    needed.
  prefs: []
  type: TYPE_NORMAL
- en: The fact that coroutines and generators are technically the same causes some
    confusion. Syntactically (and technically), they are the same, but semantically,
    they are different. We create generators when we want to achieve efficient iteration.
    We typically create coroutines with the goal of running non-blocking I/O operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this difference is clear, the dynamic nature of Python would still allow
    developers to mix these different types of objects, ending up with a runtime error
    at a very late stage of the program. Remember that in the simplest and most basic
    form of the `yield from` syntax, we used this construction over iterable objects
    (we created a sort of `chain` function applied over strings, lists, and so on).
    None of these objects were coroutines, and it still worked. Then, we saw that
    we can have multiple coroutines, use `yield from` to send the value (or exceptions),
    and get some results back. These are clearly two very different use cases; however,
    if we write something along the lines of the following statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: It's not clear what `iterable_or_awaitable` returns. It can be a simple iterable
    such as a `string`, and it might still be syntactically correct. Or, it might
    be an actual coroutine. The cost of this mistake will be paid much later, at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, the typing system in Python had to be extended. Before Python
    3.5, coroutines were just generators with a `@coroutine` decorator applied, and
    they were to be called with the `yield from` syntax. Now, there is a specific
    type of object the Python interpreter recognizes as such, that is, a coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: This change heralded syntax changes as well. The `await` and `async def` syntax
    were introduced. The former is intended to be used instead of `yield from`, and
    it only works with `awaitable` objects (which coroutines conveniently happen to
    be). Trying to call `await` with something that doesn't respect the interface
    of an `awaitable` will raise an exception (this is a good example of how interfaces
    can help to achieve a more solid design, preventing runtime errors).
  prefs: []
  type: TYPE_NORMAL
- en: '`async def` is the new way of defining coroutines, replacing the aforementioned
    decorator, and this actually creates an object that, when called, will return
    an instance of a coroutine. In the same way as when you invoke a generator function,
    the interpreter will return you a generator object, when you invoke an object
    defined with `async def`, it''ll give you a coroutine object that has an `__await__`
    method, and therefore can be used in await expressions.'
  prefs: []
  type: TYPE_NORMAL
- en: Without going into all the details and possibilities of asynchronous programming
    in Python, we can say that despite the new syntax and the new types, this is not
    doing anything fundamentally different from the concepts we have covered in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind programming asynchronously in Python is that there is an `event`
    loop (typically `asyncio` because it's the one that is included in the `standard`
    library, but there are many others that will work just the same) that manages
    a series of coroutines. These coroutines belong to the event loop, which is going
    to call them according to its scheduling mechanism. When each one of these runs,
    it will call our code (according to the logic we have defined inside the coroutine
    we programmed), and when we want to get control back to the event loop, we call
    `await <coroutine>`, which will process a task asynchronously. The event loop
    will resume and another coroutine will take place while that operation is left
    running.
  prefs: []
  type: TYPE_NORMAL
- en: This mechanism represents the basics of how asynchronous programming works in
    Python. You can think that the new syntax added for coroutines (`async def` /
    `await`) is just an API for you to write code in a way that's going to be called
    by the event loop. By default, that event loop will typically be `asyncio` because
    it's the one that comes in the `standard` library, but any event loop system that
    matches the API would work. This means you can use libraries like `uvloop` ([https://github.com/MagicStack/uvloop](https://github.com/MagicStack/uvloop))
    and `trio` ([https://github.com/python-trio/trio](https://github.com/python-trio/trio)),
    and the code would work the same. You can even register your own event loop, and
    it should also work the same (provided compliance with the API, that is).
  prefs: []
  type: TYPE_NORMAL
- en: In practice, there are more particularities and edge cases that are beyond the
    scope of this book. It is, however, worth mentioning that these concepts are related
    to the ideas introduced in this chapter and that this arena is another place where
    generators demonstrate being a core concept of the language, as there are many
    things constructed on top of them.
  prefs: []
  type: TYPE_NORMAL
- en: Magic asynchronous methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I've made the case in previous chapters (and hopefully convinced you) that whenever
    possible, we can take advantage of the magic methods in Python in order to make
    the abstractions we created blend naturally with the syntax of the language and
    this way achieve better, more compact, and perhaps cleaner code.
  prefs: []
  type: TYPE_NORMAL
- en: But what happens if on any of these methods we need to call a coroutine? If
    we have to call `await` in a function, that means the function itself would have
    to be a coroutine (defined with `async def`), or else there will be a syntax error.
  prefs: []
  type: TYPE_NORMAL
- en: But then, how does this work with the current syntax and magic methods? It doesn't.
    We need new syntax, and new magic methods, in order to work with asynchronous
    programming. The good news is that they're analogous to the previous ones.
  prefs: []
  type: TYPE_NORMAL
- en: Here's a summary of the new magic methods and how they relate to the new syntax.
  prefs: []
  type: TYPE_NORMAL
- en: '| Concept | Magic methods | Syntax usage |'
  prefs: []
  type: TYPE_TB
- en: '| Context manager | `__aenter__``__aexit__` | `async with async_cm() as x:`...
    |'
  prefs: []
  type: TYPE_TB
- en: '| Iteration | `__aiter__``__anext__` | `async for e in aiter:`... |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7.2: Asynchronous syntax and their magic methods'
  prefs: []
  type: TYPE_NORMAL
- en: This new syntax is mentioned in PEP-492 ([https://www.python.org/dev/peps/pep-0492/](https://www.python.org/dev/peps/pep-0492/)).
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous context managers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The idea is simple: if we were to use a context manager but needed to call
    a coroutine on it, we couldn''t use the normal `__enter__` and `__exit__` methods
    because they''re defined as regular functions, so instead we need to use the new
    `__aenter__` and `__aexit__` coroutine methods. And instead of calling it merely
    using with, we''d have to use `async` with.'
  prefs: []
  type: TYPE_NORMAL
- en: There's even an `@asynccontextmanager` decorator available in the `contextlib`
    module, to create an asynchronous context manager in the same way as shown before.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `async` with syntax for asynchronous context managers works in a similar
    way: when the context is entered, the `__aenter__` coroutine is called automatically,
    and when it''s being exited, `__aexit__` will trigger. It''s even possible to
    group multiple asynchronous context managers in the same `async` with statement,
    but it''s not possible to mix them with regular ones. An attempt of using a regular
    context manager with the `async` with syntax will fail with an `AttributeError`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our example from *Chapter 2*, *Pythonic Code*, would look like the following
    code if adapted to asynchronous programming:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, if we had more than one context manager that we wanted to use, we could
    do, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: As you'd expect, the `contextlib` module provides the abstract base class `AbstractAsyncContextManager`,
    which requires the implementation of the `__aenter__` and `__aexit__` methods.
  prefs: []
  type: TYPE_NORMAL
- en: Other magic methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'What happens with the rest of the magic methods? Do they all get their asynchronous
    counterpart? No, but there''s something I wanted to point out about that: it shouldn''t
    be needed.'
  prefs: []
  type: TYPE_NORMAL
- en: Remember that achieving clean code is in part about making sure you distribute
    the responsibilities correctly in the code and place things in their proper places.
    To give an example, if you're thinking about calling a coroutine inside a `__getattr__`
    method, there's something probably amiss in your design, as there should probably
    be a better place for that coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines that we await are used in order to have parts of our code running
    concurrently, so they typically relate to external resources being managed, whereas
    the logic we put in the rest of the magic methods `(__getitem__`, `__getattr__`,
    etc.) should be object-oriented code, or code that can be resolved in terms of
    solely the internal representation of that object.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the same token (and also following up on good design practices), it wouldn''t
    be good to make `__init__` a coroutine, because we typically want lightweight
    objects that we can initialize safely without side effects. Even better, we have
    already covered the benefits of using dependency injection, so that''s even more
    reason not to want an asynchronous initialization method: our object should work
    with dependencies already initialized.'
  prefs: []
  type: TYPE_NORMAL
- en: The second case of the previous table, asynchronous iteration, is of more interest
    for the purposes of this chapter, so we'll explore it in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The syntax for asynchronous iteration (`async` for) works with any asynchronous
    iterator, whether it is created by us (as we'll see how to do in the next section),
    or whether it's an asynchronous generator (which we'll see in the section after
    that).
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous iteration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the same way that we have the iterator objects we saw at the beginning of
    the chapter (that is, objects that support being iterated over with Python's built-in
    `for` loop), we can do the same, but in an asynchronous fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine we want to create an iterator to abstract the way in which we read data
    from an external source (like a database), but the part that extracts the data
    itself is a coroutine, so we couldn't call it during the already familiar `__next__`
    operation as before. That's why we need to make use of the `__anext__` coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example illustrates in a simple way how this can be achieved.
    Disregarding external dependencies, or any other accidental complexity, we''ll
    focus on the methods that make this type of operation possible, in order to study
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The first method, `__aiter__`, is used to indicate that the object is an asynchronous
    iterator. Just as in the synchronous version, most of the time it's enough to
    return self, and therefore it doesn't need to be a coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: But `__anext__`, on the other hand, is precisely the part of our code where
    our asynchronous logic lies, so that needs to be a coroutine for starters. In
    this case, we're awaiting another coroutine in order to return part of the data
    to be returned.
  prefs: []
  type: TYPE_NORMAL
- en: It also needs a separate exception in order to signal the end of the iteration,
    in this case, called `StopAsyncIteration`.
  prefs: []
  type: TYPE_NORMAL
- en: This exception works in an analogous way, only that it's meant for the `async
    for` kind of loops. When encountered, the interpreter will finish the loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'This sort of object can be used in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: You can clearly see how this is analogous to the synchronous version we explored
    at the beginning of the chapter. One important distinction though is that, as
    we would expect, the `next()` function wouldn't work on this object (it doesn't
    implement `__next__` after all), so advancing an asynchronous generator by one
    place would require a different idiom.
  prefs: []
  type: TYPE_NORMAL
- en: 'Advancing the asynchronous iterator by one place could be achieved by doing
    something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: But more interesting constructions, like the ones we saw before about using
    the `next()` function to work over a generator expression to search for the first
    value that meets certain conditions, wouldn't be supported, because they're not
    capable of handling asynchronous iterators.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspired by the previous idiom, we can create a generator expression using
    the asynchronous iteration, and then take the first value from it. Better yet,
    we can create our own version of this function to work with asynchronous generators,
    which might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Starting from Python 3.8, the `asyncio` module has a nice capability that allows
    us to interact with coroutines directly from the REPL. That way, we can test interactively
    how the previous code would work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: You'll note that it resembles the original `next()` function both in terms of
    interface and behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Now we know how to use iteration in asynchronous programming, but we can do
    better than that. Most of the time we just need a generator and not a whole iterator
    object. Generators have the advantage that their syntax makes them easier to write
    and understand, so in the next section, I'll mention how to create generators
    for asynchronous programs.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous generators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before Python 3.6, the functionality explored in the previous section was the
    only way to achieve asynchronous iteration in Python. Because of the intricacies
    of the coroutines and generators we explored in previous sections, trying to use
    the `yield` statement inside a coroutine was not entirely defined, hence not allowed
    (for example, would `yield` try to suspend the coroutine, or generate a value
    for the caller?).
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous generators were introduced in PEP-525 ([https://www.python.org/dev/peps/pep-0525/](https://www.python.org/dev/peps/pep-0525/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The issue with the use of the `yield` keyword inside a coroutine was solved
    in this PEP, and it''s now allowed, but with a different and clear meaning. Unlike
    the first example of coroutines we have seen, `yield` inside a coroutine properly
    defined (with `async` def) doesn''t mean to suspend or pause the execution of
    that coroutine, but instead to produce a value for the caller. This is an asynchronous
    generator: same as the generators we''ve seen at the very beginning of the chapter,
    but that can be used in an asynchronous way (meaning they probably await other
    coroutines inside their definition).'
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage of asynchronous generators over iterators is the same advantage
    regular generators have; they allow us to achieve the same thing but in a more
    compact way.
  prefs: []
  type: TYPE_NORMAL
- en: 'As promised, the previous example looks more compact when written with an asynchronous
    generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This feels closer to a regular generator as the structure is the same except
    for the `async def` / `await` construction. Moreover, you'll have to remember
    fewer details (as to the methods that need implementation and the right exception
    that has to be triggered), so I'd recommend that whenever possible you try to
    favor asynchronous generators over iterators.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our journey through iteration in Python and asynchronous programming.
    In particular, this last topic we've just explored is the pinnacle of it, because
    it relates to all the concepts we've learned in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators are everywhere in Python. Since their inception in Python a long
    time ago, they proved to be a great addition that makes programs more efficient
    and iteration much simpler.
  prefs: []
  type: TYPE_NORMAL
- en: As time passed by, and more complex tasks needed to be added to Python, generators
    helped again in supporting coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: And, while in Python coroutines are generators, we still don't have to forget
    that they're semantically different. Generators are created with the idea of iteration,
    while coroutines have the goal of asynchronous programming (suspending and resuming
    the execution of a part of our program at any given time). This distinction became
    so important that it made Python's syntax (and type system) evolve.
  prefs: []
  type: TYPE_NORMAL
- en: Iteration and asynchronous programming constitute the last of the main pillars
    of Python programming. Now, it's time to see how everything fits together and
    to put all of these concepts we have been exploring over the past few chapters
    into action. This means that by now, you have a complete understanding of Python's
    capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: It's now time to use this to your advantage, so in the next chapters, we'll
    see how to put these concepts into action, related to more general ideas of software
    engineering, such as testing, design patterns, and architecture.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start this new part of our journey by exploring unit testing and refactoring
    in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is a list of information you can refer to:'
  prefs: []
  type: TYPE_NORMAL
- en: '*PEP-234*: *Iterators* ([https://www.python.org/dev/peps/pep-0234/](https://www.python.org/dev/peps/pep-0234/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-255*: *Simple Generators* ([https://www.python.org/dev/peps/pep-0255/](https://www.python.org/dev/peps/pep-0255/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ITER-01*: *Python''s itertools module* ([https://docs.python.org/3/library/itertools.html](https://docs.python.org/3/library/itertools.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*GoF*: The book written by *Erich Gamma*, *Richard Helm*, *Ralph Johnson*,
    and *John Vlissides* named *Design Patterns: Elements of Reusable Object-Oriented
    Software*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-342*: *Coroutines via Enhanced Generators* ([https://www.python.org/dev/peps/pep-0342/](https://www.python.org/dev/peps/pep-0342/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PYCOOK*: The book written by *Brian Jones* and *David Beazley* named *Python
    Cookbook: Recipes for Mastering Python 3, Third Edition*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PY99*: *Fake threads (generators, coroutines, and continuations)* ([https://mail.python.org/pipermail/python-dev/1999-July/000467.html](https://mail.python.org/pipermail/python-dev/1999-July/000467.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CORO-01*: *Co Routine* ([http://wiki.c2.com/?CoRoutine](http://wiki.c2.com/?CoRoutine))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CORO-02*: *Generators Are Not Coroutines* ([http://wiki.c2.com/?GeneratorsAreNotCoroutines](http://wiki.c2.com/?GeneratorsAreNotCoroutines))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-492*: *Coroutines with async and await syntax* ([https://www.python.org/dev/peps/pep-0492/](https://www.python.org/dev/peps/pep-0492/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-525*: *Asynchronous Generators* ([https://www.python.org/dev/peps/pep-0525/](https://www.python.org/dev/peps/pep-0525/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*TEE*: *The itertools.tee function* ([https://docs.python.org/3/library/itertools.html#itertools.tee](https://docs.python.org/3/library/itertools.html#itertools.tee))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
