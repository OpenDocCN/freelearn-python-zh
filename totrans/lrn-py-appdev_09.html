<html><head></head><body><div class="chapter" title="Chapter&#xA0;9.&#xA0;Improving Performance &#x2013; Part Two, NumPy and Parallelization"><div class="titlepage"><div><div><h1 class="title"><a id="ch09"/>Chapter 9. Improving Performance – Part Two, NumPy and Parallelization</h1></div></div></div><p>This is the final chapter in the series of the three chapters on performance improvement. It will introduce you to two important libraries, <a id="id656" class="indexterm"/>
<span class="strong"><strong>NumPy</strong></span>, a third-party package, and the built-in<a id="id657" class="indexterm"/> <span class="strong"><strong>multiprocessing</strong></span> module. In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A brief introduction to the NumPy package</li><li class="listitem" style="list-style-type: disc">Using NumPy to speed up the <span class="emphasis"><em>Gold Hunt</em></span> application</li><li class="listitem" style="list-style-type: disc">An introduction to parallel processing using the <code class="literal">multiprocessing</code> module</li><li class="listitem" style="list-style-type: disc">Using the <code class="literal">multiprocessing</code> module to further improve the application runtime</li></ul></div><div class="section" title="Prerequisites for this chapter"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec75"/>Prerequisites for this chapter</h1></div></div></div><p>You should read the last two chapters, <a class="link" href="ch07.html" title="Chapter 7. Performance – Identifying Bottlenecks">Chapter 7</a>, <span class="emphasis"><em>Performance – Identifying Bottlenecks</em></span>, and <a class="link" href="ch08.html" title="Chapter 8. Improving Performance – Part One">Chapter 8</a>, <span class="emphasis"><em>Improving Performance – Part one</em></span>, on performance that teaches you how to identify the performance bottlenecks and improve the runtime using built-in functionality. This chapter takes the application to the next level by drastically improving performance.</p></div></div>
<div class="section" title="This is how the chapter is organized"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec76"/>This is how the chapter is organized</h1></div></div></div><p>This chapter will be the <span class="emphasis"><em>Part two </em></span>of performance improvement. Just like the previous chapter, the performance of the <span class="emphasis"><em>Gold Hunt</em></span> program will be improved in steps. We will start with a quick introduction to NumPy, just enough to use its functionality for <span class="emphasis"><em>optimization passes four</em></span> and <span class="emphasis"><em>five</em></span>, which follow next. Moving ahead, there will be a superficial introduction to the <code class="literal">multiprocessing</code> module. In <span class="emphasis"><em>optimization pass six</em></span>, we will use this module to parallelize a portion of the application code. Let's pull up the same bar chart from the previous chapter. The last two bars indicate the speedup accomplished by the end of this chapter.</p><div class="mediaobject"><img src="graphics/B05034_09_01.jpg" alt="This is how the chapter is organized"/></div><p>But the chart does not tell the full story. The <span class="emphasis"><em>optimization pass four</em></span>, will significantly speedup the <code class="literal">generate_random_points</code> function of the <span class="emphasis"><em>Gold Hunt</em></span> program. This speedup is not reflected in the chart as the function does not significantly contribute to the runtime in this scenario. Towards the end, the chapter will provide preliminary information on <span class="strong"><strong>PyPy</strong></span>
<a id="id658" class="indexterm"/> for further reading. PyPy is a Python interpreter that provides a<a id="id659" class="indexterm"/> <span class="strong"><strong>Just In Time</strong></span> (<span class="strong"><strong>JIT</strong></span>) compiler.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note27"/>Note</h3><p>
<span class="strong"><strong>Running Gold Hunt optimization examples</strong></span>
</p><p>If you look closely at the profiling output shown in the upcoming discussion, you will notice a filename, <code class="literal">goldhunt_run_master.py</code>. Using this file is optional but it provides a convenient way to run any of the optimization passes. You can find this file in this chapter's supporting code bundle.</p></div></div></div>
<div class="section" title="Introduction to NumPy"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec77"/>Introduction to NumPy</h1></div></div></div><p>NumPy<a id="id660" class="indexterm"/> is a powerful Python package for scientific computing. It provides a multidimensional <code class="literal">array</code> object that enables efficient implementation of numerical computations in Python. It also has a relatively smaller memory footprint when compared to a list. An <code class="literal">array</code> object is just one of the many important features of NumPy. Among other things, it offers linear algebra and random number generation capabilities. It also provides tools to access codes written in other languages, such as C/C++ and Fortran. Let's start with a short introduction that gives a flavor of its capabilities. What we will discuss in this book is more like scratching the surface of NumPy! This chapter covers some features to be used later to speed up the <span class="emphasis"><em>Gold Hunt</em></span> application.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip91"/>Tip</h3><p>Review the official<a id="id661" class="indexterm"/> NumPy documentation (<a class="ulink" href="http://docs.scipy.org">http://docs.scipy.org</a>) to learn about several other features that are not covered here.</p><p>If you are already familiar with NumPy, you can optionally skip this introduction and directly move on to the <span class="emphasis"><em>Optimizing Gold Hunt – Part two </em></span>section.</p></div></div><div class="section" title="Installing NumPy"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec157"/>Installing NumPy</h2></div></div></div><p>Some Python <a id="id662" class="indexterm"/>distributions, such as Anaconda<a id="id663" class="indexterm"/> (<a class="ulink" href="https://www.continuum.io/downloads">https://www.continuum.io/downloads</a>), provide NumPy by default. If unavailable, use <code class="literal">pip</code> to install it. Here is how to do it on Linux, assuming <code class="literal">pip</code> is available as a command in the terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ pip install numpy </strong></span>
</pre></div><p>This should install NumPy. If you encounter problems, refer to the platform specific installation instructions at <a class="ulink" href="http://www.scipy.org/install.html">http://www.scipy.org/install.html</a>. Alternatively, you can use the earlier mentioned Anaconda Python distribution.</p><p>Once installed, open the Python interpreter and type the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; import numpy as np </strong></span>
</pre></div><p>Assuming the installation is successful, it should import NumPy. For the rest of the discussion, we will use the notation <code class="literal">np</code> as the alias for <code class="literal">numpy</code>. Keep the interpreter window open. For the rest of the introduction, we will run some simple NumPy operations.</p></div><div class="section" title="Creating array objects"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec158"/>Creating array objects</h2></div></div></div><p>As noted before, a <a id="id664" class="indexterm"/>multidimensional (<span class="strong"><strong>N-dimensional</strong></span>) array object is one of the core NumPy capabilities. This array is provided by a built-in class, <code class="literal">numpy.ndarray</code>. It represents a collection of elements of the same type. In other words, it is a homogeneous array. There are several ways to create a Numpy array. Type the following code in your Python interpreter:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; import numpy as np </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x = np.array([2, 4]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x </strong></span>
<span class="strong"><strong>array([2, 4])</strong></span>
</pre></div><p>This creates an array instance denoted by the <code class="literal">x</code> variable with two elements. This is of the <code class="literal">numpy.ndarray</code> type. It is a single dimensional array. You can access any element or change its value, just like a Python <code class="literal">list</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; x[0] </strong></span>
<span class="strong"><strong>2 </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x[0]=8 </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x </strong></span>
<span class="strong"><strong>array([8, 4]) </strong></span>
</pre></div><p>In this simple example, the size of the array is <code class="literal">2</code>. This is also called the <span class="emphasis"><em>shape</em></span> of an array. NumPy represents the array shape as a tuple of integers. It gives the size of the array along each dimension. This is shown in the following line of code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; x.shape </strong></span>
<span class="strong"><strong>(2,)</strong></span>
</pre></div><p>Continuing further, here is another example that creates a two-dimensional array:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; p = np.array([[4, 8], [10, 20]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; p </strong></span>
<span class="strong"><strong>array([[ 4,  8], </strong></span>
<span class="strong"><strong>       [10, 20]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; p.ndim</strong></span>
<span class="strong"><strong>2</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; p.shape </strong></span>
<span class="strong"><strong>(2, 2)</strong></span>
</pre></div><p>Here, <code class="literal">ndim</code> represents the number<a id="id665" class="indexterm"/> of dimensions of an array. The array shape indicates the size of two in each dimension.</p><p>Let's review the <code class="literal">numpy.arange</code> function. This is similar to the Python <code class="literal">range</code> function. But, <code class="literal">arange </code>returns an <code class="literal">array</code> object instead of a <code class="literal">list</code>. The following is another way to create an array using <code class="literal">numpy.arange</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; a = np.arange(10) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; a </strong></span>
<span class="strong"><strong>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) </strong></span>
</pre></div><p>There are many other ways to create <a id="id666" class="indexterm"/>arrays in NumPy. Refer to the documentation, (<a class="ulink" href="http://docs.scipy.org/doc/numpy/reference/">http://docs.scipy.org/doc/numpy/reference/</a>) for more details. Specifically, look for array creation routines.</p></div><div class="section" title="Simple array operations"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec159"/>Simple array operations</h2></div></div></div><p>We will review some <a id="id667" class="indexterm"/>basic mathematical operations that can be performed on NumPy arrays. Let's create two arrays, <code class="literal">x</code> and <code class="literal">y</code> (these are one-dimensional arrays or vectors):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; import numpy as np </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x = np.array([2, 4]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; y = np.array([2, 4]) </strong></span>
</pre></div><p>Using these arrays, you can perform mathematical operations, such as addition, subtraction, multiplication, and so on. NumPy performs all these operations element by element:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; x - y </strong></span>
<span class="strong"><strong>array([0, 0]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x + y </strong></span>
<span class="strong"><strong>array([4, 8]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x*y </strong></span>
<span class="strong"><strong>array([ 4, 16]) </strong></span>
</pre></div><p>It is important to note here that <code class="literal">x*y</code> is not the inner product. It is just a multiplication of the corresponding elements in the <code class="literal">x</code> and <code class="literal">y</code> arrays. The inner product of these vectors can be accomplished using the <code class="literal">dot</code> function, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; x.dot(y) </strong></span>
<span class="strong"><strong>20 </strong></span>
</pre></div><p>The following code illustrates the concept using a two-dimensional array. Here, <code class="literal">x2.dot(y2)</code> is a matrix multiplication operation:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; x2 = np.array([[2, 4], [6, 8]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; y2 = np.array([[2, 4], [1, 2]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x2*y2 </strong></span>
<span class="strong"><strong>array([[ 4, 16], </strong></span>
<span class="strong"><strong>       [ 6, 16]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x2.dot(y2) </strong></span>
<span class="strong"><strong>array([[ 8, 16], </strong></span>
<span class="strong"><strong>       [20, 40]])</strong></span>
</pre></div></div><div class="section" title="Array slicing and indexing"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec160"/>Array slicing and indexing</h2></div></div></div><p>For single dimensional arrays, the <span class="strong"><strong>indexing</strong></span>
<a id="id668" class="indexterm"/> and <span class="strong"><strong>slicing</strong></span>
<a id="id669" class="indexterm"/> operations are similar to a Python <code class="literal">list</code>. If you are unfamiliar with the <code class="literal">list</code> slicing operation, refer<a id="id670" class="indexterm"/> to <a class="ulink" href="https://docs.python.org/3/tutorial/introduction.html#lists">https://docs.python.org/3/tutorial/introduction.html#lists</a>. This is an important concept. In this chapter, we will only need to perform a few basic indexing operations.</p><div class="section" title="Indexing"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec80"/>Indexing</h3></div></div></div><p>Array indexing is <a id="id671" class="indexterm"/>essentially an operation that enables us to access a particular element in an array. Here is a simple one-dimensional array with a size of five:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; b = np.arange(5) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; b </strong></span>
<span class="strong"><strong>array([0, 1, 2, 3, 4]) </strong></span>
</pre></div><p>The simplest indexing operation is shown below, which accesses an element of this array. This operation is similar to how it is done for a Python <code class="literal">list</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; b[2] </strong></span>
<span class="strong"><strong>2 </strong></span>
</pre></div><p>Here is how you can retrieve elements from a two-dimensional array:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; p = np.array([[2,2], [4,4]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; p </strong></span>
<span class="strong"><strong>array([[2, 2], </strong></span>
<span class="strong"><strong>       [4, 4]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; p[0] </strong></span>
<span class="strong"><strong>array([2, 2]) </strong></span>
</pre></div><p>Once complete, it returns an array with only the first row.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip92"/>Tip</h3><p>It is important to note that the basic array indexing does not return a copy of the original array. It just points to the same memory location as the original array. Refer to the following link where the basic and <a id="id672" class="indexterm"/>advanced indexing has been comprehensively documented: <a class="ulink" href="http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html">http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html</a>
</p></div></div><p>The following code will retrieve a single value from a two-dimensional array:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; p[0][1] </strong></span>
<span class="strong"><strong>2</strong></span>
</pre></div><p>With this basic introduction to array indexing, let's learn about some common slicing operations.</p></div><div class="section" title="Slicing"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec81"/>Slicing</h3></div></div></div><p>Suppose you want to get an array with only the <a id="id673" class="indexterm"/>first two elements. Just like a <code class="literal">list</code>, you will need to specify a start and an end. For example, <code class="literal">b[start:stop]</code> means the resulting (sliced) array will begin at the <code class="literal">start</code> index and end at the <code class="literal">stop-1</code> index:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; b[0:2] </strong></span>
<span class="strong"><strong>array([0, 1]) </strong></span>
</pre></div><p>Similarly, to get any array with only the elements at the positions <code class="literal">1</code> and <code class="literal">2</code>, you can do as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; b[1:3] </strong></span>
<span class="strong"><strong>array([1, 2]) </strong></span>
</pre></div><p>For the N-dimensional arrays, you have to give the slicing instructions in each direction. Consider the following array with four rows and columns:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; z2 = np.array([[2, 4, 6, 8], [1, 5, 7, 9], [3, 3, 3, 3], [4, 4, 9, 4]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; z2 </strong></span>
<span class="strong"><strong>array([[2, 4, 6, 8], </strong></span>
<span class="strong"><strong>       [1, 5, 7, 9], </strong></span>
<span class="strong"><strong>       [3, 3, 3, 3], </strong></span>
<span class="strong"><strong>       [4, 4, 9, 4]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; z2.shape </strong></span>
<span class="strong"><strong>(4, 4) </strong></span>
</pre></div><p>Let's slice this array so that it returns only the first row. Here is the syntax to do that:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; z2[0:1, :] </strong></span>
<span class="strong"><strong>array([[2, 4, 6, 8]]) </strong></span>
</pre></div><p>If you want to get only the first column of <code class="literal">z2</code> instead, then specify the slicing as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; z2[:, 0:1] </strong></span>
<span class="strong"><strong>array([[2], </strong></span>
<span class="strong"><strong>       [1], </strong></span>
<span class="strong"><strong>       [3], </strong></span>
<span class="strong"><strong>       [4]]) </strong></span>
</pre></div><p>The following slicing operation will create a new array using elements of the first two rows and columns:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; z2[0:2, 0:2] </strong></span>
<span class="strong"><strong>array([[2, 4], </strong></span>
<span class="strong"><strong>       [1, 5]])</strong></span>
</pre></div><p>To gain a better understanding of array<a id="id674" class="indexterm"/> slicing operations, try more examples in a Python interpreter. See the documentation for details (search the Web for NumPy array slicing).</p></div></div><div class="section" title="Broadcasting"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec161"/>Broadcasting</h2></div></div></div><p>Broadcasting <a id="id675" class="indexterm"/>is another important NumPy feature. Let's understand this concept with a simple example. We have two arrays, <code class="literal">p0</code> and <code class="literal">p1</code>, as shown in the following example:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; p0 = np.array([10]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; p1 = np.array([[1, 2], [3,4]]) </strong></span>
</pre></div><p>The shapes of these arrays are as follows: </p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; p0.shape </strong></span>
<span class="strong"><strong>(1,) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; p1.shape </strong></span>
<span class="strong"><strong>(2,2) </strong></span>
</pre></div><p>Although the arrays have different shapes, NumPy can perform arithmetic operations on these arrays. A basic multiplication operation is shown next:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; p0*p1 </strong></span>
<span class="strong"><strong>array([[10, 20], </strong></span>
<span class="strong"><strong>       [30, 40]]) </strong></span>
</pre></div><p>This is referred to<a id="id676" class="indexterm"/> as broadcasting. The <code class="literal">p0</code> array has a smaller shape relative to <code class="literal">p1</code>. The broadcasting enables this array to work with <code class="literal">p1</code>. In this example, it enables the multiplication operation. Of course, the two arrays need to meet certain requirements to take advantage of this feature. Refer to the NumPy documentation to learn more about broadcasting.</p></div><div class="section" title="Miscellaneous functions"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec162"/>Miscellaneous functions</h2></div></div></div><p>Let's look at some advanced mathematical operations that you can perform using the NumPy arrays.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip93"/>Tip</h3><p>Most of the operations illustrated here will be used in the upcoming discussion on performance improvement using NumPy. So, pay close attention to this section.</p></div></div><div class="section" title="numpy.ndarray.tolist"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec82"/>numpy.ndarray.tolist</h3></div></div></div><p>This<a id="id677" class="indexterm"/> is a handy function that returns the NumPy array as a Python <code class="literal">list</code> object. Depending on the array dimension, it can be a nested list. Here is an example that shows this function in action:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; x = np.array([2, 4]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x_list = x.tolist() </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x_list </strong></span>
<span class="strong"><strong>[2, 4]</strong></span>
</pre></div></div><div class="section" title="numpy.reshape"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec83"/>numpy.reshape</h3></div></div></div><p>As<a id="id678" class="indexterm"/> the name suggests, it changes the shape of an array without actually changing its data. Look at the following code; the <code class="literal">x</code> array is one dimensional and has a size (shape) of <code class="literal">9</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; x = np.arange(9) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x </strong></span>
<span class="strong"><strong>array([0, 1, 2, 3, 4, 5, 6, 7, 8]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; x.shape </strong></span>
<span class="strong"><strong>(9,) </strong></span>
</pre></div><p>Let's see how to reshape this into a matrix that has three rows and columns. In other words, the following code returns an array with a new shape of <code class="literal">(3,3)</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; np.reshape(x, (3,3)) </strong></span>
<span class="strong"><strong>array([[0, 1, 2], </strong></span>
<span class="strong"><strong>       [3, 4, 5], </strong></span>
<span class="strong"><strong>       [6, 7, 8]]) </strong></span>
</pre></div><p>The new shape selected should be compatible with the original shape of the array; otherwise, it will throw an error. For the preceding example, if you reshape it as <code class="literal">np.reshape(x, (3,2))</code>, it will throw a value error complaining about changed size.</p></div><div class="section" title="numpy.random"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec84"/>numpy.random</h3></div></div></div><p>This <a id="id679" class="indexterm"/>module provides several functions for random sampling. For a detailed list, refer to <a class="ulink" href="http://docs.scipy.org/doc/numpy/reference/routines.random.html">http://docs.scipy.org/doc/numpy/reference/routines.random.html</a>.</p><p>Let's review <code class="literal">np.random.uniform</code> that draws samples from a uniform distribution:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; np.random.uniform(0.0, 2.0, size=3) </strong></span>
<span class="strong"><strong>array([ 0.24061728,  0.66123504,  1.86137435]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; np.random.uniform(0.0, 2.0, size=4) </strong></span>
<span class="strong"><strong>array([ 1.81382452,  1.20355728,  1.07085075,  0.9653697 ]) </strong></span>
</pre></div><p>The first two arguments of this function represent the lower (<code class="literal">0.0</code>) and upper (<code class="literal">2.0</code>) boundaries of the output interval. You can specify any float value as the limit. All the random values or samples generated by the function lie within these two limits. The default lower and upper limits are <code class="literal">0.0</code> and <code class="literal">1.0</code>, respectively. The <code class="literal">size</code> argument represents the shape of the output array. In the preceding example, it is specified as a single integer value. If you do not specify the <code class="literal">size</code> argument, it defaults to <code class="literal">None</code>. In that case, the function will simply return a single floating point number. The following is a slightly complicated example of when the <code class="literal">size</code> (or shape) argument is a tuple <code class="literal">(2,2)</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; np.random.uniform(0.0, 2.0, size=(2,2)) </strong></span>
<span class="strong"><strong>array([[  1.02970767e+00,   4.48798719e-02], </strong></span>
<span class="strong"><strong>       [  5.20609066e-04,   6.10167655e-01]]) </strong></span>
</pre></div><p>Have you already noticed a difference between Python's built-in <code class="literal">random.uniform</code> function and NumPy equivalent's <code class="literal">np.random.uniform</code>? The Numpy <code class="literal">np.random.uniform</code> function, can optionally give us an <code class="literal">array</code> object with samples drawn from uniform distribution, whereas the built-in <code class="literal">random.uniform</code> can only give us a single number. We will use this NumPy function in <span class="emphasis"><em>optimization pass four</em></span>.</p></div><div class="section" title="numpy.dstack"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec85"/>numpy.dstack</h3></div></div></div><p>This <a id="id680" class="indexterm"/>provides a simple way to stack or concatenate a sequence of arrays along a third axis. Consider two NumPy arrays, <code class="literal">x</code> and <code class="literal">y</code>, representing the x and y coordinates of some points in space. These arrays are shown below:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; x = np.array((1, 2, 3, 4)) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; y = np.array((10, 20, 30, 40)) </strong></span>
</pre></div><p>Thus, <code class="literal">x[0]=1</code> and <code class="literal">y[0]=10</code> represent a point <code class="literal">(1, 10)</code>. Likewise, we can represent other points for the remaining elements. Sometimes, it is convenient to use a single array to express the coordinates of several such points, as follows:</p><div class="informalexample"><pre class="programlisting">points = [ [1,10], [2,20], [3, 30], [4, 40]] </pre></div><p>How do we create such an array using the <code class="literal">x</code> and <code class="literal">y</code> arrays shown earlier? There are multiple ways to do this. One option is to use <code class="literal">numpy.dstack</code>. This function enables stacking arrays along a third axis to create a single array. The following code shows how to create a <code class="literal">points</code> array discussed earlier using the input <code class="literal">x</code> and <code class="literal">y</code> arrays:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; points = np.dstack((x,y)) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; points </strong></span>
<span class="strong"><strong>array([[[ 1, 10], </strong></span>
<span class="strong"><strong>        [ 2, 20], </strong></span>
<span class="strong"><strong>        [ 3, 30], </strong></span>
<span class="strong"><strong>        [ 4, 40]]]) </strong></span>
</pre></div><p>Notice that the resultant array is three-dimensional:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; points.ndim </strong></span>
<span class="strong"><strong>3 </strong></span>
</pre></div><p>The size of the array along each axis (or dimension) is given by its shape:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; points.shape </strong></span>
<span class="strong"><strong>(1, 4, 2) </strong></span>
</pre></div><p>We will use this function in <span class="emphasis"><em>optimization pass five</em></span>. Similarly, there are other ways of stacking arrays, for example, <code class="literal">numpy.hstack</code> or <code class="literal">numpy.vstack</code>. These are not discussed in this book. Refer to the NumPy documentation for further details.</p></div><div class="section" title="numpy.einsum"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec86"/>numpy.einsum</h3></div></div></div><p>This<a id="id681" class="indexterm"/> function provides a way to compute the <span class="strong"><strong>Einstein notation</strong></span>
<a id="id682" class="indexterm"/> (or <span class="strong"><strong>Einstein summation convention</strong></span>) on the input arrays for the operations (called <span class="strong"><strong>operands</strong></span>). In terms of<a id="id683" class="indexterm"/> performance, this function offers great efficiency. Later in the chapter, we will exploit it to find the square of the distance between two points.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note28"/>Note</h3><p>Understanding the mathematical concept behind <code class="literal">einsum</code> can be a bit challenging, especially if you do not have a math background. In that case, just remember one key thing about <code class="literal">numpy.einsum</code>—It is a function that allows you to perform some highly efficient operations involving arrays. For example, a matrix multiplication operation between two NumPy arrays or a dot product can be done more efficiently using <code class="literal">numpy.einsum</code>.</p><p>Refer to the NumPy documentation for more information on this function. Also, see <a class="ulink" href="https://en.wikipedia.org/wiki/Einstein_notation">https://en.wikipedia.org/wiki/Einstein_notation</a> for information on <a id="id684" class="indexterm"/>Einstein notation.</p></div></div><p>This can be<a id="id685" class="indexterm"/> better explained with an example. Consider the following equations that represent two vectors, <span class="emphasis"><em>A</em></span> and <span class="emphasis"><em>B</em></span>:</p><div class="mediaobject"><img src="graphics/B05034_09_02.jpg" alt="numpy.einsum"/></div><p>These are two points in space with some <span class="emphasis"><em>x</em></span>, <span class="emphasis"><em>y</em></span>, and <span class="emphasis"><em>z</em></span> coordinates. The dot product of these vectors is represented as follows:</p><div class="mediaobject"><img src="graphics/B05034_09_03.jpg" alt="numpy.einsum"/></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip94"/>Tip</h3><p>To learn more about a<a id="id686" class="indexterm"/> dot product, see <a class="ulink" href="https://en.wikipedia.org/wiki/Dot_product">https://en.wikipedia.org/wiki/Dot_product</a>.</p></div></div><p>It is a scalar product and can be represented as a summation, as shown in the following equation:</p><div class="mediaobject"><img src="graphics/B05034_09_04.jpg" alt="numpy.einsum"/></div><p>The Einstein summation convention for the preceding equation is written as follows:</p><div class="mediaobject"><img src="graphics/B05034_09_05.jpg" alt="numpy.einsum"/></div><p>Here, it is implied that <span class="emphasis"><em>AiBi</em></span> is a summation over <span class="emphasis"><em>i</em></span> with a lower bound of <span class="emphasis"><em>1</em></span> and upper bound of <span class="emphasis"><em>3</em></span>. This is the Einstein summation convention in a nutshell.</p><p>
<code class="literal">numpy.einsum</code> evaluates the Einstein summation convention on the given input arrays. The basic syntax is shown below—there are other optional arguments as well, but those are not shown here:</p><div class="informalexample"><pre class="programlisting">numpy.einsum(subscripts, *operands)</pre></div><p>The first <a id="id687" class="indexterm"/>argument, <code class="literal">subscripts</code>, is a string that represents a list of subscript labels. These are separated by a comma and each label represents a dimension of a particular operand. In the example we just saw, there was only one subscript label, <span class="emphasis"><em>i</em></span>. The second argument, <code class="literal">operands</code>, represents the input arrays (<span class="emphasis"><em>A</em></span> and <span class="emphasis"><em>B</em></span> in the example).</p><p>Suppose the <span class="emphasis"><em>A</em></span> and <span class="emphasis"><em>B</em></span> vectors are one dimensional. Their inner product can be represented with the subscript string <code class="literal">'i,i'</code>. This can be better explained with the following example:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; import numpy as np </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; a = np.array([2, 2]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; b = np.array([4, 4]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; np.einsum('i,i', a, b) </strong></span>
<span class="strong"><strong>16 </strong></span>
</pre></div><p>The arrays <code class="literal">a</code> and <code class="literal">b</code> are one dimensional. You can also cross-check the answer using the <code class="literal">numpy.inner</code> function, which returns the same answer:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; np.inner(a,b) </strong></span>
<span class="strong"><strong>16 </strong></span>
</pre></div><p>The <code class="literal">numpy.einsum</code> function is faster and also memory efficient. Now, take a look at the following code—it represents a dot product (or matrix multiplication) of two vectors, <code class="literal">a2</code> and <code class="literal">b2</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; a2 = np.array([[1,1], [2, 2]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; b2 = np.array([[4,4], [6, 6]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; np.einsum('ij,jk', a2, b2) </strong></span>
<span class="strong"><strong>array([[10, 10], </strong></span>
<span class="strong"><strong>       [20, 20]]) </strong></span>
</pre></div><p>The subscript string <a id="id688" class="indexterm"/>for <code class="literal">numpy.einsum </code>is <code class="literal">'ij,jk'</code>, where <code class="literal">ij</code> is the subscript for two dimensions of array <code class="literal">a2</code>, and <code class="literal">jk</code> is the one for array <code class="literal">b2</code>. The dot product can also be obtained by following this example:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; np.dot(a2, b2) </strong></span>
<span class="strong"><strong>array([[10, 10], </strong></span>
<span class="strong"><strong>       [20, 20]])</strong></span>
</pre></div></div><div class="section" title="Computing distance square with einsum"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec87"/>Computing distance square with einsum</h3></div></div></div><p>The examples shown so far<a id="id689" class="indexterm"/> should just give you a flavor of the <code class="literal">einsum</code> function. Let's only discuss how to use this function to calculate the square of the distance<a id="id690" class="indexterm"/> between two points. Again, for a comprehensive reference, refer to the NumPy documentation.</p><p>Consider any point<code class="literal"> p1</code> with coordinates (<code class="literal">0, 2</code>). Furthermore, assume that the center is located at (<code class="literal">0,</code> <code class="literal">0</code>). As the x coordinate of the <code class="literal">p1</code> point is <code class="literal">0</code>, you can easily determine the distance between <code class="literal">p1</code> and center as 2 units. The square of the distance can be found using the <code class="literal">einsum</code> function, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; p1 = np.array([0,2]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; center = np.array([0, 0]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; d = p1 - center </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; d </strong></span>
<span class="strong"><strong>array([0, 2]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; np.einsum('i,i', d, d) </strong></span>
<span class="strong"><strong>4 </strong></span>
</pre></div><p>Now, imagine that there are multiple such points and you want to find the square of the distance of each point from the center. Here is one way to compute this using <code class="literal">einsum</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; points = np.array([[0,2], [0,4], [2, 2], [4, 4]]) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; center = np.array([0,0]) </strong></span>
</pre></div><p>The <code class="literal">points</code> array represents a list of points. For each of these points, we will find a vector, with <code class="literal">center</code> as its starting point and the given point (from the <code class="literal">points</code> array) as its end. Let's represent the array of such vectors as <code class="literal">diff</code>, as shown in the following example:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; diffs = points - center </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; diffs.shape </strong></span>
<span class="strong"><strong>(4, 2) </strong></span>
<span class="strong"><strong>&gt;&gt;&gt; diffs </strong></span>
<span class="strong"><strong>array([[0, 2], </strong></span>
<span class="strong"><strong>       [0, 4], </strong></span>
<span class="strong"><strong>       [2, 2], </strong></span>
<span class="strong"><strong>       [4, 4]]) </strong></span>
</pre></div><p>As the center is (<code class="literal">0,0</code>), the <code class="literal">diff</code> array is essentially the same as the <code class="literal">points</code> array. The following line of code shows the <code class="literal">einsum</code> syntax—it uses the ellipsis notation (<code class="literal">…</code>), to the left of each term in the subscripts argument:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; np.einsum('...i,...i', diffs, diffs) </strong></span>
<span class="strong"><strong>array([ 4, 16,  8, 32]) </strong></span>
</pre></div><p>It returns an array that contains a square of the distances for each point in the <code class="literal">points</code> array. That's all we need!</p><p>What does this ellipsis notation do? Why didn't we use the earlier syntax?</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt;  np.einsum('i,i', d, d) </strong></span>
</pre></div><p>The earlier syntax involved<a id="id691" class="indexterm"/> single dimensional arrays (<code class="literal">d</code>) that<a id="id692" class="indexterm"/> had only one subscript label. We cannot use it here as the operand (or the <code class="literal">diffs</code> array) for the Einstein sum is a two-dimensional array. To understand this, let's look at the <code class="literal">diffs</code> array one more time:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; diffs </strong></span>
<span class="strong"><strong>array([[0, 2], </strong></span>
<span class="strong"><strong>       [0, 4], </strong></span>
<span class="strong"><strong>       [2, 2], </strong></span>
<span class="strong"><strong>       [4, 4]]) </strong></span>
</pre></div><p>Consider any row of this array. It is essentially a vector between a point and the center. For example, <code class="literal">[0, 2]</code> represents a vector between a center <code class="literal">[0,0]</code> and a point <code class="literal">[0,2]</code>. The other dimension of the array is to hold many such vectors. The ellipsis symbol, "<code class="literal">…</code>", is a convenient way to broadcast the second dimension. The alternative syntax to get the same result is as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt;&gt;&gt; np.einsum('ij,ij-&gt;i', diffs, diffs) </strong></span>
<span class="strong"><strong>array([ 4, 16,  8, 32]) </strong></span>
</pre></div><p>However, if the array shapes change further, you will need to work on constructing a proper subscript string for the <code class="literal">einsum</code> function again. The NumPy documentation has several examples that show how to <a id="id693" class="indexterm"/>use <code class="literal">einsum</code>. Here is a NumPy version 1.10 documentation: <a class="ulink" href="http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.einsum.html">http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.einsum.html</a>.</p></div></div><div class="section" title="Where to get more information on NumPy?"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec163"/>Where to get more information on NumPy?</h2></div></div></div><p>In the NumPy introduction, you were presented with several links to the documentation. Just for the completeness, let's summarize where to find more information on NumPy. You can start by visiting their <a id="id694" class="indexterm"/>website (<a class="ulink" href="http://www.numpy.org/">http://www.numpy.org/</a>) or just do a web search on NumPy to get to its homepage.</p><p>
<span class="strong"><strong>SciPy</strong></span> is<a id="id695" class="indexterm"/> another project worth mentioning. It is a library that integrates several open source tools for mathematics, science, and engineering disciplines. NumPy, matplotlib, and pandas are<a id="id696" class="indexterm"/> some of its core packages. See the project website (<a class="ulink" href="https://www.scipy.org/">https://www.scipy.org/</a>) for more information.</p><p>In an earlier discussion, several links were provided to the NumPy documentation. Looking at those links, you must have already noticed that they all point to the SciPy website. The documentation for both NumPy and SciPy is located at <a class="ulink" href="http://docs.scipy.org/doc/">http://docs.scipy.org/doc/</a>.</p><p>The open source pandas library<a id="id697" class="indexterm"/> is used for data analysis using Python. It provides high performance data structures and tools to analyze data. Refer to <a class="ulink" href="http://pandas.pydata.org/">http://pandas.pydata.org/</a> for more information.</p></div></div>
<div class="section" title="Optimizing Gold Hunt &#x2013; Part two"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec78"/>Optimizing Gold Hunt – Part two</h1></div></div></div><p>The previous section<a id="id698" class="indexterm"/> served as a short introduction to NumPy. Recall that, in earlier chapters, we gradually improved the runtime performance of the game. The last recorded timing was the one obtained with <span class="emphasis"><em>optimization pass three</em></span>. We successfully reduced the total runtime down to nearly 44 seconds from the original time of about 106 seconds. NumPy supports vectorized calculation routines such as element-wise multiplication. It internally uses efficient C loops that help run such operations faster. Let's leverage NumPy capabilities to speed up the <span class="emphasis"><em>Gold Hunt</em></span> game even further.</p><div class="section" title="Gold Hunt optimization – pass four"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec164"/>Gold Hunt optimization – pass four</h2></div></div></div><p>It is now time to resume the optimization operation for the <span class="emphasis"><em>Gold Hunt</em></span> problem. Let's start with <span class="emphasis"><em>optimization pass four</em></span>. We will focus our attention once again on the function, <code class="literal">generate_random_numbers</code>. As a refresher, the <code class="literal">cProfiler</code> output of the last optimization run reported the total time as ~ 2.6 seconds and a cumulative time, which includes the time spent by sub-functions, was ~ 5.2 seconds<span class="emphasis"><em>.</em></span>
</p><div class="mediaobject"><img src="graphics/B05034_09_06.jpg" alt="Gold Hunt optimization – pass four"/></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="emphasis"><em>You are right. For this example, it is not worth optimizing this piece of code. The 5.2 seconds time doesn't look that bad. At this time, the function is called only once, as indicated by the </em></span>
<code class="literal">ncalls</code><span class="emphasis"><em> column of the </em></span>
<code class="literal">cProfile</code><span class="emphasis"><em> output. But any future requirements can potentially make this function a new bottleneck. As an example, imagine a new game scenario where there are hundreds of such gold fields or places full of abandoned weapons. We might need to call such a function many times. This will increase the total time spent in generating points. Keeping this in mind, let's work on improving its performance.</em></span>
</p>
</td></tr></tbody></table></div><p>We will revamp the code <a id="id699" class="indexterm"/>from the previous optimization run (<code class="literal">goldhunt_pass3.py</code>). The supporting source code is in the <code class="literal">goldhunt_pass4.py</code> file. The first thing we will add is the NumPy <code class="literal">import</code> statement at the beginning of the file:</p><div class="informalexample"><pre class="programlisting">import numpy as np</pre></div><p>The reworked <code class="literal">generate_random_points</code> function is illustrated in the following code snippet:</p><div class="mediaobject"><img src="graphics/B05034_09_07.jpg" alt="Gold Hunt optimization – pass four"/></div><p>It is optional to use local <a id="id700" class="indexterm"/>variables such as <code class="literal">l_uniform</code>. Those are used here to skip the function reevaluation. This was already discussed in the <span class="emphasis"><em>Skipping the dots</em></span> section from the previous chapter. Let's review this function next:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Compare the new function with the previous implementation. The key thing to note here is the use of the NumPy functions, such as <code class="literal">np.random.uniform</code>, <code class="literal">np.sqrt</code>, and others in place of the built-in functions.</li><li class="listitem" style="list-style-type: disc">Another major difference is that we no longer need a <code class="literal">for</code> loop. The <code class="literal">np.random.uniform</code> function returns a NumPy array. The last argument specifies its size. Refer to the earlier introductory section on NumPy for more information on the <code class="literal">random.uniform</code> functionality.</li><li class="listitem" style="list-style-type: disc">The <code class="literal">x</code> and <code class="literal">y</code> coordinates are computed using the <code class="literal">radius</code> and <code class="literal">theta</code> arrays. Note that the variables, <code class="literal">x</code> and <code class="literal">y</code>, are created as NumPy arrays. For efficiency reasons, we will return these as Python lists. This is accomplished by using <code class="literal">numpy.ndarray.tolist()</code>, a method accessible to NumPy <code class="literal">array</code> objects.</li></ul></div><p>Let's profile this code and compare the performance with the previous optimization pass. Here is the command to execute this code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ python goldhunt_pass4.py</strong></span>
</pre></div><p>The profiler output is shown next:</p><div class="mediaobject"><img src="graphics/B05034_09_08.jpg" alt="Gold Hunt optimization – pass four"/></div><p>Observe the cumulative time column for the <code class="literal">generate_random_points</code> function. The cumulative time for the original function was ~ 5.2 seconds, that is now reduced to <code class="literal">0.346</code> seconds. This is already a significant improvement.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip95"/>Tip</h3><p>It is possible to further improve the performance of the <code class="literal">generate_random_points</code> function. For example, at the beginning of the function, you can compute the product <code class="literal">2*l_pi</code>, for example:</p><div class="informalexample"><pre class="programlisting">two_pi = 2*np.pi </pre></div><p>Then use this<a id="id701" class="indexterm"/> variable in the computation of <code class="literal">theta</code>. However, this will only result in a marginal improvement in the runtime.</p></div></div></div><div class="section" title="Gold Hunt optimization – pass five"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec165"/>Gold Hunt optimization – pass five</h2></div></div></div><p>In this optimization pass, we will further improve the runtime performance of the <code class="literal">GoldHunt.find_coins</code> method. The original method is shown in the following code snippet for convenience. You can also find it in an earlier <code class="literal">goldhunt_pass4.py</code> file. For more details, see the previous chapter's, <span class="emphasis"><em>Gold Hunt Optimization – Pass two</em></span> section.</p><div class="mediaobject"><img src="graphics/B05034_09_09.jpg" alt="Gold Hunt optimization – pass five"/></div><p>Recall that the last<a id="id702" class="indexterm"/> recorded runtime for this method was about 38 seconds. Our task is to improve it further. We will start the optimization work by making a small change to the <code class="literal">generate_random_points</code> function. Recall that this function returns the <code class="literal">x</code> and <code class="literal">y</code> coordinates of the <span class="emphasis"><em>gold coins</em></span> on the field as Python lists. Instead, let's return these as NumPy arrays.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip97"/>Tip</h3><p>If you have skipped reading the earlier introductory section on NumPy, now would be the time to go back and read it! The <span class="emphasis"><em>optimization pass five</em></span> uses the NumPy functions discussed in that section. More specifically, the code presented next uses the <code class="literal">einsum</code> and <code class="literal">dpstack</code> functions. You may find the <code class="literal">einsum</code> syntax confusing. Therefore, it is recommended that you read the introduction first before diving into the code.</p></div></div><p>In the <code class="literal">find_coins</code> method, we will use the NumPy functions that work efficiently with these NumPy arrays. The following code fragment shows the updated function:</p><div class="mediaobject"><img src="graphics/B05034_09_10.jpg" alt="Gold Hunt optimization – pass five"/></div><p>With this change, let's<a id="id703" class="indexterm"/> quickly review the reworked <code class="literal">find_coins</code> method next:</p><div class="mediaobject"><img src="graphics/B05034_09_11.jpg" alt="Gold Hunt optimization – pass five"/></div><p>Let's review the preceding code snippet:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Recall that our task is to find the square of the distance between any gold coin on the field and the center of the search circle, and then use this value to check if the gold coin lies inside the search circle.</li><li class="listitem" style="list-style-type: disc">The input argument, <code class="literal">x_list</code> and <code class="literal">y_list</code>, are the NumPy arrays representing the x and y positions of the gold coins on the field.</li><li class="listitem" style="list-style-type: disc">Using these coordinates, we will create a single <code class="literal">points</code> array that contains (x, y) coordinate pairs as its elements. This is accomplished using <code class="literal">numpy.dstack</code>. See the earlier introductory section on NumPy for an example usage.</li><li class="listitem" style="list-style-type: disc">Next, we will find the <a id="id704" class="indexterm"/>vector between each point in the <code class="literal">points</code> array and the <code class="literal">center</code> array for the search circle. These vectors are stored as the elements of the <code class="literal">diff</code> array.</li><li class="listitem" style="list-style-type: disc">Using this <code class="literal">diff</code> array, we will find the square of the distances between all the gold coins from the center using <code class="literal">einsum</code>. See an earlier, <span class="emphasis"><em>Computing distance square with einsum</em></span> section, where this was discussed in detail.</li><li class="listitem" style="list-style-type: disc">Finally, we will check if the gold coin lies inside the circle by comparing the distance squares. The <code class="literal">enumerate()</code> function is a built-in function that presents a cleaner way to get the current index (<code class="literal">i</code>) of the loop and the corresponding value (<code class="literal">d</code>).</li></ul></div><p>The code is ready. Now, it is time to profile it:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ python goldhunt_pass5.py</strong></span>
</pre></div><p>The profiler output is shown below:</p><div class="mediaobject"><img src="graphics/B05034_09_12.jpg" alt="Gold Hunt optimization – pass five"/></div><p>Observe that the <a id="id705" class="indexterm"/>cumulative time taken by the <code class="literal">find_coins</code> function has gone down to ~19.5 seconds from the earlier ~ 38 seconds. It is nearly a 50% improvement for this function alone. Also, the total runtime is now ~ 21.5 seconds compared to the previous timing of ~38 seconds.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip98"/>Tip</h3><p>It is possible to improve the performance of <code class="literal">find_coins</code> by using list comprehension instead of the <code class="literal">for</code> loop. However, the improvement will be marginal. You can try it as an exercise (no solution is provided). Here is a sample code that uses list comprehension:</p><div class="informalexample"><pre class="programlisting">collected_coins = [(x_list[i], y_list[i]) 
                    for i, d in enumerate(dist_sq_list) 
                    if d &lt;= search_radius_square]</pre></div></div></div></div></div>
<div class="section" title="Parallelization with the multiprocessing module"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec79"/>Parallelization with the multiprocessing module</h1></div></div></div><p>Before jumping onto the discussion of the <code class="literal">multiprocessing</code> module, let's first understand what we mean by parallelization. This will be a very short introduction to parallelization, just enough to understand how to use some features of the <code class="literal">multiprocessing</code> module.</p><div class="section" title="Introduction to parallelization"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec166"/>Introduction to parallelization</h2></div></div></div><p>Imagine you are standing in a long queue at a checkout counter in a grocery store, waiting for your turn. Now, three more counters are opened to serve the customers and the existing queue is split. As a result, you can pay and get out of the store quickly.</p><p>Parallelization, in<a id="id706" class="indexterm"/> some sense, accomplishes similar results. In this example, each counter can be imagined as a separate process, carrying out independent tasks of accepting payments. The initial queue of the customers can be imagined as your program. This long queue is then divided into independent queues (or tasks), processing them parallely on separate counters (processes).</p><p>The <span class="emphasis"><em>Gold Hunt</em></span> program we have written so far runs serially. The program executes a set of tasks one after another on a single processor. This is analogous to the single counter in the previously mentioned grocery store example. Many times, it is possible to split the program into smaller tasks and run them independently using multiple processes or threads.</p><p>Let's quickly review two broad programming models that handle parallel process communications. These are <span class="strong"><strong>shared memory</strong></span> and <span class="strong"><strong>distributed memory</strong></span> parallelization.</p><div class="section" title="Shared memory parallelization"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec88"/>Shared memory parallelization</h3></div></div></div><p>In the shared memory <a id="id707" class="indexterm"/>programming model, the parallel processes access <a id="id708" class="indexterm"/>the same memory segment. Thus, the exchange of data and the communication between processes happens through this common memory. This programming model is often referred to as <span class="emphasis"><em>threaded programming</em></span>. The disadvantage of the shared memory model is something known as a <a id="id709" class="indexterm"/>
<span class="strong"><strong>race condition</strong></span>. Here, multiple threads compete to access or modify, for instance, data at a memory location. The race condition can be avoided by controlling access to that critical information using <span class="emphasis"><em>locks</em></span>. However, this adds to the programming <a id="id710" class="indexterm"/>overhead. Refer to <a class="ulink" href="https://en.wikipedia.org/wiki/Shared_memory">https://en.wikipedia.org/wiki/Shared_memory</a> for further information.</p></div><div class="section" title="Distributed memory parallelization"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec89"/>Distributed memory parallelization</h3></div></div></div><p>Here, each <a id="id711" class="indexterm"/>process gets its own memory space. The processes <a id="id712" class="indexterm"/>do not share any memory resources, and they run independent of each other. The communication between the processes happens over inter-process communication channels. This is referred to as <a id="id713" class="indexterm"/>
<span class="strong"><strong>message passing</strong></span>. To learn more <a id="id714" class="indexterm"/>about message passing, see <a class="ulink" href="https://en.wikipedia.org/wiki/Message_passing">https://en.wikipedia.org/wiki/Message_passing</a>. Since the processes do not share the same memory space, there is an additional communication overhead associated with the distributed memory mechanism.</p></div></div><div class="section" title="Global interpreter lock"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec167"/>Global interpreter lock</h2></div></div></div><p>In Python, the <code class="literal">threading</code> module provides a high-level interface for thread based parallelization. To avoid the race condition discussed earlier, Python employs a mechanism called <a id="id715" class="indexterm"/>
<span class="strong"><strong>global interpreter lock</strong></span> (<span class="strong"><strong>GIL</strong></span>). When a thread is executing a block of code, a global lock is acquired. This lock makes sure that only one thread is executed at a time in the Python interpreter environment. The disadvantage of GIL is that you cannot take full advantage of a multiprocessor machine.</p></div><div class="section" title="The multiprocessing module"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec168"/>The multiprocessing module</h2></div></div></div><p>The <code class="literal">multiprocessing</code> module <a id="id716" class="indexterm"/>addresses the GIL problem and provides a simple way to parallelize Python programs. Instead of using threads, it uses sub-processes and avoids GIL. In this module, the exchange of data between processes is supported using two communication channels, a <code class="literal">Queue</code> class and a <code class="literal">Pipe</code> function. This module also provides several other useful features, such as <span class="emphasis"><em>managers</em></span> and <span class="emphasis"><em>proxy objects</em></span>. The <code class="literal">Manager</code> object is created using <code class="literal">multiprocessing.Manager()</code>. It controls a server process that manages the Python objects. The manager also enables other processes to manipulate these Python objects using proxies. Discussing these features is beyond the scope of this book. Python documentation has great examples of how these features work. Refer<a id="id717" class="indexterm"/> to <a class="ulink" href="https://docs.python.org/3/library/multiprocessing.html">https://docs.python.org/3/library/multiprocessing.html</a> for more information.</p><p>In this chapter, we will cover only a few features of the <code class="literal">Pool</code> class.</p><div class="section" title="The Pool class"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec90"/>The Pool class</h3></div></div></div><p>The <code class="literal">multiprocessing.Pool</code> class provides<a id="id718" class="indexterm"/> a simple approach to parallelize the program. It is used to manage a pool of worker processes and defines methods that enable various ways to run the given tasks parallely.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip99"/>Tip</h3><p>The other basic approach is to use the <code class="literal">Process</code> class, which is not discussed in this book. See the previous documentation link for details.</p></div></div><p>The <code class="literal">Pool.map</code> and <code class="literal">Pool.apply</code> methods are among the ones frequently used. These are the parallel equivalents of the Python built-in <code class="literal">map</code> and <code class="literal">apply</code> functions. Both these methods block the main program until a worker process is finished and the results are ready. The blocking nature is useful if you are interested in getting a sequential output from the parallel processes. They also have their asynchronous variants, namely <code class="literal">map_async</code> and <code class="literal">apply_async</code>. The asynchronous variants are better suited to run parallel jobs where you don't care about the order in which results are returned by the processes.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip100"/>Tip</h3><p>The <code class="literal">apply</code> function is no longer a built-in function in Python 3. However, it was supported in Python 2.7. You can refer to Python 2 documentation to learn what this function does.</p></div></div><p>Let's work on a simple example that shows how to use the <code class="literal">Pool</code> class and its methods, <code class="literal">map</code> and <code class="literal">apply</code>. Observe the following code:</p><div class="mediaobject"><img src="graphics/B05034_09_13.jpg" alt="The Pool class"/></div><p>Let's review the<a id="id719" class="indexterm"/> preceding code snippet:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We start by importing the <code class="literal">multiprocessing</code> module.</li><li class="listitem" style="list-style-type: disc">The <code class="literal">pool</code> instance is created with two worker processes. You can specify the number of worker processes as an optional input argument.</li><li class="listitem" style="list-style-type: disc">After creating a pool of workers, the <code class="literal">pool.map</code> method is called. As previously stated, this is a parallel equivalent of the built-in <code class="literal">map</code> function. The first argument is a trivial function called <code class="literal">get_result</code>. This function is applied to the <code class="literal">iterable</code> specified as the second argument.</li><li class="listitem" style="list-style-type: disc">In this case, the <code class="literal">get_result</code> function is applied on each element of the <code class="literal">numbers</code> list. Inside this function, we also print the name of the current worker process doing the job.</li><li class="listitem" style="list-style-type: disc">The <code class="literal">pool.close()</code> method stops the worker processes after execution, whereas the <code class="literal">pool.join()</code> method blocks until the worker process terminates. This mimics the API provided by the <code class="literal">threading</code> module.</li></ul></div><p>The preceding <a id="id720" class="indexterm"/>code can also be found in <code class="literal">pool_example.py</code>. In this file, you just need to enable the relevant code and disable the other function calls. The file can be run from the Command Prompt, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ python  pool_example.py </strong></span>
</pre></div><p>Here is a sample command-line output after this execution:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Current process: ForkPoolWorker-1 , Input Number: 2 </strong></span>
<span class="strong"><strong>Current process: ForkPoolWorker-2 , Input Number: 4 </strong></span>
<span class="strong"><strong>Current process: ForkPoolWorker-2 , Input Number: 6 </strong></span>
<span class="strong"><strong>Current process: ForkPoolWorker-1 , Input Number: 8 </strong></span>
<span class="strong"><strong>Output: [20, 40, 60, 80] </strong></span>
</pre></div><p>Notice that the elements of the output list (<code class="literal">mylist</code>) are arranged in the same order as the input list (<code class="literal">numbers</code>). In other words, we have the input as <code class="literal">[2, 4, 6, 8]</code> and the output is 10 times each element, given as <code class="literal">[20, 40, 60, 80]</code>. This may or may not be the case for asynchronous variants. It will depend on which order the processes finish and return the results for.</p><p>With just a single line change, we can run the same example using <code class="literal">Pool.apply</code>. The following code snippet shows how to do this. The <code class="literal">get_result</code> function is not shown as it remains the same as before, as follows:</p><div class="mediaobject"><img src="graphics/B05034_09_14.jpg" alt="The Pool class"/></div><p>Here, we created <code class="literal">mylist</code> using list comprehension. For each element of the <code class="literal">numbers</code> list, it calls the <code class="literal">Pool.apply</code> method. The first argument to the method is the name of the function whereas the second argument, <code class="literal">args</code>,is used to specify the other arguments to this function. This method offers convenient syntax to specify any number of arguments to the function being sent to the worker processes. The rest of the code and programming output remains the same, as shown in the <code class="literal">Pool.map</code> method example. Let's review one of the asynchronous variants, <code class="literal">Pool.apply_async</code>. The code is shown as follows:</p><div class="mediaobject"><img src="graphics/B05034_09_15.jpg" alt="The Pool class"/></div><p>Let's talk through <a id="id721" class="indexterm"/>this code:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">This involves two changes. The first one is a trivial one. The <code class="literal">apply</code> method is simply replaced with <code class="literal">apply_async</code> (shown highlighted). There is no change in the method syntax.</li><li class="listitem" style="list-style-type: disc">However, the output of the <code class="literal">apply_async</code> call does not directly give us the final values we need. Instead, it returns the object of a <code class="literal">Pool.ApplyResult</code> class.</li><li class="listitem" style="list-style-type: disc">In this example, <code class="literal">apply_async</code> is used inside a list comprehension. So, the elements of the <code class="literal">results</code> list are objects of the <code class="literal">ApplyResult</code> class.</li><li class="listitem" style="list-style-type: disc">The final value can be obtained using the <code class="literal">ApplyResult.get()</code> method. We do this using a list comprehension, as shown in the preceding image. Alternatively, you can also use the generator expression syntax discussed in the previous chapter.</li></ul></div><p>With this short introduction on parallelization, let's see how to parallelize some functionality from the <span class="emphasis"><em>Gold Hunt</em></span> application.</p></div></div></div>
<div class="section" title="Parallelizing the Gold Hunt program"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec80"/>Parallelizing the Gold Hunt program</h1></div></div></div><p>Looking at the previous profiler output, the <code class="literal">find_coins</code> function is still the main bottleneck with ~19.5<a id="id722" class="indexterm"/> seconds of cumulative time. Let's see how parallelization can help speed it up further.</p><div class="section" title="Revisiting the gold field"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec169"/>Revisiting the gold field</h2></div></div></div><p>Here is the <span class="emphasis"><em>gold field</em></span> image<a id="id723" class="indexterm"/> from <a class="link" href="ch07.html" title="Chapter 7. Performance – Identifying Bottlenecks">Chapter 7</a>, <span class="emphasis"><em>Performance – Identifying Bottlenecks</em></span>:</p><div class="mediaobject"><img src="graphics/B05034_09_16.jpg" alt="Revisiting the gold field"/></div><p>Let's quickly summarize what we already saw in <a class="link" href="ch07.html" title="Chapter 7. Performance – Identifying Bottlenecks">Chapter 7</a>, <span class="emphasis"><em>Performance – Identifying Bottlenecks</em></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <code class="literal">find_coins</code> method is called for each of the small search circles shown in the figure. So, if there are 10 search circles, <code class="literal">find_coins</code> will be called 10 times, one after the other.</li><li class="listitem" style="list-style-type: disc">The <code class="literal">find_coins</code> method returns the coordinates of the gold coins lying inside the given search circle.</li><li class="listitem" style="list-style-type: disc">The information about all such collected coins is maintained in a list object.</li></ul></div><p>There is one important thing to note here. It is a serial execution. You start with the first circle, collect the <a id="id724" class="indexterm"/>coins and move on to the next one, and repeat the procedure until you hit the other end of the field.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="emphasis"><em>So how can we further enhance the search operation? Any thoughts, Mr. Great Dwarf?</em></span>
</p>
</td></tr></tbody></table></div><div class="mediaobject"><img src="graphics/B05034_09_17.jpg" alt="Revisiting the gold field"/></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="emphasis"><em>Perfect! The search</em></span>
<a id="id725" class="indexterm"/>
<span class="emphasis"><em> operation inside each circle is independent of the others. Therefore, the </em></span>
<code class="literal">find_coins</code><span class="emphasis"><em> function can be independently executed for each search circle. This is an ideal candidate for parallelization.</em></span>
</p>
</td></tr></tbody></table></div><div class="mediaobject"><img src="graphics/B05034_09_18.jpg" alt="Revisiting the gold field"/></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="emphasis"><em>That is even better!</em></span>
</p>
<p>
<span class="emphasis"><em>Since the order in which the results are returned (by the worker processes) is not important, we can use </em></span>
<code class="literal">Pool.apply_async</code><span class="emphasis"><em> to parallelize this task.</em></span>
</p>
</td></tr></tbody></table></div></div><div class="section" title="Gold Hunt optimization – Pass six, parallelization"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec170"/>Gold Hunt optimization – Pass six, parallelization</h2></div></div></div><p>As a first step, you should skim <a id="id726" class="indexterm"/>through the <code class="literal">play</code> method of the last <span class="emphasis"><em>optimization pass five</em></span>. Most of the changes we are about to make will be in this method. Additionally, we will pass some more arguments to the <code class="literal">find_coins</code> method.</p><p>So, we decided to use a pool of worker processes represented by a <code class="literal">Pool</code> object. The <span class="emphasis"><em>work queue</em></span> of this <code class="literal">Pool</code> object consists of all the search circles inside the gold field shown earlier. Each worker process will parallely run the search operation (<code class="literal">find_coins</code>), and it doesn't depend on other search circles. Generally, the worker processes within a <code class="literal">Pool</code> object are not terminated until the complete work queue is processed. When a worker process is done finding the coins in a particular search circle, it may get assigned to perform this operation for another search circle.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="emphasis"><em>So what changes are required to be done to the play method? The code will be very similar to the basic example of </em></span>
<code class="literal">apply_async</code><span class="emphasis"><em>, as seen earlier. Does anything else need to be changed in the existing method? Our friend Elf has a question...</em></span>
</p>
</td></tr></tbody></table></div><div class="mediaobject"><img src="graphics/B05034_09_19.jpg" alt="Gold Hunt optimization – Pass six, parallelization"/></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="emphasis"><em>You are spot on! The existing </em></span>
<code class="literal">play</code><span class="emphasis"><em> method serially runs the search operation. It starts with the leftmost circle, finds the coins, and moves on to the next circle by updating</em></span> <code class="literal">x_ref</code>.<span class="emphasis"><em> Note that we have chosen </em></span>
<code class="literal">y_ref</code> <span class="emphasis"><em>as</em></span> <code class="literal">0.0</code><span class="emphasis"><em> in this example.</em></span>
</p>
<p>
<span class="emphasis"><em>When we run this search</em></span>
<a id="id727" class="indexterm"/>
<span class="emphasis"><em> operation on parallel processes, each circle will have its unique center coordinates. We need to provide appropriate values of these coordinates to each parallel process. To do this, let's remove the dependence on </em></span>
<code class="literal">x_ref</code><span class="emphasis"><em> and</em></span> <code class="literal">y_ref</code><span class="emphasis"><em>. The center coordinates of all the circles will be determined and stored in a list before parallelizing the search operation.</em></span>
</p>
</td></tr></tbody></table></div><p>The <code class="literal">play</code> method with the preceding changes is shown below:</p><div class="mediaobject"><img src="graphics/B05034_09_20.jpg" alt="Gold Hunt optimization – Pass six, parallelization"/></div><p>Let's talk through the important changes in this method:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">In a <code class="literal">while</code> loop, we <a id="id728" class="indexterm"/>will first determine the centers of all the search circles and store the coordinates in a list called <code class="literal">x_centers</code>. The y coordinate (<code class="literal">y_ref</code>) is not updated because we have chosen it as constant <code class="literal">(0.0)</code> for all the circles.</li><li class="listitem" style="list-style-type: disc">In the same <code class="literal">while</code> loop, another <code class="literal">circle_number</code> list is populated to represent the circle id. This is just for printing purposes so that we will know which search operation is being performed.</li><li class="listitem" style="list-style-type: disc">After preparing the list, a pool of worker threads is created and then <code class="literal">apply_async</code> is called in a list comprehension.</li><li class="listitem" style="list-style-type: disc">Recall that the first argument to the <code class="literal">Pool.apply_async</code> method is the name of the function (<code class="literal">self.find_coins)</code>, whereas the second argument, <code class="literal">args</code>, is used to specify all the arguments to this function.</li><li class="listitem" style="list-style-type: disc">The rest of the code is similar to what we saw in the introduction of the <code class="literal">multiprocessing</code> module. The <code class="literal">apply_async</code> call returns a list containing objects of the <code class="literal">ApplyResult</code> class. Then, the <code class="literal">get()</code> method of this class is used to obtain the final values.</li></ul></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip101"/>Tip</h3><p>If you are using Python 2.7.9, you may have to create and use a global function as the first argument to <code class="literal">apply_async</code>. This global function can then return the <code class="literal">GoldHunt.find_coins</code> method. This is a workaround to avoid a <code class="literal">PicklingError</code> exception noticed while testing the code. For Python 3.x, there is no problem. This code is provided in the supplementary code bundle. See the Python 2 equivalent of the <code class="literal">goldhunt_pass6_parallel.py</code> file for details.</p></div></div><p>Finally, there are some <a id="id729" class="indexterm"/>changes to the <code class="literal">GoldHunt.find_coins</code> method. It now takes the <code class="literal">process_x_ref</code> and <code class="literal">circle_number</code> functions as two new arguments. The <code class="literal">process_x_ref</code> function represents the x coordinate of a given search circle. The <code class="literal">process_</code> prefix is added just to distinguish it from <code class="literal">self.x_ref</code>, and indicate that its value will be different for each worker process.</p><p>Using <code class="literal">apply_async</code>, we will run this method on separate parallel processes. Each process gets its own circle center and number to be given as an input for the <code class="literal">find_coins</code> method. The method is shown in the following code snippet. The highlighted code indicates the changes in comparison with the previous optimization pass.</p><div class="mediaobject"><img src="graphics/B05034_09_21.jpg" alt="Gold Hunt optimization – Pass six, parallelization"/></div><p>The rest of the code <a id="id730" class="indexterm"/>remains the same as the previous optimization pass. The source code is provided in the <code class="literal">goldhunt_pass6_parallel.py</code> file. Let's run this code and see the profiler output:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ python goldhunt_pass6_parallel.py</strong></span>
</pre></div><p>This will print information on the search circles as it did earlier. Here is the profiler output:</p><div class="mediaobject"><img src="graphics/B05034_09_22.jpg" alt="Gold Hunt optimization – Pass six, parallelization"/></div><p>Note that the <code class="literal">find_coins</code> call is not shown in the profiler output. It is hidden inside the reported timing of the <code class="literal">play</code> method. Comparing the cumulative time (<code class="literal">cumtime</code>) of the <code class="literal">play</code> method should give a reasonable estimate on the performance gain with parallelization.</p><p>In summary, the parallelization has helped improve the total timing from earlier, ~21.5 seconds to ~13.5 seconds.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip102"/>Tip</h3><p>Depending on your machine specifications, you can try increasing the number of worker processes by updating the argument to the <code class="literal">Pool</code> class. For example, instead of three processes you can run the program with four processes. However, this is a simple case and the runtime is so short that you will hardly see any further improvement. In fact, the overhead of the sub-processes may even result in a slightly degraded performance. Also, depending on the problem, beyond a certain number of processes, the performance gain due to parallelization can fade away.</p></div></div><div class="section" title="Other methods for parallelization"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec91"/>Other methods for parallelization</h3></div></div></div><p>Is the <code class="literal">apply_async</code> method the only way to parallelize this problem? Certainly not. There are other methods in the <code class="literal">multiprocessing</code> module that can do this efficiently. <code class="literal">Pool.starmap_async</code> is one such method available in Python 3.3 and beyond. We are not going to discuss this here, but the following code shows how to invoke it along with the <code class="literal">itertools.repeat</code> function:</p><div class="informalexample"><pre class="programlisting">results = pool.starmap_async(self.find_coins, 
                               zip(itertools.repeat(x_list), 
                                   itertools.repeat(y_list), 
                                   x_centers, 
                                   circle_numbers))</pre></div><p>For more information on such methods, refer to the <code class="literal">multiprocessing</code> module documentation.</p></div></div></div>
<div class="section" title="Further reading"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec81"/>Further reading</h1></div></div></div><p>In the series of the three chapters on performance, we covered several important aspects. The things learned here will help you with the majority of common application performance enhancement tasks. Where do we go from here? There are some other important topics that you can explore, among those are JIT compilers and <span class="strong"><strong>Graphics Processing Unit</strong></span> (<span class="strong"><strong>GPU</strong></span>)<a id="id731" class="indexterm"/> programming. This section aims at providing some basic information on these two topics. You can follow the links provided here for further understanding.</p><div class="section" title="JIT compilers"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec171"/>JIT compilers</h2></div></div></div><p>Python is an <a id="id732" class="indexterm"/>interpreted language. In simple terms, it means that the code is parsed and executed directly without involving any code compilation. Although this offers a great deal of flexibility, the program typically runs slower.</p><p>In high-level programming languages such as C++, the code is compiled ahead of time or before the execution. Generally speaking, a compiled program (C++) runs faster compared to the equivalent interpreted program (Python).</p><p>Thus, we have an interpreted code on one side which offers flexibility and a compiled code on the other that runs faster. The JIT compiler gets the best of both worlds. It compiles the code, but instead of compiling it ahead of execution, it does this just-in-time or during the program execution.</p><p>PyPy<a id="id733" class="indexterm"/> is one such project that provides an alternative implementation of the Python language that comes with a JIT compiler. Python programs often run faster with PyPy. It is also memory efficient and offers high compatibility with the existing Python code. To learn more<a id="id734" class="indexterm"/> about PyPy, check out <a class="ulink" href="http://pypy.org">http://pypy.org</a>.</p><p>
<span class="strong"><strong>Numba</strong></span>
<a id="id735" class="indexterm"/> is another project aimed at speeding up the application. It provides a JIT  compiler and a very simple syntax to mark a function for optimization using a JIT compiler. You just need to use the <code class="literal">numba.git()</code> decorator. In other words, add <code class="literal">@jit</code> above the function name to mark the function for optimization. If you are using the Anaconda Python distribution discussed in <a class="link" href="ch01.html" title="Chapter 1. Developing Simple Applications">Chapter 1</a>, <span class="emphasis"><em>Developing Simple Applications</em></span>, it already provides the <a id="id736" class="indexterm"/>
<code class="literal">numba</code> module by default. To learn more, visit the project home page (<a class="ulink" href="http://numba.pydata.org">http://numba.pydata.org</a>).</p><div class="section" title="GPU accelerated computing"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec92"/>GPU accelerated computing</h3></div></div></div><p>GPU is traditionally used <a id="id737" class="indexterm"/>for applications involving heavy rendering, such as game applications. It is now widely used for applications involving scientific simulations, neural networks, financial modeling, and so on. The massively parallel architecture of a GPU offers tremendous performance improvement (of the order of 100x or more) over the CPU-based parallelization. A typical strategy is to identify the most compute intensive part of your application, and then send it to a GPU. The rest of the code can continue to use CPU. However, it is not as simple as it sounds, especially if you are working on a legacy code. In such cases, the challenge can be to make it compatible to fully utilize the GPU acceleration.</p><p>
<span class="strong"><strong>PyCUDA</strong></span> (<a class="ulink" href="https://pypi.python.org/pypi/pycuda">https://pypi.python.org/pypi/pycuda</a>) is a popular Python package that<a id="id738" class="indexterm"/> provides a <a id="id739" class="indexterm"/>wrapper to access Nvidia's CUDA parallel API. CUDA<a id="id740" class="indexterm"/> is a parallel computing platform by NVIDIA. More information can be <a id="id741" class="indexterm"/>found at <a class="ulink" href="http://www.nvidia.com/object/cuda_home_new.html">http://www.nvidia.com/object/cuda_home_new.html</a>.</p><p>
<span class="strong"><strong>PyOpenCL </strong></span>(<a class="ulink" href="https://pypi.python.org/pypi/pyopencl">https://pypi.python.org/pypi/pyopencl</a>) is another Python package. It provides <a id="id742" class="indexterm"/>an easy <a id="id743" class="indexterm"/>access to the <span class="strong"><strong>Open Computing Language</strong></span> (<span class="strong"><strong>OpenCL</strong></span>)<a id="id744" class="indexterm"/> API. OpenCL is a<a id="id745" class="indexterm"/> framework for parallel computation. Refer to <a class="ulink" href="https://en.wikipedia.org/wiki/OpenCL">https://en.wikipedia.org/wiki/OpenCL</a> for further information.</p></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec82"/>Summary</h1></div></div></div><p>With this chapter, we end the series of chapters focused on performance improvements. Let's first summarize what you learned in this chapter. We started with a basic introduction to the NumPy library and saw how to leverage it to further speed up the <span class="emphasis"><em>Gold Hunt</em></span> application. In particular, we used the array (<code class="literal">numpy.ndarray</code>) data structure and other functionalities, such as <code class="literal">numpy.random.uniform</code> and <code class="literal">numpy.einsum</code> to achieve the speedup. The final optimization pass involved parallelizing the code. The chapter briefly introduced you to the basics of parallel processing. We used functionality from Python's <code class="literal">multiprocessing.Pool</code> class to further trim down the application runtime.</p><p>Finally, let's summarize the three performance chapters together. We started by profiling the code to identify the performance bottlenecks and learned about the big O notation. We gradually addressed these bottlenecks to improve the application performance. This was accomplished by several means, ranging from changing the algorithm and implementing efficient data structures to using the functionality from a Python standard library. We further improved the runtime by using NumPy and also by parallelizing the code.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip103"/>Tip</h3><p>The timings reported by the profiler will vary widely. It depends on your machine specifications, and also on the current running tasks. So, the timings observed in your case will likely be different than the numbers reported in this book.</p></div></div><p>For the <span class="emphasis"><em>Gold Hunt</em></span> example discussed in these chapters, the total runtime was reduced almost by an order of magnitude, from an initial value of about 106 seconds to a final runtime of nearly 13.5 seconds.</p><p>So far, in this book, you learned several key aspects of application development using command-line programs. In the final chapter, we'll  see how to develop simple GUI applications in Python.</p></div></body></html>