["```py\nclass Task(Entity):\n    \"\"\"Anti-pattern: Domain entity with\n    direct infrastructure dependencies.\"\"\"\n    def __init__(self, title: str, description: str):\n        self.title = title\n        self.description = description\n        # Direct database dependency:\n        self.db = Database() \n        # Direct notification dependency:\n        self.notifier = NotificationService() \n        self.priority = Priority.MEDIUM\n        # Save to database and notify on creation\n        self.id = self.db.save_task(self.as_dict())\n        self.notifier(f\"Task {self.id} created\") \n```", "```py\ndef test_new_task_priority_antipattern():\n    \"\"\"An anti-pattern mixing infrastructure concerns\n    with simple domain logic.\"\"\"\n    # Complex setup just to test a default value\n    db_connection = create_database_connection()\n    notification_service = create_notification_service()\n    # Just creating a task hits the database and notification service\n    task = Task(\n        title=\"Test task\",\n        description=\"Test description\"\n    )\n    # Even checking a simple property requires a database query\n    saved_task = task.db.get_task(task.id)\n    assert saved_task['priority'] == Priority.MEDIUM \n```", "```py\n@dataclass\nclass Task:\n    \"\"\"Clean Architecture: Pure domain entity.\"\"\"\n    title: str\n    description: str\n    project_id: UUID\n    priority: Priority = Priority.MEDIUM\ndef test_new_task_priority():\n    \"\"\"Clean test focused purely on domain logic.\"\"\"\n    task = Task(\n        title=\"Test task\",\n        description=\"Test description\",\n        project_id=UUID('12345678-1234-5678-1234-567812345678')\n    )\n    assert task.priority == Priority.MEDIUM \n```", "```py\ndef test_task_completion_captures_completion_time():\n    \"\"\"Test that completing a task records the completion timestamp.\"\"\"\n    # Arrange\n    task = Task(\n        title=\"Test task\",\n        description=\"Test description\",\n        project_id=UUID('12345678-1234-5678-1234-567812345678'),\n    )\n\n    # Act\n    task.complete()\n\n    # Assert\n    assert task.completed_at is not None\n    assert (datetime.now() - task.completed_at) < timedelta(seconds=1) \n```", "```py\nfrom unittest.mock import Mock\n# Create a mock object that records calls and can return preset values\nmock_repo = Mock()\n# Configure the response we want\nmock_repo.get.return_value = some_task\n# Call will return some_task\nmock_repo.get(123)\n# Verify the call happened exactly once\nmock_repo.get.assert_called_once()\n# Mocks track all interaction details\n# Shows what arguments were passed\nprint(mock_repo.get.call_args)\n# Shows how many times it was called\nprint(mock_repo.get.call_count) \n```", "```py\ndef test_successful_task_completion():\n    \"\"\"Test task completion using mock dependencies.\"\"\"\n    # Arrange\n    task = Task(\n        title=\"Test task\",\n        description=\"Test description\",\n        project_id=UUID('12345678-1234-5678-1234-567812345678'),\n    )\n    task_repo = Mock()\n    task_repo.get.return_value = task\n    notification_service = Mock()\n\n    use_case = CompleteTaskUseCase(\n        task_repository=task_repo,\n        notification_service=notification_service\n    )\n    request = CompleteTaskRequest(task_id=str(task.id)) \n```", "```py\n # Act\n    result = use_case.execute(request)\n    # Assert\n    assert result.is_success\n    task_repo.save.assert_called_once_with(task)\n    notification_service\n      .notify_task_completed\n      .assert_called_once_with(task) \n```", "```py\ndef test_controller_converts_string_id_to_uuid():\n    \"\"\"Test that controller properly converts\n    string IDs to UUIDs for use cases.\"\"\"\n    # Arrange\n    task_id = \"123e4567-e89b-12d3-a456-426614174000\"\n    complete_use_case = Mock()\n    complete_use_case.execute.return_value = Result.success(\n        TaskResponse.from_entity(\n            Task(\n                title=\"Test Task\",\n                description=\"Test Description\",\n                project_id=UUID('12345678-1234-5678-1234-567812345678')\n            )\n        )\n    )\n    presenter = Mock(spec=TaskPresenter)\n\n    controller = TaskController(\n        complete_use_case=complete_use_case,\n        presenter=presenter,\n    ) \n```", "```py\n# Without spec, any method can be called\nloose_mock = Mock()\nloose_mock.non_existent_method()  # Works, but could hide bugs\n# With spec, mock enforces the interface\nstrict_mock = Mock(spec=TaskPresenter)\nstrict_mock.non_existent_method()  # Raises AttributeError \n```", "```py\n # Act\n    controller.handle_complete(task_id=task_id)\n    # Assert\n    complete_use_case.execute.assert_called_once()\n    called_request = complete_use_case.execute.call_args[0][0]\n    assert isinstance(called_request.task_id, UUID) \n```", "```py\ndef test_presenter_formats_completion_date():\n    \"\"\"Test that presenter formats dates according to\n    interface requirements.\"\"\"\n    # Arrange\n    completion_time = datetime(2024, 1, 15, 14, 30, tzinfo=timezone.utc)\n    task = Task(\n        title=\"Test Task\",\n        description=\"Test Description\",\n        project_id=UUID('12345678-1234-5678-1234-567812345678')\n    )\n    task.complete()\n    # Override completion time for deterministic testing\n    task.completed_at = completion_time\n    task_response = TaskResponse.from_entity(task)\n    presenter = CliTaskPresenter() \n```", "```py\n # Act\n    view_model = presenter.present_task(task_response)\n    # Assert\n    expected_format = \"2024-01-15 14:30\"\n    assert expected_format in view_model.completion_info \n```", "```py\ndef test_presenter_provides_complete_view_model():\n    \"\"\"Test presenter creates properly formatted view model\n    with all display fields.\"\"\"\n    # Arrange\n    task = Task(\n        title=\"Important Task\",\n        description=\"Testing view model creation\",\n        project_id=UUID('12345678-1234-5678-1234-567812345678'),\n        priority=Priority.HIGH\n    )\n    task.complete()  # Set status to DONE\n    task_response = TaskResponse.from_entity(task)\n    presenter = CliTaskPresenter()\n      # Act\n    view_model = presenter.present_task(task_response)\n\n    # Assert\n    assert view_model.title == \"Important Task\"\n    assert view_model.status_display == \"[DONE]\"\n    assert view_model.priority_display == \"HIGH PRIORITY\"\n    assert isinstance(view_model.completion_info, str) \n```", "```py\n@pytest.fixture\ndef repository(tmp_path): # tmp_path is a pytest builtin for temp dirs\n    \"\"\"Create repository using temporary directory.\"\"\"\n    return FileTaskRepository(data_dir=tmp_path)\ndef test_repo_handles_project_task_relationships(tmp_path):\n    # Arrange\n    task_repo = FileTaskRepository(tmp_path)\n    project_repo = FileProjectRepository(tmp_path)\n    project_repo.set_task_repository(task_repo)\n\n    # Create project and tasks through the repository\n    project = Project(name=\"Test Project\",\n                      description=\"Testing relationships\")\n    project_repo.save(project)\n    task = Task(title=\"Test Task\",\n                description=\"Testing relationships\",\n                project_id=project.id)\n    task_repo.save(task) \n```", "```py\n # Act - Load project with its tasks\n    loaded_project = project_repo.get(project.id)\n    # Assert\n    assert len(loaded_project.tasks) == 1\n    assert loaded_project.tasks[0].title == \"Test Task\" \n```", "```py\ndef test_repository_automatically_creates_inbox(tmp_path):\n    \"\"\"Test that project repository maintains inbox project\n    across instantiations.\"\"\"\n    # Arrange - Create initial repository and verify Inbox exists\n    initial_repo = FileProjectRepository(tmp_path)\n    initial_inbox = initial_repo.get_inbox()\n    assert initial_inbox.name == \"INBOX\"\n    assert initial_inbox.project_type == ProjectType.INBOX\n    # Act - Create new repository instance pointing to same directory\n    new_repo = FileProjectRepository(tmp_path)\n\n    # Assert - New instance maintains same Inbox\n    persisted_inbox = new_repo.get_inbox()\n    assert persisted_inbox.id == initial_inbox.id\n    assert persisted_inbox.project_type == ProjectType.INBOX \n```", "```py\ndef test_task_creation_with_persistence(tmp_path):\n    \"\"\"Test task creation use case with real persistence.\"\"\"\n    # Arrange\n    task_repo = FileTaskRepository(tmp_path)\n    project_repo = FileProjectRepository(tmp_path)\n    project_repo.set_task_repository(task_repo)\n\n    use_case = CreateTaskUseCase(\n        task_repository=task_repo,\n        project_repository=project_repo,\n        notification_service=Mock()  # Still mock non-persistence concerns\n    ) \n```", "```py\n # Act\n    result = use_case.execute(CreateTaskRequest(\n        title=\"Test Task\",\n        description=\"Integration test\"\n    ))\n    # Assert - Task was persisted\n    assert result.is_success\n    created_task = task_repo.get(UUID(result.value.id))\n    assert created_task.project_id == project_repo.get_inbox().id \n```", "```py\ntests/\n    domain/\n        entities/\n            test_task.py\n            test_project.py\n        value_objects/\n            test_deadline.py\n    application/\n        use_cases/\n            test_task_use_cases.py\n    # ... Remaining tests by layer \n```", "```py\n@pytest.mark.parametrize(\n    \"request_data,expected_behavior\",\n    [\n        # Basic task creation - defaults to INBOX project\n        (\n            {\n                \"title\": \"Test Task\",\n                \"description\": \"Basic creation\"\n            },\n            {\n                \"project_type\": ProjectType.INBOX,\n                \"priority\": Priority.MEDIUM\n            }\n        ),\n        # Explicit project assignment\n        (\n            {\n                \"title\": \"Project Task\",\n                \"description\": \"With project\",\n                \"project_id\": \"project-uuid\"\n            },\n            {\n                \"project_type\": ProjectType.REGULAR,\n                \"priority\": Priority.MEDIUM\n            }\n        ),\n        # High priority task\n        # ... data for task\n    ],\n    ids=[\"basic-task\", \"project-task\", \"priority-task\"]\n) \n```", "```py\ndef test_task_creation_scenarios(request_data, expected_behavior):\n    \"\"\"Test task creation use case handles various\n    input scenarios correctly.\"\"\"\n    # Arrange\n    task_repo = Mock(spec=TaskRepository)\n    project_repo = FileProjectRepository(tmp_path) \n    # Real project repo for INBOX\n\n    use_case = CreateTaskUseCase(\n        task_repository=task_repo,\n        project_repository=project_repo\n    )\n\n    # Act\n    result = use_case.execute(CreateTaskRequest(**request_data))\n\n    # Assert\n    assert result.is_success\n    created_task = result.value\n    if expected_behavior[\"project_type\"] == ProjectType.INBOX:\n        assert UUID(created_task.project_id) == (\n            project_repo.get_inbox().id\n        )\n    assert created_task.priority == expected_behavior[\"priority\"] \n```", "```py\n# tests/conftest.py - Root fixtures available to all tests\n@pytest.fixture\ndef sample_task_data():\n    \"\"\"Provide basic task attributes for testing.\"\"\"\n    return {\n        \"title\": \"Test Task\",\n        \"description\": \"Sample task for testing\",\n        \"project_id\": UUID('12345678-1234-5678-1234-567812345678'),\n    }\n# tests/domain/conftest.py - Domain layer fixtures\n@pytest.fixture\ndef domain_task(sample_task_data):\n    \"\"\"Provide a clean Task entity for domain tests.\"\"\"\n    return Task(**sample_task_data)\n# tests/application/conftest.py - Application layer fixtures\n@pytest.fixture\ndef mock_task_repository(domain_task):\n    \"\"\"Provide a pre-configured mock repository.\"\"\"\n    repo = Mock(spec=TaskRepository)\n    repo.get.return_value = domain_task\n    return repo \n```", "```py\n# tests/interfaces/conftest.py - Interface layer fixtures\n@pytest.fixture\ndef task_controller(mock_task_repository, mock_notification_port):\n    \"\"\"Provide a properly configured TaskController.\"\"\"\n    return TaskController(\n        create_use_case=CreateTaskUseCase(\n            task_repository=mock_task_repository,\n            project_repository=Mock(spec=ProjectRepository),\n            notification_service=mock_notification_port\n        ),\n        presenter=Mock(spec=TaskPresenter)\n    )\n@pytest.fixture\ndef task_request_json():\n    \"\"\"Provide sample request data as it would come from clients.\"\"\"\n    return {\n        \"title\": \"Test Task\",\n        \"description\": \"Testing task creation\",\n        \"priority\": \"HIGH\"\n    } \n```", "```py\ndef test_controller_handles_task_creation(\n    task_controller,\n    task_request_json,\n    mock_task_repository\n):\n    \"\"\"Test task creation through controller layer.\"\"\"\n    result = task_controller.handle_create(**task_request_json)\n\n    assert result.is_success\n    mock_task_repository.save.assert_called_once() \n```", "```py\npip install freezegun \n```", "```py\nfrom freezegun import freeze_time\ndef test_task_deadline_approaching():\n    \"\"\"Test deadline notifications respect time boundaries.\"\"\"\n    # Arrange\n    with freeze_time(\"2024-01-14 12:00:00\"):\n        task = Task(\n            title=\"Time-sensitive task\",\n            description=\"Testing deadlines\",\n            project_id=UUID('12345678-1234-5678-1234-567812345678'),\n            due_date=Deadline(datetime(\n                2024, 1, 15, 12, 0, tzinfo=timezone.utc))\n        )\n\n    notification_service = Mock(spec=NotificationPort)\n    use_case = CheckDeadlinesUseCase(\n        task_repository=Mock(spec=TaskRepository),\n        notification_service=notification_service,\n        warning_threshold=timedelta(days=1)\n    ) \n```", "```py\n # Act\n    with freeze_time(\"2024-01-14 13:00:00\"):\n        result = use_case.execute()\n    # Assert\n    assert result.is_success\n    notification_service.notify_task_deadline_approaching.assert_called_once() \n```", "```py\npip install pytest-random-order \n```", "```py\n# pytest.ini\n[pytest]\naddopts = --random-order \n```", "```py\npytest --random-order-seed=123456 \n```", "```py\npip install pytest-xdist \n```", "```py\n# pytest.ini\n[pytest]\naddopts = --random-order -n auto  # Combine random order with parallel execution \n```"]