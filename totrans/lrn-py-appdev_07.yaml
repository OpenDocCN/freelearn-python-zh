- en: Chapter 7. Performance – Identifying Bottlenecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, you have learned various ways to make the application robust and accommodating
    for new features. Now, let''s discuss techniques to improve the application performance.
    This broad topic is split into a series of three chapters—this is the first one
    in this series. It will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic ways to clock the application runtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to identify the runtime performance bottlenecks by profiling the code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic memory profiling with the `memory_profiler` package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Big O** notation for the computational complexity'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand these concepts better, we will develop an interesting game scenario
    called *Gold Hunt*. You will soon realize that the application runs very slow
    when you increase the input data size. This chapter will elaborate on techniques
    to pinpoint such problems.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of three performance chapters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we dive into the main discussion, let's first understand how the chapters
    on performance improvement are organized. As mentioned earlier, this discussion
    is split into a series of three interlinked chapters.
  prefs: []
  type: TYPE_NORMAL
- en: More focus on the runtime performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The term performance improvement can mean several things. One can be talking
    about improving the runtime (CPU usage), making the application memory efficient,
    reducing the network consumption, or a combination of these. In this book, we
    will primarily focus on the runtime performance improvement. We will also discuss
    the memory consumption aspect, but the discussion will be limited to the **memory
    profiling** technique and the use of generator expressions.
  prefs: []
  type: TYPE_NORMAL
- en: The first performance chapter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You are reading the first chapter in this series. It does some preparatory work
    to improve the application performance. This preparation involves measuring the
    runtime, identifying pieces of the code that cause the performance bottlenecks,
    understanding the big O notation, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '![The first performance chapter](img/B05034_07_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *Of course! We will develop the earlier mentioned **Gold Hunt scenario**,
    and then identify the performance bottlenecks in the code. The next two chapters
    will use this groundwork to gradually improve the application performance.* |'
  prefs: []
  type: TYPE_TB
- en: The second performance chapter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next chapter is all about learning various performance improvement techniques.
    The first half aims at improving the application runtime for the *Gold Hunt* application.
    The second half teaches several tricks to optimize the code. The chapter covers
    some built-in modules designed for high performance and memory efficiency. It
    also talks about list comprehension, generator expressions, choice of data structures,
    algorithmic changes, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The third performance chapter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last chapter in this series will briefly talk about the **NumPy** package
    and **parallelization** using the `multiprocessing` module in Python. We will
    use these techniques to drastically improve the runtime performance of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Sneak peek at the upcoming application speedup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here is a preview of how the *Gold Hunt* program will evolve from a turtle to
    a rabbit. The following figure shows the approximate runtime after each major
    step of performance improvement. By the time we complete [Chapter 9](ch09.html
    "Chapter 9. Improving Performance – Part Two, NumPy and Parallelization"), *Improving
    Performance – Part two, NumPy and Parallelization*, the application runtime will
    be brought down to approximately 14 seconds from an initial value of nearly 106
    seconds.
  prefs: []
  type: TYPE_NORMAL
- en: '![Sneak peek at the upcoming application speedup](img/B05034_07_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: No need to spend any time trying to understand the elements presented in this
    chart; things will become clear once you read all three chapters on performance.
    For now, all you need to know is that we will learn some techniques to drastically
    improve the application runtime in the upcoming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Caution**'
  prefs: []
  type: TYPE_NORMAL
- en: The chapters on performance will show some examples of inefficient code. Running
    these examples can consume a lot of compute resources. Instead of using the problem
    size illustrated in these chapters, you should choose an appropriate data size
    depending on what your machine can handle.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario – The Gold Hunt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| *You recently introduced* *a new scenario in the game—to meet the expenses
    of his army, Sir Foo is out on a mission to collect gold from a recently acquired
    territory. The scenario starts with Sir Foo arriving at a place full of gold coins,
    jewelry, and so on. There are a couple of problems though. Firstly, the gold is
    scattered all over the field. Secondly, Sir Foo doesn''t have time to collect
    all the gold on the field.* |'
  prefs: []
  type: TYPE_TB
- en: '![Scenario – The Gold Hunt](img/B05034_07_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *What you see behind Sir Foo is an imaginary **gold field**. Sir Foo will
    enter from the left side and travel across the field. He will only collect the
    coins lying along his path and **ignore all the remaining gold** scattered across
    the field.* |'
  prefs: []
  type: TYPE_TB
- en: 'Let''s represent this gold field as a circle with a radius of nearly 10 miles
    (diameter of 20 miles), and center located at coordinates *x = 0* and *y = 0*,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scenario – The Gold Hunt](img/B05034_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Observe the following screenshot. The *dotted line* (the diameter of the field)
    shows the path that Sir Foo traverses on his way out. During this 20 mile journey,
    he stops at 10 *equally spaced points*. In other words, these points are 2 miles
    apart, represented by the centers of the small "search circles". For each stop,
    he collects the gold within a search circle. The total collected gold is the sum
    of the coins inside each of those 10 tiny circles. Let's not worry about the gold
    lying outside of these search circles.
  prefs: []
  type: TYPE_NORMAL
- en: Assume that the remaining gold on the field is irrelevant for the problem we
    are solving.
  prefs: []
  type: TYPE_NORMAL
- en: '![Scenario – The Gold Hunt](img/B05034_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: High-level algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the preceding screenshot as a reference, let''s write the high-level algorithm.
    We will keep it simple. The task is to collect the gold coins found inside each
    of the small circles in this image (recall that these circles are referred to
    as *search circles*). We will call the radius of each of these circles a *search
    radius*. In the present scenario, the search radius is 1 mile, or let''s simply
    call it 1 unit:'
  prefs: []
  type: TYPE_NORMAL
- en: Randomly create points representing the gold coins inside a gold field. The
    gold field is represented by a large circle with a radius of 10 units and center
    at *(x = 0, y = 0)*. Each gold coin is represented with a *(x,y)* location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start with the leftmost search circle, the center of which represents Sir Foo's
    current location. The coin hunt is constrained within this search circle.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each search circle:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get Sir Foo's current location coordinates.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Find the distance between each gold coin on the field and Sir Foo's location,
    the center of a search circle.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Collect all the coins with distance less than the *search radius*. These are
    the coins lying inside the perimeter of the current search circle.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Advance Sir Foo to the center of the next search circle.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeat the preceding steps until you reach the rightmost circle.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Report the total number of collected gold coins.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reviewing the initial code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s review the code next (it can also be found in the supporting code bundle,
    just look for the `goldhunt_inefficient.py` file). Here is a new `GoldHunt` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reviewing the initial code](img/B05034_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `play` method of this class contains the main logic, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reviewing the initial code](img/B05034_07_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s review the code in the preceding screenshots:'
  prefs: []
  type: TYPE_NORMAL
- en: The input arguments for the `play` method, `field_coins` and `field_radius`,
    set the number of coins and the radius of the circular gold field, respectively.
    These are optional arguments with default values, as shown in the `__init__` method.
    The third optional argument, `search_radius`, helps define the radius of the smaller
    search circles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `x_ref` and `y_ref` variables represent the *center* of the current search
    circle. We simplified the problem by assuming a constant `y_ref` of `0.0`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `play` method starts by generating random points representing the scattered
    gold coins. The `generate_random_points` function returns two Python lists containing
    the `x` and `y` coordinates of all the coins on the field.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a `while` loop, the `total_collected_coins` list stores the coordinates of
    coins inside the *search circles*, starting with the leftmost one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The actual search operation is performed by the `find_coins` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, let''s review the `GoldHunt.find_coins` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reviewing the initial code](img/B05034_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This method loops over all the points (gold coins) on the field and for each
    point, it computes its distance from the center of the search circle. With this
    distance, we can determine whether or not the given gold coin lies inside the
    perimeter of the search circle. This is shown schematically in the following diagram.
    The `(x_ref, y_ref)` coordinates represent the center of the search circle. The
    `(x, y)` parameters are the coordinates of any gold coin on the field.
  prefs: []
  type: TYPE_NORMAL
- en: '![Reviewing the initial code](img/B05034_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In this diagram, the distance between a point and the center is represented
    by **dist**. It shows two representative points (or coins). The first one with
    a *check mark* next to it lies inside the circle, whereas the other one with a
    *cross mark* is outside. Only the point lying inside the circle is collected.
    The method returns a `collected_coins` list that contains the location tuples
    `(x,y)` of all such points.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review the function that creates random points on the field:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reviewing the initial code](img/B05034_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You should be able to understand this code fragment fairly easily if you have
    a basic math background. Here is how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: Consider a point with radius `r` and an angle `theta`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Cartesian coordinates of this point are *x = r*cos(theta)* and *y = r*sin(theta)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The built-in function, `random.uniform`, is used to randomly vary `r` between
    `0.0` (the field center) and `ref_radius` (the field radius). Note that the `import`
    statements are not shown. For that, refer to `goldhunt_inefficient.py`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, the `theta` angle is randomly varied between `0.0` and `2*math.pi`
    (360 degrees).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Plotting the points**'
  prefs: []
  type: TYPE_NORMAL
- en: You can visualize the generated random distribution of gold coins using **matplotlib**,
    a Python plotting library. We won't discuss the plotting techniques here. Check
    out their website ([http://matplotlib.org](http://matplotlib.org)) that hosts
    a number of tutorials and installation instructions. Python distributions, such
    as Anaconda, come preinstalled with matplotlib. You can also use the plotting
    function, `plot_points`, provided in the `goldhunt_inefficient.py` file.
  prefs: []
  type: TYPE_NORMAL
- en: Running the code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main execution code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This code uses the default arguments to instantiate `GoldHunt`. With the default
    arguments, the code should run smoothly and finish within a few seconds. The actual
    time will vary depending on your machine configuration, available RAM, and so
    on. You can add some informative `print` statements to see how the game is progressing.
    Here is a sample output using the default arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| *In the game scenario, you allowed the users to tweak certain parameters.
    For example, the users can control the **total number of coins** on the field
    or modify the **radius of the search circle**. Unknowingly, you opened a new can
    of worms. For a large input size, the program runs very slow. For example, one
    variant of the game, **The Great Dwarf of the Foo mountain**, is performing the
    gold hunt. Let''s hear what he has to say:* |'
  prefs: []
  type: TYPE_TB
- en: '![The problem](img/B05034_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you change `field_coins` from `5000` to `1000000` and set `search_radius`
    to `0.1`, the application will take quite a bit of time to finish. Here is the
    updated main execution code with these new parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If you increase the coins further or make the search radius even smaller, it
    will severely affect the application runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Warning!**'
  prefs: []
  type: TYPE_NORMAL
- en: If you run the following code, depending on your machine configuration, it can
    slow down your machine, take longer time to finish, and in some cases (a machine
    with an average configuration) the computer can stop responding. If you are unsure,
    it is better not to run it! It is presented here just as an example. If you really
    want to, then do it at your own risk!
  prefs: []
  type: TYPE_NORMAL
- en: For example, it can take several seconds or minutes to complete this operation.
    What can we do here to improve the performance? Before jumping to that, let's
    first review some techniques to identify the bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying the bottlenecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we saw how a different choice of input parameters degrades
    the application runtime. Now, we need some way to accurately measure the execution
    time and find out the performance bottlenecks or the time consuming blocks of
    the code.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the execution time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's start by monitoring the time taken by the application. To do this, we
    will use Python's built-in `time` module. The `time.perf_counter` function is
    a performance counter that returns a clock with the highest available resolution.
    This function can be used to determine the time interval or the system-wide time
    difference between the two consecutive calls to the function.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `time.perf_counter` function is available in Python versions 3.3 onwards.
    If you have an older version of Python (for example, version 2.7), use `time.clock()`
    instead. On Unix, `time.clock()` returns a floating point number within seconds
    that represents the processor time. On Windows, it returns the elapsed wall-clock
    time within seconds after the first call to the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The original file, `goldhunt_inefficient.py`, already has the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: At the beginning of the file, we import the `time` module. The `start` variable
    marks the beginning of the performance counter, and the `end` variable represents
    its second consecutive call. In between, we will run the main execution code.
    The difference between the two values of the counter can be used as an indicator
    for the runtime of the application. Similarly, you can insert these calls elsewhere
    in the code to monitor individual code fragments.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the runtime of small code snippets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The built-in `timeit` module is a useful tool for quickly checking the execution
    time of a small code fragment. It can be used from the command line or imported
    and called inside the code. Here is one way to use this functionality using the
    command-line interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `-m` option allows running the `timeit` module from the command line. In
    the preceding example, it measures the execution time for the `x = 100*100` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review the output of this execution. The `100000000 loops` in the output
    indicates how many times the code is executed by `timeit`. It reports the best
    of three timings. In this example, the best time taken is `0.0155` microseconds
    for a single execution. You can also tweak the number of times the code is run
    by using the `--number` argument, as shown in the following code snippet. Here,
    the code is run only `10` times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Internally, `timeit` uses `time.perf_counter` to measure the time taken. This
    is the default implementation since Python version 3.3\. For further details,
    check out the documentation ([https://docs.python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html)).
  prefs: []
  type: TYPE_NORMAL
- en: Code profiling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The performance measurement techniques that we have seen so far work quite well,
    especially when you want to run benchmarks for the application. However, it is
    often cumbersome to implement these timers throughout your project to get a full
    execution profile. This is where the code profiling helps. It is a technique that
    analyzes a program while it is running and gathers some important statistics.
    For example, it reports the duration and frequency of various function calls within
    that program. This information can be used to identify the performance bottlenecks
    in the code.
  prefs: []
  type: TYPE_NORMAL
- en: The cProfile module
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s see how to use `cProfile`, Python''s built-in module for code profiling.
    For illustration purposes, we will use the `profile_ex.py` file from the supporting
    code bundle. It has three simple functions that do some trivial tasks, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The cProfile module](img/B05034_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `cProfile` command can either be run from the command prompt or by importing
    it inside the module to be tested. Here is the output when run from the Command
    Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The cProfile module](img/B05034_07_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **IPython** interactive shell also provides a convenient magic command called
    `%prun`. With this, you can quickly profile a Python statement. For more information,
    check out [https://ipython.org/ipython-doc/3/interactive/magics.html](https://ipython.org/ipython-doc/3/interactive/magics.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s understand the output of this run:'
  prefs: []
  type: TYPE_NORMAL
- en: The first line of the output shows the total number of function calls monitored.
    A majority of these are due to `for loop` inside `test_2`. For each iteration,
    it calls the `append` function of the Python `list` datatype.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the same output line, it also reports the number of `primitive calls`. These
    are the function calls that do not involve **recursion**. The `test_3` function
    shows an example of recursion. To understand this better, run the code by printing
    the value of the input argument `condition`. In this case, there is only one recursive
    function call.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `ncalls` column indicates the number of function calls. If you add them
    up, the total number of calls becomes `10007`, same as the ones reported on the
    first line of the output. Notice that for `test_3`, it reports the function calls
    as `2/1`. It means that the function was called twice but one of the calls was
    recursive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `tottime` column indicates the total time spent in a given function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `percall` column records the quotient of the `totcall/ncalls` division.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The time spent inside a particular function, including its sub-functions, is
    reported by `cumtime` (the cumulative time).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `percall` column reports the `cumtime`/`primitive calls` quotient.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last column is, essentially, the data related to the functions. It includes
    the built-in function calls, such as the `append` method of the Python `list`,
    and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, the output is sorted by `standard name`. To understand the bottlenecks,
    this sorting order is not quite useful. Instead, you can sort by cumulative time,
    number of function calls, and so on. This is accomplished using the command-line
    option, `-s`. For a complete list of available sorting options, refer to [https://docs.python.org/3/library/profile.html](https://docs.python.org/3/library/profile.html).
  prefs: []
  type: TYPE_NORMAL
- en: The following screenshot shows the output sorted by `tottime`. Observe that
    it spends the most time in the `test_2` function.
  prefs: []
  type: TYPE_NORMAL
- en: '![The cProfile module](img/B05034_07_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we know how to use `cProfile`, let''s use it to analyze the *Gold
    Hunt* problem. Run the original `goldhunt_inefficient.py` file with all the default
    options, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: It prints a lot of information in the terminal window as there are several of
    the internal function calls involved. Optionally, you can redirect `stdout` to
    a text file. To effectively analyze this data, Python provides a built-in module
    called `pstats`. Let's see how to use it in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: The pstats module
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `pstats` module can be used to further process the profiling data generated
    by `cProfile`. It gives you greater control over creating your reports as compared
    to the limited options provided by `cProfile`. The analysis of the data generated
    by `cProfile` is done using the `pstats.Stats` class. To make the `cProfile` output
    usable by `pstats`, we will need to write it to a file using the command-line
    option, `-o`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The `profile_output` file, thus generated, is not human readable. While we
    can go on and feed this file to `pstats.Stats`, it is better to automate the whole
    process by stitching together these two utilities. Here is a simplified code that
    does this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The pstats module](img/B05034_07_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Warning**'
  prefs: []
  type: TYPE_NORMAL
- en: This is a simplified example without any error checks! For example, the code
    does not check if the output file already exists. To make the code robust, add
    such checks and the `try…except` clauses wherever appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code is also available as `profiling_goldhunt.py` in the supporting code
    bundle for this chapter. Let''s quickly review what this code does:'
  prefs: []
  type: TYPE_NORMAL
- en: The main execution code shows a way to run `cProfile` using its `run` method.
    The first argument to `run` is the function (or statement) to be monitored, whereas
    the second argument is the filename where the profiling output is stored.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `view_stats` function is where we use the functionality from `pstats`. This
    function takes the generated profiling output (`filname`) as the first argument.
    It is used while creating an instance of `pstats.Stats`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `strip_dirs` method of the `Stats` class is used to remove all leading path
    information strings from filenames. This reduces the clutter in the final output
    by just displaying the name of the file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the `print_stats` method, we can impose some restrictions in the final
    output. In this example, it looks for the `goldhunt` string in the rightmost columns
    and displays the matching row, ignoring all others. Put in another way, it limits
    the information related to the function calls inside `goldhunt_inefficient.py`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `pstats.Stats` class provides several other useful features. For example,
    the `print_callees` method prints a list of all the functions that were called
    by the function being monitored. For further details, check out the Python documentation
    ([https://docs.python.org/3/library/profile.html#pstats.Stats](https://docs.python.org/3/library/profile.html#pstats.Stats)).
  prefs: []
  type: TYPE_NORMAL
- en: 'This code can be run from the command prompt, as follows (it has a dependency
    on `goldhunt_inefficient.py` so put it in the same directory as this file):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the sample output of this run (only the output pertaining to the statistics
    is shown):'
  prefs: []
  type: TYPE_NORMAL
- en: '![The pstats module](img/B05034_07_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is significantly less output and is restricted to the function calls from
    the program we wish to monitor. As indicated in the output, only `5` out of `19`
    function calls are listed. The list is sorted by the total internal time taken
    to execute the functions. The two functions, `find_coins` and `generate_random_points`,
    top the chart! Their order may vary depending on the values we choose for the
    `field_coins` and `search_radius` variables. But essentially, the code profiling
    has helped us identify the most time consuming code in our application.
  prefs: []
  type: TYPE_NORMAL
- en: '![The pstats module](img/B05034_07_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *Good question! It will certainly help if we can peep inside the function
    and see the line-by-line profiling output. Luckily, there is a tool that enables
    exactly this. Let''s review it next.* |'
  prefs: []
  type: TYPE_TB
- en: The line_profiler package
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `line_profiler` package is a third-party Python package that can be installed
    using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This package can be used to monitor the performance of a function, line by line.
    When you install the package, it also creates an executable `kernprof`.
  prefs: []
  type: TYPE_NORMAL
- en: On Linux, this executable is created at the same location as your Python executable.
    For example, on Linux, if Python is available as `/usr/bin/python`, this executable
    is created as `/usr/bin/kernprof` (or look for the `kernprof.py` script). On Windows
    OS, it should be created at the same location as `pip.exe`. Refer to [Chapter
    1](ch01.html "Chapter 1. Developing Simple Applications"), *Developing Simple
    Applications* for the `pip.exe` path.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'On Windows OS, if you encounter any error, such as **error: Unable to find
    vcvarsall.bat**, you will probably need to use Visual C++ Express. Check out [https://www.visualstudio.com/en-US/products/visual-studio-express-vs](https://www.visualstudio.com/en-US/products/visual-studio-express-vs)
    for more information.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using this tool requires trivial changes to the code. All you need to do is
    add a `@profile` decorator above the function or method name, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The line_profiler package](img/B05034_07_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, run the tool using the `kernprof` command as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `-v` or `--view` option displays the results of the profile output in the
    terminal window. The profiler also creates an output file, `goldhunt_inefficient.py.lprof`.
    The `-l` or `--line-by-line` option uses the line-by-line profiler from the `line_profiler`
    module.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Be sure to remove the decorator `@profile` when you are not profiling the application
    using the `line_profiler`. In other words, remove it while running the application,
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Otherwise, it will raise a `NameError` exception.
  prefs: []
  type: TYPE_NORMAL
- en: The `line_profiler` output for the `find_coins` method is shown below.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, quite a bit of time is spent computing the distance between
    the points (gold coins) and the center of the search circle.
  prefs: []
  type: TYPE_NORMAL
- en: '![The line_profiler package](img/B05034_07_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Similarly, if you see the output for the `generate_random_point` function, the
    majority of the time is spent while creating a random combination of the `theta`
    angle and the `r` radius, which is used to define a point (a gold coin).
  prefs: []
  type: TYPE_NORMAL
- en: Memory profiling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The profiling techniques we have covered so far aim at finding the runtime bottlenecks.
    Let's briefly discuss memory profiling, another important aspect of profiling.
  prefs: []
  type: TYPE_NORMAL
- en: The memory_profiler package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For memory profiling, we will use a popular Python package called `memory_profiler`.
    It can be installed using `pip`. Here is how to install it on Linux from the command
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The documentation highly recommends installing the `psutils` module. It also
    suggests that, in order for `memory_profiler` to work on Windows OS, you will
    need the `psutil` module. The `psutil` module can be installed using `pip`, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For more information on `memory_profiler`, check out the following page: [https://pypi.python.org/pypi/memory_profiler](https://pypi.python.org/pypi/memory_profiler).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like `line_profiler`, the `memory_profiler` package uses the `@profile`
    decorator above the function name. Let''s add the decorator `@profile` just above
    the `generate_random_points` function, and then run the memory profiler on the
    `goldhunt_inefficient.py` file. The command to run this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output of the memory profiler. It reports the line-by-line memory
    consumption. Note that the profiler prints the whole function, including the docstrings.
    For ease of illustration, part of the docstring is not shown.
  prefs: []
  type: TYPE_NORMAL
- en: '![The memory_profiler package](img/B05034_07_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The line number in the code is shown in the first column. The second column,
    `Mem Usage`, tells us how much memory the Python interpreter consumes after executing
    that line number. The unit of the memory is **mebibyte** (**MiB**).The third column,
    `Increment`, gives the memory difference between the current line and the previous
    line. If the memory is released by the current line of code, then the `Increment`
    column shows a negative number. The last column shows the actual line of code.
    As can be seen from the `Increment` column, the memory is mainly consumed in the
    `for` loop. We will use the memory profiler in the next chapter to compare the
    memory efficiency of a **generator expression** and a **list comprehension**.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm efficiency and complexity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An algorithm is a set of instructions to solve a particular problem. In this
    context, an algorithm can be a function or even a simple operation that adds two
    numbers. Let''s understand two related terms: algorithm efficiency and algorithm
    complexity.'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm efficiency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Algorithm efficiency indicates the computation resources consumed by an algorithm.
    Typically, the lower the resource consumption, the better the efficiency. The
    computational resources can mean several things. One can be talking about the
    runtime (CPU usage), the memory consumption (RAM or hard disk) or the network
    consumption, or a combination of these.
  prefs: []
  type: TYPE_NORMAL
- en: The application requirement determines which resource takes precedence over
    the others. For example, in a web application, the network usage can be more important
    than the disk space. For a scientific application, you might have all the memory
    you need but the runtime can be a pain in the neck, and so on. In this book, we
    will limit our discussion to the runtime efficiency only.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm complexity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose you have a program (an algorithm) that processes some data in five minutes.
    If you increase the size of the data, how much time will the program need? The
    answer lies in the algorithm complexity. It tells us how well the algorithm will
    scale if you increase the size of the problem. In other words, the computational
    complexity influences the performance of the algorithm. In the next section, you
    will learn how to represent the computational complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Big O notation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In simple terms, the big O or big Oh notation is a way to represent the computational
    complexity of an algorithm. Here, the O is the letter *O*, as in *order*, and
    not the number zero. The big O indicates an upper bound or the worst-case scenario
    of the complexity of an algorithm (details to follow in the next section). This
    concept can be better explained with an example. Let''s take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Let's call this trivial code fragment an algorithm. It is a simple operation
    that appends a number to the `list` inside a `for` loop. Here, `num` represents
    the size of the input used by the algorithm. If you increase `num`, the algorithm
    will have to do more work inside the `for` loop. Increase it further, and the
    poor algorithm will have to do even more work. Thus, the time taken by the algorithm
    depends on the value of `num` and can be expressed as a growth function, *f(n)*.
    Here, *n* represents the size of the input that corresponds to `num` in this example.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Making sense so far? You can also test this by measuring the execution time.
    To see a real difference, choose a larger value of `num`.
  prefs: []
  type: TYPE_NORMAL
- en: In this algorithm, the most time consuming piece is the `for` loop, and it will
    determine the overall runtime of the algorithm. Inside the `for` loop, each call
    to `x.append(i)` takes constant time, *t*, to finish. For a large value of `num`,
    the total time taken by the loop will be approximately *num*(t)*. Thus, the runtime
    efficiency of the whole algorithm relative to `num` is linear. In terms of the
    big O notation, this particular algorithm is said to have *O(n)* complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Big O complexity classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s review some big O complexity classes. The following chart annotates
    various complexity classes and shows how *f(n)* influences the running time of
    algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Big O complexity classes](img/B05034_07_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: On the *y* axis, we have the *f(n)* function, and the *x* axis represents the
    input size, *n* (the `num` variable in the previous discussion). The plot compares
    some common functions that represent the time complexity of algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that the big O representation does not include the constants.
    So, even if two algorithms share the same big O complexity, they can clock a very
    different runtime performance. The circle marker in the plot shows a typical crossover
    point between two complexity functions. In this example, this is between *O(n)*
    and *O(n log n)*. As noted earlier, the individual algorithms representing these
    complexity functions will have different constant multipliers (not reflected in
    the big O notation). Tweaking those multipliers can change where this crossover
    happens.
  prefs: []
  type: TYPE_NORMAL
- en: Let's briefly review these notations now.
  prefs: []
  type: TYPE_NORMAL
- en: O(1) – constant time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Regardless of the value of the input size, the time taken by the algorithm remains
    constant. Getting the length of a Python list (`len(x)`, where `x` is the list)
    or the `append` list operation we saw earlier, are a few examples of *O(1)* complexity.
  prefs: []
  type: TYPE_NORMAL
- en: O(log n) – logarithmic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The time required by the algorithm is proportional to the logarithm of the input
    size. One of the examples of logarithmic complexity is a **binary search algorithm**.
    It starts with inspecting the middle element of a sorted array. If the value being
    searched is lower than the middle element, the entire upper half, including this
    middle element, is eliminated from the search. We can do this because it is a
    **sorted array**. This process is repeated for the remaining half and it continues
    until we find the desired value.
  prefs: []
  type: TYPE_NORMAL
- en: Confused? Let's see what Fairy is up to these days…
  prefs: []
  type: TYPE_NORMAL
- en: '| *Fairy has lost her enchanted locket in a room full of treasure chests. These
    boxes are numbered 1 to 100 and are arranged in increasing order. In other words,
    the boxes are sorted and the locket is placed in one of them. She is trying to
    find it with the help of her magical wand. The wand knows that the locket is in,
    for instance, box number 82, but it won''t give a straight answer! It expects
    her to ask the right questions.**She is standing exactly in the middle of the
    room and in front of box 50\. Towards her left, she sees numbers 1 to 49; and
    towards the right, numbers 51 to 100, in that order.**She asks her wand, is the
    locket in box 50? The wand says "no". She further asks, is the number greater
    than 50 or less than 50? The wand answers "greater than 50".**With this answer,
    she ignores the boxes on the left side (1-49), including box 50, and stands in
    the middle of the group, to her right (51-100). Now, she has box 75 in front of
    her. She repeats the questions with box 75 as the reference. Each time, half of
    the remaining chests are eliminated. The search operation goes on until she finds
    her locket in box 82.* |'
  prefs: []
  type: TYPE_TB
- en: This is the binary search in a nutshell. You can find more information on Wikipedia
    ([https://en.wikipedia.org/wiki/Binary_search_algorithm](https://en.wikipedia.org/wiki/Binary_search_algorithm)).
    In the worst case scenario, the time complexity of this search is *O(log n)*.
    Another way to look at the logarithmic complexity is as follows. For an exponential
    increase in the size of the problem *n*, the time taken by the algorithm increases
    linearly. As can be seen in the earlier chart, the *O(log n)* time complexity
    is better compared to the *O(n)* (linear-time) complexity, but not as good as
    *O(1)*.
  prefs: []
  type: TYPE_NORMAL
- en: O(n) – Linear time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We already saw an example where a `for` loop makes the algorithm of the *O(n)*
    complexity. Finding a min or max element in a Python list and copying a list or
    a dictionary are some other examples of this complexity.
  prefs: []
  type: TYPE_NORMAL
- en: O(n log n) – Log linear
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An example of a log linear time complexity is a **quicksort algorithm**. Let's
    call Fairy one more time to get a better idea of the working of this algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '| *Fairy enters another treasure room and finds it extremely disorganized.
    The treasure chests are randomly scattered everywhere in the room. Not liking
    this, she decides to sort the chests in an increasing order of their value (or
    price). Initially, the chests are randomly placed, like this:**[5 3 2 4 9 7 8
    8 ]**Here, the number represents the value of each chest. Fairy starts picking
    a pivot chest, say with a value tag of 5\. She then rearranges the chests into
    three sections: (i) The ones with a value lower than 5 are on the left side of
    the pivot, (ii) the pivotal chest 5, (iii) and the values greater than 5 are on
    the right side. This is shown below:**[3 2 4 5 9 7 8 8 ]**Next, with 5 fixed to
    its position, she repeats the preceding procedure to the items on the left and
    right sides of 5\. For example, consider only the left side of 5:**[3 2 4]**The
    fairy chooses number 3 as a new pivot and arranges the values to the left and
    right of 3, as shown earlier. This rearrangement results in:**[2 3 4]**The process
    goes on until all the chests are sorted in the increasing order of the valuables,
    as shown below:**[2 3 4 5 7 8 8 9]* |'
  prefs: []
  type: TYPE_TB
- en: This is the basic quicksort operation and has the complexity of *O(n log n)*.
    As shown in the earlier chart, for a higher value of *n*, the *O(n log n)* complexity
    is expensive compared to *O(n)*, but it is much better than the quadratic complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It should be noted that *O(n log n)* is the **average-case** complexity of the
    quicksort algorithm. Refer to the section, *Upper bound (worst-case) of the complexity*,
    of this chapter to learn about average-case and worst-case complexities.
  prefs: []
  type: TYPE_NORMAL
- en: O(n²) – Quadratic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This represents the quadratic runtime complexity. The time required to run
    the program grows as square of the size of the input to the algorithm. Let''s
    extend the previous example to understand this further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: It is a nested `for` loop. Let *t* be the time it takes to append an element
    to the list. As mentioned earlier, a single append operation is of *O(1)* complexity.
    The inner `for` loop will take approximately *n*t* (or *num*t*) to execute. Since
    we have an outer `for` loop, the total time complexity becomes *n*(n*t)*. A classic
    example of this complexity is a **bubble sort algorithm** ([https://en.wikipedia.org/wiki/Bubble_sort](https://en.wikipedia.org/wiki/Bubble_sort)).
    This algorithm sorts a list in an iterative manner, and it repeatedly swaps the
    adjacent elements of the list if these elements are placed in a wrong order.
  prefs: []
  type: TYPE_NORMAL
- en: O(n³) – cubic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a cubic complexity, which is worse than the quadratic complexity. A
    small increase in the problem size will result in a big increase in the runtime.
    Adding another outer `for` loop in the illustration on quadratic complexity will
    make it *O(n**3**)*.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is only a partial list of complexity classes. There are many more. For
    further information, check out [https://en.wikipedia.org/wiki/Big_O_notation](https://en.wikipedia.org/wiki/Big_O_notation).
  prefs: []
  type: TYPE_NORMAL
- en: Upper bound of the complexity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s revisit the statement we made earlier: "Big O notation indicates an
    upper bound or the worst-case scenario of the complexity of an algorithm". Quite
    a mouthful? An explanation is in order. We will reuse the illustration used in
    the discussion on the *O(n²)* complexity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We already saw that a single `x.append(i)` operation is *O(1)*, the inner loop
    is *O(N)*, and the full nested `for` loop has the time complexity of *O(n²)*.
    Then why do we say that the complexity of the algorithm as a whole is *O(n²)*?
  prefs: []
  type: TYPE_NORMAL
- en: If you look at the earlier chart that compared various complexities, *O(n²)*
    is the costliest among these three complexities and thus the most significant
    part of it. In other words, the algorithm complexity cannot get worse than *O(n²)*.
    Now, read the earlier statement on upper bounds one more time. The big O notation
    represents the worst-case scenario of the complexity of the algorithm. This is
    the reason why the big O complexity class for this algorithm is represented as
    *O(n²)*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Average-case time complexity:**'
  prefs: []
  type: TYPE_NORMAL
- en: Most of the time, an algorithm is analyzed by measuring its worst-case complexity.
    However, there are some problems where it makes practical sense to measure the
    **average-case time complexity**. Here, the amount of time taken to run the algorithm
    is averaged over all possible inputs. The quicksort algorithm we saw earlier is
    a classic example where average-case complexity is useful. It determines the real
    (or practical) efficiency of the algorithm. The average-case time complexity of
    this algorithm is *O(n log n),* whereas the worst-case complexity is *O(n²)*.
    For more information, check out [https://en.wikipedia.org/wiki/Average-case_complexity](https://en.wikipedia.org/wiki/Average-case_complexity).
  prefs: []
  type: TYPE_NORMAL
- en: Complexity for common data structures and algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The following table summarizes the time complexity of a few frequently performed
    operations on some Python data structures. This is not an exhaustive list, for
    that, see the Python wiki ([https://wiki.python.org/moin/TimeComplexity](https://wiki.python.org/moin/TimeComplexity)).
    It documents the time complexity of several other operations on these data structures.
  prefs: []
  type: TYPE_NORMAL
- en: '![Complexity for common data structures and algorithms](img/B05034_07_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The following table summarizes the time complexity of some common algorithms
    along with the Python functions that implement them. Note that the functions listed
    are from the NumPy library. Although the next chapter will introduce you to NumPy,
    we won't specifically talk about these functions in this book.
  prefs: []
  type: TYPE_NORMAL
- en: '![Complexity for common data structures and algorithms](img/B05034_07_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The first algorithm listed in the preceding table is a binary search algorithm.
    This was already illustrated when we talked about the *O(log n)* or logarithmic
    complexity. The `numpy.searchsorted` function uses binary search to find array
    indices where the elements need to be inserted to maintain order. The remaining
    algorithms in this table are a few common sorting algorithms that put elements
    in a list in a specific order. We already talked about quicksort. To learn more
    about the other algorithms, refer to [https://en.wikipedia.org/wiki/Sorting_algorithm](https://en.wikipedia.org/wiki/Sorting_algorithm).
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up the big O discussion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s summarize what you learned about the big O notation so far:'
  prefs: []
  type: TYPE_NORMAL
- en: Big O enables us to compare different algorithms in terms of their time (or
    space) complexity. This helps us choose the right algorithm (if possible) or determine
    the strategy to implement changes that speed things up.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It gives us the growth rate of an algorithm, but it will not give us the absolute
    value of the runtime. For example, some algorithm A takes 10 minutes to execute.
    On the same machine, algorithm B takes 200 minutes to execute, and guess what—both
    algorithms have the same complexity, say *O(n)*. Although they have different
    execution times, they have one thing in common, the time taken linearly increases
    with their problem size.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Wrapping up the big O discussion](img/B05034_07_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *Glad you brought that up! The big O notation indicates the worst-case scenario
    of an algorithm, and it rules other (less costly) complexity classes present in
    that algorithm. In other words, the worst-case complexity drives the performance
    of that algorithm.* |'
  prefs: []
  type: TYPE_TB
- en: It is good to be aware of the complexity, especially when the problem size is
    large. For a very small problem, it may or may not make a huge difference. A good
    practice is to analyze the existing algorithm for the performance bottlenecks,
    and then see if it is worth revamping the algorithm for speedup. Weigh in the
    factors, such as the time you spend on changing the algorithm and its impact on
    the quality (bugs and testing) versus the long term benefit of the speedup accomplished.
    In a nutshell, choose the strategy that best fits your needs.
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth noting that sometimes you have to live with an algorithm with
    a certain complexity class. But that is not the end of the road. You can still
    implement techniques to speedup the code without changing its order of complexity.
    The performance improvement obtained will depend on the problem in hand. For example,
    you can parallelize the code or compute some parameters in advance to achieve
    speedup. Later in this book, we will cover basics of parallelization in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was the first one in the series of three chapters based on performance.
    It laid the ground work to improve application performance. We learned how to
    record the runtime using the `time` module. We also saw how the `timeit` module
    can be used to measure the performance of small pieces of code. We took a practical
    problem where an application ran fine when working with a small input, but, as
    the input grew larger, it slowed down considerably. With this example, we learned
    how to identify the bottlenecks using `cProfile` and display the results using
    `pstats`.
  prefs: []
  type: TYPE_NORMAL
- en: We saw how the `line_profiler` module can help locate the time consuming statements
    inside a function. While most of the discussion was focused on the runtime performance,
    we briefly covered the `memory_profiler` module. This module enabled line-by-line
    analysis of memory consumption for the given functions. Finally, we learned about
    the big O notation that represents the computational complexity of an algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have identified the performance bottlenecks, let's move on to the
    next chapter to improve the application performance.
  prefs: []
  type: TYPE_NORMAL
