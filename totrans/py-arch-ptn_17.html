<html><head></head><body><div><p>&#13;&#13;
    <h1 class="chapterNumber">13</h1>&#13;&#13;
    <h1 id="_idParaDest-247" class="chapterTitle">Metrics</h1>&#13;&#13;
    <p class="normal">As well as logging, the other key element of observability is metrics. Metrics allow you to see the general state of the system and observe trends and situations that are mostly caused by multiple, perhaps even many, tasks being executed at the same time.</p>&#13;&#13;
    <div>&#13;&#13;
      <p class="Tip--PACKT-">During this chapter, we will mostly use examples of web services, like request metrics. Do not feel restricted by them; you can generate metrics in all kinds of services!</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">When monitoring a live system, typically metrics are the main focus, as they allow you to see at a glance whether everything appears to be working correctly. Normally with metrics, it is possible to detect if a system is struggling, for example, for a sudden increase in the number of incoming requests, but also to foresee problems by showing trends, like a small but constant increase in the number of requests. This allows you to act preemptively, without waiting until a problem is serious.</p>&#13;&#13;
    <p class="normal">Generating a good metric system to monitor the life of a system is invaluable to be able to react quickly when problems arise. Metrics can also be used as a base for automatic alerts that can help warn about certain conditions taking place, typically something to investigate or correct.</p>&#13;&#13;
    <p class="normal">In this chapter, we'll cover the following topics:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet">Metrics versus logs</li>&#13;&#13;
      <li class="bullet">Generating metrics with Prometheus</li>&#13;&#13;
      <li class="bullet">Querying Prometheus</li>&#13;&#13;
      <li class="bullet">Proactively working with metrics</li>&#13;&#13;
      <li class="bullet">Alerting</li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">First, we will take a look at metrics compared with the other main tool for observability, logs.</p>&#13;&#13;
    <h1 id="_idParaDest-248" class="title">Metrics versus logs</h1>&#13;&#13;
    <p class="normal">As we saw in the previous chapter, logs are text messages produced as code is executed. They are good at giving visibility on each of the specific tasks that the system is performing, but they generate a huge amount of data, which is difficult to digest in bulk. Instead, only small groups of logs are able to be analyzed at any given time.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Information-Box--PACKT-">Normally, the logs analyzed will all be related to a single task. We saw in the previous chapter how to use a request ID for that. But on certain occasions, it may be necessary to check all logs happening in a particular time window to see crossing effects, like a problem in one server that affects all tasks during certain times.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">But sometimes<a id="_idIndexMarker865"/> the important information is not a specific request, but to understand the <a id="_idIndexMarker866"/>behavior of the system as a whole. Is the load of the system growing compared to yesterday's? How many errors are we returning? Is the time it takes to process tasks increasing? Or decreasing?</p>&#13;&#13;
    <p class="normal">All those questions are impossible to answer with logs, as they require a broader view, at a higher level. To be able to achieve that, the data needs to be aggregated to be able to understand the system as a whole.</p>&#13;&#13;
    <p class="normal">The information to store in metrics is also different. While each recorded log is a text message, each produced metric is a number. These numbers will later be statistically processed to aggregate the information. </p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Information-Box--PACKT-">We will talk later in the chapter about the different kinds of numbers that can be produced as a metric.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">The difference between the amount of information produced in each record means that metrics are much more lightweight compared with logs. To further reduce the amount of data stored, the data is aggregated automatically. </p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">The resolution of metrics may depend on the tool and set configuration. Keep in mind that a higher resolution will require more resources to store all the data. A typical resolution is one minute, which is small enough to present detailed information unless you have a very active system that routinely receives 10 tasks per second or more.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">Metrics should capture and analyze information related to performance, such as the average time to process a task. That allows you to detect possible bottlenecks and act quickly in order to<a id="_idIndexMarker867"/> improve the performance of the system. This is easier to do in an<a id="_idIndexMarker868"/> aggregated way, as information for a single task, like generated logs, may not capture enough information to see the big picture. An important outcome of this is to be able to see trends and detect problems before they grow too big, remediating them early. Compared to this, logs are mostly used after the fact and are difficult to use as a way to take preventive action.</p>&#13;&#13;
    <h2 id="_idParaDest-249" class="title">Kinds of metrics</h2>&#13;&#13;
    <p class="normal">There are different kinds of metrics that can be produced. This can be different depending on the specific tool used to generate the metrics, but in general, there are a few that are common in most systems, like the following:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet"><strong class="keyword">Counter</strong>: A trigger is<a id="_idIndexMarker869"/> generated each time something happens. This will be counted and aggregated as a total; for example, in a web service, the number of requests or the number of generated errors. Counters are useful for understanding how many times a certain action happens in the system.</li>&#13;&#13;
      <li class="bullet"><strong class="keyword">Gauge</strong>: A single number across the system. A gauge<a id="_idIndexMarker870"/> number can go up or down, but the last value overwrites the previous, as it stores the general state of the system; for example, the number of elements in a queue, or the number of existing workers in the system.</li>&#13;&#13;
      <li class="bullet"><strong class="keyword">Measure</strong>: Events that have a numeric value associated with them. These numbers can be averaged, summed, or aggregated in a certain way. Compared with gauges, the difference is that previous measures are still independent; for example, when we emit a metric with a request time in milliseconds and request size in bytes. <p class="bullet">Measures<a id="_idIndexMarker871"/> can also work as counters, since each emitted event is, in essence, a counter. For example, tracking the request time will also count the number of requests, as it will be generated once per request. Tools will normally create the associated counter automatically for every measure.</p>&#13;&#13;
      </li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">Defining which metric is adequate for the specific value to measure is important. In most cases, they'll be <em class="italic">measures</em>, to allow storing a value produced by events. <em class="italic">Counters</em> are normally evident (they are <em class="italic">measures</em> without values), while <em class="italic">gauges</em> are normally the ones that are less obvious and can present more of a challenge on when to use them.</p>&#13;&#13;
    <p class="normal">Metrics can <a id="_idIndexMarker872"/>also be derived from other metrics to generate new ones. For example, we can divide the number of requests that return an error code by the total number of requests to produce an error percentage. Such derived metrics can help you understand information in a meaningful way.</p>&#13;&#13;
    <p class="normal">There are also two kinds of metric systems, depending on how the metrics are produced:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet">Every time there's a metric produced, an event gets <em class="italic">pushed</em> toward the metrics collector</li>&#13;&#13;
      <li class="bullet">Each system maintains its own metrics internally, which are periodically <em class="italic">pulled</em> from the metrics collector</li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">Each system has its own pros and cons. Pushing events produces higher traffic and activity, as every individual event is sent immediately, which can cause bottlenecks and delays. Pulling events will only sample the information, and produce lower-resolution data, as it can miss what happened between samples, but it's more stable as the number of requests is not increasing with the number of events.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">Both approaches are used, but the current trend is moving toward pulling systems. They reduce the amount of maintenance that is required for pushing systems and are easier to scale.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">We will use some examples with Prometheus, a metrics system that uses the pulling approach. The most used exponent of the push approach is Graphite.</p>&#13;&#13;
    <h1 id="_idParaDest-250" class="title">Generating metrics with Prometheus</h1>&#13;&#13;
    <p class="normal">Prometheus is a popular metrics system that is well supported and easy to use. We will use it as an example during the chapter to show how to collect metrics and how it interconnects with other tools to display metrics.</p>&#13;&#13;
    <p class="normal">As we saw before, Prometheus <a id="_idIndexMarker873"/>uses the <em class="italic">pulling</em> approach to metrics <a id="_idIndexMarker874"/>generation. That means that any system that produces metrics will run its own internal Prometheus client that keeps track of metrics. </p>&#13;&#13;
    <p class="normal">For web services, this can be added as an extra endpoint that serves the metrics. This is the approach taken by the <code class="Code-In-Text--PACKT-">django-prometheus</code> module, which will automatically collect a lot of common metrics for a Django web service.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">We will build up from the Django application code presented in <em class="chapterRef">Chapter 6</em>, <em class="italic">Web Server Structures</em>, to present a working application. Check the code in GitHub at <a href="https://github.com/PacktPublishing/Python-Architecture-Patterns/tree/main/chapter_13_metrics/microposts">https://github.com/PacktPublishing/Python-Architecture-Patterns/tree/main/chapter_13_metrics/microposts</a>.</p>&#13;&#13;
    </p>&#13;&#13;
    <h2 id="_idParaDest-251" class="title">Preparing the environment</h2>&#13;&#13;
    <p class="normal">We need to set up the<a id="_idIndexMarker875"/> environment to be sure to install all the required packages and dependencies of the code. </p>&#13;&#13;
    <p class="normal">Let's start by creating a new virtual environment, as introduced in <em class="chapterRef">Chapter 11</em>, <em class="italic">Package Management</em>, to be sure to create our own isolated sandbox to install packages:</p>&#13;&#13;
    <pre class="programlisting con"><code class="hljs-con">$ python3 -m venv venv&#13;&#13;
$ source venv/bin/activate&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">We can now install the prepared list of requirements, stored in <code class="Code-In-Text--PACKT-">requirements.txt</code>. This contains the Django and Django REST framework modules, as seen in <em class="chapterRef">Chapter 6</em>, <em class="italic">Web Server Structures</em>, but also the Prometheus dependency:</p>&#13;&#13;
    <pre class="programlisting con"><code class="hljs-con">(venv) $ cat requirements.txt&#13;&#13;
django&#13;&#13;
django-rest-framework&#13;&#13;
django-prometheus&#13;&#13;
(venv) $ pip install -r requirements.txt&#13;&#13;
Collecting Django&#13;&#13;
  Downloading Django-3.2.7-py3-none-any.whl (7.9 MB)&#13;&#13;
     |████████████████████████████████| 7.9 MB 5.7 MB/s&#13;&#13;
...&#13;&#13;
Installing collected packages: djangorestframework, django-rest-framework&#13;&#13;
    Running setup.py install for django-rest-framework ... done&#13;&#13;
Successfully installed django-rest-framework-0.1.0 djangorestframework-3.12.4&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">To start the server, go to the <code class="Code-In-Text--PACKT-">micropost</code> subdirectory and run the <code class="Code-In-Text--PACKT-">runserver</code> command:</p>&#13;&#13;
    <pre class="programlisting con"><code class="hljs-con">(venv) $ python3 manage.py runserver 0.0.0.0:8000&#13;&#13;
Watching for file changes with StatReloader&#13;&#13;
Performing system checks...&#13;&#13;
System check identified no issues (0 silenced).&#13;&#13;
October 01, 2021 - 23:24:26&#13;&#13;
Django version 3.2.7, using settings 'microposts.settings'&#13;&#13;
Starting development server at http://0.0.0.0:8000/&#13;&#13;
Quit the server with CONTROL-C.&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">The application is<a id="_idIndexMarker876"/> now accessible in the root address: <code class="Code-In-Text--PACKT-">http://localhost:8000</code>, for example, <code class="Code-In-Text--PACKT-">http://localhost:8000/api/users/jaime/collection</code>.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Information-Box--PACKT-">Note that we started the server at address 0.0.0.0. This opens Django to serve any IP address, and not only requests coming from <code class="Code-In-Text--PACKT-">localhost</code>. This is an important detail that will be clarified later.</p>&#13;&#13;
      <p class="Information-Box--PACKT-">Note also that the root address will return a 404 error, as no endpoint is defined there.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">If you remember from <em class="chapterRef">Chapter 3</em>, <em class="italic">Data Modeling</em>, we added some initial data, so you can access the URLs <code class="Code-In-Text--PACKT-">http://localhost:8000/api/users/jaime/collection</code> and <code class="Code-In-Text--PACKT-">http://localhost:8000/api/users/dana/collection</code> to see some data. </p>&#13;&#13;
    <figure class="mediaobject"><img src="img/B17580_13_1.png" alt="Graphical user interface, application&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="606"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 13.1: Accessing an available URL in the application</p>&#13;&#13;
    <p class="normal">Access these <a id="_idIndexMarker877"/>pages a couple of times to produce metrics that we can later access.</p>&#13;&#13;
    <h2 id="_idParaDest-252" class="title">Configuring Django Prometheus</h2>&#13;&#13;
    <p class="normal">The configuration<a id="_idIndexMarker878"/> of the <code class="Code-In-Text--PACKT-">django-prometheus</code> module is done in the <code class="Code-In-Text--PACKT-">microposts/settings.py</code> file, where we need to do two things.</p>&#13;&#13;
    <p class="normal">First, add the <code class="Code-In-Text--PACKT-">django-prometheus</code> application to the installed app list which enables <a id="_idIndexMarker879"/>the module:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">INSTALLED_APPS = [&#13;&#13;
    'django.contrib.admin',&#13;&#13;
    'django.contrib.auth',&#13;&#13;
    'django.contrib.contenttypes',&#13;&#13;
    'django.contrib.sessions',&#13;&#13;
    'django.contrib.messages',&#13;&#13;
    'django.contrib.staticfiles',&#13;&#13;
    'django_prometheus',&#13;&#13;
    'rest_framework',&#13;&#13;
    'api',&#13;&#13;
]&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">We also need to include the proper middlewares to track requests. We need to put one middleware at the start of the request process and another at the end, to be sure to capture and measure the whole process:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">MIDDLEWARE = [&#13;&#13;
    'django_prometheus.middleware.PrometheusBeforeMiddleware',&#13;&#13;
    'django.middleware.security.SecurityMiddleware',&#13;&#13;
    'django.contrib.sessions.middleware.SessionMiddleware',&#13;&#13;
    'django.middleware.common.CommonMiddleware',&#13;&#13;
    'django.middleware.csrf.CsrfViewMiddleware',&#13;&#13;
    'django.contrib.auth.middleware.AuthenticationMiddleware',&#13;&#13;
    'django.contrib.messages.middleware.MessageMiddleware',&#13;&#13;
    'django.middleware.clickjacking.XFrameOptionsMiddleware',&#13;&#13;
    'django_prometheus.middleware.PrometheusAfterMiddleware',&#13;&#13;
]&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">Check the position of <code class="Code-In-Text--PACKT-">django.prometheus.middleware.PrometheusBeforeMiddleware</code> and <code class="Code-In-Text--PACKT-">django_prometheus.middleware.PrometheusAfterMiddleware</code>.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Information-Box--PACKT-">We also changed the <code class="Code-In-Text--PACKT-">ALLOWED_HOSTS</code> value to be <code class="Code-In-Text--PACKT-">'*'</code> and allow requests from any hostname. This detail will be explained a bit later.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">With this configuration, the Prometheus collection is now enabled. But we also need a way to access them. Remember, an important element for the Prometheus system is that each application serves its own metric collection. </p>&#13;&#13;
    <p class="normal">In this case, we can<a id="_idIndexMarker880"/> add an endpoint to the file <code class="Code-In-Text--PACKT-">microposts/url.py</code>, which handles the top-level URLs for the system:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">from django.contrib import admin&#13;&#13;
from django.urls import include, path&#13;&#13;
urlpatterns = [&#13;&#13;
    path('', include('django_prometheus.urls')),&#13;&#13;
    path('api/', include('api.urls')),&#13;&#13;
    path('admin/', admin.site.urls),&#13;&#13;
]&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">The <code class="Code-In-Text--PACKT-">path('', include('django_prometheus.urls'))</code> line sets up a <code class="Code-In-Text--PACKT-">/metrics</code> URL that we can now<a id="_idIndexMarker881"/> access.</p>&#13;&#13;
    <h2 id="_idParaDest-253" class="title">Checking the metrics</h2>&#13;&#13;
    <p class="normal">The main URL root shows that <a id="_idIndexMarker882"/>there's a new endpoint – <code class="Code-In-Text--PACKT-">/metrics</code>:</p>&#13;&#13;
    <figure class="mediaobject"><img src="img/B17580_13_02.png" alt="Graphical user interface, text, application&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="462"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 13.2: This page appears because the DEBUG mode is active. Remember to deactivate it before deploying in production</p>&#13;&#13;
    <p class="normal">When accessing the <code class="Code-In-Text--PACKT-">/metrics</code> endpoint, it shows all the collected metrics. Note that there are a lot of metrics that are collected. This is all in text format, and it's expected to be collected by a <a id="_idIndexMarker883"/>Prometheus metric server.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">Be sure to access a few times the endpoints <code class="Code-In-Text--PACKT-">http://localhost:8000/api/users/jaime/collection</code> and <code class="Code-In-Text--PACKT-">http://localhost:8000/api/users/dana/collection</code> to produce some metrics. You can check how some metrics, like <code class="Code-In-Text--PACKT-">django_http_requests_total_by_view_transport_method_total{method="GET",transport="http",view="user-collection"}</code>, are increasing.</p>&#13;&#13;
    </p>&#13;&#13;
    <figure class="mediaobject"><img src="img/B17580_13_3.png" alt="Graphical user interface, text&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="553"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 13.3: The raw Prometheus metrics, as collected by the application</p>&#13;&#13;
    <p class="normal">The next step is to start a <a id="_idIndexMarker884"/>Prometheus server that can pull the info and display it.</p>&#13;&#13;
    <h2 id="_idParaDest-254" class="title">Starting a Prometheus server</h2>&#13;&#13;
    <p class="normal">The Prometheus server <a id="_idIndexMarker885"/>will pull periodically for metrics to all the configured applications that are collecting their metrics. These elements are called <em class="italic">targets</em> by Prometheus.</p>&#13;&#13;
    <p class="normal">The easiest way to start a Prometheus server is to start the official Docker image.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">We introduced Docker in <em class="chapterRef">Chapter 9</em>, <em class="italic">Microservices vs Monolith</em>. Refer to that chapter for more information.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">We need to start the server, but before that, we need to set up the configuration in the <code class="Code-In-Text--PACKT-">prometheus.yml</code> file. You can check the example on GitHub: <a href="https://github.com/PacktPublishing/Python-Architecture-Patterns/blob/main/chapter_13_metrics/prometheus.yml">https://github.com/PacktPublishing/Python-Architecture-Patterns/blob/main/chapter_13_metrics/prometheus.yml</a>:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code"># my global config&#13;&#13;
global:&#13;&#13;
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.&#13;&#13;
  # scrape_timeout is set to the global default (10s).&#13;&#13;
scrape_configs:&#13;&#13;
  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.&#13;&#13;
  - job_name: "prometheus"&#13;&#13;
    # metrics_path defaults to '/metrics'&#13;&#13;
    # scheme defaults to 'http'.&#13;&#13;
    static_configs:&#13;&#13;
      # The target needs to point to your local IP address&#13;&#13;
      # 192.168.1.196 IS AN EXAMPLE THAT WON'T WORK IN YOUR SYSTEM&#13;&#13;
      - targets: ["192.168.1.196:8000"]&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">The config file has two main sections. The first with <code class="Code-In-Text--PACKT-">global</code> indicates how often to scrape (to read information from the targets) and other general configuration values.</p>&#13;&#13;
    <p class="normal">The second, <code class="Code-In-Text--PACKT-">scrape_config</code>, describes what to scrape from, and the main parameter is <code class="Code-In-Text--PACKT-">targets</code>. Here, we need to configure all our targets. This one in particular needs to be described by its external IP, which will be the IP from your computer. </p>&#13;&#13;
    <p class="normal">This address cannot be <code class="Code-In-Text--PACKT-">localhost</code>, as inside the Prometheus Docker container it will resolve as the same <a id="_idIndexMarker886"/>container, which is not what you want. You'll need to find out your local IP address. </p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">If you don't know how to find it through ipconfig or ifconfig, you can check out this article on ways to find it: <a href="https://lifehacker.com/how-to-find-your-local-and-external-ip-address-5833108">https://lifehacker.com/how-to-find-your-local-and-external-ip-address-5833108</a>. Remember that it's your <strong class="keyword">local address</strong>, not the external one.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">This is to ensure that the Prometheus server can access the Django application that's running locally. As you remember, we opened the access allowing connections from any hostname with the option <code class="Code-In-Text--PACKT-">0.0.0.0</code> when starting the server and allowing all hosts in the config parameter <code class="Code-In-Text--PACKT-">ALLOWED_HOSTS</code>.</p>&#13;&#13;
    <p class="normal">Double-check that you can access the metrics in the local IP.</p>&#13;&#13;
    <figure class="mediaobject"><img src="img/B17580_13_4.png" alt="Text&#13;&#10;&#13;&#10;Description automatically generated with low confidence" width="829" height="653"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 13.4: Note the IP used to access; remember that you should use your own local one</p>&#13;&#13;
    <p class="normal">With all this<a id="_idIndexMarker887"/> information, you are now ready to start the Prometheus server in Docker, using your own config file. </p>&#13;&#13;
    <p class="normal">Please note that this command requires you to find the full path to the <code class="Code-In-Text--PACKT-">prometheus.yml</code> file. If you are in the same directory, you can address it as <code class="Code-In-Text--PACKT-">$(pwd)/prometheus.yml</code>.</p>&#13;&#13;
    <p class="normal">For this, run the following <code class="Code-In-Text--PACKT-">docker</code> command, adding the whole path to the config file to share it with the new container:</p>&#13;&#13;
    <pre class="programlisting con"><code class="hljs-con">$ docker run -p 9090:9090  -v /full/path/to/file/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus&#13;&#13;
level=info ts=2021-10-02T15:24:17.228Z caller=main.go:400 msg="No time or size retention was set so using the default time retention" duration=15d&#13;&#13;
level=info ts=2021-10-02T15:24:17.228Z caller=main.go:438 msg="Starting Prometheus" version="(version=2.30.2, branch=HEAD, revision=b30db03f35651888e34ac101a06e25d27d15b476)"&#13;&#13;
... &#13;&#13;
level=info ts=2021-10-02T15:24:17.266Z caller=main.go:794 msg="Server is ready to receive web requests."&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">The <code class="Code-In-Text--PACKT-">docker</code> command<a id="_idIndexMarker888"/> is structured in the following way:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet"><code class="Code-In-Text--PACKT-">-p 9090:9090</code> maps the local 9090 port to the 9090 port inside the container</li>&#13;&#13;
      <li class="bullet"><code class="Code-In-Text--PACKT-">-v /full/path/to/file/prometheus.yml:/etc/prometheus/prometheus.yml</code> mounts the local file (remember to add the full path or use <code class="Code-In-Text--PACKT-">$(pwd)/prometheus.yml</code>) in the expected configuration route for Prometheus</li>&#13;&#13;
      <li class="bullet"><code class="Code-In-Text--PACKT-">docker run prom/Prometheus</code> is the command to run the <code class="Code-In-Text--PACKT-">prom/Prometheus </code>image, which is the official Prometheus image</li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">After the Prometheus server is up and running, the server is accessible at <code class="Code-In-Text--PACKT-">http://localhost:9090</code>.</p>&#13;&#13;
    <figure class="mediaobject"><img src="img/B17580_13_5.png" alt="A picture containing text, screenshot, monitor, screen&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="645"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 13.5: The empty graph Prometheus page</p>&#13;&#13;
    <p class="normal">From here, we can start querying the system.</p>&#13;&#13;
    <h1 id="_idParaDest-255" class="title">Querying Prometheus</h1>&#13;&#13;
    <p class="normal">Prometheus has its <a id="_idIndexMarker889"/>own query system, called PromQL, and ways of operating with metrics that, while powerful, can be a little confusing at the beginning. Part of it is its pull approach to metrics.</p>&#13;&#13;
    <p class="normal">For example, requesting one useful metric, like <code class="Code-In-Text--PACKT-">django_http_requests_latency_seconds_by_view_method_count</code>, will display how many times each view has <a id="_idIndexMarker890"/>been called for each method.</p>&#13;&#13;
    <figure class="mediaobject"><img src="img/B17580_13_6.png" alt="Graphical user interface, application, table, Excel&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="649"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 13.6: Notice how the prometheus-django-metrics view is called more often, as it is called automatically by Prometheus once every 15 seconds to scrape the results</p>&#13;&#13;
    <p class="normal">This is presented as an accumulated value that grows over time. This is not very useful, as it's difficult to make<a id="_idIndexMarker891"/> sense of what exactly it means.</p>&#13;&#13;
    <p class="normal">Instead, the value is more likely to be presented as a <code class="Code-In-Text--PACKT-">rate</code>, representing how many requests have been detected per second. For example, with a resolution of 1 minute, <code class="Code-In-Text--PACKT-">rate(django_http_requests_latency_seconds_by_view_method_count[1m])</code> shows the following graph instead:</p>&#13;&#13;
    <figure class="mediaobject"><img src="img/B17580_13_7.png" alt="Graphical user interface, application, table&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="650"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 13.7: Note that the different methods and views are displayed as different lines</p>&#13;&#13;
    <p class="normal">As you can see, there's a <a id="_idIndexMarker892"/>constant number of requests from <code class="Code-In-Text--PACKT-">prometheus-django-metrics</code>, which is Prometheus requesting the metrics information. This happens once every 15 seconds, or approximately 0.066 times per second.</p>&#13;&#13;
    <p class="normal">In the graph, there's also another spike of the <code class="Code-In-Text--PACKT-">user-collection</code> method happening at 15:55, at the time where we manually generated some requests to the service. As you can see, the resolution is per minute, as described in the rate.</p>&#13;&#13;
    <p class="normal">If we want to aggregate all of this in a single graph, we can use the sum operator, specifying what we want to<a id="_idIndexMarker893"/> aggregate from. To sum all <code class="Code-In-Text--PACKT-">GET</code> requests, for example, with:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">sum(rate(django_http_requests_latency_seconds_by_view_method_count[1m])) by (method)&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">This produces this other graph: </p>&#13;&#13;
    <figure class="mediaobject"><img src="img/B17580_13_8.png" alt="Graphical user interface, application, table, Excel&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="645"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 13.8: Note the bottom value is based on the baseline created by the calls to prometheus-django-metrics</p>&#13;&#13;
    <p class="normal">To plot times instead, the metric to use is the <code class="Code-In-Text--PACKT-">django_http_requests_latency_seconds_by_view_method_bucket</code> one. The bucket metrics are generated in a<a id="_idIndexMarker894"/> way that can be combined with the <code class="Code-In-Text--PACKT-">histogram_quantile</code> function to display a particular quantile, which is useful for giving a proper feeling of times.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">For example, quantile 0.95 means that the time is the highest of 95% of the requests. This is more useful than creating averages as they can get skewed by high numbers. Instead, you can draw the quantile 0.50 (the maximum time it takes for half of the requests), the quantile 0.90 (the maximum time for most of the requests), and quantile 0.99 for the very top time it takes to return a request. This allows you to get a better picture, as it's different from the situation of growing quantile 0.50 (most requests take longer to return) with growing quantile 0.99 (some slow queries are getting worse).</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">To plot the 0.95 quantile over a period of 5 minutes, the following query can be generated:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">histogram_quantile(0.95, rate(django_http_requests_latency_seconds_by_view_method_bucket[5m]))&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">When you run it, you should receive the following:</p>&#13;&#13;
    <figure class="mediaobject"><img src="img/B17580_13_9.png" alt="Table&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="649"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 13.9: Note how the metrics collection is much faster than the user-collection requests</p>&#13;&#13;
    <p class="normal">To plot times instead, the <a id="_idIndexMarker895"/>metric to use is the <code class="Code-In-Text--PACKT-">django_http_requests_latency_seconds_by_view_method_bucket</code> one. The bucket metrics are generated in a way that can be combined with the <code class="Code-In-Text--PACKT-">histogram_quantile</code> function to display a particular quantile, which is useful for giving a proper feeling of times.</p>&#13;&#13;
    <p class="normal">Metrics can also be filtered to display only specific labels, and a good number of functions to multiply, divide, add, create averages, and all kinds of operations are available.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">Prometheus queries can be a bit long and complicated when trying to display the result of several metrics, such as the percentage of successful requests over the total. Be sure to test that the result is what you expect it to be and allocate time to tweak the queries later to keep improving them.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">The interface has <a id="_idIndexMarker896"/>autocompleted, which can help you find certain metrics.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">Prometheus is normally paired with Grafana. Grafana is an open source, interactive visualization tool that can be connected with Prometheus to create rich dashboards. This leverages the collection of metrics and helps visualize the state of the system in a much more understandable way. Describing how to use Grafana<a id="_idIndexMarker897"/> is out of scope for this book, but using it to display metrics is highly recommended: <a href="https://grafana.com/">https://grafana.com/</a>.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">Check the Prometheus <a id="_idIndexMarker898"/>documentation about queries to find out more: <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/">https://prometheus.io/docs/prometheus/latest/querying/basics/</a>.</p>&#13;&#13;
    <h1 id="_idParaDest-256" class="title">Proactively working with metrics</h1>&#13;&#13;
    <p class="normal">As we've seen, metrics <a id="_idIndexMarker899"/>show an aggregated point of view for the status of the whole cluster. They allow you to detect trending problems, but it's difficult to pinpoint a single spurious error.</p>&#13;&#13;
    <p class="normal">This shouldn't stop us from considering them as a critical tool for successful monitoring because they can tell whether the whole system is healthy. In some companies, the most critical metrics are on permanent display on screens so the operations team can see them and react quickly to any sudden problem.</p>&#13;&#13;
    <p class="normal">Finding the proper balance of what metrics are the key ones for a service is not as straightforward as it seems, and it will require time and experience, perhaps even trial and error. </p>&#13;&#13;
    <p class="normal">There are, though, four metrics for online services that are considered always important. They are:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet"><strong class="keyword">Latency</strong>: How many <a id="_idIndexMarker900"/>milliseconds it takes for the system to respond to a request. Depending on the service, sometimes seconds can be used instead. In my experience, milliseconds are typically the adequate time scale, as most web applications take between 50 ms and 1 second to respond, depending on the request. Requests taking longer than 1 second are typically rarer, though there are always some, depending on the system.</li>&#13;&#13;
      <li class="bullet"><strong class="keyword">Traffic</strong>: The <a id="_idIndexMarker901"/>number of requests flowing through the system per unit of time, for example, the number of requests per minute.</li>&#13;&#13;
      <li class="bullet"><strong class="keyword">Errors</strong>: The <a id="_idIndexMarker902"/>percentage of requests received that return an error.</li>&#13;&#13;
      <li class="bullet"><strong class="keyword">Saturation</strong>: Describing <a id="_idIndexMarker903"/>whether the capacity of the cluster has enough headroom. This includes elements as available hard drive space, memory, and so on. For example, there's 15% available RAM in the system.</li>&#13;&#13;
    </ul>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">The main tool to check saturation is the multiple default exporters available to collect most of the hardware information automatically, like memory, CPU, and hard drive space. When using a cloud provider, normally they expose their own set of related metrics, like CloudWatch in AWS.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">These metrics can be found in the Google SRE book as <em class="italic">the four golden signals</em> and are recognized as the most important high-level elements for successful monitoring.</p>&#13;&#13;
    <h1 id="_idParaDest-257" class="title">Alerting</h1>&#13;&#13;
    <p class="normal">When problems are detected <a id="_idIndexMarker904"/>through the metrics, an automatic alert should be triggered. Prometheus has an alert system that will raise when a defined metric fulfills the defined alert.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Information-Box--PACKT-">Check out the Prometheus <a id="_idIndexMarker905"/>documentation on alerting for more information: <a href="https://prometheus.io/docs/alerting/latest/overview/">https://prometheus.io/docs/alerting/latest/overview/</a>.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">Normally, alerts will be configured when the value of metrics is crossing some threshold. For example, the number of errors is higher than X, or the time to return a request is too high.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">An alert could also be that some element is too low; for example, if the number of requests in a system falls to zero, that could be an indication that the system is down.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">The built-in Alertmanager can alert in some ways, like sending an email, but it can also be connected to other tools to perform more complex actions. For example, connecting to an integrated incident solution like <a id="_idIndexMarker906"/>Opsgenie (<a href="https://www.atlassian.com/software/opsgenie">https://www.atlassian.com/software/opsgenie</a>) allows you to create alert flows, such as sending emails and SMS, calls.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">While alerts can be generated directly from metrics, there are tools that allow you also to generate alerts from logs directly. For example, Sentry (<a href="https://sentry.io/">https://sentry.io/</a>) will aggregate errors <a id="_idIndexMarker907"/>based on logs and can set up thresholds to escalate toward more active alerts, like sending emails.Another alternative is to derivate metrics from logs using external logging systems. This allows you, for example, to create a counter based on the number of <code class="Code-In-Text--PACKT-">ERROR</code> logs, or more complicated metrics. These systems, once more, allow you to trigger alerts based on these derived metrics.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">Alerting, as with metrics, is an ongoing<a id="_idIndexMarker908"/> process. Some key thresholds won't be evident at the start of the system, and only experience will allow you to discover them. In the same way, it's very likely that some alerts are created that don't require active monitoring, and should be disconnected to ensure that the alerts in the system are on point and have a high signal-to-noise ratio.</p>&#13;&#13;
    <h1 id="_idParaDest-258" class="title">Summary</h1>&#13;&#13;
    <p class="normal">In this chapter, we described what metrics are and how they compare with logs. We described how metrics are useful to analyze the general state of the system, while logs describe specific tasks, being more difficult to describe the aggregated situation.</p>&#13;&#13;
    <p class="normal">We enumerated different kinds of metrics that can be produced and described Prometheus, a common metrics system that uses the pull approach on how to capture metrics.</p>&#13;&#13;
    <p class="normal">We set an example of how to generate metrics automatically in Django by installing and configuring the <code class="Code-In-Text--PACKT-">django-prometheus</code> module, and how to start a Prometheus server that scrapes the generated metrics.</p>&#13;&#13;
    <p>&#13;&#13;
      <p class="Tip--PACKT-">Keep in mind that you can also generate your own custom metrics, not having to only rely on the ones in an external module. Check the Prometheus client to see how, for example, for Python: <a href="https://github.com/prometheus/client_python">https://github.com/prometheus/client_python</a>.</p>&#13;&#13;
    </p>&#13;&#13;
    <p class="normal">Next, we described how to query metrics in Prometheus, introducing PromQL, and showed some common examples of how to display metrics, plot <code class="Code-In-Text--PACKT-">rate</code> to see clearly how the metrics are changing over time, and how to use the <code class="Code-In-Text--PACKT-">histogram_quantile</code> function to work with times.</p>&#13;&#13;
    <p class="normal">We also showed in the chapter how to work proactively to detect common problems as soon as possible and what the four golden signals are, as described by Google. Finally, we introduced alerts as a way to be notified when metrics are out of a normal margin. Using alerts is a smart way to be notified without having to manually look at metrics.</p>&#13;&#13;
  </div>&#13;&#13;
</div></body></html>