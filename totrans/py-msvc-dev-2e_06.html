<html><head></head><body>
  <div id="_idContainer040">
    <h1 class="chapterNumber">6</h1>
    <h1 id="_idParaDest-98" class="chapterTitle">Interacting with Other Services</h1>
    <p class="normal">In the previous chapter, our monolithic application was split up into several microservices, and consequently, more network interactions between the different parts were included.</p>
    <p class="normal">More interactions with other components can lead to complications of their own, however, such as a high volume of messages or large data sizes delaying responses, or long-running tasks taking up valuable resources. Since many of our useful tasks involve interacting with third-party services, the techniques to manage these changes are useful both inside our application and for communicating outside of it. Having the ability to loosely couple different parts of the system using some asynchronous messages is useful to prevent blockages and unwanted dependency entanglements.</p>
    <p class="normal">In any case, the bottom line is that we need to interact with other services through the network, both synchronously and asynchronously. These interactions need to be efficient, and when something goes wrong, we need to have a plan.</p>
    <p class="normal">The other problem introduced by adding more network connections is <strong class="keyword">testing</strong>: how do we test a microservice in isolation that also needs to call other microservices to function? In this chapter, we will explore this in detail:</p>
    <ul>
      <li class="bullet">How one service can call another using synchronous and asynchronous libraries, and how to make these calls more efficient</li>
      <li class="bullet">How a service can use messages to make asynchronous calls and communicate with other services via events</li>
      <li class="bullet">We will also see some techniques to test services that have network dependencies</li>
    </ul>
    <h1 id="_idParaDest-99" class="title">Calling other web resources</h1>
    <p class="normal">As we have seen in the<a id="_idIndexMarker353"/> previous chapters, synchronous interactions between microservices can be done via HTTP APIs using JSON payloads. This is by far the pattern most often used, because both HTTP and JSON are common standards. If your web service implements an HTTP API that accepts JSON, any developer using any programming<a id="_idIndexMarker354"/> language will be able to use it. Most of these interfaces are also RESTful, meaning that they follow the <strong class="keyword">Representational State Transfer</strong> (<strong class="keyword">REST</strong>) architecture principles of being stateless—with each interaction containing all the information needed instead of relying on previous exchanges—as well as cacheable and having a well-defined interface.</p>
    <p class="normal">Following a RESTful scheme<a id="_idIndexMarker355"/> is not a requirement, however, and some projects implement <strong class="keyword">Remote Procedure Call</strong> (<strong class="keyword">RPC</strong>) APIs, which focus on the action being performed and abstract away the network requests from the code that handles the messages. In REST, the focus is on the resource, and actions are defined by HTTP methods. Some projects are a mix of both and don't strictly follow a given standard. The most important thing is that your service behavior should be consistent and well-documented. This book leans on REST rather than RPC, but is not strict about it, and recognizes that different situations have different solutions.</p>
    <p class="normal">Sending and receiving JSON payloads is the simplest way for a microservice to interact with others, and only requires microservices to know the entry points and parameters to pass using HTTP requests.</p>
    <p class="normal">To do this, you just need to use an HTTP client. Python has one as part of the <code class="Code-In-Text--PACKT-">http.client</code> module, and in a <a id="_idIndexMarker356"/>synchronous Python environment, the <code class="Code-In-Text--PACKT-">Requests</code> library is rightfully popular: <a href="https://docs.python-requests.org"><span class="url">https://docs.python-requests.org</span></a>.</p>
    <p class="normal">As we are in an asynchronous environment, we will use <code class="Code-In-Text--PACKT-">aiohttp</code>, which has a clean way of creating asynchronous web requests and offers built-in features that make it easier to perform multiple <a id="_idIndexMarker357"/>simultaneous asynchronous requests: <a href="https://docs.aiohttp.org/en/stable/"><span class="url">https://docs.aiohttp.org/en/stable/</span></a>.</p>
    <p class="normal">HTTP requests in the <code class="Code-In-Text--PACKT-">aiohttp</code> library are built around the concept of a session, and the best way to use it is to call <code class="Code-In-Text--PACKT-">CreateSession</code>, creating a <code class="Code-In-Text--PACKT-">Session</code> object that can be reused every time you interact with any service.</p>
    <p class="normal">A <code class="Code-In-Text--PACKT-">Session</code> object can hold authentication information and some default headers you may want to set for all requests that your application will make. It can also control default error handling behavior, storing cookies, and what timeouts to use. In the following example, the call to <code class="Code-In-Text--PACKT-">ClientSession</code> will create an object with the right <code class="Code-In-Text--PACKT-">Content-Type</code> headers:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># clientsession.py</span>
<span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">import</span> aiohttp
 
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">make_request</span>(<span class="hljs-params">url</span>):
    headers = {
        <span class="hljs-string">"Content-Type"</span>: <span class="hljs-string">"application/json"</span>,
    }
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession(headers=headers) <span class="hljs-keyword">as</span> session:
        <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> session.get(url) <span class="hljs-keyword">as</span> response:
            <span class="hljs-built_in">print</span>(<span class="hljs-keyword">await</span> response.text())
 
 
url = <span class="hljs-string">"http://localhost:5000/api"</span>
loop = asyncio.get_event_loop()
loop.run_until_complete(make_request(url))
</code></pre>
    <p class="normal">If we should limit <a id="_idIndexMarker358"/>how many concurrent requests are being made to an external endpoint, there are two main approaches. <code class="Code-In-Text--PACKT-">aiohttp</code> has a concept of connectors, and we can set options to control how many outgoing TCP connections a <code class="Code-In-Text--PACKT-">session</code> can operate at once, as well as limiting those numbers for a single destination:</p>
    <pre class="programlisting code"><code class="hljs-code">conn = aiohttp.TCPConnector(limit=<span class="hljs-number">300</span>, limit_per_host=<span class="hljs-number">10</span>)
session = aiohttp.ClientSession(connector=conn)
</code></pre>
    <p class="normal">This might be enough for our needs; however, if we make several outgoing connections to complete one request, we could end up in a situation where each piece of work is continuously blocking after each one as we reach the limit. Ideally, we would like a discrete chunk of work to continue until it's done, and for that we can use a semaphore. A semaphore is a simple token that gives code permission to perform a task. If we were to add a semaphore with three slots, then the first three tasks that try to access the semaphore will take a slot each and carry on. Any other task that requests the semaphore will have to wait until one of the slots is free. </p>
    <p class="normal">Since the most common way to request a semaphore is inside a <code class="Code-In-Text--PACKT-">with</code> block, this means that as soon as the context of the <code class="Code-In-Text--PACKT-">with</code> block is over, the semaphore is released—inside the semaphore object's <code class="Code-In-Text--PACKT-">__exit__</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># clientsession_list.py</span>
<span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">import</span> aiohttp
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">make_request</span>(<span class="hljs-params">url, session, semaphore</span>):
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> semaphore, session.get(url) <span class="hljs-keyword">as</span> response:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Fetching </span><span class="hljs-subst">{url}</span><span class="hljs-string">"</span>)
        <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)  <span class="hljs-comment"># Pretend there is real work happening</span>
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> response.text()
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">organise_requests</span>(<span class="hljs-params">url_list</span>):
    semaphore = asyncio.Semaphore(<span class="hljs-number">3</span>)
    tasks = <span class="hljs-built_in">list</span>()
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession() <span class="hljs-keyword">as</span> session:
        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> url_list:
            tasks.append(make_request(url, session, semaphore))
        <span class="hljs-keyword">await</span> asyncio.gather(*tasks)
 
urls = [
    <span class="hljs-string">"https://www.google.com"</span>,
    <span class="hljs-string">"https://developer.mozilla.org/en-US/"</span>,
    <span class="hljs-string">"https://www.packtpub.com/"</span>,
    <span class="hljs-string">"https://aws.amazon.com/"</span>,
]
loop = asyncio.get_event_loop()
loop.run_until_complete(organise_requests(urls))
</code></pre>
    <p class="normal">Let us now see how we can generalize this pattern in a Quart app that needs to interact with other services.</p>
    <p class="normal">This naive<a id="_idIndexMarker359"/> implementation is based on the hypothesis that everything will go smoothly, but real life is rarely so easy. We can set up different error handling options in a <code class="Code-In-Text--PACKT-">ClientSession</code>, such as retries and timeouts, and we only need to set them up in that one place.</p>
    <h1 id="_idParaDest-100" class="title">Finding out where to go</h1>
    <p class="normal">When we make a web <a id="_idIndexMarker360"/>request to a service, we need to know which <strong class="keyword">Uniform Resource Locator</strong> (<strong class="keyword">URL</strong>) to use. Most of the examples in this book use <a id="_idIndexMarker361"/>hardcoded URLs—that is, they are written into the source code. This is nice and easy to read for an example, but can be a problem when maintaining software. What happens when a service gets a new URI, and its hostname or IP address changes? It might move between AWS regions due to a failure or be migrated from Google Cloud Platform to Microsoft Azure. An API update can make the path to a resource change, even if the hostname or IP address has not updated.</p>
    <p class="normal">We want to pass in data<a id="_idIndexMarker362"/> about which URLs to use as configuration to our application. There are several options to manage more configuration options without adding them directly to the code, such as environment variables and service discovery.</p>
    <h2 id="_idParaDest-101" class="title">Environment variables</h2>
    <p class="normal">Container-based<a id="_idIndexMarker363"/> environments are common these days, and we will discuss them in more detail in <em class="chapterRef">Chapter 10</em>, <em class="italic">Deploying on AWS</em>. The most common approach to get configuration options into a container is to pass the container some environment variables. This has the advantage of being straightforward, since the code just needs to examine the environment when processing its configuration:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">def</span> <span class="hljs-title">create_app</span>(<span class="hljs-params">name=__name__, blueprints=</span><span class="hljs-literal">None</span><span class="hljs-params">, settings=</span><span class="hljs-literal">None</span>):
    app = Quart(name)
    app.config[<span class="hljs-string">"REMOTE_URL"</span>] = os.environ.get(<span class="hljs-string">"OTHER_SERVICE_URL"</span>, <span class="hljs-string">"https://default.url/here"</span>)
</code></pre>
    <p class="normal">The downside to this approach is that if the URL changes, then we need to restart the application—and sometimes redeploy it—with the new environment. If you don't expect the configuration to change very often, environment variables are still a good idea due to their simplicity, although we must be careful to not record any secrets that are in environment variables when we log messages.</p>
    <h2 id="_idParaDest-102" class="title">Service discovery</h2>
    <p class="normal">But what if we did not <a id="_idIndexMarker364"/>need to tell our service about all its options when we deploy it? Service discovery is an approach that involves configuring an application with just a few pieces of information: where to ask for configuration and how to identify the right questions to ask.</p>
    <p class="normal">Services such as <code class="Code-In-Text--PACKT-">etcd</code> (<a href="https://etcd.io/"><span class="url">https://etcd.io/</span></a>) provide a <a id="_idIndexMarker365"/>reliable key-value store in which to keep this configuration data. For example, let's use <code class="Code-In-Text--PACKT-">etcd</code> to store the URL of the production and development RabbitMQ instances:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>etcdctl put myservice/production/rabbitmq/url https://my.rabbitmq.url/
OK
<span class="hljs-con-meta">$ </span>etcdctl get myservice/production/rabbitmq/url
myservice/production/rabbitmq/url
https://my.rabbitmq.url/
</code></pre>
    <p class="normal">When an application starts up, it can check to see whether it is running in production or in a local development environment and ask <code class="Code-In-Text--PACKT-">etcd</code> for the right value—either <code class="Code-In-Text--PACKT-">myservice/production/rabbitmq/url</code> or <code class="Code-In-Text--PACKT-">myservice/development/rabbitmq/url</code>. With a single option in a deployment, it is possible to change a whole number of configuration options, use different external URLs, bind to different ports, or any other piece of configuration you might think of.</p>
    <p class="normal">It's also possible to <a id="_idIndexMarker366"/>update the values in <code class="Code-In-Text--PACKT-">etcd</code>, and when your application next checks for a new value, it will update and use that instead. Deploying a new version of <code class="Code-In-Text--PACKT-">RabbitMQ</code> can now be done alongside the old version, and the swap will be a value change in <code class="Code-In-Text--PACKT-">etcd</code>—or a change back if it goes wrong.</p>
    <p class="normal">This approach does add complexity, both as an extra service to run and in terms of updating these values within your application, but it can be a valuable approach in more dynamic environments. We will discuss service discovery more in <em class="chapterRef">Chapter 10</em>, <em class="italic">Deploying on AWS</em>, when we cover deploying an application on containers and in the cloud.</p>
    <h1 id="_idParaDest-103" class="title">Transferring data</h1>
    <p class="normal">JSON is a<a id="_idIndexMarker367"/> human-readable data format. There is a long history of human-readable data transfer on the internet—a good example would be email, as you can quite happily type out the protocol needed to send an email as a human author. This readability is useful for determining exactly what is happening in your code and its connections, especially as JSON maps directly onto Python data structures.</p>
    <p class="normal">The downside to this <a id="_idIndexMarker368"/>readability is the size of the data. Sending HTTP requests and responses with JSON payloads can add some bandwidth overhead in the long run, and serializing and deserializing data from Python objects to JSON structures also adds a bit of CPU overhead.</p>
    <p class="normal">There are other ways to transfer data that involve caching, compression, binary payloads, or RPC, however.</p>
    <h2 id="_idParaDest-104" class="title">HTTP cache headers</h2>
    <p class="normal">In the HTTP <a id="_idIndexMarker369"/>protocol, there are a few cache mechanisms that can be used to indicate to a client that a page that it's trying to fetch has not changed since its last visit. Caching is something we can do in our microservices on all the read-only API endpoints, such as <code class="Code-In-Text--PACKT-">GETs</code> and <code class="Code-In-Text--PACKT-">HEADs</code>.</p>
    <p class="normal">The simplest way to implement it is to return, along with a result, an ETag header in the response. An <code class="Code-In-Text--PACKT-">ETag</code> value is a string that can be considered as a version for the resource the client is trying to get. It can be a timestamp, an incremental version, or a hash. It's up to the server to decide what to put in it, but the idea is that it should be unique to the value of the response.</p>
    <p class="normal">Like web browsers, when the client fetches a response that contains such a header, it can build a local dictionary cache that stores the response bodies and <code class="Code-In-Text--PACKT-">ETags</code> as its values, and the URLs as its keys.</p>
    <p class="normal">When making a new request, the client can look in its local cache and pass along a stored <code class="Code-In-Text--PACKT-">ETag</code> value in the <code class="Code-In-Text--PACKT-">If-Modified-Since</code> header. If the server sends back a <code class="Code-In-Text--PACKT-">304</code> status code, it means that the response has not changed, and the client can use the previously stored one.</p>
    <p class="normal">This mechanism can greatly reduce the response times from the server, since it can immediately return an empty <code class="Code-In-Text--PACKT-">304</code> response when the content has not changed. If it has changed, the client gets the full message in the usual way.</p>
    <p class="normal">Of course, this means the services that you are calling should implement this caching behavior by adding the proper <code class="Code-In-Text--PACKT-">ETag</code> support. It's not possible to implement a generic solution for this because the cache logic depends on the nature of the data your service is managing. The rule of thumb is to version each resource and change that version every time the data changes. In the following example, the Quart app uses the current server time to create <code class="Code-In-Text--PACKT-">ETag</code> values associated with users' entries. The <code class="Code-In-Text--PACKT-">ETag</code> value is the current time since the epoch, in milliseconds, and is stored in the modified field.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">get_user()</code> method returns a user entry from <code class="Code-In-Text--PACKT-">_USERS</code> and sets the <code class="Code-In-Text--PACKT-">ETag</code> value with <code class="Code-In-Text--PACKT-">response.set_etag</code>. When the view gets some calls, it also looks for the <code class="Code-In-Text--PACKT-">If-None-Match</code> header to compare it to the user's modified field, and returns a <code class="Code-In-Text--PACKT-">304</code> response if it matches:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># quart_etag.py</span>
<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime
<span class="hljs-keyword">from</span> quart <span class="hljs-keyword">import</span> Quart, Response, abort, jsonify, request
app = Quart(__name__)
<span class="hljs-keyword">def</span> <span class="hljs-title">_time2etag</span>():
    <span class="hljs-keyword">return</span> datetime.now().isoformat()
_USERS = {<span class="hljs-string">"1"</span>: {<span class="hljs-string">"name"</span>: <span class="hljs-string">"Simon"</span>, <span class="hljs-string">"modified"</span>: _time2etag()}}
<span class="hljs-meta">@app.route(</span><span class="hljs-string">"/api/user/&lt;user_id&gt;"</span><span class="hljs-meta">)</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">get_user</span>(<span class="hljs-params">user_id</span>):
    <span class="hljs-keyword">if</span> user_id <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> _USERS:
        <span class="hljs-keyword">return</span> abort(<span class="hljs-number">404</span>)
    user = _USERS[user_id]
    <span class="hljs-comment"># returning 304 if If-None-Match matches</span>
    <span class="hljs-keyword">if</span> user[<span class="hljs-string">"modified"</span>] <span class="hljs-keyword">in</span> request.if_none_match:
        <span class="hljs-keyword">return</span> Response(<span class="hljs-string">"Not modified"</span>, status=<span class="hljs-number">304</span>)
    resp = jsonify(user)
    <span class="hljs-comment"># setting the ETag</span>
    resp.set_etag(user[<span class="hljs-string">"modified"</span>])
    <span class="hljs-keyword">return</span> resp
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    app.run()
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">change_user()</code> view sets a<a id="_idIndexMarker370"/> new modified value when the client modifies a user. In the following client session, we're changing the user, while also making sure that we get a <code class="Code-In-Text--PACKT-">304</code> response when providing the new <code class="Code-In-Text--PACKT-">ETag</code> value:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>curl -v http://127.0.0.1:5000/api/user/1
*   Trying 127.0.0.1...
...
&lt; HTTP/1.1 200
&lt; content-type: application/json
&lt; content-length: 56
&lt; etag: "2021-06-29T21:32:25.685907"
&lt; date: Tue, 29 Jun 2021 20:32:30 GMT
&lt; server: hypercorn-h11
&lt;
* Connection #0 to host 127.0.0.1 left intact
{"modified":"2021-06-29T21:32:25.685907","name":"Simon"}
<span class="hljs-con-meta"> $ </span>curl -v -H 'If-None-Match: 2021-06-29T21:32:25.685907' http://127.0.0.1:5000/api/user/1
...
&lt; HTTP/1.1 304
...
</code></pre>
    <p class="normal">This demonstration is a toy implementation that might not work well in production; relying on a server<a id="_idIndexMarker371"/> clock to store <code class="Code-In-Text--PACKT-">ETag</code> values means you are sure that the clock is never set back in time and that if you have several servers, their clocks are all synchronized with a service, such as ntpdate.</p>
    <p class="normal">There is also the problem of race conditions if two requests change the same entry within the same millisecond. Depending on your app, it may not be an issue, but then again if it is, then it may be a big one. A cleaner option is to have the modified field handled by your database system directly, and make sure its changes are done in serialized transactions. Sending the <code class="Code-In-Text--PACKT-">ETag</code> with a <code class="Code-In-Text--PACKT-">POST</code> request is also a good precaution against a race between concurrent updates—the server can use the <code class="Code-In-Text--PACKT-">ETag</code> to verify what version of the data the client wants to update from, and if that version doesn't match, it is probably unsafe to update the data, as someone else has changed it first.</p>
    <p class="normal">Some developers use hash functions for their <code class="Code-In-Text--PACKT-">ETag</code> value because it's easy to compute in a distributed architecture, and it doesn't introduce any of the problems timestamps have. But calculating a hash has a CPU cost, and it means you need to pull the whole entry to do it—so it might be as slow as if you were sending back the actual data. That said, with a dedicated table in your database for all your hashes, you can probably come up with a solution that makes your <code class="Code-In-Text--PACKT-">304</code> response fast in its return.</p>
    <p class="normal">As we said earlier, there is no generic solution to implement an efficient HTTP cache logic—but it's worth implementing one if your client is doing a lot of reads on your service. When you have no choice but to send some data back, there are several ways to make it as efficient as possible, as we will see in the next section.</p>
    <h2 id="_idParaDest-105" class="title">GZIP compression</h2>
    <p class="normal">Compression is <a id="_idIndexMarker372"/>an overarching term for reducing the size of data in such a way that the original data can be recovered. There are many different compression algorithms—some of them are general-purpose algorithms that can be used on any sort of data, while some of them are specialized to particular data formats and achieve very good results due to them making assumptions about how the data is structured.</p>
    <p class="normal">There are trade-offs to make between the size of the compressed data, the speed of compression and decompression, and how widely implemented the compression algorithm is. It might be acceptable to spend a few minutes compressing a large data file if it spends most of its time being stored, as the space savings outweigh the access time taken, but for data that is short-lived or regularly accessed, then the overhead of compression and decompression is more important. For our purposes, we need a compression algorithm that is widely understood by different environments, even if it doesn't always achieve<a id="_idIndexMarker373"/> the smallest end result.</p>
    <p class="normal">GZIP compression is available on almost every single system, and web servers such as Apache or nginx provide native support to compress responses that pass through them—which is far better than implementing your own ad hoc compression at the level of Python. It's important to remember that while this will save network bandwidth, it will use more CPU, and so experimenting with metrics collection activated will let us see the results—and decide whether this option is a good idea.</p>
    <p class="normal">For example, this nginx configuration will enable GZIP compression for any response produced by the Quart app on port <code class="Code-In-Text--PACKT-">5000</code>, with an <code class="Code-In-Text--PACKT-">application/json</code> content type:</p>
    <pre class="programlisting code"><code class="hljs-code">http { 
    gzip  on; 
    gzip_types application/json; 
    gzip_proxied      any; 
    gzip_vary on; 
    server { 
        listen       80; 
        server_name  localhost; 
        
        location / {  
            proxy_pass http://localhost:5000; 
        } 
    } 
</code></pre>
    <p class="normal">From the client side, making an HTTP request to the nginx server at <code class="Code-In-Text--PACKT-">localhost:8080</code>, proxying for the application at <code class="Code-In-Text--PACKT-">localhost:5000</code> with an <code class="Code-In-Text--PACKT-">Accept-Encoding: gzip</code> header, will trigger the compression:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$</span> curl http://localhost:8080/api -H "Accept-Encoding: gzip" 
&lt;some binary output&gt; 
</code></pre>
    <p class="normal">In Python, requests made using the <code class="Code-In-Text--PACKT-">aiohttp</code> and <code class="Code-In-Text--PACKT-">requests</code> libraries will automatically decompress responses that are GZIP-encoded, so you don't have to worry about doing this when your service is calling another service. </p>
    <p class="normal">Decompressing the data adds some processing, but Python's GZIP module relies on <code class="Code-In-Text--PACKT-">zlib</code> (<code class="Code-In-Text--PACKT-">http://www.zlib.net/</code>), which is very fast. To accept<a id="_idIndexMarker374"/> compressed responses to HTTP queries, we just need to add a header indicating we can deal with a GZIP-encoded response:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">import</span> aiohttp
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">make_request</span>():
    url = <span class="hljs-string">"http://127.0.0.1:5000/api"</span>
    headers = {
        <span class="hljs-string">"Accept-Encoding"</span>: <span class="hljs-string">"gzip"</span>,
    }
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession(headers=headers) <span class="hljs-keyword">as</span> session:
        <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> session.get(url) <span class="hljs-keyword">as</span> response:
            <span class="hljs-built_in">print</span>(<span class="hljs-keyword">await</span> response.text())
loop = asyncio.get_event_loop()
loop.run_until_complete(make_request())
</code></pre>
    <p class="normal">To compress the data that you are sending to the server, you can use the <code class="Code-In-Text--PACKT-">gzip</code> module and specify a <code class="Code-In-Text--PACKT-">Content-Encoding</code> header:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">import</span> gzip
<span class="hljs-keyword">import</span> json
<span class="hljs-keyword">import</span> aiohttp
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">make_request</span>():
    url = <span class="hljs-string">"http://127.0.0.1:8080/api_post"</span>
    headers = {
        <span class="hljs-string">"Content-Encoding"</span>: <span class="hljs-string">"gzip"</span>,
    }
    data = {<span class="hljs-string">"Hello"</span>: <span class="hljs-string">"World!"</span>, <span class="hljs-string">"result"</span>: <span class="hljs-string">"OK"</span>}
    data = <span class="hljs-built_in">bytes</span>(json.dumps(data), <span class="hljs-string">"utf8"</span>)
    data = gzip.compress(data)
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession(headers=headers) <span class="hljs-keyword">as</span> session:
        <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> session.post(url, data=data) <span class="hljs-keyword">as</span> response:
            <span class="hljs-built_in">print</span>(<span class="hljs-keyword">await</span> response.text())
loop = asyncio.get_event_loop()
loop.run_until_complete(make_request())
</code></pre>
    <p class="normal">In that case, however, you will get the zipped content in your Quart application, and you will need to decompress it in your Python code, or if you are using an nginx proxy that handles incoming <a id="_idIndexMarker375"/>web connections, nginx can decompress the requests for you. We discuss nginx in more detail in <em class="chapterRef">Chapter 10</em>, <em class="italic">Deploying on AWS</em>. To summarize, setting up GZIP compression for all your service responses is a low-effort change with nginx, and your Python client can benefit from it by setting the right header. Sending compressed data is a little more complicated however, because the work isn't done for you—but it may still have benefits for large data transfers.</p>
    <p class="normal">If you want to further reduce the size of HTTP request/response payloads, another option is to switch from JSON to binary payloads. That way, you do not have to deal with compression, and processing the data may be faster, but the message size reduction is not as good.</p>
    <h2 id="_idParaDest-106" class="title">Protocol Buffers</h2>
    <p class="normal">While it is usually <a id="_idIndexMarker376"/>not relevant, if your microservice deals with a lot of data, using an alternative format can be an attractive option to increase performance, and decrease the required network bandwidth without having to use extra processing power and time compressing and decompressing the data. Two widely used binary <a id="_idIndexMarker377"/>formats are <strong class="keyword">Protocol Buffers</strong> (<strong class="keyword">protobuf</strong>) (<a href="https://developers.google.com/protocol-buffers"><span class="url">https://developers.google.com/protocol-buffers</span></a>) and <strong class="keyword">MessagePack</strong>.</p>
    <p class="normal">Protocol Buffers requires you to describe data that's being exchanged into some schema that will be used to index the binary content. The schemas add some work because all data that is transferred will <a id="_idIndexMarker378"/>need to be described in a schema, and you will need to learn a new <strong class="keyword">Domain-Specific Language</strong> (<strong class="keyword">DSL</strong>). In a typed language, such as Rust, C++, or Go, defining these structures is something that already has to be done, so the overhead is far less.</p>
    <p class="normal">However, the advantages are that the messages are well defined and can be easily validated before either end of the network conversation attempts to use the information. It is also possible to generate code for various languages—including Python—that let you construct the data in a way that is more suitable for the language being used. The following example is taken from the protobuf documentation:</p>
    <pre class="programlisting code"><code class="hljs-code">syntax = "proto2";
package tutorial; 
message Person { 
  required string name = 1; 
  required int32 id = 2; 
  optional string email = 3; 
  enum PhoneType { 
    MOBILE = 0; 
    HOME = 1; 
    WORK = 2; 
  } 
  message PhoneNumber { 
    required string number = 1; 
    optional PhoneType type = 2 [default = HOME]; 
  } 
  repeated PhoneNumber phones = 4; 
} 
message AddressBook { 
  repeated Person people = 1; 
} 
</code></pre>
    <p class="normal">The schema is not very<a id="_idIndexMarker379"/> Pythonic, as it is intended to support multiple languages and environments. If you interact with statically typed languages or would like a feature to do basic syntax checking on data for you, then a definition like this may be helpful.</p>
    <p class="normal">Using<a id="_idIndexMarker380"/> Protocol Buffers with a framework such as gRPC (<a href="https://grpc.io/"><span class="url">https://grpc.io/</span></a>) can abstract away the network interaction from your application, and instead provide a client with a function call in Python and little need to consider how it generates its return value.</p>
    <h2 id="_idParaDest-107" class="title">MessagePack</h2>
    <p class="normal">Unlike Protocol <a id="_idIndexMarker381"/>Buffers, MessagePack (<a href="http://msgpack.org/"><span class="url">http://msgpack.org/</span></a>) is schemaless, and <a id="_idIndexMarker382"/>can serialize your data by just calling a function. It's a simple alternative to JSON, and has implementations in most languages. The <code class="Code-In-Text--PACKT-">msgpack</code> Python library (installed using the <code class="Code-In-Text--PACKT-">pip install</code> <code class="Code-In-Text--PACKT-">msgpack-python</code> command) offers the same level of integration as JSON:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">import</span> msgpack
<span class="hljs-con-meta">&gt;&gt;&gt;</span> data = {<span class="hljs-con-string">"this"</span>: <span class="hljs-con-string">"is"</span>, <span class="hljs-con-string">"some"</span>: <span class="hljs-con-string">"data"</span>}
<span class="hljs-con-meta">&gt;</span><span class="hljs-con-meta">&gt;&gt;</span> msgpack.packb(data, use_bin_type=<span class="hljs-con-literal">True</span>)
b'\x82\xa4this\xa2is\xa4some\xa4data'
<span class="hljs-con-meta">&gt;&gt;&gt;</span> msgpack.unpackb(msgpack.packb(data, use_bin_type=<span class="hljs-con-literal">True</span>))
{'this': 'is', 'some': 'data'}
</code></pre>
    <p class="normal">Using MessagePack is simple compared to protobuf, but which one is faster and provides the best compression ratio depends a lot on your data. In some rare cases, plain JSON might be even quicker to serialize than a binary format.</p>
    <p class="normal">In terms of compression, you can expect 10% to 20% compression with MessagePack, but if your JSON contains a lot of strings—which is often the case in microservices—GZIP will perform much better.</p>
    <p class="normal">In the following <a id="_idIndexMarker383"/>example, a huge JSON payload of 48 KB that contains a lot of strings is converted using MessagePack and JSON and then GZIPped in both cases:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> sys.getsizeof(json.dumps(data))
35602
<span class="hljs-con-meta">&gt;&gt;&gt;</span> sys.getsizeof(msgpack.packb(data))
30777
<span class="hljs-con-meta">&gt;&gt;&gt;</span> sys.getsizeof(gzip.compress(<span class="hljs-con-built_in">bytes</span>(json.dumps(data), <span class="hljs-con-string">'utf8'</span>)))
3138
<span class="hljs-con-meta">&gt;&gt;&gt;</span> sys.getsizeof(gzip.compress(msgpack.packb(data)))
3174
</code></pre>
    <p class="normal">Using MessagePack reduces the size of the payload by approximately 14%, but GZIP is making it 11 times smaller with both JSON and MessagePack payloads!</p>
    <p class="normal">It's clear that whatever format you are using, the best way to reduce the payload sizes is to use GZIP—and if your web server does not deal with decompression, it's straightforward in Python thanks to <code class="Code-In-Text--PACKT-">gzip.uncompress()</code>.</p>
    <p class="normal">Message serialization often only supports basic data types, as they must remain unaware of what environment is running in both the source and destination. This means that they cannot encode data that might be commonly used in Python, such as <code class="Code-In-Text--PACKT-">datetime</code> objects to represent time. While other languages have date and time representation, it is not done in the same way, and so data like this and other Python objects need to be converted into a <a id="_idIndexMarker384"/>serializable form that other platforms can understand. For date and time, common options include an integer representing epoch time (the number of seconds since 1<sup class="Superscript--PACKT-">st</sup> January 1970) or a string in ISO8601 format, such as 2021-03-01T13:31:03+00:00.</p>
    <p class="normal">In any case, in a world of microservices where JSON is the most accepted standard, taking care of dates is a minor annoyance to stick with a universally adopted standard.</p>
    <p class="normal">Unless all your services are in Python with well-defined structures, and you need to speed up the serialization steps as much as possible, it is probably simpler to stick with JSON.</p>
    <h2 id="_idParaDest-108" class="title">Putting it together</h2>
    <p class="normal">Before moving on, we will quickly recall what we have covered so far:</p>
    <ul>
      <li class="bullet">Implementing HTTP cache headers is a great way to speed up repeated requests for data</li>
      <li class="bullet">GZIP compression is an efficient way to lessen the size of requests and responses and is easy to set up</li>
      <li class="bullet">Binary protocols are an attractive alternative to plain JSON, but it does depend on the situation</li>
    </ul>
    <p class="normal">The next section will focus on asynchronous calls; everything your microservice can do that goes beyond the request/response pattern.</p>
    <h1 id="_idParaDest-109" class="title">Asynchronous messages</h1>
    <p class="normal">In microservice<a id="_idIndexMarker385"/> architecture, asynchronous calls play a fundamental role when a process that is used to be performed in a single application now implicates several microservices. We touched briefly on this in the previous chapter with our change to the Jeeves application, which now communicates with its workers using an asynchronous message queue. To make the best use of these, we will investigate these tools in more depth.</p>
    <p class="normal">Asynchronous calls can be as simple as a separate thread or process within a microservice app that is receiving some work to be done, and performs it without interfering with the HTTP request/response round trips that are happening at the same time.</p>
    <p class="normal">But doing everything directly from the same Python process is not very robust. What happens if the process crashes and gets restarted? How do we scale background tasks if they are built like that?</p>
    <p class="normal">It's much more reliable to send a message that gets picked by another program, and let the microservice focus on its primary goal, which is to serve responses to clients. If a web request does not need an immediate answer, an endpoint in our service can then become code that <a id="_idIndexMarker386"/>accepts an HTTP request, processes it, and passes it on, and its response to the client is now whether or not our service has successfully received the request rather than whether the request has been processed.</p>
    <p class="normal">In the previous chapter, we looked at how Celery could be used to build a microservice that gets some work from a message broker like RabbitMQ. In that design, the Celery worker blocks—that is, it halts operation while it is waiting—until a new message is added to the RabbitMQ queue.</p>
    <h2 id="_idParaDest-110" class="title">Message queue reliability</h2>
    <p class="normal">As with any<a id="_idIndexMarker387"/> distributed system, there are considerations with regard to reliability and consistency. Ideally, we would like to add a message to the queue and have it delivered—and acted upon—exactly once. In practice this is almost impossible to achieve in a distributed system, as components fail, experiencing high latency or packet loss, while all sorts of complex interactions occur.</p>
    <p class="normal">We have two real choices, encoded in RabbitMQ's delivery strategies: "at-most-once" and "at-least-once."</p>
    <p class="normal">A strategy to deliver a message at most once will not account for any unreliability in the message delivery system or failures in a worker. Once a worker has accepted the message, that is it: the message queue forgets about it. If the worker then suffers a failure and does not complete the chunk of work it has been given, that is something the wider system needs to cope with.</p>
    <p class="normal">With a promise to deliver a message at least once, in the case of any failures the deliveries will be attempted again until a worker both accepts the message and acknowledges that it has acted upon it. This ensures that no data is lost, but it does mean that there are situations where the message can be delivered to more than one worker, and so some<a id="_idIndexMarker388"/> sort of <strong class="keyword">universally unique identifier</strong> (<strong class="keyword">UUID</strong>) is a good idea, so that while some work may be duplicated, it can be deduplicated when it is written to any database or storage. A wider discussion of distributed system<a id="_idIndexMarker389"/> reliability and consensus protocols like PAXOS would require a book of its own.</p>
    <h2 id="_idParaDest-111" class="title">Basic queues</h2>
    <p class="normal">The pattern used by Celery workers is<a id="_idIndexMarker390"/> a push-pull tasks queue. One service pushes messages into a specific queue, and some workers pick them up from the other end and perform an action on them. Each task goes to a single worker. Consider the following diagram, shown in <em class="italic">Figure 6.1</em>.</p>
    <figure class="mediaobject"><img src="../Images/B17108_06_01.png" alt="image2.jpg"/></figure>
    <p class="packt_figref">Figure 6.1: Tasks passing through a message queue</p>
    <p class="normal">There is no bidirectional communication—the sender merely deposits a message in the queue and leaves. The next available worker gets the next message. This blind, unidirectional message passing is perfect when you want to perform some asynchronous parallel tasks, which makes it easy to scale.</p>
    <p class="normal">In addition, once the sender has confirmed that the message was added to the broker, we can have message brokers—such as RabbitMQ—offer some message persistence. In other words, if all workers go offline, we don't lose the messages that are in the queue.</p>
    <h2 id="_idParaDest-112" class="title">Topic exchanges and queues</h2>
    <p class="normal">Topics are a way<a id="_idIndexMarker391"/> of filtering and classifying messages that travel through the queue. When using topics, each message is sent with an extra label that helps to identify what sort of message it is, and our workers can subscribe to specific topics, or patterns that match several topics.</p>
    <p class="normal">Let's imagine a <a id="_idIndexMarker392"/>scenario where we are releasing a mobile app to the Android Play Store and the Apple App Store. When our automation tasks finish building the Android app, we can send a message with a routing key of <code class="Code-In-Text--PACKT-">publish.playstore</code>, so that RabbitMQ can route this message to the right topics. The reason that there is a difference between a routing key and a topic is that a topic can match a pattern. The worker that is capable of publishing files to the Play Store can subscribe to the topic <code class="Code-In-Text--PACKT-">publish.playstore</code> and get its workload from those messages, but we could also have a queue for messages matching <code class="Code-In-Text--PACKT-">publish.*</code> and a worker that sends notifications whenever something is about to be uploaded to the Play Store, the App Store, or any other place you might publish software.</p>
    <p class="normal">In our microservices, this means we can have specialized workers that all register to the same messaging broker and get a subset of the messages that are added to it.</p>
    <figure class="mediaobject"><img src="../Images/B17108_06_02.png" alt="image1.jpg"/></figure>
    <p class="packt_figref">Figure 6.2: Tasks of different types passing through a message queue</p>
    <p class="normal">This sort of behavior exists in most message queue services, in slightly different forms. Let's look at how to set this up in RabbitMQ.</p>
    <p class="normal">To install a <strong class="keyword"><a id="_idIndexMarker393"/></strong><strong class="keyword">RabbitMQ</strong> broker, you can look at the download page at <a href="http://www.rabbitmq.com/download.html"><span class="url">http://www.rabbitmq.com/download.html</span></a>.</p>
    <p class="normal">Running the<a id="_idIndexMarker394"/> container should be enough for any local experiments. RabbitMQ implements the <strong class="keyword">Advanced Message Queuing Protocol</strong> (<strong class="keyword">AMQP</strong>). This protocol, described at <a href="http://www.amqp.org/"><span class="url">http://www.amqp.org/</span></a>, is a <a id="_idIndexMarker395"/>complete standard that has been developed for years by a group of companies working together.</p>
    <p class="normal">AMQP is organized<a id="_idIndexMarker396"/> into three concepts: queues, exchanges, and bindings:</p>
    <ul>
      <li class="bullet">A queue is a recipient that holds messages and waits for consumers to pick them</li>
      <li class="bullet">An exchange is an entry point for publishers to add new messages to the system</li>
      <li class="bullet">A binding defines how messages are routed from exchanges to queues</li>
    </ul>
    <p class="normal">For our topic queue, we need to set one exchange, so RabbitMQ accepts new messages, and all the queues we want for workers to pick messages. Between those two ends, we want to route the messages to the different queues, depending on the topics, using a binding.</p>
    <p class="normal">Let's look at how we would set up our app publishing example from earlier. We will assume we have two workers: one that publishes Android applications, and the other that sends notifications, such as updating a website or sending an email. Using the <code class="Code-In-Text--PACKT-">rabbitmqadmin</code> command line that gets installed with RabbitMQ, we can create all the necessary parts. If the admin command does not come installed, you can find instructions on installing it at <a href="https://www.rabbitmq.com/management-cli.html"><span class="url">https://www.rabbitmq.com/management-cli.html</span></a>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>rabbitmqadmin <span class="hljs-con-built_in">declare</span> exchange name=incoming <span class="hljs-con-built_in">type</span>=topic 
exchange declared 
<span class="hljs-con-meta"> </span>
<span class="hljs-con-meta">$ </span>rabbitmqadmin <span class="hljs-con-built_in">declare</span> queue name=playstore 
queue declared 
<span class="hljs-con-meta"> </span>
<span class="hljs-con-meta">$ </span>rabbitmqadmin <span class="hljs-con-built_in">declare</span> queue name=notifications
queue declared 
<span class="hljs-con-meta"> </span>
<span class="hljs-con-meta">$ </span>rabbitmqadmin <span class="hljs-con-built_in">declare</span> binding <span class="hljs-con-built_in">source</span>=<span class="hljs-con-string">"incoming"</span> destination_type=<span class="hljs-con-string">"queue"</span> destination=<span class="hljs-con-string">"playstore"</span> routing_key=<span class="hljs-con-string">"publish.playstore"</span> 
binding declared 
<span class="hljs-con-meta"> </span>
<span class="hljs-con-meta">$ </span>rabbitmqadmin <span class="hljs-con-built_in">declare</span> binding <span class="hljs-con-built_in">source</span>=<span class="hljs-con-string">"incoming"</span> destination_type=<span class="hljs-con-string">"queue"</span> destination=<span class="hljs-con-string">"notifications"</span> routing_key=<span class="hljs-con-string">"publish.*"</span> 
binding declared 
</code></pre>
    <p class="normal">In this setup, whenever a message is sent to RabbitMQ—and if the topic starts with <code class="Code-In-Text--PACKT-">publish</code>—it will be sent to the notifications queue; and if it is <code class="Code-In-Text--PACKT-">publish.playstore</code>, then it will end up in both the notifications and playstore queues. Any other topics will cause the message to<a id="_idIndexMarker397"/> be discarded.</p>
    <p class="normal">To interact with<a id="_idIndexMarker398"/> RabbitMQ in the code, we can use <strong class="keyword">Pika</strong>. This is a Python RPC client that implements all the RPC endpoints that a Rabbit service <a id="_idIndexMarker399"/>publishes: <a href="https://pika.readthedocs.io"><span class="url">https://pika.readthedocs.io</span></a>.</p>
    <p class="normal">Everything we do with Pika can be done on the command line using <code class="Code-In-Text--PACKT-">rabbitmqadmin</code>. You can directly get the status of all parts of the system, send and receive messages, and check what's in a queue. It is an excellent way to experiment with your messaging setup.</p>
    <p class="normal">The following script shows how to publish two messages in RabbitMQ in the incoming exchange. One concerns a new app being published, and the other is about a newsletter:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> pika <span class="hljs-keyword">import</span> BlockingConnection, BasicProperties
<span class="hljs-comment"># assuming there's a working local RabbitMQ server with a working # guest/guest account</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">message</span>(<span class="hljs-params">topic, message</span>):
    connection = BlockingConnection()
    <span class="hljs-keyword">try</span>:
        channel = connection.channel()
        props = BasicProperties(content_type=<span class="hljs-string">"text/plain"</span>, delivery_mode=<span class="hljs-number">1</span>)
        channel.basic_publish(<span class="hljs-string">"incoming"</span>, topic, message, props)
    <span class="hljs-keyword">finally</span>:
        connection.close()
message(<span class="hljs-string">"publish.playstore"</span>, <span class="hljs-string">"We are publishing an Android App!"</span>)
message(<span class="hljs-string">"publish.newsletter"</span>, <span class="hljs-string">"We are publishing a newsletter!"</span>)
</code></pre>
    <p class="normal">These RPC calls will each add one message to the incoming topic exchange. For the first message, the exchange will then add one message to the <code class="Code-In-Text--PACKT-">playstore</code> queue, and for the second, two messages will be added—one to each queue. A worker script that waits for work that needs to be published to the Play Store would look like this:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pika
<span class="hljs-keyword">def</span> <span class="hljs-title">on_message</span>(<span class="hljs-params">channel, method_frame, header_frame, body</span>):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Now publishing to the play store: </span><span class="hljs-subst">{body}</span><span class="hljs-string">!"</span>)
    channel.basic_ack(delivery_tag=method_frame.delivery_tag)
connection = pika.BlockingConnection()
channel = connection.channel()
channel.basic_consume(<span class="hljs-string">"playstore"</span>, on_message)
<span class="hljs-keyword">try</span>:
    channel.start_consuming()
<span class="hljs-keyword">except</span> KeyboardInterrupt:
    channel.stop_consuming()
connection.close()
</code></pre>
    <p class="normal">Notice that Pika sends <a id="_idIndexMarker400"/>back an ACK to RabbitMQ about the <a id="_idIndexMarker401"/>message, so it can be safely removed from the queue once the worker has succeeded. This is the at-least-once strategy approach to message delivery. The <code class="Code-In-Text--PACKT-">notifications</code> receiver can be identical apart from the queue it subscribes to and what it does with the message body:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>python ./playstore_receiver.py
Now publishing to the play store: b'We are publishing an Android App!'!
<span class="hljs-con-meta">$ </span>python ./publish_receiver.py
We have some news! b'We are publishing an Android App!'!
We have some news! b'We are publishing a newsletter!'!
</code></pre>
    <p class="normal">AMQP offers many patterns that you can investigate to exchange messages. The tutorial page has many examples, and they are all implemented using Python and Pika: <a href="http://www.rabbitmq.com/getstarted.html"><span class="url">http://www.rabbitmq.com/getstarted.html</span></a>.</p>
    <p class="normal">To integrate these examples in our microservices, the publisher phase is straightforward. Your Quart application can create a connection to RabbitMQ using <code class="Code-In-Text--PACKT-">pika.BlockingConnection</code> and send<a id="_idIndexMarker402"/> messages through it. Projects such as pika-pool (<a href="https://github.com/bninja/pika-pool"><span class="url">https://github.com/bninja/pika-pool</span></a>) implement simple connection pools so you can manage RabbitMQ channels without having to connect/disconnect every time you are sending something through RPC.</p>
    <p class="normal">The consumers, on the other hand, are trickier to integrate into microservices. Pika can be embedded into an event loop running in the same process as the Quart application, and trigger a function when a message is received. It will simply be another entry point into the same code, and could be run alongside a RESTful API if that's also required.</p>
    <h2 id="_idParaDest-113" class="title">Publish/subscribe</h2>
    <p class="normal">The previous pattern has workers that handle the specific topics of messages, and the messages consumed by a worker are completely gone from the queue. We even added code to<a id="_idIndexMarker403"/> acknowledge that the message was consumed. </p>
    <p class="normal">When you want a message to be published to several<a id="_idIndexMarker404"/> workers, however, the <strong class="keyword">Publish/Subscribe</strong> (<strong class="keyword">pubsub</strong>) pattern needs to be used.</p>
    <p class="normal">This pattern is the basis for building a general event system and is implemented exactly like the previous one, in which there is one exchange and several queues. The difference is that the exchange part has a fanout type.</p>
    <p class="normal">In that setup, every queue that you bind to a fanout exchange will receive the same message. With pubsub in place, you can broadcast messages to all your microservices if necessary.</p>
    <h2 id="_idParaDest-114" class="title">Putting it together</h2>
    <p class="normal">In this section, we have<a id="_idIndexMarker405"/> covered the following about asynchronous messaging:</p>
    <ul>
      <li class="bullet">Non-blocking calls should be used every time a microservice can execute some work out of band. There's no good reason to block a request if what you are doing is not utilized in the response.</li>
      <li class="bullet">Service-to-service communication is not always limited to task queues.</li>
      <li class="bullet">Sending events through a message queue is a good way to prevent tightly coupled components.</li>
      <li class="bullet">We can build a full event system around a broker—such as RabbitMQ—to make our microservices interact with each other via messages.</li>
      <li class="bullet">RabbitMQ can be used to coordinate all the message passing, with messages sent using Pika.</li>
    </ul>
    <h1 id="_idParaDest-115" class="title">Testing</h1>
    <p class="normal">As we <a id="_idIndexMarker406"/>learned in <em class="chapterRef">Chapter 3</em>, <em class="italic">Coding, Testing, and Documentation: the Virtuous Cycle</em>, the biggest challenge when writing functional tests for a service that calls other services is to isolate all network calls. In this section, we'll see how we can mock asynchronous calls made using <code class="Code-In-Text--PACKT-">aiohttp</code>.</p>
    <p class="normal">Testing <code class="Code-In-Text--PACKT-">aiohttp</code> and its outgoing web requests involves a different approach to traditional synchronous tests. The <code class="Code-In-Text--PACKT-">aioresponses</code> project (<a href="https://github.com/pnuckowski/aioresponses"><span class="url">https://github.com/pnuckowski/aioresponses</span></a>) allows you to easily create mocked responses to web<a id="_idIndexMarker407"/> requests made using an <code class="Code-In-Text--PACKT-">aiohttp</code> <code class="Code-In-Text--PACKT-">ClientSession</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># test_aiohttp_fixture.py</span>
<span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">import</span> aiohttp
<span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">from</span> aioresponses <span class="hljs-keyword">import</span> aioresponses
<span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">mock_aioresponse</span>():
    <span class="hljs-keyword">with</span> aioresponses() <span class="hljs-keyword">as</span> m:
        <span class="hljs-keyword">yield</span> m
<span class="hljs-meta">@pytest.mark.asyncio</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">test_ctx</span>(<span class="hljs-params">mock_aioresponse</span>):
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession() <span class="hljs-keyword">as</span> session:
        mock_aioresponse.get(<span class="hljs-string">"http://test.example.com"</span>, payload={<span class="hljs-string">"foo"</span>: <span class="hljs-string">"bar"</span>})
        resp = <span class="hljs-keyword">await</span> session.get(<span class="hljs-string">"http://test.example.com"</span>)
        data = <span class="hljs-keyword">await</span> resp.json()
    <span class="hljs-keyword">assert</span> {<span class="hljs-string">"foo"</span>: <span class="hljs-string">"bar"</span>} == data  
</code></pre>
    <p class="normal">In this example, we tell <code class="Code-In-Text--PACKT-">aioresponses</code> that any GET request made to <code class="Code-In-Text--PACKT-">http://test.example.com</code> should return the data we specify. This way we can easily provide mocked responses for several URLs, and even the same URL by invoking <code class="Code-In-Text--PACKT-">mocked.get</code> more than once to create multiple responses for the same endpoint.</p>
    <p class="normal">If you are using Requests to perform all the calls—or you are using a library that is based on Requests that <a id="_idIndexMarker408"/>does not customize it too much—this isolation work is also easy to do thanks to the <code class="Code-In-Text--PACKT-">requests-mock</code> project (<a href="https://requests-mock.readthedocs.io"><span class="url">https://requests-mock.readthedocs.io</span></a>), which implements mocked calls in a similar way, and likely inspired <code class="Code-In-Text--PACKT-">aioresponses</code>.</p>
    <p class="normal">That said, mocking responses from other services is still a fair amount of work, and can be difficult to maintain. It means that an eye needs to be kept on how the other services are evolving over time, so <a id="_idIndexMarker409"/>your tests are not based on a mock that's no longer a reflection of the real API.</p>
    <p class="normal">Using mocks is encouraged to build good functional tests coverage, but make sure you are doing integration tests as well, where the service is tested in a deployment where it calls other services for real.</p>
    <h1 id="_idParaDest-116" class="title">Using OpenAPI</h1>
    <p class="normal">The OpenAPI <a id="_idIndexMarker410"/>Specification (<a href="https://www.openapis.org/"><span class="url">https://www.openapis.org/</span></a>), previously known as Swagger, is a standard way<a id="_idIndexMarker411"/> of describing a set of HTTP endpoints, how they are used, and the structure of <a id="_idIndexMarker412"/>the data that is sent and received. By describing an API using a JSON or YAML file, it allows the intent to become machine-readable—this means that with an OpenAPI Specification, you can use a code generator to produce a client library in a language of your choosing, or to automatically validate data as it enters or leaves the system.</p>
    <p class="normal">OpenAPI has the same goal that WSDL (<a href="https://www.w3.org/TR/2001/NOTE-wsdl-20010315"><span class="url">https://www.w3.org/TR/2001/NOTE-wsdl-20010315</span></a>) had back in the XML web services era, but it's much lighter and straight to the point.</p>
    <p class="normal">The following example is a minimal OpenAPI description file that defines one single <code class="Code-In-Text--PACKT-">/apis/users_ids</code> endpoint and supports the <code class="Code-In-Text--PACKT-">GET</code> method to retrieve the list of user IDs:</p>
    <pre class="programlisting code"><code class="hljs-code">---
openapi: "3.0.0"
info:
  title: Data Service
  description: returns info about users
  license:
    name: APLv2
    url: https://www.apache.org/licenses/LICENSE-2.0.html
  version: 0.1.0
basePath: /api
paths:
  /user_ids:
    get:
      operationId: getUserIds
      description: Returns a list of ids
      produces:
        - application/json
      responses:
        '200':
          description: List of Ids
          schema:
            type: array
            items:
              type: integer
</code></pre>
    <p class="normal">The full OpenAPI Specification can be found on GitHub; it is very detailed and will let you describe metadata about the API, its endpoints, and the data types it uses: <a href="https://github.com/OAI/OpenAPI-Specification"><span class="url">https://github.com/OAI/OpenAPI-Specification</span></a>.</p>
    <p class="normal">The data types described in the schema sections are following the JSON Schema specification (<a href="http://json-schema.org/latest/json-schema-core.html"><span class="url">http://json-schema.org/latest/json-schema-core.html</span></a>). Here, we are describing that the <code class="Code-In-Text--PACKT-">/get_ids</code> endpoint returns an array of integers.</p>
    <p class="normal">You can provide a lot of detail about your API in that specification—things such as what headers should be present in your requests, or what will be the content type of some responses and can<a id="_idIndexMarker413"/> be added to it.</p>
    <p class="normal">Describing your HTTP endpoints with OpenAPI offers some excellent possibilities:</p>
    <ul>
      <li class="bullet">There are a plethora of OpenAPI clients that can consume your description and do something useful with it, such as building functional tests against your service, or validating data that is sent to it.</li>
      <li class="bullet">It provides a standard, language-agnostic documentation for your API</li>
      <li class="bullet">The server can check that the requests and responses follow the spec</li>
    </ul>
    <p class="normal">Some web frameworks even use the specification to create all the routing and I/O data checks for your microservices; for instance, Connexion (<a href="https://github.com/zalando/connexion"><span class="url">https://github.com/zalando/connexion</span></a>) does this for Flask. Support for this within Quart is limited at the time of writing, but the situation is always improving. For this reason, we won't be using OpenAPI a great deal in the examples presented here.</p>
    <p class="normal">There are two schools of thought when people are building HTTP APIs with OpenAPI:</p>
    <ul>
      <li class="bullet">Specification-first, where you create a Swagger specification file and then create your app on top of it, using all the information provided in that specification. That's the principle behind Connexion.</li>
      <li class="bullet">Specification-extracted, where it is your code that generates the Swagger specification file. Some toolkits out there will do this by reading your view docstrings, for instance.</li>
    </ul>
    <h1 id="_idParaDest-117" class="title">Summary</h1>
    <p class="normal">In this chapter, we've looked at how a service can interact with other services synchronously, by using a Requests session, and asynchronously, by using Celery workers or more advanced messaging patterns based on RabbitMQ.</p>
    <p class="normal">We've also looked at some ways to test a service in isolation by mocking other services, but without mocking the message brokers themselves.</p>
    <p class="normal">Testing each service in isolation is useful, but when something goes wrong, it's hard to know what happened, particularly if the bug happens in a series of asynchronous calls.</p>
    <p class="normal">In that case, tracking what's going on with a centralized logging system helps a lot. The next chapter will explain how we can tool our microservices to follow their activities.</p>
  </div>
</body></html>