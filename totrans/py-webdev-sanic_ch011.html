<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-US">
<head>
<meta charset="utf-8"/>
<meta name="generator" content="packt"/>
<title>10 Implementing Common Use Cases with Sanic</title>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet2.css"/>

</head>
<body>
<section id="implementing-common-use-cases-with-sanic" class="level1 pkt" data-number="11">
<h1 data-number="11">10 Implementing Common Use Cases with Sanic</h1>
<p>We have learned how to use Sanic, and we have learned some good practices and habits to get into. Now, let’s go build some fun stuff. When starting to work on a new project it is very tempting to start here. Afterall, the idea you have in your head about what to build is the implementation, right? You have a final idea of what you want (a chat bot for example). So, you sit down and you start building the bot.</p>
<p>But the reason this chapter is at the end of the book is because you obviously cannot start here. Only after gaining the knowledge of HTTP and Sanic, and leveling up our technical skills along the way, can we dig into implementation details. The goal of this chapter is to look at some practical features that you may be tasked to build. With the plubming out of the way, and now that we have a solid foundation and understanding of HTTP and Sanic, we can start to build some real-world use cases.</p>
<p>When considering what topics to include in this chapter I thought about what are some common use cases that I know Sanic is used for. It makes sense to select a handful of implementations that often come up, and then try and build them together. This book is obviously a bit space constrained, and so we will not dive into the minute details here. Instead, we will look at some implementation details, talk about some of the considerations, and describe the general approach you might take to the problem. I hope to show you some insight into my own thought process when tasked with a project like this.</p>
<p>Just like the previous chapter, there will be a lot of code in the repository that will not be in the book. It is simply is not all relevant to the conversation, but I wanted to make sure that you have full working examples to use as a launching pad for your own projects. To receive a complete understanding, you really ought to follow along with the source code online while reading this chapter. I will point out specific design decisions and include some choice bits that are particularly worth mentioning.</p>
<p>So, what are we going to build? The list includes:</p>
<ul>
<li>Synchronized websocket feeds</li>
<li>Progressive web app backend</li>
<li>GraphQL API</li>
<li>Chat bot</li>
</ul>
<section id="technical-requirements-9" class="level2" data-number="11.1">
<h2 data-number="11.1">Technical requirements</h2>
<p>Since this chapter builds upon the previous chapters, you should have all of the technical needs already fulfilled. We will start seeing some additional third-party packages in use, so make sure you have <code>pip </code>handy.</p>
<p>If you would like to jump ahead to make sure your environment is setup, here are the pip packages that we plan to use:</p>
<pre><code>$ pip instal aioredis ariande databases[postgresql] nextcord</code></pre>
<p>Furthermore, if you recall, back in Chapter 2 we discussed using factory patterns. Because we are now starting to build what can become the base of a <em>real world</em> application, I feel it is much better to use a factory pattern here that can be expanded. Therefore, for the remainder of this book you will see more and more usage of the factory pattern that we already have established and used.///</p>
</section>
<section id="websocket-feeds" class="level2" data-number="11.2">
<h2 data-number="11.2">Websocket feeds</h2>
<p>Earlier in this book we explored websockets in <em>Websockets for two-way communication</em> section <em>Chapter 5</em> . If you have not read that section yet, I encourage you to do that now. At this time, we are going to take our websocket implementation and create a horizontally scalable websocket feed. The basic premise of the code here will be the same as in that section, which is why you should have an understanding of what we build there before moving onto the example here.</p>
<p>The purpose of the feed we will build is to share events that happen in one browser across to another browser. Building upon the example from Chapter 5, we are going to add a third-party broker that will allow us to run multiple application instances. This means that we can horizontally scale our application. The previous implementation suffered from the fact that it stored client information in memory. With no mechanism to share state or broadcast messages across multiple application instances, there was no way for one websocket connection to guarantee that it would be able to push messages to every other client. At best it would only be able to push messages to clients that happened to be routed and connected to the same application instance. Ultimately, this made it impossible to scale the application with multiple workers.</p>
<p>The goal now will be to create what is known as a <strong>pubsub</strong>. This is a term that means “publish and subscribe” since the pattern relies upon multiple sources subscribing to a central broker. When one of those sources publishes a message to the broker, all of the other sources that are subscribed receive that message. The term pubsub is a simple description of this push and pull between the broker and the sources. We will use this concept when building our feed.</p>
<p>The simplest way to handle pubsub in my opinion is with Redis, which has a very simple built-in pubsub mechanism. The idea is simple: every application instance will be a source. At startup, the application instance will subscribe to a specific channel on the Redis instance. With this connection established, it now has the ability to push and pull messages from that Broker on a specific channel By pushing this off to a third-party service, all of our applications will be able to access the same information through the push and pull of the pubsub.</p>
<p>In the Chapter 5 websockets example, when a message was received, the server would push that message out to other clients that were connected to the same application instance. We will still do something similar. Browser clients will open a websocket with one of many web servers, which will hold onto that client connection. This again will be held in memory. When there is an incoming message from a client instance, it will publish that message not by directly distributing it to the other clients, but instead it will push the message to the pubsub broker. Then, all of the other instances will receive that message since they are subscribed to the same broker and can push the message to any websocket clients that happen to be connected to that application instance. In this way, we can build a distributed websocket feed.</p>
<p>To get started, we will spin up a Redis service using <code>docker-compose</code>, as well as our development application. Take a look in the repository for the details on how to accomplish that: ___. We will assume that you have a Redis instance available and running.</p>
<ol>
<li><p>We begin by creating a websocket handler and attaching it to a Blueprint.</p>
<pre><code>from sanic import Blueprint
from sanic.log import logger
from .channel import Channel
bp = Blueprint(&quot;Feed&quot;, url_prefix=&quot;/feed&quot;)
@bp.websocket(&quot;/&lt;channel_name&gt;&quot;)
async def feed(request, ws, channel_name):
    logger.info(&quot;Incoming WS request&quot;)
    channel, is_existing = await Channel.get(
        request.app.ctx.pubsub, request.app.ctx.redis, channel_name
    )
    if not is_existing:
        request.app.add_task(channel.receiver())
    client = await channel.register(ws)
    try:
        await client.receiver()
    finally:
        await channel.unregister(client)</code></pre>
<p>This is the entirety of our Sanic integration on this example. We defined a websocket endpoint. The endpoint requires us to access a feed by going to a <code>channel_name</code> which is meant to be a unique listening location. This could either be a username or chatroom stock ticker and so on. The point is that the <code>channel_name</code> is meant to represent some location in your application where people will want to continuously retrieve information from your application as a feed. For example, this also could be used to build out a sort of shared editing application where multiple users are able to make changes simultaneously to the same resource.The handler in this example works by fetching a <code>Channel </code>object. If it created a new <code>Channel</code>, then we send off a <code>receiver </code>task to the background that is responsible for listening to our pubsub broker. The next thing in the handler is to register our current websocket connection on the channel, and then create another <code>receiver</code>. The point of this second <code>client.receiver</code> is to listen to the websocket connection, and take incoming messages to push off to the pubsub broker.</p></li>
<li><p>Let’s take a quick look at the <code>Client </code>object.</p>
<pre><code>from dataclasses import dataclass, field
from uuid import UUID, uuid4
from aioredis import Redis
from sanic.server.websockets.impl import WebsocketImplProtocol
@dataclass
class Client:
    protocol: WebsocketImplProtocol
    redis: Redis
    channel_name: str
    uid: UUID = field(default_factory=uuid4)
    def __hash__(self) -&gt; int:
        return self.uid.int
    async def receiver(self):
        while True:
            message = await self.protocol.recv()
            if not message:
                break
            await self.redis.publish(self.channel_name, message)
    async def shutdown(self):
        await self.protocol.close()</code></pre>
<p>As just stated, the purpose of this object is to listen to the current websocket connection and send messages off to the pubsub broker when there is a message. That happens with the <code>publish </code>method.</p></li>
<li><p>We now will take a look at the <code>Channel </code>object. This class is a bit longer than the <code>Client</code>, so we will look at the code for it in sections. It might be helpful to open the GitHub repository to see the class definition in full.</p>
<pre><code>class ChannelCache(dict):
    ...
class Channel:
    cache = ChannelCache()
    def __init__(self, pubsub: PubSub, redis: Redis, name: str) -&gt; None:
        self.pubsub = pubsub
        self.redis = redis
        self.name = name
        self.clients: Set[Client] = set()
        self.lock = Lock()
    @classmethod
    async def get(cls, pubsub: PubSub, redis: Redis, name: str) -&gt; Tuple[Channel, bool]:
        is_existing = False
        if name in cls.cache:
            channel = cls.cache[name]
            await channel.acquire_lock()
            is_existing = True
        else:
            channel = cls(pubsub=pubsub, redis=redis, name=name)
            await channel.acquire_lock()
            cls.cache[name] = channel
            await pubsub.subscribe(name)
        return channel, is_existing</code></pre></li>
</ol>
<p>A channel is created and cached in each application instance in memory. This means that for every single application instance where an incoming request asks to join a specific channel, there is only one instance of that channel being created. Even if we have ten (10) application instances, it does not matter that we have ten (10) instances of the channel. What we care about is that on any <em>single</em> application instance, there is never more than one <code>Channel </code>subscribing to a single Redis pubsub channel. Having multiple channels on the same application instance could get messy and lead to a memory leak. Therefore, we also want to add a mechanism to clean up the cache when a channel is no longer needed. We can do that like this:</p>
<pre><code>    async def destroy(self) -&gt; None:
        if not self.lock.locked():
            logger.debug(f&quot;Destroying Channel {self.name}&quot;)
            await self.pubsub.reset()
            del self.__class__.cache[self.name]
        else:
            logger.debug(f&quot;Abort destroying Channel {self.name}. It is locked&quot;)</code></pre>
<p>The reason we are using a <code>Lock </code>on this is to try and avoid race conditions where multiple requests make an attempt to destroy a channel instance.</p>
<p>If you recall from above, after the channel is created (or fetched from the cache), we register the websocket connection on the Channel instance which looks like this:</p>
<pre><code>    async def register(self, protocol: WebsocketImplProtocol) -&gt; Client:
        client = Client(protocol=protocol, redis=self.redis, channel_name=self.name)
        self.clients.add(client)
        await self.publish(f&quot;Client {client.uid} has joined&quot;)
        return client</code></pre>
<p>We simply create the <code>Client </code>object, add it to the known clients that need to be notified from this instance on an incoming message, and send off a message to let other clients know that someone has just joined. The publish message method simply looks like this:</p>
<pre><code>    async def publish(self, message: str) -&gt; None:
        logger.debug(f&quot;Sending message: {message}&quot;)
        await self.redis.publish(self.name, message)</code></pre>
<p>Once a client has been registered, it also needs to have the ability to unregister. A method to unregister is as follows:</p>
<pre><code>    async def unregister(self, client: Client) -&gt; None:
        if client in self.clients:
            await client.shutdown()
            self.clients.remove(client)
            await self.publish(f&quot;Client {client.uid} has left&quot;)
        if not self.clients:
            self.lock.release()
            await self.destroy()</code></pre>
<p>Here, we remove the current client from the known clients on the <code>Channel</code>. If there are no longer anymore clients listening to this channel, then we can close it and clean up after ourselves.</p>
<p>This is a super simple pattern that provides an immense amount of flexibility. In fact, in my course of providing support and helping people with their Sanic applications, I have provided assistance in building applications using a similar pattern to this on numerous occasions. Using this, you could create some truly incredible frontend applications. I know I have. Speaking of which, in our next section we are going to start looking at the interplay between Sanic and frontend web applications that run in the browser.</p>
</section>
<section id="powering-a-progressive-web-app" class="level2" data-number="11.3">
<h2 data-number="11.3">Powering a progressive web app</h2>
<p>A lot of use cases for building web APIs are to power a <strong>progressive web application</strong> (PWA, also known as a single-page application, or SPA). Like many other web developers out there, the real draw to web development was for the purpose of building a usable application or website in the browser. Let’s be honest, not many of us are out there writing <code>curl </code>commands to use our favorite APIs. The real power of a web API is when it powers something else.</p>
<p>What does a PWA need in order to run? Well, when you build a PWA the final product is a bunch of static files. Okay, so we put those files into a directory called <code>./public</code> and then we serve them:</p>
<pre><code>app.static(&quot;/&quot;, &quot;./public&quot;)</code></pre>
<p>There you go, we now are running a PWA. We’re finished.</p>
<p>Well, not so fast. Being able to serve the static content is important, but it is also not the only factor you need to consider. Let’s look at some considerations when building PWAs.</p>
<section id="dealing-with-subdomains-and-cors" class="level3" data-number="11.3.1">
<h3 data-number="11.3.1">Dealing with subdomains and CORS</h3>
<p>In Chapter 7 we spent a significant amount of time looking into CORS from a security lens. I would venture a guess that by far the biggest rationale for requiring CORS protection is the need to serve content to a PWA. These types of applications are ubiquitous on the Internet, and usually have to tackle. The reason this usually happens is that often times the frontend of a PWA and the backend are on different subdomains. This usually is because they are running on different servers. The static content might be served with a CDN, and the backend is on a VPS or PAAS offering (see Chapter 8 for more on Sanic deployment options).</p>
<p>CORS is a big topic. It is also something easy to get wrong. Luckily, there is a simple method for getting this up and running using Sanic Extensions, a package that is developed and maintained by the Sanic team to add some extra features to Sanic. Sanic Extensions focus on all of the more opinionated and use-case specific implementations that are inappropriate for the core project. CORS is one of those features.</p>
<p>So, how do we get going out of the box?</p>
<pre><code>$ pip install sanic[ext]</code></pre>
<p>or</p>
<pre><code>$ pip install sanic sanic-ext</code></pre>
<p>That’s it. Just install the <code>sanic-ext </code>package into your environment and you will get CORS protection out of the box. As of version 21.12, if you have the <code>sanic-ext </code>in your environment, Sanic will auto-instantiate it for you.</p>
<p>The only thing we need to do now is to configure it. Usually, to get started with CORS configuration, we need to set the allowed origins:</p>
<pre><code>app.config.CORS_ORIGINS = &quot;http://foobar.com,http://bar.com&quot;</code></pre>
<p>Well, hang on a minute, you say, “Can’t I just serve the frontend assets from Sanic and avoid CORS because the front and back are on the same server?” Yup. If that approach works for you, go for it. Let’s see what that might look like (from a development perspective).</p>
</section>
<section id="running-a-development-server" class="level3" data-number="11.3.2">
<h3 data-number="11.3.2">Running a development server</h3>
<p>What happens when you decide that you want both frontend and backend applications to run on the same server? Or, when you want to use the <code>app.static </code>method shown above to serve your project files? Building this locally could be very tricky.</p>
<p>The reason this is the case is because when building a frontend application, you need a frontend server. Most frameworks have some sort of a build requirement. That is to say that you type some code, hit save, then some package like <code>webpack </code>or <code>rollup </code>compiles your JS and serves it to you from a local development web server. Your frontend development server might run on port 5555, so you go to <code>http://localhost:5555</code>.</p>
<p>But, you want to access your locally running backend from that frontend application to populate content. The backend is running on <code>http://localhost:7777</code>. Uh oh, do you see where this is going? We are right back to CORS all over again. As long as your frontend application is being run by a different server than your backend, you will continue to run into CORS issues.</p>
<p>Ultimately, we are trying to get a single server to run both the backend and frontend. Since we are talking about local development, we also want auto-reload capabilities for both our Python files and our Javascript files. We also need to trigger a rebuild of the Javascript, and finally we need to serve this all from one location.</p>
<p>Luckily, Sanic can do all of this for us. Let’s now use Sanic as a local development server for a frontend project.</p>
<p>This will work with any frontend tools you want since we will essentially be calling those tools from within Python. My frontend development framework of choice is Svelte, but feel free to try this with React, Vue, or any of the other many alternatives. I will not walk you through the steps of setting up a frontend project since that is not important here. Imagine that you have already done it. If you would like to follow along in code, please see the GitHub repository: ___.</p>
<p>To accomplish our goals, we will setup the Sanic server to add auto-reload capabilities to the build directory of the frontend application. For Svelte projects using <code>rollup </code>(a popular JS build tool), that is a <code>./public</code> directory.</p>
<ol>
<li><p>We start by declaring the location of the static files and serving them with <code>static</code>:</p>
<pre><code>app = Sanic(&quot;MainApp&quot;)
app.config.FRONTEND_DIR = Path(__file__).parent / &quot;my-svelte-project&quot;
app.static(&quot;/&quot;, app.config.FRONTEND_DIR / &quot;public&quot;)</code></pre></li>
<li><p>When we run Sanic, make sure to add that directory to the auto-reloader like this:</p>
<pre><code>sanic server:app -d -p7777 -R ./my-svelte-project/src</code></pre></li>
<li><p>The next thing we want to do is define a custom signal. We are going to use this later, so all it needs to do now is define it. It just needs to exist so that we can later await the event.</p>
<pre><code>@app.signal(&quot;watchdog.file.reload&quot;)
async def file_reloaded():
...</code></pre></li>
<li><p>We are now ready to build something that will check the files that were reloaded and decide whether or not we need to trigger the <code>rollup </code>build process. We will look at this in two parts. First, we create a startup listener that checks the file extensions to determine the server start was triggered by a reload from any <code>.svelte</code> or <code>.js</code> file extensions.</p>
<pre><code>@app.before_server_start
async def check_reloads(app, _):
    do_rebuild = False
    if reloaded := app.config.get(&quot;RELOADED_FILES&quot;):
        reloaded = reloaded.split(&quot;,&quot;)
        do_rebuild = any(
            ext in (&quot;svelte&quot;, &quot;js&quot;)
            for filename in reloaded
            if (ext := filename.rsplit(&quot;.&quot;, 1)[-1])
        )</code></pre>
<p>As of version 21.12, the files that triggered a reload are stashed in a <code>SANIC_RELOADED_FILES </code>environment variable. Since any environment variables starting with SANIC_ prefix are loaded into our <code>app.config</code>, we can simply read that value if it exists and check the file extensions.Assuming there is a rebuild required, we next want to trigger a subprocess call to our shell to run the build command:</p>
<pre><code>    if do_rebuild:
        rebuild = await create_subprocess_shell(
            &quot;yarn run build&quot;,
            stdout=PIPE,
            stderr=PIPE,
            cwd=app.config.FRONTEND_DIR,
        )
        while True:
            message = await rebuild.stdout.readline()
            if not message:
                break
            output = message.decode(&quot;ascii&quot;).rstrip()
            logger.info(f&quot;[reload] {output}&quot;)
        await app.dispatch(&quot;watchdog.file.reload&quot;)</code></pre>
<p>Finally, when this is all done, we are going to dispatch that custom event that we created earlier.</p></li>
<li><p>Up until now, we have the auto-reload and auto-rebuilding working as expected. The only thing we are missing now is the ability to trigger the web browser to refresh the page. This can be accomplished using a tool called <code>livereload.js</code>. You can access livereload.js by searching for it and installing the Javascript. Essentially what it will do is create a websocket connection to a server on port 35729. Then from that websocket you can send messages prompting the browser to perform a refresh. To do this from Sanic, we are going to run nested applications. Add a second application definition:</p>
<pre><code>livereload = Sanic(&quot;livereload&quot;)
livereload.static(&quot;/livereload.js&quot;, app.config.FRONTEND_DIR / &quot;livereload.js&quot;)</code></pre></li>
<li><p>We also will need to declare a few more constants. These are mainly to run the two types of messages that livereload needs to send from the server:</p>
<pre><code>INDEX_HTML = app.config.FRONTEND_DIR / &quot;public&quot; / &quot;index.html&quot;
HELLO = {
    &quot;command&quot;: &quot;hello&quot;,
    &quot;protocols&quot;: [
        &quot;http://livereload.com/protocols/official-7&quot;,
    ],
    &quot;serverName&quot;: app.name,
}
RELOAD = {&quot;command&quot;: &quot;reload&quot;, &quot;path&quot;: str(INDEX_HTML)}</code></pre></li>
<li><p>Next, setup the necessary listeners to run the nested server:</p>
<pre><code>@app.before_server_start
async def start(app, _):
    app.ctx.livereload_server = await livereload.create_server(
        port=35729, return_asyncio_server=True
    )
    app.add_task(runner(livereload, app.ctx.livereload_server))
@app.before_server_stop
async def stop(app, _):
    await app.ctx.livereload_server.close()</code></pre>
<p>The <code>runner </code>task used in the code above should look like this:</p>
<pre><code>async def runner(app, app_server):
    app.is_running = True
    try:
        app.signalize()
        app.finalize()
        await app_server.serve_forever()
    finally:
        app.is_running = False
        app.is_stopping = True</code></pre></li>
<li><p>It is time to add the websocket handler:</p>
<pre><code>@livereload.websocket(&quot;/livereload&quot;)
async def livereload_handler(request, ws):
    global app
    logger.info(&quot;Connected&quot;)
    msg = await ws.recv()
    logger.info(msg)
    await ws.send(ujson.dumps(HELLO))
    while True:
        await app.event(&quot;watchdog.file.reload&quot;)
        await ws.send(ujson.dumps(RELOAD))</code></pre></li>
</ol>
<p>As you can see, the handler accepts an initial message from livereload, and then sends a <code>HELLO </code>message back. Afterwards we are going to run a loop and wait until the custom signal we created is triggered. When it is, we send off the RELOAD message, which triggers the browser to refresh the webpage.</p>
<p>Voila! We now have a full Javascript development environment running inside of Sanic. This is a perfect setup for those PWAs where you want to serve the frontend and backend content from the same location.</p>
<p>Since we are already talking about frontend content, we will next visit another important topic for frontend developers: GraphQL</p>
</section>
</section>
<section id="graphql" class="level2" data-number="11.4">
<h2 data-number="11.4">GraphQL</h2>
<p>In 2015, Facebook publicly released a project of meant to rival traditional web APIs and flip the concept of a RESTful web application on its head. This project is what we now know as GraphQL. This book has so far assumed that we are building out endpoints using the traditional method of combining HTTP Methods with thoughtful paths to point to specific resources. In this approach, web servers are responsible for being the interface between a client and the source of data (i.e, a database). The concept of GraphQL pushes all of that aside and allows the client to directly request what information it wants to receive. There is a single endpoint (usually <code>/graphql</code>) and a single HTTP Method (usually <code>POST</code>). The single route definition is meant to be used for both retrieving data and causing state changes in the application. This all happens through a set of queries that are sent as the body on that single endpoint. GraphQL was meant to revolutionize the way we build the web, and to take over as the standard practice of the future. At least, that is what many people said was going to happen.</p>
<p>This has not actually come to pass. At the time of this writing, the popularity of GraphQL has seemingly peaked and is now on a decline. Nevertheless, I do believe that GraphQL fulfills a necessary niche in the web application world, and it will continue to live on as an alternative implementation for years to come (just not as a replacement). We, therefore, do need to know how to integrate it with Sanic for the instances where you may be asked to deploy one of these servers.</p>
<p>Before we can answer the question of “why use GraphQL?” we must understand what it is. As the name seemingly implies, <strong>GraphQL</strong> is a sort of query language. A query is a JSON-like request for information to be delivered in a specific format. A client looking to receive information from a web server might send a <code>POST </code>request with a body that includes a query like this:</p>
<pre><code>{
  countries (limit: 3, offset:2) {
    name
    region
    continent
    capital {
      name
      district
    }
    languages {
      language
      isofficial
      percentage
    }
  }
}</code></pre>
<p>In return, a server would go and fetch whatever data it needed and compile a return JSON document matching that description:</p>
<pre><code>{
  &quot;data&quot;: {
    &quot;countries&quot;: [
      {
        &quot;name&quot;: &quot;Netherlands Antilles&quot;,
        &quot;region&quot;: &quot;Caribbean&quot;,
        &quot;continent&quot;: &quot;North America&quot;,
        &quot;capital&quot;: {
          &quot;name&quot;: &quot;Willemstad&quot;,
          &quot;district&quot;: &quot;Curaçao&quot;
        },
        &quot;languages&quot;: [
          {
            &quot;language&quot;: &quot;Papiamento&quot;,
            &quot;isofficial&quot;: true,
            &quot;percentage&quot;: 86.19999694824219
          },
          {
            &quot;language&quot;: &quot;English&quot;,
            &quot;isofficial&quot;: false,
            &quot;percentage&quot;: 7.800000190734863
          },
          {
            &quot;language&quot;: &quot;Dutch&quot;,
            &quot;isofficial&quot;: true,
            &quot;percentage&quot;: 0
          }
        ]
      },
      ...
    ]
  }
}</code></pre>
<p>As you might be able to tell, this becomes a very powerful tool for the client as it can bundle what might otherwise be multiple network calls into a single operation. It also allows a client (for example a PWA) to specifically retrieve the exact data that it needs in the format that it needs it.</p>
<section id="why-would-i-want-to-use-graphql" class="level3" data-number="11.4.1">
<h3 data-number="11.4.1">Why would I want to use GraphQL?</h3>
<p>I believe that GraphQL is the best friend of the frontend developer, but the bane of existence for the backend developer. It is certainly true that web applications using GraphQL will generally issue fewer HTTP calls to web servers than their counterparts. It is also certainly true that a frontend developer will have an easier time manipulating responses from a web server using GraphQL since they get to be the architect of how that data is structured.</p>
<p>GraphQL provides a very easy method for data retrieval. Because it is a strongly typed specification, it makes it possible to have tools that make the whole process of generating a query very elegant. For example, many GraphQL implementations come with an out-of-the-box web UI that can be used for development. These UIs usually include the ability to navigate the schema and see exactly what types of queries can be made, and what information is retrievable. See Figure __ for an example.</p>
<p>INSERT IMAGE</p>
<p>Figure ___. Example of a GraphQL UI showing the “SCHEMA” tab that displays all of the available information</p>
<p>There is certainly a fun factor that goes into these tools as you play with them to craft exactly the information you want. Simply put: GraphQL is simple to use and implement. It also has a very satisfying “coolness” factor to it when you start building ad-hoc custom queries.</p>
<p>Except, it is a nightmare in the backend. For all of the simplification from the client perspective, the web server now needs to deal with a much greater level of complexity. For this reason, when someone tells me that they want to build a GraphQL application I usually ask them: why? If they are building it as a public facing API, then this may be wonderful. GitHub is a great example of a public-facing GraphQL API that is a treat to work in. Querying the GitHub API is simple and intuitive. If, however, they are building the API for their own internal purposes, then there is a set of tradeoffs that must be considered.</p>
<p>GraphQL is not in totality any easier or simpler than REST. Instead, it represents the shifting of complexity almost entirely to the web server. This may be acceptable, but it is a tradeoff that you must consider. I generally find the overall increase in complexity of the backend outweighs any benefits of implementation.</p>
<p>I know it may sound like I am not a fan of GraphQL. This is not true. I do think that GraphQL is a great concept, and I think there are some amazing tools out there (including in the Python world) to help build these applications. If you want to include GraphQL in your Sanic application, I would highly recommend tools like <code>Ariadne </code>(<a href="https://ariadnegraphql.org/">https://ariadnegraphql.org/</a>) and <code>Strawberry </code>(<a href="https://strawberry.rocks/">https://strawberry.rocks/</a>). Even with these tools, a good GraphQL application in my opinion is more difficult to build with a few pitfalls waiting to swallow you up. As we look into how we can build a Sanic GraphQL application, I will try and point out these issues so that we can work around them.</p>
</section>
<section id="adding-graphql-to-sanic" class="level3" data-number="11.4.2">
<h3 data-number="11.4.2">Adding GraphQL to Sanic</h3>
<p>I have built a small GraphQL application for this section. All of the code is, of course, on the GitHub repository for this book: ___. I highly suggest you have the code available while reading. Quite frankly the code in its entirety is much too complex and lengthy to include it all here. So, instead we will talk through it in general, and I will refer you back to the repository for specifics. For your convenience I have also added a number of comments and further discussion points in the code base itself.</p>
<p>When we discussed database access in Chapter 9 in the section called <em>To ORM or Not to ORM, that is the question</em>, we talked about whether you should or should not implement an ORM. The discussion was about whether you should use a tool to help you build the SQL queries or to build them yourself. There are very good arguments on both sides: pro-ORM versus anit-ORM. I opted for a somewhat hybrid approach to build the SQL queries by hand, and then build a lightweight utility to hydrate the data to a usable model.</p>
<p>A similar question <em>could</em> be posed here: should I build it myself or use a package? My answer is that you should absolutely use a package. I cannot see any reason to try and build a custom implementation yourself. There are several good options in Python; my personal preference is Ariadne. I particularly like the schema-first approach that the package takes. Using it allows me to define the GraphQL parts of my application in <code>.gql </code>files, therefore enabling my IDE to add syntax highlighting and other language specific conveniences.</p>
<p>Let’s begin:</p>
<ol>
<li><p>Since we are using Ariadne in our example here, we begin by installing it into our virtual environment:</p>
<pre><code>$ pip install ariadne</code></pre></li>
<li><p>To get up and running with Ariadne’s “hello world” application does not take much:</p>
<pre><code>from ariadne import QueryType, graphql, make_executable_schema
from ariadne.constants import PLAYGROUND_HTML
from graphql.type import GraphQLResolveInfo
from sanic import Request, Sanic, html, json
app = Sanic(__name__)
query = QueryType()
type_defs = &quot;&quot;&quot;
    type Query {
        hello: String!
    }
&quot;&quot;&quot;
@query.field(&quot;hello&quot;)
async def resolve_hello(_, info: GraphQLResolveInfo):
    user_agent = info.context.headers.get(&quot;user-agent&quot;, &quot;guest&quot;)
    return &quot;Hello, %s!&quot; % user_agent
@app.post(&quot;/graphql&quot;)
async def graphql_handler(request: Request):
    success, result = await graphql(
        request.app.ctx.schema,
        request.json,
        context_value=request,
        debug=app.debug,
    )
    status_code = 200 if success else 400
    return json(result, status=status_code)
@app.get(&quot;/graphql&quot;)
async def graphql_playground(request: Request):
    return html(PLAYGROUND_HTML)
@app.before_server_start
async def setup_graphql(app, _):
    app.ctx.schema = make_executable_schema(type_defs, query)</code></pre></li>
</ol>
<p>As you can see, there are two endpoints:</p>
<ul>
<li>a <code>GET </code>that displays the GraphQL query builder</li>
<li>a <code>POST </code>that is the ingress to the GraphQL backend</li>
</ul>
<p>From this humble beginning, you can build from Sanic and Ariadne however your heart desires. Let’s take a look at a potential strategy you might take.</p>
<ol>
<li><p>Scrapping the above, we begin with an app that looks very similar in structure to what we have seen before. Create <code>./blueprints/graphql/query.py </code>and place your root level GraphQL object.</p>
<pre><code>from ariadne import QueryType
query = QueryType()</code></pre></li>
<li><p>Now, we create the two endpoints needed inside of a CBV on our GraphQL Blueprint instance:</p>
<pre><code>from sanic import Blueprint, Request, html, json
from sanic.views import HTTPMethodView
from ariadne.constants import PLAYGROUND_HTML
bp = Blueprint(&quot;GraphQL&quot;, url_prefix=&quot;/graphql&quot;)
class GraphQLView(HTTPMethodView, attach=bp, uri=&quot;&quot;):
    async def get(self, request: Request):
        return html(PLAYGROUND_HTML)
    async def post(self, request: Request):
        success, result = await graphql(
            request.app.ctx.schema,
            request.json,
            context_value=request,
            debug=request.app.debug,
        )
        status_code = 200 if success else 400
        return json(result, status=status_code)</code></pre>
<p>As you can see, this is nearly identical to the simple version from before.</p></li>
<li><p>On this same Blueprint instance, we are going to place all of our startup logic. This keeps it all in a convenient location and allows us to attach it to our application instance all at once.</p>
<pre><code>from ariadne import graphql, make_executable_schema
from world.common.dao.integrator import RootIntegrator
from world.blueprints.cities.integrator import CityIntegrator
from world.blueprints.countries.integrator import CountryIntegrator
from world.blueprints.languages.integrator import LanguageIntegrator
@bp.before_server_start
async def setup_graphql(app, _):
    integrator = RootIntegrator.create(
        CityIntegrator,
        CountryIntegrator,
        LanguageIntegrator,
        query=query,
    )
    integrator.load()
    integrator.attach_resolvers()
    defs = integrator.generate_query_defs()
    additional = integrator.generate_additional_schemas()
    app.ctx.schema = make_executable_schema(defs, query, *additional)</code></pre></li>
</ol>
<p>You may be wondering, what is an integrator, and what is it all of that code doing. This is where I am going to refer you to the repository for the specifics, but we will walk through the concept here.</p>
<p>In my application example, an <code>Integrator </code>is an object that lives inside of a domain and is the conduit to setting up a GraphQL schema that Ariadne can use.</p>
<p>In the GitHub repository, you will see that the simplest Integrator is for the <code>languages </code>module. It looks like this:</p>
<pre><code>from world.common.dao.integrator import BaseIntegrator
class LanguageIntegrator(BaseIntegrator):
    name = &quot;language&quot;</code></pre>
<p>Next to it is a file called <code>schema.gql</code>:</p>
<pre><code>type Language {
    countrycode: String
    language: String
    isofficial: Boolean
    percentage: Float
}</code></pre>
<p>It is then the job of the <code>RootIntegrator </code>to marshall all of the various domains together and generate the schema for Ariadne using both dynamically generated schema, and the hardcoded schema like the snippet above.</p>
<p>We also need to create a place for our GraphQL query to start. A query might look like this:</p>
<pre><code>    async def query_country(
        self, _, info: GraphQLResolveInfo, *, name: str
    ) -&gt; Country:
        executor = CountryExecutor(info.context.app.ctx.postgres)
        return await executor.get_country_by_name(name=name)</code></pre>
<p>A user creates a query and we go and fetch it from the database. The Executor here works exactly as it does in the <code>hikingapp</code>. Refer back to Chapter ___. Therefore, with a query like this, we can now translate the GraphQL query to an object.</p>
<pre><code>{
  country(name: &quot;Israel&quot;) {
    name
    region
    continent
    capital {
      name
      district
    }
    languages {
      language
      isofficial
      percentage
    }
  }
}</code></pre>
<p>With the power of GraphQL, our response should be this:</p>
<pre><code>{
  &quot;data&quot;: {
    &quot;country&quot;: {
      &quot;name&quot;: &quot;Israel&quot;,
      &quot;region&quot;: &quot;Middle East&quot;,
      &quot;continent&quot;: &quot;Asia&quot;,
      &quot;capital&quot;: {
        &quot;name&quot;: &quot;Jerusalem&quot;,
        &quot;district&quot;: &quot;Jerusalem&quot;
      },
      &quot;languages&quot;: [
        {
          &quot;language&quot;: &quot;Hebrew&quot;,
          &quot;isofficial&quot;: true,
          &quot;percentage&quot;: 63.099998474121094
        },
        {
          &quot;language&quot;: &quot;Arabic&quot;,
          &quot;isofficial&quot;: true,
          &quot;percentage&quot;: 18
        },
        {
          &quot;language&quot;: &quot;Russian&quot;,
          &quot;isofficial&quot;: false,
          &quot;percentage&quot;: 8.899999618530273
        }
      ]
    }
  }
}</code></pre>
<p>The way that Ariadne (and other GraphQL implementations) works is that you define a strongly typed schema. With the knowledge of that schema, you might end up with nested objects. For example, the above <code>Country </code>schema might look like this:</p>
<pre><code>type Country {
    code: String
    name: String
    continent: String
    region: String
    capital: City
    languages: [Language]
}</code></pre>
<p>The Country type has a field called <code>capital</code>, which is a <code>City </code>type. Since this is not a simple scalar value that easily serializes to JSON, we need to tell Ariadne how to translate—or resolve—that field. Given the example in GitHub, it would be to query our database like this:</p>
<pre><code>class CountryIntegrator(BaseIntegrator):
    name = &quot;country&quot;
    async def resolve_capital(
        self,
        country: Country,
        info: GraphQLResolveInfo
    ) -&gt; City:
        executor = CityExecutor(info.context.app.ctx.postgres)
        return await executor.get_city_by_id(country.capital)</code></pre>
<p>This is how we can follow the path between different objects. It is then the job of Ariadne to piece all of these different queries and resolvers together to generate a final object to return. This is the power of GraphQL.</p>
<p>You may have also noticed a flaw. Because every resolver is meant to operate independently and to handle the conversion of a single field into a value, you can very easily overfetch data from the database. This is especially true if you have an array of objects that all resolve to the same database instance. This is known as the “n+1” problem. While it is not a unique problem to GraphQL, the design of many GraphQL systems make it acutely prone to it. If you ignore this problem, while responding to a single request your server might ask the database for the same information over and over again even though it should otherwise already have it.</p>
<p>Many applications suffer from this issue. They rely on many more database queries than may otherwise be needed. All of this overfetching adds up and reduces the performance and efficiency of web applications. While you should certainly be aware of this issue and cognizant as you develop any application, I feel it is something you must particularly plan for with GraphQL implementations since they thrive off of simplified resolvers. Therefore, the biggest piece of advice I can provide when building one of these applications is to think about in-memory, request-based caching. That is to say that caching objects on a request instance might save a ton of SQL queries.</p>
<p>I encourage you to take some time to review the rest of the code in the GitHub repository. There are some helpful patterns that could be usable in a real-world application. Since they are not necessarily on-point to Sanic or implementing GraphQL in Sanic, we will leave the discussion here for now and turn to another popular use case with Sanic: chat bots.</p>
</section>
</section>
<section id="building-a-discord-bot-running-sanic-in-another-service" class="level2" data-number="11.5">
<h2 data-number="11.5">Building a Discord bot (running Sanic in another service)</h2>
<p>At some point early in 2021, I was convinced by a few people in the Sanic community that we needed to move our primary discussion and community building tool. We had a somewhat underutilized chat application and also the community forums that were mainly used for longer style support questions. Discord is a more intimate conversation than what other options could offer. When it was suggested to me that we use Discord, I was a little hesitant to add another application to my tool belt. Nevertheless, we went forward with it. If there are Discord fans out there reading this book, then you do not need me to explain to you its benefits. For everyone else, Discord is a very easy to use and engaging platform that really facilitates the types of discussion helpful to our corner of the Internet.</p>
<p>As I learned more about the platform, the biggest thing that stuck out to me was that chat bots are everywhere. There is an incredible underculture I was unaware of relating to the building of bots. The vast majority of these bots are built using the SDKs, which are open-source projects that wrap much of the client HTTP interactions needed to interface with Discord’s API. There are entire ecosystems and frameworks built up on top of this to help developers make engaging bots.</p>
<p>Naturally, one of the next questions that gets asked all the time is: how can I integrate Sanic with my bot application? We are going to try and do that.</p>
<p>But first, I want to point out that while the example we are going to build uses Discord, the principles are in no way connected to running this on Discord. The core of what we are about to do is to run some <code>asyncio </code>process and reuse that loop for running Sanic. This means that you could in fact use this exact same technique to run nested Sanic applications. We will see what that looks like in the next section.</p>
<section id="building-a-simple-discord-bot" class="level3" data-number="11.5.1">
<h3 data-number="11.5.1">Building a simple discord bot</h3>
<p>I am not an expert with Discord. There is an entire realm of development that occurs based upon this platform and I will not pretend to be an authority. Our goal here is to integrate a bot application with Sanic. To do this, we are going to standup a basic Discord bot using <code>nextcord</code>. If you are not familiar with <code>nextcord</code>, as of the time of the writing of this book, it is an actively maintained fork of the abandoned <code>discord.py </code>project. If you are also not familiar with that, no worries. The simple explanation is that these are frameworks used to build a bot application on Discord. Similar to how Sanic provides tools for HTTP communications, these frameworks provide tools to communicate with Discord.</p>
<p>Let’s take a minute to consider the basic hello world application from their documentation:</p>
<pre><code>import nextcord
client = nextcord.Client()
@client.event
async def on_ready():
    print(f&#39;We have logged in as {client.user}&#39;)
@client.event
async def on_message(message):
    if message.author == client.user:
        return
    if message.content.startswith(&#39;$hello&#39;):
        await message.channel.send(&#39;Hello!&#39;)
client.run(&#39;your token here&#39;)</code></pre>
<p>To be honest, this looks not too dissimilar from what we build in Sanic. It starts with an application instance. Then, there are decorators that wrap handlers. The last thing we see is a <code>client.run</code>.</p>
<p>This is the key to what we want to build. This <code>run</code> method is going to create a loop and run it until the application is shutdown. Our job now is to run Sanic inside of this application. This means we will <em>not</em> be using the Sanic cli to standup our application. Instead, we will run the application using:</p>
<pre><code>$ python bot.py</code></pre>
<p>Let’s get started.</p>
<ol>
<li>Start by copying the minimal bot example from their documentation into <code>bot.py</code>. You can grab the code here: <a href="https://nextcord.readthedocs.io/en/latest/quickstart.html">https://nextcord.readthedocs.io/en/latest/quickstart.html</a></li>
<li><p>Create a simple Sanic application as a proof of concept.</p>
<pre><code>from sanic import Sanic, Request, json
app = Sanic(__name__)
@app.get(&quot;/&quot;)
async def handler(request: Request):
    await request.app.ctx.general.send(&quot;Someone sent a message&quot;)
    return json({&quot;foo&quot;: &quot;bar&quot;})
@app.before_server_start
async def before_server_start(app, _):
    await app.ctx.general.send(&quot;Wadsworth, reporting for duty&quot;)</code></pre>
<p>Nothing fancy is happening so far. We have a single handler that will send off a message in a listener before the server starts. And, we also have a single handler that will also trigger a message to our Discord server when the route endpoint is hit.</p></li>
<li><p>To integrate this with the Discord bot, we will use the <code>on_ready </code>event to run our sanic server.</p>
<pre><code>from server import app
@client.event
async def on_ready():
    app.config.GENERAL_CHANNEL_ID = 906651165649928245
    app.ctx.wadsworth = client
    app.ctx.general = client.get_channel(app.config.GENERAL_CHANNEL_ID)
        
    if not app.is_running:
        app_server = await app.create_server(port=9999, return_asyncio_server=True)
        app.ctx.app_server = app_server
        client.loop.create_task(runner(app_server))</code></pre>
<blockquote>
<p><strong>IMPORTANT NOTICE</strong></p>
<p>For the sake of simplicity, I am just importing from server import app. That is because it is a super simple implementation. In actuality, if I were building a proper application, I would <strong>NOT</strong> use this pattern. Instead, I would use the factory pattern discussed repeatedly throughout this book and build my application from a callable. This is to help with import management and to avoid passing global scope variables.</p>
</blockquote>
<p>A few things are happening here that we need to discuss. First, as mentioned, this is the syntax used to tell <code>nextcord </code>to run this handler when the application starts up and is connected to Discord, and therefore “ready.” But, according to their documentation, this event could be triggered multiple times. That would be a mistake to try and run Sanic multiple times since it would fail to properly bind to a socket.To avoid this, we look at the <code>app.is_running </code>flag to determine if we should run this again.What happens next is that we are going to manually create a Sanic server. After that–and this part is critical—we pass that app server instance into a <em>NEW</em> task. Why? Because if we ran Sanic from the current task it would block indefinitely, and the Discord bot would never actually run. Since we want them both to run concurrently, it is imperative that we run Sanic from another <code>asyncio </code>task.</p></li>
<li><p>Next, we need to create that <code>runner </code>operation. The job here is to run the created server. This means that we need to manually trigger all of the listener events. It also means that we need to perform some shutdown of connections. Because we are operating at a MUCH lower level than normal, you will be required to be more hands on.</p>
<pre><code>async def runner(app_server: AsyncioServer):
    app.is_running = True
    try:
        await app_server.startup()
        await app_server.before_start()
        await app_server.after_start()
        await app_server.serve_forever()
    finally:
        app.is_running = False
        app.is_stopping = True
        await app_server.before_stop()
        await app_server.close()
        for connection in app_server.connections:
            connection.close_if_idle()
        await app_server.after_stop()
        app.is_stopping = False</code></pre></li>
</ol>
<p>The job here looks simple. It starts the application, runs some listener events and then will listen forever until the application shuts down. Before completely exiting, we need to run some cleanup operations inside the finally block.</p>
<p>Once you have all of this implemented, you can run it as we said before by executing the bot.py script. You should now see this message in your Discord server that was triggered by Sanic during the application startup lifecycle.</p>
<p>&lt;&lt;&lt;&lt; IMAGE &gt;&gt;&gt;&gt;&gt;</p>
<p>Next, you should be able to hit your single endpoint and see another message:</p>
<p>&lt;&lt;&lt;&lt; IMAGE &gt;&gt;&gt;&gt;&gt;</p>
<p>Because we are not using the standard method for running Sanic, I do not like to recommend this approach. For starters, it is easy to mess up the order of calls and either leave out some critical events, or improperly handle things like shutdown. Admittedly the shutdown mechanism above is incomplete. For starters, it does not include any sort of handling for the graceful shutdown of existing connections.</p>
<p>This leads to the next question: instead of running Sanic inside the Discord bot, can we run the bot inside Sanic? Yes. That is what we will do next.</p>
</section>
<section id="running-the-discord-bot-from-sanic" class="level3" data-number="11.5.2">
<h3 data-number="11.5.2">Running the Discord bot from Sanic</h3>
<p>Before we get started, let’s consider what <code>client.run </code>is doing. It does whatever internal instantiation is needed to run its service, including making a connection to the Discord server. Then, it enters into a loop to asynchronously receive and send messages to the Discord server. This sounds very similar to what Sanic server does. And, therefore, we can do the exact same thing that we just did, except in reverse.</p>
<ol>
<li>Take the code we just built and remove the <code>on_ready </code>event from the bot.</li>
<li><p>Add a startup time listener that starts the bot in a new background task.</p>
<pre><code>@app.before_server_start
async def startup_wadsworth(app, _):
    app.ctx.wadsworth = client
    app.add_task(client.start(app.config.DISCORD_TOKEN))
    while True:
        if client.is_ready():
            app.ctx.general = client.get_channel(app.config.GENERAL_CHANNEL_ID)
            await app.ctx.general.send(&quot;Wadsworth, reporting for duty&quot;)
            break
        await asyncio.sleep(0.1)</code></pre>
<p>In this listener, we are also doing the same thing we did in the previous example. We setup <code>app.ctx.wadsworth</code> and <code>app.ctx.general</code> so that they are easily accessible for use later on in the build. Also, we want to send a message when Wadsworth is online and ready to work. Yes, we could do this from the bot using <code>on_ready </code>as before, but we can also do this from Sanic. In the above code, we create a loop to check for the state of the bot. Once it is ready, we will send the message and close out the loop.</p></li>
<li><p>The next thing we need to make sure to do is to properly close the bot connection. We will do that in a shutdown listener.</p>
<pre><code>@app.before_server_stop
async def shutdown(app, _):
    await client.close()</code></pre></li>
</ol>
<p>Now, you have full capability to run your bot from Sanic. This should behave exactly as before, but you have the full power of running your application with the Sanic CLI as we have throughout the rest of this book. Go ahead and fire it up now:</p>
<pre><code>$ sanic server:app -p 7777 --debug --workers=2</code></pre>
<p>This pattern of nesting other <code>asyncio </code>applications has broader applicability than just running Discord bots and Sanic together. It also allows us to run multiple Sanic applications in the same process, albeit on different ports. This is what we are going to do next.</p>
</section>
</section>
<section id="nested-sanic-applications-running-sanic-inside-sanic-to-create-a-http-proxy" class="level2" data-number="11.6">
<h2 data-number="11.6">Nested Sanic applications: running Sanic inside Sanic to create a HTTP proxy</h2>
<p>Running Sanic from within Sanic seems a bit like those Russian nesting dolls. While it may initially seem like an amazing thought experiment, it does have some real-world applicability. The most obvious example of running two instances of Sanic together like this would be to create your own HTTP to HTTPS proxy. That is what we are going to do now. Or, at least sort of.</p>
<p>The caveat that I want to add to this is that this example will use a <strong>self-signed certificate</strong>. That means that it is not suitable for production use. You should look at the section called ___ in Chapter 7 for details on how to properly secure your application using TLS.</p>
<p>To begin, we will create two servers. For the sake of simplicity, one will be server.py (your main application running HTTPS over port 443) and the other will be redirect.py (the HTTP to HTTPS proxy running on port 80).</p>
<ol>
<li><p>We will start by creating our self-signed certificate. If you are on a Windows machine, you might need to lookup how to do this on your OS.</p>
<pre><code>$ openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 365</code></pre></li>
<li><p>Next, we start building our Sanic application in server.py with a simple factory pattern. The code for this build is available at ___.</p>
<pre><code>from sanic import Sanic
from wadsworth.blueprints.view import bp
from wadsworth.blueprints.info.view import bp as info_view
from wadsworth.applications.redirect import attach_redirect_app
def create_app():
    app = Sanic(&quot;MainApp&quot;)
    app.config.SERVER_NAME = &quot;localhost:8443&quot;
    app.blueprint(bp)
    app.blueprint(info_view)
    attach_redirect_app(app)
    return app</code></pre>
<blockquote>
<p><strong>TIP</strong></p>
<p>The first thing that I would like to point out is the usage of <code>SERVER_NAME</code>. This is a configuration value that is unset out of the box in Sanic. It is usually something that you should use in all of your applications. It is a helpful value used by Sanic behind the scenes in a few locations. For our purpose in this example, we want to use it to help us generate URLs further down the road with app.url_for. The value should be the domain name of your application, plus the port (if it is not using a standard 80 or 443). You should not include the http:// or https://.</p>
</blockquote>
<p>What is <code>attach_redirect_app</code>? This is another application factory. But it will work a little bit differently since it will also act to nest the resitect app inside of the <code>MainApp</code>.The last thing worth pointing out is that there is the Blueprint Group bp that we will attach all of our Blueprints to. Except, the <code>info_view </code>will be separate. More on that in just a bit.</p></li>
<li><p>We begin the second factory pattern: <code>attach_redirect_app </code>at <code>redirect.py</code>.</p>
<pre><code>def attach_redirect_app(main_app: Sanic):
    redirect_app = Sanic(&quot;RedirectApp&quot;)
    redirect_app.blueprint(info_view)
    redirect_app.blueprint(redirect_view)
    redirect_app.ctx.main_app = main_app</code></pre>
<p>We are attaching two views: the same <code>info_view </code>that we just attached to the <code>MainApp</code>, and the <code>redirect_view </code>that will do our redirection logic. We will look at that once we are done with the factory and server here in <code>redirect.py</code>.Also, please notice that we are attaching the <code>main_app </code>to the <code>redirect_app.ctx </code>for later retrieval. As we have learned, passing objects through the ctx is the preferred method for handling objects that need to be referenced throughout an application.</p></li>
<li><p>Next we will add a few listeners to the <code>MainApp</code>. This is going to happen inside of the <code>attach_redirect_app </code>factory. There are some software architects that may dislike my nesting of logical concerns together, we are going to silence the critics and do it anyway because what we are after is necessarily tightly couple logic that will be easy for us to debug and update in the future.</p>
<pre><code>def attach_redirect_app(main_app: Sanic):
    ...
    @main_app.before_server_start
    async def startup_redirect_app(main: Sanic, _):
        app_server = await redirect_app.create_server(
            port=8080, return_asyncio_server=True
        )
        if not app_server:
            raise ServerError(&quot;Failed to create redirect server&quot;)
        main_app.ctx.redirect = app_server
        main_app.add_task(runner(redirect_app, app_server))</code></pre>
<p>Here we are dropping down into some lower level operations of the Sanic server. We basically need to mimic what the Sanic CLI and app.run do, except inside the confines of the already existing loop.When you run a Sanic server instance, it will block the process until shutdown. But we need to have two servers running. Therefore, the <code>RedirectApp </code>server needs to be run in a background task. We accomplish that by pushing off the work of running the server by using add_task. We will come back to runner when we are done with the factory.</p></li>
<li><p>The <code>RedirectApp </code>also needs to be turned down. Therefore, we attach to the MainApp another listener to do that.</p>
<pre><code>def attach_redirect_app(main_app: Sanic):
    ...
    @main_app.after_server_stop
    async def shutdown_redirect_app(main: Sanic, _):
        await main.ctx.redirect.before_stop()
        await main.ctx.redirect.close()
        for connection in main.ctx.redirect.connections:
            connection.close_if_idle()
        await main.ctx.redirect.after_stop()
        redirect_app.is_stopping = False
This includes all of the major elements you need for turning down Sanic. It is a little bit basic and if you are implementing this in the real world, you might want to take a look into how Sanic server performs a graceful shutdown to close out any existing requests.
We now turn to runner, the function that we passed off to be run in a background task to run the RedirectApp.
async def runner(app: Sanic, app_server: AsyncioServer):
    app.is_running = True
    try:
        app.signalize()
        app.finalize()
        ErrorHandler.finalize(app.error_handler)
        app_server.init = True
        await app_server.before_start()
        await app_server.after_start()
        await app_server.serve_forever()
    finally:
        app.is_running = False
        app.is_stopping = True</code></pre>
<p>Again, what we are accomplishing are some of the high level steps that Sanic takes under the hood to stand up a server. It does run <code>before_start </code>slightly out of order. Typically, that would happen before <code>create_server</code>. The impact is minimal. Since our <code>RedirectApp </code>does not even use any of the even listeners, we could do without <code>before_start </code>and <code>after_start </code>(and the shutdown events too).</p></li>
<li><p>Now to the important part of the application: the redirection view.</p>
<pre><code>from sanic import Blueprint, Request, response
from sanic.constants import HTTP_METHODS
bp = Blueprint(&quot;Redirect&quot;)
@bp.route(&quot;/&lt;path:path&gt;&quot;, methods=HTTP_METHODS)
async def proxy(request: Request, path: str):
    return response.redirect(
        request.app.url_for(
            &quot;Redirect.proxy&quot;,
            path=path,
            _server=request.app.ctx.main_app.config.SERVER_NAME,
            _external=True,
            _scheme=&quot;https&quot;,
        ),
        status=301,
    )</code></pre>
<p>This route is going to be fairly all-encompassing. It basically will accept every endpoint that remains unmatched, not matter what HTTP method is used. This is accomplished using the path parameter type and passing the <code>HTTP_METHODS</code> constant to the route definition.The job is to redirect the exact same request to the https version. You could do this a few ways. For example, the following works:</p>
<pre><code>f&quot;https://{request.app.ctx.main_app.config.SERVER_NAME}{request.path}&quot;</code></pre>
<p>However, for me and my brain, I like to use <code>url_for</code>. If you prefer the alternative: you do you. The redirect function is a convenience method for generating the appropriate redirection response. Since our use case calls for a redirection from http to https, we use a 301 redirect to indicate that this is a permanent (and not temporary) redirection. Let’s see it in action.</p></li>
<li><p>To run our application, we need to use the TLS certificates that we generated.</p>
<pre><code>$ sanic wadsworth.applications.server:create_app \
    --factory --workers=2 --port=8443 \
    --cert=./wadsworth/certs/cert.pem \
    --key=./wadsworth/certs/key.pem</code></pre>
<p>We are running the application again using the CLI. Make sure to use <code>--factory </code>since we are passing it a callable. Also, we are telling Sanic where it can find the certificate and key that were generated for the TLS encryption.</p></li>
<li><p>Once that is running, we jump into a terminal to test with <code>curl</code>. First we will make sure that both applications are accessible:</p>
<pre><code>$ curl http://localhost:8080/info
{&quot;server&quot;:&quot;RedirectApp&quot;}
That looks right.
$ curl -k https://localhost:8443/info   
{&quot;server&quot;:&quot;MainApp&quot;}</code></pre>
<p>This also looks right. Please note that I included <code>-k </code>in the curl command. This is because of the self-signed certificate we created. Since it is not from an official trusted Certificate Authority, <code>curl </code>will not automatically issue the request until you specifically tell it that the certificate is okay.Something that is really interesting about this is that the <code>/info </code>endpoint is <em>NOT</em> defined twice. If you look in the source code, you will see that it is a single blueprint that has been applied to both applications. Super handy.</p></li>
<li><p>And now we come to the final test: the redirection.</p>
<pre><code>$ curl -kiL http://localhost:8080/v1/hello/Adam      
HTTP/1.1 301 Moved Permanently
Location: https://localhost:8443/v1/hello/Adam
content-length: 0
connection: keep-alive
content-type: text/html; charset=utf-8
HTTP/1.1 200 OK
content-length: 16
connection: keep-alive
content-type: application/json
{&quot;hello&quot;:&quot;Adam&quot;}</code></pre></li>
</ol>
<p>Make sure to notice that we are hitting the 8080 port, which is the <code>RedirectApp</code>. We again use <code>-k </code>to tell curl to not worry about certificate validation. We also use <code>-L </code>to tell <code>curl </code>to follow forward any redirections. Lastly, we add <code>-i </code>to output the full HTTP responses so that we can see what is going on.</p>
<p>As you can see from the above response, we generated an appropriate 301 redirection and sent the user on to the https version, which greeted me so nicely by first name.</p>
<p>And that’s it: a simple HTTP to HTTPS redirection application running Sanic inside Sanic.</p>
</section>
<section id="summary-9" class="level2" data-number="11.7">
<h2 data-number="11.7">Summary</h2>
<p>What I love about building web applications is the chance to build solutions to problems. For example, earlier in this chapter we had the problem of wanting to run a Javascript development server from Sanic. If you put five different developers on that problem, you might end up with five different solutions. I believe that building web applications is on some level an art form. That is to say that it is not a strict field that must be solved in only one <em>obvious</em> way. Rather, what is obvious can only be determined given the unique circumstances and parameters surrounding your build.</p>
<p>Of course, what we have built here is just the tip of the iceberg for what is possible with Sanic. The choices displayed are both some popular use cases, and also some use cases that might not be so straightforward. I hope that you can take some of the ideas and patterns and put them to good use. By reading this book and internalizing the examples in this Chapter, I hope that I have helped to stimulate the creative ideas of application building for you.</p>
<p>If we mash up all of the ideas from this chapter into a single application, you would end up with a PWA powered by Sanic using distributed websocket feeds and a GraphQL API, that also runs a Discord bot. My point is that creating features to implement in your application cannot be done in a vacuum. You must consider other parts of your architecture when deciding on how to build something. This chapter is meant to help see some of my thought process when I tackled these problems.</p>
<p>As we near the conclusion of this book, the last things we need to do is actually pull together a lot of what we know into a single deployable application. That is what we do next in Chapter 11: build a fully functional, production grade Sanic application.</p>
</section>
</section>
</body>
</html>
