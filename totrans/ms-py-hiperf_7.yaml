- en: Chapter 7. Lightning Fast Number Crunching with Numba, Parakeet, and pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Number crunching is a topic specific to the programming world. However, given
    that Python is so often used for scientific research and data science problems,
    number crunching ends up being a very common topic in the Python world.
  prefs: []
  type: TYPE_NORMAL
- en: That being said, we could just as easily implement our algorithms using the
    information from the earlier six chapters, and we would most likely end up with
    pretty fast and performant code. Again, that information is meant to be for generic
    use cases. There will always be something to say about optimizing for a particular
    case.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll cover three options that will help us write faster and
    more optimized code focused on scientific problems. For each one, we'll go over
    the basic installation instructions. We will also look at some code samples showing
    the benefits of each option.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tools we''ll review in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Numba**: This is a module that allows you to write high-performance functions
    in pure Python by generating optimized machine code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parakeet**: This is a runtime compiler for scientific operations written
    in a subset of Python. It is ideal for expressing numerical computations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pandas**: This is a library that provides a set of high-performance data
    structures and analysis tools.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Numba
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Numba ([http://numba.pydata.org/](http://numba.pydata.org/)) is a module that
    allows you to indicate (via decorators) to the Python interpreter which functions
    should be translated into machine code. Numba thus provides equivalent performance
    to C or Cython without the need to either use a different interpreter or actually
    code in C.
  prefs: []
  type: TYPE_NORMAL
- en: The module will generate optimized machine code just by requiring it. It can
    even be compiled to run on either CPU or GPU hardware.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a very basic example taken from their official site, showing how to
    use it. We''ll go into more detail in a bit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that even though the promise of Numba sounds impressive, the library is
    meant to optimize operations on arrays. It is considerably tied to NumPy (which
    we'll review shortly). So, not every function will be optimizable by it, and using
    it might even hurt performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, let''s take a look at a similar example, one that doesn''t use
    NumPy and accomplishes a similar task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code has the following execution times, depending on whether
    we keep the `@jit` line or not:'
  prefs: []
  type: TYPE_NORMAL
- en: 'With the `@jit` line on: 0.3 seconds'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Without the `@jit` line: 0.1 seconds'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are actually two ways to install Numba: you can either use the `conda`
    package manager from Anaconda, or you can just clone the GitHub repo and compile
    it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''re going for the `conda` approach, you can install the command-line
    tool called `miniconda` (which can be downloaded from [http://conda.pydata.org/miniconda.html](http://conda.pydata.org/miniconda.html)).
    After installing it, you can just use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output from this command. The command lists
    all packages that will be installed or updated, specifically `numpy` and `llvmlite`,
    which are direct dependencies from Numba:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installation](img/B02088_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If, on the other hand, you want to use the source code, you could clone the
    repo by using this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll need to have `numpy` and `llvmlite` installed as well. After that,
    you can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the preceding command will succeed even if you don't have the requirements
    installed. However, you won't be able to use Numba unless you install them.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to check whether your installation was successful, you can do a simple
    check from the Python REPL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Using Numba
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that you have managed to install Numba, let''s take a look at what we can
    do with it. The main features provided by this module are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: On-the-fly code generation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Native code generation for both CPU and GPU hardware
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration with Python's scientific software, thanks to the Numpy dependency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Numba's code generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When it comes to code generation, the main feature of Numba is its `@jit` decorator.
    Using it, you can mark a function for optimization under Numba's JIT compiler.
  prefs: []
  type: TYPE_NORMAL
- en: We already talked about the benefits of having a JIT compiler in the previous
    chapter, so we won't go into the details here. Instead, let's see how to use the
    decorator for our benefit.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several ways to use this decorator. The default one, which is also
    the recommended way, is the one we already showed earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code will cause Numba to generate the optimized code once the
    function is called. It''ll try to infer the types of its attributes and the return
    type of the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If you call the same function with different types, then different code paths
    will be generated and optimized.
  prefs: []
  type: TYPE_NORMAL
- en: Eager compilation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: On the other hand, if you happen to know the types that your function will receive
    (and optionally, return), you could pass those to the `@jit` decorator. Then,
    only that specific case would be optimized.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the added code needed to pass in the function signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the most common types that are used to specify function signatures:'
  prefs: []
  type: TYPE_NORMAL
- en: '`void`: These are used as the return type for functions not returning anything'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`intp` and `uintp`: These are pointer-sized integers, signed and unsigned respectively'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`intc` and `uintc`: These are the C equivalent to the int and unsigned int
    types'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`int8`, `int16`, `int32`, and `int64`: These are the fix-width integers of
    the corresponding bit width (for the unsigned version, just add `u` as a prefix,
    for instance, `uint8`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`float32` and `float64`: These are single and double-precision floating-point
    numbers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`complex64` and `complex128`: These represent single and double-precision complex
    numbers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arrays can also be declared by indexing any of the numeric types, for example,
    `float32[:]` for a one-dimensional floating-point number array and `int32[:,:]`
    for a two-dimensional integer array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other configuration settings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Apart from eager compilation, there are two more options we can pass onto the
    `@jit` decorator. These options will help us force Numba's optimization. They
    are described here.
  prefs: []
  type: TYPE_NORMAL
- en: No GIL
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Whenever our code is optimized using native types (rather than using Python
    types), the GIL (which we discussed in [Chapter 6](ch06.html "Chapter 6. Generic
    Optimization Options"), *Generic Optimization Options*) is no longer necessary.
  prefs: []
  type: TYPE_NORMAL
- en: We have a way of disabling the GIL in such cases. We can pass the `nogil=True`
    attribute to the decorator. This way, we can run Python code (or Numba code) concurrently
    with other threads.
  prefs: []
  type: TYPE_NORMAL
- en: That being said, remember that if you don't have the GIL limitation, then you
    will have to deal with the common problems of multithreaded systems (consistency,
    synchronization, race conditions, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: NoPython mode
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This option will let us set the compilation mode of Numba. By default, it will
    try to jump between modes. It will try to decide the best mode possible depending
    on the code of the optimized function.
  prefs: []
  type: TYPE_NORMAL
- en: There are two modes that are available. On one hand, there is `object` mode.
    It generates code capable of handling all Python objects and uses the C API to
    perform operations on those objects. On the other hand, the `nopython` mode generates
    much faster code by avoiding the calls to the C API. The only problem with it
    is that only a subset of functions and methods are available to be used.
  prefs: []
  type: TYPE_NORMAL
- en: The `object` mode will not generate faster code unless Numba can take advantage
    of loop-jitting (which means that a loop can be extracted and compiled in `nopython`
    mode).
  prefs: []
  type: TYPE_NORMAL
- en: 'What we can do is force Numba to go into `nopython` mode and raise an error
    if such a thing is not possible. This can be done using these lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The issue with the `nopython` mode is that it has certain restrictions, apart
    from the limited subset of Python it supports:'
  prefs: []
  type: TYPE_NORMAL
- en: The native types used for all values inside the function have to be capable
    of being inferred
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No new memory can be allocated inside the function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As an added extra, for loop-jitting to take place, the to-be-optimized loops
    can't have a return statement inside. Otherwise, they won't be eligible for optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s now look at an example of how this will look for our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding example is taken from the Numba site. It shows a function that
    is eligible for loop-jitting, also called loop-lifting. To make sure it works
    as expected, we can use the Python REPL as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![NoPython mode](img/B02088_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Alternatively, we can also call the `inspect_types` method directly from our
    code. The benefit of the latter is that we'll also have access to the source code
    of our functions. This is a great advantage when trying to match Numba-generated
    instructions to lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding output is useful to understand the behind-the-scenes action that
    goes on when we optimize our code with Numba. More specifically, we can understand
    how it infers the types, whether there is any automatic optimization going on,
    and basically, how many instructions each Python line is translated into.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the output we would get from calling the `inspect_types`
    method from within our code (which is considerably more detailed than using the
    REPL):'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the following code is a reduced version of the entire output. If you
    want to study it completely, you need to run the command on your computer.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In order to understand the preceding output, notice how every commented block
    starts with the line number of the original source code. It then follows with
    the instructions generated by that line, and finally, you'll see the uncommented
    Python line you wrote.
  prefs: []
  type: TYPE_NORMAL
- en: Notice the `LiftedLoop` line. In this line, you can see the automatic optimization
    done by Numba. Also, notice the type inferred by Numba at the end of most lines.
    Whenever you see a `pyobject` property, it means that it is not using a native
    type. Instead, it is using a generic object that wraps all Python types.
  prefs: []
  type: TYPE_NORMAL
- en: Running your code on the GPU
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As it's been already mentioned, Numba provides support to run our code on both
    CPU and GPU hardware. This, in practice, would allow us to improve the performance
    of certain computations by running them in an environment better suited for parallel
    computation than the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, Numba supports CUDA programming ([http://www.nvidia.com/object/cuda_home_new.html](http://www.nvidia.com/object/cuda_home_new.html))
    by translating a subset of Python functions into CUDA kernels and devices following
    the CUDA execution model.
  prefs: []
  type: TYPE_NORMAL
- en: CUDA is a parallel computing platform and programming model invented by Nvidia.
    It enables considerable speed boosts by harnessing the power of GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: GPU programming is a topic that could most likely fill an entire book, so we
    won't go into details here. Instead, we'll just mention that Numba possesses this
    capability and that it can be achieved using the `@cuda.jit` decorator. For full
    documentation on this subject, refer to the official documents at [http://numba.pydata.org/numba-doc/0.18.2/cuda/index.html](http://numba.pydata.org/numba-doc/0.18.2/cuda/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: The pandas tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The second tool that we'll discuss in this chapter is called pandas ([http://pandas.pydata.org/](http://pandas.pydata.org/)).
    It is an open source library that provides high-performance, easy-to-use data
    structures, and data-analysis tools for Python.
  prefs: []
  type: TYPE_NORMAL
- en: This tool was invented back in 2008 by developer Wes McKinney while needing
    a performant solution to perform quantitative analysis on financial data. The
    library has become one of the most popular and active projects in the Python community.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to note regarding the performance of code written using pandas is
    that parts of its critical code paths were written using Cython (we covered Cython
    in [Chapter 6](ch06.html "Chapter 6. Generic Optimization Options"), *Generic
    Optimization Options*).
  prefs: []
  type: TYPE_NORMAL
- en: Installing pandas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given the popularity of pandas, there are many ways to install it onto your
    system. It all depends on the type of setup you have.
  prefs: []
  type: TYPE_NORMAL
- en: The recommended way is to directly install the Anaconda Python distribution
    ([docs.continuum.io/anaconda/](http://docs.continuum.io/anaconda/)), which comes
    packed with pandas and the rest of the SciPy stack (such as NumPy, Matplotlib,
    and so on). This way, by the time you're done, you'd have installed over 100 packages
    and downloaded several 100 megabytes of data during the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'If, on the other hand, you don''t want to deal with the full Anaconda distribution,
    you could use `miniconda` (which we already covered earlier when discussing Numba''s
    installation). With this approach, you can use the `conda` package manager by
    following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new environment in which you can install a new version of Python using
    this line of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Enable that environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, install pandas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Additionally, pandas can be installed using the `pip` command-line tool (probably,
    the easiest and most compatible way of doing it) using this line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, one more option could be installing it using your OS''s package manager,
    given that the package is available:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Distribution | Repo link | Installation method |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Debian | [packages.debian.org/search?keywords=pandas&searchon=names&suite=all&section=all](http://packages.debian.org/search?keywords=pandas&searchon=names&suite=all&section=all)
    |'
  prefs: []
  type: TYPE_TB
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Ubuntu | [http://packages.ubuntu.com/search?keywords=pandas&searchon=names&suite=all&section=all](http://packages.ubuntu.com/search?keywords=pandas&searchon=names&suite=all&section=all)
    |'
  prefs: []
  type: TYPE_TB
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| OpenSUSE and Fedora | [http://software.opensuse.org/package/python-pandas?search_term=pandas](http://software.opensuse.org/package/python-pandas?search_term=pandas)
    |'
  prefs: []
  type: TYPE_TB
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: If the preceding options fail and you choose to install pandas from source,
    you can get the instructions from their website at [http://pandas.pydata.org/pandas-docs/stable/install.html](http://pandas.pydata.org/pandas-docs/stable/install.html).
  prefs: []
  type: TYPE_NORMAL
- en: Using pandas for data analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the world of big data and data analytics, having the right tools for the
    job means having the upper hand (of course, this is just one side of the story;
    the other one is knowing how to use them). For data analysis and, more specifically,
    for ad hoc tasks and data cleanup processes, one would normally use a programming
    language. A programming language would provide considerably more flexibility than
    a standard tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'That being said, there are two languages that lead this particular performance
    race: R and Python. In the case of Python, this might come as a bit of a shock
    for some, since we''ve been showing nothing but evidence that Python by itself
    is not fast enough when it comes to number crunching. This is why libraries such
    as pandas are created.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It provides tools designed to ease and simplify the task commonly known as
    "data wrangling", such as:'
  prefs: []
  type: TYPE_NORMAL
- en: The ability to load big data files into memory and stream out
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple integration with `matplotlib` ([http://matplotlib.org/](http://matplotlib.org/)),
    which enables it to create interactive plots with very few lines of code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple syntax to deal with missing data, dropping fields, and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's now look at a very simple and quick example of how using pandas can benefit
    the performance of your code as well as improve the syntax of your programs. The
    following code grabs a CSV file, with a portion of the export (a 500 MB file)
    from the **311 service requests from 2010 to present** taken from the NYC OpenData
    site ([https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9)).
  prefs: []
  type: TYPE_NORMAL
- en: 'It then tries to simply calculate the number of records per zip code using
    both plain Python and pandas code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The `process` function is very simple. It has only five lines of code. It loads
    the file, does a bit of processing (mainly manual grouping and counting), and
    finally, it sorts the results and returns the first 10 of them. As an added bonus,
    we use the `defaultdict` data type, which we mentioned a few chapters ago as a
    possible performance improvement in these cases.
  prefs: []
  type: TYPE_NORMAL
- en: On the other side, the `process_pandas` function does essentially the same thing,
    only with pandas. We have some more lines of code, but they are quite simple to
    understand. They're clearly "data-wrangling oriented", as you can see that there
    are no loops declared. We can even access the columns by name automatically and
    apply functions over those groups of records without having to manually iterate
    over them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using pandas for data analysis](img/B02088_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, there is a 3-second improvement on the performance of our algorithm
    when we simply reimplement it in pandas. Let''s now dig a bit deeper into the
    API of pandas in order to get even better numbers. There are two major improvements
    we can make to our code, and they''re both related to the `read_csv` method, which
    uses a lot of parameters. Two of these parameters are of real interest to us:'
  prefs: []
  type: TYPE_NORMAL
- en: '`usecols`: This will only return the columns we want, effectively helping us
    deal with only 2 columns out of the 40+ our dataset has. This will also help us
    get rid of the logic that we have to drop the columns before returning the results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`converters`: This allows us to auto-convert data with a function, instead
    of calling the apply method, as we will do now.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our new function looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s right. Only two lines of code! The reader will do all the work for
    us. Then, we need to simply group, count, and sort. Now, check out how this looks
    compared to our previous results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using pandas for data analysis](img/B02088_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: That's a 10-second improvement on the performance of our algorithm and considerably
    less code to deal with, otherwise known as a "win-win" situation.
  prefs: []
  type: TYPE_NORMAL
- en: An added bonus to our code is that it scales. The pandas-based function can
    deal with a 5.9 GB file in just 30 seconds with no changes. On the other hand,
    our pure Python code won't even load that file in that time, let alone process
    it if we don't have enough resources.
  prefs: []
  type: TYPE_NORMAL
- en: Parakeet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This one is the most specific tool yet to deal with numbers in Python. It is
    very specific because it only supports a very narrow subset of the resulting combination
    of Python and NumPy. So, if you're dealing with anything outside that universe,
    this might not be an option for you, but if you can fit your solution into it,
    then keep on reading.
  prefs: []
  type: TYPE_NORMAL
- en: 'To be more specific about the limited universe that Parakeet supports (normally
    useful only to express numerical computations), here is a short list:'
  prefs: []
  type: TYPE_NORMAL
- en: Types supported by Python are numbers, tuples, slices, and NumPy's arrays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parakeet follows the upcasting rule, that is, whenever two values of different
    types try to reach the same variable, they'll be upcast into a unifying one. For
    instance, the Python expression `1.0 if b else false` would translate to `1.0
    if b else 0.0`, but when automatic casting isn't possible, such as `1.0 if b else
    (1,2)`, then an uncatchable exception (see next point) will be raised during compilation
    time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Catching or even raising exceptions isn't possible in Parakeet; neither are
    break and continue statements. This is because Parakeet represents programs using
    structured SSA ([http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.4503](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.4503)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Array broadcasting (a feature of NumPy) is partially implemented by inserting
    explicit map operators based on the types of array arguments. This is a limited
    implementation because it can't really handle an expansion of dimensions (such
    as broadcasting 8 x 2 x 3 and 7 x 2 arrays).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is only a small subset of the built-in functions of Python and NumPy that
    have been implemented. The complete list can be seen at [https://github.com/iskandr/parakeet/blob/master/parakeet/mappings.py](https://github.com/iskandr/parakeet/blob/master/parakeet/mappings.py).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: List comprehension expressions are treated as array comprehensions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Parakeet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The installation of Parakeet is simple enough. There are no hard-to-get requirements
    if you want to go with the `pip` route. Simply type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: And you're done!
  prefs: []
  type: TYPE_NORMAL
- en: 'If, on the other hand, you want to directly try the source code approach, you
    would need some other packages installed beforehand. Here is a list of these packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Python 2.7**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dsltools** ([https://github.com/iskandr/dsltools](https://github.com/iskandr/dsltools))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nose** for running the tests ([https://nose.readthedocs.org/en/latest/](https://nose.readthedocs.org/en/latest/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NumPy** ([http://www.scipy.org/install.html](http://www.scipy.org/install.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**appDirs** ([https://pypi.python.org/pypi/appdirs/](https://pypi.python.org/pypi/appdirs/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gcc 4.4+** for the OpenMP back-end, which is the default one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you're on a Windows box, you would have better luck if it's a 32-bit machine.
    Otherwise, you might be out of luck since there is no official documentation on
    the subject.
  prefs: []
  type: TYPE_NORMAL
- en: If you are a OS X user you'll probably want to install a more up-to-date version
    of the C compiler using HomeBrew, since either clang or the installed version
    of `gcc` might not be updated enough.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the prerequisites are met, simply download the code from: [https://github.com/iskandr/parakeet](https://github.com/iskandr/parakeet)
    and run the following command (from within the code''s folder):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: How does Parakeet work?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instead of going deep into the details about the theory behind Parakeet, let's
    simply see how to use it to optimize our code. This will help you get a feel of
    the module without having to chew through all the documentation.
  prefs: []
  type: TYPE_NORMAL
- en: The main construct of this library is a decorator that you can apply to your
    functions, so Parakeet can take control and optimize your code if possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our simple test, let''s take one of the example functions presented on
    Parakeet''s website and run a simple test against a `4000` * `4000` random floating-point
    list. The code will run the same function in both an optimized way using Parakeet,
    and in an unoptimized way. Then, it will measure the time each one takes to process
    the exact same input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'In an i7 processor, with 8 GB of RAM, this is the performance we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How does Parakeet work?](img/B02088_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot shows the amazing performance boost we get in this
    particular function (which complies with the required subset of Python supported
    by Parakeet).
  prefs: []
  type: TYPE_NORMAL
- en: Simply put, the decorated function is being used as a template from which several
    type-specialized functions are created, one for each input type (in our case,
    we only need one). It is these new functions that get optimized in several different
    ways by Parakeet before getting translated into native code.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that even though the performance gain is amazing, Parakeet only supports
    a very limited version of Python, so it is not really meant to be a general purpose
    optimizer (quite the opposite actually).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we covered three alternatives to data processing with Python.
    We covered specific use cases (but with amazing benefits), such as Parakeet, and
    others more generic ones, such as pandas and Numba. For all three of them, we
    covered the basics: description, installation, and an example. There is a lot
    more to discover for each one, depending on your specific needs. However, the
    information provided here should be enough to start you in the right direction.'
  prefs: []
  type: TYPE_NORMAL
- en: For the next and final chapter, we'll cover a practical example of a script
    in need of optimization. We'll try to apply everything (or as much as makes sense)
    that we've covered so far in the book.
  prefs: []
  type: TYPE_NORMAL
