<html><head></head><body>
		<div><h1 id="_idParaDest-131"><em class="italic"><a id="_idTextAnchor169"/>Chapter 5</em>: Testing and Automation with Python</h1>
			<p>Software testing is the process of validating an application or a program as per user requirements or desired specifications and evaluating the software for scalability and optimization goals. Validating software as a real user takes a long time and is not an efficient use of human resources. Moreover, testing is not performed only one or two times, but it is a continuous process as a part of software development. To rescue the situation, test automation is recommended for all sorts of testing. <strong class="bold">Test automation</strong> is a set<a id="_idIndexMarker487"/> of programs written to validate an application's behavior using different scenarios as input to these programs. For professional software development environments, it is a must that automation tests get executed every time the source code<a id="_idIndexMarker488"/> is updated (also called a <strong class="bold">commit operation</strong>) into a central repository.</p>
			<p>In this chapter, we will study different approaches to automated testing, followed by looking at different types of testing frameworks and libraries that are available for Python applications. Then, we will focus on unit testing and will look into different ways of implementing unit testing in Python. Next, we will study the usefulness of <strong class="bold">test-driven development</strong> (<strong class="bold">TDD</strong>) and the right way to implement it. Finally, we will focus on automated <strong class="bold">continuous integration</strong> (<strong class="bold">CI</strong>) and will look into the challenges of implementing it robustly and efficiently. This chapter will help you understand the concepts of automated testing in Python at various levels.</p>
			<p>We will cover the following topics in this chapter:</p>
			<ul>
				<li>Understanding various levels of testing</li>
				<li>Working with Python test frameworks</li>
				<li>Executing TDD</li>
				<li>Introducing automated CI</li>
			</ul>
			<p>At the end of this chapter, you will not only understand different types of test automation but will also be able to write unit tests using one of the two popular test frameworks.</p>
			<h1 id="_idParaDest-132"><a id="_idTextAnchor170"/>Technical requirements</h1>
			<p>These are the technical requirements for this chapter:</p>
			<ul>
				<li>You need to have installed Python 3.7 or later on your computer.</li>
				<li>You need to register an account with Test PyPI and create an <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>) token under your account.</li>
			</ul>
			<p>The sample code for this chapter can be found at <a href="https://github.com/PacktPublishing/Python-for-Geeks/tree/master/Chapter05">https://github.com/PacktPublishing/Python-for-Geeks/tree/master/Chapter05</a>.</p>
			<h1 id="_idParaDest-133"><a id="_idTextAnchor171"/>Understanding various levels of testing</h1>
			<p>Testing<a id="_idIndexMarker489"/> is performed at various levels based on the application type, its complexity level, and the role of the team that is working on the application. The different levels of testing include the following:</p>
			<ul>
				<li>Unit testing </li>
				<li>Integration testing</li>
				<li>System testing</li>
				<li>Acceptance testing </li>
			</ul>
			<p>These different levels of testing are applied in the order shown here:</p>
			<div><div><img src="img/B17189_05_01.jpg" alt="Figure 5.1 – Different levels of testing during software development&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.1 – Different levels of testing during software development</p>
			<p>These testing levels are described in the next subsections.</p>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor172"/>Unit testing</h2>
			<p>Unit testing<a id="_idIndexMarker490"/> is a type of testing that is focused on the smallest<a id="_idIndexMarker491"/> possible unit level. A unit corresponds to a unit of code that can be a function in a module or a method in a class, or it can be a module in an application. A unit test executes a single unit of code in isolation and validates that the code is working as expected. Unit testing is a technique used by developers to identify bugs at the early stages of code development and fix them as part of the first iteration of the development process. In Python, unit testing mainly targets a particular class or module without involving dependencies.</p>
			<p>Unit tests are developed by application<a id="_idIndexMarker492"/> developers and can be performed at any time. Unit testing is a kind of <code>pyunit</code> (<code>unittest</code>), <code>pytest</code>, <code>doctest</code>, <code>nose</code>, and a few others.</p>
			<h2 id="_idParaDest-135"><a id="_idTextAnchor173"/>Integration testing</h2>
			<p>Integration testing is about testing<a id="_idIndexMarker493"/> individual units of a program<a id="_idIndexMarker494"/> collectively in the form of a group. The idea behind this type of testing is to test the combination of different functions or modules of an application together to validate the interfaces between the components and the data exchange between them.</p>
			<p>Integration testing is typically done by testers and not by developers. This type of testing starts after the unit testing process, and the focus of this testing is to identify the integration problem when different modules or functions are used together. In some cases, integration<a id="_idIndexMarker495"/> testing requires<a id="_idIndexMarker496"/> external resources or data that may not be possible to provide in a development environment. This limitation can be managed by using mock testing, which provides replacement mock objects for external or internal dependencies. The mock objects simulate the behavior of the real dependencies. Examples of mock testing can be sending an email or making a payment using a credit card.</p>
			<p>Integration testing is a kind of <strong class="bold">black-box testing</strong>. The libraries and the tools<a id="_idIndexMarker497"/> used for integration testing are pretty much the same as for unit testing, with a difference that the boundaries of tests are pushed further out to include multiple units in a single test.</p>
			<h2 id="_idParaDest-136"><a id="_idTextAnchor174"/>System testing</h2>
			<p>The boundaries of system<a id="_idIndexMarker498"/> testing are further pushed out to the system level, which may be a full-blown module or an application. This type of testing validates<a id="_idIndexMarker499"/> the application functionality from an <strong class="bold">end-to-end</strong> (<strong class="bold">E2E</strong>) perspective.</p>
			<p>System tests<a id="_idIndexMarker500"/> are also developed by testers but after completing the integration testing process. We can say that integration testing is a prerequisite for system testing; otherwise, a lot of effort will be repeated while performing system testing. System testing can identify potential problems but does not pinpoint the location of the problem. The exact root cause of the problem is typically identified by integration testing or even by adding more unit tests.</p>
			<p>System testing is also a type of black-box testing and can leverage the same libraries that are available for integration testing.</p>
			<h2 id="_idParaDest-137"><a id="_idTextAnchor175"/>Acceptance testing</h2>
			<p>Acceptance testing<a id="_idIndexMarker501"/> is end-user testing before accepting the software for day-to-day use. Acceptance testing<a id="_idIndexMarker502"/> is not commonly a candidate for automation testing, but it is worth using automation for acceptance testing in situations where application users have to interact with the product<a id="_idIndexMarker503"/> using an API. This testing is also called <strong class="bold">user acceptance testing</strong> (<strong class="bold">UAT</strong>). This type of testing can be easily mixed up with system testing but it is different in that it ensures the usability of the application from a real user's point of view. There are also<a id="_idIndexMarker504"/> further two types of acceptance testing: <strong class="bold">factory acceptance testing </strong>(<strong class="bold">FAT</strong>) and <strong class="bold">operational acceptance testing</strong> (<strong class="bold">OAT</strong>). The former is more popular from a hardware point<a id="_idIndexMarker505"/> of view, and the latter<a id="_idIndexMarker506"/> is performed by the operation<a id="_idIndexMarker507"/> teams, who are responsible for using the product in production environments.</p>
			<p>Additionally, we also hear about <strong class="bold">alpha</strong> and <strong class="bold">beta</strong> testing. These are also user-level testing<a id="_idIndexMarker508"/> approaches and are not meant<a id="_idIndexMarker509"/> for test automation. Alpha testing is performed by developers and internal staff to emulate actual user behavior. Beta testing<a id="_idIndexMarker510"/> is performed by customers or actual users for early feedback before declaring <strong class="bold">general availability</strong> (<strong class="bold">GA</strong>) of the software.</p>
			<p>We also use the term <strong class="bold">regression testing</strong> in software development. This is basically the execution<a id="_idIndexMarker511"/> of tests every time we make a change in the source code or any internal or external dependency changes. This practice ensures that our product is performing in the same way as it was before making a change. Since regression testing is repeated many times, automating the tests is a must for this type of testing.</p>
			<p>In the next section, we will investigate how to build test cases using the test frameworks in Python.</p>
			<h1 id="_idParaDest-138"><a id="_idTextAnchor176"/>Working with Python test frameworks</h1>
			<p>Python comes with standard<a id="_idIndexMarker512"/> as well as third-party libraries for test automation. The most popular frameworks are listed here:</p>
			<ul>
				<li><code>pytest</code></li>
				<li><code>unittest</code></li>
				<li><code>doctest</code> </li>
				<li><code>nose</code></li>
			</ul>
			<p>These frameworks<a id="_idIndexMarker513"/> can be used for unit testing as well as for integration and system testing. In this section, we will evaluate two of these frameworks: <code>unittest</code>, which is part of the Python standard library, and <code>pytest</code>, which is available as an external library. The focus of this evaluation will be on building test cases (mainly unit tests) using these two frameworks, although the integration and system tests can also be built using the same libraries and design patterns.</p>
			<p>Before we start writing any test cases, it is important to understand what a test case is. In the context of this chapter and book, we can define a test case as a way of validating the outcomes of a particular behavior of a programming code as per the expected results. The development of a test case can be broken down into the following four stages:</p>
			<ol>
				<li value="1"><strong class="bold">Arrange</strong>: This is a stage<a id="_idIndexMarker514"/> where we prepare the environment for our test cases. This does not include any action or validation step. In the test automation<a id="_idIndexMarker515"/> community, this stage is more commonly known as preparing <strong class="bold">test fixtures</strong>. </li>
				<li><strong class="bold">Act</strong>: This is the action<a id="_idIndexMarker516"/> stage that triggers the system we want to test. This action stage results in a change in the system behavior, and the changed state of the system is something we want to evaluate for validation purposes. Note that we do not validate anything at this stage.</li>
				<li><strong class="bold">Assert</strong>: At this stage, we evaluate the results of the <em class="italic">act</em> stage and validate the results against<a id="_idIndexMarker517"/> the expected outcome. Based on this validation, the test automation tools mark the test case as failed or passed. In most of the tools, this validation is achieved using built-in <em class="italic">assert</em> functions or statements. </li>
				<li><strong class="bold">Cleanup</strong>: At this stage, the environment<a id="_idIndexMarker518"/> is cleaned up to make sure the other tests are not impacted by the status changes caused by the <em class="italic">act</em> stage.</li>
			</ol>
			<p>The core stages of a test case are <em class="italic">act</em> and <em class="italic">assert</em>. The <em class="italic">arrange</em> and <em class="italic">cleanup</em> stages are optional but highly recommended. These two stages mainly provide software test fixtures. A test fixture is a type of equipment or device or software that provides an environment to test a device or a machine or software consistently. The term <em class="italic">test fixture</em> is used in the same context for unit testing and integration testing.</p>
			<p>The test frameworks<a id="_idIndexMarker519"/> or libraries provide helper methods or statements to facilitate the implementation of these stages conveniently. In the next sections, we will evaluate the <code>unittest</code> and the <code>pytest</code> frameworks for the following topics:</p>
			<ul>
				<li>How to build base-level test cases for act and assert stages </li>
				<li>How to build test cases with test fixtures</li>
				<li>How to build test cases for exception and error validation</li>
				<li>How to run test cases in bulk</li>
				<li>How to include and exclude test cases in execution</li>
			</ul>
			<p>These topics not only cover the development of a variety of test cases but also include different ways to execute them. We will start our evaluation with the <code>unittest</code> framework. </p>
			<h2 id="_idParaDest-139"><a id="_idTextAnchor177"/>Working with the unittest framework</h2>
			<p>Before starting<a id="_idIndexMarker520"/> to discuss practical examples<a id="_idIndexMarker521"/> with the <code>unittest</code> framework or library, it is important to introduce a few terms and traditional method names related to unit testing and, in particular, to the <code>unittest</code> library. This terminology is used more or less by all test frameworks and is outlined here:</p>
			<ul>
				<li><strong class="bold">Test case</strong>: A test or test case<a id="_idIndexMarker522"/> or test method<a id="_idIndexMarker523"/> is a set of code instructions that are based on a comparison of the current condition versus the post-execution conditions after executing a unit of application code. </li>
				<li><strong class="bold">Test suite</strong>: A test suite<a id="_idIndexMarker524"/> is a collection of test cases<a id="_idIndexMarker525"/> that may have common pre-conditions, initialization steps, and perhaps the same cleanup steps. This foments reusability of test automation code and reduced execution time. </li>
				<li><strong class="bold">Test runner</strong>: This is a Python application<a id="_idIndexMarker526"/> that executes the tests<a id="_idIndexMarker527"/> (unit tests), validates all the assertions defined in the code, and gives the results back to us as a success or a failure. </li>
				<li><strong class="bold">Setup</strong>: This is a special method<a id="_idIndexMarker528"/> in a test suite that will be executed before each test case.</li>
				<li><code>setupClass</code>: This is a special method in a test suite that will be executed only once at the start of the execution of tests in a test suite.</li>
				<li><code>teardown</code>: This is another special method in a test suite that is executed after completion of every test regardless of whether the test passes or fails.</li>
				<li><code>teardownClass</code>: This is another special method in a test suite that is executed only once when all the tests in a suite are completed.</li>
			</ul>
			<p>To write test cases using the <code>unittest</code> library, we are required to implement the test cases as instance methods of a class that must be inherited from the <code>TestCase</code> base class. The <code>TestCase</code> class comes with several methods to facilitate writing as well as executing the test cases. These methods are grouped into three categories, which are discussed next:</p>
			<ul>
				<li><code>setUp</code>, <code>tearDown</code>, <code>setupClass</code>, <code>teardownClass</code>, <code>run</code>, <code>skipTest</code>, <code>skipTestIf</code>, <code>subTest</code>, and <code>debug</code>. These tests<a id="_idIndexMarker529"/> are used by the test runner to execute a piece of code before or after a test case or running a set of test cases, running a test, skipping a test, or running any block of code as a sub-test. In our test case implementation class, we can override these methods. The exact<a id="_idIndexMarker530"/> details of these methods are available as part of the Python documentation at <a href="https://docs.python.org/3/library/unittest.html">https://docs.python.org/3/library/unittest.html</a>.</li>
				<li><strong class="bold">Validation methods</strong> (assert methods): These methods are used to implement test<a id="_idIndexMarker531"/> cases to check for success<a id="_idIndexMarker532"/> or failure conditions and report success or failures for a test case automatically. These methods' name typically starts with an <em class="italic">assert</em> prefix. The list of assert methods is very long. We provide commonly used assert methods here as examples:<div><img src="img/B17189_05_02.jpg" alt="Figure 5.2 – A few examples of assert methods of the TestCase class&#13;&#10;"/></div></li>
			</ul>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 5.2 – A few examples of assert methods of the TestCase class</p>
			<ul>
				<li><code>failureException</code>: This attribute provides an exception raised by a test method. This exception can be used as a superclass to define a custom failure exception with additional information.</p><p>b) <code>longMessage</code>: This attribute determines what to do with a custom message that is passed as an argument with an <code>assert</code> method. If the value of this attribute is set to <code>True</code>, the message is appended to the standard failure message. If this attribute is set to <code>false</code>, a custom message replaces the standard message.</p><p>c) <code>countTestCases()</code>: This method returns the number of tests attached to a test object.</p><p>d) <code>shortDescription()</code>: This method returns a description of a test method if there is any description added, using a docstring.</p></li>
			</ul>
			<p>We have reviewed<a id="_idIndexMarker535"/> the main methods of the <code>TestCase</code> class in<a id="_idIndexMarker536"/> this section. In the next section, we will explore how to use <code>unittest</code> to build unit tests for a sample module or an application.</p>
			<h3>Building test cases using the base TestCase class</h3>
			<p>The <code>unittest</code> library is a standard<a id="_idIndexMarker537"/> Python testing framework<a id="_idIndexMarker538"/> that is highly inspired<a id="_idIndexMarker539"/> by the <strong class="bold">JUnit</strong> framework, a popular testing framework in the Java community. Unit tests are written in separate Python files and it is recommended to make the files part of the main project. As we discussed in <a href="B17189_02_Final_PG_ePub.xhtml#_idTextAnchor086"><em class="italic">Chapter 2</em></a>, <em class="italic">Using Modularization to Handle Complex Projects</em>, in the <em class="italic">Building a package</em> section, the <strong class="bold">Python Packaging Authority</strong> (<strong class="bold">PyPA</strong>) guidelines recommend<a id="_idIndexMarker540"/> having a separate folder for tests when building packages for a project or a library. In our code examples for this section, we will follow a similar structure to the one shown here:</p>
			<pre>Project-name
|-- src
|   -- __init__.py
|   -- myadd/myadd.py 
|-- tests
|   -- __init__.py
|   -- tests_myadd/test_myadd1.py 
|   -- tests_myadd/test_myadd2.py
|-- README.md</pre>
			<p>In our first code example, we will build a test suite for the <code>add</code> function in the <code>myadd.py</code> module, as follows:</p>
			<pre># <strong class="bold">myadd.py</strong> with add two numbers
def <strong class="bold">add</strong>(x, y):
    """This function adds two numbers"""
    return x + y</pre>
			<p>It is important<a id="_idIndexMarker541"/> to understand that there<a id="_idIndexMarker542"/> can be more than one test<a id="_idIndexMarker543"/> case for the same piece of code (an <code>add</code> function, in our case). For the <code>add</code> function, we implemented four test cases by varying the values of input parameters. Next is a code sample with four test cases for the <code>add</code> function, as follows: </p>
			<pre>#<strong class="bold">test_myadd1</strong>.py test suite for myadd function
import unittest
from myunittest.src.myadd.myadd import add
class <strong class="bold">MyAddTestSuite</strong>(unittest.<strong class="bold">TestCase</strong>):
def <strong class="bold">test_add1</strong>(self):
    """ test case to validate two positive numbers"""
    self.<strong class="bold">assertEqual</strong>(15, add(10 , 5), "should be 15")
def test_add2(self):
    """ test case to validate positive and negative \
     numbers"""
    self.<strong class="bold">assertEqual</strong>(5, add(10 , -5), "should be 5")
def test_add3(self):
    """ test case to validate positive and negative \
     numbers"""
    self.<strong class="bold">assertEqual</strong>(-5, add(-10 , 5), "should be -5")
def test_add4(self):
    """ test case to validate two negative numbers"""
    self.<strong class="bold">assertEqual</strong>(-15, add(-10 , -5), "should be -15")
if __name__ == '__main__':
    unittest.main()</pre>
			<p>All the key points of the preceding<a id="_idIndexMarker544"/> test suite are discussed next, as follows: </p>
			<ul>
				<li>To implement unit tests using the <code>unittest</code> framework, we need to import a standard library with the same name, <code>unittest</code>.</li>
				<li>We need to import the module or modules we want to test in our test suite. In this case, we imported the <code>add</code> function from the <code>myadd.py</code> module using the relative import approach (see the <em class="italic">Importing modules</em> section of <a href="B17189_02_Final_PG_ePub.xhtml#_idTextAnchor086"><em class="italic">Chapter 2</em></a>, <em class="italic">Using Modularization to Handle Complex Projects,</em> for details)</li>
				<li>We will implement a test suite class that is inherited from the <code>unittest.Testcase</code> base class. The test cases are implemented in the subclass, which is the <code>MyAddTestSuite</code> class in this case. The <code>unittest.Testcase</code> class constructor can take a method name as an input that can be used to run the test cases. By default, there is a <code>runTest</code> method already implemented that is used by the test runner to execute the tests. In a majority of the cases, we do not need to provide our own method or re-implement the <code>runTest</code> method. </li>
				<li>To implement a test case, we need to write a method that starts with the <code>test</code> prefix and is followed by an underscore. This helps the test runner to look for the test cases to be executed. Using this naming convention, we added four methods to our test suite.</li>
				<li>In each test-case<a id="_idIndexMarker545"/> method, we used a special <code>assertEqual</code> method, which is available from the base class. This method represents the assert stage of a test case and is used to decide if our test will be declared as passed or failed. The first parameter of this method is the expected results of the unit test, the second parameter is the value that we get after executing the code under test, and the third parameter (optional) is the message to be provided in the report in case the test is failed.</li>
				<li>At the end of the test suite, we added the <code>unittest.main</code> method to trigger the test runner to run the <code>runTest</code> method, which makes it easy to execute the tests without using the commands at the console. This <code>main</code> method (a <code>TestProgram</code> class under the hood) will first discover all the tests to be executed and then execute the tests.<p class="callout-heading">Important note</p><p class="callout">Unit tests can be run<a id="_idIndexMarker546"/> using a command such as <code>Python -m unittest &lt;test suite or module&gt;</code>, but the code examples we provide in this chapter will assume that we are running the test cases using the PyCharm <strong class="bold">integrated development environment</strong> (<strong class="bold">IDE</strong>). </p></li>
			</ul>
			<p>Next, we will build the next level of test cases using the test fixtures.</p>
			<h3>Building test cases with test fixtures</h3>
			<p>We have discussed <code>setUp</code> and <code>tearDown</code> methods<a id="_idIndexMarker547"/> that are run<a id="_idIndexMarker548"/> automatically by test runners before and after executing<a id="_idIndexMarker549"/> a test case. These methods (along with the <code>setUpClass</code> and <code>tearDownClass</code> methods) provide the test fixtures and are useful to implement the unit tests efficiently.</p>
			<p>First, we will revise<a id="_idIndexMarker550"/> the implementation of our <code>add</code> function. In the new implementation, we will make this unit of code a part of the <code>MyAdd</code> class. We are also handling the situation by throwing a <code>TypeError</code> exception in case the input arguments are invalid. Next is the complete code snippet with the new <code>add</code> method:</p>
			<pre># <strong class="bold">myadd2.py</strong> is a class with add two numbers method
class <strong class="bold">MyAdd</strong>:
    def <strong class="bold">add</strong>(self, x, y):
        """This function adds two numbers"""
        if (not isinstance(x, (int, float))) | \
                (not isinstance(y, (int, float))) :
            <strong class="bold">raise TypeError</strong>("only numbers are allowed")
        return x + y</pre>
			<p>In the previous section, we built test cases using only the act stage and the assert stage. In this section, we will revise the previous code example by adding <code>setUp</code> and <code>tearDown</code> methods. Next is the test suite for this <code>myAdd</code> class, as follows:</p>
			<pre>#<strong class="bold">test_myadd2.py</strong> test suite for myadd2 class method
import unittest
from myunittest.src.myadd.myadd2 import MyAdd
class <strong class="bold">MyAddTestSuite</strong>(unittest.TestCase):
    def <strong class="bold">setUp</strong>(self):
        self.myadd = MyAdd()
    def <strong class="bold">tearDown</strong>(self):
        del (self.myadd)
    def <strong class="bold">test_add1</strong>(self):
       """ test case to validate two positive numbers"""
       self.assertEqual(15, self.myadd.add(10 , 5), \
        "should be 15")
    def <strong class="bold">test_add2</strong>(self):
        """ test case to validate positive and negative           numbers"""
        self.assertEqual(5, self.myadd.add(10 , -5), \
         "should be 5")
#test_add3 and test_add4 are skipped as they are very \
 same as test_add1 and test_add2</pre>
			<p>In this test suite, we added or changed the following:</p>
			<ul>
				<li>We added a <code>setUp</code> method<a id="_idIndexMarker551"/> in which we created a new instance<a id="_idIndexMarker552"/> of the <code>MyAdd</code> class and saved its reference as an instance attribute. This means we will be creating a new instance of the <code>MyAdd</code> class <em class="italic">before</em> we execute any test case. This may not be ideal for this test suite, as a better approach could be to use the <code>setUpClass</code> method and create a single instance of the <code>MyAdd</code> class for the whole test suite, but we have implemented it this way for illustration purposes.</li>
				<li>We also added a <code>tearDown</code> method. To demonstrate how to implement it, we simply called the destructor<a id="_idIndexMarker553"/> (using the <code>del</code> function) on the <code>MyAdd</code> instance that we created in the <code>setUp</code> method. As with the <code>setUp</code> method, the <code>tearDown</code> method is executed <em class="italic">after</em> each test case. If we intend to use the <code>setUpClass</code> method, there is an equivalent method for teardown, which is <code>tearDownClass</code>.</li>
			</ul>
			<p>In the next section, we will present code examples that will build test cases to handle a <code>TypeError</code> exception. </p>
			<h3>Building test cases with error handling </h3>
			<p>In the previous code<a id="_idIndexMarker554"/> examples, we only compared the test-case<a id="_idIndexMarker555"/> results with the expected<a id="_idIndexMarker556"/> results. We did not consider any exception handling such as what would be the behavior of our program if the wrong types of arguments were passed as input to our <code>add</code> function. The unit tests have to cover these aspects of the programming as well.</p>
			<p>In the next code example, we will build test cases to handle errors or exceptions which are expected from a unit of code. For this example, we will use the same <code>add</code> function, which throws a <code>TypeError</code> exception if the argument is not a number. The test cases will be built by passing non-numeric arguments to the <code>add</code> function. The next code snippet shows the test cases:</p>
			<pre>#<strong class="bold">test_myadd3.py</strong> test suite for myadd2 class method to validate errors
import unittest
from myunittest.src.myadd.myadd2 import MyAdd
class MyAddTestSuite(unittest.TestCase):
    def setUp(self):
        self.myadd = MyAdd()
    def <strong class="bold">test_typeerror1</strong>(self):
        """ test case to check if we can handle non \
         number input"""
        self.<strong class="bold">assertRaises</strong>(<strong class="bold">TypeError</strong>, <strong class="bold">self.myadd.add</strong>, \
         'a' , -5)
    def test_typeerror2(self):
        """ test case to check if we can handle non \
         number input"""
        self.<strong class="bold">assertRaises</strong>(<strong class="bold">TypeError</strong>, <strong class="bold">self.myadd.add</strong>, \
         'a' , 'b')</pre>
			<p>In the preceding code snippet, we added two additional test cases to the <code>test_add3.py</code> module. These test cases use the <code>assertRaises</code> method to validate if a particular<a id="_idIndexMarker557"/> type of exception is thrown<a id="_idIndexMarker558"/> or not. In our test cases, we used<a id="_idIndexMarker559"/> a single letter (<code>a</code>) or two letters (<code>a</code> and <code>b</code>) as arguments for the two test cases. In both cases, we are expecting the intended exception (<code>TypeError</code>) to be thrown. It is important to note the arguments of the <code>assertRaises</code> method. This method expects only the method or function name as a second argument. The parameters of the method or function have to be passed separately as arguments of the <code>assertRaises</code> function.</p>
			<p>So far, we have executed multiple test cases under a single test suite. In the next section, we will discuss how we can run multiple test suites simultaneously, using the command line and also programmatically.</p>
			<h3>Executing multiple test suites</h3>
			<p>As we built test<a id="_idIndexMarker560"/> cases for each unit of code, the number<a id="_idIndexMarker561"/> of test cases (unit test cases) grows very quickly. The idea of using test suites is to bring modularity into the test-case development. Test suites also make it easier to maintain and extend the test cases as we add more functionality to an application. The next aspect that comes to our mind is how to execute multiple test suites through a master script or a workflow. CI tools such as Jenkins provides such functionality out of the box. Test frameworks such as <code>unittest</code>, <code>nose</code>, or <code>pytest</code> also provide similar features.</p>
			<p>In this section, we will build a simple calculator application (a <code>MyCalc</code> class) with <code>add</code>, <code>subtract</code>, <code>multiply</code>, and <code>divide</code> methods in it. Later, we will add one test suite for each method in this class. This way, we will add four test suites for this calculator application. A directory structure is important in implementing the test suites and test cases. For this application, we will use the following directory structure:</p>
			<div><div><img src="img/B17189_05_03.jpg" alt="Figure 5.3 – Directory structure for the mycalc application and test suites associated with this application&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 5.3 – Directory structure for the mycalc application and test suites associated with this application</p>
			<p>The Python code is written in the <code>mycalc.py</code> module and the test suite files (<code>test_mycalc*.py</code>) are shown next. Note that we show only one test case in each test suite in the code examples shown next. In reality, there will be multiple<a id="_idIndexMarker562"/> test cases in each test suite. We will start<a id="_idIndexMarker563"/> with the calculator functions in the <code>mycalc.py</code> file, as follows:</p>
			<pre># <strong class="bold">mycalc.py</strong> with add, subtract, multiply and divide functions
class MyCalc:
    def <strong class="bold">add</strong>(self, x, y):
        """This function adds two numbers"""
        return x + y
    def <strong class="bold">subtract</strong>(self, x, y):
        """This function subtracts two numbers"""
        return x - y
    def <strong class="bold">multiply</strong>(self, x, y):
        """This function subtracts two numbers"""
        return x * y
    def <strong class="bold">divide</strong>(self, x, y):
        """This function subtracts two numbers"""
        return x / y</pre>
			<p>Next, we have a test<a id="_idIndexMarker564"/> suite to test the <code>add</code> function in the <code>test_mycalc_add.py</code> file, as illustrated<a id="_idIndexMarker565"/> in the following code snippet: </p>
			<pre># test_mycalc_add.py test suite for add class method
import unittest
from myunittest.src.mycalc.mycalc import MyCalc
class <strong class="bold">MyCalcAddTestSuite</strong>(unittest.TestCase):
    def <strong class="bold">setUp</strong>(self):
        self.calc = MyCalc()
    def <strong class="bold">test_add</strong>(self):
        """ test case to validate two positive numbers"""
        self.assertEqual(15, self.calc.add(10, 5), \
         "should be 15")</pre>
			<p>Next, we have a test suite<a id="_idIndexMarker566"/> to test the <code>subtract</code> function in the <code>test_mycalc_subtract.py</code> file, as illustrated<a id="_idIndexMarker567"/> in the following code snippet:</p>
			<pre>#test_mycalc_subtract.py test suite for subtract class method
import unittest
from myunittest.src.mycalc.mycalc import MyCalc
class <strong class="bold">MyCalcSubtractTestSuite</strong>(unittest.TestCase):
    def <strong class="bold">setUp</strong>(self):
        self.calc = MyCalc()
    def <strong class="bold">test_subtract</strong>(self):
        """ test case to validate two positive numbers"""
        self.assertEqual(5, self.calc.subtract(10,5), \
         "should be 5")</pre>
			<p>Next, we have a test suite to test the <code>multiply</code> function in the <code>test_mycalc_multiply.py</code> file, as illustrated in the following code snippet:</p>
			<pre>#test_mycalc_multiply.py test suite for multiply class method
import unittest
from myunittest.src.mycalc.mycalc import MyCalc
class <strong class="bold">MyCalcMultiplyTestSuite</strong>(unittest.TestCase):
    def <strong class="bold">setUp</strong>(self):
        self.calc = MyCalc()
    def <strong class="bold">test_multiply</strong>(self):
        """ test case to validate two positive numbers"""
        self.assertEqual(50, self.calc.multiply(10, 5), "should           be 50")</pre>
			<p>Next, we have a test suite<a id="_idIndexMarker568"/> to test the <code>divide</code> function<a id="_idIndexMarker569"/> in the <code>test_mycalc_divide.py</code> file, as illustrated in the following code snippet:</p>
			<pre>#test_mycalc_divide.py test suite for divide class method
import unittest
from myunittest.src.mycalc.mycalc import MyCalc
class <strong class="bold">MyCalcDivideTestSuite</strong>(unittest.TestCase):
    def <strong class="bold">setUp</strong>(self):
        self.calc = MyCalc()
    def <strong class="bold">test_divide</strong>(self):
        """ test case to validate two positive numbers"""
        self.assertEqual(2, self.calc.divide(10 , 5), \
         "should be 2")</pre>
			<p>We have the sample application code and all four test suites' code. The next aspect is how to execute all the test suites<a id="_idIndexMarker570"/> in one go. One easy way to do this is by using the <code>discover</code> keyword. In our example case, we will run the following command from the top of the project to discover and execute all test cases in all the four test suites that are available in the <code>tests_mycalc</code> directory: </p>
			<pre>python -m unittest discover myunittest/tests/tests_mycalc</pre>
			<p>This command will be executed recursively, which means it can discover the test cases in sub-directories<a id="_idIndexMarker571"/> as well. The other (optional) parameters can be used to select a set of test cases for execution, and these are described as follows:</p>
			<ul>
				<li><code>-v</code>: To make the output verbose. </li>
				<li><code>-s</code>: Start directory for the discovery of test cases.</li>
				<li><code>-p</code>: Pattern to use for searching the test files. The default is <code>test*.py</code>, but it can be changed by this parameter.</li>
				<li><code>-t</code>: This is a top-level directory of the project. If not specified, the start directory is the top-level directory</li>
			</ul>
			<p>Although the command-line option of running multiple test suites is simple and powerful, we sometimes<a id="_idIndexMarker572"/> need to control the way we run selected<a id="_idIndexMarker573"/> tests from different test suites that may be in different locations. This is where loading and executing the test cases through the Python code is handy. The next code snippet is an example of how to load the test suites from a class name, find the test cases in each of the suites, and then run them using the <code>unittest</code> test runner: </p>
			<pre>import unittest
from test_mycalc_add import MyCalcAddTestSuite
from test_mycalc_subtract import MyCalcSubtractTestSuite
from test_mycalc_multiply import MyCalcMultiplyTestSuite
from test_mycalc_divide import MyCalcDivideTestSuite
def <strong class="bold">run_mytests</strong>():
    <strong class="bold">test_classes</strong> = [MyCalcAddTestSuite, \
      MyCalcSubtractTestSuite,\
      MyCalcMultiplyTestSuite,MyCalcDivideTestSuite ]
    loader = unittest.<strong class="bold">TestLoader</strong>()
    test_suites = []
    for t_class in test_classes:
        suite = loader.<strong class="bold">loadTestsFromTestCase</strong>(t_class)
        test_suites.append(suite)
    final_suite = unittest.<strong class="bold">TestSuite</strong>(test_suites)
    runner = unittest.<strong class="bold">TextTestRunner</strong>()
    results = runner.<strong class="bold">run</strong>(final_suite)
    
if __name__ == '__main__':
    run_mytests()</pre>
			<p>In this section, we have covered building test cases using the <code>unittest</code> library. In the next section, we will work with the <code>pytest</code> library. </p>
			<h2 id="_idParaDest-140"><a id="_idTextAnchor178"/>Working with the pytest framework</h2>
			<p>The test cases<a id="_idIndexMarker574"/> written using the <code>unittest</code> library are easier<a id="_idIndexMarker575"/> to read and manage, especially if you are coming from a background of using JUnit or other similar frameworks. But for large-scale Python applications, the <code>pytest</code> library stands out as one of the most popular frameworks, mainly because of its ease of use in implementation and its ability to extend for complex testing requirements. In the case of the <code>pytest</code> library, there is no requirement to extend the unit test class from any base class; in fact, we can<a id="_idIndexMarker576"/> write the test cases without even implementing any class.</p>
			<p><code>pytest</code> is an open source framework. The <code>pytest</code> test framework<a id="_idIndexMarker577"/> can auto-discover tests, just as with the <code>unittest</code> framework, if the filename has a <code>test</code> prefix, and this discovery format is configurable. The <code>pytest</code> framework includes the same level of functionality as it is provided by the <code>unittest</code> framework for writing unit tests. In this section, we will focus on discussing the features that are different or additional in the <code>pytest</code> framework.</p>
			<h3>Building test cases without a base class</h3>
			<p>To demonstrate how to write unit test cases using the <code>pytest</code> library, we will revise our <code>myadd2.py</code> module<a id="_idIndexMarker578"/> by implementing the <code>add</code> function<a id="_idIndexMarker579"/> without a class. This new <code>add</code> function will add two numbers and throw an exception if the <em class="italic">numbers</em> are not passed as arguments. The test-case code using the <code>pytest</code> framework is shown in the following snippet:</p>
			<pre># <strong class="bold">myadd3.py</strong> is a class with add two numbers method
def <strong class="bold">add</strong>(self, x, y):
    """This function adds two numbers"""
    if (not <strong class="bold">isinstance</strong>(x, (int, float))) | \
            (not <strong class="bold">isinstance</strong>(y, (int, float))):
        raise <strong class="bold">TypeError</strong>("only numbers are allowed")
    return x + y</pre>
			<p>And the test cases' module is shown next, as follows:</p>
			<pre>#<strong class="bold">test_myadd3.py</strong> test suite for myadd function
import pytest
from mypytest.src.myadd3 import add
def test_add1():
    """ test case to validate two positive numbers"""
    <strong class="bold">assert add(10, 5) == 15"</strong>
def test_add2():
    """ test case to validate two positive numbers"""
    <strong class="bold">assert add(10, -5) == 5, "should be 5"</strong></pre>
			<p>We only showed two test cases for the <code>test_myadd3.py</code> module as the other test cases will be similar to the first two test cases. These additional test cases are available with this chapter's source code under the GitHub directory. A couple of key differences<a id="_idIndexMarker580"/> in the test case implementation are outlined here:</p>
			<ul>
				<li>There is no requirement to implement test cases under a class, and we can implement test cases as class methods without inheriting them from any base class. This is a key difference in comparison to the <code>unittest</code> library.</li>
				<li>The <code>assert</code> statements are available as a keyword for validation of any condition to declare whether a test passed or failed. Separating <code>assert</code> keywords from the conditional statement makes assertions in test cases very flexible and customizable.</li>
			</ul>
			<p>It is also important to mention that the console output and the reporting is more powerful with the <code>pytest</code> framework. As an example, the console output of executing test cases using the <code>test_myadd3.py</code> module is shown here:</p>
			<pre>test_myadd3.py::test_add1 PASSED                         [25%]
test_myadd3.py::test_add2 PASSED                         [50%]
test_myadd3.py::test_add3 PASSED                         [75%]
test_myadd3.py::test_add4 PASSED                         [100%]
===================== 4 passed in 0.03s =======================</pre>
			<p>Next, we will investigate how to validate expected errors using the <code>pytest</code> library.</p>
			<h3>Building test cases with error handling </h3>
			<p>Writing test cases to validate<a id="_idIndexMarker581"/> the throwing of an expected exception<a id="_idIndexMarker582"/> or error is different<a id="_idIndexMarker583"/> in the <code>pytest</code> framework as compared to writing such test cases in the <code>unittest</code> framework. The <code>pytest</code> framework utilizes the context manager for exception validation. In our <code>test_myadd3.py</code> test module, we already added two test cases for exception validation. An extract of the code in the <code>test_myadd3.py</code> module with the two test cases is shown next, as follows:</p>
			<pre>def <strong class="bold">test_typeerror1</strong>():
    """ test case to check if we can handle non number \
     input"""
    with <strong class="bold">pytest.raises</strong>(TypeError):
        add('a', 5)
def <strong class="bold">test_typeerror2</strong>():
    """ test case to check if we can handle non number \
      input"""
    with <strong class="bold">pytest.raises</strong>(TypeError, <strong class="bold">match</strong>="only numbers are \
     allowed"):
        add('a', 'b')</pre>
			<p>To validate the exception, we are using the <code>raises</code> function of the <code>pytest</code> library to indicate what sort of exception is expected by running a certain unit of code (<code>add('a', 5)</code> in our first test case). In the second test case, we used a <code>match</code> argument to validate the message that is set when an exception is thrown.</p>
			<p>Next, we will discuss how to use markers with the <code>pytest</code> framework.</p>
			<h3>Building test cases with pytest markers</h3>
			<p>The <code>pytest</code> framework is equipped<a id="_idIndexMarker584"/> with markers<a id="_idIndexMarker585"/> that allow us to attach<a id="_idIndexMarker586"/> metadata or define different categories for our test cases. This metadata can be used for many purposes, such as including or excluding certain test cases. The markers are implemented using the <code>@pytest.mark</code> decorator.</p>
			<p>The <code>pytest</code> framework provides a few built-in markers, with the most popular ones being described next:</p>
			<ul>
				<li><code>skip</code>: The test runner will skip a test case unconditionally when this marker is used.</li>
				<li><code>skipif</code>: This marker is used to skip a test based on a conditional expression that is passed as an argument to this marker.</li>
				<li><code>xfail</code>: This marker is used to ignore an expected failure in a test case. It is used with a certain condition.</li>
				<li><code>parametrize</code>: This marker is used to perform multiple calls to the test case with different values as arguments.</li>
			</ul>
			<p>To demonstrate the use of the first three markers, we rewrite our <code>test_add3.py</code> module by adding markers with the test-case functions. The revised test-case module (<code>test_add4.py</code>) is shown here:</p>
			<pre><strong class="bold">@pytest.mark.skip</strong>
def test_add1():
    """ test case to validate two positive numbers"""
    assert add(10, 5) == 15
<strong class="bold">@pytest.mark.skipif</strong>(sys.version_info &gt; (3,6),\ 
<strong class="bold">reason</strong>=" skipped for release &gt; than Python 3.6")
def test_add2():
    """ test case to validate two positive numbers"""
    assert add(10, -5) == 5, "should be 5"
<strong class="bold">@pytest.mark.xfail</strong>(sys.platform == "win32", \
reason="ignore exception for windows")
def test_add3():
    """ test case to validate two positive numbers"""
    assert add(-10, 5) == -5
    raise Exception()</pre>
			<p>We used the <code>skip</code> marker unconditionally for the first test case. This will ignore the test case. For the second test case, we used the <code>skipif</code> marker with a condition of a Python version<a id="_idIndexMarker587"/> greater than 3.6. For the last<a id="_idIndexMarker588"/> test case, we deliberately<a id="_idIndexMarker589"/> raised an exception, and we used the <code>xfail</code> marker to ignore this type of exception if the system platform is Windows. This type of marker is helpful for ignoring errors in test cases if they are expected for a certain condition, such as the operating system in this case. </p>
			<p>The console output from the execution of the test cases is shown here: </p>
			<pre>test_myadd4.py::test_add1 SKIPPED (unconditional skip)   [33%]
Skipped: unconditional skip
test_myadd4.py::test_add2 SKIPPED ( skipped for release &gt; than Pytho...)                                                [66%]
Skipped:  skipped for release &gt; than Python 3.6
test_myadd4.py::test_add3 XFAIL (ignore exception for mac)                                                    [100%]
@pytest.mark.xfail(sys.platform == "win32",
                       reason="ignore exception for mac")
============== 2 skipped, 1 xfailed in 0.06s =================</pre>
			<p>Next, we will discuss the use of the <code>parametrize</code> marker with the <code>pytest</code> library.</p>
			<h3>Building test cases with parametrization</h3>
			<p>In all previous code examples, we built<a id="_idIndexMarker590"/> test-case functions<a id="_idIndexMarker591"/> or methods without passing any parameters<a id="_idIndexMarker592"/> to them. But for many test scenarios, we need to run the same test case by varying the input data. In a classical approach, we run multiple test cases that are different only in terms of the input data we used for them. Our previous example of <code>test_myadd3.py</code> shows how to implement test cases using this classical approach. A recommended approach<a id="_idIndexMarker593"/> for such type of testing is to use <code>pytest</code> will execute our test case as many times as the number of permutations is in the table or the dictionary. A real-world example of DDT is to validate the behavior of a login feature of an application by using a variety of users with valid and invalid credentials.</p>
			<p>In the <code>pytest</code> framework, DDT can be implemented using parametrization with the <code>pytest</code> marker. By using the <code>parametrize</code> marker, we can define which input argument we need to pass and also the test dataset we need to use. The <code>pytest</code> framework will automatically execute the test-case function multiple times as per the number of entries in the test data provided with the <code>parametrize</code> marker. </p>
			<p>To illustrate how to use the <code>parametrize</code> marker for DDT, we will revise our <code>myadd4.py</code> module for the test cases of the <code>add</code> function. In the revised code, we will have only one test-case function but different test data<a id="_idIndexMarker596"/> to be used for the input parameters, as illustrated<a id="_idIndexMarker597"/> in the following<a id="_idIndexMarker598"/> snippet:</p>
			<pre># <strong class="bold">test_myadd5.py</strong> test suite using parameterize marker
import sys
import pytest
from mypytest.src.myadd3 import add
@pytest.mark.<strong class="bold">parametrize</strong>("<strong class="bold">x,y,ans</strong>",
                         [(10,5,15),(10,-5,5),
                          (-10,5,-5),(-10,-5,-15)],
                         <strong class="bold">ids</strong>=["pos-pos","pos-neg",
                              "neg-pos", "neg-neg"])
def test_add(<strong class="bold">x, y, ans</strong>):
    """ test case to validate two positive numbers"""
    assert add(x, y) == ans</pre>
			<p>For the <code>parametrize</code> marker, we used<a id="_idIndexMarker599"/> three parameters, which are described as follows:</p>
			<ul>
				<li><strong class="bold">Test-case arguments</strong>: We provide a list of arguments<a id="_idIndexMarker600"/> to be passed to our test function in the same order as defined with the test-case function definition. Also, the test data we need to provide in the next argument will follow the same order.</li>
				<li><strong class="bold">Data</strong>: The test data to be passed will be a list<a id="_idIndexMarker601"/> of different sets of input arguments. The number of entries in the test data will determine how many times the test case will be executed.</li>
				<li><code>ids</code>: This is an optional parameter that is mainly attaching a friendly tag to different test datasets<a id="_idIndexMarker602"/> we provided in the previous argument. These <strong class="bold">identifier </strong>(<strong class="bold">ID</strong>) tags will be used in the output report to identify different executions of the same test case. </li>
			</ul>
			<p>The console output for this test-case execution is shown next:</p>
			<pre>test_myadd5.py::test_add[pos-pos] PASSED                 [ 25%]
test_myadd5.py::test_add[pos-neg] PASSED                 [ 50%]
test_myadd5.py::test_add[neg-pos] PASSED                 [ 75%]
test_myadd5.py::test_add[neg-neg] PASSED                 [100%]
=============== 4 passed in 0.04s ================= </pre>
			<p>This console output shows us how many times the test case is executed and with which test data. The test cases<a id="_idIndexMarker603"/> built using the <code>pytest</code> markers are concise and easy to implement. This saves a lot of time and enables us to write more test cases (by varying data only) in a short time. </p>
			<p>Next, we will discuss another important feature of the <code>pytest</code> library: fixtures.</p>
			<h3>Building test cases with pytest fixtures</h3>
			<p>In the <code>pytest</code> framework, the test fixtures<a id="_idIndexMarker604"/> are implemented using Python<a id="_idIndexMarker605"/> decorators <code>(@pytest.fixture</code>). The implementation<a id="_idIndexMarker606"/> of test fixtures in the <code>pytest</code> framework is very powerful as compared to the other frameworks for the following key reasons:</p>
			<ul>
				<li>Fixtures in the <code>pytest</code> framework provide high scalability. We can define a generic setup or fixtures (methods) that can be reused across functions, classes, modules, and packages.</li>
				<li>Fixture implementation of the <code>pytest</code> framework is modular in nature. We can use one or more fixtures with a test case. A fixture can use one or many other fixtures as well, just as we use functions to call other functions. </li>
				<li>Each test case in a test suite will have the flexibility to use the same or a different set of fixtures. </li>
				<li>We can create fixtures in the <code>pytest</code> framework with a scope set for them. The default scope is <code>function</code>, which means the fixture will be executed before every function (test case). Other scope options are <code>module</code>, <code>class</code>, <code>package</code>, or <code>session</code>. These are defined briefly next: <p>a) <code>Function</code>: The fixture is destroyed after executing a test case.</p><p>b) <code>Module</code>: The fixture is destroyed after executing the last test case in a module.</p><p>c) <code>Class</code>: The fixture is destroyed after executing the last test case in a class.</p><p>d) <code>Package</code>: The fixture is destroyed after executing the last test case in a package.</p><p>e) <code>Session</code>: The fixture is destroyed after executing the last test case in a test session.</p></li>
			</ul>
			<p>The <code>pytest</code> framework<a id="_idIndexMarker607"/> has a few useful built-in fixtures<a id="_idIndexMarker608"/> that can be used<a id="_idIndexMarker609"/> out of the box, such as <code>capfd</code> to capture output to the file descriptors, <code>capsys</code> to capture output to <code>stdout</code> and <code>stderr</code>, <code>request</code> to provide information on the requesting test function, and <code>testdir</code> to provide a temporary test directory for test executions.  </p>
			<p>Fixtures in the <code>pytest</code> framework can be used to reset or tear down at the end of a test case as well. We will discuss this later on in this section.</p>
			<p>In the next code example, we will build test cases for our <code>MyCalc</code> class using custom fixtures. The sample code for <code>MyCalc</code> is already shared in the <em class="italic">Executing multiple test suites</em> section. The implementation of a test fixture and test cases is shown here: </p>
			<pre># <strong class="bold">test_mycalc1.py</strong> test calc functions using test fixture
import sys
import pytest
from mypytest.src.myadd3 import add
from mypytest.src.mycalc import MyCalc
@<strong class="bold">pytest.fixture</strong>(scope="<strong class="bold">module</strong>")
def <strong class="bold">my_calc</strong>():
    return MyCalc()
@<strong class="bold">pytest.fixture</strong>
def <strong class="bold">test_data</strong> ():
    return {'x':10, 'y':5}
def <strong class="bold">test_add</strong>(<strong class="bold">my_calc</strong>, <strong class="bold">test_data</strong>):
    """ test case to add two numbers"""
    assert my_calc.add(test_data.get('x'),\
      test_data.get('y')) == 15
def <strong class="bold">test_subtract</strong>(<strong class="bold">my_calc</strong>, <strong class="bold">test_data</strong>):
    """ test case to subtract two numbers"""
    assert my_calc.subtract(test_data.get('x'), \
     test_data.get('y'))== 5</pre>
			<p>In this test-suite example, these are the key points of discussion:</p>
			<ul>
				<li>We created two fixtures: <code>my_calc</code> and <code>test_data</code>. The <code>my_calc</code> fixture is set with a scope set to <code>module</code> because we want it to be executed only once to provide an instance of the <code>MyCalc</code> class. The <code>test_data</code> fixture is using the default scope (<code>function</code>), which means it will be executed before every method. </li>
				<li>For the test cases (<code>test_add</code> and <code>test_subtract</code>), we used the fixtures as input arguments. The name of the argument has to match the fixture function name. The <code>pytest</code> framework automatically looks for a fixture with the name used as an argument for a test case.</li>
			</ul>
			<p>The code example<a id="_idIndexMarker610"/> we discussed is using a fixture as the setup function. A question<a id="_idIndexMarker611"/> we may want to<a id="_idIndexMarker612"/> ask is: <em class="italic">How we can achieve teardown functionality with the pytest fixtures?</em> There are two approaches available for implementing the teardown functionality, and these are discussed next.</p>
			<h4>Using yield instead of a return statement</h4>
			<p>With this approach, we write some code mainly for setup purposes, use a <code>yield</code> statement<a id="_idIndexMarker613"/> instead of <code>return</code>, and then write code for teardown purposes after the <code>yield</code> statement. If we have a test suite or module with many fixtures used in it, the <code>pytest</code> test runner will execute each fixture (as per the evaluated order of execution) till the <code>yield</code> statement is encountered. As soon as the test-case execution is completed, the <code>pytest</code> test runner triggers the execution of all fixtures that are yielded and executes the code that is written after the <code>yield</code> statement. The use of a yield-based approach is clean in the sense that the code is easy to follow and maintain. Therefore, it is a recommended approach.</p>
			<h4>Adding a finalizer method using the request fixture</h4>
			<p>With this approach, we have to consider<a id="_idIndexMarker614"/> three steps to write<a id="_idIndexMarker615"/> a teardown method, outlined as follows: </p>
			<ul>
				<li>We have to use a <code>request</code> object in our fixtures. The <code>request</code> object can be provided using the built-in fixture with the same name.</li>
				<li>We will define a <code>teardown</code> method, separately or as a part of the fixture implementation.</li>
				<li>We will provide the <code>teardown</code> method as a callable method to the request object using the <code>addfinalizer</code> method.</li>
			</ul>
			<p>To illustrate both approaches<a id="_idIndexMarker616"/> with code examples, we will modify<a id="_idIndexMarker617"/> our previous implementation of the fixtures. In the revised code, we will implement the <code>my_calc</code> fixture using a <code>yield</code> approach and the <code>data_set</code> fixture using an <code>addfinalizer</code> approach. Here is the revised code example: </p>
			<pre># <strong class="bold">test_mycalc2.py</strong> test calc functions using test fixture
&lt;import statements&gt;
@pytest.fixture(scope="module")
def my_calc():
    my_calc = MyCalc()
    <strong class="bold">yield</strong> my_calc
    <strong class="bold">del my_calc</strong>
@pytest.fixture
def data_set(<strong class="bold">request</strong>):
    dict = {'x':10, 'y':5}
    <strong class="bold">def delete_dict</strong>(<strong class="bold">obj</strong>):
        del obj
    <strong class="bold">request.addfinalizer</strong>(lambda: delete_dict(dict))
    return dict
&lt;rest of the test cases&gt;</pre>
			<p>Note that there is no real need for teardown functionality for these example fixtures, but we added them for illustration purposes.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Using <code>nose</code> and <code>doctest</code> for test automation is similar to using the <code>unittest</code> and <code>pytest</code> frameworks.</p>
			<p>In the next section, we will discuss a TDD approach to software development.</p>
			<h1 id="_idParaDest-141"><a id="_idTextAnchor179"/>Executing TDD</h1>
			<p>TDD is a well-known practice<a id="_idIndexMarker618"/> in software engineering. This is a software development approach in which test cases are written first before writing any code for a required feature in an application. Here are the three simple rules<a id="_idIndexMarker619"/> of TDD:</p>
			<ul>
				<li>Do not write any functional code unless you write a unit test that is failing.</li>
				<li>Do not write any additional code in the same test more than you need to make the test fail.</li>
				<li>Do not write any functional code more than what is needed to pass a failing test.</li>
			</ul>
			<p>These TDD rules also drive us to follow a famous three-phase approach of software development<a id="_idIndexMarker620"/> called <strong class="bold">Red, Green, Refactor</strong>. The phases are repeated continuously for TDD. These three phases are shown in <em class="italic">Figure 5.4</em> and are described next.</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor180"/>Red</h2>
			<p>In this phase, the first step<a id="_idIndexMarker621"/> is to write a test without having<a id="_idIndexMarker622"/> any code to test. The test will obviously fail in this case. We will not try to write a complete test case but only write enough code to fail the test.</p>
			<h2 id="_idParaDest-143"><a id="_idTextAnchor181"/>Green</h2>
			<p>In this phase, the first step<a id="_idIndexMarker623"/> is to write the code until<a id="_idIndexMarker624"/> an already written test passes. Again, we will only write enough code to pass the test. We will run all tests to make sure previously written tests also pass.</p>
			<h2 id="_idParaDest-144"><a id="_idTextAnchor182"/>Refactor</h2>
			<p>In this phase, we should consider improving the quality of the code, which means making the code easy to read and use optimization—for example, any hardcoded values have to be removed. Running the tests after each refactoring cycle is also recommended. The outcome of the refactor phase<a id="_idIndexMarker625"/> is clean code. We can repeat<a id="_idIndexMarker626"/> the cycle by adding more test scenarios and adding code to make the new test pass, and this cycle must be repeated until a feature is developed.</p>
			<p>It is important to understand that TDD is neither a testing nor a design approach. It is an approach to developing software according to specifications that are defined by writing test cases first.</p>
			<p>The following diagram shows the three phases of TDD:</p>
			<p class="figure-caption"> </p>
			<div><div><img src="img/B17189_05_04.jpg" alt="Figure 5.4 – TDD, also known as Red, Green, Refactor &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.4 – TDD, also known as Red, Green, Refactor </p>
			<p>In the next section, we will introduce the role of test automation in the CI process.</p>
			<h1 id="_idParaDest-145"><a id="_idTextAnchor183"/>Introducing automated CI</h1>
			<p>CI is a process that combines the benefits of both automated testing and version control systems to achieve a fully automated integration environment. With a CI development approach, we integrate<a id="_idIndexMarker627"/> our code into a shared repository frequently. Every time we add our code to a repository, the following two processes are expected to kick in:</p>
			<ul>
				<li>An automated build process starts to validate that the newly added code is not breaking anything from a compilation or syntax point of view. </li>
				<li>An automated test execution starts to verify that the existing, as well as new functionality is as per the test cases defined. </li>
			</ul>
			<p>The different steps and phases of the CI process are depicted in the following diagram. Although we have shown the build phase in this flowchart, it is not a required phase for Python-based projects as we can execute integration tests without compiled code:</p>
			<div><div><img src="img/B17189_05_05.jpg" alt="Figure 5.5 – Phases of CI testing &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.5 – Phases of CI testing </p>
			<p>To build a CI system, we need to have a stable distributed version control and a tool that can be used to implement workflow for testing the whole application through a series of test suites. There are several commercial and open source software tools available that provide CI and <strong class="bold">continuous delivery</strong> (<strong class="bold">CD</strong>) functionality. These tools are designed for easy integration with a source control system and with a test automation framework. A few popular tools available for CI are <em class="italic">Jenkins</em>, <em class="italic">Bamboo</em>, <em class="italic">Buildbot</em>, <em class="italic">GitLab CI</em>, <em class="italic">CircleCI,</em> and <em class="italic">Buddy</em>. Details of these tools appear in the <em class="italic">Further reading</em> section, for those of you who are interested to learn more.</p>
			<p>The obvious benefits of this automated CI<a id="_idIndexMarker628"/> are to detect errors quickly and fix them more conveniently right at the beginning. It is important to understand that CI is not about bug fixing, but it definitely helps to identify bugs easily and get them fixed promptly.</p>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor184"/>Summary</h1>
			<p>In this chapter, we introduced different levels of testing for software applications. We also evaluated two test frameworks (<code>unittest</code> and <code>pytest</code>) that are available for Python test automation. We learned how to build basic- and advanced-level test cases using these two frameworks. Later in the chapter, we introduced the TDD approach and its clear benefits for software development. Finally, we touched base on the topic of CI, which is a key step in delivering software using <strong class="bold">agile</strong> and <strong class="bold">development-operations</strong> (<strong class="bold">devops</strong>) models.</p>
			<p>This chapter is useful for anyone who wants to start writing unit tests for their Python application. The code examples provided provide a good starting point for us to write test cases using any test framework.</p>
			<p>In the next chapter, we will explore different tricks and tips for developing applications in Python.</p>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor185"/>Questions</h1>
			<ol>
				<li value="1">Is unit testing a form of white-box or black-box testing?</li>
				<li>When should we use mock objects?</li>
				<li>Which methods are used to implement test fixtures with the <code>unittest</code> framework?</li>
				<li>How is TDD different from CI?</li>
				<li>When should we use DDT?</li>
			</ol>
			<h1 id="_idParaDest-148"><a id="_idTextAnchor186"/>Further reading</h1>
			<ul>
				<li><em class="italic">Learning Python Testing</em>, by <em class="italic">Daniel Arbuckle</em></li>
				<li><em class="italic">Test-Driven Development with Python</em>, by <em class="italic">Harry J.W. Percival</em></li>
				<li><em class="italic">Expert Python Programming</em>, by <em class="italic">Michał Jaworski and Tarek Ziadé</em></li>
				<li><em class="italic">unittest</em> framework details are available with the Python documentation at <a href="https://docs.python.org/3/library/unittest.html">https://docs.python.org/3/library/unittest.html</a>.</li>
			</ul>
			<h1 id="_idParaDest-149"><a id="_idTextAnchor187"/>Answers</h1>
			<ol>
				<li value="1">White-box testing</li>
				<li>Mock objects help simulate the behavior of external or internal dependencies. By using mock objects, we can focus on writing tests for validating functional behavior. </li>
				<li><code>setUp</code>, <code>tearDown</code>, <code>setUpClass</code>, <code>tearDownClass</code> </li>
				<li>TDD is an approach to developing software by writing the test cases first. CI is a process in which all the tests are executed every time we build a new release. There is no direct relationship between TDD and CI.</li>
				<li>DDT is used when we have to do functional testing with several permutations of input parameters. For example, if we are required to test an API endpoint with a different combination of arguments, we can leverage DDT. </li>
			</ol>
		</div>
	</body></html>