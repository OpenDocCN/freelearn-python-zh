- en: Thread-Based Parallelism
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Currently, the most widely used programming paradigm for the management of concurrency
    in software applications is based on multithreading. Generally, an application
    is made by a single processthat is divided into multiple independent threads,
    which represent activities of different types that run in paralleland compete
    with each other.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, modern applications that use multithreading have been adopted on a
    massive scale. In fact, all current processors are multicore, just so they can
    perform parallel operations and exploit the computer's computational resources.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, *multithreaded programming*is definitely a good way to achieve concurrent
    applications. However, multithreaded programming often hides some non-trivial
    difficulties, which must be managed appropriately to avoid errors such as deadlocksor synchronization
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: We will first define the concepts of thread-based and multithreaded programming
    and then introduce the `multithreading` library. We will learn about the main
    directives for thread definition, management, and communication.
  prefs: []
  type: TYPE_NORMAL
- en: Through the `multithreading` library, we will see how to solve problems through
    different techniques, such as *lock*, *RLock*, *semaphores*, *condition*, *event*, *barrier, *and
    *queue*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: What is a thread?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to define a thread
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to determine the current thread
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use a thread in a subclass
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread synchronization with a lock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread synchronization with an RLock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread synchronization with semaphores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread synchronization with a condition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread synchronization with an event
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread synchronization with a barrier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread communication using a queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will also explore the main options offered by Python to program with threads.
    To do this, we will focus on using the `threading` module.
  prefs: []
  type: TYPE_NORMAL
- en: What is a thread?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A *thread* is an independent execution flow that can be executed in parallel
    and concurrently with other threads in the system.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple threads can share data and resources, taking advantage of the so-called
    space of shared information. The specific implementation of threads and processes
    depends on the OS on which you plan to run the application, but, in general, it
    can be stated that a thread is contained inside a process and that different threads
    in the same process conditions share some resources. In contrast to this, different
    processes do not share their own resources with other processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'A thread is composed of three elements: program counters, registers, and stack.
    Shared resources with other threads of the same process essentially include *data*
    and *OS resources*. Moreover, threads have their own state of execution, namely,
    *thread state*, and can be *synchronized* with other threads.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A thread state can be ready, running, or blocked:'
  prefs: []
  type: TYPE_NORMAL
- en: When a thread is created, it enters the **Ready **state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A thread is scheduled for execution by the OS (or by the runtime support system)
    and, when its turn arrives, it begins execution by going into the **Running **state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The thread can wait for a condition to occur, passing from the **Running **state
    to the **Blocked **state. Once the locked condition is terminated, the **Blocked **thread
    returns to the **Ready **state:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/1c9d8391-719e-4277-a1ae-dd4155345659.png)'
  prefs: []
  type: TYPE_IMG
- en: Thread life cycle
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage of multithreading programming lies in performances, as the
    context switch between processes turns out to be much heavier than the switch
    context between threads that belong to the same process.
  prefs: []
  type: TYPE_NORMAL
- en: In the next recipes, until the end of the chapter, we will examine the Python
    `threading` module, introducing its main functions through programming examples.
  prefs: []
  type: TYPE_NORMAL
- en: Python threading module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python manages threads with the `threading` module provided by the Python standard
    library. This module provides some very interesting features that make the threading-based
    approach a whole lot easier; in fact, the `threading` module provides several
    synchronization mechanisms that are very simple to implement.
  prefs: []
  type: TYPE_NORMAL
- en: 'The major components of the threading module are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The `thread` object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `lock` object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `RLock` object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `semaphore` object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `condition` object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `event` object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following recipes, we examine the features offered by the `threading`
    library with different application examples. For the examples that follow, we
    will refer to the Python 3.5.0 distribution ([https://www.python.org/downloads/release/python-350/](https://www.python.org/downloads/release/python-350/)).
  prefs: []
  type: TYPE_NORMAL
- en: Defining a thread
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The simplest way to use a thread is to instantiate it with a target function
    and then call the start method to let it begin the job.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Python `threading` module provides a `Thread` class that is used to run
    processes and functions in a different thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the parameters of the `Thread` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`group`: This is the `group` value, which should be `None`; this is reserved
    for future implementations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target`: This is the function that is to be executed when you start a thread
    activity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: This is the name of the thread; by default, a unique name of the form
    of `Thread-N` is assigned to it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args`: This is the tuple of arguments that are to be passed to a target.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kwargs`: This is the dictionary of keyword arguments that are to be used for
    the `target` function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, let's learn about how to define a thread.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ll define a thread by passing it a number, which represents the thread
    number, and finally, the result will be printed out:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `threading` module by using the following Python command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `main` program, a `Thread` object is instantiated with a `target` function
    called `my_func`. Then, an argument to the function that will be included in the
    output message is passed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The thread does not start running until the start method is called, and the
    `join` method makes the calling thread and waits until the thread has finished
    the execution, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the `main` program, we initialize the thread''s list, to which we add the
    instance of each thread that is created. The total number of threads created is
    10, while the **i**-index for the i^(th) thread is passed as an argument to the
    i^(th) thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All current processors are multicore, thus offering the possibility of performing
    multiple parallel operations and making the most of the computer's computational
    resources. Although this is true, multithread programming hides a number of non-trivial
    difficulties, which must be managed appropriately to avoid errors such as deadlocks
    or synchronization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Determining the current thread
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using arguments to identify or name the thread is cumbersome and unnecessary.
    Each `Thread` instance has a *name* with a default value that can be changed as
    the thread is created.
  prefs: []
  type: TYPE_NORMAL
- en: Naming threads is useful in server proc*esses* with multiple service threads
    that handle different operations.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This `threading` module provides the `currentThread().getName()` method, which
    returns the name of the current thread.
  prefs: []
  type: TYPE_NORMAL
- en: The following section shows us how to use this function to determine which thread
    is running.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s have a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To determine which thread is running, we create three `target` functions and
    import the `time` module to introduce a suspended execution of two seconds:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Three threads are instantiated with a `target` function. Then, we pass the
    name that is to be printed and, if it is not defined, then the default name will
    be used. Then, the `start()` and `join()` methods are called for each thread:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to set up three threads, each of which is assigned a `target` function.
    When the `target` function is executed and terminated, the function name is appropriately
    printed out.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, the output should look like this (even if the order shown
    cannot be the same):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Defining a thread subclass
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating a thread can require the definition of a subclass, which inherits from
    the `Thread` class. The latter, as explained in *Defining a thread* section, is
    included in the `threading` module, which must then be imported.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The class that we will define in the next section, which represents our thread,
    respects a precise structure: we will first have to define the **`__init__`**
    method, but, above all, we will have to override the `run` method.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps involved are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We defined the `MyThreadClass` class, which we can use to create all the threads
    we want. Each thread of this type will be characterized by the operations defined
    in the `run` method, which, in this simple example, limits itself to printing
    a string at the beginning and at the end of its execution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Furthermore, in the `__init__` method, we have specified two initialization
    parameters, respectively, `name` and `duration`, that will be used in the `run`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'These parameters will then be set during the creation of the thread. In particular,
    the `duration` parameter is computed using the `randint` function that outputs
    a random integer between `1` and `10`. Starting from the definition of `MyThreadClass`,
    let''s see how to instantiate more threads, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we created nine threads, each with their own `name` and `duration`
    property, according to the definition of the `__init__` method.
  prefs: []
  type: TYPE_NORMAL
- en: We then run them using the `start` method, which is limited to executing the
    contents of the previously defined `run` method. Note that the process ID for
    each thread is the same, meaning that we are in a multithreaded process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, note that the start method *is not blocking*: when it is executed, the
    control immediately goes to the next line, while the thread is started in the
    background. In fact, as you can see, the creation of threads *does not take place*
    in the order specified by the code. Likewise, thread termination is constrained
    to the value of the `duration` parameter, evaluated using the `randint` function,
    and passed by the parameter for each thread creation instance. To wait for a thread
    to finish, a `join` operation must be performed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The feature that is most frequently associated with OOP is *inheritance*, which
    is the ability to define a new class as a modified version of an already existing
    class. The main advantage of inheritance is that you can add new methods to a
    class without having to change the original definition.
  prefs: []
  type: TYPE_NORMAL
- en: The original class is often referred to as the parent class and the derived
    class, subclass. Inheritance is a powerful feature, and some programs can be written
    much more easily and concisely, providing the possibility to customize the behavior
    of a class without modifying the original class. The very fact that the inheritance
    structure can reflect that of the problem can, in some cases, make the program
    easier to understand.
  prefs: []
  type: TYPE_NORMAL
- en: However (to put the user on guard!), inheritance can make it more difficult
    to read the program. This is because, when invoking a method, it is not always
    clear where this has been defined within the code that must be traced within multiple
    modules, instead of being in a single well-defined place.
  prefs: []
  type: TYPE_NORMAL
- en: Many of the things that can be done with inheritance can usually be managed
    elegantly even without it, so it is appropriate to only use inheritance if the
    structure of the problem requires it. If used at the wrong time, then the harm
    inheritance can cause can outweigh the benefits of using it.
  prefs: []
  type: TYPE_NORMAL
- en: Thread synchronization with a lock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `threading` module also includes a simple lock mechanism, which allows us
    to implement synchronization between threads.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A *lock* is nothing more than an object that is typically accessible by multiple
    threads, which a thread must possess before it can proceed to the execution of
    a protected section of a program. These locks are created by executing the `Lock()`
    method, which is defined in the `threading` module.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the lock has been created, we can use two methods that allow us to synchronize
    the execution of two (or more) threads: the `acquire()` method to acquire the
    lock control, and the `release()` method to release it.'
  prefs: []
  type: TYPE_NORMAL
- en: The `acquire()` method accepts an optional parameter that, if not specified
    or set to `True`, forces the thread to suspend its execution until the lock is
    released and can then be acquired. If, on the other hand, the `acquire()` method
    is executed with an argument equal to `False`, then it immediately returns a Boolean
    result, which is `True` if the lock has been acquired, or `False` otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we show the lock mechanism by modifying the code introduced
    in the previous recipe, *Defining a thread subclass*.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps involved are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the following code block, the `MyThreadClass` class has been modified,
    introducing the `acquire()` and `release()` methods within the **`run`** method,
    while the `Lock()` definition is outside the definition of the class itself:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `main()` function has not changed with respect to the previous code sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have modified the code of the previous section by using a lock so that the
    threads will be executed in sequence.
  prefs: []
  type: TYPE_NORMAL
- en: The first thread acquires the lock and performs its task while the other eight
    remain *on hold.* At the end of the execution of the first thread, that is, when
    the `release()` method is executed, the second one will get the lock and the threads
    from three to eight will still be waiting until the end of the execution (that
    is, once again, only after running the `release()` method).
  prefs: []
  type: TYPE_NORMAL
- en: 'The *lock-acquire* and *lock-release* execution are repeated until the ninth
    thread, with the final result that as a result of the lock mechanism, this execution
    takes place in a sequential mode, as can be seen in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The insertion points of the `acquire()` and `release()` methods determine the
    entire execution of the code. For this reason, it is very important that you take
    the time to analyze what threads you want to use and how you want to synchronize
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we can change the insertion point of the `release()` method in
    the `MyThreadClass` class like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the output changes quite significantly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, only the thread creation happens in sequential mode. Once thread
    creation is complete, the new thread acquires the lock, while the previous one
    continues the computation in the background.
  prefs: []
  type: TYPE_NORMAL
- en: Thread synchronization with RLock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A reentrant lock, or simply an RLock, is a synchronization primitive that can
    be acquired multiple times by the same thread.
  prefs: []
  type: TYPE_NORMAL
- en: It uses the concept of the proprietary thread. This means that in the *locked
    state*, some threads own the lock, while in the *unlocked state*, the lock is
    not owned by any thread.
  prefs: []
  type: TYPE_NORMAL
- en: The next example demonstrates how to manage threads through the `RLock()` mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An RLock is implemented through the `threading.RLock()` class. It provides the
    `acquire()` and `release()` methods that have the same syntax as the `threading.Lock()`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: An `RLock` block can be acquired multiple times by the same thread. Other threads
    will not be able to acquire the `RLock` block until the thread that owns it has
    made a `release()` call for every previous `acquire()` call. Indeed, the `RLock`
    block must be released, but only by the thread that acquired it.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps involved are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We introduced the `Box` class, which provides the `add()` and `remove()` methods
    that access the `execute()` method in order to perform the action to add or delete
    an item, respectively. Access to the `execute()` method is regulated by `RLock()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The following functions are called by the two threads. They have the `box` class and
    the total number of `items` to add or to remove as parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the total number of items to add or to remove from the box is set. As
    you can see, these two numbers will be different. The execution ends when both
    the `adder` and `remover` methods accomplish their tasks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the `main` program, the two threads of `t1` and `t2` have been associated
    with the `adder()` and `remover()` functions. The functions are active if the
    number of items is greater than zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'The call to `RLock()` is carried out inside the `__init__` method of the **`Box`**
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The two `adder()` and `remover()` functions interact with the items of the `Box`
    class, respectively, and call the `Box` class methods of `add()` and `remove()`.
  prefs: []
  type: TYPE_NORMAL
- en: In each method call, a resource is captured and then released using the `lock`
    parameter that is set in the `_init_` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The differences between *lock* and *RLock* are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A *lock* can only be acquired once before it must be released. However, `RLock`
    can be acquired multiple times from the same thread; it must be released the same
    number of times in order to be released.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another difference is that an acquired lock can be released by any thread, whereas
    an acquired `RLock` can only be released by the thread that acquired it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread synchronization with semaphores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **semaphore** is an abstract data type managed by the OS to synchronize access
    by multiple threads to shared resources and data. It consists of an internal variable
    that identifies the amount of concurrent access to a resource with which it is
    associated.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The operation of a semaphore is based on two functions: `acquire()` and `release()`,
    as explained here:'
  prefs: []
  type: TYPE_NORMAL
- en: Whenever a thread wants to access a given or a resource that is associated with
    a semaphore, it must invoke the `acquire()` operation, which *decreases the internal
    variable of the semaphore* and allows access to the resource if the value of this
    variable appears to be non-negative. If the value is negative, then the thread
    will be suspended and the release of the resource by another thread will be placed
    on hold.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having finished using shared resources, the thread frees resources through the
    `release()` instruction. In this way, the internal variable of the semaphore is
    increased, allowing, for a *waiting* thread (if any), the opportunity to access
    the newly freed resource.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The semaphore is one of the oldest synchronization primitives in the history
    of computer science, invented by the early Dutch computer scientist Edsger W.
    Dijkstra.
  prefs: []
  type: TYPE_NORMAL
- en: The following example shows how to synchronize threads through a semaphore.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following code describes a problem where we have two threads, `producer()`
    and `consumer()`, that share a common resource, which is the item. The task of
    `producer()` is to generate the item while the `consumer()` thread's task is to
    use the item that has been produced.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the item has not yet produced the `consumer()` thread, then it has to wait.
    As soon as the item is produced, the `producer()` thread notifies the consumer
    that the resource should be used:'
  prefs: []
  type: TYPE_NORMAL
- en: 'By initializing a semaphore to `0`, we obtain a so-called semaphore event whose
    sole purpose is to synchronize the computation of two or more threads. Here, a
    thread must make use of data or common resources simultaneously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This operation is very similar to that described in the lock mechanism of the
    lock. The `producer()` thread creates the item and, after that, it frees the resource
    by calling the `release()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the `consumer()` thread acquires the data by the `acquire()` method.
    If the semaphore''s counter is equal to `0`, then it blocks the condition''s `acquire()`
    method until it gets notified by a different thread. If the semaphore''s counter
    is greater than `0`, then it decrements the value. When the producer creates an
    item, it releases the semaphore, and then the consumer acquires it and consumes
    the shared resource:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The synchronization process that is done via the semaphores is shown in the
    following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The data acquired is then printed on the standard output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the result that we get after 10 runs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A particular use of semaphores is the *mutex*. A mutex is nothing but a semaphore
    with an internal variable initialized to the value of `1`, which allows the realization
    of mutual exclusion in access to data and resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Semaphores are still commonly used in programming languages that are multithreaded;
    however, they have two major problems, which we have discussed, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: They do not prevent the possibility of a thread performing more wait operations
    on the same semaphore. It is very easy to forget to do all the necessary signals
    in relation to the number of waits performed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can run into situations of deadlock. For example, a deadlock situation is
    created when the `t1` thread executes a wait on the `s1` semaphore, while the
    **`t2`** thread executes a wait on the thread `t1`, executes a wait on `s2` and
    `t2`, and then executes a wait on `s1`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread synchronization with a condition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A *condition* identifies a change of state in the application. It is a synchronization
    mechanism where a thread waits for a specific condition and another thread notifies
    that this *condition has taken place*.
  prefs: []
  type: TYPE_NORMAL
- en: Once the condition takes place, the thread *acquires* the lock in order to get
    *exclusive access* to the shared resource.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good way to illustrate this mechanism is by looking again at a producer/consumer
    problem. The class producer writes to a buffer if it is not full, and the class
    consumer takes the data from the buffer (eliminating them from the latter) if
    the buffer is full. The class producer will notify the consumer that the buffer
    is not empty, while the consumer will report to the producer that the buffer is
    not full.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps involved are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The class consumer acquires the shared resource that is modelled through the **`items[]`** list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'If the length of the list is equal to `0`, then the consumer is placed in a
    waiting state:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Then it makes a **`pop`** operation from the items list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the consumer''s state is notified to the producer and the shared resource
    is released:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The class producer acquires the shared resource and then it verifies that the
    list is completely full (in our example, we place the maximum number of items,
    `10`, that can be contained in the items list). If the list is full, then the
    producer is placed in the wait state until the list is consumed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'If the list is not full, then a single item is added. The state is notified
    and the resource is released:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'To show you the condition mechanism, we will use the *consumer/producer* model again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`producer` generates the item and stores it in the buffer continuously. At
    the same time, `consumer` uses the data produced, removing it from the buffer
    from time to time.'
  prefs: []
  type: TYPE_NORMAL
- en: As soon as `consumer` has picked up an object from the buffer, it will wake
    up `producer`, who will start to fill the buffer again.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, `consumer` will suspend if the buffer is empty. As soon as `producer`
    has downloaded the data into the buffer, `consumer` will wake up.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, even in this case, the use of the `condition` directive allows
    the threads to be properly synchronized.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result that we get after a single run is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s interesting to see the Python internals for the condition synchronization
    mechanism. The internal `class _Condition` creates an `RLock()` object if no existing
    lock has been passed to the class''s constructor. Also, the lock will be managed
    when `acquire()` and `released()` are called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Thread synchronization with an event
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An event is an object that is used for communication between threads. A thread
    waits for a signal while another thread outputs it. Basically, an `event` object
    manages an internal flag that can be set to `false` with `clear()`, set to `true`
    with `set()`, and tested with `is_set()`.
  prefs: []
  type: TYPE_NORMAL
- en: A thread can hold a signal by means of the `wait()` method, which sends the
    call with the `set()` method.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To understand thread synchronization through the `event` object, let's take
    a look at the producer/consumer problem.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Again, to explain how to synchronize threads through events, we will refer to
    the *producer/consumer* problem. The problem describes two processes, a producer
    and a consumer, who share a common buffer of a fixed size. The producer's task
    is to generate items and deposit them in the continuous buffer. At the same time,
    the consumer will use the items produced, removing them from the buffer from time
    to time.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is to ensure that the producer does not process new data if the
    buffer is full and that the consumer does not look for data if the buffer is empty.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see how to implement the consumer/producer problem by using thread
    synchronization with an `event` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the relevant libraries are imported as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define the log output format. It is useful to clearly visualize what''s
    happening:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the `items` list. This parameter will be used by the `Consumer` and `Producer`
    classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The `event` parameter is defined as follows. This parameter will be used to
    synchronize the communication between threads:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Consumer` class is initialized with the list of items and the `Event()`
    function. In the `run` method, the consumer waits for a new item to consume. When
    the item arrives, it is popped from the `item` list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Producer` class is initialized with the list of items and the `Event()`
    function. Unlike the example with `condition` objects, the item list is not global,
    but it is passed as a parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `run` method for each item that is created, the `Producer` class appends
    it to the list of items and then notifies the event:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two steps that you need to take for this and the first step, which
    are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The `t1` thread appends a value to the list and then sets the event to notify
    the consumer. The consumer''s call to `wait()` stops blocking and the integer
    is retrieved from the list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All the operations between the `Producer` and the `Consumer` classes can be
    easily resumed with the help of the following schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/915fcac0-899f-465a-9fd2-ce18a24bb0f0.png)'
  prefs: []
  type: TYPE_IMG
- en: Thread synchronization with event objects
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, the `Producer` and the `Consumer` classes have the following
    behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Producer` acquires a lock, adds an item to the queue, and notifies this event
    to `Consumer` (`set event`). It then sleeps until it receives a new item to add.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Consumer` acquires a block and then begins to listen to the elements in a
    continuous cycle. The moment the event arrives, the consumer abandons the block,
    thus allowing other producers/consumers to enter and acquire the block. If `Consumer`
    is reactivated, then it reacquires the lock by safely processing new items from
    the queue:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Thread synchronization with a barrier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sometimes, an application can be divided into phases with the rule that no
    process can continue if first, all threads of the process have completed their
    own task. A **barrier** implements this concept: a thread that has finished its
    phase calls a primitive barrier and stops. When all the threads involved have
    finished their stage of execution and have also invoked the primitive barrier,
    the system unlocks them all, allowing threads to move to a later stage.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python's threading module implements barriers through the **`Barrier`** class. In
    the next section, let's learn about how to use this synchronization mechanism
    in a very simple example.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we simulate a run with three participants, `Huey`, `Dewey`,
    and `Louie`, in which a barrier is assimilated to that of a finish line.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the race can end on its own when all three participants cross the
    finish line.
  prefs: []
  type: TYPE_NORMAL
- en: 'The barrier is implemented through the `Barrier` class, in which the number
    of threads to be completed must be specified as an argument to move to the next
    stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we set the number of runners to `num_runners = 3` in order to set the
    final goal on the next line through the `Barrier` directive. The runners are set
    in the runners' list; each of them will have an arrival time that is determined
    in the `runner` function, using the `randrange` directive.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a runner arrives at the finish line, call the `wait` method, which will
    block all the runners (the threads) that have made that call. The output for this
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: In this case, `Dewey` won the race.
  prefs: []
  type: TYPE_NORMAL
- en: Thread communication using a queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multithreading can be complicated when threads need to share data or resources.
    Luckily, the threading module provides many synchronization primitives, including
    semaphores, condition variables, events, and locks.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is considered a best practice to use the `queue` module. In fact,
    a queue is much easier to deal with and makes threaded programming considerably
    safer, as it effectively funnels all access to a resource of a single thread and
    allows for a cleaner and more readable design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will simply consider these queue methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`put()`: Puts an item in the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`get()`: Removes and returns an item from the queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`task_done()`: Needs to be called each time an item has been processed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`join()`: Blocks until all items have been processed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, we will see how to use the `threading` module with the `queue`
    module. Also, we have two entities here that try to share a common resource, a
    queue. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, with the `producer` class, we don't need to pass the integers list because
    we use the queue to store the integers that are generated.
  prefs: []
  type: TYPE_NORMAL
- en: The thread in the `producer` class generates integers and puts them in the queue
    in a `for` loop. The `producer` class uses `Queue.put(item[, block[, timeout]])`
    to insert data in the queue. It has the logic to acquire the lock before inserting
    data in a queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: If the optional arguments `block` is `true` and `timeout` is `None` (this is
    the default case that we used in the example), then it is necessary for us to
    block until a free slot is available. If the timeout is a positive number, then
    it blocks at most timeout seconds and raises the full exception if no free slot
    is available within that time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the block is `false`, then put an item in the queue if a free slot is immediately
    available, otherwise, raise the full exception (timeout is ignored in this case).
    Here, `put` checks whether the queue is full and then calls `wait` internally,
    after which, the producer starts waiting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next is the `consumer` class. The thread gets the integer from the queue and
    indicates that it is done working on it by using `task_done`. The `consumer` class
    uses `Queue.get([block[, timeout]])` and acquires the lock before removing data
    from the queue. The consumer is placed in a waiting state, in case the queue is
    empty. Finally, in the `main` function, we create four threads, one for the `producer`
    class and three for the `consumer` class, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output should be like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All the operations between the `producer` class and the `consumer` class can
    easily be resumed with the following schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb11a94d-258a-485f-a1b4-8954a860b41a.png)'
  prefs: []
  type: TYPE_IMG
- en: Thread synchronization with the queue module
  prefs: []
  type: TYPE_NORMAL
- en: The `Producer` thread acquires the lock and then inserts data in the **QUEUE**
    data structure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Consumer` threads get the integers from the **QUEUE**. These threads acquire
    the lock before removing data from the **QUEUE**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the **QUEUE** is empty, then the `consumer` threads get in a **waiting**
    state.
  prefs: []
  type: TYPE_NORMAL
- en: With this recipe, the chapter dedicated to thread-based parallelism comes to
    an end.
  prefs: []
  type: TYPE_NORMAL
