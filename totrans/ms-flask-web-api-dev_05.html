<html><head></head><body>
		<div id="_idContainer043">
			<h1 id="_idParaDest-110" class="chapter-number"><a id="_idTextAnchor111"/><st c="0">5</st></h1>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor112"/><st c="2">Building Asynchronous Transactions</st></h1>
			<p><st c="36">After rigorous discussion on the core components and advanced features of the Flask 3.0 framework, this chapter will explore Flask’s capability to manage requests and responses asynchronously and its ability to execute asynchronous services and </st><span class="No-Break"><st c="282">repository transactions.</st></span></p>
			<p><st c="306">Flask was originally a standard Python framework that ran on the </st><strong class="bold"><st c="372">Web Server Gateway Interface</st></strong><st c="400"> (</st><strong class="bold"><st c="402">WSGI</st></strong><st c="406">)-based platform popular in managing blocking processes. </st><st c="464">But Flask 3.0 supports the creation and execution of non-blocking view and API functions. </st><st c="554">It can run transactions using some </st><strong class="source-inline"><st c="589">asyncio</st></strong><st c="596"> utilities and build asynchronous repository transactions with </st><span class="No-Break"><st c="659">SQLAlchemy 2.x.</st></span></p>
			<p><st c="674">This chapter will also explore other avenues that help provide Flask applications with the fastest performance using asynchronous mechanisms, such as Celery tasks, task queues, WebSocket, and server push. </st><st c="880">The chapter will also introduce </st><strong class="bold"><st c="912">Quart</st></strong><st c="917">, the asynchronous Flask-based platform that can build and run all components asynchronously compared to the original </st><span class="No-Break"><st c="1035">Flask framework.</st></span></p>
			<p><st c="1051">Here are the topics that this chapter </st><span class="No-Break"><st c="1090">will highlight:</st></span></p>
			<ul>
				<li><st c="1105">Creating asynchronous </st><span class="No-Break"><st c="1128">Flask components</st></span></li>
				<li><a id="_idTextAnchor113"/><st c="1144">Building an asynchronous SQLAlchemy </st><span class="No-Break"><st c="1181">repository layer</st></span></li>
				<li><st c="1197">Implementing async transactions </st><span class="No-Break"><st c="1230">with </st></span><span class="No-Break"><strong class="source-inline"><st c="1235">asyncio</st></strong></span></li>
				<li><st c="1242">Utilizing asynchronous </st><span class="No-Break"><st c="1266">signal notifications</st></span></li>
				<li><st c="1286">Constructing background tasks with Celery </st><span class="No-Break"><st c="1329">and Redis</st></span></li>
				<li><st c="1338">Building WebSockets with </st><span class="No-Break"><st c="1364">asynchronous transactions</st></span></li>
				<li><st c="1389">Implementing asynchronous </st><strong class="bold"><st c="1416">Server-Sent </st></strong><span class="No-Break"><strong class="bold"><st c="1428">Events</st></strong></span><span class="No-Break"><st c="1434"> (</st></span><span class="No-Break"><strong class="bold"><st c="1436">SSE</st></strong></span><span class="No-Break"><st c="1439">)</st></span></li>
				<li><st c="1441">Applying reactive programming </st><span class="No-Break"><st c="1471">with RxPy</st></span></li>
				<li><st c="1480">Choosing Quart over </st><span class="No-Break"><st c="1501">Flask 2.x</st></span></li>
			</ul>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor114"/><st c="1510">Technical requirements</st></h1>
			<p><st c="1533">This chapter will highlight an </st><em class="italic"><st c="1565">Online Voting System</st></em><st c="1585"> prototype with some asynchronous tasks and background processes to manage the high bandwidth of candidates’ applications and election-related submissions from different areas and to cater to the simultaneous retrieval of vote tallies from various parties. </st><st c="1842">The system is composed of three separate projects, namely </st><strong class="source-inline"><st c="1900">ch05-api</st></strong><st c="1908">, which has the API endpoints, </st><strong class="source-inline"><st c="1939">ch05-web</st></strong><st c="1947">, which implements the SSE, WebSocket, and template-based results, and </st><strong class="source-inline"><st c="2018">ch05-quart</st></strong><st c="2028">, which provides another platform for the app using the Quart framework. </st><st c="2101">All these projects use the </st><strong class="bold"><st c="2128">application factory design</st></strong><st c="2154"> pattern and are available </st><span class="No-Break"><st c="2181">at </st></span><a href="https://github.com/PacktPublishing/Mastering-Flask-Web-Development/tree/main/ch05"><span class="No-Break"><st c="2184">https://github.com/PacktPublishing/Mastering-Flask-Web-Development/tree/main/ch05</st></span></a><span class="No-Break"><st c="2265">.</st></span></p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor115"/><st c="2266">Creating asynchronous Flask components</st></h1>
			<p><st c="2305">Flask 2.3 and up</st><a id="_idIndexMarker285"/><st c="2322"> to the current version support running asynchronous API endpoint and web-based view functions over its WSGI-based platform. </st><st c="2447">However, to fully use this feature, install the </st><strong class="source-inline"><st c="2495">flask[async]</st></strong><st c="2507"> module using the following </st><span class="No-Break"><strong class="source-inline"><st c="2535">pip</st></strong></span><span class="No-Break"><st c="2538"> command:</st></span></p>
			<pre class="console"><st c="2547">
pip install flask[async]</st></pre>			<p><st c="2572">After installing the </st><strong class="source-inline"><st c="2594">flask[async]</st></strong><st c="2606"> module, implementing synchronous views using the </st><strong class="source-inline"><st c="2656">async</st></strong><st c="2661">/</st><strong class="source-inline"><st c="2663">await</st></strong><st c="2668"> design pattern can now </st><span class="No-Break"><st c="2692">be feasible.</st></span></p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor116"/><st c="2704">Implementing asynchronous views and endpoints</st></h2>
			<p><st c="2750">Like</st><a id="_idIndexMarker286"/><st c="2755"> Django or FastAPI, creating asynchronous views and endpoints in the Flask framework involves applying the </st><strong class="source-inline"><st c="2862">async</st></strong><st c="2867">/</st><strong class="source-inline"><st c="2869">await</st></strong><st c="2874"> keywords. </st><st c="2885">The following web view from </st><strong class="source-inline"><st c="2913">ch05-web</st></strong><st c="2921"> renders a welcome greeting message to the users with the description of our </st><em class="italic"><st c="2998">Online </st></em><span class="No-Break"><em class="italic"><st c="3005">Voting</st></em></span><span class="No-Break"><st c="3011"> application:</st></span></p>
			<pre class="source-code"><st c="3024">
@current_app.route('/ch05/web/index')
</st><strong class="bold"><st c="3063">async</st></strong><st c="3068"> def welcome():
    return render_template('index.html'), 200</st></pre>			<p><st c="3125">Another asynchronous view function from the other application, </st><strong class="source-inline"><st c="3189">ch05-api</st></strong><st c="3197">, is showcased in the following </st><a id="_idIndexMarker287"/><st c="3229">API endpoint that adds new login credentials to the </st><span class="No-Break"><strong class="bold"><st c="3281">database</st></strong></span><span class="No-Break"><st c="3289"> (</st></span><span class="No-Break"><strong class="bold"><st c="3291">DB</st></strong></span><span class="No-Break"><st c="3293">):</st></span></p>
			<pre class="source-code"><st c="3296">
@current_app.post('/ch05/login/add')
</st><strong class="bold"><st c="3334">async</st></strong><st c="3339"> def add_login():
   async with db_session() as sess:
            repo = LoginRepository(sess)
            login_json = request.get_json()
            login = Login(**login_json)
            result = await repo.insert(login)
            if result:
                content = jsonify(login_json)
                return make_response(content, 201)
            else:
                raise DuplicateRecordException("add login credential has failed")</st></pre>			<p><st c="3660">Both the given view and API functions use </st><strong class="source-inline"><st c="3703">async</st></strong><st c="3708"> routes to manage their respective request and response objects. </st><st c="3773">Defining these routes with </st><strong class="source-inline"><st c="3800">async</st></strong><st c="3805"> creates coroutines that Flask 2.x can surprisingly run using the </st><strong class="source-inline"><st c="3871">run()</st></strong><st c="3876"> utility of the </st><strong class="source-inline"><st c="3892">asyncio</st></strong><st c="3899"> module. </st><st c="3908">But how does the Flask framework manage the coroutine executions despite the pitfalls of its </st><span class="No-Break"><st c="4001">WSGI platform?</st></span></p>
			<p><st c="4015">Flask spawns a </st><strong class="bold"><st c="4031">worker thread</st></strong><st c="4044"> to run</st><a id="_idIndexMarker288"/><st c="4051"> these views and endpoints. </st><st c="4079">With </st><strong class="source-inline"><st c="4084">async</st></strong><st c="4089">, the framework creates a </st><em class="italic"><st c="4115">sub-thread</st></em><st c="4125"> from the worker thread to create an </st><strong class="bold"><st c="4162">event loop</st></strong><st c="4172"> that </st><a id="_idIndexMarker289"/><st c="4178">will execute the coroutine using the </st><strong class="source-inline"><st c="4215">asyncio</st></strong><st c="4222"> utilities. </st><st c="4234">Despite the asynchronous processes, there are still limitations on how far </st><strong class="source-inline"><st c="4309">async</st></strong><st c="4314"> can push through since the environment is still within the WSGI, a synchronous platform. </st><st c="4404">However, for not-so-complex non-blocking transactions, the </st><strong class="source-inline"><st c="4463">flask[async]</st></strong><st c="4475"> framework is enough to improve software quality </st><span class="No-Break"><st c="4524">and performance.</st></span></p>
			<p><st c="4540">However, async components</st><a id="_idIndexMarker290"/><st c="4566"> are not limited to view and API functions and also have Flask </st><span class="No-Break"><st c="4629">event handlers.</st></span></p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor117"/><st c="4644">Implementing the async before_request and after_request handlers</st></h2>
			<p><st c="4709">Aside from </st><a id="_idIndexMarker291"/><st c="4721">views and endpoints, the Flask 3.0 framework allows the</st><a id="_idIndexMarker292"/><st c="4776"> implementation of asynchronous </st><strong class="source-inline"><st c="4808">before_request</st></strong><st c="4822"> and </st><strong class="source-inline"><st c="4827">after_request</st></strong><st c="4840"> handlers, just like the following </st><strong class="source-inline"><st c="4875">ch05-api</st></strong><st c="4883"> handlers that log every API </st><span class="No-Break"><st c="4912">request transaction:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="4932">@app.before_request</st></strong>
<strong class="bold"><st c="4952">async</st></strong><st c="4958"> def init_request():
    app.logger.info('executing ' + request.endpoint + ' starts')
</st><strong class="bold"><st c="5040">@app.after_request</st></strong>
<strong class="bold"><st c="5058">async</st></strong><st c="5064"> def return_response(response):
    app.logger.info('executing ' + request.endpoint + ' stops')
    return response</st></pre>			<p><st c="5171">These event handlers still use the </st><strong class="source-inline"><st c="5207">app</st></strong><st c="5210"> instance created in </st><strong class="source-inline"><st c="5231">main.py</st></strong><st c="5238"> to create the log files using the built-in </st><span class="No-Break"><strong class="source-inline"><st c="5282">logging</st></strong></span><span class="No-Break"><st c="5289"> module.</st></span></p>
			<p><st c="5297">On the other hand, the </st><strong class="source-inline"><st c="5321">flask[async]</st></strong><st c="5333"> module can allow the creation of asynchronous </st><span class="No-Break"><st c="5380">error handlers.</st></span></p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor118"/><st c="5395">Creating asynchronous error handlers</st></h2>
			<p><st c="5432">Flask 2.x can </st><a id="_idIndexMarker293"/><st c="5447">decorate coroutines with </st><strong class="source-inline"><st c="5472">@errorhandler</st></strong><st c="5485"> to manage raised exceptions and HTTP status codes. </st><st c="5537">The following are the asynchronous error handlers of the </st><strong class="source-inline"><st c="5594">ch05-api</st></strong><st c="5602"> project placed </st><span class="No-Break"><st c="5618">in </st></span><span class="No-Break"><strong class="source-inline"><st c="5621">main.py</st></strong></span><span class="No-Break"><st c="5628">:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="5630">@app.errorhandler(404)</st></strong>
<strong class="bold"><st c="5652">async</st></strong><st c="5658"> def not_found(e):
    return jsonify(error=str(e)), 404
</st><strong class="bold"><st c="5711">@app.errorhandler(400)</st></strong>
<strong class="bold"><st c="5733">async</st></strong><st c="5739"> def bad_request(e):
    return jsonify(error=str(e)), 400
</st><strong class="bold"><st c="5794">@app.errorhandler(DuplicateRecordException)</st></strong>
<strong class="bold"><st c="5837">async</st></strong><st c="5843"> def insert_record_exception(e):
    return jsonify(e.to_dict()), e.code
</st><strong class="bold"><st c="5912">async</st></strong><st c="5917"> def server_error(e):
    return jsonify(error=str(e)), 500
app.register_error_handler(500, server_error)</st></pre>			<p><st c="6018">Now, all these </st><a id="_idIndexMarker294"/><st c="6034">asynchronous Flask components can also await other asynchronous operations such as the repository layer of the application. </st><st c="6158">Indeed, the asynchronous Flask environment is open to integration with asynchronous third-party extension modules such as the async </st><span class="No-Break"><st c="6290">SQLAlchemy 2.x.</st></span></p>
			<h1 id="_idParaDest-117"><a id="_idTextAnchor119"/><st c="6305">Building an asynchronous SQLAlchemy repository layer</st></h1>
			<p><st c="6358">The</st><a id="_idIndexMarker295"/><st c="6362"> updated </st><strong class="source-inline"><st c="6371">flask-sqlalchemy</st></strong><st c="6387"> extension module supports SQLAlchemy 2.x that provides API utilities, which use the </st><strong class="source-inline"><st c="6472">asyncio</st></strong><st c="6479"> environment with </st><strong class="source-inline"><st c="6497">greenlet</st></strong><st c="6505"> as the main library, allowing propagation of the </st><strong class="source-inline"><st c="6555">await</st></strong><st c="6560"> keyword in the APIs’ internal processes. </st><st c="6602">Our </st><strong class="source-inline"><st c="6606">ch05-web</st></strong><st c="6614"> and </st><strong class="source-inline"><st c="6619">ch05-api</st></strong><st c="6627"> projects have the async transactions that call these awaited</st><a id="_idIndexMarker296"/><st c="6688"> SQLAlchemy </st><strong class="bold"><st c="6700">Create-Read-Update-Delete</st></strong><st c="6725"> (</st><strong class="bold"><st c="6727">CRUD</st></strong><st c="6731">) operations using a new DB configuration in our projects’ </st><strong class="source-inline"><st c="6791">/models/config.py</st></strong><st c="6808"> file that utilizes an </st><strong class="source-inline"><st c="6831">asyncpg</st></strong><st c="6838"> driver to build a session for non-blocking </st><span class="No-Break"><st c="6882">repository transactions.</st></span></p>
			<h2 id="_idParaDest-118"><a id="_idTextAnchor120"/><st c="6906">Setting up the DB connectivity</st></h2>
			<p><st c="6937">To start</st><a id="_idIndexMarker297"/><st c="6946"> with the configuration, install the </st><strong class="source-inline"><st c="6983">asyncpg</st></strong><st c="6990"> DB driver or dialect that the </st><strong class="source-inline"><st c="7021">asyncio</st></strong><st c="7028">-driven SQLAlchemy module requires using the </st><span class="No-Break"><strong class="source-inline"><st c="7074">pip</st></strong></span><span class="No-Break"><st c="7077"> command:</st></span></p>
			<pre class="console"><st c="7086">
pip install asyncpg</st></pre>			<p><st c="7106">Also, include the greenlet library in the installation if it is not yet part of the </st><span class="No-Break"><st c="7191">virtual environment:</st></span></p>
			<pre class="console"><st c="7211">
pip install greenlet</st></pre>			<p><st c="7232">The setup also requires </st><a id="_idIndexMarker298"/><st c="7257">a </st><strong class="bold"><st c="7259">connection string</st></strong><st c="7276"> or </st><strong class="bold"><st c="7280">DB URL</st></strong><st c="7286"> for the DB</st><a id="_idIndexMarker299"/><st c="7297"> connectivity that includes the installed </st><strong class="source-inline"><st c="7339">asyncpg</st></strong><st c="7346"> protocol, user credentials, the DB server host address, port, and the schema name. </st><st c="7430">Our projects use the connection string, </st><strong class="source-inline"><st c="7470">postgresql+asyncpg://postgres:admin2255@localhost:5433/ovs</st></strong><st c="7528">, to generate the </st><strong class="source-inline"><st c="7546">AsyncEngine</st></strong><st c="7557"> instance of the connection using </st><strong class="source-inline"><st c="7591">create_async_engine()</st></strong><st c="7612"> of the SQLAlchemy framework, the asynchronous version of its </st><strong class="source-inline"><st c="7674">create_engine()</st></strong><st c="7689"> utility. </st><st c="7699">Aside from the DB URL, the method requires its </st><strong class="source-inline"><st c="7746">future</st></strong><st c="7752"> parameter to be set to </st><strong class="source-inline"><st c="7776">True</st></strong><st c="7780">, </st><strong class="source-inline"><st c="7782">pool_pre_pring</st></strong><st c="7796"> to be set to </st><strong class="source-inline"><st c="7810">True</st></strong><st c="7814">, and </st><strong class="source-inline"><st c="7820">poolclass</st></strong><st c="7829"> to be set to a connection pooling strategy such as </st><strong class="source-inline"><st c="7881">NullPool</st></strong><st c="7889">. </st><strong class="source-inline"><st c="7891">poolclass</st></strong><st c="7900"> manages the threads the SQLAlchemy will utilize during its CRUD operations, and setting it to </st><strong class="source-inline"><st c="7995">NullPool</st></strong><st c="8003"> will restrict one Python thread to run only one event loop for one CRUD operation. </st><strong class="source-inline"><st c="8087">pool_pre_ping</st></strong><st c="8100">, on the other hand, helps connection pooling for the pessimistic approach of handling disconnection. </st><st c="8202">If it determines the DB connection as non-usable or invalid, that connection and its previous ones will be immediately recycled before executing a new operation. </st><st c="8364">Most importantly, the </st><strong class="source-inline"><st c="8386">future</st></strong><st c="8392"> parameter must be set to </st><strong class="source-inline"><st c="8418">True</st></strong><st c="8422"> to enable asynchronous features of SQLAlchemy 2.x, or else the asynchronous SQLAlchemy setup will </st><span class="No-Break"><st c="8521">not work.</st></span></p>
			<p><st c="8530">After its successful creation, the </st><strong class="source-inline"><st c="8566">sessionmaker</st></strong><st c="8578"> callable will need the </st><strong class="source-inline"><st c="8602">AsyncEngine</st></strong><st c="8613"> instance to instantiate the session that every CRUD operation requires. </st><st c="8686">However, this time, the session will be of the </st><strong class="source-inline"><st c="8733">AsyncSession</st></strong><st c="8745"> type, and the </st><strong class="source-inline"><st c="8760">async_scoped_session</st></strong><st c="8780"> callable will help derive the object with its provided </st><strong class="source-inline"><st c="8836">scopefunc</st></strong><st c="8845"> parameter to manage lightweight thread-local session-based operations in the repository layer. </st><st c="8941">Every repository class will require this </st><strong class="source-inline"><st c="8982">AsyncSession</st></strong><st c="8994"> instance to implement every necessary DB transaction of the asynchronous </st><span class="No-Break"><st c="9068">Flask platform.</st></span></p>
			<p><st c="9083">Now, there is nothing new with the </st><strong class="source-inline"><st c="9119">declarative_base()</st></strong><st c="9137"> method, for it will still provide the needed helper classes to generate the model classes for the repository layer, like in the standard SQLAlchemy setup. </st><st c="9293">The following is the complete module script of the </st><a id="_idIndexMarker300"/><st c="9344">specified </st><span class="No-Break"><st c="9354">SQLAlchemy setup:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="9371">from sqlalchemy.ext.asyncio</st></strong><st c="9399"> import </st><strong class="bold"><st c="9407">create_async_engine</st></strong><st c="9426">, </st><strong class="bold"><st c="9428">AsyncSession, async_scoped_session</st></strong>
<strong class="bold"><st c="9462">from sqlalchemy.orm</st></strong><st c="9482"> import declarative_base, </st><strong class="bold"><st c="9508">sessionmaker</st></strong>
<strong class="bold"><st c="9520">from sqlalchemy.pool import NullPool</st></strong>
<strong class="bold"><st c="9557">from asyncio import current_task</st></strong><st c="9590">
DB_URL = "postgresql+</st><strong class="bold"><st c="9612">asyncpg</st></strong><st c="9620">:// postgres:admin2255@localhost:5433/ovs"
engine = </st><strong class="bold"><st c="9673">create_async_engine</st></strong><st c="9692">(DB_URL, </st><strong class="bold"><st c="9702">future=True</st></strong><st c="9713">, echo=True, </st><strong class="bold"><st c="9726">pool_pre_ping=True</st></strong><st c="9744">, </st><strong class="bold"><st c="9746">poolclass=NullPool</st></strong><st c="9764">)
db_session = </st><strong class="bold"><st c="9780">async_scoped_session</st></strong><st c="9800">(</st><strong class="bold"><st c="9802">sessionmaker</st></strong><st c="9814">(engine, expire_on_commit=False, class_=AsyncSession), </st><strong class="bold"><st c="9870">scopefunc=current_task</st></strong><st c="9892">)
Base = declarative_base()
</st><strong class="bold"><st c="9921">def init_db():</st></strong><st c="9935">
    import app.model.db</st></pre>			<p><st c="9955">The </st><strong class="source-inline"><st c="9960">echo</st></strong><st c="9964"> parameter of the given </st><strong class="source-inline"><st c="9988">create_async_engine</st></strong><st c="10007"> enables logging for the </st><strong class="source-inline"><st c="10032">AsyncEngine</st></strong><st c="10043">-related transactions. </st><st c="10067">Now, the </st><strong class="source-inline"><st c="10076">init_db()</st></strong><st c="10085"> method from the preceding configuration exposes the model classes to the different areas of the application. </st><st c="10195">These model classes, built using the </st><strong class="source-inline"><st c="10232">Base</st></strong><st c="10236"> instance, help auto-generate the table schemas of our DB through the </st><em class="italic"><st c="10306">Flask-Migrate</st></em><st c="10319"> extension module, which still works with </st><strong class="source-inline"><st c="10361">flask[async]</st></strong><st c="10373"> and </st><span class="No-Break"><strong class="source-inline"><st c="10378">flask-sqlalchemy</st></strong></span><span class="No-Break"><st c="10394"> integration.</st></span></p>
			<p><st c="10407">Let us now use the derived </st><strong class="source-inline"><st c="10435">async_scoped_session()</st></strong><st c="10457"> to build </st><span class="No-Break"><st c="10467">repository classes.</st></span></p>
			<h2 id="_idParaDest-119"><a id="_idTextAnchor121"/><st c="10486">Building the asynchronous repository layer</st></h2>
			<p><st c="10529">The</st><a id="_idIndexMarker301"/><st c="10533"> asynchronous repository layer of the application requires the </st><strong class="source-inline"><st c="10596">AsyncSession</st></strong><st c="10608"> and the model classes to be created in the setup. </st><st c="10659">The following is a </st><strong class="source-inline"><st c="10678">VoterRepository</st></strong><st c="10693"> class implementation that provides CRUD transactions for managing the </st><span class="No-Break"><strong class="source-inline"><st c="10764">Voter</st></strong></span><span class="No-Break"><st c="10769"> records:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="10778">from sqlalchemy import update, delete, insert</st></strong>
<strong class="bold"><st c="10824">from sqlalchemy.future import select</st></strong>
<strong class="bold"><st c="10861">from sqlalchemy.orm import Session</st></strong>
<strong class="bold"><st c="10896">from app.model.db import Voter</st></strong><st c="10927">
from datetime import datetime
class </st><strong class="bold"><st c="10964">VoterRepository</st></strong><st c="10979">:
    </st><strong class="bold"><st c="10982">def __init__(self, sess:Session):</st></strong><strong class="bold"><st c="11015">self.sess:Session = sess</st></strong></pre>			<p><st c="11040">Like in the standard SQLAlchemy repository, all executions are session managed, so the </st><strong class="source-inline"><st c="11128">Session</st></strong><st c="11135"> object is always part of the constructor parameters of the repository class, like in the preceding </st><span class="No-Break"><strong class="source-inline"><st c="11235">VoterRepository</st></strong></span><span class="No-Break"><st c="11250">.</st></span></p>
			<p><st c="11251">Every operation under the </st><strong class="source-inline"><st c="11278">AsyncSession</st></strong><st c="11290"> scope requires an </st><strong class="source-inline"><st c="11309">await</st></strong><st c="11314"> process to finish its execution, which means every repository transaction must be </st><em class="italic"><st c="11397">coroutines</st></em><st c="11407">. Every repository transaction requires an event loop to pursue its execution because of the </st><strong class="source-inline"><st c="11500">async</st></strong><st c="11505">/</st><strong class="source-inline"><st c="11507">await</st></strong><st c="11512"> design pattern delegated </st><span class="No-Break"><st c="11538">by </st></span><span class="No-Break"><strong class="source-inline"><st c="11541">AsyncSession</st></strong></span><span class="No-Break"><st c="11553">.</st></span></p>
			<p><st c="11554">The best-fit approach to applying the asynchronous </st><em class="italic"><st c="11606">INSERT</st></em><st c="11612"> operation is to utilize the </st><strong class="source-inline"><st c="11641">insert()</st></strong><st c="11649"> method from SQLAlchemy utilities. </st><st c="11684">The </st><strong class="source-inline"><st c="11688">insert()</st></strong><st c="11696"> method will establish the </st><em class="italic"><st c="11723">INSERT</st></em><st c="11729"> command, which </st><strong class="source-inline"><st c="11745">AsyncSession</st></strong><st c="11757"> will </st><em class="italic"><st c="11763">execute</st></em><st c="11770">, </st><em class="italic"><st c="11772">commit</st></em><st c="11778">, or </st><em class="italic"><st c="11783">roll back</st></em><st c="11792"> asynchronously. </st><st c="11809">The following is </st><strong class="source-inline"><st c="11826">VoterRepository</st></strong><st c="11841">’s </st><span class="No-Break"><st c="11845">INSERT transaction:</st></span></p>
			<pre class="source-code"><strong class="bold"><st c="11864">async</st></strong><st c="11870"> def insert_voter(self, voter: Voter) -&gt; bool:
        try:
            </st><strong class="bold"><st c="11922">sql = insert(Voter).values(mid=voter.mid,</st></strong> <strong class="bold"><st c="11963">precinct=voter.precinct,</st></strong> <strong class="bold"><st c="11988">voter_id=voter.voter_id,</st></strong> <strong class="bold"><st c="12013">last_vote_date=datetime.strptime(</st></strong><strong class="bold"><st c="12047">voter.last_vote_date, '%Y-%m-%d').date())</st></strong><strong class="bold"><st c="12089">await</st></strong><st c="12095"> self.sess.execute(sql)
            </st><strong class="bold"><st c="12119">await</st></strong><st c="12124"> self.sess.commit()
            </st><strong class="bold"><st c="12144">await</st></strong><st c="12149"> self.sess.close()
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="12224">As depicted in the preceding snippet, the transaction awaits the </st><strong class="source-inline"><st c="12290">execute()</st></strong><st c="12299">, </st><strong class="source-inline"><st c="12301">commit()</st></strong><st c="12309">, and </st><strong class="source-inline"><st c="12315">close()</st></strong><st c="12322"> methods to finish their respective tasks, which is a clear indicator that a repository operation needs to be a coroutine before executing these </st><strong class="source-inline"><st c="12467">AsyncSession</st></strong><st c="12479"> member methods. </st><st c="12496">The same applies to the following UPDATE transaction of </st><span class="No-Break"><st c="12552">the</st></span><span class="No-Break"><a id="_idIndexMarker302"/></span><span class="No-Break"><st c="12555"> repository:</st></span></p>
			<pre class="source-code"><strong class="bold"><st c="12567">async </st></strong><st c="12574">def update_voter(self, id:int, details:Dict[str, Any]) -&gt; bool:
       try:
           </st><strong class="bold"><st c="12643">sql = update(Voter).where(Voter.id ==</st></strong> <strong class="bold"><st c="12680">id).values(**details)</st></strong><strong class="bold"><st c="12702">await</st></strong><st c="12708"> self.sess.execute(sql)
           </st><strong class="bold"><st c="12732">await</st></strong><st c="12737"> self.sess.commit()
           </st><strong class="bold"><st c="12757">await</st></strong><st c="12762"> self.sess.close()
           return True
       except Exception as e:
           print(e)
       return False</st></pre>			<p><st c="12837">The preceding </st><strong class="source-inline"><st c="12852">update_voter()</st></strong><st c="12866"> also uses the same asynchronous approach as </st><strong class="source-inline"><st c="12911">insert_voter()</st></strong><st c="12925"> using the </st><strong class="source-inline"><st c="12936">AsyncSession</st></strong><st c="12948"> methods. </st><strong class="source-inline"><st c="12958">update_voter()</st></strong><st c="12972"> also needs an event loop from </st><a id="_idIndexMarker303"/><st c="13003">Flask to run successfully as an </st><span class="No-Break"><st c="13035">asynchronous task:</st></span></p>
			<pre class="source-code"><strong class="bold"><st c="13053">async</st></strong><st c="13059"> def delete_voter(self, id:int) -&gt; bool:
        try:
           </st><strong class="bold"><st c="13105">sql = delete(Voter).where(Voter.id == id)</st></strong><strong class="bold"><st c="13146">await</st></strong><st c="13152"> self.sess.execute(sql)
           </st><strong class="bold"><st c="13176">await</st></strong><st c="13181"> self.sess.commit()
           </st><strong class="bold"><st c="13201">await</st></strong><st c="13206"> self.sess.close()
           return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="13281">For the query transactions, the following are the repository’s coroutines that implement its SELECT </st><span class="No-Break"><st c="13382">operations:</st></span></p>
			<pre class="source-code"><strong class="bold"><st c="13393">async</st></strong><st c="13399"> def select_all_voter(self):
        </st><strong class="bold"><st c="13428">sql = select(Voter)</st></strong><st c="13447">
        q = </st><strong class="bold"><st c="13452">await</st></strong><st c="13457"> self.sess.execute(sql)
        records = q.scalars().all()
        </st><strong class="bold"><st c="13509">await</st></strong><st c="13514"> self.sess.close()
        return records</st></pre>			<p><st c="13547">Both </st><strong class="source-inline"><st c="13553">select_all_voter()</st></strong><st c="13571"> and </st><strong class="source-inline"><st c="13576">select_voter()</st></strong><st c="13590"> use the </st><strong class="source-inline"><st c="13599">select()</st></strong><st c="13607"> method from the </st><strong class="source-inline"><st c="13624">sqlalchemy</st></strong><st c="13634"> or </st><strong class="source-inline"><st c="13638">sqlalchemy.future</st></strong><st c="13655"> module. </st><st c="13664">With the same objective as the </st><strong class="source-inline"><st c="13695">insert()</st></strong><st c="13703">, </st><strong class="source-inline"><st c="13705">update()</st></strong><st c="13713">, and </st><strong class="source-inline"><st c="13719">delete()</st></strong><st c="13727"> utilities, the </st><strong class="source-inline"><st c="13743">select()</st></strong><st c="13751"> method establishes a </st><em class="italic"><st c="13773">SELECT</st></em><st c="13779"> command object, which requires the asynchronous </st><strong class="source-inline"><st c="13828">execute()</st></strong><st c="13837"> utility for its execution. </st><st c="13865">Thus, both query implementations are </st><span class="No-Break"><st c="13902">also coroutines:</st></span></p>
			<pre class="source-code"><strong class="bold"><st c="13918">async</st></strong><st c="13924"> def select_voter(self, id:int):
        </st><strong class="bold"><st c="13957">sql = select(Voter).where(Voter.id == id)</st></strong><st c="13998">
        q = </st><strong class="bold"><st c="14003">await</st></strong><st c="14008"> self.sess.execute(sql)
        record = q.scalars().all()
        </st><strong class="bold"><st c="14059">await</st></strong><st c="14064"> self.sess.close()
        return record</st></pre>			<p><st c="14096">In SQLAlchemy, the </st><em class="italic"><st c="14116">INSERT</st></em><st c="14122">, </st><em class="italic"><st c="14124">UPDATE</st></em><st c="14130">, and </st><em class="italic"><st c="14136">DELETE</st></em><st c="14142"> transactions technically utilize the model attributes that refer to the primary keys of the models’ corresponding DB tables, such as </st><strong class="source-inline"><st c="14276">id</st></strong><st c="14278">. Conventionally, SQLAlchemy recommends updating and removing retrieved records based on</st><a id="_idIndexMarker304"/><st c="14366"> their </st><strong class="bold"><st c="14373">primary keys</st></strong><st c="14385">. However, there are special cases in </st><em class="italic"><st c="14423">UPDATE</st></em><st c="14429"> and </st><em class="italic"><st c="14434">DELETE</st></em><st c="14440"> operations </st><a id="_idIndexMarker305"/><st c="14452">when record searches are based on non-primary keys or arbitrary values, like in the following </st><strong class="source-inline"><st c="14546">update_precinct()</st></strong><st c="14563"> and </st><strong class="source-inline"><st c="14568">delete_voter_by_precinct()</st></strong><st c="14594"> of </st><span class="No-Break"><st c="14598">the repository:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="14613">async</st></strong><st c="14619"> def update_precinct(self, old_prec:str,   new_prec:str) -&gt; bool:
       try:
           sql = update(Voter).</st><strong class="bold"><st c="14708">where(Voter.precinct == old_prec).values(precint=new_prec)</st></strong><strong class="bold"><st c="14767">sql.execution_options(synchronize_session=</st></strong> <strong class="bold"><st c="14810">"fetch")</st></strong><st c="14819">
           await self.sess.execute(sql)
           await self.sess.commit()
           await self.sess.close()
           return True
       except Exception as e:
           print(e)
       return False</st></pre>			<p><strong class="source-inline"><st c="14954">update_precinct()</st></strong><st c="14972"> searches a </st><strong class="source-inline"><st c="14984">Voter</st></strong><st c="14989"> record with an existing </st><strong class="source-inline"><st c="15014">old_prec</st></strong><st c="15022"> (old precinct) and replaces it with </st><strong class="source-inline"><st c="15059">new_prec</st></strong><st c="15067"> (new precinct). </st><st c="15084">There is no </st><strong class="source-inline"><st c="15096">id</st></strong><st c="15098"> primary key used to search the records for updating. </st><st c="15152">The same scenario is also depicted in </st><strong class="source-inline"><st c="15190">delete_voter_by_precinct()</st></strong><st c="15216">, which uses the </st><strong class="source-inline"><st c="15233">precinct</st></strong><st c="15241"> non-primary key value for record removal. </st><st c="15284">Both</st><a id="_idIndexMarker306"/><st c="15288"> transactions do not conform with the </st><a id="_idIndexMarker307"/><st c="15326">ideal </st><strong class="bold"><st c="15332">object-relational </st></strong><span class="No-Break"><strong class="bold"><st c="15350">mapper</st></strong></span><span class="No-Break"><st c="15356"> persistence:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="15369">async</st></strong><st c="15375"> def delete_voter_by_precinct(self, precint:str) -&gt; bool:
        try:
           sql = delete(Voter).</st><strong class="bold"><st c="15458">where(Voter.precinct == precint)</st></strong><strong class="bold"><st c="15491">sql.execution_options(synchronize_session=</st></strong> <strong class="bold"><st c="15534">"fetch")</st></strong><st c="15543">
           await self.sess.execute(sql)
           await self.sess.commit()
           await self.sess.close()
           return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="15678">In this regard, it is mandatory to perform </st><strong class="source-inline"><st c="15722">execution_options()</st></strong><st c="15741"> to apply the necessary synchronization strategy, preferably the </st><strong class="source-inline"><st c="15806">fetch</st></strong><st c="15811"> strategy, before executing the </st><em class="italic"><st c="15843">UPDATE</st></em><st c="15849"> and </st><em class="italic"><st c="15854">DELETE </st></em><st c="15861">operations that do not conform with the ORM persistence. </st><st c="15918">This mechanism provides the session with the resolution to manage the changes reflected by these two operations. </st><st c="16031">For instance, the </st><strong class="source-inline"><st c="16049">fetch</st></strong><st c="16054"> strategy will let the session retrieve the primary keys of those records retrieved through the arbitrary values and will eventually update the in-memory objects or records affected by the operations and merge them into the actual table records. </st><st c="16300">This setup is essential for the asynchronous </st><span class="No-Break"><st c="16345">SQLAlchemy operations.</st></span></p>
			<p><st c="16367">After </st><a id="_idIndexMarker308"/><st c="16374">building the repository layer, let us call these CRUD transactions in our view or </st><span class="No-Break"><st c="16456">API functions.</st></span></p>
			<h2 id="_idParaDest-120"><a id="_idTextAnchor122"/><st c="16470">Utilizing the asynchronous DB transactions</st></h2>
			<p><st c="16513">To call the </st><a id="_idIndexMarker309"/><st c="16526">repository transactions, the asynchronous view and endpoint functions require an asynchronous context manager to create and manage </st><strong class="source-inline"><st c="16657">AsyncSession</st></strong><st c="16669"> for the repository class. </st><st c="16696">The following is an </st><strong class="source-inline"><st c="16716">add_login()</st></strong><st c="16727"> API function that adds a new </st><strong class="source-inline"><st c="16757">Login</st></strong><st c="16762"> credential to </st><span class="No-Break"><st c="16777">the DB:</st></span></p>
			<pre class="source-code"><st c="16784">
from app.model.db import Login
from app.repository.login import LoginRepository
</st><strong class="bold"><st c="16865">from app.model.config import db_session</st></strong><st c="16904">
@current_app.post('/ch05/login/add')
</st><strong class="bold"><st c="16942">async</st></strong><st c="16947"> def add_login():
   </st><strong class="bold"><st c="16965">async with db_session() as sess:</st></strong><strong class="bold"><st c="16997">async with sess.begin():</st></strong><strong class="bold"><st c="17022">repo = LoginRepository(sess)</st></strong><st c="17051">
            login_json = request.get_json()
            login = Login(**login_json)
            </st><strong class="bold"><st c="17112">result = await repo.insert_login(login)</st></strong><st c="17151">
            if result:
                content = jsonify(login_json)
                return make_response(content, 201)
            else:
                abort(500)</st></pre>			<p><st c="17244">The view function uses the </st><strong class="source-inline"><st c="17272">async with</st></strong><st c="17282"> context manager to localize the session for the coroutine or task execution. </st><st c="17360">It opens the session for that specific task that will run the </st><strong class="source-inline"><st c="17422">insert_login()</st></strong><st c="17436"> transaction of </st><strong class="source-inline"><st c="17452">LoginRepository</st></strong><st c="17467">. Then, eventually, the session will be closed by</st><a id="_idIndexMarker310"/><st c="17516"> the repository or the context </st><span class="No-Break"><st c="17547">manager itself.</st></span></p>
			<p><st c="17562">Now, let us focus on another way of running asynchronous transactions using the </st><span class="No-Break"><strong class="source-inline"><st c="17643">asyncio</st></strong></span><span class="No-Break"><st c="17650"> library.</st></span></p>
			<h1 id="_idParaDest-121"><a id="_idTextAnchor123"/><st c="17659">Implementing async transactions with asyncio</st></h1>
			<p><st c="17704">The </st><strong class="source-inline"><st c="17709">asyncio</st></strong><st c="17716"> module</st><a id="_idIndexMarker311"/><st c="17723"> is an easy-to-use library for implementing asynchronous tasks. </st><st c="17787">Compared to the </st><strong class="source-inline"><st c="17803">threading</st></strong><st c="17812"> module, the </st><strong class="source-inline"><st c="17825">asyncio</st></strong><st c="17832"> utilities use an event loop to execute each task, which is lightweight and easier to control. </st><st c="17927">Threading uses one whole thread to run one specific operation, while </st><strong class="source-inline"><st c="17996">asyncio</st></strong><st c="18003"> utilizes only a single event loop to run all registered tasks concurrently. </st><st c="18080">Thus, constructing an event loop is more resource friendly than running multiple threads to build </st><span class="No-Break"><st c="18178">concurrent transactions.</st></span></p>
			<p><strong class="source-inline"><st c="18202">asyncio</st></strong><st c="18210"> is seamlessly compatible with </st><strong class="source-inline"><st c="18241">flask[async]</st></strong><st c="18253">, and the clear proof is the following API function that adds a new voter to the DB using the task created by the </st><span class="No-Break"><strong class="source-inline"><st c="18367">create_task()</st></strong></span><span class="No-Break"><st c="18380"> method:</st></span></p>
			<pre class="source-code"><st c="18388">
from app.model.db import Member
from app.repository.member import MemberRepository
from app.model.config import db_session
</st><strong class="bold"><st c="18512">from asyncio import create_task, ensure_future,</st></strong> <strong class="bold"><st c="18559">InvalidStateError</st></strong><st c="18577">
from app.exceptions.db import DuplicateRecordException
</st><strong class="bold"><st c="18633">@current_app.post("/ch05/member/add")</st></strong><st c="18670">
async def add_member():
    async with db_session() as sess:
        async with sess.begin():
            repo = MemberRepository(sess)
            member_json = request.get_json()
            member = Member(**member_json)
            try:
                </st><strong class="bold"><st c="18852">insert_task =</st></strong> <strong class="bold"><st c="18865">create_task(repo.insert(member))</st></strong><strong class="bold"><st c="18898">await insert_task</st></strong><strong class="bold"><st c="18916">result = insert_task.result()</st></strong><st c="18946">
                if result:
                    content = jsonify(member_json)
                    return make_response(content, 201)
                else:
                    raise DuplicateRecordException("insert member record failed")
            except InvalidStateError:
                abort(500)</st></pre>			<p><st c="19128">The </st><strong class="source-inline"><st c="19133">create_task()</st></strong><st c="19146"> method</st><a id="_idIndexMarker312"/><st c="19153"> requires a coroutine to create a task and schedule its execution in an event loop. </st><st c="19237">So, coroutines are not tasks at all, but they are the core inputs for generating these tasks. </st><st c="19331">Running the scheduled task requires the </st><strong class="source-inline"><st c="19371">await</st></strong><st c="19376"> keyword. </st><st c="19386">After its execution, the task returns a </st><strong class="source-inline"><st c="19426">Future</st></strong><st c="19432"> object that requires the task’s </st><strong class="source-inline"><st c="19465">result()</st></strong><st c="19473"> built-in method to retrieve its actual returned value. </st><st c="19529">The given API transaction creates an </st><em class="italic"><st c="19566">INSERT</st></em><st c="19572"> task from the </st><strong class="source-inline"><st c="19587">insert_login()</st></strong><st c="19601"> coroutine and retrieves a </st><strong class="source-inline"><st c="19628">bool</st></strong><st c="19632"> result </st><span class="No-Break"><st c="19640">after execution.</st></span></p>
			<p><st c="19656">Now, </st><strong class="source-inline"><st c="19662">create_task()</st></strong><st c="19675"> automatically utilizes Flask’s internal event loop in running its tasks. </st><st c="19749">However, for complex cases such as executing scheduled tasks, </st><strong class="source-inline"><st c="19811">get_event_loop()</st></strong><st c="19827"> or </st><strong class="source-inline"><st c="19831">get_running_loop()</st></strong><st c="19849"> are more applicable to utilize than </st><strong class="source-inline"><st c="19886">create_task()</st></strong><st c="19899"> due to their flexible settings. </st><strong class="source-inline"><st c="19932">get_event_loop()</st></strong><st c="19948"> gets the current running event loop, while </st><strong class="source-inline"><st c="19992">get_running_loop()</st></strong><st c="20010"> uses the running event in the current </st><span class="No-Break"><st c="20049">system’s thread.</st></span></p>
			<p><st c="20065">Another way of creating tasks from the coroutine is through </st><strong class="source-inline"><st c="20126">asyncio</st></strong><st c="20133">’s </st><strong class="source-inline"><st c="20137">ensure_future()</st></strong><st c="20152">. The following API uses this utility to spawn a task that lists all </st><span class="No-Break"><st c="20221">user accounts:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="20235">@current_app.get("/ch05/member/list/all")</st></strong>
<strong class="bold"><st c="20277">async</st></strong><st c="20283"> def list_all_member():
     async with db_session() as sess:
        async with sess.begin():
            repo = MemberRepository(sess)
            </st><strong class="bold"><st c="20395">list_member_task =</st></strong> <strong class="bold"><st c="20413">ensure_future(repo.select_all_member())</st></strong><strong class="bold"><st c="20453">await list_member_task</st></strong><strong class="bold"><st c="20476">records = list_member_task.result()</st></strong><st c="20512">
            member_rec = [rec.to_json() for rec in records]
            return make_response(member_rec, 201)</st></pre>			<p><st c="20598">The only difference</st><a id="_idIndexMarker313"/><st c="20618"> between </st><strong class="source-inline"><st c="20627">create_task()</st></strong><st c="20640"> and </st><strong class="source-inline"><st c="20645">ensure_future()</st></strong><st c="20660"> is that the former strictly requires coroutines, while the latter can accept coroutines, </st><strong class="source-inline"><st c="20750">Future</st></strong><st c="20756">, or any awaitable objects. </st><strong class="source-inline"><st c="20784">ensure_future()</st></strong><st c="20799"> also invokes </st><strong class="source-inline"><st c="20813">create_task()</st></strong><st c="20826"> to wrap a </st><strong class="source-inline"><st c="20837">coroutine()</st></strong><st c="20848"> argument or directly return a </st><strong class="source-inline"><st c="20879">Future</st></strong><st c="20885"> result from a </st><strong class="source-inline"><st c="20900">Future</st></strong> <span class="No-Break"><st c="20906">parameter object.</st></span></p>
			<p><st c="20924">On the other hand, </st><strong class="source-inline"><st c="20944">flask[async]</st></strong><st c="20956"> supports creating and running multiple tasks concurrently using </st><strong class="source-inline"><st c="21021">asyncio</st></strong><st c="21028">. Its </st><strong class="source-inline"><st c="21034">gather()</st></strong><st c="21042"> method has </st><span class="No-Break"><st c="21054">two parameters:</st></span></p>
			<ul>
				<li><st c="21069">The first parameter is the sequence of coroutines, </st><strong class="source-inline"><st c="21121">Future</st></strong><st c="21127">, or any </st><span class="No-Break"><st c="21136">awaitable objects.</st></span></li>
				<li><st c="21154">The second parameter is </st><strong class="source-inline"><st c="21179">return_exceptions</st></strong><st c="21196">, which is set to </st><strong class="source-inline"><st c="21214">False</st></strong> <span class="No-Break"><st c="21219">by default.</st></span></li>
			</ul>
			<p><st c="21231">The following is an endpoint function that inserts multiple profiles of candidates using </st><span class="No-Break"><st c="21321">concurrent tasks:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="21338">@current_app.post('/ch05/candidates/party')</st></strong>
<strong class="bold"><st c="21382">async</st></strong><st c="21388"> def add_list_candidates():
    candidates = request.get_json()
    count_rec_added = 0
    </st><strong class="bold"><st c="21468">results = await gather( *[insert_candidate_task(data)</st></strong> <strong class="bold"><st c="21521">for data in candidates])</st></strong><st c="21546">
    for success in results:
        if success:
            count_rec_added = count_rec_added  + 1
    return jsonify(message=f'there are {count_rec_added} newly added candidates'), 201</st></pre>			<p><st c="21703">The given API</st><a id="_idIndexMarker314"/><st c="21717"> expects a list of candidate profile details from </st><strong class="source-inline"><st c="21767">request</st></strong><st c="21774">. A service named </st><strong class="source-inline"><st c="21792">insert_candidate_task()</st></strong><st c="21815"> will create a task that will convert the dictionary of objects to a </st><strong class="source-inline"><st c="21884">Candidate</st></strong><st c="21893"> instance and add the model instance to the DB through the </st><strong class="source-inline"><st c="21952">insert_candidate()</st></strong><st c="21970"> transaction of </st><strong class="source-inline"><st c="21986">CandidateRepository</st></strong><st c="22005">. The following code showcases the complete implementation of this </st><span class="No-Break"><st c="22072">service task:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="22085">from asyncio import create_task</st></strong><st c="22117">
… … … … … …
</st><strong class="bold"><st c="22129">async</st></strong><st c="22134"> def insert_candidate_task(data):
    </st><strong class="bold"><st c="22168">async with db_session() as sess:</st></strong><strong class="bold"><st c="22200">async with sess.begin():</st></strong><st c="22225">
            repo = CandidateRepository(sess)
            </st><strong class="bold"><st c="22259">insert_task =</st></strong> <strong class="bold"><st c="22272">create_task(repo.insert_candidate(</st></strong><strong class="bold"><st c="22307">Candidate(**data)))</st></strong><strong class="bold"><st c="22327">await insert_task</st></strong><strong class="bold"><st c="22345">result = insert_task.result()</st></strong><st c="22375">
            return result</st></pre>			<p><st c="22389">Since our SQLAlchemy connection pooling is </st><strong class="source-inline"><st c="22433">NullPool</st></strong><st c="22441">, which means connection pooling is disabled, we cannot utilize the same </st><strong class="source-inline"><st c="22514">AsyncSession</st></strong><st c="22526"> for all the </st><strong class="source-inline"><st c="22539">insert_candidate()</st></strong><st c="22557"> transactions. </st><st c="22572">Otherwise, </st><strong class="source-inline"><st c="22583">gather()</st></strong><st c="22591"> will throw </st><strong class="source-inline"><st c="22603">RuntimeError</st></strong><st c="22615"> object. </st><st c="22624">Thus, each </st><strong class="source-inline"><st c="22635">insert_candidate_task()</st></strong><st c="22658"> will open a new localized session for every </st><strong class="source-inline"><st c="22703">insert_candidate()</st></strong><st c="22721"> task execution. </st><st c="22738">To add connection pooling, replace </st><strong class="source-inline"><st c="22773">NullPool</st></strong><st c="22781"> with </st><strong class="source-inline"><st c="22787">QueuePool</st></strong><st c="22796">, </st><strong class="source-inline"><st c="22798">AsyncAdaptedQueuePool</st></strong><st c="22819">, </st><span class="No-Break"><st c="22821">or </st></span><span class="No-Break"><strong class="source-inline"><st c="22824">SingletonThreadPool</st></strong></span><span class="No-Break"><st c="22843">.</st></span></p>
			<p><st c="22844">Now, the </st><strong class="source-inline"><st c="22854">await</st></strong><st c="22859"> keyword will concurrently run the sequence of tasks registered in </st><strong class="source-inline"><st c="22926">gather()</st></strong><st c="22934"> and propagate all results in the resulting </st><strong class="source-inline"><st c="22978">tuple</st></strong><st c="22983"> of </st><strong class="source-inline"><st c="22987">Future</st></strong><st c="22993"> once these tasks have finished their execution successfully. </st><st c="23055">The order of these </st><strong class="source-inline"><st c="23074">Future</st></strong><st c="23080"> objects is the same as the sequence of the awaitable objects provided in </st><strong class="source-inline"><st c="23154">gather()</st></strong><st c="23162">. If a task has encountered failure or exception, it will not throw any exception and pre-empt the other task execution because </st><strong class="source-inline"><st c="23290">return_exceptions</st></strong><st c="23307"> of </st><strong class="source-inline"><st c="23311">gather()</st></strong><st c="23319"> is </st><strong class="source-inline"><st c="23323">False</st></strong><st c="23328">. Instead, the failed task will join as a typical awaitable object in the </st><span class="No-Break"><st c="23402">resulting </st></span><span class="No-Break"><strong class="source-inline"><st c="23412">tuple</st></strong></span><span class="No-Break"><st c="23417">.</st></span></p>
			<p><st c="23418">By the way, the</st><a id="_idIndexMarker315"/><st c="23434"> given </st><strong class="source-inline"><st c="23441">add_list_candidates()</st></strong><st c="23462"> API function will return the number of successful INSERT tasks that persisted in the </st><span class="No-Break"><st c="23548">candidate profiles.</st></span></p>
			<p><st c="23567">The next section will discuss how to de-couple Flask components using the event-driven behavior of </st><span class="No-Break"><st c="23667">Flask </st></span><span class="No-Break"><strong class="bold"><st c="23673">signals</st></strong></span><span class="No-Break"><st c="23680">.</st></span></p>
			<h1 id="_idParaDest-122"><a id="_idTextAnchor124"/><st c="23681">Utilizing asynchronous signal notifications</st></h1>
			<p><st c="23725">Flask has a</st><a id="_idIndexMarker316"/><st c="23737"> built-in lightweight event-driven mechanism called signals that can establish a loosely coupled software architecture using subscription-based event handling. </st><st c="23897">It can trigger single or multiple transactions depending on the purpose. </st><st c="23970">The </st><strong class="source-inline"><st c="23974">blinker</st></strong><st c="23981"> module provides the building blocks for Flask signal utilities, so install </st><strong class="source-inline"><st c="24057">blinker</st></strong><st c="24064"> using the </st><strong class="source-inline"><st c="24075">pip</st></strong><st c="24078"> command if it is not yet in the </st><span class="No-Break"><st c="24111">virtual environment.</st></span></p>
			<p><st c="24131">Flask has built-in signals and listens to many Flask events and callbacks such as </st><strong class="source-inline"><st c="24214">render_template()</st></strong><st c="24231">, </st><strong class="source-inline"><st c="24233">before_request()</st></strong><st c="24249">, and </st><strong class="source-inline"><st c="24255">after_request()</st></strong><st c="24270">. These signals, such as </st><strong class="source-inline"><st c="24295">request_started</st></strong><st c="24310">, </st><strong class="source-inline"><st c="24312">request_finished</st></strong><st c="24328">, </st><strong class="source-inline"><st c="24330">message_flashed</st></strong><st c="24345">, and </st><strong class="source-inline"><st c="24351">template_rendered</st></strong><st c="24368">, are found in the </st><strong class="source-inline"><st c="24387">flask</st></strong><st c="24392"> module. </st><st c="24401">For instance, once a component connects to </st><strong class="source-inline"><st c="24444">template_rendered</st></strong><st c="24461">, it will run its callback method after </st><strong class="source-inline"><st c="24501">render_template()</st></strong><st c="24518"> finishes posting a Jinja template. </st><st c="24554">However, our target is to create custom </st><span class="No-Break"><em class="italic"><st c="24594">asynchronous signals</st></em></span><span class="No-Break"><st c="24614">.</st></span></p>
			<p><st c="24615">To create custom signals, import the </st><strong class="source-inline"><st c="24653">Namespace</st></strong><st c="24662"> class from the </st><strong class="source-inline"><st c="24678">flask.signals</st></strong><st c="24691"> module and instantiate it. </st><st c="24719">Use its instance to define and instantiate specific custom signals, each having a unique name. </st><st c="24814">The following is a snippet from our applications that creates an event signal for election date verification and another for retrieving all the </st><span class="No-Break"><st c="24958">election details:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="24975">from flask.signals import Namespace</st></strong>
<strong class="bold"><st c="25011">election_ns = Namespace()</st></strong><st c="25037">
check_election = election_ns.</st><strong class="bold"><st c="25067">signal('check_election')</st></strong><st c="25092">
list_elections = election_ns.</st><strong class="bold"><st c="25122">signal('list_elections')</st></strong></pre>			<p><st c="25147">Each</st><a id="_idIndexMarker317"/><st c="25152"> named signal must have an assigned function or event, either asynchronous or standard, that will serve as their implementation. </st><strong class="source-inline"><st c="25281">check_election_event</st></strong><st c="25301">, for instance, has the following asynchronous method that uses </st><strong class="source-inline"><st c="25365">ElectionRepository </st></strong><st c="25384">to verify an </st><span class="No-Break"><st c="25397">election date:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="25411">@check_election.connect</st></strong>
<strong class="bold"><st c="25435">async</st></strong><st c="25441"> def check_election_event(</st><strong class="bold"><st c="25467">app</st></strong><st c="25471">, election_date):
    async with db_session() as sess:
        async with sess.begin():
            repo = ElectionRepository(sess)
            records = await repo.select_all_election()
            election_rec = [rec.to_json() for rec in records if rec.election_date == datetime.strptime(election_date, '%Y-%m-%d').date()]
            if len(election_rec) &gt; 0:
                return True
            return False</st></pre>			<p><st c="25798">Meanwhile, our </st><strong class="source-inline"><st c="25814">list_all_election()</st></strong><st c="25833"> API endpoint has the following </st><strong class="source-inline"><st c="25865">list_elections_event()</st></strong><st c="25887"> that returns a list of records in </st><span class="No-Break"><st c="25922">JSON format:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="25934">@list_elections.connect</st></strong>
<strong class="bold"><st c="25958">async</st></strong><st c="25964"> def list_elections_event(app):
    async with db_session() as sess:
        async with sess.begin():
            repo = ElectionRepository(sess)
            records = await repo.select_all_election()
            election_rec = [rec.to_json() for rec in records]
            return election_rec</st></pre>			<p><st c="26198">Event or</st><a id="_idIndexMarker318"/><st c="26207"> signal functions must accept a </st><em class="italic"><st c="26239">sender</st></em><st c="26245"> or </st><em class="italic"><st c="26249">listener</st></em><st c="26257"> as the first local parameter argument, followed by the other custom </st><strong class="source-inline"><st c="26326">args</st></strong><st c="26330"> objects essential to the event transaction. </st><st c="26375">If the event mechanism is part of the class scope, the value of the function must be </st><strong class="source-inline"><st c="26460">self</st></strong><st c="26464"> or the class instance itself. </st><st c="26495">Otherwise, if the signal is for a global event handling, its first argument must be the Flask </st><span class="No-Break"><strong class="source-inline"><st c="26589">app</st></strong></span><span class="No-Break"><st c="26592"> instance.</st></span></p>
			<p><st c="26602">A signal has a </st><strong class="source-inline"><st c="26618">connect()</st></strong><st c="26627"> function or decorator that registers an event or function as its implementation. </st><st c="26709">These events will execute once a caller emits the signals. </st><st c="26768">Flask components can emit signals by invoking the signal’s </st><strong class="source-inline"><st c="26827">send()</st></strong><st c="26833"> or </st><strong class="source-inline"><st c="26837">send_async()</st></strong><st c="26849"> utility with the event function arguments. </st><st c="26893">The following </st><strong class="source-inline"><st c="26907">verify_election()</st></strong><st c="26924"> endpoint checks from the DB through the </st><strong class="source-inline"><st c="26965">check_election</st></strong><st c="26979"> signal if an election happens on a </st><span class="No-Break"><st c="27015">particular date:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="27031">@current_app.post('/ch05/election/verify')</st></strong>
<strong class="bold"><st c="27074">async</st></strong><st c="27080"> def verify_election():
    election_json = request.get_json()
    election_date = election_json['election_date']
    </st><strong class="bold"><st c="27186">result_tuple = await</st></strong> <strong class="bold"><st c="27206">check_election.send_async(current_app,</st></strong> <strong class="bold"><st c="27245">election_date=election_date)</st></strong><st c="27274">
    isApproved = result_tuple[0][1]
    if isApproved:
        return jsonify(message=f'election for {election_date} is approved'), 201
    else:
        return jsonify(message=f'election for {election_date} is disabled'), 201</st></pre>			<p><st c="27473">If the event function is a standard Python function, send the notification for its execution through the signal’s </st><strong class="source-inline"><st c="27588">send()</st></strong><st c="27594"> method. </st><st c="27603">However, if it is an asynchronous method, like in our case, use </st><strong class="source-inline"><st c="27667">send_async()</st></strong><st c="27679"> to create and run the task for the coroutine with </st><strong class="source-inline"><st c="27730">await</st></strong><st c="27735"> to extract its </st><span class="No-Break"><strong class="source-inline"><st c="27751">Future</st></strong></span><span class="No-Break"><st c="27757"> value.</st></span></p>
			<p><st c="27764">Generally, signals can employ the de-coupling of components in a scalable application to reduce dependencies and improve modularity and maintainability. </st><st c="27918">This can also help build applications to have a distributed architecture design. </st><st c="27999">However, as the requirements become complicated and the subscribers of the signals become numerous, the notifications can slow down the performance of the whole application. </st><st c="28173">So, it is a good design if the caller and the event function can lessen the dependencies on each other’s parameters, returned values, and conditions. </st><st c="28323">The subscribers must have an independent scope as to the event functions. </st><st c="28397">Also, it is a good programming approach to create an event function that is flexible and not too narrow in its objectives so that many </st><a id="_idIndexMarker319"/><st c="28532">components can subscribe </st><span class="No-Break"><st c="28557">to it.</st></span></p>
			<p><st c="28563">After exploring how Flask supports event handling using its signals, let us now learn how to create background processes using </st><span class="No-Break"><st c="28691">its platform.</st></span></p>
			<h1 id="_idParaDest-123"><a id="_idTextAnchor125"/><st c="28704">Constructing background tasks with Celery and Redis</st></h1>
			<p><st c="28756">It is </st><a id="_idIndexMarker320"/><st c="28763">impossible to create background processes</st><a id="_idIndexMarker321"/><st c="28804"> or</st><a id="_idIndexMarker322"/><st c="28807"> transactions in</st><a id="_idIndexMarker323"/><st c="28823"> Flask using its </st><strong class="source-inline"><st c="28840">flask[async]</st></strong><st c="28852"> platform. </st><st c="28863">The event loop that runs tasks for the asynchronous view or endpoint will not allow the spawning of another event loop that will cater to background tasks because it cannot wait for the background processes to finish once the view or endpoint finishes its processing. </st><st c="29131">However, with some third-party components, such as task queues, background processing is feasible for the </st><span class="No-Break"><st c="29237">Flask platform.</st></span></p>
			<p><st c="29252">One of the solutions is to use Celery, which is an asynchronous task queue that can run processes outside the context of the application. </st><st c="29391">So, while the event loop is running the view or endpoint coroutines, they can entrust to Celery the management of the </st><span class="No-Break"><st c="29509">background transactions.</st></span></p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor126"/><st c="29533">Setting up the Celery task queue</st></h2>
			<p><st c="29566">There are a few </st><a id="_idIndexMarker324"/><st c="29583">considerations when writing the background processes with Celery, and the first is to install the </st><strong class="source-inline"><st c="29681">celery</st></strong><st c="29687"> extension module using the </st><span class="No-Break"><strong class="source-inline"><st c="29715">pip</st></strong></span><span class="No-Break"><st c="29718"> command:</st></span></p>
			<pre class="console"><st c="29727">
pip install celery</st></pre>			<p><st c="29746">Then, we designate some local workers in the WSGI server to run tasks with the background jobs in the Celery queue, but in our application, our Flask server will only use a single worker to run all </st><span class="No-Break"><st c="29945">the processes.</st></span></p>
			<p><st c="29959">Let us now install the Redis server, which will serve as the message broker to </st><span class="No-Break"><st c="30039">the Celery.</st></span></p>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor127"/><st c="30050">Installing the Redis DB</st></h2>
			<p><st c="30074">After designating</st><a id="_idIndexMarker325"/><st c="30092"> the worker, Celery requires a message broker for its workers to communicate with the client application about running the background jobs. </st><st c="30232">Our applications use the Redis DB as the broker. </st><st c="30281">So, install Redis in Windows using</st><a id="_idIndexMarker326"/><st c="30315"> the </st><strong class="bold"><st c="30320">Windows Subsystem for Linux</st></strong><st c="30347"> (</st><strong class="bold"><st c="30349">WSL2</st></strong><st c="30353">) shell or by downloading the Windows installer </st><span class="No-Break"><st c="30402">at </st></span><a href="https://github.com/microsoftarchive/redis/releases"><span class="No-Break"><st c="30405">https://github.com/microsoftarchive/redis/releases</st></span></a><span class="No-Break"><st c="30455">.</st></span></p>
			<p><st c="30456">The next step is to add the necessary Celery configuration variables, including </st><strong class="source-inline"><st c="30537">CELERY_BROKER_URL</st></strong><st c="30554">, to the </st><span class="No-Break"><strong class="source-inline"><st c="30563">app</st></strong></span><span class="No-Break"><st c="30566"> instance.</st></span></p>
			<h2 id="_idParaDest-126"><a id="_idTextAnchor128"/><st c="30576">Setting up the Celery client configuration</st></h2>
			<p><st c="30619">Since our projects use</st><a id="_idIndexMarker327"/><st c="30642"> TOML files for setting the configuration environment variables, Celery will fetch all its configuration details from these files as TOML variables. </st><st c="30791">The following is a snapshot of the </st><strong class="source-inline"><st c="30826">config_dev.toml</st></strong><st c="30841"> file that contains Celery </st><span class="No-Break"><st c="30868">setup variables:</st></span></p>
			<pre class="source-code"><st c="30884">
CELERY_BROKER_URL = "redis://127.0.0.1:6379/0"
CELERY_RESULT_BACKEND = "redis://127.0.0.1:6379/0
</st><strong class="bold"><st c="30982">[CELERY]</st></strong><st c="30990">
celery_store_errors_even_if_ignored = true
task_create_missing_queues = true
task_store_errors_even_if_ignored = true
task_ignore_result = false
broker_connection_retry_on_startup = true
celery_task_serializer = "pickle"
celery_result_serializer = "pickle"
celery_event_serializer = "json"
celery_accept_content = ["pickle", "application/json", "application/x-python-serialize"]
celery_result_accept_content = ["pickle", "application/json", "application/x-python-serialize"]</st></pre>			<p><st c="31465">The two most</st><a id="_idIndexMarker328"/><st c="31478"> important variables needed by the Celery client module are </st><strong class="source-inline"><st c="31538">CELERY_BROKER_URL</st></strong><st c="31555"> and </st><strong class="source-inline"><st c="31560">CELERY_RESULT_BACKEND</st></strong><st c="31581">, which provide the address, port, and DB name of the Redis broker and backend server, respectively. </st><st c="31682">Redis has DBs </st><strong class="source-inline"><st c="31696">0</st></strong><st c="31697"> to </st><strong class="source-inline"><st c="31701">15</st></strong><st c="31703">, but our application utilizes only DB </st><strong class="source-inline"><st c="31742">0</st></strong><st c="31743"> for default purposes. </st><st c="31766">Since the </st><strong class="source-inline"><st c="31776">CELERY_RESULT_BACKEND</st></strong><st c="31797"> is not that important in this setup, setting </st><strong class="source-inline"><st c="31843">CELERY_RESULT_BACKEND</st></strong><st c="31864"> as the defined broker URL or removing it from the configuration </st><span class="No-Break"><st c="31929">is acceptable.</st></span></p>
			<p><st c="31943">Then, create the </st><strong class="source-inline"><st c="31961">CELERY</st></strong><st c="31967"> TOML dictionary to contain the details needed by the Celery instance in managing the background task executions. </st><st c="32081">First, </st><strong class="source-inline"><st c="32088">celery_store_errors_even_if_ignored</st></strong><st c="32123"> and </st><strong class="source-inline"><st c="32128">task_store_errors_even_if_ignored</st></strong><st c="32161"> must be </st><strong class="source-inline"><st c="32170">True</st></strong><st c="32174"> to enable audit trail features for logging errors during Celery execution. </st><strong class="source-inline"><st c="32250">broker_connection_retry_on_startup</st></strong><st c="32284"> should be </st><strong class="source-inline"><st c="32295">True</st></strong><st c="32299"> in case Redis is still in shutdown mode. </st><st c="32341">On the other hand, </st><strong class="source-inline"><st c="32360">task_ignore_result</st></strong><st c="32378"> must be </st><strong class="source-inline"><st c="32387">False</st></strong><st c="32392"> since some of our coroutine jobs will be returning some values to the caller. </st><st c="32471">Moreover, </st><strong class="source-inline"><st c="32481">task_create_missing_queues</st></strong><st c="32507"> is set to </st><strong class="source-inline"><st c="32518">True</st></strong><st c="32522"> in case there are undefined task queues that the application can utilize during traffic. </st><st c="32612">By the way, the default task queue’s name </st><span class="No-Break"><st c="32654">is </st></span><span class="No-Break"><strong class="source-inline"><st c="32657">celery</st></strong></span><span class="No-Break"><st c="32663">.</st></span></p>
			<p><st c="32664">Other details are about the mime-type of resources that tasks can accept for their coroutines (</st><strong class="source-inline"><st c="32760">celery_accept_content</st></strong><st c="32782">) and the returned values that these background processes can return to the invoker (</st><strong class="source-inline"><st c="32868">celery_result_accept_content</st></strong><st c="32897">). </st><st c="32901">The task serializers are also part of the details because they are the mechanisms that convert the task’s incoming arguments and returning</st><a id="_idIndexMarker329"/><st c="33039"> values to be in their acceptable state and valid </st><span class="No-Break"><st c="33089">mime-type types.</st></span></p>
			<p><st c="33105">Now, let us focus on building the Celery client modules of our projects, starting with the instantiation of the </st><span class="No-Break"><st c="33218">Celery instance.</st></span></p>
			<h2 id="_idParaDest-127"><a id="_idTextAnchor129"/><st c="33234">Creating the Client instance</st></h2>
			<p><st c="33263">Since all </st><a id="_idIndexMarker330"/><st c="33274">projects in this chapter use the application factory approach, the setup recognizing the application as a Celery client happens in </st><strong class="source-inline"><st c="33405">app/__init__.py</st></strong><st c="33420">. However, the exact </st><strong class="source-inline"><st c="33441">Celery</st></strong><st c="33447"> class instantiation occurs in another module, </st><strong class="source-inline"><st c="33494">celery_config.py</st></strong><st c="33510">, to avoid circular import errors. </st><st c="33545">The following snippet shows the instantiation of the </st><strong class="source-inline"><st c="33598">Celery</st></strong><st c="33604"> class </st><span class="No-Break"><st c="33611">in </st></span><span class="No-Break"><strong class="source-inline"><st c="33614">celery_config.py</st></strong></span><span class="No-Break"><st c="33630">:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="33632">from celery import Celery, Task</st></strong><st c="33663">
from flask import Flask
def </st><strong class="bold"><st c="33692">celery_init_app</st></strong><st c="33707">(app: Flask) -&gt; Celery:
    class FlaskTask(Task):
        def __call__(self, *args: object, **kwargs: object) -&gt; object:
            </st><strong class="bold"><st c="33818">with app.app_context():</st></strong><st c="33841">
                return self.run(*args, **kwargs)
    celery_app = </st><strong class="bold"><st c="33888">Celery(app.name, task_cls=FlaskTask,</st></strong> <strong class="bold"><st c="33924">broker=app.config["CELERY_BROKER_URL"],</st></strong> <strong class="bold"><st c="33964">backend=app.config["CELERY_RESULT_BACKEND"])</st></strong><strong class="bold"><st c="34009">celery_app.config_from_object(app.config["CELERY"])</st></strong><strong class="bold"><st c="34061">celery_app.set_default()</st></strong><st c="34086">
    return celery_app</st></pre>			<p><st c="34104">From the preceding snippet, the instantiation of the </st><strong class="source-inline"><st c="34158">Celery</st></strong><st c="34164"> class strictly requires the Celery application name, </st><strong class="source-inline"><st c="34218">CELERY_BROKER_URL</st></strong><st c="34235">, and the worker task. </st><st c="34258">The first parameter, the Celery application name, can have any prescribed name or just the Flask app’s name since the Celery client module will run background jobs (</st><strong class="source-inline"><st c="34423">FlaskTask</st></strong><st c="34433">) in the </st><span class="No-Break"><st c="34443">app’s thread.</st></span></p>
			<p><st c="34456">After</st><a id="_idIndexMarker331"/><st c="34462"> instantiating the Celery, the Celery instance, </st><strong class="source-inline"><st c="34510">celery_app</st></strong><st c="34520">, needs to load the </st><strong class="source-inline"><st c="34540">CELERY</st></strong><st c="34546"> TOML dictionary from the Flask </st><strong class="source-inline"><st c="34578">app</st></strong><st c="34581"> to configure the task queue and its message broker. </st><st c="34634">Lastly, </st><strong class="source-inline"><st c="34642">celery_app</st></strong><st c="34652"> must invoke </st><strong class="source-inline"><st c="34665">set_default()</st></strong><st c="34678"> to seal the configuration. </st><st c="34706">Now, </st><strong class="source-inline"><st c="34711">app/__init__.py</st></strong><st c="34726"> will import the </st><strong class="source-inline"><st c="34743">celery_init_app()</st></strong><st c="34760"> factory to eventually pursue the creation of the Celery client out of the </st><span class="No-Break"><st c="34835">Flask application.</st></span></p>
			<p><st c="34853">Let us now build the Celery client module with </st><span class="No-Break"><st c="34901">custom tasks.</st></span></p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor130"/><st c="34914">Implementing the Celery tasks</st></h2>
			<p><st c="34944">To avoid circular </st><a id="_idIndexMarker332"/><st c="34963">import problems, it is not advisable to import </st><strong class="source-inline"><st c="35010">celery_app</st></strong><st c="35020"> and use it to decorate functions with the </st><strong class="source-inline"><st c="35063">task()</st></strong><st c="35069"> decorator. </st><st c="35081">The </st><strong class="source-inline"><st c="35085">shared_task()</st></strong><st c="35098"> decorator from the </st><strong class="source-inline"><st c="35118">celery</st></strong><st c="35124"> module is enough proxy to define functions as Celery tasks. </st><st c="35185">Here is a Celery task that adds a new vote to </st><span class="No-Break"><st c="35231">a candidate:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="35243">from celery import shared_task</st></strong>
<strong class="bold"><st c="35274">from asyncio import run</st></strong>
<strong class="bold"><st c="35298">@shared_task</st></strong><st c="35311">
def add_vote_task_wrapper(details):
    </st><strong class="bold"><st c="35348">async</st></strong><st c="35353"> def add_vote_task(details):
        try:
            </st><strong class="bold"><st c="35387">async</st></strong><st c="35392"> with db_session() as sess:
             </st><strong class="bold"><st c="35420">async</st></strong><st c="35425"> with sess.begin():
                repo = VoteRepository(sess)
                details_dict = loads(details)
                print(details_dict)
                election = Vote(**details_dict)
                result = await repo.insert(election)
                if result:
                    </st><strong class="bold"><st c="35603">return str(True)</st></strong><st c="35619">
                else:
                    </st><strong class="bold"><st c="35626">return str(False)</st></strong><st c="35643">
        except Exception as e:
            print(e)
            </st><strong class="bold"><st c="35676">return str(False)</st></strong><st c="35693">
    return </st><strong class="bold"><st c="35701">run(add_vote_task(details))</st></strong></pre>			<p><st c="35728">Now, a Celery task, such</st><a id="_idIndexMarker333"/><st c="35753"> as the one created by </st><strong class="source-inline"><st c="35776">add_vote_task_wrapper()</st></strong><st c="35799">, must not be a coroutine. </st><st c="35826">A Celery task is a class generated by any callable decorated by </st><strong class="source-inline"><st c="35890">@shared_task</st></strong><st c="35902">, which means it cannot propagate the </st><strong class="source-inline"><st c="35940">await</st></strong><st c="35945"> keyword outwards with the </st><strong class="source-inline"><st c="35972">async</st></strong><st c="35977"> function call. </st><st c="35993">However, it can enclose an asynchronous local method to handle all the operations asynchronously, such as </st><strong class="source-inline"><st c="36099">add_vote_task()</st></strong><st c="36114">, which wraps and executes the INSERT transactions for new vote details. </st><st c="36187">The Celery task can apply the </st><strong class="source-inline"><st c="36217">asyncio</st></strong><st c="36224">’s </st><strong class="source-inline"><st c="36228">run()</st></strong><st c="36233"> utility method to run its async </st><span class="No-Break"><st c="36266">local function.</st></span></p>
			<p><st c="36281">Since our Celery app does not ignore the result, our task returns a Boolean value converted into a string, a safe object type that a task can return to the caller. </st><st c="36446">Although it is feasible to use pickling, through the </st><strong class="source-inline"><st c="36499">pickle</st></strong><st c="36505"> module, to pass an argument to or transport return values from Celery tasks to the callers, it might open vulnerabilities that can pose security risks to the application, such as accidentally exposing confidential information stored in the pickled object or unpickling/de-serializing </st><span class="No-Break"><st c="36790">malicious objects.</st></span></p>
			<p><st c="36808">Another approach to manage the Celery task’s input arguments and returned values, especially if they are collection types, is through the </st><strong class="source-inline"><st c="36947">loads()</st></strong><st c="36954"> and </st><strong class="source-inline"><st c="36959">dumps()</st></strong><st c="36966"> utilities of the </st><strong class="source-inline"><st c="36984">json</st></strong><st c="36988"> module. </st><st c="36997">This </st><strong class="source-inline"><st c="37002">loads()</st></strong><st c="37009"> function deserializes a JSON string into a Python object while </st><strong class="source-inline"><st c="37073">dumps()</st></strong><st c="37080"> serializes Python objects (e.g., dictionaries, lists, etc.) into a JSON formatted string. </st><st c="37171">However, sometimes, using </st><strong class="source-inline"><st c="37197">dumps()</st></strong><st c="37204"> to convert these objects to strings is not certain. </st><st c="37257">There are data in the string payload that can cause serialization error, because Celery does not support their default format, such as </st><strong class="source-inline"><st c="37392">time</st></strong><st c="37396">, </st><strong class="source-inline"><st c="37398">date</st></strong><st c="37402">, and </st><strong class="source-inline"><st c="37408">datetime</st></strong><st c="37416">. In this</st><a id="_idIndexMarker334"/><st c="37425"> scenario, the </st><strong class="source-inline"><st c="37440">dumps()</st></strong><st c="37447"> method needs a custom serializer to convert these temporal data types to their equivalent </st><em class="italic"><st c="37538">ISO 8601</st></em><st c="37546"> formats. </st><st c="37556">The following Celery task has the same problem, thus the presence of a </st><span class="No-Break"><st c="37627">custom </st></span><span class="No-Break"><strong class="source-inline"><st c="37634">json_date_serializer()</st></strong></span><span class="No-Break"><st c="37656">:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="37658">@shared_task</st></strong><st c="37670">
def list_all_votes_task_wrapper():
    async def list_all_votes_task():
      async with db_session() as sess:
        async with sess.begin():
            repo = VoteRepository(sess)
            records = await repo.select_all_vote()
            vote_rec = [rec.to_json() for rec in records]
            return </st><strong class="bold"><st c="37917">dumps(vote_rec,</st></strong> <strong class="bold"><st c="37932">default=json_date_serializer)</st></strong><st c="37962">
    return </st><strong class="bold"><st c="37970">run(list_all_votes_task())</st></strong>
<strong class="bold"><st c="37996">def json_date_serializer(obj):</st></strong><st c="38027">
    if isinstance(obj, time):
        return obj.isoformat()
    raise TypeError ("Type %s not …" % type(obj))</st></pre>			<p><st c="38122">Among the many</st><a id="_idIndexMarker335"/><st c="38137"> ways to implement a date serializer, </st><strong class="source-inline"><st c="38175">json_date_serializer()</st></strong><st c="38197"> uses the </st><strong class="source-inline"><st c="38207">time</st></strong><st c="38211">’s </st><strong class="source-inline"><st c="38215">isoformat()</st></strong><st c="38226"> method to convert the time object to an </st><em class="italic"><st c="38267">ISO 8601</st></em><st c="38275"> or </st><em class="italic"><st c="38279">HH:MM:SS:ssssss</st></em><st c="38294"> formatted string value so that the task can return the list of vote records without conflicts on the </st><span class="No-Break"><strong class="source-inline"><st c="38396">date</st></strong></span><span class="No-Break"><st c="38400"> types.</st></span></p>
			<h2 id="_idParaDest-129"><a id="_idTextAnchor131"/><st c="38407">Running the Celery worker server</st></h2>
			<p><st c="38440">After creating the </st><a id="_idIndexMarker336"/><st c="38460">Celery tasks, the next step is to run the built-in Celery server through the following command to check whether the server can </st><span class="No-Break"><st c="38587">recognize them:</st></span></p>
			<pre class="console"><st c="38602">
celery -A main.celery_app worker --loglevel=info -P solo</st></pre>			<p><strong class="source-inline"><st c="38659">main</st></strong><st c="38664"> in the command is the </st><strong class="source-inline"><st c="38687">main.py</st></strong><st c="38694"> module, and </st><strong class="source-inline"><st c="38707">celery_app</st></strong><st c="38717"> is the Celery instance found in the </st><strong class="source-inline"><st c="38754">main.py</st></strong><st c="38761"> module. </st><st c="38770">The </st><strong class="source-inline"><st c="38774">loglevel</st></strong><st c="38782"> option creates a console logger for the server, and the </st><strong class="source-inline"><st c="38839">P</st></strong><st c="38840"> option indicates the </st><em class="italic"><st c="38862">concurrency pool</st></em><st c="38878">, which is </st><strong class="source-inline"><st c="38889">solo</st></strong><st c="38893"> in the given command. </st><span class="No-Break"><em class="italic"><st c="38916">Figure 5</st></em></span><em class="italic"><st c="38924">.1</st></em><st c="38926"> shows the screen details after the </st><span class="No-Break"><st c="38962">server started.</st></span></p>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="image/B19383_05_001.jpg" alt="Figure 5.1 – Server details after Celery server startup"/><st c="38977"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="39751">Figure 5.1 – Server details after Celery server startup</st></p>
			<p><st c="39806">Celery server fetched the </st><strong class="source-inline"><st c="39833">add_vote_task_wrapper()</st></strong><st c="39856"> and </st><strong class="source-inline"><st c="39861">list_all_votes_task_wrapper()</st></strong><st c="39890"> tasks, as indicated in </st><span class="No-Break"><em class="italic"><st c="39914">Figure 5</st></em></span><em class="italic"><st c="39922">.1</st></em><st c="39924">. Thus, Flask views and endpoints can now use these tasks to cast and view the votes from users. </st><st c="40021">Aside from the list of ready-to-use tasks, the server logs also show details of the default task queue, </st><strong class="source-inline"><st c="40125">celery</st></strong><st c="40131">. Also, it indicates the concurrency pool type, which is </st><strong class="source-inline"><st c="40188">solo</st></strong><st c="40192">, and has a concurrency worker limit of </st><strong class="source-inline"><st c="40232">8</st></strong><st c="40233">. Among the </st><strong class="source-inline"><st c="40245">prefork</st></strong><st c="40252">, </st><strong class="source-inline"><st c="40254">eventlet</st></strong><st c="40262">, </st><strong class="source-inline"><st c="40264">gevent</st></strong><st c="40270">, and </st><strong class="source-inline"><st c="40276">solo</st></strong><st c="40280"> concurrency options, our applications use </st><strong class="source-inline"><st c="40323">solo</st></strong><st c="40327"> and </st><strong class="source-inline"><st c="40332">eventlet</st></strong><st c="40340">. However, to use </st><strong class="source-inline"><st c="40358">eventlet</st></strong><st c="40366">, install the </st><strong class="source-inline"><st c="40380">eventlet</st></strong><st c="40388"> module using the </st><span class="No-Break"><strong class="source-inline"><st c="40406">pip</st></strong></span><span class="No-Break"><st c="40409"> command:</st></span></p>
			<pre class="console"><st c="40418">
pip install eventlet</st></pre>			<p><st c="40439">Our application uses the solo Celery execution pool because it runs within the worker process, which makes a task’s performance fast. </st><st c="40574">This pool is fit for running resource-intensive tasks. </st><st c="40629">Other better options are </st><strong class="source-inline"><st c="40654">eventlet</st></strong><st c="40662"> and </st><strong class="source-inline"><st c="40667">gevent</st></strong><st c="40673">, which spawn greenlets, sometimes called green threads, cooperative threads, or coroutines. </st><st c="40766">Most Input/Output-bound tasks run better with </st><strong class="source-inline"><st c="40812">eventlet</st></strong><st c="40820"> or </st><strong class="source-inline"><st c="40824">gevent</st></strong><st c="40830"> because they generate more threads and emulate a multi-threading environment </st><span class="No-Break"><st c="40908">for efficiency.</st></span></p>
			<p><st c="40923">Once the Celery </st><a id="_idIndexMarker337"/><st c="40940">server loads and recognizes the tasks with a worker managing the message queues, Flask view and endpoint functions can invoke the tasks now using Celery </st><span class="No-Break"><st c="41093">utility methods.</st></span></p>
			<h2 id="_idParaDest-130"><a id="_idTextAnchor132"/><st c="41109">Utilizing the Celery tasks</st></h2>
			<p><st c="41136">Once the </st><a id="_idIndexMarker338"/><st c="41146">Celery worker server runs with the list of tasks, Flask’s </st><strong class="source-inline"><st c="41204">async</st></strong><st c="41209"> views and endpoints can now access and run these tasks like signals. </st><st c="41279">These tasks will execute only when the caller invokes their built-in </st><strong class="source-inline"><st c="41348">delay()</st></strong><st c="41355"> or </st><strong class="source-inline"><st c="41359">apply_async()</st></strong><st c="41372"> methods. </st><st c="41382">The following endpoint function runs </st><strong class="source-inline"><st c="41419">add_vote_task_wrapper()</st></strong><st c="41442"> to cast a vote for </st><span class="No-Break"><st c="41462">a user:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="41469">@current_app.post('/ch05/vote/add')</st></strong>
<strong class="bold"><st c="41505">async</st></strong><st c="41511"> def add_vote():
    vote_json = request.get_json()
    </st><strong class="bold"><st c="41559">vote_str = dumps(vote_json)</st></strong><strong class="bold"><st c="41586">task =</st></strong> <strong class="bold"><st c="41593">add_vote_task_wrapper.apply_async(args=[vote_str])</st></strong><strong class="bold"><st c="41644">result = task.get()</st></strong><st c="41664">
    return jsonify(message=result), 201</st></pre>			<p><st c="41700">The given </st><strong class="source-inline"><st c="41711">add_vote()</st></strong><st c="41721"> endpoint retrieves the request JSON data and converts it to a string before passing it as an argument to </st><strong class="source-inline"><st c="41827">add_vote_task_wrapper()</st></strong><st c="41850">. Without using the </st><strong class="source-inline"><st c="41870">await</st></strong><st c="41875"> keyword, the Celery task has </st><strong class="source-inline"><st c="41905">apply_async()</st></strong><st c="41918">, which the invoker can use to trigger its execution with the argument. </st><strong class="source-inline"><st c="41990">apply_async()</st></strong><st c="42003"> returns an </st><strong class="source-inline"><st c="42015">AsyncResult</st></strong><st c="42026"> object with a </st><strong class="source-inline"><st c="42041">get()</st></strong><st c="42046"> method that returns the returned value, if any. </st><st c="42095">It also has a </st><strong class="source-inline"><st c="42109">traceback</st></strong><st c="42118"> variable</st><a id="_idIndexMarker339"/><st c="42127"> that retrieves an exception stack trace when the execution raises </st><span class="No-Break"><st c="42194">an exception.</st></span></p>
			<p><st c="42207">From creating asynchronous background tasks, let us move on to WebSocket implementation with </st><span class="No-Break"><st c="42301">asynchronous transactions.</st></span></p>
			<h1 id="_idParaDest-131"><a id="_idTextAnchor133"/><st c="42327">Building WebSockets with asynchronous transactions</st></h1>
			<p><st c="42378">WebSocket is</st><a id="_idIndexMarker340"/><st c="42391"> a well-known bi-directional communication between a server and browser-based clients. </st><st c="42478">Many popular frameworks such as Spring, JSF, Jakarta EE, Django, FastAPI, Angular, and React support this technology, and Flask is one of them. </st><st c="42622">However, this chapter will focus on implementing WebSocket and its client applications using the </st><span class="No-Break"><st c="42719">asynchronous paradigm.</st></span></p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor134"/><st c="42741">Creating the client-side application</st></h2>
			<p><st c="42778">Our WebSocket implementation with the </st><a id="_idIndexMarker341"/><st c="42817">client-side application is in the </st><strong class="source-inline"><st c="42851">ch05-web</st></strong><st c="42859"> project. </st><st c="42869">Calling </st><strong class="source-inline"><st c="42877">/ch05/votecount/add</st></strong><st c="42896"> from the </st><strong class="source-inline"><st c="42906">vote_count.py</st></strong><st c="42919"> view module will give us the following HTML form in </st><span class="No-Break"><em class="italic"><st c="42972">Figure 5</st></em></span><em class="italic"><st c="42980">.2</st></em><st c="42982">, which handles the data entry for the final vote tally per precinct or </st><span class="No-Break"><st c="43054">election district:</st></span></p>
			<div>
				<div id="_idContainer039" class="IMG---Figure">
					<img src="image/B19383_05_002.jpg" alt="Figure 5.2 – Client-side application for adding final vote counts"/><st c="43072"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="43230">Figure 5.2 – Client-side application for adding final vote counts</st></p>
			<p><st c="43295">Our</st><a id="_idIndexMarker342"/><st c="43299"> WebSocket captures election data from officers and then updates DB records in real time. </st><st c="43389">It retrieves a string message from the server as a response. </st><st c="43450">The HTML form and the </st><strong class="bold"><st c="43472">JavaScript</st></strong><st c="43482"> (</st><strong class="bold"><st c="43484">JS</st></strong><st c="43486">) implementation of </st><strong class="source-inline"><st c="43507">WebSocket</st></strong><st c="43516"> are in </st><strong class="source-inline"><st c="43524">pages/vote_count_add.html</st></strong><st c="43549"> of </st><strong class="source-inline"><st c="43553">ch05-web</st></strong><st c="43561">. The following snippet is the JS code that communicates with our </st><span class="No-Break"><st c="43627">server-side </st></span><span class="No-Break"><strong class="source-inline"><st c="43639">WebSocket</st></strong></span><span class="No-Break"><st c="43648">:</st></span></p>
			<pre class="source-code"><st c="43650">
&lt;script&gt;
      </st><strong class="bold"><st c="43660">const add_log = (message) =&gt; {</st></strong><st c="43690">
        document.getElementById('add_log').innerHTML += `&lt;span&gt;${message}&lt;/span&gt;&lt;br&gt;`;
      };
      </st><strong class="bold"><st c="43773">const socket = new WebSocket('ws://' + location.host</st></strong> <strong class="bold"><st c="43825">+ '/ch05/vote/save/ws');</st></strong><strong class="bold"><st c="43850">socket.addEventListener('message', msg =&gt; {</st></strong><strong class="bold"><st c="43894">add_log('server: ' + msg.data);</st></strong><strong class="bold"><st c="43926">});</st></strong><st c="43930">
      document.getElementById('vote_form').onsubmit = data =&gt; {
            data.preventDefault();
            const election_id = document.getElementById('election_id');
            const precinct = document.getElementById('precinct');
            const final_tally = document.getElementById('final_tally');
            const approved_date = document.getElementById('approved_date');
            var vote_count = new Object();
            vote_count.election_id = election_id.value;
            vote_count.precinct  = precinct.value;
            vote_count.final_tally = final_tally.value;
            vote_count.approved_date = approved_date.value;
            var vote_count_json = JSON.stringify(vote_count);
            add_log('client: ' + vote_count_json);
            </st><strong class="bold"><st c="44544">socket.send(vote_count_json);</st></strong><st c="44573">
            election_id.value = '';
            precinct.value = '';
            final_tally.value = '';
            approved_date.value = '';
      };
    &lt;/script&gt;</st></pre>			<p><st c="44681">The preceding JS script will connect to the Flask server through </st><strong class="source-inline"><st c="44747">ws://localhost:5001/ch05/vote/save/ws</st></strong><st c="44784"> by instantiating the </st><strong class="source-inline"><st c="44806">WebSocket</st></strong><st c="44815"> API. </st><st c="44821">When the connection is ready, the client can ask for vote details from the client through the form components. </st><st c="44932">Submitting the data will create a JSON object out of the form data before sending the JSON formatted details to the server through the </st><span class="No-Break"><strong class="source-inline"><st c="45067">WebSocket</st></strong></span><span class="No-Break"><st c="45076"> connection.</st></span></p>
			<p><st c="45088">On the other </st><a id="_idIndexMarker343"/><st c="45102">hand, to capture the message from the server, the client must create a listener to the message emitter by calling the WebSocket’s </st><strong class="source-inline"><st c="45232">addEventListener()</st></strong><st c="45250">, which will watch and retrieve any JSON message from the Flask server. </st><st c="45322">The custom </st><strong class="source-inline"><st c="45333">add_log()</st></strong><st c="45342"> function will render the message to the front end using the </st><strong class="source-inline"><st c="45403">&lt;</st></strong><span class="No-Break"><strong class="source-inline"><st c="45404">span&gt;</st></strong></span><span class="No-Break"><st c="45409"> tag.</st></span></p>
			<p><st c="45414">Next, let us focus on the WebSocket implementation per se using the </st><span class="No-Break"><strong class="source-inline"><st c="45483">flask-sock</st></strong></span><span class="No-Break"><st c="45493"> module.</st></span></p>
			<h2 id="_idParaDest-133"><a id="_idTextAnchor135"/><st c="45501">Creating server-side transactions</st></h2>
			<p><st c="45535">There are many ways to implement a </st><a id="_idIndexMarker344"/><st c="45571">server-side message emitter, such as </st><strong class="source-inline"><st c="45608">WebSocket</st></strong><st c="45617">, in Flask, and many Flask extensions can provide support for it, such as </st><strong class="source-inline"><st c="45691">flask-socketio</st></strong><st c="45705">, </st><strong class="source-inline"><st c="45707">flask-sockets</st></strong><st c="45720">, and </st><strong class="source-inline"><st c="45726">flask-sock</st></strong><st c="45736">. This chapter will use the </st><strong class="source-inline"><st c="45764">flask-sock</st></strong><st c="45774"> module to create WebSocket routes because it can implement WebSocket communication with minimal configuration and setup. </st><st c="45896">So, to start, install the </st><strong class="source-inline"><st c="45922">flask-sock</st></strong><st c="45932"> extension using the </st><span class="No-Break"><strong class="source-inline"><st c="45953">pip</st></strong></span><span class="No-Break"><st c="45956"> command:</st></span></p>
			<pre class="console"><st c="45965">
pip install flask-sock</st></pre>			<p><st c="45988">Then, integrate the extension to Flask by instantiating the </st><strong class="source-inline"><st c="46049">Sock</st></strong><st c="46053"> class with the </st><strong class="source-inline"><st c="46069">app</st></strong><st c="46072"> instance as its required argument. </st><st c="46108">The following </st><strong class="source-inline"><st c="46122">app/__init__.py</st></strong><st c="46137"> snippet shows the </st><span class="No-Break"><strong class="source-inline"><st c="46156">flask-sock</st></strong></span><span class="No-Break"><st c="46166"> setup:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="46173">from flask_sock import Sock</st></strong>
<strong class="bold"><st c="46201">sock = Sock()</st></strong><st c="46215">
def create_app(config_file):
    app = Flask(__name__, template_folder='../app/pages', static_folder="../app/resources")
    app.config.from_file(config_file, toml.load)
    init_db()
    </st><strong class="bold"><st c="46388">sock.init_app(app)</st></strong></pre>			<p><st c="46406">After that simple configuration, import the </st><strong class="source-inline"><st c="46451">sock</st></strong><st c="46455"> instance in </st><strong class="source-inline"><st c="46468">/api/ votecount_websocket.py module</st></strong><st c="46503"> to define the WebSocket routes. </st><strong class="source-inline"><st c="46536">ws://localhost:5001/ch05/vote/save/ws</st></strong><st c="46573">, which was invoked by the preceding JS </st><a id="_idIndexMarker345"/><st c="46613">code, has the following </st><span class="No-Break"><st c="46637">route implementation:</st></span></p>
			<pre class="source-code"><st c="46658">
from app import sock
</st><strong class="bold"><st c="46680">@sock.route('/ch05/vote/save/ws')</st></strong><st c="46713">
def add_vote_count_server(</st><strong class="bold"><st c="46740">ws</st></strong><st c="46743">):
    async def add_vote_count():
        while True:
            vote_count_json = ws.receive()
            vote_count_dict = loads(vote_count_json)
            async with db_session() as sess:
                repo = VoteCountRepository(sess)
                vote_count = VoteCount(**vote_count_dict)
                result = await repo.insert(vote_count)
                if result:
                    ws.send("data added")
                else:
                    ws.send("data not added")
    run(add_vote_count())</st></pre>			<p><st c="47092">The </st><strong class="source-inline"><st c="47097">Sock</st></strong><st c="47101"> instance has a </st><strong class="source-inline"><st c="47117">route()</st></strong><st c="47124"> decorator that defines WebSocket implementation. </st><st c="47174">WebSocket route function or handler is always non-asynchronous with a required parameter that accepts an injected WebSocket object from </st><strong class="source-inline"><st c="47310">Sock</st></strong><st c="47314">. This </st><strong class="source-inline"><st c="47321">ws</st></strong><st c="47323"> object has a </st><strong class="source-inline"><st c="47337">send()</st></strong><st c="47343"> method that emits data to the client application, a </st><strong class="source-inline"><st c="47396">receive()</st></strong><st c="47405"> utility that accepts messages from the client, and </st><strong class="source-inline"><st c="47457">close()</st></strong><st c="47464"> to employ forced disconnection of the two-way communication when runtime exceptions or server-related </st><span class="No-Break"><st c="47567">problems occur.</st></span></p>
			<p><st c="47582">The </st><a id="_idIndexMarker346"/><st c="47587">WebSocket handler usually holds an </st><em class="italic"><st c="47622">open loop process</st></em><st c="47639"> where it can receive a message first through </st><strong class="source-inline"><st c="47685">receive()</st></strong><st c="47694"> and then emit its message using </st><strong class="source-inline"><st c="47727">send()</st></strong><st c="47733"> continuously, depending on the purpose of </st><span class="No-Break"><st c="47776">the messaging.</st></span></p>
			<p><st c="47790">In the case of </st><strong class="source-inline"><st c="47806">add_vote_count_server()</st></strong><st c="47829">, which needs to await asynchronous </st><strong class="source-inline"><st c="47865">VoteCountRepository</st></strong><st c="47884">’s INSERT transaction, an </st><strong class="source-inline"><st c="47911">async</st></strong><st c="47916"> local method similar to the Celery task must be present inside the WebSocket route function. </st><st c="48010">This local method will encase the asynchronous operations, and the </st><strong class="source-inline"><st c="48077">asyncio</st></strong><st c="48084">’s </st><strong class="source-inline"><st c="48088">run()</st></strong><st c="48093"> will execute it inside the </st><span class="No-Break"><st c="48121">route function.</st></span></p>
			<p><st c="48136">Now, to witness the exchange of messages, </st><span class="No-Break"><em class="italic"><st c="48179">Figure 5</st></em></span><em class="italic"><st c="48187">.3</st></em><st c="48189"> shows a snapshot of the communication between our JS client and the </st><strong class="source-inline"><st c="48258">add_vote_count_server()</st></strong><st c="48281"> handler </st><span class="No-Break"><st c="48290">at runtime:</st></span></p>
			<div>
				<div id="_idContainer040" class="IMG---Figure">
					<img src="image/B19383_05_003.jpg" alt="Figure 5.3 – A message exchange between a JS client and flask-sock WebSocket"/><st c="48301"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="48668">Figure 5.3 – A message exchange between a JS client and flask-sock WebSocket</st></p>
			<p><st c="48744">Aside from web-based clients, WebSocket can also propagate or send data to </st><span class="No-Break"><st c="48820">API clients.</st></span></p>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor136"/><st c="48832">Creating a Flask API client application</st></h2>
			<p><st c="48872">Another way to </st><a id="_idIndexMarker347"/><st c="48888">connect through WebSocket emitters is through Flask components, not JS codes. </st><st c="48966">Sometimes, the client applications are not web components composed of HTML, CSS, and frontend JS frameworks that support WebSocket communication. </st><st c="49112">For instance, in our </st><strong class="source-inline"><st c="49133">ch05-api</st></strong><st c="49141"> project, a POST API function, </st><strong class="source-inline"><st c="49172">bulk_check_vote_count()</st></strong><st c="49195">, asks for a list of candidates to count the votes they have during the election. </st><st c="49277">The input to the API is a JSON string, such as the following </st><span class="No-Break"><st c="49338">sample data:</st></span></p>
			<pre class="source-code"><st c="49350">
[
    {
        "election_id": 1,
        "cand_id": "PHL-101"
    },
    {
        "election_id": 1,
        "cand_id": "PHL-111"
    },
    {
        "election_id": 1,
        "cand_id": "PHL-005"
    }
]</st></pre>			<p><st c="49485">Then, the API function converts this JSON input to a list of dictionaries containing the candidate and election IDs. </st><st c="49603">Here is the implementation of this API function that serves as a client to </st><span class="No-Break"><st c="49678">a WebSocket:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="49690">from simple_websocket import Client</st></strong>
<strong class="bold"><st c="49726">from json import dumps</st></strong>
<strong class="bold"><st c="49749">@current_app.post("/ch05/check/vote/counts/client")</st></strong><st c="49801">
def bulk_check_vote_count():
    </st><strong class="bold"><st c="49831">ws =</st></strong> <strong class="bold"><st c="49835">Client('ws://127.0.0.1:5000/ch05/check/vote/counts/ws',</st></strong><strong class="bold"><st c="49891">headers={"Access-Control-Allow-Origin": "*"})</st></strong><strong class="bold"><st c="49937">candidates = request.get_json()</st></strong><st c="49969">
    for candidate in candidates:
            try:
                print(f'client sent: {candidate}')
                </st><strong class="bold"><st c="50039">ws.send(dumps(candidate))</st></strong><strong class="bold"><st c="50064">vote_count = ws.receive()</st></strong><st c="50090">
                print(f'client recieved: {vote_count}')
            except Exception as e:
                print(e)
    return jsonify(message="done client transaction"), 201</st></pre>			<p><st c="50217">Since the most compatible WebSocket client extension for </st><strong class="source-inline"><st c="50275">flask-sock</st></strong><st c="50285"> is </st><strong class="source-inline"><st c="50289">simple-websocket</st></strong><st c="50305">, install this module using the </st><span class="No-Break"><strong class="source-inline"><st c="50337">pip</st></strong></span><span class="No-Break"><st c="50340"> command:</st></span></p>
			<pre class="console"><st c="50349">
pip install simple-websocket</st></pre>			<p><st c="50378">Instantiate the </st><strong class="source-inline"><st c="50395">Client</st></strong><st c="50401"> class</st><a id="_idIndexMarker348"/><st c="50407"> from the </st><strong class="source-inline"><st c="50417">simple-websocket</st></strong><st c="50433"> module to connect to the </st><strong class="source-inline"><st c="50459">flask-sock</st></strong><st c="50469"> WebSocket emitter with </st><strong class="source-inline"><st c="50493">Access-Control-Allow-Origin</st></strong><st c="50520"> to allow cross-origin access. </st><st c="50551">Then, the API will send the dictionary-converted-to-string details to the emitter using the </st><strong class="source-inline"><st c="50643">Client</st></strong><st c="50649">’s </st><span class="No-Break"><strong class="source-inline"><st c="50653">send()</st></strong></span><span class="No-Break"><st c="50659"> method.</st></span></p>
			<p><st c="50667">On the other hand, the WebSocket route that will receive the election details from the </st><strong class="source-inline"><st c="50755">bulk_check_vote_count()</st></strong><st c="50778"> client API has the </st><span class="No-Break"><st c="50798">following implementation:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="50823">@sock.route("/ch05/check/vote/counts/ws")</st></strong><st c="50865">
def bulk_check_vote_count_ws(</st><strong class="bold"><st c="50895">websocket</st></strong><st c="50905">):
   </st><strong class="bold"><st c="50909">async</st></strong><st c="50914"> def vote_count():
      While True:
        try:
          </st><strong class="bold"><st c="50950">candidate = websocket.receive()</st></strong><st c="50981">
          candidate_map = loads(candidate)
          print(f'server received: {candidate_map}')
          async with db_session() as sess:
            async with sess.begin():
               repo = VoteRepository(sess)
               </st><strong class="bold"><st c="51144">count = await repo.count_votes_by_candidate(</st></strong> <strong class="bold"><st c="51188">candidate_map["cand_id"],</st></strong> <strong class="bold"><st c="51214">int(candidate_map["election_id"]))</st></strong><st c="51249">
               vote_count_data = {"cand_id": candidate_map["cand_id"], "vote_count": count}
               </st><strong class="bold"><st c="51327">websocket.send(dumps(vote_count_data))</st></strong><st c="51365">
               print(f'server sent: {candidate_map}')
        except  Exception as e:
          print(e)
          break
   </st><strong class="bold"><st c="51443">run(vote_count())</st></strong></pre>			<p><st c="51460">Similar to the preceding</st><a id="_idIndexMarker349"/><st c="51485"> implementation, our WebSocket route uses </st><strong class="source-inline"><st c="51527">run()</st></strong><st c="51532"> from </st><strong class="source-inline"><st c="51538">asyncio</st></strong><st c="51545"> to execute asynchronous query transactions from </st><strong class="source-inline"><st c="51594">VoteRepository</st></strong><st c="51608"> and extract the total number of votes for each candidate sent by the API client. </st><st c="51690">The emitter will send a newly formed dictionary containing the candidate’s ID and counted votes back to the client API in string format. </st><st c="51827">So, the handshake in this setup is between two Flask components, the WebSocket route and an async </st><span class="No-Break"><st c="51925">Flask API.</st></span></p>
			<p><st c="51935">There are other client-server interactions that </st><strong class="source-inline"><st c="51984">flask[async]</st></strong><st c="51996"> can build, and one of these is </st><span class="No-Break"><st c="52028">the SSE.</st></span></p>
			<h1 id="_idParaDest-135"><a id="_idTextAnchor137"/><st c="52036">Implementing asynchronous SSE</st></h1>
			<p><st c="52066">Like the</st><a id="_idIndexMarker350"/><st c="52075"> WebSocket, the SSE is a real-time mechanism for sending messages from the server to client applications. </st><st c="52181">However, unlike the WebSocket, it establishes unidirectional communication between the server and </st><span class="No-Break"><st c="52279">client applications.</st></span></p>
			<p><st c="52299">There are many ways to build server push solutions in Flask, but our applications prefer using the built-in </st><span class="No-Break"><st c="52408">response’s </st></span><span class="No-Break"><strong class="source-inline"><st c="52419">text/event-stream</st></strong></span><span class="No-Break"><st c="52436">.</st></span></p>
			<h2 id="_idParaDest-136"><a id="_idTextAnchor138"/><st c="52437">Implementing the message publisher</st></h2>
			<p><st c="52472">SSE is a </st><em class="italic"><st c="52482">server push</st></em><st c="52493"> solution </st><a id="_idIndexMarker351"/><st c="52503">that requires an input source where it can listen for incoming data or messages in real time and push that data to its client applications. </st><st c="52643">One of the reliable sources that will work with SSE is </st><a id="_idIndexMarker352"/><st c="52698">a </st><strong class="bold"><st c="52700">message broker</st></strong><st c="52714">, which can store messages from various resources. </st><st c="52765">It can also help the SSE generator function to listen for incoming messages before yielding them to </st><span class="No-Break"><st c="52865">the clients.</st></span></p>
			<p><st c="52877">In this chapter, our </st><strong class="source-inline"><st c="52899">ch05-web</st></strong><st c="52907"> application utilizes Redis as the broker, which our </st><strong class="source-inline"><st c="52960">ch05-api</st></strong><st c="52968"> project used for invoking the Celery background tasks. </st><st c="53024">However, in this scenario, there is a need to create a Redis client application that will implement its publisher-subscribe pattern. </st><st c="53157">So, install the </st><em class="italic"><st c="53173">redis-py</st></em><st c="53181"> extension by using the </st><span class="No-Break"><strong class="source-inline"><st c="53205">pip</st></strong></span><span class="No-Break"><st c="53208"> command:</st></span></p>
			<pre class="console"><st c="53217">
pip install redis</st></pre>			<p><st c="53235">This extension will provide us with the </st><strong class="source-inline"><st c="53276">Redis</st></strong><st c="53281"> client that will connect to the Redis server once instantiated in the </st><strong class="source-inline"><st c="53352">main</st></strong><st c="53356"> module. </st><st c="53365">The following </st><strong class="source-inline"><st c="53379">main.py</st></strong><st c="53386"> snippet shows the setup of the Redis </st><span class="No-Break"><st c="53424">client application:</st></span></p>
			<pre class="source-code"><st c="53443">
from app import create_app
</st><strong class="bold"><st c="53471">from redis import Redis</st></strong><st c="53494">
app = create_app('../config_dev.toml')
</st><strong class="bold"><st c="53534">redis_conn = Redis(</st></strong><strong class="bold"><st c="53553">db = 0,</st></strong><strong class="bold"><st c="53561">host='127.0.0.1',</st></strong><strong class="bold"><st c="53579">port=6379,</st></strong><strong class="bold"><st c="53590">decode_responses=True</st></strong><st c="53612">
)</st></pre>			<p><st c="53614">The Redis callable requires details about the DB (</st><strong class="source-inline"><st c="53664">db</st></strong><st c="53667">), port, and host address of the installed Redis server as its parameters for setup. </st><st c="53753">Since Celery tasks can return bytes, the </st><strong class="source-inline"><st c="53794">Redis</st></strong><st c="53799"> constructor should set its </st><strong class="source-inline"><st c="53827">decode_response</st></strong><st c="53842"> parameter to </st><strong class="source-inline"><st c="53856">True</st></strong><st c="53860"> to enable binary message data decoding mechanism and receive decoded strings. </st><st c="53939">The instance, </st><strong class="source-inline"><st c="53953">redis_conn</st></strong><st c="53963">, will be the key to the message publisher implementation needed by the SSE. </st><st c="54040">In the complaint module of the application, our input source is a form view function that requests the user its statement and voter’s ID before pushing these details to the Redis </st><a id="_idIndexMarker353"/><st c="54219">broker. </st><st c="54227">The following is the view that publishes data to the </st><span class="No-Break"><st c="54280">Redis server:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="54293">from main import redis_conn</st></strong><st c="54321">
from  json import dumps
</st><strong class="bold"><st c="54345">@current_app.route('/ch05/election/complaint/form', methods = ['GET','POST'])</st></strong>
<strong class="bold"><st c="54422">async</st></strong><st c="54428"> def create_complaint():
    if request.method == "GET":
        return render_template('complaint_form.html')
    else:
        voter_id = request.form['voter_id']
        complaint = request.form['complaint']
        record = {'voter_id': voter_id, 'complaint': complaint}
        </st><strong class="bold"><st c="54663">redis_conn.publish("complaint_channel",</st></strong> <strong class="bold"><st c="54702">dumps(record))</st></strong><st c="54717">
        return render_template('complaint_form.html')</st></pre>			<p><st c="54763">The </st><strong class="source-inline"><st c="54768">Redis</st></strong><st c="54773"> client</st><a id="_idIndexMarker354"/><st c="54780"> instance, </st><strong class="source-inline"><st c="54791">redis_conn</st></strong><st c="54801">, has a </st><strong class="source-inline"><st c="54809">publish()</st></strong><st c="54818"> method that stores a message to Redis under a specific topic or channel, a point where a subscriber will fetch the message from the broker. </st><st c="54959">The name of our Redis channel </st><span class="No-Break"><st c="54989">is </st></span><span class="No-Break"><strong class="source-inline"><st c="54992">complaint_channel</st></strong></span><span class="No-Break"><st c="55009">.</st></span></p>
			<h2 id="_idParaDest-137"><a id="_idTextAnchor139"/><st c="55010">Building the server push</st></h2>
			<p><st c="55035">Our SSE will be</st><a id="_idIndexMarker355"/><st c="55051"> the subscriber to </st><strong class="source-inline"><st c="55070">complaint_channel</st></strong><st c="55087">. It will create a subscriber object first, through </st><strong class="source-inline"><st c="55139">redis_conn</st></strong><st c="55149">’s </st><strong class="source-inline"><st c="55153">pubsub()</st></strong><st c="55161"> method, to connect to Redis and eventually use the broker to listen for any published message from the form view. </st><st c="55276">The following is our SSE implementation using the </st><strong class="source-inline"><st c="55326">async</st></strong> <span class="No-Break"><st c="55331">Flask route:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="55344">@current_app.route('/ch05/elec/comaplaint/stream')</st></strong>
<strong class="bold"><st c="55395">async</st></strong><st c="55401"> def elec_complaint_sse():
    def process_complaint_event():
        </st><strong class="bold"><st c="55459">connection = redis_conn.pubsub()</st></strong><strong class="bold"><st c="55491">connection.subscribe('complaint_channel')</st></strong><st c="55533">
        for message in </st><strong class="bold"><st c="55549">connection.listen()</st></strong><st c="55568">:
            time.sleep(1)
            if message is not None and message['type'] == 'message':
                </st><strong class="bold"><st c="55642">data = message['data']</st></strong><strong class="bold"><st c="55664">yield 'data: %s\n\n' % data</st></strong><st c="55692">
    return </st><strong class="bold"><st c="55700">Response(process_complaint_event(),</st></strong> <strong class="bold"><st c="55735">mimetype="text/event-stream")</st></strong></pre>			<p><strong class="source-inline"><st c="55765">process_complaint_event()</st></strong><st c="55791"> in the given SSE route is the </st><em class="italic"><st c="55822">generator function</st></em><st c="55840"> that creates the subscriber object (</st><strong class="source-inline"><st c="55877">connection</st></strong><st c="55888">), connects to Redis by invoking the </st><strong class="source-inline"><st c="55926">subscribe()</st></strong><st c="55937"> method, and builds an open loop transaction that will listen continuously from the broker for currently published messages. </st><st c="56062">The message it retrieves from the </st><strong class="source-inline"><st c="56096">listen()</st></strong><st c="56104"> utility of the subscriber object is a JSON entity containing details about the message type, channel, and the </st><strong class="source-inline"><st c="56215">data</st></strong><st c="56219"> published by the form view publisher. </st><strong class="source-inline"><st c="56258">elec_complaint_sse()</st></strong><st c="56278"> only needs to yield the </st><strong class="source-inline"><st c="56303">data</st></strong><st c="56307"> portion of the message. </st><st c="56332">Now, running the </st><strong class="source-inline"><st c="56349">process_complaint_event()</st></strong><st c="56374"> generator requires the SSE route to return Flask’s </st><strong class="source-inline"><st c="56426">Response</st></strong><st c="56434">, which will execute and render it as a </st><strong class="source-inline"><st c="56474">text/event-stream</st></strong><st c="56491"> type</st><a id="_idIndexMarker356"/><st c="56496"> object. </st><span class="No-Break"><em class="italic"><st c="56505">Figure 5</st></em></span><em class="italic"><st c="56513">.4</st></em><st c="56515"> shows the form view catering to the voters for </st><span class="No-Break"><st c="56563">their complaints:</st></span></p>
			<div>
				<div id="_idContainer041" class="IMG---Figure">
					<img src="image/B19383_05_004.jpg" alt="Figure 5.4 – A complaint form view of the published data to Redis"/><st c="56580"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="56748">Figure 5.4 – A complaint form view of the published data to Redis</st></p>
			<p><span class="No-Break"><em class="italic"><st c="56813">Figure 5</st></em></span><em class="italic"><st c="56822">.5</st></em><st c="56824"> provides a snapshot of the SSE client page with the pushed messages from the </st><span class="No-Break"><st c="56902">Redis broker.</st></span></p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B19383_05_005.jpg" alt="Figure 5.5 – An SSE client page rendering pushed data from Redis"/><st c="56915"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="57234">Figure 5.5 – An SSE client page rendering pushed data from Redis</st></p>
			<p><st c="57298">Aside from broker messaging, Flask supports other libraries that use publisher-subscriber design patterns in creating its components. </st><st c="57433">The next subject will showcase one of them, the </st><span class="No-Break"><strong class="source-inline"><st c="57481">reactivex</st></strong></span><span class="No-Break"><st c="57490"> module.</st></span></p>
			<h1 id="_idParaDest-138"><a id="_idTextAnchor140"/><st c="57498">Applying reactive programming with RxPy</st></h1>
			<p><strong class="bold"><st c="57538">Reactive programming</st></strong><st c="57559"> is </st><a id="_idIndexMarker357"/><st c="57563">one of the emerging popular programming paradigms nowadays that focuses on asynchronous data streams and operations that can manage executions, events, repositories, and exception propagations. </st><st c="57757">It utilizes the publisher-subscriber programming approach, which builds asynchronous interactions between software components </st><span class="No-Break"><st c="57883">and transactions.</st></span></p>
			<p><st c="57900">The</st><a id="_idIndexMarker358"/><st c="57904"> library used to apply reactive streams to build services transactions and API functions in this chapter is </st><strong class="source-inline"><st c="58012">reactivex</st></strong><st c="58021">, so install the module using the </st><span class="No-Break"><strong class="source-inline"><st c="58055">pip</st></strong></span><span class="No-Break"><st c="58058"> command:</st></span></p>
			<pre class="console"><st c="58067">
pip install reactivex</st></pre>			<p><st c="58089">The </st><strong class="source-inline"><st c="58094">reactivex</st></strong><st c="58103"> module has an </st><strong class="source-inline"><st c="58118">Observable</st></strong><st c="58128"> class that generates data sources for the subscribers to consume. </st><strong class="source-inline"><st c="58195">Observer</st></strong><st c="58203"> is another API class that pertains to the subscriber entities. </st><strong class="source-inline"><st c="58267">reactivex</st></strong><st c="58276"> will not be a complete reactive programming library without its </st><em class="italic"><st c="58341">operators</st></em><st c="58350">. The following is a vote-counting service implementation that uses the </st><span class="No-Break"><strong class="source-inline"><st c="58422">reactivex</st></strong></span><span class="No-Break"><st c="58431"> utilities:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="58442">from reactivex import Observable, Observer, create</st></strong>
<strong class="bold"><st c="58493">from reactivex.disposable import Disposable</st></strong>
<strong class="bold"><st c="58537">from asyncio import ensure_future</st></strong>
<strong class="bold"><st c="58571">async</st></strong><st c="58577"> def extract_precinct_tally(rec_dict):
    del rec_dict['id']
    del rec_dict['election_id']
    del rec_dict['approved_date']
    return str(rec_dict)
</st><strong class="bold"><st c="58714">async</st></strong><st c="58719"> def create_tally_data(</st><strong class="bold"><st c="58742">observer</st></strong><st c="58751">):
    async with db_session() as sess:
          async with sess.begin():
            repo = VoteCountRepository(sess)
            records = await repo.select_all_votecount()
            votecount_rec = [rec.to_json() for rec in records]
            print(votecount_rec)
            for vc in votecount_rec:
                rec_str = await extract_precinct_tally(vc)
                </st><strong class="bold"><st c="59030">observer.on_next(rec_str)</st></strong><strong class="bold"><st c="59055">observer.on_completed()</st></strong>
<strong class="bold"><st c="59079">def create_observable(loop) -&gt; Observable:</st></strong><strong class="bold"><st c="59122">def on_subscribe(observer: Observer, scheduler):</st></strong><strong class="bold"><st c="59171">task = ensure_future(create_tally_data(observer),</st></strong> <strong class="bold"><st c="59221">loop=loop)</st></strong><strong class="bold"><st c="59232">return Disposable(lambda: task.cancel())</st></strong><strong class="bold"><st c="59273">return create(on_subscribe)</st></strong></pre>			<p><st c="59301">All repository transactions</st><a id="_idIndexMarker359"/><st c="59329"> involved in the process are asynchronous, which makes the </st><strong class="source-inline"><st c="59388">create_tally_data()</st></strong><st c="59407"> and </st><strong class="source-inline"><st c="59412">extract_precinct_tally()</st></strong><st c="59436"> service operations that utilize these </st><strong class="source-inline"><st c="59475">async</st></strong><st c="59480"> queries also asynchronous. </st><st c="59508">The objective is not to call these </st><strong class="source-inline"><st c="59543">async</st></strong><st c="59548"> services directly from the API layer but to wrap these service transactions in one </st><strong class="source-inline"><st c="59632">Observable</st></strong><st c="59642"> object through </st><strong class="source-inline"><st c="59658">create_observable()</st></strong><st c="59677"> and let the API functions subscribe to it. </st><st c="59721">However, the problem is that </st><strong class="source-inline"><st c="59750">create_observable()</st></strong><st c="59769"> can’t be </st><strong class="source-inline"><st c="59779">async</st></strong><st c="59784"> because </st><strong class="source-inline"><st c="59793">reactivex</st></strong><st c="59802"> does not allow </st><strong class="source-inline"><st c="59818">async</st></strong><st c="59823"> to deal with its operators such as </st><strong class="source-inline"><st c="59859">create()</st></strong><st c="59867">, </st><strong class="source-inline"><st c="59869">from_iterable()</st></strong><st c="59884">, </st><span class="No-Break"><st c="59886">and </st></span><span class="No-Break"><strong class="source-inline"><st c="59890">from_list()</st></strong></span><span class="No-Break"><st c="59901">.</st></span></p>
			<p><st c="59902">With that, the </st><strong class="source-inline"><st c="59918">create_observable()</st></strong><st c="59937"> custom function needs a local-scoped subscriber function, </st><strong class="source-inline"><st c="59996">on_subscribe()</st></strong><st c="60010">, that will invoke </st><strong class="source-inline"><st c="60029">create_task()</st></strong><st c="60042"> or </st><strong class="source-inline"><st c="60046">ensure_future()</st></strong><st c="60061"> with an event loop to create a task for the </st><strong class="source-inline"><st c="60106">create_tally_data()</st></strong><st c="60125"> coroutine and return it as a </st><strong class="source-inline"><st c="60155">Disposable</st></strong><st c="60165"> resource object. </st><st c="60183">A disposable resource link allows for the cleaning up of the resources used by the observable operators during the subscription. </st><st c="60312">Creating the </st><strong class="source-inline"><st c="60325">async</st></strong><st c="60330"> subscriber disposable will help manage the </st><span class="No-Break"><st c="60374">Flask resources.</st></span></p>
			<p><st c="60390">In connection with this setup, </st><strong class="source-inline"><st c="60422">create_tally_data()</st></strong><st c="60441"> will now emit the vote counts from the repository to the observer or subscriber. </st><st c="60523">The only goal now of </st><strong class="source-inline"><st c="60544">create_observable()</st></strong><st c="60563"> is to return its created </st><strong class="source-inline"><st c="60589">Observable</st></strong><st c="60599"> based on the </st><span class="No-Break"><strong class="source-inline"><st c="60613">on_subscribe()</st></strong></span><span class="No-Break"><st c="60627"> emissions.</st></span></p>
			<p><st c="60638">The API transaction needs </st><a id="_idIndexMarker360"/><st c="60665">to run the </st><strong class="source-inline"><st c="60676">create_tally_date()</st></strong><st c="60695"> service and extract all the emitted vote counts by invoking </st><strong class="source-inline"><st c="60756">create_observable()</st></strong><st c="60775"> and subscribing to its returned </st><strong class="source-inline"><st c="60808">Observable</st></strong><st c="60818"> through the </st><strong class="source-inline"><st c="60831">subscribe()</st></strong><st c="60842"> method. </st><st c="60851">The following is the </st><strong class="source-inline"><st c="60872">list_votecount_tally()</st></strong><st c="60894"> endpoint function that creates a subscription to the </st><span class="No-Break"><st c="60948">returned </st></span><span class="No-Break"><strong class="source-inline"><st c="60957">Observable</st></strong></span><span class="No-Break"><st c="60967">:</st></span></p>
			<pre class="source-code"><st c="60969">
from app.services.vote_count import create_observable
from asyncio import get_event_loop, Future
</st><strong class="bold"><st c="61067">@current_app.get("/ch05/votecount/tally")</st></strong><st c="61108">
async def list_votecount_tally():
    finished = Future()
    </st><strong class="bold"><st c="61163">loop = get_event_loop()</st></strong><st c="61186">
    def on_completed():
        finished.set_result(0)
    tally = []
    </st><strong class="bold"><st c="61241">disposable</st></strong><st c="61251"> = </st><strong class="bold"><st c="61254">create_observable(loop).subscribe(</st></strong><strong class="bold"><st c="61288">on_next = lambda i: tally.append(i),</st></strong><strong class="bold"><st c="61325">on_error = lambda e: print("Error</st></strong> <strong class="bold"><st c="61359">Occurred: {0}".format(e)),</st></strong><strong class="bold"><st c="61386">on_completed = on_completed)</st></strong><strong class="bold"><st c="61415">await finished</st></strong><strong class="bold"><st c="61430">disposable.dispose()</st></strong><st c="61451">
    return jsonify(tally=tally), 201</st></pre>			<p><strong class="source-inline"><st c="61484">subscribe()</st></strong><st c="61496"> has three</st><a id="_idIndexMarker361"/><st c="61506"> callback methods that are all active and ready to run anytime </st><span class="No-Break"><st c="61569">when triggered:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="61584">on_next()</st></strong><st c="61594">: This executes when </st><strong class="source-inline"><st c="61616">Observer</st></strong><st c="61624"> receives </st><span class="No-Break"><st c="61634">emitted data.</st></span></li>
				<li><strong class="source-inline"><st c="61647">on_error()</st></strong><st c="61658">: This executes when </st><strong class="source-inline"><st c="61680">Observable</st></strong><st c="61690"> encounters an exception along </st><span class="No-Break"><st c="61721">its operators.</st></span></li>
				<li><strong class="source-inline"><st c="61735">on_completed()</st></strong><st c="61750">: This runs when </st><strong class="source-inline"><st c="61768">Observable</st></strong><st c="61778"> completes </st><span class="No-Break"><st c="61789">its task.</st></span></li>
			</ul>
			<p><st c="61798">Our </st><strong class="source-inline"><st c="61803">on_next()</st></strong><st c="61812"> callback adds all the emitted data to the </st><span class="No-Break"><st c="61855">tally list.</st></span></p>
			<p><st c="61866">Now, the execution of the </st><strong class="source-inline"><st c="61893">Observable</st></strong><st c="61903"> operations will not be possible without the event loop. </st><st c="61960">The API function needs the currently running event loop for the </st><strong class="source-inline"><st c="62024">create_tally_data()</st></strong><st c="62043"> coroutine execution, and thus its </st><strong class="source-inline"><st c="62078">get_event_loop()</st></strong><st c="62094"> invocation. </st><st c="62107">The API will return the tally list once it disposes of the task running </st><span class="No-Break"><st c="62179">in </st></span><span class="No-Break"><strong class="source-inline"><st c="62182">Observable</st></strong></span><span class="No-Break"><st c="62192">.</st></span></p>
			<p><st c="62193">Even though our framework is asynchronous Flask or the solutions applied to our applications are reactive and asynchronous, Flask will remain a WSGI-based framework, unlike FastAPI. </st><st c="62376">The platform is still not 100% asynchronous friendly. </st><st c="62430">However, if the application requires a 100% Flask environment, replace Flask with one of its variations called the </st><span class="No-Break"><em class="italic"><st c="62545">Quart</st></em></span><span class="No-Break"><st c="62550"> framework.</st></span></p>
			<h1 id="_idParaDest-139"><a id="_idTextAnchor141"/><st c="62561">Choosing Quart over Flask 2.x</st></h1>
			<p><st c="62591">Quart</st><a id="_idIndexMarker362"/><st c="62597"> is a Flask framework in and out but with a platform that runs entirely on </st><strong class="source-inline"><st c="62672">asyncio</st></strong><st c="62679">. Many of the core features from Flask are part of the Quart framework, except for the main application class. </st><st c="62790">The framework has its </st><strong class="source-inline"><st c="62812">Quart</st></strong><st c="62817"> class to set up </st><span class="No-Break"><st c="62834">an application.</st></span></p>
			<p><st c="62849">Moreover, Quart supports the </st><strong class="bold"><st c="62879">HTTP/2</st></strong><st c="62885"> protocol, which </st><a id="_idIndexMarker363"/><st c="62902">allows faster interaction between its components and the server. </st><st c="62967">Therefore, it is best to use servers such as the </st><strong class="source-inline"><st c="63016">hypercorn</st></strong><st c="63025"> server, which supports HTTP/2 </st><span class="No-Break"><st c="63056">request-response transactions.</st></span></p>
			<p><st c="63086">Since Quart and</st><a id="_idIndexMarker364"/><st c="63102"> Flask are almost the same, migration of Flask applications to Quart is seamless and straightforward. </st><strong class="source-inline"><st c="63204">ch05-quart</st></strong><st c="63214"> is a product of migrating our </st><strong class="source-inline"><st c="63245">ch05-web</st></strong><st c="63253"> and </st><strong class="source-inline"><st c="63258">ch05-api</st></strong><st c="63266"> projects into using the Quart platform. </st><st c="63307">The following is the </st><strong class="source-inline"><st c="63328">app/__init__.py</st></strong><st c="63343"> configuration of </st><span class="No-Break"><st c="63361">that project:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="63374">from quart import Quart</st></strong><st c="63398">
import toml
from app.model.config import init_db
from app.api.home import home, welcome
from app.api.login import add_login, list_all_login
def create_app(config_file):
    </st><strong class="bold"><st c="63568">app = Quart(__name__, template_folder='../app/pages',</st></strong> <strong class="bold"><st c="63621">static_folder="../app/resources")</st></strong><strong class="bold"><st c="63655">app.config.from_file(config_file, toml.load)</st></strong><st c="63700">
    init_db()
    app.</st><strong class="bold"><st c="63715">add_url_rule</st></strong><st c="63728">('/ch05/home', view_func=home, endpoint='home')
    app.</st><strong class="bold"><st c="63781">add_url_rule</st></strong><st c="63794">('/ch05/welcome', view_func=welcome, endpoint='welcome')
    app.</st><strong class="bold"><st c="63856">add_url_rule</st></strong><st c="63869">('/ch05/login/add', view_func=add_login, endpoint='add_login')
    app.</st><strong class="bold"><st c="63937">add_url_rule</st></strong><st c="63950">('/ch05/login/list/all', view_func=list_all_login, endpoint='list_all_login')
    return app</st></pre>			<p><st c="64039">The </st><a id="_idIndexMarker365"/><st c="64044">Quart framework has a </st><strong class="source-inline"><st c="64066">Quart</st></strong><st c="64071"> class to build the application. </st><st c="64104">Its constructor parameters, such as </st><strong class="source-inline"><st c="64140">template_folder</st></strong><st c="64155"> and </st><strong class="source-inline"><st c="64160">static_folder</st></strong><st c="64173">, are the same as those of Flask. </st><st c="64207">The framework can also recognize TOML </st><span class="No-Break"><st c="64245">configuration files.</st></span></p>
			<p><st c="64265">On the repository layer, the framework has a </st><strong class="source-inline"><st c="64311">quart-sqlalchemy</st></strong><st c="64327"> extension module that supports asynchronous ORM operations for Quart applications. </st><st c="64411">There is no need to rewrite the model and repository classes during the migration because all the helper classes and utilities are the same as the </st><strong class="source-inline"><st c="64558">flask-sqlalchemy</st></strong><st c="64574"> extension. </st><st c="64586">The same </st><strong class="source-inline"><st c="64595">init_db()</st></strong><st c="64604"> from the project’s application factory will set up and load the helper functions, methods, and model classes of the </st><span class="No-Break"><strong class="source-inline"><st c="64721">quart-sqlalchemy</st></strong></span><span class="No-Break"><st c="64737"> ORM.</st></span></p>
			<p><st c="64742">Quart also supports blueprint, application factory design, or even the hybrid approach in building the application. </st><st c="64859">However, the current version, </st><em class="italic"><st c="64889">Quart 0.18.4</st></em><st c="64901">, does not have an easy way to manage the asynchronous request context so that modules inside the application can access the </st><strong class="source-inline"><st c="65026">current_app</st></strong><st c="65037"> proxy for view or API implementation. </st><st c="65076">That’s why, from the given configuration, the views and endpoints can be defined inside </st><strong class="source-inline"><st c="65164">create_app()</st></strong><st c="65176"> using </st><strong class="source-inline"><st c="65183">add_url_rule()</st></strong><st c="65197">. Decorating them with </st><strong class="source-inline"><st c="65220">route()</st></strong><st c="65227"> in their respective module script using the </st><strong class="source-inline"><st c="65272">app</st></strong><st c="65275"> object or </st><strong class="source-inline"><st c="65286">current_app</st></strong><st c="65297"> raises an exception. </st><st c="65319">Now, the following are the view and endpoint implementations in the </st><span class="No-Break"><st c="65387">Quart platform:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="65402">from quart import jsonify, render_template, request,</st></strong> <strong class="bold"><st c="65455">make_response</st></strong>
<strong class="bold"><st c="65469">async def add_login():</st></strong><st c="65492">
   async with db_session() as sess:
            repo = LoginRepository(sess)
            login_json = request.get_json()
            login = Login(**login_json)
            result = await repo.insert(login)
            if result:
                </st><strong class="bold"><st c="65660">content = jsonify(login_json)</st></strong><strong class="bold"><st c="65689">return await make_response(content, 201)</st></strong><st c="65730">
            else:
                content = jsonify(message="insert complaint details record encountered a problem")
                </st><strong class="bold"><st c="65820">return await make_response(content, 500)</st></strong>
<strong class="bold"><st c="65860">async</st></strong><st c="65866"> def welcome():
    </st><strong class="bold"><st c="65882">return await render_template('index.html'), 200</st></strong></pre>			<p><st c="65929">Compared to Flask, </st><strong class="source-inline"><st c="65949">render_template()</st></strong><st c="65966"> and </st><strong class="source-inline"><st c="65971">make_response()</st></strong><st c="65986"> here in Quart need the </st><strong class="source-inline"><st c="66010">await</st></strong><st c="66015"> keyword. </st><st c="66025">Another difference is Quart’s use of </st><strong class="source-inline"><st c="66062">hypercorn</st></strong><st c="66071"> to run its applications instead of the Werkzeug server. </st><st c="66128">So, install </st><strong class="source-inline"><st c="66140">hypercorn</st></strong><st c="66149"> using the </st><span class="No-Break"><strong class="source-inline"><st c="66160">pip</st></strong></span><span class="No-Break"><st c="66163"> command:</st></span></p>
			<pre class="console"><st c="66172">
pip install hypercorn</st></pre>			<p><st c="66194">Then, run the application with the </st><strong class="source-inline"><st c="66230">hypercorn </st></strong><span class="No-Break"><strong class="source-inline"><st c="66240">main:app</st></strong></span><span class="No-Break"><st c="66248"> command.</st></span></p>
			<p><st c="66257">So far, in </st><a id="_idIndexMarker366"/><st c="66269">general, Quart has been a promising asynchronous framework. </st><st c="66329">Let’s hope that collaborations with the creator, support groups, and enthusiasts can help upgrade and expand this framework in the </st><span class="No-Break"><st c="66460">near future.</st></span></p>
			<h1 id="_idParaDest-140"><a id="_idTextAnchor142"/><st c="66472">Summary</st></h1>
			<p><st c="66480">Flask 2.2 is now at par with the other frameworks that support and utilize asynchronous solutions to improve the application’s runtime performance. </st><st c="66629">Its view and API functions can now be </st><strong class="source-inline"><st c="66667">async</st></strong><st c="66672"> and runnable on an event loop created by Flask. </st><st c="66721">Asynchronous services and transactions can now be executed and awaited on the Flask platform as tasks created by </st><strong class="source-inline"><st c="66834">create_task()</st></strong> <span class="No-Break"><st c="66847">and </st></span><span class="No-Break"><strong class="source-inline"><st c="66852">ensure_future()</st></strong></span><span class="No-Break"><st c="66867">.</st></span></p>
			<p><st c="66868">The latest </st><em class="italic"><st c="66880">SQLAlchemy[async]</st></em><st c="66897"> can easily integrate with the Flask application to provide asynchronous CRUD transactions. </st><st c="66989">Also, creating asynchronous tasks to break down the sequence of blocking transactions in Celery background processes, WebSocket messaging, and Observable operations are now possible with </st><span class="No-Break"><st c="67176">Flask 2.2.</st></span></p>
			<p><st c="67186">Moreover, designing loosely coupled components, application-scoped cross-cut concern solutions, and some distributed setups is now feasible with Flask 2.2 through the built-in </st><span class="No-Break"><st c="67363">asynchronous signals.</st></span></p>
			<p><st c="67384">There is even a 100% asynchronous Flask framework called Quart that can build fast-performing </st><span class="No-Break"><st c="67479">request-response transactions.</st></span></p>
			<p><st c="67509">Although the purpose of asynchronous support in Flask is for performance, there is still a boundary on when it can be part of our applications. </st><st c="67654">Some components or utilities will degrade in their running time when used with </st><strong class="source-inline"><st c="67733">asyncio</st></strong><st c="67740">. Others, such as CRUD operations, will slow down DB access due to DB specifications that do not comply with the asynchronous setup. </st><st c="67873">So, the effect of asynchronous programming still depends on the requirements of the projects and the resources the </st><span class="No-Break"><st c="67988">application uses.</st></span></p>
			<p><st c="68005">The next chapter will bring us to the computational world of Flask, which deals with </st><strong class="source-inline"><st c="68091">numpy</st></strong><st c="68096">, </st><strong class="source-inline"><st c="68098">pandas</st></strong><st c="68104">, graphs, charts, statistics, file serializations, and other scientific solutions that Flask </st><span class="No-Break"><st c="68197">can provide.</st></span></p>
		</div>
	<div id="charCountTotal" value="68209"/></body></html>