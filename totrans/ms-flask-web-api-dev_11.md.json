["```py\n pip install psycopg2 peewee\n```", "```py\n<st c=\"2578\">(app/models/config.py)</st> from peewee import PostgresqlDatabase <st c=\"2640\">database = PostgresqlDatabase(</st> 'ogs', user='postgres', password='admin2255', <st c=\"2775\">PostgresqlDatabase</st>, <st c=\"2795\">MySQLDatabase</st>, and <st c=\"2814\">SqliteDatabase</st> driver classes that will create a connection object for the application. Our option is <st c=\"2916\">PostgresqlDatabase</st>, as shown in the preceding code, since our application uses the <st c=\"3065\">autocommit</st> constructor parameter to <st c=\"3101\">False</st> to enable transaction management for CRUD operations.\n\t\t\t<st c=\"3160\">The</st> `<st c=\"3165\">database</st>` <st c=\"3173\">connection object will map Peewee’s model classes to their actual table schemas.</st> <st c=\"3255\">The</st> <st c=\"3259\">following are some model classes of</st> <st c=\"3295\">our applications:</st>\n\n```", "```py\n<st c=\"4178\">class Stock(Model):</st> id = BigIntegerField(<st c=\"4220\">primary_key=True</st>, null=False, <st c=\"4251\">sequence=\"stock_id_seq\"</st>) <st c=\"4277\">sid = ForeignKeyField(model=Supplier, null=False,</st> <st c=\"4326\">to_field=\"sid\", backref=\"supplier\")</st><st c=\"4362\">invcode = ForeignKeyField(model=InvoiceRequest,</st> <st c=\"4410\">null=False, to_field=\"code\", backref=\"invoice\")</st> qty = IntegerField(null=False)\n    payment_date = DateField(null=True)\n    received_date = DateField(null=False)\n    recieved_by = CharField(max_length=\"100\") <st c=\"4606\">class Meta:</st><st c=\"4617\">db_table = \"stock\"</st><st c=\"4636\">database = database</st> … … … … … …\n```", "```py\n from app import create_app\nfrom app.models.config import database\napp = create_app('../config_dev.toml') <st c=\"5367\">@app.before_request</st> def db_connect(): <st c=\"5405\">database.connect()</st>\n<st c=\"5423\">@app.teardown_request</st> def db_close(exc): <st c=\"5517\">teardown_request()</st> closes the connection during server shutdown.\n\t\t\t<st c=\"5581\">Like</st> <st c=\"5587\">in SQLAlchemy, the Peewee ORM needs the model classes to create the transaction layer to</st> <st c=\"5676\">perform the CRUD operations.</st> <st c=\"5705\">The following is a</st> `<st c=\"5724\">ProductRepository</st>` <st c=\"5741\">class that manages and executes SQL statements using the standard</st> <st c=\"5808\">Peewee transactions:</st>\n\n```", "```py\n\n\t\t\t<st c=\"6139\">The Peewee repository class derives its transaction management from the</st> `<st c=\"6212\">database</st>` <st c=\"6220\">connection object.</st> <st c=\"6240\">Its emitted</st> `<st c=\"6252\">atomic()</st>` <st c=\"6260\">method provides a transaction object that performs</st> `<st c=\"6312\">commit()</st>` <st c=\"6320\">and</st> `<st c=\"6325\">rollback()</st>` <st c=\"6335\">during SQL execution.</st> <st c=\"6358\">The given</st> `<st c=\"6368\">insert_product()</st>` <st c=\"6384\">function performs an</st> `<st c=\"6406\">INSERT</st>` <st c=\"6412\">operation of a</st> `<st c=\"6428\">Product</st>` <st c=\"6435\">record by calling the model’s</st> `<st c=\"6466\">create()</st>` <st c=\"6474\">class method with the</st> `<st c=\"6497\">kwargs</st>` <st c=\"6503\">variable of details and returns</st> `<st c=\"6536\">True</st>` <st c=\"6540\">if the operation is successful.</st> <st c=\"6573\">Otherwise, it</st> <st c=\"6587\">returns</st> `<st c=\"6595\">False</st>`<st c=\"6600\">.</st>\n\t\t\t<st c=\"6601\">On the</st> <st c=\"6609\">other hand, an</st> `<st c=\"6624\">UPDATE</st>` <st c=\"6630\">operation in standard Peewee requires a transaction layer to retrieve the</st> <st c=\"6705\">record object that needs an update, access its concerned field(s), and replace them with new values.</st> <st c=\"6806\">The following</st> `<st c=\"6820\">update_product()</st>` <st c=\"6836\">function shows the implementation of a</st> `<st c=\"6876\">Product</st>` <st c=\"6883\">update:</st>\n\n```", "```py\n\n\t\t\t<st c=\"7338\">The</st> `<st c=\"7343\">get()</st>` <st c=\"7348\">method of the</st> <st c=\"7363\">model class retrieves a single instance matching the given query constraint.</st> <st c=\"7440\">The goal is to update only one record, so be sure that the constraint parameters in the record object retrieval only involve the</st> `<st c=\"7569\">unique</st>` <st c=\"7575\">or</st> `<st c=\"7579\">primary key</st>` <st c=\"7590\">column fields.</st>\n\t\t\t<st c=\"7605\">Now, the</st> `<st c=\"7615\">save()</st>` <st c=\"7621\">method of the</st> <st c=\"7636\">record object will eventually merge the new record object with the old one linked to the database.</st> <st c=\"7735\">This</st> `<st c=\"7740\">commit()</st>` <st c=\"7748\">will finally persist and flush the updated record to</st> <st c=\"7802\">the table.</st>\n\t\t\t<st c=\"7812\">When</st> <st c=\"7818\">it comes to deletion, the initial step is similar to updating a record, which involves retrieving the record</st> <st c=\"7927\">object for deletion.</st> <st c=\"7948\">The following</st> `<st c=\"7962\">delete_product_code()</st>` <st c=\"7983\">repository method depicts this</st> <st c=\"8015\">initial process:</st>\n\n```", "```py\n\n\t\t\t<st c=\"8246\">The record object has a</st> `<st c=\"8271\">delete_instance()</st>` <st c=\"8288\">function that removes the record from the schema.</st> <st c=\"8339\">In the case of</st> `<st c=\"8354\">delete_product_code()</st>`<st c=\"8375\">, it deletes a</st> `<st c=\"8390\">Product</st>` <st c=\"8397\">record through the record object retrieved by its</st> <st c=\"8448\">product code.</st>\n\t\t\t<st c=\"8461\">When</st> <st c=\"8467\">retrieving records, the</st> <st c=\"8491\">Peewee ORM has a</st> `<st c=\"8508\">select()</st>` <st c=\"8516\">method that builds variations of query implementations.</st> <st c=\"8573\">The following</st> `<st c=\"8587\">select_product_code()</st>` <st c=\"8608\">and</st> `<st c=\"8613\">select_product_id()</st>` <st c=\"8632\">functions show how to retrieve single records based on unique or primary</st> <st c=\"8706\">key constraints:</st>\n\n```", "```py\n\n\t\t\t<st c=\"8924\">On the other hand, the following</st> `<st c=\"8958\">select_all_product()</st>` <st c=\"8978\">function retrieves all records in the</st> `<st c=\"9017\">product</st>` <st c=\"9024\">table:</st>\n\n```", "```py\n\n\t\t\t<st c=\"9144\">All model classes retrieved by the</st> `<st c=\"9180\">select()</st>` <st c=\"9188\">method are non-serializable or non-JSONable.</st> <st c=\"9234\">So, in the implementation, be sure to include the conversion of all model objects into JSON records using any accepted method.</st> <st c=\"9361\">In the given sample, all our model classes have a</st> `<st c=\"9411\">to_json()</st>` <st c=\"9420\">method that returns a JSON object containing all the</st> `<st c=\"9474\">Product</st>` <st c=\"9481\">fields and values.</st> <st c=\"9501\">The query transactions include a list comprehension in its procedure to generate a list of JSONable records of</st> `<st c=\"9612\">Product</st>` <st c=\"9619\">details using the</st> `<st c=\"9638\">to_json()</st>` <st c=\"9647\">method.</st>\n\t\t\t<st c=\"9655\">Classes and methods for the Async Peewee ORM</st>\n\t\t\t<st c=\"9700\">Some parts of</st> <st c=\"9715\">our deployed</st> *<st c=\"9728\">Online Grocery</st>* <st c=\"9742\">application runs on the</st> `<st c=\"9975\">peewee-async</st>` <st c=\"9987\">module using the</st> <st c=\"10005\">following</st> `<st c=\"10015\">pip</st>` <st c=\"10018\">command:</st>\n\n```", "```py\n\n\t\t\t<st c=\"10058\">Also, include the</st> `<st c=\"10077\">aiopg</st>` <st c=\"10082\">module, which provides PostgreSQL asynchronous database access through the</st> *<st c=\"10158\">DB</st>* *<st c=\"10161\">API</st>* <st c=\"10164\">specification.</st>\n\t\t\t<st c=\"10179\">Async Peewee has</st> `<st c=\"10197\">PooledPostgresqlDatabase</st>`<st c=\"10221\">,</st> `<st c=\"10223\">AsyncPostgresqlConnection</st>`<st c=\"10248\">, and</st> `<st c=\"10254\">AsyncMySQLConnection</st>` <st c=\"10274\">driver classes that create database connection objects in</st> `<st c=\"10333\">async</st>` <st c=\"10338\">mode.</st> <st c=\"10345\">Our configuration uses the</st> `<st c=\"10372\">PooledPostgresqlDatabase</st>` <st c=\"10396\">driver class to include the creation of a</st> <st c=\"10439\">connection pool:</st>\n\n```", "```py\n<st c=\"11070\">from app.models.config import database</st>\n<st c=\"11109\">from peewee_async import Manager</st> def create_app(config_file):\n    app = Flask(__name__)\n    app.config.from_file(config_file, toml.load)\n    global conn_mgr <st c=\"11255\">conn_mgr = Manager(database)</st><st c=\"11283\">database.set_allow_sync(False)</st> … … … … … …\n```", "```py\n from app.models.db import Discount\nfrom app.models.db import database\nfrom app import conn_mgr\nfrom typing import Dict, Any\nclass DiscountRepository:\n    async def insert_discount(self, details:Dict[str, Any]) -> bool:\n        try: <st c=\"12249\">async with database.atomic_async() as tx:</st><st c=\"12290\">await conn_mgr.create(Discount, **details)</st><st c=\"12333\">await tx.commit()</st> return True\n        except Exception as e:\n            print(e)\n        return False\n```", "```py\n async def update_discount(self, details:Dict[str,Any]) -> bool:\n       try: <st c=\"13359\">async with database.atomic_async():</st><st c=\"13394\">discount = await conn_mgr.get(Discount,</st> <st c=\"13434\">code=details[\"code\"])</st> discount.rate = details[\"rate\"] <st c=\"13489\">await conn_mgr.update(discount,</st> <st c=\"13520\">only=(\"rate\", ))</st> return True\n       except Exception as e:\n           print(e)\n       return False\n```", "```py\n async def delete_discount_code(self, code:str) -> bool:\n        try: <st c=\"14163\">async with database.atomic_async():</st><st c=\"14198\">discount = await conn_mgr.get(Discount,</st> <st c=\"14238\">code=code)</st><st c=\"14249\">await conn_mgr.delete(discount)</st> return True\n        except Exception as e:\n            print(e)\n        return False\n```", "```py\n async def select_discount_code(self, code:str): <st c=\"14725\">discount = await conn_mgr.get(Discount, code=code)</st> return discount.to_json()\n    async def select_discount_id(self, id:int): <st c=\"14846\">discount = await conn_mgr.get(Discount, id=id)</st> return discount.to_json()\n    async def select_all_discount(self): <st c=\"14956\">discounts = await conn_mgr.execute(</st> <st c=\"14991\">Discount.select())</st> records = [log.to_json() for log in discounts]\n        return records\n```", "```py\n pip install gunicorn\n```", "```py\n gunicorn --bind 127.0.0.1:8000 main:app\n```", "```py\n gunicorn --bind 127.0.0.1:8000 main:app --workers 9\n```", "```py\n gunicorn --bind 127.0.0.1:8000 main:app --workers 1 --threads 2\n```", "```py\n pip install greenlet eventlet\n```", "```py\n pip install psycogreen\n```", "```py\n<st c=\"22360\">import psycogreen.eventlet</st>\n<st c=\"22387\">psycogreen.eventlet.patch_psycopg()</st> from app import create_app\nfrom app.models.config import database\napp = create_app('../config_dev.toml')\n… … … … … …\n```", "```py\n gunicorn --bind 127.0.0.1:8000 main:app --workers 1 --worker-class  eventlet --threads 2\n```", "```py\n pip install greenlet eventlet gevent\n```", "```py\n<st c=\"24743\">import gevent.monkey</st>\n<st c=\"24764\">gevent.monkey.patch_all()</st>\n<st c=\"24790\">import psycogreen.gevent</st>\n<st c=\"24815\">psycogreen.gevent.patch_psycopg()</st> import gevent\nfrom app import create_app\n… … … … … …\napp = create_app('../config_dev.toml')\n… … … … … …\n```", "```py\n gunicorn --bind 127.0.0.1:8000 main:app --workers 2 --worker-class gevent --threads 2\n```", "```py\n pip install pyuwsgi\n```", "```py\n uwsgi --http 127.0.0.1:8000 --master -p 4 -w main:app --enable-threads\n```", "```py\n pip install uvicorn\n```", "```py\n<st c=\"31138\">from asgiref.wsgi import WsgiToAsgi</st> from app import create_app\napp = create_app('../config_dev.toml') <st c=\"31297\">asgi_app</st> instead of the original Flask <st c=\"31336\">app</st>. To start Gunicorn using two Uvicorn workers with two threads each, run the following command:\n\n```", "```py\n\n\t\t\t<st c=\"31546\">Here,</st> `<st c=\"31553\">UvicornWorker</st>`<st c=\"31566\">, a Gunicorn-compatible worker class from the</st> `<st c=\"31612\">uvicorn</st>` <st c=\"31619\">library, provides an interface to an ASGI-based application so that Gunicorn can communicate with all the HTTP requests from the coroutines of the applications and eventually handle</st> <st c=\"31802\">those requests.</st>\n\t\t\t*<st c=\"31817\">Figure 11</st>**<st c=\"31827\">.8</st>* <st c=\"31829\">shows the server log after running the</st> <st c=\"31869\">Gunicorn server:</st>\n\t\t\t![Figure 11.8 – Server log after starting the Gunicorn server using UvicornWorker](img/B19383_11_008.jpg)\n\n\t\t\t<st c=\"33005\">Figure 11.8 – Server log after starting the Gunicorn server using UvicornWorker</st>\n\t\t\t<st c=\"33084\">The server log depicts the use of</st> `<st c=\"33119\">uvicorn.workers.UvicornWorker</st>` <st c=\"33148\">as the Gunicorn worker, and it also shows the “</st>*<st c=\"33196\">ASGI ‘lifespan’ protocol appears unsupported.</st>*<st c=\"33242\">” log message, which means Flask does not yet support ASGI with the lifespan</st> <st c=\"33320\">protocol used to manage server startup</st> <st c=\"33359\">and shutdown.</st>\n\t\t\t<st c=\"33372\">The Apache HTTP Server, a popular production server for most PHP applications, can also host and run standard Flask applications.</st> <st c=\"33503\">So, let’s explore the process of migrating our applications to the</st> *<st c=\"33570\">Apache</st>* *<st c=\"33577\">HTTP Server</st>*<st c=\"33588\">.</st>\n\t\t\t<st c=\"33589\">Deploying the application on the Apache HTTP Server</st>\n\t\t\t**<st c=\"33641\">Apache HTTP Server</st>** <st c=\"33660\">is an</st> <st c=\"33667\">open source server under the Apache</st> <st c=\"33703\">projects that can</st> <st c=\"33721\">run on Windows and UNIX-based platforms to provide an efficient, simple, and flexible HTTP server for</st> <st c=\"33823\">various applications.</st>\n\t\t\t<st c=\"33844\">Before anything else, download the latest server from</st> [<st c=\"33899\">https://httpd.apache.org/download.cgi</st>](https://httpd.apache.org/download.cgi) <st c=\"33936\">and unzip the file to the production server’s installation directory.</st> <st c=\"34007\">Then, download the latest</st> *<st c=\"34033\">Microsoft Visual C++ Redistributable</st>* <st c=\"34069\">from</st> [<st c=\"34075\">https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist</st>](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist)<st c=\"34147\">, install it, and run the server through the</st> `<st c=\"34192\">httpd.exe</st>` <st c=\"34201\">file of its</st> `<st c=\"34214\">/</st>``<st c=\"34215\">bin</st>` <st c=\"34218\">folder.</st>\n\t\t\t<st c=\"34226\">After the installation, follow these steps to deploy our application to the Apache</st> <st c=\"34310\">HTTP Server:</st>\n\n\t\t\t\t1.  <st c=\"34322\">Build your Flask application, as we did with our</st> *<st c=\"34372\">Online Grocery</st>* <st c=\"34386\">application, run it using the built-in WSGI server, and refine the components using</st> `<st c=\"34471\">pytest</st>` <st c=\"34477\">testing.</st>\n\t\t\t\t2.  <st c=\"34486\">Next, install the</st> `<st c=\"34505\">mod_wsgi</st>` <st c=\"34513\">module, which enables the Apache HTTP Server’s support to run WSGI applications.</st> <st c=\"34595\">Install the module using the following</st> `<st c=\"34634\">pip</st>` <st c=\"34637\">command:</st>\n\n    ```", "```py\n\n    \t\t\t\t3.  <st c=\"34667\">If the installation encounters an error similar to what’s shown in the error log in</st> *<st c=\"34752\">Figure 11</st>**<st c=\"34761\">.9</st>*<st c=\"34763\">, run the</st> `<st c=\"34773\">set</st>` <st c=\"34776\">command to assign the</st> `<st c=\"34850\">MOD_WSGI_APACHE_ROOTDIR</st>` <st c=\"34873\">environment variable:</st>\n\n    ```", "```py\n\n    \t\t\t\t4.  <st c=\"34949\">Apply</st> *<st c=\"34956\">forward slashes</st>* <st c=\"34971\">(</st>`<st c=\"34973\">/</st>`<st c=\"34974\">) to create the directory path.</st> <st c=\"35006\">Afterward, re-install the</st> `<st c=\"35032\">mod_wsgi</st>` <st c=\"35040\">module:</st>\n\n\t\t\t![Figure 11.9 – No MOD_WSGI_APACHE_ROOTDIR error](img/B19383_11_009.jpg)\n\n\t\t\t<st c=\"35501\">Figure 11.9 – No MOD_WSGI_APACHE_ROOTDIR error</st>\n\n\t\t\t\t1.  <st c=\"35547\">Again, if the</st> <st c=\"35562\">re-installation</st> <st c=\"35578\">of</st> `<st c=\"35581\">mod_wsgi</st>` <st c=\"35589\">gives another</st> <st c=\"35604\">error stating the required</st> `<st c=\"35685\">VisualStudioSetup.exe</st>` <st c=\"35706\">from</st> [<st c=\"35711\">https://visualstudio.microsoft.com/downloads</st>](https://visualstudio.microsoft.com/downloads)<st c=\"35756\">.</st>2.  <st c=\"35757\">Run the</st> `<st c=\"35766\">VisualStudioSetup.exe</st>` <st c=\"35787\">file; a menu dashboard will appear, as shown in</st> *<st c=\"35836\">Figure 11</st>**<st c=\"35845\">.10</st>*<st c=\"35848\">.</st>3.  <st c=\"35849\">Click the</st> **<st c=\"35860\">Desktop Development with C++</st>** <st c=\"35888\">menu option to show the installation details on the right-hand side of</st> <st c=\"35960\">the dashboard:</st>\n\n\t\t\t![Figure 11.10 – Microsoft Visual Studio Library dashboard](img/B19383_11_010.jpg)\n\n\t\t\t<st c=\"37920\">Figure 11.10 – Microsoft Visual Studio Library dashboard</st>\n\t\t\t<st c=\"37976\">This</st> <st c=\"37982\">installation</st> <st c=\"37995\">is different from the previous Microsoft Visual C++ Redistributable</st> <st c=\"38063\">installation procedure.</st>\n\n\t\t\t\t1.  <st c=\"38086\">Now, select</st> `<st c=\"38322\">mod_wsgi</st>` <st c=\"38330\">installation.</st>\n\t\t\t\t2.  <st c=\"38344\">After choosing the necessary components, click the</st> **<st c=\"38396\">Install</st>** <st c=\"38403\">button at the bottom right of</st> <st c=\"38434\">the dashboard.</st>\n\t\t\t\t3.  <st c=\"38448\">After installing</st> `<st c=\"38497\">pip install mod_wsgi</st>` <st c=\"38517\">once more.</st> <st c=\"38529\">This time, the</st> `<st c=\"38544\">mod_wsgi</st>` <st c=\"38552\">installation must</st> <st c=\"38571\">proceed successfully.</st>\n\t\t\t\t4.  <st c=\"38592\">The</st> `<st c=\"38597\">mod_wsgi</st>` <st c=\"38605\">module needs a configuration file inside the project that the Apache HTTP Server needs to load during startup.</st> <st c=\"38717\">This file should be in a separate folder, say</st> `<st c=\"38763\">wsgi</st>`<st c=\"38767\">, and must be in the main project folder.</st> <st c=\"38809\">In our</st> `<st c=\"38816\">ch11-apache</st>` <st c=\"38827\">project, the configuration file is</st> `<st c=\"38863\">conf.wsgi</st>` <st c=\"38872\">and has been placed in the</st> `<st c=\"38900\">wsgi</st>` <st c=\"38904\">folder.</st> <st c=\"38913\">Be sure to add the</st> `<st c=\"38932\">__init__.py</st>` <st c=\"38943\">file to this folder too.</st> <st c=\"38969\">The following is the content</st> <st c=\"38998\">of</st> `<st c=\"39001\">conf.wsgi</st>`<st c=\"39010\">:</st>\n\n    ```", "```py\n\n    \t\t\t\t5.  <st c=\"39303\">Run the</st> `<st c=\"39312\">mod_wsgi-express module-config</st>` <st c=\"39342\">command to generate the</st> `<st c=\"39367\">LoadModule</st>` <st c=\"39377\">configuration statements that the Apache HTTP Server needs to integrate</st> <st c=\"39450\">with the project</st> <st c=\"39467\">directory.</st> <st c=\"39478\">The following are the</st> `<st c=\"39500\">LoadModule</st>` <st c=\"39510\">snippets that have been generated for our</st> *<st c=\"39553\">Online</st>* *<st c=\"39560\">Grocery</st>* <st c=\"39567\">application:</st>\n\n    ```", "```py\n\n    \t\t\t\t6.  <st c=\"39880\">Place these</st> `<st c=\"39893\">LoadModule</st>` <st c=\"39903\">configuration statements in the Apache HTTP Server’s</st> `<st c=\"39957\">/conf/http.conf</st>` <st c=\"39972\">file, specifically anywhere in the</st> `<st c=\"40008\">LoadModule</st>` <st c=\"40018\">area under the</st> **<st c=\"40034\">Dynamic Shared Object (DSO)</st>** **<st c=\"40062\">Support</st>** <st c=\"40069\">segment.</st>\n\t\t\t\t7.  <st c=\"40078\">At the end of the</st> `<st c=\"40097\">/conf/http.conf</st>` <st c=\"40112\">file, import the custom</st> `<st c=\"40137\">VirtualHost</st>` <st c=\"40149\">configuration file of the project.</st> <st c=\"40184\">The following is a sample import statement for our</st> *<st c=\"40235\">Online</st>* *<st c=\"40242\">Grocery</st>* <st c=\"40249\">application:</st>\n\n    ```", "```py\n     <VirtualHost *:<st c=\"40455\">8080</st>> <st c=\"40463\">ServerName localhost</st> WSGIScriptAlias / C<st c=\"40503\">:/Alibata/Training/Source/ flask/mastering/ch11-apache/wsgi/conf.wsgi</st> <Directory C:/Alibata/Training/Source/ flask/mastering/ch11-apache> <st c=\"40642\">Require all granted</st> </Directory>\n    </VirtualHost>\n    ```", "```py\n\n    \t\t\t\t8.  <st c=\"41016\">Now, open a terminal and run or restart the server through</st> `<st c=\"41076\">httpd.exe</st>`<st c=\"41085\">. Access all the APIs using</st> `<st c=\"41113\">pytest</st>` <st c=\"41119\">or</st> <st c=\"41123\">API clients.</st>\n\n\t\t\t<st c=\"41135\">Choosing the Apache HTTP Server as the production server is a common approach in many deployment plans for Flask projects involving the standalone server platform.</st> <st c=\"41300\">Although the deployment process is tricky and lengthy, the server’s fast and stable performance, once configured and managed well, makes it a better choice for setting up a significantly effective production environment for</st> <st c=\"41524\">Flask applications.</st>\n\t\t\t<st c=\"41543\">There is another way of deploying Flask applications that involves fewer tweaks and configurations</st> <st c=\"41643\">but provides an enterprise-grade production setup:</st> **<st c=\"41694\">the containerized deployment approach</st>**<st c=\"41731\">. Let’s discuss how to deploy the application to</st> *<st c=\"41780\">Docker</st>* <st c=\"41787\">containers.</st>\n\t\t\t<st c=\"41798\">Deploying the application on Docker</st>\n\t\t\t**<st c=\"41834\">Docker</st>** <st c=\"41841\">is a</st> <st c=\"41847\">powerful tool for deploying and running applications using software</st> <st c=\"41915\">units instead of hardware setups.</st> <st c=\"41949\">Each</st> <st c=\"41954\">independent, lightweight, standalone, and executable</st> <st c=\"42007\">unit, called a</st> **<st c=\"42022\">container</st>**<st c=\"42031\">, must contain all the files of the applications that it needs to run.</st> <st c=\"42102\">Docker is the core container engine that manages all the containers</st> <st c=\"42170\">and packages applications in their appropriate containers.</st> <st c=\"42229\">To download Docker, download the</st> **<st c=\"42262\">Docker Desktop</st>** <st c=\"42276\">installer that’s appropriate for your system from</st> [<st c=\"42327\">https://docs.docker.com/engine/install/</st>](https://docs.docker.com/engine/install/)<st c=\"42366\">. Be sure to enable the Window’s</st> **<st c=\"42399\">Hyper-V service</st>** <st c=\"42414\">before</st> <st c=\"42422\">installing Docker.</st> <st c=\"42441\">Use your Docker credentials to log in to the application.</st> *<st c=\"42499\">Figure 11</st>**<st c=\"42508\">.11</st>* <st c=\"42511\">shows a sample account dashboard of the Docker</st> <st c=\"42559\">Desktop application:</st>\n\t\t\t![Figure 11.11 – A Desktop Docker profile](img/B19383_11_011.jpg)\n\n\t\t\t<st c=\"43320\">Figure 11.11 – A Desktop Docker profile</st>\n\t\t\t<st c=\"43359\">Docker requires some rules when deploying applications to its containers.</st> <st c=\"43434\">The first requirement is to create a Dockerfile inside the project’s</st> *<st c=\"43503\">main</st>* <st c=\"43507\">directory, on the same level as the</st> `<st c=\"43544\">main.py</st>` <st c=\"43551\">and</st> `<st c=\"43556\">.toml</st>` <st c=\"43561\">configuration files.</st> <st c=\"43583\">The following is the content of the</st> `<st c=\"43619\">ch11-asgi</st>` <st c=\"43628\">file’s Dockerfile:</st>\n\n```", "```py\n\n\t\t\t<st c=\"43984\">A</st> **<st c=\"43987\">Dockerfile</st>** <st c=\"43997\">contains a</st> <st c=\"44009\">series of instructions made by Docker commands that the engine will use to assemble an image.</st> <st c=\"44103\">A</st> **<st c=\"44105\">Docker image</st>** <st c=\"44117\">is a software</st> <st c=\"44132\">template containing the needed project files, folders, Python modules, server details, and commands to start the Flask server.</st> <st c=\"44259\">Docker will run the image to generate a running image instance called</st> <st c=\"44329\">a container.</st>\n\t\t\t<st c=\"44341\">The first</st> <st c=\"44352\">line of our Dockerfile is the</st> `<st c=\"44382\">FROM</st>` <st c=\"44386\">instruction, which</st> <st c=\"44406\">creates a stage or a copy of the base image from the Docker repository.</st> <st c=\"44478\">Here are the guidelines to follow when choosing the</st> <st c=\"44530\">base image:</st>\n\n\t\t\t\t*   <st c=\"44541\">Ensure it is complete with libraries, tools, filesystem structure, and network structures so that the container will</st> <st c=\"44659\">be stable.</st>\n\t\t\t\t*   <st c=\"44669\">Ensure it can be updated in terms of operating system plugins</st> <st c=\"44732\">and libraries.</st>\n\t\t\t\t*   <st c=\"44746\">Ensure it’s equipped with up-to-date and stable Python compilers and</st> <st c=\"44816\">core libraries.</st>\n\t\t\t\t*   <st c=\"44831\">Ensure it’s loaded with extensions and additional plugins for additional</st> <st c=\"44905\">complex integrations.</st>\n\t\t\t\t*   <st c=\"44926\">Ensure it has a smaller</st> <st c=\"44951\">file size.</st>\n\n\t\t\t<st c=\"44961\">Choosing the right base image is crucial for the application to avoid problems during</st> <st c=\"45048\">production phases.</st>\n\t\t\t<st c=\"45066\">The next instruction is the</st> `<st c=\"45095\">WORKDIR</st>` <st c=\"45102\">command, which creates and sets the new application’s working directory.</st> <st c=\"45176\">The first</st> `<st c=\"45186\">RUN</st>` <st c=\"45189\">command updates the container’s</st> `<st c=\"45222\">pip</st>` <st c=\"45225\">command, which will install all the libraries from the</st> `<st c=\"45281\">requirements.txt</st>` <st c=\"45297\">file copied by the</st> `<st c=\"45317\">COPY</st>` <st c=\"45321\">command from our local project folder.</st> <st c=\"45361\">After installing the modules in the container, the next instruction is to</st> `<st c=\"45435\">COPY</st>` <st c=\"45439\">all the project files from the local folder to</st> <st c=\"45487\">the container.</st>\n\t\t\t<st c=\"45501\">The</st> `<st c=\"45506\">EXPOSE</st>` <st c=\"45512\">command defines the port the application will listen on.</st> <st c=\"45570\">The</st> `<st c=\"45574\">CMD</st>` <st c=\"45578\">command, on the other hand, tells Docker how to start the Gunicorn server with</st> `<st c=\"45657\">UvicornWorker</st>` <st c=\"45670\">when the</st> <st c=\"45680\">container starts.</st>\n\t\t\t<st c=\"45697\">After composing the Dockerfile, open a terminal to run the</st> `<st c=\"45757\">docker login</st>` <st c=\"45769\">CLI command</st> <st c=\"45782\">and input your credentials.</st> <st c=\"45810\">The</st> `<st c=\"45814\">docker login</st>` <st c=\"45826\">command enables access to your Docker repository using other Docker’s</st> <st c=\"45897\">CLI commands, such as</st> `<st c=\"45919\">docker run</st>` <st c=\"45929\">to execute the instructions from the Dockerfile.</st> <st c=\"45979\">By the way, aside from our Flask[async] application, there is a need to pull an image to generate a container for the PostgreSQL database of our application.</st> <st c=\"46137\">Conventionally, to connect these containers, such as our PostgreSQL and Redis containers, to the Python container with the Flask application, Docker networking, through running the</st> `<st c=\"46318\">docker network</st>` <st c=\"46332\">command, creates the network connections that will link these containers to establish the needed connectivity.</st> <st c=\"46444\">But this becomes complex if there are more containers to attach.</st> <st c=\"46509\">As a replacement to save time and effort,</st> *<st c=\"46551\">Docker Compose</st>* <st c=\"46565\">can establish all these step-by-step networking procedures by only running the</st> `<st c=\"46645\">docker-compose</st>` <st c=\"46659\">command.</st> <st c=\"46669\">There is no need to install Docker Compose since it is part of the bundle that’s installed by the Docker Desktop installer.</st> <st c=\"46793\">Docker Compose uses Docker Engine, so installing the engine also includes Compose.</st> <st c=\"46876\">To start Docker Compose, just run</st> `<st c=\"46910\">docker login</st>` <st c=\"46922\">and enter a valid</st> <st c=\"46941\">Docker account.</st>\n\t\t\t<st c=\"46956\">Using Docker Compose</st>\n\t\t\t`<st c=\"47177\">docker-compose.yaml</st>`<st c=\"47196\">. The following is the configuration file that’s used by our</st> `<st c=\"47257\">ch11-asgi-deployment</st>` <st c=\"47277\">project:</st>\n\n```", "```py\n POSTGRES_USER=postgres\nPOSTGRES_PASSWORD=admin2255\nPOSTGRES_DB=ogs\n```", "```py\n docker cp ogs.sql ch11-asgi-deployment-postgres-1:/docker-entrypoint-initdb.d/ogs.sql\n```", "```py\n docker exec -it ch11-asgi-deployment-postgres-1 psql -U postgres -d ogs -f docker-entrypoint-initdb.d/ogs.sql\n```", "```py\n docker exec -it ch11-asgi-deployment-postgres-1 psql -U postgres\n```", "```py\n from peewee_async import PooledPostgresqlDatabase\ndatabase = PooledPostgresqlDatabase(\n        'ogs',\n        user='postgres',\n        password='admin2255', <st c=\"55715\">host='ch11-asgi-deployment-postgres-1',</st><st c=\"55754\">port='5432',</st> max_connections = 3,\n        connect_timeout = 3\n    )\n```", "```py\n<st c=\"59738\">apiVersion: v1</st>\n<st c=\"59753\">kind: Secret</st>\n<st c=\"59766\">metadata:</st><st c=\"59776\">name: postgres-credentials</st> data:\n  # replace this with your base4-encoded username\n  user: cG9zdGdyZXM=\n  # replace this with your base4-encoded password\n  password: YWRtaW4yMjU1\n```", "```py\n<st c=\"60690\">apiVersion: v1</st>\n<st c=\"60705\">kind: PersistentVolume</st>\n<st c=\"60728\">metadata:</st><st c=\"60738\">name: postgres-pv-volume</st> labels:\n      type: local <st c=\"60784\">spec:</st><st c=\"60789\">storageClassName: manual</st> capacity:\n      storage: 5Gi\n   accessModes:\n       - ReadWriteOnce\n   hostPath:\n      path: \"/mnt/data\"\n```", "```py\n<st c=\"61238\">kind: PersistentVolumeClaim</st>\n<st c=\"61266\">apiVersion: v1</st>\n<st c=\"61281\">metadata:</st><st c=\"61291\">name: postgresql-db-claim</st>\n<st c=\"61317\">spec:</st> accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n```", "```py\n<st c=\"62436\">apiVersion: apps/v1</st>\n<st c=\"62456\">kind: Deployment</st>\n<st c=\"62541\">v1</st> or <st c=\"62547\">apps/v1</st> is the proper choice for the <st c=\"62584\">apiVersion</st> metadata. The <st c=\"62609\">kub-postgresql-deployment.yaml</st> file is a <st c=\"62650\">Deployment</st> type of Kubernetes document, as indicated in the <st c=\"62710\">kind</st> metadata, which will generate a container named <st c=\"62763\">ch11-postgresql</st>:\n\n```", "```py\n\n\t\t\t<st c=\"63074\">From the</st> <st c=\"63084\">overall state indicated</st> <st c=\"63108\">in the</st> `<st c=\"63115\">spec</st>` <st c=\"63119\">metadata, the deployment will create</st> *<st c=\"63157\">1 replica</st>* <st c=\"63166\">in a Kubernetes pod, with</st> `<st c=\"63193\">ch11-postgresql</st>` <st c=\"63208\">as its label, to run the PostgreSQL server.</st> <st c=\"63253\">Moreover, the deployment will pull the</st> `<st c=\"63292\">bitnami/postgresql:latest</st>` <st c=\"63317\">image to create the PostgreSQL container, bearing the</st> `<st c=\"63372\">ch11-postgresql</st>` <st c=\"63387\">label also.</st> <st c=\"63400\">The configuration also includes a</st> `<st c=\"63434\">terminationGracePeriodSeconds</st>` <st c=\"63463\">value of</st> `<st c=\"63473\">180</st>` <st c=\"63476\">to shut down the database</st> <st c=\"63503\">server safely:</st>\n\n```", "```py\n\n\t\t\t<st c=\"63783\">The</st> `<st c=\"63788\">env</st>` <st c=\"63791\">or environment variables portion provides the database credentials,</st> `<st c=\"63860\">POSTGRES_USER</st>` <st c=\"63873\">and</st> `<st c=\"63878\">POSTGRES_DB</st>`<st c=\"63889\">, to the database, which are base64-encoded values</st> <st c=\"63940\">from the previously created</st> `<st c=\"63968\">Secret</st>` <st c=\"63974\">object,</st> `<st c=\"63983\">postgres-credentials</st>`<st c=\"64003\">. Note that this deployment will also</st> <st c=\"64041\">auto-generate the database with the</st> <st c=\"64077\">name</st> `<st c=\"64082\">ogs</st>`<st c=\"64085\">:</st>\n\n```", "```py\n\n\t\t\t<st c=\"64340\">The deployment will also allow us to save all data files in the</st> `<st c=\"64405\">/var/lib/postgresql/data</st>` <st c=\"64429\">file of the generated container in the</st> `<st c=\"64469\">ch11-postgresql</st>` <st c=\"64484\">pod, as indicated in the</st> `<st c=\"64510\">volumeMounts</st>` <st c=\"64522\">metadata.</st> <st c=\"64533\">Specifying the</st> `<st c=\"64548\">volumeMounts</st>` <st c=\"64560\">metadata avoids data loss when the database shuts down and makes the database and tables accessible across the network.</st> <st c=\"64681\">The pod will access the volume storage created by the</st> `<st c=\"64735\">postgres-pv-volume</st>` <st c=\"64753\">and</st> `<st c=\"64758\">postgresql-db-claim</st>` <st c=\"64777\">objects.</st>\n\t\t\t<st c=\"64786\">Aside from the</st> `<st c=\"64802\">Deployment</st>` <st c=\"64812\">object, this document defines a</st> `<st c=\"64845\">Service</st>` <st c=\"64852\">type that will expose our PostgreSQL container to other Pods within the cluster at port</st> `<st c=\"64941\">5432</st>` <st c=\"64945\">through</st> <st c=\"64954\">a</st> *<st c=\"64956\">ClusterIP</st>*<st c=\"64965\">:</st>\n\n```", "```py\n\n\t\t\t<st c=\"65127\">The</st> `<st c=\"65132\">---</st>` <st c=\"65135\">symbol is a valid separator syntax separating the</st> `<st c=\"65186\">Deployment</st>` <st c=\"65196\">and</st> `<st c=\"65201\">Service</st>` <st c=\"65208\">definitions.</st>\n\t\t\t<st c=\"65221\">Our last</st> <st c=\"65231\">deployment file,</st> `<st c=\"65248\">kub-app-deployment.yaml</st>`<st c=\"65271\">, pulls the</st> `<st c=\"65283\">ch11-asgi</st>` <st c=\"65292\">Docker image and assigns the generated</st> <st c=\"65332\">container to</st> <st c=\"65345\">the Pods:</st>\n\n```", "```py\n\n\t\t\t<st c=\"65439\">The</st> `<st c=\"65444\">apiVersion</st>` <st c=\"65454\">field of our deployment configuration file is</st> `<st c=\"65501\">v1</st>`<st c=\"65503\">, an appropriate Kubernetes version for deployment.</st> <st c=\"65555\">In this case, our container will be labeled</st> `<st c=\"65599\">ch11-app</st>`<st c=\"65607\">, as indicated in the</st> `<st c=\"65629\">metadata/name</st>` <st c=\"65642\">configuration:</st>\n\n```", "```py\n\n\t\t\t<st c=\"65712\">The</st> `<st c=\"65717\">spec</st>` <st c=\"65721\">field</st> <st c=\"65728\">describes the overall</st> <st c=\"65750\">state of the deployment, starting with the number of</st> `<st c=\"65803\">replicas</st>` <st c=\"65811\">the deployment will create, how many</st> `<st c=\"65849\">containers</st>` <st c=\"65859\">the Pods will run, the environment variables – namely</st> `<st c=\"65914\">username</st>`<st c=\"65922\">,</st> `<st c=\"65924\">password</st>`<st c=\"65932\">, and</st> `<st c=\"65938\">SERVICE_POSTGRES_SERVICE_HOST</st>` <st c=\"65967\">– that</st> `<st c=\"65975\">ch11-app</st>` <st c=\"65983\">will use to connect to the PostgreSQL container, and the</st> `<st c=\"66041\">containerPort</st>` <st c=\"66054\">variable the container will</st> <st c=\"66083\">listen to:</st>\n\n```", "```py\n\n\t\t\t<st c=\"66509\">Also</st> <st c=\"66515\">included in the YAML file</st> <st c=\"66541\">is the</st> `<st c=\"66548\">Service</st>` <st c=\"66555\">type that will make the application to</st> <st c=\"66595\">the users:</st>\n\n```", "```py\n\n\t\t\t<st c=\"66771\">The definition links the</st> `<st c=\"66797\">postgres-credentials</st>` <st c=\"66817\">object to the pod’s environment variables that refer to the</st> <st c=\"66878\">database credentials.</st> <st c=\"66900\">It also defines a</st> *<st c=\"66918\">LoadBalancer</st>* `<st c=\"66931\">Service</st>` <st c=\"66938\">to expose our containerized Flask[async] to the HTTP client at</st> <st c=\"67002\">port</st> `<st c=\"67007\">8000</st>`<st c=\"67011\">.</st>\n\t\t\t<st c=\"67012\">To apply</st> <st c=\"67022\">these configuration files, Kubernetes has a</st> `<st c=\"67066\">kubectl</st>` <st c=\"67073\">client command to communicate with Kubernetes</st> <st c=\"67120\">and run its APIs defined in the manifest files.</st> <st c=\"67168\">Here is the order of applying the given</st> <st c=\"67208\">YAML files:</st>\n\n\t\t\t\t1.  `<st c=\"67219\">kubectl apply -</st>``<st c=\"67235\">f kub-secrets.yaml</st>`<st c=\"67254\">.</st>\n\t\t\t\t2.  `<st c=\"67255\">kubectl apply -</st>``<st c=\"67271\">f kub-postgresql-pv.yaml</st>`<st c=\"67296\">.</st>\n\t\t\t\t3.  `<st c=\"67297\">kubectl apply -</st>``<st c=\"67313\">f kub-postgresql-pvc.yaml</st>`<st c=\"67339\">.</st>\n\t\t\t\t4.  `<st c=\"67340\">kubectl apply -</st>``<st c=\"67356\">f kub-postgresql-deployment.yaml</st>`<st c=\"67389\">.</st>\n\t\t\t\t5.  `<st c=\"67390\">kubectl apply -</st>``<st c=\"67406\">f kub-app-deployment</st>`<st c=\"67427\">.</st>\n\n\t\t\t<st c=\"67428\">To learn about the status and instances that run the applications, run</st> `<st c=\"67500\">kubectl get pods</st>`<st c=\"67516\">. To view the Services that have been created, run</st> `<st c=\"67567\">kubectl get services</st>`<st c=\"67587\">.</st> *<st c=\"67589\">Figure 11</st>**<st c=\"67598\">.17</st>* <st c=\"67601\">shows the list of Services after applying all our</st> <st c=\"67652\">deployment files:</st>\n\t\t\t![Figure 11.17 – Listing all Kubernetes Services with their details](img/B19383_11_017.jpg)\n\n\t\t\t<st c=\"67994\">Figure 11.17 – Listing all Kubernetes Services with their details</st>\n\t\t\t<st c=\"68059\">To learn all the details about the Services and Pods that have been deployed and the status of each pod, run</st> `<st c=\"68169\">kubectl get all</st>`<st c=\"68184\">. The result will be similar to what’s shown in</st> *<st c=\"68232\">Figure 11</st>**<st c=\"68241\">.18</st>*<st c=\"68244\">:</st>\n\t\t\t![Figure 11.18 – Listing all the Kubernetes cluster details](img/B19383_11_018.jpg)\n\n\t\t\t<st c=\"68901\">Figure 11.18 – Listing all the Kubernetes cluster details</st>\n\t\t\t<st c=\"68958\">All the</st> <st c=\"68967\">Pods and the containerized</st> <st c=\"68994\">applications can be viewed on Docker Desktop, as shown in</st> *<st c=\"69052\">Figure 11</st>**<st c=\"69061\">.19</st>*<st c=\"69064\">:</st>\n\t\t\t![Figure 11.19 – Docker Desktop view of all Pods and applications](img/B19383_11_019.jpg)\n\n\t\t\t<st c=\"69586\">Figure 11.19 – Docker Desktop view of all Pods and applications</st>\n\t\t\t<st c=\"69649\">Before accessing the</st> `<st c=\"69671\">ch11-asgi</st>` <st c=\"69680\">container, populate the empty PostgreSQL database with the</st> `<st c=\"69740\">.sql</st>` <st c=\"69744\">dump file from the local database.</st> <st c=\"69780\">Use the</st> `<st c=\"69788\">Pod</st>` <st c=\"69791\">name (for example,</st> `<st c=\"69811\">ch11-postgresql-b7fc578f4-6g4nc</st>`<st c=\"69842\">) of the deployed PostgreSQL container and copy the</st> `<st c=\"69895\">.sql</st>` <st c=\"69899\">file to the</st> `<st c=\"69912\">/temp</st>` <st c=\"69917\">directory of the container (for example,</st> `<st c=\"69959\">ch11-postgresql-b7fc578f4-6g4nc:/temp/ogs.sql</st>`<st c=\"70004\">) using the</st> `<st c=\"70017\">kubectl cp</st>` <st c=\"70027\">command and the pod.</st> <st c=\"70049\">Be sure to run the command in the location of the</st> `<st c=\"70099\">.</st>``<st c=\"70100\">sql</st>` <st c=\"70104\">file:</st>\n\n```", "```py\n\n\t\t\t<st c=\"70174\">Run the</st> `<st c=\"70183\">.sql</st>` <st c=\"70187\">file in the</st> `<st c=\"70200\">/temp</st>` <st c=\"70205\">folder of the container using the</st> `<st c=\"70240\">kubectl exec</st>` <st c=\"70252\">command and</st> <st c=\"70265\">the pod:</st>\n\n```", "```py\n\n\t\t\t<st c=\"70365\">Also, replace the</st> `<st c=\"70384\">user</st>`<st c=\"70388\">,</st> `<st c=\"70390\">password</st>`<st c=\"70398\">,</st> `<st c=\"70400\">port</st>`<st c=\"70404\">, and</st> `<st c=\"70410\">host</st>` <st c=\"70414\">parameters of</st> <st c=\"70429\">Peewee’s</st> `<st c=\"70438\">Pooled</st>` **<st c=\"70444\">PostgresqlDatabase</st>** <st c=\"70463\">with the environment variables declared in the</st> `<st c=\"70511\">kub-app-deployment.yaml</st>` <st c=\"70534\">file.</st> <st c=\"70541\">The following snippet shows the changes in the driver</st> <st c=\"70595\">class configuration found</st> <st c=\"70621\">in the</st> `<st c=\"70628\">app/models/config</st>` <st c=\"70645\">module:</st>\n\n```", "```py\n\n\t\t\t<st c=\"70953\">After migrating the tables and the data, the client application can now access the API endpoints of our</st> *<st c=\"71058\">Online Grocery</st>* <st c=\"71072\">application (</st>`<st c=\"71086\">ch11-asgi</st>`<st c=\"71096\">).</st>\n\t\t\t<st c=\"71099\">A Kubernetes pod undergoes</st> `<st c=\"71434\">CrashLoopBackOff</st>` <st c=\"71450\">and stay in</st> **<st c=\"71463\">Awaiting</st>** <st c=\"71471\">mode.</st> <st c=\"71478\">To avoid Pods crashing, always carefully review the definitions files before applying them and monitor the logs of running Pods from time</st> <st c=\"71616\">to time.</st>\n\t\t\t<st c=\"71624\">Sometimes, a Docker or Kubernetes deployment requires adding a reverse proxy server to manage all the incoming requests of the deployed applications.</st> <st c=\"71775\">In the next section, we’ll add the</st> *<st c=\"71810\">NGINX</st>* <st c=\"71815\">gateway server to our containerized</st> `<st c=\"71852\">ch11-asgi</st>` <st c=\"71861\">application.</st>\n\t\t\t<st c=\"71874\">Creating an API gateway using NGINX</st>\n\t\t\t<st c=\"71910\">Our deployment needs</st> `<st c=\"72284\">ch11-asgi</st>` <st c=\"72293\">app and PostgreSQL database platform.</st> <st c=\"72332\">It will serve as the facade of the Gunicorn server running</st> <st c=\"72391\">our application.</st>\n\t\t\t<st c=\"72407\">Here,</st> `<st c=\"72414\">ch11-asgi-dep-nginx</st>` <st c=\"72433\">is a Docker Compose folder consisting of the</st> `<st c=\"72479\">ch11-asgi</st>` <st c=\"72488\">project directory, which contains a Dockerfile, the</st> `<st c=\"72541\">docker-compose.yaml</st>` <st c=\"72560\">file, and the</st> `<st c=\"72575\">nginx</st>` <st c=\"72580\">folder containing a Dockerfile and our NGINX configuration settings.</st> <st c=\"72650\">The following is the</st> `<st c=\"72671\">nginx.conf</st>` <st c=\"72681\">file that’s used by Compose to set up our</st> <st c=\"72724\">NGINX server:</st>\n\n```", "```py\n\n\t\t\t<st c=\"73035\">The NGINX configuration depends on its installation setup, the applications that have been deployed to the servers, and the server architecture.</st> <st c=\"73181\">Ours is for a reverse proxy NGINX</st> <st c=\"73215\">server of our application deployed on a single server.</st> <st c=\"73270\">NGINX</st> <st c=\"73276\">will allow access to our application through</st> `<st c=\"73321\">localhost</st>` <st c=\"73330\">and port</st> `<st c=\"73340\">80</st>` <st c=\"73342\">instead of</st> `<st c=\"73354\">http://ch11-asgi-dep-nginx-api-1:8000</st>`<st c=\"73391\">, as indicated in</st> `<st c=\"73409\">proxy_pass</st>`<st c=\"73419\">. Since we don’t have a new domain name,</st> `<st c=\"73460\">localhost</st>` <st c=\"73469\">will be the proxy’s hostname.</st> <st c=\"73500\">The de facto request headers, such as</st> `<st c=\"73538\">X-Forwarded-Host</st>`<st c=\"73554\">,</st> `<st c=\"73556\">X-Forwarded-Proto</st>`<st c=\"73573\">,</st> `<st c=\"73575\">X-Forwarded-Host</st>`<st c=\"73591\">, and</st> `<st c=\"73597\">X-Forwarded-Prefix</st>`<st c=\"73615\">, will collectively help the load balancing mechanism during NGINX’s interference on</st> <st c=\"73700\">a request.</st>\n\t\t\t<st c=\"73710\">When the</st> `<st c=\"73720\">docker-compose</st>` <st c=\"73734\">command runs the YAML file, NGINX’s Dockerfile will pull the latest</st> `<st c=\"73803\">nginx</st>` <st c=\"73808\">image and copy the given</st> `<st c=\"73834\">nginx.conf</st>` <st c=\"73844\">settings to the</st> `<st c=\"73861\">/etc/nginx/conf.d/</st>` <st c=\"73879\">directory of its container.</st> <st c=\"73908\">Then, it will instruct the container to run the NGINX server using the</st> `<st c=\"73979\">nginx -g daemon</st>` `<st c=\"73995\">off</st>` <st c=\"73998\">command.</st>\n\t\t\t<st c=\"74007\">Adding NGINX makes the deployed application manageable, scalable, and maintainable.</st> <st c=\"74092\">It can also centralize user request traffic in a microservice architecture, ensuring that the access reaches the expected API endpoints, containers,</st> <st c=\"74241\">or sub-modules.</st>\n\t\t\t<st c=\"74256\">Summary</st>\n\t\t\t<st c=\"74264\">There are several solutions and approaches to migrating a Flask application from the development to the production stage.</st> <st c=\"74387\">The most common server that’s used to run Flask’s WSGI applications in production is Gunicorn.</st> <st c=\"74482\">uWSGI, on the other hand, can run WSGI applications in more complex and refined settings.</st> <st c=\"74572\">Flask[async] applications can run on Uvicorn workers with a</st> <st c=\"74632\">Gunicorn server.</st>\n\t\t\t<st c=\"74648\">For external server-based deployment, the Apache HTTP Server with Python provides a stable and reliable container for running Flask applications with the support of Python’s</st> `<st c=\"74823\">mod_wsgi</st>` <st c=\"74831\">module.</st>\n\t\t\t<st c=\"74839\">Flask applications can also run on containers through Docker and Docker Compose to avoid the nitty gritty configuration and installations in the Apache HTTP Server.</st> <st c=\"75005\">In Dockerization, what matters is the Dockerfile for a single deployment or the</st> `<st c=\"75085\">docker-compose.yaml</st>` <st c=\"75104\">file for multiple deployments and the combinations of Docker instructions that will contain these configuration files.</st> <st c=\"75224\">For a more distributed, flexible, and complex orchestration, Kubernetes’s Pods and Services can aid a better deployment scheme for</st> <st c=\"75355\">multiple deployments.</st>\n\t\t\t<st c=\"75376\">To manage incoming requests across the servers, the Gunicorn servers running in containers can work with NGINX for reverse proxy, load balancing, and additional HTTP security protocols.</st> <st c=\"75563\">A good NGINX setting can provide a better facade for the entire</st> <st c=\"75627\">production setup.</st>\n\t\t\t<st c=\"75644\">Generally, the deployment procedures that were created, applied, and utilized in this chapter are translatable, workable, and reversible to other more modern and advanced approaches, such as deploying Flask applications to Google Cloud and AWS cloud services.</st> <st c=\"75905\">Apart from deployment, Flask has the edge to compete with other frameworks when dealing with innovation and building</st> <st c=\"76022\">enterprise-grade solutions.</st>\n\t\t\t<st c=\"76049\">In the next chapter, we will showcase the use of the Flask platform in providing middleware solutions to many</st> <st c=\"76160\">popular integrations.</st>\n\n```", "```py\n\n```", "```py\n\n```", "```py\n\n```"]