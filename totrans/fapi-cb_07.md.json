["```py\n$ pip install –r requirements.txt\n```", "```py\n$ pip install motor\n```", "```py\n    from motor.motor_asyncio import AsyncIOMotorClient\n    mongo_client = AsyncIOMotorClient(\n        \"mongodb://localhost:27017\"\n    )\n    ```", "```py\n    import logging\n    logger = logging.getLogger(\"uvicorn.error\")\n    ```", "```py\n    async def ping_mongo_db_server():\n        try:\n            await mongo_client.admin.command(\"ping\")\n            logger.info(\"Connected to MongoDB\")\n        except Exception as e:\n            logger.error(\n                f\"Error connecting to MongoDB: {e}\"\n            )\n            raise e\n    ```", "```py\n    from contextlib import asynccontextmanager\n    from app.db_connection import (\n        ping_mongo_db_server,\n    )\n    @asynccontextmanager\n    async def lifespan(app: FastAPI):\n        await ping_mongo_db_server(),\n        yield\n    ```", "```py\n    from fastapi import FastAPI\n    app = FastAPI(lifespan=lifespan)\n    ```", "```py\n$ uvicorn app.main:app\n```", "```py\nINFO:    Started server process [1364]\nINFO:    Waiting for application startup.\nINFO:    Connected to MongoDB\nINFO:    Application startup complete.\n```", "```py\nfrom app.db_connection import mongo_client\ndatabase = mongo_client.beat_streaming\n```", "```py\ndef mongo_database():\n    return database\n```", "```py\n    from bson import ObjectId\n    from fastapi import Body, Depends\n    from app.database import mongo_database\n    from fastapi.encoders import ENCODERS_BY_TYPE\n    ENCODERS_BY_TYPE[ObjectId] = str\n    @app.post(\"/song\")\n    async def add_song(\n        song: dict = Body(\n            example={\n                \"title\": \"My Song\",\n                \"artist\": \"My Artist\",\n                \"genre\": \"My Genre\",\n            },\n        ),\n        mongo_db=Depends(mongo_database),\n    ):\n        await mongo_db.songs.insert_one(song)\n        return {\n            \"message\": \"Song added successfully\",\n            \"id\": song[\"_id\"],\n        }\n    ```", "```py\n    @app.get(\"/song/{song_id}\")\n    async def get_song(\n        song_id: str,\n        db=Depends(mongo_database),\n    ):\n        song = await db.songs.find_one(\n            {\n                \"_id\": ObjectId(song_id)\n                if ObjectId.is_valid(song_id)\n                else None\n            }\n        )\n        if not song:\n            raise HTTPException(\n                status_code=404,\n                detail=\"Song not found\"\n            )\n        return song\n    ```", "```py\n    @app.put(\"/song/{song_id}\")\n    async def update_song(\n        song_id: str,\n        updated_song: dict,\n        db=Depends(mongo_database),\n    ):\n        result = await db.songs.update_one(\n            {\n                \"_id\": ObjectId(song_id)\n                if ObjectId.is_valid(song_id)\n                else None\n            },\n            {\"$set\": updated_song},\n        )\n        if result.modified_count == 1:\n          return {\n              \"message\": \"Song updated successfully\"\n          }\n        raise HTTPException(\n            status_code=404, detail=\"Song not found\"\n        )\n    ```", "```py\n    @app.delete(\"/song/{song_id}\")\n    async def delete_song(\n        song_id: str,\n        db=Depends(mongo_database),\n    ):\n        result = await db.songs.delete_one(\n            {\n                \"_id\": ObjectId(song_id)\n                if ObjectId.is_valid(song_id)\n                else None\n            }\n        )\n        if result.deleted_count == 1:\n            return {\n                \"message\": \"Song deleted successfully\"\n            }\n        raise HTTPException(\n            status_code=404, detail=\"Song not found\"\n        )\n    ```", "```py\n$ python fill_mongo_db_database.py\n```", "```py\n{\n    \"title\": \"Title of the Song\",\n    \"artist\": \"Singer Name\",\n    \"genre\": \"Music genre\",\n    \"album\": {\n        \"title\": \"Album Title\",\n        \"release_year\": 2017,\n    },\n}\n```", "```py\n    class Playlist(BaseModel):\n        name: str\n        songs: list[str] = []\n    @app.post(\"/playlist\")\n    async def create_playlist(\n        playlist: Playlist = Body(\n            example={\n                \"name\": \"My Playlist\",\n                \"songs\": [\"song_id\"],\n            }\n        ),\n        db=Depends(mongo_database),\n    ):\n        result = await db.playlists.insert_one(\n            playlist.model_dump()\n        )\n        return {\n            \"message\": \"Playlist created successfully\",\n            \"id\": str(result.inserted_id),\n        }\n    ```", "```py\n    @app.get(\"/playlist/{playlist_id}\")\n    async def get_playlist(\n        playlist_id: str,\n        db=Depends(mongo_database),\n    ):\n        playlist = await db.playlists.find_one(\n            {\n                \"_id\": ObjectId(playlist_id)\n                if ObjectId.is_valid(playlist_id)\n                else None\n            }\n        )\n        if not playlist:\n            raise HTTPException(\n                status_code=404,\n                detail=\"Playlist not found\"\n            )\n        songs = await db.songs.find(\n            {\n                \"_id\": {\n                    \"$in\": [\n                        ObjectId(song_id)\n                        for song_id in playlist[\"songs\"]\n                    ]\n                }\n            }\n        ).to_list(None)\n        return {\n            \"name\": playlist[\"name\"],\n            \"songs\": songs\n        }\n    ```", "```py\nhttp://localhost:8000/docs and you will see the new endpoints: POST /playlist and GET /playlist.\nTo test the endpoints, create some songs and note their IDs. Then, create a playlist and retrieve the playlist with the `GET /playlist` endpoint. You will see that the response will contain the songs with all the information including the album.\nAt this point, you have all the tools to manage relationships between collections in MongoDB.\nSee also\nWe just saw how to manage relationships with MongoDB and create relative endpoints. Feel free to check the official MongoDB guidelines at this link:\n\n*   *MongoDB Model* *Relationships*: [https://www.mongodb.com/docs/manual/applications/data-models-relationships/](https://www.mongodb.com/docs/manual/applications/data-models-relationships/)\n\nWorking with indexes in MongoDB\nAn **index** is a data structure that provides a quick lookup mechanism for locating specific pieces of data within a vast dataset. Indexes are crucial for enhancing query performance by enabling the database to quickly locate documents based on specific fields.\nBy creating appropriate indexes, you can significantly reduce the time taken to execute queries, especially for large collections. Indexes also facilitate the enforcement of uniqueness constraints and support the execution of sorted queries and text search queries.\nIn this recipe, we’ll explore the concept of indexes in MongoDB and we will create indexes to improve search performances for songs in our streaming platform.\nGetting ready\nTo follow along with the recipe, you need to have a MongoDB instance already set up with at least a collection to apply indexes. If you are following along with the cookbook, make sure you went through the *Setting up MongoDB with FastAPI* and *CRUD operations in* *MongoDB* recipes.\nHow to do it…\nLet’s imagine we need to search for songs released in a certain year. We can create a dedicated endpoint directly in the `main.py` module as follows:\n\n```", "```py\n\n The query will fetch all documents and filter the one with a certain `release_year`. To speed up the query, we can create a dedicated index on the release year. We can do it at the server startup in the `lifespan` context manager in `main.py`. A text search in MongoDB won’t be possible without a text index.\nFirst, at the startup server, let’s create a text index based on the `artist` field of the collection document. To do this, let’s modify the `lifespan` context manager in the `main.py` module:\n\n```", "```py\n\n The `create_index` method will create an index based on the `release_year` field sorted in descending mode because of the `-``1` value.\nYou’ve just created an index based on the `release_year` field.\nHow it works…\nThe index just created is automatically used by MongoDB when running the query.\nLet’s check it by leveraging the explain query method. Let’s add the following log message to the endpoint to retrieve songs released in a certain year:\n\n```", "```py\n\n The `explained_query` variable holds information about the query such as the query execution or index used for the search.\nIf you run the server and call the `GET /songs/year` endpoint, you will see the following message log on the terminal output:\n\n```", "```py\n\n This confirms that the query has correctly used the index we created to run.\nThere’s more…\nDatabase indexes become necessary to run text search queries. Imagine we need to retrieve the songs of a certain artist.\nTo query and create the endpoint, we need to make a text index on the `artist` field. We can do it at the server startup like the previous index on `album.release_year`.\nIn the `lifespan` context manager, you can add the index creation:\n\n```", "```py\n\n Once we have created the index, we can proceed to create the endpoint to retrieve the song based on the artist’s name.\nIn the same `main.py` module, create the endpoint as follows:\n\n```", "```py\n\n Spin up the server from the command line with the following:\n\n```", "```py\n\n Go to the interactive documentation at `http:/localhost:8000/docs` and try to run the new `GET /``songs/artist` endpoint.\nText searching allow you to fetch records based on text matching. If you have filled the database with the `fill_mongo_db_database.py` script you can try searching for Bruno Mars’s songs by specifying the family name `\"mars\"`. The query will be:\n\n```", "```py\n\n This will return at the least the song:\n\n```", "```py\n\n Also, you will see a message on the terminal output like:\n\n```", "```py\n\n That means that the database has used the correct index to fetch the data.\nImportant note\nBy using the `explanation_query` variable, you can also check the difference in the execution time. However, you need a huge number of documents in your collection to appreciate the improvement.\nSee also\nWe saw how to build a text index for the search over the artist and a numbered index for the year of release. MongoDB allows you to do more, such as defining 2D sphere index types or compound indexes. Have a look at the documentation to discover the potential of indexing your MongoDB database:\n\n*   *Mongo* *Indexes*: https://www.mongodb.com/docs/v5.3/indexes/\n*   *MongoDB Text* *Search*: [https://www.mongodb.com/docs/manual/core/link-text-indexes/](https://www.mongodb.com/docs/manual/core/link-text-indexes/)\n\nExposing sensitive data from NoSQL databases\nThe way to expose sensitive data in NoSQL databases is pivotal to protecting sensitive information and maintaining the integrity of your application.\nIn this recipe, we will demonstrate how to securely view our data through database aggregations with the intent to expose it to a third-party consumer of our API. This technique is known as **data masking**. Then, we will explore some strategies and best practices for securing sensitive data in MongoDB and NoSQL databases in general.\nBy following best practices and staying informed about the latest security updates, you can effectively safeguard your MongoDB databases against potential security threats.\nGetting ready\nTo follow the recipe, you need to have a running FastAPI application with a MongoDB connection already set up. If don’t have it yet, have a look at the *Setting up MongoDB with FastAPI* recipe. In addition, you need a collection of sensitive data such as **Personal Identifiable Information** (**PII**) or other restricted information.\nAlternatively, we can build a collection of users into our MongoDB database, `beat_streaming`. The document contains PIIs such as names and emails, as well as users actions on the platform. The document will look like this:\n\n```", "```py\n\n The `consent_to_share_data` field stores the consent of the user to share behavioral data with third-party partners.\nLet’s first fill the collection users in our database. You can do this with a user’s sample by running the script provided in the GitHub repository:\n\n```", "```py\n\n If everything runs smoothly, you should have the collection users in your MongoDB instance.\nHow to do it…\nImagine we need to expose users data for marketing research to a third-party API consumer for commercial purposes. The third-party consumer does not need PII information such as names or emails, and they are also not allowed to have data from users who didn’t give their consent. This is a perfect use case to apply data masking.\nIn MongoDB, you can build aggregation pipelines in stages. We will do it step by step.\n\n1.  Since the database scaffolding is an infrastructure operation rather than an application, let’s create the pipeline with the view in a separate script that we will run separately from the server.\n\n    In a new file called `create_aggregation_and_user_data_view.py`, let’s start by defining the client:\n\n    ```", "```py\n\n    Since we don’t have any need to manage high traffic, we will use the simple `pymongo` client instead of the asynchronous one. We will reserve the asynchronous to the sole use of the application interactions.\n\n     2.  The pipeline stage follows a specific aggregations framework. The first step of the pipeline will be to filter out the users who didn’t approve the consent. This can be done with a `$``redact` stage:\n\n    ```", "```py\n\n     3.  Then, we filter out the emails that shouldn’t be shared with a `$``unset` stage:\n\n    ```", "```py\n\n     4.  This part of the pipeline will prevent emails and names from appearing in the pipeline’s output. We will split stage definition into three dictionaries for a better understanding.\n\n    First, we define the action to obfuscate the day for each date:\n\n    ```", "```py\n\n     5.  Then, we map the new `date` field for each element of the actions list:\n\n    ```", "```py\n\n     6.  Then, we use a `$set` operation to apply the `rebuild_actions_element` operation to every record like that:\n\n    ```", "```py\n\n     7.  Then, we gather the pipelines just created to define the entire pipeline stage:\n\n    ```", "```py\n\n     8.  We can use the list of aggregation stages to retrieve results and create the view in the `__main__` section of the script:\n\n    ```", "```py\n\n     9.  Once we have the view, we can create a dedicated endpoint to expose this view to a third-party customer without exposing any sensible data. We can create our endpoint in a separate module for clarity. In the `app` folder, let’s create the `third_party_endpoint.py` module. In the module, let’s create the module router as follows:\n\n    ```", "```py\n\n     10.  Then, we can define the endpoint:\n\n    ```", "```py\n\n     11.  Once the endpoint function has been created, let’s include the new router in the `FastAPI` object in the `main.py` module:\n\n    ```", "```py\n\nThe endpoint is now implemented in our API. Let’s start the server by running the following command:\n\n```", "```py\n$ pip install \"elasticsearch>=8,<9\" aiohttp\n```", "```py\nfrom elasticsearch import AsyncElasticsearch,\nes_client = AsyncElasticsearch(\n    \"localhost:27017\"\n)\n```", "```py\nfrom elasticsearch import (\n    TransportError,\n)\nasync def ping_elasticsearch_server():\n    try:\n        await es_client.info()\n        logger.info(\n            \"Elasticsearch connection successful\"\n        )\n    except TransportError as e:\n        logger.error(\n            f\"Elasticsearch connection failed: {e}\"\n        )\n        raise e\n```", "```py\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    await ping_mongo_db_server(),\n    await ping_elasticsearch_server()\n# rest of the code\n```", "```py\n{\n    \"title\": \"Song Title\",\n    \"artist\": \"Singer Name\",\n    \"album\": {\n    \"title\": \"Album Title\",\n    \"release_year\": 2012,\n    },\n    \"genre\": \"rock pop\",\n    \"views_per_country\": {\n    \"India\": 50_000_000,\n    \"UK\": 35_000_150_000,\n    \"Mexico\": 60_000_000,\n    \"Spain\": 40_000_000,\n    },\n}\n```", "```py\nfrom app.db_connection import es_client\nasync def fill_elastichsearch():\n    for song in songs_info:\n        await es_client.index(\n            index=\"songs_index\", body=song\n        )\n    await es_client.close()\n```", "```py\nmapping = {\n    \"mappings\": {\n        \"properties\": {\n            \"artist\": {\"type\": \"keyword\"},\n            \"views_per_country\": {\n                \"type\": \"object\",\n                \"dynamic\": True,\n            },\n        }\n    }\n}\n```", "```py\nfrom app.db_connection import es_client\nasync def create_index():\n    await es_client.options(\n        ignore_status=[400, 404]\n    ).indices.create(\n        index=\"songs_index\",\n        body=mapping,\n    )\n    await es_client.close()\n```", "```py\nasync def main():\n    await create_index()\n    await fill_elastichsearch() # only if you use it\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(create_index())\n```", "```py\n$ python fill_elasticsearch_index.py\n```", "```py\ndef top_ten_songs_query(country) -> dict:\n    views_field = f\"views_per_country.{country}\"\n    query = {\n        \"bool\": {\n            \"must\": {\"match_all\": {}},\n            \"filter\": [\n                {\"exists\": {\"field\": views_field}}\n            ],\n        }\n    }\n    sort = {views_field: {\"order\": \"desc\"}}\n```", "```py\n    source = [\n        \"title\",\n        views_field,\n        \"album.title\",\n        \"artist\",\n    ]\n```", "```py\n      return {\n        \"index\": \"songs_index\",\n        \"query\": query,\n        \"size\": 10,\n        \"sort\": sort,\n        \"source\": source,\n    }\n```", "```py\nfrom fastapi import APIRouter\nrouter = APIRouter(prefix=\"/search\", tags=[\"search\"])\n```", "```py\nfrom fastapi import Depends, HTTPException\nfrom app.db_connection import es_client\ndef get_elasticsearch_client():\n    return es_client\n@router.get(\"/top/ten/artists/{country}\")\nasync def top_ten_artist_by_country(\n    country: str,\n    es_client=Depends(get_elasticsearch_client),\n):\n    try:\n        response = await es_client.search(\n         *top_ten_artists_query(country)\n    )\n    except BadRequestError as e:\n        logger.error(e)\n        raise HTTPException(\n            status_code=400,\n            detail=\"Invalid country\",\n        )\n    return [\n        {\n            \"artist\": record.get(\"key\"),\n            \"views\": record.get(\"views\", {}).get(\n                \"value\"\n            ),\n        }\n        for record in response[\"aggregations\"][\n            \"top_ten_artists\"\n        ][\"buckets\"]\n    ]\n```", "```py\nimport main_search\n## existing code in main.py\napp = FastAPI(lifespan=lifespan)\napp.include_router(third_party_endpoint.router)\napp.include_router(main_search.router)\n## rest of the code\n```", "```py\n$ pip install redis\n```", "```py\n    from redis import asyncio as aioredis\n    redis_client = aioredis.from_url(\"redis://localhost\")\n    ```", "```py\n    async def ping_redis_server():\n        try:\n            await redis_client.ping()\n            logger.info(\"Connected to Redis\")\n        except Exception as e:\n            logger.error(\n                f\"Error connecting to Redis: {e}\"\n            )\n            raise e\n    ```", "```py\n    @asynccontextmanager\n    async def lifespan(app: FastAPI):\n        await ping_mongo_db_server(),\n        await ping_elasticsearch_server(),\n        await ping_redis_server(),\n        yield\n    ```", "```py\n    def get_redis_client():\n        return redis_client\n    ```", "```py\n    @router.get(\"/top/ten/artists/{country}\")\n    async def top_ten_artist_by_country(\n        country: str,\n        es_client=Depends(get_elasticsearch_client),\n        redis_client=Depends(get_redis_client),\n    ):\n    ```", "```py\n        cache_key = f\"top_ten_artists_{country}\"\n        cached_data = await redis_client.get(cache_key)\n        if cached_data:\n            logger.info(\n                f\"Returning cached data for {country}\"\n            )\n            return json.loads(cached_data)\n    ```", "```py\n        try:\n            response = await es_client.search(\n                 *top_ten_artists_query(country)\n            )\n        except BadRequestError as e:\n            logger.error(e)\n            raise HTTPException(\n                status_code=400,\n                detail=\"Invalid country\",\n            )\n        artists = [\n            {\n                \"artist\": record.get(\"key\"),\n                \"views\": record.get(\"views\", {}).get(\n                    \"value\"\n                ),\n            }\n            for record in response[\"aggregations\"][\n                \"top_ten_artists\"\n            ][\"buckets\"]\n        ]\n    ```", "```py\n        await redis_client.set(\n            cache_key, json.dumps(artists), ex=3600\n        )\n        return artists\n    ```", "```py\n\n```"]