- en: Unit Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we saw various approaches to metaprogramming and programmable
    syntax in Python. In this chapter, we're going to take a look at the ideas behind
    unit testing, then move on to several test automation tools we can use to make
    our testing easier and more useful. We'll focus on what unit testing is, and the
    ideas that motivate it. We'll also discuss Python's standard `unittest` package
    and how it works.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you'll learn how to use `unittest.mock` to control the environment
    that your test code will run in so that the test will remain focused on making
    sure one thing works properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the principle of unit testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the unittest package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using unittest.mock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using unittest's test discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using nose for unified test discovery and reporting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the principle of unit testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Testing is often something of an afterthought for programmers because it tends
    to be laborious and annoying. Also, we usually have a high degree of confidence
    in our work and testing it seems unnecessary. It''s also a fact, though, that
    the confidence is often misplaced. Source code is a complex and subtle language,
    and it''s easy to make mistakes while writing it and not even notice them. We
    all know this from experience, but that doesn''t make it any easier to make time
    for something that is laborious, annoying, and feels unnecessary. The following
    flow diagram illustrates a simple example of testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/946c5ebf-b5e3-4b24-83a8-1151da7c5ade.png)'
  prefs: []
  type: TYPE_IMG
- en: So, the first question about testing is, *How can we do it in a way that doesn't
    feel like a painful waste of time?* Finding a way to overcome this psychological
    barrier is the first step toward creating a testing method that will actually
    work for a lot of programmers. Unit testing does this by reducing the effort needed
    to run tests, integrating testing with the development process, and making the
    tests themselves visibly useful.
  prefs: []
  type: TYPE_NORMAL
- en: What is a unit test?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First of all, let's find out what is a unit test. A **unit test** is a single
    small chunk of test code that tests correct behavior or a single specific flaw
    within an isolated small chunk of program code.
  prefs: []
  type: TYPE_NORMAL
- en: There are reasons for each part of this definition. A unit test is source code
    because one of the secrets of unit testing is that we put the maximum amount of
    the effort of testing on the computer, which is where it should belong.
  prefs: []
  type: TYPE_NORMAL
- en: The test code tells the computer how to perform the test, which allows us to
    perform the test often and easily. A unit test is small because a large test is
    almost inevitably testing for more than one thing.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be summarized as:'
  prefs: []
  type: TYPE_NORMAL
- en: Small, simple code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checks a small piece of the program
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answers a single yes-or-no question about program functionality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we want to test for more than one thing, we should write more than one test.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two rules for a unit test. These are:'
  prefs: []
  type: TYPE_NORMAL
- en: A unit test only checks a single aspect of the program code because when a test
    fails, we want it to tell us exactly what the problem is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A unit test only involves a narrow region of the program code because when a
    test fails, we want it to tell us exactly where the problem is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we write a collection of tests that follow these rules, they are called a
    **unit test suite**.
  prefs: []
  type: TYPE_NORMAL
- en: With proper tools, we can run our whole test suite with a single command, and
    the output of this command will immediately tell us the status of our code with
    respect to the test. If the test fails, it tells us what we need to work on next.
    If it succeeds, it gives us a reason to build our confidence in the code it tested.
  prefs: []
  type: TYPE_NORMAL
- en: 'The availability of automated unit testing leads to a programming paradigm
    called **test-driven development** (**TDD**), as illustrated in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe2f8b4b-45c7-4c35-8aa2-069f0cc3fd2b.png)'
  prefs: []
  type: TYPE_IMG
- en: The basic idea of TDD is that since a failing test tells us what to do next,
    we should never write program code except when we want to make a failing test
    pass. If all the presently available tests pass and the program isn't finished,
    we first add another test to the test suite, and then write program code to make
    it pass.
  prefs: []
  type: TYPE_NORMAL
- en: Doing things this way ensures that there are tests that cover most or all of
    the source code and that the tests are run often, which makes it very difficult
    for bugs and regressions to sneak into the code without being noticed. It also
    lets us break the development process down into a series of short-term goals,
    which produce a visible result when we achieve them.
  prefs: []
  type: TYPE_NORMAL
- en: This is psychologically useful because it makes the programming process feel
    more productive, and it's much easier to perform a task that feels rewarding.
    Further, debugging tends to dominate the time needed for a project, and TDD reduces
    the time needed to deal with bugs.
  prefs: []
  type: TYPE_NORMAL
- en: So, when applied properly, unit testing principles and tools help us produce
    better code, perform the test faster, and enjoy the process more. It's an all-round
    win.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we've had a high-level discussion of the reasons for and the benefits
    of automated unit testing and TDD. Python includes a framework for automated unit
    testing, and we'll take a look at it in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Using the unittest package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we're going to look at Python's standard `unittest` package.
    We'll talk about how to structure a test file and how to write tests and draw
    a comparison between what happens and what should happen in these tests. Let's
    jump straight into it!
  prefs: []
  type: TYPE_NORMAL
- en: Structuring a test file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The unittest module contains a framework for performing automated unit testing.
    Most of this functionality is based around the `unittest.TestCase` class, which
    we will inherit from to create our own tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we see the basic features of `TestCase` in action
    and also test and assert methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dc0b2b97-8c1c-4d63-94ed-c0b2d50ef1dc.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Any method that we define using a class inherited from `TestCase`, and that
    has a name that starts with the word **test**, is assumed to be a unit test. In
    the preceding example, this means that the `test_addition` method is a unit test;
    however, if we had added another method to the class, called `connect`, the unittest
    module would not have treated it as a unit test.
  prefs: []
  type: TYPE_NORMAL
- en: A `TestCase` class can contain more than one unit test and should run when those
    tests are logically related and require the same operating environment.
  prefs: []
  type: TYPE_NORMAL
- en: assert methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Inside our `test_addition` method, which is a unit test, we used a method called
    `assertEqual` to actually check that the result of the code was as expected. `TestCase`
    provides a wide range of these assert methods that test for various relationships
    between our results and what we expected. This is shown in the following code
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/becea722-e559-4054-8783-07e2beede181.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a closer look at what these assert methods actually do:'
  prefs: []
  type: TYPE_NORMAL
- en: We've already seen the `assertEqual` method in the previous code example; it
    checks whether two values are equal and makes the test fail if they are not. The
    `assertNotEqual` method performs the inverse operation, checking whether two values
    are equal and failing the test if they are.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `assertAlmostEqual` and `assertNotAlmostEqual` methods are for use with
    floating point numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The way computers handle floating point numbers indicates that numbers that
    should be exactly equal actually differ in their least significant bits. For example,
    if we square the square root of seven, the result is not exactly seven, so `assertEqual`
    will treat it as *not equal*. However, `assertAlmostEqual` will recognize that
    the two numbers are the same for practical purposes.
  prefs: []
  type: TYPE_NORMAL
- en: The `assertGreaterEqual`, `assertLess`, and `assertLessEqual` methods check
    for ordering relationships between their arguments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `assertIs` and `assertIsNot` methods check whether their arguments are references
    to the exact same object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `assertIsNone` and `assertIsNotNone` methods are a special case of `assertIs`
    and `assertIsNot` methods and check whether their single argument is in fact `None`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `assertIsInstance` and `assertIsNotInstant` methods check whether the object
    in the first argument is an instance of the type in their second argument.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `assertIn` and `assertNotIn` check whether the object in the first argument
    is a member of the container in their second argument.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `assertCountEqual` method is interesting. If we want to check whether two
    sequences are the same, we could just use `assertEqual`, but `assertCountEqual`
    is for when we want to check whether two sequences contain the same values but
    don't care about the order.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The method will cause a test to fail if any of the members of either sequence
    appears in the other sequence a different number of times. So, if `a` is in the
    first sequence twice, it has to be in the second sequence twice as well, but we
    don't care where.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we have `assertRaises`, which functions a little differently because
    it needs to catch the exception raised by running some code. This is a situation
    tailor-made for a context manager, and that's what `assertRaises` is.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Used in a `with` statement, `assertRaises` makes the test fail if the code inside
    the with block does not raise the expected exception. This could seem a little
    backward, but it's correct. The test fails if the expected exception is not raised.
    Sometimes, raising an exception is the correct behavior. For example, passing
    `None` to the end constructor should raise a type error, and if it doesn't, that's
    a bug.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing what happens to what should happen in unit tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I mentioned in passing that all the unit tests in a `TestCase` class should
    share the same operating environment. What does that mean?
  prefs: []
  type: TYPE_NORMAL
- en: It means that each of them expects any external data that they access to be
    in the same state. For example, each of the tests accesses a particular file and
    each of them expects to find the same information inside that file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s have a look at a code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98fa707d-ae87-44d6-9552-ee7c54299fb3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, we have two tests that both read and write in the
    same text file. Both of them expected to come in to contain the same specific
    information when they started running. In other words, both of them have the same
    expectations about their operating environment.
  prefs: []
  type: TYPE_NORMAL
- en: When we have multiple tests that share the same expectations and they're logically
    related, we should group them into a single `TestCase` class. Then, we should
    give that class a `setUp` method, which would be responsible for making sure those
    shared expectations are met, and possibly a `tearDown` method, which would clean
    up any changes that `setup` may have made or the tests left lying around.
  prefs: []
  type: TYPE_NORMAL
- en: The name of the class itself doesn't matter; simply inheriting from `TestCase`
    is sufficient to identify them.
  prefs: []
  type: TYPE_NORMAL
- en: The `setUp` method is run before each unit test in `TestCase`. So, in our code
    example, which has two unit tests, `setUp` is run twice. Similarly, `tearDown`
    runs after each unit test. That way, the changes that one test might make to the
    operating environment are removed before the next test is run.
  prefs: []
  type: TYPE_NORMAL
- en: The starting environment is the same for each unit test in `TestCase`. So, that's
    the basic mechanics of Python's unit test framework, as far as writing tests goes.
  prefs: []
  type: TYPE_NORMAL
- en: To run the tests, we just need to invoke the `unittest` package from the command
    line. We tell it the name of the module we want to run the tests from and it finds
    the `TestCase` classes in that module, creates instances of them, runs all their
    tests, and gives us a report on which test has passed and which failed.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we've seen how to write basic unit tests and run them. There
    are even easier ways to run a test, but we'll look at them after we examine unit
    test mock objects.
  prefs: []
  type: TYPE_NORMAL
- en: Using unittest.mock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll take a look at a subpackage of unit tests, called **mock**.
    The tools in the `mock` package help us keep our test isolated, so they aren't
    made to succeed or fail based on the behavior of the code, which isn't supposed
    to be covered by the test.
  prefs: []
  type: TYPE_NORMAL
- en: We talked about how important it is that unit tests only interact with a small
    section of code, but how can we arrange for this when so many pieces of code interact
    with objects and functions originating from all over the source tree? One answer
    is that we can replace those objects and functions with mock objects.
  prefs: []
  type: TYPE_NORMAL
- en: What is a mock object?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A mock object is a clever piece of code; it could pretend to be almost any
    kind of object or function, but instead of doing whatever the original did, it
    just records what is done with it so we can check it later. Let''s play with a
    mock object for a moment to get a feel for them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7f6f5d9c-a63d-47f0-a209-5acfeae4291d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Refer to the preceding screenshot. We can access pretty much any attribute
    of the mock object without defining it ahead of time. The result is another mock
    object. Similarly, we can call almost any method we want without defining it ahead
    of time and the result is yet another mock object, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b47ead3-58d4-4b53-ad62-45733cb5c96c.png)'
  prefs: []
  type: TYPE_IMG
- en: This by itself is enough to let a mock object replace a large range of functions
    and objects that our tested code might interact with. But, we can go further if
    we take time to preconfigure our mock objects.
  prefs: []
  type: TYPE_NORMAL
- en: Preconfiguring mock objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can assign non-mock objects to a mock object''s attributes, so that when
    we access the attribute, we''d get a specific value instead of a generic mock
    object. This is illustrated by the following simple code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/19118bc9-a4f4-4b04-9ac5-99a35565a323.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also assign a customized mock object in place of a method so that we
    can make the mocked method act more like the original, but in a way, this is controlled
    by the test. We do this by passing a return value parameter to the `mock` constructor,
    which tells the mock object that every time it''s called, it should return this
    value, as shown in the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d3f02ce0-f6fc-4068-9296-62b6c58f5af9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we want the mock to return different values each time it''s called, we use
    a different parameter of the constructor, called `side_effect`, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/569e85fd-7bb3-440d-97c1-c9417abb0980.png)'
  prefs: []
  type: TYPE_IMG
- en: We have to know how many times the test will call the mock as a function so
    we can provide a return value for each call; otherwise, this doesn't present a
    difficulty.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also make the mock object raise an exception by passing that exception
    as `side_effect` or a member of the `side_effect` sequence, as shown in the following
    code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ccc3c1a1-9c8a-4d86-a112-76fbd4cda1a4.png)'
  prefs: []
  type: TYPE_IMG
- en: That pretty well covers how to make a mock that can, in a controlled way, stand
    in for real objects and code while we run our test. However, to really support
    testing, we also need to be able to check the mock and confirm whether it was
    used as expected.
  prefs: []
  type: TYPE_NORMAL
- en: assert methods of mock objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've already seen the `method_calls` attribute that mock objects use to track
    their interactions, but mock objects also have their own assert methods that are
    usually easier to use than accessing the method calls' list directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most useful mock object assertion method is `assert_called_with` (refer
    to the following code example):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6df0132d-256c-402b-b856-50ada446cdb3.png)'
  prefs: []
  type: TYPE_IMG
- en: It checks whether the most recent call to the mock object was done with a specified
    argument and `assert_any_call`, which checks whether the mock has ever been called
    with specified arguments.
  prefs: []
  type: TYPE_NORMAL
- en: So, we know what mock objects are for, how to create them, and how to check
    the record of what has been done with them. That's enough for replacing the parameters
    of a tested function with mock objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can even replace the `self` parameter of methods if we call the method via
    the class instead of a real instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/69345cc7-00c3-45e4-954c-c75ebfb17d07.png)'
  prefs: []
  type: TYPE_IMG
- en: The unittest.mock patch function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What do we do, though, when the code we're testing reaches out to the system
    automatically and accesses something we want to replace with a mock object? For
    example, what if the code we're testing calls `time.time`? This is where the `unittest.mock``patch`
    function comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `patch` function is a context manager and it could temporarily replace
    nearly any object in any package or module with a mock object. Once the with block
    exits, the real object is restored to its position, as shown in the following
    code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a79484dd-4f79-4a7b-af0c-66fe2b7650ac.png)'
  prefs: []
  type: TYPE_IMG
- en: Something to be aware of is that patch doesn't replace every reference to the
    target object with a mock; it only replaces the single reference that we specified
    in the first argument.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, any code that accesses the time function by looking
    up the reference in the `time` module will get our mock object; however, if there
    were any code that had used `from time``import time` to create a local reference
    to the `time` function, then that reference would still refer to the real-time
    function. If we want to patch the time function for code that has a local reference
    to it, we need to pass the path to that local reference into the patch.
  prefs: []
  type: TYPE_NORMAL
- en: OK, we're pretty much good to go with mock objects now. This means we know everything
    we need to write powerful tests easily. All we are left to do is find out how
    to run our test suites, which is our next topic.
  prefs: []
  type: TYPE_NORMAL
- en: Using unittest's test discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll take a look at the `unittest` package's ability to run
    many tests at once with a single command.
  prefs: []
  type: TYPE_NORMAL
- en: We've seen how to easily run all the tests in a particular file, but for a large
    project, putting all the tests into a single file would be troublesome. They need
    to be separated into different files according to logical groupings, or the test
    suite will become unmanageable. On the other hand, it would be a pain to have
    to manually tell unittests to run the test and a whole bunch of files if we were
    to test or list out each file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, there''s a way to split our test suites into many files and still
    run them with a simple command, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6033f8db-20e3-48e9-9200-4678b4313bbd.png)'
  prefs: []
  type: TYPE_IMG
- en: We use a unit testing tool that supports test discovery. This basically just
    means it looks at the available files and decides for itself which ones seems
    like a test file; then it loads the test from those files and runs them.
  prefs: []
  type: TYPE_NORMAL
- en: Unittest's discovery tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `unittest` package has a basic but useful built-in test discovery tool.
    When we run `python -m unittest discover`, it searches the current directory for
    Python S, whose names start with the word `test`. In addition, it recursively
    performs the same scan on any subdirectories that contain an `init.py` file. Once
    it collects the names of all the matching modules, it runs the test just as if
    we''d specified the modules on the command line ourselves. This can be illustrated
    using the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c5e2ebaf-4813-499b-b5ab-b4d73113f842.png)'
  prefs: []
  type: TYPE_IMG
- en: Command-line options in unit test discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few command-line options we can use to adjust the behavior of unit
    test discovery. The first, which we saw in the previous code example, is the `-v`
    switch. This switch makes test reports somewhat more verbose. We used it in the
    previous code so we could see that the discovery had worked properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use the `-p` command-line option (as shown in the following code
    example) to change the pattern that is used to recognize test files:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ef21fcda-2637-4042-be24-205bf43016f7.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we've changed it so that the filenames ending in the word `one.py` are
    recognized as test files.
  prefs: []
  type: TYPE_NORMAL
- en: 'The unittest discover code also recognizes `-s` to specify the directory where
    the test search should start. This is shown in the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8642c979-0002-47b1-bee8-224ba8ca01ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Notice that by making a suite act as the starting directory for the search,
    we''ve stopped it from being recognized as a package containing the test. If that''s
    a problem, we could supplement the `-s` option with `-t` (refer to the following
    code example), which tells you to test where to find the top-level directory for
    this run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6dfdadf5-033f-4820-ad29-364dbc8bff55.png)'
  prefs: []
  type: TYPE_IMG
- en: Using both `-s` and `-t`, we're able to narrow the test search to a particular
    subdirectory while still running the tests in the context of a parent directory.
  prefs: []
  type: TYPE_NORMAL
- en: There's a bit of a pitfall to be aware of when using unit test discovery code
    or any other test discovery that works by importing modules to check whether they
    contain tests. This pitfall is that the modules are imported.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the time, that's not a problem, but if a piece of test discovery code
    imports the module that was meant to be a program's entry point, it might result
    in actually running the program, which is not the desired behavior. It's easy
    to avoid this problem when we're writing an entry point by wrapping the entry
    point code in the `if '__name__' = = '__main__'` statement.
  prefs: []
  type: TYPE_NORMAL
- en: However, if we, or somebody else, skips this check and unittest thinks the file
    looks like a test file, running unit test discovery code will have surprising
    results. That's all there is in regard to unittest's test discovery tool. It doesn't
    have many features, but it does have the features that everybody needs, and there's
    a good chance that it's all we'll need for the majority of our projects.
  prefs: []
  type: TYPE_NORMAL
- en: For cases where we need more from our test discovery tool, we can use `nose`,
    which we'll look at in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Using nose for unified test discovery and reporting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Note that `nose` is a third-party tool available via `pip` and Python Package
    Index. It does basically the same job as a unittest `discover` command, but it
    supports more control and customization as well as recognizing a wider range of
    tests. It can be installed using the following command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '****![](img/10500722-c392-45b0-a574-59846bb4432a.jpg)****'
  prefs: []
  type: TYPE_NORMAL
- en: Running our tests with nose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''re going to look at two specific features among the many that nose provides.
    These are:'
  prefs: []
  type: TYPE_NORMAL
- en: It can generate a code coverage report that tells us how much of the code our
    test actually tested
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can run tests across multiple processes, allowing them to be executed in
    parallel on multiple CPUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In order to get a coverage report, we first need to make sure that the coverage
    module is installed. We could do this with a simple `pip` command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '****![](img/e2995c59-4230-46cc-a2bd-aebd4a404923.jpg)****'
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the `coverage` module in place, we can enable a coverage report
    for our test with nothing more than a couple of nose's command-line options.
  prefs: []
  type: TYPE_NORMAL
- en: 'Strictly speaking, only the `--with-coverage` option is required to enable
    the coverage report, as shown in the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d070144f-452a-4ba8-9b6c-c0605a196ba0.png)'
  prefs: []
  type: TYPE_IMG
- en: However, if we don't include `--cover-erase` as well, coverage data from previous
    test runs will get mixed with our current run, which will make the results harder
    to interpret.
  prefs: []
  type: TYPE_NORMAL
- en: The cover-package option
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There''s a third coverage-related command-line option that is sometimes useful.
    It is the `cover-package` option; it narrows down the code coverage report to
    only a specific package, as shown in the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/630e8538-4e98-408f-8698-4a3ddf272273.png)'
  prefs: []
  type: TYPE_IMG
- en: Focusing the report this way can make it easier to read and extract useful information.
  prefs: []
  type: TYPE_NORMAL
- en: Testing multiple worker processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The other nose feature we''re going to look at is the ability to farm outÂ tests
    to multiple worker processes and thus spread them across the available CPU cores.
    To test multiple worker processes, we just have to provide the `--processes=`
    command-line option and tell it how many processes to use. If we pass `-1` to
    indicate the number of processes, it uses the detected number of CPU cores, which
    is probably what we want anyway (refer to the following code example):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/69feb791-f01e-40d2-9bc9-84b05d60e7a2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So, unless we have a specific reason to do otherwise, we should always just
    use `-1`.
  prefs: []
  type: TYPE_NORMAL
- en: If we look carefully at the preceding code example, we can see that it actually
    took longer to run our test suite on multiple processes. That's because conducting
    the tests themselves involves low effort, but it's not the same when it comes
    to launching a worker process. Fortunately, that's a fixed cost, so when we start
    running larger test suites that contain more expensive tests, we start seeing
    the benefits of parallel execution.
  prefs: []
  type: TYPE_NORMAL
- en: This was just a taste of the sort of features that nose supports and that's
    without writing our own nose plugins to customize it further. It's a very capable
    system, so if we find ourselves needing a particular feature from our test runner,
    a good first step is to see whether nose already has that feature.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to use the `unittest` and `unittest.mock` packages
    to write an automated test; we also learned the process of test-driven development.
    Next, we saw how to use `unittest.mock` to control the environment that our test
    code runs in so that the test can remain focused on making sure one thing works
    properly. Post this, we learned how to run a test using Python's built-in unit
    test tools, and finally, we discussed how to take advantage of a couple of features
    of the nose test runner.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we're going to take a look at the reactive programming
    paradigm and RxPY.
  prefs: []
  type: TYPE_NORMAL
