- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Intersection of Object-Oriented and Functional Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many aspects of Python that appear more reminiscent of structural
    or functional programming than object-oriented programming. Although object-oriented
    programming has been the most visible paradigm of the past two decades, the old
    models have seen a recent resurgence. As with Python''s data structures, most of
    these tools are syntactic sugar over an underlying object-oriented implementation;
    we can think of them as a further abstraction layer built on top of the (already
    abstracted) object-oriented paradigm. In this chapter, we''ll be covering a grab
    bag of Python features that are not strictly object-oriented:'
  prefs: []
  type: TYPE_NORMAL
- en: Built-in functions that take care of common tasks in one call
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An alternative to method overloading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions as objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: File I/O and context managers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The case study in this chapter will revisit some of the essential algorithms
    of *k*-nearest neighbor classification. We'll look at how we can use functions
    instead of classes with methods. For parts of the application, separating algorithms
    from a class definition can provide some flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start this chapter by looking at some of Python's built-in functions.
    Some of these are closely related to class definitions, allowing us to use a functional
    style of programming with the underlying complex objects.
  prefs: []
  type: TYPE_NORMAL
- en: Python built-in functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are numerous functions in Python that perform a task or calculate a result
    on certain types of objects without being methods on the underlying class. They
    usually abstract common calculations that apply to multiple types of classes.
    This is duck typing at its best; these functions accept objects that have certain
    attributes or methods, and are able to perform generic operations using those
    methods. We've used many of the built-in functions already, but let's quickly
    go through the important ones and pick up a few neat tricks along the way.
  prefs: []
  type: TYPE_NORMAL
- en: The len() function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One simple example of functions that are related to object methods is the `len()` function,
    which returns the number of items in some kind of container object, such as a
    dictionary or list. You''ve seen it before, demonstrated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You may wonder why these objects don't have a length property instead of having
    to call a function on them. Technically, they do. Most objects that `len()` will
    apply to have a method called `__len__()` that returns the same value. So `len(myobj)`
    seems to call `myobj.__len__()`.
  prefs: []
  type: TYPE_NORMAL
- en: Why should we use the `len()` function instead of the `__len__()` method? Obviously, `__len__()` is
    a special double-underscore method, suggesting that we shouldn't call it directly.
    There must be an explanation for this. The Python developers don't make such design
    decisions lightly.
  prefs: []
  type: TYPE_NORMAL
- en: The main reason is efficiency. When we call the `__len__()` method of an object,
    the object has to look the method up in its namespace, and, if the special `__getattribute__()`
    method (which is called every time an attribute or method on an object is accessed)
    is defined on that object, it has to be called as well. Furthermore, the `__getattribute__()`
    method may have been written to do something clever, for example, refusing to
    give us access to special methods such as `__len__()`! The `len()` function doesn't
    encounter any of this. It actually calls the `__len__()` method on the underlying
    class, so `len(myobj)` maps to `MyObj.``__len__(myobj)`.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason is maintainability. In the future, Python developers may want
    to change `len()` so that it can calculate the length of objects that don't have `__len__()`,
    for example, by counting the number of items returned in an iterator. They'll
    only have to change one function instead of countless `__len__()` methods in many
    objects across the board.
  prefs: []
  type: TYPE_NORMAL
- en: The functional style, `len(myobj)`, is described by some as more readable than
    the alternative method style, `myobj.len()`. Some debate the inconsistency of
    this syntax, but others prefer it for those few common operations that are applied
    to a wide number of collection types.
  prefs: []
  type: TYPE_NORMAL
- en: Another, sometimes overlooked, reason for `len()` being an external function
    is backward compatibility. This is often cited in articles as *for historical
    reasons*, which can be a mildly dismissive way of saying a mistake was made long
    ago and we're stuck with it. Strictly speaking, `len()` isn't a mistake; it's
    a design decision that has stood the test of time and has some benefits.
  prefs: []
  type: TYPE_NORMAL
- en: The reversed() function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `reversed()` function takes any sequence as input and returns a copy of
    that sequence in reverse order. It is normally used in `for` statements when we
    want to iterate over items from back to front.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the `len()` function, `reversed()` calls the `__reversed__()` method
    on the class for the parameter. If that method does not exist, `reversed` builds
    the reversed sequence itself using calls to `__len__()` and `__getitem__()`, which
    are used to define a sequence. We only need to override `__reversed__()` if we
    want to somehow customize or optimize the process, as demonstrated in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s exercise this function on three different kinds of lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `for` statements at the end print reversed versions of a generic list object,
    and instances of the `CustomSequence` class and the `FunkyBackwards` class. The
    output shows that `reversed` works on all three of them, but has very different
    results.
  prefs: []
  type: TYPE_NORMAL
- en: When we reverse `CustomSequence`, the `__getitem__()` method is called for each
    item, which just inserts an `x` before the index. For `FunkyBackwards`, the `__reversed__()`
    method returns a string, each character of which is output individually in the
    `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: The `CustomSequence` class is incomplete. It doesn't define a proper version
    of `__iter__()`, so a forward `for` loop over them will never end. This is the
    subject of *Chapter 10*, *The Iterator Pattern*.
  prefs: []
  type: TYPE_NORMAL
- en: The enumerate() function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sometimes, when we''re examining items in a container with a `for` statement,
    we want access to the index (the current position in the container) of the current
    item being processed. The `for` statement doesn''t provide us with indexes, but
    the `enumerate()` function gives us something better: it creates a sequence of
    tuples, where the first object in each tuple is the index and the second is the
    original item.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is useful because it assigns an index number. It works well for sets or
    dictionaries where there isn''t an inherent index order to the values. It also
    works for text files, which have an implied line number. Consider some simple
    code that outputs each of the lines in a file with the associated line numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this shows the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `enumerate` function is an iterable: it returns a sequence of tuples. Our
    `for` statement splits each tuple into two values, and the `print()` function
    formats them together. We used the optional `start=1` on the enumerate function
    to provide a convention 1-based sequence of line numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve only touched on a few of the more important Python built-in functions.
    As you can see, many of them call into object-oriented concepts, while others
    subscribe to purely functional or procedural paradigms. There are numerous others
    in the standard library; some of the more interesting ones include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`abs()`, `str()`, `repr()`, `pow()`, and `divmod()` map directly to the special
    methods `__abs__()`, `__str__()`, `__repr__()`, `__pow__()`, and `__divmod__()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bytes()`, `format()`, `hash()`, and `bool()` also map directly to the special
    methods `__bytes__()`, `__format__()`, `__hash__()`, and `__bool__()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And several more. *Section 3.3, Special Methods Names* of *The Python Language
    Reference*, provides the details of these mappings. Other interesting built-in
    functions include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`all()` and `any()`, which accept an iterable object and return `True` if all,
    or any, of the items evaluate to true (such as a non-empty string or list, a non-zero
    number, an object that is not `None`, or the literal `True`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eval()`, `exec()`, and `compile()`, which execute string as code inside the
    interpreter. Be careful with these ones; they are not safe, so don''t execute
    code an unknown user has supplied to you (in general, assume all unknown users
    are malicious, foolish, or both).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hasattr()`, `getattr()`, `setattr()`, and `delattr()`, which allow attributes
    on an object to be manipulated by their string names.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`zip()`, which takes two or more sequences and returns a new sequence of tuples,
    where each tuple contains a single value from each sequence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And many more! See the interpreter help documentation for each of the functions
    listed in `help("builtins")`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What's central is avoiding a narrow viewpoint that an object-oriented programming
    language must always use `object.method()` syntax for everything. Python strives
    for readability, and a simple `len(collection)` seems more clear than the slightly
    more consistent *potential* alternative, `collection.len()`.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative to method overloading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One prominent feature of many object-oriented programming languages is a tool
    called **method overloading**. Method overloading refers to having multiple methods
    with the same name that accept different sets of parameters. In statically typed
    languages, this is useful if we want to have a method that accepts either an integer
    or a string, for example. In non-object-oriented languages, we might need two
    functions, called `add_s` and `add_i`, to accommodate such situations. In statically
    typed object-oriented languages, we'd need two methods, both called `add`, one
    that accepts strings, and one that accepts integers.
  prefs: []
  type: TYPE_NORMAL
- en: In Python, we've already seen that we only need one method, which accepts any
    type of object. It may have to do some testing on the object type (for example,
    if it is a string, convert it to an integer), but only one method is required.
  prefs: []
  type: TYPE_NORMAL
- en: The type hints for a parameter that can take on multiple types can become rather
    complex. We'll often have to use a `typing.Union` hint to show that a parameter
    can have values from `Union[int, str]`. This definition clarifies the alternatives
    so **mypy** can confirm that we're using the overloaded function properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have to distinguish between two varieties of overloading here:'
  prefs: []
  type: TYPE_NORMAL
- en: Overloading parameters to allow alternative types using `Union[...]` hints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overloading the method by using more complex patterns of parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, an email message method might come in two versions, one of which
    accepts a parameter for the *from* email address. The other method might look
    up a default *from* email address instead. Some languages force us to write multiple
    methods with the same name and different parameter patterns. Python doesn't permit
    multiple definitions of methods with the same name, but it does provide a different,
    equally flexible way to specify variant parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve seen some of the possible ways to send argument values to methods and
    functions in previous examples, but now we''ll cover all the details. The simplest
    function accepts no parameters. We probably don''t need an example, but here''s
    one for completeness:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'And here''s how it''s called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In this case, since we're working interactively, we omitted the type hint. A
    function that does accept parameters will provide the names of those parameter
    names in a comma-separated list. Only the name of each parameter needs to be supplied.
    A type hint, however, is always helpful. The hints follow the names, separated
    by a colon, `:`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When calling the function, the values for the positional parameters must be
    specified in order, and none can be missed or skipped. This is the most common
    way in which we''ve specified parameters in our previous examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'To call it, type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Python code is generic with respect to type. This means that any type of object
    can be passed as an argument value: an object, a container, a primitive, even
    functions and classes. The preceding call shows a hardcoded string, the value
    of a variable, and a Boolean passed into the function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, our applications are not completely generic. That''s why we often
    provide type hints to narrow the domain of possible values. In the rare case when
    we''re writing something truly generic, we can use the `typing.Any` hint to tell
    **mypy** that we really mean that any object is usable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We can use **mypy** to locate code like this using the `--disallow-any-expr`
    option. This can flag lines that may be in need of some clarity on what types
    are really important.
  prefs: []
  type: TYPE_NORMAL
- en: Default values for parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we want to make a parameter's value optional, we can specify a default value.
    Some other languages (Java, for example) require a second method with a different
    set of parameters. In Python, we define a single method; we can provide a default
    value for a parameter using an equals sign. If the calling code does not supply
    an argument value for the parameter, it will be assigned the given default value.
    This means calling code can still choose to override the default by passing in
    a different value. If a value of `None` is used as the default for optional parameter
    values, the `typing` module lets us describe this using the `Optional` type hint.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a function definition with default parameter definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The first two parameters are mandatory and must be provided. The last two parameters
    have default argument values and can be omitted.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several ways we can call this function. We can supply all argument
    values in order, as though all the parameters were positional, as can be seen
    in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can supply just the mandatory argument values in order, allowing
    one of the keyword parameters (`sec`) to use a default value, and providing a
    keyword argument for the `dir` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We've used equals sign syntax when calling a function to skip default values
    that we aren't interested in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Surprisingly, we can even use the equals sign syntax to mix up the order of
    arguments for the positional parameters, so long as all the parameters are given
    an argument value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You may occasionally find it useful to make a *keyword-only* parameter. To
    use this, the argument value must be supplied as a keyword argument. You can do
    that by placing a `*` before all of the keyword-only parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This function has one positional parameter, `x`, and three keyword parameters, `y`, `a`,
    and `b`. The `x` and `y` parameters are both mandatory, but `a` can only be passed
    as a keyword argument. `y` and `b` are both optional with default values, but
    if `b` is supplied, it can only be a keyword argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'This function fails if you don''t pass `a`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'It also fails if you pass `a` as a positional argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'But you can pass `a` and `b` as keyword arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We can also mark parameters as being supplied only by position. We do this by
    providing these names before a single `/` that separates the positional-only parameters
    from the more flexible parameters that follow.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This function requires argument values for the `x` and `y` parameters be the
    first two, and named arguments for `x` and `y` are specifically not permitted.
    Here''s what happens if we try:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We must provide argument values for the first two parameters, `x` and `y`, positionally.
    The third parameter, `z`, can be provided positionally, or with a keyword.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have three separate kinds of parameter possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Positional only**: These are handy in a few cases; see PEP 570 for examples:
    [https://www.python.org/dev/peps/pep-0570](https://www.python.org/dev/peps/pep-0570).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Either positional or keyword**: This is the case for most parameters. The
    order is designed to be helpful, and keywords can be used for clarification. More
    than three positional parameters invites confusion, so a long list of positional
    parameters isn''t a great idea.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Keyword only**: After the `*`, the argument values **must** have a keyword
    supplied. This can be helpful to make rarely used options more visible. It can help
    to think of keywords as keys to a dictionary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing how to call the method normally takes care of itself, depending on
    which values need to be supplied, and which can be left at their defaults. For
    simple methods with a few argument values, positional parameters are more or less
    expected. For complex methods with a lot of argument values, using keywords can help
    to clarify how things work.
  prefs: []
  type: TYPE_NORMAL
- en: Additional details on defaults
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One thing to take note of with keyword arguments is that anything we provide
    as a default argument is evaluated exactly once when the function is first created,
    not when it is evaluated. This means we can''t have dynamically generated default
    values. For example, the following code won''t behave quite as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The default value for the `x` parameter is the current value *when the function
    is defined*. We can see that behavior when we try to evaluate this with different
    values for the `number` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The first evaluation looks like our expectation; the default value is the original
    value. This is a coincidence. The second evaluation, after changing the global
    variable, `number`, shows that the function definition has a fixed value for the
    default – the variable is not re-evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this work, we''ll often use `None` as a default value and assign the
    current value of a global variable within the body of the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This `better_function()` does not have a value for the `number` variable bound
    into the function definition. It uses the current value of a global `number` variable.
    Yes, this function is implicitly dependent on a global variable, and the docstring
    should explain that, ideally surrounded by flame emojis to make it clear to anyone
    reading it how the function's results may not be obviously idempotent.
  prefs: []
  type: TYPE_NORMAL
- en: 'A slightly more compact way to set a parameter value to an argument or a default
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The `number if x is None else x` expression seems to make it clear that `x`
    will have the value of the global, `number`, or the argument value provided for
    `x`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The "evaluation at definition time" can trip us up when working with mutable
    containers such as lists, sets, and dictionaries. It seems like a good design
    decision to make an empty list (or set or dictionary) as a default value for a
    parameter. We shouldn''t do this because it will create only one instance of the
    mutable object, when the code is first constructed. This one object will be reused,
    demonstrated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This is very bad design. We can try to create a history list, `h`, and append
    things to it. This seems to work. Spoiler alert: the default object is one specific
    mutable, `list`, that''s shared:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Whoops, that''s not quite what we expected! When we tried to create a second
    history list, `h2`, it was based on the one and only default value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The usual way to get around this is to make the default value `None`. We''ve
    seen this in previous examples, and this is a common approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This will build a fresh, empty `list[str]` object if no parameter was supplied.
    This is the best way to work with default values that are also mutable objects.
  prefs: []
  type: TYPE_NORMAL
- en: Variable argument lists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Default values alone do not allow us all the flexibility we might want. One
    thing that makes Python really slick is the ability to write methods that accept
    an arbitrary number of positional or keyword arguments without explicitly naming
    them. We can also pass arbitrary lists and dictionaries into such functions. In
    other languages, these are sometimes called variadic arguments, **varargs**.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we could write a function to accept a link or list of URLs and
    download the web pages. The idea is to avoid the confusing-looking overhead of
    a singleton list when we only want one page downloaded. Instead of accepting a
    single value with a list of URLs, we can accept an arbitrary number of arguments,
    where each argument is a URL. We do this by defining one positional parameter
    to receive all the argument values. This parameter has to be last (among the positional
    parameters), and we''ll decorate it with a `*` in the function definition, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The `*` in the `*links` parameter says, *I''ll accept any number of arguments
    and put them all in a tuple named* `links`. If we supply only one argument, it
    will be a list with one element; if we supply no arguments, it will be an empty
    list. Thus, all these function calls are valid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that our type hint suggested that all of the positional argument values
    are of the same type, `str`, in this example. This is a widespread expectation:
    the variable parameters feature is little more than syntactic sugar, saving us
    from writing a dumb-looking list. The alternative to one type for the variable
    parameter tuple is potentially confusing: why write a function expecting a complex
    collection of distinct types, but – somehow – not state this in the parameter
    definitions? Don''t write that function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also accept arbitrary keyword arguments. These arrive in the function
    as a dictionary. They are specified with two asterisks (as in `**kwargs`) in the
    function declaration. This tool is commonly used in configuration setups. The
    following class allows us to specify a set of options with default values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This class leverages a feature of the `__init__()` method. We have a dictionary
    of default options, with the boring name of `default_options`, defined as part
    of the class. The `__init__()` method starts initializing this instance with the
    values from the class-level dictionary of defaults. We do that instead of modifying
    the dictionary directly, in case we instantiate two separate sets of options.
    (Remember, class-level variables are shared among all instances of the class.)
  prefs: []
  type: TYPE_NORMAL
- en: After having seeded the instance from the class-level source data, `__init__()` uses
    the `update()` method inherited from the superclass to change any non-default
    values to those supplied as keyword arguments. Because the value of `kwargs` is
    also a dictionary, the `update()` method handles the merge of default values with
    override values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a session demonstrating the class in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: We're able to access our `options` instance using dictionary indexing syntax.
    The `Options` dictionary includes both default values and the ones we set using
    keyword arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the parent class is `typing.Dict[str, Any]`, the class for a generic
    dictionary limited to strings for keys. When we initialize the `default_options`
    object, we can rely on the `from __future__ import annotations` statement and
    use `dict[str, Any]` to tell the **mypy** tool what to expect for this variable.
    The distinction is important: the class relies on `typing.Dict` as a superclass.'
  prefs: []
  type: TYPE_NORMAL
- en: The variable needs a type hint, and we can use either the `typing.Dict` class
    or we can use the built-in `dict` class. We suggest using the `typing` module
    only when absolutely required, and using the built-in classes as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, it's possible to pass arbitrary keyword arguments
    to the `Options` initializer to represent options that don't exist in the default
    dictionary. This can be handy when adding new features to an application. This
    can be bad when debugging a spelling mistake. Providing the "Port" option instead
    of the "port" option will lead to two similar-looking options where only one should
    have existed.
  prefs: []
  type: TYPE_NORMAL
- en: One way to limit the risk of spelling mistakes is to write an `update()` method
    that only replaces existing keys. This can prevent misspellings from creating
    problems. The solution is interesting and we'll leave it as an exercise for the
    reader.
  prefs: []
  type: TYPE_NORMAL
- en: Keyword arguments are also very useful when we need to accept arbitrary arguments
    to pass to a second function, but we don't know what those arguments will be.
    We saw this in action in *Chapter 3*, *When Objects Are Alike*, when we were building
    support for multiple inheritance.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can, of course, combine the variable argument and variable keyword argument
    syntax in one function call, and we can use normal positional and default arguments
    as well. The following example is somewhat contrived, but demonstrates the four
    types of parameters in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This example processes an arbitrary list of directory paths to run the **doctest**
    tool on markdown files in those directories. Let''s look at each parameter definition
    in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: The first parameter, `output`, is an open file to which output will be written.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `directories` parameter will be given all non-keyword arguments. These should
    all be `Path()` objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The keyword-only parameter, `verbose`, tells us whether to print information
    on each file processed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we can supply any other keyword as the name of a file to process specially.
    Four names – output, directories, verbose, and stems – are effectively special
    filenames that can't be given special processing. Any other keyword argument will
    be collected into the `stems` dictionary, and these names will be singled out
    for special processing. Specifically, if a file stem is listed with a value of
    `"SKIP"`, the file won't be tested. If there's a value of `"ellipsis"`, then a
    special option flag will be provided to doctest.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We create an inner helper function, `log()`, which will print messages only
    if the `verbose` parameter has been set. This function keeps code readable by
    encapsulating this functionality in a single location.
  prefs: []
  type: TYPE_NORMAL
- en: The outermost `with` statement redirects all output normally sent to `sys.stdout`
    to the desired file. This lets us collect a single log from `print()` functions.
    The `for` statement examines all the positional argument values collected into
    the `directories` parameter. Each directory is examined with the `glob()` method
    to locate all `*.md` files in any subdirectory.
  prefs: []
  type: TYPE_NORMAL
- en: A file's *stem* is the name without its path or suffix. So `ch_03/docs/examples.md`
    has a stem of `examples`. If the stem was used as a keyword argument, the value
    of that argument provides additional details of what to do for files with that
    specific stem. For example, if we provide the keyword argument `examples='SKIP'`,
    this will populate the `**stems` dictionary, and any file with a stem of `examples`
    will be skipped.
  prefs: []
  type: TYPE_NORMAL
- en: We use `subprocess.run()` because of the way doctest works out the local directory.
    When we want to run doctest in a number of different directories, it seems easiest
    to be sure that the current working directory (`cwd`) is set first, before we
    run doctest.
  prefs: []
  type: TYPE_NORMAL
- en: 'In common cases, this function could be called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This command would locate all the `*.md` files in these two directories and
    run doctest. The output would appear on the console because we redirected `sys.stdout`
    back to `sys.stdout`. Very little output would be produced because the `verbose`
    parameter would have a default value of `False`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to collect detailed output, we can call it with the help of the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This tests files in two directories and tells us what it's doing. Notice that
    it is impossible to specify `verbose` as a positional argument in this example;
    we must pass this as a keyword argument. Otherwise, Python would think it was
    another `Path` in the `*directories` list.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to change the processing for a selected set of files in the list,
    we can pass additional keyword arguments, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This will test two directories, but won't display any output, since we didn't
    specify `verbose`. This will apply the `doctest --ellipsis` option to any file
    with a step of `examples`. Similarly, any file with a stem of `examples_38`, `case_study_2`,
    or `case_study_3`, are skipped.
  prefs: []
  type: TYPE_NORMAL
- en: Because we can provide any name we choose, and they will all be collected into
    the value of the `stems` parameter, we can make use of this flexibility to match
    names of files in the directory structures. There are, of course, a number of
    limitations on Python identifiers that don't match operating system filenames,
    making this less than perfect. It does, however, show the amazing flexibility
    of Python function arguments.
  prefs: []
  type: TYPE_NORMAL
- en: Unpacking arguments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There''s one more nifty trick involving positional and keyword parameters.
    We''ve used it in some of our previous examples, but it''s never too late for
    an explanation. Given a list or dictionary of values, we can pass a sequence of
    values into a function as if they were normal positional or keyword arguments.
    Have a look at this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The function accepts three parameters, one of which has a default value. But
    when we have a list of three argument values, we can use the `*` operator inside
    a function call to unpack it into the three arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s what it looks like when we run it with `*some_args` to provide a three-element
    iterable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The value of `*some_args` has to match the positional parameter definition.
    Because there's a default value for `arg3`, making it optional, we can provide
    two or three values.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we have a dictionary of arguments, we can use the `**` syntax to unpack
    a dictionary to supply argument values for keyword parameters. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This is often useful when mapping information that has been collected from user
    input or from an outside source (for example, an internet page or a text file)
    and needs to be provided to a function or method call. Rather than decompose an
    external source of data into individual keyword parameters, we simply provide
    the keyword parameters from the dictionary keys. An expression like `show_args(arg1=more_args['arg1'],
    arg2=more_args['arg2'])` seems an error-prone way to match a parameter name with
    the dictionary key.
  prefs: []
  type: TYPE_NORMAL
- en: 'This unpacking syntax can be used in some areas outside of function calls,
    too. The `Options` class shown in the *Variable argument lists* section, earlier
    in this chapter, had an `__init__()` method that looked like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'An even more succinct way to do this would be to unpack the two dictionaries
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The expression `{**self.default_options, **kwargs}` merges dictionaries by
    unpacking each dictionary into keyword arguments and then assembling a final dictionary
    from them. Because the dictionaries are unpacked in order from left to right,
    the resulting dictionary will contain all the default options, with any of the
    `kwarg` options replacing some of the keys. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: This dictionary unpacking is a handy consequence of the way the `**` operator
    transforms a dictionary into named parameters for a function call.
  prefs: []
  type: TYPE_NORMAL
- en: After looking at sophisticated ways we can provide argument values to functions,
    we need to look at functions a little more broadly. Python considers functions
    as one kind of "callable" object. This means functions are objects, and higher-order
    functions can accept functions as argument values and return functions as results.
  prefs: []
  type: TYPE_NORMAL
- en: Functions are objects, too
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are numerous situations where we'd like to pass around a small object
    that is simply called to perform an action. In essence, we'd like an object that
    is a callable function. This is most frequently done in event-driven programming,
    such as graphical toolkits or asynchronous servers; we'll see some design patterns
    that use it in *Chapter 11*, *Common Design Patterns*, and *Chapter 12*, *Advanced Design
    Patterns*.
  prefs: []
  type: TYPE_NORMAL
- en: In Python, we don't need to wrap such methods in a class definition because
    functions are already objects! We can set attributes on functions (though this
    isn't a common activity), and we can pass them around to be called at a later
    date. They even have a few special properties that can be accessed directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s yet another contrived example, sometimes used as an interview question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The `fizz()` and `buzz()` functions check to see whether their parameter, `x`,
    is an exact multiple of another number. This relies on the definition of the modulo
    operator: if *x* is a multiple of 3, then 3 divides *x* with no remainder. Sometimes
    they say ![](img/B17070_08_001.png) in the math books. In Python, we say `x %
    3 == 0`.'
  prefs: []
  type: TYPE_NORMAL
- en: The `name_or_number()` function uses any number of test functions, provided
    as the `tests` parameter value. The `for` statement assigns each function in the
    `tests` collection to a variable, `t`, then evaluates the variable with the number
    parameter's value. If the function's value is true, then the result is the function's
    name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how this function looks when we apply it to a number and another function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: In each case, the value of the `tests` parameter is `(fizz,)` a tuple that contains
    only the `fizz` function. The `name_or_number()` function evaluates `t(number)`,
    where `t` is the `fizz()` function. When `fizz(number)` is true, the value returned
    is the value of the function's `__name__` attribute – the `'fizz'` string. Function
    names are available at runtime as an attribute of the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we provide multiple functions? Each is applied to the number until
    one is true:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This is, by the way, not completely correct. What should happen for a number
    like 15? Is it `fizz` or `buzz` or both? Because it's both, some work needs to
    be done in the `name_or_number()` function to collect **all** the names of all
    the true functions. That sounds like it would make a good exercise.
  prefs: []
  type: TYPE_NORMAL
- en: We can add to our list of special functions. We might define `bazz()` to be
    true for multiples of seven. This, too, sounds like a good exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run this code, we can see that we were able to pass two different functions
    into our `name_or_number()` function, and get different output for each one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: We could apply our functions to an argument value using `t(number)`. We were
    able to get the value of the function's `__name__` attribute using `t.__name__`.
  prefs: []
  type: TYPE_NORMAL
- en: Function objects and callbacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The fact that functions are top-level objects is most often used to pass them
    around to be executed at a later date, for example, when a certain condition has
    been satisfied. Callbacks are common as part of building a user interface: when
    the user clicks on something, the framework can call a function so the application
    code can create a visual response. For very long-running tasks, like file transfers,
    it is often helpful for the transfer library to call back to the application with
    status on the number of bytes transferred so far – this makes it possible to display
    status thermometers to show status.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s build an event-driven timer using callbacks so that things will happen
    at scheduled intervals. This can be handy for an **IoT** (**Internet of Things**)
    application built on a small CircuitPython or MicroPython device. We''ll break
    this down into two parts: a task, and a scheduler that executes the function object
    stored in the task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The `Task` class definition has two mandatory fields and two optional fields.
    The mandatory fields, `scheduled` and `callback`, provide a scheduled time to
    do something and a callback function, the thing to be done at the scheduled time.
    The scheduled time has an `int` type hint; the time module can use floating-point
    time, for super-accurate operations. We're going to ignore these details. Also,
    the **mypy** tool is well aware that integers can be coerced to floating-point
    numbers, so we don't have to be super-fussy-precise about numeric types.
  prefs: []
  type: TYPE_NORMAL
- en: 'The callback has a hint of `Callable[[int], None]`. This summarizes what the
    function definition should look like. A callback function definition should look
    like `def some_name(an_arg: int) -> None:`. If it doesn''t match, **mypy** will
    alert us to the potential mismatch between our callback function definition and
    the contract specified by the type hint.'
  prefs: []
  type: TYPE_NORMAL
- en: The `repeat()` method can return a task for those tasks that might repeat. It
    computes a new time for the task, provides the reference to the original function
    object, and may provide a subsequent delay and a changed limit. The changed limit
    will count the number of repetitions toward zero, giving us a defined upper limit
    on processing; it's always nice to be sure that iteration will terminate.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `# type: ignore [misc]` comments are there because there''s a feature here
    that''s confusing to **mypy**. When we use code like `self.callback` or `someTask.callback()`,
    it looks like an ordinary method. The code in the `Scheduler` class is not going
    to use it as an ordinary method; it will be used as a reference to a separate
    function defined entirely outside of the class. The assumption wired into Python
    is this: a `Callable` attribute must be a method, and that means the method must
    have a "`self`" variable. In this case, the callable object is a separate function.
    The easiest way to refute the assumption is by silencing **mypy**''s checking
    of this line of code. An alternative is to assign `self.callback` to another non-`self`
    variable to make it look like it''s an external function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the overall `Scheduler` class that uses these `Task` objects and their
    associated callback functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The central feature of the `Scheduler` class is a heap queue, a `List` of `Task`
    objects kept in a specific order. We mentioned the heap queue in the *Three types
    of queues* section of *Chapter 7*, *Python Data Structures*, noting that the priority
    ordering made it inappropriate for that use case. Here, however, the heap data
    structure makes use of the flexibility of a list to keep items in order without
    the overhead of a complete sort of the entire list. In this case, we want to keep
    items in order by the time they''re required to be executed: "first things first"
    order. When we push something to a heap queue, it''s inserted so the time order
    will be maintained. When we pop the next thing from the queue, the heap may be
    adjusted to keep the first things at the front of the queue.'
  prefs: []
  type: TYPE_NORMAL
- en: The `Scheduler` class provides an `enter()` method to add a new task to the
    queue. This method accepts a `delay` parameter representing the interval to wait
    before executing the callback task, and the `task` function itself, a function
    to be executed at the correct time. This `task` function should fit the type hint
    of `Callback`, defined above.
  prefs: []
  type: TYPE_NORMAL
- en: There are no runtime checks to ensure the callback function really does meet
    the type hint. It's only checked by **mypy**. More importantly, the `after`, `delay`,
    and `limit` parameters should have some validation checks. For example, a negative
    value of `after` or `delay` should raise a `ValueError` exception. There's a special
    method name, `__post_init__()`, that a dataclass can use for validation. This
    is invoked after `__init__()` and can be used for other initialization, pre-computing
    derived values, or validating that the combination of values is sensible.
  prefs: []
  type: TYPE_NORMAL
- en: The `run()` method removes items from the queue in order by the time they're
    supposed to be performed. If we're at (or past) the required time, then the value
    computed for `delay` will be zero or negative, and we don't need to wait; we can
    perform the callback immediately. If we're before the required time, then we need
    to sleep until the time arrives.
  prefs: []
  type: TYPE_NORMAL
- en: At the appointed time, we'll update our current time in the `current_time` variable.
    We'll call the callback function provided in the `Task` object. And then we'll
    see if the `Task` object's `repeat()` method will provide another repeat task
    into the queue.
  prefs: []
  type: TYPE_NORMAL
- en: The important things to note here are the lines that touch callback functions.
    The function is passed around like any other object and the `Scheduler` and `Task`
    classes never know or care what the original name of the function is or where
    it was defined. When it's time to call the function, the `Scheduler` simply evaluates
    the function with `new_task.callback(current_time)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a set of callback functions that test the `Scheduler` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: These functions all meet the definition of the `Callback` type hint, so they'll
    work nicely. The `Repeater` class definition has a method, `four()`, that meets
    the definition. That means an instance of `Repeater` can also be used.
  prefs: []
  type: TYPE_NORMAL
- en: We've defined a handy utility function, `format_time()`, to write common messages.
    It uses the format string syntax to add the current time to the message. The three
    small callback functions output the current time and a short message telling us
    which of the callbacks has been fired.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of creating a scheduler and loading it up with callback
    functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: This example allows us to see how multiple callbacks interact with the timer.
  prefs: []
  type: TYPE_NORMAL
- en: The `Repeater` class demonstrates that methods can be used as callbacks too,
    since they are really functions that happen to be bound to an object. Using a
    method of an instance of the `Repeater` class is a function like any other.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output shows that events are run in the expected order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Note that some events have the same scheduled run time. Scheduled after 2 seconds,
    for example, both callback functions `one()` and `two()` are defined. They both
    ran at 01:44:36\. There's no rule to decide how to resolve the tie between these
    two functions. The scheduler's algorithm is to pop an item from the heap queue,
    execute the callback function, then pop another item from the heap queue; if it
    has the same execution time, then evaluate the next callback function. Which of
    the two callbacks is performed first and which is done second is an implementation
    detail of the heap queue. If order matters to your application, you'll need an
    additional attribute to distinguish among items scheduled at the same time; a
    priority number is often used for this.
  prefs: []
  type: TYPE_NORMAL
- en: Because Python is a dynamic language, the contents of a class are not fixed.
    There are some more advanced programming techniques available to us. In the next
    section, we'll look at changing the methods of a class.
  prefs: []
  type: TYPE_NORMAL
- en: Using functions to patch a class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the things we noted in the previous example was that **mypy** assumed
    that the `Callable` attribute, `callback`, was a method of the `Task` class. This
    leads to a potentially confusing **mypy** error message, `Invalid self argument
    "Task" to attribute function "callback" with type "Callable[[int], None]"`. In
    the previous example, the callable attribute was emphatically not a method.
  prefs: []
  type: TYPE_NORMAL
- en: The presence of the confusion means that a callable attribute can be treated
    as a method of a class. Since we can generally supply extra methods to a class,
    it means we can patch in additional methods at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Does it mean we **should** do this? It's perhaps a bad idea, except in a very
    special situation.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible to add or change a function to an instantiated object, demonstrated
    as follows. First we''ll define a class, `A`, with a method, `show_something()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'This looks like what we''d expect. We invoke the method on an instance of the
    class and see the results of the `print()` function. Now, let''s patch this object,
    replacing the `show_something()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: We've patched the object introducing an attribute that's a callable function.
    When we use `a_object.show_something()`, the rule is to look in local attributes
    first, then look in class attributes. Because of this, we've used a callable attribute
    to create a localized patch to this instance of the `A` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create another instance of the class, unpatched, and see that it''s
    still using the class-level method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: If we can patch an object, you'd think we can also patch the class. We can.
    It is possible to replace methods on classes instead of objects. If we change
    the class, we have to account for the `self` argument that will be implicitly
    provided to methods defined in the class.
  prefs: []
  type: TYPE_NORMAL
- en: It's very important to note that patching a class will change the method for
    all instances of that object, even ones that have already been instantiated. Obviously,
    replacing methods like this can be both dangerous and confusing to maintain. Somebody
    reading the code will see that a method has been called and look up that method
    on the original class. But the method on the original class is not the one that
    was called. Figuring out what really happened can become a tricky, frustrating
    debugging session.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s a cardinal assumption that needs to underpin everything we write.
    It''s a kind of contract that is essential to understanding how software works:'
  prefs: []
  type: TYPE_NORMAL
- en: The code people see in a module file must be the code that is running.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking this assumption will really confuse people. Our previous example showed
    an instance of class `A` that had a method named `show_something()` with behavior
    clearly different to the definition for class `A`. That's going to be lead people
    to distrust your application software.
  prefs: []
  type: TYPE_NORMAL
- en: This technique does have its uses though. Often, replacing or adding methods
    at runtime (called **monkey patching**) is used in automated testing. If testing
    a client-server application, we may not want to actually connect to the server
    while testing the client; this may result in accidental transfers of funds or
    embarrassing test emails being sent to real people.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we can set up our test code to replace some of the key methods on the
    object that sends requests to the server so that it only records that the methods
    have been called. We'll cover this in detail in *Chapter 13*, *Testing Object-Oriented
    Programs*. Outside the narrow realm of testing, monkey patching is generally a
    sign of bad design.
  prefs: []
  type: TYPE_NORMAL
- en: This is sometimes justified as part of a bug fix for imported components. If
    this is done, the patch needs to be clearly flagged so anyone looking at the code
    knows what bug is being worked around and when the fix can be removed. We call
    this kind of code *tech debt*, because the complication of using a monkey patch
    is a liability.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of our class in this example, a subclass of `A` with a distinct
    implementation of `show_something()` would make things much more clear than a
    patched method.
  prefs: []
  type: TYPE_NORMAL
- en: We can use class definitions to create objects that are usable as if they were
    functions. This gives us another path toward using small, separate functions to
    build applications.
  prefs: []
  type: TYPE_NORMAL
- en: Callable objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just as functions are objects that can have attributes set on them, it is possible
    to create an object that can be called as though it were a function. Any object
    can be made callable by giving it a `__call__()` method that accepts the required
    arguments. Let''s make our `Repeater` class, from the timer example, a little
    easier to use by making it a callable, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'This example isn''t much different from the earlier class; all we did was change
    the name of the `repeater` function to `__call__` and pass the object itself as
    a callable. How does this work? We can do the following interactively to see an
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we''ve created a callable object, `rpt()`. When we evaluate
    something like `rpt(1)`, Python will evaluate `rpt.__call__(1)` for us because
    there''s a `__call__()` method defined. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s an example of using this variation on the `Repeater_2` class definition
    with a `Scheduler` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Note that, when we make the `enter()` call, we pass as an argument the value `Repeater_2()`.
    Those two parentheses are creating a new instance of the class. The instance that
    is created has the `__call__()` method, which can be used by the `Scheduler`.
    When working with callable objects, it's essential to create an instance of a class;
    it's the object that's callable, not the class.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we''ve seen two different kinds of callable objects:'
  prefs: []
  type: TYPE_NORMAL
- en: Python's functions, built with the `def` statement.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Callable objects. These are instances of a class with the `__call__()` method
    defined.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generally, the simple `def` statement is all we need. Callable objects, however,
    can do something an ordinary function can't do. Our `Repeater_2` class counts
    the number of times it was used. An ordinary function is stateless. A callable
    object can be stateful. This needs to be used with some care, but some algorithms
    can have a dramatic performance improvement from saving results in a cache, and
    a callable object is a great way to save results from a function so they don't
    need to be recomputed.
  prefs: []
  type: TYPE_NORMAL
- en: File I/O
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our examples so far that have touched the filesystem have operated entirely
    on text files without much thought as to what is going on under the hood. Operating
    systems represent files as a sequence of bytes, not text. We'll take a deep dive
    into the relationship between bytes and text in *Chapter 9*, *Strings, Serialization,
    and File Paths*. For now, be aware that reading textual data from a file is a
    fairly involved process, but Python takes care of most of the work for us behind
    the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of files has been around since long before anyone coined the term *object-oriented
    programming*. However, Python has wrapped the interface that operating systems
    provide in a sweet abstraction that allows us to work with file (or file-like,
    vis-à-vis duck typing) objects.
  prefs: []
  type: TYPE_NORMAL
- en: The confusion arises because the operating system file and the Python file object
    are both, commonly, called "files." It's difficult to be ultra-cautious and wrap
    each reference to the term *file* with appropriate context to distinguish bytes
    on a disk from the OS libraries for accessing those bytes from the Python file
    object that wraps the OS libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Python's `open()` built-in function is used to open the OS file and return a
    Python file object. For reading text from a file, we only need to pass the name
    of the file into the function. The OS file will be opened for reading, and the
    bytes will be converted to text using the platform's default encoding.
  prefs: []
  type: TYPE_NORMAL
- en: A file "name" can be a name relative to the current working directory. It can
    also be an absolute name, beginning from the root of the directory tree. A file's
    name is the tail end of a path to the file from the root of the filesystem. The
    root in a Linux-based filesystem is "`/`". In Windows, there's a filesystem on
    each device, so we use a more complex name like "`C:\`". While Windows uses `\`
    for separating elements of the file path, Python's `pathlib` uses "`/`" consistently,
    converting the string to the OS-specific names when needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, we don''t always want to *read* files; often we want to *write*
    data to them! To open a file for writing, we need to pass a `mode` argument as
    the second positional argument to `open()`, with a value of `"w"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: We could also supply the value `"a"` as a mode argument, to *append* to the
    end of the file, rather than completely overwriting existing file content.
  prefs: []
  type: TYPE_NORMAL
- en: These files with built-in wrappers for converting bytes to text are great, but
    it'd be awfully inconvenient if the file we wanted to open was an image, executable,
    or other binary file, wouldn't it?
  prefs: []
  type: TYPE_NORMAL
- en: To open a binary file, we modify the mode string to append `"b"`. So, `"wb"` would
    open a file for writing bytes, while `"rb"` allows us to read them. They will
    behave like text files, but without the automatic encoding of text to bytes. When
    we read such a file, it will return `bytes` objects instead of `str`, and when
    we write to it, it will fail if we try to pass a text object.
  prefs: []
  type: TYPE_NORMAL
- en: These mode strings for controlling how files are opened are rather cryptic and
    are neither Pythonic nor object-oriented. However, they are consistent with virtually
    every other programming language out there because they are based on the venerable
    standard I/O library. File I/O is one of the fundamental jobs an operating system
    has to handle, and all programming languages have to talk to the operating system using
    the same system calls.
  prefs: []
  type: TYPE_NORMAL
- en: Since all files are actually bytes, it's important to be aware that reading
    text means that the bytes are converted to text characters. Most operating systems
    use an encoding called UTF-8 to represent the Unicode characters Python uses as
    bytes. In some cases, other encodings might be used, and we may have to provide
    an `encoding='cp1252'` argument value when opening a text file that uses an uncommon
    encoding.
  prefs: []
  type: TYPE_NORMAL
- en: Once a file is opened for reading, we can call any of the `read()`, `readline()`,
    or `readlines()` methods to get the contents of the file. The `read()` method
    returns the entire contents of the file as a `str` or `bytes` object, depending
    on whether there is `"b"` in the mode. Be careful not to use this method without
    arguments on huge files. You don't want to find out what happens if you try to
    load that much data into memory!
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible to read a fixed number of bytes from a file; we pass an
    integer argument to the `read()` method, describing how many bytes we want to
    read. The next call to `read()` will load the next sequence of bytes, and so on.
    We can do this inside a `while` statement to read the entire file in manageable
    chunks.
  prefs: []
  type: TYPE_NORMAL
- en: Some file formats define neatly bounded chunks for us. The logging module can
    transmit log objects as bytes. A process reading those bytes must first read four
    bytes to determine the size of the log message. The size value defines how many
    more bytes must be read to gather a single, complete message.
  prefs: []
  type: TYPE_NORMAL
- en: The `readline()` method returns a single line from the file (where each line
    ends in a newline, a carriage return, or both, depending on the operating system
    on which the file was created). We can call it repeatedly to get additional lines.
    The plural `readlines()` method returns a list of all the lines in the file. Like
    the `read()` method, it's not safe to use on very large files. These two methods
    even work when the file is open in `bytes` mode, but it only makes sense if we
    are parsing text-like data that has newlines at reasonable positions. An image
    or audio file, for example, will not have newline characters in it (unless the
    newline byte happened to represent a certain pixel or sound), so applying `readline()` wouldn't
    make sense.
  prefs: []
  type: TYPE_NORMAL
- en: For readability, and to avoid reading a large file into memory at once, it is
    often better to use a `for` statement to consume lines from a file object. For
    text files, it will read each line, one at a time, and we can process it inside
    the `for` statement. For binary files, this will also work, but it's often unlikely
    that the binary file adheres to text file rules. For binary files, it's better
    to read fixed-sized chunks of data using the `read()` method, passing a parameter
    for the maximum number of bytes to read.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reading a file might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Writing to a file is just as easy; the `write()` method on file objects writes
    a string (or bytes, for binary data) object to the file. It can be called repeatedly
    to write multiple strings, one after the other. The `writelines()` method accepts
    a sequence of strings and writes each of the iterated values to the file. The `writelines()` method
    does *not* append a new line after each item in the sequence. It is basically
    a poorly named convenience function to write the contents of a sequence of strings
    without having to explicitly iterate over it using a `for` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing to a file might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: The explicit newline characters, `\n`, are required to create line breaks in
    the file. Only the `print()` function adds newlines automatically. Because the
    `open()` function is built-in, there are no imports required for simple file input
    and output operations.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, and we do mean lastly, we come to the `close()` method. This method
    should be called when we are finished reading or writing the file, to ensure any
    buffered writes are written to the disk, that the file has been properly cleaned
    up, and that all resources associated with the file are released back to the operating
    system. It's very important to be explicit and clean up after ourselves, especially
    in long-running processes like web servers.
  prefs: []
  type: TYPE_NORMAL
- en: Each open file is a context manager, usable by the `with` statement. If we use
    files like this, the `close()` happens automatically at the end of the context.
    We'll look closely at using context managers to control the OS resources in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Placing it in context
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The need to close files when we are finished with them can make our code quite
    ugly. Because an exception may occur at any time during file I/O, we ought to
    wrap all calls to a file in a `try...finally` clause. The file should be closed
    in the `finally` clause, regardless of whether I/O was successful. This isn't
    very Pythonic. Of course, there is a more elegant way to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Python's file objects are also **context managers**. By using the `with` statement,
    the context management methods ensure that the file is closed, even if an exception
    is raised. By using the `with` statement, we no longer have to explicitly manage
    the closing of the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what a file-oriented `with` statement looks like in practice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: The `open` method of a `Path` object returns a file object, which has `__enter__()`
    and `__exit__()` methods. The returned object is assigned to the variable named
    `source_file` by the `as` clause. We know the file will be closed when the code
    returns to the outer indentation level, and that this will happen even if an exception
    is raised. (We'll look at `Path` objects in more detail in *Chapter 9*, *Strings*,
    *Serialization*, *and File Paths*. For now, we'll use them to open our files.)
  prefs: []
  type: TYPE_NORMAL
- en: The `with` statement is used widely, often where startup and cleanup code need
    to be connected in spite of anything that might go wrong. For example, the `urlopen` call
    returns a context object that can be used in a `with` statement to clean up the
    socket when we're done. Locks in the `threading` module can automatically release
    the lock after the body of the `with` statement has been executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most interestingly, because any object that has the appropriate special methods
    can be a context manager, used by the `with` statement, we can use it in our own
    frameworks. For example, remember that strings are immutable, but sometimes you
    need to build a string from multiple parts. For efficiency, this is usually done
    by storing the component strings in a list and joining them at the end. Let''s
    extend the list class to create a simple context manager that allows us to construct
    a sequence of characters and automatically convert it to a string upon exit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: This code adds the two special methods required of a context manager to the `list` class
    it inherits from. The `__enter__()` method performs any required setup code (in
    this case, there isn't any) and then returns the object that will be assigned
    to the variable after `as` in the `with` statement. Often, as we've done here,
    this is the context manager object itself. The `__exit__()` method accepts three
    arguments. In a normal situation, these are all given a value of `None`. However,
    if an exception occurs inside the `with` block, they will be set to values related
    to the type, value, and traceback for the exception. This allows the `__exit__()` method
    to perform any cleanup code that may be required, even if an exception occurred.
    In our example, we create a result string by joining the characters in the string,
    regardless of whether an exception was thrown. In some cases, it may be necessary
    to do more sophisticated cleanup to respond to the exceptional condition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Formally, the type hints look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we''ve defined `__exit__()` to always return `False`. A return value
    of `False` makes sure any exception that is raised in the context will be seen.
    This is the typical behavior. We can, however, silence the exceptions raised by
    returning `True`. This means changing the type hint from `Literal[False]` to `bool`
    and – of course – examining the exception details to see if it should be silenced.
    We might, for example, check `exc_type` to see if it is `StopIteration`, like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: This will silence only `StopIteration` exceptions, and allow all others to propagate
    outside the context. For a refresher on exceptions, refer back to *Chapter 4*,
    *Expecting the Unexpected*.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this is one of the simplest context managers we could write, and its
    usefulness is dubious, it does work with a `with` statement. Have a look at it
    in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'This code constructs a string by appending and extending an initial list of
    characters. When the `with` statement finishes the indented statements of the
    context, the `__exit__()` method is called, and the `result` attribute becomes
    available on the `StringJoiner` object, `sj`. We then print this value to see
    the resulting string. Note that the `__exit__()` is always executed, even if there''s
    an exception. The following example raises an exception inside the context, and
    the final result is still built:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The division by zero raised an exception. The statement appending this to the
    `sj` variable failed, and the remaining statements within the context aren't executed.
    The context's `__exit__()` method is executed, with details of the exception.
    The `__exit__()` method computed the `result` attribute, and allowed the exception
    to propagate. The `sj` variable has the partial result.
  prefs: []
  type: TYPE_NORMAL
- en: We can also build a context manager from a simple function. This relies on a
    feature of an iterator, something we'll look at deeply in *Chapter 10*, *The Iterator
    Pattern*. For now, it's enough to know that the `yield` statement produces the
    first result of a sequence of results. Because of the way iterators work in Python,
    we can write a function that has the `__enter__()` processing and the `__exit__()`
    processing separated by a single `yield` statement.
  prefs: []
  type: TYPE_NORMAL
- en: The example of a string joiner is a stateful context manager, and using a function
    can cleanly separate the state-changing object from the context manager that makes
    the state change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a revised "`string joiner`" object that implements part of the work.
    It contains the strings and also the final result attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Separate from this is a context manager that has some steps for entering the
    context and exiting it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: The steps prior to the `yield` are performed on entry into the context. The
    expression in the `yield` statement is assigned to the `as` variable in the `with`
    statement. When the context finishes normally, the code after the `yield` is processed.
    The `try:` statement's `finally:` clause will make sure that the final result
    attribute is always set, irrespective of the presence of an exception. Since the
    `try:` statement doesn't explicitly match any exceptions, it doesn't silence anything,
    and the exception will be visible outside the enclosing `with` statement. This
    behaves identically to the `StringJoiner` examples above; the only change is to
    replace `StringJoiner` – a class that is a context manager – with `joiner`.
  prefs: []
  type: TYPE_NORMAL
- en: The `@contextmanager` decorator is used to add some features around this function
    to make it work like a context manager class definition. This saves us from the
    overhead of a class that defines both `__enter__()` and `__exit__()` methods.
    In this case, the context management involves so few lines of code that a decorated
    function seems more appropriate than a longer and more complex-looking class.
  prefs: []
  type: TYPE_NORMAL
- en: Context managers can do many things. The reason why we cover them adjacent to
    simple file operations is because one of the important places we can use context
    managers is when opening files, databases, or network connections. Any place where
    external, operating system-managed resources are involved, we need a context manager
    to be sure that the external resources are properly released no matter what goes
    wrong in our application programming.
  prefs: []
  type: TYPE_NORMAL
- en: Any time we're working with a file, always wrap the processing in a `with` statement.
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While object-oriented programming is helpful for encapsulating features, it's
    not the only way to create flexible, expressive, and succinct application programs.
    Functional programming emphasizes functional design and function composition over
    object-oriented design.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, functional design often involves using a few object-oriented techniques.
    This is one of the beauties of Python: being able to choose an appropriate set
    of design tools to address the problem effectively.'
  prefs: []
  type: TYPE_NORMAL
- en: We often depict object-oriented designs with the classes and their various associations.
    For functional design, we're interested in functions to transform objects. A functional
    design can follow mathematical practices closely.
  prefs: []
  type: TYPE_NORMAL
- en: In this part of the case study, we'll revisit a number of features of the classifier
    as functions mixed with class definitions. We'll step away from a pure object-oriented
    view and adopt a hybrid view. In particular, we'll look closely at segregating
    data into a training set and a testing set.
  prefs: []
  type: TYPE_NORMAL
- en: Processing overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The initial analysis from *Chapter 1*, *Object-Oriented Design*, identified
    three distinct processes for gathering training data, testing the classifier,
    and actually doing classification. The context diagram looked like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17070_08_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.1: Context diagram'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can think of these as separate functions to build some collections of sample
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: A function based on the "Provide Training Data" use case would transform source
    data into two collections of samples, a training set and a testing set. We'd like
    to avoid placing items in the testing set that are exact matches for items in
    the training set, creating some constraints on this process. We can think of this
    as a mapping from a `KnownSample` to a `TestingKnownSample` or a `TrainingKnownSample`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A function based on the "Set Parameters and Test Classifier" use case would
    transform a `Hyperparameter` (the *k* value and the distance algorithm) and the
    testing set of samples into a quality score. We can think of this as a mapping
    from `TestingKnownSample` to a correct or incorrect classification, and a reduction
    to a single value showing the number correct out of the number of tests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A function based on the "Make Classification Request" use case would transform
    a `Hyperparameter` (the *k* value and the distance algorithm) and a single sample
    into a classification result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We'll look at each of these functions separately. We can build an alternative
    model for our application using these processing steps to define a functional
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In effect, splitting the data into two subsets can be defined around some filter
    functions. We'll avoid Python for a moment and focus on the conceptual math to
    make sure we have the logic completely correct before diving into code. Conceptually,
    we have a pair of functions, ![](img/B17070_08_002.png) and ![](img/B17070_08_003.png),
    that decide if a sample, ![](img/B17070_08_004.png), is for testing, *e*, or training,
    *r*. These functions are used to partition the samples into two subsets. (If testing
    and training didn't both begin with t, we'd have an easier time finding names.
    It might help to think about ![](img/B17070_08_005.png) for evaluation and testing,
    and ![](img/B17070_08_006.png) for running a real classification.)
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s simpler if these two functions are exclusive, ![](img/B17070_08_007.png).
    (We''ll use ¬ instead of the longer `not`.) If they are proper inverses of each
    other, this means we only need to define one of the two functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17070_08_008.png)![](img/B17070_08_009.png)'
  prefs: []
  type: TYPE_IMG
- en: If the above syntax is unfamiliar, it just means that the training set is all
    items, ![](img/B17070_08_010.png), from the source data, *S*, where ![](img/B17070_08_011.png)
    is true. The testing set is all the items from the source where ![](img/B17070_08_012.png)
    is false. This mathematical formalism can help make sure all the cases are properly
    covered.
  prefs: []
  type: TYPE_NORMAL
- en: 'This concept is a kind of "comprehension" or "builder" for a set of samples.
    We can translate the mathematical comprehension into a Python list comprehension
    in a fairly direct way. We''ll implement our conceptual function ![](img/B17070_08_013.png)
    as a Python function, `training()`. We''ll also expose the index value, *i*, as
    a separate parameter to this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'In *Chapter 10*, *The Iterator Pattern*, we''ll dive into this deeply. For
    now, it''s enough to see that the comprehensions have three parts: an expression,
    a `for` clause, and an `if` condition. The `for` clause provides the values, in
    effect the ![](img/B17070_08_014.png) portion of the formal statement. The `if` condition
    filters the values, in effect the ![](img/B17070_08_015.png) clause. The final
    expression, `s`, determines what is accumulated into the resulting list object.'
  prefs: []
  type: TYPE_NORMAL
- en: We've composed a `TrainingKnownSample` object as a wrapper around the source
    `KnownSample` instances. This leverages the composition-based design from *Chapter
    7*, *Python Data Structures*.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the index value to partition the data. The remainder after division,
    the modulo, can be used to break data into subsets. The value of `i % 5`, for
    example, is a value from 0 to 4\. If we use `i % 5 == 0` as test data, 20% of
    the values will be selected. When `i % 5 != 0`, this is the remaining 80% of the
    data that will be used for training.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a list comprehension without the `[]` wrapper. We''ve used
    the `list()` function to consume items from the generator and build a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: The processing with `[]` or `list()` is the same. Some folks like the clarity
    of `list()`, even though it's wordier than `[]`. If we create our own extension
    to the list class, it's slightly simpler to find `list(...)` than to find all
    the places where `[...]` is used and separate out the list builders from other
    uses of `[]`.
  prefs: []
  type: TYPE_NORMAL
- en: Rethinking classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In *Chapter 2*, *Objects in Python*, we wrestled with a number of ways of handling
    the state change that goes with classification. There are two similar processes,
    one for `KnownSample` objects that will be used for testing, and one for `UnknownSample`
    objects being classified by users. The process diagrams are simple-looking but
    conceal an important question.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the user''s classification of an unknown sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, schematic  Description automatically generated](img/B17070_08_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.2: UnknownSample classification process diagram'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can borrow this (with a few tiny class changes) and use it for testing.
    Here''s an approach to handling classification for test purposes that parallels
    the unknown sample process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, schematic  Description automatically generated](img/B17070_08_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: TestingKnownSample classification process diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, the same code can be used in both cases, reducing the overall complexity
    of the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we consider the different alternatives to the process view, this leads to
    changes in the logical view. Here''s a revised view, thinking of these classes
    as immutable compositions. We''ve included notes to suggest when these objects
    are created during application processing. We''ve highlighted two classes requiring
    careful consideration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17070_08_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.4: Revised logical view'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `TestingKnownSample` and the `TrainingKnownSample` classes have very minor
    differences. They don''t introduce new attributes or methods. Here are the differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '`TrainingKnownSample` instances are never used for classification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TestingKnownSample` and `UnknownSample` instances are used for classification
    and testing. We''ll create a `ClassifiedKnownSample` object from a `TestingKnownSample` object
    by repackaging the `KnownSample` instance into a new container. This creates a
    more consistent set of definitions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The idea is that the `classifier()` method of the `Hyperparameter` class should
    work with objects of two classes, summarized by the type hint `Union[TestingKnownSample,
    UnknownSample]`. This kind of hint can help us spot application code that uses
    the classes incorrectly.
  prefs: []
  type: TYPE_NORMAL
- en: This diagram seems to capture the ways in which these objects are used. Having
    these details available can lead to more detailed type hints that can be used
    to clarify our intent.
  prefs: []
  type: TYPE_NORMAL
- en: The partition() function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can define multiple versions of the `training()` function to divide our
    data into an 80/20, 75/25, or 67/33 split:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s a function, `partition()`, that takes one of the `training_xx()` functions
    as an argument. The `training_xx()` function is applied to a sample to decide
    if it''s training data or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: We've built a "higher-order" function that takes another function as an argument
    value. This is a very cool feature of functional programming that is an integral
    part of Python.
  prefs: []
  type: TYPE_NORMAL
- en: This `partition()` function builds two lists from a source of data and a function.
    This covers the simple case, where we don't care about introducing values into
    the `testing` list that are duplicates of values in the `training` list.
  prefs: []
  type: TYPE_NORMAL
- en: While this is pleasantly succinct and expressive, it has a hidden cost. We'd
    like to avoid examining the data twice. For the small set of known samples in
    this particular problem, the processing is not particularly costly. But we may
    have a generator expression creating the raw data in the first place. Since we
    can only consume a generator once, we'd like to avoid creating multiple copies
    of a large set of data.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we'd like to avoid assigning test values that happen to be exact matches
    for training values. This turns into a more complex problem. We'll defer this
    until *Chapter 10*, *The Iterator Pattern*.
  prefs: []
  type: TYPE_NORMAL
- en: One-pass partitioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can create multiple pools of samples in one pass through the data. There
    are several approaches; we'll show one that has simpler type hints. Again, this
    is a function, not a full class definition. The individual sample instances have
    distinct classes, but this process yields objects of distinct classes, and is
    a better fit for a functional style.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea is to create two empty list objects, one for training, the other for
    testing. We can then assign specific type hints to each list, and leverage **mypy** to
    be sure we are using the lists appropriately:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: In this `partition_1()` function, we've used the `rule` function to determine
    if the data will be used for training. We expect one of the `training_xx()` functions
    defined earlier in this case study to be provided as the argument for the `rule` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Based on this output, we can create an appropriate class for each sample instance,
    and then assign the sample to an appropriate list.
  prefs: []
  type: TYPE_NORMAL
- en: This example doesn't check for duplicates between testing samples and training
    samples. Some data scientists suggest we don't want any test samples that are
    exact matches for training samples; it biases the testing. We can see where that
    needed decision can be inserted between when the `training_use` variable is assigned
    and when the final appends are done to either list. If `training_use` is `False`
    and the item already exists in the training set, this item, too, must be used
    for training.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can refactor this algorithm slightly by performing the type conversions
    later in the process. This lets us create a dictionary of various "pools" of `KnownSample` objects
    based on the intended usage. So far, we only have two pools – training, where
    a `training_xx()` rule is `True`, and testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The `defaultdict` object, `pools`, will map Boolean values to `List[KnownSample]`
    objects. We provided the `list` function to set a default value when a key is
    accessed that did not previously exist. We only anticipate two keys, and this
    could also have been written as `pools: dict[bool, list[KnownSample]] = {True:
    [], False: []}`.'
  prefs: []
  type: TYPE_NORMAL
- en: The partitioning starts by creating a generator function to apply the given `rule` function
    to each sample. The result is a two-tuple; we could write an explicit type hint
    of `tuple[bool, KnownSample]`. This generator expression assigned to the partition
    `variable` is lazy, and doesn't compute anything until the values are consumed
    by the `for` statement.
  prefs: []
  type: TYPE_NORMAL
- en: The `for` statement consumes values from the generator, appending each sample
    to the appropriate pool. When values are consumed, the generator function is evaluated,
    producing a stream of two-tuples with the pool, a Boolean value, and the `KnownSample` instance.
  prefs: []
  type: TYPE_NORMAL
- en: Once the `KnownSample` objects have been partitioned, we can wrap them up as
    instances of the `TrainingKnownSample` class or the `TestingKnownSample` class.
    The type hints seem simpler in this example than in the previous version.
  prefs: []
  type: TYPE_NORMAL
- en: This doesn't actually create two copies of the data. References to the `KnownSample`
    objects are collected into a dictionary. From these, the two lists of `TrainingKnownSample`
    and `TestingKnownSample` objects are created. Each of the derived objects contains
    a reference to the original `KnownSample` object. The structure of the temporary
    dictionary represents some memory overhead, but overall, we've avoided duplicating
    data, reducing the memory required by this application.
  prefs: []
  type: TYPE_NORMAL
- en: This example suffers from a complication. It's not perfectly clear how to prevent
    creating test samples that are exact matches for training samples. An additional
    `if` statement inside the `for` statement could check for an item with `usage_pool` of
    `False` (in other words, a testing item) that also existed in `pools[True]` (in
    other words, the training items). This is quite a bit of extra complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than add the additional steps here, we'll wait for *Chapter 10*, *The
    Iterator Pattern*, and revise the algorithm to handle duplicate removal that avoids
    too many special cases or extra `if` statements.
  prefs: []
  type: TYPE_NORMAL
- en: In the case study for *Chapter 5*, *When to Use Object-Oriented Programming*,
    we used `with` statements and the `csv` module to load the raw sample data. In
    that chapter, we defined a `SampleReader` class. It's important to review the
    older definition with these newer partitioning functions to create an integrated
    whole that can properly read and partition the source of sample data.
  prefs: []
  type: TYPE_NORMAL
- en: Recall
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ve touched on a number of ways that object-oriented and functional programming
    techniques are part of Python:'
  prefs: []
  type: TYPE_NORMAL
- en: Python built-in functions provide access to special methods that can be implemented
    by a wide variety of classes. Almost all classes, most of them utterly unrelated,
    provide an implementation for `__str__( )` and `__repr__()` methods, which can
    be used by the built-in `str()` and `repr()` functions. There are many functions
    like this where a function is provided to access implementations that cut across
    class boundaries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some object-oriented languages rely on "method overloading" – a single name
    can have multiple implementations with different combinations of parameters. Python
    provides an alternative, where one method name can have optional, mandatory, position-only,
    and keyword-only parameters. This provides tremendous flexibility.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions are objects and can be used in ways that other objects are used. We can
    provide them as argument values; we can return them from functions. A function
    has attributes, also.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: File I/O leads us to look closely at how we interact with external objects.
    Files are always composed of bytes. Python will convert the bytes to text for
    us. The most common encoding, UTF-8, is the default, but we can specify other
    encodings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Context managers are a way to be sure that the operating system entanglements
    are correctly cleaned up even when there's an exception raised. The use goes beyond
    simply handling files and network connections, however. Anywhere we have a clear
    context where we want consistent processing on entry or exit, we have a place
    where a context manager can be useful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you haven't encountered `with` statements and context managers before, I
    encourage you, as usual, to go through your old code, find all the places where
    you were opening files, and make sure they are safely closed using the `with` statement.
    Look for places to write your own context managers as well. Ugly or repetitive `try...finally` clauses
    are a good place to start, but you may find them useful any time you need to do
    before and/or after tasks in context.
  prefs: []
  type: TYPE_NORMAL
- en: You've probably used many of the basic built-in functions before now. We covered
    several of them, but didn't go into a great deal of detail. Play with `enumerate`, `zip`, `reversed`, `any`,
    and `all` until you know you'll remember to use them when they are the right tool
    for the job. The `enumerate` function is especially important because not using
    it results in some pretty ugly `while` loops.
  prefs: []
  type: TYPE_NORMAL
- en: Also explore some applications that pass functions around as callable objects,
    as well as using the `__call__()` method to make your own objects callable. You
    can get the same effect by attaching attributes to functions or by creating a `__call__()` method
    on an object. In which case would you use one syntax, and when would it be more
    suitable to use the other?
  prefs: []
  type: TYPE_NORMAL
- en: The relationship between arguments, keyword arguments, variable arguments, and
    variable keyword arguments can be a bit confusing. We saw how painfully they can
    interact when we covered multiple inheritance. Devise some other examples to see
    how they can work well together, as well as to understand when they don't.
  prefs: []
  type: TYPE_NORMAL
- en: The `Options` example for using `**kwargs` has a potential problem. The `update()`
    method inherited from the `dict` class will add or replace keys. What if we only
    want to replace key values? We'd have to write our own version of `update()` that
    will update existing keys and raise a `ValueError` exception when a new key is
    provided
  prefs: []
  type: TYPE_NORMAL
- en: The `name_or_number()` function example has a blatant bug. It is not completely
    correct. For a number 15, it will not report both "fizz" and "buzz". Fix the `name_or_number()`
    function to collect all the names of all the true functions. A good exercise.
  prefs: []
  type: TYPE_NORMAL
- en: The `name_or_number()` function example has two test functions, `fizz()`, and
    `buzz()`. We need an additional function, `bazz()`, to be true for multiples of
    seven. Write the function and be sure it works with the `name_or_number()` function.
    Be sure that the number 105 is handled correctly.
  prefs: []
  type: TYPE_NORMAL
- en: It's helpful to review the previous case studies and combine them into a more
    complete application. The chapter case studies tend to focus on details, avoiding
    the overall integration of a more complete application. We've left the integration
    as work for the reader to allow them to dig more deeply into the design.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We covered a grab bag of topics in this chapter. Each represented an important
    non-object-oriented feature that is popular in Python. Just because we can use
    object-oriented principles does not always mean we should!
  prefs: []
  type: TYPE_NORMAL
- en: However, we also saw that Python typically implements such features by providing
    a syntax shortcut to traditional object-oriented syntax. Knowing the object-oriented
    principles underlying these tools allows us to use them more effectively in our
    own classes.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed a series of built-in functions and file I/O operations. There are
    a whole bunch of different syntaxes available to us when calling functions with
    arguments, keyword arguments, and variable argument lists. Context managers are
    useful for the common pattern of sandwiching a piece of code between two method
    calls. Even functions are objects, and, conversely, any normal object can be made
    callable.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we''ll learn more about string and file manipulation,
    and even spend some time with one of the least object-oriented topics in the standard
    library: regular expressions.'
  prefs: []
  type: TYPE_NORMAL
