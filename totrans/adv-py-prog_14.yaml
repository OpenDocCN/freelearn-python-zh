- en: '*Chapter 12*: Deadlocks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Deadlocks**, one of the most common concurrency problems, will be the first
    problem that we will analyze in this book. In this chapter, we will discuss the
    theoretical causes of deadlocks in concurrent programming. We will cover a classical
    synchronization problem in concurrency, called the **dining philosophers problem**,
    as a real-life example of a deadlock. We will also illustrate an actual implementation
    of a deadlock in Python and discuss several methods to address this problem. This
    chapter will also cover the concept of livelocks, which are relevant to deadlocks
    and are also a common problem in concurrent programming.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of deadlocks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaches to deadlock situations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of livelocks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, we will have gained a deep understanding of the
    problem, its place in concurrent programming, and the practical approaches to
    solving it.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code files for this chapter can be accessed through this link: [https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter12](https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter12).'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of deadlocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In concurrent programming, a deadlock refers to a specific situation in which
    no progress can be made, and the program becomes locked in its current state.
    In most cases, this phenomenon is caused by a lack of, or mishandled, coordination
    between different lock objects (for thread synchronization purposes). In this
    section, we will discuss a thought experiment, commonly known as the dining philosophers
    problem, to illustrate the concept of a deadlock and its causes; from there, you
    will learn how to simulate the problem in a Python concurrent program.
  prefs: []
  type: TYPE_NORMAL
- en: The dining philosophers problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dining philosophers problem was first introduced by Edgar Dijkstra, a leading
    pioneer in concurrent programming, in 1965\. This problem was first demonstrated
    using different technical terms (resource contention in computer systems) and
    was later rephrased by Tony Hoare, a British computer scientist and the inventor
    of the quicksort sorting algorithm. The problem statement is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Five philosophers sit around a table, and each has a bowl of food in front
    of them. Placed between these five bowls of food are five forks, so each philosopher
    has one fork to their left and one fork to their right. This setup is shown in
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1 – An illustration of the dining philosophers problem ](img/Figure_12.1_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – An illustration of the dining philosophers problem
  prefs: []
  type: TYPE_NORMAL
- en: Each silent philosopher is to alternate between thinking and eating. Each is
    required to have both of the forks around them to be able to pick up the food
    from their bowl, and no fork can be shared between two or more different philosophers.
    When a philosopher finishes eating a specific amount of food, they are to place
    both of the forks back in their respective, original locations. At this point,
    the philosophers around that philosopher will be able to use those forks.
  prefs: []
  type: TYPE_NORMAL
- en: Since the philosophers are silent and cannot communicate with each other, they
    have no way to let each other know they need the forks to eat. In other words,
    the only way for a philosopher to eat is to have both of the forks already available
    to them. For this problem, a set of instructions must be designed for the philosophers
    to efficiently switch between eating and thinking so that each philosopher is
    provided with enough food.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, a potential approach to this problem would be the following set of instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: A philosopher must think until the fork on their left becomes available. When
    that happens, the philosopher is to pick it up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A philosopher must think until the fork on their right becomes available. When
    that happens, the philosopher is to pick it up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If a philosopher is holding two forks, they will eat a specific amount of food
    from the bowl in front of them, and then the following will apply:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Afterward, the philosopher has to put the right fork down in its original place.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Afterward, the philosopher has to put the left fork down in its original place.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The process repeats from the first step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is clear to see how this set of instructions can lead to a situation where
    no progress can be made; namely, if, in the beginning, all of the philosophers
    start to execute their instructions at the same time. Since all of the forks are
    on the table at the beginning and are therefore available to be picked up by nearby
    philosophers, each philosopher will be able to execute the first instruction (picking
    up the fork on their left).
  prefs: []
  type: TYPE_NORMAL
- en: Now, after this step, each philosopher will be holding a fork with their left
    hand, and no forks will be left on the table. Since no philosopher has both forks
    in their hands, they cannot eat their food. Furthermore, the set of instructions
    that they were given specifies that only after a philosopher has eaten a specific
    amount of food can they put their forks down on the table. This means that so
    long as a philosopher has not eaten, they will not release the fork that they
    are holding.
  prefs: []
  type: TYPE_NORMAL
- en: So, as each philosopher is holding only one fork with their left hand, this
    means they cannot eat or put down the fork they are holding. The only time a philosopher
    gets to eat their food is when their neighboring philosopher puts their fork down,
    which is only possible if they can eat their food; this creates a never-ending
    circle of conditions that can never be satisfied. This situation is, in essence,
    the nature of a deadlock, in which all of the elements of a system are stuck in
    place, and no progress can be made.
  prefs: []
  type: TYPE_NORMAL
- en: It is not difficult to imagine real-world situations that involve shared resources
    and are modeled by this dining philosophers problem. For example, the original
    problems that inspired Dijkstra to construct this formulation involved working
    with external devices such as tape drives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example is in terms of banks: to execute transactions between two bank
    accounts, you must ensure that both accounts are locked from other transactions
    for the correct amount of money to be transferred. Here, the analogy does not
    exactly hold – a philosopher corresponds to a transaction that locks accounts
    (the forks) – but the same technical difficulties could arise. Other examples
    include making online reservations and allowing a database to be modified by multiple
    clients at the same time.'
  prefs: []
  type: TYPE_NORMAL
- en: With that said, we will be exclusively focusing on the formal dining philosophers
    problem as it provides a clean, abstract setting that could easily be analyzed
    and taken apart. With that in mind, let's consider the formal concept of a deadlock
    and the relevant theories around it.
  prefs: []
  type: TYPE_NORMAL
- en: A deadlock in a concurrent system
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given a concurrent program with multiple threads or processes, the execution
    flow enters a deadlock if a process (or thread) is waiting on a resource that
    is being held and utilized by another process, which is, in turn, waiting for
    another resource that is held by a different process. In other words, processes
    cannot proceed with their execution instructions while waiting for resources that
    can only be released after the execution is completed; therefore, these processes
    are unable to change their execution states.
  prefs: []
  type: TYPE_NORMAL
- en: 'A deadlock is also defined by the conditions that a concurrent program needs
    to have at the same time for a deadlock to occur. These conditions were first
    proposed by the computer scientist Edward G. Coffman, Jr., and are therefore known
    as the **Coffman conditions**. These conditions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: At least one resource has to be in a non-shareable state. This means that that
    resource is being held by an individual process (or thread) and cannot be accessed
    by others; the resource can only be accessed and held by a single process (or
    thread) at any given time. This condition is also known as **mutual exclusion**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One process (or thread) exists that is simultaneously accessing a resource and
    waiting for another held by other processes (or threads). In other words, this
    process (or thread) needs access to two resources to execute its instructions,
    one of which it is already holding, the other of which it is waiting for from
    other processes (or threads). This condition is called **hold and wait**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resources can only be released by a process (or a thread) holding them if there
    are specific instructions for the process (or thread) to do so. This is to say
    that unless the process (or thread) voluntarily and actively releases the resource,
    that resource remains in a non-shareable state. This is the **no preemption condition**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final condition is called **circular wait**. As its name suggests, this
    condition specifies that a set of processes (or threads) exist so that the first
    process (or thread) in the set is waiting for a resource to be released by the
    second process (or thread), which, in turn, needs to be waiting for the third
    process (or thread); finally, the last process (or thread) in the set is waiting
    for the first one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s quickly take a look at a basic example of a deadlock. Consider a concurrent
    program in which there are two different processes (process **A** and process
    **B**) and two different resources (resource **R1** and resource **R2**), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2 – Sample deadlock diagram ](img/Figure_12.2_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Sample deadlock diagram
  prefs: []
  type: TYPE_NORMAL
- en: Neither of the resources can be shared across separate processes, and each process
    needs to access both resources to execute its instructions. Take process **A**,
    for example. It is already holding resource **R1**, but it also needs **R2** to
    proceed with its execution. However, **R2** cannot be acquired by process **A**,
    as it is being held by process **B**. So, process **A** cannot proceed. The same
    goes for process **B**, which is holding **R2** and needs **R1** to proceed. **R1**
    is, in turn, held by process **A**.
  prefs: []
  type: TYPE_NORMAL
- en: Python simulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will implement the preceding situation in an actual Python
    program. Specifically, we will have two locks (we will call them **lock A** and
    **lock B**) and two separate threads interacting with the locks (**thread A**
    and **thread B**). In our program, we will set up a situation in which thread
    A has acquired lock A and is waiting to acquire lock B, which has already been
    acquired by thread B, which is, in turn, waiting for lock A to be released.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have already downloaded the code for this book from the relevant GitHub
    page, then go ahead and navigate to the `Chapter12` folder. Let''s consider the
    `Chapter12/example1.py` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this script, the `thread_a()` and `thread_b()` functions specify thread
    A and thread B, respectively. In our main program, we also have two `threading.Lock`
    objects: lock A and lock B. The general structure of the thread instructions is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start the thread.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try to acquire the lock with the same name as the thread (thread A will try
    to acquire lock A, while thread B will try to acquire lock B).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform some calculations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try to acquire the other lock (thread A will try to acquire lock B, while thread
    B will try to acquire lock A).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform some other calculations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Release both locks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: End the thread.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that we are using the `time.sleep()` function to simulate the action of
    some calculations being processed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: First of all, we are starting both threads A and B almost simultaneously, within
    the main program. With the structure of the thread instruction set in mind, we
    can see that at this point, both threads will be initiated; thread A will try
    to acquire lock A and will succeed in doing so since lock A is still available
    at this point. The same goes for thread B and lock B. The two threads will then
    go on to perform some calculations on their own.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the current state of our program: lock A has been acquired
    by thread A, and lock B has been acquired by thread B. After their respective
    calculation processes are complete, thread A will then try to acquire lock B,
    and thread B will try to acquire lock A. We can easily see that this is the beginning
    of our deadlock situation: since lock B is already being held by thread B and
    cannot be acquired by thread A, thread B, for the same reason, cannot acquire
    lock A.'
  prefs: []
  type: TYPE_NORMAL
- en: Both of the threads will now wait infinitely to acquire their respective second
    lock. However, the only way a lock can be released is for a thread to continue
    its execution instructions and release all of the locks it has at the end. So,
    our program will be stuck in its execution at this point, and no further progress
    will be made.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram further illustrates the process of how the deadlock unfolds,
    in sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Deadlock sequence diagram ](img/Figure_12.3_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Deadlock sequence diagram
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at the deadlock that we have created in action. By running
    the script, you should obtain the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As we discussed previously, since each thread is trying to acquire a lock that
    is currently held by the other thread, the only way for a lock to be released
    is for a thread to continue its execution. This is a deadlock, and your program
    will hang infinitely, never reaching the final `print` statement in the last line
    of the program.
  prefs: []
  type: TYPE_NORMAL
- en: This behavior is undesirable in every way. In the next section, we will be discussing
    potential approaches to prevent deadlocks from occurring.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches to deadlock situations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Intuitively, each of the following approaches looks to eliminate one of the
    four Coffman conditions from our program to prevent deadlocks. Our first solution
    is to implement ranking among the competing resources.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing ranking among resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From both the dining philosophers problem and our Python example, we can see
    that the last condition of the four Coffman conditions, circular wait, is at the
    heart of the deadlock problem. It specifies that the different processes (or threads)
    in our concurrent program wait for resources held by other processes (or threads)
    circularly. By taking a closer look, we can see that the root cause for this condition
    is the order (or lack thereof) in which the processes (or threads) access the
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: In the dining philosophers problem, each philosopher is instructed to pick up
    the fork on their left first, while in our Python example, the threads always
    try to acquire the locks with the same name before performing any calculations.
    As you have seen, when the philosophers want to start eating at the same time,
    they will pick up their respective left forks and will be stuck in an infinite
    waiting loop. Similarly, when the two threads start their execution at the same
    time, they will acquire their locks and, again, wait for the other locks infinitely.
  prefs: []
  type: TYPE_NORMAL
- en: The conclusion that we can infer from this is that if, instead of accessing
    the resources arbitrarily, the processes (or threads) were to access them in a
    predetermined, static order, the circular nature of the way that they acquire
    and wait for the resources will be eliminated. So, for our two-lock Python example,
    instead of having thread A try to acquire lock A and thread B try to acquire lock
    B in their respective execution instructions, we will want both threads to try
    and acquire the locks in the same order. For example, both threads will now try
    to acquire lock A first, perform some calculations, try to acquire lock B, perform
    further calculations, and, finally, release both threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'This change is implemented in the `Chapter12/example2.py` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This version of the script is now able to finish its execution and should produce
    the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This approach efficiently eliminates the deadlock problem in our two-lock example,
    but how well does it hold up for the dining philosophers problem? To answer this
    question, let''s try to simulate the problem and the solution in Python by ourselves.
    The `Chapter12/example3.py` file contains the implementation of the dining philosophers
    problem in Python, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have the `philosopher()` function as the underlying logic for our separate
    threads. It takes in two `Threading.Lock` objects and simulates the previously
    discussed eating procedure, with two context managers. In our main program, we
    create a list of five lock objects, named `forks`, and a list of five threads,
    named `phils`, with the specification that the first thread will take in the first
    and second locks, the second thread will take in the second and third locks, and
    so on; and the fifth thread will take in the fifth and first locks (in order).
    Finally, we start all five threads simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run the script, we will see that deadlock occurs almost immediately.
    The following is my output, up until the program hangs infinitely:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The question that naturally follows is: how can we implement an order in which
    the locks are acquired in the `philosopher()` function? We will be using the built-in
    `id()` function in Python here, which returns the unique, constant identity of
    the parameter, as the keys to sort the lock objects. We will also implement a
    custom context manager to factor out this sorting logic in a separate class. Navigate
    to `Chapter12/example4.py` for this specific implementation, which looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: With the main program remaining the same, this script will produce an output
    showing that this solution of ranking can effectively address the dining philosophers
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is a problem with this approach when it is applied to some particular
    cases. Keeping the high-level idea of concurrency in mind, we know that one of
    our main goals when applying concurrency to our programs is to improve the speed.
    Let's go back to our two-lock example and examine the execution time of our program
    with resource ranking implemented. Take a look at the `Chapter12/example5.py`
    file; it is simply the two-lock program with ranked (or ordered) locking implemented,
    combined with a timer that has been added to keep track of how much time it takes
    for the two threads to finish executing.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the script, your output should look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, you can see that the combined execution of both threads took around 14
    seconds. However, if we take a closer look at the specific instructions in the
    two threads, we will see that aside from interacting with the locks, thread A
    would take around 4 seconds to do its calculations (simulated by two `time.sleep(2)`
    commands), while thread B would take around 10 seconds (two `time.sleep(5)` commands).
  prefs: []
  type: TYPE_NORMAL
- en: 'Does this mean that our program is taking as long as it would if we were to
    execute the two threads sequentially? We will test this theory with our `Chapter12/example6.py`
    file, in which we specify that each thread should execute its instructions one
    at a time with the same `thread_a()` and `thread_b()` functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run this script, you will see that this sequential version of our two-lock
    program will take the same amount of time as its concurrent counterpart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This interesting phenomenon is a direct result of the heavy requirements that
    we have placed on the locks in the program. In other words, since each thread
    has to acquire both locks to complete its execution, each lock cannot be acquired
    by more than one thread at any given time. The locks must be acquired in a specific
    order, and the execution of individual threads cannot happen simultaneously. If
    we were to go back and examine the output produced by the `Chapter12/example5.py`
    file, it would be apparent that thread B could not start its calculations after
    thread A released both locks at the end of its execution.
  prefs: []
  type: TYPE_NORMAL
- en: It is quite intuitive, then, to conclude that if you placed enough locks on
    the resources of your concurrent program, it would become entirely sequential
    in its execution, and, combined with the overhead of concurrent programming functionalities,
    it would have an even worse speed than the purely sequential version of the program.
    However, we did not see this sequentiality that's created by locks in the dining
    philosophers problem (simulated in Python). This is because, in the two-thread
    problem, two locks were enough to sequentialize the program execution, while five
    were not enough to do the same for the dining philosophers problem.
  prefs: []
  type: TYPE_NORMAL
- en: We will explore another instance of this phenomenon in [*Chapter 13*](B17499_13_Final_SS_ePub.xhtml#_idTextAnchor228),
    *Starvation*.
  prefs: []
  type: TYPE_NORMAL
- en: Ignoring locks and sharing resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Locks** are undoubtedly an important tool in synchronization tasks, and in
    concurrent programming in general. However, if using locks leads to an undesirable
    situation, such as a deadlock, then it is natural for us to explore the option
    of simply not using locks in our concurrent programs. By ignoring locks, our program''s
    resources effectively become shareable among different processes/threads in a
    concurrent program, thus eliminating the first of the four Coffman conditions:
    **mutual exclusion**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach to the problem of a deadlock is straightforward to implement;
    let''s try this with the two preceding examples. In the two-lock example, we simply
    remove the code that specifies any interaction with the lock objects both inside
    the thread functions and in the main program. In other words, we are not utilizing
    a locking mechanism anymore. The `Chapter12/example7.py` file contains the implementation
    of this approach, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the script, your output should look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'It is clear that since we are not using locks to restrict access to any calculation
    processes, the executions of the two threads have become entirely independent
    of one another, so the threads were run completely in parallel. For this reason,
    we also obtained a better speed: since the threads ran in parallel, the total
    time that the whole program took was the same as the time that the longer of the
    two threads took (in other words, thread `B`, with `10` seconds).'
  prefs: []
  type: TYPE_NORMAL
- en: What about the dining philosophers problem? It seems that we can also conclude
    that without locks (the forks), the problem can be solved easily. Since the resources
    (food) are unique to each philosopher (in other words, no philosopher should eat
    another philosopher's food), it should be the case that each philosopher can proceed
    with their execution without worrying about the others. By ignoring the locks,
    each can be executed in parallel, similar to what we saw in our two-lock example.
  prefs: []
  type: TYPE_NORMAL
- en: Doing this, however, means that we are completely misunderstanding the problem.
    We know that locks are utilized so that processes and threads can access the shared
    resources in a program in a systematic, coordinated way, to avoid mishandling
    the data. Therefore, removing any locking mechanisms in a concurrent program means
    that the likelihood of the shared resources, which are now free from access limitations,
    being manipulated in an uncoordinated way (and therefore, becoming corrupted)
    increases significantly.
  prefs: []
  type: TYPE_NORMAL
- en: So, by ignoring locks, it is relatively likely that we will need to completely
    redesign and restructure our concurrent program. If the shared resources still
    need to be accessed and manipulated in an organized way, other synchronization
    methods will need to be implemented. The logic of our processes and threads might
    need to be altered to interact with this new synchronization method appropriately,
    the execution time might be negatively affected by this change in the structure
    of the program, and other potential synchronization problems might also arise.
  prefs: []
  type: TYPE_NORMAL
- en: An additional note about locks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'While the approach of dismissing locking mechanisms in our program to eliminate
    deadlocks might raise some questions and concerns, it does effectively reveal
    a new point for us about lock objects in Python: it is possible for an element
    of a concurrent program to completely bypass the locks when accessing a given
    resource. In other words, lock objects only prevent different processes/threads
    from accessing and manipulating a shared resource if those processes or threads
    acquire the lock objects.'
  prefs: []
  type: TYPE_NORMAL
- en: Locks, then, do not lock anything. They are simply flags that help indicate
    whether a resource should be accessed at a given time; if a poorly instructed,
    or even malicious, process/thread attempts to access that resource without checking
    that the lock object exists, it will most likely be able to do that without difficulty.
    In other words, locks are not connected to the resources that they are supposed
    to lock, and they most certainly do not block processes/threads from accessing
    those resources.
  prefs: []
  type: TYPE_NORMAL
- en: So, simply using locks is inefficient for designing and implementing a secure,
    dynamic, concurrent data structure. To achieve that, we would need to either add
    more concrete links between the locks and their corresponding resources or utilize
    a different synchronization tool altogether (for example, atomic message queues).
  prefs: []
  type: TYPE_NORMAL
- en: Concluding note on deadlock solutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, you have seen two of the most common approaches to the deadlock
    problem. Each addresses one of the four Coffman conditions, and while both (somewhat)
    successfully prevent deadlocks from occurring in our examples, each raises different,
    additional problems and concerns. So, it is important to truly understand the
    nature of your concurrent programs to know which of the two is applicable, if
    either of them is.
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible that some programs, through deadlocks, are revealed to us
    as unsuitable to be made concurrent; some programs are better left sequential
    and will be made worse with forced concurrency. As we have discussed, while concurrency
    provides significant improvements in many areas of our applications, some are
    inherently inappropriate for concurrent programming. In deadlock situations, developers
    should be ready to consider different approaches to designing a concurrent program
    and should not be reluctant to implement another method when one concurrent approach
    does not work.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of livelocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concept of a livelock is connected to a deadlock; some even consider it
    an alternate version of a deadlock. In a livelock situation, the processes (or
    threads) in the concurrent program can switch their states; in fact, they switch
    states constantly. Yet, they simply switch back and forth infinitely, and no progress
    is made. We will now consider an actual scenario of a livelock.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that a pair of spouses are eating dinner together at a table. They
    only have one fork to share, so only one of them can eat at any given point. Additionally,
    the spouses are polite to each other, so even if one spouse is hungry and wants
    to eat their food, they will leave the fork on the table if their partner is also
    hungry. This specification is at the heart of creating a livelock for this problem:
    when both spouses are hungry, each will wait for the other to eat first, creating
    an infinite loop in which each spouse switches between wanting to eat and waiting
    for the other spouse to eat.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s simulate this problem in Python. Navigate to `Chapter12/example8.py`
    and take a look at the `Spouse` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This class inherits from the `threading.Thread` class and implements the logic
    that we discussed previously. It takes in a name for the `Spouse` instance and
    another `Spouse` object as its partner; when initialized, a `Spouse` object is
    also always hungry (the `hungry` attribute is always set to `True`). The `run()`
    function in the class specifies the logic when the thread is started: so long
    as the `Spouse` object''s `hungry` attribute is set to `True`, the object will
    attempt to use the fork, which is a lock object, to eat. However, it always checks
    whether its partner also has its `hungry` attribute set to `True`, in which case
    it will not proceed to acquire the lock, and will instead wait for its partner
    to do it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our main program, we create the fork as a lock object first; then, we create
    two `Spouse` thread objects, which are each other''s `partner` attributes. Finally,
    we start both threads and run the program until both threads finish executing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the script, you will see that, as we discussed, each thread will
    go into an infinite loop, switching between wanting to eat and waiting for its
    partner to eat; the program will run forever until Python is interrupted. The
    following code shows the first few lines of output that I obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: And with that, we can conclude our discussion on deadlocks and livelocks.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the causes of deadlocks in concurrent applications
    and implemented approaches to prevent them from occurring. Our examples have shown
    that concurrency cannot always be achieved straightforwardly and that some situations
    may require special handling. These discussions have prepared us for deadlocks
    in the real world and pointed us toward potential solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will discuss another common problem in concurrent programming:
    starvation.'
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What can lead to a deadlock situation, and why is it undesirable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How is the dining philosophers problem related to the problem of a deadlock?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the four Coffman conditions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can resource ranking solve the problem of a deadlock? What other problems
    can occur when this is implemented?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can ignoring locks solve the problem of a deadlock? What other problems
    can occur when this is implemented?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How is a livelock related to a deadlock?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Parallel Programming with Python*, by Jan. Palach, Packt Publishing Ltd, 2014'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Python Parallel Programming Cookbook*, by Giancarlo Zaccone, Packt Publishing
    Ltd, 2015'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Python Thread Deadlock Avoidance* (`dabeaz.blogspot.com/2009/11/python-thread-deadlock-avoidance_20`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
