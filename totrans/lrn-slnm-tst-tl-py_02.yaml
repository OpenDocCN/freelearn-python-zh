- en: Chapter 2. Writing Tests Using unittest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Selenium WebDriver is a browser automation API. It provides features to automate
    browser interaction, and this API is mainly used to test web applications. We
    cannot set up test preconditions and post conditions, check the expected and actual
    output, check the state of the application, report test results, create data-driven
    tests, and so on with Selenium WebDriver. We can use a unit testing framework
    or test runners used for unit testing along with Selenium to create a testing
    framework. In this chapter, we will learn how to use the `unittest` library to
    create Selenium WebDriver tests in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What `unittest` is?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the `unittest` library to write Selenium WebDriver tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a test using the `TestCase` class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding various types of `assert` methods provided by the `unittest` library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a `TestSuite` for a group of tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating test reports in HTML format using the `unittest` extension
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The unittest library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `unittest` library (originally named as PyUnit) is inspired by the JUnit
    library widely used in Java application development. We can use `unittest` to
    create a comprehensive suite of tests for any project. The `unittest` module is
    used within the Python project to test various standard library modules including
    `unittest` itself. You can find the `unittest` documentation at [http://docs.python.org/2/library/unittest.html](http://docs.python.org/2/library/unittest.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `unittest` library provides us with the ability to create test cases, test
    suites, and test fixtures. Let''s understand each of these components as shown
    in following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The unittest library](img/3506_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Test Fixture**: By using a test fixture, we can define the preparation needed
    to perform one or more tests and any associated clean-up actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test Case**: A test case is the smallest unit of testing in `unittest`. It
    checks for a specific response to a particular set of actions and inputs using
    various `assert` methods provided by the `unittest` library. The `unittest` library
    provides a base class called `TestCase` that may be used to create new test cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test Suite**: A test suite is a collection of multiple tests or test cases
    to create groups of tests representing specific functionality or modules of the
    application under test, which will be executed together.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test Runner**: The test runner orchestrates execution of tests and provides
    results to the user. The runner may use a graphical interface, a textual interface,
    or return a special value to indicate the results of executing the tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test Report**: A test report displays a summary of test results showing the
    pass or fail status of executed test cases, expected versus actual results for
    failed steps, and summary of overall run and timing information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A test created with the `xUnit` framework such as `unittest` is divided into
    three parts also known as the 3 A''s, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Arrange**: This part sets up the preconditions for tests including the object(s)
    that need to be tested, related configuration, and dependencies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Act**: This part exercises the functionality'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Assert**: This part checks the outcome with the expected results'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use this approach to create tests with the `unittest` library in rest
    of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will use the `unittest` library in rest of the book to create and run Selenium
    WebDriver tests. However, there are other testing frameworks available in Python
    with additional features, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Nose**: The `nose` framework extends the `unittest` library and provides
    ability to search and run tests automatically. It also provides various plugins
    to create more advanced tests. You can find more about `nose` at [https://nose.readthedocs.org/en/latest/](https://nose.readthedocs.org/en/latest/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pytest**: The `pytest` framework is another testing framework that offers
    a number of advanced features to write and run unit tests in Python. You can find
    out more about `pytest` at [http://pytest.org/latest/](http://pytest.org/latest/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The TestCase class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can create a test, or group of tests, by inheriting the `TestCase` class
    and adding each test as a method to this class. To make a test, we need to either
    use `assert` or one of the many variations on `assert` that are part of the `TestCase`
    class. The most important task of each test is a call to `assertEqual()` to check
    for an expected result, `assertTrue()` to verify a condition, or `assertRaises()`
    to verify that an expected exception gets raised.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to adding tests, we can add test fixtures: that is the `setUp()`
    and `tearDown()` methods to handle creation and disposition of any objects or
    conditions that are needed for a test.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's start using the `unittest` library, first writing a simple test by inheriting
    the `TestCase` class and then adding a test method for the sample script that
    we created in [Chapter 1](ch01.html "Chapter 1. Getting Started with Selenium
    WebDriver and Python"), *Getting Started with Selenium WebDriver and Python*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to import the `unittest` module and define a class that inherits the
    `TestCase` class, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The setUp() method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The starting point for test cases is the `setUp()` method, which we can use
    to perform some tasks at the start of each test or all the tests that will be
    defined in the class. These can be test preparation tasks such as creating an
    instance of a browser driver, navigating to the base URL, loading test data, opening
    logfiles, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'This method takes no arguments and doesn''t return anything. When a `setUp()`
    method is defined, the test runner will run that method prior to each test method.
    In our example, we will use the `setUp()` method to create an instance of Firefox,
    set up the properties, and navigate to the main page of the application before
    a test is executed as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Writing tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With a setup method in place, we can now write some tests to verify the application's
    functionality that we want to test. In this example, we will search for a product
    and check if the result returns a number of items. Similar to the `setUp()` method,
    test methods are implemented in the `TestCase` class. It is important that we
    name these methods beginning with the word `test`. This naming convention informs
    the test runner about which methods represent a test.
  prefs: []
  type: TYPE_NORMAL
- en: For each test method that the test runner finds, it executes the `setUp()` method
    before executing the `test` method. This helps ensure that each `test` method
    can depend on a consistent environment, regardless of how many tests are defined
    in the class. We will use a simple `assertEqual()` method to check that the expected
    results for the given search term match with the results returned by the application.
    We will discuss more about assertions later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a new test method, `test_search_by_category()`, which searches for products
    by category and checks for the number of products returned by the search, as shown
    in following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Cleaning up the code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Similar to the `setUp()` method that is called before each test method, the
    `TestCase` class also calls a `tearDown()` method to clean up any initialized
    values after the test is executed. Once a test is executed, the values defined
    in the `setUp()` method are no longer required; so, it is good practice to clean
    up the values initialized by the `setUp()` method after a test is completed. In
    our example, after a test is executed, we no longer need the instance of Firefox.
    We will close the Firefox instance that was created for the test in the `tearDown()`
    method, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Running the test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To run the test from command line, we can add a call to the `main` method of
    the test case. We will pass the `verbosity` argument that is used to display the
    amount of test result details on the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can store the tests as a normal Python script. For this example, save the
    sample test as `searchtests.py`. After saving the file, we can execute it through
    command line by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the tests, `unittest` shows the results on the console along
    with the summary of tests as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Running the test](img/3506_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In addition to the results summary, when a test case fails, for each failure,
    summary will produce a block of text to describe what went wrong. Look at the
    following screenshot to see what happens when we change the expected value to
    something else:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Running the test](img/3506_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, it shows exactly which test method generated the failure, with
    trace-back information to track down the code flow that led to the failure. In
    addition, the failure itself is shown as `AssertionError`, with a mismatch of
    the expected output with the actual output.
  prefs: []
  type: TYPE_NORMAL
- en: Adding another test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can group a number of tests as part of one test class. This helps in creating
    logical groups of tests that belong to a specific functionality. Let''s add another
    test to the test class. The rule is simple; name the new method starting with
    the word `test`, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the test and you will see two instances of Firefox opening and closing.
    This is how the `setUp()` and `tearDown()` methods work for each test method.
    You will see the result as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adding another test](img/3506_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Class-level setUp() and tearDown() methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous example, we created a new instance of Firefox using the `setUp()`
    method before the execution of each test method and closed that instance after
    the execution of the test method. How about sharing a single Firefox instance
    between the methods instead of creating a new instance every time? This can be
    done by using the `setUpClass()` and `tearDownClass()` methods and using the `@classmethod`
    decorator. These methods allow us to initialize values at the class level instead
    of the method level and then share these values between the test methods. In the
    following example, the code is modified to call the `setUpClass()` and `tearDownClass()`
    methods with the `@classmethod` decorator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Run the test and you will see a single Firefox instance created; both the tests
    will use this instance.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more information on the `@classmethod` decorator, refer to [https://docs.python.org/2/library/functions.html#classmethod](https://docs.python.org/2/library/functions.html#classmethod).
  prefs: []
  type: TYPE_NORMAL
- en: Assertions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `TestCase` class of the `unittest` library offers a number of utility methods
    to check the expected values against actual values returned by the application.
    These methods are implemented in such a way that they represent a condition that
    must be true in order to continue the execution of the test. There are broadly
    three types of such methods, each covering a specific type of condition such as
    checking equivalence, logical comparison, and exceptions. If the given assertion
    passes, the test will continue to the next line of code; otherwise, the test halts
    immediately and a failure message will be generated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `unittest` library provides all the standard xUnit `asserts` methods. The
    following table lists some of the important methods that we will be using in the
    rest of the book:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Condition that is checked | Example uses |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `assertEqual(a, b [,msg])` | a == b | These methods check whether or not
    `a` and `b` are equal to each other. The `msg` object is a message explaining
    the failure (if any).This is useful to check values of elements, attributes, and
    so on. For example:`assertEqual(element.text,"10")` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertNotEqual(a, b[,msg])` | a != b |'
  prefs: []
  type: TYPE_TB
- en: '| `assertTrue(x[,msg]))` | bool(x) is True | These methods check whether the
    given expression evaluates to `True` or `False`.For example, to check whether
    the element is displayed on a page, we can use the following method:`assertTrue(element.is_dispalyed())`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `assertFalse(x[,msg]))` | bool(x) is False |'
  prefs: []
  type: TYPE_TB
- en: '| `assertIsNot(a, b[,msg]))` | a is not b |'
  prefs: []
  type: TYPE_TB
- en: '| `assertRaises(exc, fun, *args, **kwds)` | fun(*args, **kwds) raises exc |
    These methods check whether the specific exceptions are raised by the test steps.
    A possible use of this method is to check `NoSuchElementFoundexception`. |'
  prefs: []
  type: TYPE_TB
- en: '| `assertRaisesRegexp(exc, r, fun, *args, **kwds)` | fun(*args, **kwds) raises
    exc and the message matches regex r |'
  prefs: []
  type: TYPE_TB
- en: '| `assertAlmostEqual(a, b)` | round(a-b, 7) == 0 | These methods specifically
    check for numeric values, and round the value to the given number of decimal places
    before checking for equality. This helps account for rounding errors and other
    problems due to floating-point arithmetic. |'
  prefs: []
  type: TYPE_TB
- en: '| `assertNotAlmostEqual(a, b)` | round(a-b, 7) != 0 |'
  prefs: []
  type: TYPE_TB
- en: '| `assertGreater(a, b)` | a > b | These methods are similar to the `assertEqual()`
    method, designed with logical conditions. |'
  prefs: []
  type: TYPE_TB
- en: '| `assertGreaterEqual(a, b)` | a >= b |'
  prefs: []
  type: TYPE_TB
- en: '| `assertLess(a, b)` | a < b |'
  prefs: []
  type: TYPE_TB
- en: '| `assertLessEqual(a, b)` | a <= b |'
  prefs: []
  type: TYPE_TB
- en: '| `assertRegexpMatches(s, r)` | r.search(s) | These methods check whether a
    `regexp` search matches the text. |'
  prefs: []
  type: TYPE_TB
- en: '| `assertNotRegexpMatches(s, r)` | not r.search(s) |'
  prefs: []
  type: TYPE_TB
- en: '| `assertMultiLineEqual(a, b)` | strings | This method is a specialized form
    of `assertEqual()`, designed for multiline strings. Equality works like any other
    string, but the default failure message is optimized to show the differences between
    the values. |'
  prefs: []
  type: TYPE_TB
- en: '| `assertListEqual(a, b)` | lists | This method checks whether the lists `a`
    and `b` match. This is useful to match options from drop-down fields. |'
  prefs: []
  type: TYPE_TB
- en: '| `fail()` |   | This method fails the test unconditionally. This can also
    be used to create custom conditional blocks where other `assert` methods do not
    work easily. |'
  prefs: []
  type: TYPE_TB
- en: Test suites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the `TestSuites` feature of `unittest`, we can collect various tests into
    logical groups and then into a unified test suite that can be run with a single
    command. This is done by using the `TestSuite`, `TestLoader`, and `TestRunner`
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we get into details of `TestSuite`, let''s add a new test to check the
    home page of the sample application. We will aggregate this test along with the
    previous search tests into a single test suite, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the `TestSuite` class for defining and running the test suite.
    We can add multiple test cases to the test suite. In addition to the `TestSuite`
    class we need to use `TestLoader` and `TextTestRunner` to create and run a test
    suite as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Using the `TestLoader` class, we will get all the test methods from the specified
    test files that will be used to create the test suite. The `TestRunner` class
    will take the test suite and run all the tests from these files.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can run the new test suite file using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This will run all the tests from the `SearchProductTest` and `HomePageTest`
    class and generate the following output in the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Test suites](img/3506_02_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Generating the HTML test report
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `unittest` library generates the test output on a console window. You might
    want to generate a report of all the tests executed as evidence or to distribute
    test results to various stakeholders. Sending console logs to the stakeholder
    may not be a good idea. Stakeholders will need nicely formatted, summary reports
    with a drill-down access to the details. The `unittest` library does not have
    an in-built way to generate nicely formatted reports. We can use the `HTMLTestRunner`
    extension of `unittest` written by Wai Yip Tung. You can find more about `HTMLTestRunner`
    at [https://pypi.python.org/pypi/HTMLTestRunner](https://pypi.python.org/pypi/HTMLTestRunner)
    along with the download instructions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `HTMLTestRunner` extension is bundled with the book's source code.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use `HTMLTestRunner` in our test to generate a nice-looking report.
    Let''s modify the test suite file that we created earlier in the chapter and add
    `HTMLTestRunner` support. We need to create an output file that will contain the
    actual report, configure the `HTMLTestRunner` options, and run the tests in the
    following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the test suite; `HTMLTestRunner` executes all the tests similar to the
    `unittest` library''s default test runner. At the end of the execution, it will
    generate a report file as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating the HTML test report](img/3506_02_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to use the `unittest` testing library for writing
    and running tests with Selenium WebDriver. We created a test using the `TestClass`
    class with the `setUp()` and `tearDown()` methods. We added an assertion to check
    the expected output with the actual output.
  prefs: []
  type: TYPE_NORMAL
- en: We also learned how to use different types of assertions that are supported
    by the `unittest` library. We implemented the test suite that provides the ability
    to aggregate tests in logical groups. Finally, we used `HTMLTestRunner` to generate
    test reports in HTML format that show nicely formatted test results.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to use and define locators to interact
    with various HTML elements displayed on a page.
  prefs: []
  type: TYPE_NORMAL
