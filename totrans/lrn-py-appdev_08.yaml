- en: Chapter 8. Improving Performance – Part One
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s recap what you learned in the previous chapter. We started with a program
    that appeared harmless until some parameters were tweaked. This change revealed
    performance issues. Hence, we performed a *search operation* (profiling) to catch
    the *culprits* (the bottlenecks). Now, let''s see what we can do to speed up the
    application code. To be specific, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Cutting down the runtime of the *Gold Hunt* application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Learning to improve the application performance using the following ways:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making changes to the algorithm
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding the function re-evaluation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the list and dictionary comprehensions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Using generator expressions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Using tricks to improve the performance of code involving loops
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the right data structures
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussing the `collections` and `itertools` modules briefly
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, this chapter will cover several (but not all) techniques to speed
    up the application. Some of these can be directly applied to alleviate the performance
    problems of the *Gold Hunt* scenario from the previous chapter. For the rest,
    we will use generic examples to illustrate the efficacy of those techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisite for the chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Have you already read [Chapter 7](ch07.html "Chapter 7. Performance – Identifying
    Bottlenecks"), *Performance – Identifying Bottlenecks*? It teaches you how to
    identify the performance bottlenecks. A part of this chapter uses the same problem
    that was discussed in the previous chapter and gradually improves its performance.
    Also, in this chapter, it is assumed that you already know how to profile the
    code.
  prefs: []
  type: TYPE_NORMAL
- en: This is how the chapter is organized
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will start with first part of the performance improvements for the *Gold
    Hunt* scenario. The aim is to provide you with a practical example of how to approach
    the problem and gradually cut down the runtime. The following chart shows a preview
    of what will be accomplished by the end of this chapter—this is the same chart
    shown in the previous chapter. The application runtime is about to be cut down
    by more than 50%!
  prefs: []
  type: TYPE_NORMAL
- en: '![This is how the chapter is organized](img/B05034_08_33.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The second half of this book will show you many ways to improve the application
    speed. For this discussion, we will use generic examples, as not all techniques
    can be applied directly to the *Gold Hunt* scenario. The second half will serve
    as a handy reference for performance improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Python wiki has documented several performance improvement tips. Some of
    these will be covered here. Refer to [https://wiki.python.org/moin/PythonSpeed/PerformanceTips](https://wiki.python.org/moin/PythonSpeed/PerformanceTips)
    for further details.
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting the Gold Hunt scenario
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, you should go back to [Chapter 7](ch07.html "Chapter 7. Performance
    – Identifying Bottlenecks"), *Performance – Identifying Bottlenecks*, and refresh
    your memory on the *Gold Hunt* scenario. To summarize the problem, a circular
    field has gold coins scattered all over and you need to pick as many coins as
    you can while traveling across the field. However, you can only pick the coins
    lying inside the small search circles. We wrote an application code and discussed
    how tweaking the `search_radius` and `field_coins` (total scattered coins) parameters
    impact the performance. In the upcoming discussion, we will gradually improve
    the performance of this code.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting a problem size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| *In order to* *see a real difference in the timing after optimizing the code,
    let''s increase the problem size further. In the previous chapter, **The Great
    Dwarf** wanted us to put one million coins on the field. **Let''s double the deal**.
    Now, there are **two million** gold coins up for grabs! In short,* `search_radius`
    *and* `field_coins` *will be set to* `0.1` *and* `2000000`*, respectively.* |'
  prefs: []
  type: TYPE_TB
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Caution! Read this before running any example**'
  prefs: []
  type: TYPE_NORMAL
- en: Running the examples in this chapter can consume a lot of computational resources
    (the sample output will be shown in this chapter so you don't have to run these).
    The `goldhunt_0.py` file, for instance, takes nearly two minutes to complete on
    a 64 bit Linux machine with an 8 GB RAM and a good processor with only a few running
    tasks. It also consumes quite a bit of memory during the execution. The performance
    is not that bad for this system configuration. In general, it will depend on the
    specifications of your machine. So, be careful! One strategy is to set `field_coins=5000`
    and `search_radius=1` and see how well the application runs. Then, progressively
    tweak these parameters to an acceptable configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling the initial code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will start with the source `goldhunt_0.py` file (see the supporting code
    for the chapter). This is same as `goldhunt_inefficient.py` except for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: It profiles the game execution using `cProfile` and prints the statistics. Thus,
    it also includes the functions from the `profiling_goldhunt.py module`. Although
    combining these two modules is not the best practice, it will help simplify the
    upcoming illustrations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The updated `play_game()` function is shown next. It uses the new parameter
    values, as shown:![Profiling the initial code](img/B05034_08_03.png.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code can be run as follows—if necessary, tweak the input arguments to `GoldHunt()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the profiling statistics for this run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Profiling the initial code](img/B05034_08_04.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Notice that `find_coins` eats up a significant amount of time. The next on the
    list is `generate_random_points`. Let's see what we can do to improve the performance.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing Gold Hunt – Part one
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is time for some action. This section is organized in the following manner—you
    will learn some techniques to optimize the code and speedup the application. These
    techniques will be directly applied to improve the performance of the *Gold Hunt*
    game.
  prefs: []
  type: TYPE_NORMAL
- en: This is the first part of the optimization task. Here, the performance will
    be improved in three steps. We will call these *optimization pass one*, *pass
    two*, and *pass three*. After implementing each of these strategies, the code
    will be re-profiled to get an understanding of the speedup accomplished. Let's
    get started with *optimization pass one*.
  prefs: []
  type: TYPE_NORMAL
- en: Tweaking the algorithm – The square root
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The profiling output (refer to the *Profiling the initial code* section) shows
    the `find_distance` method as the bottleneck. As a starter, let''s make some changes
    to this algorithm so that it runs faster. Here is the original method that was
    presented in the *Reviewing the initial code* section in [Chapter 7](ch07.html
    "Chapter 7. Performance – Identifying Bottlenecks"), *Performance – Identifying
    Bottlenecks*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Tweaking the algorithm – The square root](img/B05034_08_05.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The method computes the distance to each gold coin from the center of the search
    circle and determines whether or not the given gold coin lies inside the search
    circle. The computed distance, denoted by `dist`, is a square root.
  prefs: []
  type: TYPE_NORMAL
- en: 'Do we really need to compute a square root? The square root computation is
    time consuming and in this case unnecessary. All we are doing is just comparing
    two numbers. Can we avoid that by comparing the square of two numbers instead?
    Confused? Have a look at the following comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Tweaking the algorithm – The square root](img/B05034_08_06.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We have two positive numbers, *a=4* and *b=9*. Obviously, *a* is smaller than
    *b*. So, the comparison *a < b* will always return `true`. This is applicable
    even for the comparison of their square roots. The same logic can be applied to
    our problem. The `dist` and `self.search_radius` variables can be considered as
    square roots of two numbers. We have got the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, we can say `dist` is the square root of some number, `dist_square`, given
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we already know the value of `self.search_radius`. Now, imagine it as
    a square root of another number, `search_radius_square`. This number is not already
    available, and it needs to be computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As the last step, we will need to compare these two numbers instead of their
    square roots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Tweaking the algorithm – The square root](img/B05034_08_07.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *That''s a good observation! It requires us to do an extra computation to
    find out the square of* `self.search_radius`*. But, we do not need to compute
    that for every iteration inside the* `for` *loop. The* `self.search_radius` *does
    not change inside the loop. So, this computation can be done just once before
    the* `for` *loop.* |'
  prefs: []
  type: TYPE_TB
- en: Gold Hunt optimization – Pass one
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Putting it all together, the updated `find_coins` method is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – Pass one](img/B05034_08_08.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'It is now time to profile this code again and see if we get any improvement
    in the performance. The supporting source file, `goldhunt_pass1.py`, has these
    changes incorporated. It can be run as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the profiling statistics for this run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – Pass one](img/B05034_08_09.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Compare the timings with that of the original code. There is a significant improvement
    in the application's runtime. Earlier, the total runtime was more than 100 seconds,
    but this optimization has brought it down to less than 60 seconds! You can also
    compare the first row in the output (`find_coins`) against the original timings.
    The timings noted by the profiler will depend on the machine specifications and
    the input values chosen.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The timings will vary slightly even if you run the same program again. There
    are two reasons behind this; first, we are distributing the gold coins randomly
    on the field. As a result, for each run, there will be a variation in the total
    number of coins appended to the list. The second factor that influences this is
    the other running processes on your system. Ideally, you should run it under the
    same environment to reduce these variations (or *noise*). For example, close other
    running applications so that they don't interfere with the timing. During the
    performance benchmarking process, quite often, the same application is run multiple
    times and an average time is noted to reduce the effect of these variations.
  prefs: []
  type: TYPE_NORMAL
- en: Skipping the dots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **dot** notation in Python enables access to the attributes of the given
    object. Take a look at the following code from the previous example. This is taken
    from the `for` loop of the `find_coins` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In this loop, for every iteration, the `collected_coins.append` function is
    re-evaluated. Recall that in [Chapter 6](ch06.html "Chapter 6. Design Patterns"),
    *Design Patterns*, you learned about the first-class functions. Let's represent
    `collected_coins.append` with a local function. This avoids the function re-evaluation
    (skips the dots) and will help speed up the loop.
  prefs: []
  type: TYPE_NORMAL
- en: Gold Hunt optimization – Pass two
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In pass two, we will improve the code from the earlier pass (*optimization
    pass one*). The `goldhunt_pass2.py` file in the supporting code bundle incorporates
    all the changes to be discussed next. Here is the modified `find_coins` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – Pass two](img/B05034_08_10.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, a local function called `append_coins_function` is assigned to the built-in
    `append` function of a Python `list`. This avoids the re-evaluation of the `append`
    function. Similarly, `self.xref` and `self.yref` are represented with local variables.
    Let''s profile this new code and see if we get any improvements. The command is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![Gold Hunt optimization – Pass two](img/B05034_08_11.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There is an improvement in the performance, but the results are not as impressive
    as the first pass of the optimization. It is still a reasonable improvement of
    about 10 seconds or more than 15%.
  prefs: []
  type: TYPE_NORMAL
- en: '| *You can make similar changes elsewhere in the code, but before you jump
    the gun, Sir Foo has an important message for you.* |'
  prefs: []
  type: TYPE_TB
- en: '![Gold Hunt optimization – Pass two](img/B05034_08_12.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *That is an excellent point! Care should be taken while adopting such techniques.
    You should document the code or define a project-specific coding convention so
    that the local functions clearly stand out. This will help other developers understand
    the purpose of such assignments. More generally, do not overdo it and see if there
    is a real benefit.* |'
  prefs: []
  type: TYPE_TB
- en: Using local scope
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While looking for a variable or a function definition, Python first searches
    the following **namespaces** in that order: **local**, **global**, and **built-in**.
    In simpler terms, it first looks for local variables or functions, then performs
    the search at the module level, and if nothing can be found, it looks for a built-in
    function or variable name. So, the look up for local variables or functions is
    the fastest. Using a local function in place of a global or built-in function
    may help improve the performance. The amount of speedup you get will depend on
    the problem.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's review the `generate_random_points` function. The original code is shown
    next. Refer to the *Reviewing the initial code* section in [Chapter 7](ch07.html
    "Chapter 7. Performance – Identifying Bottlenecks"), *Performance – Identifying
    Bottlenecks*, where it was explained.
  prefs: []
  type: TYPE_NORMAL
- en: '![Using local scope](img/B05034_08_13.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the original function, we are calling various functions of the built-in modules,
    `random` and `math`. Let's update `generate_random_points` in the next optimization
    pass.
  prefs: []
  type: TYPE_NORMAL
- en: Gold Hunt optimization – Pass three
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's go further into the optimization process. We will replace the built-in
    function calls in the `generate_random_points` function with local ones. The reworked
    code is shown next. Here, the `l_uniform` variable represents the `random.uniform`
    function. Likewise, you can see the other assignments in this code snippet.
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – Pass three](img/B05034_08_14.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The optimization accomplished after this step is a combination of using local
    scope and skipping the dots. As an exercise, you can try to separate these components.
    For example, to avoid using dots, at the top of the module, import `pi`, `cos`
    and other symbols, and directly use them in the function. Then compare the performance
    with and without the use of local functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, before implementing such a code, ask yourself a few questions: By using
    local scope, is the code quality getting compromised (is it harder to read and
    maintain)? Does the final performance improvement outweigh all other factors?'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also find this code in `goldhunt_pass3.py`. The following is the `cProfile`
    output for this file. There is only a minor improvement in the overall timing.
    The real difference will be noticeable if you compare the second row of the list
    (`generate_random_points`) with the corresponding output of *optimization pass
    two*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – Pass three](img/B05034_08_15.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The total runtime has been reduced to ~2.6 seconds from an initial ~ 3.2 seconds.
    Increasing the problem size (number of coins) could make this difference further
    noticeable.
  prefs: []
  type: TYPE_NORMAL
- en: '| *But it looks like someone is not quite impressed with the speedup...* |'
  prefs: []
  type: TYPE_TB
- en: '![Gold Hunt optimization – Pass three](img/B05034_08_16.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *Absolutely! The task to improve the **Gold Hunt** game performance is far
    from over! Before we do that, let''s discuss some other techniques that help speed
    up the application. We will use generic examples as many of these techniques are
    not relevant in the context of the previously mentioned game scenario.**In the
    next chapter, we will revisit the **Gold Hunt** problem and speed up the application
    further using NumPy and parallelization. It will be a drastic improvement in the
    performance. If you do not want to break the continuity, read the next chapter
    first and then come back here for the rest of the discussion.* |'
  prefs: []
  type: TYPE_TB
- en: Performance improvement goodies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's spend some time discussing miscellaneous tips and tricks that help improve
    the runtime performance of the code. You can still apply a few of these techniques
    to the *Gold Hunt* problem, but let's just use generic examples to explain these
    concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All the illustrations in this section can be found in the supporting file, `misc_performance.py`.
    To compare the performance, we will use the `timeit` module that was discussed
    in [Chapter 7](ch07.html "Chapter 7. Performance – Identifying Bottlenecks"),
    *Performance – Identifying Bottlenecks* (refer to the *Measuring runtime of small
    code snippets* section). See also the `timeit` documentation, [https://docs.python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html).
  prefs: []
  type: TYPE_NORMAL
- en: List comprehension
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**List comprehension** is a compact way of creating a Python `list`. It is
    often used to replace the nested `for` loops or the `map` and `filter` functionality.
    Besides being compact, it is also efficient compared to, for instance, an equivalent
    `for` loop. The basic syntax is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates a list with elements: `[0, 1, 4, 9, 16]`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding syntax is equivalent to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Let's wrap these code blocks in two functions. We will measure the performance
    of each function using the `timeit` module. The previously mentioned file, `misc_performance.py`,
    also has these functions. To get a better idea of the performance gain, we will
    select a larger problem size. As noted a few times earlier in this book, select
    a problem size depending on what your machine can comfortably handle.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code fragment shows these functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![List comprehension](img/B05034_08_17.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `sample_size_1` variable is chosen sufficiently large to see a difference.
    The runtime is captured using the `timeit.timeit` method, whose first argument
    is a string representing the function name. The second argument is a `setup` parameter
    that tells us where to look for this function. The runtime performance can be
    compared by executing the script, as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As can be seen from the following output, the list comprehension is faster
    compared to an equivalent `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As an exercise, try comparing the timings of a nested `for` loop and an equivalent
    list comprehension syntax. Refer to the `list_comprehension_ex2` function in the
    `misc_performance.py` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *Gold Hunt* problem, it is also possible to use list comprehension in
    the `generate_random_points` function. For example, you can optionally write `theta`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: But before making such changes, read the next chapter, which shows how the NumPy
    package drastically improves the performance of this function.
  prefs: []
  type: TYPE_NORMAL
- en: Recording execution time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous section, we used the `timeit.timeit` function to record and
    compare the performance of list comprehension against a classical `for` loop.
    Let''s wrap the `timeit` code into a utility function so that we can reuse it
    for the rest of the discussion. The `run_timeit` function is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recording execution time](img/B05034_08_18.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, `func_1` and `func_2` are the function names (strings) whose execution
    time needs to be recorded. The `number` argument in the `timeit.timeit` function
    indicates the number of times the given function is executed. The callers of `run_timeit`
    can tune this number by using the optional `num` argument. See the documentation
    for further details.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This function does not do any error checking. As an exercise, you can add that
    capability. For example, add the `try…except` clause to catch errors if the function
    is not found.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming discussion, we will use `run_timeit` to compare the performance
    of two functionally equivalent code blocks.
  prefs: []
  type: TYPE_NORMAL
- en: Dictionary comprehension
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just like the list comprehension, a **dictionary comprehension** is the syntactic
    construct to create a Python dictionary object. The following functions show two
    ways to create a dictionary. The first one (`no_dict_comprehension`) uses a `for`
    loop to create a dictionary, whereas the second function shows the dictionary
    comprehension syntax.
  prefs: []
  type: TYPE_NORMAL
- en: '![Dictionary comprehension](img/B05034_08_19.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As noted in the previous section, from now onwards, we will use the `run_timeit`
    utility function to record timings. The `timeit` output after executing this code
    is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Swapping conditional block and for loops
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Consider the following trivial code. There is a top-level `for` loop with an
    `if…else` condition block. Depending on the value of the `num` variable (assume
    it changes), either `if` or `else` condition is executed. As before, an appropriate
    integer for the `sample_size_1` variable should be chosen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Swapping conditional block and for loops](img/B05034_08_20.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can write the same code by swapping the `for` loop and the `if…else` block.
    The new function has a top-level `if…else` block. Inside each condition statement,
    we have the same `for` loop. The following `if_condition_loop_opt` function shows
    this (its output remains the same):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Swapping conditional block and for loops](img/B05034_08_21.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s find out the winner between these two functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: To summarize, the function with a top-level `if…else` block runs faster compared
    to the function with a top-level `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This was a simple example where the swapping of the `for` loop and condition
    blocks was easy. However, in the real world, weigh in the advantages of making
    such modifications over the risk of introducing bugs. Does the profiling really
    show this code block as a major bottleneck? If you finally decide to go ahead
    with it, add enough automated tests to make sure that the function output remains
    the same! See [Chapter 5](ch05.html "Chapter 5. Unit Testing and Refactoring"),
    *Unit Testing and Refactoring*, to learn how to write unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: '''try'' it out in a loop'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Remember the **Easier to ask for forgiveness than permission** (**EAFP**) principle
    that encourages using the `try…except` clause? It was discussed briefly in [Chapter
    2](ch02.html "Chapter 2. Dealing with Exceptions"), *Dealing with Exceptions*.
    Let's see how a `try…except` clause can save some execution time. Consider the
    following function, which populates a list in a `for` loop based on the value
    of `i`. Only for the first iteration of the `for` loop (`i=0`), the `if` statement
    is executed. For all other values of `i`, it executes the `else` block, `val /=i`.
  prefs: []
  type: TYPE_NORMAL
- en: '![''try'' it out in a loop](img/B05034_08_22.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let's replace the `if…else` block with a `try…except` clause. The `try` clause
    will always try to execute the `val /= i` statement. When we have `i=0`, it raises
    the `ZeroDivisionError` exception, which is handled in the `except` clause.
  prefs: []
  type: TYPE_NORMAL
- en: '![''try'' it out in a loop](img/B05034_08_23.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we need to catch the error only for the initial value, `i=0`. For the
    rest of the loop, the code should run smoothly. The `try…except` clause effectively
    gets rid of the extra checks imposed by the `if…else` condition block. In other
    words, we will no longer need to check `if i==0` for each value of `i`. As a result,
    the code runs faster. The execution time for these functions is shown next—clearly,
    the `using_try` function performs better:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Choosing the right data structures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is fairly a broad topic. The choice of data structure largely depends on
    the problem you are trying to solve. In this section, we will limit our discussion
    to just one example that shows how the right choice of data structure improves
    the runtime performance. Observe the `data_struct_choice_list` function; it first
    creates a list object, `mylist`. Next, inside a `for` loop, the code checks if
    `j` is one of the elements of `mylist` and updates the `val` parameter accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '![Choosing the right data structures](img/B05034_08_24.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now look at the following `data_struct_choice_set` function. Instead of a `list`
    object, it creates a `set` object denoted by the `myset` variable. The syntax
    is similar to the `list` or dictionary comprehension syntax we saw earlier (the
    rest of the code remains the same and both the functions return the same value).
  prefs: []
  type: TYPE_NORMAL
- en: '![Choosing the right data structures](img/B05034_08_25.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: When it comes to checking the membership of an element, the Python `set` is
    faster compared to a `list`. In other words, the "`if (j in myset)`" operation
    is faster compared to "`if (j in mylist)`". As summarized in a table in [Chapter
    7](ch07.html "Chapter 7. Performance – Identifying Bottlenecks"), *Performance
    – Identifying Bottlenecks*, the average-case time complexity of this operation
    is *O(1)* for `set` and *O(n)* for `list`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `timeit` output for these two functions is shown next. Clearly, the function
    that implements `set` is much faster compared to the one that implements `list`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Have you noticed a problem in this example? The runtime reported by `timeit`
    includes the time required to create the `list` and `set` objects. For an accurate
    comparison, you should only compare the `for` loops in these functions. In other
    words, move the `list` and `set` creation part out of the function definition
    and then do the timing comparison.
  prefs: []
  type: TYPE_NORMAL
- en: Let's continue the discussion on the data structures and review Python's `collections`
    module next.
  prefs: []
  type: TYPE_NORMAL
- en: The collections module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `collections` module offers a number of special purpose container data types.
    Let's review a few of the common ones. If you want to know about the other data
    structures in this module, see the Python documentation ([https://docs.python.org/3/library/collections.html](https://docs.python.org/3/library/collections.html)).
  prefs: []
  type: TYPE_NORMAL
- en: The deque class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `deque` class enables appending or deleting elements from either side of
    the `deque` data structure. The `append` and `pop` operations in `deque` class
    are memory efficient and thread-safe with a complexity of *O(1)*. The following
    code shows a simple way to create `deque` and then remove the rightmost element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s compare the performance of `deque` with an equivalent `list`. Observe
    the following two functions, where we call the `pop()` method of the `list` and
    `deque` classes—note that we are creating the `list` and `deque` objects outside
    of these functions to make sure that the reported timing is not influenced by
    the object creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The deque class](img/B05034_08_26.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following `timeit` output shows that the `pop()` operation on `deque` is
    faster compared to that of `list`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: So, when should we use `deque`? In general, if your code involves a lot of operations
    where the data needs to be appended or popped from one of the ends, `deque` is
    preferred over a `list`. But, if the code needs fast random access to the elements,
    `list` is a better choice of data structure.
  prefs: []
  type: TYPE_NORMAL
- en: The defaultdict class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `defaultdict` class is derived from the built-in `dict` class. If you try
    to access a key that doesn''t exist, a simple Python dictionary throws a `KeyError`
    exception. But, a `defaultdict` class creates a new key instead. This can be better
    explained with the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The standard dictionary object, `d1`, doesn''t have an `''a''` key, so it throws
    an error. If you try to access this key with a `defaultdict` class, it simply
    creates it, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The built-in `setdefault()` method of the standard dictionary does a similar
    job. If the key you are trying to access does not exist, it inserts a new key
    in the dictionary, assigns a default value to it, and returns this default. However,
    using `defaultdict` is faster compared to the `setdefault` method. Refer to the
    documentation ([https://docs.python.org/3/library/stdtypes.html#dict](https://docs.python.org/3/library/stdtypes.html#dict))
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: This is just one of the features offered by `defaultdict`. It also provides
    an efficient means to count the number of times an element occurs in a container.
    Let's see this with an example. The following `dict_counter` function defines
    a `list` called `game_characters`. There are many repeating elements in this `list`.
    The function uses a standard dictionary to count how many times each element occurs,
    and then returns this dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '![The defaultdict class](img/B05034_08_27.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For example, the output of this function will be a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The `sample_size_1` is just a multiplication factor to make this list big enough
    to see the difference in the execution time. In this example, it is chosen as
    `100000`. Now, let''s write a function that uses a `defaultdict` class to do the
    same job. Take a look at how compact the resulting code is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The defaultdict class](img/B05034_08_28.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s compare the performance of these two functions. The following `timeit`
    output confirms that the function implementing `defaultdict` runs faster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The counting operation can also be performed using the `collections.Counter`
    class. The syntax is simple and efficient compared to a `defaultdict` class (we
    will not discuss the `Counter` class in this book). As an exercise, read the documentation
    and write a function that uses the `Counter` class for the earlier example.
  prefs: []
  type: TYPE_NORMAL
- en: Generators and generator expressions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **generator** is basically an iterator. It is a powerful tool to handle a
    very large, or an infinite data set. A generator function is written just like
    a regular function, but is characterized by the use of the `yield` statement.
    It is similar to a `return` statement, in the sense that it returns a value. However,
    a generator function "freezes" the current environment after it yields. So, the
    next time you want a value, the generator function continues from where it left
    off and yields the next value.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, a generator returns values (say from a list) one at a time,
    keeps track of the current state of the iteration (remembers all the values it
    has returned in the previous calls), and when called again, it picks up from the
    position where it left off. When you add a `yield` statement to a function, it
    automatically becomes a generator function. Let''s write a trivial example to
    understand this concept better:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The `get_data()` function returns a generator object, `g`. The `next()` function
    is just one way of getting the values from the generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'For the first iteration in the `get_data()` function, we have `i=0` . So, the
    value returned by the generator is `i*i=0`. Now comes the interesting part. Let''s
    call the `next()` function again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'It returned the value as `1`. This corresponds to the next value of the iterator
    in the `get_data()` function, `i=1`, which makes `i*i=1`. If we call `next()`
    one more time, it will return the result for `i=2`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This will continue until the generator is exhausted with all the values. If
    we call `next()` again, it raises a `StopIteration` exception, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Using the `yield` statement is one way of creating a generator function, and
    hence a generator object. Let's learn about the generator expression, which provides
    another way to create a generator object.
  prefs: []
  type: TYPE_NORMAL
- en: Generator expressions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The generator expression is proposed as *PEP 289* and is summarized as a high
    performance memory efficient generalization of list comprehension and generators.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Refer to [https://www.python.org/dev/peps/pep-0289](https://www.python.org/dev/peps/pep-0289)
    for further details on *PEP 289*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic syntax for a generator expression is similar to that of a list comprehension.
    Instead of square brackets `[]`, it uses the round brackets `()` to create a generator
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We already saw how to use the `next()` function to get values out of a generator
    object. You can also get the data from a generator using a `for` loop, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see a simple example where a generator expression can be used. The built-in
    `sum` function accepts an iterable as an input. It sums all the elements of that
    iterable and returns the total sum as a single value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Note that you can even pass a `list` to the `sum()` method to get the same result.
    Next, we will compare the memory efficiency of a generator expression with that
    of a list comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing the memory efficiency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For a moderately-sized problem, the runtime performance of a list comprehension
    is typically better compared to an equivalent generator expression. We won't make
    that comparison here. Instead, we will see how the generator expression and the
    list comprehension compare when it comes to memory consumption.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous chapter, we saw how to use the `memory_profiler` package. Let''s
    use it here to profile the memory usage. Create a `compare_memory.py` file or
    download it from the supporting code bundle for this chapter. The code is shown
    next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing the memory efficiency](img/B05034_08_29.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `list_comp_memory` function creates a `list` using the list comprehension
    syntax. The `generator_expr_memory` function creates a generator object using
    the generator expression syntax. The `@profile` decorator marks the function for
    profiling by the memory profiler. Let''s run the `memory_profiler` function on
    this file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output of this run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing the memory efficiency](img/B05034_08_30.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s review the output achieved from the profiling done on the `compare_memory.py`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: The `Increment` column indicates that the list comprehension creates a `list`
    and puts it in the memory. In the present example, it consumes about 0.37 MiB.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The memory profiler reports the usage in MiB. For the generator expression,
    it reports 0.0 MiB or interprets it as only a few bytes in this example.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you increase the `sample_size` variable further, the memory consumed by the
    list comprehension will increase accordingly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a very large `sample_size`, your computer may even choke while creating
    the `list` with the list comprehension.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the generator expression, the memory consumed will remain constant, no
    matter how large the data size gets. This is an extremely useful feature when
    operating on a very large or an infinite data set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generator expressions or list comprehensions?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Generator expressions or list comprehensions?](img/B05034_08_31.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *Good question. How to decide between generator expressions and list comprehensions?
    The choice depends on the type of problem you are dealing with. The following
    points should help you make that decision:* |'
  prefs: []
  type: TYPE_TB
- en: Use generator expressions when you are working with a very large (or infinite)
    data set, iterated over only once. The list comprehension puts the whole list
    in the memory, which works fine on small or mid-sized data sets. However, as the
    data size grows bigger, you will notice problems. The generator expression, on
    the other hand, uses constant memory. It returns data on the fly. Once the data
    is generated, the memory is freed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is really another way to put the first point. Do not use generator expressions
    if you want to loop over the whole data set several times. In such cases, use
    the list comprehension.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generator expressions do not support list operations such as **slicing**. So,
    if you want to perform such operations, use the list comprehension.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The itertools module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we know how the generator expressions work, let's briefly review `itertools`,
    another important built-in module in Python. It provides functionality to create
    iterators for efficient looping. The `itertools` module offers several building
    blocks for iterators. Some of the frequently used iterators include `count()`,
    `repeat()`, `chain()`, `groupBy()`, `tee()`, `product()`, `permutation()`, `combination()`,
    and so on. This is just a partial list of the supported functionality. In this
    chapter, we will only review the `chain()` iterator.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Refer to [https://docs.python.org/3/library/itertools.html](https://docs.python.org/3/library/itertools.html)
    for information on other iterators offered by the `itertools` module.
  prefs: []
  type: TYPE_NORMAL
- en: The itertools.chain iterator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This iterator is used to chain multiple iterators together. It can take lists,
    tuples, generators, or even a combination of these iterators as an input. Let''s
    review a simple example that shows how to create a `chain` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The simplest way to view the contents of this `chain` object is to print it
    as a new `list` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'As can be seen, the `chain` iterator combined the two input lists and a tuple
    (or the iterators). Sometimes, you want to perform identical operations on more
    than one list or any other iterable data structures. The `chain` iterator enables
    this by combining or chaining these data structures. More importantly, it does
    not consume any significant amount of memory. Just like a generator, the memory
    consumed by a `chain` object remains constant even when the size of the data grows
    bigger. It is also important to note that, just like a generator, a `chain` object
    can be used to iterate over a given data set only once. This is illustrated by
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: You can compare the memory efficiency of a `chain` object with an equivalent
    code that combines the input lists. The code is shown next. The `for` loop in
    these functions is just to illustrate how the `chain` object can be used in a
    loop.
  prefs: []
  type: TYPE_NORMAL
- en: '![The itertools.chain iterator](img/B05034_08_32.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also find this code in `compare_memory.py`. In this file, just add
    the `@profile` decorator. With this change, run the memory profiler as an exercise.
    The following can be observed from the memory profiler output (not shown here):'
  prefs: []
  type: TYPE_NORMAL
- en: The `chain` object consumes about 0.004 MiB memory and the consumption remains
    constant even after you increase the size of the input lists, `data_1`, `data_2`
    and `data_3`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `list_memory` function consumes nearly 0.383 MiB of memory to create the
    `mylist` object. The memory consumed by this function increases with the input
    data size.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A few exercises were already suggested. Let''s list a few of these. (Note that
    the solution are not provided for these exercises.):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Write a list comprehension syntax for a nested `for` loop. Compare the timings
    of a nested `for` loop and the list comprehension. Here is an example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Write a generator expression for the preceding list comprehension. You just
    need to change the outer square brackets `[]` to the round brackets `()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned many techniques that help cut down the application's
    runtime. We started by improving the speed of the *Gold Hunt* application. The
    total time taken to run this application was improved by more than 50%—we accomplished
    this by changing the algorithm so that it does not need to compute the square
    root for distance comparison. Two more changes knocked off a few more seconds
    from the total execution time. We avoided the function re-evaluation (skipped
    the "dots") and preferred local scope for the variables over global scope. This
    was the end of *part one* of the performance improvement for the *Gold Hunt* program.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on, the chapter taught you a number of ways that help speed up the code.
    It illustrated how a list comprehension does a better job compared to an equivalent
    `for` loop. We also saw how the choice of data structure affects the performance.
    The chapter further introduced us to the generator expressions that offer memory
    advantage over the list comprehensions. Additionally, we also briefly reviewed
    the functionality offered by the `itertools` and `collections` modules.
  prefs: []
  type: TYPE_NORMAL
- en: We promised *The Great Dwarf* further improvements to the application. In the
    next chapter, let's learn the things that will help us keep our promise!
  prefs: []
  type: TYPE_NORMAL
