- en: Chapter 6. Audio Controls and Effects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。音频控制和效果
- en: In the previous chapter, the focus was on learning fundamentals of audio processing.
    It introduced us to the GStreamer multimedia framework. We applied this knowledge
    to develop some frequently needed audio processing tools. In this chapter, we
    will go one step further by developing tools for adding audio effects, mixing
    audio tracks, creating custom music tracks, and so on.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在上一章中，我们的重点是学习音频处理的基础知识。它向我们介绍了 GStreamer 多媒体框架。我们应用这些知识开发了一些常用的音频处理工具。在这一章中，我们将更进一步，开发添加音频效果、混音音频轨道、创建自定义音乐轨道等工具。
- en: 'In this chapter, we shall:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将：
- en: Learn how to control a streaming audio.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何控制流音频。
- en: Spice up the audio by adding effects such as fading, echo, and panorama.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过添加如淡入淡出、回声和全景等效果来增强音频。
- en: Work on a project where a custom music track will be created by combining different
    audio clips.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个项目中工作，通过组合不同的音频片段创建自定义音乐轨道。
- en: Add visualization effect to a streaming audio.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向流音频添加可视化效果。
- en: Mix two audio streams into a single track. For example, mix an audio containing
    only a *vocal track* with an audio containing only *background music track*.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将两个音频流混合成单个轨道。例如，将只包含*人声轨道*的音频与只包含*背景音乐轨道*的音频混合。
- en: So let's get on with it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们开始吧。
- en: Controlling playback
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制播放
- en: In an audio player, various options such as Play, Pause, Stop, and so on, provide
    a way to control the streaming audio. Such playback controls also find use in
    other audio processing techniques. We have already used some of the playback controls
    in [Chapter 5](ch05.html "Chapter 5. Working with Audios"), *Working with Audios*.
    In this chapter, we will study some more controlling options.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在音频播放器中，各种选项如播放、暂停、停止等，提供了一种控制流音频的方式。这些播放控制也在其他音频处理技术中得到应用。我们已经在[第5章](ch05.html
    "第5章。处理音频") *处理音频* 中使用了一些播放控制。在这一章中，我们将研究更多的控制选项。
- en: Play
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 播放
- en: 'In the previous chapter, we developed a preliminary command-line audio player
    using GStreamer. The audio streaming can be started by instructing the GStreamer
    pipeline to begin the flow of audio data. This was achieved by the following code:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们使用 GStreamer 开发了一个初步的命令行音频播放器。可以通过指示 GStreamer 管道开始音频数据的流动来启动音频流。这是通过以下代码实现的：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With the above instruction, the audio will be streamed until the end of the
    stream is reached. Refer to the code in the *Playing Audio* section of [Chapter
    5](ch05.html "Chapter 5. Working with Audios"), *Working with Audios* to see what
    the surrounding code looks like. If you develop a user interface for a simple
    audio player, the "Play" button can be connected to a method that will set the
    state of pipeline to `gst.STATE_PLAYING`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述指令，音频将一直流出到流结束。参考[第5章](ch05.html "第5章。处理音频") *处理音频* 中 *播放音频* 部分的代码，看看周围的代码是什么样的。如果你为简单的音频播放器开发用户界面，可以将“播放”按钮连接到一个方法，该方法将设置管道状态为
    `gst.STATE_PLAYING`。
- en: Pause/resume
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 暂停/恢复
- en: The streaming audio can be paused temporarily by setting the GStreamer pipeline
    state to `gst.STATE_PAUSED`. Pausing music in an audio player is another commonly
    performed operation. But this also finds use while doing some special audio processing.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过将 GStreamer 管道状态设置为 `gst.STATE_PAUSED` 来暂时暂停流音频。在音频播放器中暂停音乐是另一个常见的操作。但这在执行一些特殊音频处理时也有用途。
- en: Time for action - pause and resume a playing audio stream
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 暂停和恢复播放音频流
- en: We will now review a very simple example demonstrating various playback control
    techniques. The same example will be used in the next few sections. This exercise
    will be an ideal preparation while working on the project 'Extract Audio Using
    Playback Controls'. So let's get started!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将回顾一个非常简单的示例，演示各种播放控制技术。在接下来的几个部分中，将使用相同的示例。这个练习将在“使用播放控制提取音频”项目中进行时是一个理想的准备。那么，让我们开始吧！
- en: Download the file `PlaybackControlExamples.py` from the Packt website. This
    file has all the necessary code that illustrates various playback controls. The
    overall class and its methods are illustrated below for reference. See the source
    file to know more about each of these methods.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Packt 网站下载文件 `PlaybackControlExamples.py`。此文件包含展示各种播放控制的必要代码。以下是对整体类及其方法的参考说明。查看源文件以了解更多关于这些方法的信息。
- en: '[PRE1]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The overall code layout is very similar to the code developed in the Playing
    audio section of Chapter 5, Working with Audios. Thus, we will just review some
    of the newly added methods relevant to this section.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 整体代码布局与第5章“与音频工作”部分中“播放音频”小节开发的代码非常相似。因此，我们只需回顾一些与该部分相关的新增方法。
- en: Here is the code for `self.play` method.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是`self.play`方法的代码。
- en: '[PRE2]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Inside the while loop, on line 9, the current position of the streaming audio
    is queried using the query_position call. This is an API method of GStreamer Pipeline
    object. When the pipeline approaches the end of the stream, it may throw an error
    while querying the current position. Therefore, we catch the exception gst.QueryError,
    in the try-except block. The time.sleep call is important before entering the
    try-except block. It ensures that the position is queried every 0.5 seconds. If
    you remove this call, the next code will be executed for each incremental tiny
    step. From a performance standpoint this is unnecessary. The current position
    thus obtained is expressed in nanoseconds, Thus, if the time is say 0.1 seconds,
    it is obtained as 100 000 000 nanoseconds. To convert it into seconds, it is divided
    by a GStreamer constant gst.SECOND. On line 30, the main method that runs various
    audio control examples is called.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在while循环中，第9行使用`query_position` 调用查询流式音频的当前位置。这是GStreamer Pipeline对象的API方法。当流接近结束时，在查询当前位置时可能会抛出错误。因此，我们在try-except块中捕获`gst.QueryError`异常。在进入try-except块之前，`time.sleep`
    调用非常重要。它确保每0.5秒查询一次位置。如果你删除这个调用，下一行代码将在每个增量的小步骤上执行。从性能的角度来看，这是不必要的。因此获得的位置以纳秒表示，因此，如果时间是0.1秒，它将以10
    000 000纳秒获得。为了将其转换为秒，它被除以GStreamer常量`gst.SECOND`。在第30行，调用运行各种音频控制示例的主方法。
- en: Let's see the code in `self.runExamples` method now.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们看看`self.runExamples`方法中的代码。
- en: '[PRE3]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The method self.okToRunExamples does some preliminary error checking and ensures
    that the total streaming duration is greater than 20 seconds. This method will
    not be discussed here. When the current track position reaches 5 seconds, one
    of the examples is run. Which example to run is determined by the corresponding
    boolean flag. For instance, if self.pause_example flag is set to True, it will
    run the code that will 'pause' the audio stream. Likewise for the other examples.
    These three flags are initialized to False in the __init__ method.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`self.okToRunExamples`方法进行一些初步的错误检查，并确保总流式传输时间超过20秒。这里不会讨论这个方法。当当前轨道位置达到5秒时，将运行一个示例。运行哪个示例由相应的布尔标志确定。例如，如果`self.pause_example`标志设置为True，它将运行将“暂停”音频流的代码。其他示例也是如此。这三个标志在`__init__`方法中初始化为False。'
- en: The last method we will review is `self.runPauseExample`.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将要回顾的最后一个方法是`self.runPauseExample`。
- en: '[PRE4]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The streaming audio is paused by the call on line 4\. The time.sleep call will
    keep the audio paused for 5 seconds and then the audio playback is resumed by
    the call on line 7.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 流式音频在第四行被调用暂停。`time.sleep` 调用将使音频暂停5秒钟，然后通过第七行的调用恢复音频播放。
- en: 'Make sure to set the flag `self.pause_example` to True in the `__init__` method
    and specify the proper audio file path for the variable for `self.inFileLocation`.
    Then run this example from the command prompt as:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保在`__init__`方法中将`self.pause_example`标志设置为True，并为`self.inFileLocation`变量指定正确的音频文件路径。然后从命令提示符运行此示例：
- en: '[PRE5]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The audio will be played for the first 5 seconds. It will be then paused for
    another 5 seconds and finally the playback will be resumed.
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频将播放前5秒钟。然后暂停5秒钟，最后恢复播放。
- en: What just happened?
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: With the help of a simple example, we learned how to pause a streaming audio.
    We also saw how the current position of the streaming audio is queried. This knowledge
    will be used in a project later in this chapter.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一个简单的示例，我们学习了如何暂停流式音频。我们还看到了如何查询流式音频的当前位置。这些知识将在本章后面的项目中使用。
- en: Stop
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 停止
- en: Setting the state of the GStreamer pipeline to `gst.STATE_NULL` stops the audio
    streaming. Recall the `message_handler` method explained in the Playing Audio
    section of the previous chapter. We made use of this state when the end of stream
    message was put on the `bus`. In the file `PlaybackControlExamples.py`, the following
    code stops the streaming of the audio.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 将GStreamer管道的状态设置为`gst.STATE_NULL`将停止音频流。回想一下前一章“播放音频”部分中解释的`message_handler`方法。我们在将流结束消息放在`bus`上时使用了这个状态。在`PlaybackControlExamples.py`文件中，以下代码停止了音频的流式传输。
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this file, set the flag `self.stop_example` to `True` and then run the program
    from the command line to see this illustration.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个文件中，将标志`self.stop_example`设置为`True`，然后从命令行运行程序以查看这个示例。
- en: Fast-forward/rewind
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快进/倒带
- en: Fast-forwarding or rewinding a track simply means that the current position
    on the audio track being played is shifted to some other position. This is also
    called seeking a position on a track. The `pipeline` element of GStreamer defines
    an API method, `seek_simple`, that facilitates jumping to a specified position
    on the track in a streaming audio. In the file `PlabackControlExamples.py`, this
    is illustrated by the following method.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 快进或倒带一个音轨简单来说就是将正在播放的音频轨道上的当前位置移动到另一个位置。这也被称为在音轨上定位位置。GStreamer的`pipeline`元素定义了一个API方法`seek_simple`，它简化了在流式音频中跳转到音轨上指定位置的操作。在`PlabackControlExamples.py`文件中，这通过以下方法进行了说明。
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: When this method is called, the current audio position is shifted to a position
    corresponding to 15 seconds duration on the audio track. The highlighted lines
    of code are the key. The `seek_simple` method takes three arguments. The first
    argument, `gst.FORMAT_TIME`, represents the time on the track. The second argument,gst.SEEK_GLAG_FLUSH,
    is a 'seek flag'. It tells the pipeline to clear the currently playing audio data.
    In other words it instructs to flush the pipeline. This makes the seek operation
    faster according to the documentation. There are several other seek flags. Refer
    to the GStreamer documentation to know more about these flags. The third argument
    specifies the time on the track that will be the new 'current position' of the
    streaming audio. This time I specified in nanoseconds and so, it is multiplied
    by a constant `gst.SECOND`. Note that pipeline should be in playing state, before
    calling `seek_simple` method.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当调用此方法时，当前音频位置将移动到音频轨道上对应15秒持续时间的位置。代码中的高亮行是关键。`seek_simple`方法接受三个参数。第一个参数`gst.FORMAT_TIME`代表音轨上的时间。第二个参数`gst.SEEK_FLAG_FLUSH`是一个“定位标志”。它告诉管道清除当前正在播放的音频数据。换句话说，它指示清空管道。根据文档，这使得定位操作更快。还有其他几个定位标志。请参阅GStreamer文档以了解更多关于这些标志的信息。第三个参数指定了音轨上的时间，这将成为流式音频的新“当前位置”。这次我指定了纳秒，因此它乘以一个常数`gst.SECOND`。请注意，在调用`seek_simple`方法之前，管道应该处于播放状态。
- en: 'Project: extract audio using playback controls'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目：使用播放控制提取音频
- en: In the last chapter, we learned how to use `gnonlin` plugin to extract a piece
    of audio. `Gnonlin` made our job very easy. In this project, we will see another
    way of extracting the audio files, by applying basic audio processing techniques
    using GStreamer. We will use some of the audio playback controls just learned.
    This project will serve as a refresher on various fundamental components of GStreamer
    API.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一章，我们学习了如何使用`gnonlin`插件提取音频片段。`Gnonlin`使我们的工作变得非常简单。在这个项目中，我们将看到另一种提取音频文件的方法，即通过使用GStreamer的基本音频处理技术。我们将使用刚刚学到的某些音频播放控制。这个项目将作为GStreamer
    API各种基本组件的复习。
- en: Time for action - MP3 cutter from basic principles
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 从基本原理开始的MP3裁剪
- en: Let's create an MP3 cutter from 'basic principles'. That is we won't be using
    `gnonlin` to do this. In this project, we will apply knowledge about seeking a
    track playing, pausing the pipeline along with the basic audio processing operations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个从“基本原理”开始的MP3裁剪器。也就是说，我们不会使用`gnonlin`来完成这个任务。在这个项目中，我们将应用关于定位播放音轨、暂停管道以及基本音频处理操作的知识。
- en: 'This utility can be run from the command line as:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此实用程序可以从命令行运行：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Where, the `[options]` are as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，`[options]`如下：
- en: '`--input_file:` The input audio file in MP3 format from which a piece of audio
    needs to be cut.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--input_file:` 需要从其中裁剪音频片段的MP3格式的输入音频文件。'
- en: '`--output_file:` The output file path where the extracted audio will be saved.
    This needs to be in MP3 format.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--output_file:` 存储提取音频的输出文件路径。这需要是MP3格式。'
- en: '`--start_time:` The position in seconds on the original track. This will be
    the starting position of the audio to be extracted.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--start_time:` 在原始音轨上的秒数位置。这将是提取音频的起始位置。'
- en: '`--end_time:` The position in seconds on the original track. This will be the
    end position of the extracted audio.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--end_time:` 在原始音轨上的秒数位置。这将是提取音频的结束位置。'
- en: '`--verbose_mode:` Prints useful information such as current position of the
    track (in seconds) while extracting the audio. By default, this flag is set to
    `False`.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--verbose_mode:` 在提取音频时打印有用的信息，例如音轨的当前位置（以秒为单位）。默认情况下，此标志设置为`False`。'
- en: Download the file `AudioCutter_Method2.py` from the Packt website. We will discuss
    only the most important methods here. You can refer to the source code in this
    file for developing the rest of the code.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Packt 网站下载文件 `AudioCutter_Method2.py`。在这里，我们只讨论最重要的方法。你可以参考这个文件中的源代码来开发其余的代码。
- en: We will start as usual, by defining a class with empty methods.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将像往常一样开始，定义一个具有空方法的类。
- en: '[PRE9]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As you can see, the overall structure and the method names are very much consistent
    with the MP3 cutter example in earlier chapters. Instead of method `gnonlin_pad_added`
    we have `decodebin_pad_added` which indicates we are going to capture the `pad_added`
    signal for the `decodebin`. Also, there are new methods `run` and `extractAudio`.
    We will discuss these in detail.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如你所见，整体结构和方法名与前面章节中的 MP3 切割示例非常一致。我们不再有 `gnonlin_pad_added` 方法，而是有 `decodebin_pad_added`，这表明我们将捕获
    `decodebin` 的 `pad_added` 信号。此外，还有新的方法 `run` 和 `extractAudio`。我们将详细讨论这些方法。
- en: Now let's review the constructor of the class.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来回顾一下类的构造函数。
- en: '[PRE10]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `__init__` method calls methods to process user input and then constructs
    the GStreamer pipeline by calling the `constructPipeline()` method. This is similar
    to what we have seen in several examples earlier.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`__init__` 方法调用方法处理用户输入，然后通过调用 `constructPipeline()` 方法构建 GStreamer 管道。这与我们在前面几个示例中看到的情况类似。'
- en: Think about this. To extract an audio, what elements do you need? We need all
    the elements used in audio conversion utility developed in last chapter. Note
    that in this example we are saving the output in the same audio format as the
    input. Let's try to construct an initial pipeline.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 想想这个问题。要提取音频，你需要哪些元素？我们需要在上一章开发的音频转换工具中使用的所有元素。请注意，在这个示例中，我们将输出保存为与输入相同的音频格式。让我们尝试构建一个初始管道。
- en: '[PRE11]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We are already familiar with most of the elements included in this pipeline.
    The pipeline looks identical to the one in audio conversion utility except for
    the sink element. Notice that the `filesink` element is created on line 18\. But
    it is not added to the pipeline! Instead we have added a `fakesink` element. Can
    you guess why? This is an extraction utility. We just need to save a portion of
    an input audio file. The start position of the extracted portion may not be the
    start position of the original track. Thus, at this time, we will not add the
    `filesink` to the pipeline.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经熟悉了包含在这个管道中的大多数元素。管道看起来与音频转换工具中的管道相同，只是 sink 元素不同。注意，在第 18 行创建了 `filesink`
    元素。但是，它没有被添加到管道中！相反，我们添加了一个 `fakesink` 元素。你能猜到为什么吗？这是一个提取工具。我们只需要保存输入音频文件的一部分。提取部分的起始位置可能不是原始轨道的起始位置。因此，在这个时候，我们不会将
    `filesink` 添加到管道中。
- en: Next write the `AudioCutter.run` method.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来编写 `AudioCutter.run` 方法。
- en: '[PRE12]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: On line 4, we apply one of the playback control commands to instruct the pipeline
    to 'begin'. The state of the input audio is set to `STATE_PLAYING`. As seen earlier,
    the flag `self.is_playing` is changed in the `message_handler` method. In the
    `while` loop, the workhorse method `self.extractAudio()` is called. The rest of
    the code is self-explanatory.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第 4 行，我们应用了一个播放控制命令来指示管道开始播放。输入音频的状态被设置为 `STATE_PLAYING`。如前所述，`self.is_playing`
    标志在 `message_handler` 方法中被更改。在 `while` 循环中，调用工作马方法 `self.extractAudio()`。其余的代码是自解释的。
- en: Now we will review the method that does the job of cutting the piece of input
    audio. Let us first see the important things considered in `extractAudio()` method.
    Then it will be very easy to understand the code. This following illustration
    lists these important things.![Time for action - MP3 cutter from basic principles](img/0165_06_01.jpg)
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将回顾执行切割输入音频片段工作的方法。让我们首先看看在 `extractAudio()` 方法中考虑的重要事项。然后，理解代码将会非常容易。下面的插图列出了这些重要事项。![时间行动
    - 从基本原理开始的 MP3 切割](img/0165_06_01.jpg)
- en: Important steps considered in AudioCutter.extractAudio() method appear in the
    preceding image.
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `AudioCutter.extractAudio()` 方法中考虑的重要步骤在前面的图像中显示。
- en: To extract a piece of audio from the input, the flow of data through the pipeline
    needs to be 'started'. Then, we need to jump to a position in the input audio
    that corresponds to the start position of the audio file to be extracted. Once
    the start position is identified, the GStreamer pipeline needs to be tweaked so
    that there is a `filesink` element. The `filesink` will specify the output audio
    file. After setting the pipeline, we need to begin the flow of data. When the
    user-specified end position is reached, the program execution should stop. Now
    let's write the code.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从输入中提取一段音频，需要通过管道的数据流开始。然后，我们需要跳转到输入音频中对应于要提取的音频文件起始位置的点。一旦确定了起始位置，GStreamer管道需要调整，以便有一个`filesink`元素。`filesink`将指定输出音频文件。设置好管道后，我们需要开始数据流。当达到用户指定的结束位置时，程序执行应停止。现在让我们编写代码。
- en: '[PRE13]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The code block between lines 3 to 25 is executed only once, when the program
    enters this method for the first time. The flag `self.seek_done` ensures it is
    executed only once. This is an important piece of code that does the steps 2 to
    5 represented by rectangular blocks in the above illustration. Let's review this
    code in detail now.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码块在第3到25行之间执行，仅在程序第一次进入此方法时执行。标志`self.seek_done`确保它只执行一次。这是上述插图中的矩形块表示的步骤2到5的重要代码片段。现在让我们详细回顾这段代码。
- en: On line 3, we ask the program to wait for 0.1 seconds by `time.sleep` call.
    This is necessary for the next line of code that queries the total duration of
    the playback. The API method query duration returns the total duration of the
    playback. The argument `gst.FORMAT_TIME` ensures that the return value is in time
    format (nanoseconds). To get it in seconds, we divide it by `gst.SECOND`.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第3行，我们通过`time.sleep`调用让程序等待0.1秒。这是为了下一行代码查询播放总时长所必需的。API方法`query duration`返回播放的总时长。参数`gst.FORMAT_TIME`确保返回值是以时间格式（纳秒）表示的。为了将其转换为秒，我们需要将其除以`gst.SECOND`。
- en: Next, on lines 15-17, we jump to the position on the input audio track pertaining
    to the user-supplied argument `self.start_time`. Note that the time argument in
    the method `seek_simple` needs to be in nanoseconds. So it is multiplied by `gst.SECOND`.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在第15-17行，我们跳转到输入音频轨道中与用户提供的参数`self.start_time`相对应的位置。请注意，方法`seek_simple`中的时间参数需要以纳秒为单位。因此，它乘以`gst.SECOND`。
- en: On line 19, the `gst.STATE_PAUSED` call pauses the flow of data in the pipeline.
    The `fakesink` element is removed from the pipeline with `self.pipline.remove`
    call. This also unlinks it from the pipeline. Then the `self.filesink` element
    is added and linked in the pipeline on lines 23 and 24\. With this, we are all
    set to start playing the audio file again. Here onwards, the audio data will be
    saved to the audio file indicated by the `filesink` element.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第19行，`gst.STATE_PAUSED`调用暂停了管道中的数据流。通过`self.pipline.remove`调用从管道中移除`fakesink`元素。这也将其从管道中解链。然后，在第23和24行将`self.filesink`元素添加到管道中并连接。这样，我们就准备好再次播放音频文件了。从现在开始，音频数据将保存到由`filesink`元素指示的音频文件中。
- en: On line 27, the current position being played is queried. Note that this is
    done in a try-except block to avoid any possible error while querying the position
    when the audio is very near to the end of the file. When `self.position` reaches
    the specified `self.end_time`, the data flow through the pipeline is stopped by
    the `gst.STATE_NULL` call.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第27行，查询正在播放的当前位置。请注意，这是在try-except块中完成的，以避免在音频接近文件末尾时查询位置时出现任何可能的错误。当`self.position`达到指定的`self.end_time`时，通过`gst.STATE_NULL`调用停止通过管道的数据流。
- en: Write other methods such as `decodebin_pad_added, connectSignals`. The source
    code can be found in the file `AudioCutter_Method2.py`.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写其他方法，如`decodebin_pad_added`、`connectSignals`。源代码可以在文件`AudioCutter_Method2.py`中找到。
- en: We are now all set to run the program. Run it from the command line by specifying
    the appropriate arguments mentioned at the beginning of this section.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经准备好运行程序了。通过指定本节开头提到的适当参数，从命令行运行它。
- en: What just happened?
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: By applying fundamental audio processing techniques, we developed an MP3 cutter
    utility. This is just another way of extracting audio. We accomplished this task
    by making use of various playback controls learned in earlier sections.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用基本的音频处理技术，我们开发了一个MP3切割工具。这是提取音频的另一种方式。我们通过利用前面章节中学到的各种播放控制完成了这项任务。
- en: Adjusting volume
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整音量
- en: One of the most common audio operations we perform is to adjust the volume level
    of a playing audio. Suppose you have a collection of your favourite songs on your
    computer. You have been adding songs to this collection from various sources over
    the years and have created a 'playlist' so that you can listen to them one after
    the other. But some of the songs start much louder than the others. Of course
    you can adjust the volume every time such songs start playing but that's not what
    you would like to do is it?? You want to fix this, but how? Let's learn how!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行的最常见的音频操作之一是调整正在播放的音频的音量级别。假设你在电脑上有一系列你最喜欢的歌曲。多年来，你从各种来源添加歌曲到这个收藏夹，并创建了一个
    '播放列表'，以便你可以一首接一首地听。但有些歌曲的音量比其他歌曲大得多。当然，每次这样的歌曲开始播放时，你可以调整音量，但这不是你想要的，对吧？你想要解决这个问题，但怎么做呢？让我们来学习一下！
- en: The `volume` element in GStreamer can be used to control the volume of the streaming
    audio. It is classified as a type of audio filter. Run `gst-inspect-0.10` command
    on `volume` to know more details about its properties.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: GStreamer 中的 `volume` 元素可以用来控制流音频的音量。它被归类为一种音频过滤器。运行 `gst-inspect-0.10` 命令来了解其属性的更多详细信息。
- en: How will you adjust volume using the command-line version of GStreamer? Here
    is the command on Windows XP that accomplishes this. You should use forward slashes
    as the backward slashes are not parsed properly by the 'location' property.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你将如何使用 GStreamer 命令行版本调整音量？以下是在 Windows XP 上完成此操作的命令。你应该使用正斜杠，因为反斜杠不能被 'location'
    属性正确解析。
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This pipeline is very similar to the audio playing example. All we did was to
    add a `volume` element after `audioconvert`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此管道与音频播放示例非常相似。我们只是添加了一个 `volume` 元素在 `audioconvert` 之后。
- en: Time for action - adjusting volume
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 调整音量
- en: Now let's develop a Python example of modifying volume of an audio file. We
    will write a utility that can take an input audio file and write the output file
    with increased or decreased level of the default volume. The utility will support
    writing audio files with MP3 format. If you need some other formats, you can extend
    this application. Refer to the Audio Converter project we did in the previous
    chapter.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开发一个修改音频文件音量的 Python 示例。我们将编写一个实用程序，它可以接受一个输入音频文件，并以增加或减少默认音量级别的方式写入输出文件。该实用程序将支持写入
    MP3 格式的音频文件。如果你需要其他格式，你可以扩展此应用程序。参考我们在上一章中做的 Audio Converter 项目。
- en: Download the file `AudioEffects.py` from Packt website. It has the source code
    for this example as well as for the *Fading effect*.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Packt 网站下载 `AudioEffects.py` 文件。它包含此示例以及 *淡入淡出效果* 的源代码。
- en: Write the constructor of the class `AudioEffects`.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写 `AudioEffects` 类的构造函数。
- en: '[PRE16]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The flag `self.fade_example` should be set to `False` in this example. You can
    ignore it for now. It will be used in the *Fading effects* section. Specify appropriate
    input and output audio file paths on lines 6 and 8.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此示例中，`self.fade_example` 标志应设置为 `False`。现在你可以忽略它。它将在 *淡入淡出效果* 部分中使用。在 6 和 8
    行指定适当的输入和输出音频文件路径。
- en: We will review the `self.constructPipeline()` method next.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将接下来查看 `self.constructPipeline()` 方法。
- en: '[PRE17]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Various GStreamer elements are created the usual way. On line 17, the volume
    element is created.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以通常的方式创建各种 GStreamer 元素。在第 17 行，创建了音量元素。
- en: The `volume` element has a "volume" property. This determines the level of volume
    in the streaming audio. By default, this has a value of 1.0 which indicates 100%
    of the current default volume of the audio. A value of 0.0 indicates no volume.
    A value greater than 1.0 will make the audio louder than the original level. Let's
    set this level as 2.0, which means the resultant volume will be louder than the
    original. The rest of the code in this method adds and links elements in the GStreamer
    pipeline.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`volume` 元素有一个 "volume" 属性。这决定了流音频的音量级别。默认情况下，此值为 1.0，表示音频的当前默认音量的 100%。0.0
    的值表示没有音量。大于 1.0 的值将使音频比原始级别更响亮。让我们将此级别设置为 2.0，这意味着生成的音量将比原始音量更大。此方法中的其余代码在 GStreamer
    管道中添加并链接元素。'
- en: Review the rest of the code from the file mentioned earlier. It is self- explanatory.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看之前提到的文件中的其余代码。它很直观。
- en: 'Run the program on the command prompt as:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在命令提示符下运行程序：
- en: Play the resultant audio and compare its default sound level with the original
    audio.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 播放生成的音频，并将其默认音量与原始音频进行比较。
- en: '[PRE18]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: What just happened?
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: With a very simple illustration, we learned how to change the default sound
    level of an audio file. What if you want to have varying sound levels at certain
    points in the audio? We will discuss that very soon, in the *Fading effects* section.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一个非常简单的示例，我们学习了如何更改音频文件的默认音量级别。如果您想在音频的某些点有不同的音量级别怎么办？我们将在 *淡入淡出效果* 部分很快讨论这个问题。
- en: Audio effects
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 音频效果
- en: One adds spices for improved taste to food, similarly, to enhance the music
    or any sound we add audio effects. There is a wide range of audio effect plugins
    available in GStreamer. We will discuss some of the commonly used audio effects
    in the coming sections.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 就像人们为了改善食物的味道而添加香料一样，为了增强音乐或任何声音，我们添加音频效果。GStreamer 中有各种各样的音频效果插件。在接下来的章节中，我们将讨论一些常用的音频效果。
- en: Fading effects
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 淡入淡出效果
- en: Fading is a gradual increase or decrease in the volume level of an audio. Fading-out
    means gradually decreasing the volume of the audio file as it approaches the end.
    Typically, at the end, the volume level is set as 0\. On similar lines, fade-in
    effect gradually increases the volume level from the beginning of an audio. In
    this chapter, we will learn how to add fade-out effect to an audio. Once we learn
    that, it is trivial to implement fade-in effects.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 淡入淡出是音频音量级别的逐渐增加或减少。淡出意味着随着音频接近结尾时逐渐降低音频文件的音量。通常，在结尾时，音量级别被设置为 0。类似地，淡入效果从音频的开始逐渐增加音量级别。在本章中，我们将学习如何向音频添加淡出效果。一旦我们学会了这一点，实现淡入效果就变得非常简单了。
- en: Time for action - fading effects
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动手时间 - 淡入淡出效果
- en: Let's add fade-out effect to an input audio. We will use the same source file
    as used in the *Adjusting volume* section.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们向输入音频添加淡出效果。我们将使用与 *调整音量* 部分中相同的源文件。
- en: If you haven't already, download the file `AudioEffects.py` that has the source
    code for this example.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您还没有下载，请下载包含此示例源代码的文件 `AudioEffects.py`。
- en: In the `__init__` method of this class, you will need to do one small change.
    Set the flag `self.fade_example` to `True` so that it now runs the code that adds
    fade-out effect.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个类的 `__init__` 方法中，您需要做一个小改动。将标志 `self.fade_example` 设置为 `True`，这样它现在将运行添加淡出效果的代码。
- en: We already reviewed the `self.constructPipeline()` method in *Adjusting volume*
    section. It calls the method `self.setupVolumeControl()`.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经在 *调整音量* 部分中回顾了 `self.constructPipeline()` 方法。它调用了 `self.setupVolumeControl()`
    方法。
- en: '[PRE19]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The GStreamer `Controller` object is created on line 2\. It is a light-weight
    object that provides a way to control various properties of GStreamer objects.
    In this case, it will be used to adjust the 'volume' property of `self.volume`.
    The set method of the `Controller` takes three arguments, namely, the property
    that needs to be controlled ("volume"), the time on the audio track at which it
    needs to be changed, and the new value of that property (self.volumeLevel). Here,
    the volume level at the beginning of the audio is set `self.volumeLevel`. Next,
    the interpolation mode is set for the `volume` property being adjusted by the
    `Controller` object. Here, we ask the `self.volumeControl` to linearly change
    the volume from its earlier value to the new value as the audio track progresses.
    For example, if the sound level at the beginning is set as 1.0 and at 30 seconds
    it is set as 0.5, the volume levels between 0 to 30 seconds on the track will
    be linearly interpolated. In this case it will linearly decrease from level 1.0
    at 0 seconds to level 0.5 at 30 seconds.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GStreamer 的 `Controller` 对象在第 2 行创建。它是一个轻量级对象，提供了一种控制 GStreamer 对象各种属性的方式。在这种情况下，它将被用来调整
    `self.volume` 的 'volume' 属性。`Controller` 的设置方法接受三个参数，即需要控制的属性（"volume"）、需要在音频轨道上更改属性的时间，以及该属性的新值（self.volumeLevel）。在这里，音频开始时的音量级别被设置为
    `self.volumeLevel`。接下来，为 `volume` 属性设置由 `Controller` 对象调整的插值模式。在这里，我们要求 `self.volumeControl`
    线性地从其早期值变化到新值，随着音频轨道的进行。例如，如果开始时的音量级别设置为 1.0，在 30 秒时设置为 0.5，那么在 0 到 30 秒之间的音量级别将在轨道上线性插值。在这种情况下，它将从
    0 秒的 1.0 级别线性降低到 30 秒的 0.5 级别。
- en: Tip
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: The GStreamer documentation suggests that `Controller.set_interpolation_mode`
    is deprecated (but is still backward compatible in the version 0.10.5 which is
    used in this book). See a 'TODO' comment in file `AudioEffects.py`.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GStreamer 文档建议 `Controller.set_interpolation_mode` 已被弃用（但在本书使用的 0.10.5 版本中仍然向后兼容）。请参阅文件
    `AudioEffects.py` 中的 'TODO' 注释。
- en: In order to add a fade-out effect towards the end, first we need to get the
    total duration of the audio being played. We can query the duration only after
    the audio has been set for playing (example, when it is in `gst.STATE_PLAYING`
    mode). This is done in `self.play()` method.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了在音频末尾添加淡出效果，首先我们需要获取正在播放的音频的总时长。我们只能在音频被设置为播放后查询时长（例如，当它处于`gst.STATE_PLAYING`模式时）。这是在`self.play()`方法中完成的。
- en: '[PRE20]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Once the pipeline's state is set to `gst.STATE_PLAYING`, the `self.addFadingEffects()`
    method will be called as shown by the highlighted line of code.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦将管道的状态设置为`gst.STATE_PLAYING`，就会调用`self.addFadingEffects()`方法，如代码中高亮显示的行所示。
- en: We will review this method now.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将回顾这个方法。
- en: '[PRE21]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: First we ensure that duration of the audio being played can be computed without
    any errors. This is done by the code block 2-24\. Next, the `fade_start` time
    is defined. At this control point the fade-out effect will begin. The fade-out
    will start 4 seconds before the end of the audio. The volume will linearly decrease
    from `fade_start` time to `fade_end` time. The fade_volume is the reference volume
    level when the fade-out begins. On lines 30 and 34 we actually set these fade
    timing and volume parameters for `self.volumeController` , the `Controller` object
    that adjusts the volume. The gradual decrease in the volume level is achieved
    by the `gst.INTERPOLATE_LINEAR`, discussed in an earlier step.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们确保正在播放的音频时长可以无错误地计算。这是通过代码块2-24完成的。接下来，定义了`fade_start`时间。在这个控制点，淡出效果将开始。淡出将在音频结束前4秒开始。音量将从`fade_start`时间线性减少到`fade_end`时间。`fade_volume`是淡出开始时的参考音量级别。在第30行和第34行，我们实际上为`self.volumeController`设置了这些淡出时间和音量参数，`self.volumeController`是调整音量的`Controller`对象。通过`gst.INTERPOLATE_LINEAR`（在早期步骤中讨论过）实现了音量级别的逐渐降低。
- en: 'Develop or review the remaining code using the reference file `AudioEffects.py`.
    Make sure to specify appropriate input and output audio paths for variables `self.inFileLocation`
    and `self.outFileLocation` respectively. Then run the program from the command
    line as:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用参考文件`AudioEffects.py`开发或审查剩余的代码。确保为变量`self.inFileLocation`和`self.outFileLocation`分别指定适当的输入和输出音频路径。然后从命令行运行程序，如下所示：
- en: This should create the output audio file, with a fade-out effect that begins
    4 seconds before the end of the file.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这应该创建一个输出音频文件，其中淡出效果在文件结束前4秒开始。
- en: '[PRE22]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: What just happened?
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We learned how to add a fading effect to an audio file using GStreamer multimedia
    framework. We used the same GStreamer pipeline as the one used in the *Adjusting
    volume* section, but this time, the volume level was controlled using the `Controller`
    object in GStreamer. The technique we just learned will come handy while working
    on project 'Combining Audio Clips ' later in this chapter.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何使用GStreamer多媒体框架向音频文件添加淡变效果。我们使用了与*调整音量*部分相同的GStreamer管道，但这次，音量级别是通过GStreamer中的`Controller`对象控制的。我们刚刚学到的技术将在本章后面的“组合音频片段”项目中派上用场。
- en: Have a go hero add fade-in effect
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试添加淡入效果
- en: This is going to be straightforward. We added a fade-out effect earlier. Now
    extend this utility by adding a fade-in effect to the input audio. Use a total
    fade duration of 4 seconds. The `fade_start` time in this case will be 0 seconds.
    Try the interpolation mode as `gst.INTERPOLATE_CUBIC`.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这将非常直接。我们之前添加了淡出效果。现在通过添加淡入效果到输入音频来扩展这个实用程序。使用总淡入时长为4秒。在这种情况下，`fade_start`时间将是0秒。尝试使用`gst.INTERPOLATE_CUBIC`作为插值模式。
- en: Echo echo echo...
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嗡嗡嗡...
- en: 'Echo is a reflection of a sound heard a short time period after the original
    sound. In audio processing, to achieve this effect the input audio signal is recorded
    and then played back after the specified ''delay time'' with a specified intensity.
    An echo effect can be added using the `audioecho` plugin in GStreamer. The audio
    echo plugin should be available by default in your GStreamer installation. Check
    this by running the following command:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 响应是原声在短时间内听到的声音的反射。在音频处理中，为了实现这种效果，输入音频信号被记录下来，然后在指定的'延迟时间'后以指定的强度播放。可以使用GStreamer中的`audioecho`插件添加回声效果。音频回声插件应默认包含在您的GStreamer安装中。可以通过运行以下命令来检查：
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: If it is not available, you will need to install it separately. Refer to the
    GStreamer website for installation instructions.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它不可用，您需要单独安装它。请参阅GStreamer网站以获取安装说明。
- en: Time for action - adding echo effect
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加回声效果的行动时间
- en: Let's write code to add an echo effect to an input audio. The code is very similar
    to the one in the `AudioEffects.py` file discussed in earlier section. Just to
    simplify the matter, we will use the code in file `EchoEffect.py` file for easier
    understanding. Later, you can easily integrate this with the code in `AudioEffects.py`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写代码将回声效果添加到输入音频。代码与在前面部分讨论的`AudioEffects.py`文件中的代码非常相似。为了简化问题，我们将使用`EchoEffect.py`文件中的代码，以便更容易理解。稍后，你可以轻松地将此代码与`AudioEffects.py`中的代码集成。
- en: Download the file `EchoEffect.py` that has the source code to add audio echo
    effect. The file contains class `AudioEffects` whose constructor has the following
    code.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载包含添加音频回声效果的源代码的文件`EchoEffect.py`。该文件包含名为`AudioEffects`的类，其构造函数具有以下代码。
- en: '[PRE24]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: It is similar to the __init__ method discussed in the Fading Effects section.
    One difference here is the flag self.use_echo_controller. If it is set to True,
    the GStreamer Controller object will be used to adjust certain echo properties
    while the audio is being streamed. We will first see how a simple echo effect
    can be implemented and then discuss the echo control details. Specify the appropriate
    values for audio file path variables self.inFileLocation and self.outFileLocation.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它与在“衰减效果”部分讨论的`__init__`方法类似。这里的一个区别是标志`self.use_echo_controller`。如果它被设置为True，GStreamer控制器对象将在音频流传输时调整某些回声属性。我们首先将看到如何实现一个简单的回声效果，然后讨论回声控制细节。指定音频文件路径变量`self.inFileLocation`和`self.outFileLocation`的适当值。
- en: Let's build the GStreamer pipeline.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们构建GStreamer管道。
- en: '[PRE25]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The audioecho element is created on line 21\. The property delay specifies the
    duration after which the echo sound will be played. We specify it as 1 second,
    and you can increase or decrease this value further. The echo feedback value is
    set as 0.3\. On line 28, the intensity property is set to 0.5\. It can be set
    in a range 0.0 to 1.0 and determines the sound intensity of the echo. Thus, if
    you set it to 0.0, the echo won't be heard.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第21行创建了`audioecho`元素。属性`delay`指定了回声声音播放的持续时间。我们将其指定为1秒，你可以进一步增加或减少这个值。回声反馈值设置为0.3。在第28行，强度属性设置为0.5。它可以在0.0到1.0的范围内设置，并决定了回声的声音强度。因此，如果你将其设置为0.0，回声将不会被听到。
- en: Notice that there are two `audioconvert` elements. The first `audioconvert`
    converts the decoded audio stream into a playable format input to the `self.echo`
    element. Similarly on the other end of the echo element, we need `audioconvert`
    element to process the audio format after the echo effect has been added. This
    audio is then encoded in MP3 format and saved to the location specified by `self.filesink`.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意有两个`audioconvert`元素。第一个`audioconvert`将解码的音频流转换为可播放的格式，作为`self.echo`元素的输入。同样，在回声元素的另一端，我们需要`audioconvert`元素来处理回声效果添加后的音频格式。然后，该音频以MP3格式编码并保存到由`self.filesink`指定的位置。
- en: 'Run the program from the command line as:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从命令行运行程序如下：
- en: '[PRE26]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: If you play the output file, the echo sound will be audible throughout the playback
    duration.
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你播放输出文件，回声声音将在整个播放期间可闻。
- en: Now we will add a feature that will allow us to add echo effect only for a certain
    duration of the audio track. In the `__init__` method, set the flag `self.use_echo_controller`
    to `True`.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将添加一个功能，允许我们只为音频轨道的一定持续时间添加回声效果。在`__init__`方法中，将标志`self.use_echo_controller`设置为`True`。
- en: We will now review the method `self.setupEchoControl()` which is called in `self.constructPipeline()`.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将回顾在`self.constructPipeline()`中调用的方法`self.setupEchoControl()`。
- en: '[PRE27]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Setting up `gst.Controller` object is very similar to the one developed in the
    *Fading effects* section. Here, we ask the `Controller` object, `self.echoControl`,
    to control the property 'intensity' of the `audioecho` element, `self.echo`. At
    the beginning of the playback (0 seconds), we set the echo intensity as `0.5`.
    We add another control point at 4 seconds during the playback and set the `intensity`
    level as `0.0`. What this effectively means is that we don't want to hear any
    echo after the first 4 seconds of the audio playback! .
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置`gst.Controller`对象与在“衰减效果”部分开发的类似。在这里，我们要求`Controller`对象`self.echoControl`控制`audioecho`元素`self.echo`的属性`intensity`。在播放开始时（0秒），我们将回声强度设置为`0.5`。在播放过程中4秒时，我们添加另一个控制点并将`intensity`级别设置为`0.0`。这实际上意味着我们不想在音频播放的前4秒后听到任何回声！
- en: 'Run the program again from the command line as:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次从命令行运行程序如下：
- en: '[PRE28]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note that the only change done here is the value of flag self.use_echo_controller
    is set to True. Play the output file; the echo sound will be audible only for
    the first 4 seconds during the playback.
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意，这里所做的唯一更改是将标志 self.use_echo_controller 的值设置为 True。播放输出文件；回声声音在播放过程中仅在最初的
    4 秒内可听见。
- en: What just happened?
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We learned how to add echo to an audio clip. To accomplish this, the `audioecho`
    element was added and linked in the GStreamer pipeline. We also learned how to
    selectively add echo effect to the audio using GStreamer `Controller` object.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何向音频剪辑添加回声。为了完成这个任务，我们在 GStreamer 管道中添加并链接了 `audioecho` 元素。我们还学习了如何使用
    GStreamer `Controller` 对象有选择性地添加回声效果到音频中。
- en: Have a go hero add Reverberation Effect
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试添加混响效果，英雄们！
- en: Suppose you are in a theater. When an actor at the center stage talks, the sound
    waves are reflected from the surfaces of the theater before reaching your ears.
    Thus what you hear is a bunch of these reflected sounds. This is known as reverberation
    effect. According to the `audioecho` plugin documentation, if you set the `delay`
    property to a value of less than 0.2 seconds in `audioecho` element, it produces
    a reverberation effect. Try setting different values for `delay`, less than 0.2
    seconds and see how it affects the output audio. Note, this argument is taken
    as an integer. Therefore, specify this value in nanoseconds. For example specify
    0.05 seconds as `50000000` instead of `0.05*gst.SECOND`. This is illustrated below.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在一个剧院里。当舞台中央的演员说话时，声波会在到达你的耳朵之前从剧院的表面反射。因此，你所听到的是一系列这些反射的声音。这被称为混响效果。根据 `audioecho`
    插件文档，如果你将 `audioecho` 元素的 `delay` 属性设置为小于 0.2 秒的值，它会产生混响效果。尝试设置不同的 `delay` 值，小于
    0.2 秒，看看它如何影响输出音频。注意，这个参数被视为整数。因此，请以纳秒为单位指定此值。例如，将 0.05 秒指定为 `50000000` 而不是 `0.05*gst.SECOND`。这在下文中进行了说明。
- en: '[PRE29]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Panning/panorama
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 播放/全景
- en: The stereo panorama effect can be added to a sound by using `audiopanorama`
    plugin (part of `audiofx` plugin). This plugin should be available by default
    in your GStreamer installation. Use `gst-inspect-0.10` to verify it is there and
    also to know more about its properties. Download the file `PanoramaEffect.py`
    from the Packt website. This file is more or less identical to `AudioEffects.py`
    or `EchoEffect.py`. The following is a code snippet from the `self.contructPipeline`
    method in file `PanoramaEffect.py`
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用 `audiopanorama` 插件（`audiofx` 插件的一部分）将立体声全景效果添加到声音中。这个插件应该默认包含在你的 GStreamer
    安装中。使用 `gst-inspect-0.10` 来验证它是否存在，并了解更多关于其属性的信息。从 Packt 网站下载文件 `PanoramaEffect.py`。这个文件与
    `AudioEffects.py` 或 `EchoEffect.py` 大致相同。以下是从文件 `PanoramaEffect.py` 中的 `self.constructPipeline`
    方法的一个代码片段。
- en: '[PRE30]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We have discussed the following many times. Let's go over the code once again
    as a refresher… just in case you missed it earlier. The code block 6-11 adds all
    the elements to the GStreamer pipeline. Notice that we call `gst.element_link_many`
    twice. Do you recall why? The first call on line 14 makes a connection between
    `self.filesrc` and `self.decodebin`. There is one important point to note when
    we make a second call to `gst.element_link_many`. Notice that we have not linked
    `self.decodebin` with `self.audioconvert`. This is because `self.decodebin` implements
    dynamic pads. So we connect it at the runtime, using the callback method, `decodebin_pad_added`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过很多次了。让我们再次回顾一下代码，作为复习……以防你之前错过了。代码块 6-11 将所有元素添加到 GStreamer 管道中。请注意，我们调用了
    `gst.element_link_many` 两次。你还记得为什么吗？第 14 行的第一次调用在 `self.filesrc` 和 `self.decodebin`
    之间建立了一个连接。当我们第二次调用 `gst.element_link_many` 时，有一个重要点需要注意。请注意，我们没有将 `self.decodebin`
    与 `self.audioconvert` 链接。这是因为 `self.decodebin` 实现了动态垫。因此，我们使用回调方法 `decodebin_pad_added`
    在运行时将其连接。
- en: You can review the rest of the code from this file. The `audiopanorama` element
    is created on line 2 in the code snippet. The `panorama` property can have a value
    in the range `-1.0` to `1.0`. If you have stereo speakers connects, the sound
    will entirely come from the left speaker if a value of `-1.0` is specified. Likewise,
    a value of `1.0` will make the sound come from right speaker only. In the above
    code snippet, we instruct the program to exclusively use the right speaker for
    audio streaming. The audio will be streamed from both speakers if the value is
    in-between these two limits. Each speaker's contribution will be determined by
    actual value.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从此文件中查看其余的代码。`audiopanorama`元素在代码片段的第2行创建。`panorama`属性可以有一个在`-1.0`到`1.0`范围内的值。如果您连接了立体声扬声器，当指定值为`-1.0`时，声音将完全来自左扬声器。同样，`1.0`的值将使声音仅来自右扬声器。在上面的代码片段中，我们指示程序仅使用右扬声器进行音频流传输。如果值在这两个限制之间，则两个扬声器都会传输音频。每个扬声器的贡献将由实际值确定。
- en: Have a go hero control panorama effect and more...
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试控制全景效果和更多...
- en: '''Move'' the sound around! Add a GStreamer `Controller` object to adjust the
    `panorama` property of the `self.panorama` element. This is similar to what we
    did in `EchoEffect.py`. Add some control points in the audio stream as done earlier,
    and specify different values for the `panorama` property.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: “移动”声音！向`self.panorama`元素的`panorama`属性添加一个GStreamer `Controller`对象进行调整。这与我们在`EchoEffect.py`中做的是类似的。在音频流中添加一些控制点，就像之前做的那样，并为`panorama`属性指定不同的值。
- en: Integrate this feature with the code in `AudioEffects.py` discussed earlier
    in this chapter.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 将此功能与本章前面讨论的`AudioEffects.py`中的代码集成。
- en: 'Project: combining audio clips'
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目：组合音频片段
- en: It is time for a project! In this project, we will create a single audio file,
    which has custom audio clips appended one after the other. Here, we will apply
    several of the things learned in earlier section, and also in the previous chapter
    on audio processing.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候进行一个项目了！在这个项目中，我们将创建一个单一的音频文件，该文件将依次附加自定义音频剪辑。在这里，我们将应用之前章节和上一章中学习到的几个东西。
- en: 'Creating a new audio file, which is a combination of several audio tracks of
    your choice involves the following steps:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的音频文件，该文件是您选择的几个音频轨道的组合，涉及以下步骤：
- en: First thing we need are the audio files that need to be included. Depending
    upon our requirement, we may need only a small portion of an audio track. So we
    will develop a general application considering this possibility. This is illustrated
    in the time-line illustrated earlier.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先我们需要的是需要包含的音频文件。根据我们的需求，我们可能只需要音频轨道的一小部分。因此，我们将开发一个通用应用程序，考虑到这种可能性。这在前面的时间线中得到了说明。
- en: Next, we need to make sure that these audio pieces are played in a specified
    order.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们需要确保这些音频片段按指定的顺序播放。
- en: There should be a 'blank' or a 'silent' audio in-between the two audio pieces.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在两个音频片段之间应该有一个“空白”或“静音”音频。
- en: Next, we will also implement audio fade-out effect for each of the pieces in
    the track. This will ensure that the audio doesn't end abruptly.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们还将为轨道中的每个片段实现音频淡出效果。这将确保音频不会突然结束。
- en: Media 'timeline' explained
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 媒体“时间线”解释
- en: Before we begin this project, it is important to understand the concept of a
    timeline. A timeline can be viewed as the overall representation of a path where
    you can control the time for which an individual audio clip is played.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始这个项目之前，理解时间线的概念非常重要。时间线可以看作是控制单个音频片段播放时间的路径的整体表示。
- en: 'In this project, since we are saving the resultant audio, it is the same as
    the total playback time of the resultant audio. In this timeline, we can specify
    ''when'' an audio needs to be played and how long it needs to be played. This
    is better explained with the illustration below. Consider a timeline with a total
    duration of 250 seconds. This is represented by the central thick line with circles
    at the end. Suppose there are three audio clips, namely, `Media #1, Media #2`
    and `Media #3` as indicated in the illustration. We wish to include a portion
    of each of these audio clips in the main timeline (the audio file to be saved).
    In the main media timeline, the audio between 0 seconds to 80 second represents
    a portion from `Media #1`. It corresponds to the audio between 30 seconds to 110
    seconds in `Media #1`. Likewise, audio between 90 to 200 seconds on main media
    timeline represents a chunk from `Media #2` and so on. Thus, we can tweak the
    priority and position of the individual audio clips on the main media timeline
    to create the desired audio output.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，由于我们正在保存结果音频，所以它与结果音频的总播放时间相同。在这个时间线中，我们可以指定音频需要播放的时间和需要播放多长时间。以下插图更好地解释了这一点。考虑一个总时长为250秒的时间线。这由中央粗线及其末端的圆圈表示。假设有三个音频剪辑，分别是`媒体#1、媒体#2`和`媒体#3`，如插图所示。我们希望在主时间线（要保存的音频文件）中包含这些音频剪辑的每个部分。在主媒体时间线中，从0秒到80秒的音频代表来自`媒体#1`的部分。它对应于`媒体#1`中从30秒到110秒的音频。同样，主媒体时间线上的90至200秒的音频代表来自`媒体#2`的部分，依此类推。因此，我们可以调整主媒体时间线中单个音频剪辑的优先级和位置，以创建所需的音频输出。
- en: '![Media ''timeline'' explained](img/0165_06_02.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![媒体“时间线”解释](img/0165_06_02.jpg)'
- en: Main media timeline is represented with multiple media tracks in the preceding
    image.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图像中，主媒体时间线由多个媒体轨道表示。
- en: Time for action - creating custom audio by combining clips
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 通过组合剪辑创建自定义音频
- en: Let's develop an application where we will combine multiple audio clips into
    a single audio file.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开发一个应用程序，我们将把多个音频剪辑组合成一个单独的音频文件。
- en: Download the file `CombiningAudio.py`. This file contains all the code necessary
    to run this application. As done earlier, we will discuss only the most important
    methods in this class.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载文件`CombiningAudio.py`。此文件包含运行此应用程序所需的所有代码。与之前一样，我们只讨论此类中最重要的方法。
- en: Write the following code.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 写下以下代码。
- en: '[PRE31]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The overall structure of the code is identical to several other examples in
    this book. We will expand some of the class methods such as addFadingEffect, setupFadeBin
    in the next steps.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码的整体结构与本书中的其他几个示例相同。在接下来的步骤中，我们将扩展一些类方法，如addFadingEffect、setupFadeBin。
- en: Now, let's review the `constructPipeline` method.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们回顾一下`constructPipeline`方法。
- en: '[PRE32]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We used functionality such as gnlcomposition, gnlcontroller, and so on while
    implementing audio fading effects in an earlier section. These modules will be
    used in this project as well. On line 7, all the audio clips we wish to include
    are added to the timeline or gnlcomposition. We will review this method later.
    Note that the gnlcomposition uses dynamic pads. The pad-added signal is connected
    in self.connectSignals. On line 17, a fading effect is set up for the audio clips.
    This ensures smooth termination of individual audio clips in the timeline. Finally,
    the code block between lines 19 to 26 constructs the pipeline and links various
    GStreamer elements in the pipeline. Let's review other important methods in this
    class one by one.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在之前的部分实现音频淡入淡出效果时，我们使用了gnlcomposition、gnlcontroller等功能。这些模块也将在此项目中使用。在第7行，我们希望包含的所有音频剪辑都被添加到时间线或gnlcomposition中。我们将在稍后回顾此方法。请注意，gnlcomposition使用动态垫。垫添加的信号连接在self.connectSignals中。在第17行，为音频剪辑设置了淡入淡出效果。这确保了时间线中单个音频剪辑的平滑终止。最后，第19至26行的代码块构建了管道并链接了管道中的各种GStreamer元素。让我们逐一回顾这个类中的其他重要方法。
- en: The method `self.addGnlFileSources` does multiple things. It adds the audio
    clips to the main timeline in a desired order. This method also ensures that there
    is some 'breathing space' or a blank audio of a short duration in between any
    two audio clips. Write the following method.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 方法`self.addGnlFileSources`执行多项操作。它按所需顺序将音频剪辑添加到主时间线中。此方法还确保在任意两个音频剪辑之间有一些“呼吸空间”或短时间的空白音频。写下以下方法。
- en: '[PRE33]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: First we declare various parameters needed to put the audio clips in the main
    timeline. Here, the audio clips are mostly the gnlfilesource elements whereas
    the timeline is the total length of the output audio track. This parameter setting
    is done by the code between lines 3 to 13\. In this example, we are combining
    only two audio clips. Replace the audio file paths on lines 7 and 13 with the
    appropriate file paths on your machine.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们声明将音频片段放入主时间线所需的各种参数。在这里，音频片段主要是`gnlfilesource`元素，而时间线是输出音频轨道的总长度。这个参数设置是通过第3到13行的代码完成的。在这个例子中，我们只结合了两个音频片段。将第7行和第13行的音频文件路径替换为你的机器上的适当文件路径。
- en: Tip
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'Important note for Windows users: Make sure to specify the file path with forward
    slashes ''/'' as shown on line 13 of the code snippet. If the path is specified
    as, for instance, `C:\AudioFiles\audio2.mp3`, the ''\a'' is treated differently
    by GStreamer! A workaround could be to normalize the path or to always use forward
    slashes while specifying the path. In this case `C:/AudioFiles/audio2.mp3`.'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示：对于Windows用户，请确保按照代码片段第13行的示例使用正斜杠`/`指定文件路径。如果路径被指定为，例如`C:\AudioFiles\audio2.mp3`，GStreamer会以不同的方式处理`\a`！一种解决方案是将路径标准化，或者始终在指定路径时使用正斜杠。在这种情况下`C:/AudioFiles/audio2.mp3`。
- en: The first media file will be placed for 20 seconds on the main timeline. The
    total duration of the audio is specified by the parameter media_duration_1\. The
    parameter media_start_1 specifies the actual time of the first audio file which
    will be the start_time_1 on the main timeline. The basic concept behind timeline
    is explained earlier in this section. Try tweaking a few parameters to get a good
    grasp of how the timeline works. For the second audio, notice how the start_time_2
    is specified. It is equal to duration_1 + 3\. A time of 3 seconds is added so
    that there is a 'sound of silence' between two tracks. You can change this to
    a silent duration of your choice.
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个媒体文件将在主时间线上放置20秒。音频的总时长由参数`media_duration_1`指定。参数`media_start_1`指定第一个音频文件的实际时间，这将是主时间线上的`start_time_1`。时间线背后的基本概念在本节中已解释。尝试调整一些参数，以更好地理解时间线的工作原理。对于第二个音频，注意`start_time_2`是如何指定的。它等于`duration_1
    + 3`。添加3秒的时间是为了在两个轨道之间有一个“无声的寂静”。你可以将其更改为你选择的任何静音时长。
- en: Next, the parameters necessary for the blank audio are defined. In general,
    the `gnlcomposition` will 'play' the blank audio when nothing else is being played
    (this is with the assumption that a proper `priority` is set). We define the total
    duration of this silent track sufficiently long enough, longer than the combined
    duration of all the audio clips, so that this track is 'available to play' when
    the time comes. Note that `gnlcomposition` won't play the silent track for its
    complete duration! It is just so that we have a long enough track that can be
    played at various points. In this project, we are only using two audio files.
    So, it is not really necessary to set blank duration parameter as greater than
    or equal to the total timeline duration. It is okay if we just have it for 3 seconds.
    But imagine that you have more than 2 audio clips. The silent audio will be played
    between tracks 1 and 2 but then it won't be available for tracks between 2 and
    3! If we were to have 3 audio tracks, then the blank audio duration can be set
    as illustrated in the following code snippet and by adding another `gnlfilesource`
    to the `self.composition`. You can also test the resultant audio file by specifying
    `blank_duration = 3`. In that case, there won't be a silent track between audio
    clips 2 and 3!
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义了空白音频所需的参数。一般来说，`gnlcomposition`会在没有其他音频播放时播放空白音频（这是基于已设置适当的`priority`）。我们定义这个静音轨道的总时长足够长，比所有音频片段的总时长都要长，这样在需要的时候这个轨道就可以“可供播放”。请注意，`gnlcomposition`不会播放整个静音轨道！这只是确保我们有一个足够长的轨道可以在不同的点播放。在这个项目中，我们只使用两个音频文件。因此，没有必要将空白时长参数设置为大于或等于总时间线时长。如果只有3秒也行。但想象一下，如果你有超过2个音频片段。静音音频将在第1和第2个轨道之间播放，但之后它将不再适用于第2和第3个轨道之间的轨道！如果我们有3个音频轨道，那么空白音频的时长可以按照以下代码片段所示设置，并且通过向`self.composition`添加另一个`gnlfilesource`来实现。你也可以通过指定`blank_duration
    = 3`来测试生成的音频文件。在这种情况下，音频片段2和3之间不会有静音轨道！
- en: '[PRE34]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The code between lines 19 to 24 sets up some instance variables needed to add
    fade-out effect to the individual audio clips in the `gnlcomposition`. These will
    be used in the `self.addFadingEffect` method.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第19行到第24行之间的代码设置了添加到`gnlcomposition`中单个音频片段淡出效果所需的实例变量。这些将在`self.addFadingEffect`方法中使用。
- en: The code blocks 26-36 and 50-61 define the `gnlfilesource` elements to be added
    to the `self.composition` along with their properties. We have already learned
    about `gnlfilesource`, so these code blocks should be self-explanatory. However,
    see the code on lines 36 ad 61? Here we set the priority of the audio clips in
    the main timeline. It is important step. If you don't define the priority, by
    default, each `gnlsource` will have highest priority indicated by value '0'. This
    is a little bit tricky. It is best explained by tweaking certain values and actually
    playing the output audio! Let's keep it simple for now. See the next 'Have a go
    Hero' section that asks you to experiment a few things related to the `priority`.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码块26-36和50-61定义了要添加到`self.composition`中的`gnlfilesource`元素及其属性。我们已经学习了`gnlfilesource`，因此这些代码块应该是自解释的。然而，请看第36行和第61行的代码？在这里，我们设置了主时间线中音频片段的优先级。这是一个重要的步骤。如果你没有定义优先级，默认情况下，每个`gnlsource`都将具有最高优先级，表示为值'0'。这有点棘手。最好通过调整某些值并实际播放输出音频来解释。现在让我们保持简单。请看下一个“尝试一下英雄”部分，它要求你尝试一些与`priority`相关的实验。
- en: Let's review the code block 40-44\. Here, a `gnlsource` (and not `gnlfilesource)`
    is created on line 40\. We call it `gnlBlankAudio`. Line 41 is very important.
    It tells the program to consider this element last. That is, `gnlBlankAudio` is
    set with the least possible priority among the elements added to the `gnlcomposition`.
    This ensures that the blank piece of audio is played only between the tracks and
    not as an audio clip of its own. Whenever the start point of the next audio in
    the `gnlcomposition` approaches, it will push the `gnlBlankAudio` to a backseat
    and start playing this new audio clip instead. This is because the other audio
    clips are set at a higher `priority` than the `gnlBlankAudio`. You might be wondering
    what the value `4294967295` for `priority` signifies. If you run `gst-inspect-0.10`
    command on `gnlsource` you will notice that the `priority` has a range from `0`
    to4294967295\. Thus the least possible priority level is `4294967295`. In this
    example, we can get away with the priority level of `3` because we have specified
    the `blank_duration` parameter appropriately. But, suppose you don't know beforehand
    what `blank_duration` should be and you set it to a large number. In this case,
    if you have set the priority of `gnlBlankAudio` as `3`, at the end of the output
    audio it will play the remaining portion of the `gnlBlankAudio`. Thus, the total
    track duration will be unnecessarily increased. Instead, if you use priority as
    `4294967295`, it won't play the surplus portion of the blank audio. If you have
    multiple of audio tracks and if their number is not known to begin with, the least
    priority level we are using is the safest value for the blank audio clip. As mentioned
    earlier, the following priority for `gnlBlankAudio` should work as well.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们回顾一下代码块40-44。在这里，第40行创建了一个`gnlsource`（而不是`gnlfilesource`）。我们称之为`gnlBlankAudio`。第41行非常重要。它告诉程序将此元素视为最后。也就是说，`gnlBlankAudio`被设置为添加到`gnlcomposition`中的元素中最低可能的优先级。这确保了空白音频片段仅在轨道之间播放，而不是作为一个单独的音频片段。每当`gnlcomposition`中下一个音频的起始点接近时，它将`gnlBlankAudio`推到次要位置，并开始播放这个新的音频片段。这是因为其他音频片段的`priority`设置高于`gnlBlankAudio`。你可能想知道`priority`的值`4294967295`代表什么。如果你在`gnlsource`上运行`gst-inspect-0.10`命令，你会注意到`priority`的范围是从`0`到4294967295。因此，最低可能的优先级级别是`4294967295`。在这个例子中，我们可以通过适当地指定`blank_duration`参数来避免使用`3`的优先级级别。但是，假设你事先不知道`blank_duration`应该是多少，并将其设置为一个很大的数字。在这种情况下，如果你将`gnlBlankAudio`的优先级设置为`3`，在输出音频的末尾将播放`gnlBlankAudio`的剩余部分。因此，总轨道持续时间将不必要地增加。相反，如果你使用`4294967295`作为优先级，它将不会播放空白音频的剩余部分。如果你有多个音频轨道，并且它们的数量一开始就不知道，我们使用的最低优先级级别是空白音频片段最安全的值。如前所述，以下`gnlBlankAudio`的优先级也应该有效。
- en: '[PRE35]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: On line 46, an `audiotestsrc` element is created. This plugin should be available
    in your installation of GStreamer. This plugin can be used to generate several
    elementary audio signals such as a sine waveform, a silent wave form, and so on.
    Run `gst-inspect-0.10` on `audiotestsrc` to see what types of audio signals it
    can generate. The type of audio signal we need can be specified by the 'wave'
    property of `audiotestsrc` . The value of 4 for `wave` property corresponds to
    a silence waveform. A value of 3 generates triangle wave forms and so on. On line
    48, the `audiotestsrc` element is added to the `gnlsource` element (gnlBlankAudio).
    This simply means that when we start playing the `gnlcomposition`, the silent
    audio pertaining `gnlsource` element is generated using `audiotestsrc` element
    within it.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第46行，创建了一个`audiotestsrc`元素。这个插件应该包含在你的GStreamer安装中。这个插件可以用来生成多种基本的音频信号，例如正弦波形、静音波形等。在`audiotestsrc`上运行`gst-inspect-0.10`来查看它可以生成哪些类型的音频信号。所需的音频信号类型可以通过`audiotestsrc`的`wave`属性来指定。`wave`属性的值为4对应于静音波形。值为3生成三角波形等。在第48行，将`audiotestsrc`元素添加到`gnlsource`元素（gnlBlankAudio）中。这仅仅意味着当我们开始播放`gnlcomposition`时，与`gnlsource`元素相关的静音音频将通过它内部的`audiotestsrc`元素生成。
- en: Finally, the code between lines 63-65 adds the `gnlfilesource` and `gnlsource`
    elements to the `self.composition`.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，第63-65行之间的代码将`gnlfilesource`和`gnlsource`元素添加到`self.composition`中。
- en: Now we will quickly review the method `self.addFadingEffect()`.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将快速回顾一下`self.addFadingEffect()`方法。
- en: '[PRE36]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: In *Fading effects* section, we added fade-out effect to an audio file. In that
    section individual elements such as audio convert and volume were added and linked
    in the main pipeline. Here, we will follow a different way, so as to learn a few
    more things in GStreamer. We will create a GStreamer `bin` element to add the
    fade-out effect to the audio clips. You can choose to do it the old way, but creating
    a `bin` provides a certain level of abstraction. The `bin` element is created
    by the highlighted line of code. We will review that method next. The rest of
    the code in this method is very similar to the one developed earlier. The `self.volumeControl`
    is a GStreamer `Controller` element. We specify volume at appropriate time intervals
    in the timeline to implement fade-out effect for the individual audio clips. It
    is important to adjust the level of volume back to the original one after each
    `fade_end` time. This ensures that the next clip starts with an appropriate level
    of volume. This is achieved by code between lines 22-24.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*渐变效果*部分，我们向音频文件添加了淡出效果。在那个部分，我们添加并链接了主管道中的单个元素，如音频转换和音量。在这里，我们将采取不同的方法，以便在GStreamer中学习更多。我们将创建一个GStreamer
    `bin`元素，以向音频剪辑添加淡出效果。你可以选择使用旧方法，但创建`bin`提供了一定程度的抽象。`bin`元素是通过高亮显示的代码行创建的。我们将在下一个方法中回顾它。这个方法中的其余代码与之前开发的非常相似。`self.volumeControl`是一个GStreamer
    `Controller`元素。我们在时间轴上指定适当的音量间隔来实现单个音频剪辑的淡出效果。在每次`fade_end`时间后调整音量级别回到原始值非常重要。这确保了下一个剪辑以适当的音量级别开始。这是通过第22-24行之间的代码实现的。
- en: Now let's see how to construct a GStreamer bin element for the fading effect.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来看看如何构建一个用于渐变效果的GStreamer bin元素。
- en: '[PRE37]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: On lines 2-6, we define the elements necessary to change volume of an audio
    in a GStreamer pipeline. This is nothing new. On line 8, we create `self.fadeBin`,
    a GStreamer bin element. A `bin` is a container that manages the element objects
    added to it. The essential elements are added to this bin on line 10\. The elements
    are then linked the same way we link elements in a GStreamer pipeline. The bin
    itself is pretty much set up. But there is one more important thing. We need to
    ensure that this bin can be linked with other elements in a GStreamer pipeline.
    For that we need to create ghost pads.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第2-6行，我们定义了在GStreamer管道中改变音频音量的必要元素。这没有什么新奇的。在第8行，我们创建了`self.fadeBin`，一个GStreamer
    bin元素。`bin`是一个容器，用于管理添加到其中的元素对象。基本元素在第10行添加到这个bin中。然后，元素以与我们在GStreamer管道中链接元素相同的方式链接。bin本身已经基本设置好了。但还有一件更重要的事情。我们需要确保这个bin可以与GStreamer管道中的其他元素链接。为此，我们需要创建幽灵垫。
- en: Recall what a `ghost pad` is from the last chapter. A `bin` element is an 'abstract
    element'. It doesn't have `pads` of its own. But in order to work like an element,
    it needs `pads` to connect to the other elements within the pipeline. So the `bin`
    uses a `pad` of an element within it as if it was its own `pad.` This is called
    a ghost pad. Thus the `ghost pads` are used to connect an appropriate element
    inside a `bin`. It enables using a `bin` object as an abstract element in a GStreamer
    pipeline. We create two `ghost pads`. One as `src pad` and one as `sink pad`.
    It is done by the code on lines 19-22\. Note that we use `sink pad` of `self.audioconvert`
    as the `sink ghost pad` of the bin and `src pad` of `self.audioconvert2` as `src
    ghost pad`. Which pad to use as src or sink is decided by how we link elements
    within the bin. Looking at the code between lines 14 to 17 will make it clear.
    Finally, the `ghost pads` are added to the `self.fadeBin` on lines 24 and 25.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回想一下上一章中提到的“幽灵垫”（`ghost pad`）。一个“bin”元素是一个“抽象元素”。它没有自己的`pads`。但是为了像元素一样工作，它需要`pads`来连接管道内的其他元素。因此，“bin”使用其内部元素的`pad`，就像它是自己的`pad`一样。这被称为幽灵垫。因此，幽灵垫用于连接`bin`内的适当元素。这使得可以使用`bin`对象作为GStreamer管道中的抽象元素。我们创建了两个幽灵垫。一个作为`src
    pad`，另一个作为`sink pad`。这是通过第19-22行的代码完成的。注意，我们使用`self.audioconvert`的`sink pad`作为`bin`的`sink
    ghost pad`，以及`self.audioconvert2`的`src pad`作为`src ghost pad`。哪个`pad`用作src或sink取决于我们在`bin`内如何链接元素。查看第14到17行之间的代码将使问题变得清晰。最后，在第24和25行将幽灵垫添加到`self.fadeBin`。
- en: The method `self.gnonlin_pad_added()` gets called whenever the `pad-added` signal
    is emitted for `self.composition`. Notice that `compatible_pad` in this method
    is obtained from `self.fadeBin`.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当`self.composition`发出`pad-added`信号时，会调用`self.gnonlin_pad_added()`方法。注意，在这个方法中，`compatible_pad`是从`self.fadeBin`获得的。
- en: '[PRE38]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Develop the rest of the methods by reviewing the code in file `CombiningAudio.py`.
    Be sure to specify appropriate input and output audio file locations. Once all
    the pieces are in place, run the program as:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过查看`CombiningAudio.py`文件中的代码来开发其余的方法。务必指定适当的输入和输出音频文件位置。一旦所有部分都到位，运行程序如下：
- en: '[PRE39]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This should create the output audio file containing audio clips combined together!
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这应该会创建包含合并在一起的音频剪辑的输出音频文件！
- en: What just happened?
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: In this project we developed a cool application that can combine two or more
    audio clips into a single audio file. To accomplish this, we used many audio processing
    techniques learned in earlier sections and the previous chapter on audio processing.
    We made use of various elements from `gnonlin` plugin such as `gnlcomposition,
    gnlfilesource`, and `gnlsource` . We learned how to create and link a GStreamer
    `bin` container to represent the fade-out effect as an abstract element in the
    pipeline. Among other things, we learned how to insert a blank audio in-between
    audio clips.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们开发了一个可以将两个或更多音频剪辑合并成一个音频文件的应用程序。为了实现这一点，我们使用了在早期章节和上一章中学习的许多音频处理技术。我们使用了`gnonlin`插件中的各种元素，如`gnlcomposition`、`gnlfilesource`和`gnlsource`。我们学习了如何创建和链接GStreamer
    `bin`容器，以在管道中表示淡出效果作为抽象元素。除此之外，我们还学习了如何在音频剪辑之间插入空白音频。
- en: Have a go hero change various properties of 'gnlfilesource'
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试更改`gnlfilesource`的各种属性
- en: In the earlier *Time for action* section, we set priority property for the two
    `gnlfilesource` elements added to the `gnlcomposition`. Tweak the `start` and
    the `priority` properties of the two `gnlfilesource` elements to see what happens
    to the output audio. For example, swap the priority of two `gnlfilesource` elements
    and change the `start_time_2` to `duration_1`, and see what happens. Notice how
    it affects the playback of the first audio clip!
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期的“行动时间”部分，我们为添加到`gnlcomposition`的`gnlfilesource`元素设置了优先级属性。调整两个`gnlfilesource`元素的`start`和`priority`属性，看看输出音频会发生什么。例如，交换两个`gnlfilesource`元素的优先级，并将`start_time_2`改为`duration_1`，看看会发生什么。注意它如何影响第一个音频剪辑的播放！
- en: Audio mixing
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 音频混音
- en: Imagine that you have some instrumental music files in your collection. You
    have a hidden desire to become a playback singer and you wish to sing these songs
    with the background music. What will you do? Well, the simplest thing to do is
    to put on headphones and play any instrumental music. Then sing along and record
    your vocal. OK, what's next? You need to mix the instrumental music and your own
    vocal together to get what you want!
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一些乐器音乐文件在你的收藏中。你有一个成为播放歌手的隐藏愿望，并希望与背景音乐一起唱这些歌曲。你会怎么做？好吧，最简单的事情就是戴上耳机播放任何乐器音乐。然后跟着唱并录制你的声音。好的，下一步是什么？你需要将乐器音乐和你的声音混合在一起，以得到你想要的效果！
- en: Let's see how to mix two audio tracks together. The `interleave` is a GStreamer
    plugin that facilitates mixing of two audio tracks. It merges multiple mono channel
    input audios into a single audio stream in a non-contiguous fashion. This plugin
    should be available in your default GStreamer installation.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何混合两个音频轨道。`interleave` 是一个 GStreamer 插件，它简化了两个音频轨道的混合。它以非连续的方式将多个单声道输入音频合并成一个音频流。这个插件应该包含在你的默认
    GStreamer 安装中。
- en: Time for action - mixing audio tracks
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 混合音频轨道
- en: Let's write a utility that can mix two audio streams together.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个可以混合两个音频流在一起的实用程序。
- en: Download the file `AudioMixer.py` which contains the source code for this utility.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载包含此实用程序源代码的文件 `AudioMixer.py`。
- en: Now we will review the `constructPipeline` method. The API method `gst.parse_launch()`
    explained in the previous chapter will be used here.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将回顾 `constructPipeline` 方法。在上一章中解释的 API 方法 `gst.parse_launch()` 将在这里使用。
- en: '[PRE40]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The `audio1_str` and `audio2_str` are the portions of the main pipeline strings.
    Each of these contain `filesrc` , `decodebin`, and `audioconvert` elements. The
    `filesrc` provides the location of respective input audio files. By now, we very
    well know what this portion of a GStreamer pipeline does.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`audio1_str` 和 `audio2_str` 是主管道字符串的部分。每个都包含 `filesrc`、`decodebin` 和 `audioconvert`
    元素。`filesrc` 提供了相应输入音频文件的位置。到目前为止，我们非常清楚这个 GStreamer 管道部分的作用。'
- en: On lines 10-12, the `interleave_str` defines another portion of the main pipeline
    string. The data output from the `interleave` element needs to be converted into
    a format expected by the encoder element. The encoder is then connected to the
    `filesink` element where the output audio will be stored.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第 10-12 行，`interleave_str` 定义了主管道字符串的另一部分。从 `interleave` 元素输出的数据需要转换成编码器元素期望的格式。然后，编码器连接到
    `filesink` 元素，输出音频将存储在那里。
- en: As mentioned earlier, the `interleave` merges multiple audio channels into a
    single audio stream. In this case, the `interleave` element reads in data from
    two different audio streams via queue elements.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，`interleave` 将多个音频通道合并成一个单一的音频流。在这种情况下，`interleave` 元素通过队列元素从两个不同的音频流中读取数据。
- en: The sink pad of the queue element is linked with the audioconvert element. The
    queue element is a buffer to which the audio data from the audioconvert is written.
    Then this data is further read by the interleave element. This linkage within
    the GStreamer pipeline can be represented by the following string "audioconvert
    ! queue ! mix.". Note that the dot '.' after 'mix' is important. It is a part
    of the syntax when gst.parse_launch is used.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 队列元素的 sink pad 与 audioconvert 元素相连。队列元素是一个缓冲区，音频convert 的音频数据被写入其中。然后这些数据被 interleave
    元素进一步读取。GStreamer 管道中的这种链接可以用以下字符串表示 "audioconvert ! queue ! mix."。注意，'mix' 后的点
    '.' 是重要的。它是使用 `gst.parse_launch` 时的语法的一部分。
- en: To summarize, the data streamed from the portions of the pipeline, `audio1_str`
    and `audio2_str`, will be ultimately read by the `interleave` via 'queue' elements
    and then it will follow the rest of the pipeline represented by `interleave_str`.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总结一下，从管道的部分 `audio1_str` 和 `audio2_str` 流出的数据最终将通过 'queue' 元素被 `interleave`
    读取，然后它将跟随由 `interleave_str` 表示的管道的其余部分。
- en: On line 20, the pipeline string is fed to gst.parse_launch to create a GStreamer
    pipeline instance.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第 20 行，管道字符串被输入到 `gst.parse_launch` 中以创建一个 GStreamer 管道实例。
- en: 'Review the rest of the code from the source file `AudioMixer.py`. Change the
    input and output audio file path strings represented by `self.inFileLocation_1,
    self.inFileLocation_2`, and `self.outFileLocation`. Then run the code as:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看源文件 `AudioMixer.py` 的其余代码。更改由 `self.inFileLocation_1, self.inFileLocation_2`
    和 `self.outFileLocation` 表示的输入和输出音频文件路径字符串，然后按照以下方式运行代码：
- en: '[PRE41]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This should create the interleaved audio output. If you play this audio file,
    you will hear both the audio clips playing at once. Try selecting only a single
    audio channel, such as "Left" channel or "Right" channel. In this case, you will
    notice that each of these audio clips is sent stored on a separate channel. For
    example, if you play only the left channel, only one of these audio clips will
    be heard, so would be the case for the other channel.
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这应该会创建交错音频输出。如果您播放此音频文件，您将听到两个音频剪辑同时播放。尝试仅选择单个音频通道，例如“左”通道或“右”通道。在这种情况下，您会注意到每个音频剪辑都存储在单独的通道上。例如，如果您只播放左通道，则只会听到这些音频剪辑中的一个，其他通道也是如此。
- en: What just happened?
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: Using `interleave` element, we merged two audio tracks to create an interleaved
    audio. This can be used as an audio mixing utility. We learned how to use `queue`
    element as an audio data buffer which is then read by the interleave element.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`interleave`元素，我们将两个音频轨道合并以创建一个交错音频。这可以用作音频混音工具。我们学习了如何使用`queue`元素作为音频数据缓冲区，然后由交错元素读取。
- en: Visualizing an audio track
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化音频轨道
- en: Most of the popular audio players provide a feature to 'visualize' the audio
    being played. This visualization effect is typically generated on the fly and
    is synchronized with the audio signal. Typically, the visualizer responds to changes
    in audio frequency and volume level among other properties. These changes are
    then shown by use of animated graphics. GStreamer provides certain plugins to
    visualize a track. The 'monoscope' visualization plugin is generally available
    in the default GStreamer installation. It displays a highly stabilized waveform
    of the streaming audio. Make sure that the GStreamer installation has the `monoscope`
    plugin by running the `gst-inspect-0.10` command. There are several other popular
    plugins such as `goom` and `libvisual`. But these are not available by default
    in the GStreamer binary installed on Windows XP. You can install these plugins
    and try using these to add visualization effects.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数流行的音频播放器都提供了一种将正在播放的音频进行“可视化”的功能。这种可视化效果通常是即时生成的，并与音频信号同步。通常，可视化器会响应音频频率和音量水平等属性的变化。这些变化通过动画图形来展示。GStreamer提供了一些插件来可视化音轨。'monoscope'可视化插件通常包含在默认的GStreamer安装中。它显示流音频的高度稳定波形。请确保通过运行`gst-inspect-0.10`命令，GStreamer安装中包含`monoscope`插件。还有一些其他流行的插件，如`goom`和`libvisual`。但在Windows
    XP上安装的GStreamer二进制文件中，这些插件默认不可用。您可以安装这些插件并尝试使用它们来添加可视化效果。
- en: Time for action - audio visualizer
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 音频可视化
- en: The visualization effect can be added to the streaming audio using different
    techniques. We will use the simplest approach of all to develop a Music Visualizer
    utility.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用不同的技术将可视化效果添加到流音频中。我们将使用所有方法中最简单的方法来开发一个音乐可视化工具。
- en: Here, we will be using the `playbin` plugin of GStreamer. Recall that the `playbin`
    was first used in the *Playing an audio from a Website* section of the Working
    with Audios chapter. This plugin provides a higher level audio /video player and
    it should be available in the default GStreamer installation.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用GStreamer的`playbin`插件。回想一下，`playbin`首次在“与音频一起工作”章节的“从网站播放音频”部分中使用。这个插件提供了一个高级的音频/视频播放器，并且应该包含在默认的GStreamer安装中。
- en: Download the file `MusicVisualizer.py` from the Packt website. This is a small
    program. The class methods are represented below. Look at the code from this file
    for more details.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Packt网站下载`MusicVisualizer.py`文件。这是一个小程序。下面展示了类方法。查看此文件中的代码以获取更多详细信息。
- en: '[PRE42]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Most of the code is identical to the one illustrated in the Playing audio from
    a website section of the previous chapter. The only difference here is the constructor
    of the class where various properties of the playbin element are defined.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大部分代码与上一章“从网站播放音频”部分中展示的代码相同。这里唯一的区别是类的构造函数，其中定义了playbin元素的各种属性。
- en: Now let's review the constructor of the class AudioPlayer.
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们来回顾一下`AudioPlayer`类的构造函数。
- en: '[PRE43]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Modify the `inFileLocation` on line 3 to match an audio file path on your computer.
    On line 6 and 8, the `playbin` and `monoscope` elements are created. The latter
    is a plugin that enables audio visualization. On line 12, we set the value for
    property `vis-plugin` as the `monoscope` element created earlier. The `vis-plugin`
    stands for 'visualization plugin' that the `playbin` element should use to visualize
    the music.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将第3行的`inFileLocation`修改为匹配你电脑上的音频文件路径。在第6行和第8行，创建了`playbin`和`monoscope`元素。后者是一个插件，它能够实现音频可视化。在第12行，我们将属性`vis-plugin`的值设置为之前创建的`monoscope`元素。`vis-plugin`代表'可视化插件'，`playbin`元素应该使用它来可视化音乐。
- en: 'That''s all! You can review the rest of the code from the file `MusicVisualizer.py`.
    Now run the program from the command line as:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就这些！你可以从文件`MusicVisualizer.py`中查看其余的代码。现在从命令行运行程序，如下所示：
- en: '[PRE44]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This should start playing the input audio file and at the same time, it should
    also pop up a small window where you can 'visualize' the streaming audio.
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这应该开始播放输入音频文件，同时，它还应该弹出一个小窗口，你可以在其中'可视化'流式音频。
- en: Tip
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'Note: The overall performance of this application may depend on the number
    of processes running at the time this program is run. It may also depend on the
    specifications of your computer such as processor speed.'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：此应用程序的整体性能可能取决于程序运行时正在运行的进程数量。它也可能取决于你电脑的规格，如处理器速度。
- en: Here, the stable audio waveform will be shown as the music plays. The following
    shows a snapshot of this visualization window at two different timeframes.
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这里，随着音乐的播放，稳定的音频波形将显示出来。以下显示了在两个不同时间段的这个可视化窗口的快照。
- en: '![Time for action - audio visualizer](img/0165_6_3.jpg)![Time for action -
    audio visualizer](img/0165_6_4.jpg)'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![行动时间 - 音频可视化](img/0165_6_3.jpg)![行动时间 - 音频可视化](img/0165_6_4.jpg)'
- en: Snapshots at some random timeframes using Music Visualizer using 'monoscope'
    are depicted here.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用'monoscope'的音频可视化工具在某个随机时间段的快照如下所示。
- en: What just happened?
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We used the GStreamer plugins `playbin` and `monoscope` to develop an audio
    visualization utility for a streaming audio. The `monoscope` element provided
    a way to visualize highly stable audio waveforms.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了GStreamer插件`playbin`和`monoscope`开发了一个用于流式音频的音频可视化工具。`monoscope`元素提供了一种可视化高度稳定的音频波形的方法。
- en: Have a go hero use other visualization plugins
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试使用其他可视化插件
- en: 'To illustrate visualization effects for an audio, the `monoscope` plugin was
    used. If you have some other visualization plugins available in the GStreamer
    installation, use those to create different visualization effects. The following
    are some of the plugins that can be used for this purpose: `goom, goom2k1, libvisual`,
    and `synaesthesia`. The audio visualization accomplished by `synaesthesia` plugin
    is shown in the next illustration.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明音频的视觉效果，使用了`monoscope`插件。如果你在GStreamer安装中有其他可视化插件，可以使用它们来创建不同的视觉效果。以下是一些可用于此目的的插件：`goom,
    goom2k1, libvisual`和`synaesthesia`。下一张插图显示了由`synaesthesia`插件实现的音频可视化。
- en: '![Have a go hero use other visualization plugins](img/0165_6_5.jpg)![Have a
    go hero use other visualization plugins](img/0165_6_6.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![尝试使用其他可视化插件](img/0165_6_5.jpg)![尝试使用其他可视化插件](img/0165_6_6.jpg)'
- en: 'Music Visualizer using ''synaesthesia'': Snapshots at some random timeframes
    is depicted here.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 使用'通感'的音频可视化：这里展示了某些随机时间段的快照。
- en: Summary
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'We learned a lot in this chapter about various audio enhancement and control
    techniques. The GStreamer multimedia framework was used to accomplish this. We
    specifically covered:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们关于各种音频增强和控制技术学到了很多。我们使用了GStreamer多媒体框架来完成这些工作。我们特别介绍了：
- en: 'Audio controls: How to control the streaming of an audio data. With the help
    of coding illustrations, we learned about playback controls such as play, pause,
    seek, and stop. These controls were then used in a project where a portion of
    an audio was extracted.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频控制：如何控制音频数据的流。通过编码示例，我们学习了播放控制（如播放、暂停、搜索和停止）。然后，这些控制被用于一个项目中，从音频中提取了一部分。
- en: 'Adding effects: Enhancing the audio by adding audio effects such as fade-in,
    echo/reverberation, and so on.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加效果：通过添加音频效果（如淡入、回声/混响等）来增强音频。
- en: 'Non-linear audio editing: How to combine two or more audio streams into a single
    track. This was done in one of the projects we undertook.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非线性音频编辑：如何将两个或多个音频流合并成一个单独的轨道。这是我们承担的一个项目中完成的。
- en: Audio mixing technique to merge multiple mono channel audio streams into a single
    interleaved audio.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频混合技术，用于将多个单声道音频流合并成一个单声道交错音频。
- en: Additionally, we also learned techniques such as visualizing an audio. This
    concludes our discussion on audio processing in Python using GStreamer framework.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还学习了诸如可视化音频等技巧。这标志着我们使用 GStreamer 框架在 Python 中处理音频讨论的结束。
- en: In the next chapter, we will learn how to process videos using Python.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何使用 Python 处理视频。
