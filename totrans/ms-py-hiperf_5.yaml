- en: Chapter 5. Multithreading versus Multiprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to optimizing code, concurrency and parallelism are two topics
    that are rarely left out of the conversation. However, in the case of Python these
    are topics that are normally used to criticize the language. Critics normally
    blame the difficulty of using these mechanics versus the actual benefit they bring
    to the table (which, in some instances, is nonexistent).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will see that the critics are right some of the time and
    wrong in other cases. Just like with most tools, these mechanics require certain
    conditions to work for the developer, instead of working against them. During
    our tour of the internals of how we can achieve parallelism in Python and on which
    occasions it is actually worth it, we''ll discuss two specific topics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multithreading**: This is the most classical approach in trying to achieve
    true parallelism. Other languages such as C++ and Java provide this feature as
    well.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Multiprocessing**: Although not as common and with some potentially difficult
    problems to solve, we''ll discuss this feature as a valid alternative to multithreading.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After reading this chapter, you'll fully understand the difference between Multithreading
    and Multiprocessing. Moreover, you will also understand what a **Global Interpreter
    Lock** (**GIL**) is, and how it will affect your decision when trying to pick
    the right parallelism technique.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelism versus concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These two terms are often used together and even interchangeably, but they are
    technically two different things. On one side, we have parallelism, which happens
    when two or more processes can run at the exact same time. This can happen, for
    instance, in multicore systems, where each process runs on a different processor.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, concurrency happens when two or more processes try to run
    at the same time on top of the same processor. This is usually solved by techniques
    such as time slicing. However, these techniques do not execute in a truly parallel
    fashion. It just looks parallel to observers because of the speed at which the
    processor switches between tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram tries to illustrate this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Parallelism versus concurrency](img/B02088_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Concurrency, for instance, is a technique used by all modern operating systems.
    This is because irrespective of the number of processors a computer has, the system
    alone will probably need to have more processes running at the same time, let
    alone anything the user might want to do. So, to solve this, the operative system
    will take care of scheduling time with the processor for each process that requires
    it. Then, it'll switch context between them, giving each one a slice of time.
  prefs: []
  type: TYPE_NORMAL
- en: Now, with this in mind, how can we achieve either parallelism or concurrency
    in our Python programs? This is where multithreading and multiprocessing come
    into play.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multithreading is the ability of a program to run multiple threads within the
    context of the same program. These threads share the process's resources and allow
    multiple actions to run in the concurrent mode (for single processor systems)
    and in the parallel mode (for multicore systems).
  prefs: []
  type: TYPE_NORMAL
- en: 'Structuring your program to utilize these threads is not an easy task. However,
    it comes with some very interesting benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Responsiveness**: In single-threaded programs, executing a long running task
    might cause the program to appear to freeze. Thanks to multithreading and by moving
    such code into a worker thread, the program can remain responsive while concurrently
    executing the long running task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Faster execution**: In multicore processors or multiprocessor systems, multithreading
    can be used to improve the program''s performance by achieving true parallelism.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lower resource consumption**: Using threads, a program can serve many requests
    using the resources from the original process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simplified sharing and communication**: Since threads already share the same
    resources and memory space, communication between them is much simpler than interprocess
    communication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parallelization**: Multicore or multiprocessor systems can be used to leverage
    multithreading and run each thread independently. **Compute Unified Device Architecture**
    (**CUDA**) from Nvidia ([http://www.nvidia.com/object/cuda_home_new.html](http://www.nvidia.com/object/cuda_home_new.html))
    or OpenCL from Khronos Group ([https://www.khronos.org/opencl/](https://www.khronos.org/opencl/))
    are GPU-computing environments that utilize from dozens to hundreds of processors
    to run tasks in parallel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are also some drawbacks of multithreading:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Thread synchronization**: Since threads can potentially work on the same
    data, you will need to implement some sort of mechanics to prevent race conditions
    (causing corrupted data reads).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Crash due to problematic thread**: Although it might seem independent, a
    single problematic thread acting up and performing an invalid action can crash
    the entire process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deadlocks**: This is a common problem associated with working with threads.
    Normally, when a thread needs a resource, it will lock it until it is done with
    it. A deadlock occurs when one thread enters a wait state, waiting for a second
    thread to release its resources but the second thread is, in turn, waiting for
    the first one to release its locked ones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normally, this technique should be enough to achieve parallelism on multiprocessor
    systems. However, the official version of Python (CPython) has a limitation called
    GIL. This GIL prevents multiple native threads from running Python's bytecode
    at once, which effectively trumps parallelism. If you have a four-processor system,
    your code would not run at 400 percent. Instead, it would just run at 100 percent
    or a bit slower actually, because of the extra overhead from threading.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the GIL is not an invention only of Python (or CPython). Other programming
    languages also have a GIL, such as Ruby's official implementation Ruby MRI or
    even OCaml ([https://ocaml.org/](https://ocaml.org/)).
  prefs: []
  type: TYPE_NORMAL
- en: A GIL is necessary because the memory management in CPython is not thread safe.
    So, by forcing everything to run serially, it makes sure that nothing corrupts
    the memory. It is also faster for single-threaded programs and simplifies the
    creation of C extensions, because they don't have to take multithreading into
    account.
  prefs: []
  type: TYPE_NORMAL
- en: There are, however, some ways around the GIL. For instance, since it only prevents
    threads from running Python's bytecode at the same time, you could potentially
    code your tasks in C and have Python just as a wrapper for that code. The GIL
    would not stop the C code from running all threads concurrently in this case.
  prefs: []
  type: TYPE_NORMAL
- en: Another example where the GIL will not affect the performance would be a network
    server, which spends most of its time reading packets off the network. In this
    case, the added concurrency will allow more packets to be serviced, even if there
    is no real parallelism. This effectively boosts the performance of our program
    (it can serve a lot more clients per second), but it does not affect its speed,
    as every task takes the same amount of time
  prefs: []
  type: TYPE_NORMAL
- en: Threads
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, let's talk a bit about threads in Python in order to understand how to
    use them. They are composed of a beginning, an execution sequence, and a conclusion.
    There is also an instruction pointer, which keeps track of where a thread is currently
    running within the thread's context.
  prefs: []
  type: TYPE_NORMAL
- en: That pointer can be pre-empted or interrupted in order to stop the thread. Alternatively,
    it can also be put on hold temporarily. This basically means putting the thread
    to sleep.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to work with threads in Python, we have the following two options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The thread module**: This provides some limited ability to work with threads.
    It''s simple to use, and for small tasks, it adds little overhead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The threading module**: This is newer and included in Python since version
    2.4\. It provides a more powerful and higher level support for threads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a thread with the thread module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although we'll focus on the threading module, we'll quickly show an example
    of how to use this module for the simpler times, when not a lot of work is required
    from your script.
  prefs: []
  type: TYPE_NORMAL
- en: 'The thread module ([https://docs.python.org/2/library/thread.html](https://docs.python.org/2/library/thread.html))
    provides the `start_new_thread` method. We can pass it in the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: We can pass it in a function that will contain the actual code to run. Once
    this function returns, the thread will be stopped.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can pass it in a tuple of arguments. This list will be passed to the function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we can pass it in an optional dictionary of named arguments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see an example of all the preceding parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code prints the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a thread with the thread module](img/B02088_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding code is simple enough, and the output clearly shows how both threads
    are actually running concurrently. The interesting thing about this is that in
    the code, the `print_time` function itself has an inside loop. If we were to run
    this function twice serially, then it would last `5` * delay seconds each time
    we call it.
  prefs: []
  type: TYPE_NORMAL
- en: However, using threads and without having to change anything, we're running
    the loop twice concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: 'This module also provides other threading primitives that can come in handy.
    Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This method sends a keyboard interrupt exception to the main thread. This, effectively,
    is like hitting *CTRL*+*C* on your program while running. If not caught, the thread
    that sent the signal would terminate the program.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This method exits the thread silently. It is a good way to terminate a thread
    without affecting anything else. Let''s assume that we changed our `print_time`
    function into the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the output would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a thread with the thread module](img/B02088_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The `allocate_lock` method returns a lock for the threads to use. The lock will
    help the developer protect sensitive code and make sure that there are no race
    conditions during execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The lock objects returned have these three simple methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`acquire`: This basically acquires the lock for the current thread. It accepts
    an optional integer parameter. If it is zero, the lock would be acquired only
    if it can be acquired immediately, without waiting. If it''s non-zero, the lock
    would be acquired unconditionally (like when you omit the parameter). This means
    that if the thread needs to wait to acquire the lock, it would.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`release`: This will release the lock for the next thread to acquire it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`locked`: This would return `TRUE` if the lock is acquired by some thread.
    Otherwise, it would be `FALSE`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a very basic example of how locking can help multithreaded code. The
    following code increments a global variable using 10 threads. Each one will add
    one thread. So, by the end, we should have 10 threads in that global variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a thread with the thread module](img/B02088_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Not only are we correctly incrementing the value of the global variable (we
    only got up to `2`), but we are also having issues printing out the strings. In
    some cases, we have two strings in the same line, when they should each occupy
    one. This is because when two strings existed in the same line, both threads tried
    to print at the same time. At that time, the current line to print on was the
    same in both cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same occurrence repeats for the global value. When threads `1`, `3`, `6`,
    `8`, `4`, `2`, and `7` read the value of the global variable in order to add `1`,
    the value was `0` (which is what they each copied to the `local_value` variable).
    We need to make sure that the code that copies the value, increments it, and prints
    it out is protected (inside a lock) so that no two threads can run it at the same
    time. To accomplish this, we''ll use two methods for the Lock object: acquire
    and release.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the output makes more sense:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a thread with the thread module](img/B02088_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The output now makes more sense, the format got fixed, and we successfully
    incremented the value of our variable. Both fixes are due to the locking mechanics.
    Regarding the code, to increment the value of `global_value`, the lock is preventing
    other threads (those which have not yet acquired the lock) from executing that
    part of the code (reading its value into a local variable and incrementing it).
    So, while the lock is active, only the thread that acquired it will be able to
    run those lines. After the lock has been released, the next thread in line will
    do the same. The preceding line of code returns the current threads identified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a non-zero integer with no direct meaning other than identifying the
    current thread between the lists of active ones. This number can be recycled after
    a thread dies or exits, so it is not unique during the lifetime of the program.
    The following code sets or returns the thread stack size used when creating new
    threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This supports an optional argument ("this" being the size to set for the stack).
    This size must either be 0 or at least 32.768 (32 Kb). Depending on the system,
    there might be other restrictions to the number or even to setting the stack size.
    So, check with your OS's manual before trying to use this method.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although it is not the target version of this book, in Python 3, this module
    has been renamed to `_thread`.
  prefs: []
  type: TYPE_NORMAL
- en: Working with the threading module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This is the current and recommended way to work with threads in Python. This
    module provides a better and higher level interface for that. It also adds complexity
    to our code, since the simplicity of the `_thread` module will not be available
    now.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this case, we can loosely quote Uncle Ben and say:'
  prefs: []
  type: TYPE_NORMAL
- en: '*With great power comes great complexity.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Jokes apart, the `threading` module encapsulates the concept of thread inside
    a class, which we're required to instantiate to be able to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a subclass of the `Thread` class ([https://docs.python.org/2/library/thread.html](https://docs.python.org/2/library/thread.html))
    provided by the module (this is normally the preferred way). Alternatively, we
    could even instantiate that class directly if we want to do something very simple.
    Let''s see how the preceding example would translate using the `threading` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For more complex things, we might want to create our own thread classes in order
    to better encapsulate its behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using the subclass approach, there are a few things you need to take into
    account when writing your own classes:'
  prefs: []
  type: TYPE_NORMAL
- en: They need to extend the `threading.Thread` class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They need to overwrite the `run` method and, optionally, the `__init__` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you overwrite the constructor, make sure to call the parent's class constructor
    (`Thread.__init__`) as the first action you take
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The thread will stop when the `run` method stops or throws an unhandled exception,
    so plan your method with this in mind
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can name your thread with the `name` argument on its constructor method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although you'll have to overwrite the `run` method, which will contain the main
    logic of the thread, you will not be in control of when that method is called.
    Instead, you will call the `start` method, which, in turn, will create a new thread
    and call the `run` method with that thread as context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now look at a simple example of a very common pitfall of working with
    threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of that code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with the threading module](img/B02088_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see highlighted in the preceding screenshot, the program is sending
    the exit message before anything else. In this case, it''s not a big issue. However,
    it would be a problem if we had something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the preceding code will fail, because it will close the file handler
    before any thread tries to use it in any way. If we want to avoid this type of
    issue, we need to use the `join` method, which will halt the calling thread until
    the target thread has completed execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, if we use the `join` method from the main thread, it would make
    sure that the program does not continue with the main chain of commands until
    both threads complete execution. We need to make sure we use the `join` method
    on the threads after both have started. Otherwise, we could end up running them
    serially:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This method also accepts an optional argument: a timeout (a `float` or `None`)
    in seconds. However, the `join` method always returns `None`. So, to find out
    whether the operation indeed timed out, we need to check whether the thread is
    still alive (with the `isAlive` method) after the `join` method returns. If the
    thread is alive, then the operation timed out.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now see another example of a simple script to check the status code
    of a list of sites. This script requires just a few lines of code to iterate over
    the list and collect the status code returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the preceding code with the time command-line tool on Linux, you
    could also get the time it takes to execute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with the threading module](img/B02088_05_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, looking at the code and with what we''ve seen so far, a clear optimization
    would be to turn the IO-bound function (`check_http_status`) into a thread. This
    way, we can concurrently check the status for all sites, instead of waiting for
    each request to finish before processing the next one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the new script with time will produce the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with the threading module](img/B02088_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Clearly, the threaded alternative is faster. In our case, it is almost three
    times faster, which is an amazing improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Interthread communication with events
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although threads are normally thought of as individual or parallel workers,
    sometimes, it is useful to allow them to communicate with each other.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, the threading module provides the event construct ([https://docs.python.org/2/library/threading.html#event-objects](https://docs.python.org/2/library/threading.html#event-objects)).
    It contains an internal flag, and caller threads can either use `set()` or `clear()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Event` class has a very simple interface. Here are the methods provided
    within the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`is_set`: this would return `True` if the internal flag of the event is set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`set`: this sets the internal flag to `True`. It awakens all threads waiting
    for this flag to be set. Threads calling `wait()` will no longer be blocked.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clear`: this resets the internal flag. Any thread calling the `wait()` method
    will become blocked until `set()` is called again.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`wait`: this blocks the calling thread until the internal flag of the event
    is set. This method accepts an optional argument for a timeout. If it is specified
    and different from none, then the thread would be blocked only by that timeout.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see a simple example of using events to communicate between two threads
    so that they can take turns printing out to a standard output. Both threads will
    share the same event object. One will set it on every iteration of the `while`
    loop, and the other would clear it if it''s set. On every action (`set` or `clear`),
    they''ll print the right letter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In conclusion, the following table shows when to use multithreading and when
    not to:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Use threads | Don''t use threads |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| For heavy IO-bound scripts | To optimize scripts that are heavily CPU bound
    |'
  prefs: []
  type: TYPE_TB
- en: '| When parallelism can be replaced by concurrency | For programs that must
    take advantage of multicore systems |'
  prefs: []
  type: TYPE_TB
- en: '| For GUI development |   |'
  prefs: []
  type: TYPE_TB
- en: Multiprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multithreading in Python fails to achieve real parallelism, thanks to the GIL,
    as we saw earlier. Thus, some types of applications will not see a real benefit
    from using this module.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, Python provides an alternative to multithreading called multiprocessing.
    In multiprocessing, threads are turned into individual subprocesses. Each one
    will run with its own GIL (which means there are no limitations on the number
    of parallel Python processes that can run at the same time).
  prefs: []
  type: TYPE_NORMAL
- en: To clarify, threads are all part of the same process, and they share the same
    memory, space, and resources. On the other hand, processes don't share memory
    space with their spawning parent, so it might be more complicated for them to
    communicate with each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach comes with advantages and disadvantages over the multithreading
    alternative:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Advantages | Disadvantages |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Takes advantage of multicore systems | Larger memory footprint |'
  prefs: []
  type: TYPE_TB
- en: '| Separate memory space removes race conditions from the equation | Harder
    to share mutable data between processes |'
  prefs: []
  type: TYPE_TB
- en: '| Child processes are easily interruptible (killable) | **Interprocess communication**
    (**IPC**) is harder than with threads |'
  prefs: []
  type: TYPE_TB
- en: '| Avoids the GIL limitation (although only in the case of CPython) |   |'
  prefs: []
  type: TYPE_TB
- en: Multiprocessing with Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `multiprocessing` module ([https://docs.python.org/2/library/multiprocessing.html](https://docs.python.org/2/library/multiprocessing.html))
    provides the `Process` class, which, in turn, has an API similar to the `threading.Thread`
    class. So, migrating code from multithreading to multiprocessing is not as difficult
    as one might think, because the basic structure of your code would remain the
    same.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at a quick example of how we might structure a multiprocessing
    script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is a basic example, but it shows just how similar to multithreading
    the code can be.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note that on Windows systems, you will need to add an extra check to make sure
    that when the subprocesses include the main code, it would not be executed again.
    To clarify, the main code should look like this (if you plan to run it on Windows):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Exit status
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When each process is finished (or terminated), it has an exit code, which is
    a number representing the result of the execution. This number might either indicate
    that the process finished correctly, incorrectly, or that it was terminated by
    another process.
  prefs: []
  type: TYPE_NORMAL
- en: 'To be more precise:'
  prefs: []
  type: TYPE_NORMAL
- en: A code equal to `0` means there was no problem at all
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A code higher than `0` means the process failed and exited with that code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A code lower than `0` means it was killed with a `-1` * `exit_code` signal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows how to read the exit code and how it is set, depending
    on the outcome of the task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this script is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exit status](img/B02088_05_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Notice how the `print` property from the third worker is never executed. This
    is because that process is terminated before the `sleep` method finishes. It is
    also important to note that we''re doing two separate `for` loops over the three
    workers: one to start them and the second one to join them using the `join()`
    method. If we were, for instance, to execute the `join()` method while starting
    each subprocess, then the third subprocess would not fail. In fact, it would return
    an exit code of zero (no problem), because as with multithreading, the `join()`
    method will block the calling process until the target one finishes.'
  prefs: []
  type: TYPE_NORMAL
- en: Process pooling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This module also provides the `Pool` class ([https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool](https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool)),
    which represents a pool of worker processes that facilitate different ways to
    execute a set of tasks in subprocesses.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main methods provided by this class are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`apply`: This executes a function in a separate subprocess. It also blocks
    the calling process until the called function returns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`apply_async`: This executes a function in a separate subprocess, asynchronously,
    which means that it''ll return immediately. It returns an `ApplyResult` object.
    To get the actual returned value, you need to use the `get()` method. This action
    will be blocked until the asynchronously executed function finishes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`map`: This executes a function for a list of values. It is a blocking action,
    so the returned value is the result of applying the function to each value of
    the list.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each one of them provides a different way of iterating over your data, be it
    asynchronously, synchronously, or even one by one. It all depends on your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Interprocess communication
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now, getting the processes to communicate with each other is not, as we already
    mentioned, as easy as with threads. However, Python provides us with several tools
    to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Queue` class provides a thread-safe and process-safe **first in first
    out** (**FIFO**) ([https://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes](https://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes))
    mechanism to exchange data. The `Queue` class provided by the multiprocessing
    module is a near clone of `Queue.Queue`, so the same API can be used. The following
    code shows an example of two processes interacting through `Queue`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Pipes
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Pipes provide ([https://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes](https://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes))
    a bidirectional channel of communication between two processes. The `Pipe()` function
    returns a pair of connection objects, each representing one side of the pipe.
    Each connection object has both a `send()` and a `recv()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows a simple usage for the pipe construct, similar to
    the preceding Queue example. This script will create two processes: one that will
    generate random numbers and send them through the pipe and one that will read
    the same one and write the numbers to a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Events
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'They are also present in the multiprocessing module, and they work in almost
    a similar way. The developer only needs to keep in mind that event objects can''t
    be passed into worker functions. If you try to do that, a runtime error will be
    issued, saying that semaphore objects can only be shared between processes through
    inheritance. This means that you can''t do what is shown in this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we've covered both alternatives, their main characteristics, and their
    ups and downs, it is really up to the developer to pick one or the other. There
    is clearly no better one, since they are meant for different scenarios, although
    they might seem to accomplish the same thing.
  prefs: []
  type: TYPE_NORMAL
- en: The main take-away from this chapter should be the points mentioned earlier,
    the main characteristics of each approach, and when each one should be used.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll continue with the optimization tools. This time,
    we will look at Cython (an alternative that allows you to compile your Python
    code on C) and PyPy (an alternative interpreter written in Python that is not
    bound to the GIL like CPython is).
  prefs: []
  type: TYPE_NORMAL
