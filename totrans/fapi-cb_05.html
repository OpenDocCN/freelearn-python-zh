<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer009">
<h1 class="chapter-number" id="_idParaDest-154"><a id="_idTextAnchor157"/>5</h1>
<h1 id="_idParaDest-155"><a id="_idTextAnchor158"/>Testing and Debugging FastAPI Applications</h1>
<p>In this chapter of our journey through mastering FastAPI, we pivot towards a crucial aspect of software development that ensures the reliability, robustness, and quality of your applications: testing and debugging. As we delve into this chapter, you’ll be equipped with the knowledge and tools necessary to create an effective testing environment, write and execute comprehensive tests, and debug your FastAPI applications with efficiency <span class="No-Break">and precision.</span></p>
<p>Understanding how to properly test and debug is not just about finding errors; it’s about ensuring your application can withstand real-world use, manage high traffic without faltering, and provide a seamless user experience. By mastering these skills, you’ll be able to confidently enhance your applications, knowing that each line of code has been scrutinized and each potential bottleneck has <span class="No-Break">been addressed.</span></p>
<p>We are going to create a proto application with a minimal setup to test <span class="No-Break">the recipes.</span></p>
<p>By the end of this chapter, you will not only have a deep understanding of the testing frameworks and debugging strategies suitable for FastAPI but also practical experience in implementing these techniques to build more resilient applications. This knowledge is invaluable, as it directly impacts the quality of your software, its maintenance, and <span class="No-Break">its scalability.</span></p>
<p>In this chapter we’re going to cover the <span class="No-Break">following recipes:</span></p>
<ul>
<li>Setting up <span class="No-Break">testing environments</span></li>
<li>Writing and running <span class="No-Break">unit tests</span></li>
<li>Testing <span class="No-Break">API endpoints</span></li>
<li>Handling <span class="No-Break">logging messages</span></li>
<li><span class="No-Break">Debugging techniques</span></li>
<li>Performance testing for high <span class="No-Break">traffic application</span></li>
</ul>
<h1 id="_idParaDest-156"><a id="_idTextAnchor159"/>Technical requirements</h1>
<p>To dive into the chapter and follow along with the recipes, ensure your setup includes the <span class="No-Break">following essentials:</span></p>
<ul>
<li><strong class="bold">Python</strong>: Make sure to have a Python version 3.7 or higher installed on <span class="No-Break">your computer.</span></li>
<li><strong class="bold">FastAPI</strong>: Have <strong class="source-inline">fastapi</strong> package in your <span class="No-Break">working environment.</span></li>
<li><strong class="bold">Pytest</strong>: Be familiar with <strong class="source-inline">pytest</strong> framework, which is a testing framework largely used to test <span class="No-Break">Python code.</span></li>
</ul>
<p>The code used in the chapter is hosted on GitHub at the <span class="No-Break">address: </span><a href="https://github.com/PacktPublishing/FastAPI-Cookbook/tree/main/Chapter05"><span class="No-Break">https://github.com/PacktPublishing/FastAPI-Cookbook/tree/main/Chapter05</span></a><span class="No-Break">.</span></p>
<p>You can setup a virtual environment for the project within the project root folder is also recommended to manage dependencies efficiently and maintain project isolation. Within your virtual environment, you can install all the dependencies at once by using the <strong class="source-inline">requirements.txt</strong> provided on the GitHub repository in the <span class="No-Break">project folder:</span></p>
<pre class="console">
$ pip install –r requirements.txt</pre> <p>A basic knowledge of HTTP protocol, although not required, can <span class="No-Break">be beneficial.</span></p>
<h1 id="_idParaDest-157"><a id="_idTextAnchor160"/>Setting up testing environments</h1>
<p>This recipe will show you<a id="_idIndexMarker285"/> how to setup an efficient and effective testing environment tailored for FastAPI applications. By the end of the recipe, you will have a solid foundation for writing, running, and <span class="No-Break">managing tests.</span></p>
<h2 id="_idParaDest-158"><a id="_idTextAnchor161"/>Getting ready</h2>
<p>Make sure you have an application running. If not you can start by creating a project <span class="No-Break">folder </span><span class="No-Break"><strong class="source-inline">proto_app</strong></span><span class="No-Break">.</span></p>
<p>If you haven’t installed the packages with the requirements.txt file provided on the GitHub repository, then install the testing libraries <strong class="source-inline">pytest</strong> and <strong class="source-inline">httpx</strong> in your <span class="No-Break">environment with:</span></p>
<pre class="console">
$ pip install pytest pytest-asyncio httpx</pre> <p>In the project root folder create a new folder <strong class="source-inline">proto_app</strong> with a <strong class="source-inline">main.py</strong> module containing the<strong class="source-inline"> app</strong> <span class="No-Break">object instance</span><span class="No-Break">:</span></p>
<pre class="source-code">
from fastapi import FastAPI
app = FastAPI()
@app.get("/home")
async def read_main():
    return {"message": "Hello World"}</pre> <p>With a minimal<a id="_idIndexMarker286"/> app setup, we can proceed by scaffolding our project to accommodate <span class="No-Break">the tests.</span></p>
<h2 id="_idParaDest-159"><a id="_idTextAnchor162"/>How to do it...</h2>
<p>First, let’s start by structuring our project folder tree to <span class="No-Break">accommodate tests.</span></p>
<ol>
<li>In the root directory let’s create a <strong class="source-inline">pytest.ini</strong> file and a <strong class="source-inline">tests</strong> folder containing the test module <strong class="source-inline">test_main.py</strong>. The project structure should look <span class="No-Break">like this:</span><pre class="source-code">
<strong class="bold">protoapp/</strong>
<strong class="bold">|─ protoapp/</strong>
<strong class="bold">│  |─ main.py</strong>
<strong class="bold">|─ tests/</strong>
<strong class="bold">│</strong><strong class="bold">  |─ test_main.py</strong>
<strong class="bold">|─ pytest.ini</strong></pre></li> <li>The <strong class="source-inline">pytest.ini</strong> contains instructions for <strong class="source-inline">pytest</strong>. You can write <span class="No-Break">in it:</span><pre class="source-code">
[pytest]
pythonpath = . protoapp</pre><p class="list-inset">This will add the project root and the folder <strong class="source-inline">protoapp</strong>, containing the code, to the <strong class="source-inline">PYTHONPATH</strong> when <span class="No-Break">running </span><span class="No-Break"><strong class="source-inline">pytest</strong></span><span class="No-Break">.</span></p></li> <li>Now, in the <strong class="source-inline">test_main.py</strong> module, let’s write a test for the <strong class="source-inline">/home</strong> endpoint we <span class="No-Break">created </span><span class="No-Break"><a id="_idIndexMarker287"/></span><span class="No-Break">earlier:</span><pre class="source-code">
import pytest
from httpx import ASGITransport, AsyncClient
from protoapp.main import app
@pytest.mark.asyncio
async def test_read_main():
    client = AsyncClient(
        transport=ASGITransport(app=app),
        base_url="http://test",
    )
    response = await client.get("/home")
    assert response.status_code == 200
    assert response.json() == {
        "message": "Hello World"
    }</pre><p class="list-inset">As a first check of the environment, we can try to collect the tests. From the <strong class="source-inline">protoapp</strong> root project <span class="No-Break">folder run:</span></p><pre class="source-code"><strong class="bold">$ pytest –-collect-only</strong></pre><p class="list-inset">You should get an <span class="No-Break">output like:</span></p><pre class="source-code"><strong class="bold">configfile: pytest.ini</strong>
<strong class="bold">plugins: anyio-4.2.0, asyncio-0.23.5, cov-4.1.0</strong>
<strong class="bold">asyncio: mode=Mode.STRICT</strong>
<strong class="bold">collected 1 item</strong>
<strong class="bold">&lt;Dir protoapp&gt;</strong>
<strong class="bold">  &lt;Dir tests&gt;</strong>
<strong class="bold">    </strong><strong class="bold">&lt;Module test_main.py&gt;</strong>
<strong class="bold">      &lt;Coroutine test_read_main&gt;</strong></pre><p class="list-inset"><span class="No-Break">This specifies:</span></p><ul><li>The<a id="_idIndexMarker288"/> configuration <span class="No-Break">file </span><span class="No-Break"><strong class="source-inline">pytest.ini</strong></span></li><li>The <strong class="source-inline">pytest</strong> <span class="No-Break">plugins used</span></li><li>The directory tests, the module <strong class="source-inline">test_main.py and</strong> the test <strong class="source-inline">test_read_main</strong> which is <span class="No-Break">a coroutine</span></li></ul></li> <li>Now, from the command line terminal at the project root folder level, run the <span class="No-Break"><strong class="source-inline">pytest</strong></span><span class="No-Break"> command:</span><pre class="source-code">
<strong class="bold">$ pytest</strong></pre></li> </ol>
<p>You’ve just setup the environment to test our <span class="No-Break">proto application.</span></p>
<h2 id="_idParaDest-160"><a id="_idTextAnchor163"/>See also</h2>
<p>The recipe has shown<a id="_idIndexMarker289"/> how to configure <strong class="source-inline">pytest</strong> within a <strong class="bold">FastAPI</strong> project with some of the good practices. Feel free to dig deeper into the <strong class="bold">Pytest</strong> official documentation at <span class="No-Break">the links:</span></p>
<ul>
<li><em class="italic">Pytest </em><span class="No-Break"><em class="italic">configuration</em></span><span class="No-Break">: </span><a href="https://docs.pytest.org/en/stable/reference/customize.xhtml"><span class="No-Break">https://docs.pytest.org/en/stable/reference/customize.xhtml</span></a></li>
<li><em class="italic">Setup PYTHONPATH in </em><span class="No-Break"><em class="italic">Pytest</em></span><span class="No-Break">: </span><a href="https://docs.pytest.org/en/7.1.x/explanation/pythonpath.xhtml"><span class="No-Break">https://docs.pytest.org/en/7.1.x/explanation/pythonpath.xhtml</span></a></li>
<li><em class="italic">Pytest good </em><span class="No-Break"><em class="italic">practices</em></span><span class="No-Break">: </span><a href="https://docs.pytest.org/en/7.1.x/explanation/goodpractices.xhtml"><span class="No-Break">https://docs.pytest.org/en/7.1.x/explanation/goodpractices.xhtml</span></a></li>
</ul>
<h1 id="_idParaDest-161"><a id="_idTextAnchor164"/>Writing and running unit tests</h1>
<p>Once we setup <a id="_idIndexMarker290"/>our testing environment, we can focus on the process of writing and executing tests for FastAPI applications. Unit tests are essential for validating the behaviour of individual parts of your application in isolation, ensuring they perform as expected. In this recipe, you will learn to test the endpoints of <span class="No-Break">your application.</span></p>
<h2 id="_idParaDest-162"><a id="_idTextAnchor165"/>Getting ready</h2>
<p>We will use <strong class="source-inline">pytest</strong> to test the FastAPI client in unit tests. Since the recipe will utilize common testing <em class="italic">fixtures</em>, used in most <strong class="bold">Python</strong> standard code, make sure to be familiar with the test fixtures before diving into the recipe. If this is not the case, you can always refer to the dedicated documentation page at the <span class="No-Break">link: </span><a href="https://docs.pytest.org/en/7.1.x/reference/fixtures.xhtml"><span class="No-Break">https://docs.pytest.org/en/7.1.x/reference/fixtures.xhtml</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-163"><a id="_idTextAnchor166"/>How to do it…</h2>
<p>We will start by creating a unit test for the same <strong class="source-inline">GET /home</strong> endpoint, but differently from the previous recipe. We will use the <strong class="source-inline">TestClient</strong> class provided <span class="No-Break">by FastAPI.</span></p>
<p>Let’s create a fixture for that. Since it could be used by multiple tests let’s do it in a new <strong class="source-inline">conftest.py</strong> module under the <strong class="source-inline">tests</strong> folder. The <strong class="source-inline">conftest.py</strong> is a default file used by <strong class="source-inline">pytest</strong> to store common elements shared amongst <span class="No-Break">test modules.</span></p>
<p>In the <strong class="source-inline">conftest.py</strong> <span class="No-Break">let’s write:</span></p>
<pre class="source-code">
import pytest
from fastapi.testclient import TestClient
from protoapp.main import app
@pytest.fixture(scope="function")
def test_client(db_session_test):
    client = TestClient(app)
    yield client</pre> <p>We are now ready<a id="_idIndexMarker291"/> to leverage the <strong class="source-inline">test_client</strong> fixture to create a proper unit test for <span class="No-Break">our endpoint.</span></p>
<p>We will write our test in the <span class="No-Break"><strong class="source-inline">test_main.py</strong></span><span class="No-Break"> module:</span></p>
<pre class="source-code">
def test_read_main_client(test_client):
    response = test_client.get("/home")
    assert response.status_code == 200
    assert response.json() == {"message": "Hello World"}</pre> <p>And that’s it. Compared to the previous test, this one is more compact and faster to write, thanks to the <strong class="source-inline">TestClient</strong> class provided by <span class="No-Break">FastAPI package.</span></p>
<p>Now <span class="No-Break">run </span><span class="No-Break"><strong class="source-inline">pytest</strong></span><span class="No-Break">:</span></p>
<pre class="console">
$ pytest</pre> <p>You will see a message on the terminal showing that two tests have been collected and <span class="No-Break">run successfully.</span></p>
<h2 id="_idParaDest-164"><a id="_idTextAnchor167"/>See also</h2>
<p>You can check more<a id="_idIndexMarker292"/> on the test client for FastAPI in the <span class="No-Break">official </span><span class="No-Break"><a id="_idIndexMarker293"/></span><span class="No-Break">documentation:</span></p>
<ul>
<li><em class="italic">FastAPI Test </em><span class="No-Break"><em class="italic">Client</em></span><span class="No-Break">: </span><a href="https://fastapi.tiangolo.com/reference/testclient/"><span class="No-Break">https://fastapi.tiangolo.com/reference/testclient/</span></a></li>
</ul>
<h1 id="_idParaDest-165"><a id="_idTextAnchor168"/>Testing API Endpoints</h1>
<p>Integration tests<a id="_idIndexMarker294"/> verify that different parts of your application work together as expected. They are crucial for ensuring that your system’s components interact correctly, especially when dealing with external services, databases, or <span class="No-Break">other APIs.</span></p>
<p>In this recipe, we will test two endpoints that interact with an SQL database. One will add an item to the database, the other will read an item based on <span class="No-Break">the ID.</span></p>
<h2 id="_idParaDest-166"><a id="_idTextAnchor169"/>Getting ready</h2>
<p>To apply the recipe you need your testing environment already setup for <strong class="source-inline">pytest</strong>. If this is not the case check the recipe <em class="italic">Setting up </em><em class="italic">testing environments</em> of the <span class="No-Break">same chapter.</span></p>
<p>Also, the recipe will show you how to make integration tests with existing endpoints of the application. You can use it for your application or you can build the endpoints for our <strong class="source-inline">protoapp</strong> <span class="No-Break">as follows.</span></p>
<p>If you are using the recipe to test your endpoint you can directly jump on the <em class="italic">How to it…</em> section and apply the rules to <span class="No-Break">tour endpoints.</span></p>
<p>Otherwise, If you haven’t installed the packages from the <strong class="source-inline">requirements.txt</strong>, install <strong class="source-inline">sqlalchemy</strong> package in <span class="No-Break">your environment:</span></p>
<pre class="console">
$ pip install "sqlalchemy&gt;=2.0.0"</pre> <p>Now let’s setup the database connection through the <span class="No-Break">following steps.</span></p>
<ol>
<li>Under the <strong class="source-inline">protoapp</strong> folder, at the same level as the <strong class="source-inline">main.py</strong> module, let’s create a module <strong class="source-inline">database.py</strong> containing the setup of the database. Let’s start by creating the <span class="No-Break"><strong class="source-inline">Base</strong></span><span class="No-Break"> class:</span><pre class="source-code">
from sqlalchemy.orm import DeclarativeBase,
class Base(DeclarativeBase):
    pass</pre><p class="list-inset">We will use the <strong class="source-inline">Base</strong> class to define the <strong class="source-inline">Item</strong> <span class="No-Break">mapping class.</span></p></li> <li>Then the database <strong class="source-inline">Item</strong> mapping class will <span class="No-Break">be like:</span><pre class="source-code">
from sqlalchemy.orm import (
    Mapped,
    mapped_column,
)
class Item(Base):
    __tablename__ = "items"
    id: Mapped[int] = mapped_column(
        primary_key=True, index=True
    )
    name: Mapped[str] = mapped_column(index=True)
    color: Mapped[str]</pre></li> <li>Then, we<a id="_idIndexMarker295"/> define the database engine that will handle <span class="No-Break">the session:</span><pre class="source-code">
DATABASE_URL = "sqlite:///./production.db"
engine = create_engine(DATABASE_URL)</pre><p class="list-inset">The engine object will be used to handle <span class="No-Break">the session.</span></p></li> <li>Then, let’s bind the engine to the Base <span class="No-Break">mapping class:</span><pre class="source-code">
Base.metadata.create_all(bind=engine)</pre><p class="list-inset">Now the engine can map the database table to our <span class="No-Break">Python classes.</span></p></li> <li>Last in the <strong class="source-inline">database.py</strong> module let’s create a <strong class="source-inline">SessionLocal</strong> class that will generate the <span class="No-Break">session as:</span><pre class="source-code">
SessionLocal = sessionmaker(
    autocommit=False, autoflush=False, bind=engine
)</pre><p class="list-inset">The <strong class="source-inline">SessionLocal</strong> is a class that will initialize the database <span class="No-Break">session object.</span></p></li> <li>Finally, before creating the endpoints, let’s create a <span class="No-Break">database session.</span><p class="list-inset">Since the app<a id="_idIndexMarker296"/> is relatively small, we can do it the <span class="No-Break">same </span><span class="No-Break"><strong class="source-inline">main.py</strong></span><span class="No-Break">:</span></p><pre class="source-code">
from protoapp.database import SessionLocal
def get_db_session():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()</pre><p class="list-inset">We will use the session to interact with <span class="No-Break">the database.</span></p></li> </ol>
<p>Now that we have setup the database connection, in the <strong class="source-inline">main.py</strong> module, we can create the endpoints one to add an item to the database and one to read it. Let's do it <span class="No-Break">as follows.</span></p>
<ol>
<li>Let's start by creating the request body for the <span class="No-Break">endpoints as::</span><pre class="source-code">
from pydantic import BaseModel
class ItemSchema(BaseModel):
    name: str
    color: str</pre></li> <li>The endpoint used to add an item will <span class="No-Break">then be:</span><pre class="source-code">
from fastapi import (
    Depends,
    Request,
    HTTPException,
    status
)
from sqlalchemy.orm import Session
@app.post(
"/item",
response_model=int,
status_code=status.HTTP_201_CREATED
)
def add_item(
    item: ItemSchema,
    db_session: Session = Depends(get_db_session),
):
    db_item = Item(name=item.name, color=item.color)
    db_session.add(db_item)
    db_session.commit()
    db_session.refresh(db_item)
    return db_item.id</pre><p class="list-inset">The endpoint will return the item ID affected when the item is stored in the database. </p></li> <li>Now that we have the endpoint to add the item, we can proceed by creating the endpoint<a id="_idIndexMarker297"/> to retrieve the item based on <span class="No-Break">its ID:</span><pre class="source-code">
@app.get("/item/{item_id}", response_model=ItemSchema)
def get_item(
    item_id: int,
    db_session: Session = Depends(get_db_session),
):
    item_db = (
        db_session.query(Item)
        .filter(Item.id == item_id)
        .first()
    )
    if item_db is None:
        raise HTTPException(
            status_code=404, detail="Item not found"
        )
    return item_db</pre><p class="list-inset">If the ID does not correspond to any item in the database the endpoint will return a 404 <span class="No-Break">status code.</span></p></li> </ol>
<p>We have just created the endpoints that will allow us to create an <span class="No-Break">integration test.</span></p>
<h2 id="_idParaDest-167"><a id="_idTextAnchor170"/>How to do it…</h2>
<p>Once we have the endpoints, in the <strong class="source-inline">tests</strong> folder we should adapt our <strong class="source-inline">test_client</strong> fixture to use a different session than the one used <span class="No-Break">in production.</span></p>
<p>We will break the process into two <span class="No-Break">main </span><span class="No-Break">actions</span><span class="No-Break">:</span></p>
<ul>
<li>Adapt the <a id="_idIndexMarker298"/>test client to accommodate the testing <span class="No-Break">database session</span></li>
<li>Create the test to simulate the interaction of <span class="No-Break">the endpoints</span></li>
</ul>
<p>Let's do it by following <span class="No-Break">these steps.</span></p>
<ol>
<li>First, In the <strong class="source-inline">conftest.py</strong> file we created earlier in the recipe <em class="italic">Writing and running unit tests</em>, let’s define a new engine that will use an in-memory SQLite database and bind it to the mapping <span class="No-Break"><strong class="source-inline">Base</strong></span><span class="No-Break"> class:</span><pre class="source-code">
from sqlalchemy.pool import StaticPool
from sqlalchemy import create_engine
engine = create_engine(
    "sqlite:///:memory:",
    connect_args={"check_same_thread": False},
    poolclass=StaticPool,
)
Base.metadata.create_all(bind=engine)  # Bind the engine</pre></li> <li>Let’s create a dedicated session maker for the testing <span class="No-Break">session as:</span><pre class="source-code">
from sqlalchemy.orm import sessionmaker
TestingSessionLocal = sessionmaker(
    autocommit=False, autoflush=False, bind=engine
)</pre></li> <li>Similarly to the function <strong class="source-inline">get_db_session</strong> in the <strong class="source-inline">main.py</strong> module, we can create a fixture to retrieve the test session in the <span class="No-Break">conftest.py module:</span><pre class="source-code">
@pytest.fixture
def test_db_session():
    db = TestingSessionLocal()
    try:
        yield db
    finally:
        db.close()</pre></li> <li>Then, we should <a id="_idIndexMarker299"/>modify the <strong class="source-inline">test_client</strong> to use this session instead of the production one. We can do it by overwriting the dependency that returns the session with the one we just created. FastAPI allows you to do it easily by calling the test client’s method <span class="No-Break"><strong class="source-inline">dependency_overrides</strong></span><span class="No-Break"> as:</span><pre class="source-code">
<strong class="bold">from protoapp.main import app, get_db_session</strong>
@pytest.fixture(scope="function")
def test_client(test_db_session):
    client = TestClient(app)
<strong class="bold">    app.dependency_overrides[get_db_session] = (</strong>
<strong class="bold">        lambda: test_db_session</strong>
<strong class="bold">    </strong><strong class="bold">)</strong>
    return client</pre><p class="list-inset">Each time the test client needs to call the session, the fixture will replace it with the test session that uses the <span class="No-Break">in-memory database.</span></p></li> <li>Then, to verify the interaction of our application with the database, we create a <span class="No-Break">test that:</span><ul><li>Create the item into the database through the <strong class="source-inline">POST /</strong><span class="No-Break"><strong class="source-inline">item</strong></span><span class="No-Break"> endpoint</span></li><li>Verify that the item is correctly created into the test database by using the <span class="No-Break">test session</span></li><li>Retrieve the item through the <strong class="source-inline">GET /</strong><span class="No-Break"><strong class="source-inline">item</strong></span><span class="No-Break"> endpoint</span></li></ul><p class="list-inset">You can put<a id="_idIndexMarker300"/> the test into the <strong class="source-inline">test_main.py</strong> and here is how it would <span class="No-Break">look like:</span></p><pre class="source-code">
def test_client_can_add_read_the_item_from_database(
    test_client, test_db_session
):
    response = test_client.get("/item/1")
    assert response.status_code == 404
    response = test_client.post(
        "/item", json={"name": "ball", "color": "red"}
    )
    assert response.status_code == 201
    # Verify the user was added to the database
    item_id = response.json()
    item = (
        test_db_session.query(Item)
        .filter(Item.id == item_id)
        .first()
    )
    assert item is not None
    response = test_client.get(f"item/{item_id}")
    assert response.status_code == 200
    assert response.json() == {
        "name": "ball",
        "color": "red",
    }</pre></li> </ol>
<p>You’ve just created an integration test for our proto application, feel free to enrich your application and <a id="_idIndexMarker301"/>create more <span class="No-Break">tests accordingly.</span></p>
<h2 id="_idParaDest-168"><a id="_idTextAnchor171"/>See also</h2>
<p>We have setup an in-memory SQLite database for our tests. Since each session is bonded to a thread, the engine needs to be configured accordingly to not <span class="No-Break">flush data.</span></p>
<p>The configuration strategy <a id="_idIndexMarker302"/>has been found on the following <span class="No-Break">documentation page:</span></p>
<ul>
<li><em class="italic">SQLite In-Memory Database </em><span class="No-Break"><em class="italic">Configuration</em></span><span class="No-Break">: </span><a href="https://docs.sqlalchemy.org/en/14/dialects/sqlite.xhtml#using-a-memory-database-in-multiple-threads"><span class="No-Break">https://docs.sqlalchemy.org/en/14/dialects/sqlite.xhtml#using-a-memory-database-in-multiple-threads</span></a></li>
</ul>
<h1 id="_idParaDest-169"><a id="_idTextAnchor172"/>Running tests techniques</h1>
<p>By systematically <a id="_idIndexMarker303"/>covering all endpoints and scenarios, you ensure that your API behaves correctly under various conditions, providing confidence in your application’s functionality. Thoroughly testing API endpoints is essential for building reliable and <span class="No-Break">robust applications.</span></p>
<p>The recipe will explain to you how to run tests individually or by group and how to check the test coverage of <span class="No-Break">our code.</span></p>
<h2 id="_idParaDest-170"><a id="_idTextAnchor173"/>Getting ready</h2>
<p>To run the recipe, make sure you already have some tests in place, or you already followed all the previous recipes of the chapter. Also, make sure you have your PYTHONPATH for tests defined in your <strong class="source-inline">pytest.ini</strong>. Have a look at the recipe <em class="italic">Setting up </em><em class="italic">testing environments</em> on how to <span class="No-Break">do it.</span></p>
<h2 id="_idParaDest-171"><a id="_idTextAnchor174"/>How to do it...</h2>
<p>We will start by looking at how to run tests by default grouping (individually or by module), and then we will cover a technique for customizing test grouping based <span class="No-Break">on marks.</span></p>
<p>As you already know, all unit tests can be run from the terminal with <span class="No-Break">the command:</span></p>
<pre class="console">
$ pytest</pre> <p>However, a test can be run individually according to the test <span class="No-Break">call syntax:</span></p>
<pre class="console">
$ pytest &lt;test_module&gt;.py::&lt;test_name&gt;</pre> <p>For example, if we want to run the test function <span class="No-Break"><strong class="source-inline">test_read_main_client</strong></span><span class="No-Break">, run:</span></p>
<pre class="console">
$ pytest tests/test_main.py::test_read_main</pre> <p>Sometimes test names become too complicated to remember or we have a specific need to run only a targeted set of tests. Here is where test marks come to <span class="No-Break">the aid.</span></p>
<p>Let’s imagine we want to run only integration tests. In our app, the only integration test is represented by the <span class="No-Break">function </span><span class="No-Break"><strong class="source-inline">tests_client_can_add_read_the_item_from_database</strong></span><span class="No-Break">.</span></p>
<p>We can apply a mark by adding the specific decorator to <span class="No-Break">the function:</span></p>
<pre class="source-code">
<strong class="bold">@pytest.mark.integration</strong>
def test_client_can_add_read_the_item_from_database(
    test_client, test_db_session
):
    # test content</pre> <p>Then, in the <strong class="source-inline">pytest.ini</strong> configuration add the <strong class="source-inline">integration</strong> marker in the dedicated sections to register <span class="No-Break">the mark:</span></p>
<pre class="source-code">
[pytest]
pythonpath = protoapp .
<strong class="bold">markers =</strong>
<strong class="bold">    integration: marks tests as integration</strong></pre> <p>Now you can run the targeted tests <span class="No-Break">by running:</span></p>
<pre class="console">
$ pytest –m integration -vv</pre> <p>In the output message, you will see that only the marked test has been selected and run. You can use markers to group your application’s tests based on logical criteria, for example by functional <a id="_idIndexMarker304"/>meaning one group for <strong class="bold">create, read, update and delete </strong>(<strong class="bold">CRUD</strong>) operations, one <a id="_idIndexMarker305"/>group for security operations, and <span class="No-Break">so on.</span></p>
<h2 id="_idParaDest-172"><a id="_idTextAnchor175"/>Check test coverage</h2>
<p>To make sure that your <a id="_idIndexMarker306"/>endpoints are covered by testing as well as the text lines of your code, it can become useful to have an idea of the <span class="No-Break">test coverage.</span></p>
<p>Test coverage is a metric used in software testing to measure the extent to which the source code of a program is executed when a particular test <span class="No-Break">suite runs.</span></p>
<p>To use it with <strong class="source-inline">pytest</strong>, if you didn’t install the packages with the <strong class="source-inline">requirements.txt</strong>, you need to install <span class="No-Break"><strong class="source-inline">pytest-cov</strong></span><span class="No-Break"> package:</span></p>
<pre class="console">
$ pip install pytest-cov</pre> <p>The way it works is quite straightforward. You need to pass the source code root, in our case the <strong class="source-inline">protoapp</strong> directory, to the parameter <strong class="source-inline">–cov</strong> of <strong class="source-inline">pytest</strong> and tests root folder, in our case tests <span class="No-Break">as follows:</span></p>
<pre class="console">
$ pytest –-cov protoapp tests</pre> <p>You will see a table in the output listing the coverage percentage for <span class="No-Break">each module:</span></p>
<pre class="console">
Name                   Stmts   Miss  Cover
------------------------------------------
protoapp\database.py      16      0   100%
protoapp\main.py          37      4    89%
protoapp\schemas.py        8      8     0%
------------------------------------------
TOTAL                     61     12    80%</pre> <p>In addition, a file named <strong class="source-inline">.coverage</strong> has been created. This is a binary file containing data on the test coverage and that can be used with additional tools to generate reports out <span class="No-Break">of it.</span></p>
<p>For example, if <span class="No-Break">you run:</span></p>
<pre class="console">
$ coverage html</pre> <p>It will create a <a id="_idIndexMarker307"/>folder <strong class="source-inline">htmlcov</strong> with an <strong class="source-inline">index.xhtml</strong> page containing the coverage page and you can visualize it by opening it with <span class="No-Break">a browser.</span></p>
<h2 id="_idParaDest-173"><a id="_idTextAnchor176"/>See also</h2>
<p>You can check more on various options to invoke unit tests with Pytest and how to evaluate test coverage<a id="_idIndexMarker308"/> at the official <span class="No-Break">documentation links</span></p>
<ul>
<li><em class="italic">Invoke Unit test with </em><span class="No-Break"><em class="italic">Pytest</em></span><span class="No-Break">: </span><a href="https://docs.pytest.org/en/7.1.x/how-to/usage.xhtml"><span class="No-Break">https://docs.pytest.org/en/7.1.x/how-to/usage.xhtml</span></a></li>
<li><em class="italic">Pytest </em><span class="No-Break"><em class="italic">Coverage</em></span><span class="No-Break">: </span><a href="https://pytest-cov.readthedocs.io/en/latest/"><span class="No-Break">https://pytest-cov.readthedocs.io/en/latest/</span></a></li>
</ul>
<h1 id="_idParaDest-174"><a id="_idTextAnchor177"/>Handling logging messages</h1>
<p>Effectively managing logs in application development not only aids in identifying errors promptly but also <a id="_idIndexMarker309"/>provides valuable<a id="_idIndexMarker310"/> insights into user interactions, system performance, and potential security threats. It serves as a crucial tool for auditing, compliance, and optimizing resource utilization, ultimately enhancing the reliability and scalability of <span class="No-Break">the software.</span></p>
<p>This recipe will show how to efficiently implement a logging system into our FastAPI application to monitor the calls to <span class="No-Break">the API.</span></p>
<h2 id="_idParaDest-175"><a id="_idTextAnchor178"/>Getting ready</h2>
<p>We are going to use some basic features of the Python <span class="No-Break">logging ecosystem.</span></p>
<p>Although the example is basic, you can refer to the official documentation to get familiar with related terms such as <strong class="bold">logger</strong>, <strong class="bold">handler</strong> , <strong class="bold">formatter</strong>, and <strong class="bold">log level</strong>. Follow <span class="No-Break">this link:</span></p>
<p><a href="https://docs.python.org/3/howto/logging-cookbook.xhtml"><span class="No-Break">https://docs.python.org/3/howto/logging-cookbook.xhtml</span></a><span class="No-Break">.</span></p>
<p>To implement logging into FastAPI, make sure you have a running application or use the <strong class="source-inline">protoapp</strong> we developed all along <span class="No-Break">the chapter.</span></p>
<h2 id="_idParaDest-176"><a id="_idTextAnchor179"/>How to do it...</h2>
<p>We want to create a logger that prints the client’s calls information to the terminal and logs them into <span class="No-Break">a file.</span></p>
<p>Let’s create the logger into a dedicated <strong class="source-inline">logging.py</strong> module under the folder <strong class="source-inline">protoapp</strong>, through the <span class="No-Break">following steps.</span></p>
<ol>
<li>Let’s start by defining the logger with a level value <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">INFO</strong></span><span class="No-Break">:</span><pre class="source-code">
import logging
client_logger = logging.getLogger("client.logger")
logger.setLevel(logging.INFO)</pre><p class="list-inset">Since we want to stream the message to the console and store it in a file, we will need to define two <span class="No-Break">separate handlers.</span></p></li> <li>Now let’s define the handler to print log messages to the console. We will use a <strong class="source-inline">StreamHandler</strong> object from the <strong class="source-inline">logging</strong> <span class="No-Break">built-in package:</span><pre class="source-code">
console_handler = logging.StreamHandler()</pre><p class="list-inset">This will stream the message to <span class="No-Break">the console.</span></p></li> <li>Let’s create <a id="_idIndexMarker311"/>a <a id="_idIndexMarker312"/>colorized formatter and add it to the handler we <span class="No-Break">just created:</span><pre class="source-code">
from uvicorn.logging import ColourizedFormatter
console_formatter = ColourizedFormatter(
    "%(levelprefix)s CLIENT CALL - %(message)s",
    use_colors=True,
)
console_handler.setFormatter(console_formatter)</pre><p class="list-inset">The formatter will format log messages in the same of the default logger uvicorn logger used <span class="No-Break">by FastAPI.</span></p></li> <li>Then let’s add the handler to <span class="No-Break">the logger:</span><pre class="source-code">
client_logger.addHandler(console_handler)</pre><p class="list-inset">We have just set up the logger to print message to <span class="No-Break">the console.</span></p></li> <li>Let’s repeat the previous <em class="italic">steps from 1 to 4</em> to create a handler that stores messages into a file and adds it to <span class="No-Break">our </span><span class="No-Break"><strong class="source-inline">client_logger</strong></span><span class="No-Break">:</span><pre class="source-code">
from logging.handlers import TimedRotatingFileHandler
file_handler = TimedRotatingFileHandler("app.log")
file_formatter = logging.Formatter(
    "time %(asctime)s, %(levelname)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
file_handler.setFormatter(file_formatter)
client_logger.addHandler(file_handler)</pre><p class="list-inset">Now we have <a id="_idIndexMarker313"/>our <a id="_idIndexMarker314"/>logger setup. Each message will be streamed to the console and stored in a <span class="No-Break"><strong class="source-inline">app.log</strong></span><span class="No-Break"> file.</span></p></li> <li>Once we have built our <strong class="source-inline">client_logger</strong>, we need to use it in the code to get information about <span class="No-Break">clients calls.</span><p class="list-inset">You can reach this by adding the logger and a dedicated middleware in the <span class="No-Break"><strong class="source-inline">main.py</strong></span><span class="No-Break"> module:</span></p><pre class="source-code">
from protoapp.logging import client_logger
# ... module content
@app.middleware("http")
async def log_requests(request: Request, call_next):
    client_logger.info(
        f"method: {request.method}, "
        f"call: {request.url.path}, "
        f"ip: {request.client.host}"
    )
    response = await call_next(request)
    return response</pre></li> <li>Now spin up <span class="No-Break">the server:</span><pre class="source-code">
<strong class="bold">$ uvicorn protoapp.main:app</strong></pre></li> </ol>
<p>Try to call any of the endpoints we defined, you will see on the terminal the logs we just defined for the request and response. Also, you will find only the messages from our <strong class="source-inline">logger_client</strong> in a<a id="_idIndexMarker315"/> newly<a id="_idIndexMarker316"/> created <strong class="source-inline">app.log</strong> file automatically created by <span class="No-Break">the application.</span></p>
<h2 id="_idParaDest-177"><a id="_idTextAnchor180"/>There’s more</h2>
<p>Defining a proper logging strategy would require a separate cookbook and it is out of the scope of the book. However, when building a logger into an application it is important to follow <span class="No-Break">some guidelines:</span></p>
<ul>
<li><strong class="bold">Use standard Logging Levels Appropriately</strong>. A classical leveling system is made up of 4 levels: <strong class="bold">INFO</strong>, <strong class="bold">WARNING</strong>, <strong class="bold">ERROR</strong>, <strong class="bold">CRITICAL</strong>. You may need to have more or even less than four depending on the application. Anyway, place each message at the <span class="No-Break">appropriate level.</span></li>
<li><strong class="bold">Consist Log Format</strong>. Maintain a consistent log format across your application. This includes consistent datetime formats, including the severity level, and describing the event clearly. A consistent format helps in parsing logs and automating <span class="No-Break">log analysis.</span></li>
<li><strong class="bold">Include Contextual Information</strong>. Include relevant contextual information in your logs (e.g., user ID, transaction ID) to help trace and debug issues across your <span class="No-Break">application’s workflow.</span></li>
<li><strong class="bold">Avoid Sensitive Information</strong>. Never log sensitive information such as passwords, API keys, or <strong class="bold">personal identifiable information</strong> (<strong class="bold">PII</strong>). If necessary, mask or hash <span class="No-Break">these details.</span></li>
<li><strong class="bold">Make Efficient Logging</strong>. Be mindful of the performance impact of logging. Logging excessively can slow down your application and lead to log noise, making it hard to find useful information. Balance the need for information against the <span class="No-Break">performance impact.</span></li>
</ul>
<p>And of course, this is not<a id="_idIndexMarker317"/> a<a id="_idIndexMarker318"/> <span class="No-Break">comprehensive list.</span></p>
<h2 id="_idParaDest-178"><a id="_idTextAnchor181"/>See also</h2>
<p>Python distribution comes with a powerful built-in package for logging, feel to have a look at the <a id="_idIndexMarker319"/><span class="No-Break">official documentation:</span></p>
<ul>
<li><em class="italic">Python </em><span class="No-Break"><em class="italic">logging</em></span><span class="No-Break">: </span><a href="https://docs.python.org/3/library/logging.xhtml"><span class="No-Break">https://docs.python.org/3/library/logging.xhtml</span></a></li>
</ul>
<p>Furthermore, discover <a id="_idIndexMarker320"/>more on logging best practices and guidelines at the <span class="No-Break"><strong class="bold">Sentry</strong></span><span class="No-Break"> blog:</span></p>
<ul>
<li><em class="italic">Logging </em><span class="No-Break"><em class="italic">Guidelines</em></span><span class="No-Break">: </span><a href="https://blog.sentry.io/logging-in-python-a-developers-guide/"><span class="No-Break">https://blog.sentry.io/logging-in-python-a-developers-guide/</span></a></li>
</ul>
<p><strong class="bold">Sentry</strong> is a tool to monitor <span class="No-Break">Python code.</span></p>
<h1 id="_idParaDest-179"><a id="_idTextAnchor182"/>Debugging techniques</h1>
<p>Mastering debugging <a id="_idIndexMarker321"/>application development is crucial for identifying and fixing issues efficiently. This recipe delves into the practical use of the debugger, leveraging tools and strategies to pinpoint problems in your <span class="No-Break">FastAPI code.</span></p>
<h2 id="_idParaDest-180"><a id="_idTextAnchor183"/>Getting ready</h2>
<p>All you need to do to apply the recipe is to have a running application. We can keep on working with <span class="No-Break">our </span><span class="No-Break"><strong class="source-inline">protoapp</strong></span><span class="No-Break">.</span></p>
<h2 id="_idParaDest-181"><a id="_idTextAnchor184"/>How to do it...</h2>
<p>The Python distribution already comes with a default debugger called <strong class="source-inline">pdb</strong>. If you use an <strong class="bold">integrated development environment</strong> (<strong class="bold">IDE</strong>), it usually comes with an editor distribution <a id="_idIndexMarker322"/>debugger. Whatever you are using to debug your code, you must be familiar with the concept <span class="No-Break">of breakpoints.</span></p>
<p>A <strong class="bold">breakpoint</strong> is a point within the code that pauses the execution and shows you the state of the code variables and calls. It can be attached with a condition that, if satisfied, activate it or <span class="No-Break">skips otherwise.</span></p>
<p>Whether you are using the Python distribution debugger <strong class="source-inline">pdb</strong> or the one provided by your IDE, it can be useful to define a starting script to spin up <span class="No-Break">the server.</span></p>
<p>Create on the <a id="_idIndexMarker323"/>project root folder a file called <strong class="source-inline">run_server.py</strong> containing the <span class="No-Break">following code:</span></p>
<pre class="source-code">
import uvicorn
from protoapp.main import app
if __name__ == "__main__":
    uvicorn.run(app)</pre> <p>The script imports the <strong class="source-inline">uvicorn</strong> package and our application <strong class="source-inline">app</strong> and runs the application into the <strong class="source-inline">uvicorn</strong> server. It is equivalent to the <span class="No-Break">launching command:</span></p>
<pre class="console">
$ uvicorn protoapp.main:app</pre> <p>Having a script gives us more flexibility to run the server and include it into a broader python routine <span class="No-Break">if required.</span></p>
<p>To check that it is correctly setup run the script as you would run a normal <span class="No-Break">python script:</span></p>
<pre class="console">
$ python run_server.py</pre> <p>With your favourite<a id="_idIndexMarker324"/> browser go to <strong class="source-inline">localhost:8000/docs</strong> and check that the documentation has been <span class="No-Break">correctly generated.</span></p>
<h2 id="_idParaDest-182"><a id="_idTextAnchor185"/>Debugging with PDB</h2>
<p>The PDB debugger<a id="_idIndexMarker325"/> comes by default with any Python<a id="_idIndexMarker326"/> distribution. From Python versions higher than 3.7, you can define a breakpoint by simply adding the function call <strong class="source-inline">breakpoint()</strong> at the line of the code you want to pause, and then run the code as you would <span class="No-Break">it normally.</span></p>
<p>If you then run the code, when it reaches the breakpoint line, the execution will automatically shift to debug mode, and you can run debugging commands from the terminal. You can find the list of the commands you can run by <span class="No-Break">typing help:</span></p>
<pre class="console">
(Pdb) help</pre> <p>You can run commands to list variables, show the stack trace to check to recent frame, or define new breakpoints with conditions <span class="No-Break">and more.</span></p>
<p>Here you can find the list of all the command <span class="No-Break">available: </span><a href="https://docs.python.org/3/library/pdb.xhtml#debugger-commands"><span class="No-Break">https://docs.python.org/3/library/pdb.xhtml#debugger-commands</span></a><span class="No-Break">.</span></p>
<p>You can also invoke <strong class="source-inline">pdb</strong> as a module. In this case <strong class="source-inline">pdb</strong> will automatically enter <strong class="bold">post-mortem</strong> debugging if the program <span class="No-Break">exists abnormally:</span></p>
<pre class="console">
$ python –m pdb run_server.py</pre> <p>That means that <strong class="source-inline">pdb</strong> will restart the program automatically by preserving <strong class="source-inline">pdb</strong> module's execution state <span class="No-Break">including breakpoints.</span></p>
<p>The same can be done when debugging tests by calling <strong class="source-inline">pytest</strong> as a module, <span class="No-Break">for example:</span></p>
<pre class="console">
$ python –m pdb -m pytest tests</pre> <p>Another debugging strategy consists of leveraging the reload functionality of the <strong class="source-inline">uvicorn</strong> server. To do that, you need to modify the <strong class="source-inline">run_server.py</strong> <span class="No-Break">file as:</span></p>
<pre class="source-code">
import uvicorn
if __name__ == "__main__":
    uvicorn.run("protoapp.main:app", reload=True)</pre> <p>Then, run the server without the <span class="No-Break"><strong class="source-inline">pdb</strong></span><span class="No-Break"> module:</span></p>
<pre class="console">
$ python run_server.py</pre> <p>In this way, you can always use the breakpoints at ease with the reloading <span class="No-Break">server functionality.</span></p>
<p>At the time of <a id="_idIndexMarker327"/>writing, <strong class="bold">post-mortem</strong> debugging is not<a id="_idIndexMarker328"/> supported with the automatic reload <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">unvicorn</strong></span><span class="No-Break">.</span></p>
<h2 id="_idParaDest-183"><a id="_idTextAnchor186"/>Debugging with VS Code</h2>
<p>VS <a id="_idIndexMarker329"/>Code Python <a id="_idIndexMarker330"/>extension comes with its distribution debugger called <em class="italic">debugpy</em>. Configurations for the running environment can be managed in the <strong class="source-inline">.vscode/launch.json</strong> file. An example of the configuration file to debug our <span class="No-Break">server is:</span></p>
<pre class="source-code">
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debugger FastAPI server",
            "type": "debugpy",
            "request": "launch",
            "program": "run_server.py",
            "console": "integratedTerminal",
        },
}</pre> <p>The configuration specifies the type of debugger to use (<strong class="source-inline">debugpy</strong>), the program to run (our launching script <strong class="source-inline">run_server.py</strong>), and it can be found in the <span class="No-Break">GUI options.</span></p>
<p>The <strong class="source-inline">request</strong> field specifies the mode to run the debugger, it can be <em class="italic">launch</em>, intended to run the program, or <em class="italic">attach</em>, intended to be attached to an already running instance, particularly useful to debug programs running on <span class="No-Break">remote instances.</span></p>
<p>Debugging remote instance is out of the scope of the recipe, but you can find detailed instructions at on the official <span class="No-Break">documentation: </span><a href="https://code.visualstudio.com/docs/python/debugging#_debugging-by-attaching-over-a-network-connection"><span class="No-Break">https://code.visualstudio.com/docs/python/debugging#_debugging-by-attaching-over-a-network-connection</span></a></p>
<p>Debugging configuration can be setup to run unit tests as well by leveraging the <em class="italic">Test Explorer</em> extension. The <a id="_idIndexMarker331"/>extension will look for <a id="_idIndexMarker332"/>a configuration in the <strong class="source-inline">launch.json</strong> containing <strong class="source-inline">"type": "python"</strong> and <strong class="source-inline">"purpose": ["debug-test"]</strong> (or <strong class="source-inline">"request": "test"</strong>). An example of configuration to debug tests <span class="No-Break">would be:</span></p>
<pre class="source-code">
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug test",
            "type": "python",
            "request": "launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "stopOnEntry": true,
            "envFile": "${workspaceFolder}/.env.test",
            "purpose": ["debug-test"]
        }
    ]
}</pre> <p>You can find an <a id="_idIndexMarker333"/>extensive explication on<a id="_idIndexMarker334"/> the extension page from the VS Code marketplace <span class="No-Break">at:</span><span class="No-Break"><span class="P---URL"> </span></span><a href="https://marketplace.visualstudio.com/items?itemName=LittleFoxTeam.vscode-python-test-adapter"><span class="No-Break">https://marketplace.visualstudio.com/items?itemName=LittleFoxTeam.vscode-python-test-adapter</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-184"><a id="_idTextAnchor187"/>Debugging with PyCharm</h2>
<p>PyCharm manages<a id="_idIndexMarker335"/> code execution through run/debug <a id="_idIndexMarker336"/>configurations, which are sets of named startup properties detailing execution parameters and environments. These configurations allow running scripts with different settings, such as using various Python interpreters, environment variables, and <span class="No-Break">input sources.</span></p>
<p>Run/debug configurations are of <span class="No-Break">two kinds:</span></p>
<ul>
<li>Temporary: Automatically generated for each run or <span class="No-Break">debug session.</span></li>
<li>Permanent: Manually created from a template or by converting a temporary one, and saved within your project indefinitely <span class="No-Break">until deleted.</span></li>
</ul>
<p>PyCharm by default uses an existing permanent configuration or creates a temporary one for each session. Temporary configurations are capped at five, with the oldest deleted for new ones. This limit can be adjusted in the settings (<strong class="bold">Settings</strong> | <strong class="bold">Advanced Settings</strong> | <strong class="bold">Run/Debug</strong> | <strong class="bold">Temporary configurations limit</strong>). Icons distinguish between permanent (opaque) and temporary (<span class="No-Break">semi-transparent) configurations.</span></p>
<p>Each configuration can be stored in a single xml file that is automatically detected by <span class="No-Break">the GUI.</span></p>
<p>An example of configuration for our FastAPI <strong class="source-inline">protoapp</strong> is <span class="No-Break">the following:</span></p>
<pre class="source-code">
&lt;component name="ProjectRunConfigurationManager"&gt;
  &lt;configuration default="false" name="run_server"
    type="PythonConfigurationType" factoryName="Python"
    nameIsGenerated="true"&gt;
    &lt;module name="protoapp" /&gt;
    &lt;option name="INTERPRETER_OPTIONS" value="" /&gt;
    &lt;option name="PARENT_ENVS" value="true" /&gt;
    &lt;envs&gt;
      &lt;env name="PYTHONUNBUFFERED" value="1" /&gt;
    &lt;/envs&gt;
    &lt;option name="WORKING_DIRECTORY"
      value="$PROJECT_DIR$" /&gt;
    &lt;option name="IS_MODULE_SDK" value="true" /&gt;
    &lt;option name="ADD_CONTENT_ROOTS" value="true" /&gt;
    &lt;option name="ADD_SOURCE_ROOTS" value="true" /&gt;
    &lt;option name="SCRIPT_NAME"
      value="$PROJECT_DIR$/run_server.py" /&gt;
    &lt;option name="SHOW_COMMAND_LINE" value="false" /&gt;
    &lt;option name="MODULE_MODE" value="false" /&gt;
    &lt;option name="REDIRECT_INPUT" value="false" /&gt;
    &lt;option name="INPUT_FILE" value="" /&gt;
    &lt;method v="2" /&gt;
  &lt;/configuration&gt;
&lt;/component&gt;</pre> <p>You can find a<a id="_idIndexMarker337"/> detailed guide on how to setup it <a id="_idIndexMarker338"/>at the dedicated <a id="_idIndexMarker339"/>Pycharm documentation page <span class="No-Break">at: </span><a href="https://www.jetbrains.com/help/pycharm/run-debug-configuration.xhtml"><span class="No-Break">https://www.jetbrains.com/help/pycharm/run-debug-configuration.xhtml</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-185"><a id="_idTextAnchor188"/>See also</h2>
<p>Feel free to dig into each<a id="_idIndexMarker340"/> of the debugging solutions and concepts we just explained at <span class="No-Break">the links:</span></p>
<ul>
<li><em class="italic">Python distribution </em><span class="No-Break"><em class="italic">debugger</em></span><span class="No-Break">: </span><a href="https://docs.python.org/3/library/pdb.xhtml"><span class="No-Break">https://docs.python.org/3/library/pdb.xhtml</span></a></li>
<li><span class="No-Break"><em class="italic">Breakpoints</em></span><span class="No-Break">: </span><a href="https://docs.python.org/3/library/functions.xhtml#breakpoint"><span class="No-Break">https://docs.python.org/3/library/functions.xhtml#breakpoint</span></a></li>
<li><em class="italic">Uvicorn </em><span class="No-Break"><em class="italic">Settings</em></span><span class="No-Break">: </span><a href="https://www.uvicorn.org/settings/"><span class="No-Break">https://www.uvicorn.org/settings/</span></a></li>
<li><em class="italic">Debugging with VS </em><span class="No-Break"><em class="italic">Code</em></span><span class="No-Break">: </span><a href="https://code.visualstudio.com/docs/python/debugging"><span class="No-Break">https://code.visualstudio.com/docs/python/debugging</span></a></li>
<li><em class="italic">Debugy </em><span class="No-Break"><em class="italic">Debugger</em></span><span class="No-Break">: </span><a href="https://github.com/microsoft/debugpy/"><span class="No-Break">https://github.com/microsoft/debugpy/</span></a></li>
<li><em class="italic">Debugging with </em><span class="No-Break"><em class="italic">PyCharm</em></span><span class="No-Break">: </span><a href="https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.xhtml"><span class="No-Break">https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.xhtml</span></a></li>
</ul>
<h1 id="_idParaDest-186"><a id="_idTextAnchor189"/>Performance testing for high traffic applications</h1>
<p>Performance testing<a id="_idIndexMarker341"/> is crucial for ensuring your application can handle real-world usage scenarios, especially under high load. By systematically implementing and running performance tests, analyzing results, and optimizing based on findings, you can significantly improve your application’s responsiveness, stability, <span class="No-Break">and scalability.</span></p>
<p>The recipe will show the basics of how to benchmark your application with <span class="No-Break"><strong class="bold">Locust</strong></span><span class="No-Break"> framework.</span></p>
<h2 id="_idParaDest-187"><a id="_idTextAnchor190"/>Getting ready</h2>
<p>To run performance testing you need a working application, we will use our <strong class="source-inline">protoapp</strong>, and a testing framework. We will use <strong class="bold">Locust</strong> framework for the purpose, which a testing framework based on <span class="No-Break">Python syntax.</span></p>
<p>You can find a detailed explication on the official documentation <span class="No-Break">at: </span><a href="https://docs.locust.io/en/stable/"><span class="No-Break">https://docs.locust.io/en/stable/</span></a><span class="No-Break">.</span></p>
<p>Before starting, make sure you installed it in your virtual environment <span class="No-Break">by running:</span></p>
<pre class="console">
$ pip install locust</pre> <p>Now we are ready to setup our configuration file and run the <span class="No-Break">locust instance.</span></p>
<h2 id="_idParaDest-188"><a id="_idTextAnchor191"/>How to do it...</h2>
<p>With the application running and the <strong class="source-inline">locust</strong> package installed, we will proceed by specifying our configuration to run the <span class="No-Break">performance test.</span></p>
<p>Create a <strong class="source-inline">locustfile.py</strong> in your project root. This file will define the behavior of users interacting with your application <span class="No-Break">under test.</span></p>
<p>A minimal<a id="_idIndexMarker342"/> example of <strong class="source-inline">locustfile.py</strong> <span class="No-Break">can be:</span></p>
<pre class="source-code">
from locust import HttpUser, task
class ProtoappUser(HttpUser):
    host = "http://localhost:8000"
    @task
    def hello_world(self):
        self.client.get("/home")</pre> <p>The configuration defines a client class with the service address and the endpoint we want <span class="No-Break">to test.</span></p>
<p>Start your FastAPI <span class="No-Break">server with:</span></p>
<pre class="console">
$ uvicorn protoapp.main:app</pre> <p>Then in another terminal window <span class="No-Break">run locust:</span></p>
<pre class="console">
$ locust</pre> <p>Open your browser and navigate to <strong class="source-inline">http://localhost:8089</strong> to access the web interface of <span class="No-Break">the application.</span></p>
<p>The web interface is intuitively designed, making it <span class="No-Break">straightforward to:</span></p>
<ul>
<li><strong class="bold">Set Concurrent Users</strong>: Specify the maximum number of users accessing the service simultaneously during <span class="No-Break">peak usage.</span></li>
<li><strong class="bold">Configure Ramp-Up Rate</strong>: Determine the rate of new users added per second to simulate <span class="No-Break">increasing traffic.</span></li>
</ul>
<p>After configuring these parameters, click the <strong class="bold">Start</strong> button to initiate a simulation that generates traffic to the protoapp via the <strong class="source-inline">/home</strong> endpoint defined in <span class="No-Break">the </span><span class="No-Break"><strong class="source-inline">locustfile.py</strong></span><span class="No-Break">.</span></p>
<p>Alternatively, you can simulate traffic using the command line. <span class="No-Break">Here’s how:</span></p>
<pre class="console">
$ locust --headless --users 10 --spawn-rate 1</pre> <p>This command runs Locust in a headless mode <span class="No-Break">to simulate:</span></p>
<ul>
<li>10 users accessing your <span class="No-Break">application concurrently.</span></li>
<li>A spawn rate of 1 user <span class="No-Break">per second.</span></li>
</ul>
<p>You push your test <a id="_idIndexMarker343"/>experience further by including it in a <strong class="bold">Continuous Integration /Continuous Delivery</strong> (<strong class="bold">CI/CD</strong>) pipeline before deploying, or even into a larger <span class="No-Break">testing routine.</span></p>
<p>Dig into the documentation to test every aspect of the traffic for <span class="No-Break">your application.</span></p>
<p>You have all the tools to debug and fully test <span class="No-Break">your application.</span></p>
<p>In the next <a id="_idIndexMarker344"/>chapter, we are going to build a comprehensive RESTful application interacting with an <span class="No-Break">SQL database.</span></p>
<h2 id="_idParaDest-189"><a id="_idTextAnchor192"/>See also</h2>
<p>You can find more<a id="_idIndexMarker345"/> on Locust on the official <span class="No-Break">documentation pages:</span></p>
<ul>
<li><em class="italic">Locust </em><span class="No-Break"><em class="italic">QuickStart</em></span><span class="No-Break">: </span><a href="https://docs.locust.io/en/stable/quickstart.xhtml"><span class="No-Break">https://docs.locust.io/en/stable/quickstart.xhtml</span></a></li>
<li><em class="italic">Writing a Locust </em><span class="No-Break"><em class="italic">file</em></span><span class="No-Break">: </span><a href="https://docs.locust.io/en/stable/writing-a-locustfile.xhtml"><span class="No-Break">https://docs.locust.io/en/stable/writing-a-locustfile.xhtml</span></a></li>
<li><em class="italic">Running Locust from the Command </em><span class="No-Break"><em class="italic">Line</em></span><span class="No-Break">: </span><a href="https://docs.locust.io/en/stable/running-without-web-ui.xhtml"><span class="No-Break">https://docs.locust.io/en/stable/running-without-web-ui.xhtml</span></a></li>
</ul>
</div>
</div></body></html>