<html><head></head><body>
        

            
                <h1 class="header-title">Home Automation Using the Raspberry Pi Zero</h1>
            

            
                
<p>As the title of the chapter suggests, we will discuss home improvement projects involving the Raspberry Pi Zero in this chapter. We selected our projects such that each example could be executed as a weekend project.</p>
<p>The projects include the following topics:</p>
<ul>
<li>Voice-activated personal assistant</li>
<li>Web framework-based appliance control</li>
<li>Physical activity motivation tool</li>
<li>Smart lawn sprinkler</li>
</ul>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Voice activated personal assistant</h1>
            

            
                
<p>In our first project, we are going to emulate personal assistants such as Google Home (<a href="https://madeby.google.com/home/" target="_blank">https://madeby.google.com/home/</a>) and Amazon Echo (<a href="http://a.co/cQ6zJk6" target="_blank">http://a.co/cQ6zJk6</a>) using a Raspberry Pi Zero. We will build an application where we can add reminders and events to a calendar and controlling appliances.</p>
<p>We will be making use of <strong>houndify</strong> (<a href="http://houndify.com">houndify.com</a>)—a tool that is designed to provide interactions with smart devices. We will install the requisite software tools on the Raspberry Pi Zero. We will interface a button to the Raspberry Pi Zero's GPIO. We will write some code to create reminders and turn on/off appliances using <em>Houndify</em>.</p>
<p>The following accessories (apart from your Raspberry Pi Zero) are recommended for this project:</p>
<table class="MsoTableGrid">
<tbody>
<tr>
<td><strong>Item</strong></td>
<td><strong>Source</strong></td>
<td><strong>Price (in USD)</strong></td>
</tr>
<tr>
<td>USB sound card</td>
<td><a href="http://a.co/824dfM8" target="_blank">http://a.co/824dfM8</a></td>
<td>8.79</td>
</tr>
<tr>
<td>Microphone amplifier board with adjustable gain</td>
<td><a href="https://www.adafruit.com/products/1713" target="_blank">https://www.adafruit.com/products/1713</a></td>
<td>7.95</td>
</tr>
<tr>
<td>3.5 mm auxiliary cable</td>
<td><a href="https://www.adafruit.com/products/2698" target="_blank">https://www.adafruit.com/products/2698</a></td>
<td>2.50</td>
</tr>
<tr>
<td>Momentary push button set</td>
<td><a href="https://www.adafruit.com/products/1009" target="_blank">https://www.adafruit.com/products/1009</a></td>
<td>5.95</td>
</tr>
<tr>
<td>Breadboard, resistors, jumper wires, and capacitors</td>
<td>N. A.</td>
<td>N. A.</td>
</tr>
<tr>
<td>Speaker (suggestion)</td>
<td><a href="http://a.co/3h9uaTI" target="_blank">http://a.co/3h9uaTI</a></td>
<td>14.99</td>
</tr>
</tbody>
</table>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Installing requisite packages</h1>
            

            
                
<p>The first step is installing the requisite packages for the project. This includes the following packages: <kbd>python3-pyaudio python3-numpy</kbd>. They may be installed as follows:</p>
<pre>
<strong>sudo apt-get update<br/></strong><strong>sudo apt-get install alsa-utils mplayer python3-numpy</strong>
</pre>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">How does it work?</h1>
            

            
                
<p>The following are the steps to be performed:</p>
<ol>
<li>A push button is interfaced to the Raspberry Pi Zero's GPIO. When the GPIO button is pressed, the recorder is turned on (at the start of a beep sound from the speaker).</li>
<li>The recorder accepts the user request and processes it using the <kbd>Houndify</kbd> library.</li>
<li>The assistant processes the audio file using <kbd>Houndify</kbd> and responds to the user request.</li>
</ol>
<p>In this project, we are using a push button to start listening to user requests, whereas commercially available products, such as Amazon's Echo or the Google Home, have special hardware (along with software) to enable this capability. We are using a push button to simplify the problem.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Setting up the audio tools</h1>
            

            
                
<p>In this section, we will connect the USB sound card, speaker, and the microphone for the project.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Connecting the speaker</h1>
            

            
                
<p>Perform the following steps to connect to speakers:</p>
<ol>
<li>Connect the USB sound card to your Raspberry Pi Zero and find out if the USB sound card enumerates using the <kbd>lsusb</kbd> command (on your Raspberry Pi Zero's command-line terminal):</li>
</ol>
<div><img class=" image-border" height="78" src="img/image_10_001.png" width="488"/></div>
<p>USB sound card enumeration</p>
<ol start="2">
<li>Cheap USB sound cards typically have an input terminal (to connect a microphone) and an output terminal (to connect a speaker). Both the terminals are standard 3.5 mm jacks. The input terminal is pink and typically marked with a microphone symbol. The output terminal is green and marked with a speaker symbol.</li>
<li>Connect a speaker to the output terminal (green) of the USB sound card.</li>
<li>On your Raspberry Pi Zero's command-line terminal, list all the audio sources connected to your Raspberry Pi Zero using the following command:</li>
</ol>
<pre>
<strong>       aplay -l<br/></strong><strong>       **** List of PLAYBACK Hardware Devices ****<br/></strong><strong>       card 0: ALSA [bcm2835 ALSA], device 0: bcm2835 <br/>         ALSA [bcm2835 ALSA]<br/></strong><strong>       Subdevices: 8/8<br/></strong><strong>       Subdevice #0: subdevice #0<br/></strong><strong>       Subdevice #1: subdevice #1<br/></strong><strong>       Subdevice #2: subdevice #2<br/></strong><strong>       Subdevice #3: subdevice #3<br/></strong><strong>       Subdevice #4: subdevice #4<br/></strong><strong>       Subdevice #5: subdevice #5<br/></strong><strong>       Subdevice #6: subdevice #6<br/></strong><strong>       Subdevice #7: subdevice #7<br/></strong><strong>       card 0: ALSA [bcm2835 ALSA], device 1: bcm2835 <br/>         ALSA [bcm2835 IEC958/HDMI]<br/></strong><strong>       Subdevices: 1/1<br/></strong><strong>       Subdevice #0: subdevice #0<br/></strong><strong>       card 1: Set [C-Media USB Headphone Set], <br/>         device 0: USB Audio [USB Audio]<br/></strong><strong>       Subdevices: 1/1<br/></strong><strong>       Subdevice #0: subdevice #0</strong>
</pre>
<ol start="5">
<li>As shown in the <kbd>aplay</kbd> command's output, the sound card is listed as <kbd>card 1</kbd>. We need this information to set the USB sound card as the default audio source</li>
<li>Open your sound configuration file from the command line as follows:</li>
</ol>
<pre>
<strong>       nano ~/.asoundrc</strong>
</pre>
<ol start="7">
<li>Make sure that the configuration file's source is set to <kbd>card 1</kbd> (the soundcard):</li>
</ol>
<pre>
       pcm.!default {<br/>               type hw<br/>               card 1<br/>       }<br/><br/>       ctl.!default {<br/>               type hw<br/>               card 1<br/>       }
</pre>
<p style="padding-left: 60px">Save the configuration file (by pressing <em>Ctrl </em>+ <em>X</em> and press <em>Y</em> to confirm the name of the file. Press <em>Enter</em> to save the file. Refer to <a href="83036e86-f65c-46ed-996d-4f1aeeab5022.xhtml" target="_blank">Chapter 11</a>, <em>Tips and Tricks</em> chapter for a detailed tutorial) and reboot your Raspberry Pi Zero.</p>
<ol start="8">
<li>On reboot, test if the speaker works by downloading a wave file (<a href="http://Freesound.org" target="_blank">Freesound.org</a> has plenty of wave files). From the command-line terminal, play your file as follows:</li>
</ol>
<pre>
<strong>       aplay test.wav</strong>
</pre>
<p>If everything is configured properly, you should be able to play audio using your USB sound card and speaker. If you are not able to play the audio, check the connections and make sure that your USB sound card is enumerated correctly and you have chosen the right audio source in the configuration file. In the next section, we will set up the microphone.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Connecting the microphone</h1>
            

            
                
<p>In this section, we will be setting up an omnidirectional microphone to listen for commands/inputs.</p>
<p>We tested off-the-shelf electret microphones, and the audio quality was not sufficient to perform speech recognition on the recorded audio samples. As an alternative, we recommend boundary microphones for a wide pickup, for example, <a href="http://a.co/8YKSy4c" target="_blank">http://a.co/8YKSy4c</a>.</p>
<div><img class=" image-border" height="295" src="img/image_10_002.png" width="377"/></div>
<p>MAX9814 with omnidirectional microphone Source: Adafruit.com</p>
<ol>
<li>The gain of the amplifier can be set to three levels: <strong>60 dB</strong> when the gain pin is unconnected, <strong>50 dB</strong> when the gain pin is connected to ground, and <strong>40 dB</strong> when the gain pin is connected to <strong>V<sub>dd</sub></strong>.</li>
<li>Connect <strong>Vdd</strong> and the <strong>GND</strong> pins to the <strong>5V</strong> and <strong>GND</strong> pins of the Raspberry Pi's GPIO pins (,pins 4 and 6 of the Raspberry Pi's GPIO).</li>
</ol>
<ol start="3">
<li>Cut the 3.5 mm cable into two halves. It consists of three wires connected to the <strong>Tip</strong>, <strong>Ring</strong> and <strong>Sleeve</strong> of the 3.5 mm connector (as shown in the picture here). Use a multimeter to identify the <strong>Sleeve</strong>, <strong>Tip</strong>, and <strong>Ring</strong> wires of the 3.5 mm connector.</li>
</ol>
<div><img class=" image-border" height="148" src="img/image_10_003.png" width="389"/></div>
<p>Cut the auxiliary cable and identify the three wires of the cable</p>
<ol start="4">
<li>Connect a 100 mF electrolytic capacitor to the output of the amplifier where the positive lead is connected to the output and the other end is connected to the tip of the 3.5 mm connector. The ground pin of the amplifier is connected to the sleeve of the 3.5 mm connector.</li>
</ol>
<div><img class=" image-border" height="254" src="img/image_10_004.png" width="284"/></div>
<p>Microphone connections to the 3.5 mm connector</p>
<p>The microphone is ready to use. Power the microphone using the GPIO pins of the Raspberry Pi Zero and plug the 3.5 mm connector into the input terminals of the USB sound card (marked with the microphone symbol).</p>
<div><img class=" image-border" height="319" src="img/image_10_005.jpg" width="436"/></div>
<p>Microphone connected to 3.5 mm connector</p>
<p>We are ready to test the microphone and set an optimal capture volume. From the Raspberry Pi Zero's command-line terminal, run the following command:</p>
<pre>
<strong>       arecord -f dat -D plughw:2 <br/>         --duration=10~/home/pi/rectest.wav</strong>
</pre>
<p>This will record the file for 10 seconds. Play it back using the <kbd>aplay</kbd> command:</p>
<pre>
<strong>       aplay rectest.wav</strong>
</pre>
<p>You should be able to hear the recorded conversation. Check your connections whether you don't hear anything (<strong>GND</strong>, <strong>5V</strong>, amplifier output pins, and so on. We have also included additional resources for the microphone troubleshooting at the end of this chapter).<br/>
If the recorded content is too loud or too feeble, adjust the capture volume using <kbd>alsamixer</kbd>. Launch <kbd>alsamixer</kbd> from the command-line terminal:</p>
<div><img class=" image-border" height="351" src="img/image_10_006.png" width="610"/></div>
<p>alsamixer control panel</p>
<p>Press <em>F5</em> to view all options. Use the arrow keys to adjust the value and M to disable autogain control. Let's move on to the next section where we build our application.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Houndify</h1>
            

            
                
<p><strong>Houndify</strong> (<a href="http://www.houndify.com" target="_blank">www.houndify.com</a>) is a tool that enables adding voice interaction to devices. Their free account enables performing 44 different types of actions. Sign up for an account on their website and activate it (via your e-mail).</p>
<ol>
<li>Once your account is activated, go to your account dashboard to create a new client:</li>
</ol>
<p>On creating a new account, a new client is automatically created. This client may not work properly. Delete it and create a new client from the dashboard.</p>
<div><img class=" image-border" height="489" src="img/image_10_007.png" width="788"/><br/>
<br/>
Create new client</div>
<ol start="2">
<li>Give a name to your application and select the platform to be Home Automation.</li>
</ol>
<div><img class=" image-border" height="335" src="img/image_10_008.png" width="432"/></div>
<p>Name the application and select the platform</p>
<ol start="3">
<li>The next step is selecting domains, that is, the nature of applications the assistant must support. Select Weather, Stock Market, Dictionary, and so on.</li>
</ol>
<div><img class=" image-border" height="357" src="img/image_10_009.png" width="544"/></div>
<p>Enable domains</p>
<ol start="4">
<li>Click on Save &amp; Continue. Once you have created your new client, click on it (from the dashboard) to retrieve the following credentials: Client ID and Client Key.</li>
</ol>
<div><img class=" image-border" height="232" src="img/image_10_010.png" width="674"/></div>
<p>Copy the Client id and the Client Key from the dashboard</p>
<ol start="5">
<li>We also need to download the SDK for Python 3.x (latest version available at <a href="https://docs.houndify.com/sdks#python" target="_blank">https://docs.houndify.com/sdks#python</a>):</li>
</ol>
<pre>
<strong>       wget <br/>       https://static.houndify.com/sdks/python<br/>       /0.5.0/houndify_python3_sdk_0.5.0.tar.gz</strong>
</pre>
<ol start="6">
<li>Extract the package as follows:</li>
</ol>
<pre>
<strong>       tar -xvzf houndify_python3_sdk_0.5.0.tar.gz</strong><strong>rm <br/>       houndify_python3_sdk_0.5.0.tar.gz</strong>
</pre>
<ol start="7">
<li>The SDK comes with plenty of examples to get started. Let's consider a scenario where you would like to find out the weather at your current location by interacting with the voice assistant:</li>
</ol>
<div><ol>
<li>Get your current GPS coordinates from a tool such as Google Maps. For example, the GPS coordinates for a specific intersection in San Francisco, California is 37.778724, -122.414778. Let's try to find the weather at this specific location.</li>
</ol>
</div>
<div><ol start="2">
<li>Open the <kbd>sample_wave.py</kbd> file and modify <kbd>line 39</kbd> of the file:</li>
</ol>
</div>
<pre>
              client.setLocation(37.778724, -37.778724)
</pre>
<div><ol start="3">
<li>Save the file and from the command-line terminal, change directories to the <kbd>Houndify SDK folder</kbd>:</li>
</ol>
</div>
<pre>
              cd houndify_python3_sdk_0.5.0/ <br/>              ./sample_wave.py &lt;client_id&gt; &lt;client_key&gt; <br/>              test_audio/whatistheweatherthere_nb.wav
</pre>
<div><ol start="4">
<li>After processing the request, it should print a detailed response:</li>
</ol>
</div>
<pre>
              src="img/>              templates.min.js"&gt;&lt;/script&gt;'}}, 'TemplateName': <br/>              'VerticalTemplateList', 'AutoListen': False, <br/>              'WeatherCommandKind': 'ShowWeatherCurrentConditions', <br/>              'SpokenResponseLong': 'The weather is 45 degrees and<br/>              mostly clear in San Francisco.',
</pre>
<p>We verified the function and setup of the Houndify SDK by testing the example. We uploaded an audio file to the Houndify server requesting the current weather information (play the audio file and find out). The <kbd>sample_wave.py</kbd> script takes the <kbd>client_id</kbd>, <kbd>client_key</kbd>, and the audio file as inputs. It prints out the output from the Houndify server.</p>
<p>You need to enable specific domains to retrieve specific information. For example, we enabled the weather domain to retrieve the weather information. It is also possible to add custom commands to the program.</p>
<p>In the next section, we will modify <kbd>sample_wave.py</kbd> to build our application.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Building voice commands</h1>
            

            
                
<p>Let's get started with building our voice assistant that we can use to find the weather and turn on/off lights. Because we enabled the weather domain while setting up our Houndify account, we need to add custom commands to turn on/off lights:</p>
<ol>
<li>On your Houndify dashboard, go to your client's home page. Dashboard | Click on your client.</li>
<li>Locate Custom Commands on the navigation bar to the left. Let's add a custom command each to turn on and turn off the light.</li>
</ol>
<ol start="3">
<li>Delete <kbd>ClientMatch #1</kbd> that comes as a template with the custom commands.</li>
</ol>
<div><img class=" image-border" src="img/image_10_011.png"/></div>
<p>Locate Custom commands and Delete Client Match #1</p>
<ol start="4">
<li>Select Add ClientMatch to add a custom command to turn on lights. Populate the fields with the following information:</li>
</ol>
<div><ul>
<li>Expression: <kbd>["Turn"].("Lights"). ["ON"]</kbd></li>
<li>Result: <kbd>{"action": "turn_light_on"}</kbd></li>
<li>SpokenResponse: <kbd>Turning Lights On</kbd></li>
<li>SpokenResponseLong: <kbd>Turning your Lights On</kbd></li>
<li>WrittenResponse: <kbd>Turning Lights On</kbd></li>
<li>WrittenResponseLong: <kbd>Turning your Lights On</kbd></li>
</ul>
</div>
<ol start="5">
<li>Repeat the preceding steps to add a command to turn lights off</li>
</ol>
<p>Test and verify that these commands work using <kbd>sample_wave.py</kbd>. Make your own recording for the test. We have also provided audio files along with this chapter's download (available in the folder <kbd>audio_files</kbd>).</p>
<p>Let's make a copy of <kbd>sample_wave.py</kbd> to build our assistant. We recommend reading through the file and familiarizing yourself with its function. The detailed documentation for the Houndify SDK is available at <a href="https://docs.houndify.com/sdks/docs/python" target="_blank">https://docs.houndify.com/sdks/docs/python</a>:</p>
<ol>
<li>In the file <kbd>stream_wav.py</kbd>, the <kbd>StreamingHoundClient</kbd> class is used to send audio queries, such as request for weather information and commands to turn on/off lights.</li>
<li>The <kbd>MyListener</kbd> class inherits the <kbd>HoundListener</kbd> class (from the <kbd>houndify</kbd> SDK).</li>
<li>The <kbd>MyListener</kbd> class implements callback functions for three scenarios:</li>
</ol>
<div><ul>
<li>Partial Transcription (the <kbd>onPartialTranscript</kbd> method)</li>
<li>Complete Transcription (the <kbd>onFinalResponse</kbd> method)</li>
<li>Error State (the <kbd>onError</kbd> method)</li>
</ul>
</div>
<ol start="4">
<li>We need to make use of action intents to turning on/off lights using voice command.</li>
<li>When we implemented the custom commands on the Houndify website, we added an action intent for each command. For example, the action intent for turning on the lights was:</li>
</ol>
<pre>
       { <br/>           "action": "turn_light_on"<br/>       }
</pre>
<ol start="6">
<li>In order to turn on/off the lights based on the received action intent, we need to import the <kbd>OutputDevice</kbd> class from <kbd>gpiozero</kbd>:</li>
</ol>
<pre>
       from gpiozero import OutputDevice
</pre>
<ol start="7">
<li>The GPIO pin that controls the light is initialized in the <kbd>__init__</kbd> method of the <kbd>MyListener</kbd> class:</li>
</ol>
<pre>
       class MyListener(houndify.HoundListener): <br/>         def __init__(self): <br/>           self.light = OutputDevice(3)
</pre>
<ol start="8">
<li>On completing transcription, if an action intent is received, the lights are either turned on or turned off. It is implemented as follows:</li>
</ol>
<pre>
       def onFinalResponse(self, response): <br/>         if "AllResults" in response: <br/>           result = response["AllResults"][0] <br/>           if result['CommandKind'] == "ClientMatchCommand": <br/>             if result["Result"]["action"] == "turn_light_on": <br/>               self.light.on() <br/>             elif result["Result"]["action"] == "turn_light_off": <br/>               self.light.off()
</pre>
<div><kbd>response</kbd> is a dictionary that consists of the parsed <kbd>json</kbd> response. Refer to the SDK documentation and try printing the response yourself to understand its structure.</div>
<ol start="9">
<li>We also need to announce the voice assistant's action while turning on/off lights. We explored different text-to-speech tools, and they sounded robotic when compared with off-the-shelf products such as the Google Home or Amazon Echo. We came across this script that makes use of the <em>Google Speech-to-Text engine</em> at <a href="http://elinux.org/RPi_Text_to_Speech_(Speech_Synthesis)" target="_blank">http://elinux.org/RPi_Text_to_Speech_(Speech_Synthesis)</a>.</li>
</ol>
<p>Because the script makes use of Google's text-to-speech engine, it connects to the Internet to fetch the transcribed audio data.</p>
<div><ol>
<li>Open a new shell script from the Raspberry Pi's command-line terminal:</li>
</ol>
</div>
<pre>
<strong>              nano speech.sh</strong>
</pre>
<div><ol start="2">
<li>Paste the following contents:</li>
</ol>
</div>
<pre>
             <strong> #!/bin/bash </strong><br/><strong>              say() { local IFS=+;/usr/bin/mplayer</strong><br/><strong>              -ao alsa -really-quiet -noconsolecontrols </strong><br/><strong>              "http://translate.google.com/translate_tts?</strong><br/><strong>              ie=UTF-8&amp;client=tw-ob&amp;q=$*&amp;tl=En-us"; } </strong><br/><strong>              say $*</strong>
</pre>
<div><ol start="3">
<li>Make the file executable:</li>
</ol>
</div>
<pre>
              <strong>chmod u+x speech.sh</strong>
</pre>
<div><ol start="4">
<li>We are going to make use of this script to announce any actions by the assistant. Test it from the command line using the following code:</li>
</ol>
</div>
<pre>
              <strong>~/speech.sh "Hello, World!"</strong>
</pre>
<div><ol start="5">
<li>The system calls to announce the voice assistant actions are implemented as follows:</li>
</ol>
</div>
<pre>
              if result["Result"]["action"] == "turn_light_on": <br/>                self.light.on() <br/>                os.system("~/speech.sh Turning Lights On") <br/>              elif result["Result"]["action"] == "turn_light_off": <br/>                self.light.off() <br/>                os.system("~/speech.sh Turning Lights Off")
</pre>
<p>Let's test what we have built so far in this section. The preceding code snippets are available for download along with this chapter as <kbd>voice_assistant_inital.py</kbd>. Make it executable as follows:</p>
<pre>
<strong>chmod +x voice_assistant_initial.py</strong>
</pre>
<p>Test the program as follows (audio files are also available for download with this chapter):</p>
<pre>
<strong>./voice_assistant.py turn_lights_on.wav</strong>
</pre>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Adding a button</h1>
            

            
                
<p>Let's add a button to our voice assistant. This momentary push button is connected to pin 2 (BCM numbering) and the LED is connected to pin 3.</p>
<div><img class=" image-border" src="img/image_10_012.png"/></div>
<p>Voice Assistant interface setup</p>
<ol>
<li>In order to read the button presses, we need to import the <kbd>Button</kbd> class from <kbd>gpiozero</kbd>:</li>
</ol>
<pre>
       from gpiozero import Button, OutputDevice
</pre>
<ol start="2">
<li>When a button is pressed, the voice assistant needs to play a beep sound indicating that it is awaiting the user's command. Beep sounds of your choice can be downloaded from <a href="http://www.freesound.org" target="_blank">www.freesound.org</a>.</li>
</ol>
<ol start="3">
<li>Following the beep sound, the user command is recorded for a duration of 5 seconds. The recorded file is then processed using the <em>Houndify</em> SDK. The following code snippet shows the trigger function that is called when the button is pressed:</li>
</ol>
<pre>
       def trigger_function(): <br/>         os.system("aplay -D plughw:1,0 /home/pi/beep.wav") <br/>         os.system("arecord -D plughw:2,0 -f S16_LE -d 5 <br/>         /home/pi/query.wav") <br/>         os.system("aplay -D plughw:1,0 /home/pi/beep.wav") <br/>         call_houndify()
</pre>
<ol start="4">
<li>The trigger function is registered as follows:</li>
</ol>
<pre>
       button = Button(4) <br/>       button.when_released = trigger_function
</pre>
<p>Connect the button and the LED to the Raspberry Pi's GPIO interface to test the voice assistant.</p>
<div><img class=" image-border" height="329" src="img/image_10_013.jpg" width="373"/></div>
<p>Voice assistant setup</p>
<p>The voice assistant code file is available for download along with this chapter as <kbd>voice_assistant.py</kbd>. Download the code sample and try the following commands:</p>
<pre>
<strong>What is the weather in San Francisco?</strong><strong>What is the weather in Santa Clara, California?</strong><strong>Turn Lights On</strong><strong>Turn Lights Off</strong>
</pre>
<p>We have shared a video (on this book's site) that demonstrates the function of the voice assistant. Now, we have demonstrated the voice assistant using an LED. In order to control a table lamp, simply replace the LED with a power switch tail II (<a href="http://www.powerswitchtail.com/Pages/default.aspx">http://www.powerswitchtail.com/Pages/default.aspx</a>).</p>
<div><img class=" image-border" src="img/image_10_014.png"/></div>
<p><strong><br/>
Things to keep in mind</strong>:</p>
<ol>
<li>Add <kbd>voice_assistant.py</kbd> to <kbd>/etc/rc.local</kbd> so that it starts automatically on boot.</li>
<li>The entire setup can be unwieldy. Assemble the components inside an enclosure to organize the wiring.</li>
<li>Because the project involves electrical appliances, use prescribed cables and terminate them properly. Ensure that the cables are connected properly. We will share examples of the same on our website.</li>
</ol>
<p><strong>Project ideas and enhancements</strong>:</p>
<ul>
<li>Currently, the assistant works only at the press of a button. How will you make it listen for a keyword? For example, "Ok, Google" or "Alexa"?</li>
<li>Is it possible to have a remote trigger? Think something on the lines of <em>Amazon Tap</em>.</li>
<li>If you have lights such as Philips Hue or Internet-connected switches such as WeMo switch smartplug or the TP-Link Smart switch, you can control them using a voice assistant. IFTTT provides applets to control them yourself. Create a maker channel web hook to control them. Refer to Chapter 8 for examples.</li>
</ul>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Web framework based appliance control/dashboard</h1>
            

            
                
<p>In this section, we will review building a dashboard in order to control appliances. This could be a dashboard for the aquarium where you would like to monitor all the requisite parameters for the tank or a dashboard for the garden where you can control the flow control valves for your garden based on information from the sensors. We will demonstrate this with a simple example and show how you can use it to meet your requirements.</p>
<p>We will make use of the <kbd>flask</kbd> framework to build our dashboard. If you haven't installed the <kbd>flask</kbd> framework (from the previous chapters), you can install it as follows:</p>
<pre>
<strong>sudo pip3 install flask</strong>
</pre>
<p>If you are not familiar with the flask framework, we have written up some basics and getting started in <a href="2316ddf6-c2d7-4810-a7ab-3600a3e2549d.xhtml">Chapter 7</a>, <em>Requests and Web Frameworks</em>. We are going to discuss controlling the relay board (shown in the picture here) from a web dashboard (available at <a href="http://a.co/1qE0I3U">http://a.co/1qE0I3U</a>).</p>
<div><img class=" image-border" height="217" src="img/image_10_015.jpg" width="598"/></div>
<p>Relay module</p>
<p>The relay board consists of eight relays that could be used to control eight devices. The relays are rated for 10A, 125V AC and 10A, 28V DC.</p>
<p>It is important to follow safety regulations while trying to control AC appliances using a relay board. If you are a beginner in electronics, we recommend using the unit, <a href="http://a.co/9WJtANZ">http://a.co/9WJtANZ</a>. It comes with the requisite circuitry and protections (shown in the following figure). <strong>Safety first!</strong></p>
<div><img class=" image-border" height="293" src="img/image_10_016.jpg" width="476"/></div>
<p>Enclosed high power relay for Raspberry Pi</p>
<p>Each relay on the 8-relay board consists of the following components: an optocoupler, transistor, relay, and a freewheeling diode (shown in the schematic here):</p>
<div><img class=" image-border" height="300" src="img/image_10_017.png" width="507"/></div>
<p>Schematic of one relay on 8-relay board (generated using fritzing)</p>
<p>The schematic is used to explain the function of the relay board; hence, it is not accurate. It is missing some discrete components.</p>
<ol>
<li>The relay board requires a 5V power supply (through the Vcc pin):</li>
</ol>
<div><p><img class=" image-border" src="img/image_10_018.jpg"/></p>
</div>
<p>Vcc, GND and GPIO pins<br/></p>
<ol start="2">
<li>Each relay on the relay board is controlled by pins IN1 through IN8. Each pin is connected to an optocoupler (optoisolator-U1 in the schematic). The function of the isolator is to separate the Raspberry Pi from high voltages connected to the relay. It protects from any transient voltages while switching the relays (we have provided additional resources at the end of this chapter to better understand optocouplers).</li>
<li>The phototransistor of the optocoupler is connected to the base of an NPN transistor. The NPN transistor's collector pin is connected to a relay, whereas the emitter is connected to the ground.</li>
<li>The relay is driven by an active-low signal that is when a 0V signal is given to one of the pins, IN1 through IN8. The phototransistor (of the optocoupler) sends a <em>high</em> signal to the base of the transistor. Here, the transistor acts as a switch. It closes the circuit and thus energizes the relay. This is basically the transistor switching circuit that we discussed in an earlier chapter except for an additional component, the optocoupler. An LED lights up indicating that the relay is energized.</li>
</ol>
<div><img class=" image-border" height="274" src="img/image_10_019.png" width="120"/></div>
<p>The components of each relay circuit (labeled)</p>
<p>We strongly recommend reading about optocouplers to understand their need and how an active-low signal to this relay board drives the relays.</p>
<ol start="5">
<li>Across each relay, there is a flywheel diode. A flywheel diode protects the circuit from any inductive kickback voltages of the relay when the relay is de-energized/turned off. (We have included a reading resource on relays and inductive kickbacks at the end of this chapter.)</li>
<li>Each relay has three terminals, namely the common terminal, normally open terminal, and the normally closed terminal. When an active-low signal is used to drive one of the relays, the common terminal comes into contact with the normally open terminal. When the relay is de-energized, the common terminal comes into contact with the normally closed terminal. Hence, the terminals have the name, normally open and normally closed (The terminals are highlighted with the labels N.O., C, and N.C. in the picture here).</li>
</ol>
<div><img class=" image-border" height="223" src="img/image_10_020.png" width="423"/></div>
<p>The terminals of a relay</p>
<ol start="7">
<li>The device that needs to be controlled using the web dashboard needs to be connected to the relay terminals, as shown in the schematic given later. For example, let's consider a device that is powered using a 12V adapter. The device's needs to be rigged such that the positive terminal of the power jack is connected to the common terminal of the relay. The normally open terminal is connected to the device's positive line. The device's ground is left untouched. Keep the power adapter plugged in, and the device shouldn't turn on as long as the relay is not energized. Let's review controlling this device using a web dashboard.</li>
</ol>
<div><img class=" image-border" src="img/image_10_021.png"/></div>
<p>Schematic to rig a 12V DC appliance with a relay</p>
<p>For an AC power appliance, we recommend using the power switch tail II or the AC relay unit discussed earlier in this section. They are safe for hobby grade applications.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Building the web dashboard</h1>
            

            
                
<p>The first step is creating the html template for the dashboard. Our dashboard is going to enable controlling four appliances, that is, turn them on or off:</p>
<ol>
<li>In our dashboard, we need an <kbd>html</kbd><kbd>table</kbd> where each row on the table represents a device, as follows:</li>
</ol>
<pre>
       &lt;table&gt; <br/>           &lt;tr&gt; <br/>               &lt;td&gt; <br/>                   &lt;input type="checkbox" name="relay" <br/>                    value="relay_0"&gt;Motor&lt;/input&gt; &lt;/br&gt; <br/>               &lt;/td&gt; <br/>           &lt;td&gt; <br/>               &lt;input type="radio" name="state_0" value="On"&gt;On<br/>               &lt;/input&gt; <br/>                   &lt;input type="radio" name="state_0" value="Off" <br/>                   checked="checked"&gt;Off&lt;/input&gt;<br/>           &lt;/td&gt; <br/>       &lt;/table&gt;
</pre>
<ol start="2">
<li>In the preceding code snippet, each device state is encapsulated in a data cell <kbd>&lt;td&gt;</kbd>, each device is represented by a <kbd>checkbox</kbd>, and the device state is represented by an on/off <kbd>radio</kbd> button. For example, a motor is represented as follows:</li>
</ol>
<pre>
       &lt;td&gt; <br/>          &lt;input type="checkbox" name="relay" <br/>          value="relay_0"&gt;Motor&lt;/input&gt; &lt;/br&gt; <br/>       &lt;/td&gt; <br/>       &lt;td&gt; <br/>          &lt;input type="radio" name="state_0" value="On"&gt;On<br/>          &lt;/input&gt; <br/>           &lt;input type="radio" name="state_0" value="Off" <br/>           checked="checked"&gt;Off&lt;/input&gt;   <br/>       &lt;/td&gt;
</pre>
<p style="padding-left: 60px">On the dashboard, this would be represented as follows:</p>
<div><img class=" image-border" height="102" src="img/image_10_022.png" width="292"/></div>
<p>Device represented by a checkbox and radio button</p>
<ol start="3">
<li>The table is encapsulated in an <kbd>html form</kbd>:</li>
</ol>
<pre>
       &lt;form action="/energize" method="POST"&gt; <br/>          &lt;table&gt; <br/>          . <br/>          . <br/>          . <br/>          &lt;/table&gt; <br/>       &lt;/form&gt;
</pre>
<ol start="4">
<li>The device states are submitted to the <kbd>flask</kbd> server when the user hits the <kbd>energize</kbd> button:</li>
</ol>
<pre>
       &lt;input type="submit" value="Energize" class="button"&gt;
</pre>
<div><img class=" image-border" height="82" src="img/image_10_023.png" width="322"/></div>
<p>Energize button</p>
<ol start="5">
<li>On the server side, we need to set up the GPIO pins used to control the relays:</li>
</ol>
<pre>
       NUM_APPLIANCES = 4 <br/><br/>       relay_index = [2, 3, 4, 14]
</pre>
<ol start="6">
<li>The list <kbd>relay_index</kbd> represents the GPIO pins being used to control the relays.</li>
<li>Before starting the server, we need to create an <kbd>OutputDevice</kbd> object (from the <kbd>gpiozero</kbd> module) for all the devices:</li>
</ol>
<pre>
       for i in range(NUM_APPLIANCES): <br/>               devices.append(OutputDevice(relay_index[i], <br/>                                      active_high=False))
</pre>
<ol start="8">
<li>The <kbd>OutputDevice</kbd> object meant for each device/relay is initialized and added to the <kbd>devices</kbd> list.</li>
<li>When the form is submitted (by hitting the energize button), the <kbd>POST</kbd> request is handled by the <kbd>energize()</kbd> method.</li>
<li>We are controlling four devices that are represented by <kbd>relay_x</kbd>, and their corresponding states are represented by <kbd>state_x</kbd>, that is, On or Off. The default state is Off.</li>
<li>When a form is submitted by the user, we determine if the <kbd>POST</kbd> request contains information related to each device. If a specific device needs to be turned on/off, we call the <kbd>on()</kbd>/<kbd>off()</kbd> method of that device's object:</li>
</ol>
<pre>
       relays = request.form.getlist("relay") <br/>       for idx in range(0, NUM_APPLIANCES): <br/>           device_name = "relay_" + str(idx) <br/>           if device_name in relays: <br/>               device_state = "state_" + str(idx) <br/>               state = request.form.get(device_state) <br/>               print(state) <br/>               if state == "On": <br/>                   print(state) <br/>                   devices[idx].on() <br/>               elif state == "Off": <br/>                   print(state) <br/>                   devices[idx].off()
</pre>
<ol start="12">
<li>In the preceding code snippet, we fetch information related to all relays as a list:</li>
</ol>
<pre>
       relays = request.form.getlist("relay")
</pre>
<ol start="13">
<li>In the form, each device is represented by a value <kbd>relay_x</kbd> (<kbd>relay_0</kbd> through <kbd>relay_3</kbd>). A <kbd>for</kbd> loop is used to determine a specific relay is turned on/off. The state of each device is represented by the value <kbd>state_x</kbd> where <kbd>x</kbd> corresponds to the device (from 0 through 3).</li>
<li>The GPIO pins used in this example are connected to the relay board pins, IN1 through IN4. The relay board is powered by the Raspberry Pi's GPIO power supply. Alternatively, you may power it using an external power supply. (You still need to connect the ground pin of the Raspberry Pi Zero to the relay board.)</li>
<li>The earlier-mentioned dashboard is available along with this chapter under the subfolder <kbd>flask_framework_appliance</kbd> (including the <kbd>flask</kbd> server, html files, and so on.). In the following snapshot, the Motor and Tank Light 2 are checked and set to On. In the picturehere, the first and the third relay are energized.</li>
</ol>
<div><img class=" image-border" height="203" src="img/image_10_024.png" width="384"/></div>
<p>Turning on Motor and Tank Light 2</p>
<div><img class=" image-border" height="221" src="img/image_10_025.jpg" width="577"/></div>
<p>Relays 1 and 3 energized</p>
<p><strong>Exercise for the reader</strong>:</p>
<p>In this section, we made use of a <kbd>POST</kbd> request to control devices. How would you make use of a <kbd>GET</kbd> request to display room temperature from a temperature sensor?</p>
<p><strong>Project ideas/enhancements</strong>:</p>
<ul>
<li>With some basic web design skills, you should be able to build a dashboard with better aesthetic appeal.</li>
<li>Keep in mind that a dashboard should provide as detailed information as possible. Determine how data visualization tools could enhance your dashboard.</li>
<li>Consider replacing the checkbox and radio buttons with a sliding toggle switch (the type used in mobile applications).</li>
<li>You can build a dashboard for switching holiday light sequences from your local browser. Think of ways to compete with your neighbours during the holidays.</li>
<li>You can permanently install the relay board and the Raspberry Pi Zero in a weather proof enclosure as given at <a href="http://www.mcmelectronics.com/product/21-14635">http://www.mcmelectronics.com/product/21-14635</a>. Check out this book's website for some examples.</li>
</ul>
<div><footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Personal Health Improvement—Sitting is the new smoking</h1>
            

            
                
<p>This project makes use of specific accessories. You are welcome to substitute it with alternatives.</p>
<p>So far, we have discussed projects that could be an enhancement around your living environment. In this section, we are going to write some Python code on the Raspberry Pi Zero and build a tool that helps improving your personal help.</p>
<p>According to the World Health Organization, physical activity of 150 minutes in a week can help you stay healthy. Recent studies have found that walking 10,000 steps in a day can help avoid life style diseases. We have been making use of pedometers to keep track of our daily physical activity. It is difficult to maintain consistency in physical activity as we tend to ignore our personal health over daily commitments. For example, in the physical activity timeline shown here, you will note that all the physical activity is concentrated toward the end of the day.</p>
<div><img class=" image-border" height="213" src="img/image_10_026.png" width="534"/></div>
<p>Physical activity in a day (data fetched from a commercially available pedometer)</p>
<p>We are going to build a visual aid that would remind us to stay physically active. We believe that this tool should help put your personal fitness tracker to good use. The following are the recommended accessories for this project:</p>
<ul>
<li><strong>Pedometer</strong>: The cost of pedometers vary anywhere from $20-$100. We recommend getting a tracker from Fitbit since it comes with extensive developer resources. It is not required to have a tracker. We are going to demonstrate this visual aid using a Fitbit One (<a href="http://a.co/8xyNSmg">http://a.co/8xyNSmg</a>) and suggest alternatives at the end.</li>
<li><strong>Pimoroni Blinkt (optional)</strong>: This is an LED strip (<a href="https://www.adafruit.com/product/3195">https://www.adafruit.com/product/3195</a>) that can be stacked on top of your Raspberry Pi Zero's GPIO pins (shown in the picture here).</li>
</ul>
<div><img class=" image-border" height="50" src="img/image_10_027.png" width="425"/></div>
<p>Pimoroni Blinkt</p>
<ul>
<li><strong>Pimoroni Rainbow HAT (optional</strong> <a href="https://www.adafruit.com/products/3354" target="_blank">https://www.adafruit.com/products/3354</a><strong>)</strong>: This is an add-on hardware designed for the Android Things platform on the Raspberry Pi. It comes with LEDs, 14-segment displays, and a buzzer. It can come handy for the project.</li>
</ul>
<div><img class=" image-border" height="318" src="img/image_10_028.jpg" width="464"/></div>
<p>Rainbow HAT for android things</p>
<ul>
<li>Alternatively, you may add LED strips and components to this visual aid using your creativity.</li>
</ul>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Installing requisite software packages</h1>
            

            
                
<p>The first step is installing the requisite packages. Because we are going to make use of the Fitbit tracker, we need to install the <kbd>fitbit python client</kbd>:</p>
<pre>
<strong>sudo pip3 install fitbit cherrypy schedule</strong>
</pre>
<p>If you are going to make use of the Pimoroni Blinkt LED strip, you should install the following package:</p>
<pre>
<strong>sudo apt-get install python3-blinkt</strong>
</pre>
<p>If you are going to be making use of the rainbow HAT, the following package needs to be installed:</p>
<pre>
<strong>curl -sS https://get.pimoroni.com/rainbowhat | bash</strong>
</pre>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Getting access keys for Fitbit client</h1>
            

            
                
<p>We need access keys to make use of the Fitbit API. There is a script available from the fitbit python client repository at <a href="https://github.com/orcasgit/python-fitbit" target="_blank">https://github.com/orcasgit/python-fitbit</a>.</p>
<p>The access keys can also be obtained from the command-line terminal of a Linux or Mac OS laptop.</p>
<ol>
<li>Create a new app at <a href="https://dev.fitbit.com/apps" target="_blank">https://dev.fitbit.com/apps</a>:</li>
</ol>
<div><img class=" image-border" height="77" src="img/image_10_029.png" width="615"/></div>
<p>Register a new app at dev.fitbit.com<br/></p>
<ol start="2">
<li>While registering a new application, fill in the description including the name of your application and give a temporary description, organization, website, and so on, and set the OAuth 2.0 Application Type to Personal and access type to Read-Only. Set the callback URL to <kbd>http://127.0.0.1:8080</kbd>.</li>
</ol>
<div><img class=" image-border" height="325" src="img/image_10_030.png" width="283"/></div>
<p>Set callback URL</p>
<ol start="3">
<li>Once your application is created, copy the Client ID and Client Secret from application's dashboard.</li>
</ol>
<div><img class=" image-border" height="380" src="img/image_10_031.png" width="471"/></div>
<p>Note down the client_id and client secret</p>
<ol start="4">
<li>From the Raspberry Pi's command-line terminal, download the following script:</li>
</ol>
<pre>
<strong>       wget https://raw.githubusercontent.com/orcasgit/<br/>       python-fitbit/master/gather_keys_oauth2.py</strong>
</pre>
<p>The next step needs to be executed by opening the command-line terminal from your Raspberry Pi Zero's desktop (not via remote access).</p>
<ol start="5">
<li>Execute the script by passing the <kbd>client id</kbd> and <kbd>client secret</kbd> as arguments:</li>
</ol>
<pre>
<strong>       python3 gather_keys_oauth2.py &lt;client_id&gt; &lt;client_secret&gt;</strong>
</pre>
<ol start="6">
<li>It should launch a browser on your Raspberry Pi Zero's desktop and direct you to a page on <a href="https://www.fitbit.com/home" target="_blank">https://www.fitbit.com/home</a> requesting your authorization to access your information.</li>
</ol>
<div><img class=" image-border" src="img/image_10_032.png"/></div>
<p>Authorize access to your data</p>
<ol start="7">
<li>If the authorization was successful, it should redirect you to a page where the following information is displayed:</li>
</ol>
<div><img class=" image-border" height="79" src="img/image_10_033.png" width="303"/></div>
<p>Authorization to access the Fitbit API</p>
<ol start="8">
<li>Close the browser and copy the <kbd>refresh_token</kbd> and <kbd>access_token</kbd> information displayed on the command prompt.</li>
</ol>
<div><img class=" image-border" height="112" src="img/image_10_034.png" width="509"/></div>
<p>Copy access_token and refresh_token</p>
<p>We are ready to use the Fitbit API! Let's test it out!</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Fitbit API Test</h1>
            

            
                
<p>The documentation for the Fitbit API is available at <a href="http://python-fitbit.readthedocs.org/">http://python-fitbit.readthedocs.org/</a>.Let's write a simple example to get today's physical activity:</p>
<ol>
<li>The first step is import the <kbd>fitbit</kbd> module:</li>
</ol>
<pre>
       import fitbit
</pre>
<ol start="2">
<li>We have to initialize the <kbd>fitbit</kbd> client using the <kbd>client key</kbd>, <kbd>client secret</kbd>, <kbd>access_token</kbd>, and <kbd>refresh_token</kbd> earlier in this section:</li>
</ol>
<pre>
       fbit_client = fitbit.Fitbit(CONSUMER_KEY, <br/>                                   CONSUMER_SECRET, <br/>                                   access_token=ACCESS_TOKEN, <br/>                                       refresh_token=REFRESH_TOKEN)
</pre>
<ol start="3">
<li>According to the Fitbit API documentation, the current day's physical activity can be retrieved using the <kbd>intraday_time_series()</kbd> method.</li>
<li>The required arguments to retrieve the physical activity include the resource that needs to be retrieved; that is, steps, <kbd>detail_level</kbd>, that is, the smallest time interval for which the given information needs to be retrieved, start times and the end times.</li>
</ol>
<ol start="5">
<li>The start time is 12:00 a.m. of the current day, and the end time is the current time. We will be making use of the <kbd>datetime</kbd> module to get the current time. There is a function named <kbd>strftime</kbd> that gives us the current time in the <em>hour:minute</em> format.</li>
</ol>
<p>Make sure that your Raspberry Pi Zero's OS time is correctly configured with the local time zone settings.</p>
<pre>
       now = datetime.datetime.now() <br/>       end_time = now.strftime("%H:%M") <br/>       response = fbit_client.intraday_time_series('activities/steps', <br/>         detail_level='15min', <br/>         start_time="00:00", <br/>         end_time=end_time)
</pre>
<ol start="6">
<li>The <kbd>fitbit</kbd> client returns a dictionary containing the current day's physical activity and intraday activity in 15-minute intervals:</li>
</ol>
<pre>
       print(response['activities-steps'][0]['value'])
</pre>
<ol start="7">
<li>This example is available for download along with this chapter as <kbd>fitbit_client.py</kbd>. If you have a Fitbit tracker, register an application and test this example for yourself.</li>
</ol>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Building the visual aid</h1>
            

            
                
<p>Let's build a visual aid where we display the number of steps taken in a given day using an LED strip. The LED strip would light up like a progress bar based on the daily physical activity.</p>
<ol>
<li>The first step is importing the requisite libraries while building the visual aid. This includes the <kbd>fitbit</kbd> and <kbd>blinkt</kbd> libraries. We will also import some additional libraries:</li>
</ol>
<pre>
       import blinkt <br/>       import datetime <br/>       import fitbit <br/>       import time <br/>       import schedule
</pre>
<ol start="2">
<li>Make sure that you have the requisite tokens discussed earlier in this section:</li>
</ol>
<pre>
       CONSUMER_KEY = "INSERT_KEY" <br/>       CONSUMER_SECRET = "INSERT_SECRET" <br/>       ACCESS_TOKEN = "INSER_TOKEN" <br/>       REFRESH_TOKEN = "INSERT_TOKEN"
</pre>
<ol start="3">
<li>A new <kbd>refresh token</kbd> is needed every <kbd>8</kbd> hours. This is a feature of the API's authorization mechanism. Hence, we need a function that gets a new token using the existing token:</li>
</ol>
<pre>
       def refresh_token(): <br/>           global REFRESH_TOKEN <br/>           oauth = fitbit.FitbitOauth2Client(client_id=CONSUMER_KEY, <br/>             client_secret=CONSUMER_SECRET, <br/>             refresh_token=REFRESH_TOKEN, <br/>             access_token=ACCESS_TOKEN) <br/>           REFRESH_TOKEN = oauth.refresh_token()
</pre>
<ol start="4">
<li>In the function <kbd>refresh_token()</kbd>, we are making use of the <kbd>FitbitOauth2Client</kbd> class to refresh the token. It is important to note that we have made use of the <kbd>global</kbd> keyword. The <kbd>global</kbd> keyword helps with modifying the <kbd>REFRESH_TOKEN</kbd> and enables the use of the new token in other parts of the program. Without the <kbd>global</kbd> keyword, the changes made to any variable is restricted to the <kbd>refresh_token()</kbd> function.</li>
</ol>
<p>In general, it is a bad practice to make use of the <kbd>global</kbd> keyword. Use it with your best judgement.</p>
<ol start="5">
<li>Next, we need a function to retrieve steps using the <kbd>Fitbit</kbd> class. We are going to use the same procedure as the previous example. Initialize the <kbd>fitbit</kbd> class and retrieve the steps using <kbd>intraday_time_series</kbd>:</li>
</ol>
<pre>
       def get_steps(): <br/>           num_steps = 0 <br/>           client = fitbit.Fitbit(CONSUMER_KEY, <br/>                                  CONSUMER_SECRET, <br/>                                  access_token=ACCESS_TOKEN, <br/>                                  refresh_token=REFRESH_TOKEN) <br/>           try: <br/>               now = datetime.datetime.now() <br/>               end_time = now.strftime("%H:%M") <br/>               response = <br/>                client.intraday_time_series('activities/steps', <br/>                  detail_level='15min', <br/>                  start_time="00:00", <br/>                  end_time=end_time) <br/>           except Exception as error: <br/>               print(error) <br/>           else: <br/>               str_steps = response['activities-steps'][0]['value'] <br/>               print(str_steps) <br/>               try: <br/>                   num_steps = int(str_steps) <br/>               except ValueError: <br/>                   pass <br/>           return num_steps
</pre>
<ol start="6">
<li>In the main function, we schedule a timer that refreshes the token every <kbd>8</kbd> hours using the schedule library (<a href="https://pypi.python.org/pypi/schedule">https://pypi.python.org/pypi/schedule</a>):</li>
</ol>
<pre>
       schedule.every(8).hours.do(refresh_token)
</pre>
<ol start="7">
<li>We check for the steps every <kbd>15</kbd> minutes and light up the LEDs accordingly. Because the <em>Pimoroni Blinkt</em> consists of eight LEDs, we can light up one LED for every <kbd>1250</kbd> steps of physical activity:</li>
</ol>
<pre>
       # update steps every 15 minutes <br/>       if (time.time() - current_time) &gt; 900: <br/>           current_time  = time.time() <br/>           steps = get_steps() <br/><br/>       num_leds = steps // 1250 <br/><br/>       if num_leds &gt; 8: <br/>           num_leds = 8 <br/><br/>       for i in range(num_leds): <br/>           blinkt.set_pixel(i, 0, 255, 0) <br/><br/>       if num_leds &lt;= 7:  <br/>           blinkt.set_pixel(num_leds, 255, 0, 0) <br/>           blinkt.show() <br/>           time.sleep(1) <br/>           blinkt.set_pixel(num_leds, 0, 0, 0) <br/>           blinkt.show() <br/>           time.sleep(1)
</pre>
<ol start="8">
<li>For every multiple of <kbd>1250</kbd> steps, we set an LED's color to green using the <kbd>blinkt.set_pixel()</kbd> method. We set the next LED to a blinking red. For example, at the time of writing this section, the total number of steps was 1604. This is (1250 x1) + 354 steps. Hence, we light up one LED in green and the next LED blinks red. This indicates that the steps are in progress.</li>
<li>The picture here shows the blinking red LED when the progress was less than <kbd>1250</kbd> steps:</li>
</ol>
<div><img class=" image-border" height="175" src="img/image_10_035.jpg" width="331"/></div>
<p>Physical activity progress less than 1250 steps</p>
<ol start="10">
<li>After walking around, the progress shifted to the right by one LED:</li>
</ol>
<div><img class=" image-border" height="175" src="img/image_10_036-1.jpg" width="317"/></div>
<p>Physical activity at 1604 steps</p>
<ol start="11">
<li>The next step is to set off a buzzer when there is no minimum physical activity. This is achieved by connecting a buzzer to the GPIO pins of the Raspberry Pi Zero. We have demonstrated the use of a buzzer in an earlier chapter.</li>
<li>The earlier example is available for download along with this chapter as <kbd>visual_aid.py</kbd>. We will let you figure out the logic to set off a buzzer when there is no minimum physical activity in a period (for example, an hour).</li>
</ol>
<p>Install this visual aid somewhere prominent and find out if it motivates you to stay physically active! If you make use of the <em>Pimoroni Rainbow HAT</em>, you can display the steps using the 14-segment display.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Smart lawn sprinkler</h1>
            

            
                
<p>In drought-struck states like California, United States, there are severe restrictions on water usage in certain parts of the state. For example: In summer, some cities passed an ordinance restricting water usage to 250 gallons per day. In such states, it is ridiculous to find lawn sprinklers going off the day before the rain. We are going to build a lawn sprinkler controller that only turns on when there is no rain predicted for the next day.</p>
<p>In order to build a smart lawn sprinkler, we need a flow control solenoid valve (for example, <a href="https://www.sparkfun.com/products/10456" target="_blank">https://www.sparkfun.com/products/10456</a>). Make sure that the valve can meet the water pressure requirements. This flow control valve can be interfaced to the Raspberry Pi Zero using a transistor switching circuit discussed in earlier chapters or the relay board we discussed earlier in this chapter.</p>
<ol>
<li>We will be making use of <em>DarkSky API</em> (<a href="https://darksky.net" target="_blank">https://darksky.net</a>) to fetch the weather information. It provides a simple response format that could be used to determine if it was going to rain the next day.</li>
<li>Sign up for a free account at the website and get a developer key from the console.</li>
<li>According to the API documentation, the local weather information may be obtained as follows:</li>
</ol>
<pre>
       https://api.darksky.net/forecast/[key]/[latitude],[longitude]
</pre>
<ol start="4">
<li>The latitude and longitudinal coordinates can be obtained using a simple web search. For example, the request URL for Newark, CA is:</li>
</ol>
<pre>
       URL = ("https://api.darksky.net/forecast/key" <br/>       "/37.8267,-122.4233?exclude=currently,minutely,hourly")
</pre>
<ol start="5">
<li>The response includes the <kbd>current</kbd>, <kbd>minutely</kbd>, and <kbd>hourly</kbd> forecasts. They can be excluded using the <kbd>exclude</kbd> parameter as shown in the preceding URL.</li>
<li>Now, we need to turn on the sprinkler only if it is not going to rain the next day. According to the API documentation, the weather forecast is returned as a <kbd>Data Point object</kbd>. The data points include a field named <kbd>icon</kbd> that indicates whether it is going to be <kbd>clear</kbd>, <kbd>cloudy</kbd>, or <kbd>rainy</kbd>.</li>
<li>Let's write a method <kbd>check_weather()</kbd> that fetches the weather for the week:</li>
</ol>
<pre>
       def check_weather(): <br/>          try: <br/>                response = requests.get(URL) <br/>          except Exception as error: <br/>                print(error) <br/>          else: <br/>                if response.status_code == 200: <br/>                      data = response.json() <br/>                      if data["daily"]["data"][1]["icon"] == "rain": <br/>                            return True <br/>                      else: <br/>                            return False
</pre>
<ol start="8">
<li>If the <kbd>GET</kbd> request was successful, which can be determined by the status code of the response, the <kbd>json</kbd> response is decoded using the <kbd>json()</kbd> method.</li>
<li>The next day's weather information is available at <kbd>data["daily"]["data"][1]</kbd> (Print the response and verify it for yourself).</li>
<li>Since the <kbd>icon</kbd> key provides a machine-readable response, it could be used to turn on the sprinkler. Hence, the <kbd>check_weather()</kbd> returns <kbd>True</kbd> if it is going to rain and vice versa.</li>
</ol>
<p>We will let you figure out interfacing the solenoid valve using the GPIO pins. The earlier code sample is available for download along with this chapter as <kbd>lawn_sprinkler.py</kbd>.</p>
<p><strong>Exercise for the reader:</strong></p>
<p>We are making use of the next day's weather information to turn on the sprinkler. Go through the documentation and modify the code to account for current weather information.</p>
<p><strong>Project enhancements:</strong></p>
<ul>
<li>How would you go about adding a moisture sensor to the controller?</li>
<li>How would you interface the sensor to the Raspberry Pi Zero and make use of it in turn on the sprinkler?</li>
</ul>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Summary</h1>
            

            
                
<p>In this chapter, we reviewed four projects involving the Raspberry Pi Zero (and Python programming) that focused on specific improvements around the house. This includes a voice assistant, web framework-based appliance control, physical activity motivation tool, and a smart lawn sprinkler. The idea behind these projects were to demonstrate the applications of python programming in improving our quality of life. We could demonstrate that it is possible to build applications (using the Raspberry Pi Zero) that can serve as a better alternative to expensive off-the-shelf products.</p>
<p>We also recommend the following project ideas for your consideration:</p>
<ul>
<li><strong>Slack channel-based appliance control</strong>: Are you concerned about the temperature conditions back home for your pets while you are away at work? How about setting up a temperature sensor to send a slack channel alert suggesting that you turn on the air conditioner?</li>
<li><strong>Tabletop fountain</strong>: Using a Raspberry Pi Zero and an RGB LED strip, you can create lighting effects for a tabletop fountain.</li>
<li><strong>Bird feeder monitor</strong>: This is something we have been working on for a while now. We are trying to track birds that come to feed in a backyard feeder. The bird feeder is equipped with a Raspberry Pi Zero and a camera. Stay tuned to this book's website for some updates.</li>
<li><strong>Holiday lights controller</strong>: How about some special light and audio effects during the holidays?</li>
<li><strong>Controlling off-the-shelf products using Raspberry Pi Zero</strong>: Do you have a lot of Wi-Fi-enabled electrical outlets lying around unused? Why not try to control them using your Raspberry Pi Zero (hint: <em>IFTTT</em>).</li>
<li><strong>Pomodoro timer</strong>: Have you heard of the Pomodoro technique for productivity? How about an interactive device to improve your productivity?</li>
</ul>
<div><p>Learning Resources</p>
<ul>
<li><strong>Setting USB Soundcard as the default audio source</strong>: <a href="http://raspberrypi.stackexchange.com/a/44825/1470" target="_blank">http://raspberrypi.stackexchange.com/a/44825/1470</a></li>
<li><strong>arecord/aplay options</strong>: <a href="http://quicktoots.linux-audio.com/toots/quick-toot-arecord_and_rtmix-1.html" target="_blank">http://quicktoots.linux-audio.com/toots/quick-toot-arecord_and_rtmix-1.html</a></li>
<li><strong>MAX9814 setup tutorial</strong>: <a href="https://learn.adafruit.com/adafruit-agc-electret-microphone-amplifier-max9814/wiring-and-test" target="_blank">https://learn.adafruit.com/adafruit-agc-electret-microphone-amplifier-max9814/wiring-and-test</a></li>
<li><strong>Understanding optocouplers</strong>: <a href="https://www.elprocus.com/opto-couplers-types-applications/" target="_blank">https://www.elprocus.com/opto-couplers-types-applications/</a></li>
<li><strong>Relays and kickback voltages</strong>: <a href="http://www.coilgun.info/theoryinductors/inductivekickback.htm" target="_blank">http://www.coilgun.info/theoryinductors/inductivekickback.htm</a></li>
</ul>
</div>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    </body></html>