- en: 'Chapter 5. When Doctest isn''t Enough: Unittest to the Rescue'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*As the tests get more detailed (or complex), or they require more setup code
    to prepare the way for them, doctest begins to get a little bit annoying. The
    very simplicity that makes it the best way to write testable specifications and
    other simple tests starts to interfere with writing tests for complicated things.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we shall:'
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to write and execute tests in the unittest framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn how to express familiar testing concepts using unittest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discuss the specific features that make unittest suitable for more complicated
    testing scenarios
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn about of couple of Mocker's features that integrate well with unittest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So let's get on with it!
  prefs: []
  type: TYPE_NORMAL
- en: Basic unittest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start talking about new concepts and features, let's take a look at
    how to use unittest to express the ideas that we've already learned about. That
    way, we'll have something solid to ground our new understanding into.
  prefs: []
  type: TYPE_NORMAL
- en: Time for action – testing PID with unittest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll revisit the PID class (or at least the tests for the PID class) from Chapter
    3\. We'll rewrite the tests so that they operate within the unittest framework.
  prefs: []
  type: TYPE_NORMAL
- en: Before moving on, take a moment to refer back to the final version of the `pid.txt`
    file from Chapter 3\. We'll be implementing the same tests using the unittest
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new file called `test_pid.py` in the same directory as `pid.py`. Notice
    that this is a `.py` file: unittest tests are pure python source code, rather
    than being plain text with source code embedded in it. That means the tests will
    be less useful from a documentary point of view, but grants other benefits in
    exchange.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Insert the following code into your newly-created `test_pid.py` (and please
    note that a few lines are long enough to get wrapped on the book''s page):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the tests by typing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Time for action – testing PID with unittest](img/8846_05_01.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '*What just happened?*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's go through the code section and see what each part does. After that, we'll
    talk about what it all means when put together.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: After a little bit of setup code, we have a test that the PID controller works
    correctly when not given a `when` parameter. Mocker is used to replace `time.time`
    with a mock that always returns a predictable value, and then we use several assertions
    to confirm that the attributes of the controller have been initialized to the
    expected values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This test confirms that the PID constructor works correctly when the `when`
    parameter is supplied. Unlike the previous test, there's no need to use Mocker,
    because the outcome of the test is not supposed to be dependant on anything except
    the parameter values—the current time is irrelevant.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The tests in this class describe the intended behavior of the `calculate_response`
    method. This first test checks the behavior when the optional `when` parameter
    is not supplied, and mocks `time.time` to make that behavior predictable.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this test, the `when` parameter is supplied, so there is no need to mock
    `time.time`. We just have to check that the result is what we expected.
  prefs: []
  type: TYPE_NORMAL
- en: The actual tests that we performed are the same ones that were written in the
    doctest. So far, all that we see is a different way of expressing them.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to notice is that the test file is divided up into classes that
    inherit from `unittest.TestCase`, each of which contains one or more test methods.
    The name of each test method begins with the word *test*, which is how unittest
    recognizes that they are tests.
  prefs: []
  type: TYPE_NORMAL
- en: Each test method embodies a single test of a single unit. This gives us a convenient
    way to structure our tests, grouping together related tests into the same class,
    so that they're easier to find.
  prefs: []
  type: TYPE_NORMAL
- en: Putting each test into its own method means that each test executes in an isolated
    namespace, which makes it somewhat easier to keep unittest-style tests from interfering
    with each other, relative to doctest-style tests. It also means that unittest
    knows how many unit tests are in your test file, instead of simply knowing how
    many expressions there are (you may have noticed that doctest counts each `>>>`
    line as a separate test). Finally, putting each test in its own method means that
    each test has a name, which can be a valuable feature.
  prefs: []
  type: TYPE_NORMAL
- en: Tests in unittest don't directly care about anything that isn't part of a call
    to one of the assert methods of `TestCase`. That means that when we're using Mocker,
    we don't have to be bothered about the mock objects that get returned from demonstration
    expressions, unless we want to use them. It also means that we need to remember
    to write an assert describing every aspect of the test that we want to have checked.
    We'll go over the various assertion methods of `TestCase` shortly.
  prefs: []
  type: TYPE_NORMAL
- en: Tests aren't of much use, if you can't execute them. For the moment, the way
    we'll be doing that is by calling `unittest.main` when our test file is executed
    as a program by the Python interpreter. That's about the simplest way to run unittest
    code, but it's cumbersome when you have lots of tests spread across lots of files.
    We'll be learning about tools to address that problem in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`if __name__ == ''__main__'':` might look strange to you, but its meaning is
    fairly straight forward. When Python loads any module, it stores that module''s
    name in a variable called `__name__` within the module (unless the module is the
    one passed to the interpreter on the command line). That module always gets the
    string `''__main__''` bound to its `__name__` variable. So, `if __name__ == ''__main__'':`
    means—if this module was executed directly from the command line.'
  prefs: []
  type: TYPE_NORMAL
- en: Assertions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Assertions are the mechanism that we use to tell unittest what the important
    outcomes of the test are. By using appropriate assertions, we can tell unittest
    exactly what to expect from each test.
  prefs: []
  type: TYPE_NORMAL
- en: assertTrue
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we call `self.assertTrue(expression)`, we're telling unittest that the
    expression must be true in order for the test to be a success.
  prefs: []
  type: TYPE_NORMAL
- en: This is a very flexible assertion, since you can check for nearly anything by
    writing the appropriate boolean expression. It's also one of the last assertions
    you should consider using, because it doesn't tell unittest anything about the
    kind of comparison you're making, which means that unittest can't tell you as
    clearly what's gone wrong if the test fails.
  prefs: []
  type: TYPE_NORMAL
- en: 'For an example of this, consider the following test code which contains two
    tests that are guaranteed to fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: It might seem like the two tests are interchangeable, since both test the same
    thing. Certainly they'll both fail (or in the unlikely event that one equals two,
    they'll both pass), so why prefer one over the other?
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at what happens when we run the tests (and also notice that the
    tests were not executed in the same order as they were written; tests are totally
    independent of each other, so that''s okay, right?):'
  prefs: []
  type: TYPE_NORMAL
- en: '![assertTrue](img/8846_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Do you see the difference? The `assertTrue` test was able to correctly determine
    that the test should fail, but it didn''t know enough to report any useful information
    about why it failed. The `assertEqual` test, on the other hand, knew first of
    all that it was checking that two expressions were equal, and second it knew how
    to present the results, so that they would be most useful: by evaluating each
    of the expressions that it was comparing and placing a `!=` symbol between the
    results. It tells us both what expectation failed, and what the relevant expressions
    evaluate to.'
  prefs: []
  type: TYPE_NORMAL
- en: assertFalse
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `assertFalse` method will succeed when the `assertTrue` method would fail,
    and vice versa. It has the same limits in terms of producing useful output that
    `assertTrue` has, and the same flexibility in terms of being able to test nearly
    any condition.
  prefs: []
  type: TYPE_NORMAL
- en: assertEqual
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned in the `assertTrue` discussion, the `assertEqual` assertion checks
    that its two parameters are in fact equal, and reports a failure if they are not,
    along with the actual values of the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: assertNotEqual
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `assertNotEqual` assertion fails whenever the `assertEqual` assertion would
    have succeeded, and vice versa. When it reports a failure, its output indicates
    that the values of the two expressions are equal, and provides you with those
    values.
  prefs: []
  type: TYPE_NORMAL
- en: assertAlmostEqual
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we've seen before, comparing floating point numbers can be troublesome. In
    particular, checking that two floating point numbers are equal is problematic,
    because things that you might expect to be equal—things that, mathematically,
    are equal—may still end up differing down among the least significant bits. Floating
    point numbers only compare equal when every bit is the same.
  prefs: []
  type: TYPE_NORMAL
- en: To address that problem, unittest provides `assertAlmostEqual`, which checks
    that two floating point values are almost the same; a small amount of difference
    between them is tolerated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lets look at this problem in action. If you take the square root of 7, and
    then square it, the result should be `7`. Here''s a pair of tests that check that
    fact:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `test_assertEqual` method checks that ![assertAlmostEqual](img/8846_05_01a.jpg),
    which is true in reality. In the more specialized number system available to computers,
    though, taking the square root of 7 and then squaring it doesn't quite get us
    back to 7, so this test will fail. More on that in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: Test `test_assertAlmostEqual` method checks that ![assertAlmostEqual](img/8846_05_01b.jpg),
    which even the computer will agree is true, so this test should pass.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running those tests produces the following, although the specific number that
    you get back instead of `7` may vary depending on the details of the computer
    the tests are being run on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![assertAlmostEqual](img/8846_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Unfortunately, floating point numbers are not precise, because the majority
    of numbers on the real number line can not be represented with a finite, non-repeating
    sequence of digits, much less a mere 64 bits. Consequently, what you get back
    from evaluating the mathematical expression is not quite `7`. It's close enough
    for government work though—or practically any other sort of work as well—so we
    don't want our test to quibble over that tiny difference. Because of that, we
    should use `assertAlmostEqual` and `assertNotAlmostEqual` when we're comparing
    floating point numbers for equality.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This problem doesn't generally carry over into other comparison operators. Checking
    that one floating point number is less than the other, for example, is very unlikely
    to produce the wrong result due to insignificant errors. It's only in cases of
    equality that this problem bites us.
  prefs: []
  type: TYPE_NORMAL
- en: assertNotAlmostEqual
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `assertNotAlmostEqual` assertion fails whenever the `assertAlmostEqual`
    assertion would have succeeded, and vice versa. When it reports a failure, its
    output indicates that the values of the two expressions are nearly equal, and
    provides you with those values.
  prefs: []
  type: TYPE_NORMAL
- en: assertRaises
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As always, we need to make sure that our units correctly signal errors. Doing
    the right thing when they receive good inputs is only half the job; they need
    to do something reasonable when they receive bad inputs, as well.
  prefs: []
  type: TYPE_NORMAL
- en: The `assertRaises` method checks that a callable (a callable is a function,
    a method, or a class. A callable can also be an object of any arbitrary type,
    so long as it has a `__call__` method) raises a specified exception, when passed
    a specified set of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: This assertion only works with callables, which means that you don't have a
    way of checking that other sorts of expressions raise an expected exception. If
    that doesn't fit the needs of your test, it's possible to construct your own test
    using the `fail` method, described below.
  prefs: []
  type: TYPE_NORMAL
- en: To use `assertRaises`, first pass it the expected exception, then pass the callable,
    and then the parameters that should be passed to the callable when it's invoked.
  prefs: []
  type: TYPE_NORMAL
- en: Here's an example test using `assertRaises`. This test ought to fail, because
    the callable won't raise the expected exception. `'8ca2'` is perfectly acceptable
    input to `int`, when you're also passing it `base = 16`. Notice that `assertRaises`
    will accept any number of positional or keyword arguments, and pass them on to
    the callable on invocation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: When we run that test, it fails (as we knew it would) because `int` didn't raise
    the exception we told `assertRaises` to expect.
  prefs: []
  type: TYPE_NORMAL
- en: '![assertRaises](img/8846_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If an exception is raised, but it's not the one you told unittest to expect,
    unittest considers that an error. An error is different from a failure. A failure
    means that one of your tests has detected a problem in the unit it's testing.
    An error means that there's a problem with the test itself.
  prefs: []
  type: TYPE_NORMAL
- en: fail
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When all else fails, you can fall back on `fail`. When the code in your test
    calls `fail`, the test fails.
  prefs: []
  type: TYPE_NORMAL
- en: What good does that do? When none of the assert methods does what you need,
    you can instead write your checks in such a way that `fail` will be called if
    the test does not pass. This allows you to use the full expressiveness of Python
    to describe checks for your expectations.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at an example. This time, we're going to test on a less-than
    operation, which isn't one of the operations directly supported by an assert method.
    Using `fail`, it's easy to implement the test anyhow.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'A couple of things to notice here: first of all, take note of the `not` in
    the `if` statement. Since we want to run `fail` if the test should not pass, but
    we''re used to describing the circumstances when the test should succeed, a good
    way to write the test is to write the success condition, and then invert it with
    `not`. That way we can continue thinking in the way we''re used to when we use
    fail. The second thing to note is that you can pass a message to fail when you
    call it, which will be printed out in unittest''s report of failed tests. If you
    choose your message carefully, it can be a big help.'
  prefs: []
  type: TYPE_NORMAL
- en: There's no screen capture of what to expect from running this test, because
    the test should pass, and the report wouldn't contain anything interesting. You
    might experiment with changing the test around and running it, to see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: Pop quiz – basic unittest knowledge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the unittest equivalent of this doctest?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How do you check whether two floating point numbers are equal?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When would you choose to use `assertTrue`? How about `fail`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Have a go hero – translating into unittest
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look back at some of the tests we write in the previous chapters, and translate
    them from doctests into unittests. Given what you already know of unittest, you
    should be able to translate any of the tests.
  prefs: []
  type: TYPE_NORMAL
- en: While you're doing this, think about the relative merits of unittest and doctest
    for each of the tests you translate. The two systems have different strengths,
    so it makes sense that each will be the more appropriate choice for different
    situations. When is doctest the better choice, and when is unittest?
  prefs: []
  type: TYPE_NORMAL
- en: Test fixtures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unittest has an important and highly useful capability that doctest lacks. You
    can tell unittest how to create a standardized environment for your unit tests
    to run inside, and how to clean up that environment when it's done. This ability
    to create and destroy a standardized test environment is a test fixture. While
    test fixtures doesn't actually make any tests possible that were impossible before,
    they can certainly make them shorter and less repetitive.
  prefs: []
  type: TYPE_NORMAL
- en: Time for action – testing database-backed units
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Many programs need to access a database for their operation, which means that
    many of the units those programs are made of also access a database. The point
    is that the purpose of a database is to store information and make it accessible
    in arbitrary other places (in other words, databases exist to break the isolation
    of units). (The same problem applies to other information stores as well: for
    example, files in permanent storage.)'
  prefs: []
  type: TYPE_NORMAL
- en: How do we deal with that? After all, just leaving the units that interact with
    the database untested is no solution. We need to create an environment where the
    database connection works as usual, but where any changes that are made do not
    last. There are a few different ways we could do that, but no matter what the
    details are, we need to set up the special database connection before each test
    that uses it, and we need to destroy any changes after each such test.
  prefs: []
  type: TYPE_NORMAL
- en: Unittest helps us to do that by providing test fixtures via the `setUp` and
    `tearDown` methods of the `TestCase` class. These methods exist for us to override,
    with the default versions doing nothing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s some database-using code (let''s say it exists in a file called `employees.py`),
    for which we''ll write tests:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This code uses the `sqlite3` database which ships with Python. Since the `sqlite3`
    interface is compatible with Python's DB-API 2.0, any database backend that you
    find yourself using will have a similar interface to what you see here.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We'll start writing the tests by importing the modules that we need and introducing
    our `TestCase` class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We need a `setUp` method to create the environment that our tests depend on.
    In this case, that means creating a new database connection to an in-memory-only
    database, and populating that database with the needed tables and rows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We need a `tearDown` method to undo whatever the `setUp` method did, so that
    each test can run in an untouched version of the environment. Since the database
    is only in memory, all we have to do is close the connection, and it goes away.
    `tearDown` may end up being much more complicated in other scenarios.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, we need the tests themselves, and the code to execute the tests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*What just happened?*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We used a `setUp` method for our `TestCase`, along with a matching `tearDown`
    method. Between them, these methods made sure that the environment in which the
    tests were executed was the one they needed (that was `setUp`'s job) and that
    the environment of each test was cleaned up after the test was run, so that the
    tests didn't interfere with each other (which was the job of `tearDown`). Unittest
    made sure that `setUp` was run once before each test method, and that `tearDown`
    was run once after each test method.
  prefs: []
  type: TYPE_NORMAL
- en: Because a test fixture—as defined by `setUp` and `tearDown`—gets wrapped around
    every test in a `TestCase` class, the `setUp` and `tearDown` for `TestCase` classes
    that contain too many tests can get very complicated and waste a lot of time dealing
    with details that are unnecessary for some of the tests. You can avoid that problem
    by simply grouping together, those tests that require specific aspects of the
    environment into their own `TestCase` classes. Give each `TestCase` an appropriate
    `setUp` and `tearDown`, only dealing with those aspects of the environment that
    are necessary for the tests it contains. You can have as many `TestCase` classes
    as you want, so there's no need to skimp on them when you're deciding which tests
    to group together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice how simple the `tearDown` method that we used was. That''s usually a
    good sign: when the changes that need to be undone in the `tearDown` method are
    simple to describe, it often means that you can be sure of doing it perfectly.
    Since any imperfection of the `tearDown` makes it possible for tests to leave
    behind stray data that might alter how other tests behave, getting it right is
    important. In this case, all of our changes were confined to the database, so
    getting rid of the database does the trick.'
  prefs: []
  type: TYPE_NORMAL
- en: Pop quiz – test fixtures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the purpose of a test fixture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How is a test fixture created?.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can a test fixture have a `tearDown` method without a `setUp`? How about `setUp`
    without `tearDown`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Have a go hero – file path abstraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Below is a class definition that describes an abstraction of file paths. Your
    challenge is to write unit tests (using unittest) that check each of the methods
    of the class, making sure that they behave as advertised. You will need to use
    a test fixture to create and destroy a sandbox area in the filesystem for your
    tests to operate on.
  prefs: []
  type: TYPE_NORMAL
- en: Because doctest doesn't support test fixtures, writing these tests using that
    framework would be quite annoying. You'd have to duplicate the code to create
    the environment before each test, and the code to clean it up after each test.
    By using `unittest`, we can avoid that duplication.
  prefs: []
  type: TYPE_NORMAL
- en: There are several things about this class that are wrong, or at least not as
    right as they ought to be. See if you can catch them with your tests.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Integrating with Python Mocker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You've used Mocker enough to see the repetitiveness involved in creating a mocking
    context at the beginning of the text and calling its `verify` and `restore` methods
    at the end. Mocker simplifies this for you by providing a class called `MockerTestCase`
    in the mocker module. `MockerTestCase` behaves just like a normal unittest `TestCase`,
    except that for each test, it automatically creates a mocking context, which it
    then verifies and restores after the test. The mocking context is stored in `self.mocker`.
  prefs: []
  type: TYPE_NORMAL
- en: The following example demonstrates `MockerTestCase` by using it to write a test
    involving a mock of `time.time`. Before the test gets executed, a mocking context
    is stored in `self.mocker`. After the test is run, the context is automatically
    verified and restored.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The above is a simple test that checks that the current time is `1.0`, which
    it would not be if we didn't mock `time.time`. Instead of creating a new Mocker
    instance, we have one already available to us as `self.mocker`, so we use that.
    We also get to leave off the calls to `verify` and `restore`, because the `MockerTestCase`
    takes care of that for us.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter contained a lot of information about how to use the unittest framework
    to write your tests.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, we covered how to use unittest to express concepts that you were
    already familiar with from doctest, differences and similarities between unittest
    and doctest, how to use test fixtures to embed your tests in a controlled and
    temporary environment, and how to use Python Mocker's `MockerTestCase` to simplify
    the integration of unittest and Mocker.
  prefs: []
  type: TYPE_NORMAL
- en: Until now, we've been running tests individually, or in small groups, by directly
    instructing Python to run them. Now that we've learned about unittest, we're ready
    to talk about managing and executing large bodies of tests, which is the topic
    of the next chapter.
  prefs: []
  type: TYPE_NORMAL
