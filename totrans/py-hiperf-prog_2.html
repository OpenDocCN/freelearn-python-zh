<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch02"/>Chapter 2. Fast Array Operations with NumPy</h1></div></div></div><p>NumPy is<a class="indexterm" id="id65"/> the <em>de facto</em> standard for scientific computing in Python. It extends Python with a flexible multidimensional array that allows fast mathematical calculations.</p><p>NumPy works as a framework that allows coding complex operations using a concise syntax. The multidimensional array (<code class="literal">numpy.ndarray</code>) is internally based on C arrays: in this way, the developer can easily interface NumPy with existing C and FORTRAN code. NumPy constitutes a bridge between Python and the legacy code written using those languages.</p><p>In this chapter, we will learn how to create and manipulate NumPy arrays. We will also explore the NumPy broadcasting feature to rewrite complex mathematical expressions in an efficient and succinct manner.</p><p>In the last few years a number of packages were developed to further increase the speed of NumPy. We will explore one of these packages, <code class="literal">numexpr</code>, that optimizes array expressions and takes advantage of multi-core architectures.</p><div><div><div><div><h1 class="title"><a id="ch02lvl1sec21"/>Getting started with NumPy</h1></div></div></div><p>NumPy is founded around<a class="indexterm" id="id66"/> its multidimensional array object, <code class="literal">numpy.ndarray</code>. NumPy arrays are a collection of elements of the same data type; this fundamental restriction allows NumPy to pack the data in an efficient way. By storing the data in this way NumPy can handle arithmetic and mathematical operations at high speed.</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec04"/>Creating arrays</h2></div></div></div><p>You can create NumPy arrays using the <code class="literal">numpy.array</code> function. It takes a<a class="indexterm" id="id67"/> list-like object (or another array) as input and, <a class="indexterm" id="id68"/>optionally, a string expressing its data type. You can interactively test the array creation using an IPython shell as follows:</p><div><pre class="programlisting">In [1]: import numpy as np
In [2]: a = np.array([0, 1, 2])</pre></div><p>Every NumPy array has a data type that can be accessed by the <code class="literal">dtype</code> attribute, as shown in the following code. In the following code example, <code class="literal">dtype</code> is a 64-bit integer:</p><div><pre class="programlisting">In [3]: a.dtype
Out[3]: dtype('int64')</pre></div><p>If we want those numbers to be treated as a <code class="literal">float</code> type of variable, we can either pass the <code class="literal">dtype</code> argument in the <code class="literal">np.array</code> function or cast the array to another data type using the <code class="literal">astype</code> method, as shown in the following code:</p><div><pre class="programlisting">In [4]: a = np.array([1, 2, 3], dtype='float32')
In [5]: a.astype('float32')
Out[5]: array([ 0.,  1.,  2.], dtype=float32)</pre></div><p>To create an array with two dimensions (an array of arrays) we can initialize the array using a nested sequence, shown as follows:</p><div><pre class="programlisting">In [6]: a = np.array([[0, 1, 2], [3, 4, 5]])
In [7]: print(a)
Out[7]: [[0 1 2][3 4 5]]</pre></div><p>The array created in this way has<a class="indexterm" id="id69"/> two dimensions—<strong>axes</strong><a class="indexterm" id="id70"/> in NumPy's jargon. Such an array is like a table that contains two rows and three columns. We can access the axes structure using the <code class="literal">ndarray.shape</code> attribute:</p><div><pre class="programlisting">In [7]: a.shape
Out[7]: (2, 3)</pre></div><p>Arrays can also be reshaped, only as long as the product of the shape dimensions is equal to the total number of elements in the array. For example, we can reshape an array containing 16 elements in the following ways: (2, 8), (4, 4), or (2, 2, 4). To reshape an array, we can either use the <code class="literal">ndarray.reshape</code> method<a class="indexterm" id="id71"/> or directly change the <code class="literal">ndarray.shape</code> attribute. The following code illustrates the use of the <code class="literal">ndarray.reshape</code> method:</p><div><pre class="programlisting">In [7]: a = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8,9, 10, 11, 12, 13, 14, 15])
In [7]: a.shape
Out[7]: (16,)
In [8]: a.reshape(4, 4) # Equivalent: a.shape = (4, 4)
Out[8]:
array([[ 0,  1,  2,  3],[ 4,  5,  6,  7],[ 8,  9, 10, 11],[12, 13, 14, 15]])</pre></div><p>Thanks to this property you are also free to add dimensions of size one. You can reshape an array with 16 elements to (16, 1), (1, 16), (16, 1, 1), and so on.</p><p>NumPy provides <a class="indexterm" id="id72"/>convenience functions, shown in the following code, to create arrays filled with zeros, filled with ones, or without an initialization value (<em>empty</em>—their actual value is <a class="indexterm" id="id73"/>meaningless and depends on the memory state). Those functions take the array shape as a tuple and optionally its <code class="literal">dtype</code>:</p><div><pre class="programlisting">In [8]: np.zeros((3, 3))
In [9]: np.empty((3, 3))
In [10]: np.ones((3, 3), dtype='float32')</pre></div><p>In our examples, we will use the <code class="literal">numpy.random</code> module to generate random floating point numbers in the (0, 1) interval. In the following code we use the <code class="literal">np.random</code>.<code class="literal">rand</code> function to generate an array of random numbers of shape (3, 3):</p><div><pre class="programlisting">In [11]: np.random.rand(3, 3)</pre></div><p>Sometimes, it is convenient to initialize arrays that have a similar shape to other arrays. Again, NumPy provides some handy functions for that purpose such as <code class="literal">zeros_like</code>, <code class="literal">empty_like</code>, and <code class="literal">ones_like</code>. These functions are as follows:</p><div><pre class="programlisting">In [12]: np.zeros_like(a)
In [13]: np.empty_like(a)
In [14]: np.ones_like(a)</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec05"/>Accessing arrays</h2></div></div></div><p>The NumPy array interface is, on a <a class="indexterm" id="id74"/>shallow level, similar to Python lists. They can be indexed using integers, and can also be<a class="indexterm" id="id75"/> iterated using a <code class="literal">for</code> loop. The following code shows how to index and iterate an array:</p><div><pre class="programlisting">In [15]: A = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])
In [16]: A[0]
Out[16]: 0
In [17]: [a for a in A]
Out[17]: [0, 1, 2, 3, 4, 5, 6, 7, 8]</pre></div><p>It is also possible to index an array in multiple dimensions. If we take a (3, 3) array (an array containing 3 triplets) and we<a class="indexterm" id="id76"/> index the first element, we obtain the first triplet shown as follows:</p><div><pre class="programlisting">In [18]: A = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
In [19]: A[0]
Out[19]: array([0, 1, 2])</pre></div><p>We can index the triplet again by adding the other index separated by a comma. To get the second element of the first triplet we can index using [0, 1], as shown in the following code:</p><div><pre class="programlisting">In [20]: A[0, 1]
Out[20]: 1</pre></div><p>NumPy allows you<a class="indexterm" id="id77"/> to slice arrays in single and multiple dimensions. If we index on the first dimension we will get a collection of triplets shown as follows:</p><div><pre class="programlisting">In [21]: A[0:2]
Out[21]: array([[0, 1, 2],
               [3, 4, 5]])</pre></div><p>If we slice the array with [0:2]. for every selected triplet we extract the first two elements, resulting in a (2, 2) array shown in the following code:</p><div><pre class="programlisting">In [22]: A[0:2, 0:2]
Out[22]: array([[0, 1],
                [3, 4]])</pre></div><p>Intuitively, you can update values in the array by using both numerical indexes and slices. The syntax is as follows:</p><div><pre class="programlisting">In [23]: A[0, 1] = 8
In [24]: A[0:2, 0:2] = [[1, 1], [1, 1]]</pre></div><div><div><h3 class="title"><a id="tip06"/>Tip</h3><p>Indexing with the slicing syntax is fast because it doesn't make copies of the array. In NumPy terminology it returns a <em>view</em> over the same memory area. If we take a slice of the original array and then change one of its values; the original array will be updated as well. The following code illustrates an example of the same:</p><div><pre class="programlisting">In [25]: a = np.array([1, 1, 1, 1])
In [26]: a_view = a[0:2]
In [27]: a_view[0] = 2
In [28]: print(a)
Out[28]: [2 1 1 1]</pre></div></div></div><p>We can take a look at another example that shows how the slicing syntax can be used in a real-world scenario. We define an array <code class="literal">r_i</code>, shown in the following line of code, which contains a set of 10 coordinates (x, y); its shape will be (10, 2):</p><div><pre class="programlisting">In [29]: r_i = np.random.rand(10, 2)</pre></div><p>A typical operation is <a class="indexterm" id="id78"/>extracting the x component of each coordinate. In other words, you want to extract the items [0, 0], [1, 0], [2, 0], and so on, resulting in an array with shape<a class="indexterm" id="id79"/> (10,). It is helpful to think that the first index is <em>moving</em> while the second one is <em>fixed</em> (at 0). With this in mind, we will slice every index on the first axis (the moving one) and take the first element (the fixed one) on the second axis, as shown in the following line of code:</p><div><pre class="programlisting">In [30]: x_i = r_i[:, 0]</pre></div><p>On the other hand, the following expression of code will keep the first index fixed and the second index moving, giving the first (x, y) coordinate:</p><div><pre class="programlisting">In [31]: r_0 = r_i[0, :]</pre></div><p>Slicing all the indexes over the last axis is optional; using <code class="literal">r_i[0]</code> has the same effect as <code class="literal">r_i[0, :]</code>.</p><p>NumPy allows to index an array by using another NumPy array made of either integer or Boolean values—a feature called <em>fancy indexing</em>.</p><p>If you index with an array of integers, NumPy will interpret the integers as indexes and will return an array containing their corresponding values. If we index an array containing 10 elements with <code class="literal">[0, 2, 3]</code>, we obtain an array of size 3 containing the elements at positions 0, 2 and 3. The following code gives us an illustration of this concept:</p><div><pre class="programlisting">In [32]: a = np.array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])
In [33]: idx = np.array([0, 2, 3])
In [34]: a[idx]
Out[34]: array([9, 7, 6])</pre></div><p>You can use fancy indexing on multiple dimensions by passing an array for each dimension. If we want to extract the elements [0, 2] and [1, 3] we have to pack all the indexes acting on the first axis in one array, and the ones acting on the second axis in another. This can be seen in the following code:</p><div><pre class="programlisting">In [35]: a = np.array([[0, 1, 2], [3, 4, 5],
                       [6, 7, 8], [9, 10, 11]])
In [36]: idx1 = np.array([0, 1])
In [37]: idx2 = np.array([2, 3])
In [38]: a[idx1, idx2]</pre></div><div><div><h3 class="title"><a id="tip07"/>Tip</h3><p>You can also use normal lists as index arrays, but not tuples. For example the following two statements are equivalent:</p><div><pre class="programlisting">&gt;&gt;&gt; a[np.array([0, 1])] # is equivalent to
&gt;&gt;&gt; a[[0, 1]]</pre></div><p>However, if you use a tuple, NumPy will interpret the following statement as an index on multiple dimensions:</p><div><pre class="programlisting">&gt;&gt;&gt; a[(0, 1)] # is equivalent to&gt;&gt;&gt; a[0, 1]</pre></div></div></div><p>The index arrays are<a class="indexterm" id="id80"/> not required to be one-dimensional; we can extract elements<a class="indexterm" id="id81"/> from the original array in any shape. For example we can select elements from the original array to form a (2, 2) array shown as follows:</p><div><pre class="programlisting">In [39]: idx1 = [[0, 1], [3, 2]]
In [40]: idx2 = [[0, 2], [1, 1]]
In [41]: a[idx1, idx2]
Out[41]: array([[ 0,  5],[10,  7]])</pre></div><p>The array slicing and fancy indexing features can be combined. For example, this is useful if we want to swap the x and y columns in a coordinate array. In the following code, the first index will be running over all the elements (a slice), and for each of those we extract the element in position 1 (the y) first and then the one in position 0 (the x):</p><div><pre class="programlisting">In [42]: r_i = np.random(10, 2)
In [43]: r_i[:, [0, 1]] = r_i[:, [1, 0]]</pre></div><p>When the index array is a boolean there are slightly different rules. The Boolean array will act like a <em>mask</em>; every element corresponding to <code class="literal">True</code> will be extracted and put in the output array. This procedure is shown as follows:</p><div><pre class="programlisting">In [44]: a = np.array([0, 1, 2, 3, 4, 5])
In [45]: mask = np.array([True, False, True, False, False, False])
In [46]: a[mask]
Out[46]: array([0, 2])</pre></div><p>The same rules apply when dealing with multiple dimensions. Furthermore, if the index array has the same shape as the original array, the elements corresponding to <code class="literal">True</code> will be selected and put in the resulting array.</p><p>Indexing in NumPy is a reasonably fast operation. Anyway, when speed is critical, you can use the slightly faster <code class="literal">numpy.take</code> and <code class="literal">numpy.compress</code> functions to squeeze out a little more speed. The <a class="indexterm" id="id82"/>first argument of <code class="literal">numpy.take</code> is the array we want to operate on, <a class="indexterm" id="id83"/>and the second is the list of indexes we want to extract. The last argument is <code class="literal">axis</code>; if not provided, the indexes will act on the flattened array, otherwise they will act along the specified axis. The following code shows the use of <code class="literal">np.take</code> and its execution time compared to fancy indexing:</p><div><pre class="programlisting">In [47]: r_i = np.random(100, 2)
In [48]: idx = np.arange(50) # integers 0 to 50
In [49]: %timeit np.take(r_i, idx, axis=0)
1000000 loops, best of 3: 962 ns per loop
In [50]: %timeit r_i[idx]
100000 loops, best of 3: 3.09 us per loop</pre></div><p>The similar, but a faster way to index using Boolean arrays is <code class="literal">numpy.compress</code> which works in the same way as <code class="literal">numpy.take</code>. The use of <code class="literal">numpy.compress</code> is shown as follows:</p><div><pre class="programlisting">In [51]: idx = np.ones(100, dtype='bool') # all True values
In [52]: %timeit np.compress(idx, r_i, axis=0)
1000000 loops, best of 3: 1.65 us per loop
In [53]: %timeit r_i[idx]
100000 loops, best of 3: 5.47 us per loop</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec06"/>Broadcasting</h2></div></div></div><p>The true power of NumPy lies in its fast<a class="indexterm" id="id84"/> mathematical operations. The approach used by NumPy is to avoid stepping into Python by performing an element-wise calculation between matching arrays.</p><p>Whenever you do an arithmetic operation on two arrays (like a product), if the two operands have the same shape, the operation will be applied in an element-wise fashion. For example, upon multiplying two (2, 2) arrays, the operation will be done between pairs of corresponding elements, producing another (2, 2) array, as shown in the following code:</p><div><pre class="programlisting">In [54]: A = np.array([[1, 2], [3, 4]])
In [55]: B = np.array([[5, 6], [7, 8]])
In [56]: A * B
Out[56]: array([[ 5, 12],[21, 32]])</pre></div><p>If the shapes of the operand don't match, NumPy will attempt to match them using certain rules—a feature called <em>broadcasting</em>. If one of the operands is a single value, it will be applied to every element of the array, as shown in the following code:</p><div><pre class="programlisting">In [57]: A * 2
Out[58]: array([[2, 4],
                [6, 8]])</pre></div><p>If the operand is another array, NumPy will try to match the shapes starting from the last axis. For example, if we want to<a class="indexterm" id="id85"/> combine an array of shape (3, 2) with one of shape (2,), the second array is repeated three times to generate a (3, 2) array. The array is <em>broadcasted</em> to match the shape of the other operand, as shown in the following figure:</p><div><img alt="Broadcasting" src="img/8458OS_02_01.jpg"/></div><p>If the shapes mismatch, for example by combining an array (3, 2) with an array (2, 2), NumPy will throw an exception.</p><p>If one of the axes size is 1, the array will be repeated over this axis until the shapes match. To illustrate that point, if we have an array of the following shape:</p><div><pre class="programlisting">5, 10, 2</pre></div><p>and we want to broadcast it with an array (5, 1, 2), the array will be repeated on the second axis for 10 times which is shown as follows:</p><div><pre class="programlisting">5, 10, 2
5,  1, 2 → repeated
- - - -
5, 10, 2</pre></div><p>We have seen earlier, that we can freely reshape arrays to add axes of size 1. Using the <code class="literal">numpy.newaxis</code> constant while indexing will introduce an extra dimension. For instance, if we have a (5, 2) array and we <a class="indexterm" id="id86"/>want to combine it with one of shape (5, 10, 2), we could add an extra axis in the middle, as shown in the following code, to obtain a compatible (5, 1, 2) array:</p><div><pre class="programlisting">In [59]: A = np.random.rand(5, 10, 2)
In [60]: B = np.random.rand(5, 2)
In [61]: A * B[:, np.newaxis, :]</pre></div><p>This feature can be used, for example, to operate on all possible combinations of the two arrays. One of these applications is the <em>outer product</em>. If we have the following two arrays:</p><div><pre class="programlisting">a = [a1, a2, a3]
b = [b1, b2, b3]</pre></div><p>The outer product is a matrix containing the product of all the possible combinations (i, j) of the two array elements, as shown in the following code:</p><div><pre class="programlisting">a x b = a1*b1, a1*b2, a1*b3
        a2*b1, a2*b2, a2*b3
        a3*b1, a3*b2, a3*b3</pre></div><p>To calculate this using NumPy we will  repeat the elements <code class="literal">[a1, a2, a3]</code> in one dimension, the elements <code class="literal">[b1, b2, b3]</code> in another dimension, and then take their product, as shown in the following figure:. </p><div><img alt="Broadcasting" src="img/8458OS_02_02.jpg"/></div><p>Our strategy will be to transform the array <code class="literal">a</code> from shape (3,) to shape (3, 1), and the array <code class="literal">b</code> from shape (3,) to shape (1, 3). The two arrays are broadcasted in the two dimensions and get multiplied together using<a class="indexterm" id="id87"/> the following code:</p><div><pre class="programlisting">AB = a[:, np.newaxis] * b[np.newaxis, :]</pre></div><p>This operation is very fast and extremely effective as it avoids Python loops and is able to process a high number of elements.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec07"/>Mathematical operations</h2></div></div></div><p>NumPy includes the most <a class="indexterm" id="id88"/>common mathematical operations available for broadcasting, by default, ranging from simple algebra to trigonometry, rounding, and logic. For instance, to take the square root of every element in the array we can use the <code class="literal">numpy.sqrt</code> function, as shown in the following code:</p><div><pre class="programlisting">In [59]: np.sqrt(np.array([4, 9, 16]))
Out[59]: array([2., 3., 4.])</pre></div><p>The comparison operators are extremely useful when trying to filter certain elements based on a condition. Imagine that we have an array of random numbers in the range [0, 1] and we want to extract the numbers greater than 0.5. We can use the <code class="literal">&gt;</code> operator on the array; The result will be a boolean array, shown as follows:</p><div><pre class="programlisting">In [60]: a = np.random.rand(5, 3)
In [61]: a &gt; 0.5
Out[61]: array([[ True, False,  True],[ True,  True,  True],[False,  True,  True],[ True,  True, False],[ True,  True, False]], dtype=bool)</pre></div><p>The resulting boolean array can then be reused as an index to retrieve the elements greater than 0.5, as shown in the following code:</p><div><pre class="programlisting">In [62]: a[a &gt; 0.5]
In [63]: print(a[a&gt;0.5])
[ 0.9755  0.5977  0.8287  0.6214  0.5669  0.9553  0.58940.7196  0.9200  0.5781  0.8281 ]</pre></div><p>NumPy also implements methods such as <code class="literal">ndarray.sum</code>, which takes the sum of all the elements on an axis. If we have an array (5, 3), we can use the <code class="literal">ndarray.sum</code> method, as follows, to add elements on the first axis, the second axis, or over all the elements of the array:</p><div><pre class="programlisting">In [64]: a = np.random.rand(5, 3)
In [65]: a.sum(axis=0)
Out[65]: array([ 2.7454,  2.5517,  2.0303])
In [66]: a.sum(axis=1)
Out[66]: array([ 1.7498,  1.2491,  1.8151,  1.9320,  0.5814])
In [67]: a.sum() # With no argument operates on flattened array
Out[67]: 7.3275</pre></div><p>Notice that by summing the elements over an axis we eliminate that axis. From the previous example, the sum on<a class="indexterm" id="id89"/> the axis 0 produces a (3,) array while the sum on the axis 1 produces a (5,) array.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec08"/>Calculating the Norm</h2></div></div></div><p>We can review the basic concepts<a class="indexterm" id="id90"/> illustrated in this section by calculating the Norm of a set of coordinates. For a two-dimensional vector the norm is defined as:</p><div><pre class="programlisting">norm = sqrt(x^2 + y^2)</pre></div><p>Given an array of 10 coordinates (x, y) we want to find the Norm of each coordinate. We can calculate the norm by taking these steps:</p><div><ol class="orderedlist arabic"><li class="listitem">Square the coordinates: obtaining an array which contains <code class="literal">(x**2, y**2)</code> elements.</li><li class="listitem">Sum those using <code class="literal">numpy.sum</code> over the last axis.</li><li class="listitem">Take the square root, element-wise, using <code class="literal">numpy.sqrt</code>.</li></ol></div><p>The final expression can be compressed in a single line:</p><div><pre class="programlisting">In [68]: r_i = np.random.rand(10, 2)
In [69]: norm = np.sqrt((r_i ** 2).sum(axis=1))
In [70]: print(norm)
[ 0.7314  0.9050  0.5063  0.2553  0.0778   0.91431.3245  0.9486  1.010   1.0212]</pre></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec22"/>Rewriting the particle simulator in NumPy</h1></div></div></div><p>In this section, we will <a class="indexterm" id="id91"/>optimize our particle simulator by rewriting some parts of it in NumPy. From the profiling we did in <a class="link" href="ch01.html" title="Chapter 1. Benchmarking and Profiling">Chapter 1</a>, <em>Benchmarking and Profiling</em>, the slowest<a class="indexterm" id="id92"/> part of our program is the following loop contained in the <code class="literal">ParticleSimulator.evolve</code> method:</p><div><pre class="programlisting">for i in range(nsteps):
  for p in self.particles:

    norm = (p.x**2 + p.y**2)**0.5
    v_x = (-p.y)/norm
    v_y = p.x/norm

    d_x = timestep * p.ang_speed * v_x
    d_y = timestep * p.ang_speed * v_y

    p.x += d_x
    p.y += d_y</pre></div><p>We may notice that the body of the loop acts solely on the current particle. If we had an array containing the particle positions <a class="indexterm" id="id93"/>and angular speed, we could rewrite the loop using a broadcasted operation. In contrast, the loop over the time steps depends on the previous step and cannot be<a class="indexterm" id="id94"/> treated in a parallel fashion.</p><p>It's natural then, to store all the array coordinates in an array of shape (nparticles, 2) and the angular speed in an array of shape (nparticles,). We'll call those arrays <code class="literal">r_i</code> and <code class="literal">ang_speed_i</code> and initialize them using the following code:</p><div><pre class="programlisting">r_i = np.array([[p.x, p.y] for p in self.particles])
ang_speed_i = np.array([p.ang_speed for p in self.particles])</pre></div><p>The velocity direction, perpendicular to the vector (x, y), was defined as:</p><div><pre class="programlisting">v_x = -y / norm
v_y = x / norm</pre></div><p>The Norm can be calculated using the strategy illustrated in the <em>Calculating the Norm</em> section under the <em>Getting Started with NumPy</em> heading. The final expression is shown in the following line of code:</p><div><pre class="programlisting">norm_i = ((r_i ** 2).sum(axis=1))**0.5</pre></div><p>For the components (-y, x) we need first to swap the x and y columns in <code class="literal">r_i</code> and then multiply the first column by -1, as shown in the following code:</p><div><pre class="programlisting">v_i = r_i[:, [1, 0]] / norm_i
v_i[:, 0] *= -1</pre></div><p>To calculate the displacement we need to compute the product of <code class="literal">v_i</code>, <code class="literal">ang_speed_i</code>, and <code class="literal">timestep</code>. Since <code class="literal">ang_speed_i</code> is of shape (nparticles,) it needs a new axis in order to operate with <code class="literal">v_i</code> of shape (nparticles, 2). We will do that using <code class="literal">numpy.newaxis</code> constant as follows:</p><div><pre class="programlisting">d_i = timestep * ang_speed_i[:, np.newaxis] * v_i
r_i += d_i</pre></div><p>Outside the loop, we have to update the particle instances with the new coordinates x and y as follows:</p><div><pre class="programlisting">for i, p in enumerate(self.particles):
  p.x, p.y = r_i[i]</pre></div><p>To summarize, we will implement a method called <code class="literal">ParticleSimulator.evolve_numpy</code> and benchmark it <a class="indexterm" id="id95"/>against the pure Python version, renamed as <code class="literal">ParticleSimulator.evolve_python</code>. The complete <code class="literal">ParticleSimulator.evolve_numpy</code> method is shown in the following code:</p><div><pre class="programlisting">def evolve_numpy(self, dt):
  timestep = 0.00001
  nsteps = int(dt/timestep)

  r_i = np.array([[p.x, p.y] for p in self.particles])
  ang_speed_i = np.array([p.ang_speed for p in self.particles])

  for i in range(nsteps):

    norm_i = np.sqrt((r_i ** 2).sum(axis=1))
    v_i = r_i[:, [1, 0]]
    v_i[:, 0] *= -1
    v_i /= norm_i[:, np.newaxis]
    d_i = timestep * ang_speed_i[:, np.newaxis] * v_i
    r_i += d_i

    for i, p in enumerate(self.particles):
      p.x, p.y = r_i[i]</pre></div><p>We also update the <a class="indexterm" id="id96"/>benchmark to conveniently change the number of particles and the simulation method as follows:</p><div><pre class="programlisting">def benchmark(npart=100, method='python'):
  particles = [Particle(uniform(-1.0, 1.0),uniform(-1.0, 1.0),uniform(-1.0, 1.0))for i in range(npart)]

  simulator = ParticleSimulator(particles)

  if method=='python':
    simulator.evolve_python(0.1)

  elif method == 'numpy':
    simulator.evolve_numpy(0.1)</pre></div><p>We can run the updated benchmark in an IPython session as follows:</p><div><pre class="programlisting">In [1]: from simul import benchmark
In [2]: %timeit benchmark(100, 'python')
1 loops, best of 3: 614 ms per loop
In [3]: %timeit benchmark(100, 'numpy')
1 loops, best of 3: 415 ms per loop</pre></div><p>We have some improvement but it doesn't look like a huge speed boost. The power of NumPy is revealed<a class="indexterm" id="id97"/> when handling big arrays. If we increase the number of particles, we will notice a more significant performance boost. We can re-run the benchmark with a higher number of particles using the following code:</p><div><pre class="programlisting">In [4]: %timeit benchmark(1000, 'python')
1 loops, best of 3: 6.13 s per loop
In [5]: %timeit benchmark(1000, 'numpy')
1 loops, best of 3: 852 ms per loop</pre></div><p>The plot in the following figure<a class="indexterm" id="id98"/> was produced by running the benchmark with different particle numbers:</p><div><img alt="Rewriting the particle simulator in NumPy" src="img/8458OS_02_03.jpg"/></div><p>The plot shows that both implementations scale linearly with the particle size, but the runtime in the pure Python version (denoted with diamonds) grows much faster than the NumPy version (denoted with circles); at greater sizes we have a greater<a class="indexterm" id="id99"/> NumPy advantage. In general, when <a class="indexterm" id="id100"/>using NumPy you should try to pack things into large arrays and group the calculations by using the broadcasting feature.</p></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec23"/>Reaching optimal performance with numexpr</h1></div></div></div><p>When handling complex expressions, NumPy stores intermediate results in the memory. David M. Cooke wrote a <a class="indexterm" id="id101"/>package called <code class="literal">numexpr</code> which optimizes and compiles array expressions on-the-fly. It works by optimizing the usage of the CPU cache and by taking advantage of multiple processors.</p><p>Its usage is generally straightforward<a class="indexterm" id="id102"/> and is based on a single function—<code class="literal">numexpr.evaluate</code>. The function takes a string containing an array expression as its first argument. The syntax is basically identical to that of NumPy. For example, we can calculate a simple <code class="literal">a + b * c</code> expression in the following way:</p><div><pre class="programlisting">a = np.random.rand(10000)
b = np.random.rand(10000)
c = np.random.rand(10000)
d = ne.evaluate('a + b * c')</pre></div><p>The <code class="literal">numexpr</code> package increases the performances in almost all cases, but to achieve a substantial advantage you should use it with large arrays. An application that involves a large array is the calculation of a <em>distance matrix</em>. In a particle system, a distance matrix contains all the possible distances between the particles. To calculate it, we should first calculate all the vectors connecting any two particles (i, j) defined as follows:</p><div><pre class="programlisting">x_ij = x_j - x_i
y_ij = y_i - y_j</pre></div><p>Then, we calculate the length of this vector by taking its Norm, as in the following code:</p><div><pre class="programlisting">d_ij = sqrt(x_ij**2 + y_ij**2)</pre></div><p>We can write this in NumPy by employing the usual broadcasting rules (the operation is similar to the outer product):</p><div><pre class="programlisting">r = np.random.rand(10000, 2)
r_i = r[:, np.newaxis]
r_j = r[np.newaxis, :]
r_ij = r_j – r_i</pre></div><p>Finally, we calculate the Norm over the last axis using the following line of code:</p><div><pre class="programlisting">d_ij = np.sqrt((r_ij ** 2).sum(axis=2))</pre></div><p>Rewriting the same expression using the <code class="literal">numexpr</code> syntax is extremely easy. The <code class="literal">numexpr</code> package <a class="indexterm" id="id103"/>doesn't support slicing in its array expression, therefore we first need to prepare the operands for broadcasting by adding an extra dimension as follows:</p><div><pre class="programlisting">r = np.random(10000, 2)
r_i = r[:, np.newaxis]
r_j = r[np.newaxis, :]</pre></div><p>At that point, we should try to pack as many operations as possible in a single expression to allow a significant optimization.</p><p>Most of the NumPy mathematical functions are also available in <code class="literal">numexpr</code>; however, there is a limitation. <a class="indexterm" id="id104"/>The reduction operations—the ones which reduce an axis, such as sum—have to happen last. So, we have to first calculate the sum, step out of <code class="literal">numexpr</code>, and calculate the square root in another expression. The <code class="literal">numexpr</code> code for those operations is as follows:</p><div><pre class="programlisting">d_ij = ne.evaluate('sum((r_j – r_i)**2, 2)')
d_ij = ne.evaluate('sqrt(d_ij)')</pre></div><p>The <code class="literal">numexpr</code> compiler will optimize memory usage by avoiding the storage of intermediate results and by taking advantage of multiple processors. In the <code class="literal">distance_matrix.py</code> file you will find two functions that implement the two versions of the distance matrix calculation: <code class="literal">distance_matrix_numpy</code> and <code class="literal">distance_matrix_numexpr</code>. We can import and benchmark them as follows:</p><div><pre class="programlisting">from distance_matrix import (distance_matrix_numpy,
                             distance_matrix_numexpr)
%timeit distance_matrix_numpy(10000)
1 loops, best of 3: 3.56 s per loop
%timeit distance_matrix_numexpr(10000)
1 loops, best of 3: 858 ms per loop</pre></div><p>By simply copying the expressions using <code class="literal">numexpr</code> we were able to obtain a 4.5x increase in performance in a real-world scenario over standard NumPy. The <code class="literal">numexpr</code> package can be used every time you need to optimize a NumPy expression that involves large arrays and complex operations, and you can do so with minimal changes in the code.</p></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec24"/>Summary</h1></div></div></div><p>In this chapter, we learned how to manipulate NumPy arrays and how to write fast mathematical expressions using array broadcasting. This knowledge will help you to design better programs while obtaining massive performance gains. We also introduced the <code class="literal">numexpr</code> library to further increase the speed of our calculations with a minimal amount of effort.</p><p>NumPy works very well when handling independent sets of inputs, but it's not suitable when the expressions grow complex and cannot be split in element-wise operations. In such cases, we can leverage Python capabilities as a glue language by interfacing it with C using the Cython package.</p></div></body></html>