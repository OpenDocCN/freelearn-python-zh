<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Multithreading versus Multiprocessing</h1></div></div></div><p>When it comes to optimizing code, concurrency and parallelism are two topics that are rarely left out of the conversation. However, in the case of Python these are topics that are normally used to criticize the language. Critics normally blame the difficulty of using these mechanics versus the actual benefit they bring to the table (which, in some instances, is nonexistent).</p><p>In this chapter, we will see that the critics are right some of the time and wrong in other cases. Just like with most tools, these mechanics require certain conditions to work for the developer, instead of working against them. During our tour of the internals of how we can achieve parallelism in Python and on which occasions it is actually worth it, we'll discuss two specific topics:</p><div><ol class="orderedlist arabic"><li class="listitem"><strong>Multithreading</strong>: This is <a id="id262" class="indexterm"/>the most classical approach in trying to achieve true parallelism. Other languages such as C++ and Java provide this feature as well.</li><li class="listitem"><strong>Multiprocessing</strong>: Although <a id="id263" class="indexterm"/>not as common and with some potentially difficult problems to solve, we'll discuss this feature as a valid alternative to multithreading.</li></ol></div><p>After reading this chapter, you'll fully understand the difference between Multithreading and Multiprocessing. Moreover, you will also understand what a <strong>Global Interpreter Lock</strong> (<strong>GIL</strong>) is, and <a id="id264" class="indexterm"/>how it will affect your decision when trying to pick the right parallelism technique.</p><div><div><div><div><h1 class="title"><a id="ch05lvl1sec29"/>Parallelism versus concurrency</h1></div></div></div><p>These two <a id="id265" class="indexterm"/>terms are often used together and even interchangeably, but they are technically two different things. On one side, we have parallelism, which happens when two or more processes can run at the exact same time. This can happen, for instance, in multicore systems, where each process runs on a different processor.</p><p>On the other hand, concurrency happens when two or more processes try to run at the same time on top of the same processor. This is usually solved by techniques such as time slicing. However, these techniques do not execute in a truly parallel fashion. It just looks parallel to observers because of the speed at which the processor switches between tasks.</p><p>The following <a id="id266" class="indexterm"/>diagram tries to illustrate this:</p><div><img src="img/B02088_05_01.jpg" alt="Parallelism versus concurrency"/></div><p>Concurrency, for instance, is a technique used by all modern operating systems. This is because irrespective of the number of processors a computer has, the system alone will probably need to have more processes running at the same time, let alone anything the user might want to do. So, to solve this, the operative system will take care of scheduling time with the processor for each process that requires it. Then, it'll switch context between them, giving each one a slice of time.</p><p>Now, with this in mind, how can we achieve either parallelism or concurrency in our Python programs? This is where multithreading and multiprocessing come into play.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec46"/>Multithreading</h2></div></div></div><p>Multithreading is the <a id="id267" class="indexterm"/>ability of a program to run multiple threads within the context of the same program. These threads share the process's resources and allow multiple actions to run in the concurrent mode (for single processor systems) and in the parallel mode (for multicore systems).</p><p>Structuring your <a id="id268" class="indexterm"/>program to utilize these threads is not an easy task. However, it comes with some very interesting benefits:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Responsiveness</strong>: In single-threaded programs, executing a long running task might cause the program to appear to freeze. Thanks to multithreading and by moving such code into a worker thread, the program can remain responsive while concurrently executing the long running task.</li><li class="listitem" style="list-style-type: disc"><strong>Faster execution</strong>: In multicore processors or multiprocessor systems, multithreading can be used to improve the program's performance by achieving true parallelism.</li><li class="listitem" style="list-style-type: disc"><strong>Lower resource consumption</strong>: Using threads, a program can serve many requests using the resources from the original process.</li><li class="listitem" style="list-style-type: disc"><strong>Simplified sharing and communication</strong>: Since threads already share the same resources and memory space, communication between them is much simpler than interprocess communication.</li><li class="listitem" style="list-style-type: disc"><strong>Parallelization</strong>: Multicore or multiprocessor systems can be used to leverage multithreading <a id="id269" class="indexterm"/>and run each thread independently. <strong>Compute Unified Device Architecture</strong> (<strong>CUDA</strong>) from Nvidia (<a class="ulink" href="http://www.nvidia.com/object/cuda_home_new.html">http://www.nvidia.com/object/cuda_home_new.html</a>) or OpenCL from <a id="id270" class="indexterm"/>Khronos Group (<a class="ulink" href="https://www.khronos.org/opencl/">https://www.khronos.org/opencl/</a>) are GPU-computing environments that utilize from dozens to hundreds of processors to run tasks in parallel.</li></ul></div><p>There are also some <a id="id271" class="indexterm"/>drawbacks of multithreading:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Thread synchronization</strong>: Since threads can potentially work on the same data, you will need to implement some sort of mechanics to prevent race conditions (causing corrupted data reads).</li><li class="listitem" style="list-style-type: disc"><strong>Crash due to problematic thread</strong>: Although it might seem independent, a single problematic thread acting up and performing an invalid action can crash the entire process.</li><li class="listitem" style="list-style-type: disc"><strong>Deadlocks</strong>: This is a common problem associated with working with threads. Normally, when a thread needs a resource, it will lock it until it is done with it. A deadlock occurs when one thread enters a wait state, waiting for a second thread to release its resources but the second thread is, in turn, waiting for the first one to release its locked ones.</li></ul></div><p>Normally, this technique should be enough to achieve parallelism on multiprocessor systems. However, the <a id="id272" class="indexterm"/>official version of Python (CPython) has a limitation called GIL. This GIL prevents multiple native threads from running Python's bytecode at once, which effectively trumps parallelism. If you have a four-processor system, your code would not run at 400 percent. Instead, it would just run at 100 percent or a bit slower actually, because of the extra overhead from threading.</p><div><div><h3 class="title"><a id="note16"/>Note</h3><p>Note that the GIL is not an invention only of Python (or CPython). Other programming languages also have a GIL, such as Ruby's official implementation Ruby MRI or <a id="id273" class="indexterm"/>even OCaml (<a class="ulink" href="https://ocaml.org/">https://ocaml.org/</a>).</p></div></div><p>A GIL is necessary because the memory management in CPython is not thread safe. So, by forcing everything to run serially, it makes sure that nothing corrupts the memory. It is also faster for single-threaded programs and simplifies the creation of C extensions, because they don't have to take multithreading into account.</p><p>There are, however, some ways around the GIL. For instance, since it only prevents threads from running Python's bytecode at the same time, you could potentially code your tasks in C and have Python just as a wrapper for that code. The GIL would not stop the C code from running all threads concurrently in this case.</p><p>Another example where the GIL will not affect the performance would be a network server, which spends most of its time reading packets off the network. In this case, the added concurrency will allow more packets to be serviced, even if there is no real parallelism. This effectively boosts the performance of our program (it can serve a lot more clients per second), but it does not affect its speed, as every task takes the same amount of time</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec05"/>Threads</h3></div></div></div><p>Now, let's talk a bit <a id="id274" class="indexterm"/>about threads in Python in order to understand how to use them. They are composed of a beginning, an execution sequence, and a conclusion. There is also an instruction pointer, which keeps track of where a thread is currently running within the thread's context.</p><p>That pointer can be pre-empted or interrupted in order to stop the thread. Alternatively, it can also be put on hold temporarily. This basically means putting the thread to sleep.</p><p>In order to work with <a id="id275" class="indexterm"/>threads in Python, we have the following two options:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>The thread module</strong>: This <a id="id276" class="indexterm"/>provides some limited ability to work with threads. It's simple to use, and for small tasks, it adds little overhead.</li><li class="listitem" style="list-style-type: disc"><strong>The threading module</strong>: This is newer and included in Python since version 2.4. It provides a <a id="id277" class="indexterm"/>more powerful and higher level support for threads.</li></ul></div><div><div><div><div><h4 class="title"><a id="ch05lvl4sec11"/>Creating a thread with the thread module</h4></div></div></div><p>Although we'll <a id="id278" class="indexterm"/>focus on the threading module, we'll <a id="id279" class="indexterm"/>quickly show an example of how to use this module for the simpler times, when not a lot of work is required from your script.</p><p>The thread <a id="id280" class="indexterm"/>module (<a class="ulink" href="https://docs.python.org/2/library/thread.html">https://docs.python.org/2/library/thread.html</a>) provides the <code class="literal">start_new_thread</code> method. We can pass it in the following parameters:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We can pass it in a function that will contain the actual code to run. Once this function returns, the thread will be stopped.</li><li class="listitem" style="list-style-type: disc">We can pass it in a tuple of arguments. This list will be passed to the function.</li><li class="listitem" style="list-style-type: disc">Finally, we can pass it in an optional dictionary of named arguments.</li></ul></div><p>Let's see an example of all the preceding parameters:</p><div><pre class="programlisting">#!/usr/bin/python

import thread
import time

# Prints the time 5 times, once every "delay" seconds
def print_time( threadName, delay):
   count = 0
   while count &lt; 5:
      time.sleep(delay)
      count += 1
      print "%s: %s" % ( threadName, time.ctime(time.time()) )

# Create two threads as follows
try:
   thread.start_new_thread( print_time, ("Thread-1", 2, ) )
   thread.start_new_thread( print_time, ("Thread-2", 4, ) )
except:
   print "Error: unable to start thread"

# We need to keep the program working, otherwise the threads won't live

while True:
   pass</pre></div><p>The preceding code prints the following output:</p><div><img src="img/B02088_05_02.jpg" alt="Creating a thread with the thread module"/></div><p>The preceding code is simple enough, and the output clearly shows how both threads are actually running <a id="id281" class="indexterm"/>concurrently. The interesting thing about this is that in the code, the <code class="literal">print_time</code> function itself has an inside loop. If we were to <a id="id282" class="indexterm"/>run this function twice serially, then it would last <code class="literal">5</code> * delay seconds each time we call it.</p><p>However, using threads and without having to change anything, we're running the loop twice concurrently.</p><p>This module also provides other threading primitives that can come in handy. Here is an example:</p><div><pre class="programlisting">interrupt_main</pre></div><p>This method sends a keyboard interrupt exception to the main thread. This, effectively, is like hitting <em>CTRL</em>+<em>C</em> on your program while running. If not caught, the thread that sent the signal would terminate the program.</p><div><pre class="programlisting">
<strong>exit</strong>
</pre></div><p>This method exits the thread silently. It is a good way to terminate a thread without affecting anything else. Let's assume that we changed our <code class="literal">print_time</code> function into the following lines of code:</p><div><pre class="programlisting">def print_time( threadName, delay):
   count = 0
   while count &lt; 5:
      time.sleep(delay)
      count += 1
      print "%s: %s" % ( threadName, time.ctime(time.time()) )
      if delay == 2 and count == 2:
      thread.exit()</pre></div><p>In this case, the output would be as follows:</p><div><img src="img/B02088_05_03.jpg" alt="Creating a thread with the thread module"/></div><p>The <code class="literal">allocate_lock</code> method returns a lock for the threads to use. The lock will help the developer protect sensitive code and make sure that there are no race conditions during execution.</p><p>The lock objects returned have these three simple methods:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">acquire</code>: This <a id="id283" class="indexterm"/>basically acquires the lock for the current thread. It accepts an optional integer parameter. If <a id="id284" class="indexterm"/>it is zero, the lock would be acquired only if it can be acquired immediately, without waiting. If it's non-zero, the lock would be acquired unconditionally (like when you omit the parameter). This means that if the thread needs to wait to acquire the lock, it would.</li><li class="listitem" style="list-style-type: disc"><code class="literal">release</code>: This will release the lock for the next thread to acquire it.</li><li class="listitem" style="list-style-type: disc"><code class="literal">locked</code>: This would return <code class="literal">TRUE</code> if the lock is acquired by some thread. Otherwise, it would be <code class="literal">FALSE</code>.</li></ul></div><p>Here is a very basic example of how locking can help multithreaded code. The following code increments a global variable using 10 threads. Each one will add one thread. So, by the end, we should have 10 threads in that global variable:</p><div><pre class="programlisting">#!/usr/bin/python

import thread
import time

global_value = 0

def run( threadName ):
   global global_value
   print "%s with value %s" % (threadName, global_value)
   global_value = global_value + 1


for i in range(10):
   thread.start_new_thread( run, ("Thread-" + str(i), ) )

# We need to keep the program working, otherwise the threads won't live
while 1:
   pass</pre></div><p>Here is the output of the preceding code:</p><div><img src="img/B02088_05_04.jpg" alt="Creating a thread with the thread module"/></div><p>Not only are we correctly incrementing the value of the global variable (we only got up to <code class="literal">2</code>), but we are also having issues printing out the strings. In some cases, we have two strings in the same line, when they should each occupy one. This is because when two strings existed in the <a id="id285" class="indexterm"/>same line, both threads tried to print <a id="id286" class="indexterm"/>at the same time. At that time, the current line to print on was the same in both cases.</p><p>The same occurrence repeats for the global value. When threads <code class="literal">1</code>, <code class="literal">3</code>, <code class="literal">6</code>, <code class="literal">8</code>, <code class="literal">4</code>, <code class="literal">2</code>, and <code class="literal">7</code> read the value of the global variable in order to add <code class="literal">1</code>, the value was <code class="literal">0</code> (which is what they each copied to the <code class="literal">local_value</code> variable). We need to make sure that the code that copies the value, increments it, and prints it out is protected (inside a lock) so that no two threads can run it at the same time. To accomplish this, we'll use two methods for the Lock object: acquire and release.</p><p>Use the following lines of code:</p><div><pre class="programlisting">#!/usr/bin/python

import thread
import time

global_value = 0

def run( threadName, lock ):
   global global_value
   lock.acquire()
   local_copy = global_value
   print "%s with value %s" % (threadName, local_copy)
   global_value = local_copy + 1
   lock.release()

lock = thread.allocate_lock()

for i in range(10):
   thread.start_new_thread( run, ("Thread-" + str(i), lock) )

# We need to keep the program working, otherwise the threads won't live
while 1:
   pass</pre></div><p>Now, the output <a id="id287" class="indexterm"/>makes more sense:</p><div><img src="img/B02088_05_05.jpg" alt="Creating a thread with the thread module"/></div><p>The output now makes more sense, the format got fixed, and we successfully incremented the value <a id="id288" class="indexterm"/>of our variable. Both fixes are due to the locking mechanics. Regarding the code, to increment the value of <code class="literal">global_value</code>, the lock is preventing other threads (those which have not yet acquired the lock) from executing that part of the code (reading its value into a local variable and incrementing it). So, while the lock is active, only the thread that acquired it will be able to run those lines. After the lock has been released, the next thread in line will do the same. The preceding line of code returns the current threads identified:</p><div><pre class="programlisting">get_ident</pre></div><p>This is a non-zero integer with no direct meaning other than identifying the current thread between the lists of active ones. This number can be recycled after a thread dies or exits, so it is not unique during the lifetime of the program. The following code sets or returns the thread stack size used when creating new threads:</p><div><pre class="programlisting">stack_size</pre></div><p>This supports an optional argument ("this" being the size to set for the stack). This size must either be 0 or at least 32.768 (32 Kb). Depending on the system, there might be other restrictions to the number or even to setting the stack size. So, check with your OS's manual before <a id="id289" class="indexterm"/>trying to use this method.</p><div><div><h3 class="title"><a id="note17"/>Note</h3><p>Although it is not the target version of this book, in Python 3, this module has been renamed to <code class="literal">_thread</code>.</p></div></div></div><div><div><div><div><h4 class="title"><a id="ch05lvl4sec12"/>Working with the threading module</h4></div></div></div><p>This is the <a id="id290" class="indexterm"/>current and recommended way to work with threads in Python. This module provides a better and higher level interface for that. It also adds complexity to our code, since the simplicity of the <code class="literal">_thread</code> module will not be available now.</p><p>For this case, we can loosely quote Uncle Ben and say:</p><div><blockquote class="blockquote"><p><em>With great power comes great complexity.</em></p></blockquote></div><p>Jokes apart, the <code class="literal">threading</code> module encapsulates the concept of thread inside a class, which we're required to instantiate to be able to use.</p><p>We can create a <a id="id291" class="indexterm"/>subclass of the <code class="literal">Thread</code> class (<a class="ulink" href="https://docs.python.org/2/library/thread.html">https://docs.python.org/2/library/thread.html</a>) provided by the module (this is normally the preferred way). Alternatively, we could even instantiate that class directly if we want to do something very simple. Let's see how the preceding example would translate using the <code class="literal">threading</code> module:</p><div><pre class="programlisting">#!/usr/bin/python

import threading

global_value = 0

def run( threadName, lock ):
   global global_value
   lock.acquire()
   local_copy = global_value
   print "%s with value %s" % (threadName, local_copy)
   global_value = local_copy + 1
   lock.release()

lock = threading.Lock()

for i in range(10):
   t = threading.Thread( target=run, args=("Thread-" + str(i), lock) )
   t.start()</pre></div><p>For more complex things, we might want to create our own thread classes in order to better encapsulate its behavior.</p><p>When using the subclass approach, there are a few things you need to take into account when writing your own classes:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">They <a id="id292" class="indexterm"/>need to extend the <code class="literal">threading.Thread</code> class</li><li class="listitem" style="list-style-type: disc">They need to overwrite the <code class="literal">run</code> method and, optionally, the <code class="literal">__init__</code> method</li><li class="listitem" style="list-style-type: disc">If you overwrite the constructor, make sure to call the parent's class constructor (<code class="literal">Thread.__init__</code>) as the first action you take</li><li class="listitem" style="list-style-type: disc">The thread will stop when the <code class="literal">run</code> method stops or throws an unhandled exception, so plan your method with this in mind</li><li class="listitem" style="list-style-type: disc">You can name your thread with the <code class="literal">name</code> argument on its constructor method</li></ul></div><p>Although you'll have to overwrite the <code class="literal">run</code> method, which will contain the main logic of the thread, you will not be in control of when that method is called. Instead, you will call the <code class="literal">start</code> method, which, in turn, will create a new thread and call the <code class="literal">run</code> method with that thread as context.</p><p>Let's now look at a simple example of a very common pitfall of working with threads:</p><div><pre class="programlisting">import threading
import time


class MyThread(threading.Thread):

  def __init__(self, count):
    threading.Thread.__init__(self)
    self.total = count

  def run(self):

    for i in range(self.total):
      time.sleep(1)
      print "Thread: %s - %s" % (self.name, i)


t = MyThread(4)
t2 = MyThread(3)

t.start()
t2.start()

print "This program has finished"</pre></div><p>The output of that code is as follows:</p><div><img src="img/B02088_05_06.jpg" alt="Working with the threading module"/></div><p>As you can see highlighted in the preceding screenshot, the program is sending the exit message before <a id="id293" class="indexterm"/>anything else. In this case, it's not a big issue. However, it would be a problem if we had something like this:</p><div><pre class="programlisting">#....
f = open("output-file.txt", "w+")
t = MyThread(4, f)
t2 = MyThread(3, f)

t.start()
t2.start()
f.close() #close the file handler
print "This program has finished"</pre></div><div><div><h3 class="title"><a id="note18"/>Note</h3><p>Note that the preceding code will fail, because it will close the file handler before any thread tries to use it in any way. If we want to avoid this type of issue, we need to use the <code class="literal">join</code> method, which will halt the calling thread until the target thread has completed execution.</p></div></div><p>In our case, if we use the <code class="literal">join</code> method from the main thread, it would make sure that the program does not continue with the main chain of commands until both threads complete execution. We need to make sure we use the <code class="literal">join</code> method on the threads after both have started. Otherwise, we could end up running them serially:</p><div><pre class="programlisting">#...
t.start()
t2.start()
#both threads are working, let's stop the main thread
t.join() 
t2.join()
f.close() #now that both threads have finished, lets close the file handler
print "This program has finished"</pre></div><p>This method also accepts an optional argument: a timeout (a <code class="literal">float</code> or <code class="literal">None</code>) in seconds. However, the <code class="literal">join</code> method always returns <code class="literal">None</code>. So, to find out whether the operation indeed timed out, we need to check whether the thread is still alive (with the <code class="literal">isAlive</code> method) after the <code class="literal">join</code> method returns. If the thread is alive, then the operation timed out.</p><p>Let's now see another example of a simple script to check the status code of a list of sites. This script requires <a id="id294" class="indexterm"/>just a few lines of code to iterate over the list and collect the status code returned:</p><div><pre class="programlisting">import urllib2

sites = [
  "http://www.google.com",
  "http://www.bing.com",
  "http://stackoverflow.com",
  "http://facebook.com",
  "http://twitter.com"
]

def check_http_status(url):
  return urllib2.urlopen(url).getcode()


http_status = {}
for url in sites:
  http_status[url] = check_http_status(url)


for  url in http_status#:
  print "%s: %s" % (url, http_status[url])</pre></div><p>If you run the preceding code with the time command-line tool on Linux, you could also get the time it takes to execute:</p><div><pre class="programlisting">
<strong>$time python non_threading_httpstatus.py</strong>
</pre></div><p>The output is as follows:</p><div><img src="img/B02088_05_07.jpg" alt="Working with the threading module"/></div><p>Now, looking at the code and with what we've seen so far, a clear optimization would be to turn the IO-bound function (<code class="literal">check_http_status</code>) into a thread. This way, we can concurrently check the <a id="id295" class="indexterm"/>status for all sites, instead of waiting for each request to finish before processing the next one:</p><div><pre class="programlisting">import urllib2
import threading


sites = [
  "http://www.google.com",
  "http://www.bing.com",
  "http://stackoverflow.com",
  "http://facebook.com",
  "http://twitter.com"
]

class HTTPStatusChecker(threading.Thread):

  def __init__(self, url):
    threading.Thread.__init__(self)
    self.url = url
    self.status = None

  def getURL(self):
    return self.url

  def getStatus(self):
    return self.status

  def run(self):
    self.status = urllib2.urlopen(self.url).getcode()


threads = []
for url in sites:
  t = HTTPStatusChecker(url)
  t.start() #start the thread
  threads.append(t) 


#let the main thread join the others, so we can print their result after all of them have finished.
for t in threads:
  t.join()

for  t in threads:
  print "%s: %s" % (t.url, t.status)</pre></div><p>Running the new script with time will produce the following result:</p><div><pre class="programlisting">
<strong>$time python threading_httpstatus.py</strong>
</pre></div><p>We will get the <a id="id296" class="indexterm"/>following output:</p><div><img src="img/B02088_05_08.jpg" alt="Working with the threading module"/></div><p>Clearly, the threaded alternative is faster. In our case, it is almost three times faster, which is an amazing improvement.</p></div><div><div><div><div><h4 class="title"><a id="ch05lvl4sec13"/>Interthread communication with events</h4></div></div></div><p>Although threads are normally thought of as individual or parallel workers, sometimes, it is useful to allow them to communicate with each other.</p><p>To achieve this, the <a id="id297" class="indexterm"/>threading module provides the event construct (<a class="ulink" href="https://docs.python.org/2/library/threading.html#event-objects">https://docs.python.org/2/library/threading.html#event-objects</a>). It contains an internal flag, and caller threads can either use <code class="literal">set()</code> or <code class="literal">clear()</code>.</p><p>The <code class="literal">Event</code> class <a id="id298" class="indexterm"/>has a very simple interface. Here are the methods provided within the class:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">is_set</code>: this would return <code class="literal">True</code> if the internal flag of the event is set.</li><li class="listitem" style="list-style-type: disc"><code class="literal">set</code>: this sets the internal flag to <code class="literal">True</code>. It awakens all threads waiting for this flag to be set. Threads calling <code class="literal">wait()</code> will no longer be blocked.</li><li class="listitem" style="list-style-type: disc"><code class="literal">clear</code>: this resets the internal flag. Any thread calling the <code class="literal">wait()</code> method will become blocked until <code class="literal">set()</code> is called again.</li><li class="listitem" style="list-style-type: disc"><code class="literal">wait</code>: this blocks the calling thread until the internal flag of the event is set. This method accepts an optional argument for a timeout. If it is specified and different from none, then the thread would be blocked only by that timeout.</li></ul></div><p>Let's see a simple example of using events to communicate between two threads so that they can take turns printing out to a standard output. Both threads will share the same event object. One will set it on every iteration of the <code class="literal">while</code> loop, and the other would clear it if it's set. On every action (<code class="literal">set</code> or <code class="literal">clear</code>), they'll print the right letter:</p><div><pre class="programlisting">import threading
import time


class ThreadA(threading.Thread):

  def __init__(self, event):
    threading.Thread.__init__(self)
    self.event = event


  def run(self):
    count = 0
    while count &lt; 5:
      time.sleep(1)
      if self.event.is_set():
        print "A"
        self.event.clear()
      count += 1

class ThreadB(threading.Thread):

  def __init__(self, evnt):
    threading.Thread.__init__(self)
    self.event = evnt


  def run(self):
    count = 0
    while count &lt; 5:
      time.sleep(1)
      if not self.event.is_set():
        print "B"
        self.event.set()
      count += 1


event = threading.Event()

ta = ThreadA(event)
tb = ThreadB(event)

ta.start()
tb.start()</pre></div><p>In conclusion, the <a id="id299" class="indexterm"/>following table shows when to use multithreading and when not to:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Use threads</p>
</th><th style="text-align: left" valign="bottom">
<p>Don't use threads</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>For heavy IO-bound scripts </p>
</td><td style="text-align: left" valign="top">
<p>To optimize scripts that are heavily CPU bound</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>When parallelism can be replaced by concurrency</p>
</td><td style="text-align: left" valign="top">
<p>For programs that must take advantage of multicore systems</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>For GUI development</p>
</td><td style="text-align: left" valign="top"> </td></tr></tbody></table></div></div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec47"/>Multiprocessing</h2></div></div></div><p>Multithreading in <a id="id300" class="indexterm"/>Python fails to achieve real parallelism, thanks to the GIL, as we saw earlier. Thus, some types of applications will not see a real benefit from using this module.</p><p>Instead, Python provides an alternative to multithreading called multiprocessing. In multiprocessing, threads are turned into individual subprocesses. Each one will run with its own GIL (which means there are no limitations on the number of parallel Python processes that can run at the same time).</p><p>To clarify, threads are all part of the same process, and they share the same memory, space, and resources. On the other hand, processes don't share memory space with their spawning parent, so it might be more complicated for them to communicate with each other.</p><p>This approach comes with advantages and disadvantages over the multithreading alternative:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Advantages</p>
</th><th style="text-align: left" valign="bottom">
<p>Disadvantages</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Takes <a id="id301" class="indexterm"/>advantage of multicore systems</p>
</td><td style="text-align: left" valign="top">
<p>Larger <a id="id302" class="indexterm"/>memory footprint</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Separate memory space removes race conditions from the equation</p>
</td><td style="text-align: left" valign="top">
<p>Harder to share mutable data between processes </p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Child processes are easily interruptible (killable)</p>
</td><td style="text-align: left" valign="top">
<p>
<strong>Interprocess communication</strong> (<strong>IPC</strong>) is harder than with threads</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Avoids the GIL limitation (although only in the case of CPython)</p>
</td><td style="text-align: left" valign="top"> </td></tr></tbody></table></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec06"/>Multiprocessing with Python</h3></div></div></div><p>The <a id="id303" class="indexterm"/>
<code class="literal">multiprocessing</code> module (<a class="ulink" href="https://docs.python.org/2/library/multiprocessing.html">https://docs.python.org/2/library/multiprocessing.html</a>) provides the <code class="literal">Process</code> class, which, in turn, has an API similar to the <code class="literal">threading.Thread</code> class. So, migrating code <a id="id304" class="indexterm"/>from multithreading to multiprocessing is not as difficult as one might think, because the basic structure of your code would remain the same.</p><p>Let's look at a quick example of how we might structure a multiprocessing script:</p><div><pre class="programlisting">#!/usr/bin/python

import multiprocessing

def run( pname ):
  print pname

for i in range(10):
  p = multiprocessing.Process(target=run, args=("Process-" + str(i), ))
  p.start()
  p.join()</pre></div><p>The preceding code is a basic example, but it shows just how similar to multithreading the code can be.</p><div><div><h3 class="title"><a id="note19"/>Note</h3><p>Note that on Windows systems, you will need to add an extra check to make sure that when the subprocesses include the main code, it would not be executed again. To clarify, the main code should look like this (if you plan to run it on Windows):</p><div><pre class="programlisting">#!/usr/bin/python

import multiprocessing

def run( pname ):
  print pname

<strong>if __name__ == '__main__':</strong>
  for i in range(10):
    p = multiprocessing.Process(target=run, args=("Process-" + str(i), ))
    p.start()
    p.join()</pre></div></div></div><div><div><div><div><h4 class="title"><a id="ch05lvl4sec14"/>Exit status</h4></div></div></div><p>When each process is finished (or terminated), it has an exit code, which is a number representing the result of <a id="id305" class="indexterm"/>the execution. This number might either indicate that the process finished correctly, incorrectly, or that it was terminated by another process.</p><p>To be more precise:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A code equal to <code class="literal">0</code> means there was no problem at all</li><li class="listitem" style="list-style-type: disc">A code higher than <code class="literal">0</code> means the process failed and exited with that code</li><li class="listitem" style="list-style-type: disc">A code lower than <code class="literal">0</code> means it was killed with a <code class="literal">-1</code> * <code class="literal">exit_code</code> signal</li></ul></div><p>The following code shows how to read the exit code and how it is set, depending on the outcome of the task:</p><div><pre class="programlisting">import multiprocessing
import time

def first():
  print "There is no problem here"

def second():
  raise RuntimeError("Error raised!")

def third():
  time.sleep(3)
  print "This process will be terminated"

workers = [ multiprocessing.Process(target=first), multiprocessing.Process(target=second), multiprocessing.Process(target=third)]

for w in workers:
  w.start()

workers[-1].terminate()

for w in workers:
  w.join()

for w in workers:
  print w.exitcode</pre></div><p>The output of this <a id="id306" class="indexterm"/>script is shown in the following screenshot:</p><div><img src="img/B02088_05_09.jpg" alt="Exit status"/></div><p>Notice how the <code class="literal">print</code> property from the third worker is never executed. This is because that process is terminated before the <code class="literal">sleep</code> method finishes. It is also important to note that we're doing two separate <code class="literal">for</code> loops over the three workers: one to start them and the second one to join them using the <code class="literal">join()</code> method. If we were, for instance, to execute the <code class="literal">join()</code> method while starting each subprocess, then the third subprocess would not fail. In fact, it would return an exit code of zero (no problem), because as with multithreading, the <code class="literal">join()</code> method will block the calling process until the target one finishes.</p></div><div><div><div><div><h4 class="title"><a id="ch05lvl4sec15"/>Process pooling</h4></div></div></div><p>This module also <a id="id307" class="indexterm"/>provides the <code class="literal">Pool</code> class (<a class="ulink" href="https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool">https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool</a>), which represents a pool of worker processes that facilitate different ways to execute a set of tasks in subprocesses.</p><p>The main methods provided by this class are:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">apply</code>: This executes a function in a separate subprocess. It also blocks the calling process until the called function returns.</li><li class="listitem" style="list-style-type: disc"><code class="literal">apply_async</code>: This executes a function in a separate subprocess, asynchronously, which means that it'll return immediately. It returns an <code class="literal">ApplyResult</code> object. To get the actual returned value, you need to use the <code class="literal">get()</code> method. This action will be blocked until the asynchronously executed function finishes.</li><li class="listitem" style="list-style-type: disc"><code class="literal">map</code>: This executes a function for a list of values. It is a blocking action, so the returned value is the result of applying the function to each value of the list.</li></ul></div><p>Each one of them <a id="id308" class="indexterm"/>provides a different way of iterating over your data, be it asynchronously, synchronously, or even one by one. It all depends on your needs.</p></div><div><div><div><div><h4 class="title"><a id="ch05lvl4sec16"/>Interprocess communication</h4></div></div></div><p>Now, getting <a id="id309" class="indexterm"/>the processes to communicate with each other is not, as we already mentioned, as easy as with threads. However, Python provides us with several tools to achieve this.</p><p>The <code class="literal">Queue</code> class <a id="id310" class="indexterm"/>provides a thread-safe and process-safe <strong>first in first out</strong> (<strong>FIFO</strong>) (<a class="ulink" href="https://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes">https://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes</a>) mechanism to exchange data. The <code class="literal">Queue</code> class provided by the multiprocessing module is a near clone of <code class="literal">Queue.Queue</code>, so the same API can be used. The following code shows an example of two processes interacting through <code class="literal">Queue</code>:</p><div><pre class="programlisting">from multiprocessing import Queue, Process
import random

def generate(q):
  while True:
    value = random.randrange(10)
    q.put(value)
    print "Value added to queue: %s" % (value)

def reader(q):
  while True:
    value = q.get()
    print "Value from queue: %s" % (value)


queue = Queue()
p1 = Process(target=generate, args=(queue,))
p2 = Process(target=reader, args=(queue,))

p1.start()
p2.start()</pre></div><div><div><div><div><h5 class="title"><a id="ch05lvl5sec01"/>Pipes</h5></div></div></div><p>Pipes provide (<a class="ulink" href="https://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes">https://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes</a>) a bidirectional channel of communication between two processes. The <code class="literal">Pipe()</code> function returns a pair of connection objects, each representing one side of the pipe. Each <a id="id311" class="indexterm"/>connection object has both a <code class="literal">send()</code> and <a id="id312" class="indexterm"/>a <code class="literal">recv()</code> method.</p><p>The following code shows a simple usage for the pipe construct, similar to the preceding Queue example. This <a id="id313" class="indexterm"/>script will create two processes: one that will generate random numbers and send them through the pipe and one that will read the same one and write the numbers to a file:</p><div><pre class="programlisting">from multiprocessing import Pipe, Process
import random

def generate(pipe):
   while True:
    value = random.randrange(10)
    pipe.send(value)
    print "Value sent: %s" % (value)

def reader(pipe):
   f = open("output.txt", "w")
   while True:
     value = pipe.recv()
     f.write(str(value))
     print "."


input_p, output_p = Pipe()
p1 = Process(target=generate, args=(input_p,))
p2 = Process(target=reader, args=(output_p,))

p1.start()
p2.start()</pre></div></div><div><div><div><div><h5 class="title"><a id="ch05lvl5sec02"/>Events</h5></div></div></div><p>They are also <a id="id314" class="indexterm"/>present in the multiprocessing module, and they work in almost a similar way. The developer only needs to keep in mind that event objects can't <a id="id315" class="indexterm"/>be passed into worker functions. If you try to do that, a runtime error will be issued, saying that semaphore objects can only be shared between processes through inheritance. This means that you can't do what is shown in this code:</p><div><pre class="programlisting">from multiprocessing import Process, Event, Pool
import time

event = Event()
event.set()

def worker(i, e):
    if e.is_set():
      time.sleep(0.1)
      print "A - %s" % (time.time())
      e.clear()
    else:
      time.sleep(0.1)
      print "B - %s" % (time.time())
      e.set()

pool = Pool(3)
pool.map(worker, [ (x, event) for x in range(9)])
Instead, you'd have to do something like this:
from multiprocessing import Process, Event, Pool
import time

event = Event()
event.set()

def worker(i):
   if event.is_set():
     time.sleep(0.1)
     print "A - %s" % (time.time())
     event.clear()
   else:
     time.sleep(0.1)
     print "B - %s" % (time.time())
     event.set()

pool = Pool(3)
pool.map(worker, range(9))</pre></div></div></div></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec30"/>Summary</h1></div></div></div><p>Now that we've covered both alternatives, their main characteristics, and their ups and downs, it is really up to the developer to pick one or the other. There is clearly no better one, since they are meant for different scenarios, although they might seem to accomplish the same thing.</p><p>The main take-away from this chapter should be the points mentioned earlier, the main characteristics of each approach, and when each one should be used.</p><p>In the next chapter, we'll continue with the optimization tools. This time, we will look at Cython (an alternative that allows you to compile your Python code on C) and PyPy (an alternative interpreter written in Python that is not bound to the GIL like CPython is).</p></div></body></html>