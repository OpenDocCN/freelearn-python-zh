- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices vs Monolith
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will present and comment on two of the most common architectures
    for complex systems. Monolithic architecture creates a single block where the
    whole system is contained, and is simple to operate. Microservices architecture,
    on the other hand, divides the system into smaller microservices that talk to
    each other, aiming to allow different teams to take ownership of different elements,
    and helping big teams to work in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss when to choose each one, based on its different characteristics.
    We will also go through the teamwork aspect of them, as they have different requirements
    in terms of how the work needs to be structured.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the architecture is not only related to tech, but to a significant
    degree to how communication is structured! Refer to *Chapter 1*, *Introduction
    to Software Architecture*, for a further discussion of Conway's Law.
  prefs: []
  type: TYPE_NORMAL
- en: A common pattern is to migrate from an old monolithic architecture to a microservices
    one. We will talk about the stages involved in such a change.
  prefs: []
  type: TYPE_NORMAL
- en: We will also introduce Docker as a way of containerizing services, something
    very useful when it comes to creating microservices, but that can also be applied
    to monoliths. We will containerize the web application presented in *Chapter 5*,
    *The Twelve-Factor App Methodology*.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will briefly describe how to deploy and operate multiple containers
    using an orchestration tool, and describe the most popular one these days – Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Monolithic architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The microservices architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which architecture to choose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving from a monolith to microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containerizing services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestration and Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start by talking in more depth about monolithic architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Monolithic architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a system is designed organically, the tendency is to generate a single
    unitary block of software that contains the whole functionality of the system.
  prefs: []
  type: TYPE_NORMAL
- en: This is a logical progression. When a software system is designed, it starts
    small, typically with a simple functionality. But, as the software is used, it
    grows in terms of its usage and starts getting requests for new functionality
    to complement the existing ones. Unless there are sufficient resources and planning
    to structure the growth, the path of least resistance will be to keep adding everything
    into the same code structure, with little modularity.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated with low confidence](img/B17580_09_01.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.1: A monolithic application'
  prefs: []
  type: TYPE_NORMAL
- en: This process ensures that all the code and functionality are tied together in
    a single block, hence the name *monolithic architecture*.
  prefs: []
  type: TYPE_NORMAL
- en: And, by extension, software that follows this pattern is called a monolith.
  prefs: []
  type: TYPE_NORMAL
- en: Although this kind of structure is quite common, in general, monolithic structures
    have a better modularity and internal structure. Even if the software is composed
    of a single block, it can be divided logically into different parts, assigning
    different responsibilities to different modules.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in previous chapters we discussed the MVC architecture. This is
    a monolithic architecture. The Models, Views, and Controllers are all under the
    same process, but there is a definitive structure in place that differentiates
    the responsibilities and functions.
  prefs: []
  type: TYPE_NORMAL
- en: Monolithic architecture is not synonymous with a lack of structure.
  prefs: []
  type: TYPE_NORMAL
- en: The defining characteristic of a monolith is that all the calls between modules
    are through *internal* APIs, within the same process. This affords the advantage
    of being very flexible. The strategy for deploying a new version of the monolith
    is also easy. Restarting the process will ensure full deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that a monolithic application can have multiple copies running.
    For example, a monolithic web application can have multiple copies of the same
    software running in parallel, with a load balancer sending requests to all of
    them. A restart, in this case, will be in multiple stages.
  prefs: []
  type: TYPE_NORMAL
- en: The version of the monolith is easy to know, as all the code is part of the
    same structure. The code, if it's under source control, will all be under the
    same repo.
  prefs: []
  type: TYPE_NORMAL
- en: The microservices architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The microservices architecture was developed as an alternative to having a single
    block containing all the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'A system following a microservices architecture is *a collection of loosely
    coupled specialized services that work in unison to provide a comprehensive service*.
    Let''s divide the definition up in order to be clearer:'
  prefs: []
  type: TYPE_NORMAL
- en: A **collection of specialized services**, meaning that there are different and
    well-defined modules
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Loosely coupled**, so each microservice can be independently deployed and
    developed'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That **work in unison**. Each microservice needs to communicate with others
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To **provide a comprehensive service**, meaning that the whole system creates
    a full system that has a clear motive and functionality
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compared with a monolith, instead of grouping the whole software under the same
    process, it uses multiple, separate functional parts (each microservice) that
    communicate through well-defined APIs. These elements can be in different processes
    and typically are moved out from different servers to allow proper scaling of
    the system.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_09_02.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.2: Note that not all microservices will be connected to the storage.
    Each microservice may have its own individual storage'
  prefs: []
  type: TYPE_NORMAL
- en: The defining characteristic is that the calls between different services are
    all through *external* APIs. These APIs act as a clear, defined barrier between
    functionalities. Because of this, microservices architecture requires advanced
    planning and needs to define clearly the differences between components.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, microservices architecture requires a good upfront design to
    be sure that the different elements connect together correctly, as any problem
    that is cross-service will be costly to work with.
  prefs: []
  type: TYPE_NORMAL
- en: A system that follows the microservices architecture doesn't happen organically,
    but it's the result of a plan created beforehand and executed carefully. This
    architecture is not typically started for systems from scratch, but instead, they
    are migrated from a previously existing, successful, monolithic architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Which architecture to choose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There's a tendency to think that a more evolved architecture, like the microservices
    architecture, is better, but that's an oversimplification. Each one has its own
    set of strengths and weaknesses.
  prefs: []
  type: TYPE_NORMAL
- en: The first one is the fact that almost every small application will start as
    a monolithic application. This is because it is the most natural way to start
    a system. Everything is at hand, the number of modules is reduced, and it's an
    easy starting point.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices, on the other hand, require the creation of a plan to divide the
    functionality carefully into different modules. This task may be complicated,
    as some designs may prove inadequate later on.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that no design can be totally future-proof. Any perfectly valid
    architectural decision may prove incorrect a year or two later when changes in
    the system require adjustments. While it is a good question to think about the
    future, trying to cover every possibility is futile. The proper balance between
    designing for the current feature and designing for the future vision of the system
    is a constant challenge in software architecture.
  prefs: []
  type: TYPE_NORMAL
- en: This requires quite a lot of work to be done beforehand, which requires an investment
    in the microservices architecture.
  prefs: []
  type: TYPE_NORMAL
- en: That said, as monoliths grow, they can start presenting problems just through
    the sheer size of the code. The main characteristic of a monolithic architecture
    is that all the code is found together, and it can start presenting a lot of connections
    that can cause developers to be confused. Complexity can be reduced by good practices
    and constant vigilance to ensure good internal structure, but that requires a
    lot of work in place by existing developers to enforce it. When dealing with a
    big and complex system, it may be easier to present clear and strict boundaries
    just by dividing different areas into different processes.
  prefs: []
  type: TYPE_NORMAL
- en: The modules can also require different specific knowledge, making it natural
    to assign different team members to different areas. To create a proper sense
    of ownership of the modules, they can have different opinions in terms of code
    standards, an adequate programming language for the job, ways of performing tasks,
    and so on; for example, a photosystem that has an interface for uploading photos
    and an AI system for categorizing them. While the first module will work as a
    web service, the abilities required for training and handling an AI model to categorize
    the data will be very different, making the module separation natural and productive.
    Both of them in the same code base may generate problems by trying to work at
    the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Another problem of monolithic applications is the inefficient utilization of
    resources, as each deployment of the monolith carries over every copy of every
    module. For example, the RAM required will be determined for the worst-case scenario
    across multiple modules. When there are multiple copies of the monolith, that
    will waste a lot of RAM preparing for worst-case scenarios that will likely be
    rare. Another example is the fact that, if any module requires a connection to
    the database, a new connection will be created, whether that's used or not.
  prefs: []
  type: TYPE_NORMAL
- en: In comparison, using microservices can adjust each service according to its
    own worst-case use case, and independently control the number of replicas for
    each. When viewed as a whole, that can lead to big resource saves in big deployments.
  prefs: []
  type: TYPE_NORMAL
- en: '![Shape'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_09_03.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.3: Notice that using different microservices allows us to reduce RAM
    usage by dividing requests into different microservices, while in a monolithic
    application, the worst-case scenario drives RAM utilization'
  prefs: []
  type: TYPE_NORMAL
- en: Deployments also work very differently between monoliths and microservices.
    As the monolithic application needs to be deployed in a single go, every deployment
    is, effectively, a task for the whole team. If the team is small, creating a new
    deployment and ensuring that the new features are properly coordinated between
    modules and not interfering incorrectly is not very complicated. However, as the
    teams grow bigger, this can present a serious challenge if the code is not strictly
    structured. In particular, a bug in a small part of the system may bring down
    the whole system completely, as any critical error in the monolith affects the
    whole of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Monolith deployments require coordination between modules, meaning that they
    need to work with each other, which normally leads to teams working closely together
    until the feature is ready to be released, and require some sort of supervision
    until the deployment is ready. This is noticeable when several teams are working
    on the same code base, with competing goals, and this blurs the ownership and
    responsibility of deployments.
  prefs: []
  type: TYPE_NORMAL
- en: By comparison, different microservices are deployed independently. The API should
    be stable and backward compatible with older releases, and that's one of the strong
    requisites that need to be enforced. However, the boundaries are very clear, and
    in the event of a critical bug, the worst that can happen is that the particular
    microservice goes down, while other unrelated microservices continue unaffected.
  prefs: []
  type: TYPE_NORMAL
- en: This makes the system work in a "degraded state," as compared to the "all-or-none"
    approach of the monolith. It limits the scope of a catastrophic failure.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, certain microservices may be more critical than others, making them
    worthy of extra attention and care regarding their stability. But, in that case,
    they can be defined as critical in advance, with stricter stability rules enforced.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, in both cases, solid testing techniques can be used to increase the
    quality of the software released.
  prefs: []
  type: TYPE_NORMAL
- en: In comparison with the monolith, microservices can be deployed independently,
    without coordinating closely with other services. This brings independence to
    the teams working on them and allows for faster, continuous deployments that require
    less central coordination.
  prefs: []
  type: TYPE_NORMAL
- en: The keyword here is *less* coordination. Coordination is still required, but
    the objective of a microservices architecture is necessarily that each microservice
    can be independently deployed and owned by a team, so the majority of changes
    can be dictated exclusively by the owner without requiring a process of warning
    other teams.
  prefs: []
  type: TYPE_NORMAL
- en: Monolithic applications, because they communicate with other modules through
    internal operations, mean that they typically can perform these operations much
    faster than through the external APIs. This allows a very high level of interaction
    between modules without paying a significant performance price.
  prefs: []
  type: TYPE_NORMAL
- en: There is an overhead related to the usage of external APIs and communication
    through a network that can produce a noticeable delay, especially if there are
    too many internal requests made to different microservices. Careful consideration
    is required to try to avoid repeating external calls and to limit the number of
    services that can be contacted in a single task.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, the usage of tools to abstract the contact with other microservices
    may produce extra calls that will be absolutely necessary. For example, a task
    to process a document needs to obtain some user information, which requires calling
    a different microservice. The name is required at the start of the document, and
    the email at the end of it. A naïve implementation may produce two requests to
    obtain the information instead of requesting it all in a single go.
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting advantage of microservices is the independence of technical
    requirements. In a monolithic application, problems may arise as a result of requiring
    different versions of libraries for different modules. For example, updating the
    version of Python requires the whole code base to be prepared for that. These
    library updates can be complicated as different modules may have different requirements,
    and one module can effectively mingle with another by requiring an upgrade of
    the version of a certain library that's used by both.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices, on the other hand, contain their own set of technical requirements,
    so there's not this limitation. Because of the external APIs used, different microservices
    can even be programmed in different programming languages. This allows the use
    of specialized tools for different microservices, tailoring each one for each
    purpose and thereby avoiding conflicts.
  prefs: []
  type: TYPE_NORMAL
- en: Just because different microservices can be programmed in different languages
    doesn't mean that they should. Avoid the temptation of using too many programming
    languages in a microservices architecture as this will complicate maintenance
    and make it difficult for a member of a different team to be able to help, thereby
    creating more isolated teams.
  prefs: []
  type: TYPE_NORMAL
- en: Having one or two default languages and frameworks available and then allowing
    special justified cases is a sensible way to proceed.
  prefs: []
  type: TYPE_NORMAL
- en: As we see, most of the characteristics of microservices make it more suited
    for a bigger operation, when the number of developers is high enough that they
    need to be split into different teams and coordination needs to be more explicit.
    The high change of pace in a big application also requires better ways to deploy
    and work independently, in general.
  prefs: []
  type: TYPE_NORMAL
- en: A small team can self-coordinate very well and will be able to work quickly
    and efficiently in a monolith.
  prefs: []
  type: TYPE_NORMAL
- en: This is not to say that a monolith can be very big. Some are. But, in a general
    sense, microservices architecture only makes sense if there are enough developers
    such that different teams are working in the same system and are required to achieve
    a good level of independence between them.
  prefs: []
  type: TYPE_NORMAL
- en: A side note about similar designs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the decision of monolith versus microservices is normally discussed in
    the context of web services, it's not exactly a new idea and it's not the only
    environment where there are similar ideas and structures.
  prefs: []
  type: TYPE_NORMAL
- en: The kernel of an OS can also be monolithic. In this case, a kernel structure
    is called monolithic if it all operates within kernel space. A program running
    in kernel space in a computer can access the whole memory and hardware directly,
    something that is critical for the usage of an OS, while at the same time, this
    is dangerous as it has big security and safety implications. Because the code
    in kernel space works so closely with the hardware, any failure here can result
    in the total failure of the system (a kernel panic). The alternative is to run
    in user space, which is the area where a program only has access to its own data,
    and has to interact explicitly with the OS to retrieve information.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a program in user space that wants to read from a file needs to
    make a call to the OS, and the OS, in kernel space, will access the file, retrieve
    the information, and return it to the requested program, copying to a part of
    the memory where the program can access.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of the monolithic kernel is that it can minimize this movement and
    context switch between different kernel elements, such as libraries or hardware
    drivers.
  prefs: []
  type: TYPE_NORMAL
- en: The alternative to a monolithic kernel is called a microkernel. In a microkernel
    structure, the kernel part is greatly reduced and elements such as filesystems,
    hardware drivers, and network stacks are executed in user space instead of in
    kernel space. This requires these elements to communicate by passing messages
    through the microkernel, which is less efficient.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, it can improve the modularity and security of the elements,
    as any crash in user space can be restarted easily.
  prefs: []
  type: TYPE_NORMAL
- en: There was a famous argument between Andrew S. Tanenbaum and Linus Torvalds about
    what architecture is better, given that Linux was created as a monolithic kernel.
    In the long run, kernels have evolved toward hybrid models, where they take aspects
    of both elements, incorporating microkernel ideas into existing monolithic kernels
    for flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering and analyzing related architectural ideas can help to improve the
    tools at the disposal of a good architect and improve architectural understanding
    and knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: The key factor – team communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A key element of the difference between microservices and monolithic architecture
    is the difference in the communication structure that they support.
  prefs: []
  type: TYPE_NORMAL
- en: If the monolithic application has grown organically from a small project, as
    usually happens, the internal structure can become messy, and requires developers
    with experience in the system who can change and adapt it for any change. In bad
    cases, the code can become very chaotic and be more and more complicated to work
    with.
  prefs: []
  type: TYPE_NORMAL
- en: Increasing the size of the development team becomes complicated, as each engineer
    requires a lot of contextual information, and learning how to navigate the code
    is difficult. The older teammates who have been around can help to train new team
    members, but they'll act as bottlenecks, and mentoring is a slow process that
    has limits. Each new member of the team will require a significant amount of training
    time until they can be productive in fixing bugs and adding new features.
  prefs: []
  type: TYPE_NORMAL
- en: Teams also have a maximum natural size limit. Managing a team with too many
    members, without dividing it into smaller groups, is difficult.
  prefs: []
  type: TYPE_NORMAL
- en: The ideal size of a team depends on a lot of different factors, but between
    5 and 9 is generally considered the ideal size to work efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Teams that are bigger than that tend to self-organize into their own smaller
    groups, losing focus as a unit and creating small information silos where parts
    of the team are not aware of what's going on.
  prefs: []
  type: TYPE_NORMAL
- en: Teams with fewer members create too much overhead in terms of management and
    communication with other teams. They will be able to work faster with a slightly
    bigger size.
  prefs: []
  type: TYPE_NORMAL
- en: If the growing size of the code requires it, this is the time to employ all
    the techniques that we are describing in this book to generate more structure,
    architecting the system. This will involve defining modules with clear responsibilities
    and clear boundaries. This division allows the team to be divided into groups
    and allows them to work at creating ownership and explicit goals for each team.
  prefs: []
  type: TYPE_NORMAL
- en: This allows the teams to work in parallel without too much interference, so
    the extra members can increase the throughput in terms of features. As we commented
    before, clear boundaries will help in defining the work for each team.
  prefs: []
  type: TYPE_NORMAL
- en: In a monolith, however, these limitations are *soft*, as the whole system is
    accessible. Sure, there is a certain discipline in terms of focusing on certain
    areas, and the tendency will be that one team will be able to access everything,
    and will tweak and bend internal APIs.
  prefs: []
  type: TYPE_NORMAL
- en: This characteristic is not necessarily a bad thing, especially on a smaller
    scale. This way of working with a small, focused team can produce fantastic results,
    as they'll be able to adjust quickly all the related parts of the software. The
    drawback is that the members of the team need to be highly experienced and know
    their way around the software, which normally becomes more and more difficult
    over time.
  prefs: []
  type: TYPE_NORMAL
- en: 'When moving to a microservices architecture, the division of work becomes way
    more explicit. The APIs between teams become hard limitations and there is a need
    for more work upfront to communicate between teams. The trade-off is that teams
    are way more independent, as they can:'
  prefs: []
  type: TYPE_NORMAL
- en: Own the microservice completely without other teams coding in the same code
    base
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy independently from other teams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the code base will be smaller, new members of the team will be able to learn
    it quickly and be productive earlier. Because the external APIs to interact with
    other microservices will be explicitly defined, a higher level of abstraction
    will be applied, making it easier to interact.
  prefs: []
  type: TYPE_NORMAL
- en: Note this also means that different teams will know less about the internals
    of other microservices compared with monolithic applications when there's at least
    a superficial knowledge of it. This can create some friction when moving people
    from one team to another.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in the first chapter, Conway's law is something to keep in mind when
    making architectural decisions that affect communication within the organization.
    Let's remember that this software law states that the structure of the software
    will replicate the communication structure of the organization.
  prefs: []
  type: TYPE_NORMAL
- en: A good example of Conway's law is the creation of DevOps practices. The older
    way of dividing work was to have different teams, one related to developing new
    features, and another in charge of deploying and operating the software. The abilities
    required for each task are different, after all.
  prefs: []
  type: TYPE_NORMAL
- en: The risk of this structure is the "I don't know what it is / I don't know where
    it runs" division, which can cause the team responsible for developing new features
    to be unaware of bugs and problems associated with operating the software, while
    the operations team finds changes with little reaction time, and identifies bugs
    without understanding the inside operation of the software.
  prefs: []
  type: TYPE_NORMAL
- en: This division is still in place in many organizations, but the idea behind DevOps
    is that the same team that develops the software is responsible for deploying
    it, thereby creating a virtuous feedback loop where developers are aware of the
    complexities of the deployment and can react and fix bugs in production and improve
    the operation of the software.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this normally involves creating a multi-functional team with people
    who both understand operations and development, though they don't necessarily
    need to be the same. Sometimes, an external team is responsible for creating a
    set of common tools for other teams to use in their operations.
  prefs: []
  type: TYPE_NORMAL
- en: This is a big change, and changing from the older structure to the DevOps one
    involves mixing teams in a way that can be very disruptive for the corporate culture.
    As we've tried to highlight here, this involves people changes, which are slow
    and have a significant amount of pain associated with them. For example, there
    may be a good operations culture where they share their knowledge and have fun
    together, and now they'll need to break up those teams and integrate them with
    new people.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of process is difficult and should be planned carefully, understanding
    both its human and social scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'Communication within the same team is different from the communication between
    different teams. Communicating with other teams is always more difficult and costlier.
    This is probably easy to say, but the implications of it for teamwork are big.
    Examples include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Because APIs to be used externally from the team are going to be used by other
    engineers without the same level of expertise in the internals, it makes sense
    to make them generic and easy to use, as well as creating proper documentation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a new design follows the structure of already existing teams, it will be
    easier to implement than the other way around. Architectural changes that lie
    between teams require organizational changes. Changing the structure of an organization
    is a long and painful process. Anyone who has been involved in a company reorganization
    can attest to that. These organizational changes will be reflected in the software
    naturally, so ideally a plan will be generated to allow for it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two teams working in the same service will create problems because each team
    will try to pull it to their own goals. This is a situation that can happen with
    some common libraries or with "core" microservices that are used by multiple teams.
    Try to enforce clear owners for them to be sure that a single team is in charge
    of any changes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explicit owners establish clarity about who is responsible for changes and new
    features. Even if something is implemented by someone else, the owner should be
    responsible for approving it and giving direction and feedback. They should also
    be prepared to have a long-term vision and handle any technical debt.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Given that different physical locations and time zones naturally impose their
    own communication barrier, they normally are used to set up different teams, describing
    their own structured communication, like the API definition, between time zones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working remotely has increased significantly as a result of the COVID-19 crisis.
    This has also created the need to structure communication differently compared
    with a team working together in the same room. This has developed and improved
    communication skills, which can lead to better ways of organizing work. In any
    case, team division is not only a matter of being physically located in the same
    place but creating the bonds and structure to work as a team.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Communication aspects of development are an important part of the work and should
    not be underestimated. Keep in mind that changes to them are "people changes,"
    which are more difficult to implement than tech changes.
  prefs: []
  type: TYPE_NORMAL
- en: Moving from a monolith to microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A usual case is the need to migrate from an existing monolithic architecture
    to a new microservices one.
  prefs: []
  type: TYPE_NORMAL
- en: The main reason for wanting to implement this change is the size of the system.
    As we've discussed before, the main advantage of a microservice system is the
    creation of multiple independent parts that can be developed in parallel, enabling
    the development to be scaled and the pace increased by allowing more engineers
    to work at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: This is a move that makes sense if the monolith has grown to exceed a manageable
    size and there are enough problems with releases, interfering features, and stepping
    on each other's toes. But, at the same time, it's a very huge and painful transition
    to perform.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges for the migration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While the final result may be much better than a monolithic application that
    shows its age, migrating to a new architecture is a big undertaking. We''ll now
    look at some of the challenges and problems that we can expect in the process:'
  prefs: []
  type: TYPE_NORMAL
- en: Migrating to microservices will require a huge amount of effort, actively changing
    the way the organization operates, and will require a big upfront investment until
    it starts to pay off. The transition time will be painful and will require compromises
    between the speed of migration and the regular operation of the service, as stopping
    the operation completely won't be an option. It will require a good deal of meetings
    and documentation to plan and communicate the migration to everyone. It needs
    to have active support at the executive level to ensure full commitment to get
    it done, with a clear understanding of why it is being done.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also requires a profound cultural change. As we've seen above, the key element
    of microservices is the interaction between teams, which will change significantly
    compared with the way of operating in a monolithic architecture. This will likely
    involve changing teams and changing tools. Teams will have to be stricter in their
    usage and documentation of external APIs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They'll need to be more formal in their interaction with other teams and probably
    take attributions they didn't have before. In general, people don't like change,
    and that could be responded to in the form of resistance by members of some teams.
    Be sure that these elements are taken into account.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Another challenge is the training aspect. New tools will surely be used (we
    will cover Docker and Kubernetes later in this chapter), so some teams will likely
    need to adapt to use them. Managing a cluster of services can be complicated to
    wrap one's head around, and it will likely involve different tools than the ones
    used previously. For example, local developers will likely be very different.
    Learning how to operate and work with containers, if going down that route, will
    take some time. This requires planning and the need to support team members until
    they are comfortable with the new system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A very clear example of this is the extra complexity for debugging a request
    coming into the system, as it can be jumping around different microservices. Previously,
    this request was probably easier to track in the monolith. Understanding how a
    request moves and finding subtle bugs produced by that can be difficult. To be
    certain of fixing this, they will likely need to be replicated and fixed in local
    development, which, as we've seen, will entail the use of different tools and
    systems.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Dividing the existing monolith into different services requires careful planning.
    A bad division between services can make two services tightly coupled, thereby
    not allowing independent deployment. This can result in a situation where practically
    any change to one service will require a change in the other, even if, theoretically,
    this could be done independently. This creates duplication of work, as routinely
    working on a single feature requires multiple microservices to be changed and
    deployed. Microservices can be mutated later and boundaries redefined, but there's
    a high cost associated with that. The same care should be taken later when adding
    new services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's an overhead in creating microservices, as there is some work that gets
    replicated on each service. That overhead gets compensated for by allowing independent
    and parallel development. But, to take full advantage of that, you need numbers.
    A small development team of up to 10 people can coordinate and handle a monolith
    very efficiently. It's only when the size grows and independent teams are formed
    that migrating to microservices starts to make sense. The bigger the company,
    the more it makes sense.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A balance between allowing each team to make their own decisions and standardize
    some common elements and decisions is necessary. If teams have too little direction,
    they'll keep reinventing the wheel over and over. They'll also end up creating
    knowledge silos where the knowledge in a section of the company is wholly non-transferable
    to another team, making it difficult to learn lessons collectively. Solid communication
    between teams is required to allow consensus and the reuse of common solutions.
    Allow controlled experimentation, label it as such, and get the lessons learned
    across the board so that the other teams benefit. There will be tension between
    shared and reusable ideas and independent, multiple-implementation ideas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be careful when introducing shared code across services. If the code grows,
    it will make services dependent on each other. This can reduce the independence
    of the microservices.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Following the Agile principles, we know that working software is more important
    than extensive documentation. However, in microservices, it's important to maximize
    the usability of each individual microservice to reduce the amount of support
    between teams. That involves some degree of documentation. The best approach is
    to create self-documenting services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we've discussed earlier, each call to a different microservice can increase
    the delay of responses, as multiple layers will have to be involved. This can
    produce latency problems, with external responses taking longer. They will also
    be affected by the performance and capacity of the internal network connecting
    the microservices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A move to microservices should be taken with care and by carefully analyzing
    its pros and cons. It is possible that it will take years to complete the migration
    in a mature system. But for a big system, the resulting system will be much more
    agile and easy to change, allowing you to tackle technical debt effectively and
    to empower developers to take full ownership and innovate, structuring communication
    and delivering a high-quality, reliable service.
  prefs: []
  type: TYPE_NORMAL
- en: A move in four acts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The migration from one architecture to another should be considered in four
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Analyze** the existing system carefully.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Design** to determine what the desired destination is.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Plan**. Create a route to move, step by step, from the current system to
    the vision designed in the first stage.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Execute** the plan. This stage will need to be done slowly and deliberately,
    and at each step, the design and plan will need to be re-evaluated.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's look at each of the steps in greater detail.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Analyze
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The very first step is to have a good understanding of our starting point with
    the existing monolith. This may appear trivial, but the fact is that it is quite
    conceivable that no particular person has a good understanding of all the details
    of the system. It may require information gathering, compilation, and digging
    deep to understand the intricacies of the system.
  prefs: []
  type: TYPE_NORMAL
- en: The existing code can be described as *legacy code*. While a debate is currently
    taking place on exactly what code can be categorized as legacy, the main property
    of it is code that is already in place and doesn't follow the best and new practices
    that new code has.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, legacy code is old code from some time ago and that is very
    likely not up to date with current practices. However, legacy code is critical,
    as it is in use and probably key for the day-to-day operations of the organization.
  prefs: []
  type: TYPE_NORMAL
- en: The main objective of this phase should be to determine whether a change will
    actually be beneficial and get a preliminary idea of what microservices will result
    from the migration. Performing this migration is a big commitment, and it's always
    a good idea to double-check that tangible benefits will result. Even if, at this
    stage, it won't be possible to estimate the effort required, it will start shaping
    the size of the task.
  prefs: []
  type: TYPE_NORMAL
- en: This analysis will benefit greatly from good metrics and actual data showing
    the number of requests and interactions that are actually being produced in the
    system. This can be achieved through good monitoring, and adding metrics and logs
    to the system to allow the current behavior to be measured. This can lead to insights
    about what parts are commonly used, and, even better, parts that are almost never
    used and can perhaps be deprecated and removed. Monitoring can continue to be
    used to ensure that the process is going according to plan.
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss monitoring in more detail in *Chapter 11*, *Package Mangement*,
    and *Chapter 12*, *Logging*.
  prefs: []
  type: TYPE_NORMAL
- en: This analysis can be almost instant if the system is already well-architected
    and properly maintained, but may extend to months of meetings and digging into
    code if the monolith is a mess of chaotic code. However, this stage will allow
    us to build on solid foundations, knowing what the current system is.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The next stage of the process is to generate a vision in terms of what the system
    will look like after breaking the monolith up into multiple microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each microservice needs to be considered in isolation, and as part of the rest.
    Think in terms of what makes sense to separate. Some questions that may help you
    to structure the design are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: What microservices should be created? Can you describe each microservice with
    a clear objective and area to control?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there any critical or core microservice that requires more attention or special
    requirements? For example, higher security or performance requirements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will the teams be structured to cover the microservices? Are there too many
    for the team to support? If that's the case, can multiple requests or areas be
    joined as part of the same microservice?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the prerequisites of each microservice?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What new technologies will be introduced? Is any training required?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are microservices independent? What are the dependencies between microservices?
    Is there any microservice that is accessed more than others?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can microservices be deployed independently from each other? What's the process
    if a new change is introduced that requires a change in a dependent dependency?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What microservices are going to be exposed externally? What microservices are
    only exposed internally?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there any prerequisite in terms of required API limitations? For example,
    is there any service that requires specific APIs, such as a SOAP connection?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other things that can be useful in informing the design can be to draw expected
    flow diagrams of requests that need to interact with multiple microservice, so
    as to analyze the expected movement between services.
  prefs: []
  type: TYPE_NORMAL
- en: Special care should be taken regarding whatever storage is decided for each
    microservice. In general, storage for one microservice should not be shared with
    another, to isolate the data.
  prefs: []
  type: TYPE_NORMAL
- en: This has a very concrete application, that is, to not access a database or other
    kind of raw storage directly by two or more microservices. Instead, one microservice
    should control the format and expose the data, and allow changes to the data by
    an accessible API.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's imagine that there are two microservices, one that controls
    reports and another that controls users. For certain reports, we may need to access
    the user information to pull, for example, the name and email of a user who generated
    a report. We can break the microservice's responsibility by allowing the report
    service to access directly a database that contains user information.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_09_04.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.4: An example of incorrect usage, accessing the information directly
    from storage'
  prefs: []
  type: TYPE_NORMAL
- en: Instead, the report service needs to access the user microservice through an
    API and pull the data. That way, each microservice is responsible for its own
    storage and format.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_09_05.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.5: This is the correct structure. Each microservice keeps its own
    independent storage. This way, any information is only shared through well-defined
    APIs'
  prefs: []
  type: TYPE_NORMAL
- en: As we commented before, creating a flow diagram of some requests will help enforce
    this separation and find possible points of improvement; for example, returning
    data from an API that is not required until later in the process.
  prefs: []
  type: TYPE_NORMAL
- en: While a prerequisite is not to mix storage, and to retain separation, you can
    use the same backend service to provide support for different microservices. The
    same database server can handle two or more logical databases that can store different
    information.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, though, most microservices won't require their own data to be stored
    and can work in a completely stateless way, relying instead on other microservices
    to store the data.
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, there's no need to design detailed APIs between microservices,
    but some general ideas on what services handle what data and what the required
    flows between microservices are would be beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Plan
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the general areas are clear, it's time to get into more detail and start
    planning how the system is going to be changed from the starting point to the
    end line.
  prefs: []
  type: TYPE_NORMAL
- en: The challenge here is to iteratively move into the new system while the system
    simultaneously remains functional at all times. New features are likely being
    introduced, but let's park that for the moment and talk only about the migration
    itself.
  prefs: []
  type: TYPE_NORMAL
- en: To be able to do so, we need to use what is known as the **strangler pattern**.
    This pattern aims to gradually replace parts of the system with new ones until
    the entire previous system is "strangled" and can be removed safely. This pattern
    gets applied iteratively, slowly, migrating the functionality from the old system
    to the new one in small increments.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_09_06.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.6: The strangler pattern'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create new microservices, there are three possible strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: Replace the functionality with new code that substitutes the old code, functionally
    producing the same result. Externally, the code reacts exactly the same to external
    requests, but internally, the implementation is new. This strategy allows you
    to start from scratch and fix some of the oddities of the old code. It can even
    be done in newer tools such as frameworks or even programming languages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the same time, this approach can be very time-consuming. If the legacy system
    is undocumented and/or untested, it can be difficult to guarantee the same functionality.
    Also, if the functionality covered by this microservice is changing quickly, it
    may enter a game of catch-up between the new system and the old one, where there's
    no time to replicate any new functionality.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This approach makes the most sense where the legacy parts to be replicated are
    small and obsolete, like using a tech stack that is considered to be deprecated.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Divide the functionality, copying and pasting code that exists in the monolith
    into a new microservice structure. If the existing code is in good shape and structured,
    this approach is relatively fast, only requiring some internal calls to be replaced
    with external API calls.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It may be necessary to include in the monolith new access points to ensure that
    a new microservice can call back to obtain some information.
  prefs: []
  type: TYPE_NORMAL
- en: It's also possible that the monolith needs to be refactored to clarify elements
    and divide them into a structure that's more in line with the new system.
  prefs: []
  type: TYPE_NORMAL
- en: This process can also be made iterative by first starting with a single functionality
    migrated to the new microservice, and then, one by one, moving the code until
    the functionality is completely migrated. At that point, it is safe to delete
    the code from the old system.
  prefs: []
  type: TYPE_NORMAL
- en: A **combination** of both divide and replace. Some parts of the same functionality
    can likely be copied directly, but for others, a new approach is preferred.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This will inform each microservice plan, although we will need to create a global
    view to determine which microservices to create in what order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some useful points to think about to determine what the best course
    of action is:'
  prefs: []
  type: TYPE_NORMAL
- en: What microservices need to be available first, taking into account dependencies
    that will be produced.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An idea of what the biggest pain points are, and whether working on them is
    a priority. Pain points are the code or other elements that are changed frequently
    and the current way of dealing with them in a monolith makes them difficult. This
    can produce great benefits following migration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the difficult points and the cans of worms? There will likely be some.
    Acknowledge that they exist and minimize their impact on other services. Note
    that they may be the same as the pain points, or they may differ. For example,
    old systems that are very stable are difficult points, but not painful as per
    our definition, as they don't change.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now for a couple of quick wins that will keep the momentum of the project going.
    Show the advantages to your teams and stakeholders quickly! This will also allow
    everyone to understand the new mode of operation you want to move to and start
    working that way.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An idea of the training that teams will require and what the new elements are
    that you want to introduce. Also, whether any skills are lacking in your team
    – you may be planning to hire.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any team changes and ownership of the new services. It's important to consider
    feedback from the teams so that they can express their concerns regarding any
    oversights during the creation of the plan. Involve the team and value their feedback.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once we have a plan on how we are going to proceed, it's time to do it.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Execute
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, we need to act on our plan to start the move from the outdated monolith
    to the new wonderful land of microservices!
  prefs: []
  type: TYPE_NORMAL
- en: This will actually be the longest stage of the four, and arguably the most difficult.
    As we said before, the objective is to keep the service running all throughout
    the process.
  prefs: []
  type: TYPE_NORMAL
- en: The key element for a successful transition is to maintain **backward compatibility**.
    This means that the system keeps behaving like the monolithic system from an external
    point of view. That way, we can change the internals in terms of how the system
    works without affecting customers.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, the new architecture will allow us to be faster, meaning the only perceived
    change will be that the system is more responsive!
  prefs: []
  type: TYPE_NORMAL
- en: This is obviously easier said than done. Software development in a production
    environment has been referred to as starting an automobile race driving a Ford
    T and crossing the finishing line in a Ferrari, changing every single piece of
    it without stopping. Fortunately, software is so flexible that this is something
    we can even discuss.
  prefs: []
  type: TYPE_NORMAL
- en: To be able to make the change, from the monolith to the new microservice or
    microservices that handle the same functionality, the key tool is to use a load
    balancer at the top level, right on the ingress of requests. This is especially
    useful if the new microservice is directly replacing the requests. The load balancer
    can take the intake of requests and redirect them to the proper service, in a
    controlled manner.
  prefs: []
  type: TYPE_NORMAL
- en: We will assume that all incoming requests are HTTP requests. A load balancer
    can handle other kinds of requests, but HTTP is by far the most common.
  prefs: []
  type: TYPE_NORMAL
- en: This can be used to migrate the requests from the monolith slowly to the new
    microservice that should receive this request. Keep in mind that the load balancer
    can be configured by a different URL to direct the request to a different service,
    so it can use that small granularity to distribute the load properly across the
    different services.
  prefs: []
  type: TYPE_NORMAL
- en: The process will look a little like this. First, the load balancer is directing
    all the requests to the legacy monolith. Once the new microservice is deployed,
    the requests can be load-balanced by introducing the new microservice. Initially,
    the balance should only be forwarding a few requests to the new system, to be
    sure that the behavior is the same.
  prefs: []
  type: TYPE_NORMAL
- en: Slowly, over time, it can grow until all requests are migrated. For example,
    the first week can only move 10% of the requests, the second week 30%, the third
    week 50%, and then 100% of all requests the week after.
  prefs: []
  type: TYPE_NORMAL
- en: The migration period is 4 weeks. During that time, no new features and changes
    should be introduced as the interface needs to be stable between the legacy monolith
    and the new microservice. Be sure that all the parties involved are aware of the
    plan and each of the steps.
  prefs: []
  type: TYPE_NORMAL
- en: At that point, the handling of the requests in the legacy monolith is unused
    and can be removed to cleanup if this makes sense.
  prefs: []
  type: TYPE_NORMAL
- en: This process is similar to the strangler pattern that we discussed before, but
    in this case applied to individual requests. The load balancer will be an invaluable
    ally for implementing the pattern in full form, extending this procedure in a
    greater mode, as we are adding more functionality and slowly migrating it to be
    certain that any problem can be detected early and without affecting a large number
    of requests.
  prefs: []
  type: TYPE_NORMAL
- en: Execution phases
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The whole execution plan should consist of three phases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The pilot phase.** Any plan will need to be tested with care. The pilot phase
    will be when the plan is checked in terms of its feasibility and the tools tested.
    A single team should lead this effort, to be sure that they are focused on it,
    and can learn and share quickly. Try to start on a couple of small services and
    low-hanging fruit, so that the improvement is obvious for the team. Good candidates
    are non-critical services, so if there''s a problem, it doesn''t present a big
    impact. This phase will allow you to prepare for the migration and to make adjustments
    and learn from inevitable mistakes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Consolidation phase.** At this point, the basics of the migration are understood,
    but there''s still a lot of code to migrate. The pilot team can then start training
    other teams and spread the knowledge, so everyone understands how it should proceed.
    By this time, the basic infrastructure will be in place, and hopefully the most
    obvious issues have been corrected or at least there''s a good understanding of
    how to deal with them.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To help with the spreading of knowledge, documenting standards will help teams
    to coordinate and depend less on asking the same questions over and over. Enforcing
    a list of prerequisites for a new microservice to be deployed and running in production
    will give clarity on what is required. Be sure also to keep a feedback channel,
    so new teams can share their findings and improve the process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This phase will probably see some plan changes, as reality will overcome whatever
    plan has been laid out in advance. Be sure to adapt and keep an eye on the objective
    while navigating through the problems.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: At this phase, the pace will be increased, as the uncertainty is being reduced
    as more and more code is migrated. At some point, creating and migrating a new
    microservice will be routine for the team.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Final phase**. In this phase, the monolithic architecture has been split,
    and any new development is done in the microservices. There may still be some
    remains of the monolith that are regarded as unimportant or low priority. If that''s
    the case, the boundaries should be clear to contain the old way of doing things.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, teams can take full ownership of their microservices and start taking more
    ambitious tasks, such as replacing a microservice completely by creating an equivalent
    one in another programming language or changing the architecture by merging or
    splitting microservices. This is the end stage where, from now on, you live in
    a microservices architecture. Be sure to celebrate it with the team accordingly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: That's roughly the process. Of course, this may be a long and arduous process
    that can span many months or even years. Be sure to keep a sustainable pace and
    a long-term view on the objective to be able to continue until the goal is reached.
  prefs: []
  type: TYPE_NORMAL
- en: Containerizing services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The traditional way of operating services is to use a server using a full OS,
    such as Linux, and then install on it all the required packages (for example,
    Python or PHP) and services (for example, nginx, uWSGI). The server acts as the
    unit, so each physical machine needs to be independently maintained and managed.
    It also may not be optimal from the point of view of hardware utilization.
  prefs: []
  type: TYPE_NORMAL
- en: This can be improved by replacing the physical server with virtual machines,
    so a single physical server can handle multiple VMs. This helps with hardware
    utilization and flexibility, but still requires each server to be managed as an
    independent physical machine.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple tools help with this management, for example, configuration management
    tools such as Chef or Puppet. They can manage multiple servers and guarantee that
    they have installed the proper versions and are running the proper services.
  prefs: []
  type: TYPE_NORMAL
- en: Containers bring a different approach to this area. Instead of using a full-fledged
    computer (a server), with an installed OS, packages, and dependencies, and then
    installing your software on top of that, which mutates more often than the underlying
    system, it creates a package (the container image) that brings it all.
  prefs: []
  type: TYPE_NORMAL
- en: The container has its own filesystem, including the OS, dependencies, packages,
    and code, and is deployed as a whole. Instead of having a stable platform and
    running services on top of them, containers run as a whole, self-containing everything
    required. The platform (host machine) is a thin layer that only needs to be able
    to run the containers. Containers share the same kernel with the host, making
    them very efficient to run, compared with VMs, which may require simulating the
    whole server.
  prefs: []
  type: TYPE_NORMAL
- en: This allows, for example, different containers to be run in the same physical
    machine and have each container run a different OS, with different packages, and
    different versions of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, containers are thought of as "lightweight virtual machines." This
    is not correct. Instead, think of them as *a process wrapped in its own filesystem*.
    This process is the main process of the container, and when it finishes, the container
    stops running.
  prefs: []
  type: TYPE_NORMAL
- en: The most popular tool for building and running containers is Docker ([https://www.docker.com/](https://www.docker.com/)).
    We will now examine how to operate with it.
  prefs: []
  type: TYPE_NORMAL
- en: To install Docker, you can go to the documentation at [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)
    and follow the instructions. Use version 20.10.7 or later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once installed, you should be able to check the version running and get something
    similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now we need to build a container image that we can run.
  prefs: []
  type: TYPE_NORMAL
- en: Building and running an image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The container image is the whole filesystem and instructions to run when it's
    started. To start using containers we need to build the proper images that form
    the basis of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Remember the description presented previously, that a container is a process
    surrounded by its own filesystem. Building the image creates this filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: An image is created by applying a `Dockerfile`, a recipe that creates the image
    by executing different layers, one by one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see a very simple `Dockerfile`. Create a file called `sometext.txt`
    containing some small example text, and another file called `Dockerfile.simple`
    containing the following text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The first line, `FROM`, will start the image by using the Ubuntu image.
  prefs: []
  type: TYPE_NORMAL
- en: There are many images that you can use as a starting point. You have all the
    usual Linux distributions, such as Ubuntu, Debian, and Fedora, but also images
    for full-fledged systems such as storage systems (MySQL, PostgreSQL, and Redis)
    or images to work with specific tools, such as Python, Node.js, or Ruby. Check
    Docker Hub ([https://hub.docker.com](https://hub.docker.com)) for all the available
    images.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting starting point is to use the Alpine Linux distribution, which
    is designed to be small and focused on security. Check out [https://www.alpinelinux.org](https://www.alpinelinux.org)
    for further information.
  prefs: []
  type: TYPE_NORMAL
- en: One of the main advantages of containers is the ability to use and share already
    created containers, either directly or as a starting point to enhance them. Nowadays,
    it is very common to create and push a container to Docker Hub to allow others
    to use it directly. That's one of the great things about containers! They are
    very easy to share and use.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second line runs a command inside the container. In this case, it creates
    a new subdirectory in `/opt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we copy the current `sometext.txt` file inside, in the new subdirectory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we define the command to execute when the image is run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To build the image, we run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In our case, we use the defined Dockerfile and `example` as a tag. The context
    is `.` (current directory), which defines the root point in terms of where to
    refer to all the `COPY` commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If we list the available images, you will be able to see the `example` one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now run the container, which will execute the `cat` command inside:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The container will stop the execution as the command finishes. You can see the
    stopped containers using the `docker ps -a` command, but a stopped container is
    generally not very interesting.
  prefs: []
  type: TYPE_NORMAL
- en: A common exception to this is that the resulting filesystem is stored onto disk,
    so the stopped container may have interesting files generated as part of the command.
  prefs: []
  type: TYPE_NORMAL
- en: While this way of running containers can be useful sometimes to compile binaries
    or other kinds of operations of a similar kind, normally, it's more common to
    create `RUN` commands that are always running. In that case, it will run until
    stopped externally, as the command will run forever.
  prefs: []
  type: TYPE_NORMAL
- en: Building and running a web service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A web service container is the most common type of microservice, as we have
    seen. To be able to build and run one, we need to have the following parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Proper infrastructure that runs the web service to a port in the container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our code, which will run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Following the usual architecture presented in previous chapters, we will use
    the following tech stack:'
  prefs: []
  type: TYPE_NORMAL
- en: Our code will be written in Python and use Django as the web framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Python code will be executed through uWSGI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The service will be exposed in port 8000 through an nginx web server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a look at the different elements.
  prefs: []
  type: TYPE_NORMAL
- en: The code is available at [https://github.com/PacktPublishing/Python-Architecture-Patterns/tree/main/chapter_09_monolith_microservices/web_service](https://github.com/PacktPublishing/Python-Architecture-Patterns/tree/main/chapter_09_monolith_microservices/web_service).
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is structured in two main directories and one file:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker`: This subdirectory contains the files related to the operation of
    Docker and other infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src`: The source code of the web service itself. The source code is the same
    as we saw in *Chapter 5*, *The Twelve-Factor App Methodology*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`requirements.txt`: The file with the Python requirements for running the source
    code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Dockerfile image is located in the `./docker` subdirectory. We will follow
    it to explain how the different parts connect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The first part of the file starts the container from the standard Ubuntu Docker
    image and install the basic requirements: Python interpreter, nginx, uWSGI, and
    a couple of complementary packages – the uWSGI plugin to run `python3` code and
    `pip` to be able to install Python packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The next stage is to add all the required scripts and config files to start
    the server and configure uWSGI and nginx. All these files are in the `./docker`
    subdirectory and are stored inside the container in `/opt/server` (except for
    the nginx configuration that is stored in the default `/etc/nginx` subdirectory).
  prefs: []
  type: TYPE_NORMAL
- en: 'We ensure that the start script is executable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The Python requirements are installed next. The `requirements.txt` file is
    added and then installed through the `pip3` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Some Python packages may need certain packages to be installed in the container
    in the first stage to be sure that some tools are available; for example, installing
    certain database connection modules will require the proper client libraries to
    be installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We add the source code to `/opt/code` next. With the `WORKDIR` command, we
    execute any `RUN` command in that subdirectory and then run `collectstatic` with
    the Django `manage.py` command to generate the static files in the proper subdirectory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we describe the exposed port (8000) and the `CMD` to run to start
    the container, the `start_server.sh` script copied previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: uWSGI configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The uWSGI configuration is very similar to the one presented in *Chapter 5*,*The
    Twelve-Factor App Methodology*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The only difference is the need to include the `plugins` parameter to indicate
    that it runs the `python3` plugin (this is because the Ubuntu-installed `uwsgi`
    package doesn't have it activated by default). Also, we will run the process with
    the same user as nginx, to allow them to communicate through the `/tmp/uwsgi.sock`
    socket. This is added with `uid=www-data`, with `www-data` being the default nginx
    user.
  prefs: []
  type: TYPE_NORMAL
- en: nginx configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The nginx configuration is also very similar to the one presented in *Chapter
    5*,*The Twelve-Factor App Methodology*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The only difference is the exposed port, which is `8000`. Note that the root
    directory is `/opt/code`, making the static file directory `/opt/code/static`.
    This needs to be in sync with the configuration from Django.
  prefs: []
  type: TYPE_NORMAL
- en: Start script
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s take a look at the script that starts the service, `start_script.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The core of the start is at the center, in these lines, nginx:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This starts both `nginx` and `uwsgi`, and waits until the `uwsgi` process is
    not running. In Bash, `$!` is the PID of the last process (the `uwsgi` process).
  prefs: []
  type: TYPE_NORMAL
- en: 'When Docker attempts to stop a container, it will first send a `SIGTERM` signal
    to the container. That''s why we create a `trap` command that captures this signal
    and executes the `_term()` function. This function sends a graceful stop command
    to the `uwsgi` queue, as we described in *Chapter 5*,*The Twelve-Factor App Methodology*,
    which ends the process in a graceful manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: If the initial `SIGTERM` signal is not successful, Docker will stop the container
    killing it following a grace period, but that will risk having a non-graceful
    end for the process.
  prefs: []
  type: TYPE_NORMAL
- en: Building and running
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can now build the image and run it. To build the image, we perform a similar
    command as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the service, start the container, mapping its port `8000` to a local
    port, for example, `local 8000`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'After doing this, you can access your local address, `http://localhost:8000`,
    and access the service; for example, accessing the URL `http://localhost:8000/api/users/jaime/collection`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_09_07.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.7: Microposts list'
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ll see the access log in the screen where you started the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The container can be stopped gracefully using the `docker stop` command. To
    do so, you''ll need to first discover the container ID using `docker ps`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The container log will show the details when capturing the `SIGTERM` signal
    sent by Docker and will then exit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: To be able to set this example, we made some conscious decisions to simplify
    the operation compared with a typical service.
  prefs: []
  type: TYPE_NORMAL
- en: Caveats
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember to check *Chapter 5*,*The Twelve-Factor App Methodology*, to see the
    defined API and understand it better.
  prefs: []
  type: TYPE_NORMAL
- en: The `DEBUG` mode in the Django `settings.py` file is set to `True`, which allows
    us to see more information when, for example, 404 or 500 errors are triggered.
    This parameter should be disabled in production as it can give away critical information.
  prefs: []
  type: TYPE_NORMAL
- en: The `STATIC_ROOT` and `STATIC_URL` parameters need to be coordinated between
    Django and nginx to point to the same place. That way, the `collectstatic` command
    will store the data in the same place where nginx will pick it up.
  prefs: []
  type: TYPE_NORMAL
- en: The most important detail is the use of a SQLite database instead of an internal
    one. This database is stored in the `src/db.sqlite3` file, in the filesystem of
    the container. This means that if the container is stopped and restarted, any
    changes will be destroyed.
  prefs: []
  type: TYPE_NORMAL
- en: The `db.sqlite3` file in the GitHub repo contains some information that has
    been stored for convenience, two users, `jaime` and `dana`, each with a couple
    of microposts. The API so far hasn't been defined in such a way to create new
    users, so it needs to relay into creating them using Django tools or manipulating
    the SQL directly. These users are added for demonstration purposes.
  prefs: []
  type: TYPE_NORMAL
- en: As an exercise, create a script that seeds the database with information as
    part of the build process.
  prefs: []
  type: TYPE_NORMAL
- en: In general, this database usage is not well suited for production usage, requiring
    connection to a database external to the container. This obviously requires an
    available external database, which complicates the setup.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to use containers, we can perhaps start another Docker
    container with a database, such as MySQL, for a better configuration.
  prefs: []
  type: TYPE_NORMAL
- en: A containerized database is not a great idea for production. In general, containers
    are great for stateless services that change often, as they can be started and
    stopped easily. Databases tend to be very stable and there are a lot of services
    that make provisions for managed databases. The advantages that containers bring
    are simply not relevant for a typical database.
  prefs: []
  type: TYPE_NORMAL
- en: That doesn't mean that there are usages out of production. It is a great option
    for local development, for example, as it allows the creation of a replicable
    local environment easily.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to create more than one container and connect them, like a web server
    and a database that acts as a backend for storing the data, instead of starting
    all the containers individually, we can use orchestration tools.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestration and Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Managing multiple containers and connecting them is known as orchestrating them.
    Microservices that are deployed in containers will have to orchestrate them to
    be sure that the multiple microservices are interconnecting.
  prefs: []
  type: TYPE_NORMAL
- en: This concept includes details such as discovering where the other containers
    are, dependencies between services, and generating multiple copies of the same
    container.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestration tools are very powerful, as well as complex, and require that
    you become familiar with a lot of terms. To explain them fully is beyond the scope
    of this book, but we will point to some and give a short introduction. Please
    refer to the linked documentation in the sections below for more information.
  prefs: []
  type: TYPE_NORMAL
- en: There are several tools that can perform orchestration, the two most common
    ones being `docker-compose` and Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: '`docker-compose` is part of the general offering by Docker. It works very well
    for small deployments or local development. It defines a single YAML file that
    contains the definition of the different services, and the name that they can
    use. It can be used to replace a lot of `docker build` and `docker run` commands,
    as it can define all the parameters in the YAML file.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check the documentation for Docker Compose here: [https://docs.docker.com/compose/](https://docs.docker.com/compose/).'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is aimed at bigger deployments and clusters and allows the generation
    of a full logical structure for containers to define how they connect to one another,
    thereby allowing abstraction to the underlying infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Any physical (or virtual) server configured in Kubernetes is called a **node**.
    All nodes define the cluster. Each node is handled by Kubernetes, and Kubernetes
    will create a network between the nodes and assign the different containers to
    each of them, attending to the available space on them. This means that the number,
    location, or kind of node doesn't need to be handled by the services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, the applications in the cluster are distributed in the logical layer.
    Several elements can be defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pod**. A Pod is the minimal unit defined in Kubernetes, and it is defined
    as a group of containers that runs as a unit. Normally, Pods will consist of just
    one container, but in some cases, they may comprise several. Everything in Kubernetes
    runs in Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment**. A collection of Pods. The Deployment will define the number
    of replicas that are needed, and create the proper number of Pods. Each Pod for
    the same deployment can live in different nodes, but that''s under the control
    of Kubernetes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because the Deployment controls the number of Pods, if a Pod crashes, the Deployment
    will restart it. Also, the Deployment can be manipulated to change the number,
    for example, by creating autoscalers. If the image to be deployed in the Pods
    is changed, the Deployment will create new Pods with the right image and remove
    the old ones accordingly, based on rolling updates or other strategies.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Service**. A label that can be used to route requests to certain Pods, acting
    as a DNS name. Normally, this will point to the Pods created for deployment. This
    allows other Pods in the system to send requests to a known place. The requests
    will be load-balanced between the different Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ingress**. External access to a service. This will map an incoming DNS to
    a service. Ingresses allow applications to be exposed externally. An external
    request will go through the process of entering through an Ingress, being directed
    to a Service, and then handled by a specific pod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some components can be described in a Kubernetes cluster, such as `ConfigMaps`,
    defining key-value pairs that can be used for configuration purposes; `Volumes`
    to share storage across Pods; and `Secrets` to define secret values that can be
    injected into Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes is a fantastic tool that can handle pretty big clusters with hundreds
    of nodes and thousands of Pods. It''s also a complex tool that requires you to
    learn how it can be used and has a significant learning curve. It''s pretty popular
    these days, and there''s plenty of documentation about it. The official documentation
    can be found here: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we described both the monolithic and microservices architectures.
    We started by presenting the monolithic architecture and how it tends to be a
    "default architecture," generated organically as an application is designed. Monoliths
    are created as unitary blocks that contain all the code within a single block.
  prefs: []
  type: TYPE_NORMAL
- en: In comparison, the microservices architecture divides the functionality of the
    whole application into smaller parts so that they can be worked in parallel. For
    this strategy to work, it needs to define clear boundaries and document how to
    interconnect the different services. Compared with the monolithic architecture,
    microservices aim to generate more structured code and control big code bases
    by dividing them into smaller, more manageable systems.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed what the best architecture is and how to choose whether to design
    a system as a monolith or as microservices. Each approach has its pros and cons,
    but in general, systems start as monolithic and the move to divide the code base
    into smaller microservices comes after the code base and the number of developers
    working on it reaches a certain size.
  prefs: []
  type: TYPE_NORMAL
- en: The difference between the two architectures is not just technical. It largely
    involves how developers working on the system need to communicate and divide the
    teams. We discussed the different aspects to take into account, including the
    structure and size of the teams.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since migrating from an old monolithic architecture to a new microservices
    one is such a common case, we talked about how to approach the work, analyze it,
    and perform it, using a four-stage roadmap: Analyze, Design, Plan, and Execute.'
  prefs: []
  type: TYPE_NORMAL
- en: We then discussed how containerizing services (and, in particular, microservices)
    can be helpful. We explored how to use Docker as a tool to containerize services
    and its multiple advantages and uses. We included an example of containerizing
    our example web service, as described in *Chapter 5*, *The Twelve-Factor App Methodology*.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we described briefly the usage of an orchestration tool to coordinate
    and intercommunicate between multiple containers, and the most popular, Kubernetes.
    We then covered a brief introduction to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: You can get more information about microservices and how to perform a migration
    from a monolithic architecture to a microservices one in the book *Hands-On Docker
    for Microservices with Python*, from the author of this book, which expands on
    these concepts and goes into greater depth.
  prefs: []
  type: TYPE_NORMAL
