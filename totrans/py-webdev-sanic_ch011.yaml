- en: 10 Implementing Common Use Cases with Sanic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have learned how to use Sanic, and we have learned some good practices and
    habits to get into. Now, let’s go build some fun stuff. When starting to work
    on a new project it is very tempting to start here. Afterall, the idea you have
    in your head about what to build is the implementation, right? You have a final
    idea of what you want (a chat bot for example). So, you sit down and you start
    building the bot.
  prefs: []
  type: TYPE_NORMAL
- en: But the reason this chapter is at the end of the book is because you obviously
    cannot start here. Only after gaining the knowledge of HTTP and Sanic, and leveling
    up our technical skills along the way, can we dig into implementation details.
    The goal of this chapter is to look at some practical features that you may be
    tasked to build. With the plubming out of the way, and now that we have a solid
    foundation and understanding of HTTP and Sanic, we can start to build some real-world
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: When considering what topics to include in this chapter I thought about what
    are some common use cases that I know Sanic is used for. It makes sense to select
    a handful of implementations that often come up, and then try and build them together.
    This book is obviously a bit space constrained, and so we will not dive into the
    minute details here. Instead, we will look at some implementation details, talk
    about some of the considerations, and describe the general approach you might
    take to the problem. I hope to show you some insight into my own thought process
    when tasked with a project like this.
  prefs: []
  type: TYPE_NORMAL
- en: Just like the previous chapter, there will be a lot of code in the repository
    that will not be in the book. It is simply is not all relevant to the conversation,
    but I wanted to make sure that you have full working examples to use as a launching
    pad for your own projects. To receive a complete understanding, you really ought
    to follow along with the source code online while reading this chapter. I will
    point out specific design decisions and include some choice bits that are particularly
    worth mentioning.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, what are we going to build? The list includes:'
  prefs: []
  type: TYPE_NORMAL
- en: Synchronized websocket feeds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Progressive web app backend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GraphQL API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chat bot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since this chapter builds upon the previous chapters, you should have all of
    the technical needs already fulfilled. We will start seeing some additional third-party
    packages in use, so make sure you have `pip` handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you would like to jump ahead to make sure your environment is setup, here
    are the pip packages that we plan to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Furthermore, if you recall, back in Chapter 2 we discussed using factory patterns.
    Because we are now starting to build what can become the base of a *real world*
    application, I feel it is much better to use a factory pattern here that can be
    expanded. Therefore, for the remainder of this book you will see more and more
    usage of the factory pattern that we already have established and used.///
  prefs: []
  type: TYPE_NORMAL
- en: Websocket feeds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier in this book we explored websockets in *Websockets for two-way communication*
    section *Chapter 5* . If you have not read that section yet, I encourage you to
    do that now. At this time, we are going to take our websocket implementation and
    create a horizontally scalable websocket feed. The basic premise of the code here
    will be the same as in that section, which is why you should have an understanding
    of what we build there before moving onto the example here.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of the feed we will build is to share events that happen in one
    browser across to another browser. Building upon the example from Chapter 5, we
    are going to add a third-party broker that will allow us to run multiple application
    instances. This means that we can horizontally scale our application. The previous
    implementation suffered from the fact that it stored client information in memory.
    With no mechanism to share state or broadcast messages across multiple application
    instances, there was no way for one websocket connection to guarantee that it
    would be able to push messages to every other client. At best it would only be
    able to push messages to clients that happened to be routed and connected to the
    same application instance. Ultimately, this made it impossible to scale the application
    with multiple workers.
  prefs: []
  type: TYPE_NORMAL
- en: The goal now will be to create what is known as a **pubsub**. This is a term
    that means “publish and subscribe” since the pattern relies upon multiple sources
    subscribing to a central broker. When one of those sources publishes a message
    to the broker, all of the other sources that are subscribed receive that message.
    The term pubsub is a simple description of this push and pull between the broker
    and the sources. We will use this concept when building our feed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest way to handle pubsub in my opinion is with Redis, which has a
    very simple built-in pubsub mechanism. The idea is simple: every application instance
    will be a source. At startup, the application instance will subscribe to a specific
    channel on the Redis instance. With this connection established, it now has the
    ability to push and pull messages from that Broker on a specific channel By pushing
    this off to a third-party service, all of our applications will be able to access
    the same information through the push and pull of the pubsub.'
  prefs: []
  type: TYPE_NORMAL
- en: In the Chapter 5 websockets example, when a message was received, the server
    would push that message out to other clients that were connected to the same application
    instance. We will still do something similar. Browser clients will open a websocket
    with one of many web servers, which will hold onto that client connection. This
    again will be held in memory. When there is an incoming message from a client
    instance, it will publish that message not by directly distributing it to the
    other clients, but instead it will push the message to the pubsub broker. Then,
    all of the other instances will receive that message since they are subscribed
    to the same broker and can push the message to any websocket clients that happen
    to be connected to that application instance. In this way, we can build a distributed
    websocket feed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, we will spin up a Redis service using `docker-compose`, as
    well as our development application. Take a look in the repository for the details
    on how to accomplish that: ___. We will assume that you have a Redis instance
    available and running.'
  prefs: []
  type: TYPE_NORMAL
- en: We begin by creating a websocket handler and attaching it to a Blueprint.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the entirety of our Sanic integration on this example. We defined a
    websocket endpoint. The endpoint requires us to access a feed by going to a `channel_name`
    which is meant to be a unique listening location. This could either be a username
    or chatroom stock ticker and so on. The point is that the `channel_name` is meant
    to represent some location in your application where people will want to continuously
    retrieve information from your application as a feed. For example, this also could
    be used to build out a sort of shared editing application where multiple users
    are able to make changes simultaneously to the same resource.The handler in this
    example works by fetching a `Channel` object. If it created a new `Channel`, then
    we send off a `receiver` task to the background that is responsible for listening
    to our pubsub broker. The next thing in the handler is to register our current
    websocket connection on the channel, and then create another `receiver`. The point
    of this second `client.receiver` is to listen to the websocket connection, and
    take incoming messages to push off to the pubsub broker.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s take a quick look at the `Client` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As just stated, the purpose of this object is to listen to the current websocket
    connection and send messages off to the pubsub broker when there is a message.
    That happens with the `publish` method.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We now will take a look at the `Channel` object. This class is a bit longer
    than the `Client`, so we will look at the code for it in sections. It might be
    helpful to open the GitHub repository to see the class definition in full.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A channel is created and cached in each application instance in memory. This
    means that for every single application instance where an incoming request asks
    to join a specific channel, there is only one instance of that channel being created.
    Even if we have ten (10) application instances, it does not matter that we have
    ten (10) instances of the channel. What we care about is that on any *single*
    application instance, there is never more than one `Channel` subscribing to a
    single Redis pubsub channel. Having multiple channels on the same application
    instance could get messy and lead to a memory leak. Therefore, we also want to
    add a mechanism to clean up the cache when a channel is no longer needed. We can
    do that like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The reason we are using a `Lock` on this is to try and avoid race conditions
    where multiple requests make an attempt to destroy a channel instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you recall from above, after the channel is created (or fetched from the
    cache), we register the websocket connection on the Channel instance which looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We simply create the `Client` object, add it to the known clients that need
    to be notified from this instance on an incoming message, and send off a message
    to let other clients know that someone has just joined. The publish message method
    simply looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Once a client has been registered, it also needs to have the ability to unregister.
    A method to unregister is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, we remove the current client from the known clients on the `Channel`.
    If there are no longer anymore clients listening to this channel, then we can
    close it and clean up after ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: This is a super simple pattern that provides an immense amount of flexibility.
    In fact, in my course of providing support and helping people with their Sanic
    applications, I have provided assistance in building applications using a similar
    pattern to this on numerous occasions. Using this, you could create some truly
    incredible frontend applications. I know I have. Speaking of which, in our next
    section we are going to start looking at the interplay between Sanic and frontend
    web applications that run in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: Powering a progressive web app
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A lot of use cases for building web APIs are to power a **progressive web application**
    (PWA, also known as a single-page application, or SPA). Like many other web developers
    out there, the real draw to web development was for the purpose of building a
    usable application or website in the browser. Let’s be honest, not many of us
    are out there writing `curl` commands to use our favorite APIs. The real power
    of a web API is when it powers something else.
  prefs: []
  type: TYPE_NORMAL
- en: 'What does a PWA need in order to run? Well, when you build a PWA the final
    product is a bunch of static files. Okay, so we put those files into a directory
    called `./public` and then we serve them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: There you go, we now are running a PWA. We’re finished.
  prefs: []
  type: TYPE_NORMAL
- en: Well, not so fast. Being able to serve the static content is important, but
    it is also not the only factor you need to consider. Let’s look at some considerations
    when building PWAs.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with subdomains and CORS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Chapter 7 we spent a significant amount of time looking into CORS from a
    security lens. I would venture a guess that by far the biggest rationale for requiring
    CORS protection is the need to serve content to a PWA. These types of applications
    are ubiquitous on the Internet, and usually have to tackle. The reason this usually
    happens is that often times the frontend of a PWA and the backend are on different
    subdomains. This usually is because they are running on different servers. The
    static content might be served with a CDN, and the backend is on a VPS or PAAS
    offering (see Chapter 8 for more on Sanic deployment options).
  prefs: []
  type: TYPE_NORMAL
- en: CORS is a big topic. It is also something easy to get wrong. Luckily, there
    is a simple method for getting this up and running using Sanic Extensions, a package
    that is developed and maintained by the Sanic team to add some extra features
    to Sanic. Sanic Extensions focus on all of the more opinionated and use-case specific
    implementations that are inappropriate for the core project. CORS is one of those
    features.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do we get going out of the box?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: That’s it. Just install the `sanic-ext` package into your environment and you
    will get CORS protection out of the box. As of version 21.12, if you have the
    `sanic-ext` in your environment, Sanic will auto-instantiate it for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only thing we need to do now is to configure it. Usually, to get started
    with CORS configuration, we need to set the allowed origins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Well, hang on a minute, you say, “Can’t I just serve the frontend assets from
    Sanic and avoid CORS because the front and back are on the same server?” Yup.
    If that approach works for you, go for it. Let’s see what that might look like
    (from a development perspective).
  prefs: []
  type: TYPE_NORMAL
- en: Running a development server
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What happens when you decide that you want both frontend and backend applications
    to run on the same server? Or, when you want to use the `app.static` method shown
    above to serve your project files? Building this locally could be very tricky.
  prefs: []
  type: TYPE_NORMAL
- en: The reason this is the case is because when building a frontend application,
    you need a frontend server. Most frameworks have some sort of a build requirement.
    That is to say that you type some code, hit save, then some package like `webpack`
    or `rollup` compiles your JS and serves it to you from a local development web
    server. Your frontend development server might run on port 5555, so you go to
    `http://localhost:5555`.
  prefs: []
  type: TYPE_NORMAL
- en: But, you want to access your locally running backend from that frontend application
    to populate content. The backend is running on `http://localhost:7777`. Uh oh,
    do you see where this is going? We are right back to CORS all over again. As long
    as your frontend application is being run by a different server than your backend,
    you will continue to run into CORS issues.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, we are trying to get a single server to run both the backend and
    frontend. Since we are talking about local development, we also want auto-reload
    capabilities for both our Python files and our Javascript files. We also need
    to trigger a rebuild of the Javascript, and finally we need to serve this all
    from one location.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, Sanic can do all of this for us. Let’s now use Sanic as a local development
    server for a frontend project.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will work with any frontend tools you want since we will essentially be
    calling those tools from within Python. My frontend development framework of choice
    is Svelte, but feel free to try this with React, Vue, or any of the other many
    alternatives. I will not walk you through the steps of setting up a frontend project
    since that is not important here. Imagine that you have already done it. If you
    would like to follow along in code, please see the GitHub repository: ___.'
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish our goals, we will setup the Sanic server to add auto-reload capabilities
    to the build directory of the frontend application. For Svelte projects using
    `rollup` (a popular JS build tool), that is a `./public` directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by declaring the location of the static files and serving them with
    `static`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When we run Sanic, make sure to add that directory to the auto-reloader like
    this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The next thing we want to do is define a custom signal. We are going to use
    this later, so all it needs to do now is define it. It just needs to exist so
    that we can later await the event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We are now ready to build something that will check the files that were reloaded
    and decide whether or not we need to trigger the `rollup` build process. We will
    look at this in two parts. First, we create a startup listener that checks the
    file extensions to determine the server start was triggered by a reload from any
    `.svelte` or `.js` file extensions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As of version 21.12, the files that triggered a reload are stashed in a `SANIC_RELOADED_FILES`
    environment variable. Since any environment variables starting with SANIC_ prefix
    are loaded into our `app.config`, we can simply read that value if it exists and
    check the file extensions.Assuming there is a rebuild required, we next want to
    trigger a subprocess call to our shell to run the build command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, when this is all done, we are going to dispatch that custom event that
    we created earlier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Up until now, we have the auto-reload and auto-rebuilding working as expected.
    The only thing we are missing now is the ability to trigger the web browser to
    refresh the page. This can be accomplished using a tool called `livereload.js`.
    You can access livereload.js by searching for it and installing the Javascript.
    Essentially what it will do is create a websocket connection to a server on port
    35729\. Then from that websocket you can send messages prompting the browser to
    perform a refresh. To do this from Sanic, we are going to run nested applications.
    Add a second application definition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We also will need to declare a few more constants. These are mainly to run
    the two types of messages that livereload needs to send from the server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, setup the necessary listeners to run the nested server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `runner` task used in the code above should look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It is time to add the websocket handler:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, the handler accepts an initial message from livereload, and
    then sends a `HELLO` message back. Afterwards we are going to run a loop and wait
    until the custom signal we created is triggered. When it is, we send off the RELOAD
    message, which triggers the browser to refresh the webpage.
  prefs: []
  type: TYPE_NORMAL
- en: Voila! We now have a full Javascript development environment running inside
    of Sanic. This is a perfect setup for those PWAs where you want to serve the frontend
    and backend content from the same location.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we are already talking about frontend content, we will next visit another
    important topic for frontend developers: GraphQL'
  prefs: []
  type: TYPE_NORMAL
- en: GraphQL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In 2015, Facebook publicly released a project of meant to rival traditional
    web APIs and flip the concept of a RESTful web application on its head. This project
    is what we now know as GraphQL. This book has so far assumed that we are building
    out endpoints using the traditional method of combining HTTP Methods with thoughtful
    paths to point to specific resources. In this approach, web servers are responsible
    for being the interface between a client and the source of data (i.e, a database).
    The concept of GraphQL pushes all of that aside and allows the client to directly
    request what information it wants to receive. There is a single endpoint (usually
    `/graphql`) and a single HTTP Method (usually `POST`). The single route definition
    is meant to be used for both retrieving data and causing state changes in the
    application. This all happens through a set of queries that are sent as the body
    on that single endpoint. GraphQL was meant to revolutionize the way we build the
    web, and to take over as the standard practice of the future. At least, that is
    what many people said was going to happen.
  prefs: []
  type: TYPE_NORMAL
- en: This has not actually come to pass. At the time of this writing, the popularity
    of GraphQL has seemingly peaked and is now on a decline. Nevertheless, I do believe
    that GraphQL fulfills a necessary niche in the web application world, and it will
    continue to live on as an alternative implementation for years to come (just not
    as a replacement). We, therefore, do need to know how to integrate it with Sanic
    for the instances where you may be asked to deploy one of these servers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can answer the question of “why use GraphQL?” we must understand
    what it is. As the name seemingly implies, **GraphQL** is a sort of query language.
    A query is a JSON-like request for information to be delivered in a specific format.
    A client looking to receive information from a web server might send a `POST`
    request with a body that includes a query like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In return, a server would go and fetch whatever data it needed and compile
    a return JSON document matching that description:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: As you might be able to tell, this becomes a very powerful tool for the client
    as it can bundle what might otherwise be multiple network calls into a single
    operation. It also allows a client (for example a PWA) to specifically retrieve
    the exact data that it needs in the format that it needs it.
  prefs: []
  type: TYPE_NORMAL
- en: Why would I want to use GraphQL?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I believe that GraphQL is the best friend of the frontend developer, but the
    bane of existence for the backend developer. It is certainly true that web applications
    using GraphQL will generally issue fewer HTTP calls to web servers than their
    counterparts. It is also certainly true that a frontend developer will have an
    easier time manipulating responses from a web server using GraphQL since they
    get to be the architect of how that data is structured.
  prefs: []
  type: TYPE_NORMAL
- en: GraphQL provides a very easy method for data retrieval. Because it is a strongly
    typed specification, it makes it possible to have tools that make the whole process
    of generating a query very elegant. For example, many GraphQL implementations
    come with an out-of-the-box web UI that can be used for development. These UIs
    usually include the ability to navigate the schema and see exactly what types
    of queries can be made, and what information is retrievable. See Figure __ for
    an example.
  prefs: []
  type: TYPE_NORMAL
- en: INSERT IMAGE
  prefs: []
  type: TYPE_NORMAL
- en: Figure ___. Example of a GraphQL UI showing the “SCHEMA” tab that displays all
    of the available information
  prefs: []
  type: TYPE_NORMAL
- en: 'There is certainly a fun factor that goes into these tools as you play with
    them to craft exactly the information you want. Simply put: GraphQL is simple
    to use and implement. It also has a very satisfying “coolness” factor to it when
    you start building ad-hoc custom queries.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Except, it is a nightmare in the backend. For all of the simplification from
    the client perspective, the web server now needs to deal with a much greater level
    of complexity. For this reason, when someone tells me that they want to build
    a GraphQL application I usually ask them: why? If they are building it as a public
    facing API, then this may be wonderful. GitHub is a great example of a public-facing
    GraphQL API that is a treat to work in. Querying the GitHub API is simple and
    intuitive. If, however, they are building the API for their own internal purposes,
    then there is a set of tradeoffs that must be considered.'
  prefs: []
  type: TYPE_NORMAL
- en: GraphQL is not in totality any easier or simpler than REST. Instead, it represents
    the shifting of complexity almost entirely to the web server. This may be acceptable,
    but it is a tradeoff that you must consider. I generally find the overall increase
    in complexity of the backend outweighs any benefits of implementation.
  prefs: []
  type: TYPE_NORMAL
- en: I know it may sound like I am not a fan of GraphQL. This is not true. I do think
    that GraphQL is a great concept, and I think there are some amazing tools out
    there (including in the Python world) to help build these applications. If you
    want to include GraphQL in your Sanic application, I would highly recommend tools
    like `Ariadne` ([https://ariadnegraphql.org/](https://ariadnegraphql.org/)) and
    `Strawberry` ([https://strawberry.rocks/](https://strawberry.rocks/)). Even with
    these tools, a good GraphQL application in my opinion is more difficult to build
    with a few pitfalls waiting to swallow you up. As we look into how we can build
    a Sanic GraphQL application, I will try and point out these issues so that we
    can work around them.
  prefs: []
  type: TYPE_NORMAL
- en: Adding GraphQL to Sanic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'I have built a small GraphQL application for this section. All of the code
    is, of course, on the GitHub repository for this book: ___. I highly suggest you
    have the code available while reading. Quite frankly the code in its entirety
    is much too complex and lengthy to include it all here. So, instead we will talk
    through it in general, and I will refer you back to the repository for specifics.
    For your convenience I have also added a number of comments and further discussion
    points in the code base itself.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When we discussed database access in Chapter 9 in the section called *To ORM
    or Not to ORM, that is the question*, we talked about whether you should or should
    not implement an ORM. The discussion was about whether you should use a tool to
    help you build the SQL queries or to build them yourself. There are very good
    arguments on both sides: pro-ORM versus anit-ORM. I opted for a somewhat hybrid
    approach to build the SQL queries by hand, and then build a lightweight utility
    to hydrate the data to a usable model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A similar question *could* be posed here: should I build it myself or use a
    package? My answer is that you should absolutely use a package. I cannot see any
    reason to try and build a custom implementation yourself. There are several good
    options in Python; my personal preference is Ariadne. I particularly like the
    schema-first approach that the package takes. Using it allows me to define the
    GraphQL parts of my application in `.gql` files, therefore enabling my IDE to
    add syntax highlighting and other language specific conveniences.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we are using Ariadne in our example here, we begin by installing it into
    our virtual environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To get up and running with Ariadne’s “hello world” application does not take
    much:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As you can see, there are two endpoints:'
  prefs: []
  type: TYPE_NORMAL
- en: a `GET` that displays the GraphQL query builder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a `POST` that is the ingress to the GraphQL backend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From this humble beginning, you can build from Sanic and Ariadne however your
    heart desires. Let’s take a look at a potential strategy you might take.
  prefs: []
  type: TYPE_NORMAL
- en: Scrapping the above, we begin with an app that looks very similar in structure
    to what we have seen before. Create `./blueprints/graphql/query.py` and place
    your root level GraphQL object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we create the two endpoints needed inside of a CBV on our GraphQL Blueprint
    instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, this is nearly identical to the simple version from before.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On this same Blueprint instance, we are going to place all of our startup logic.
    This keeps it all in a convenient location and allows us to attach it to our application
    instance all at once.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You may be wondering, what is an integrator, and what is it all of that code
    doing. This is where I am going to refer you to the repository for the specifics,
    but we will walk through the concept here.
  prefs: []
  type: TYPE_NORMAL
- en: In my application example, an `Integrator` is an object that lives inside of
    a domain and is the conduit to setting up a GraphQL schema that Ariadne can use.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the GitHub repository, you will see that the simplest Integrator is for
    the `languages` module. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Next to it is a file called `schema.gql`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: It is then the job of the `RootIntegrator` to marshall all of the various domains
    together and generate the schema for Ariadne using both dynamically generated
    schema, and the hardcoded schema like the snippet above.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to create a place for our GraphQL query to start. A query might
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: A user creates a query and we go and fetch it from the database. The Executor
    here works exactly as it does in the `hikingapp`. Refer back to Chapter ___. Therefore,
    with a query like this, we can now translate the GraphQL query to an object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'With the power of GraphQL, our response should be this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The way that Ariadne (and other GraphQL implementations) works is that you
    define a strongly typed schema. With the knowledge of that schema, you might end
    up with nested objects. For example, the above `Country` schema might look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The Country type has a field called `capital`, which is a `City` type. Since
    this is not a simple scalar value that easily serializes to JSON, we need to tell
    Ariadne how to translate—or resolve—that field. Given the example in GitHub, it
    would be to query our database like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This is how we can follow the path between different objects. It is then the
    job of Ariadne to piece all of these different queries and resolvers together
    to generate a final object to return. This is the power of GraphQL.
  prefs: []
  type: TYPE_NORMAL
- en: You may have also noticed a flaw. Because every resolver is meant to operate
    independently and to handle the conversion of a single field into a value, you
    can very easily overfetch data from the database. This is especially true if you
    have an array of objects that all resolve to the same database instance. This
    is known as the “n+1” problem. While it is not a unique problem to GraphQL, the
    design of many GraphQL systems make it acutely prone to it. If you ignore this
    problem, while responding to a single request your server might ask the database
    for the same information over and over again even though it should otherwise already
    have it.
  prefs: []
  type: TYPE_NORMAL
- en: Many applications suffer from this issue. They rely on many more database queries
    than may otherwise be needed. All of this overfetching adds up and reduces the
    performance and efficiency of web applications. While you should certainly be
    aware of this issue and cognizant as you develop any application, I feel it is
    something you must particularly plan for with GraphQL implementations since they
    thrive off of simplified resolvers. Therefore, the biggest piece of advice I can
    provide when building one of these applications is to think about in-memory, request-based
    caching. That is to say that caching objects on a request instance might save
    a ton of SQL queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'I encourage you to take some time to review the rest of the code in the GitHub
    repository. There are some helpful patterns that could be usable in a real-world
    application. Since they are not necessarily on-point to Sanic or implementing
    GraphQL in Sanic, we will leave the discussion here for now and turn to another
    popular use case with Sanic: chat bots.'
  prefs: []
  type: TYPE_NORMAL
- en: Building a Discord bot (running Sanic in another service)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At some point early in 2021, I was convinced by a few people in the Sanic community
    that we needed to move our primary discussion and community building tool. We
    had a somewhat underutilized chat application and also the community forums that
    were mainly used for longer style support questions. Discord is a more intimate
    conversation than what other options could offer. When it was suggested to me
    that we use Discord, I was a little hesitant to add another application to my
    tool belt. Nevertheless, we went forward with it. If there are Discord fans out
    there reading this book, then you do not need me to explain to you its benefits.
    For everyone else, Discord is a very easy to use and engaging platform that really
    facilitates the types of discussion helpful to our corner of the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: As I learned more about the platform, the biggest thing that stuck out to me
    was that chat bots are everywhere. There is an incredible underculture I was unaware
    of relating to the building of bots. The vast majority of these bots are built
    using the SDKs, which are open-source projects that wrap much of the client HTTP
    interactions needed to interface with Discord’s API. There are entire ecosystems
    and frameworks built up on top of this to help developers make engaging bots.
  prefs: []
  type: TYPE_NORMAL
- en: 'Naturally, one of the next questions that gets asked all the time is: how can
    I integrate Sanic with my bot application? We are going to try and do that.'
  prefs: []
  type: TYPE_NORMAL
- en: But first, I want to point out that while the example we are going to build
    uses Discord, the principles are in no way connected to running this on Discord.
    The core of what we are about to do is to run some `asyncio` process and reuse
    that loop for running Sanic. This means that you could in fact use this exact
    same technique to run nested Sanic applications. We will see what that looks like
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Building a simple discord bot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I am not an expert with Discord. There is an entire realm of development that
    occurs based upon this platform and I will not pretend to be an authority. Our
    goal here is to integrate a bot application with Sanic. To do this, we are going
    to standup a basic Discord bot using `nextcord`. If you are not familiar with
    `nextcord`, as of the time of the writing of this book, it is an actively maintained
    fork of the abandoned `discord.py` project. If you are also not familiar with
    that, no worries. The simple explanation is that these are frameworks used to
    build a bot application on Discord. Similar to how Sanic provides tools for HTTP
    communications, these frameworks provide tools to communicate with Discord.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a minute to consider the basic hello world application from their
    documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: To be honest, this looks not too dissimilar from what we build in Sanic. It
    starts with an application instance. Then, there are decorators that wrap handlers.
    The last thing we see is a `client.run`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the key to what we want to build. This `run` method is going to create
    a loop and run it until the application is shutdown. Our job now is to run Sanic
    inside of this application. This means we will *not* be using the Sanic cli to
    standup our application. Instead, we will run the application using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by copying the minimal bot example from their documentation into `bot.py`.
    You can grab the code here: [https://nextcord.readthedocs.io/en/latest/quickstart.html](https://nextcord.readthedocs.io/en/latest/quickstart.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a simple Sanic application as a proof of concept.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Nothing fancy is happening so far. We have a single handler that will send off
    a message in a listener before the server starts. And, we also have a single handler
    that will also trigger a message to our Discord server when the route endpoint
    is hit.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To integrate this with the Discord bot, we will use the `on_ready` event to
    run our sanic server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**IMPORTANT NOTICE**'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: For the sake of simplicity, I am just importing from server import app. That
    is because it is a super simple implementation. In actuality, if I were building
    a proper application, I would **NOT** use this pattern. Instead, I would use the
    factory pattern discussed repeatedly throughout this book and build my application
    from a callable. This is to help with import management and to avoid passing global
    scope variables.
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: A few things are happening here that we need to discuss. First, as mentioned,
    this is the syntax used to tell `nextcord` to run this handler when the application
    starts up and is connected to Discord, and therefore “ready.” But, according to
    their documentation, this event could be triggered multiple times. That would
    be a mistake to try and run Sanic multiple times since it would fail to properly
    bind to a socket.To avoid this, we look at the `app.is_running` flag to determine
    if we should run this again.What happens next is that we are going to manually
    create a Sanic server. After that–and this part is critical—we pass that app server
    instance into a *NEW* task. Why? Because if we ran Sanic from the current task
    it would block indefinitely, and the Discord bot would never actually run. Since
    we want them both to run concurrently, it is imperative that we run Sanic from
    another `asyncio` task.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, we need to create that `runner` operation. The job here is to run the
    created server. This means that we need to manually trigger all of the listener
    events. It also means that we need to perform some shutdown of connections. Because
    we are operating at a MUCH lower level than normal, you will be required to be
    more hands on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The job here looks simple. It starts the application, runs some listener events
    and then will listen forever until the application shuts down. Before completely
    exiting, we need to run some cleanup operations inside the finally block.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have all of this implemented, you can run it as we said before by executing
    the bot.py script. You should now see this message in your Discord server that
    was triggered by Sanic during the application startup lifecycle.
  prefs: []
  type: TYPE_NORMAL
- en: <<<< IMAGE >>>>>
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you should be able to hit your single endpoint and see another message:'
  prefs: []
  type: TYPE_NORMAL
- en: <<<< IMAGE >>>>>
  prefs: []
  type: TYPE_NORMAL
- en: Because we are not using the standard method for running Sanic, I do not like
    to recommend this approach. For starters, it is easy to mess up the order of calls
    and either leave out some critical events, or improperly handle things like shutdown.
    Admittedly the shutdown mechanism above is incomplete. For starters, it does not
    include any sort of handling for the graceful shutdown of existing connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads to the next question: instead of running Sanic inside the Discord
    bot, can we run the bot inside Sanic? Yes. That is what we will do next.'
  prefs: []
  type: TYPE_NORMAL
- en: Running the Discord bot from Sanic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we get started, let’s consider what `client.run` is doing. It does whatever
    internal instantiation is needed to run its service, including making a connection
    to the Discord server. Then, it enters into a loop to asynchronously receive and
    send messages to the Discord server. This sounds very similar to what Sanic server
    does. And, therefore, we can do the exact same thing that we just did, except
    in reverse.
  prefs: []
  type: TYPE_NORMAL
- en: Take the code we just built and remove the `on_ready` event from the bot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a startup time listener that starts the bot in a new background task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this listener, we are also doing the same thing we did in the previous example.
    We setup `app.ctx.wadsworth` and `app.ctx.general` so that they are easily accessible
    for use later on in the build. Also, we want to send a message when Wadsworth
    is online and ready to work. Yes, we could do this from the bot using `on_ready`
    as before, but we can also do this from Sanic. In the above code, we create a
    loop to check for the state of the bot. Once it is ready, we will send the message
    and close out the loop.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The next thing we need to make sure to do is to properly close the bot connection.
    We will do that in a shutdown listener.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, you have full capability to run your bot from Sanic. This should behave
    exactly as before, but you have the full power of running your application with
    the Sanic CLI as we have throughout the rest of this book. Go ahead and fire it
    up now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This pattern of nesting other `asyncio` applications has broader applicability
    than just running Discord bots and Sanic together. It also allows us to run multiple
    Sanic applications in the same process, albeit on different ports. This is what
    we are going to do next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nested Sanic applications: running Sanic inside Sanic to create a HTTP proxy'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Running Sanic from within Sanic seems a bit like those Russian nesting dolls.
    While it may initially seem like an amazing thought experiment, it does have some
    real-world applicability. The most obvious example of running two instances of
    Sanic together like this would be to create your own HTTP to HTTPS proxy. That
    is what we are going to do now. Or, at least sort of.
  prefs: []
  type: TYPE_NORMAL
- en: The caveat that I want to add to this is that this example will use a **self-signed
    certificate**. That means that it is not suitable for production use. You should
    look at the section called ___ in Chapter 7 for details on how to properly secure
    your application using TLS.
  prefs: []
  type: TYPE_NORMAL
- en: To begin, we will create two servers. For the sake of simplicity, one will be
    server.py (your main application running HTTPS over port 443) and the other will
    be redirect.py (the HTTP to HTTPS proxy running on port 80).
  prefs: []
  type: TYPE_NORMAL
- en: We will start by creating our self-signed certificate. If you are on a Windows
    machine, you might need to lookup how to do this on your OS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we start building our Sanic application in server.py with a simple factory
    pattern. The code for this build is available at ___.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**TIP**'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: The first thing that I would like to point out is the usage of `SERVER_NAME`.
    This is a configuration value that is unset out of the box in Sanic. It is usually
    something that you should use in all of your applications. It is a helpful value
    used by Sanic behind the scenes in a few locations. For our purpose in this example,
    we want to use it to help us generate URLs further down the road with app.url_for.
    The value should be the domain name of your application, plus the port (if it
    is not using a standard 80 or 443). You should not include the http:// or https://.
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: What is `attach_redirect_app`? This is another application factory. But it will
    work a little bit differently since it will also act to nest the resitect app
    inside of the `MainApp`.The last thing worth pointing out is that there is the
    Blueprint Group bp that we will attach all of our Blueprints to. Except, the `info_view`
    will be separate. More on that in just a bit.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We begin the second factory pattern: `attach_redirect_app` at `redirect.py`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We are attaching two views: the same `info_view` that we just attached to the
    `MainApp`, and the `redirect_view` that will do our redirection logic. We will
    look at that once we are done with the factory and server here in `redirect.py`.Also,
    please notice that we are attaching the `main_app` to the `redirect_app.ctx` for
    later retrieval. As we have learned, passing objects through the ctx is the preferred
    method for handling objects that need to be referenced throughout an application.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next we will add a few listeners to the `MainApp`. This is going to happen inside
    of the `attach_redirect_app` factory. There are some software architects that
    may dislike my nesting of logical concerns together, we are going to silence the
    critics and do it anyway because what we are after is necessarily tightly couple
    logic that will be easy for us to debug and update in the future.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here we are dropping down into some lower level operations of the Sanic server.
    We basically need to mimic what the Sanic CLI and app.run do, except inside the
    confines of the already existing loop.When you run a Sanic server instance, it
    will block the process until shutdown. But we need to have two servers running.
    Therefore, the `RedirectApp` server needs to be run in a background task. We accomplish
    that by pushing off the work of running the server by using add_task. We will
    come back to runner when we are done with the factory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `RedirectApp` also needs to be turned down. Therefore, we attach to the
    MainApp another listener to do that.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Again, what we are accomplishing are some of the high level steps that Sanic
    takes under the hood to stand up a server. It does run `before_start` slightly
    out of order. Typically, that would happen before `create_server`. The impact
    is minimal. Since our `RedirectApp` does not even use any of the even listeners,
    we could do without `before_start` and `after_start` (and the shutdown events
    too).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now to the important part of the application: the redirection view.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This route is going to be fairly all-encompassing. It basically will accept
    every endpoint that remains unmatched, not matter what HTTP method is used. This
    is accomplished using the path parameter type and passing the `HTTP_METHODS` constant
    to the route definition.The job is to redirect the exact same request to the https
    version. You could do this a few ways. For example, the following works:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'However, for me and my brain, I like to use `url_for`. If you prefer the alternative:
    you do you. The redirect function is a convenience method for generating the appropriate
    redirection response. Since our use case calls for a redirection from http to
    https, we use a 301 redirect to indicate that this is a permanent (and not temporary)
    redirection. Let’s see it in action.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To run our application, we need to use the TLS certificates that we generated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We are running the application again using the CLI. Make sure to use `--factory`
    since we are passing it a callable. Also, we are telling Sanic where it can find
    the certificate and key that were generated for the TLS encryption.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once that is running, we jump into a terminal to test with `curl`. First we
    will make sure that both applications are accessible:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This also looks right. Please note that I included `-k` in the curl command.
    This is because of the self-signed certificate we created. Since it is not from
    an official trusted Certificate Authority, `curl` will not automatically issue
    the request until you specifically tell it that the certificate is okay.Something
    that is really interesting about this is that the `/info` endpoint is *NOT* defined
    twice. If you look in the source code, you will see that it is a single blueprint
    that has been applied to both applications. Super handy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'And now we come to the final test: the redirection.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make sure to notice that we are hitting the 8080 port, which is the `RedirectApp`.
    We again use `-k` to tell curl to not worry about certificate validation. We also
    use `-L` to tell `curl` to follow forward any redirections. Lastly, we add `-i`
    to output the full HTTP responses so that we can see what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the above response, we generated an appropriate 301 redirection
    and sent the user on to the https version, which greeted me so nicely by first
    name.
  prefs: []
  type: TYPE_NORMAL
- en: 'And that’s it: a simple HTTP to HTTPS redirection application running Sanic
    inside Sanic.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What I love about building web applications is the chance to build solutions
    to problems. For example, earlier in this chapter we had the problem of wanting
    to run a Javascript development server from Sanic. If you put five different developers
    on that problem, you might end up with five different solutions. I believe that
    building web applications is on some level an art form. That is to say that it
    is not a strict field that must be solved in only one *obvious* way. Rather, what
    is obvious can only be determined given the unique circumstances and parameters
    surrounding your build.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, what we have built here is just the tip of the iceberg for what is
    possible with Sanic. The choices displayed are both some popular use cases, and
    also some use cases that might not be so straightforward. I hope that you can
    take some of the ideas and patterns and put them to good use. By reading this
    book and internalizing the examples in this Chapter, I hope that I have helped
    to stimulate the creative ideas of application building for you.
  prefs: []
  type: TYPE_NORMAL
- en: If we mash up all of the ideas from this chapter into a single application,
    you would end up with a PWA powered by Sanic using distributed websocket feeds
    and a GraphQL API, that also runs a Discord bot. My point is that creating features
    to implement in your application cannot be done in a vacuum. You must consider
    other parts of your architecture when deciding on how to build something. This
    chapter is meant to help see some of my thought process when I tackled these problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we near the conclusion of this book, the last things we need to do is actually
    pull together a lot of what we know into a single deployable application. That
    is what we do next in Chapter 11: build a fully functional, production grade Sanic
    application.'
  prefs: []
  type: TYPE_NORMAL
