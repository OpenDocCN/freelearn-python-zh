<html><head></head><body>
		<div id="_idContainer098">
			<h1 id="_idParaDest-263"><em class="italic"><a id="_idTextAnchor301"/>Chapter 12</em>: Building Serverless Functions using Python</h1>
			<p>Serverless computing is a new model of cloud computing that separates the management of physical or virtual servers and infrastructure-level software, such as database systems, from the application itself. This model allows developers to solely focus on application development and enables someone else to manage the underlying infrastructure resources. Cloud providers are the best option to use to adopt this model. Containers are not only opportune for complex deployments, but they are also a breakthrough technology for the <strong class="bold">serverless computing</strong> era. In addition to containers, there is another form of serverless computing, which is known as <strong class="bold">Function as a Service</strong> (<strong class="bold">FaaS</strong>). In this new paradigm, cloud providers offer a platform to develop and run application functions or <strong class="bold">serverless functions</strong>, usually in response to an event or as a direct call to those functions. All public cloud providers, such as Amazon, Google, Microsoft, IBM, and Oracle, offer this service. The focus of this chapter will be on understanding and building serverless functions using Python.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Introducing serverless functions</li>
				<li>Understanding deployment options for serverless functions</li>
				<li>Learning how to build serverless functions with a case study</li>
			</ul>
			<p>After completing this chapter, you should have a clear understanding of the role of serverless functions in cloud computing and how to build them using Python. </p>
			<h1 id="_idParaDest-264"><a id="_idTextAnchor302"/>Technical requirements</h1>
			<p>The following is a list of the technical requirements for this chapter:</p>
			<ul>
				<li>You will need to have Python 3.7, or later, installed on your computer.</li>
				<li>To deploy a serverless function in <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) Cloud Functions, you will need a GCP account (a free trial will work fine).</li>
				<li>You will need an account (that is, a free account) with <em class="italic">SendGrid</em> for sending emails.</li>
			</ul>
			<p>The sample code for this chapter can be found at <a href="https://github.com/PacktPublishing/Python-for-Geeks/tree/master/Chapter12">https://github.com/PacktPublishing/Python-for-Geeks/tree/master/Chapter12</a>. </p>
			<p>Let's begin with an introduction to serverless functions.</p>
			<h1 id="_idParaDest-265"><a id="_idTextAnchor303"/>Introducing serverless functions</h1>
			<p>A serverless function<a id="_idIndexMarker1331"/> is a model that can be used to develop and execute software components or modules without needing to know or worry about an underlying<a id="_idIndexMarker1332"/> hosting platform. These software modules or components are known as <strong class="bold">Lambda functions</strong> or <strong class="bold">Cloud functions</strong> in <a id="_idIndexMarker1333"/>the public cloud providers' product offerings. Amazon was the first vendor that offered such serverless functions on its AWS platform as <strong class="bold">AWS Lambda</strong>. It <a id="_idIndexMarker1334"/>was followed by Google <a id="_idIndexMarker1335"/>and Microsoft, which offer Google <strong class="bold">Cloud Functions</strong> and <strong class="bold">Azure Functions</strong>, respectively. </p>
			<p>Typically, a serverless function<a id="_idIndexMarker1336"/> has four components, as follows:</p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B17189_12_01.jpg" alt="Figure 12.1 – The components of a serverless function &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.1 – The components of a serverless function </p>
			<p>These four components are described next:</p>
			<ul>
				<li><strong class="bold">Functional code</strong>: This is<a id="_idIndexMarker1337"/> a programming unit that performs certain tasks as per the business or functional goal of the function. For example, we can write a serverless function to process an input stream of data or write a scheduled activity to check certain data resources for monitoring purposes.</li>
				<li><strong class="bold">Events</strong>: Serverless <a id="_idIndexMarker1338"/>functions are not meant to be used like microservices. Instead, they are meant to be used based on a trigger that can be initiated by an event from a pub/sub system, or they can come as HTTP calls based on an external event in the field such as events from field sensors.</li>
				<li><strong class="bold">Outcome</strong>: When a serverless <a id="_idIndexMarker1339"/>function is triggered to do a job, there is an output from the function, which can either be a simple response to the caller or trigger the next actions to mitigate the impact of an event. One example of the outcome of a serverless function is to trigger another cloud service such as a database service or send an email to subscribed parties.</li>
				<li> <strong class="bold">Resources</strong>: Sometimes, functional <a id="_idIndexMarker1340"/>code has to use an additional resource to do its job, for example, a database service or cloud storage to access or push files.</li>
			</ul>
			<h2 id="_idParaDest-266"><a id="_idTextAnchor304"/>Benefits</h2>
			<p>Serverless functions bring with them all the benefits<a id="_idIndexMarker1341"/> of serverless computing, as follows: </p>
			<ul>
				<li><strong class="bold">Ease of development</strong>: Serverless functions take away infrastructure complexities from developers so that they can focus on the functional aspect of the program.</li>
				<li><strong class="bold">Built-in scalability</strong>: Serverless functions are offered with built-in scalability to handle any traffic growth at any time.</li>
				<li><strong class="bold">Cost efficiency</strong>: Serverless functions not only reduce development costs but also offer optimized deployment and an operational mode. Typically, this is a <em class="italic">pay-as-you-use</em> model that means you will only be charged for the time during which your function is being executed.</li>
				<li><strong class="bold">Technology agnostic</strong>: Serverless<a id="_idIndexMarker1342"/> functions are technology agnostic. This means that you can build them in many programming languages using a variety of different cloud resources.</li>
			</ul>
			<p>Note that there are a few limitations to serverless functions; for instance, we will have less system-level control in building such functions and troubleshooting can be tricky without system-level access. </p>
			<h2 id="_idParaDest-267"><a id="_idTextAnchor305"/>Use cases</h2>
			<p>There are several possible<a id="_idIndexMarker1343"/> uses of serverless functions. For example, we can use such functions for data processing if we receive an event of a file upload in cloud storage or if we have data available through real-time streaming. In particular, serverless functions can be integrated with the <strong class="bold">Internet of Things</strong> (<strong class="bold">IoT</strong>) sensors.<a id="_idIndexMarker1344"/> Typically, IoT sensors are thousands in number. Serverless functions possess the ability to handle the requests from such a large number of sensors in a scalable manner. A mobile application can use such functions as a backend service to perform certain tasks or process data without jeopardizing the mobile device resources. One practical use of serverless functions in real life is<a id="_idIndexMarker1345"/> the <strong class="bold">Amazon Alexa</strong> product. It is not possible to put every skill or ounce of intelligence inside the Alexa device itself. Instead, it uses Amazon Lambda functions for these skills. Another reason why Alexa uses Amazon Lambda functions is the ability to scale them based on the demand. For instance, some functions might be used more often than others such as weather queries. </p>
			<p>In the next section, we will investigate the various deployment options for implementing and executing serverless functions.</p>
			<h1 id="_idParaDest-268"><a id="_idTextAnchor306"/>Understanding the deployment options for serverless functions</h1>
			<p>Using a <a id="_idIndexMarker1346"/>virtual machine or another runtime resource on public clouds for sporadically accessed applications might not be a commercially attractive solution. In such situations, serverless functions come to the rescue. Here, a cloud provider offers dynamically managed resources for your application and only charges you when your application is executed in response to a certain event. In other words, a serverless function is a backend computing method that is an on-demand and a pay-as-you-use service that is only offered on public clouds. We will introduce a few options for deploying serverless functions in the public clouds, as follows:</p>
			<ul>
				<li><strong class="bold">AWS Lambda</strong>: This is <a id="_idIndexMarker1347"/>considered to be one of the first service offerings from any of the public cloud providers. AWS Lambda<a id="_idIndexMarker1348"/> functions can be written in Python, Node.js, Java, PowerShell, Ruby, Java, C#, and Go. AWS Lambda functions can be <a id="_idIndexMarker1349"/>executed in response to events, such as file uploads to <strong class="bold">Amazon S3</strong>, a notification from <strong class="bold">Amazon SNS</strong>, or a <a id="_idIndexMarker1350"/>direct API call. AWS Lambda functions are stateless.</li>
				<li><strong class="bold">Azure Functions</strong>: Microsoft introduced Azure Functions almost two years after the launch of AWS <a id="_idIndexMarker1351"/>Lambda functions. These functions can be attached to events within the cloud infrastructure. Microsoft provides support to build and debug these <a id="_idIndexMarker1352"/>functions using Visual Studio, Visual Studio Code, IntelliJ, and Eclipse. Azure Functions can be written in C#, F#, Node.js, PowerShell, PHP, and Python. Additionally, Microsoft offers <strong class="bold">Durable Functions</strong> that<a id="_idIndexMarker1353"/> allow us to write stateful functions in a serverless environment.</li>
				<li><strong class="bold">Google Cloud Functions</strong>: GCP offers<a id="_idIndexMarker1354"/> Google Cloud Functions as serverless functions. Google<a id="_idIndexMarker1355"/> Cloud Functions can be written in Python, Node.js, Go, .NET, Ruby, and PHP. Like its competitors, AWS Lambda and Azure Functions, Google Cloud Functions can be triggered by HTTP requests or by events from the Google Cloud infrastructure. Google allows you to use Cloud Build for the automatic testing and deployment of Cloud Functions.</li>
			</ul>
			<p>In addition to the top three public cloud providers, there are a few more offerings from other cloud providers. For example, IBM offers Cloud Functions that are based on the open source <strong class="bold">Apache OpenWhisk</strong> project. Oracle offers its serverless computing platform based on the <a id="_idIndexMarker1356"/>open source <strong class="bold">Fn</strong> project. The beauty of using these open source projects is that you can develop <a id="_idIndexMarker1357"/>and test your code locally. Additionally, these projects allow you to port your code from one cloud to another cloud or even to an on-premises environment deployment without any changes.</p>
			<p>It is worth mentioning another framework that is well known in serverless computing, called the <strong class="bold">Serverless Framework</strong>. This is <a id="_idIndexMarker1358"/>not a deployment platform but a software tool that can be used locally to build and package your code for serverless deployment and then be used to deploy the package to one of your favorite public clouds. The serverless framework supports several programming languages such as Python, Java, Node.js, Go, C#, Ruby, and PHP. </p>
			<p>In the next section, we will build a couple of serverless functions using Python.</p>
			<h1 id="_idParaDest-269"><a id="_idTextAnchor307"/>Learning how to build serverless functions</h1>
			<p>In this section, we will investigate how to build serverless functions for one of the public cloud providers. Although <a id="_idIndexMarker1359"/>Amazon AWS pioneered serverless functions in 2014 by offering AWS Lambda functions, we will use the Google Cloud Functions platform for our example functions. The reason for this is that we already introduced GCP in great detail in previous chapters, and you can leverage the same GCP account for the deployment of these example functions. However, we strongly recommend that you use the other platforms, especially if you are planning to use their serverless functions in the future. The core principles of building and deploying these functions on various cloud platforms are the same.</p>
			<p>GCP Cloud Functions offers several ways in which to develop and deploy serverless functions (going forward, we will call them <em class="italic">Cloud Functions</em> in the context of GCP). We will explore two types of events in our example Cloud Functions, which can be described as follows:</p>
			<ul>
				<li>The first Cloud Function<a id="_idIndexMarker1360"/> will be built and deployed using the GCP Console from end to end. This Cloud Function will be triggered based on an HTTP call (or event).</li>
				<li>The second Cloud Function will be part of a case study to build an application that listens to an event in the cloud infrastructure and takes an action such as sending an email as a response to this event. The Cloud Function used in this case study will be built and deployed using the Cloud <strong class="bold">Software Development Kit</strong> (<strong class="bold">SDK</strong>).</li>
			</ul>
			<p>We will start by building a Cloud Function using the GCP Console.</p>
			<h2 id="_idParaDest-270"><a id="_idTextAnchor308"/>Building an HTTP-based Cloud Function using the GCP Console</h2>
			<p>Let's begin with the Google<a id="_idIndexMarker1361"/> Cloud Function development process. We will build a very simple Cloud Function that provides today's<a id="_idIndexMarker1362"/> date and current time for an HTTP trigger. Note that the HTTP trigger is the easiest way in which a Cloud Function can be invoked. First, we will need a GCP project. You can create a new GCP project using the GCP Console for this Cloud Function or an existing GCP project. The steps regarding how to create a GCP project and associate a billing account with it are discussed in <a href="B17189_09_Final_PG_ePub.xhtml#_idTextAnchor247"><em class="italic">Chapter 9</em></a>, <em class="italic">Python Programming for the Cloud</em>. Once you have a GCP project ready, building a new Cloud Function is a three-step process. We will explain these steps in the following subsections.</p>
			<h3>Configuring Cloud Function attributes</h3>
			<p>When we <a id="_idIndexMarker1363"/>initiate the <strong class="bold">Create Function</strong> workflow from the GCP Console, we are prompted to provide the Cloud Function definition, as follows: </p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/B17189_12_02.jpg" alt="Figure 12.2 – The steps to create a new Cloud Function using the GCP Console (1/2)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 12.2 – The steps to create a new Cloud Function using the GCP Console (1/2)</p>
			<p>A high-level summary of the <a id="_idIndexMarker1364"/>Cloud Function definition appears as follows:</p>
			<ol>
				<li value="1">We provide the <strong class="bold">Function Name</strong> (in our case, this is <strong class="source-inline">my-datetime</strong>) and select the GCP <strong class="bold">Region</strong> to host this function. </li>
				<li>We select <strong class="source-inline">HTTP</strong> as the <strong class="bold">Trigger type</strong> for our function. Selecting a trigger for your function is the most important step. There are also other triggers available such as <strong class="bold">Cloud Pub/Sub</strong> and <strong class="bold">Cloud Storage</strong>. At the time of writing this book, GCP has added a few more triggers for evaluation purposes. </li>
				<li>For the sake of simplicity, we will allow unauthenticated access for our function. </li>
			</ol>
			<p>After clicking on the <strong class="bold">Save</strong> button, we will be<a id="_idIndexMarker1365"/> prompted to enter <strong class="bold">RUNTIME, BUILD AND CONNECTIONS SETTINGS</strong>, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="image/B17189_12_03.jpg" alt="Figure 12.3 – The steps to create a new Cloud Function using the GCP Console (2/2)"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.3 – The steps to create a new Cloud Function using the GCP Console (2/2)</p>
			<p>We can provide the <strong class="bold">RUNTIME, BUILD AND CONNECTIONS SETTINGS</strong> as follows:</p>
			<ol>
				<li value="1">We can leave the runtime attributes in their default settings, but we will reduce the <strong class="bold">Memory allocated</strong> to <strong class="bold">128 MiB</strong> for our function. We have associated a default service account as a <strong class="bold">Runtime service account</strong> to this function. We will leave <strong class="bold">Auto-scaling</strong> to its default setting, but this can be set to a maximum number of instances for our function.</li>
				<li>We can add <strong class="bold">Runtime environment variables</strong> underneath the <strong class="bold">RUNTIME</strong> tab if we have such a <a id="_idIndexMarker1366"/>requirement to do so. We will not add any environment variables for our Cloud Function.</li>
				<li>Underneath the <strong class="bold">BUILD</strong> tab, there is an option to add <strong class="bold">Build environment variables</strong>. We will not add any variable for our Cloud Function.</li>
				<li>Underneath the <strong class="bold">CONNECTIONS</strong> tab, we can leave the default settings as they are and allow all traffic to access our Cloud Function.  </li>
			</ol>
			<p>After setting the Cloud Function's runtime, build, and connection settings, the next step will be to add the implementation code for this Cloud Function.</p>
			<h3>Adding Python code to a Cloud Function</h3>
			<p>After clicking on the <strong class="bold">Next</strong> button, as<a id="_idIndexMarker1367"/> shown in <em class="italic">Figure 12.3</em>, the GCP <a id="_idIndexMarker1368"/>Console will offer us a view to define or add the function implementation details, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer094" class="IMG---Figure">
					<img src="image/B17189_12_04.jpg" alt="Figure 12.4 – The implementation steps of a Cloud Function using the GCP Console&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.4 – The implementation steps of a Cloud Function using the GCP Console</p>
			<p>The options that are available for adding our Python code are as follows:</p>
			<ul>
				<li>We can select several runtime options such as Java, PHP, Node.js, or various Python versions. We selected <strong class="bold">Python 3.8</strong> as the <strong class="bold">Runtime</strong> for our Cloud Function. </li>
				<li>The <strong class="bold">Entry point</strong> attribute must be the name of the function in our code. Google Cloud Function will invoke the function in our code based on this <strong class="bold">Entry point</strong> attribute.</li>
				<li>The Python <a id="_idIndexMarker1369"/>source code can be added inline using<a id="_idIndexMarker1370"/> the <strong class="bold">Inline Editor</strong> on the right-hand side; alternatively, it can be uploaded using a ZIP file from your local machine or even from cloud storage. We can also provide the GCP <strong class="bold">Cloud Source</strong> repository location for the source code. Here, we selected to implement our function using the <strong class="bold">Inline Editor</strong> tool.</li>
				<li>For Python, the GCP Cloud Functions platform automatically creates two files: <strong class="source-inline">main.py</strong> and <strong class="source-inline">requirements.txt</strong>. The <strong class="source-inline">main.py</strong> file will have our code implementation and the <strong class="source-inline">requirements.txt</strong> file should contain our dependencies on third-party libraries.<p>A sample code, which is shown inside the <strong class="bold">Inline Editor</strong> tool first checks if the caller has sent a <strong class="source-inline">requester</strong> <a id="_idIndexMarker1371"/>attribute in the HTTP request or not. Based on <a id="_idIndexMarker1372"/>the <strong class="source-inline">requester</strong> attribute value, we will send a welcome message with today's date and time. We implemented a similar code example with two separate web APIs using a Flask web application in <a href="B17189_09_Final_PG_ePub.xhtml#_idTextAnchor247"><em class="italic">Chapter 9</em></a>, <em class="italic">Python Programming for the Cloud</em>, to demonstrate the capabilities of GCP App Engine.</p></li>
			</ul>
			<p>Once we are satisfied with our Python code, we will deploy the function on the Google Cloud Functions platform.</p>
			<h3>Deploying a Cloud Function</h3>
			<p>The next step is <a id="_idIndexMarker1373"/>to deploy this function using the <strong class="bold">Deploy</strong> button at the bottom of the screen, as shown in <em class="italic">Figure 12.4</em>. GCP will start deploying the function immediately, and it can take a few minutes to complete this activity. It is important to understand that Google Cloud Functions are deployed using containers just like microservices on GCP Cloud Run. The key differences are that they can be invoked using different types of events and they use the pay-as-you-use pricing model.</p>
			<p>Once our function has been deployed, we can duplicate it, test it, or delete it from the <strong class="bold">Cloud Functions</strong> list, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="image/B17189_12_05.jpg" alt="Figure 12.5 – The main view of Google Cloud Functions &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.5 – The main view of Google Cloud Functions </p>
			<p>Now, we will quickly show you how convenient it is to test and troubleshoot our Cloud Function using the GCP Console. Once we have selected the <strong class="bold">Test function</strong> option for our newly deployed Cloud Function, the GCP Console will offer us a test page, which is similar to the one shown in <em class="italic">Figure 12.6</em>, underneath the <strong class="bold">TESTING</strong> tab. To test our deployed Cloud Function, we can pass the <strong class="source-inline">requester</strong> attribute in JSON format, as follows:</p>
			<p class="source-code">{"requester":"John"} </p>
			<p>After clicking on <strong class="bold">[…]TEST THE FUNCTION</strong>, we can view the results under the <strong class="bold">Output</strong> section and the log <a id="_idIndexMarker1374"/>details under the <strong class="bold">Logs</strong> section at the bottom of the screen, as shown in <em class="italic">Figure 12.6</em>. Because we are using an HTTP trigger for our Cloud Function, we can also test it by using a web browser or <strong class="source-inline">CURL</strong> utility from anywhere on the internet. However, we have to make sure that our Cloud Function includes <strong class="source-inline">allUsers</strong> as its member with the role of <strong class="source-inline">Cloud Functions Invoker</strong>. This can be set underneath the <strong class="bold">PERMISSIONS</strong> tab. However, we do not recommend doing so without setting an authentication mechanism for your Cloud Function: </p>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="image/B17189_12_06.jpg" alt="Figure 12.6 – Testing your Cloud Function using the GCP Console&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.6 – Testing your Cloud Function using the GCP Console</p>
			<p>Building a simple Cloud Function using the GCP Console is a straightforward process. Next, we will explore a case study of a real-world application of Cloud Functions.</p>
			<h2 id="_idParaDest-271"><a id="_idTextAnchor309"/>Case study – building a notification app for cloud storage events</h2>
			<p>In this case study, we will develop a<a id="_idIndexMarker1375"/> Cloud Function that is <a id="_idIndexMarker1376"/>triggered for events on<a id="_idIndexMarker1377"/> a <strong class="bold">Google Storage bucket</strong>. On receiving such an event, our Cloud Function will send an email to a predefined list of email addresses as a notification. The flow of this notification app with a Cloud Function appears as follows:</p>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/B17189_12_07.jpg" alt="Figure 12.7 – A Cloud Function listening to Google storage bucket events&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.7 – A Cloud Function listening to Google storage bucket events</p>
			<p>Note that we can set our Cloud Function to listen to one or more Google Storage events. Google Cloud Functions supports the following Google Storage events:</p>
			<ul>
				<li><strong class="bold">finalize</strong>: This event<a id="_idIndexMarker1378"/> is created when a new file is added or replaced within a storage bucket.</li>
				<li><strong class="bold">delete</strong>: This<a id="_idIndexMarker1379"/> event represents the deletion of a file from a storage bucket. This applies to non-versioning buckets. Note that a file is not deleted in reality, but it is archived if the bucket is set to use versioning.</li>
				<li><strong class="bold">archive</strong>: This <a id="_idIndexMarker1380"/>event is raised when a file is archived. The archive operation is triggered when a file is deleted or overwritten for buckets with versioning.</li>
				<li><strong class="bold">metadata update</strong>: If there<a id="_idIndexMarker1381"/> is any update in the metadata of a file, this event is created.</li>
			</ul>
			<p>After receiving an event<a id="_idIndexMarker1382"/> from a Google Storage bucket, the<a id="_idIndexMarker1383"/> Cloud Function will extract the attributes from the context and event objects passed as arguments to our Cloud Function. Then, the cloud function will use a third-party email service (such as <em class="italic">SendGrid</em> from <em class="italic">Twilio</em>) to send the notification.</p>
			<p>As a prerequisite, you have to create a free account with <em class="italic">SendGrid</em> (<a href="https://sendgrid.com/">https://sendgrid.com/</a>). After creating an account, you will need to create at least one sender user inside your <em class="italic">SendGrid</em> account. Additionally, you will need to set up a secret API key inside the <em class="italic">SendGrid</em> account that can be used with the Cloud Function to send emails. Twilio SendGrid offers within the range of <em class="italic">100</em> emails per day for free, which is good enough for testing purposes.</p>
			<p>For this case study, we will write our Python code for the Cloud Function locally and then deploy it to the Google Cloud Functions platform using the Cloud SDK. We will implement this notification <a id="_idIndexMarker1384"/>application step by step, as follows: </p>
			<ol>
				<li value="1">We will create a storage <a id="_idIndexMarker1385"/>bucket to attach to our Cloud Function, and we will upload or delete files from this bucket to simulate the events of our Cloud Function. We can use the following Cloud SDK command to create a new bucket:<p class="source-code">gsutil mb gs://&lt;bucket name&gt;</p><p class="source-code">gsutil mb gs://muasif-testcloudfn    #Example bucket   created</p><p>To keep the generation of these events simple, we will turn off the versioning on our storage bucket by using the following Cloud SDK command:</p><p class="source-code">gsutil <strong class="bold">versioning</strong> set off gs://muasif-testcloudfn</p></li>
				<li>Once the storage bucket is ready, we will create a local project directory and set up a virtual environment using the following commands:<p class="source-code">python -m venv myenv</p><p class="source-code">source myenv/bin/activate</p></li>
				<li>Next, we will install the <strong class="source-inline">sendgrid</strong> Python package using the <strong class="source-inline">pip</strong> utility, as follows:<p class="source-code">pip install sendgrid</p></li>
				<li>Once our third-party libraries have been installed, we will need to create the <strong class="source-inline">requirements.txt</strong> dependencies file, as follows:<p class="source-code">pip freeze -&gt; requirements.txt</p></li>
				<li>Next, we will create a new Python file (<strong class="source-inline">main.py</strong>) with a <strong class="source-inline">handle_storage_event</strong> function within it. This function will be the entry point for our Cloud <a id="_idIndexMarker1386"/>Function. The sample<a id="_idIndexMarker1387"/> code for this entry point function is as follows: <p class="source-code">#<strong class="bold">main.py</strong></p><p class="source-code">from sendgrid import SendGridAPIClient</p><p class="source-code">from sendgrid.helpers.mail import Mail, Email, To,   Content</p><p class="source-code">def <strong class="bold">handle_storage_event</strong>(<strong class="bold">event</strong>, <strong class="bold">context</strong>):</p><p class="source-code">  from_email = <strong class="bold">Email</strong>("abc@domain1.com")</p><p class="source-code">  to_emails = <strong class="bold">To</strong>("zyz@domain2.com")</p><p class="source-code">  subject = "Your Storage Bucket Notification"</p><p class="source-code">  content = f"Bucket Impacted:{event['bucket']} \n" + \</p><p class="source-code">             f"File Impacted: {event['name']} \n " + \</p><p class="source-code">             f"Event Time: {event['timeCreated']} \n" + \</p><p class="source-code">             f"Event ID: {context.event_id} \n" + \</p><p class="source-code">             f"Event Type: {context.event_type}"</p><p class="source-code">  mail = <strong class="bold">Mail(from_email, to_emails, subject, content)</strong></p><p class="source-code">  sg = SendGridAPIClient()</p><p class="source-code">  response = sg.send(mail)</p><p class="source-code">  print(response.status_code) # for logging purpose</p><p class="source-code">  print(response.headers)</p><p>In the preceding Python code example, our <strong class="source-inline">handle_storage_event</strong> function is expected to receive <strong class="source-inline">event</strong> and <strong class="source-inline">context</strong> objects as input arguments. An <strong class="source-inline">event</strong> object is a dictionary that contains the data of the event. We can access the event<a id="_idIndexMarker1388"/> data from this<a id="_idIndexMarker1389"/> object using keys such as <strong class="source-inline">bucket</strong> (that is, the bucket name), <strong class="source-inline">name</strong> (that is, the filename), and <strong class="source-inline">timeCreated</strong> (that is, the creation time). The <strong class="source-inline">context</strong> object provides the context of the event such as <strong class="source-inline">event_id</strong> and <strong class="source-inline">event_type</strong>. Additionally, we use the <strong class="source-inline">sendgrid</strong> library to prepare the email contents and then send the email with the event information to the target email list.</p></li>
				<li>Once we have our Python code file (in our case, this is <strong class="source-inline">main.py</strong>) and <strong class="source-inline">requirements.txt</strong> files ready, we can trigger the deployment operation using the following Cloud SDK command:<p class="source-code">gcloud functions deploy <strong class="bold">handle_storage_create</strong> \</p><p class="source-code">--entry-point <strong class="bold">handle_storage_event</strong> --runtime python38 \</p><p class="source-code">--trigger-resource <strong class="bold">gs://muasif-testcloudfn/</strong>\</p><p class="source-code">--trigger-event <strong class="bold">google.storage.object.finalize</strong></p><p class="source-code">--set-env-vars <strong class="bold">SENDGRID_API_KEY</strong>=&lt;Your SEND-GRID KEY&gt;</p><p>We should run this command under a GCP project with billing enabled, as discussed in the previous section. We have provided the name for our Cloud Function as <strong class="source-inline">handle_storage_create</strong>, and the <strong class="source-inline">entry-point</strong> attribute is set to the <strong class="source-inline">handle_storage_event</strong> function in the Python code. We set <strong class="source-inline">trigger-event</strong> to the <strong class="source-inline">finalize</strong> event. By using <strong class="source-inline">set-env-vars</strong>, we set <strong class="source-inline">SENDGRID_API_KEY</strong> for the SendGrid service.</p><p>The <strong class="source-inline">deploy</strong> command will package the Python code from the current directory, prepare the target platform as per the <strong class="source-inline">requirements.txt</strong> file, and then deploy our Python code to the GCP Cloud Functions platform. In our case, we can create a <strong class="source-inline">.gcloudignore</strong> file to exclude the files and directories so that they can be ignored by the Cloud SDK <strong class="source-inline">deploy</strong> command.</p></li>
				<li>Once we deploy our Cloud Function, we can test it by uploading a local file to our storage bucket using the Cloud SDK command, as follows:<p class="source-code">gsutil <strong class="bold">cp</strong> test1.txt gs://muasif-testcloudfn</p><p>As soon as the file copy operation (upload) has been completed, the <strong class="source-inline">finalize</strong> event will trigger the execution of our Cloud Function. As a result, we will receive an email with the event details. We can also check the logs of the Cloud Functions by using the<a id="_idIndexMarker1390"/> following command:</p><p class="source-code">gcloud functions logs read --limit 50</p></li>
			</ol>
			<p>For this notification app, we attached our Cloud Function to the <strong class="source-inline">Finalize</strong> event only. However, what if want to attach <a id="_idIndexMarker1391"/>another event type as well, such as a <strong class="source-inline">Delete</strong> event? Well, only one Cloud Function can be attached to one trigger event. But hold on, a Cloud Function is a deployment entity and not the actual program code. This means we do not need to write or duplicate our Python code to handle another type of event. We can create a new Cloud Function using the same Python code but for the <strong class="source-inline">Delete</strong> event, as follows: </p>
			<p class="source-code">gcloud functions deploy <strong class="bold">handle_storage_delete</strong> \</p>
			<p class="source-code">--entry-point <strong class="bold">handle_storage_event</strong> --runtime python38 \</p>
			<p class="source-code">--trigger-resource gs://muasif-testcloudfn/ \</p>
			<p class="source-code">--trigger-event <strong class="bold">google.storage.object.delete</strong></p>
			<p class="source-code">--set-env-vars SENDGRID_API_KEY=&lt;Your SEND-GRID KEY&gt;</p>
			<p>If you notice this version of the <strong class="source-inline">deploy</strong> command, the only changes we made were with the <em class="italic">name</em> of the Cloud Function and the <em class="italic">type</em> of the trigger event. This <strong class="source-inline">deploy</strong> command will create a new Cloud Function and will work in parallel to an earlier Cloud Function but will be triggered based on a different event (in this case, this is <strong class="source-inline">delete</strong>).</p>
			<p>To test the <strong class="source-inline">delete</strong> event with our newly added Cloud Function, we can remove the already uploaded file (or any file) from our storage bucket using the following Cloud SDK command: </p>
			<p class="source-code">gsutil <strong class="bold">rm</strong> gs://muasif-testcloudfn/test1.txt</p>
			<p>We can create more Cloud<a id="_idIndexMarker1392"/> Functions using the same <a id="_idIndexMarker1393"/>Python code for other storage events. This concludes our discussion of how to build Cloud Functions for storage events using the Cloud SDK. All the steps discussed using the Cloud SDK can also be implemented using the GCP Console.</p>
			<h1 id="_idParaDest-272"><a id="_idTextAnchor310"/>Summary</h1>
			<p>In this chapter, we introduced serverless computing and FaaS, followed by an analysis of the main ingredients of serverless functions. Next, we discussed the key benefits of serverless functions and their pitfalls. Additionally, we analyzed several deployment options that are available to build and deploy serverless functions, and these options include AWS Lambda, Azure Functions, Google Cloud Functions, Oracle Fn, and IBM Cloud Functions. In the final part of this chapter, we built a simple Google Cloud Function based on an HTTP trigger using the GCP Console. Then, we built a notification app based on Google storage events and a Google Cloud Function using the Cloud SDK. These serverless functions were deployed using the Google Cloud Functions platform.</p>
			<p>The code examples included in this chapter should provide you with some experience of how to use both the GCP Console and the Cloud SDK to build and deploy Cloud Functions. This hands-on knowledge is beneficial for anyone who is looking to build a career in serverless computing.</p>
			<p>In the next chapter, we will explore how to use Python with machine learning.</p>
			<h1 id="_idParaDest-273"><a id="_idTextAnchor311"/>Questions</h1>
			<ol>
				<li value="1">How are serverless functions different from microservices?</li>
				<li>What is the practical use of serverless functions in real-world examples?</li>
				<li>What are Durable functions and who offers them? </li>
				<li>One Cloud Function can be attached to multiple triggers. Is this true or false?</li>
			</ol>
			<h1 id="_idParaDest-274"><a id="_idTextAnchor312"/>Further reading</h1>
			<ul>
				<li><em class="italic">Serverless Computing with Google Cloud</em> by Richard Rose</li>
				<li><em class="italic">Mastering AWS Lambda</em> by Yohan Wadia</li>
				<li><em class="italic">Mastering Azure Serverless Computing</em> by Lorenzo Barbieri and Massimo Bonanni</li>
				<li><em class="italic">Google Cloud Functions Quickstart tutorials</em> for building and deploying Cloud Functions, which is available at <a href="https://cloud.google.com/functions/docs/quickstarts">https://cloud.google.com/functions/docs/quickstarts</a></li>
			</ul>
			<h1 id="_idParaDest-275"><a id="_idTextAnchor313"/>Answers</h1>
			<ol>
				<li value="1">Both are two different offerings of serverless computing. Typically, serverless functions are triggered by an event and are based on the <em class="italic">pay-as-you-use</em> model. In comparison, microservices are typically consumed through API calls and are not based on the <em class="italic">pay-as-you-use</em> model.</li>
				<li>Amazon Alexa uses AWS Lambda functions to provide intelligence and other skills for its users.</li>
				<li>Durable functions are an extension of Microsoft Azure Functions, which offers stateful functionality in a serverless environment. </li>
				<li>False. One Cloud Function can only be attached to a single trigger.</li>
			</ol>
		</div>
	</body></html>