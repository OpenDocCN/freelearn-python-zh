- en: Chapter 16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Project 5.2: Simple Multivariate Statistics'
  prefs: []
  type: TYPE_NORMAL
- en: Are variables related? If so what’s the relationship? An analyst tries to answer
    these two questions. A negative answer — the null hypothesis — doesn’t require
    too many supporting details. A positive answer, on the other hand, suggests that
    a model can be defined to describe the relationship. In this chapter, we’ll look
    at simple correlation and linear regression as two elements of modeling a relationship
    between variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll expand on some skills of data analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: Use of the built-in `statistics` library to compute correlation measures and
    linear regression coefficients.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use of the **matplotlib** library to create images. This means creating plot
    images outside a Jupyter Lab environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expanding on the base modeling application to add features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This chapter’s project will expand on earlier projects. Look back at [*Chapter** 13*](ch017.xhtml#x1-29700013),
    [*Project 4.1: Visual Analysis Techniques*](ch017.xhtml#x1-29700013) for some
    of the graphical techniques used in a Jupyter Lab context. These need to be more
    fully automated. The project will add multivariate statistics and graphs to illustrate
    relationships among variables.'
  prefs: []
  type: TYPE_NORMAL
- en: 16.1 Description
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [*Chapter** 15*](ch019.xhtml#x1-32500015), [*Project 5.1: Modeling Base
    Application*](ch019.xhtml#x1-32500015) we created an application to create a summary
    document with some core statistics. In that application, we looked at univariate
    statistics to characterize the data distributions. These statistics included measurements
    of the location, spread, and shape of a distribution. Functions like mean, median,
    mode, variance, and standard deviation were emphasized as ways to understand location
    and spread. The characterization of shape via skewness and kurtosis was left as
    an extra exercise for you.'
  prefs: []
  type: TYPE_NORMAL
- en: The base application from the previous chapter needs to be expanded to include
    the multivariate statistics and diagrams that are essential for clarifying the
    relationships among variables. There are a vast number of possible functions to
    describe the relationships among two variables. See [https://www.itl.nist.gov/div898/handbook/pmd/section8/pmd8.htm](https://www.itl.nist.gov/div898/handbook/pmd/section8/pmd8.htm)
    for some insight into the number of choices available.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll limit ourselves to linear functions. In the simplest cases, there are
    two steps to creating a linear model: identifying a correlation and creating the
    coefficients for a line that fits the data. We’ll look at each of these steps
    in the next two sections.'
  prefs: []
  type: TYPE_NORMAL
- en: 16.1.1 Correlation coefficient
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The coefficient of correlation measures how well the values of two variables
    correlate with each other. A value of 1 indicates perfect correlation; a value
    of zero indicates no discernable correlation. A value of -1 indicates an “anti-correlation”:
    when one variable is at its maximum value, the other variable is at its minimum.'
  prefs: []
  type: TYPE_NORMAL
- en: See [*Figure 16.1*](#16.1) to see how the correlation coefficient describes
    the distribution of the two variables.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.1: Correlation Coefficients ](img/file64.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.1: Correlation Coefficients'
  prefs: []
  type: TYPE_NORMAL
- en: 'The computation of the coefficient compares individual values of variables,
    *X*[i] and *Y* [i], to the mean values for those variables, *X* and *Ȳ*. Here’s
    a formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ ∑ r = ∘-∑---(Xi-−-¯X∘)(Y∑i-−-¯Y)----- (Xi − ¯X )2 (Yi − ¯Y )2 ](img/file65.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The computations of the mean values, *X* and *Ȳ*, can be factored into this,
    creating a somewhat more complicated version that’s often used to create the coefficient
    in a single pass through the data.
  prefs: []
  type: TYPE_NORMAL
- en: This function is available as `statistics.correlation()` in the `standard` library.
  prefs: []
  type: TYPE_NORMAL
- en: If two variables correlate with each other, then a linear function will map
    one variable to a value near the other variable. If the correlation is 1.0 or
    -1.0, the mapping will be exact. For other correlation values, the mapping will
    be close, but not exact. In the next section, we’ll show how to transform the
    correlation coefficient into the parameters for a line.
  prefs: []
  type: TYPE_NORMAL
- en: 16.1.2 Linear regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One equation for a line is *y* = *mx* + *b*. The values of *m* and *b* are parameters
    that describe the specific linear relationship between the *x* and *y* variables.
  prefs: []
  type: TYPE_NORMAL
- en: When fitting a line to data, we’re estimating the parameters for a line. The
    goal is to minimize the error between the line and the actual data. The “least
    squares” technique is often used.
  prefs: []
  type: TYPE_NORMAL
- en: 'The two coefficients, *b* and *m*, can be computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ ∑ ∑ ∑ ∑ X2i Y 2i − Xi XiYi b = ----n-∑--X2-−-(∑-X--)2---- i i ](img/file66.jpg)![
    ∑ ∑ ∑ m = n---X∑iYi-−--∑-Xi---Yi n X2i − ( Xi)2 ](img/file67.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is available as `statistics.linear_regression()` in the standard library.
    This saves us from having to write these two functions.
  prefs: []
  type: TYPE_NORMAL
- en: The various sums and sums of squares are not terribly difficult values to compute.
    The built-in `sum()` function is the basis for most of this. We can use `sum(map(lambda`` x:`` x^2,`` x_values))`
    to compute ∑ *X*[i]².
  prefs: []
  type: TYPE_NORMAL
- en: To clarify these multivariate relationships, diagrams can be very helpful. In
    the next sections, we’ll look at the most important type of diagram that needs
    to be part of the overall application.
  prefs: []
  type: TYPE_NORMAL
- en: 16.1.3 Diagrams
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One essential diagram for showing multivariate data is the X-Y “scatter” plot.
    In [*Chapter** 13*](ch017.xhtml#x1-29700013), [*Project 4.1: Visual Analysis Techniques*](ch017.xhtml#x1-29700013)
    we looked at ways to create these. In that chapter, we relied on Jupyter Lab to
    present the diagram as part of the overall web page. For this application, we’ll
    need to embed the diagram into a document.'
  prefs: []
  type: TYPE_NORMAL
- en: This generally means there will be a markup document that includes a reference
    to a diagram file. The format of the diagram file can be SVG, PNG, or even JPEG.
    For technical graphics, the SVG files are often the smallest and scale extremely
    well.
  prefs: []
  type: TYPE_NORMAL
- en: Each markup language, including Markdown, RST, HTML, and LaTeX, have unique
    ways to identify the place where an image needs to be inserted. In the case of
    Markdown, it’s often necessary to use HTML syntax to properly include frames and
    captions.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve seen what the application needs to do, we can look at an approach
    to create the software.
  prefs: []
  type: TYPE_NORMAL
- en: 16.2 Approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As with the previous project, this application works in these two distinct
    parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the statistics and create the diagram files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a report file in a simplified markup language from a template with the
    details interpolated. A tool like **Jinja** is very helpful for this.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the report file in a markup language — like Markdown or RST — is available,
    then a tool like **Pandoc** can be used to create an HTML page or a PDF document
    from the markup file. Using a tool like **Pandoc** permits quite a bit of flexibility
    in choosing the final format. It also allows the insertion of style sheets and
    page templates in a tidy, uniform way.
  prefs: []
  type: TYPE_NORMAL
- en: The LaTeX language as markup provides the most comprehensive capabilities. It
    is challenging to work with, however. Languages like Markdown and RST are designed
    to offer fewer, easier-to-use capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: This book is written with LaTeX.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll look at three aspects of this application: the statistical computations,
    creating the diagrams, and finally, creating the final markup file to include
    the diagrams. We’ll start with a quick review of the statistical computations.'
  prefs: []
  type: TYPE_NORMAL
- en: 16.2.1 Statistical computations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The statistical summary output file, in TOML notation, has a section for each
    variable and the univariate statistics about those variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section of the file looked like the following snippet of TOML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When parsed, the TOML syntax of `x.location` and `x.spread` creates a dictionary
    that looks like the following fragment of a Python object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This structure can be expanded to include additional locations and spread statistical
    measures. It can also be expanded to include multivariate statistics. The `statistics`
    module has `correlation()` and `covariance()` functions, making it easy to include
    these measures.
  prefs: []
  type: TYPE_NORMAL
- en: 'For datasets with few variables, it’s common to consider a matrix that includes
    all the combinations of covariance between variables. This leads to two alternative
    representations of these additional statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: A separate section for a covariance matrix. A section label of `[covariance]`
    can be followed by nested dictionaries that include all combinations of variables.
    Since the covariance matrix is symmetric, all *n*² combinations aren’t needed;
    only *n*× (*n*− 1) values are unique.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multivariate sub-sections within each variable’s section. This means we’d have
    `x.location`, `x.spread`, `x.covariance.y`, and `x.correlation.y` sub-sections
    for the `x` variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a dataset with fewer variables, it seems sensible to bundle covariance and
    correlation into the details for a given variable. In the case of Anscombe’s Quartet,
    with only two variables, the covariance and correlation seem like they belong
    with the other statistics.
  prefs: []
  type: TYPE_NORMAL
- en: For a dataset with a larger number of variables, the covariance among all the
    variables can become bewildering. In these cases, a technique like finding principal
    components might be needed to reduce the number of variables to a more manageable
    population. In this case, separate sections with covariance and auto-correlation
    might be more useful.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting model is often the result of some careful thought, based on the
    covariance matrix. For this reason, a separate `[model]` section should be provided
    with some details about the model’s structure and the coefficients. In the case
    of a linear model, there are two coefficients, sometimes called *β*[0] and *β*[1].
    We’ve called them *b* and *m*.
  prefs: []
  type: TYPE_NORMAL
- en: For Python 3.11, the included `tomllib` module doesn’t create TOML-format files.
    It’s, therefore, necessary to properly format a text file that can be parsed by
    the `tomllib` module. It’s helpful to use a Jinja template for this.
  prefs: []
  type: TYPE_NORMAL
- en: 16.2.2 Analysis diagrams
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Diagrams must first be created. Once created, they can then be included in a
    document. The process of creating a diagram is nearly identical to the approach
    used in Jupyter Lab. A few extra steps need to be taken to export the diagram
    to a file that can be imported into a document.
  prefs: []
  type: TYPE_NORMAL
- en: 'When working in Jupyter Lab, some cells to load the data are required to create
    two variables, `x` and `y`, with the values to be plotted. After these cells,
    a cell like the following example will create and display a scatter plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This presumes previous cells have loaded clean data and extracted two list objects,
    `x` and `y`, with the values to be plotted.
  prefs: []
  type: TYPE_NORMAL
- en: 'The above code sample doesn’t save the resulting PNG or SVG file, however.
    To save the figure, we need to perform two more steps. Here are the lines of code
    required to create a file from the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It helps to transform this cell’s code into a function. This function has proper
    type annotations so that a tool like **mypy** can confirm the types are used properly.
    It can also have unit test cases to be sure it really works.
  prefs: []
  type: TYPE_NORMAL
- en: The `savefig()` function will write a new file in PNG format with the image.
    If the file path suffix is `’.jpg’` then an SVG format file will be created.
  prefs: []
  type: TYPE_NORMAL
- en: The size of the figure is defined by the `figure()` function. There are often
    design and page layout considerations that suggest an appropriate size for a figure.
    This decision can be deferred, and the size can be provided by the markup used
    to create a final PDF file or HTML page. It’s often best, however, to create the
    figure in the required size and resolution to avoid any unexpected alterations
    as part of the final publication.
  prefs: []
  type: TYPE_NORMAL
- en: Once the diagram has been created, the Markdown needs to refer to the diagram’s
    PNG or SVG file so it can be included in a document. We’ll look at some examples
    of this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 16.2.3 Including diagrams in the final document
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Diagrams are included in the final document by using markup commands to show
    where the diagram should be placed, and providing other information about captions
    and sizing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Markdown language has a tidy format for the simplest case of including
    an image in a document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Depending on the style sheet, this may be perfectly acceptable. In some cases,
    the image is the wrong size for its role in the document. Markdown permits using
    HTML directly instead of the `![image!](path)` construct. Including a diagram
    often looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Using HTML permits more control over image size and placement via references
    to CSS.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using RST, the syntax offers more options without switching to HTML. Including
    a diagram would be like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Using this kind of markup technique creates considerable freedom. The report’s
    author can include content from a variety of sources. This can include boilerplate
    text that doesn’t change, the results of computations, some text based on the
    computations, and important diagrams.
  prefs: []
  type: TYPE_NORMAL
- en: The formatting of the markup has little impact on the final document. The way
    a browser renders HTML depends on the markup and the style sheets, not the formatting
    of the source file. Similarly, when creating a PDF document, this is often done
    by LaTeX tools, which create the final document based on LaTeX settings in the
    document’s preamble.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an approach, we can look at the deliverable files that must
    be built.
  prefs: []
  type: TYPE_NORMAL
- en: 16.3 Deliverables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This project has the following deliverables:'
  prefs: []
  type: TYPE_NORMAL
- en: Documentation in the `docs` folder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acceptance tests in the `tests/features` and `tests/steps` folders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit tests for model module classes in the `tests` folder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mock objects for the `csv_extract` module tests that will be part of the unit
    tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit tests for the `csv_extract` module components that are in the `tests` folder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An application to extend the summary written to a TOML file, including figures
    with diagrams.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An application secondary feature to transform the TOML file to an HTML page
    or PDF file with the summary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll look at a few of these deliverables in a little more detail. We’ll start
    with some suggestions for creating the acceptance tests.
  prefs: []
  type: TYPE_NORMAL
- en: 16.3.1 Acceptance tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we noted in the previous chapter’s section on acceptance testing, [*Acceptance*
    *testing*](ch019.xhtml#x1-3340001), the output TOML document can be parsed and
    examined by the `Then` steps of a scenario. Because we’re looking at Anscombe’s
    Quartet data in the examples in this book, a subset of data for testing doesn’t
    really make much sense. For any other dataset, a subset should be extracted and
    used for acceptance testing.
  prefs: []
  type: TYPE_NORMAL
- en: It is often helpful to extract a small subset that’s used for acceptance testing.
    Instead of processing millions of rows, a few dozen rows are adequate to confirm
    the application read and summarized data. The data should be representative of
    the entire set of samples under consideration.
  prefs: []
  type: TYPE_NORMAL
- en: This subset is part of the testing suite; as such, it rarely changes. This makes
    the results predictable.
  prefs: []
  type: TYPE_NORMAL
- en: The secondary feature of this application — expanding on the TOML output to
    add extensive Markdown — also works with text files. This makes it relatively
    easy to create scenarios to confirm the correct behavior by reading and writing
    text files. In many cases, the `Then` steps will look for a few key features of
    the resulting document. They may check for specific section titles or a few important
    keywords included in boilerplate text. Of course, the test scenario can check
    for substitution values that are computed and are part of the TOML summary.
  prefs: []
  type: TYPE_NORMAL
- en: The automated testing can’t easily confirm that the document makes sense to
    prospective readers. It can’t be sure the colors chosen for the figures make the
    relationships clear. For this kind of usability test, a good copy editor or trusted
    associate is essential.
  prefs: []
  type: TYPE_NORMAL
- en: 16.3.2 Unit tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A unit test for a function to create a figure can’t do very much. It’s limited
    to confirming that a PNG or SVG file was created. It’s difficult for an automated
    test to “look” at the image to be sure it has a title, labels for the axes, and
    sensible colors.
  prefs: []
  type: TYPE_NORMAL
- en: It is important not to overlook the unit test cases that confirm output files
    are created. A figure that looks great in a Jupyter notebook will not get written
    to a file unless the CLI application saves the figure to a file.
  prefs: []
  type: TYPE_NORMAL
- en: For some applications, it makes sense to mock the `plt` package functions to
    be sure the application calls the right functions with the expected argument values.
    Note that a mocked version of `plt.subplots()` may need to return a tuple with
    several `Mock` objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll need to define a complex collection of mock objects to form the fixture
    for testing. The fixture creation can look like the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This fixture creates three mock objects. The `plt_mock` is a mock of the overall
    `plt` module; it defines three mock functions that will be used by the application.
    The `fig_mock` is a mock of the figure object returned by the `subplots()` function.
    The `ax_mock` is a mock of the axes object, which is also returned by the `subplots()`
    function. This mocked axes object is used to provide axis labels, and the title,
    and perform the scatter plot request.
  prefs: []
  type: TYPE_NORMAL
- en: 'This three-tuple of mock objects is then used by a test as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This test function evaluates the application’s `scatter_figure()` function.
    The test function then confirms that the various functions from the `plt` module
    are called with the expected argument values.
  prefs: []
  type: TYPE_NORMAL
- en: The test can continue by looking at the calls to the `ax_mock` object to see
    if the labels and title requests were made as expected. This level of detail —
    looking at the calls to the axes object — may be a bit too fine-grained. These
    tests become very brittle as we explore changing titles or colors to help make
    a point more clearly.
  prefs: []
  type: TYPE_NORMAL
- en: The overall use of mock objects, however, helps make sure the application will
    create the needed file with an image.
  prefs: []
  type: TYPE_NORMAL
- en: 16.4 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we’ve extended the automated analysis and reporting to include
    more use of the built-in `statistics` library to compute correlation and linear
    regression coefficients. We’ve also made use of the **matplotlib** library to
    create images that reveal relationships among variables.
  prefs: []
  type: TYPE_NORMAL
- en: The objective of automated reporting is designed to reduce the number of manual
    steps and avoid places where omissions or errors can lead to unreliable data analysis.
    Few things are more embarrassing than a presentation that reuses a diagram from
    the previous period’s data. It’s far too easy to fail to rebuild one important
    notebook in a series of analysis products.
  prefs: []
  type: TYPE_NORMAL
- en: The level of automation needs to be treated with a great deal of respect. Once
    a reporting application is built and deployed, it must be actively monitored to
    be sure it’s working and producing useful, informative results. The analysis job
    shifts from developing an understanding to monitoring and maintaining the tools
    that confirm — or reject — that understanding.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll review the journey from raw data to a polished suite
    of applications that acquires, cleans, and summarizes the data.
  prefs: []
  type: TYPE_NORMAL
- en: 16.5 Extras
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here are some ideas for you to add to this project.
  prefs: []
  type: TYPE_NORMAL
- en: 16.5.1 Use pandas to compute basic statistics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **pandas** package offers a robust set of tools for doing data analysis.
    The core concept is to create a `DataFrame` that contains the relevant samples.
    The `pandas` package needs to be installed and added to the `requirements.txt`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: There are methods for transforming a sequence of `SeriesSample` objects into
    a `DataFrame`. The best approach is often to convert each of the **pydantic**
    objects into a dictionary, and build the dataframe from the list of dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea is something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the value of `series_data` is a sequence of `SeriesSample`
    instances.
  prefs: []
  type: TYPE_NORMAL
- en: Each column in the resulting dataframe will be one of the variables of the sample.
    Given this object, methods of the `DataFrame` object produce useful statistics.
  prefs: []
  type: TYPE_NORMAL
- en: The `corr()` function, for example, computes the correlation values among all
    of the columns in the dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: The `cov()` function computes the pairwise covariance among the columns in the
    dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: Pandas doesn’t compute the linear regression parameters, but it can create a
    wide variety of descriptive statistics.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://pandas.pydata.org](https://pandas.pydata.org) for more information
    on Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to a variety of statistics computations, this package is designed
    for interactive use. It works particularly well with Juypyter Lab. The interested
    reader may want to revisit [*Chapter** 13*](ch017.xhtml#x1-29700013), [*Project
    4.1: Visual Analysis Techniques*](ch017.xhtml#x1-29700013) using Pandas instead
    of native Python.'
  prefs: []
  type: TYPE_NORMAL
- en: 16.5.2 Use the dask version of pandas
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **pandas** package offers a robust set of tools for doing data analysis.
    When the volume of data is vast, it helps to process parts of the dataset concurrently.
    The **Dask** project has an implementation of the **pandas** package that maximizes
    opportunities for concurrent processing.
  prefs: []
  type: TYPE_NORMAL
- en: The `dask` package needs to be installed and added to the `requirements.txt`
    file. This will include a `pandas` package that can be used to improve overall
    application performance.
  prefs: []
  type: TYPE_NORMAL
- en: 16.5.3 Use numpy for statistics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **numpy** package offers a collection of tools for doing high-performance
    processing on large arrays of data. These basic tools are enhanced with libraries
    for statistics and linear algebra among many, many other features. This package
    needs to be installed and added to the `requirements.txt` file.
  prefs: []
  type: TYPE_NORMAL
- en: The **numpy** package works with its own internal array type. This means the
    `SeriesSample` objects aren’t used directly. Instead, a `numpy.array` object can
    be created for each of the variables in the source series.
  prefs: []
  type: TYPE_NORMAL
- en: 'The conversion might look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '-'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the value of `series_data` is a sequence of `SeriesSample`
    instances.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also sensible to create a single multi-dimensional array. In this case,
    axis 0 (i.e. rows) will be the individual samples, and axis 1 (i.e. columns) will
    be the values for each variable of the sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'An array has methods like `mean()` to return the mean of the values. When using
    a multi-dimensional array, it’s essential to provide the `axis=0` parameter to
    ensure that the results come from processing the collection of rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: See [https://numpy.org/doc/stable/reference/routines.statistics.html#](https://numpy.org/doc/stable/reference/routines.statistics.html#)
  prefs: []
  type: TYPE_NORMAL
- en: Using the least squares technique to compute the coefficients for a line can
    be confusing. The least squares solver in **numpy.linalg** is a very general algorithm,
    which can be applied to creating a linear model. The `numpy.linalg.lstsq()` function
    expects a small matrix that contains the ”x” values. The result will be a vector
    with the same length as each of the ”x” matrices. The ”y” values will also be
    a vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'The processing winds up looking something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The value of `A` is a small matrix based on the x values. The value of `y` is
    a simple array of the y values. The least-squares algorithm returns a four-tuple
    with the coefficients, residuals, the rank of the source matrix, and any singular
    values. In the above example, we only wanted the vector of the coefficients, so
    we used `[0]` to extract the coefficient values from the four-tuple with the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is further decomposed to extract the two coefficients for the line that
    best fits this set of points. See: [https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html](https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html).'
  prefs: []
  type: TYPE_NORMAL
- en: This approach has a distinct advantage when working with very large sets of
    data. The **numpy** libraries are very fast and designed to scale to extremely
    large data volumes.
  prefs: []
  type: TYPE_NORMAL
- en: 16.5.4 Use scikit-learn for modeling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **scikit-learn** library has a vast number of tools focused on modeling
    and machine learning. This library is built on the foundation of **numpy**, so
    both packages need to be installed.
  prefs: []
  type: TYPE_NORMAL
- en: The data needs to be converted into **numpy** arrays. Because the modeling approach
    is very generalized, the assumption is there may be multiple independent variables
    that predict the value of a dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The conversion might look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the value of `series_data` is a sequence of `SeriesSample`
    instances. The `x` array uses a very short vector for each sample; in this case,
    there’s only a single value. It needs to be a vector to fit the generalized least-squares
    regression that **scikit-learn** is capable of solving.
  prefs: []
  type: TYPE_NORMAL
- en: The scikit-learn library is designed to create models in a very generalized
    way. The model isn’t always a simple line with a coefficient and an intercept
    that define the relationship. Because of this very general approach to modeling,
    we’ll create an instance of the `linear_model.LinearRegression` class. This object
    has methods to create coefficients that fit a given set of data points. We can
    then examine the coefficients, or use them to interpolate new values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code might look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The linear model’s `coef_` attribute is a vector of coefficients, the same length
    as each row of the `x` independent variable values. Even when the row length is
    1, the result is a vector with a length of 1.
  prefs: []
  type: TYPE_NORMAL
- en: Because this works with **numpy** it can work with very large sets of data.
    Further, the scikit-learn approach to creating models to fit data generalizes
    to a number of machine-learning approaches. This is often the next step in creating
    richer and more useful models.
  prefs: []
  type: TYPE_NORMAL
- en: 16.5.5 Compute the correlation and regression using functional programming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The computations for correlation and the coefficients for a line can be summarized
    as follows. First, we’ll define a function *M*(*a*;*f*()) that computes the mean
    of a transformed sequence of values. The *f*() function transforms each value,
    *a*[i]. An identity function, *ϕ*(*a*[i]) = *a*[i], does no transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![M (a;f()) = 1-∑ f(a) N i ](img/file68.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We’ll also need a function to compute the standard deviation for a variable,
    *a*.
  prefs: []
  type: TYPE_NORMAL
- en: '![ ∘ -∑--------- --(ai −-¯a)2 S (a) = N ](img/file69.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This lets us define a number of related values as mean values after some transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '![¯x = M (x;f(ai) = ai) ](img/file70.jpg)![¯y = M (y;f(ai) = ai) ](img/file71.jpg)![---
    x2 = M (x;f(ai) = a2i) ](img/file72.jpg)![--- y2 = M (y;f(ai) = a2i) ](img/file73.jpg)![---
    xy = M (x,y;f(ai,bi) = ai × bi) ](img/file74.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From these individual values, we can compute the correlation coefficient, *r*[xy].
  prefs: []
  type: TYPE_NORMAL
- en: '![ --- -----xy-−-¯xy¯------ rxy = ∘ --2---2---2----2- (x − ¯x )(y − y¯) ](img/file75.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In addition to the above values, we need two more values for the standard deviations
    of the two variables.
  prefs: []
  type: TYPE_NORMAL
- en: '![sx = S(x)sy = S(y) ](img/file76.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From the correlation coefficient, and the two standard deviations, we can compute
    the coefficient of the line, *m*, and the intercept value, *b*.
  prefs: []
  type: TYPE_NORMAL
- en: '![m = rxysy sx ](img/file77.jpg)![b = ¯y − m ¯x ](img/file78.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This yields the coefficient, *m*, and intercept, *b*, for the equation *y* =
    *mx* + *b*, which minimizes the error between the given samples and the line.
    This is computed using one higher-order function, *M*(*a*;*f*()), and one ordinary
    function, *S*(*a*). This doesn’t seem to be a significant improvement over other
    methods. Because it’s built using standard library functions and functional programming
    techniques, it can be applied to any Python data structure. This can save the
    step of transforming data into **numpy** array objects.
  prefs: []
  type: TYPE_NORMAL
