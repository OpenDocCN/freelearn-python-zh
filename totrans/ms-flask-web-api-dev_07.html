<html><head></head><body>
		<div id="_idContainer086">
			<h1 id="_idParaDest-173" class="chapter-number"><a id="_idTextAnchor177"/><st c="0">7</st></h1>
			<h1 id="_idParaDest-174"><a id="_idTextAnchor178"/><st c="2">Using Non-Relational Data Storage</st></h1>
			<p><st c="35">Most applications that use voluminous or big data, and continuously increase every user transaction, do not use relational databases for storage. </st><st c="182">Applications such as scientific information management systems, sales-related applications, stocks and investment-related software, and location finders are some applications that may utilize data from various types of data structures, such as objects, lists, dictionaries, and bytes. </st><st c="467">This data can be structured (for example, Excel-formatted medical records and CSV-formatted location data), semi-structured (for example, XML data of sales inventory and emails), and non-structured (for example, images, videos, social media postings, and Word documents). </st><st c="739">Relational databases do not have the support to manage this data, but </st><strong class="bold"><st c="809">NoSQL</st></strong> <span class="No-Break"><st c="814">databases do.</st></span></p>
			<p><st c="828">NoSQL, which stands for </st><strong class="bold"><st c="853">Not Only SQL</st></strong><st c="865">, is a schemaless form</st><a id="_idIndexMarker516"/><st c="887"> of data storage that has no concepts of rows and columns to hold records of information. </st><st c="977">Like any framework, Flask, when used to build big data applications, can support access to these non-relational databases to manage data for data mining, modeling, analytics, and </st><span class="No-Break"><st c="1156">graphical projections.</st></span></p>
			<p><st c="1178">The main goal of this chapter is to showcase how to install and configure the different NoSQL databases and how a Flask application can connect to these databases and perform </st><strong class="bold"><st c="1354">INSERT</st></strong><st c="1360">, </st><strong class="bold"><st c="1362">UPDATE</st></strong><st c="1368">, </st><strong class="bold"><st c="1370">DELETE</st></strong><st c="1376">, and </st><span class="No-Break"><strong class="bold"><st c="1382">QUERY</st></strong></span><span class="No-Break"><st c="1387"> transactions.</st></span></p>
			<p><st c="1401">This chapter will cover the following topics – this will provide you with an initial step toward building big data applications </st><span class="No-Break"><st c="1530">with Flask:</st></span></p>
			<ul>
				<li><st c="1541">Managing non-relational data using </st><span class="No-Break"><st c="1577">Apache HBase</st></span></li>
				<li><st c="1589">Utilizing the column storage of </st><span class="No-Break"><st c="1622">Apache Cassandra</st></span></li>
				<li><st c="1638">Storing search data </st><span class="No-Break"><st c="1659">in Redis</st></span></li>
				<li><st c="1667">Handling BSON-based documents </st><span class="No-Break"><st c="1698">with MongoDB</st></span></li>
				<li><st c="1710">Managing key-based JSON documents </st><span class="No-Break"><st c="1745">with Couchbase</st></span></li>
				<li><st c="1759">Establishing a data relationship </st><span class="No-Break"><st c="1793">with Neo4J</st></span></li>
			</ul>
			<h1 id="_idParaDest-175"><a id="_idTextAnchor179"/><st c="1803">Technical requirements</st></h1>
			<p><st c="1826">This chapter highlights a </st><em class="italic"><st c="1853">Tutor Finder</st></em><st c="1865"> application that accepts students and tutor profiles. </st><st c="1920">The application’s main objective is to provide a platform for vying students looking for personal tutors or trainers with different expertise. </st><st c="2063">Aside from profiling, it has a </st><em class="italic"><st c="2094">payment module</st></em><st c="2108"> for students to pay their tutor’s fees based on payment modes, </st><em class="italic"><st c="2172">course modules</st></em><st c="2186"> for course details, and </st><em class="italic"><st c="2211">search modules</st></em><st c="2225"> to find the appropriate tutor and student profiles. </st><st c="2278">The application is unique and experimental because it showcases all the NoSQL databases as its backend storage to serve as a specimen for this chapter. </st><st c="2430">On the other hand, the application utilizes the </st><em class="italic"><st c="2478">factory pattern</st></em><st c="2493"> as its main project structure design. </st><st c="2532">All files are available </st><span class="No-Break"><st c="2556">at </st></span><a href="https://github.com/PacktPublishing/Mastering-Flask-Web-Development/tree/main/ch07"><span class="No-Break"><st c="2559">https://github.com/PacktPublishing/Mastering-Flask-Web-Development/tree/main/ch07</st></span></a><span class="No-Break"><st c="2640">.</st></span></p>
			<h1 id="_idParaDest-176"><a id="_idTextAnchor180"/><st c="2641">Managing non-relational data using Apache HBase</st></h1>
			<p><st c="2689">One of the</st><a id="_idIndexMarker517"/><st c="2700"> most popular</st><a id="_idIndexMarker518"/><st c="2713"> NoSQL databases is the </st><strong class="bold"><st c="2737">column-oriented database</st></strong><st c="2761"> as it stores its records differently to the row-oriented</st><a id="_idIndexMarker519"/><st c="2818"> approach. </st><st c="2829">These column-oriented</st><a id="_idIndexMarker520"/><st c="2850"> storage options, which include </st><strong class="bold"><st c="2882">HBase</st></strong><st c="2887">, </st><strong class="bold"><st c="2889">Hypertable</st></strong><st c="2899">, and </st><strong class="bold"><st c="2905">Cloudata</st></strong><st c="2913">, are depicted as sparse and multidimensional</st><a id="_idIndexMarker521"/><st c="2958"> sorted maps</st><a id="_idIndexMarker522"/><st c="2970"> that hold each record</st><a id="_idIndexMarker523"/><st c="2992"> with a unique</st><a id="_idIndexMarker524"/><st c="3006"> index key, called the </st><em class="italic"><st c="3029">row key</st></em><st c="3036">, a </st><em class="italic"><st c="3040">column key</st></em><st c="3050">, which organizes the data, and a </st><em class="italic"><st c="3084">timestamp</st></em><st c="3093">. Each form of storage is equivalent to a relational table with records identified by the </st><em class="italic"><st c="3183">row key</st></em><st c="3190">, which is of the </st><strong class="source-inline"><st c="3208">byte[]</st></strong><st c="3214"> type. </st><st c="3221">This </st><strong class="source-inline"><st c="3226">byte[]</st></strong><st c="3232"> data is handled by the column families, which are composed of </st><em class="italic"><st c="3295">column qualifiers</st></em><st c="3312"> or </st><em class="italic"><st c="3316">columns</st></em><st c="3323">, each stored in a </st><em class="italic"><st c="3342">cell</st></em><st c="3346">. Each column qualifier addresses one </st><em class="italic"><st c="3384">data field</st></em><st c="3394"> with a </st><em class="italic"><st c="3402">timestamp</st></em><st c="3411"> that keeps track of the versions of each column field in </st><span class="No-Break"><st c="3469">every update.</st></span></p>
			<p><st c="3482">Regarding column-oriented databases, this chapter will concentrate solely on integrating Apache HBase into our Flask application. </st><st c="3613">Initially, like any database, we’ll design the HBase tables first before integrating them </st><span class="No-Break"><st c="3703">into Flask.</st></span></p>
			<h2 id="_idParaDest-177"><a id="_idTextAnchor181"/><st c="3714">Designing HBase tables</st></h2>
			<p><st c="3737">One of the leverages of using</st><a id="_idIndexMarker525"/><st c="3767"> relational databases is the availability of many design tools that can assist us with planning and organizing the table schema using different normalization levels. </st><st c="3933">Only a few data modeling</st><a id="_idIndexMarker526"/><st c="3957"> tools, such as </st><strong class="bold"><st c="3973">DBSchema</st></strong><st c="3981">, </st><strong class="bold"><st c="3983">Moon</st></strong><em class="italic"> </em><strong class="bold"><st c="3987">Modeler</st></strong><st c="3995">, </st><strong class="bold"><st c="3997">Hackolade</st></strong><st c="4006">, and </st><strong class="bold"><st c="4012">draw.io</st></strong><st c="4019">, have the support to provide</st><a id="_idIndexMarker527"/><st c="4048"> design for de-normalized</st><a id="_idIndexMarker528"/><st c="4073"> tables of NoSQL </st><a id="_idIndexMarker529"/><st c="4090">databases, such as HBase. </st><st c="4116">In this chapter, we’ll use </st><em class="italic"><st c="4143">draw.io</st></em><st c="4150"> to visualize the </st><strong class="source-inline"><st c="4168">payments</st></strong><st c="4176"> and </st><strong class="source-inline"><st c="4181">bookings</st></strong><st c="4189"> HBase tables using the UML class diagramming approach. </st><span class="No-Break"><em class="italic"><st c="4245">Figure 7</st></em></span><em class="italic"><st c="4253">.1</st></em><st c="4255"> shows the UML design for the </st><strong class="source-inline"><st c="4285">payments</st></strong><st c="4293"> and </st><span class="No-Break"><strong class="source-inline"><st c="4298">bookings</st></strong></span><span class="No-Break"><st c="4306"> tables:</st></span></p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/B19383_07_001.jpg" alt="Figure 7.1 – HBase table design for payments and bookings"/><st c="4314"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="4372">Figure 7.1 – HBase table design for payments and bookings</st></p>
			<p><st c="4429">The </st><strong class="source-inline"><st c="4434">payments</st></strong><st c="4442"> and </st><strong class="source-inline"><st c="4447">bookings</st></strong><st c="4455"> contexts signify the two tables of the HBase database. </st><st c="4511">The </st><strong class="source-inline"><st c="4515">payments</st></strong><st c="4523"> table has two column families, namely </st><strong class="source-inline"><st c="4562">PaymentDetails</st></strong><st c="4576"> and </st><strong class="source-inline"><st c="4581">PaymentItems</st></strong><st c="4593">. The </st><strong class="source-inline"><st c="4599">bookings</st></strong><st c="4607"> table has one column </st><span class="No-Break"><st c="4629">family, </st></span><span class="No-Break"><strong class="source-inline"><st c="4637">BookingDetails</st></strong></span><span class="No-Break"><st c="4651">.</st></span></p>
			<p><st c="4652">Note that </st><strong class="source-inline"><st c="4663">PaymentDetails</st></strong><st c="4677"> has </st><strong class="source-inline"><st c="4682">id</st></strong><st c="4684">, </st><strong class="source-inline"><st c="4686">stud_id</st></strong><st c="4693">, </st><strong class="source-inline"><st c="4695">tutor_id</st></strong><st c="4703">, </st><strong class="source-inline"><st c="4705">ccode</st></strong><st c="4710">, and </st><strong class="source-inline"><st c="4716">fee</st></strong><st c="4719"> as column qualifiers, while </st><strong class="source-inline"><st c="4748">PaymentItems</st></strong><st c="4760"> has </st><strong class="source-inline"><st c="4765">id</st></strong><st c="4767">, </st><strong class="source-inline"><st c="4769">receipt_id</st></strong><st c="4779">, and </st><strong class="source-inline"><st c="4785">amount</st></strong><st c="4791">. Furthermore, </st><strong class="source-inline"><st c="4806">BookingDetails</st></strong><st c="4820"> has </st><strong class="source-inline"><st c="4825">id</st></strong><st c="4827">, </st><strong class="source-inline"><st c="4829">tutor_id</st></strong><st c="4837">, </st><strong class="source-inline"><st c="4839">stud_id</st></strong><st c="4846">, and </st><strong class="source-inline"><st c="4852">date_booked</st></strong><st c="4863"> columns. </st><st c="4873">A sample record in JSON format will look </st><span class="No-Break"><st c="4914">like this:</st></span></p>
			<pre class="source-code"><st c="4924">
"payments": {
  "</st><strong class="bold"><st c="4940">details:id</st></strong><st c="4951">": 1001, "</st><strong class="bold"><st c="4962">details:stud_id</st></strong><st c="4978">": "STD-001",
  "</st><strong class="bold"><st c="4994">details:tutor_id</st></strong><st c="5011">": "TUT-001", "</st><strong class="bold"><st c="5027">details:ccode</st></strong><st c="5041">": "PY-100",
  "</st><strong class="bold"><st c="5056">details:fee</st></strong><st c="5068">": 5000.00", "</st><strong class="bold"><st c="5083">items:id</st></strong><st c="5092">": 1001,
  "</st><strong class="bold"><st c="5103">items:receipt_id</st></strong><st c="5120">": "OR-901", "</st><strong class="bold"><st c="5135">items:amount</st></strong><st c="5148">": 3000.00"
}
"bookings" : {
   "</st><strong class="bold"><st c="5179">details:id</st></strong><st c="5190">": 101, "</st><strong class="bold"><st c="5200">details:tutor_id</st></strong><st c="5217">": TUT-002",
   "</st><strong class="bold"><st c="5232">details:stud_id</st></strong><st c="5248">": "STD-201",
   "</st><strong class="bold"><st c="5264">details:date_booked</st></strong><st c="5284">": "2023-10-10"
}</st></pre>			<p><st c="5302">The actual name of the column qualifier, when accessed via the Flask app, is a </st><em class="italic"><st c="5382">concatenation</st></em><st c="5395"> of the column family and the column name itself. </st><st c="5445">An example from the given record </st><span class="No-Break"><st c="5478">is </st></span><span class="No-Break"><strong class="source-inline"><st c="5481">details:stud_id</st></strong></span><span class="No-Break"><st c="5496">.</st></span></p>
			<p><st c="5497">Now that we’ve designed</st><a id="_idIndexMarker530"/><st c="5521"> the table structure, let’s look at how we can install and configure the Apache HBase and Apache Hadoop platforms. </st><st c="5636">We’ll start by </st><span class="No-Break"><st c="5651">using Java.</st></span></p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor182"/><st c="5662">Setting up the baseline requirements</st></h2>
			<p><st c="5699">Apache HBase is a Java-based platform, and all</st><a id="_idIndexMarker531"/><st c="5746"> its components</st><a id="_idIndexMarker532"/><st c="5761"> depend on </st><strong class="bold"><st c="5772">Java Virtual Machine</st></strong><st c="5792"> (</st><strong class="bold"><st c="5794">JVM</st></strong><st c="5797">). </st><st c="5801">So, download</st><a id="_idIndexMarker533"/><st c="5813"> the </st><em class="italic"><st c="5818">Java 11</st></em><st c="5825"> ZIP file from </st><a href="https://jdk.java.net/java-se-ri/11-MR2"><st c="5840">https://jdk.java.net/java-se-ri/11-MR2</st></a><st c="5878"> and unzip it to your local filesystem. </st><st c="5918">Then, create a </st><strong class="source-inline"><st c="5933">JAVA_HOME</st></strong><st c="5942"> system environment variable in your Windows, Linux, or macOS environment and update </st><strong class="source-inline"><st c="6027">CLASSPATH</st></strong><st c="6036"> to help HBase access the JDK commands in Java’s </st><strong class="source-inline"><st c="6085">/bin</st></strong><st c="6089"> folder so that it can perform server startup and </st><span class="No-Break"><st c="6139">shutdown operations.</st></span></p>
			<p><st c="6159">Since Apache HBase</st><a id="_idIndexMarker534"/><st c="6178"> is a distributed storage that uses </st><strong class="bold"><st c="6214">Hadoop File System</st></strong><st c="6232"> (</st><strong class="bold"><st c="6234">HDFS</st></strong><st c="6238">), download the </st><strong class="source-inline"><st c="6255">hadoop-3.3.6/hadoop-3.3.6.tar.gz</st></strong><st c="6287"> file from </st><a href="https://hadoop.apache.org/releases.html"><st c="6298">https://hadoop.apache.org/releases.html</st></a><st c="6337"> and unzip it to the same local drive where the HBase installation folder is. </st><st c="6415">Create a </st><strong class="source-inline"><st c="6424">HADOOP_HOME</st></strong><st c="6435"> file and update the </st><strong class="source-inline"><st c="6456">CLASSPATH</st></strong><st c="6465"> variable of the operating system to make the Hadoop </st><strong class="source-inline"><st c="6518">/bin</st></strong><st c="6522"> commands available to HBase during startup. </st><st c="6567">Let’s have a brief look at the Apache Hadoop framework to understand </st><span class="No-Break"><st c="6636">this better.</st></span></p>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor183"/><st c="6648">Configuring Apache Hadoop</st></h2>
			<p><st c="6674">Apache Hadoop is a Java-based</st><a id="_idIndexMarker535"/><st c="6704"> framework that manages scalable big data processing across a distributed cluster setup. </st><st c="6793">It is popular due to its </st><em class="italic"><st c="6818">MapReduce</st></em><st c="6827"> algorithm, which performs data processing in parallel across cluster(s) of nodes, making the framework’s distributed operations fast. </st><st c="6962">Moreover, the</st><a id="_idIndexMarker536"/><st c="6975"> framework has </st><strong class="bold"><st c="6990">HDFS</st></strong><st c="6994"> a filesystem. </st><st c="7009">This is where it contains the input and </st><span class="No-Break"><st c="7049">output datasets.</st></span></p>
			<p><st c="7065">The </st><em class="italic"><st c="7070">MapReduce</st></em><st c="7079"> process starts with these big</st><a id="_idIndexMarker537"/><st c="7109"> datasets being stored in HDFS by the Flask application. </st><st c="7166">They’re passed through the internal Hadoop servers, which run the </st><strong class="source-inline"><st c="7232">Map()</st></strong><st c="7237"> function to break down this data into tuples of key-value pairs. </st><st c="7303">Then, these groups of key-value data blocks undergo another process called </st><strong class="source-inline"><st c="7378">Reduce()</st></strong><st c="7386">, which is performed by other Hadoop servers. </st><st c="7432">This exposes these data blocks to various reduce functions, such as summation, averaging, concatenation, compression, ordering, and shuffling, and then saves them as output datasets </st><span class="No-Break"><st c="7614">in HDFS.</st></span></p>
			<p><st c="7622">Aside from the </st><em class="italic"><st c="7638">MapReduce</st></em><st c="7647"> distributed data process, HBase needs Hadoop’s HDFS because of the high latency batch processing operations it gives to the HBase platform. </st><st c="7788">In return, HBase enables read/write transactions to access the data stored in HDFS and can provide a thrift server so that third-party applications can access the </st><span class="No-Break"><st c="7951">big datasets.</st></span></p>
			<p class="callout-heading"><st c="7964">Important note</st></p>
			<p class="callout"><st c="7979">A </st><em class="italic"><st c="7982">thrift server</st></em><st c="7995"> is a Hive-compatible </st><a id="_idIndexMarker538"/><st c="8017">interface in HBase that enables multi-language support, allowing applications developed in Python, Java, C#, C++, NodeJS, Go, PHP, and JavaScript to access big data. </st><st c="8183">The term </st><em class="italic"><st c="8192">Hive</st></em><st c="8196">, on the other </st><a id="_idIndexMarker539"/><st c="8211">hand, refers to a client application that runs on top of Hadoop and has powerful SQL utilities that are used to implement CRUD operations for </st><span class="No-Break"><st c="8353">large datasets.</st></span></p>
			<p><st c="8368">Here’s the step-by-step procedure to set up a Hadoop platform with a </st><span class="No-Break"><st c="8438">single-node cluster:</st></span></p>
			<ol>
				<li><st c="8458">Go to the installation folder of </st><em class="italic"><st c="8492">Apache Hadoop 3.3.6</st></em><st c="8511"> and open </st><strong class="source-inline"><st c="8521">/etc/hadoop/core-site.xml</st></strong><st c="8546">. Then, set the </st><strong class="source-inline"><st c="8562">fs.defaultFS</st></strong><st c="8574"> property. </st><st c="8585">This indicates the default location of </st><em class="italic"><st c="8624">NameNode</st></em><st c="8632"> (master node) in the cluster – in our case, the default</st><a id="_idIndexMarker540"/><st c="8688"> filesystem. </st><st c="8701">Its value is a URL address to which </st><em class="italic"><st c="8737">DataNode</st></em><st c="8745"> (slave node) will send a heartbeat. </st><em class="italic"><st c="8782">NameNode</st></em><st c="8790"> contains the metadata of the data stored in HDFS, while </st><em class="italic"><st c="8847">DataNode</st></em><st c="8855"> contains the big datasets. </st><st c="8883">Here is our </st><span class="No-Break"><strong class="source-inline"><st c="8895">core-site.xml</st></strong></span><span class="No-Break"><st c="8908"> file:</st></span><pre class="source-code"><st c="8914">
&lt;configuration&gt;
    &lt;property&gt;
         </st><strong class="bold"><st c="8942">&lt;name&gt;fs.defaultFS&lt;/name&gt;</st></strong><strong class="bold"><st c="8967">&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</st></strong><st c="9004">
    &lt;/property&gt;
&lt;/configuration&gt;</st></pre></li>				<li><st c="9033">Inside the same installation folder, create a custom folder called </st><strong class="source-inline"><st c="9101">data</st></strong><st c="9105"> with two sub-folders called </st><strong class="source-inline"><st c="9134">datanode</st></strong><st c="9142"> and </st><strong class="source-inline"><st c="9147">namenode</st></strong><st c="9155">, as shown in </st><span class="No-Break"><em class="italic"><st c="9169">Figure 7</st></em></span><em class="italic"><st c="9177">.2</st></em><st c="9179">. These folders will eventually contain the configuration files of </st><em class="italic"><st c="9246">DataNode</st></em><st c="9254"> and </st><span class="No-Break"><em class="italic"><st c="9259">NameNode</st></em></span><span class="No-Break"><st c="9267">, respectively:</st></span></li>
			</ol>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B19383_07_002.jpg" alt="Figure 7.2 – The DataNode and NameNode config folders"/><st c="9282"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="9388">Figure 7.2 – The DataNode and NameNode config folders</st></p>
			<ol>
				<li value="3"><st c="9441">Next, open </st><strong class="source-inline"><st c="9453">/etc/hadoop/hdfs-site.xml</st></strong><st c="9478"> and declare the newly created </st><strong class="source-inline"><st c="9509">datanode</st></strong><st c="9517"> and </st><strong class="source-inline"><st c="9522">namenode</st></strong><st c="9530"> folders as the final config locations of their respective nodes. </st><st c="9596">Also, set the </st><strong class="source-inline"><st c="9610">dfs.replication</st></strong><st c="9625"> property to </st><strong class="source-inline"><st c="9638">1</st></strong><st c="9639"> since we only have a single node </st><a id="_idIndexMarker541"/><st c="9673">cluster for our </st><em class="italic"><st c="9689">Tutor Finder</st></em><st c="9701"> project. </st><st c="9711">Here is our </st><span class="No-Break"><strong class="source-inline"><st c="9723">hdf-site.xml</st></strong></span><span class="No-Break"><st c="9735"> file:</st></span><pre class="source-code"><st c="9741">
&lt;configuration&gt;
 &lt;property&gt;
       </st><strong class="bold"><st c="9769">&lt;name&gt;dfs.replication&lt;/name&gt;</st></strong><strong class="bold"><st c="9797">&lt;value&gt;1&lt;/value&gt;</st></strong><st c="9814">
   &lt;/property&gt;
   &lt;property&gt;
       </st><strong class="bold"><st c="9838">&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</st></strong><strong class="bold"><st c="9872">&lt;value&gt;</st></strong><strong class="bold"><st c="9880">file:///C:/Alibata/Development/Database/hadoop-3.3.6/data/namenode&lt;/value&gt;</st></strong><st c="9955">
   &lt;/property&gt;
   &lt;property&gt;
       </st><strong class="bold"><st c="9979">&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</st></strong><strong class="bold"><st c="10013">&lt;value&gt;</st></strong><strong class="bold"><st c="10021">file:///C:/Alibata/Development/Database/hadoop-3.3.6/data/datanode&lt;/value&gt;</st></strong><st c="10096">
   &lt;/property&gt;
&lt;/configuration&gt;</st></pre></li>				<li><st c="10125">Since our project will use Hadoop installed in Windows, download the </st><strong class="source-inline"><st c="10195">hadoop-3.3.6-src.tar.gz</st></strong><st c="10218"> file from </st><strong class="source-inline"><st c="10229">https://hadoop.apache.org/releases.html</st></strong><st c="10268"> and compile the Hadoop source files using Maven to generate Hadoop binaries for Windows, such as </st><strong class="source-inline"><st c="10366">winutils.exe</st></strong><st c="10378">, </st><strong class="source-inline"><st c="10380">hadoop.dll</st></strong><st c="10390">, and </st><strong class="source-inline"><st c="10396">hdfs.dll</st></strong><st c="10404">. Drop these files into the </st><strong class="source-inline"><st c="10432">/</st></strong><span class="No-Break"><strong class="source-inline"><st c="10433">bin</st></strong></span><span class="No-Break"><st c="10436"> folder.</st></span></li>
				<li><st c="10444">Format the new active </st><em class="italic"><st c="10467">NameNode</st></em><st c="10475">(s) by running the following command at the </st><span class="No-Break"><st c="10520">command line:</st></span><pre class="source-code"><st c="10533">
     hdfs namenode -format</st></pre><p class="list-inset"><st c="10555">This command will clean up the </st><em class="italic"><st c="10587">NameNode</st></em><st c="10595">(s) if they have existing </st><span class="No-Break"><st c="10622">stored metadata.</st></span></p></li>			</ol>
			<p><st c="10638">Now, we can start setting</st><a id="_idIndexMarker542"/><st c="10664"> up a version of Apache HBase that’s compatible with Apache </st><span class="No-Break"><st c="10724">Hadoop 3.3.6.</st></span></p>
			<h2 id="_idParaDest-180"><a id="_idTextAnchor184"/><st c="10737">Configuring Zookeeper and Apache HBase</st></h2>
			<p><st c="10776">Apache HBase depends</st><a id="_idIndexMarker543"/><st c="10797"> on Apache Zookeeper</st><a id="_idIndexMarker544"/><st c="10817"> when running its clusters, so the next step is to install and configure a Zookeeper server. </st><strong class="bold"><st c="10910">Apache Zookeeper</st></strong><st c="10926"> is a high-performance service that manages distributed and cloud-based applications by providing synchronization and centralized services and maintains details of these applications. </st><st c="11110">Note that this project utilizes Zookeeper bundled with HBase, so you shouldn’t install Zookeeper separately unless the setup involves </st><span class="No-Break"><st c="11244">multiple clusters.</st></span></p>
			<p><st c="11262">Now, download </st><em class="italic"><st c="11277">Apache HBase 2.5.5</st></em><st c="11295">, the most compatible HBase distribution, to Apache Hadoop 3.3.6. </st><st c="11361">Unzip it to the folder where Hadoop resides. </st><st c="11406">Then, configure HBase by performing the </st><span class="No-Break"><st c="11446">following steps:</st></span></p>
			<ol>
				<li><st c="11462">First, create an </st><strong class="source-inline"><st c="11480">HBASE_HOME</st></strong><st c="11490"> system environment variable that registers the HBase </st><span class="No-Break"><st c="11544">installation folder.</st></span></li>
				<li><st c="11564">Create two folders inside the installation folder, </st><strong class="source-inline"><st c="11616">hbase</st></strong><st c="11621"> and </st><strong class="source-inline"><st c="11626">zookeeper</st></strong><st c="11635">. These will serve as the root folders of HBase and the built-in Zookeeper </st><span class="No-Break"><st c="11710">server, respectively.</st></span></li>
				<li><st c="11731">Inside the installation folder, open </st><strong class="source-inline"><st c="11769">/conf/hbase-site.xml</st></strong><st c="11789">. Here, set the </st><strong class="source-inline"><st c="11805">hbase.rootdir</st></strong><st c="11818"> property so that it points to the </st><strong class="source-inline"><st c="11853">hbase</st></strong><st c="11858"> folder and the </st><strong class="source-inline"><st c="11874">hbase.zookeeper.property.dataDir</st></strong><st c="11906"> property so that it points to the </st><strong class="source-inline"><st c="11941">zookeeper</st></strong><st c="11950"> folder. </st><st c="11959">Now, register the </st><strong class="source-inline"><st c="11977">hbase.zookeeper.quorum</st></strong><st c="11999"> property. </st><st c="12010">This will indicate the Zookeeper server’s host. </st><st c="12058">Then, set the </st><strong class="source-inline"><st c="12072">hbase.cluster.distributed</st></strong><st c="12097"> property. </st><st c="12108">This will specify the type of HBase server setup. </st><st c="12158">The following is our </st><span class="No-Break"><strong class="source-inline"><st c="12179">hbase-site.xml</st></strong></span><span class="No-Break"><st c="12193"> file:</st></span><pre class="source-code"><st c="12199">
&lt;configuration&gt;
  &lt;property&gt;
    </st><strong class="bold"><st c="12227">&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</st></strong><strong class="bold"><st c="12265">&lt;value&gt;false&lt;/value&gt;</st></strong><st c="12286">
  &lt;/property&gt;
  &lt;property&gt;
    </st><strong class="bold"><st c="12310">&lt;name&gt;hbase.tmp.dir&lt;/name&gt;</st></strong><strong class="bold"><st c="12336">&lt;value&gt;./tmp&lt;/value&gt;</st></strong><st c="12356">
  &lt;/property&gt;
  &lt;property&gt;
    </st><strong class="bold"><st c="12380">&lt;name&gt;hbase.rootdir&lt;/name&gt;</st></strong><strong class="bold"><st c="12406">&lt;value&gt;</st></strong><strong class="bold"><st c="12414">file:///C:/Alibata/Development/Database/hbase-2.5.5/hbase&lt;/value&gt;</st></strong><st c="12480">
 &lt;/property&gt;
 &lt;property&gt;
    </st><strong class="bold"><st c="12504">&lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</st></strong><strong class="bold"><st c="12549">&lt;value&gt;</st></strong><strong class="bold"><st c="12557">/C:/Alibata/Development/Database/hbase-2.5.5/zookeeper&lt;/value&gt;</st></strong><st c="12620">
 &lt;/property&gt;
 &lt;property&gt;
     </st><strong class="bold"><st c="12644">&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</st></strong><strong class="bold"><st c="12679">&lt;value&gt;localhost&lt;/value&gt;</st></strong><st c="12704">
 &lt;/property&gt;
   … … … … … …
&lt;/configuration&gt;</st></pre></li>				<li><st c="12744">Next, open </st><strong class="source-inline"><st c="12756">/bin/hbase.cmd</st></strong><st c="12770"> if you’re on Windows and search for the </st><strong class="source-inline"><st c="12811">java_arguments</st></strong><st c="12825"> property. </st><st c="12836">Remove </st><strong class="source-inline"><st c="12843">%HEAP_SETTINGS%</st></strong><st c="12858"> so that the new statement will be </st><span class="No-Break"><st c="12893">as follows:</st></span><pre class="source-code"><st c="12904">
set java_arguments=%HBASE_OPTS% -classpath "%CLASSPATH%" %CLASS% %hbase-command-arguments%</st></pre></li>				<li><st c="12995">Open </st><strong class="source-inline"><st c="13001">/conf/hbase-env.cmd</st></strong><st c="13020"> and add</st><a id="_idIndexMarker545"/><st c="13028"> the following </st><strong class="source-inline"><st c="13043">JAVA_HOME</st></strong><st c="13052"> and </st><strong class="source-inline"><st c="13057">HBASE_*</st></strong><st c="13064"> details</st><a id="_idIndexMarker546"/><st c="13072"> to </st><span class="No-Break"><st c="13076">the file:</st></span><pre class="source-code"><st c="13085">
set JAVA_HOME=%JAVA_HOME%
set HBASE_CLASSPATH=%HBASE_HOME%\lib\client-facing-thirdparty\*
set HBASE_HEAPSIZE=8000
set HBASE_OPTS="-Djava.net.preferIPv4Stack=true"
set SERVER_GC_OPTS="-verbose:gc" </st><strong class="bold"><st c="13282">"-Xlog:gc*=info:stdout" "-XX:+UseG1GC"</st></strong><strong class="bold"><st c="13320">"-XX:MaxGCPauseMillis=100" "-XX:-ResizePLAB"</st></strong><st c="13365"> %HBASE_GC_OPTS%
set HBASE_USE_GC_LOGFILE=true
set HBASE_JMX_BASE="-Dcom.sun.management.jmxremote.ssl=false" "-Dcom.sun.management.jmxremote.authenticate=false"
set HBASE_MASTER_OPTS=%HBASE_JMX_BASE% "-Dcom.sun.management.jmxremote.port=10101"
set HBASE_REGIONSERVER_OPTS=%HBASE_JMX_BASE% "-Dcom.sun.management.jmxremote.port=10102"
set HBASE_THRIFT_OPTS=%HBASE_JMX_BASE% "-Dcom.sun.management.jmxremote.port=10103"
set HBASE_ZOOKEEPER_OPTS=%HBASE_JMX_BASE% -Dcom.sun.management.jmxremote.port=10104"
set HBASE_REGIONSERVERS=%HBASE_HOME%\conf\regionservers
set HBASE_LOG_DIR=%HBASE_HOME%\logs
set HBASE_IDENT_STRING=%USERNAME%
set HBASE_MANAGES_ZK=true</st></pre><p class="list-inset"><st c="14017">Our </st><em class="italic"><st c="14022">Tutor Finding</st></em><st c="14035"> project uses </st><em class="italic"><st c="14049">Java JDK 11</st></em><st c="14060"> to run the HBase database server. </st><st c="14095">So, the usual garbage collectors that work with Java 1.8 are now deprecated and invalid. </st><st c="14184">The most suitable GC option for the HBase platform that uses Java JDK 11 to achieve better server performance </st><span class="No-Break"><st c="14294">is </st></span><span class="No-Break"><em class="italic"><st c="14297">G1GC</st></em></span><span class="No-Break"><st c="14301">.</st></span></p></li>				<li><st c="14302">Finally, go to the </st><strong class="source-inline"><st c="14322">/bin</st></strong><st c="14326"> folder</st><a id="_idIndexMarker547"/><st c="14333"> and run the </st><strong class="source-inline"><st c="14346">start-hbase</st></strong><st c="14357"> command</st><a id="_idIndexMarker548"/><st c="14365"> to start the server. </st><span class="No-Break"><em class="italic"><st c="14387">Figure 7</st></em></span><em class="italic"><st c="14395">.3</st></em><st c="14397"> shows a snapshot of the HBase logs while </st><span class="No-Break"><st c="14439">at startup:</st></span></li>
			</ol>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B19383_07_003.jpg" alt="Figure 7.3 – Starting up the HBase server"/><st c="14450"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="15289">Figure 7.3 – Starting up the HBase server</st></p>
			<ol>
				<li value="7"><st c="15330">To stop the server, run </st><strong class="source-inline"><st c="15355">stop-hbase</st></strong><st c="15365">, then </st><strong class="source-inline"><st c="15372">hbase master stop  --</st></strong><span class="No-Break"><strong class="source-inline"><st c="15392">shutDownCluster</st></strong></span><span class="No-Break"><st c="15408">.</st></span></li>
			</ol>
			<p><st c="15409">The HBase server log, shown in </st><span class="No-Break"><em class="italic"><st c="15441">Figure 7</st></em></span><em class="italic"><st c="15449">.4</st></em><st c="15451">, shows the Zookeeper server fetching all the Hadoop configuration files to handle all the Hadoop cluster(s) and providing the necessary </st><span class="No-Break"><st c="15588">operational services:</st></span></p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B19383_07_004.jpg" alt="Figure 7.4 – Starting up Zookeeper with the Hadoop cluster(s)"/><st c="15609"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="16885">Figure 7.4 – Starting up Zookeeper with the Hadoop cluster(s)</st></p>
			<p><st c="16946">Now that we’ve made</st><a id="_idIndexMarker549"/><st c="16966"> these server</st><a id="_idIndexMarker550"/><st c="16979"> configurations, let’s run the HBase client so that we can create our </st><strong class="source-inline"><st c="17049">payments</st></strong><st c="17057"> and </st><span class="No-Break"><strong class="source-inline"><st c="17062">bookings</st></strong></span><span class="No-Break"><st c="17070"> tables.</st></span></p>
			<h2 id="_idParaDest-181"><a id="_idTextAnchor185"/><st c="17078">Setting up the HBase shell</st></h2>
			<p><st c="17105">Apache HBase has a built-in interactive</st><a id="_idIndexMarker551"/><st c="17145"> shell client created via Java that can communicate with HDFS for big data. </st><st c="17221">The command to spawn the shell is </st><strong class="source-inline"><st c="17255">hbase shell</st></strong><st c="17266">. In Apache HBase 2.5.5, running this command will give us the following </st><span class="No-Break"><st c="17339">error message:</st></span></p>
			<pre class="console"><st c="17353">
This file has been superceded by packaging our ruby files into a jar and using jruby's bootstrapping to invoke them. </st><st c="17471">If you need to source this file for some reason it is now named 'jar-bootstrap.rb' and is located in the root of the file hbase-shell.jar and in the source tree at 'hbase-shell/src/main/ruby'.</st></pre>			<p><st c="17663">The reason behind this error is the missing JAR files that the client shell requires from the installation. </st><st c="17772">So, to fix this error, download </st><strong class="source-inline"><st c="17804">jansi-1.18.jar</st></strong><st c="17818"> and </st><strong class="source-inline"><st c="17823">jruby-complete-9.2.13.0.jar</st></strong><st c="17850"> from the Maven repository and place them in the </st><strong class="source-inline"><st c="17899">/lib</st></strong><st c="17903"> directory. </st><st c="17915">Then, go to the </st><strong class="source-inline"><st c="17931">/lib</st></strong><st c="17935"> folder and run the following command to open the </st><span class="No-Break"><st c="17985">client shell:</st></span></p>
			<pre class="console"><st c="17998">
java -cp hbase-shell-2.5.5.jar;client-facing-thirdparty/*;* org.jruby.JarBootstrapMain</st></pre>			<p><span class="No-Break"><em class="italic"><st c="18085">Figure 7</st></em></span><em class="italic"><st c="18094">.5</st></em><st c="18096"> shows the given command opening the </st><span class="No-Break"><st c="18133">HBase shell:</st></span></p>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/B19383_07_005.jpg" alt="Figure 7.5 – Invoking the HBase shell"/><st c="18145"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="19652">Figure 7.5 – Invoking the HBase shell</st></p>
			<p><st c="19689">The warnings that appear in the logs are due to the collisions of SL4J log libraries from Hadoop’s </st><strong class="source-inline"><st c="19789">/common/lib</st></strong><st c="19800"> and HBase’s </st><strong class="source-inline"><st c="19813">/lib/client-facing-thirdparty</st></strong><st c="19842">. Removing redundancies from among these logger libraries can fix these warnings. </st><st c="19924">Now that we’ve finalized the table</st><a id="_idIndexMarker552"/><st c="19958"> designs and set up the HBase environment, we’ll build the </st><span class="No-Break"><st c="20017">HBase tables.</st></span></p>
			<h2 id="_idParaDest-182"><a id="_idTextAnchor186"/><st c="20030">Creating the HBase tables</st></h2>
			<p><st c="20056">The HBase client application</st><a id="_idIndexMarker553"/><st c="20085"> has different commands ready to pursue administrative, table, data manipulation, cluster-related, and general operations for HBase datasets. </st><st c="20227">It can interact with HBase storage based on these commands. </st><span class="No-Break"><em class="italic"><st c="20287">Figure 7</st></em></span><em class="italic"><st c="20295">.6</st></em><st c="20297"> shows common general-purpose commands, such as </st><strong class="source-inline"><st c="20345">whoami</st></strong><st c="20351">, which checks the user information that’s been logged in the shell, and </st><strong class="source-inline"><st c="20424">version</st></strong><st c="20431">, which specifies the version of the running HBase. </st><st c="20483">It also shows the </st><strong class="source-inline"><st c="20501">status</st></strong><st c="20507"> command, which specifies the status of the server and the average load value – that is, the average number of regions per region server across </st><span class="No-Break"><st c="20651">all servers:</st></span></p>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/B19383_07_006.jpg" alt="Figure 7.6 – Running general-purpose HBase commands"/><st c="20663"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="21320">Figure 7.6 – Running general-purpose HBase commands</st></p>
			<p><st c="21371">Most enterprise applications rely on DBA</st><a id="_idIndexMarker554"/><st c="21412"> for table design and creation. </st><st c="21444">For HBase database users, the data modelers allow the application’s data layer to generate the tables at every server startup. </st><st c="21571">But often, developers build the tables before development using the HBase shell. </st><st c="21652">In our application, for instance, the </st><strong class="source-inline"><st c="21690">payments</st></strong><st c="21698"> and </st><strong class="source-inline"><st c="21703">bookings</st></strong><st c="21711"> tables are generated beforehand using the HBase </st><strong class="source-inline"><st c="21760">create</st></strong><st c="21766"> command. </st><span class="No-Break"><em class="italic"><st c="21776">Figure 7</st></em></span><em class="italic"><st c="21784">.7</st></em><st c="21786"> shows how to use the </st><span class="No-Break"><strong class="source-inline"><st c="21808">create</st></strong></span><span class="No-Break"><st c="21814"> command:</st></span></p>
			<div>
				<div id="_idContainer072" class="IMG---Figure">
					<img src="image/B19383_07_007.jpg" alt="Figure 7.7 – Using the create and list commands"/><st c="21823"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="22250">Figure 7.7 – Using the create and list commands</st></p>
			<p><st c="22297">To create an HBase table, use the </st><strong class="source-inline"><st c="22332">create</st></strong><st c="22338"> command with the </st><span class="No-Break"><st c="22356">following parameters:</st></span></p>
			<ul>
				<li><st c="22377">The single or double-quoted table name (for example, </st><strong class="source-inline"><st c="22431">'bookings'</st></strong> <span class="No-Break"><st c="22441">or </st></span><span class="No-Break"><strong class="source-inline"><st c="22445">"payments"</st></strong></span><span class="No-Break"><st c="22455">).</st></span></li>
				<li><st c="22458">The quoted column family’s name(s) or dictionaries containing the column family’s attributes, including </st><strong class="source-inline"><st c="22563">NAME</st></strong><st c="22567"> and other properties such as </st><strong class="source-inline"><st c="22597">VERSIONS</st></strong><st c="22605">, with their values all </st><span class="No-Break"><st c="22629">in quotes.</st></span></li>
			</ul>
			<p><span class="No-Break"><em class="italic"><st c="22639">Figure 7</st></em></span><em class="italic"><st c="22648">.7</st></em><st c="22650"> shows the </st><strong class="source-inline"><st c="22661">payments</st></strong><st c="22669"> table being created</st><a id="_idIndexMarker555"/><st c="22689"> with the </st><strong class="source-inline"><st c="22699">details</st></strong><st c="22706"> and </st><strong class="source-inline"><st c="22711">items</st></strong><st c="22716"> column families, each with only a maximum of five versions. </st><st c="22777">The </st><strong class="source-inline"><st c="22781">VERSIONS</st></strong><st c="22789"> property sets the maximum allowable number of updates imposed on the column family’s columns. </st><st c="22884">So, if the </st><strong class="source-inline"><st c="22895">payments</st></strong><st c="22903"> table has </st><strong class="source-inline"><st c="22914">VERSIONS</st></strong><st c="22922"> set to </st><strong class="source-inline"><st c="22930">5</st></strong><st c="22931">, the maximum number of allowed updates on the values of its column families is at most five times only. </st><st c="23036">The timestamp that’s given to each cell storage of the column qualifier traces </st><span class="No-Break"><st c="23115">these updates.</st></span></p>
			<p><st c="23129">Now, to view all the tables, use the </st><strong class="source-inline"><st c="23167">list</st></strong><st c="23171"> command. </st><st c="23181">There is also the </st><strong class="source-inline"><st c="23199">describe</st></strong><st c="23207"> command, which you can use to check the metadata information of each table (for example, </st><strong class="source-inline"><st c="23297">describe "bookings"</st></strong><st c="23316">). </st><st c="23320">To drop a table, disable the table first (for example, </st><strong class="source-inline"><st c="23375">disable "bookings"</st></strong><st c="23393">) before dropping it (for example, via </st><span class="No-Break"><strong class="source-inline"><st c="23433">drop "bookings"</st></strong></span><span class="No-Break"><st c="23448">).</st></span></p>
			<p><st c="23451">After creating the tables</st><a id="_idIndexMarker556"/><st c="23477"> in HBase storage, we can integrate our HBase database into our </st><span class="No-Break"><st c="23541">Flask application.</st></span></p>
			<h2 id="_idParaDest-183"><a id="_idTextAnchor187"/><st c="23559">Establishing an HBase connection</st></h2>
			<p><st c="23592">Many modern Python libraries</st><a id="_idIndexMarker557"/><st c="23621"> that can integrate HBase into Flask are proprietary, such as</st><a id="_idIndexMarker558"/><st c="23682"> this CData Python driver (</st><a href="https://www.cdata.com/drivers/hbase/download/python/"><st c="23709">https://www.cdata.com/drivers/hbase/download/python/</st></a><st c="23762">), which can utilize SQLAlchemy to manage HBase storage. </st><st c="23820">But there is one reliable and popular Python driver in the </st><em class="italic"><st c="23879">PyPI</st></em><st c="23883"> repository that can integrate any Python application into Hbase: the </st><span class="No-Break"><st c="23953">HappyBase library.</st></span></p>
			<p><st c="23971">The </st><strong class="source-inline"><st c="23976">happybase</st></strong><st c="23985"> module is a standard Python library that uses the </st><em class="italic"><st c="24036">Python Thrift</st></em><st c="24049"> library to connect to any HBase database using the </st><em class="italic"><st c="24101">Thrift</st></em><st c="24107"> service, which is already part of the Apache HBase </st><span class="No-Break"><st c="24159">2.5.5 platform.</st></span></p>
			<p><st c="24174">To utilize the </st><strong class="source-inline"><st c="24190">happybase</st></strong><st c="24199"> module, install it using the </st><span class="No-Break"><strong class="source-inline"><st c="24229">pip</st></strong></span><span class="No-Break"><st c="24232"> command:</st></span></p>
			<pre class="console"><st c="24241">
pip install happybase</st></pre>			<p><st c="24263">For </st><em class="italic"><st c="24268">Tutor Finder</st></em><st c="24280"> to establish a connection to HBase and create multiple threads for reusable connections, the application factory function in </st><strong class="source-inline"><st c="24406">__init__.py</st></strong><st c="24417"> must import </st><strong class="source-inline"><st c="24430">ConnectionPool</st></strong><st c="24444"> from the </st><strong class="source-inline"><st c="24454">happybase</st></strong><st c="24463"> module and provide it the </st><strong class="source-inline"><st c="24490">host</st></strong><st c="24494"> and </st><strong class="source-inline"><st c="24499">port</st></strong><st c="24503"> values of the Thrift gateway, as well as the number of connections in the pool. </st><st c="24584">The following script shows the application factory function, </st><strong class="source-inline"><st c="24645">create_app()</st></strong><st c="24657">, that initiates the </st><span class="No-Break"><strong class="source-inline"><st c="24678">happybase</st></strong></span><span class="No-Break"><st c="24687"> setup:</st></span></p>
			<pre class="source-code"><st c="24694">
from flask import Flask
import toml
</st><strong class="bold"><st c="24731">import happybase</st></strong><st c="24747">
def create_app(config_file):
    app = Flask(__name__)
    app.config.from_file(config_file, toml.load)
    </st><strong class="bold"><st c="24844">global pool</st></strong><strong class="bold"><st c="24855">pool = happybase.ConnectionPool(size=5,</st></strong> <strong class="bold"><st c="24895">host='localhost', port=9090)</st></strong><st c="24924">
    with app.app_context():
        import modules.api.hbase.payments
        import modules.api.hbase.bookings</st></pre>			<p><st c="25016">The entry point to the HBase platform is the </st><strong class="source-inline"><st c="25062">Connection</st></strong><st c="25072"> class. </st><st c="25080">The </st><strong class="source-inline"><st c="25084">Connection</st></strong><st c="25094"> class creates an open socket to the HBase database through the Thrift service. </st><st c="25174">But </st><strong class="source-inline"><st c="25178">ConnectionPool</st></strong><st c="25192"> provides faster access than the single </st><strong class="source-inline"><st c="25232">Connection</st></strong><st c="25242"> instance, especially if the Flask application is in asynchronous mode. </st><st c="25314">The only requirement is for the application to use a </st><strong class="source-inline"><st c="25367">with</st></strong><st c="25371"> context manager for the connection pool to spawn a </st><strong class="source-inline"><st c="25423">Connection</st></strong><st c="25433"> instance, assign a thread to it, and dispose of the thread when the transaction ends, eventually returning</st><a id="_idIndexMarker559"/><st c="25540"> the connection’s state to </st><span class="No-Break"><st c="25567">the pool.</st></span></p>
			<p><st c="25576">Let’s use </st><strong class="source-inline"><st c="25587">ConnectionPool</st></strong><st c="25601"> to build the </st><span class="No-Break"><st c="25615">repository layer.</st></span></p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor188"/><st c="25632">Building the repository layer</st></h2>
			<p><st c="25662">The </st><strong class="source-inline"><st c="25667">ConnectionPool</st></strong><st c="25681"> instance</st><a id="_idIndexMarker560"/><st c="25690"> from </st><strong class="source-inline"><st c="25696">create_app()</st></strong><st c="25708"> provides the </st><strong class="source-inline"><st c="25722">Connection</st></strong><st c="25732"> instance that implements the CRUD transactions. </st><st c="25781">But it needs a </st><strong class="source-inline"><st c="25796">with</st></strong><st c="25800"> context manager to spawn a </st><strong class="source-inline"><st c="25828">Connection</st></strong><st c="25838"> instance or reuse a connection state from the pool so that the thread can run the CRUD transactions using the </st><strong class="source-inline"><st c="25949">happybase</st></strong><st c="25958"> utility methods. </st><st c="25976">The following script shows the repository class that uses the </st><strong class="source-inline"><st c="26038">ConnectionPool</st></strong><st c="26052"> instance to implement the CRUD transactions for the </st><span class="No-Break"><strong class="source-inline"><st c="26105">payments</st></strong></span><span class="No-Break"><st c="26113"> table:</st></span></p>
			<pre class="source-code"><st c="26120">
from typing import Dict, List, Any
</st><strong class="bold"><st c="26156">from happybase import Table</st></strong><st c="26183">
class PaymentRepository:
    def __init__(self, </st><strong class="bold"><st c="26228">pool</st></strong><st c="26232">):
        </st><strong class="bold"><st c="26236">self.pool = pool</st></strong><st c="26252">
    def upsert_details(self, rowkey, tutor_id, stud_id, ccode, fee) -&gt; bool:
        record = </st><strong class="bold"><st c="26335">{'details:id' : str(rowkey),</st></strong> <strong class="bold"><st c="26363">'details:tutor_id': tutor_id, 'details:stud_id':</st></strong> <strong class="bold"><st c="26412">stud_id, 'details:course_code': ccode,</st></strong> <strong class="bold"><st c="26451">'details:total_package': str(fee)}</st></strong><st c="26486">
        try:
            </st><strong class="bold"><st c="26492">with self.pool.connection() as conn:</st></strong><strong class="bold"><st c="26528">tbl:Table = conn.table("payments")</st></strong><strong class="bold"><st c="26563">tbl.put(row=str(rowkey).encode('utf-8'),</st></strong> <strong class="bold"><st c="26604">data=record)</st></strong><st c="26617">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="26674">The </st><strong class="source-inline"><st c="26679">PaymentRepository</st></strong><st c="26696"> class requires a </st><strong class="source-inline"><st c="26714">ConnectionPool</st></strong><st c="26728"> instance (</st><strong class="source-inline"><st c="26739">pool</st></strong><st c="26744">) as a constructor argument</st><a id="_idIndexMarker561"/><st c="26772"> for its instantiation. </st><st c="26796">The </st><strong class="source-inline"><st c="26800">pool</st></strong><st c="26804"> object has a </st><strong class="source-inline"><st c="26818">connection()</st></strong><st c="26830"> method that returns an HBase connection that provides the </st><strong class="source-inline"><st c="26889">happybase</st></strong><st c="26898"> utility methods for CRUD transactions. </st><st c="26938">With the help of a thread, the connection object has a </st><strong class="source-inline"><st c="26993">table()</st></strong><st c="27000"> utility that accesses the HBase table and returns a </st><strong class="source-inline"><st c="27053">Table</st></strong><st c="27058"> object that provides several methods to execute database transactions, such </st><span class="No-Break"><st c="27135">as </st></span><span class="No-Break"><strong class="source-inline"><st c="27138">put()</st></strong></span><span class="No-Break"><st c="27143">.</st></span></p>
			<p><st c="27144">The </st><strong class="source-inline"><st c="27149">put()</st></strong><st c="27154"> method performs both </st><em class="italic"><st c="27176">INSERT</st></em><st c="27182"> and </st><em class="italic"><st c="27187">UPDATE</st></em><st c="27193"> transactions. </st><st c="27208">It requires </st><strong class="source-inline"><st c="27220">rowkey</st></strong><st c="27226"> as its primary parameter for inserting a record in dictionary format. </st><st c="27297">The dictionary record consists of a </st><em class="italic"><st c="27333">column qualifier-value pair</st></em><st c="27360">, wherein all the values should be byte strings or any type converted into </st><strong class="source-inline"><st c="27435">bytes</st></strong><st c="27440"> by the </st><strong class="source-inline"><st c="27448">encode('utf-8')</st></strong><st c="27463"> method. </st><st c="27472">Also, </st><strong class="source-inline"><st c="27478">rowkey</st></strong><st c="27484"> should always be a byte string. </st><st c="27517">The given </st><strong class="source-inline"><st c="27527">upsert_details()</st></strong><st c="27543"> inserts payment records into the </st><strong class="source-inline"><st c="27577">payments</st></strong><st c="27585"> table of the </st><span class="No-Break"><st c="27599">HBase database.</st></span></p>
			<p><st c="27614">Aside from </st><strong class="source-inline"><st c="27626">put()</st></strong><st c="27631">, the </st><strong class="source-inline"><st c="27637">Table</st></strong><st c="27642"> object has a </st><strong class="source-inline"><st c="27656">delete()</st></strong><st c="27664"> method that deletes a record using its </st><strong class="source-inline"><st c="27704">rowkey</st></strong><st c="27710">. The following </st><strong class="source-inline"><st c="27726">delete_payment_details()</st></strong><st c="27750"> function of </st><strong class="source-inline"><st c="27763">PaymentRepository</st></strong><st c="27780"> highlights  payment details being deleted from the </st><span class="No-Break"><strong class="source-inline"><st c="27831">payments</st></strong></span><span class="No-Break"><st c="27839"> table:</st></span></p>
			<pre class="source-code"><st c="27846">
def delete_payment_items(self, rowkey) -&gt; bool:
        try:
            </st><strong class="bold"><st c="27900">with self.pool.connection() as conn:</st></strong><strong class="bold"><st c="27936">tbl:Table = conn.table("payments")</st></strong><strong class="bold"><st c="27971">tbl.delete(rowkey.encode('utf-8'),</st></strong> <strong class="bold"><st c="28006">columns=["items"])</st></strong><st c="28025">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="28082">Aside from </st><strong class="source-inline"><st c="28094">rowkey</st></strong><st c="28100">, the </st><strong class="source-inline"><st c="28106">delete()</st></strong><st c="28114"> method</st><a id="_idIndexMarker562"/><st c="28121"> needs the name of the column family or families in its </st><strong class="source-inline"><st c="28177">columns</st></strong><st c="28184"> parameter, which means deleting the whole record. </st><st c="28235">But sometimes, deletion requires only removing the column qualifier(s) or column(s) instead of the entire row so that only the column qualifier name(s) appear in the </st><span class="No-Break"><strong class="source-inline"><st c="28401">columns</st></strong></span><span class="No-Break"><st c="28408"> parameter.</st></span></p>
			<p><st c="28419">The </st><strong class="source-inline"><st c="28424">Table</st></strong><st c="28429"> object has a </st><strong class="source-inline"><st c="28443">rows()</st></strong><st c="28449"> method that returns a </st><strong class="source-inline"><st c="28472">Tuple</st></strong><st c="28477"> value or list of tuples, each containing </st><strong class="source-inline"><st c="28519">rowkey</st></strong><st c="28525"> and the record in </st><strong class="source-inline"><st c="28544">bytes</st></strong><st c="28549">. This method has two parameters, the </st><em class="italic"><st c="28587">row key</st></em><st c="28594"> and </st><em class="italic"><st c="28599">column family or families</st></em><st c="28624"> of the data records in the search. </st><st c="28660">Here, </st><strong class="source-inline"><st c="28666">select_records_ids()</st></strong><st c="28686"> returns a list of payment records based on a selected list of row keys with some specified </st><span class="No-Break"><st c="28778">column families:</st></span></p>
			<pre class="source-code"><st c="28794">
def select_records_ids(self, rowkeys:List[str], cols:List[str] = None):
        try:
            </st><strong class="bold"><st c="28872">with self.pool.connection() as conn:</st></strong><st c="28908">
                tbl:Table = conn.table("payments")
                if cols == None or len(cols) == 0:
                    </st><strong class="bold"><st c="28979">rowkeys = tbl.rows(rowkeys)</st></strong><strong class="bold"><st c="29006">rows = [rec[1] for rec in rowkeys]</st></strong><st c="29041">
                else:
                    </st><strong class="bold"><st c="29048">rowkeys = tbl.rows(rowkeys, cols)</st></strong><strong class="bold"><st c="29081">rows = [rec[1] for rec in rowkeys]</st></strong><st c="29116">
            records = list()
            </st><strong class="bold"><st c="29134">for r in rows:</st></strong><strong class="bold"><st c="29148">records.append({key.decode():value.decode()</st></strong> <strong class="bold"><st c="29192">for key, value in r.items()})</st></strong><st c="29222">
            return records
        except Exception as e:
            print(e)
        return None</st></pre>			<p><st c="29281">The </st><strong class="source-inline"><st c="29286">rows()</st></strong><st c="29292"> method returns a </st><strong class="source-inline"><st c="29310">Tuple</st></strong><st c="29315"> value or tuples</st><a id="_idIndexMarker563"/><st c="29331"> containing the </st><em class="italic"><st c="29347">row key</st></em><st c="29354"> as the first element and the </st><em class="italic"><st c="29384">records</st></em><st c="29391"> in dictionary format as the second element. </st><st c="29436">Thus, we only need to shift the dictionary part using a list comprehension, as depicted in the code. </st><st c="29537">Also, decoding each dictionary of fields will avoid JSON errors in Flask during its </st><span class="No-Break"><strong class="source-inline"><st c="29621">Response</st></strong></span><span class="No-Break"><st c="29629"> generation.</st></span></p>
			<p><st c="29641">For its input, the </st><strong class="source-inline"><st c="29661">select_records_ids()</st></strong><st c="29681"> function can accept JSON requests containing the row keys of the records in search, as </st><span class="No-Break"><st c="29769">shown here:</st></span></p>
			<pre class="source-code"><st c="29780">
{
    </st><strong class="bold"><st c="29783">"rowkeys": ["1", "2", "101"],</st></strong><st c="29812">
    "cols": []
}</st></pre>			<p><st c="29825">Alternatively, it can accept both the row keys and the column families, such as for the following </st><span class="No-Break"><st c="29924">request data:</st></span></p>
			<pre class="source-code"><st c="29937">
{
    "rowkeys": ["1", "2", "101"],
    </st><strong class="bold"><st c="29970">"cols": ["details"]</st></strong><st c="29989">
}</st></pre>			<p><st c="29991">It can also accept specific column qualifiers that need to appear in the search output, as shown in the </st><span class="No-Break"><st c="30095">following code:</st></span></p>
			<pre class="source-code"><st c="30110">
{
    "rowkeys": ["1", "2", "101"],
    </st><strong class="bold"><st c="30143">"cols": ["details:stud_id", "details:tutor_id",</st></strong> <strong class="bold"><st c="30190">"details:course_code"]</st></strong><st c="30213">
}</st></pre>			<p><st c="30215">Another way of retrieving data</st><a id="_idIndexMarker564"/><st c="30245"> in the </st><strong class="source-inline"><st c="30253">happybase</st></strong><st c="30262"> module is through the </st><strong class="source-inline"><st c="30285">scan()</st></strong><st c="30291"> method, which returns a generator of tuples – similar tuples returned by </st><strong class="source-inline"><st c="30365">rows()</st></strong><st c="30371">. Here, </st><strong class="source-inline"><st c="30379">select_all_records()</st></strong><st c="30399"> shows how to use </st><strong class="source-inline"><st c="30417">scan()</st></strong><st c="30423"> to retrieve all the </st><span class="No-Break"><st c="30444">payment records:</st></span></p>
			<pre class="source-code"><st c="30460">
def select_all_records(self):
        records = []
        try:
            </st><strong class="bold"><st c="30509">with self.pool.connection() as conn:</st></strong><st c="30545">
                tbl:Table = conn.table("payments")
                </st><strong class="bold"><st c="30581">datalist = tbl.scan(columns=['details',</st></strong> <strong class="bold"><st c="30620">'items'])</st></strong><strong class="bold"><st c="30630">for key, data in datalist:</st></strong><strong class="bold"><st c="30657">data_str = {k.decode(): v.decode() for</st></strong> <strong class="bold"><st c="30696">k, v in data.items()}</st></strong><st c="30718">
                    records.append(data_str)
                return records
        except Exception as e:
            print(e)
        return records</st></pre>			<p><st c="30805">The method requires a </st><strong class="source-inline"><st c="30828">for</st></strong><st c="30831"> loop to extract all these records from the generator and decode all the details, which includes the column qualifier as the key and the value of each key, before adding them to a list. </st><st c="31017">This retrieval consumes less running time than using lots of list and dictionary comprehensions </st><span class="No-Break"><st c="31113">with </st></span><span class="No-Break"><strong class="source-inline"><st c="31118">rows()</st></strong></span><span class="No-Break"><st c="31124">.</st></span></p>
			<p><st c="31125">Another advantage</st><a id="_idIndexMarker565"/><st c="31143"> of using </st><strong class="source-inline"><st c="31153">scan()</st></strong><st c="31159"> instead of </st><strong class="source-inline"><st c="31171">rows()</st></strong><st c="31177"> is its advanced feature to filter records using the predicate conditions on columns, similar to a </st><strong class="source-inline"><st c="31276">WHERE</st></strong><st c="31281"> clause in a SQL statement. </st><st c="31309">The following query transaction retrieves all payment records with a specific </st><em class="italic"><st c="31387">tutor ID</st></em><st c="31395"> specified by </st><span class="No-Break"><st c="31409">the client:</st></span></p>
			<pre class="source-code"><st c="31420">
def select_records_tutor(self, tutor_id):
   records = []
   try:
      </st><strong class="bold"><st c="31481">with self.pool.connection() as conn:</st></strong><st c="31517">
          tbl:Table = conn.table("payments")
          </st><strong class="bold"><st c="31553">datalist = tbl.scan(columns=["details", "items"],</st></strong> <strong class="bold"><st c="31602">filter="SingleColumnValueFilter('details',</st></strong> <strong class="bold"><st c="31645">'tutor_id', =,'binary:{}')".format(tutor_id))</st></strong><strong class="bold"><st c="31691">for key, data in datalist:</st></strong><strong class="bold"><st c="31718">data_str = {k.decode(): v.decode() for k, v in</st></strong> <strong class="bold"><st c="31765">data.items()}</st></strong><strong class="bold"><st c="31779">records.append(data_str)</st></strong><st c="31804">
      return records
   except Exception as e:
       print(e)
   return records</st></pre>			<p><st c="31866">The </st><strong class="source-inline"><st c="31871">scan()</st></strong><st c="31877"> method has a </st><strong class="source-inline"><st c="31891">filter</st></strong><st c="31897"> parameter that accepts a </st><em class="italic"><st c="31923">filter string</st></em><st c="31936"> constituting the </st><em class="italic"><st c="31954">filter class</st></em><st c="31966"> and its </st><em class="italic"><st c="31975">constructor arguments</st></em><st c="31996">, which will streamline the search. </st><st c="32032">The </st><strong class="source-inline"><st c="32036">filter</st></strong><st c="32042"> parameter indicates what filter class to instantiate to build the appropriate search constraints. </st><st c="32141">The given </st><strong class="source-inline"><st c="32151">select_records_tutor()</st></strong><st c="32173"> function uses </st><strong class="source-inline"><st c="32188">SingleColumnValueFilter</st></strong><st c="32211">, which filters rows based on a value constraint given to the </st><em class="italic"><st c="32273">column family</st></em><st c="32286">, </st><em class="italic"><st c="32288">column qualifier</st></em><st c="32304">, </st><em class="italic"><st c="32306">conditional operator</st></em><st c="32326">, and </st><strong class="source-inline"><st c="32332">BinaryComparator (binary)</st></strong><st c="32357">. Aside from </st><strong class="source-inline"><st c="32370">SingleColumnValueFilter</st></strong><st c="32393">, here are some widely used types of filter classes that can create search conditions for the </st><span class="No-Break"><strong class="source-inline"><st c="32487">scan()</st></strong></span><span class="No-Break"><st c="32493"> method:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="32501">RowFilter</st></strong><st c="32511">: Accepts a comparison operator and the preferred comparator (for example, </st><strong class="source-inline"><st c="32587">ByteComparator</st></strong><st c="32601">, </st><strong class="source-inline"><st c="32603">RegexStringComparator</st></strong><st c="32624">, and so on) needed to compare the indicated value with each </st><span class="No-Break"><st c="32685">row key.</st></span></li>
				<li><strong class="source-inline"><st c="32693">QualifierFilter</st></strong><st c="32709">: Accepts a conditional operator and the preferred comparator (for example, </st><strong class="source-inline"><st c="32786">ByteComparator</st></strong><st c="32800">, </st><strong class="source-inline"><st c="32802">RegexStringComparator</st></strong><st c="32823">, and so on) needed to compare the column qualifier name of each row with the </st><span class="No-Break"><st c="32901">given value.</st></span></li>
				<li><strong class="source-inline"><st c="32913">ColumnRangeFilter</st></strong><st c="32931">: Accepts the minimum range column and maximum range column and then checks if the indicated value falls between the range </st><span class="No-Break"><st c="33055">column values.</st></span></li>
				<li><strong class="source-inline"><st c="33069">ValueFilter</st></strong><st c="33081">: Accepts a conditional operator and the preferred comparator needed to compare the value to each </st><span class="No-Break"><st c="33180">field value.</st></span></li>
			</ul>
			<p><st c="33192">Aside from </st><strong class="source-inline"><st c="33204">BinaryComparator</st></strong><st c="33220">, other comparators that provide conversion and comparison methods</st><a id="_idIndexMarker566"/><st c="33286"> for a filter class are </st><strong class="source-inline"><st c="33310">BinaryPrefixComparator</st></strong><st c="33332">, </st><strong class="source-inline"><st c="33334">RegexStringComparator</st></strong><st c="33355">, </st><span class="No-Break"><st c="33357">and </st></span><span class="No-Break"><strong class="source-inline"><st c="33361">SubStringComparator</st></strong></span><span class="No-Break"><st c="33380">.</st></span></p>
			<p><st c="33381">In the next section, we’ll apply </st><strong class="source-inline"><st c="33415">PaymentsRepository</st></strong><st c="33433"> so that we can store and retrieve payment details in and from the </st><span class="No-Break"><strong class="source-inline"><st c="33500">payments</st></strong></span><span class="No-Break"><st c="33508"> table.</st></span></p>
			<h2 id="_idParaDest-185"><a id="_idTextAnchor189"/><st c="33515">Applying a repository to API functions</st></h2>
			<p><st c="33554">The following API function</st><a id="_idIndexMarker567"/><st c="33581"> uses </st><strong class="source-inline"><st c="33587">upsert_details()</st></strong><st c="33603"> from </st><strong class="source-inline"><st c="33609">PaymentRepository</st></strong><st c="33626"> to perform an </st><em class="italic"><st c="33641">INSERT</st></em><st c="33647"> transaction after receiving JSON request data from </st><span class="No-Break"><st c="33699">the client:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="33710">from modules import pool</st></strong>
<strong class="bold"><st c="33735">@current_app.post('/ch07/payment/details/add')</st></strong><st c="33782">
def add_payment_details():
    data = request.get_json()
    </st><strong class="bold"><st c="33836">repo = PaymentRepository(pool)</st></strong><strong class="bold"><st c="33866">result = repo.upsert_details(data['id'],</st></strong> <strong class="bold"><st c="33907">data['tutor_id'], data['stud_id'], data['ccode'],</st></strong> <strong class="bold"><st c="33957">data['fee'])</st></strong><st c="33970">
    if result == False:
        return jsonify(message="error encountered in payment details record insert"), 500
    return jsonify(message="inserted payment details record"), 201</st></pre>			<p><st c="34135">The repository’s </st><strong class="source-inline"><st c="34153">select_all_records()</st></strong><st c="34173"> provides the following </st><strong class="source-inline"><st c="34197">list_all_payments()</st></strong><st c="34216"> function to render</st><a id="_idIndexMarker568"/><st c="34235"> all the records from the </st><span class="No-Break"><strong class="source-inline"><st c="34261">payments</st></strong></span><span class="No-Break"><st c="34269"> table:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="34276">from modules import pool</st></strong>
<strong class="bold"><st c="34301">@current_app.get('/ch07/payment/list/all')</st></strong><st c="34344">
def list_all_payments():
    </st><strong class="bold"><st c="34370">repo = PaymentRepository(pool)</st></strong><strong class="bold"><st c="34400">results = repo.select_all_records()</st></strong><st c="34436">
    return jsonify(records=results), 201</st></pre>			<p><st c="34473">Here, </st><strong class="source-inline"><st c="34480">pool</st></strong><st c="34484"> is the </st><strong class="source-inline"><st c="34492">ConnectionPool</st></strong><st c="34506"> instance that was created in the </st><strong class="source-inline"><st c="34540">create_app()</st></strong><st c="34552"> factory from the </st><strong class="source-inline"><st c="34570">__init__.py</st></strong><st c="34581"> file of the </st><span class="No-Break"><strong class="source-inline"><st c="34594">modules</st></strong></span><span class="No-Break"><st c="34601"> package.</st></span></p>
			<p><st c="34610">Now, for </st><strong class="source-inline"><st c="34620">happybase</st></strong><st c="34629"> to work, start up the </st><em class="italic"><st c="34652">thrift server</st></em><st c="34665">. Let’s showcase the Apache Thrift framework in the </st><span class="No-Break"><st c="34717">HBase platform.</st></span></p>
			<h2 id="_idParaDest-186"><a id="_idTextAnchor190"/><st c="34732">Running the thrift server</st></h2>
			<p><strong class="bold"><st c="34758">Apache Thrift</st></strong><st c="34772"> is an RPC-based framework that provides</st><a id="_idIndexMarker569"/><st c="34812"> an interface for cross-language </st><a id="_idIndexMarker570"/><st c="34845">service development, such as building clients to HBase using Python, Java, C++, C#, or PHP to access HBase tables. </st><st c="34960">To start the built-in thrift server of Apache HBase 2.5.5, run the </st><strong class="source-inline"><st c="35027">hbase thrift start</st></strong><st c="35045"> command. </st><span class="No-Break"><em class="italic"><st c="35055">Figure 7</st></em></span><em class="italic"><st c="35063">.8</st></em><st c="35065"> shows the logs after starting up the </st><span class="No-Break"><st c="35103">thrift server:</st></span></p>
			<div>
				<div id="_idContainer073" class="IMG---Figure">
					<img src="image/B19383_07_008.jpg" alt="Figure 7.8 – Running a built-in HBase thrift server"/><st c="35117"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="35871">Figure 7.8 – Running a built-in HBase thrift server</st></p>
			<p><st c="35922">Apache Thrift will only run if Apache HBase, Hadoop, and Zookeeper are </st><span class="No-Break"><st c="35994">all running.</st></span></p>
			<p><st c="36006">The </st><strong class="source-inline"><st c="36011">happybase</st></strong><st c="36020"> module is non-Flask-specific, which means any Python client can use it to connect to the </st><strong class="source-inline"><st c="36110">HBase</st></strong><st c="36115"> server. </st><st c="36124">The thrift server will always bridge between the client and HBase considering that the Python library uses the </st><em class="italic"><st c="36235">Thrift 1</st></em><st c="36243"> or </st><em class="italic"><st c="36247">2</st></em><st c="36248"> library to establish a connection. </st><st c="36284">The </st><strong class="source-inline"><st c="36288">happybase</st></strong><st c="36297"> module uses the Thrift </st><span class="No-Break"><st c="36321">1 library.</st></span></p>
			<p><st c="36331">Now that we’ve created Flask repository transactions for the HBase database, let’s explore a type of NoSQL storage that uses columns and rows for </st><span class="No-Break"><st c="36478">data storage.</st></span></p>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor191"/><st c="36491">Utilizing the column storage of Apache Cassandra</st></h1>
			<p><strong class="bold"><st c="36540">Apache Cassandra</st></strong><st c="36557"> is a </st><em class="italic"><st c="36563">column-family</st></em><st c="36576"> NoSQL database</st><a id="_idIndexMarker571"/><st c="36591"> that can also hold</st><a id="_idIndexMarker572"/><st c="36610"> large amounts of data. </st><st c="36634">HBase can share big data</st><a id="_idIndexMarker573"/><st c="36658"> across its regions using auto-sharding, which makes HBase horizontally scalable. </st><st c="36740">Likewise, Cassandra supports adding more nodes horizontally to improve server throughput, a characteristic of horizontal scaling. </st><st c="36870">But there are also some differences between the two storages in terms of their architectures, table read and write performances, data </st><a id="_idIndexMarker574"/><st c="37004">modeling approaches, and </st><span class="No-Break"><st c="37029">query </st></span><span class="No-Break"><a id="_idIndexMarker575"/></span><span class="No-Break"><st c="37035">languages.</st></span></p>
			<p><st c="37045">Let’s start by designing our </st><strong class="source-inline"><st c="37075">course</st></strong><st c="37081">, </st><strong class="source-inline"><st c="37083">degree_level</st></strong><st c="37095">, </st><strong class="source-inline"><st c="37097">student</st></strong><st c="37104">, and </st><strong class="source-inline"><st c="37110">student_perf</st></strong> <span class="No-Break"><st c="37122">Cassandra tables.</st></span></p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor192"/><st c="37140">Designing Cassandra tables</st></h2>
			<p><st c="37167">Unlike HBase, Cassandra stores</st><a id="_idIndexMarker576"/><st c="37198"> its data per row, grouping all column fields, thus why the data model approach is a </st><em class="italic"><st c="37283">column family</st></em><st c="37296">. Its database transactions are atomic, isolated, and durable, but with eventual</st><a id="_idIndexMarker577"/><st c="37376"> or tunable consistency, so it doesn’t offer an </st><strong class="bold"><st c="37424">Atomicity, Consistency, Isolation, Durability</st></strong><st c="37469"> (</st><strong class="bold"><st c="37471">ACID</st></strong><st c="37475">) model like a </st><strong class="bold"><st c="37491">relational database management system</st></strong><st c="37528"> (</st><strong class="bold"><st c="37530">RDBMS</st></strong><st c="37535">). </st><st c="37539">Sometimes, the Cassandra setup favors</st><a id="_idIndexMarker578"/><st c="37576"> higher-availability performance over atomic and </st><span class="No-Break"><st c="37625">isolated transactions.</st></span></p>
			<p><st c="37647">This project used </st><em class="italic"><st c="37666">draw.io</st></em><st c="37673"> to design the tables in Cassandra using UML class diagrams. </st><span class="No-Break"><em class="italic"><st c="37734">Figure 7</st></em></span><em class="italic"><st c="37742">.9</st></em><st c="37744"> shows the data model for the project’s Cassandra </st><span class="No-Break"><st c="37794">data storage:</st></span></p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/B19383_07_009.jpg" alt="Figure 7.9 – Cassandra table designs using UML"/><st c="37807"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="38370">Figure 7.9 – Cassandra table designs using UML</st></p>
			<p><st c="38416">Each Cassandra table must</st><a id="_idIndexMarker579"/><st c="38442"> have a primary key. </st><st c="38463">But, unlike in RDBMS, a primary key in </st><em class="italic"><st c="38502">column-family</st></em><st c="38515"> storage has at least one </st><em class="italic"><st c="38541">partition key</st></em><st c="38554"> and zero or more </st><em class="italic"><st c="38572">clustering keys</st></em><st c="38587">. Since Cassandra storage runs on a distributed environment of clusters and nodes, the </st><em class="italic"><st c="38674">partition key</st></em><st c="38687"> evenly distributes the row data across the clustered storage. </st><st c="38750">On the other hand, the </st><em class="italic"><st c="38773">clustering key</st></em><st c="38787"> sorts and manages the rows of data in a table. </st><st c="38835">Also, the performance of the query transactions is the ultimate basis of the table design; the faster the query will be, the better </st><span class="No-Break"><st c="38967">the design.</st></span></p>
			<p><st c="38978">Let’s install Apache Cassandra so that we can realize our </st><span class="No-Break"><st c="39037">table design.</st></span></p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor193"/><st c="39050">Installing and configuring Apache Cassandra</st></h2>
			<p><st c="39094">Download the ZIP</st><a id="_idIndexMarker580"/><st c="39111"> file for Apache</st><a id="_idIndexMarker581"/><st c="39127"> Cassandra at </st><a href="https://cassandra.apache.org/_/download.html"><st c="39141">https://cassandra.apache.org/_/download.html</st></a><st c="39185">. The </st><strong class="bold"><st c="39191">general availability</st></strong><st c="39211"> (</st><strong class="bold"><st c="39213">GA</st></strong><st c="39215">) versions 3.x and below</st><a id="_idIndexMarker582"/><st c="39240"> support Windows but not version 4.x. </st><st c="39278">Since the project uses version 4.1.3, Windows PowerShell with WSL2 installed must be used to configure and run </st><span class="No-Break"><st c="39389">the server.</st></span></p>
			<p><st c="39400">After unzipping the file, enable the Ubuntu firewall using the </st><span class="No-Break"><strong class="source-inline"><st c="39464">sudo</st></strong></span><span class="No-Break"><st c="39468"> command:</st></span></p>
			<pre class="console"><st c="39477">
sudo ufw enable</st></pre>			<p><st c="39493">Then, allow non-WSL clients to access ports </st><em class="italic"><st c="39538">7000</st></em><st c="39542"> (port for cluster communication), </st><em class="italic"><st c="39577">9042</st></em><st c="39581"> (default port for client access), and </st><em class="italic"><st c="39620">7199</st></em><st c="39624"> (port for JMX) using the following </st><span class="No-Break"><strong class="source-inline"><st c="39660">sudo</st></strong></span><span class="No-Break"><st c="39664"> commands:</st></span></p>
			<pre class="console"><st c="39674">
sudo ufw allow 7000
sudo ufw allow 9042
sudo ufw allow 7199</st></pre>			<p><st c="39734">Apache Cassandra 4.1.3 requires </st><em class="italic"><st c="39767">Java 11</st></em><st c="39774"> as its virtual machine, so run the following </st><strong class="source-inline"><st c="39820">sudo</st></strong><st c="39824"> command to install Java SDK 11 in the </st><span class="No-Break"><st c="39863">Ubuntu environment:</st></span></p>
			<pre class="console"><st c="39882">
sudo apt install openjdk-11-jdk</st></pre>			<p><st c="39914">After, go to the </st><strong class="source-inline"><st c="39932">/conf</st></strong><st c="39937"> directory of Cassandra’s installation folder and open the </st><strong class="source-inline"><st c="39996">jvm11-server.options</st></strong><st c="40016"> file. </st><st c="40023">Comment all the </st><em class="italic"><st c="40039">CMS</st></em><st c="40042"> GC option details and uncomment </st><em class="italic"><st c="40075">G1GC</st></em><st c="40079">, the default GC option for </st><span class="No-Break"><st c="40107">Java 11.</st></span></p>
			<p><st c="40115">Finally, run the following command from the </st><strong class="source-inline"><st c="40160">/</st></strong><span class="No-Break"><strong class="source-inline"><st c="40161">conf</st></strong></span><span class="No-Break"><st c="40165"> directory:</st></span></p>
			<pre class="console"><st c="40176">
cassandra -f</st></pre>			<p><st c="40189">To shut down the Cassandra server, use the </st><strong class="source-inline"><st c="40233">nodetool </st></strong><span class="No-Break"><strong class="source-inline"><st c="40242">drain</st></strong></span><span class="No-Break"><st c="40247"> command.</st></span></p>
			<p><st c="40256">Now, let’s open the Cassandra shell client to create</st><a id="_idIndexMarker583"/><st c="40309"> the project’s tables and learn </st><strong class="bold"><st c="40341">Cassandra Query Language</st></strong><st c="40365"> (</st><span class="No-Break"><strong class="bold"><st c="40367">CQL</st></strong></span><span class="No-Break"><st c="40370">) commands.</st></span></p>
			<h2 id="_idParaDest-190"><a id="_idTextAnchor194"/><st c="40382">Running the CQL shell client</st></h2>
			<p><st c="40411">Cassandra 4.1.3 has</st><a id="_idIndexMarker584"/><st c="40431"> a query language called </st><strong class="bold"><st c="40456">Cassandra Query Language</st></strong><st c="40480"> (</st><strong class="bold"><st c="40482">CQL</st></strong><st c="40485">) that supports row and column</st><a id="_idIndexMarker585"/><st c="40516"> operations, similar to relational SQL. </st><st c="40556">To run these CQL commands, spawn the CQL shell client by running the </st><strong class="source-inline"><st c="40625">cqlsh</st></strong><st c="40630"> command in the </st><strong class="source-inline"><st c="40646">/conf</st></strong><st c="40651"> directory. </st><span class="No-Break"><em class="italic"><st c="40663">Figure 7</st></em></span><em class="italic"><st c="40671">.10</st></em><st c="40674"> shows the process of opening the </st><em class="italic"><st c="40708">CQL </st></em><span class="No-Break"><em class="italic"><st c="40712">shell</st></em></span><span class="No-Break"><st c="40717"> (</st></span><span class="No-Break"><strong class="source-inline"><st c="40719">cqlsh</st></strong></span><span class="No-Break"><st c="40724">):</st></span></p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B19383_07_010.jpg" alt="Figure 7.10 – Running the cqlsh command"/><st c="40727"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="40952">Figure 7.10 – Running the cqlsh command</st></p>
			<p><st c="40991">CQL has </st><strong class="bold"><st c="41000">data definition languages</st></strong><st c="41025"> (</st><strong class="bold"><st c="41027">DDLs</st></strong><st c="41031">), </st><strong class="bold"><st c="41035">data manipulation languages</st></strong><st c="41062"> (</st><strong class="bold"><st c="41064">DML</st></strong><st c="41067">), queries, and general-purpose</st><a id="_idIndexMarker586"/><st c="41099"> commands. </st><st c="41110">For DDL, it has</st><a id="_idIndexMarker587"/><st c="41125"> the </st><strong class="source-inline"><st c="41130">create</st></strong><st c="41136"> |</st><strong class="source-inline"><st c="41138">alter</st></strong><st c="41143"> | </st><strong class="source-inline"><st c="41146">drop keyspace</st></strong><st c="41159">, </st><strong class="source-inline"><st c="41161">create</st></strong><st c="41167"> | </st><strong class="source-inline"><st c="41170">alter</st></strong><st c="41175"> | </st><strong class="source-inline"><st c="41178">drop table</st></strong><st c="41188">, </st><strong class="source-inline"><st c="41190">use</st></strong><st c="41193">, and </st><strong class="source-inline"><st c="41199">truncate</st></strong><st c="41207"> statements. </st><st c="41220">For DML, it has </st><strong class="source-inline"><st c="41236">insert</st></strong><st c="41242">, </st><strong class="source-inline"><st c="41244">delete</st></strong><st c="41250">, </st><strong class="source-inline"><st c="41252">update</st></strong><st c="41258">, and </st><strong class="source-inline"><st c="41264">batch</st></strong><st c="41269"> commands. </st><st c="41280">For query transactions, it utilizes the </st><strong class="source-inline"><st c="41320">select</st></strong><st c="41326"> clause like in SQL. </st><st c="41347">However, the </st><strong class="source-inline"><st c="41360">where</st></strong><st c="41365"> clause is limited only to partition, clustering, and composite keys. </st><st c="41435">Some CQL commands end with </st><span class="No-Break"><st c="41462">a semicolon.</st></span></p>
			<p><st c="41474">CQL has general-purpose</st><a id="_idIndexMarker588"/><st c="41498"> commands such as </st><strong class="source-inline"><st c="41516">show version</st></strong><st c="41528">, </st><strong class="source-inline"><st c="41530">expand</st></strong><st c="41536">, and </st><strong class="source-inline"><st c="41542">describe</st></strong><st c="41550">. To check all the clusters, run the </st><strong class="source-inline"><st c="41587">describe cluster</st></strong><st c="41603"> command. </st><st c="41613">To check all the keyspaces, run the </st><strong class="source-inline"><st c="41649">describe keyspaces</st></strong><st c="41667"> command. </st><st c="41677">To list all the tables in a keyspace, run the </st><strong class="source-inline"><st c="41723">describe tables</st></strong><st c="41738"> command. </st><span class="No-Break"><em class="italic"><st c="41748">Figure 7</st></em></span><em class="italic"><st c="41756">.11</st></em><st c="41759"> shows a series of CQL commands that view Cassandra’s </st><span class="No-Break"><st c="41813">data storage:</st></span></p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B19383_07_011.jpg" alt="Figure 7.11 – Running CQL general-purpose commands"/><st c="41826"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="42521">Figure 7.11 – Running CQL general-purpose commands</st></p>
			<p><st c="42571">Running the </st><strong class="source-inline"><st c="42584">describe</st></strong><st c="42592"> command on a table returns the metadata description of the Cassandra table, as shown in </st><span class="No-Break"><em class="italic"><st c="42681">Figure 7</st></em></span><span class="No-Break"><em class="italic"><st c="42689">.12</st></em></span><span class="No-Break"><st c="42692">:</st></span></p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B19383_07_012.jpg" alt="Figure 7.12 – Running the describe command on tables"/><st c="42694"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="43661">Figure 7.12 – Running the describe command on tables</st></p>
			<p><st c="43713">A </st><em class="italic"><st c="43716">cluster</st></em><st c="43723"> contains more than one data</st><a id="_idIndexMarker589"/><st c="43751"> center, and a </st><em class="italic"><st c="43766">data center</st></em><st c="43777"> can have more than one node. </st><st c="43807">Each </st><em class="italic"><st c="43812">node</st></em><st c="43816"> must have a keyspace to hold all the tables, materialized views, user-defined types, functions, and aggregates. </st><st c="43929">So, the first thing you must do with the CQL shell client is run the </st><strong class="source-inline"><st c="43998">create keyspace</st></strong><st c="44013"> command before building the project’s tables. </st><st c="44060">The following code creates </st><strong class="source-inline"><st c="44087">packtspace</st></strong><st c="44097">, which holds the tables of </st><span class="No-Break"><st c="44125">our application:</st></span></p>
			<pre class="console"><st c="44141">
CREATE KEYSPACE packtspace WITH replication = {'class': 'NetworkTopologyStrategy', 'datacenter1': '1'}  AND durable_writes = false;</st></pre>			<p><st c="44272">The </st><em class="italic"><st c="44277">replication strategy</st></em><st c="44297"> that’s used is called </st><strong class="source-inline"><st c="44320">NetworkTopologyStrategy</st></strong><st c="44343">. It makes </st><strong class="source-inline"><st c="44354">packtspace</st></strong><st c="44364"> open for replication and data storage expansion in the long run and also applicable for </st><span class="No-Break"><st c="44453">production deployment.</st></span></p>
			<p><st c="44475">After creating </st><strong class="source-inline"><st c="44491">packspace</st></strong><st c="44500">, you can manually create the </st><strong class="source-inline"><st c="44530">course</st></strong><st c="44536">, </st><strong class="source-inline"><st c="44538">student</st></strong><st c="44545">, </st><strong class="source-inline"><st c="44547">degree_level</st></strong><st c="44559">, and </st><strong class="source-inline"><st c="44565">student_perf</st></strong><st c="44577"> tables in </st><strong class="source-inline"><st c="44588">keyspace</st></strong><st c="44596"> using the CQL command. </st><st c="44620">However, DataStax has a </st><strong class="source-inline"><st c="44644">cassandra-driver</st></strong><st c="44660"> module that establishes a database connection to Cassandra and generates tables using the entity or model classes. </st><st c="44776">Let’s use this external module</st><a id="_idIndexMarker590"/><st c="44806"> to build the application’s </st><span class="No-Break"><st c="44834">model layer.</st></span></p>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor195"/><st c="44846">Establishing a database connection</st></h2>
			<p><st c="44881">The </st><strong class="source-inline"><st c="44886">cassandra-driver</st></strong><st c="44902"> module is a Python</st><a id="_idIndexMarker591"/><st c="44921"> client driver that integrates Apache Cassandra into the Flask application. </st><st c="44997">It contains classes and methods that will only be available after installing the module using the </st><span class="No-Break"><strong class="source-inline"><st c="45095">pip</st></strong></span><span class="No-Break"><st c="45098"> command:</st></span></p>
			<pre class="console"><st c="45107">
pip install cassandra-driver</st></pre>			<p><st c="45136">For our </st><em class="italic"><st c="45145">Tutor Finder</st></em><st c="45157"> to establish a Cassandra database connection, import </st><strong class="source-inline"><st c="45211">setup()</st></strong><st c="45218"> from the </st><strong class="source-inline"><st c="45228">cassandra.cqlengine.connection</st></strong><st c="45258"> module in the </st><strong class="source-inline"><st c="45273">__init__.py</st></strong><st c="45284"> file of the </st><strong class="source-inline"><st c="45297">modules</st></strong><st c="45304"> package and invoke </st><strong class="source-inline"><st c="45324">setup()</st></strong><st c="45331"> inside the </st><strong class="source-inline"><st c="45343">create_app()</st></strong><st c="45355"> factory method with the arguments for its </st><strong class="source-inline"><st c="45398">hosts</st></strong><st c="45403">, </st><strong class="source-inline"><st c="45405">default_keyspace</st></strong><st c="45421">, and </st><strong class="source-inline"><st c="45427">protocol_version</st></strong><st c="45443"> parameters. </st><st c="45456">The following snippet shows the </st><span class="No-Break"><st c="45488">whole process:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="45502">from cassandra.cqlengine.connection import setup</st></strong><st c="45551">
def create_app(config_file):
    app = Flask(__name__)
    app.config.from_file(config_file, toml.load)
    </st><strong class="bold"><st c="45648">setup(['127.0.0.1'], "packtspace", protocol_version=4)</st></strong></pre>			<p><st c="45702">The </st><strong class="source-inline"><st c="45707">hosts</st></strong><st c="45712"> parameter provides the initial set of IP addresses that will serve as the contact points for the clusters. </st><st c="45820">The second parameter is </st><strong class="source-inline"><st c="45844">keyspace</st></strong><st c="45852">, which was created beforehand with the CQL shell. </st><st c="45903">The </st><strong class="source-inline"><st c="45907">protocol version</st></strong><st c="45923"> parameter refers to the native protocol that </st><strong class="source-inline"><st c="45969">cassandra-driver</st></strong><st c="45985"> uses to communicate with the server. </st><st c="46023">It depicts the maximum number</st><a id="_idIndexMarker592"/><st c="46052"> of requests a connection can handle </st><span class="No-Break"><st c="46089">during communication.</st></span></p>
			<p><st c="46110">Next, we’ll create the </st><span class="No-Break"><st c="46134">model layer.</st></span></p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor196"/><st c="46146">Building the model layer</st></h2>
			<p><st c="46171">Instead of using the CQL</st><a id="_idIndexMarker593"/><st c="46196"> shell to create the tables, we’ll use the </st><strong class="source-inline"><st c="46239">cassandra-driver</st></strong><st c="46255"> module since it can create the tables programmatically using entity model classes that can translate into actual tables upon application server startup. </st><st c="46409">These model classes are often referred to as </st><em class="italic"><st c="46454">object mappers</st></em><st c="46468"> since they also map</st><a id="_idIndexMarker594"/><st c="46488"> to the metadata of the </st><span class="No-Break"><st c="46512">physical tables.</st></span></p>
			<p><st c="46528">Unlike HBase, Cassandra recognizes data structures and data types for its tables. </st><st c="46611">Thus, the driver has a </st><strong class="source-inline"><st c="46634">Model</st></strong><st c="46639"> class that subclasses entities for Cassandra table generation. </st><st c="46703">It also provides helper classes, such as </st><strong class="source-inline"><st c="46744">UUID</st></strong><st c="46748">, </st><strong class="source-inline"><st c="46750">Integer</st></strong><st c="46757">, </st><strong class="source-inline"><st c="46759">Float</st></strong><st c="46764">, and </st><strong class="source-inline"><st c="46770">DateTime</st></strong><st c="46778">, that can define column metadata in an entity class. </st><st c="46832">The following code shows the entity models that are created through the </st><span class="No-Break"><strong class="source-inline"><st c="46904">cassandra-driver</st></strong></span><span class="No-Break"><st c="46920"> module:</st></span></p>
			<pre class="source-code"><st c="46928">
import uuid
</st><strong class="bold"><st c="46941">from cassandra.cqlengine.columns import UUID, Text, Float,</st></strong> <strong class="bold"><st c="46999">DateTime, Integer, Blob</st></strong>
<strong class="bold"><st c="47023">from cassandra.cqlengine.models import Model</st></strong>
<strong class="bold"><st c="47068">from cassandra.cqlengine.management import sync_table</st></strong><st c="47122">
class Course(</st><strong class="bold"><st c="47136">Model</st></strong><st c="47142">):
    id      = </st><strong class="bold"><st c="47151">UUID</st></strong><st c="47155">(primary_key=True, default=uuid.uuid4)
    code    = </st><strong class="bold"><st c="47202">Text</st></strong><st c="47206">(primary_key=True, max_length=20, required=True,clustering_order="ASC")
    title   = </st><strong class="bold"><st c="47287">Text</st></strong><st c="47291">(required=True, max_length=100)
    req_hrs = </st><strong class="bold"><st c="47334">Float</st></strong><st c="47339">(required=True, default = 0)
    total_cost = </st><strong class="bold"><st c="47382">Float</st></strong><st c="47387">(required=True, default = 0.0)
    course_offered  = </st><strong class="bold"><st c="47436">DateTime</st></strong><st c="47444">()
    level = </st><strong class="bold"><st c="47456">Integer</st></strong><st c="47463">(required=True, default=-1)
    description   = </st><strong class="bold"><st c="47506">Text</st></strong><st c="47510">(required=False, max_length=200)
    </st><strong class="bold"><st c="47544">def get_json(self):</st></strong><st c="47563">
        return {
            'id': str(self.id),
            'code': self.code,
            'title' : self.title,
            'req_hrs': self.req_hrs,
            'total_cost': self.total_cost,
            'course_offered': self.course_offered,
            'level': self.level,
            'description': self.description
    }</st></pre>			<p><st c="47783">In the given </st><strong class="source-inline"><st c="47797">Course</st></strong><st c="47803"> entity, </st><strong class="source-inline"><st c="47812">id</st></strong><st c="47814"> and </st><strong class="source-inline"><st c="47819">code</st></strong><st c="47823"> are columns</st><a id="_idIndexMarker595"/><st c="47835"> that are declared as </st><em class="italic"><st c="47857">primary keys</st></em><st c="47869">; </st><strong class="source-inline"><st c="47872">id</st></strong><st c="47874"> is the </st><em class="italic"><st c="47882">partition key</st></em><st c="47895">, while </st><strong class="source-inline"><st c="47903">code</st></strong><st c="47907"> is the </st><em class="italic"><st c="47915">clustering key</st></em><st c="47929"> that will manage and sort the records per node in ascending order. </st><st c="47997">The </st><strong class="source-inline"><st c="48001">title</st></strong><st c="48006">, </st><strong class="source-inline"><st c="48008">req_hrs</st></strong><st c="48015">, </st><strong class="source-inline"><st c="48017">total_cost</st></strong><st c="48027">, </st><strong class="source-inline"><st c="48029">course_offered</st></strong><st c="48043">, </st><strong class="source-inline"><st c="48045">level</st></strong><st c="48050">, and </st><strong class="source-inline"><st c="48056">descriptions</st></strong><st c="48068"> columns are typical columns that contain their respective metadata. </st><st c="48137">On the other hand, the </st><strong class="source-inline"><st c="48160">get_json()</st></strong><st c="48170"> custom method is an optional mechanism that will serialize the model when </st><strong class="source-inline"><st c="48245">jsonify()</st></strong><st c="48254"> needs to render them as a </st><span class="No-Break"><st c="48281">JSON response.</st></span></p>
			<p><st c="48295">The following model classes define the </st><strong class="source-inline"><st c="48335">degree_level</st></strong><st c="48347">, </st><strong class="source-inline"><st c="48349">student</st></strong><st c="48356">, and </st><span class="No-Break"><strong class="source-inline"><st c="48362">student_perf</st></strong></span><span class="No-Break"><st c="48374"> tables:</st></span></p>
			<pre class="source-code"><st c="48382">
class DegreeLevel(</st><strong class="bold"><st c="48401">Model</st></strong><st c="48407">):
    id = </st><strong class="bold"><st c="48416">UUID</st></strong><st c="48420">(primary_key=True, default=uuid.uuid4)
    code = </st><strong class="bold"><st c="48467">Integer</st></strong><st c="48474">(primary_key=True,required=True, clustering_order="ASC")
    description = </st><strong class="bold"><st c="48546">Text</st></strong><st c="48550">(required=True)
    … … … … … …
    … … … … … …
class Student(Model):
    id = UUID(primary_key=True, default=uuid.uuid4)
    std_id = Text(primary_key=True,required=True, max_length=12, clustering_order="ASC")
    firstname = Text(required=True, max_length=60)
    midname = Text(required=True, max_length=60)
    … … … … … …
    … … … … … …
class StudentPerf(Model):
    id = UUID(primary_key=True, default=uuid.uuid4)
    std_id = Text(primary_key=True,required=True, max_length=12)
    course_code = Text(required=True, max_length=20)
    … … … … … …
    … … … … … …
sync_table(Course)
sync_table(DegreeLevel)
sync_table(Student)
sync_table(StudentPerf)</st></pre>			<p><st c="49156">Here, </st><strong class="source-inline"><st c="49163">sync_table()</st></strong><st c="49175"> from </st><strong class="source-inline"><st c="49181">cassandra-driver</st></strong><st c="49197"> converts each model into a table and synchronizes any changes made in the model classes to the mapped table in </st><strong class="source-inline"><st c="49309">keyspace</st></strong><st c="49317">. However, applying this method to the model class with too many changes may mess up the existing table’s metadata. </st><st c="49433">So, it is more acceptable to drop all old tables using the CQL shell before running </st><strong class="source-inline"><st c="49517">sync_table()</st></strong><st c="49529"> with the updated </st><span class="No-Break"><st c="49547">model classes.</st></span></p>
			<p><st c="49561">After building the model layer, the subsequent</st><a id="_idIndexMarker596"/><st c="49608"> procedure is to implement the repository transactions to access the data in Cassandra. </st><st c="49696">So, let’s access the keyspace and tables in our Cassandra platform so that we can perform </st><span class="No-Break"><st c="49786">CRUD operations.</st></span></p>
			<h2 id="_idParaDest-193"><a id="_idTextAnchor197"/><st c="49802">Implementing the repository layer</st></h2>
			<p><st c="49836">Entity models inherit</st><a id="_idIndexMarker597"/><st c="49858"> some attributes from the </st><strong class="source-inline"><st c="49884">Model</st></strong><st c="49889"> class, such as </st><strong class="source-inline"><st c="49905">__table_name__</st></strong><st c="49919">, which accepts and replaces the default table name of the mapping, and </st><strong class="source-inline"><st c="49991">__keyspace__</st></strong><st c="50003">, which replaces the default </st><em class="italic"><st c="50032">keyspace</st></em><st c="50040"> of the </st><span class="No-Break"><st c="50048">mapped table.</st></span></p>
			<p><st c="50061">Moreover, entity models also inherit some other </st><span class="No-Break"><st c="50110">instance methods:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="50127">save()</st></strong><st c="50134">: Persists the entity object in </st><span class="No-Break"><st c="50167">the database.</st></span></li>
				<li><strong class="source-inline"><st c="50180">update(**kwargs)</st></strong><st c="50197">: Updates the existing column fields based on the new column (</st><span class="No-Break"><strong class="source-inline"><st c="50260">kwargs</st></strong></span><span class="No-Break"><st c="50267">) details.</st></span></li>
				<li><strong class="source-inline"><st c="50278">delete()</st></strong><st c="50287">: Removes the record from </st><span class="No-Break"><st c="50314">the database.</st></span></li>
				<li><strong class="source-inline"><st c="50327">batch()</st></strong><st c="50335">: Runs synchronized updates or inserts </st><span class="No-Break"><st c="50375">on replicas.</st></span></li>
				<li><strong class="source-inline"><st c="50387">iff(**kwargs)</st></strong><st c="50401">: Checks if the indicated </st><strong class="source-inline"><st c="50428">kwargs</st></strong><st c="50434"> matches the column values of the object before the update or </st><span class="No-Break"><st c="50496">delete happens.</st></span></li>
				<li><strong class="source-inline"><st c="50511">if_exists()</st></strong><st c="50523">/</st><strong class="source-inline"><st c="50525">if_not_exists()</st></strong><st c="50540">: Verifies if the mapped record exists in </st><span class="No-Break"><st c="50583">the database.</st></span></li>
			</ul>
			<p><st c="50596">Also, the entity classes derive the </st><strong class="source-inline"><st c="50633">objects</st></strong><st c="50640"> class variable from their </st><strong class="source-inline"><st c="50667">Model</st></strong><st c="50672"> superclass, which can provide query methods such as </st><strong class="source-inline"><st c="50725">filter()</st></strong><st c="50733">, </st><strong class="source-inline"><st c="50735">allow_filtering()</st></strong><st c="50752">, and </st><strong class="source-inline"><st c="50758">get()</st></strong><st c="50763"> for record retrieval. </st><st c="50786">They also inherit the </st><strong class="source-inline"><st c="50808">create()</st></strong><st c="50816"> class method, which can insert records into the database, an option other </st><span class="No-Break"><st c="50891">than </st></span><span class="No-Break"><strong class="source-inline"><st c="50896">save()</st></strong></span><span class="No-Break"><st c="50902">.</st></span></p>
			<p><st c="50903">All these derived methods are the building blocks of our repository class. </st><st c="50979">The following repository class shows how the </st><strong class="source-inline"><st c="51024">Course</st></strong><st c="51030"> model implements its </st><span class="No-Break"><st c="51052">CRUD transactions:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="51070">from modules.models.db.cassandra_models import Course</st></strong><st c="51124">
from datetime import datetime
from typing import Dict, Any
class CourseRepository:
    def __init__(self):
        pass
    def insert_course(self, details:Dict[str, Any]):
        try:
            </st><strong class="bold"><st c="51287">Course.create(**details)</st></strong><st c="51311">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="51368">Gere, </st><strong class="source-inline"><st c="51375">insert_course()</st></strong><st c="51390"> uses the </st><strong class="source-inline"><st c="51400">create()</st></strong><st c="51408"> method</st><a id="_idIndexMarker598"/><st c="51415"> to persist a </st><strong class="source-inline"><st c="51429">course</st></strong><st c="51435"> record instead of applying </st><strong class="source-inline"><st c="51463">save()</st></strong><st c="51469">. For the update transaction, </st><strong class="source-inline"><st c="51499">update_course()</st></strong><st c="51514"> filters a </st><strong class="source-inline"><st c="51525">course</st></strong><st c="51531"> record by course code </st><span class="No-Break"><st c="51554">for updating:</st></span></p>
			<pre class="source-code"><st c="51567">
    def update_course(self, details:Dict[str, Any]):
        try:
            </st><strong class="bold"><st c="51622">rec = Course.objects.filter(</st></strong><strong class="bold"><st c="51650">code=str(details['code']))</st></strong><strong class="bold"><st c="51677">.allow_filtering().get()</st></strong><st c="51701">
            del details['id']
            del details['code']
            </st><strong class="bold"><st c="51740">rec.update(**details)</st></strong><st c="51761">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="51818">In Cassandra, when querying records with constraints, the </st><em class="italic"><st c="51877">partition key</st></em><st c="51890"> must always be included in the constraint. </st><st c="51934">However, </st><strong class="source-inline"><st c="51943">update_course()</st></strong><st c="51958"> uses the </st><strong class="source-inline"><st c="51968">allow_filtering()</st></strong><st c="51985"> method to allow data retrieval without the </st><em class="italic"><st c="52029">partition key</st></em><st c="52042"> and bypass the </st><em class="italic"><st c="52058">Invalid Query Error</st></em><st c="52077"> or </st><em class="italic"><st c="52081">error </st></em><span class="No-Break"><em class="italic"><st c="52087">code 2200</st></em></span><span class="No-Break"><st c="52096">.</st></span></p>
			<p><st c="52097">The following </st><strong class="source-inline"><st c="52112">delete_course_code()</st></strong><st c="52132"> transaction</st><a id="_idIndexMarker599"/><st c="52144"> uses the </st><strong class="source-inline"><st c="52154">delete()</st></strong><st c="52162"> entity class method to remove the filtered record object. </st><st c="52221">Again, the </st><strong class="source-inline"><st c="52232">allow_filtering()</st></strong><st c="52249"> method helps filter the record by code without messing up the </st><span class="No-Break"><em class="italic"><st c="52312">partition key</st></em></span><span class="No-Break"><st c="52325">:</st></span></p>
			<pre class="source-code"><st c="52327">
    def delete_course_code(self, code):
        try:
            </st><strong class="bold"><st c="52369">rec = Course.objects.filter(code=code)</st></strong><strong class="bold"><st c="52407">.allow_filtering().get()</st></strong><strong class="bold"><st c="52431">rec.delete()</st></strong><st c="52444">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="52501">Here, </st><strong class="source-inline"><st c="52508">search_by_code()</st></strong><st c="52524"> and </st><strong class="source-inline"><st c="52529">search_all_courses()</st></strong><st c="52549"> are the two query transactions of this </st><strong class="source-inline"><st c="52589">CourseRepository</st></strong><st c="52605">. The former retrieves a single record based on a </st><strong class="source-inline"><st c="52655">course</st></strong><st c="52661"> code, while the latter filters all </st><strong class="source-inline"><st c="52697">course</st></strong><st c="52703"> records without any condition. </st><st c="52735">The </st><strong class="source-inline"><st c="52739">get()</st></strong><st c="52744"> method of </st><strong class="source-inline"><st c="52755">objects</st></strong><st c="52762"> returns a non-JSONable </st><strong class="source-inline"><st c="52786">Course</st></strong><st c="52792"> object that </st><strong class="source-inline"><st c="52805">jsonify()</st></strong><st c="52814"> cannot process. </st><st c="52831">But wrapping the object with </st><strong class="source-inline"><st c="52860">dict()</st></strong><st c="52866"> after converts it into a JSON serializable record. </st><st c="52918">In </st><strong class="source-inline"><st c="52921">search_all_courses()</st></strong><st c="52941">, the custom </st><strong class="source-inline"><st c="52954">get_json()</st></strong><st c="52964"> method helps generate a list of JSONable course records for easy </st><span class="No-Break"><strong class="source-inline"><st c="53030">Response</st></strong></span><span class="No-Break"><st c="53038"> generation:</st></span></p>
			<pre class="source-code"><st c="53050">
    def search_by_code(self, code:str):
        </st><strong class="bold"><st c="53087">result = Course.objects.filter(code=code).allow_filtering().get()</st></strong><strong class="bold"><st c="53152">records = dict(result)</st></strong><st c="53175">
        return records
    def search_all_courses(self):
        </st><strong class="bold"><st c="53221">result = Course.objects.all()</st></strong><strong class="bold"><st c="53250">records = [course.get_json() for course in result]</st></strong><st c="53301">
        return records</st></pre>			<p><st c="53316">Cassandra is known for its faster write than read operations. </st><st c="53379">It writes data to the commit log and then caches it simultaneously, preserving data from unexpected occurrences, damage, or downtime. </st><st c="53513">But there is one form of NoSQL data storage that’s popular</st><a id="_idIndexMarker600"/><st c="53571"> for its faster reads operations: </st><strong class="bold"><st c="53605">Remote Dictionary </st></strong><span class="No-Break"><strong class="bold"><st c="53623">Server</st></strong></span><span class="No-Break"><st c="53629"> (</st></span><span class="No-Break"><strong class="bold"><st c="53631">Redis</st></strong></span><span class="No-Break"><st c="53636">).</st></span></p>
			<h1 id="_idParaDest-194"><a id="_idTextAnchor198"/><st c="53639">Storing search data in Redis</st></h1>
			<p><st c="53668">Redis is a fast, open</st><a id="_idIndexMarker601"/><st c="53690"> source, in-memory, </st><em class="italic"><st c="53710">key-value</st></em><st c="53719"> form of NoSQL storage</st><a id="_idIndexMarker602"/><st c="53741"> that’s popular in messaging and caching. </st><st c="53783">In </st><a href="B19383_05.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic"><st c="53786">Chapter 5</st></em></span></a><st c="53795">, we used it as the message broker of Celery, while in </st><a href="B19383_06.xhtml#_idTextAnchor143"><span class="No-Break"><em class="italic"><st c="53850">Chapter 6</st></em></span></a><st c="53859">, we used it as a message queue for the SSE and WebSocket programming. </st><st c="53930">However, this chapter will utilize Redis as a data cache to create a fast </st><span class="No-Break"><st c="54004">search mechanism.</st></span></p>
			<p><st c="54021">First, let’s install Redis on </st><span class="No-Break"><st c="54052">our system.</st></span></p>
			<h2 id="_idParaDest-195"><a id="_idTextAnchor199"/><st c="54063">Installing the Redis server</st></h2>
			<p><st c="54091">For Windows, download</st><a id="_idIndexMarker603"/><st c="54113"> the latest Redis</st><a id="_idIndexMarker604"/><st c="54130"> TAR file from </st><a href="https://redis.io/download/"><st c="54145">https://redis.io/download/</st></a><st c="54171">, unzip it to an installation folder, and run </st><strong class="source-inline"><st c="54217">redis-server.exe</st></strong><st c="54233"> from </st><span class="No-Break"><st c="54239">the directory.</st></span></p>
			<p><st c="54253">For WSL, run the following series of </st><span class="No-Break"><strong class="source-inline"><st c="54291">sudo</st></strong></span><span class="No-Break"><st c="54295"> commands:</st></span></p>
			<pre class="console"><st c="54305">
sudo apt-add-repository ppa:redislabs/redis
sudo apt-get update
sudo apt-get upgrade
sudo apt-get install redis-server</st></pre>			<p><st c="54424">Then, run </st><strong class="source-inline"><st c="54435">redis-cli -v</st></strong><st c="54447"> to check if the installation was successful. </st><st c="54493">If so, run the </st><strong class="source-inline"><st c="54508">redis-server</st></strong><st c="54520"> command to start the Redis server. </st><span class="No-Break"><em class="italic"><st c="54556">Figure 7</st></em></span><em class="italic"><st c="54564">.13</st></em><st c="54567"> shows the server log after the Redis server starts up on the </st><span class="No-Break"><st c="54629">WSL-Ubuntu platform:</st></span></p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B19383_07_013.jpg" alt="Figure 7.13 – Running the redis-server command"/><st c="54649"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="56140">Figure 7.13 – Running the redis-server command</st></p>
			<p><st c="56186">To stop the server, run the </st><strong class="source-inline"><st c="56215">redis-cli</st></strong><st c="56224"> shutdown command or press </st><em class="italic"><st c="56251">Ctrl</st></em><st c="56255"> + </st><em class="italic"><st c="56258">C</st></em><st c="56259"> on </st><span class="No-Break"><st c="56263">your keyboard.</st></span></p>
			<p><st c="56277">Now, let’s explore the Redis</st><a id="_idIndexMarker605"/><st c="56306"> server using its client shell and understand its CLI commands so that we can run its </st><span class="No-Break"><st c="56392">CRUD operations.</st></span></p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor200"/><st c="56408">Understanding the Redis database</st></h2>
			<p><st c="56441">Key-value storage uses a </st><em class="italic"><st c="56467">hashtable</st></em><st c="56476"> data</st><a id="_idIndexMarker606"/><st c="56481"> structure model wherein its unique key value serves as a pointer to a corresponding value of any type. </st><st c="56585">For Redis, the key is always a string that points to values of type strings, JSON, lists, sets, hashes, sorted set, streams, bitfields, geospatial, and time series. </st><st c="56750">Since Redis is an in-memory storage type, it stores all its simple to complex key-value pairs of data in the host’s RAM, which is volatile and cannot persist data permanently. </st><st c="56926">However, in return, Redis can provide faster reads and access to its data than HBase </st><span class="No-Break"><st c="57011">and Cassandra.</st></span></p>
			<p><st c="57025">To learn more about this storage, Redis has a built-in shell client that interacts with the database through some commands. </st><span class="No-Break"><em class="italic"><st c="57150">Figure 7</st></em></span><em class="italic"><st c="57158">.14</st></em><st c="57161"> shows opening a client shell by running the </st><strong class="source-inline"><st c="57206">redis-cli</st></strong><st c="57215"> command and checking the number of databases the storage has using the </st><strong class="source-inline"><st c="57287">CONFIG GET </st></strong><span class="No-Break"><strong class="source-inline"><st c="57298">databases</st></strong></span><span class="No-Break"><st c="57307"> command:</st></span></p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B19383_07_014.jpg" alt="Figure 7.14 – Opening a Redis shell"/><st c="57316"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="57476">Figure 7.14 – Opening a Redis shell</st></p>
			<p><st c="57511">The typical number of databases</st><a id="_idIndexMarker607"/><st c="57543"> in Redis storage is </st><em class="italic"><st c="57564">16</st></em><st c="57566">. Redis databases are named from </st><em class="italic"><st c="57599">0 </st></em><st c="57601">to </st><em class="italic"><st c="57604">15</st></em><st c="57606">, like indexes of an array. </st><st c="57634">The default database name is </st><em class="italic"><st c="57663">0</st></em><st c="57664">, but it has a </st><strong class="source-inline"><st c="57679">select</st></strong><st c="57685"> command that chooses the preferred database other than 0 (for example, </st><span class="No-Break"><strong class="source-inline"><st c="57757">select 1</st></strong></span><span class="No-Break"><st c="57765">).</st></span></p>
			<p><st c="57768">Since Redis is a simple NoSQL database, it only has the following</st><a id="_idIndexMarker608"/><st c="57834"> few commands, including CRUD, we need </st><span class="No-Break"><st c="57873">to consider:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="57885">set</st></strong><st c="57889">: Adds a key-value pair to </st><span class="No-Break"><st c="57917">the database.</st></span></li>
				<li><strong class="source-inline"><st c="57930">get</st></strong><st c="57934">: Retrieves the value of </st><span class="No-Break"><st c="57960">a key.</st></span></li>
				<li><strong class="source-inline"><st c="57966">hset</st></strong><st c="57971">: Adds a hash with multiple </st><span class="No-Break"><st c="58000">key-value pairs.</st></span></li>
				<li><strong class="source-inline"><st c="58016">hget</st></strong><st c="58021">: Retrieves the value of a key in </st><span class="No-Break"><st c="58056">a hash.</st></span></li>
				<li><strong class="source-inline"><st c="58063">hgetall</st></strong><st c="58071">: Retrieves all the key-value pairs in </st><span class="No-Break"><st c="58111">a hash.</st></span></li>
				<li><strong class="source-inline"><st c="58118">hkeys</st></strong><st c="58124">: Retrieves all the keys in </st><span class="No-Break"><st c="58153">a hash.</st></span></li>
				<li><strong class="source-inline"><st c="58160">hvals</st></strong><st c="58166">: Retrieves all the values in </st><span class="No-Break"><st c="58197">a hash.</st></span></li>
				<li><strong class="source-inline"><st c="58204">del</st></strong><st c="58208">: Removes an existing key-value pair using the key or the </st><span class="No-Break"><st c="58267">whole hash.</st></span></li>
				<li><strong class="source-inline"><st c="58278">hdel</st></strong><st c="58283">: Removes single or multiple key-value pairs in </st><span class="No-Break"><st c="58332">a hash.</st></span></li>
			</ul>
			<p><st c="58339">Redis hashes are records or structured</st><a id="_idIndexMarker609"/><st c="58378"> types that can hold collections of field-value pairs with values of varying types. </st><st c="58462">In a way, it can represent a Python object persisted in the database. </st><span class="No-Break"><em class="italic"><st c="58532">Figure 7</st></em></span><em class="italic"><st c="58540">.15</st></em><st c="58543"> shows a list of Redis commands being run on the </st><span class="No-Break"><st c="58592">Redis shell:</st></span></p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B19383_07_015.jpg" alt="Figure 7.15 – Running Redis commands on the Redis shell"/><st c="58604"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="59167">Figure 7.15 – Running Redis commands on the Redis shell</st></p>
			<p><st c="59222">But how can our </st><em class="italic"><st c="59239">Tutor Finder</st></em><st c="59251"> application </st><a id="_idIndexMarker610"/><st c="59264">connect to a Redis database as a client? </st><st c="59305">We’ll answer this question in the </st><span class="No-Break"><st c="59339">next section.</st></span></p>
			<h2 id="_idParaDest-197"><a id="_idTextAnchor201"/><st c="59352">Establishing a database connection</st></h2>
			<p><st c="59387">In </st><a href="B19383_05.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic"><st c="59391">Chapter 5</st></em></span></a><st c="59400"> and </st><a href="B19383_06.xhtml#_idTextAnchor143"><span class="No-Break"><em class="italic"><st c="59405">Chapter 6</st></em></span></a><st c="59414">, the </st><em class="italic"><st c="59420">redis-py</st></em><st c="59428"> module established</st><a id="_idIndexMarker611"/><st c="59447"> a connection to Redis as a broker or message queue. </st><st c="59500">This time, our application will connect to the Redis database for data storage </st><span class="No-Break"><st c="59579">and caching.</st></span></p>
			<p><st c="59591">So far, the Redis OM module is the most efficient and convenient Redis database connector that can provide database connectivity and methods for CRUD operations, similar to an ORM. </st><st c="59773">However, before accessing its utilities, install it using the </st><span class="No-Break"><strong class="source-inline"><st c="59835">pip</st></strong></span><span class="No-Break"><st c="59838"> command:</st></span></p>
			<pre class="console"><st c="59847">
pip install redis-om</st></pre>			<p><strong class="source-inline"><st c="59868">redis-py</st></strong><st c="59877"> is the other library that’s included in the installation of the </st><strong class="source-inline"><st c="59942">redis-om</st></strong><st c="59950"> module. </st><st c="59959">The </st><strong class="source-inline"><st c="59963">redis</st></strong><st c="59968"> module has a Redis callable object that builds the database connectivity. </st><st c="60043">The callable has a </st><strong class="source-inline"><st c="60062">from_url()</st></strong><st c="60072"> method that accepts the database URL and some parameter values for the </st><strong class="source-inline"><st c="60144">encoding</st></strong><st c="60152"> and </st><strong class="source-inline"><st c="60157">decode_responses</st></strong><st c="60173"> parameters. </st><st c="60186">The following code shows </st><strong class="source-inline"><st c="60211">create_app()</st></strong><st c="60223">, which creates the Redis connection to </st><span class="No-Break"><st c="60263">database </st></span><span class="No-Break"><strong class="source-inline"><st c="60272">0</st></strong></span><span class="No-Break"><st c="60273">:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="60274">import redis</st></strong><st c="60286">
def create_app(config_file):
    app = Flask(__name__)
    app.config.from_file(config_file, toml.load)
    </st><strong class="bold"><st c="60383">redis.Redis.from_url("redis://localhost:6379/0",</st></strong> <strong class="bold"><st c="60431">encoding="utf8", decode_responses=True)</st></strong></pre>			<p><st c="60471">Here, </st><strong class="source-inline"><st c="60478">redis</st></strong><st c="60483"> in the URI indicates that the connection is a Redis standalone one to database </st><strong class="source-inline"><st c="60563">0</st></strong><st c="60564"> in localhost at port </st><strong class="source-inline"><st c="60586">6379</st></strong><st c="60590">. All responses of the </st><strong class="source-inline"><st c="60613">redis-om</st></strong><st c="60621"> transactions are decoded into strings because the </st><strong class="source-inline"><st c="60672">decode_responses</st></strong><st c="60688"> parameter is assigned a value of </st><strong class="source-inline"><st c="60722">True</st></strong><st c="60726">. All these string results are in </st><span class="No-Break"><strong class="source-inline"><st c="60760">UTF-8</st></strong></span><span class="No-Break"><st c="60765"> encoding.</st></span></p>
			<p><st c="60775">At this point, the </st><strong class="source-inline"><st c="60795">redis-om</st></strong><st c="60803"> module is ready</st><a id="_idIndexMarker612"/><st c="60819"> to build the application’s </st><span class="No-Break"><st c="60847">model layer.</st></span></p>
			<h2 id="_idParaDest-198"><a id="_idTextAnchor202"/><st c="60859">Implementing the model layer</st></h2>
			<p><strong class="bold"><st c="60888">Redis OM</st></strong><st c="60897"> is a high-level</st><a id="_idIndexMarker613"/><st c="60913"> and object-oriented library that uses entity classes to manage the Redis data compared to the native approach of the </st><strong class="source-inline"><st c="61031">redis-py</st></strong><st c="61039"> module. </st><st c="61048">Each model class contains the hash fields with types validated by Pydantic validators. </st><st c="61135">Once instantiated, the model object will hold the values of the keys before inserting them into</st><a id="_idIndexMarker614"/><st c="61230"> the database with the auto-generated </st><strong class="bold"><st c="61268">hash value</st></strong> <span class="No-Break"><st c="61278">or </st></span><span class="No-Break"><strong class="bold"><st c="61282">pk</st></strong></span><span class="No-Break"><st c="61284">.</st></span></p>
			<p><st c="61285">The </st><strong class="source-inline"><st c="61290">redis-om</st></strong><st c="61298"> module has the </st><strong class="source-inline"><st c="61314">HashModel</st></strong><st c="61323"> class, which will implement the entity classes of the application. </st><st c="61391">The </st><strong class="source-inline"><st c="61395">HashModel</st></strong><st c="61404"> class is a representation of a Redis hash. </st><st c="61448">It captures the key-value pairs and uses its instance methods to manage the data. </st><st c="61530">It automatically generates the primary key or hash key for each model object. </st><st c="61608">The following are the </st><strong class="source-inline"><st c="61630">HashModel</st></strong><st c="61639"> classes for the </st><em class="italic"><st c="61656">course</st></em><st c="61662">, </st><em class="italic"><st c="61664">student</st></em><st c="61671">, and </st><span class="No-Break"><em class="italic"><st c="61677">tutor</st></em></span><span class="No-Break"><st c="61682"> data:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="61688">from redis_om import  HashModel, Field,</st></strong> <strong class="bold"><st c="61727">get_redis_connection</st></strong>
<strong class="bold"><st c="61748">redis_conn = get_redis_connection(decode_responses=True)</st></strong><st c="61805">
class SearchCourse(</st><strong class="bold"><st c="61825">HashModel</st></strong><st c="61835">):
    code: str  = Field(index=True)
    title: str
    description: str
    req_hrs: float
    total_cost: float
    level: int
class SearchStudent(</st><strong class="bold"><st c="61961">HashModel</st></strong><st c="61971">):
    std_id: str
    firstname: str
    midname: str
    lastname: str
    … … … … … …
class SearchTutor(</st><strong class="bold"><st c="62059">HashModel</st></strong><st c="62069">):
    firstname: str
    lastname: str
    midname: str
    … … … … … …
    </st><strong class="bold"><st c="62127">class Meta:</st></strong><strong class="bold"><st c="62138">database = redis_conn</st></strong></pre>			<p><st c="62160">Here, </st><strong class="source-inline"><st c="62167">CourseSearch</st></strong><st c="62179">, </st><strong class="source-inline"><st c="62181">SearchStudent</st></strong><st c="62194">, and </st><strong class="source-inline"><st c="62200">SearchTutor</st></strong><st c="62211"> are model classes that have been created to cache incoming request data to the Redis database for fast search transactions. </st><st c="62336">Each class has declared attributes that correspond to the keys of a record. </st><st c="62412">After its instantiation, the model object will have a </st><strong class="source-inline"><st c="62466">pk</st></strong><st c="62468"> instance variable that contains the unique hash key of the </st><span class="No-Break"><st c="62528">data record.</st></span></p>
			<p><st c="62540">Aside from relying on the Redis</st><a id="_idIndexMarker615"/><st c="62572"> connection created by </st><strong class="source-inline"><st c="62595">Redis.from_url()</st></strong><st c="62611">, a </st><strong class="source-inline"><st c="62615">HashModel</st></strong><st c="62624"> object can independently or directly connect to the Redis database by assigning a connection instance to its </st><strong class="source-inline"><st c="62734">Meta</st></strong><st c="62738"> object’s </st><strong class="source-inline"><st c="62748">database</st></strong><st c="62756"> variable. </st><st c="62767">In either of these connectivity approaches, the model object can still emit the methods that will operate the </st><span class="No-Break"><st c="62877">repository layer.</st></span></p>
			<p><st c="62894">After establishing the Redis connection and creating the model classes, the next step is to build the </st><span class="No-Break"><st c="62997">repository layer.</st></span></p>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor203"/><st c="63014">Building the repository layer</st></h2>
			<p><st c="63044">Like in Cassandra’s repository</st><a id="_idIndexMarker616"/><st c="63075"> layer, the model object of the </st><strong class="source-inline"><st c="63107">redis-om</st></strong><st c="63115"> module implements the repository class. </st><st c="63156">The </st><strong class="source-inline"><st c="63160">HashModel</st></strong><st c="63169"> entity emits methods that will implement the CRUD transactions. </st><st c="63234">The following </st><strong class="source-inline"><st c="63248">SearchCourseRepository</st></strong><st c="63270"> class manages course details in the </st><span class="No-Break"><st c="63307">Redis database:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="63322">from modules.models.db.redis_models import SearchCourse</st></strong><st c="63378">
from typing import Dict, Any
class SearchCourseRepository:
    def __init__(self):
        pass
    def insert_course(self, details:Dict[str, Any]):
        try:
            </st><strong class="bold"><st c="63517">course = SearchCourse(**details)</st></strong><strong class="bold"><st c="63549">course.save()</st></strong><st c="63563">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="63620">The given </st><strong class="source-inline"><st c="63631">insert_course()</st></strong><st c="63646"> method uses the </st><strong class="source-inline"><st c="63663">HashModel</st></strong><st c="63672"> entity’s </st><strong class="source-inline"><st c="63682">save()</st></strong><st c="63688"> instance method, which adds</st><a id="_idIndexMarker617"/><st c="63716"> the course details as key-value pairs in database </st><strong class="source-inline"><st c="63767">0</st></strong><st c="63768"> of Redis. </st><st c="63779">To update a record, retrieve the data object using its </st><strong class="source-inline"><st c="63834">pk</st></strong><st c="63836"> from the database and then invoke the </st><strong class="source-inline"><st c="63875">update()</st></strong><st c="63883"> method of the resulting model object with the new field values. </st><st c="63948">The following </st><strong class="source-inline"><st c="63962">update_course()</st></strong><st c="63977"> method applies this </st><span class="No-Break"><strong class="source-inline"><st c="63998">redis-om</st></strong></span><span class="No-Break"><st c="64006"> approach:</st></span></p>
			<pre class="source-code"><st c="64016">
    def update_course(self, details:Dict[str, Any]):
        try:
            </st><strong class="bold"><st c="64071">record = SearchCourse.get(details['pk'])</st></strong><strong class="bold"><st c="64111">record.update(**details)</st></strong><st c="64136">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="64193">When deleting a record, </st><strong class="source-inline"><st c="64218">HashModel</st></strong><st c="64227"> has a class method called </st><strong class="source-inline"><st c="64254">delete()</st></strong><st c="64262"> that removes a hashed object using its </st><strong class="source-inline"><st c="64302">pk</st></strong><st c="64304">, similar to the following </st><span class="No-Break"><strong class="source-inline"><st c="64331">delete_course()</st></strong></span><span class="No-Break"><st c="64346"> method:</st></span></p>
			<pre class="source-code"><st c="64354">
    def delete_course(self, pk):
        try:
            </st><strong class="bold"><st c="64389">SearchCourse.delete(pk)</st></strong><st c="64412">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="64469">When retrieving data</st><a id="_idIndexMarker618"/><st c="64490"> from the database, the </st><strong class="source-inline"><st c="64514">get()</st></strong><st c="64519"> method is the only way to retrieve a single model object using an existing </st><strong class="source-inline"><st c="64595">pk</st></strong><st c="64597">. Querying all the records requires a </st><strong class="source-inline"><st c="64635">for</st></strong><st c="64638"> loop to enumerate all </st><strong class="source-inline"><st c="64661">pk</st></strong><st c="64663"> values from the </st><strong class="source-inline"><st c="64680">HashModel</st></strong><st c="64689"> entity’s </st><strong class="source-inline"><st c="64699">all_pks()</st></strong><st c="64708"> generator, which retrieves all </st><strong class="source-inline"><st c="64740">pk</st></strong><st c="64742"> from the database. </st><st c="64762">The loop will fetch all the model objects using the enumerated </st><strong class="source-inline"><st c="64825">pk</st></strong><st c="64827">. The following </st><strong class="source-inline"><st c="64843">select_course()</st></strong><st c="64858"> class retrieves all course details from the </st><strong class="source-inline"><st c="64903">search_course</st></strong><st c="64916"> table using the </st><strong class="source-inline"><st c="64933">pk</st></strong><st c="64935"> value of </st><span class="No-Break"><st c="64945">each record:</st></span></p>
			<pre class="source-code"><st c="64957">
    def select_course(self, pk):
        try:
            </st><strong class="bold"><st c="64992">record = SearchCourse.get(pk)</st></strong><strong class="bold"><st c="65021">return record.dict()</st></strong><st c="65042">
        except Exception as e:
            print(e)
        return None
    def select_all_course(self):
        records = list()
        </st><strong class="bold"><st c="65133">for id in SearchCourse.all_pks():</st></strong><strong class="bold"><st c="65166">records.append(SearchCourse.get(id).dict())</st></strong><st c="65210">
        return records</st></pre>			<p><st c="65225">All resulting objects from the query transactions are JSONable and don’t need a JSON serializer. </st><st c="65323">Running the given </st><strong class="source-inline"><st c="65341">select_all_course()</st></strong><st c="65360"> class will return the following sample </st><span class="No-Break"><st c="65400">Redis records:</st></span></p>
			<pre class="source-code"><st c="65414">
{
    "records": [
        {
            "code": "PY-201",
            "description": "Advanced Python",
            "level": 3,
            </st><strong class="bold"><st c="65496">"pk": "01HDH2VPZBGJJ16JKE3KE7RGPQ",</st></strong><st c="65531">
            "req_hrs": 50.0,
            "title": "Advanced Python Programming",
            "total_cost": 15000.0
        },
        {
            "code": "PY-101",
            "description": "Intro to Python programming",
            "level": 1,
            </st><strong class="bold"><st c="65692">"pk": "01HDH2SVYR7AYMRD28RE6HSHYB",</st></strong><st c="65727">
            "req_hrs": 45.0,
            "title": "Python Basics",
            "total_cost": 5000.0
        },</st></pre>			<p><st c="65794">Although Redis OM</st><a id="_idIndexMarker619"/><st c="65812"> is perfectly compatible with FastAPI, it can also make any Flask application a client for Redis. </st><st c="65910">Now, Redis OM cannot implement filtered queries. </st><st c="65959">If Redis OM needs a filtered search with some constraints, it needs a </st><em class="italic"><st c="66029">RediSearch</st></em><st c="66039"> extension module that calibrates and provides more search constraints to query transactions. </st><st c="66133">But </st><em class="italic"><st c="66137">RediSearch</st></em><st c="66147"> can only run with Redis OM if the application uses Redis Stack instead of the </st><span class="No-Break"><st c="66226">typical server.</st></span></p>
			<p><st c="66241">The next section will highlight a </st><em class="italic"><st c="66276">document-oriented</st></em><st c="66293"> NoSQL database that’s popular for enterprise application </st><span class="No-Break"><st c="66351">development: </st></span><span class="No-Break"><em class="italic"><st c="66364">MongoDB</st></em></span><span class="No-Break"><st c="66371">.</st></span></p>
			<h1 id="_idParaDest-200"><a id="_idTextAnchor204"/><st c="66372">Handling BSON-based documents with MongoDB</st></h1>
			<p><strong class="bold"><st c="66415">MongoDB</st></strong><st c="66423"> is a NoSQL database that stores JSON-like</st><a id="_idIndexMarker620"/><st c="66465"> documents of key-value pairs </st><a id="_idIndexMarker621"/><st c="66495">with a flexible and scalable schema, thus classified as a document-oriented database. </st><st c="66581">It can store huge volumes of data with varying data structures, types, </st><span class="No-Break"><st c="66652">and formations.</st></span></p>
			<p><st c="66667">These JSON-like documents use </st><strong class="bold"><st c="66698">Binary Javascript Object Notation</st></strong><st c="66731"> (</st><strong class="bold"><st c="66733">BSON</st></strong><st c="66737">), a binary-encoded representation</st><a id="_idIndexMarker622"/><st c="66772"> of JSON documents suitable for network-based data transport because of its compact nature. </st><st c="66864">It has non-JSON-native data type support for date and binary data and recognizes embedded documents or an array of documents because of its </st><span class="No-Break"><st c="67004">traversable structure.</st></span></p>
			<p><st c="67026">Next, we’ll install MongoDB and compare its process to HBase, Cassandra, </st><span class="No-Break"><st c="67100">and Redis.</st></span></p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor205"/><st c="67110">Installing and configuring the MongoDB server</st></h2>
			<p><st c="67156">First, download the</st><a id="_idIndexMarker623"/><st c="67176"> preferred MongoDB</st><a id="_idIndexMarker624"/><st c="67194"> community server from </st><a href="https://www.mongodb.com/try/download/community"><st c="67217">https://www.mongodb.com/try/download/community</st></a><st c="67263">. Install it to</st><a id="_idIndexMarker625"/><st c="67278"> your preferred drive and directory. </st><st c="67315">Next, create a data directory where MongoDB can store its documents. </st><st c="67384">If the data folder doesn’t exist, MongoDB will resort to </st><strong class="source-inline"><st c="67441">C:\data\db</st></strong><st c="67451"> as its default data folder. </st><st c="67480">Afterward, run the server by running the </st><span class="No-Break"><st c="67521">following command:</st></span></p>
			<pre class="console"><st c="67539">
mongod.exe --dbpath="c:\data\db"</st></pre>			<p><st c="67572">The default host of the server is localhost, and its port </st><span class="No-Break"><st c="67631">is </st></span><span class="No-Break"><strong class="source-inline"><st c="67634">27017</st></strong></span><span class="No-Break"><st c="67639">.</st></span></p>
			<p><st c="67640">Download MongoDB Shell</st><a id="_idIndexMarker626"/><st c="67663"> from </st><a href="https://www.mongodb.com/try/download/shell"><st c="67669">https://www.mongodb.com/try/download/shell</st></a><st c="67711"> to open the client console for the server. </st><st c="67755">Also, download</st><a id="_idIndexMarker627"/><st c="67769"> MongoDB Compass from </st><a href="https://www.mongodb.com/try/download/compass"><st c="67791">https://www.mongodb.com/try/download/compass</st></a><st c="67835">, the GUI administration tool for the </st><span class="No-Break"><st c="67873">database server.</st></span></p>
			<p><st c="67889">So far, installing the MongoDB server and its tools takes less time than installing the other NoSQL databases. </st><st c="68001">Next, we’ll integrate MongoDB into our </st><em class="italic"><st c="68040">Tutor </st></em><span class="No-Break"><em class="italic"><st c="68046">Finder</st></em></span><span class="No-Break"><st c="68052"> application.</st></span></p>
			<h2 id="_idParaDest-202"><a id="_idTextAnchor206"/><st c="68065">Establishing a database connection</st></h2>
			<p><st c="68100">To create database</st><a id="_idIndexMarker628"/><st c="68119"> connectivity, MongoDB uses the </st><strong class="source-inline"><st c="68151">pymongo</st></strong><st c="68158"> module as its native driver, which is made from BSON utilities. </st><st c="68223">However, the driver requires more codes to implement the CRUD transactions because it offers low-level utilities. </st><st c="68337">A high-level and object-oriented module, such as </st><strong class="source-inline"><st c="68386">mongoengine</st></strong><st c="68397">, can provide a better database connection than </st><strong class="source-inline"><st c="68445">pymongo</st></strong><st c="68452">. The </st><strong class="source-inline"><st c="68458">mongoengine</st></strong><st c="68469"> library is a popular </st><strong class="bold"><st c="68491">object document mapper</st></strong><st c="68513"> (</st><strong class="bold"><st c="68515">ODM</st></strong><st c="68518">) that can build a client application</st><a id="_idIndexMarker629"/><st c="68556"> with a model and </st><span class="No-Break"><st c="68574">repository layers.</st></span></p>
			<p><st c="68592">The </st><strong class="source-inline"><st c="68597">flask-mongoengine</st></strong><st c="68614"> library is written solely for Flask. </st><st c="68652">However, since Flask 3.x, the </st><strong class="source-inline"><st c="68682">flask.json</st></strong><st c="68692"> module, on which the module is tightly dependent, was removed. </st><st c="68756">This change affected the </st><strong class="source-inline"><st c="68781">MongoEngine</st></strong><st c="68792"> class of the </st><strong class="source-inline"><st c="68806">flask_mongoengine</st></strong><st c="68823"> library, which creates a MongoDB client. </st><st c="68865">Until the library is updated so that it supports the latest version of Flask, the native </st><strong class="source-inline"><st c="68954">connect()</st></strong><st c="68963"> method from the native </st><strong class="source-inline"><st c="68987">mongoengine.connection</st></strong><st c="69009"> module will always be the solution to connect to the MongoDB database. </st><st c="69081">The following snippet from the </st><em class="italic"><st c="69112">Tutor Finder</st></em><st c="69124"> application’s </st><strong class="source-inline"><st c="69139">create_app()</st></strong><st c="69151"> factory method uses </st><strong class="source-inline"><st c="69172">connect()</st></strong><st c="69181"> to establish communication with the </st><span class="No-Break"><st c="69218">MongoDB server:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="69233">from mongoengine.connection import connect</st></strong><st c="69276">
def create_app(config_file):
    app = Flask(__name__)
    app.config.from_file(config_file, toml.load
    </st><strong class="bold"><st c="69372">connect(host='localhost', port=27017, db='tfs',</st></strong> <strong class="bold"><st c="69419">uuidRepresentation='standard')</st></strong></pre>			<p><st c="69450">The </st><strong class="source-inline"><st c="69455">connect()</st></strong><st c="69464"> method requires </st><strong class="source-inline"><st c="69481">db name</st></strong><st c="69488">, </st><strong class="source-inline"><st c="69490">host</st></strong><st c="69494">, </st><strong class="source-inline"><st c="69496">port</st></strong><st c="69500">, and the type of </st><strong class="source-inline"><st c="69518">UUID</st></strong><st c="69522"> the server will use to recognize the UUID primary key. </st><st c="69578">This can be </st><strong class="source-inline"><st c="69590">unspecified</st></strong><st c="69601">, </st><strong class="source-inline"><st c="69603">standard</st></strong><st c="69611">, </st><strong class="source-inline"><st c="69613">pythonLegacy</st></strong><st c="69625">, </st><strong class="source-inline"><st c="69627">javaLegacy</st></strong><st c="69637">, </st><span class="No-Break"><st c="69639">or </st></span><span class="No-Break"><strong class="source-inline"><st c="69642">csharpLegacy</st></strong></span><span class="No-Break"><st c="69654">.</st></span></p>
			<p><st c="69655">On the other hand, the client</st><a id="_idIndexMarker630"/><st c="69685"> can invoke the </st><strong class="source-inline"><st c="69701">disconnect()</st></strong><st c="69713"> method to close </st><span class="No-Break"><st c="69730">the connection.</st></span></p>
			<p><st c="69745">Now, let’s build the model layer using the helper classes from the </st><span class="No-Break"><strong class="source-inline"><st c="69813">flask-mongoengine</st></strong></span><span class="No-Break"><st c="69830"> module.</st></span></p>
			<h2 id="_idParaDest-203"><a id="_idTextAnchor207"/><st c="69838">Building the model layer</st></h2>
			<p><st c="69863">The </st><strong class="source-inline"><st c="69868">flask-mongoengine</st></strong><st c="69885"> module has a </st><strong class="bold"><st c="69899">Document</st></strong><st c="69907"> base class that defines the structure of the MongoDB</st><a id="_idIndexMarker631"/><st c="69960"> key-value pairs and their fields and properties. </st><st c="70010">These model classes are translated afterward into BSON documents after the </st><em class="italic"><st c="70085">INSERT</st></em><st c="70091"> transactions. </st><st c="70106">Here are the model classes that subclass the </st><strong class="source-inline"><st c="70151">Document</st></strong><st c="70159"> base class to build the login details of </st><span class="No-Break"><st c="70201">our application:</st></span></p>
			<pre class="source-code"><st c="70217">
from mongoengine import </st><strong class="bold"><st c="70242">Document</st></strong><st c="70250">, </st><strong class="bold"><st c="70252">SequenceField</st></strong><st c="70265">, </st><strong class="bold"><st c="70267">BooleanField</st></strong><st c="70279">, </st><strong class="bold"><st c="70281">EmbeddedDocumentField</st></strong><st c="70302">, </st><strong class="bold"><st c="70304">BinaryField</st></strong><st c="70315">, </st><strong class="bold"><st c="70317">IntField</st></strong><st c="70325">, </st><strong class="bold"><st c="70327">StringField</st></strong><st c="70338">, </st><strong class="bold"><st c="70340">DateField</st></strong><st c="70349">, </st><strong class="bold"><st c="70351">EmailField</st></strong><st c="70361">, </st><strong class="bold"><st c="70363">EmbeddedDocumentListField</st></strong><st c="70388">, </st><strong class="bold"><st c="70390">EmbeddedDocument</st></strong><st c="70406">
class Savings(</st><strong class="bold"><st c="70421">EmbeddedDocument</st></strong><st c="70438">):
    acct_name = StringField(db_field='acct_name', max_length=100, required=True)
    acct_number = StringField(db_field='acct_number', max_length=16, required=True)
        … … … … … …
class Checking(EmbeddedDocument):
    acct_name = StringField(db_field='acct_name', max_length=100, required=True)
    acct_number = StringField(db_field='acct_number', max_length=16, required=True)
    bank =  StringField(db_field='bank', max_length=100, required=True)
    … … … … … …
class PayPal(EmbeddedDocument):
    email = EmailField(db_field='email', max_length=20, required=True)
    address = StringField(db_field='address', max_length=200, required=True)
class Tutor(EmbeddedDocument):
    firstname = StringField(db_field='firstname', max_length=50, required=True)
    lastname = StringField(db_field='lastname', max_length=50, required=True)
    … … …. </st><st c="71241">… …
    </st><strong class="bold"><st c="71245">savings = EmbeddedDocumentListField(Savings, required=False)</st></strong><strong class="bold"><st c="71305">checkings = EmbeddedDocumentListField(Checking, required=False)</st></strong><strong class="bold"><st c="71369">gcash = EmbeddedDocumentField(GCash, required=False)</st></strong><strong class="bold"><st c="71422">paypal = EmbeddedDocumentField(PayPal, required=False)</st></strong><st c="71477">
class TutorLogin(Document):
    id = SequenceField(required=True, primary_key=True)
    username = StringField(db_field='email',max_length=25, required=True)
    password = StringField(db_field='password',maxent=25, required=True)
    encpass = BinaryField(db_field='encpass', required=True)
    </st><strong class="bold"><st c="71754">tutor = EmbeddedDocumentField(Tutor, required=False)</st></strong></pre>			<p><st c="71806">Like in SQLAlchemy, </st><strong class="source-inline"><st c="71827">flask-mongengine</st></strong><st c="71843"> offers helper classes, such as </st><strong class="source-inline"><st c="71875">StringField</st></strong><st c="71886">, </st><strong class="source-inline"><st c="71888">BinaryField</st></strong><st c="71899">, </st><strong class="source-inline"><st c="71901">DateField</st></strong><st c="71910">, </st><strong class="source-inline"><st c="71912">IntField</st></strong><st c="71920">, and </st><strong class="source-inline"><st c="71926">EmailField</st></strong><st c="71936">, that build the metadata of a document. </st><st c="71977">These helper classes have parameters, such as </st><strong class="source-inline"><st c="72023">db_field</st></strong><st c="72031"> and </st><strong class="source-inline"><st c="72036">required</st></strong><st c="72044">, that will add details to the key-value pairs. </st><st c="72092">Moreover, some parameters appear only in one helper class, such as </st><strong class="source-inline"><st c="72159">min_length</st></strong><st c="72169"> and </st><strong class="source-inline"><st c="72174">max_length</st></strong><st c="72184"> in </st><strong class="source-inline"><st c="72188">StringField</st></strong><st c="72199">, because they control the number of characters in the string. </st><st c="72262">Likewise, </st><strong class="source-inline"><st c="72272">ByteField</st></strong><st c="72281"> has a </st><strong class="source-inline"><st c="72288">max_bytes</st></strong><st c="72297"> parameter that will not appear in other helper classes. </st><st c="72354">Note that, the </st><strong class="source-inline"><st c="72369">Document</st></strong><st c="72377"> base class’ </st><strong class="source-inline"><st c="72390">BinaryField</st></strong><st c="72401"> translates to BSON’s binary data and </st><strong class="source-inline"><st c="72439">DateField</st></strong><st c="72448"> to BSON’s date type, not the common </st><span class="No-Break"><st c="72485">Python type.</st></span></p>
			<p><st c="72497">Unlike Cassandra, Redis, and HBase, MongoDB</st><a id="_idIndexMarker632"/><st c="72541"> allows relationships among structures. </st><st c="72581">Although not normalized like in an RDBMS, MongoDB can link one document to its subdocuments using the </st><strong class="source-inline"><st c="72683">EmbeddedDocumentField</st></strong><st c="72704"> and </st><strong class="source-inline"><st c="72709">EmbeddedDocumentListField</st></strong><st c="72734"> helper classes. </st><st c="72751">In the given model classes, the </st><strong class="source-inline"><st c="72783">TutorLogin</st></strong><st c="72793"> model will create a parent document collection called </st><strong class="source-inline"><st c="72848">tutor_login</st></strong><st c="72859"> that will reference a </st><strong class="source-inline"><st c="72882">tutor</st></strong><st c="72887"> sub-document because the sub-document’s </st><strong class="source-inline"><st c="72928">Tutor</st></strong><st c="72933"> model is an </st><strong class="source-inline"><st c="72946">EmbeddedDocumentField</st></strong><st c="72967"> helper class of the parent </st><strong class="source-inline"><st c="72995">TutorLogin</st></strong><st c="73005"> model. </st><st c="73013">The idea is similar to a one-to-one relationship concept in a relational ERD but not totally the same. </st><st c="73116">On the other hand, the relationship between </st><strong class="source-inline"><st c="73160">Tutor</st></strong><st c="73165"> and </st><strong class="source-inline"><st c="73170">Savings</st></strong><st c="73177"> is like a one-to-many relationship because </st><strong class="source-inline"><st c="73221">Savings</st></strong><st c="73228"> is the </st><strong class="source-inline"><st c="73236">EmbeddedDocumentListField</st></strong><st c="73261"> helper class of the </st><strong class="source-inline"><st c="73282">Tutor</st></strong><st c="73287"> model. </st><st c="73295">In other words, the </st><strong class="source-inline"><st c="73315">tutor</st></strong><st c="73320"> document collections will reference a list of savings sub-documents. </st><st c="73390">Here </st><strong class="source-inline"><st c="73395">EmbeddedDocumentField</st></strong><st c="73416"> does not have an </st><strong class="source-inline"><st c="73434">_id</st></strong><st c="73437"> field because it cannot construct an actual document</st><a id="_idIndexMarker633"/><st c="73490"> collection, unlike in an independent </st><strong class="source-inline"><st c="73528">Document</st></strong> <span class="No-Break"><st c="73536">base class.</st></span></p>
			<p><st c="73548">Next, we’ll create the repository layer from the </st><strong class="source-inline"><st c="73598">Tutor</st></strong><st c="73603"> document and </st><span class="No-Break"><st c="73617">its sub-documents.</st></span></p>
			<h2 id="_idParaDest-204"><a id="_idTextAnchor208"/><st c="73635">Implementing the repository</st></h2>
			<p><st c="73663">The </st><strong class="source-inline"><st c="73668">Document</st></strong><st c="73676"> object emits utility methods</st><a id="_idIndexMarker634"/><st c="73705"> that perform CRUD operations for the repository layer. </st><st c="73761">Here is a </st><strong class="source-inline"><st c="73771">TutorLoginRepository</st></strong><st c="73791"> class that inserts, updates, deletes, and retrieves </st><span class="No-Break"><strong class="source-inline"><st c="73844">tutor_login</st></strong></span><span class="No-Break"><st c="73855"> documents:</st></span></p>
			<pre class="source-code"><st c="73866">
from typing import Dict, Any
from modules.models.db.mongo_models import TutorLogin
import json
class TutorLoginRepository:
    def insert_login(self, details:Dict[str, Any]) -&gt; bool:
        try:
            </st><strong class="bold"><st c="74051">login = TutorLogin(**details)</st></strong><strong class="bold"><st c="74080">login.save()</st></strong><st c="74093">
        except Exception as e:
            print(e)
            return False
        return True</st></pre>			<p><st c="74150">The </st><strong class="source-inline"><st c="74155">insert_login()</st></strong><st c="74169"> method uses the </st><strong class="source-inline"><st c="74186">save()</st></strong><st c="74192"> method of the </st><strong class="source-inline"><st c="74207">TutorLogin</st></strong><st c="74217"> model object for persistence. </st><st c="74248">The </st><strong class="source-inline"><st c="74252">save()</st></strong><st c="74258"> method will persist all the </st><strong class="source-inline"><st c="74287">kwargs</st></strong><st c="74293"> data that’s passed to the constructor </st><span class="No-Break"><st c="74332">of </st></span><span class="No-Break"><strong class="source-inline"><st c="74335">TutorLogin</st></strong></span><span class="No-Break"><st c="74345">.</st></span></p>
			<p><st c="74346">Like the Cassandra</st><a id="_idIndexMarker635"/><st c="74365"> driver, the </st><strong class="source-inline"><st c="74378">Document</st></strong><st c="74386"> class has an </st><strong class="source-inline"><st c="74400">objects</st></strong><st c="74407"> class attribute that provides all query methods. </st><st c="74457">Updating a document uses the </st><strong class="source-inline"><st c="74486">objects</st></strong><st c="74493"> attribute to filter the data using any document keys and then fetches the record using the attribute’s </st><strong class="source-inline"><st c="74597">get()</st></strong><st c="74602"> method. </st><st c="74611">If the document exists, the </st><strong class="source-inline"><st c="74639">update()</st></strong><st c="74647"> method of the filtered record object will update the given </st><strong class="source-inline"><st c="74707">kwargs</st></strong><st c="74713"> of fields that require updating. </st><st c="74747">The following code shows </st><strong class="source-inline"><st c="74772">update_login()</st></strong><st c="74786">, which updates a </st><span class="No-Break"><strong class="source-inline"><st c="74804">TutorLogin</st></strong></span><span class="No-Break"><st c="74814"> document:</st></span></p>
			<pre class="source-code"><st c="74824">
    def update_login(self, id:int, details:Dict[str, Any]) -&gt; bool:
       try:
          </st><strong class="bold"><st c="74894">login = TutorLogin.objects(id=id).get()</st></strong><strong class="bold"><st c="74933">login.update(**details)</st></strong><st c="74957">
       except:
           return False
       return True</st></pre>			<p><st c="74990">Deleting a document in MongoDB also uses the </st><strong class="source-inline"><st c="75036">objects</st></strong><st c="75043"> attribute to filter and extract the document that needs to be removed. </st><st c="75115">The </st><strong class="source-inline"><st c="75119">delete()</st></strong><st c="75127"> method of the retrieved model object will delete the filtered record from the database once the repository invokes it. </st><st c="75247">Here, </st><strong class="source-inline"><st c="75253">delete_login()</st></strong><st c="75267"> removes a filtered document from </st><span class="No-Break"><st c="75301">the database:</st></span></p>
			<pre class="source-code"><st c="75314">
    def delete_login(self, id:int) -&gt; bool:
        try:
            </st><strong class="bold"><st c="75360">login = TutorLogin.objects(id=id).get()</st></strong><strong class="bold"><st c="75399">login.delete()</st></strong><st c="75414">
        except:
            return False
        return True</st></pre>			<p><st c="75447">The </st><strong class="source-inline"><st c="75452">objects</st></strong><st c="75459"> attribute is responsible</st><a id="_idIndexMarker636"/><st c="75484"> for implementing all the query transactions. </st><st c="75530">Here, </st><strong class="source-inline"><st c="75536">get_login()</st></strong><st c="75547"> fetches a single object identified by its unique </st><strong class="source-inline"><st c="75597">_id</st></strong><st c="75600"> value using the </st><strong class="source-inline"><st c="75617">get()</st></strong><st c="75622"> method, while the </st><strong class="source-inline"><st c="75641">get_login_username()</st></strong><st c="75661"> transaction retrieves a single record filtered by the tutor’s username and password. </st><st c="75747">On the other hand, </st><strong class="source-inline"><st c="75766">get_all_login()</st></strong><st c="75781"> retrieves all the </st><strong class="source-inline"><st c="75800">tutor_login</st></strong><st c="75811"> documents from </st><span class="No-Break"><st c="75827">the database:</st></span></p>
			<pre class="source-code"><strong class="bold"><st c="75840">def get_all_login(self):</st></strong><strong class="bold"><st c="75865">login = TutorLogin.objects()</st></strong><st c="75894">
        return json.loads(login.to_json())
    </st><strong class="bold"><st c="75930">def get_login(self, id:int):</st></strong><strong class="bold"><st c="75958">login = TutorLogin.objects(id=id).get()</st></strong><strong class="bold"><st c="75998">return login.to_json()</st></strong><strong class="bold"><st c="76021">def get_login_username(self, username:str,</st></strong> <strong class="bold"><st c="76064">password:str):</st></strong><strong class="bold"><st c="76079">login = TutorLogin.objects(username=username,</st></strong> <strong class="bold"><st c="76125">password=password).get()</st></strong><st c="76150">
        return login.to_json()</st></pre>			<p><st c="76173">All these query transactions invoke the built-in </st><strong class="source-inline"><st c="76223">to_json()</st></strong><st c="76232"> method, which serializes and converts the BSON-based documents into JSON for the API’s response </st><span class="No-Break"><st c="76329">generation process.</st></span></p>
			<p><st c="76348">Embedded documents do not have dedicated collection storage because they are part of a parent document collection. </st><st c="76464">Adding and removing embedded documents from the parent document requires using string queries and operators or typical object referencing in Python, such as setting to </st><strong class="source-inline"><st c="76632">None</st></strong><st c="76636"> when removing a sub-document. </st><st c="76667">The following repository adds</st><a id="_idIndexMarker637"/><st c="76696"> and removes a tutor’s profile details from the </st><span class="No-Break"><st c="76744">login credentials:</st></span></p>
			<pre class="source-code"><st c="76762">
from typing import Dict, Any
from modules.models.db.mongo_models import TutorLogin, Tutor
class TutorProfileRepository:
    def add_tutor_profile(self, details:Dict[str, Any]) -&gt; bool:
        try:
            </st><strong class="bold"><st c="76949">login = TutorLogin.objects(id=details['id'])</st></strong> <strong class="bold"><st c="76993">.get()</st></strong><st c="76999">
            del details['id']
            </st><strong class="bold"><st c="77018">profile = Tutor(**details)</st></strong><strong class="bold"><st c="77044">login.update(tutor=profile)</st></strong><st c="77072">
        except Exception as e:
            print(e)
            return False
        return True</st></pre>			<p><st c="77129">Here, </st><strong class="source-inline"><st c="77136">add_tutor_profile()</st></strong><st c="77155"> embeds the </st><strong class="source-inline"><st c="77167">TutorProfile</st></strong><st c="77179"> document via the tutor key of the </st><strong class="source-inline"><st c="77214">TutorLogin</st></strong><st c="77224"> main document. </st><st c="77240">Another solution is to pass the </st><strong class="source-inline"><st c="77272">set_tutor=profile</st></strong><st c="77289"> query parameter to the </st><strong class="source-inline"><st c="77313">update()</st></strong><st c="77321"> operation. </st><st c="77333">The following transaction removes the tutor</st><a id="_idIndexMarker638"/><st c="77376"> profile from the </st><span class="No-Break"><st c="77394">main document:</st></span></p>
			<pre class="source-code"><st c="77408">
    def delete_tutor_profile(self, id:int) -&gt; bool:
        try:
            </st><strong class="bold"><st c="77462">login = TutorLogin.objects(id=id).get()</st></strong><strong class="bold"><st c="77501">login.update(tutor=None)</st></strong><st c="77526">
        except Exception as e:
            print(e)
            return False
        return True</st></pre>			<p><st c="77583">Then, </st><strong class="source-inline"><st c="77590">delete_tutor_profile()</st></strong><st c="77612"> unsets the profile document from the </st><strong class="source-inline"><st c="77650">TutorLogin</st></strong><st c="77660"> document by setting the tutor field to </st><strong class="source-inline"><st c="77700">None</st></strong><st c="77704">. Another way to do this is to use the </st><strong class="source-inline"><st c="77743">unset__tutor=True</st></strong><st c="77760"> query parameter for the </st><span class="No-Break"><strong class="source-inline"><st c="77785">update()</st></strong></span><span class="No-Break"><st c="77793"> method.</st></span></p>
			<p><st c="77801">The most effective way to manage a list of embedded documents is to use query strings or query parameters to avoid lengthy implementations. </st><st c="77942">The following </st><strong class="source-inline"><st c="77956">SavingsRepository</st></strong><st c="77973"> class adds and removes a bank account from a list of savings accounts of a tutor. </st><st c="78056">Its </st><strong class="source-inline"><st c="78060">add_savings()</st></strong><st c="78073"> method adds a new saving account to the tutor’s list of saving accounts. </st><st c="78147">It uses the </st><strong class="source-inline"><st c="78159">update()</st></strong><st c="78167"> method with the </st><strong class="source-inline"><st c="78184">push__tutor__savings=savings</st></strong><st c="78212"> query parameter, which pushes a new </st><strong class="source-inline"><st c="78249">Savings</st></strong><st c="78256"> instance to </st><span class="No-Break"><st c="78269">the list:</st></span></p>
			<pre class="source-code"><st c="78278">
from typing import Dict, Any
from modules.models.db.mongo_models import Savings, TutorLogin
class SavingsRepository:
    </st><strong class="bold"><st c="78396">def add_savings(self, details:Dict[str, Any]):</st></strong><st c="78442">
        try:
           </st><strong class="bold"><st c="78448">login = TutorLogin.objects(id=details['id'])</st></strong> <strong class="bold"><st c="78492">.get()</st></strong><strong class="bold"><st c="78498">del details['id']</st></strong><strong class="bold"><st c="78516">savings = Savings(**details)</st></strong><strong class="bold"><st c="78545">login.update(push__tutor__savings=savings)</st></strong><st c="78588">
        except Exception as e:
            print(e)
            return False
        return True</st></pre>			<p><st c="78645">On the other hand, the </st><strong class="source-inline"><st c="78669">delete_savings()</st></strong><st c="78685"> method deletes an account using the </st><strong class="source-inline"><st c="78722">pull__tutor__savings__acct_number= details['acct_number']</st></strong><st c="78779"> query parameter, which removes a savings account from </st><span class="No-Break"><st c="78834">the list:</st></span></p>
			<pre class="source-code"><strong class="bold"><st c="78843">def delete_savings(self, details:Dict[str, Any]):</st></strong><st c="78893">
        try:
            </st><strong class="bold"><st c="78899">login = TutorLogin.objects(id=details['id'])</st></strong><st c="78943"> .get()
            </st><strong class="bold"><st c="78950">login.update(pull__tutor__savings__acct_number=</st></strong> <strong class="bold"><st c="78997">details['acct_number'])</st></strong><st c="79021">
        except Exception as e:
            print(e)
            return False
        return True</st></pre>			<p><st c="79078">Although MongoDB is popular</st><a id="_idIndexMarker639"/><st c="79106"> and has the most support, it slows down when the number of users increases. </st><st c="79183">When the datasets become massive, adding more replications and configurations becomes difficult due to its master-slave architecture. </st><st c="79317">Adding caches is also part of the plan to improve </st><span class="No-Break"><st c="79367">data retrieval.</st></span></p>
			<p><st c="79382">However, there is another document-oriented NoSQL database that’s designed for distributed architecture and high availability with internal caching for </st><span class="No-Break"><st c="79535">datasets: </st></span><span class="No-Break"><strong class="bold"><st c="79545">Couchbase</st></strong></span><span class="No-Break"><st c="79554">.</st></span></p>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor209"/><st c="79555">Managing key-based JSON documents with Couchbase</st></h1>
			<p><strong class="bold"><st c="79604">Couchbase</st></strong><st c="79614"> is a NoSQL database that’s designed</st><a id="_idIndexMarker640"/><st c="79650"> for distributed architectures</st><a id="_idIndexMarker641"/><st c="79680"> and offers high performance on concurrent, web-based, and cloud-based applications. </st><st c="79765">It</st><a id="_idIndexMarker642"/><st c="79767"> supports distributed </st><strong class="bold"><st c="79789">ACID</st></strong><st c="79793"> transactions and has a</st><a id="_idIndexMarker643"/><st c="79816"> SQL-like language called </st><strong class="bold"><st c="79842">N1QL</st></strong><st c="79846">. All documents stored in Couchbase databases </st><span class="No-Break"><st c="79892">are JSON-formatted.</st></span></p>
			<p><st c="79911">Now, let’s install and configure the Couchbase </st><span class="No-Break"><st c="79959">database server.</st></span></p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor210"/><st c="79975">Installing and configuring the database instance</st></h2>
			<p><st c="80024">To begin, download</st><a id="_idIndexMarker644"/><st c="80043"> Couchbase Community Edition from </st><a href="https://www.couchbase.com/downloads/"><st c="80077">https://www.couchbase.com/downloads/</st></a><st c="80113">. Once it’s been installed, Couchbase will need cluster</st><a id="_idIndexMarker645"/><st c="80168"> configuration details</st><a id="_idIndexMarker646"/><st c="80190"> to be added, including the user profile for accessing the server dashboard at </st><strong class="source-inline"><st c="80269">http://localhost:8091/ui/index.html</st></strong><st c="80304">. Accepting the user agreement for the configuration is also part of the process. </st><st c="80386">After configuring the cluster, the URL will show us the login form to access the default server instance. </st><span class="No-Break"><em class="italic"><st c="80492">Figure 7</st></em></span><em class="italic"><st c="80500">.16</st></em><st c="80503"> shows the login page of the Couchbase </st><span class="No-Break"><st c="80542">web portal:</st></span></p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B19383_07_016.jpg" alt="Figure 7.16 – Accessing the login page of Couchbase"/><st c="80553"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="80601">Figure 7.16 – Accessing the login page of Couchbase</st></p>
			<p><st c="80652">After logging in to the portal, the next step is to create a </st><em class="italic"><st c="80714">bucket</st></em><st c="80720">. A </st><em class="italic"><st c="80724">bucket</st></em><st c="80730"> is a named container that saves all the data in Couchbase. </st><st c="80790">It groups all the keys and values based on collections and scopes. </st><st c="80857">Somehow, it is similar to the concept of a database schema in a relational DBMS. </st><span class="No-Break"><em class="italic"><st c="80938">Figure 7</st></em></span><em class="italic"><st c="80946">.17</st></em><st c="80949"> shows </st><strong class="bold"><st c="80956">packtbucket</st></strong><st c="80967">, which has been created on the </st><span class="No-Break"><strong class="bold"><st c="80999">Buckets</st></strong></span><span class="No-Break"><st c="81006"> dashboard:</st></span></p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B19383_07_017.jpg" alt="Figure 7.17 – Creating a bucket in the cluster"/><st c="81017"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="81241">Figure 7.17 – Creating a bucket in the cluster</st></p>
			<p><st c="81287">Afterward, create a scope</st><a id="_idIndexMarker647"/><st c="81313"> that will hold the tables or document </st><a id="_idIndexMarker648"/><st c="81352">collections of the database instance. </st><st c="81390">A bucket scope is a named mechanism that manages and organizes these collections. </st><st c="81472">In some aspects, it is similar to a tablespace in a relational DBMS. </st><st c="81541">To create these scopes, click the </st><strong class="bold"><st c="81575">Scopes &amp; Collections</st></strong><st c="81595"> hyperlink to the right of the bucket name on the </st><strong class="bold"><st c="81645">Add Bucket</st></strong><st c="81655"> page. </st><st c="81662">The </st><strong class="bold"><st c="81666">Add Scope</st></strong><st c="81675"> page will appear, as shown in </st><span class="No-Break"><em class="italic"><st c="81706">Figure 7</st></em></span><span class="No-Break"><em class="italic"><st c="81714">.18</st></em></span><span class="No-Break"><st c="81717">:</st></span></p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B19383_07_018.jpg" alt="Figure 7.18 – Creating a scope in a bucket"/><st c="81719"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="81968">Figure 7.18 – Creating a scope in a bucket</st></p>
			<p><st c="82010">On the </st><strong class="bold"><st c="82018">Add Scope</st></strong><st c="82027"> page, click the </st><strong class="bold"><st c="82044">Add Scope</st></strong><st c="82053"> hyperlink at the top-right portion and then enter the scope name – in our </st><span class="No-Break"><st c="82128">case, </st></span><span class="No-Break"><strong class="source-inline"><st c="82134">tfs</st></strong></span><span class="No-Break"><st c="82137">.</st></span></p>
			<p><st c="82138">Lastly, click the </st><strong class="bold"><st c="82157">Add Collection</st></strong><st c="82171"> hyperlink </st><a id="_idIndexMarker649"/><st c="82182">of a scope to add its</st><a id="_idIndexMarker650"/><st c="82203"> collections. </st><st c="82217">Clicking the scope’s name will list all the document collections that have been created. </st><span class="No-Break"><em class="italic"><st c="82306">Figure 7</st></em></span><em class="italic"><st c="82314">.19</st></em><st c="82317"> shows a list of all the </st><span class="No-Break"><strong class="source-inline"><st c="82342">tfs</st></strong></span><span class="No-Break"><st c="82345"> collections:</st></span></p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B19383_07_019.jpg" alt="Figure 7.19 – List of collections in a tfs scope"/><st c="82358"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="82943">Figure 7.19 – List of collections in a tfs scope</st></p>
			<p><st c="82991">Now, let’s establish the bucket connection using the </st><span class="No-Break"><strong class="source-inline"><st c="83045">couchbase</st></strong></span><span class="No-Break"><st c="83054"> module.</st></span></p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor211"/><st c="83062">Setting up the server connection</st></h2>
			<p><st c="83095">To create a client connection</st><a id="_idIndexMarker651"/><st c="83125"> to Couchbase, install the </st><strong class="source-inline"><st c="83152">couchbase</st></strong><st c="83161"> module using the </st><span class="No-Break"><strong class="source-inline"><st c="83179">pip</st></strong></span><span class="No-Break"><st c="83182"> command:</st></span></p>
			<pre class="console"><st c="83191">
pip install couchbase</st></pre>			<p><st c="83213">In the </st><strong class="source-inline"><st c="83221">create_app()</st></strong><st c="83233"> factory function of the application, perform the following steps to access the Couchbase </st><span class="No-Break"><st c="83323">server instance:</st></span></p>
			<ol>
				<li><st c="83339">Create a </st><strong class="source-inline"><st c="83349">PasswordAuthenticator</st></strong><st c="83370"> object with the correct user profile’s credential to access the </st><span class="No-Break"><st c="83435">specified bucket.</st></span></li>
				<li><st c="83452">Instantiate the </st><strong class="source-inline"><st c="83469">Cluster</st></strong><st c="83476"> class with its required constructor arguments, namely the Couchbase URL and some options, such as the </st><strong class="source-inline"><st c="83579">PasswordAuthenticator</st></strong><st c="83600"> object, wrapped in the </st><span class="No-Break"><strong class="source-inline"><st c="83624">ClusterOptions</st></strong></span><span class="No-Break"><st c="83638"> instance.</st></span></li>
				<li><st c="83648">Access the preferred bucket by calling the </st><strong class="source-inline"><st c="83692">Cluster</st></strong><st c="83699">’s </st><strong class="source-inline"><st c="83703">bucket()</st></strong> <span class="No-Break"><st c="83711">instance method.</st></span></li>
			</ol>
			<p><st c="83728">The following snippet shows</st><a id="_idIndexMarker652"/><st c="83756"> how to implement these steps in our </st><em class="italic"><st c="83793">Tutor Finder</st></em><st c="83805"> application’s </st><span class="No-Break"><strong class="source-inline"><st c="83820">create_app()</st></strong></span><span class="No-Break"><st c="83832"> method:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="83840">from couchbase.auth import PasswordAuthenticator</st></strong>
<strong class="bold"><st c="83889">from couchbase.cluster import Cluster</st></strong>
<strong class="bold"><st c="83927">from couchbase.options import ClusterOptions</st></strong><st c="83972">
def create_app(config_file):
    app = Flask(__name__)
    app.config.from_file(config_file, toml.load)
    </st><strong class="bold"><st c="84069">auth = PasswordAuthenticator("sjctrags", "packt2255",)</st></strong><strong class="bold"><st c="84123">cluster = Cluster('couchbase://localhost',</st></strong> <strong class="bold"><st c="84166">ClusterOptions(auth))</st></strong><st c="84188">
    cluster.wait_until_ready(timedelta(seconds=5))
    global cb
    </st><strong class="bold"><st c="84246">cb = cluster.bucket("packtbucket")</st></strong></pre>			<p><st c="84280">The </st><strong class="source-inline"><st c="84285">Cluster</st></strong><st c="84292"> object has a </st><strong class="source-inline"><st c="84306">wait_until_ready()</st></strong><st c="84324"> method that pings to the Couchbase services regarding the connection status and returns control to </st><strong class="source-inline"><st c="84424">create_app()</st></strong><st c="84436"> once the connection is ready. </st><st c="84467">But calling this method slows down the startup of the Flask server. </st><st c="84535">Our application has only invoked the method for </st><span class="No-Break"><st c="84583">experimentation purposes.</st></span></p>
			<p><st c="84608">After a successful </st><a id="_idIndexMarker653"/><st c="84628">setup, we must ensure the </st><strong class="source-inline"><st c="84654">Bucket</st></strong><st c="84660"> object is ready for implementing the </st><span class="No-Break"><st c="84698">repository layer.</st></span></p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor212"/><st c="84715">Creating the repository layer</st></h2>
			<p><st c="84745">The repository layer</st><a id="_idIndexMarker654"/><st c="84766"> needs the </st><strong class="source-inline"><st c="84777">Bucket</st></strong><st c="84783"> object from </st><strong class="source-inline"><st c="84796">create_app()</st></strong><st c="84808"> to implement the CRUD transactions. </st><st c="84845">The </st><strong class="source-inline"><st c="84849">Bucket</st></strong><st c="84855"> object has a </st><strong class="source-inline"><st c="84869">scope()</st></strong><st c="84876"> method that will access the container space that contains the collections. </st><st c="84952">It returns a </st><strong class="source-inline"><st c="84965">Scope</st></strong><st c="84970"> object that emits </st><strong class="source-inline"><st c="84989">collection()</st></strong><st c="85001">, which retrieves the preferred document collections. </st><st c="85055">Here, </st><strong class="source-inline"><st c="85061">DirectMessageRepository</st></strong><st c="85084"> manages all the direct messages that students send to trainers and </st><span class="No-Break"><st c="85152">vice versa:</st></span></p>
			<pre class="source-code"><st c="85163">
class DirectMessageRepository:
    def insert_dm(self, details:Dict[str, Any]):
        try:
            </st><strong class="bold"><st c="85245">cb_coll = cb.scope("tfs")</st></strong> <strong class="bold"><st c="85270">.collection("direct_messages")</st></strong><st c="85300">
            key = "chat_" + str(details['id']) + '-' + str(details["date_sent"])
            </st><strong class="bold"><st c="85370">cb_coll.insert(key, details)</st></strong><st c="85398">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="85455">The </st><strong class="source-inline"><st c="85460">dm_insert()</st></strong><st c="85471"> method gives us access to the </st><strong class="source-inline"><st c="85502">tfs</st></strong><st c="85505"> scope and its </st><strong class="source-inline"><st c="85520">direct_messages</st></strong><st c="85535"> document collections. </st><st c="85558">Its main goal is to insert the details of a chat message between the tutor and trainer into the document collection using the given key through the collection’s </st><span class="No-Break"><strong class="source-inline"><st c="85719">insert()</st></strong></span><span class="No-Break"><st c="85727"> method.</st></span></p>
			<p><st c="85735">On the other hand, the </st><strong class="source-inline"><st c="85759">update_dm()</st></strong><st c="85770"> method uses the collection’s </st><strong class="source-inline"><st c="85800">upsert()</st></strong><st c="85808"> method to update a JSON document using </st><span class="No-Break"><st c="85848">a key:</st></span></p>
			<pre class="source-code"><st c="85854">
    def update_dm(self, details:Dict[str, Any]):
        try:
            </st><strong class="bold"><st c="85905">cb_coll = cb.scope("tfs")</st></strong> <strong class="bold"><st c="85930">.collection("direct_messages")</st></strong><st c="85960">
            key = "chat_" + str(details['id']) + '-' + str(details["date_sent"])
            </st><strong class="bold"><st c="86030">cb_coll.upsert(key, details)</st></strong><st c="86058">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="86115">The collection’s </st><strong class="source-inline"><st c="86133">remove()</st></strong><st c="86141"> method deletes</st><a id="_idIndexMarker655"/><st c="86156"> a document from the collection. </st><st c="86189">This can be seen in the following </st><strong class="source-inline"><st c="86223">delete_dm()</st></strong><st c="86234"> transaction, where it removes a chat message using </st><span class="No-Break"><st c="86286">its </st></span><span class="No-Break"><strong class="source-inline"><st c="86290">key</st></strong></span><span class="No-Break"><st c="86293">:</st></span></p>
			<pre class="source-code"><st c="86295">
    def delete_dm_key(self, details:Dict[str, Any]):
        try:
            </st><strong class="bold"><st c="86350">cb_coll = cb.scope("tfs")</st></strong> <strong class="bold"><st c="86375">.collection("direct_messages")</st></strong><st c="86405">
            key = "chat_" + str(details['id']) + '-' + str(details["date_sent"])
            </st><strong class="bold"><st c="86475">cb_coll.remove(key)</st></strong><st c="86494">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="86551">Couchbase, unlike MongoDB, uses a SQL-like</st><a id="_idIndexMarker656"/><st c="86594"> mechanism called </st><em class="italic"><st c="86612">N1QL</st></em><st c="86616"> to retrieve documents. </st><st c="86640">The following </st><em class="italic"><st c="86654">DELETE</st></em><st c="86660"> transaction uses the N1QL query transaction instead of the collection’s </st><span class="No-Break"><strong class="source-inline"><st c="86733">delete()</st></strong></span><span class="No-Break"><st c="86741"> method:</st></span></p>
			<pre class="source-code"><st c="86749">
    def delete_dm_sender(self, sender):
        try:
            </st><strong class="bold"><st c="86791">cb_scope = cb.scope("tfs")</st></strong><strong class="bold"><st c="86817">stmt = f"delete from `direct_messages` where</st></strong> <strong class="bold"><st c="86862">`sender_id` LIKE '{sender}'"</st></strong><strong class="bold"><st c="86891">cb_scope.query(stmt)</st></strong><st c="86912">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="86969">The </st><strong class="source-inline"><st c="86974">Scope</st></strong><st c="86979"> instance, derived from the </st><strong class="source-inline"><st c="87007">Bucket</st></strong><st c="87013"> object’s </st><strong class="source-inline"><st c="87023">scope()</st></strong><st c="87030"> method, has a </st><strong class="source-inline"><st c="87045">query()</st></strong><st c="87052"> method that executes a query statement in string form. </st><st c="87108">The query statement should have its collection and field names enclosed in ticks (</st><strong class="source-inline"><st c="87190">``</st></strong><st c="87193">), while its string constraint values should be in single quotes. </st><st c="87260">Thus, we have the </st><strong class="source-inline"><st c="87278">delete from `direct_messages` where `sender_id` LIKE '{sender},'</st></strong><st c="87342"> query statement in </st><strong class="source-inline"><st c="87362">delete_dm_sender()</st></strong><st c="87380">, where </st><strong class="source-inline"><st c="87388">sender</st></strong><st c="87394"> is a </st><span class="No-Break"><st c="87400">parameter value.</st></span></p>
			<p><st c="87416">The advantage of using N1QL queries in </st><em class="italic"><st c="87456">DELETE</st></em><st c="87462"> and </st><em class="italic"><st c="87467">UPDATE</st></em><st c="87473"> transactions is that the key is not the only basis</st><a id="_idIndexMarker657"/><st c="87524"> for performing these operations. </st><st c="87558">The </st><em class="italic"><st c="87562">DELETE</st></em><st c="87568"> operation can base its document removal on other fields, such as removing a chat message using the given </st><span class="No-Break"><st c="87674">sender ID:</st></span></p>
			<pre class="source-code"><st c="87684">
def delete_dm_sender(self, sender):
        try:
            cb_scope = cb.scope("tfs")
            stmt = f"delete from `direct_messages` where `sender_id` LIKE '{sender}'"
            cb_scope.query(stmt)
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><em class="italic"><st c="87904">N1QL</st></em><st c="87909"> is popular in retrieving JSON documents from the keyspace with or without constraints. </st><st c="87997">The following query transaction uses the </st><em class="italic"><st c="88038">SELECT</st></em><st c="88044"> query statement to retrieve all the documents in the </st><span class="No-Break"><strong class="source-inline"><st c="88098">direct_messages</st></strong></span><span class="No-Break"><st c="88113"> collections:</st></span></p>
			<pre class="source-code"><st c="88126">
def select_all_dm(self):
        cb_scope = cb.scope("tfs")
        raw_data = cb_scope.query('select * from `direct_messages`', QueryOptions(read_only=True))
        records = [rec for rec in raw_data.rows()]
        return records</st></pre>			<p><st c="88327">Couchbase can be a suitable form of backend storage for Flask applications when managing a dump of JSON data. </st><st c="88438">Flask and Couchbase can build fast, scalable, and efficient microservices or distributed applications with rapid development and less database administration. </st><st c="88597">However, compared to HBase, Redis, Cassandra, MongoDB, and Couchbase, Flask can integrate</st><a id="_idIndexMarker658"/><st c="88686"> with graph databases, such as Neo4J, for </st><span class="No-Break"><st c="88728">graph-related algorithms.</st></span></p>
			<h1 id="_idParaDest-209"><a id="_idTextAnchor213"/><st c="88753">Establishing a data relationship with Neo4J</st></h1>
			<p><strong class="bold"><st c="88797">Neo4J</st></strong><st c="88803"> is a NoSQL database that focuses</st><a id="_idIndexMarker659"/><st c="88836"> on relationships</st><a id="_idIndexMarker660"/><st c="88853"> between data. </st><st c="88868">Instead</st><a id="_idIndexMarker661"/><st c="88875"> of documents, it stores nodes, relationships, and the properties that link these nodes. </st><st c="88964">Neo4J is also known as a popular graph database because the concept relies on a graph model composed of nodes and lines directed </st><span class="No-Break"><st c="89093">between nodes.</st></span></p>
			<p><st c="89107">Before integrating our application into the Neo4J database, we must install the current version of the Neo4J platform using </st><span class="No-Break"><st c="89232">Neo4J Desktop.</st></span></p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor214"/><st c="89246">Installing Neo4J Desktop</st></h2>
			<p><st c="89271">Neo4J Desktop provides</st><a id="_idIndexMarker662"/><st c="89294"> a local development environment and includes all the functionality needed to learn the database, from creating a custom local database to starting</st><a id="_idIndexMarker663"/><st c="89441"> the Neo4J browser. </st><st c="89461">Its installer can be found </st><span class="No-Break"><st c="89488">at </st></span><a href="https://neo4j.com/download/"><span class="No-Break"><st c="89491">https://neo4j.com/download/</st></span></a><span class="No-Break"><st c="89518">.</st></span></p>
			<p><st c="89519">Once it’s been installed, create a Neo4J project that will contain the local databases and configuration settings. </st><st c="89635">Aside from the project’s name, the process will also ask for a username and password for its authentication details. </st><st c="89752">Once you’ve done this, delete its default Movie database and create the necessary graph database. </st><span class="No-Break"><em class="italic"><st c="89850">Figure 7</st></em></span><em class="italic"><st c="89858">.20</st></em><st c="89861"> shows </st><strong class="bold"><st c="89868">Packt Flask Project</st></strong><st c="89887"> with a </st><span class="No-Break"><strong class="bold"><st c="89895">Tutor</st></strong></span><span class="No-Break"><st c="89900"> database:</st></span></p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B19383_07_020.jpg" alt="Figure 7.20 – The Neo4J Desktop dashboard"/><st c="89910"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="90213">Figure 7.20 – The Neo4J Desktop dashboard</st></p>
			<p><st c="90254">There are so many ways Flask can connect to a graph database, and one of them is through the </st><strong class="source-inline"><st c="90348">py2neo</st></strong><st c="90354"> library. </st><st c="90364">We’ll take a closer look at this in the </st><span class="No-Break"><st c="90404">next section.</st></span></p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor215"/><st c="90417">Establishing a connection to the database</st></h2>
			<p><st c="90459">To start, install </st><strong class="source-inline"><st c="90478">py2neo</st></strong><st c="90484"> using </st><a id="_idIndexMarker664"/><st c="90491">the </st><span class="No-Break"><strong class="source-inline"><st c="90495">pip</st></strong></span><span class="No-Break"><st c="90498"> command:</st></span></p>
			<pre class="console"><st c="90507">
pip install py2neo</st></pre>			<p><st c="90526">Next, create a </st><strong class="source-inline"><st c="90542">neo4j_config.py</st></strong><st c="90557"> module in the main project folder with the following script to ensure </st><span class="No-Break"><st c="90628">database connectivity:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="90650">from py2neo import Graph</st></strong><st c="90675">
def db_auth():
    </st><strong class="bold"><st c="90691">graph = Graph("bolt://127.0.0.1:7687", auth=("neo4j",</st></strong> <strong class="bold"><st c="90744">"packt2255"))</st></strong><st c="90758">
    return graph</st></pre>			<p><st c="90771">Now, calling the given </st><strong class="source-inline"><st c="90795">db_auth()</st></strong><st c="90804"> method will initiate the bolts connection protocol with the host, port, and authentication details to open a connection for our </st><em class="italic"><st c="90933">Tutor Finder</st></em><st c="90945"> application through</st><a id="_idIndexMarker665"/><st c="90965"> the </st><strong class="source-inline"><st c="90970">Graph</st></strong><st c="90975"> instance, the object responsible for repository </st><span class="No-Break"><st c="91024">layer implementation.</st></span></p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor216"/><st c="91045">Implementing the repository</st></h2>
			<p><strong class="bold"><st c="91073">Cypher</st></strong><st c="91080"> is the official query language</st><a id="_idIndexMarker666"/><st c="91111"> of Neo4J and allows client</st><a id="_idIndexMarker667"/><st c="91138"> applications to perform CRUD operations on the database. </st><st c="91196">Python-Neo4J libraries provide various helper classes and methods to execute these Cypher commands at the Python level. </st><st c="91316">In our case, the </st><strong class="source-inline"><st c="91333">Graph</st></strong><st c="91338"> instance has several utility methods to derive the building blocks of the module, namely </st><strong class="source-inline"><st c="91428">SubGraph</st></strong><st c="91436">, </st><strong class="source-inline"><st c="91438">Node</st></strong><st c="91442">, </st><strong class="source-inline"><st c="91444">NodeMatcher</st></strong><st c="91455">, and </st><strong class="source-inline"><st c="91461">Relationship</st></strong><st c="91473">. Here, </st><strong class="source-inline"><st c="91481">StudentNodeRepository</st></strong><st c="91502"> showcases the use of py2neo’s API classes and methods in managing the </st><span class="No-Break"><st c="91573">student nodes:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="91587">from main import graph</st></strong>
<strong class="bold"><st c="91610">from py2neo import Node, NodeMatcher, Subgraph, Transaction</st></strong>
<strong class="bold"><st c="91670">from py2neo.cypher import Cursor</st></strong><st c="91703">
from typing import Any, Dict
class StudentNodeRepository:
    def __init__(self):
        pass
    def insert_student_node(self, details:Dict[str, Any]):
        try:
            </st><strong class="bold"><st c="91847">tx:Transaction = graph.begin()</st></strong><strong class="bold"><st c="91877">node_trainer = Node("Tutor", **details)</st></strong><strong class="bold"><st c="91917">graph.create(node_trainer)</st></strong><strong class="bold"><st c="91944">graph.commit(tx)</st></strong><st c="91961">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="92018">The </st><strong class="source-inline"><st c="92023">insert_student_node()</st></strong><st c="92044"> method creates a </st><strong class="source-inline"><st c="92062">Student</st></strong><st c="92069"> node and stores its details in the graph database. </st><st c="92121">A node is the fundamental unit of data in Neo4J; it can be an independent node or connected to other nodes through </st><span class="No-Break"><st c="92236">a relationship.</st></span></p>
			<p><st c="92251">There are two ways to create a node</st><a id="_idIndexMarker668"/><st c="92287"> using the </st><span class="No-Break"><strong class="source-inline"><st c="92298">py2neo</st></strong></span><span class="No-Break"><st c="92304"> library:</st></span></p>
			<ul>
				<li><st c="92313">Running a query with Cypher’s </st><em class="italic"><st c="92344">CREATE</st></em><st c="92350"> transaction using Graph’s </st><strong class="source-inline"><st c="92377">query()</st></strong><st c="92384"> or </st><span class="No-Break"><strong class="source-inline"><st c="92388">run()</st></strong></span><span class="No-Break"><st c="92393"> methods.</st></span></li>
				<li><st c="92402">Persisting the </st><strong class="source-inline"><st c="92418">Node</st></strong><st c="92422"> object using the </st><strong class="source-inline"><st c="92440">Graph</st></strong><st c="92445"> object’s </st><span class="No-Break"><strong class="source-inline"><st c="92455">create()</st></strong></span><span class="No-Break"><st c="92463"> method.</st></span></li>
			</ul>
			<p><st c="92471">Creating a node requires transaction</st><a id="_idIndexMarker669"/><st c="92508"> management, so we must start a </st><strong class="source-inline"><st c="92540">Transaction</st></strong><st c="92551"> context to commit all the data manipulation operations. </st><st c="92608">Here, </st><strong class="source-inline"><st c="92614">insert_student_node()</st></strong><st c="92635"> creates a </st><strong class="source-inline"><st c="92646">Transaction</st></strong><st c="92657"> object to create a logical context for the node creation operation for the </st><strong class="source-inline"><st c="92733">Graph</st></strong><st c="92738"> object’s </st><strong class="source-inline"><st c="92748">commit()</st></strong><st c="92756"> method </st><span class="No-Break"><st c="92764">to commit:</st></span></p>
			<pre class="source-code"><st c="92774">
    def update_student_node(self, details:Dict[str, Any]):
        try:
            </st><strong class="bold"><st c="92835">tx = graph.begin()</st></strong><strong class="bold"><st c="92853">matcher = NodeMatcher(graph)</st></strong><strong class="bold"><st c="92882">student_node:Node  = matcher.match('Student',</st></strong> <strong class="bold"><st c="92927">student_id=details['student_id']).first()</st></strong><st c="92969">
            if not student_node == None:
                del details['student_id']
                </st><strong class="bold"><st c="93025">student_node.update(**details)</st></strong><strong class="bold"><st c="93055">graph.push(student_node)</st></strong><strong class="bold"><st c="93080">graph.commit(tx)</st></strong><st c="93097">
                return True
            else:
                return False
        except Exception as e:
            print(e)
        return False</st></pre>			<p><em class="italic"><st c="93173">NodeManager</st></em><st c="93185"> can locate a specific node</st><a id="_idIndexMarker670"/><st c="93212"> given the criteria in key-value pairs. </st><st c="93252">Here, </st><strong class="source-inline"><st c="93258">update_student_node()</st></strong><st c="93279"> uses the </st><strong class="source-inline"><st c="93289">match()</st></strong><st c="93296"> method from </st><strong class="source-inline"><st c="93309">NodeManager</st></strong><st c="93320"> to single out a </st><strong class="source-inline"><st c="93337">Node</st></strong><st c="93341"> object with the specific </st><strong class="source-inline"><st c="93367">student_id</st></strong><st c="93377"> value. </st><st c="93385">After retrieving a graph node, if there is one, you must call the </st><strong class="source-inline"><st c="93451">Node</st></strong><st c="93455"> object’s </st><strong class="source-inline"><st c="93465">update()</st></strong><st c="93473"> method with the </st><strong class="source-inline"><st c="93490">kwargs</st></strong><st c="93496"> value of the new data. </st><st c="93520">To merge the updated </st><strong class="source-inline"><st c="93541">Node</st></strong><st c="93545"> object with its committed version, invoke the </st><strong class="source-inline"><st c="93592">Graph</st></strong><st c="93597"> object’s </st><strong class="source-inline"><st c="93607">push()</st></strong><st c="93613"> method and perform </st><span class="No-Break"><st c="93633">a commit.</st></span></p>
			<p><st c="93642">Another way of searching and retrieving a </st><strong class="source-inline"><st c="93685">Node</st></strong><st c="93689"> match is through the </st><strong class="source-inline"><st c="93711">Graph</st></strong><st c="93716"> object’s </st><strong class="source-inline"><st c="93726">query()</st></strong><st c="93733"> method. </st><st c="93742">It can execute </st><em class="italic"><st c="93757">CREATE</st></em><st c="93763"> and other Cipher manipulation commands because it has auto-commit features. </st><st c="93840">But in most cases, it is applied in node retrieval transactions. </st><st c="93905">Here, </st><strong class="source-inline"><st c="93911">delete_student_node()</st></strong><st c="93932"> uses the </st><strong class="source-inline"><st c="93942">query()</st></strong><st c="93949"> method with the </st><strong class="source-inline"><st c="93966">MATCH</st></strong><st c="93971"> command to retrieve a specific node </st><span class="No-Break"><st c="94008">for deletion:</st></span></p>
			<pre class="source-code"><st c="94021">
    def delete_student_node(self, student_id:str):
        try:
            </st><strong class="bold"><st c="94074">tx = graph.begin()</st></strong><strong class="bold"><st c="94092">student_cur:Cursor = graph.query(f"MATCH</st></strong> <strong class="bold"><st c="94133">(st:Student) WHERE st.student_id =</st></strong> <strong class="bold"><st c="94168">'{student_id}' Return st")</st></strong><strong class="bold"><st c="94195">student_sg:Subgraph = student_cur.to_subgraph()</st></strong><strong class="bold"><st c="94243">graph.delete(student_sg)</st></strong><strong class="bold"><st c="94268">graph.commit(tx)</st></strong><st c="94285">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="94342">The </st><strong class="source-inline"><st c="94347">Graph</st></strong><st c="94352"> object’s </st><strong class="source-inline"><st c="94362">query()</st></strong><st c="94369"> method returns </st><strong class="source-inline"><st c="94385">Cursor</st></strong><st c="94391">, which is a navigator for streams of nodes. </st><st c="94436">The </st><strong class="source-inline"><st c="94440">Graph</st></strong><st c="94445"> object has a </st><strong class="source-inline"><st c="94459">delete()</st></strong><st c="94467"> method that can delete any nodes retrieved by </st><strong class="source-inline"><st c="94514">query()</st></strong><st c="94521">, but the nodes should be in </st><em class="italic"><st c="94550">SubGraph</st></em><st c="94558"> form. </st><st c="94565">To delete the retrieved nodes, convert the </st><strong class="source-inline"><st c="94608">Cursor</st></strong><st c="94614"> object into a </st><em class="italic"><st c="94629">SubGraph</st></em><st c="94637"> by calling it from the </st><strong class="source-inline"><st c="94661">to_subgraph()</st></strong><st c="94674"> method. </st><st c="94683">Then, call </st><strong class="source-inline"><st c="94694">commit()</st></strong><st c="94702"> to handle the whole </st><span class="No-Break"><st c="94723">delete transaction.</st></span></p>
			<p><st c="94742">Retrieving nodes in </st><strong class="source-inline"><st c="94763">py2neo</st></strong><st c="94769"> can utilize</st><a id="_idIndexMarker671"/><st c="94781"> either </st><strong class="source-inline"><st c="94789">NodeManager</st></strong><st c="94800"> or the </st><strong class="source-inline"><st c="94808">Graph</st></strong><st c="94813"> object’s </st><strong class="source-inline"><st c="94823">query()</st></strong><st c="94830"> method. </st><st c="94839">Here, </st><strong class="source-inline"><st c="94845">get_student_node()</st></strong><st c="94863"> retrieves a specific </st><strong class="source-inline"><st c="94885">Student</st></strong><st c="94892"> node filtered by student ID using </st><strong class="source-inline"><st c="94927">NodeMatcher</st></strong><st c="94938">, while </st><strong class="source-inline"><st c="94946">select_student_nodes()</st></strong><st c="94968"> uses </st><strong class="source-inline"><st c="94974">query()</st></strong><st c="94981"> to retrieve a list of </st><span class="No-Break"><strong class="source-inline"><st c="95004">Student</st></strong></span><span class="No-Break"><st c="95011"> nodes:</st></span></p>
			<pre class="source-code"><st c="95018">
    def get_student_node(self, student_id:str):
        </st><strong class="bold"><st c="95063">matcher = NodeMatcher(graph)</st></strong><strong class="bold"><st c="95091">student_node:Node  = matcher.match('Student',</st></strong> <strong class="bold"><st c="95136">student_id=student_id).first()</st></strong><strong class="bold"><st c="95167">record = dict(student_node)</st></strong><st c="95195">
        return record
    def select_student_nodes(self):
        </st><strong class="bold"><st c="95242">student_cur:Cursor = graph.query(f"MATCH (st:Student)</st></strong> <strong class="bold"><st c="95295">Return st")</st></strong><st c="95307">
        records = student_cur.data()
        return records</st></pre>			<p><st c="95351">The </st><strong class="source-inline"><st c="95356">dict()</st></strong><st c="95362"> function converts a </st><strong class="source-inline"><st c="95383">Node</st></strong><st c="95387"> object into a dictionary, thus wrapping a </st><strong class="source-inline"><st c="95430">Student</st></strong><st c="95437"> node with the </st><strong class="source-inline"><st c="95452">dict()</st></strong><st c="95458"> function in the given </st><strong class="source-inline"><st c="95481">get_student_node()</st></strong><st c="95499">. On the other hand, </st><strong class="source-inline"><st c="95520">Cursor</st></strong><st c="95526"> has a </st><strong class="source-inline"><st c="95533">data()</st></strong><st c="95539"> function to convert the streams of </st><strong class="source-inline"><st c="95575">Node</st></strong><st c="95579"> objects into a list of dictionary elements. </st><st c="95624">So, </st><strong class="source-inline"><st c="95628">select_student_nodes()</st></strong><st c="95650"> returns the stream of </st><strong class="source-inline"><st c="95673">Student</st></strong><st c="95680"> nodes</st><a id="_idIndexMarker672"/><st c="95686"> as a list of </st><span class="No-Break"><strong class="source-inline"><st c="95700">Student</st></strong></span><span class="No-Break"><st c="95707"> records.</st></span></p>
			<h1 id="_idParaDest-213"><a id="_idTextAnchor217"/><st c="95716">Summary</st></h1>
			<p><st c="95724">There are lots of NoSQL databases that can store non-relational data for big data applications built with Flask 3.x. </st><st c="95842">Flask can </st><strong class="source-inline"><st c="95852">PUT</st></strong><st c="95855">, </st><strong class="source-inline"><st c="95857">GET</st></strong><st c="95860">, and </st><strong class="source-inline"><st c="95866">SCAN</st></strong><st c="95870"> data in HBase using HDFS, access the Cassandra database, execute </st><strong class="source-inline"><st c="95936">HGET</st></strong><st c="95940"> an </st><strong class="source-inline"><st c="95944">HSET</st></strong><st c="95948"> with Redis, perform CRUD operations in Couchbase and MongoDB, and manage nodes with Neo4J. </st><st c="96040">Although there are changes in some support modules, such as in </st><strong class="source-inline"><st c="96103">flask-mongoengine</st></strong><st c="96120">, because of the transformations in the Flask internal modules (for example, the removal of </st><strong class="source-inline"><st c="96212">flask.json</st></strong><st c="96222">), Flask can still adapt to other Python module extensions and workarounds to connect to and manage its data, such as using the FastAPI-compatible </st><span class="No-Break"><st c="96370">Redis OM.</st></span></p>
			<p><st c="96379">In general, this chapter showcased Flask’s compatibility with almost all the efficient, popular, and widely used NoSQL databases. </st><st c="96510">It is also a Python framework that’s fit for building big data applications for many enterprises and scientific development because it supports many </st><span class="No-Break"><st c="96659">NoSQL storages.</st></span></p>
			<p><st c="96674">The next chapter is about using Flask to implement task management </st><span class="No-Break"><st c="96742">with workflows.</st></span></p>
		</div>
	<div id="charCountTotal" value="96757"/></body></html>