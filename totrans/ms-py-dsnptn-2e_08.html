<html><head></head><body>
		<div id="_idContainer024">
			<h1 id="_idParaDest-202" class="chapter-number"><a id="_idTextAnchor216"/>8</h1>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor217"/>Performance Patterns</h1>
			<p>In the previous chapter, we covered concurrency and asynchronous patterns, useful for writing efficient software that can handle multiple tasks at once. Next, we are going to discuss specific performance patterns that help enhance the speed and resource utilization <span class="No-Break">of applications.</span></p>
			<p>Performance patterns<a id="_idIndexMarker803"/> address common bottlenecks and optimization challenges, providing developers with proven methodologies to improve execution time, reduce memory usage, and <span class="No-Break">scale effectively.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>The <span class="No-Break">Cache-Aside pattern</span></li>
				<li>The <span class="No-Break">Memoization pattern</span></li>
				<li>The Lazy <span class="No-Break">Loading pattern</span></li>
			</ul>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor218"/>Technical requirements</h1>
			<p>See the requirements presented in <a href="B21896_01.xhtml#_idTextAnchor017"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>. The additional technical requirements for the code discussed in this chapter are <span class="No-Break">the following:</span></p>
			<ul>
				<li>Add the <strong class="source-inline">Faker</strong> module to your Python environment using the following command: <strong class="source-inline">python -m pip </strong><span class="No-Break"><strong class="source-inline">install faker</strong></span></li>
				<li>Add the <strong class="source-inline">Redis</strong> module to your Python environment using the following command: <strong class="source-inline">python -m pip </strong><span class="No-Break"><strong class="source-inline">install redis</strong></span></li>
				<li>Install the Redis server and run it using Docker: <strong class="source-inline">docker run --name myredis -p </strong><span class="No-Break"><strong class="source-inline">6379:6379 redis</strong></span><p class="list-inset">If needed, follow the documentation <span class="No-Break">at </span><a href="https://redis.io/docs/latest/"><span class="No-Break">https://redis.io/docs/latest/</span></a><a href="https://redis.io/docs&#13;"/></p></li>
			</ul>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor219"/>The Cache-Aside pattern</h1>
			<p>In<a id="_idIndexMarker804"/> situations where data is more frequently <a id="_idIndexMarker805"/>read than updated, applications use a cache to optimize repeated access to information stored in a database or data store. In some systems, that type of caching mechanism is built in and works automatically. When this is not the case, we must implement it in the application ourselves, using a caching strategy that is suitable for the particular <span class="No-Break">use case.</span></p>
			<p>One such strategy is called <strong class="bold">Cache-Aside</strong>, where, to improve performance, we store frequently accessed data in a cache, reducing the need to fetch data from the data <span class="No-Break">store repeatedly.</span></p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor220"/>Real-world examples</h2>
			<p>We <a id="_idIndexMarker806"/>can cite the following examples in the <span class="No-Break">software realm:</span></p>
			<ul>
				<li>Memcached is commonly used as a cache server. It is a popular in-memory key-value store for small chunks of data from the results of database calls, API calls, or HTML <span class="No-Break">page content.</span></li>
				<li>Redis is another server solution that is used for cache. Nowadays, it is my go-to server for caching or application in-memory storage use cases where <span class="No-Break">it shines.</span></li>
				<li>Amazon’s ElastiCache, according to<a id="_idIndexMarker807"/> the documentation site (<a href="https://docs.aws.amazon.com/elasticache/">https://docs.aws.amazon.com/elasticache/</a>), is a web service that makes it easy to set up, manage, and scale a distributed in-memory data store or cache environment in <span class="No-Break">the cloud.</span></li>
			</ul>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor221"/>Use cases for the cache-aside pattern</h2>
			<p>The cache-aside pattern<a id="_idIndexMarker808"/> is useful when we need to reduce the database load in our application. By caching frequently accessed data, fewer queries are sent to the database. It also helps improve application responsiveness, since cached data can be <span class="No-Break">retrieved faster.</span></p>
			<p>Note that this pattern works for data that doesn’t change often and for data storage that doesn’t depend on the consistency of a set of entries in the storage (multiple keys). For example, it might work for certain kinds of document stores or databases where keys are never updated and occasionally data entries are deleted but there is no strong requirement to <a id="_idIndexMarker809"/>continue to serve them for some time (until the cache <span class="No-Break">is refreshed).</span></p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor222"/>Implementing the cache-aside pattern</h2>
			<p>We <a id="_idIndexMarker810"/>can summarize the steps needed when implementing<a id="_idIndexMarker811"/> the Cache-Aside pattern, involving a database and a cache, <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Case 1 – When we want to fetch a data item</strong>: Return the item from the cache if found in it. If not found in the cache, read the data from the database. Put the item we got in the cache and <span class="No-Break">return it.</span></li>
				<li><strong class="bold">Case 2 – When we want to update a data item</strong>: Write the item in the database and remove the corresponding entry from <span class="No-Break">the cache.</span></li>
			</ul>
			<p>Let’s try a simple implementation with a database of quotes from which the user can ask to retrieve some quotes via an application. Our focus here will be implementing the <em class="italic">Case </em><span class="No-Break"><em class="italic">1</em></span><span class="No-Break"> part.</span></p>
			<p>Here are our choices for the additional software dependencies we need to install on the machine for <span class="No-Break">this implementation:</span></p>
			<ul>
				<li>An SQLite database, since we can query an SQLite database using Python’s standard <span class="No-Break">module, </span><span class="No-Break"><strong class="source-inline">sqlite3</strong></span></li>
				<li>A Redis server and the <strong class="source-inline">redis-py</strong> <span class="No-Break">Python module</span></li>
			</ul>
			<p>We will use a script (in the <strong class="source-inline">ch08/cache_aside/populate_db.py</strong> file) to handle the creation of a database and a <strong class="source-inline">quotes</strong> table and add example data to it. For practical reasons, we also use the <strong class="source-inline">Faker</strong> module there to generate fake quotes that are used when populating <span class="No-Break">the database.</span></p>
			<p>Our code starts with the imports we need, followed by the creation of the Faker instance that we will use to generate fake quotes, as well as some constants or <span class="No-Break">module-level variables:</span></p>
			<pre class="source-code">
import sqlite3
from pathlib import Path
from random import randint
import redis
from faker import Faker
fake = Faker()
DB_PATH = Path(__file__).parent / Path("quotes.sqlite3")
cache = redis.StrictRedis(host="localhost", port=6379, decode_responses=True)</pre>			<p>Then, we <a id="_idIndexMarker812"/>write a function to take care of the database<a id="_idIndexMarker813"/> setup part, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
def setup_db():
    try:
        with sqlite3.connect(DB_PATH) as db:
            cursor = db.cursor()
            cursor.execute(
                """
                CREATE TABLE quotes(id INTEGER PRIMARY KEY, text TEXT)
            """
            )
            db.commit()
            print("Table 'quotes' created")
    except Exception as e:
        print(e)</pre>			<p>Then, we <a id="_idIndexMarker814"/>define a central function that takes care of <a id="_idIndexMarker815"/>adding a set of new quotes based on a list of sentences or text snippets. Among different things, we associate a quote identifier to the quote, for the <strong class="source-inline">id</strong> column in the database table. To make things easier, we just pick a number randomly using <strong class="source-inline">quote_id = randint(1, 100)</strong>. The <strong class="source-inline">add_quotes()</strong> function is defined <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
def add_quotes(quotes_list):
    added = []
    try:
        with sqlite3.connect(DB_PATH) as db:
            cursor = db.cursor()
            for quote_text in quotes_list:
                quote_id = randint(1, 100) # nosec
                quote = (quote_id, quote_text)
                cursor.execute(
                    """INSERT OR IGNORE INTO quotes(id, text) VALUES(?, ?)""", quote
                )
                added.append(quote)
            db.commit()
    except Exception as e:
        print(e)
    return added</pre>			<p>Next, we <a id="_idIndexMarker816"/>add a <strong class="source-inline">main()</strong> function, which in fact will <a id="_idIndexMarker817"/>have several parts; we want to use command-line argument parsing. Note <span class="No-Break">the following:</span></p>
			<ul>
				<li>If we pass the <strong class="source-inline">init</strong> argument, we call the <span class="No-Break"><strong class="source-inline">setup_db()</strong></span><span class="No-Break"> function</span></li>
				<li>If we pass the <strong class="source-inline">update_all</strong> argument, we inject the quotes into the database and add them to <span class="No-Break">the cache</span></li>
				<li>If we pass the <strong class="source-inline">update_db_only</strong> argument, we only inject the quotes into <span class="No-Break">the database</span></li>
			</ul>
			<p>The code of the <strong class="source-inline">main()</strong> function, called when running the Python script, is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
def main():
    msg = "Choose your mode! Enter 'init' or 'update_db_only' or 'update_all': "
    mode = input(msg)
    if mode.lower() == "init":
        setup_db()
    elif mode.lower() == "update_all":
        quotes_list = [fake.sentence() for _ in range(1, 11)]
        added = add_quotes(quotes_list)
        if added:
            print("New (fake) quotes added to the database:")
            for q in added:
                print(f"Added to DB: {q}")
                print("  - Also adding to the cache")
                cache.set(str(q[0]), q[1], ex=60)
    elif mode.lower() == "update_db_only":
        quotes_list = [fake.sentence() for _ in range(1, 11)]
        added = add_quotes(quotes_list)
        if added:
            print("New (fake) quotes added to the database ONLY:")
            for q in added:
                print(f"Added to DB: {q}")</pre>			<p>That<a id="_idIndexMarker818"/> part is done. Now, we will create another module and <a id="_idIndexMarker819"/>script for the cache-aside-related operations themselves (in the <span class="No-Break"><strong class="source-inline">ch08/cache_aside/cache_aside.py</strong></span><span class="No-Break"> file).</span></p>
			<p>We have a few imports needed here too, followed <span class="No-Break">by constants:</span></p>
			<pre class="source-code">
import sqlite3
from pathlib import Path
import redis
CACHE_KEY_PREFIX = "quote"
DB_PATH = Path(__file__).parent / Path("quotes.sqlite3")
cache = redis.StrictRedis(host="localhost", port=6379, decode_responses=True)</pre>			<p>Next, we define a <strong class="source-inline">get_quote()</strong> function to fetch a quote by its identifier. If we do not find the quote in the cache, we query the database to get it and we put the result in the cache<a id="_idIndexMarker820"/> before returning it. The function is defined <a id="_idIndexMarker821"/><span class="No-Break">as follows:</span></p>
			<pre class="source-code">
def get_quote(quote_id: str) -&gt; str:
    out = []
    quote = cache.get(f"{CACHE_KEY_PREFIX}.{quote_id}")
    if quote is None:
        # Get from the database
        query_fmt = "SELECT text FROM quotes WHERE id = {}"
        try:
            with sqlite3.connect(DB_PATH) as db:
                cursor = db.cursor()
                res = cursor.execute(query_fmt.format(quote_id)).fetchone()
                if not res:
                    return "There was no quote stored matching that id!"
                quote = res[0]
                out.append(f"Got '{quote}' FROM DB")
        except Exception as e:
            print(e)
            quote = ""
        # Add to the cache
        if quote:
            key = f"{CACHE_KEY_PREFIX}.{quote_id}"
            cache.set(key, quote, ex=60)
            out.append(f"Added TO CACHE, with key '{key}'")
    else:
        out.append(f"Got '{quote}' FROM CACHE")
    if out:
        return " - ".join(out)
    else:
        return ""</pre>			<p>Finally, in <a id="_idIndexMarker822"/>the main part of the script, we ask for user <a id="_idIndexMarker823"/>input of a quote identifier, and we call <strong class="source-inline">get_quote()</strong> to fetch the quote. The code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
def main():
    while True:
        quote_id = input("Enter the ID of the quote: ")
        if quote_id.isdigit():
            out = get_quote(quote_id)
            print(out)
        else:
            print("You must enter a number. Please retry.")</pre>			<p>Now is the time to test our scripts, using the <span class="No-Break">following steps.</span></p>
			<p>First, by calling <strong class="source-inline">python ch08/cache_aside/populate_db.py</strong>, and choosing <strong class="source-inline">"init"</strong> for the mode option, we can see that a <strong class="source-inline">quotes.sqlite3</strong> file is created (in the <strong class="source-inline">ch08/cache_aside/</strong> folder), so we can conclude the database has been created and a <strong class="source-inline">quotes</strong> table created <span class="No-Break">in it.</span></p>
			<p>Then, we<a id="_idIndexMarker824"/> call <strong class="source-inline">python ch08/cache_aside/populate_db.py</strong> and pass <a id="_idIndexMarker825"/>the <strong class="source-inline">update_all</strong> mode; we get the <span class="No-Break">following output:</span></p>
			<pre class="source-code">
<strong class="bold">Choose your mode! Enter 'init' or 'update_db_only' or 'update_all': update_all</strong>
<strong class="bold">New (fake) quotes added to the database:</strong>
<strong class="bold">Added to DB: (62, 'Instead not here public.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (26, 'Training degree crime serious beyond management and.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (25, 'Agree hour example cover game bed.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (23, 'Dark team exactly really wind.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (46, 'Only loss simple born remain.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (13, 'Clearly statement mean growth executive mean.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (88, 'West policy a human job structure bed.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (25, 'Work maybe back play.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (18, 'Here certain require consumer strategy.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (48, 'Discover method many by hotel.')</strong>
<strong class="bold">- Also adding to the cache</strong></pre>			<p>We can<a id="_idIndexMarker826"/> also call <strong class="source-inline">python ch08/cache_aside/populate_db.py</strong> and<a id="_idIndexMarker827"/> choose the <strong class="source-inline">update_db_only</strong> mode. In that case, we get the <span class="No-Break">following output:</span></p>
			<pre class="source-code">
<strong class="bold">Choose your mode! Enter 'init' or 'update_db_only' or 'update_all': update_db_only</strong>
<strong class="bold">New (fake) quotes added to the database ONLY:</strong>
<strong class="bold">Added to DB: (73, 'Whose determine group what site.')</strong>
<strong class="bold">Added to DB: (77, 'Standard much career either will when chance.')</strong>
<strong class="bold">Added to DB: (5, 'Nature when event appear yeah.')</strong>
<strong class="bold">Added to DB: (81, 'By himself in treat.')</strong>
<strong class="bold">Added to DB: (88, 'Establish deal sometimes stage college everybody close thank.')</strong>
<strong class="bold">Added to DB: (99, 'Room recently authority station relationship our knowledge occur.')</strong>
<strong class="bold">Added to DB: (63, 'Price who a crime garden doctor eat.')</strong>
<strong class="bold">Added to DB: (43, 'Significant hot those think heart shake ago.')</strong>
<strong class="bold">Added to DB: (80, 'Understand and view happy.')</strong>
<strong class="bold">Added to DB: (54, 'Happen some family human involve.')</strong></pre>			<p>Next, we call the <strong class="source-inline">python ch08/cache_aside/cache_aside.py</strong> command, and we are asked for an input to try to fetch the matching quote. Here are the different outputs I got depending on the values <span class="No-Break">I provided:</span></p>
			<pre class="source-code">
<strong class="bold">Enter the ID of the quote: 23</strong>
<strong class="bold">Got 'Dark team exactly really wind.' FROM DB - Added TO CACHE, with key 'quote.23'</strong>
<strong class="bold">Enter the ID of the quote: 12</strong>
<strong class="bold">There was no quote stored matching that id!</strong>
<strong class="bold">Enter the ID of the quote: 43</strong>
<strong class="bold">Got 'Significant hot those think heart shake ago.' FROM DB - Added TO CACHE, with key 'quote.43'</strong>
<strong class="bold">Enter the ID of the quote: 45</strong>
<strong class="bold">There was no quote stored matching that id!</strong>
<strong class="bold">Enter the ID of the quote: 77</strong>
<strong class="bold">Got 'Standard much career either will when chance.' FROM DB - Added TO CACHE, with key 'quote.77'</strong></pre>			<p>So, each time I entered an identifier number that matched a quote stored only in the database (as shown by the previous output), the specific output showed that the data was obtained from the database first, before being returned from the cache (where it was <span class="No-Break">immediately added).</span></p>
			<p>We can <a id="_idIndexMarker828"/>see that things work as expected. The <a id="_idIndexMarker829"/>update part of the cache-aside implementation (to write the item in the database and remove the corresponding entry from the cache) is left to you to try. You could add an <strong class="source-inline">update_quote()</strong> function used to update a quote when you pass <strong class="source-inline">quote_id</strong> to it and call it using the right command line (such as <strong class="source-inline">python </strong><span class="No-Break"><strong class="source-inline">cache_aside.py update</strong></span><span class="No-Break">).</span></p>
			<h1 id="_idParaDest-209"><a id="_idTextAnchor223"/>The Memoization pattern</h1>
			<p>The <strong class="bold">Memoization</strong> pattern is <a id="_idIndexMarker830"/>a crucial optimization technique in software development<a id="_idIndexMarker831"/> that improves the efficiency of programs by caching the results of expensive function calls. This approach ensures that if a function is called with the same inputs more than once, the cached result is returned, eliminating the need for repetitive and <span class="No-Break">costly computations.</span></p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor224"/>Real-world examples</h2>
			<p>We can<a id="_idIndexMarker832"/> think of calculating Fibonacci numbers as a classic example of the memoization pattern. By storing previously computed<a id="_idIndexMarker833"/> values of the sequence, the algorithm avoids recalculating them, which drastically speeds up the computation of higher numbers in <span class="No-Break">the sequence.</span></p>
			<p>Another example is a text search algorithm. In applications dealing with large volumes of text, such as search engines or document analysis tools, caching the results of previous searches means that identical queries can return instant results, significantly improving <span class="No-Break">user experience.</span></p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor225"/>Use cases for the memoization pattern</h2>
			<p>The memoization <a id="_idIndexMarker834"/>pattern can be useful for the following <span class="No-Break">use cases:</span></p>
			<ol>
				<li><strong class="bold">Speeding up recursive algorithms</strong>: Memoization transforms recursive algorithms from having a high time complexity. This is particularly beneficial for algorithms such as those calculating <span class="No-Break">Fibonacci numbers.</span></li>
				<li><strong class="bold">Reducing computational overhead</strong>: Memoization conserves CPU resources by avoiding unnecessary recalculations. This is crucial in resource-constrained environments or when dealing with high-volume <span class="No-Break">data processing.</span></li>
				<li><strong class="bold">Improving application performance</strong>: The direct result of memoization is a noticeable improvement in application performance, making applications feel more responsive and efficient from the <span class="No-Break">user’s perspective.</span></li>
			</ol>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor226"/>Implementing the memoization pattern</h2>
			<p>Let’s discuss an <a id="_idIndexMarker835"/>implementation of the memoization pattern using Python’s <strong class="source-inline">functools.lru_cache</strong> decorator. This tool is particularly effective for functions with expensive computations that are called repeatedly with the same arguments. By caching the results, subsequent calls with the same arguments retrieve the result from the cache, significantly reducing <span class="No-Break">execution time.</span></p>
			<p>For our example, we will apply memoization to a classic problem where a recursive algorithm is used: calculating <span class="No-Break">Fibonacci numbers.</span></p>
			<p>We start with the <strong class="source-inline">import</strong> statements <span class="No-Break">we need:</span></p>
			<pre class="source-code">
from datetime import timedelta
from functools import lru_cache</pre>			<p>Second, we<a id="_idIndexMarker836"/> create a <strong class="source-inline">fibonacci_func1</strong> function <a id="_idIndexMarker837"/>that does the Fibonacci numbers computation using recursion (without any caching involved). We will use this <span class="No-Break">for comparison:</span></p>
			<pre class="source-code">
def fibonacci_func1(n):
    if n &lt; 2:
        return n
    return fibonacci_func1(n - 1) + fibonacci_func1(n - 2)</pre>			<p>Third, we define a <strong class="source-inline">fibonacci_func2</strong> function, with the same code, but this one is decorated with <strong class="source-inline">lru_cache</strong>, to enable memoization. What happens here is that the results of the function calls are stored in a cache in memory, and repeated calls with the same arguments fetch results directly from the cache rather than executing the function’s code. The code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
@lru_cache(maxsize=None)
def fibonacci_func2(n):
    if n &lt; 2:
        return n
    return fibonacci_func2(n - 1) + fibonacci_func2(n - 2)</pre>			<p>Finally, we create a <strong class="source-inline">main()</strong> function to test calling both functions using <strong class="source-inline">n=30</strong> as input and measuring the time spent for each execution. The testing code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
def main():
    import time
    n = 30
    start_time = time.time()
    result = fibonacci_func1(n)
    duration = timedelta(time.time() - start_time)
    print(f"Fibonacci_func1({n}) = {result}, calculated in {duration}")
    start_time = time.time()
    result = fibonacci_func2(n)
    duration = timedelta(time.time() - start_time)
    print(f"Fibonacci_func2({n}) = {result}, calculated in {duration}")</pre>			<p>To test the implementation, run the following command: <strong class="source-inline">python ch08/memoization.py</strong>. You should get an output like the <span class="No-Break">following one:</span></p>
			<pre class="source-code">
<strong class="bold">Fibonacci_func1(30) = 832040, calculated in 7:38:53.090973</strong>
<strong class="bold">Fibonacci_func2(30) = 832040, calculated in 0:00:02.760315</strong></pre>			<p>Of course, the durations you get would probably be different than mine, but the duration for the second function, the one using caching, should be less than the one for the function without caching. Also, the difference between both durations should <span class="No-Break">be important.</span></p>
			<p>This was a <a id="_idIndexMarker838"/>demonstration that memoization <a id="_idIndexMarker839"/>reduces the number of recursive calls needed to calculate Fibonacci numbers, especially for large <strong class="source-inline">n</strong> values. By reducing the computational overhead, memoization not only speeds up calculations but also conserves system resources, leading to a more efficient and <span class="No-Break">responsive application.</span></p>
			<h1 id="_idParaDest-213"><a id="_idTextAnchor227"/>The Lazy Loading pattern</h1>
			<p>The <strong class="bold">Lazy Loading</strong> pattern <a id="_idIndexMarker840"/>is a critical design approach in software engineering, particularly<a id="_idIndexMarker841"/> useful in optimizing performance and resource management. The idea with lazy loading is to defer the initialization or loading of resources to the moment they are really needed. This way, applications can achieve more efficient resource utilization, reduce initial load times, and enhance the overall <span class="No-Break">user experience.</span></p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor228"/>Real-world examples</h2>
			<p>Browsing an <a id="_idIndexMarker842"/>online art gallery provides a first example. Instead of waiting for hundreds of high-resolution images to load upfront, the website loads only images currently in view. As you scroll, additional images load seamlessly, enhancing your browsing experience without overwhelming your device’s memory or <span class="No-Break">network bandwidth.</span></p>
			<p>Another example is an on-demand video streaming service, such as Netflix or YouTube. Such a platform offers an uninterrupted viewing experience by loading videos in chunks. This approach not only minimizes buffering times at the start but also adapts to changing network conditions, ensuring consistent video quality with <span class="No-Break">minimal interruptions.</span></p>
			<p>In applications such as Microsoft Excel or Google Sheets, working with large datasets can be resource-intensive. Lazy loading allows these applications to load only data relevant to your current view or operation, such as a particular sheet or a range of cells. This significantly speeds up operations and reduces <span class="No-Break">memory usage.</span></p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor229"/>Use cases for the lazy loading pattern</h2>
			<p>We can think <a id="_idIndexMarker843"/>of the following performance-related use cases for the lazy <span class="No-Break">loading pattern:</span></p>
			<ol>
				<li><strong class="bold">Reducing initial load time</strong>: This is particularly beneficial in web development, where a shorter load time can translate into improved user engagement and <span class="No-Break">retention rates.</span></li>
				<li><strong class="bold">Conserving system resources</strong>: In an era of diverse devices, from high-end desktops to entry-level smartphones, optimizing resource usage is crucial for delivering a uniform user experience across <span class="No-Break">all platforms.</span></li>
				<li><strong class="bold">Enhancing user experience</strong>: Users expect fast, responsive interactions with software. Lazy <a id="_idIndexMarker844"/>loading contributes to this by minimizing waiting <a id="_idIndexMarker845"/>times and making applications feel <span class="No-Break">more responsive.</span></li>
			</ol>
			<h2 id="_idParaDest-216"><a id="_idTextAnchor230"/>Implementing the lazy loading pattern – lazy attribute loading</h2>
			<p>Consider an <a id="_idIndexMarker846"/>application that performs complex data analysis or generates sophisticated visualizations based on user input. The computation behind this is resource-intensive and time-consuming. Implementing lazy loading, in this case, can drastically improve performance. But for demonstration purposes, we will be less ambitious than the complex data analysis application scenario. We will use a function that simulates an expensive computation and returns a value used for an attribute on <span class="No-Break">a class.</span></p>
			<p>For this lazy loading example, the idea is to have a class that initializes an attribute only when it’s accessed for the first time. This approach is commonly used in scenarios where initializing an attribute is resource-intensive, and you want to postpone this process until <span class="No-Break">it’s necessary.</span></p>
			<p>We start with the initialization part of the <strong class="source-inline">LazyLoadedData</strong> class, where we set the <strong class="source-inline">_data</strong> attribute to <strong class="source-inline">None</strong>. Here, the expensive data hasn’t been <span class="No-Break">loaded yet:</span></p>
			<pre class="source-code">
class LazyLoadedData:
    def __init__(self):
        self._data = None</pre>			<p>We add a <strong class="source-inline">data()</strong> method, decorated with <strong class="source-inline">@property</strong>, making it act like an attribute (a property) with the added logic for lazy loading. Here, we check if <strong class="source-inline">_data</strong> is <strong class="source-inline">None</strong>. If it is, we call the <span class="No-Break"><strong class="source-inline">load_data()</strong></span><span class="No-Break"> method:</span></p>
			<pre class="source-code">
    @property
    def data(self):
        if self._data is None:
            self._data = self.load_data()
        return self._data</pre>			<p>We<a id="_idIndexMarker847"/> add the <strong class="source-inline">load_data()</strong> method simulating an expensive operation, using <strong class="source-inline">sum(i * i for i in range(100000))</strong>. In a<a id="_idIndexMarker848"/> real-world scenario, this could involve fetching data from a remote database, performing a complex calculation, or other <span class="No-Break">resource-intensive tasks:</span></p>
			<pre class="source-code">
    def load_data(self):
        print("Loading expensive data...")
        return sum(i * i for i in range(100000))</pre>			<p>We then add a <strong class="source-inline">main()</strong> function to test the implementation. We create an instance of the <strong class="source-inline">LazyLoadedData</strong> class and access the <strong class="source-inline">_data</strong> <span class="No-Break">attribute twice:</span></p>
			<pre class="source-code">
def main():
    obj = LazyLoadedData()
    print("Object created, expensive attribute not loaded yet.")
    print("Accessing expensive attribute:")
    print(obj.data)
    print("Accessing expensive attribute again, no reloading occurs:")
    print(obj.data)</pre>			<p>To test the implementation, run the <strong class="source-inline">python ch08/lazy_loading/lazy_attribute_loading.py</strong> command. You should get the <span class="No-Break">following output:</span></p>
			<pre class="source-code">
<strong class="bold">Object created, expensive attribute not loaded yet.</strong>
<strong class="bold">Accessing expensive attribute:</strong>
<strong class="bold">Loading expensive data...</strong>
<strong class="bold">333328333350000</strong>
<strong class="bold">Accessing expensive attribute again, no reloading occurs:</strong>
<strong class="bold">333328333350000</strong></pre>			<p>As we can see, on the first access, the expensive data is loaded and stored in <strong class="source-inline">_data</strong>. On subsequent accesses, the data stored is retrieved (from the attribute) without re-performing the <span class="No-Break">expensive operation.</span></p>
			<p>The<a id="_idIndexMarker849"/> lazy loading <a id="_idIndexMarker850"/>pattern, applied this way, is very useful for improving performance in applications where certain data or computations are needed from time to time but are expensive <span class="No-Break">to produce.</span></p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor231"/>Implementing the lazy loading pattern – using caching</h2>
			<p>In this second example, we consider a function that calculates the factorial of a number using recursion, which can become quite expensive computationally as the input number grows. While Python’s <strong class="source-inline">math</strong> module provides a built-in function for calculating factorials efficiently, implementing it recursively serves as a good example of an expensive computation that could benefit from caching. We will use caching with <strong class="source-inline">lru_cache</strong>, as in the previous section, but this time for the purpose of <span class="No-Break">lazy loading.</span></p>
			<p>We start with importing the modules and functions <span class="No-Break">we need:</span></p>
			<pre class="source-code">
import time
from datetime import timedelta
from functools import lru_cache</pre>			<p>Then, we create a <strong class="source-inline">recursive_factorial()</strong> function that calculates the factorial of a number <span class="No-Break"><strong class="source-inline">n</strong></span><span class="No-Break"> recursively:</span></p>
			<pre class="source-code">
def recursive_factorial(n):
    """Calculate factorial (expensive for large n)"""
    if n == 1:
        return 1
    else:
        return n * recursive_factorial(n - 1)</pre>			<p>Third, we create a <strong class="source-inline">cached_factorial()</strong> function that returns the result of calling <strong class="source-inline">recursive_factorial()</strong> and is decorated with <strong class="source-inline">@lru_cache</strong>. This way, if the function is called again with the same arguments, the result is retrieved from the cache instead of being recalculated, significantly reducing <span class="No-Break">computation time:</span></p>
			<pre class="source-code">
@lru_cache(maxsize=128)
def cached_factorial(n):
    return recursive_factorial(n)</pre>			<p>We<a id="_idIndexMarker851"/> create a <strong class="source-inline">main()</strong> function as usual for testing the functions. We call the non-cached function, and then we call the <strong class="source-inline">cached_factorial</strong> function twice, showing the <a id="_idIndexMarker852"/>computation time for each case. The code is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
def main():
    # Testing the performance
    n = 20
    # Without caching
    start_time = time.time()
    print(f"Recursive factorial of {n}: {recursive_factorial(n)}")
    duration = timedelta(time.time() - start_time)
    print(f"Calculation time without caching: {duration}.")
    # With caching
    start_time = time.time()
    print(f"Cached factorial of {n}: {cached_factorial(n)}")
    duration = timedelta(time.time() - start_time)
    print(f"Calculation time with caching: {duration}.")
    start_time = time.time()
    print(f"Cached factorial of {n}, repeated: {cached_factorial(n)}")
    duration = timedelta(time.time() - start_time)
    print(f"Second calculation time with caching: {duration}.")</pre>			<p>To test the implementation, run the <strong class="source-inline">python ch08/lazy_loading/lazy_loading_with_caching.py</strong> command. You should get the <span class="No-Break">following output:</span></p>
			<pre class="source-code">
<strong class="bold">Recursive factorial of 20: 2432902008176640000</strong>
<strong class="bold">Calculation time without caching: 0:00:04.840851</strong>
<strong class="bold">Cached factorial of 20: 2432902008176640000</strong>
<strong class="bold">Calculation time with caching: 0:00:00.865173</strong>
<strong class="bold">Cached factorial of 20, repeated: 2432902008176640000</strong>
<strong class="bold">Second calculation time with caching: 0:00:00.350189</strong></pre>			<p>You will<a id="_idIndexMarker853"/> notice the time taken for the initial calculation of the factorial without<a id="_idIndexMarker854"/> caching, then the time with caching, and finally, the time for a repeated calculation <span class="No-Break">with caching.</span></p>
			<p>Also, <strong class="source-inline">lru_cache</strong> is inherently a memoization tool, but it can be adapted and used in cases where, for example, there are expensive initialization processes that need to be executed only when required and not make the application slow. In our example, we used factorial computation to simulate such <span class="No-Break">expensive processes.</span></p>
			<p>If you are asking yourself what is the difference from memoization, the answer is that the context in which caching is used here is for managing <span class="No-Break">resource initialization.</span></p>
			<h1 id="_idParaDest-218"><a id="_idTextAnchor232"/>Summary</h1>
			<p>Throughout this chapter, we have explored patterns that developers can use to enhance the efficiency and scalability <span class="No-Break">of applications.</span></p>
			<p>The cache-aside pattern teaches us how to manage cache effectively, ensuring data is fetched and stored in a manner that optimizes performance and consistency, particularly in environments with dynamic <span class="No-Break">data sources.</span></p>
			<p>The memoization pattern demonstrates the power of caching function results to speed up applications by avoiding redundant computations. This pattern is beneficial for expensive, repeatable operations and can dramatically improve the performance of recursive algorithms and <span class="No-Break">complex calculations.</span></p>
			<p>Finally, the lazy loading pattern emphasizes delaying the initialization of resources until they are needed. This approach not only improves the startup time of applications but also reduces memory overhead, making it ideal for resource-intensive operations that may not always be necessary for the <span class="No-Break">user’s interactions.</span></p>
			<p>In the next chapter, we are going to discuss patterns that govern <span class="No-Break">distributed systems.</span></p>
		</div>
	</body></html>