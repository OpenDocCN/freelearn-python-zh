<html><head></head><body>
		<div><h1 id="_idParaDest-202" class="chapter-number"><a id="_idTextAnchor216"/>8</h1>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor217"/>Performance Patterns</h1>
			<p>In the previous chapter, we covered concurrency and asynchronous patterns, useful for writing efficient software that can handle multiple tasks at once. Next, we are going to discuss specific performance patterns that help enhance the speed and resource utilization of applications.</p>
			<p>Performance patterns<a id="_idIndexMarker803"/> address common bottlenecks and optimization challenges, providing developers with proven methodologies to improve execution time, reduce memory usage, and scale effectively.</p>
			<p>In this chapter, we’re going to cover the following main topics:</p>
			<ul>
				<li>The Cache-Aside pattern</li>
				<li>The Memoization pattern</li>
				<li>The Lazy Loading pattern</li>
			</ul>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor218"/>Technical requirements</h1>
			<p>See the requirements presented in <a href="B21896_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>. The additional technical requirements for the code discussed in this chapter are the following:</p>
			<ul>
				<li>Add the <code>Faker</code> module to your Python environment using the following command: <code>python -m pip </code><code>install faker</code></li>
				<li>Add the <code>Redis</code> module to your Python environment using the following command: <code>python -m pip </code><code>install redis</code></li>
				<li>Install the Redis server and run it using Docker: <code>docker run --name myredis -p </code><code>6379:6379 redis</code><p class="list-inset">If needed, follow the documentation at <a href="https://redis.io/docs/latest/">https://redis.io/docs/latest/</a><a href="https://redis.io/docs&#13;"/></p></li>
			</ul>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor219"/>The Cache-Aside pattern</h1>
			<p>In<a id="_idIndexMarker804"/> situations where data is more frequently <a id="_idIndexMarker805"/>read than updated, applications use a cache to optimize repeated access to information stored in a database or data store. In some systems, that type of caching mechanism is built in and works automatically. When this is not the case, we must implement it in the application ourselves, using a caching strategy that is suitable for the particular use case.</p>
			<p>One such strategy is called <strong class="bold">Cache-Aside</strong>, where, to improve performance, we store frequently accessed data in a cache, reducing the need to fetch data from the data store repeatedly.</p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor220"/>Real-world examples</h2>
			<p>We <a id="_idIndexMarker806"/>can cite the following examples in the software realm:</p>
			<ul>
				<li>Memcached is commonly used as a cache server. It is a popular in-memory key-value store for small chunks of data from the results of database calls, API calls, or HTML page content.</li>
				<li>Redis is another server solution that is used for cache. Nowadays, it is my go-to server for caching or application in-memory storage use cases where it shines.</li>
				<li>Amazon’s ElastiCache, according to<a id="_idIndexMarker807"/> the documentation site (<a href="https://docs.aws.amazon.com/elasticache/">https://docs.aws.amazon.com/elasticache/</a>), is a web service that makes it easy to set up, manage, and scale a distributed in-memory data store or cache environment in the cloud.</li>
			</ul>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor221"/>Use cases for the cache-aside pattern</h2>
			<p>The cache-aside pattern<a id="_idIndexMarker808"/> is useful when we need to reduce the database load in our application. By caching frequently accessed data, fewer queries are sent to the database. It also helps improve application responsiveness, since cached data can be retrieved faster.</p>
			<p>Note that this pattern works for data that doesn’t change often and for data storage that doesn’t depend on the consistency of a set of entries in the storage (multiple keys). For example, it might work for certain kinds of document stores or databases where keys are never updated and occasionally data entries are deleted but there is no strong requirement to <a id="_idIndexMarker809"/>continue to serve them for some time (until the cache is refreshed).</p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor222"/>Implementing the cache-aside pattern</h2>
			<p>We <a id="_idIndexMarker810"/>can summarize the steps needed when implementing<a id="_idIndexMarker811"/> the Cache-Aside pattern, involving a database and a cache, as follows:</p>
			<ul>
				<li><strong class="bold">Case 1 – When we want to fetch a data item</strong>: Return the item from the cache if found in it. If not found in the cache, read the data from the database. Put the item we got in the cache and return it.</li>
				<li><strong class="bold">Case 2 – When we want to update a data item</strong>: Write the item in the database and remove the corresponding entry from the cache.</li>
			</ul>
			<p>Let’s try a simple implementation with a database of quotes from which the user can ask to retrieve some quotes via an application. Our focus here will be implementing the <em class="italic">Case </em><em class="italic">1</em> part.</p>
			<p>Here are our choices for the additional software dependencies we need to install on the machine for this implementation:</p>
			<ul>
				<li>An SQLite database, since we can query an SQLite database using Python’s standard module, <code>sqlite3</code></li>
				<li>A Redis server and the <code>redis-py</code> Python module</li>
			</ul>
			<p>We will use a script (in the <code>ch08/cache_aside/populate_db.py</code> file) to handle the creation of a database and a <code>quotes</code> table and add example data to it. For practical reasons, we also use the <code>Faker</code> module there to generate fake quotes that are used when populating the database.</p>
			<p>Our code starts with the imports we need, followed by the creation of the Faker instance that we will use to generate fake quotes, as well as some constants or module-level variables:</p>
			<pre class="source-code">
import sqlite3
from pathlib import Path
from random import randint
import redis
from faker import Faker
fake = Faker()
DB_PATH = Path(__file__).parent / Path("quotes.sqlite3")
cache = redis.StrictRedis(host="localhost", port=6379, decode_responses=True)</pre>			<p>Then, we <a id="_idIndexMarker812"/>write a function to take care of the database<a id="_idIndexMarker813"/> setup part, as follows:</p>
			<pre class="source-code">
def setup_db():
    try:
        with sqlite3.connect(DB_PATH) as db:
            cursor = db.cursor()
            cursor.execute(
                """
                CREATE TABLE quotes(id INTEGER PRIMARY KEY, text TEXT)
            """
            )
            db.commit()
            print("Table 'quotes' created")
    except Exception as e:
        print(e)</pre>			<p>Then, we <a id="_idIndexMarker814"/>define a central function that takes care of <a id="_idIndexMarker815"/>adding a set of new quotes based on a list of sentences or text snippets. Among different things, we associate a quote identifier to the quote, for the <code>id</code> column in the database table. To make things easier, we just pick a number randomly using <code>quote_id = randint(1, 100)</code>. The <code>add_quotes()</code> function is defined as follows:</p>
			<pre class="source-code">
def add_quotes(quotes_list):
    added = []
    try:
        with sqlite3.connect(DB_PATH) as db:
            cursor = db.cursor()
            for quote_text in quotes_list:
                quote_id = randint(1, 100) # nosec
                quote = (quote_id, quote_text)
                cursor.execute(
                    """INSERT OR IGNORE INTO quotes(id, text) VALUES(?, ?)""", quote
                )
                added.append(quote)
            db.commit()
    except Exception as e:
        print(e)
    return added</pre>			<p>Next, we <a id="_idIndexMarker816"/>add a <code>main()</code> function, which in fact will <a id="_idIndexMarker817"/>have several parts; we want to use command-line argument parsing. Note the following:</p>
			<ul>
				<li>If we pass the <code>init</code> argument, we call the <code>setup_db()</code> function</li>
				<li>If we pass the <code>update_all</code> argument, we inject the quotes into the database and add them to the cache</li>
				<li>If we pass the <code>update_db_only</code> argument, we only inject the quotes into the database</li>
			</ul>
			<p>The code of the <code>main()</code> function, called when running the Python script, is as follows:</p>
			<pre class="source-code">
def main():
    msg = "Choose your mode! Enter 'init' or 'update_db_only' or 'update_all': "
    mode = input(msg)
    if mode.lower() == "init":
        setup_db()
    elif mode.lower() == "update_all":
        quotes_list = [fake.sentence() for _ in range(1, 11)]
        added = add_quotes(quotes_list)
        if added:
            print("New (fake) quotes added to the database:")
            for q in added:
                print(f"Added to DB: {q}")
                print("  - Also adding to the cache")
                cache.set(str(q[0]), q[1], ex=60)
    elif mode.lower() == "update_db_only":
        quotes_list = [fake.sentence() for _ in range(1, 11)]
        added = add_quotes(quotes_list)
        if added:
            print("New (fake) quotes added to the database ONLY:")
            for q in added:
                print(f"Added to DB: {q}")</pre>			<p>That<a id="_idIndexMarker818"/> part is done. Now, we will create another module and <a id="_idIndexMarker819"/>script for the cache-aside-related operations themselves (in the <code>ch08/cache_aside/cache_aside.py</code> file).</p>
			<p>We have a few imports needed here too, followed by constants:</p>
			<pre class="source-code">
import sqlite3
from pathlib import Path
import redis
CACHE_KEY_PREFIX = "quote"
DB_PATH = Path(__file__).parent / Path("quotes.sqlite3")
cache = redis.StrictRedis(host="localhost", port=6379, decode_responses=True)</pre>			<p>Next, we define a <code>get_quote()</code> function to fetch a quote by its identifier. If we do not find the quote in the cache, we query the database to get it and we put the result in the cache<a id="_idIndexMarker820"/> before returning it. The function is defined <a id="_idIndexMarker821"/>as follows:</p>
			<pre class="source-code">
def get_quote(quote_id: str) -&gt; str:
    out = []
    quote = cache.get(f"{CACHE_KEY_PREFIX}.{quote_id}")
    if quote is None:
        # Get from the database
        query_fmt = "SELECT text FROM quotes WHERE id = {}"
        try:
            with sqlite3.connect(DB_PATH) as db:
                cursor = db.cursor()
                res = cursor.execute(query_fmt.format(quote_id)).fetchone()
                if not res:
                    return "There was no quote stored matching that id!"
                quote = res[0]
                out.append(f"Got '{quote}' FROM DB")
        except Exception as e:
            print(e)
            quote = ""
        # Add to the cache
        if quote:
            key = f"{CACHE_KEY_PREFIX}.{quote_id}"
            cache.set(key, quote, ex=60)
            out.append(f"Added TO CACHE, with key '{key}'")
    else:
        out.append(f"Got '{quote}' FROM CACHE")
    if out:
        return " - ".join(out)
    else:
        return ""</pre>			<p>Finally, in <a id="_idIndexMarker822"/>the main part of the script, we ask for user <a id="_idIndexMarker823"/>input of a quote identifier, and we call <code>get_quote()</code> to fetch the quote. The code is as follows:</p>
			<pre class="source-code">
def main():
    while True:
        quote_id = input("Enter the ID of the quote: ")
        if quote_id.isdigit():
            out = get_quote(quote_id)
            print(out)
        else:
            print("You must enter a number. Please retry.")</pre>			<p>Now is the time to test our scripts, using the following steps.</p>
			<p>First, by calling <code>python ch08/cache_aside/populate_db.py</code>, and choosing <code>"init"</code> for the mode option, we can see that a <code>quotes.sqlite3</code> file is created (in the <code>ch08/cache_aside/</code> folder), so we can conclude the database has been created and a <code>quotes</code> table created in it.</p>
			<p>Then, we<a id="_idIndexMarker824"/> call <code>python ch08/cache_aside/populate_db.py</code> and pass <a id="_idIndexMarker825"/>the <code>update_all</code> mode; we get the following output:</p>
			<pre class="source-code">
<strong class="bold">Choose your mode! Enter 'init' or 'update_db_only' or 'update_all': update_all</strong>
<strong class="bold">New (fake) quotes added to the database:</strong>
<strong class="bold">Added to DB: (62, 'Instead not here public.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (26, 'Training degree crime serious beyond management and.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (25, 'Agree hour example cover game bed.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (23, 'Dark team exactly really wind.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (46, 'Only loss simple born remain.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (13, 'Clearly statement mean growth executive mean.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (88, 'West policy a human job structure bed.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (25, 'Work maybe back play.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (18, 'Here certain require consumer strategy.')</strong>
<strong class="bold">- Also adding to the cache</strong>
<strong class="bold">Added to DB: (48, 'Discover method many by hotel.')</strong>
<code>python ch08/cache_aside/populate_db.py</code> and<a id="_idIndexMarker827"/> choose the <code>update_db_only</code> mode. In that case, we get the following output:</p>
			<pre class="source-code">
<strong class="bold">Choose your mode! Enter 'init' or 'update_db_only' or 'update_all': update_db_only</strong>
<strong class="bold">New (fake) quotes added to the database ONLY:</strong>
<strong class="bold">Added to DB: (73, 'Whose determine group what site.')</strong>
<strong class="bold">Added to DB: (77, 'Standard much career either will when chance.')</strong>
<strong class="bold">Added to DB: (5, 'Nature when event appear yeah.')</strong>
<strong class="bold">Added to DB: (81, 'By himself in treat.')</strong>
<strong class="bold">Added to DB: (88, 'Establish deal sometimes stage college everybody close thank.')</strong>
<strong class="bold">Added to DB: (99, 'Room recently authority station relationship our knowledge occur.')</strong>
<strong class="bold">Added to DB: (63, 'Price who a crime garden doctor eat.')</strong>
<strong class="bold">Added to DB: (43, 'Significant hot those think heart shake ago.')</strong>
<strong class="bold">Added to DB: (80, 'Understand and view happy.')</strong>
<code>python ch08/cache_aside/cache_aside.py</code> command, and we are asked for an input to try to fetch the matching quote. Here are the different outputs I got depending on the values I provided:</p>
			<pre class="source-code">
<strong class="bold">Enter the ID of the quote: 23</strong>
<strong class="bold">Got 'Dark team exactly really wind.' FROM DB - Added TO CACHE, with key 'quote.23'</strong>
<strong class="bold">Enter the ID of the quote: 12</strong>
<strong class="bold">There was no quote stored matching that id!</strong>
<strong class="bold">Enter the ID of the quote: 43</strong>
<strong class="bold">Got 'Significant hot those think heart shake ago.' FROM DB - Added TO CACHE, with key 'quote.43'</strong>
<strong class="bold">Enter the ID of the quote: 45</strong>
<strong class="bold">There was no quote stored matching that id!</strong>
<strong class="bold">Enter the ID of the quote: 77</strong>
<strong class="bold">Got 'Standard much career either will when chance.' FROM DB - Added TO CACHE, with key 'quote.77'</strong></pre>			<p>So, each time I entered an identifier number that matched a quote stored only in the database (as shown by the previous output), the specific output showed that the data was obtained from the database first, before being returned from the cache (where it was immediately added).</p>
			<p>We can <a id="_idIndexMarker828"/>see that things work as expected. The <a id="_idIndexMarker829"/>update part of the cache-aside implementation (to write the item in the database and remove the corresponding entry from the cache) is left to you to try. You could add an <code>update_quote()</code> function used to update a quote when you pass <code>quote_id</code> to it and call it using the right command line (such as <code>python </code><code>cache_aside.py update</code>).</p>
			<h1 id="_idParaDest-209"><a id="_idTextAnchor223"/>The Memoization pattern</h1>
			<p>The <strong class="bold">Memoization</strong> pattern is <a id="_idIndexMarker830"/>a crucial optimization technique in software development<a id="_idIndexMarker831"/> that improves the efficiency of programs by caching the results of expensive function calls. This approach ensures that if a function is called with the same inputs more than once, the cached result is returned, eliminating the need for repetitive and costly computations.</p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor224"/>Real-world examples</h2>
			<p>We can<a id="_idIndexMarker832"/> think of calculating Fibonacci numbers as a classic example of the memoization pattern. By storing previously computed<a id="_idIndexMarker833"/> values of the sequence, the algorithm avoids recalculating them, which drastically speeds up the computation of higher numbers in the sequence.</p>
			<p>Another example is a text search algorithm. In applications dealing with large volumes of text, such as search engines or document analysis tools, caching the results of previous searches means that identical queries can return instant results, significantly improving user experience.</p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor225"/>Use cases for the memoization pattern</h2>
			<p>The memoization <a id="_idIndexMarker834"/>pattern can be useful for the following use cases:</p>
			<ol>
				<li><strong class="bold">Speeding up recursive algorithms</strong>: Memoization transforms recursive algorithms from having a high time complexity. This is particularly beneficial for algorithms such as those calculating Fibonacci numbers.</li>
				<li><strong class="bold">Reducing computational overhead</strong>: Memoization conserves CPU resources by avoiding unnecessary recalculations. This is crucial in resource-constrained environments or when dealing with high-volume data processing.</li>
				<li><strong class="bold">Improving application performance</strong>: The direct result of memoization is a noticeable improvement in application performance, making applications feel more responsive and efficient from the user’s perspective.</li>
			</ol>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor226"/>Implementing the memoization pattern</h2>
			<p>Let’s discuss an <a id="_idIndexMarker835"/>implementation of the memoization pattern using Python’s <code>functools.lru_cache</code> decorator. This tool is particularly effective for functions with expensive computations that are called repeatedly with the same arguments. By caching the results, subsequent calls with the same arguments retrieve the result from the cache, significantly reducing execution time.</p>
			<p>For our example, we will apply memoization to a classic problem where a recursive algorithm is used: calculating Fibonacci numbers.</p>
			<p>We start with the <code>import</code> statements we need:</p>
			<pre class="source-code">
from datetime import timedelta
from functools import lru_cache</pre>			<p>Second, we<a id="_idIndexMarker836"/> create a <code>fibonacci_func1</code> function <a id="_idIndexMarker837"/>that does the Fibonacci numbers computation using recursion (without any caching involved). We will use this for comparison:</p>
			<pre class="source-code">
def fibonacci_func1(n):
    if n &lt; 2:
        return n
    return fibonacci_func1(n - 1) + fibonacci_func1(n - 2)</pre>			<p>Third, we define a <code>fibonacci_func2</code> function, with the same code, but this one is decorated with <code>lru_cache</code>, to enable memoization. What happens here is that the results of the function calls are stored in a cache in memory, and repeated calls with the same arguments fetch results directly from the cache rather than executing the function’s code. The code is as follows:</p>
			<pre class="source-code">
@lru_cache(maxsize=None)
def fibonacci_func2(n):
    if n &lt; 2:
        return n
    return fibonacci_func2(n - 1) + fibonacci_func2(n - 2)</pre>			<p>Finally, we create a <code>main()</code> function to test calling both functions using <code>n=30</code> as input and measuring the time spent for each execution. The testing code is as follows:</p>
			<pre class="source-code">
def main():
    import time
    n = 30
    start_time = time.time()
    result = fibonacci_func1(n)
    duration = timedelta(time.time() - start_time)
    print(f"Fibonacci_func1({n}) = {result}, calculated in {duration}")
    start_time = time.time()
    result = fibonacci_func2(n)
    duration = timedelta(time.time() - start_time)
    print(f"Fibonacci_func2({n}) = {result}, calculated in {duration}")</pre>			<p>To test the implementation, run the following command: <code>python ch08/memoization.py</code>. You should get an output like the following one:</p>
			<pre class="source-code">
<strong class="bold">Fibonacci_func1(30) = 832040, calculated in 7:38:53.090973</strong>
<strong class="bold">Fibonacci_func2(30) = 832040, calculated in 0:00:02.760315</strong></pre>			<p>Of course, the durations you get would probably be different than mine, but the duration for the second function, the one using caching, should be less than the one for the function without caching. Also, the difference between both durations should be important.</p>
			<p>This was a <a id="_idIndexMarker838"/>demonstration that memoization <a id="_idIndexMarker839"/>reduces the number of recursive calls needed to calculate Fibonacci numbers, especially for large <code>n</code> values. By reducing the computational overhead, memoization not only speeds up calculations but also conserves system resources, leading to a more efficient and responsive application.</p>
			<h1 id="_idParaDest-213"><a id="_idTextAnchor227"/>The Lazy Loading pattern</h1>
			<p>The <strong class="bold">Lazy Loading</strong> pattern <a id="_idIndexMarker840"/>is a critical design approach in software engineering, particularly<a id="_idIndexMarker841"/> useful in optimizing performance and resource management. The idea with lazy loading is to defer the initialization or loading of resources to the moment they are really needed. This way, applications can achieve more efficient resource utilization, reduce initial load times, and enhance the overall user experience.</p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor228"/>Real-world examples</h2>
			<p>Browsing an <a id="_idIndexMarker842"/>online art gallery provides a first example. Instead of waiting for hundreds of high-resolution images to load upfront, the website loads only images currently in view. As you scroll, additional images load seamlessly, enhancing your browsing experience without overwhelming your device’s memory or network bandwidth.</p>
			<p>Another example is an on-demand video streaming service, such as Netflix or YouTube. Such a platform offers an uninterrupted viewing experience by loading videos in chunks. This approach not only minimizes buffering times at the start but also adapts to changing network conditions, ensuring consistent video quality with minimal interruptions.</p>
			<p>In applications such as Microsoft Excel or Google Sheets, working with large datasets can be resource-intensive. Lazy loading allows these applications to load only data relevant to your current view or operation, such as a particular sheet or a range of cells. This significantly speeds up operations and reduces memory usage.</p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor229"/>Use cases for the lazy loading pattern</h2>
			<p>We can think <a id="_idIndexMarker843"/>of the following performance-related use cases for the lazy loading pattern:</p>
			<ol>
				<li><strong class="bold">Reducing initial load time</strong>: This is particularly beneficial in web development, where a shorter load time can translate into improved user engagement and retention rates.</li>
				<li><strong class="bold">Conserving system resources</strong>: In an era of diverse devices, from high-end desktops to entry-level smartphones, optimizing resource usage is crucial for delivering a uniform user experience across all platforms.</li>
				<li><strong class="bold">Enhancing user experience</strong>: Users expect fast, responsive interactions with software. Lazy <a id="_idIndexMarker844"/>loading contributes to this by minimizing waiting <a id="_idIndexMarker845"/>times and making applications feel more responsive.</li>
			</ol>
			<h2 id="_idParaDest-216"><a id="_idTextAnchor230"/>Implementing the lazy loading pattern – lazy attribute loading</h2>
			<p>Consider an <a id="_idIndexMarker846"/>application that performs complex data analysis or generates sophisticated visualizations based on user input. The computation behind this is resource-intensive and time-consuming. Implementing lazy loading, in this case, can drastically improve performance. But for demonstration purposes, we will be less ambitious than the complex data analysis application scenario. We will use a function that simulates an expensive computation and returns a value used for an attribute on a class.</p>
			<p>For this lazy loading example, the idea is to have a class that initializes an attribute only when it’s accessed for the first time. This approach is commonly used in scenarios where initializing an attribute is resource-intensive, and you want to postpone this process until it’s necessary.</p>
			<p>We start with the initialization part of the <code>LazyLoadedData</code> class, where we set the <code>_data</code> attribute to <code>None</code>. Here, the expensive data hasn’t been loaded yet:</p>
			<pre class="source-code">
class LazyLoadedData:
    def __init__(self):
        self._data = None</pre>			<p>We add a <code>data()</code> method, decorated with <code>@property</code>, making it act like an attribute (a property) with the added logic for lazy loading. Here, we check if <code>_data</code> is <code>None</code>. If it is, we call the <code>load_data()</code> method:</p>
			<pre class="source-code">
    @property
    def data(self):
        if self._data is None:
            self._data = self.load_data()
        return self._data</pre>			<p>We<a id="_idIndexMarker847"/> add the <code>load_data()</code> method simulating an expensive operation, using <code>sum(i * i for i in range(100000))</code>. In a<a id="_idIndexMarker848"/> real-world scenario, this could involve fetching data from a remote database, performing a complex calculation, or other resource-intensive tasks:</p>
			<pre class="source-code">
    def load_data(self):
        print("Loading expensive data...")
        return sum(i * i for i in range(100000))</pre>			<p>We then add a <code>main()</code> function to test the implementation. We create an instance of the <code>LazyLoadedData</code> class and access the <code>_data</code> attribute twice:</p>
			<pre class="source-code">
def main():
    obj = LazyLoadedData()
    print("Object created, expensive attribute not loaded yet.")
    print("Accessing expensive attribute:")
    print(obj.data)
    print("Accessing expensive attribute again, no reloading occurs:")
    print(obj.data)</pre>			<p>To test the implementation, run the <code>python ch08/lazy_loading/lazy_attribute_loading.py</code> command. You should get the following output:</p>
			<pre class="source-code">
<strong class="bold">Object created, expensive attribute not loaded yet.</strong>
<strong class="bold">Accessing expensive attribute:</strong>
<strong class="bold">Loading expensive data...</strong>
<strong class="bold">333328333350000</strong>
<strong class="bold">Accessing expensive attribute again, no reloading occurs:</strong>
<code>_data</code>. On subsequent accesses, the data stored is retrieved (from the attribute) without re-performing the expensive operation.</p>
			<p>The<a id="_idIndexMarker849"/> lazy loading <a id="_idIndexMarker850"/>pattern, applied this way, is very useful for improving performance in applications where certain data or computations are needed from time to time but are expensive to produce.</p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor231"/>Implementing the lazy loading pattern – using caching</h2>
			<p>In this second example, we consider a function that calculates the factorial of a number using recursion, which can become quite expensive computationally as the input number grows. While Python’s <code>math</code> module provides a built-in function for calculating factorials efficiently, implementing it recursively serves as a good example of an expensive computation that could benefit from caching. We will use caching with <code>lru_cache</code>, as in the previous section, but this time for the purpose of lazy loading.</p>
			<p>We start with importing the modules and functions we need:</p>
			<pre class="source-code">
import time
from datetime import timedelta
from functools import lru_cache</pre>			<p>Then, we create a <code>recursive_factorial()</code> function that calculates the factorial of a number <code>n</code> recursively:</p>
			<pre class="source-code">
def recursive_factorial(n):
    """Calculate factorial (expensive for large n)"""
    if n == 1:
        return 1
    else:
        return n * recursive_factorial(n - 1)</pre>			<p>Third, we create a <code>cached_factorial()</code> function that returns the result of calling <code>recursive_factorial()</code> and is decorated with <code>@lru_cache</code>. This way, if the function is called again with the same arguments, the result is retrieved from the cache instead of being recalculated, significantly reducing computation time:</p>
			<pre class="source-code">
@lru_cache(maxsize=128)
def cached_factorial(n):
    return recursive_factorial(n)</pre>			<p>We<a id="_idIndexMarker851"/> create a <code>main()</code> function as usual for testing the functions. We call the non-cached function, and then we call the <code>cached_factorial</code> function twice, showing the <a id="_idIndexMarker852"/>computation time for each case. The code is as follows:</p>
			<pre class="source-code">
def main():
    # Testing the performance
    n = 20
    # Without caching
    start_time = time.time()
    print(f"Recursive factorial of {n}: {recursive_factorial(n)}")
    duration = timedelta(time.time() - start_time)
    print(f"Calculation time without caching: {duration}.")
    # With caching
    start_time = time.time()
    print(f"Cached factorial of {n}: {cached_factorial(n)}")
    duration = timedelta(time.time() - start_time)
    print(f"Calculation time with caching: {duration}.")
    start_time = time.time()
    print(f"Cached factorial of {n}, repeated: {cached_factorial(n)}")
    duration = timedelta(time.time() - start_time)
    print(f"Second calculation time with caching: {duration}.")</pre>			<p>To test the implementation, run the <code>python ch08/lazy_loading/lazy_loading_with_caching.py</code> command. You should get the following output:</p>
			<pre class="source-code">
<strong class="bold">Recursive factorial of 20: 2432902008176640000</strong>
<strong class="bold">Calculation time without caching: 0:00:04.840851</strong>
<strong class="bold">Cached factorial of 20: 2432902008176640000</strong>
<strong class="bold">Calculation time with caching: 0:00:00.865173</strong>
<strong class="bold">Cached factorial of 20, repeated: 2432902008176640000</strong>
<strong class="bold">Second calculation time with caching: 0:00:00.350189</strong></pre>			<p>You will<a id="_idIndexMarker853"/> notice the time taken for the initial calculation of the factorial without<a id="_idIndexMarker854"/> caching, then the time with caching, and finally, the time for a repeated calculation with caching.</p>
			<p>Also, <code>lru_cache</code> is inherently a memoization tool, but it can be adapted and used in cases where, for example, there are expensive initialization processes that need to be executed only when required and not make the application slow. In our example, we used factorial computation to simulate such expensive processes.</p>
			<p>If you are asking yourself what is the difference from memoization, the answer is that the context in which caching is used here is for managing resource initialization.</p>
			<h1 id="_idParaDest-218"><a id="_idTextAnchor232"/>Summary</h1>
			<p>Throughout this chapter, we have explored patterns that developers can use to enhance the efficiency and scalability of applications.</p>
			<p>The cache-aside pattern teaches us how to manage cache effectively, ensuring data is fetched and stored in a manner that optimizes performance and consistency, particularly in environments with dynamic data sources.</p>
			<p>The memoization pattern demonstrates the power of caching function results to speed up applications by avoiding redundant computations. This pattern is beneficial for expensive, repeatable operations and can dramatically improve the performance of recursive algorithms and complex calculations.</p>
			<p>Finally, the lazy loading pattern emphasizes delaying the initialization of resources until they are needed. This approach not only improves the startup time of applications but also reduces memory overhead, making it ideal for resource-intensive operations that may not always be necessary for the user’s interactions.</p>
			<p>In the next chapter, we are going to discuss patterns that govern distributed systems.</p>
		</div>
	</body></html>