- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Abstract Base Classes and Operator Overloading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We often need to make a distinction between concrete classes that have a complete
    set of attributes and methods, and an abstract class that is missing some details.
    This parallels the philosophical idea of abstraction as a way to summarize complexities.
    We might say that a sailboat and an airplane have a common, abstract relationship
    of being vehicles, but the details of how they move are distinct.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, we have two approaches to defining similar things:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Duck typing**: When two class definitions have the same attributes and methods,
    then instances of the two classes have the same protocol and can be used interchangeably.
    We often say, "When I see a bird that walks like a duck and swims like a duck and
    quacks like a duck, I call that bird a duck."'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inheritance**: When two class definitions have common aspects, a subclass
    can share common features of a superclass. The implementation details of the two
    classes may vary, but the classes should be interchangeable when we use the common
    features defined by the superclass.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can take inheritance one step further. We can have superclass definitions
    that are abstract: this means they aren''t directly useable by themselves, but
    can be used through inheritance to create concrete classes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have to acknowledge a terminology problem around the terms *base class*
    and *superclass*. This is confusing because they''re synonyms. There are two parallel
    metaphors here, and we flip back and forth between them. Sometimes, we''ll use
    the "base class is a foundation" metaphor, where another class builds on it via
    inheritance. Other times, we''ll use the "concrete class extends a superclass"
    metaphor. The "super" class is superior to the concrete class; it''s typically
    drawn above it on a UML class diagram, and it needs to be defined first. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17070_06_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: Abstract base class'
  prefs: []
  type: TYPE_NORMAL
- en: Our base class, named `BaseClass` here, has a special class, `abc.ABC`, as a
    parent class. This provides some special metaclass features that help make sure
    the concrete classes have replaced the abstractions. In this diagram, we have
    added a big "A" circle to mark the class as abstract. This bit of decoration is
    optional, and often unhelpful, so we won't use it in other diagrams. The slanted
    font is another hint that the class is abstract.
  prefs: []
  type: TYPE_NORMAL
- en: The diagram shows an abstract method, `a_method()`, which doesn't have a defined
    body. A subclass must provide this. Again, a slanted font is used for the method
    name to provide a hint that it's abstract. The two concrete subclasses provide
    this missing method.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an abstract base class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ABCs and type hints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `collections.abc` module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating your own abstract base class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demystifying the magic – looking under the hood at the implementation of an
    ABC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operator overloading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extending built-ins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metaclasses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The case study in this chapter will build on the case study material in previous
    chapters. We'll be able to look closely at different ways to partition data among
    training sets and testing sets.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start by looking at how we use an abstract class and create a concrete
    class from it.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an abstract base class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine we are creating a media player with third-party plugins. It is advisable
    to create an abstract base class (ABC) in this case to document what API the third-party
    plugins should provide (documentation is one of the stronger use cases for ABCs).
  prefs: []
  type: TYPE_NORMAL
- en: The general design is to have a common feature, like `play()`, that applies
    to a number of classes. We don't want to pick some particular media format to
    use as a superclass; it seems somehow wrong to claim that some format is foundational,
    and all others are derived from it.
  prefs: []
  type: TYPE_NORMAL
- en: We'd prefer to define the media player as an *abstraction*. Each unique kind
    of media file format can provide a *concrete* implementation of the abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `abc` module provides the tools to do this. Here''s an abstract class that
    requires a subclass to provide a concrete method and a concrete property to be
    useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `abc.ABC` class introduces a **metaclass** – a class used to build the concrete
    class definitions. Python's default metaclass is named `type`. The default metaclass
    doesn't check for abstract methods when we try to create an instance. The `abc.ABC`
    class includes an extension to the `type` metaclass to prevent us from creating
    instances of classes that are not fully defined.
  prefs: []
  type: TYPE_NORMAL
- en: There are two decorators used to describe the placeholders in the abstraction.
    The example shows `@abc.abstractmethod` and a combination of `@property` and `@abc.abstractmethod`.
    Python uses decorators widely to make modifications to the general nature of the
    method or function. In this case, it provides additional details used by the metaclass
    that was included by the `ABC` class. Because we marked a method or property as
    abstract, any subclass of this class must implement that method or property in
    order to be a useful, concrete implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The bodies of the methods are actually `...` . This three-dot token, the ellipsis,
    really is valid Python syntax. It's not a placeholder used only in this book;
    it's the Python code to remind everyone a useful body needs to be written in order
    to create a working, concrete subclass.
  prefs: []
  type: TYPE_NORMAL
- en: We've used the `@property` decorator on the `ext()` method, also. Our intent
    for the `ext` property is to provide a simple class-level variable with a string
    literal value. It's helpful to describe this as an `@property` to allow the implementation
    to choose between a simple variable and a method that implements the property.
    A simple variable in the concrete class will meet the expectations of the abstract
    class at runtime and will also help **mypy** to check the code for consistent
    use of types. A method could be used as an alternative to a simple attribute variable
    in case some more sophisticated computation is required.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the consequences of marking these properties is the class now has a
    new special attribute, `__abstractmethods__`. This attribute lists all of the
    names that need to be filled in to create a concrete class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'See what happens if you implement a subclass? We''ll look at an example that
    doesn''t supply concrete implementations for the abstractions. We''ll also look
    at an example that does supply the required attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The definition of a `Wav` subclass fails to implement either of the abstract
    attributes. When we try to create an instance of the `Wav` class, an exception
    is raised. Because this subclass of `MediaLoader` is still abstract, it is not
    possible to instantiate the class. The class is still a potentially useful abstract
    class, but you'd have to subclass it and fill in the abstract placeholders before
    it can actually do anything.
  prefs: []
  type: TYPE_NORMAL
- en: The `Ogg` subclass supplies both attributes, so it – at the least – can instantiate
    cleanly. It's true, the body of the `play()` method doesn't do very much. What's
    important is that all of the placeholders were filled, making `Ogg` a concrete
    subclass of the abstract `MediaLoader` class.
  prefs: []
  type: TYPE_NORMAL
- en: There's a subtle issue with using a class-level variable for the preferred media
    file extension. Because the `ext` attribute is a variable, it can be updated.
    Using `o.ext = '.xyz'` is not expressly prohibited. Python doesn't have an easy,
    obvious way to create read-only attributes. We often rely on documentation to
    explain the consequences of changing the value of the `ext` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: This has clear advantages when creating a complex application. The use of abstraction
    like this makes it very easy for **mypy** to conclude that a class does (or does
    not) have the required methods and attributes.
  prefs: []
  type: TYPE_NORMAL
- en: This also mandates a certain amount of fussy importing to be sure that the module
    has access to the necessary abstract base classes for an application. One of the
    advantages of duck typing is the ability to avoid complex imports and still create
    a useful class that can act polymorphically with peer classes. This advantage
    is often outweighed by the ability of the `abc.ABC` class definition to support
    type checking via **mypy**, and to also do a runtime check for completeness of
    a subclass definition. The `abc.ABC` class also provides far more useful error
    messages when something is wrong.
  prefs: []
  type: TYPE_NORMAL
- en: One important use case for ABCs is the `collections` module. This module defines
    the built-in generic collections using a sophisticated set of base classes and
    mixins.
  prefs: []
  type: TYPE_NORMAL
- en: The ABCs of collections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A really comprehensive use of the abstract base classes in the Python standard
    library lives in the `collections` module. The collections we use are extensions
    of the `Collection` abstract class. `Collection` is an extension of an even more
    fundamental abstraction, `Container`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the foundation is the `Container` class, let''s inspect it in the Python
    interpreter to see what methods this class requires:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the `Container` class has exactly one abstract method that needs to be
    implemented, `__contains__()`. You can issue `help(Container.__contains__)` to
    see what the function signature should look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We can see that `__contains__()` needs to take a single argument. Unfortunately,
    the help file doesn't tell us much about what that argument should be, but it's
    pretty obvious from the name of the ABC and the single method it implements that
    this argument is the value the user is checking to see whether the container holds.
  prefs: []
  type: TYPE_NORMAL
- en: 'This `__contains__()` special method implements the Python `in` operator. This
    method is implemented by `set`, `list`, `str`, `tuple`, and `dict`. However, we
    can also define a silly container that tells us whether a given value is in the
    set of odd integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We've used the modulo test for oddity. If the remainder of `x` divided by two
    is zero, then `x` was even, otherwise `x` was odd.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the interesting part: we can instantiate an `OddContainer` object and
    determine that, even though we did not extend `Container`, the class behaves as
    a `Container` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: And that is why duck typing is way more awesome than classical polymorphism.
    We can create is-a relationships without the overhead of writing the code to set
    up inheritance (or worse, multiple inheritance).
  prefs: []
  type: TYPE_NORMAL
- en: 'One cool thing about the `Container` ABC is that any class that implements
    it gets to use the `in` keyword for free. In fact, `in` is just syntax sugar that
    delegates to the `__contains__()` method. Any class that has a `__contains__()` method
    is a `Container` and can therefore be queried by the `in` keyword. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The real value here is the ability to create new kinds of collections that are
    completely compatible with Python's built-in generic collections. We could, for
    example, create a dictionary that uses a binary tree structure to retain keys
    instead of a hashed lookup. We'd start with the `Mapping` abstract base class
    definitions, but change the algorithms that support methods like `__getitem__()`,
    `__setitem__()`, and `__delitem__()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python''s duck typing works (in part) via the `isinstance()` and `issubclass()`
    built-in functions. These functions are used to determine class relationships.
    They rely on two internal methods that classes can provide: `__instancecheck__()`
    and `__subclasscheck__()`. An ABC class can provide a `__subclasshook__()` method,
    which is used by the `__subclasscheck__()` method to assert that a given class
    is a proper subclass of the abstract base class. The details are a bit beyond
    this book; consider this a signpost pointing out the path that needs to be followed
    when creating novel classes that need to live side by side with built-in classes.'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract base classes and type hints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The concept of an abstract base class is closely tied to the idea of a generic
    class. An abstract base class is often generic with respect to some detail that
    is supplied by a concrete implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Most of Python's generic classes – classes like `list`, `dict`, and `set` –
    can be used as type hints, and these hints can be parameterized to narrow the
    domain. There's a world of difference between `list[Any]` and `list[int]`; the
    value `["a", 42, 3.14]` is valid for the first type hint, but invalid for the
    other. This concept of *parameterizing* the generic type to make it more specific
    often applies to abstract classes, also.
  prefs: []
  type: TYPE_NORMAL
- en: For this to work, you'll often need to incorporate `from __future__ import annotations`
    as the very first line of code. This modifies the behavior of Python to permit
    function and variable annotations to parameterize these standard collections.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generic classes and abstract base classes are not the same thing. The two concepts
    overlap, but are distinct:'
  prefs: []
  type: TYPE_NORMAL
- en: Generic classes have an implicit relationship with `Any`. This often needs to
    be narrowed using type parameters, like `list[int]`. The list class is concrete,
    and when we want to extend it, we'll need to plug in a class name to replace the
    `Any` type. The Python interpreter does not use generic class hints in any way;
    they are only checked by static analysis tools such as **mypy**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abstract classes have placeholders instead of one or more methods. These placeholder
    methods require a design decision that supplies a concrete implementation. These
    classes are not completely defined. When we extend it, we'll need to provide a
    concrete method implementation. This is checked by **mypy**. That's not all. If
    we don't provide the missing methods, the interpreter will raise a runtime exception
    when we try to create an instance of an abstract class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some classes can be both abstract and generic. As noted above, the type parameter
    helps **mypy** understand our intention, but isn't required. The concrete implementation
    is required.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another concept that''s adjacent to abstract classes is the **protocol**. This
    is the essence of how duck typing works: when two classes have the same batch
    of methods, they both adhere to a common protocol. Any time we see classes with
    similar methods, there''s a common protocol; this may be formalized with a type
    hint.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider objects that can be hashed. Immutable classes implement the `__hash__()`
    method, including strings, integers, and tuples. Generally, mutable classes don''t
    implement the `__hash__()` method; this includes classes like `list`, `dict`,
    and `set`. This one method is the `Hashable` protocol. If we attempt to write
    a type hint like `dict[list[int], list[str]]`, then **mypy** will object that
    `list[int]` can''t be used as a key. It can''t be a key because the given type,
    `list[int]`, doesn''t implement the `Hashable` protocol. At runtime, the attempt
    to create a dictionary item with a mutable key will fail for the same reason:
    a list doesn''t implement the required method.'
  prefs: []
  type: TYPE_NORMAL
- en: The essence of creating ABCs is defined in the `abc` module. We'll look at how
    this works later. For now, we want to make use of abstract classes, and that means
    using the definitions in the `collections` module.
  prefs: []
  type: TYPE_NORMAL
- en: The collections.abc module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One prominent use of abstract base classes is in the `collections.abc` module.
    This module provides the abstract base class definitions for Python's built-in
    collections. This is how `list`, `set`, and `dict` (and a few others) can be built
    from individual component definitions.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the definitions to build our own unique data structures in ways that
    overlap with built-in structures. We can also use the definitions when we want
    to write a type hint for a specific feature of a data structure, without being
    overly specific about alternative implementations that might also be acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: The definitions in `collections.abc` don't – trivially – include `list`, `set`,
    or `dict`. Instead, the module provides definitions like `MutableSequence`, `MutableMapping`,
    and `MutableSet`, which are – in effect – abstract base classes for which the
    `list`, `dict`, or `set` classes we use are the concrete implementations. Let's
    follow the various aspects of the definition of `Mapping` back to their origins.
    Python's `dict` class is a concrete implementation of `MutableMapping`. The abstraction
    comes from the idea of mapping a key to a value. The `MutableMapping` class depends
    on the `Mapping` definition, an immutable, frozen dictionary, potentially optimized
    for lookups. Let's follow the relationships among these abstractions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the path we want to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17070_06_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.2: The Mapping abstractions'
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting in the middle, we can see the `Mapping` definition depends on the
    `Collection` class definition. The definition of the `Collection` abstract class,
    in turn, depends on three other abstract base classes: `Sized`, `Iterable`, and
    `Container`. Each of these abstractions demands specific methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we''re going to create a lookup-only dictionary – a concrete `Mapping` implementation
    – we''ll need to implement at least the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: The `Sized` abstraction requires an implementation for the `__len__()` method.
    This lets an instance of our class respond to the `len()` function with a useful
    answer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Iterable` abstraction requires an implementation for the `__iter__()` method.
    This lets an object work with the `for` statement and the `iter()` function. In
    *Chapter 10*, *The Iterator Pattern*, we'll revisit this topic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Container` abstraction requires an implementation for the `__contains__()`
    method. This permits the `in` and `not in` operators to work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Collection` abstraction combines `Sized`, `Iterable`, and `Container` without
    introducing additional abstract methods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Mapping` abstraction, based on `Collection`, requires, among other things,
    `__getitem__()`, `__iter__()`, and `__len__()`. It has a default definition for
    `__contains__()`, based on whatever `__iter__()` method we provide. The `Mapping`
    definition will provide a few other methods, also.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This list of methods comes directly from the abstract relationships in the base
    classes. By building our new dictionary-like immutable class from these abstractions,
    we can be sure that our class will collaborate seamlessly with other Python generic
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at the documentation in [https://docs.python.org/3.9/library/collections.abc.html](https://docs.python.org/3.9/library/collections.abc.html),
    we see the page is dominated by a table showing abstract class definitions and
    the definitions they depend on. There's a lattice of dependencies showing overlap
    among the class definitions. It's this overlap that allows us to use a `for` statement
    to iterate through every kind of collection that implements the `Iterable` abstract
    base class.
  prefs: []
  type: TYPE_NORMAL
- en: Let's define our own immutable `Mapping` object implementation by extending
    the abstract classes. The goal is to be able to load our dictionary-like mapping
    once with keys and values, and then use it to map the keys to their values. Since
    we aren't going to allow any updates, we can apply a variety of algorithms to
    make it very fast as well as very compact.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal is a class with a type hint like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We're going to create a dictionary-like mapping from some key to – well – an
    object of any possible type. We've defined the key with the type `Comparable`
    because we want to be able to compare the keys and sort them into order. Searching
    through a list in order is often more efficient than searching a list that's not
    in order.
  prefs: []
  type: TYPE_NORMAL
- en: We'll look at the core of a `Lookup` class definition first. We'll return to
    the `Comparable` class definition after solidifying the essentials of a new kind
    of mapping from keys to values.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we look at ways we can construct a dictionary, we see that a dictionary
    can be built from two different kinds of data structures. Our new mapping has
    to have this same flexibility. The two structures are exemplified by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can build a mapping from an existing mapping, or we can build a mapping
    from a sequence of two-tuples with keys and values. This means there are two separate
    definitions for `__init__()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`def __init__(self, source: BaseMapping) -> None`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`def __init__(self, source: Iterable[tuple[Comparable, Any]]) -> None`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These two definitions have distinct type hints. To make it clear to **mypy**,
    we need to provide **overloaded** method definitions. This is done with a special
    decoration from the `typing` module, `@overload`. We'll provide two method definitions
    with the two alternatives; after these, we'll provide the real method definition
    that does the useful work. Because these are type hints, they're not *required*.
    They're wordy, and they help us be sure we've got a sensible implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the first part of the `Lookup` class definition. We''ll break this
    into pieces because the `__init__()` method needs to cover these two cases defined
    by the alternative overloads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `__init__()` method needs to handle three cases for loading a mapping. This
    means building the values from a sequence of pairs, or building the values from
    another mapping object, or creating an empty sequence of values. We need to separate
    the keys from the values and put them into two parallel lists. A sorted list of
    keys can be rapidly searched to find a match. The sorted list of values is returned
    when we get a key's value from the mapping.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the imports needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the other abstract methods that are defined by the `@abstractmethod`
    decorator. We provide the following concrete implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `__len__()`, `__iter__()`, and `__contains__()` methods are required by
    the `Sized`, `Iterable`, and `Container` abstract classes. The `Collection` abstract
    class combines the other three without introducing any new abstract methods.
  prefs: []
  type: TYPE_NORMAL
- en: The `__getitem__()` is required to be a `Mapping`. Without it, we can't retrieve
    an individual value for a given key.
  prefs: []
  type: TYPE_NORMAL
- en: The use of the `bisect` module is one way to find a specific value rapidly in
    a sorted list of keys. The `bisect.bisect_left()` function finds the spot where
    a key belongs in a list. If the key is there, we can return the value to which
    it maps. If the key is not there, we can raise the `KeyError` exception.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `__contains__()` definition has the `object` class as the type
    hint, unlike the other methods. This is required because Python's `in` operation
    needs to support any kind of object, even ones that don't obviously support the
    `Comparable` protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how it looks when we use our shiny new `Lookup` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This collection, generally, behaves a bit like a dictionary. There are a number
    of dict-like aspects we can't use, though, because we chose an abstract base class
    that didn't describe the full set of methods for the `dict` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we try something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll get an exception that spells out the limitation of the class we built:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This exception is consistent with the rest of our design. An update to this
    object means inserting an item at the correct position to maintain a sorted order.
    Shuffling a large list around gets expensive; if we need to update the lookup
    collection, we should consider other data structures like a Red-Black tree. But,
    for the pure search operation using the bisect algorithm, this performs nicely.
  prefs: []
  type: TYPE_NORMAL
- en: 'We skipped over the definition of the `Comparable` class. This defines the
    minimum set of features – the protocol – for the keys. It''s a way to formalize
    the comparison rules required to keep the keys for the mapping in order. This
    helps **mypy** confirm that objects we try to use as keys really can be compared:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: There's no implementation. This definition is used to introduce a new type hint.
    Because it's a hint, we provide `...` as the body for the methods, since the bodies
    will be provided by existing class definitions like `str` and `int`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we don't rely on items having a hash code. This is an interesting
    extension to the built-in `dict` class, which requires the keys be hashable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The general approach to using abstract classes is this:'
  prefs: []
  type: TYPE_NORMAL
- en: Find a class that does most of what you need.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify the methods in the `collections.abc` definitions that are marked as
    *abstract*. The documentation often gives a lot of information, but you'll also
    have to look at the source.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Subclass the abstract class, filling in the missing methods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While it can help to make a checklist of the methods, there are tools to help
    with this. Creating a unit test (we'll cover testing in *Chapter 13*, *Testing
    Object-Oriented Programs*) means you need to create an instance of your new class.
    If you haven't defined all the abstract methods, this will raise an exception.
    Using **mypy** will also spot abstract methods that aren't properly defined in
    the concrete subclass.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is a powerful way to reuse code when we choose the abstractions well; a
    person can form a mental model of the class without knowing all of the details.
    It's also a powerful way to create closely related classes that can easily be
    examined by **mypy**. Beyond those two advantages, the formality of marking a
    method as abstract gives us a runtime assurance that the concrete subclass really
    does implement all the required methods.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've seen how to use an abstract base class, let's look at defining
    a new abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: Creating your own abstract base class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have two general paths to creating classes that are similar: we can leverage
    duck typing or we can define common abstractions. When we leverage duck typing,
    we can formalize the related types by creating a type hint using a protocol definition
    to enumerate the common methods, or a `Union[]` to enumerate the common types.'
  prefs: []
  type: TYPE_NORMAL
- en: There are an almost unlimited number of influencing factors that suggest one
    or the other approach. While duck typing offers the most flexibility, we may sacrifice
    the ability to use **mypy**. An abstract base class definition can be wordy and
    potentially confusing.
  prefs: []
  type: TYPE_NORMAL
- en: We'll tackle a small problem. We want to build a simulation of games that involve
    polyhedral dice. These are the dice including four, six, eight, twelve, and twenty
    sides. The six-sided dice are conventional cubes. Some sets of dice include 10-sided
    dice, which are cool, but aren't – technically – a *regular* polyhedron; they're
    two sets of five "kite-shaped" faces.
  prefs: []
  type: TYPE_NORMAL
- en: 'One question that comes up is how best to simulate rolls of these different
    shaped dice. There are three readily available sources of random data in Python:
    the `random` module, the `os` module, and the `secrets` module. If we turn to
    third-party modules, we can add in cryptographic libraries like `pynacl`, which
    offer yet more random number capabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: Rather than bake the choice of random number generator into a class, we can
    define an abstract class that has the general features of a die. A concrete subclass
    can supply the missing randomization capability. The random module has a very
    flexible generator. The `os` module's capability is limited, but involves using
    an *entropy collector* to increase randomness. Flexibility and high entropy are
    generally combined by cryptographic generators.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create our dice-rolling abstraction, we''ll need the `abc` module. This
    is distinct from the `collections.abc` module. The `abc` module has the foundational
    definitions for abstract classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We've defined a class that inherits from the `abc.ABC` class. Using `ABC` as
    the parent class assures us that any attempt to create an instance of the `Die`
    class directly will raise a `TypeError` exception. This is a runtime exception;
    it's also checked by **mypy**.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve marked a method, `roll()`, as abstract with the `@abc.abstract` decorator.
    This isn''t a very complex method, but any subclass should match this abstract
    definition. This is only checked by **mypy**. Of course, if we make a mess of
    the concrete implementation, things are likely to break at runtime. Consider this
    mess of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This will raise a `TypeError` exception at runtime. The problem is caused by
    the base class `__init__()` not providing the `a` and `b` parameters to this strange-looking
    `roll()` method. This is valid Python code, but it doesn't make sense in this
    context. The method will also generate **mypy** errors, providing ample warning
    the method definition doesn't match the abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s what two proper extensions to the `Die` class look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We've provided methods that provide a suitable definition for the abstract placeholder
    in the `Die` class. They use vastly different approaches to selecting a random
    value. The four-sided die uses `random.choice()`. The six-sided die – the common
    cube most people know – uses `random.randint()`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go a step further and create another abstract class. This one will represent
    a handful of dice. Again, we have a number of candidate solutions, and we can
    use an abstract class to defer the final design choices.
  prefs: []
  type: TYPE_NORMAL
- en: The interesting part of this design is the differences in the rules for games
    with handfuls of dice. In some games, the rules require the player to roll all
    the dice. The rules for a lot of games with two dice require the player to roll
    both dice. In other games, the rules allow players to save dice, and re-roll selected
    dice. In some games, like Yacht, the players are allowed at most two re-rolls.
    In other games, like Zilch, they are allowed to re-roll until they elect to save
    their score or roll something invalid and lose all their points, scoring zilch
    (hence the name).
  prefs: []
  type: TYPE_NORMAL
- en: 'These are dramatically different rules that apply to a simple list of `Die`
    instances. Here''s a class that leaves the roll implementation as an abstraction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `__init__()` method expects an integer, `n`, and the class used to create
    `Die` instances, named `die_class`. The type hint is `Type[Die]`, telling **mypy**
    to be on the lookout for any subclass of the abstract base class `Die`. We don't
    expect an instance of any of the `Die` subclasses; we expect the class object
    itself. We'd expect to see `SomeDice(6, D6)` to create a list of six instances
    of the `D6` class.
  prefs: []
  type: TYPE_NORMAL
- en: We've defined the collection of `Die` instances as a list because that seems
    simple. Some games will identify dice by their position when saving some dice
    and rerolling the remainder of the dice, and the integer list indices seem useful
    for that.
  prefs: []
  type: TYPE_NORMAL
- en: 'This subclass implements the roll-all-the-dice rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Each time the application evaluates `roll()`, all the dice are updated. It
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The object, `sd`, is an instance of the concrete class, `SimpleDice`, built
    from the abstract class, `Dice`. The instance of `SimpleDice` contains six instances
    of the `D6` class. This, too, is a concrete class built from the abstract class
    `Die`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s another subclass that provides a dramatically different set of methods.
    Some of these fill in the spaces left by abstract methods. Others, however, are
    unique to the subclass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve created a set of saved positions. This is initially empty. We can use
    the `saving()` method to provide an iterable collection of integers as positions
    to save. It works like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We improved the hand from three of a kind to a full house.
  prefs: []
  type: TYPE_NORMAL
- en: In both cases, the `Die` class and the `Dice` class, it's not clear that the
    `abc.ABC` base class and the presence of an `@abc.abstractmethod` decoration is
    dramatically better than providing a concrete base class with a common set of
    default definitions.
  prefs: []
  type: TYPE_NORMAL
- en: In some languages, the abstraction-based definition is required. In Python,
    because of duck typing, abstraction is optional. In cases where it clarifies the
    design intent, use it. In cases where it seems fussy and little more than overhead,
    set it aside.
  prefs: []
  type: TYPE_NORMAL
- en: Because it's used to define the collections, we'll often use the `collection.abc`
    names in type hints to describe the protocols objects must follow. In less common
    cases, we'll leverage the `collections.abc` abstractions to create our own unique
    collections.
  prefs: []
  type: TYPE_NORMAL
- en: Demystifying the magic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ve used abstract base classes and it''s clear they''re doing a lot of work
    for us. Let''s look inside the class to see some of what''s going on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The abstract method, `roll()`, is tracked in a specially named attribute, `__abstractmethods__`,
    of the class. This suggests what the `@abc.abstractmethod` decorator does. This
    decorator sets `__isabstractmethod__` to mark the method. When Python finally
    builds the class from the various methods and attributes, the list of abstractions
    is also collected to create a class-level set of methods that must be implemented.
  prefs: []
  type: TYPE_NORMAL
- en: Any subclass that extends `Die` will also inherit this `__abstractmethods__`
    set. When methods are defined inside the subclass, names are removed from the
    set as Python builds the class from the definitions. We can only create instances
    of a class where the set of abstract methods in the class is empty.
  prefs: []
  type: TYPE_NORMAL
- en: 'Central to this is the way classes are created: a class builds objects. This
    is the essence of most of object-oriented programming. But what is a class?'
  prefs: []
  type: TYPE_NORMAL
- en: 'A class is another object with two very limited jobs: it has the special methods
    used to create and manage instances of the class, and it also acts as a container
    for the method definitions for objects of the class. We think of building class
    objects with the `class` statement, which leaves open the question of how the
    `class` statement builds the `class` object.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `type` class is the internal object that builds our application classes.
    When we enter the code for a class, the details of construction are actually the
    responsibility of methods of the `type` class. After `type` has created our application
    class, our class then creates the application objects that solve our problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `type` object is called the **metaclass**, the class used to build classes.
    This means every class object is an instance of `type`. Most of the time, we're
    perfectly happy with letting a `class` statement be handled by the `type` class
    so our application code can run. There's one place, however, where we might want
    to change how `type` works.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because `type` is itself a class, it can be extended. A class `abc.ABCMeta`
    extends the `type` class to check for methods decorated with `@abstractmethod`.
    When we extend `abc.ABC`, we''re creating a new class that uses the `ABCMeta`
    metaclass. We can see this in the value of the special `__mro__` attribute of
    the `ABCMeta` class; this attribute lists the classes used for resolving method
    names (**MRO** is **Method Resolution Order**). This special attribute lists the
    following classes to be searched for a given attribute: the `abc.ABCMeta` class,
    the `type` class, and finally the `object` class.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `ABCMeta` metaclass explicitly when we create a new class, if
    we want:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We've used `metaclass` as a keyword parameter when defining the components that
    make up a class. This means the `abc.ABCMeta` extension to type will be used to
    create the final class object.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've seen how classes are built, we can consider other things we can
    do when creating and extending classes. Python exposes the binding between the
    syntactic operators, like the `/` operator, and the methods of the implementing
    class. This allows the `float` and `int` classes to do different things with the
    `/` operator, but it can also be used for quite different purposes. For example,
    the `pathlib.Path` class, which we will discuss in *Chapter 9*, *Strings, Serialization,
    and File Paths*, also makes use of the `/` operator.
  prefs: []
  type: TYPE_NORMAL
- en: Operator overloading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Python''s operators, `+`, `/`, `-`, `*`, and so on, are implemented by special
    methods on classes. We can apply Python operators more widely than the built-in
    numbers and collection types. Doing this can be called "overloading" the operators:
    letting them work with more than the built-in types.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking back at the *The collections.abc module* section, earlier in this chapter,
    we dropped a hint about how Python connects some built-in features with our classes.
    When we look at the `collections.abc.Collection` class, it is the abstract base
    class for all `Sized`, `Iterable`, `Containers`; it requires three methods that
    enable two built-in functions and one built-in operator:'
  prefs: []
  type: TYPE_NORMAL
- en: The `__len__()` method is used by the built-in `len()` function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `__iter__()` method is used by the built-in `iter()` function, which means
    it's used by the `for` statement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `__contains__()` method is used by the built-in `in` operator. This operator
    is implemented by methods of built-in classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It''s not wrong to imagine the built-in `len()` function has this definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: When we ask for `len(x)`, it's doing the same thing as `x.__len__()`, but is
    shorter, easier to read, and easier to remember. Similarly, `iter(y)` is effectively
    `y.__iter__()`. And an expression like `z in S` is evaluated as if it was `S.__contains__(z)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'And yes, with a few exceptions, all of Python works this way. We write pleasant,
    easy-to-read expressions that are transformed into special methods. The only exceptions
    are the logic operations: `and`, `or`, `not`, and `if-else`. These don''t map
    directly to special method definitions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because almost all of Python relies on the special methods, it means we can
    change their behavior to add features. We can overload the operators with new
    data types. One prominent example of this is in the `pathlib` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Note: Your results will vary, depending on your operating system and your username.'
  prefs: []
  type: TYPE_NORMAL
- en: What doesn't vary is that the `/` operator is used to connect a `Path` object
    with string objects to create a new `Path` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `/` operator is implemented by the `__truediv__()` and `__rtruediv__()`
    methods. In order to make operations commutative, Python has two places to look
    for an implementation. Given an expression of `A` *op* `B`, where *op* is any
    of the Python operators like `__add__` for `+`, Python does the following checks
    for special methods to implement the operator:'
  prefs: []
  type: TYPE_NORMAL
- en: There's a special case when `B` is a proper subclass of `A`. In those rare cases,
    the order is reversed so `B.__r`*op*`__(A)` can be tried before any of the others.
    This lets the subclass `B` override an operation from superclass `A`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try `A.__`*op*`__(B)`. If this returns a value that's not the special `NotImplemented`
    value, this is the result. For a `Path` object expression like `home / "miniconda3"`,
    this is effectively `home.__truediv__("miniconda3")`. A new `Path` object is built
    from the old `Path` object and the string.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try `B.__r`*op*`__(A)`. This might be the `__radd__()` method for the reverse
    addition implementation. If this method returns a value other than the `NotImplemented`
    value, this is the result. Note that the operand ordering is reversed. For commutative
    operations, like addition and multiplication, this does not matter. For non-commutative
    operations, like subtraction and division, the change in ordering needs to be
    reflected in the implementation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s return to our handful of dice example. We can implement a `+` operator
    to add a `Die` instance to a collection of `Dice`. We''ll start with a base definition
    of a class that contains a heterogenous handful of different kinds of dice. Check
    the previous `Dice` class, which assumed homogenous dice. This isn''t an abstract
    class; it has a definition of `roll` that re-rolls all the dice. We''ll start
    with some basics and then incorporate the `__add__()` special method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This shouldn't be much of a surprise. It looks a lot like the `Dice` class defined
    above. We've added an `adjust` attribute set by the `plus()` method so we can
    use `DDice(D6, D6, D6).plus(2)`. It fits better with some tabletop role-playing
    games (TTRPGs).
  prefs: []
  type: TYPE_NORMAL
- en: Also, recall that we provide the types of the dice to the `DDice` class, not
    instances of the dice. We use the class object, `D6`, not a `Die` instance, created
    by an expression like `D6()`. The instances of the classes are created by `DDice`
    in the `__init__()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the cool part: we can use the plus operator with `DDice` objects, `Die`
    classes, and integers to define a complex roll of the dice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'These two methods are similar in many ways. We check for three separate kinds
    of `+` operations:'
  prefs: []
  type: TYPE_NORMAL
- en: If the argument value, `die_class`, is a type, and it's a subclass of the `Die`
    class, then we're adding another `Die` object to a `DDice` collection. It's an
    expression like `DDice(D6) + D6 + D6`. The semantics of most operator implementations
    is to create a new object from the previous objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the argument value is an integer, then we're adding an adjustment to a set
    of dice. This is something like `DDice(D6, D6, D6) + 2`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the argument value is neither a subclass of `Die` nor an integer, then something
    else is going on, and this class doesn't have an implementation. This may be some
    kind of bug, or it might be that the other class involved in the operation can
    provide an implementation; returning `NotImplemented` gives the other object a
    chance at performing the operation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because we've provided `__radd__()` as well as `__add__()`, these operations
    are commutative. We can use expressions like `D6 + DDice(D6) + D6` and `2 + DDice(D6,
    D6)`.
  prefs: []
  type: TYPE_NORMAL
- en: We need to make specific `isinstance()` checks because Python operators are
    completely generic, and the expected type hint must be `Any`. We can only narrow
    down the applicable types through runtime checks. The **mypy** program is astute
    about following the branching logic to confirm that an integer object was properly
    used in an integer context.
  prefs: []
  type: TYPE_NORMAL
- en: '"But wait," you say. "My favorite game has rules that call for 3d6+2." This
    is shorthand for rolling three six-sided dice and adding two to the result. In
    many TTRPGs, this kind of abbreviation is used to summarize the dice.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Can we add multiplication to do this? There''s no reason why not. For multiplication,
    we only need to worry about integers. `D6 * D6` isn''t used in any of the rules,
    but `3*D6` matches the text of most TTRPG rules nicely:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: These two methods follow a similar design pattern to the `__add__()` and `__radd__()`
    methods. For each existing `Die` subclass, we'll create several instances of the
    class. This lets us use `3 * DDice(D6) + 2` as an expression to define a dice-rolling
    rule. The Python operator precedence rules still apply, so the `3 * DDice(D6)`
    portion is evaluated first.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python''s use of the various `__`*op*`__()` and `__r`*op*`__()` methods works
    out extremely well for applying the various operators to objects that are immutable:
    strings, numbers, and tuples being the primary examples. Our handful of dice presents
    a bit of a head-scratcher because the state of the individual dice can change.
    What''s important is that we treat the composition of the hand as immutable. Each operation on
    a `DDice` object creates a new `DDice` instance.'
  prefs: []
  type: TYPE_NORMAL
- en: What about mutable objects? When we write an assignment statement like `some_list
    += [some_item]`, we're mutating the value of the `some_list` object. The `+=`
    statement does the same thing as the more complex expression `some_list.extend([some_item])`.
    Python supports this with operators with names like `__iadd__()` and `__imul__()`.
    These are "in-place" operations, designed to mutate objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This can be processed one of two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: If `DDice` implements `__iadd__()`, this becomes `y.__iadd__(D6)`. The object
    can mutate itself in place.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `DDice` does not implement `__iadd__()`, this is `y = y.__add__(D6)`. The
    object creates a new, immutable object, and that's given the old object's variable
    name. This lets us do things like `string_variable += "."`. Under the hood, `string_variable`
    is not mutated; it's replaced.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If it makes sense for an object to be mutable, we can support in-place mutation
    of a `DDice` object with this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__iadd__()` method appends to the internal collection of dice. It follows
    rules similar to the `__add__()` methods: when a class is provided, an instance
    is created, and it''s added to the `self.dice` list; if an integer is provided,
    it''s added to the `self.adjust` value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now perform incremental changes to a single dice-rolling rule. We can
    mutate the state of a single `DDice` object using assignment statements. Because
    the object mutates, we aren''t creating a lot of copies of the object. The creation
    of complex dice looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This builds the 3d6+2 dice roller in incremental pieces.
  prefs: []
  type: TYPE_NORMAL
- en: The use of the internal special method names allows for seamless integration
    with other Python features. We can build classes using `collections.abc` that
    fit with existing collections. We can override the methods implementing the Python
    operators to create easy-to-use syntax.
  prefs: []
  type: TYPE_NORMAL
- en: We can leverage the special method names to add features to Python's built-in
    generic collections. We'll turn to that topic next.
  prefs: []
  type: TYPE_NORMAL
- en: Extending built-ins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Python has two collections of built-ins that we might want to extend. We can
    broadly classify these into the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Immutable objects, including numbers, strings, bytes, and tuples. These will
    often have extended operators defined. In the *Operator overloading* section of
    this chapter, we looked at how we can provide arithmetic operations for objects
    of the `Dice` class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mutable collections, including sets, lists, and dictionaries. When we look at
    the definitions in `collections.abc`, these are sized, iterable containers, three
    distinct aspects that we might want to focus on. In *The collections.abc module*
    section of this chapter, we looked at creating an extension to the `Mapping` abstract
    base class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are other built-in types, but these two groupings are generally applicable
    to a variety of problems. For example, we could create a dictionary that rejects
    duplicate values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The built-in dictionary always updates the value associated with a key. This
    can lead to odd-looking code that works. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'And:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: These are well-defined behaviors. It may be odd-looking to provide two keys
    in the expression but have only one key in the result, but the rules for building
    dictionaries make these inevitable and correct results.
  prefs: []
  type: TYPE_NORMAL
- en: We may, however, not like the behavior of silently ignoring a key. It may make
    our application needlessly complex to worry about the possibility of duplicates.
    Let's create a new kind of dictionary that won't update items once they've been
    loaded.
  prefs: []
  type: TYPE_NORMAL
- en: 'Studying `collections.abc`, we need to extend a mapping, with a changed definition
    of `__setitem__()` to prevent updating an existing key. Working at the interactive
    Python prompt, we can try this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'And when we put it to use, we see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We're not done, but we're off to a good start. This dictionary rejects duplicates
    under some circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, it isn''t blocking duplicate keys when we try to construct a dictionary
    from another dictionary. We don''t want this to work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: So we've got some work to do. Some expressions properly raise exceptions, where
    as other expressions still silently ignore duplicate keys.
  prefs: []
  type: TYPE_NORMAL
- en: The basic problem is that not all methods that set items are using `__setitem__()`.
    To alleviate the above problems, we'll need to override `__init__()` as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll also need to add type hints to our initial draft. This will let us leverage
    **mypy** to confirm that our implementation will work in general. Here''s a version
    with `__init__()` added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This version of the `NoDupDict` class implements an `__init__()` method that
    will work with a variety of data types. We enumerated the various types using
    the `DictInit` type hint. This includes a sequence of *key-value* pairs, as well
    as another mapping. In the case of a sequence of key-value pairs, we can use the
    previously defined `__setitem__()` to raise an exception in the event of duplicate
    key values.
  prefs: []
  type: TYPE_NORMAL
- en: This covers the initialization use cases, but – still – doesn't cover every
    method that can update a mapping. We still have to implement `update()`, `setdefault()`,
    `_``_or__()`, and `__ior__()` to extend all the methods that can mutate a dictionary.
    While this is a pile of work to create, the work is encapsulated in a dictionary
    subclass that we can use in our application. This subclass is completely compatible
    with built-in classes; it implements many methods we didn't write, and it has
    one extra feature we did write.
  prefs: []
  type: TYPE_NORMAL
- en: We've built a more complex dictionary that extends the core features of a Python
    `dict` class. Our version adds a feature to reject duplicates. We've also touched
    on the use of `abc.ABC` (and `abc.ABCMeta`) to create abstract base classes. There
    are times when we might want to take more direct control of the mechanics of creating
    a new class. We'll turn next to metaclasses.
  prefs: []
  type: TYPE_NORMAL
- en: Metaclasses
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we noted earlier, creating a new class involves work done by the `type` class.
    The job of the `type` class is to create an empty class object so the various
    definitions and attributes assignment statements will build the final, usable
    class we need for our application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17070_06_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.3: How type creates MyClass'
  prefs: []
  type: TYPE_NORMAL
- en: The `class` statement is used to locate the appropriate metaclass; if no special
    `metaclass=` is provided, then the `type` class is used. The `type` class will
    prepare a new, empty dictionary, called a namespace, and then the various statements
    in the class populate this container with attributes and method definitions. Finally,
    the "new" step completes creation of the class; this is generally where we can
    make our changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a diagram showing how we can use a new class, SpecialMeta, to tap into
    the way `type` builds a new class for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17070_06_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.4: Extending the type class'
  prefs: []
  type: TYPE_NORMAL
- en: If we use the `metaclass=` option when creating a class, we change the metaclass
    that's used. In the preceding diagram, `SpecialMeta` is a subclass of the `type`
    class, and it can do some special processing for our class definitions.
  prefs: []
  type: TYPE_NORMAL
- en: While there are some clever things we can do with this technique, it's important
    to keep metaclasses in perspective. They change the way class objects are built,
    with the potential to redefine what it means to be a class. This can drastically
    shift the foundation of Pythonic object-oriented programming. It can lead to frustration
    when people reading and maintaining the code can't figure out why something works;
    it should not be undertaken lightly.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at a metaclass that builds a few small features into a class definition
    for us. Let's continue to extend the dice simulation examples from earlier in
    this chapter. We may have a number of classes of die, each an instance of the
    abstract base class `Die`. We'd like them all to have an audit log surrounding
    the `roll()` method supplied by the implementation. We'd like to track each roll
    separately, perhaps so someone can review them for their statistical validity.
  prefs: []
  type: TYPE_NORMAL
- en: Because we don't want to force the programmers of various kinds of dice to include
    any extra or new code, we prefer to add logging to the abstract base class for
    all `Die` classes, and also adjust the concrete implementation of the `roll()`
    method to create logging output.
  prefs: []
  type: TYPE_NORMAL
- en: This is a tall order. It's made a little more challenging because we're working
    with abstract classes. This requires some care to disentangle abstract class construction
    from concrete class construction. We don't want to force programmers to change
    their concrete `Die` class definitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this problem using metaclasses, we need to do three things to each
    concrete `Die`-related class that gets built:'
  prefs: []
  type: TYPE_NORMAL
- en: Extend the `ABCMeta` metaclass. We need to support the `@abc.abstractmethod`
    decoration, so we want all the existing metaclass features from the built-in `type`
    metaclass.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inject a `logger` attribute into each class. It's common to have the logger
    name match the class name; this is easy to do in a metaclass. We can create the
    logger as part of the class, prior to any instances of the class being created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Wrap the concrete `roll()` method into a function that uses the programmer's
    supplied `roll()` method, but also writes a message to the logger. This is similar
    to the way a method decorator works.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The metaclass definition needs a `__new__()` method to make slight adjustments
    to the way the final class is built. We don''t need to extend the `__prepare__()`
    method. Our `__new__()` method will use `abc.ABCMeta.__new__()` to build the final
    class object. This `ABCMeta` class will decide if the object is concrete or remains
    abstract because `roll()` was not defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__new__()` method is given a bewildering pile of argument values:'
  prefs: []
  type: TYPE_NORMAL
- en: The `metaclass` parameter is a reference to the metaclass doing the work. Python
    doesn't generally create and use instances of metaclasses. Instead, the metaclass
    itself is passed as a parameter to each method. It's a bit like the `self` value
    provided to an object, but it's the class, not an instance of a class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `name` parameter is the name of the target class, taken from the original
    `class` statement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `bases` parameter is the list of base classes. These are the mixins, sorted
    into method resolution order. In this example, it will be the superclass we'll
    define that uses this metaclass, `DieLog`, shown shortly below.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `namespace` parameter is a dictionary that was started by the `__prepare__()`
    method of the built-in `type` class. The dictionary was updated when the body
    of the class was executed; `def` statements and assignment statements will create
    items in this dictionary. When we get to the `__new__()` method, the methods (and
    variables) of the class are staged here, waiting to build the final class object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `kwargs` parameter will have any keyword arguments provided as part of the
    class definition. If we used a statement like `class D6L(DieLog, otherparam="something")`
    to create a new class, then the `otherparam` would be one of the `kwargs` to `__new__()`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `__new__()` method must return the new class definition. Generally, this
    is the result of using the superclass `__new__()` method to build the class object.
    In our case, the superclass method is `abc.ABCMeta.__new__()`.
  prefs: []
  type: TYPE_NORMAL
- en: Within this method, the `if` statement checks to see if the class being built
    defined the needed `roll()` method. If the method is marked with the `@abc.abstractmethod`
    decorator, then the method will have an attribute of `__isabstractmethod__` and
    the value of the attribute will be `True`. For a concrete method – without a decorator
    – there will be no `__isabstractmethod__` attribute value. The condition confirms
    there's a `roll()` method and if that `roll()` method is concrete.
  prefs: []
  type: TYPE_NORMAL
- en: For classes with a concrete `roll()` method, we'll add `"logger"` to the namespace
    that was built, providing a default value of an appropriately named logger. If
    a logger is already present, we'll leave it in place.
  prefs: []
  type: TYPE_NORMAL
- en: Next, `namespace["roll"]` picks out the function defined in the concrete class,
    the `roll` method. We'll define a replacement method, `logged_roll`. To be sure
    the new `logged_roll()` method looks like the original method, we've used the
    `@wraps` decorator. This will copy the original method name and docstring onto
    the new method, making it look like the definition originally present in the class.
    This is put back into the namespace so it can be incorporated into the new class.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we evaluate `abc.ABCMeta.__new__()` with the metaclass, the class name,
    the base classes, and the namespace that we modified if there was a concrete implementation
    of the `roll()` method. The `__new__()` operation finalizes the class, doing all
    the original Python housekeeping.
  prefs: []
  type: TYPE_NORMAL
- en: 'It can be awkward to use a metaclass; for this reason, it''s common to provide
    a superclass that uses the metaclass. This means our application can extend the
    superclass without having to fuss around with an extra `metaclass=` parameter
    in the class definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This superclass, `DieLog`, is built by the metaclass. Any subclass of this class
    will also be built by the metaclass.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, our application can create subclasses of `DieLog`, without having to worry
    about the details of the metaclass: we don''t have to remember to include `metaclass=`
    in the definition. Our final application classes are quite streamlined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve created a dice roller here that logs each roll in a logger named after
    the class. Here''s how it looks logging to the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The details of the logging aspect of this `D6L` class are completely divorced
    from the application-specific processing of this class. We can change the metaclass
    to change details of the logging, knowing that all of the relevant application
    classes will be changed when the metaclass changes.
  prefs: []
  type: TYPE_NORMAL
- en: Since a metaclass changes how a class is built, there are no boundaries on the
    kinds of things a metaclass can do. The common advice is to keep the metaclass
    features very small because they're obscure. As written, the `logged_roll()` method
    of the metaclass will discard any return value from the concrete `roll()` method
    in a subclass.
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll refine our case study in this chapter. Previously, in *Chapter 2*, *Objects
    in Python*, we talked in a vague way about loading the training data and splitting
    it into two clumps – the training set and the testing set. In *Chapter 5*, *When
    to Use Object-Oriented Programming*, we looked at ways to deserialize the source
    file into `Sample` instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we want to look further at this operation of using the raw
    data to create a number of `TrainingKnownSample` instances separate from a number
    of `TestingKnownSample` instances. In the previous chapter, we identified four
    cases for sample objects, shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Known | Unknown |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Unclassified | Training data | Sample waiting to be classified |'
  prefs: []
  type: TYPE_TB
- en: '| Classified | Testing data | Classified sample |'
  prefs: []
  type: TYPE_TB
- en: When looking at the known samples, classified by a Botanist, we need to split
    the data into two separate classes. We'll use a variety of approaches to do this,
    including a number of overloaded comparison operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our training data sorting can be approached from two distinct directions:'
  prefs: []
  type: TYPE_NORMAL
- en: We can ingest all the raw data, then distribute it into two collections for
    later use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During the process of ingestion, we can make selections among the collections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The net effect is the same. Working with an entire collection can be relatively
    simple, while using a great deal of memory. Processing items individually can
    be more complex, without requiring as much memory.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start by building some sophisticated collections. The first will be a
    list that tracks two sublists.
  prefs: []
  type: TYPE_NORMAL
- en: Extending the list class with two sublists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can extend the built-in `list` class to add some features. It's important
    to note that extending built-in types can be tricky because the type hints for
    these types are sometimes surprisingly complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python''s built-in structures like `list` have a variety of initialization
    alternatives:'
  prefs: []
  type: TYPE_NORMAL
- en: We can use `list()` to create an empty list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use `list(x)` to create a list from an iterable source of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To make this clear to **mypy**, we need to use the `@overload` decorator; this
    will expose the two distinct ways the `list` class `__init__()` method is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: We've defined two overloads for the `__init__()` method; these are the formalisms
    to tell **mypy** what our intent is. The first overload is `__init__()` with no
    positional parameters. This should create an empty list of `SampleDict` objects.
    The second overload is `__init__()` with an iterable source of `SampleDict` objects
    as the only positional parameter. The lonely `*` separates parameters where the
    argument value can be provided positionally from parameters where the argument
    value must be provided as a keyword. The `training_subset` parameter will stand
    out from the ordinary list-like initializer.
  prefs: []
  type: TYPE_NORMAL
- en: The third definition is the actual implementation. This definition of the `__init__()`
    method lacks the `@overload` decorator. The implementation uses the superclass'`__init__()`
    method to build a `List[SampleDict]` object. A subclass might want to extend this
    method to partition the data when creating a `SamplePartition` object.
  prefs: []
  type: TYPE_NORMAL
- en: The intent is to be able to subclass this with a class having a name like `SomeSamplePartition`,
    and use `data = SomeSamplePartition(data, training_subset=0.67)` to create an
    object, `data`, which is a list with a few extra features.
  prefs: []
  type: TYPE_NORMAL
- en: Since this is a superclass, we haven't provided a definition for the `training`
    or `testing` properties. Each algorithm can have different implementations of
    the methods that provide values for these attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This depends on the following `SampleDict` definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This tells **mypy** that we're working with a dictionary that has only the five
    supplied keys and no others. This can support some validation to check that literal
    key values match this set.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at some subclasses that provide different partitioning strategies.
    We'll start with one that shuffles and cuts, like a deck of cards.
  prefs: []
  type: TYPE_NORMAL
- en: A shuffling strategy for partitioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One alternative is to shuffle and cut a list – precisely the way a deck of cards
    is shuffled and cut before a game. We can use `random.shuffle()` to handle the
    randomized shuffling. The cut is – in a way – a hyperparameter. How large should
    the training set be compared to the testing set? Suggestions for knowledgeable
    data scientists include 80% to 20%, 67% to 33%, and an even 50% to 50% split.
    Because expert opinion varies, we need to provide a way for a scientist to adjust
    the partition ratio.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll make the split a feature of the class. We can create separate subclasses
    to implement alternative splits. Here''s a shuffling implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Since we're extending the `SamplePartition` superclass, we can leverage the
    overloaded `__init__()` method definitions. For this subclass, we need to provide
    a concrete implementation compatible with the superclass.
  prefs: []
  type: TYPE_NORMAL
- en: The two properties, `training` and `testing`, both make use of an internal `shuffle()`
    method. This method uses the split attribute to make sure it will shuffle the
    samples exactly one time. In addition to tracking whether or not the data is shuffled,
    the `self.split` attribute also shows where to split the samples into training
    and test subsets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `training` and `testing` properties also use Python list slicing to subdivide
    the raw `SampleDict` objects, and build useful `TrainingKnownSample` and `TestingKnownSample`
    objects from the raw data. These rely on a list comprehension to apply a class
    constructor, for example `TrainingKnownSample`, to the dictionary of row values
    in a subset of the list, `self[: self.split]]`. The list comprehension saves us
    from building a list with a `for` statement and a bunch of `append()` operations.
    We''ll look at even more variations of this in *Chapter 10*, *The Iterator Pattern*.'
  prefs: []
  type: TYPE_NORMAL
- en: Because this depends on the `random` module, the results are difficult to predict,
    making testing needless complex. Many data scientists want the data shuffled,
    but they also want reproducible results. By setting `random.seed()` to a fixed
    value, we can create random, but reproducible, collections of samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'This works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: With a random seed of `42`, we always get the same two samples in the testing
    set.
  prefs: []
  type: TYPE_NORMAL
- en: 'This allows us to build the initial list in a variety of ways. We can, for
    example, append data items to an empty list, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The `SamplePartition` subclass of `list` will inherit all the methods of the
    parent class. This allows us to make changes to the internal state of the list
    prior to extracting the training and testing subsets. We've added the sizing parameter
    as a keyword-only parameter to make sure it's clearly separated from the list
    object used to initialize the list.
  prefs: []
  type: TYPE_NORMAL
- en: An incremental strategy for partitioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have an alternative to splitting a single list after it's been built. Instead
    of extending the `list` class to provide two sub-lists, we can reframe the problem
    slightly. Let's define a subclass of `SamplePartition` that makes a random choice
    between testing and training on each `SampleDict` object that is presented via
    initialization, or the `append()` or `extend()` methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an abstraction that summarizes our thinking on this. We''ll have three
    methods for building a list, and two properties that will provide the training
    and testing sets, as below. We don''t inherit from `List` because we''re not providing
    any other list-like features, not even `__len__()`. The class has only five methods,
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This definition has no concrete implementations. It provides five placeholders
    where methods can be defined to implement the necessary dealing algorithm. We've
    changed the definition of the `training_subset` parameter slightly from the previous
    example. Here, we've defined it as two integers. This lets us count and deal incrementally.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how we can extend this to create a concrete subclass that wraps two
    internal collections. We''ll break this into two parts – first, building the collections,
    and then building the properties to expose the values of the collections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: We've defined an initializer that sets the initial state of two empty collections.
    Then, it uses the `extend()` method to build the collections from a source iterable,
    if it's provided.
  prefs: []
  type: TYPE_NORMAL
- en: The `extend()` method relies on the `append()` method to allocate a `SampleDict` instance
    to either the testing or training subsets. The `append()` method actually does
    all the work. It counts the items and makes a decision based on some modulo arithmetic.
  prefs: []
  type: TYPE_NORMAL
- en: The training subset is defined as a fraction; we've shown it defined as a tuple,
    (8, 10), with a comment suggesting this means 8/10 or 80% training, the remainder
    for testing. For a given counter value, *c*, if *c* *< 8 (mod 10)*, we'll call
    it training, while if *c* *≥* *8 (mod 10)*, we'll call it testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the remaining two methods that are used to expose the values of the
    two internal list objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: To an extent, these can be seen as useless. It's common in Python to simply
    name the two internal collections `self.training` and `self.testing`. If we use
    attributes, we don't really need these property methods.
  prefs: []
  type: TYPE_NORMAL
- en: We've seen two class designs to partition the source data into testing and training
    subsets. One version relies on random numbers for shuffling, while the other doesn't
    rely on a random number generator. There are, of course, other combinations of
    random-based selection and incremental distribution of items that we've left as
    exercises for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: Recall
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some of the key points in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Using abstract base class definitions is a way to create class definitions with
    placeholders. This is a handy technique, and can be somewhat clearer than using
    `raise NotImplementedError` in unimplemented methods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ABCs and type hints provide ways to create class definitions. An ABC is a type
    hint that can help to clarify the essential features we need from an object. It's
    common, for example, to use `Iterable[X]` to emphasize that we need one aspect
    of a class implementation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `collections.abc` module defines abstract base classes for Python's built-in
    collections. When we want to make our own unique collect class that can integrate
    seamlessly with Python, we need to start with the definitions from this module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating your own abstract base class leverages the `abc` module. The `abc.ABC`
    class definition is often a perfect starting point for creating an abstract base
    class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bulk of the work is done by the `type` class. It's helpful to review this
    class to understand how classes are created by the methods of `type`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python operators are implemented by special methods in classes. We can – in
    a way – "overload" an operator by defining appropriate special methods so that
    the operator works with objects of our unique class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extending built-ins is done via a subclass that modifies the behavior of a built-in
    type. We'll often use `super()` to leverage the built-in behavior.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can implement our own metaclasses to change – in a fundamental way – how
    Python class objects are built.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've looked at the concept of defining abstract classes to define some – but
    not all – common features of two objects. Take a quick look around to see how
    you can apply these principles to your own work. A script can often be restated
    as a class; each major step of the work a separate method. Do you have similar-looking
    scripts that – perhaps – share a common abstract definition? Another place to
    find things that are partially related is in the classes that describe data files.
    A spreadsheet file often has small variations in layout; this suggests they have
    a common abstract relationship, but a method needs to be part of an extension
    to handle the variations in the layouts.
  prefs: []
  type: TYPE_NORMAL
- en: When we think about the `DDice` class, there's yet another enhancement that
    would be nice. Right now, the operators are all defined for `DDice` instances
    only. In order to create a hand of dice, we need to – somewhere – use a `DDice`
    constructor. This leads to `3*DDice(D6)+2`, which seems to be needlessly wordy.
  prefs: []
  type: TYPE_NORMAL
- en: 'It would be nicer to be able to write `3*d6+1`. This implies some changes to
    the design:'
  prefs: []
  type: TYPE_NORMAL
- en: Since we can't (easily) apply operators to classes, we have to work with instances
    of classes. We've assumed `d6 = D6()` was used to create a `Die` instance that
    can be an operand.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `Die` class needs a `__mul__()` method and an `__rmul__()` method. When
    we multiply a `Die` instance by an integer, this will create a `DDice` instance
    populated with the die's type, `DDice(type(self))`. This is because `DDice` expects
    a type and it creates its own instances from the type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This creates a circular relationship between `Die` and `DDice`. It doesn't present
    any real problems because both definitions are in the same module. We can use
    strings in the type hints, so having a `Die` method use a type hint of `-> "DDice"`
    works out nicely. The **mypy** program can use strings for forward references
    to types that haven't been defined yet.
  prefs: []
  type: TYPE_NORMAL
- en: Now, look back over some of the examples we looked at in previous chapters.
    Can we leverage an abstract class definition to perhaps simplify the various ways
    in which `Sample` instances need to behave?
  prefs: []
  type: TYPE_NORMAL
- en: Look at the `DieMeta` example. As written, the `logged_roll()` method of the
    metaclass will discard any return value from the concrete `roll()` method in a
    subclass. This may not be appropriate in all cases. What kind of rewrite is required
    to make the metaclass method wrapper return a value from the wrapped method? Does
    this change the `DieLog` superclass definition?
  prefs: []
  type: TYPE_NORMAL
- en: Can we use the superclass to provide a logger? (It seems like the answer is
    a resounding "yes.")
  prefs: []
  type: TYPE_NORMAL
- en: 'More importantly, can we use a decorator to provide logging for a concrete
    `roll()` method? Write this decorator. Then consider whether or not we can trust
    developers to include this decorator. Should we trust other developers to use
    the framework correctly? While we can imagine developers forgetting to include
    the decorator, we can also imagine unit tests to confirm that log entries are
    written. Which seems better: a visible decorator with a unit test or a metaclass
    that tweaks code invisibly?'
  prefs: []
  type: TYPE_NORMAL
- en: In the case study, we defined the testing and training properties as `Iterable[SampleDict]`
    instead of `List[SampleDict]`. When we look at `collections.abc`, we see that
    a `List` is a `Sequence` that is a subclass of the `Iterable` base class. Can
    you see advantages to distinguishing between these three levels of abstraction?
    If `Iterable` works in general, should we always use iterables? What aspects distinguish
    `Sequence` from `Iterable`? Do the different collections of features have any
    impact on the classes in the case study?
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we focused on identifying objects, especially objects that
    are not immediately apparent; objects that manage and control. Objects should
    have both data and behaviors, but properties can be used to blur the distinction
    between the two. The DRY principle is an important indicator of code quality,
    and inheritance and composition can be applied to reduce code duplication.
  prefs: []
  type: TYPE_NORMAL
- en: In the next two chapters, we'll cover several of the built-in Python data structures
    and objects, focusing on their object-oriented properties and how they can be
    extended or adapted.
  prefs: []
  type: TYPE_NORMAL
