- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As well as logging, the other key element of observability is metrics. Metrics
    allow you to see the general state of the system and observe trends and situations
    that are mostly caused by multiple, perhaps even many, tasks being executed at
    the same time.
  prefs: []
  type: TYPE_NORMAL
- en: During this chapter, we will mostly use examples of web services, like request
    metrics. Do not feel restricted by them; you can generate metrics in all kinds
    of services!
  prefs: []
  type: TYPE_NORMAL
- en: When monitoring a live system, typically metrics are the main focus, as they
    allow you to see at a glance whether everything appears to be working correctly.
    Normally with metrics, it is possible to detect if a system is struggling, for
    example, for a sudden increase in the number of incoming requests, but also to
    foresee problems by showing trends, like a small but constant increase in the
    number of requests. This allows you to act preemptively, without waiting until
    a problem is serious.
  prefs: []
  type: TYPE_NORMAL
- en: Generating a good metric system to monitor the life of a system is invaluable
    to be able to react quickly when problems arise. Metrics can also be used as a
    base for automatic alerts that can help warn about certain conditions taking place,
    typically something to investigate or correct.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Metrics versus logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating metrics with Prometheus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Querying Prometheus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proactively working with metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alerting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, we will take a look at metrics compared with the other main tool for
    observability, logs.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics versus logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in the previous chapter, logs are text messages produced as code is
    executed. They are good at giving visibility on each of the specific tasks that
    the system is performing, but they generate a huge amount of data, which is difficult
    to digest in bulk. Instead, only small groups of logs are able to be analyzed
    at any given time.
  prefs: []
  type: TYPE_NORMAL
- en: Normally, the logs analyzed will all be related to a single task. We saw in
    the previous chapter how to use a request ID for that. But on certain occasions,
    it may be necessary to check all logs happening in a particular time window to
    see crossing effects, like a problem in one server that affects all tasks during
    certain times.
  prefs: []
  type: TYPE_NORMAL
- en: But sometimes the important information is not a specific request, but to understand
    the behavior of the system as a whole. Is the load of the system growing compared
    to yesterday's? How many errors are we returning? Is the time it takes to process
    tasks increasing? Or decreasing?
  prefs: []
  type: TYPE_NORMAL
- en: All those questions are impossible to answer with logs, as they require a broader
    view, at a higher level. To be able to achieve that, the data needs to be aggregated
    to be able to understand the system as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: The information to store in metrics is also different. While each recorded log
    is a text message, each produced metric is a number. These numbers will later
    be statistically processed to aggregate the information.
  prefs: []
  type: TYPE_NORMAL
- en: We will talk later in the chapter about the different kinds of numbers that
    can be produced as a metric.
  prefs: []
  type: TYPE_NORMAL
- en: The difference between the amount of information produced in each record means
    that metrics are much more lightweight compared with logs. To further reduce the
    amount of data stored, the data is aggregated automatically.
  prefs: []
  type: TYPE_NORMAL
- en: The resolution of metrics may depend on the tool and set configuration. Keep
    in mind that a higher resolution will require more resources to store all the
    data. A typical resolution is one minute, which is small enough to present detailed
    information unless you have a very active system that routinely receives 10 tasks
    per second or more.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics should capture and analyze information related to performance, such
    as the average time to process a task. That allows you to detect possible bottlenecks
    and act quickly in order to improve the performance of the system. This is easier
    to do in an aggregated way, as information for a single task, like generated logs,
    may not capture enough information to see the big picture. An important outcome
    of this is to be able to see trends and detect problems before they grow too big,
    remediating them early. Compared to this, logs are mostly used after the fact
    and are difficult to use as a way to take preventive action.
  prefs: []
  type: TYPE_NORMAL
- en: Kinds of metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are different kinds of metrics that can be produced. This can be different
    depending on the specific tool used to generate the metrics, but in general, there
    are a few that are common in most systems, like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Counter**: A trigger is generated each time something happens. This will
    be counted and aggregated as a total; for example, in a web service, the number
    of requests or the number of generated errors. Counters are useful for understanding
    how many times a certain action happens in the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gauge**: A single number across the system. A gauge number can go up or down,
    but the last value overwrites the previous, as it stores the general state of
    the system; for example, the number of elements in a queue, or the number of existing
    workers in the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Measure**: Events that have a numeric value associated with them. These numbers
    can be averaged, summed, or aggregated in a certain way. Compared with gauges,
    the difference is that previous measures are still independent; for example, when
    we emit a metric with a request time in milliseconds and request size in bytes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measures can also work as counters, since each emitted event is, in essence,
    a counter. For example, tracking the request time will also count the number of
    requests, as it will be generated once per request. Tools will normally create
    the associated counter automatically for every measure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Defining which metric is adequate for the specific value to measure is important.
    In most cases, they'll be *measures*, to allow storing a value produced by events.
    *Counters* are normally evident (they are *measures* without values), while *gauges*
    are normally the ones that are less obvious and can present more of a challenge
    on when to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics can also be derived from other metrics to generate new ones. For example,
    we can divide the number of requests that return an error code by the total number
    of requests to produce an error percentage. Such derived metrics can help you
    understand information in a meaningful way.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also two kinds of metric systems, depending on how the metrics are
    produced:'
  prefs: []
  type: TYPE_NORMAL
- en: Every time there's a metric produced, an event gets *pushed* toward the metrics
    collector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each system maintains its own metrics internally, which are periodically *pulled*
    from the metrics collector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each system has its own pros and cons. Pushing events produces higher traffic
    and activity, as every individual event is sent immediately, which can cause bottlenecks
    and delays. Pulling events will only sample the information, and produce lower-resolution
    data, as it can miss what happened between samples, but it's more stable as the
    number of requests is not increasing with the number of events.
  prefs: []
  type: TYPE_NORMAL
- en: Both approaches are used, but the current trend is moving toward pulling systems.
    They reduce the amount of maintenance that is required for pushing systems and
    are easier to scale.
  prefs: []
  type: TYPE_NORMAL
- en: We will use some examples with Prometheus, a metrics system that uses the pulling
    approach. The most used exponent of the push approach is Graphite.
  prefs: []
  type: TYPE_NORMAL
- en: Generating metrics with Prometheus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prometheus is a popular metrics system that is well supported and easy to use.
    We will use it as an example during the chapter to show how to collect metrics
    and how it interconnects with other tools to display metrics.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw before, Prometheus uses the *pulling* approach to metrics generation.
    That means that any system that produces metrics will run its own internal Prometheus
    client that keeps track of metrics.
  prefs: []
  type: TYPE_NORMAL
- en: For web services, this can be added as an extra endpoint that serves the metrics.
    This is the approach taken by the `django-prometheus` module, which will automatically
    collect a lot of common metrics for a Django web service.
  prefs: []
  type: TYPE_NORMAL
- en: We will build up from the Django application code presented in *Chapter 6*,
    *Web Server Structures*, to present a working application. Check the code in GitHub
    at [https://github.com/PacktPublishing/Python-Architecture-Patterns/tree/main/chapter_13_metrics/microposts](https://github.com/PacktPublishing/Python-Architecture-Patterns/tree/main/chapter_13_metrics/microposts).
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to set up the environment to be sure to install all the required packages
    and dependencies of the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by creating a new virtual environment, as introduced in *Chapter
    11*, *Package Management*, to be sure to create our own isolated sandbox to install
    packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now install the prepared list of requirements, stored in `requirements.txt`.
    This contains the Django and Django REST framework modules, as seen in *Chapter
    6*, *Web Server Structures*, but also the Prometheus dependency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To start the server, go to the `micropost` subdirectory and run the `runserver`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The application is now accessible in the root address: `http://localhost:8000`,
    for example, `http://localhost:8000/api/users/jaime/collection`.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that we started the server at address 0.0.0.0\. This opens Django to serve
    any IP address, and not only requests coming from `localhost`. This is an important
    detail that will be clarified later.
  prefs: []
  type: TYPE_NORMAL
- en: Note also that the root address will return a 404 error, as no endpoint is defined
    there.
  prefs: []
  type: TYPE_NORMAL
- en: If you remember from *Chapter 3*, *Data Modeling*, we added some initial data,
    so you can access the URLs `http://localhost:8000/api/users/jaime/collection`
    and `http://localhost:8000/api/users/dana/collection` to see some data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_13_1.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.1: Accessing an available URL in the application'
  prefs: []
  type: TYPE_NORMAL
- en: Access these pages a couple of times to produce metrics that we can later access.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Django Prometheus
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The configuration of the `django-prometheus` module is done in the `microposts/settings.py`
    file, where we need to do two things.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, add the `django-prometheus` application to the installed app list which
    enables the module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to include the proper middlewares to track requests. We need to
    put one middleware at the start of the request process and another at the end,
    to be sure to capture and measure the whole process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Check the position of `django.prometheus.middleware.PrometheusBeforeMiddleware`
    and `django_prometheus.middleware.PrometheusAfterMiddleware`.
  prefs: []
  type: TYPE_NORMAL
- en: We also changed the `ALLOWED_HOSTS` value to be `'*'` and allow requests from
    any hostname. This detail will be explained a bit later.
  prefs: []
  type: TYPE_NORMAL
- en: With this configuration, the Prometheus collection is now enabled. But we also
    need a way to access them. Remember, an important element for the Prometheus system
    is that each application serves its own metric collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we can add an endpoint to the file `microposts/url.py`, which
    handles the top-level URLs for the system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `path('', include('django_prometheus.urls'))` line sets up a `/metrics`
    URL that we can now access.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main URL root shows that there''s a new endpoint – `/metrics`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_13_02.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.2: This page appears because the DEBUG mode is active. Remember to
    deactivate it before deploying in production'
  prefs: []
  type: TYPE_NORMAL
- en: When accessing the `/metrics` endpoint, it shows all the collected metrics.
    Note that there are a lot of metrics that are collected. This is all in text format,
    and it's expected to be collected by a Prometheus metric server.
  prefs: []
  type: TYPE_NORMAL
- en: Be sure to access a few times the endpoints `http://localhost:8000/api/users/jaime/collection`
    and `http://localhost:8000/api/users/dana/collection` to produce some metrics.
    You can check how some metrics, like `django_http_requests_total_by_view_transport_method_total{method="GET",transport="http",view="user-collection"}`,
    are increasing.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_13_3.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.3: The raw Prometheus metrics, as collected by the application'
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to start a Prometheus server that can pull the info and display
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Starting a Prometheus server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Prometheus server will pull periodically for metrics to all the configured
    applications that are collecting their metrics. These elements are called *targets*
    by Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to start a Prometheus server is to start the official Docker
    image.
  prefs: []
  type: TYPE_NORMAL
- en: We introduced Docker in *Chapter 9*, *Microservices vs Monolith*. Refer to that
    chapter for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to start the server, but before that, we need to set up the configuration
    in the `prometheus.yml` file. You can check the example on GitHub: [https://github.com/PacktPublishing/Python-Architecture-Patterns/blob/main/chapter_13_metrics/prometheus.yml](https://github.com/PacktPublishing/Python-Architecture-Patterns/blob/main/chapter_13_metrics/prometheus.yml):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The config file has two main sections. The first with `global` indicates how
    often to scrape (to read information from the targets) and other general configuration
    values.
  prefs: []
  type: TYPE_NORMAL
- en: The second, `scrape_config`, describes what to scrape from, and the main parameter
    is `targets`. Here, we need to configure all our targets. This one in particular
    needs to be described by its external IP, which will be the IP from your computer.
  prefs: []
  type: TYPE_NORMAL
- en: This address cannot be `localhost`, as inside the Prometheus Docker container
    it will resolve as the same container, which is not what you want. You'll need
    to find out your local IP address.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you don''t know how to find it through ipconfig or ifconfig, you can check
    out this article on ways to find it: [https://lifehacker.com/how-to-find-your-local-and-external-ip-address-5833108](https://lifehacker.com/how-to-find-your-local-and-external-ip-address-5833108).
    Remember that it''s your **local address**, not the external one.'
  prefs: []
  type: TYPE_NORMAL
- en: This is to ensure that the Prometheus server can access the Django application
    that's running locally. As you remember, we opened the access allowing connections
    from any hostname with the option `0.0.0.0` when starting the server and allowing
    all hosts in the config parameter `ALLOWED_HOSTS`.
  prefs: []
  type: TYPE_NORMAL
- en: Double-check that you can access the metrics in the local IP.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated with low confidence](img/B17580_13_4.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.4: Note the IP used to access; remember that you should use your
    own local one'
  prefs: []
  type: TYPE_NORMAL
- en: With all this information, you are now ready to start the Prometheus server
    in Docker, using your own config file.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that this command requires you to find the full path to the `prometheus.yml`
    file. If you are in the same directory, you can address it as `$(pwd)/prometheus.yml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, run the following `docker` command, adding the whole path to the
    config file to share it with the new container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The `docker` command is structured in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-p 9090:9090` maps the local 9090 port to the 9090 port inside the container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-v /full/path/to/file/prometheus.yml:/etc/prometheus/prometheus.yml` mounts
    the local file (remember to add the full path or use `$(pwd)/prometheus.yml`)
    in the expected configuration route for Prometheus'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker run prom/Prometheus` is the command to run the `prom/Prometheus` image,
    which is the official Prometheus image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the Prometheus server is up and running, the server is accessible at `http://localhost:9090`.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, screenshot, monitor, screen'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_13_5.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.5: The empty graph Prometheus page'
  prefs: []
  type: TYPE_NORMAL
- en: From here, we can start querying the system.
  prefs: []
  type: TYPE_NORMAL
- en: Querying Prometheus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prometheus has its own query system, called PromQL, and ways of operating with
    metrics that, while powerful, can be a little confusing at the beginning. Part
    of it is its pull approach to metrics.
  prefs: []
  type: TYPE_NORMAL
- en: For example, requesting one useful metric, like `django_http_requests_latency_seconds_by_view_method_count`,
    will display how many times each view has been called for each method.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application, table, Excel'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_13_6.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.6: Notice how the prometheus-django-metrics view is called more often,
    as it is called automatically by Prometheus once every 15 seconds to scrape the
    results'
  prefs: []
  type: TYPE_NORMAL
- en: This is presented as an accumulated value that grows over time. This is not
    very useful, as it's difficult to make sense of what exactly it means.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, the value is more likely to be presented as a `rate`, representing
    how many requests have been detected per second. For example, with a resolution
    of 1 minute, `rate(django_http_requests_latency_seconds_by_view_method_count[1m])`
    shows the following graph instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application, table'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_13_7.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.7: Note that the different methods and views are displayed as different
    lines'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there's a constant number of requests from `prometheus-django-metrics`,
    which is Prometheus requesting the metrics information. This happens once every
    15 seconds, or approximately 0.066 times per second.
  prefs: []
  type: TYPE_NORMAL
- en: In the graph, there's also another spike of the `user-collection` method happening
    at 15:55, at the time where we manually generated some requests to the service.
    As you can see, the resolution is per minute, as described in the rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to aggregate all of this in a single graph, we can use the sum operator,
    specifying what we want to aggregate from. To sum all `GET` requests, for example,
    with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces this other graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application, table, Excel'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_13_8.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.8: Note the bottom value is based on the baseline created by the
    calls to prometheus-django-metrics'
  prefs: []
  type: TYPE_NORMAL
- en: To plot times instead, the metric to use is the `django_http_requests_latency_seconds_by_view_method_bucket`
    one. The bucket metrics are generated in a way that can be combined with the `histogram_quantile`
    function to display a particular quantile, which is useful for giving a proper
    feeling of times.
  prefs: []
  type: TYPE_NORMAL
- en: For example, quantile 0.95 means that the time is the highest of 95% of the
    requests. This is more useful than creating averages as they can get skewed by
    high numbers. Instead, you can draw the quantile 0.50 (the maximum time it takes
    for half of the requests), the quantile 0.90 (the maximum time for most of the
    requests), and quantile 0.99 for the very top time it takes to return a request.
    This allows you to get a better picture, as it's different from the situation
    of growing quantile 0.50 (most requests take longer to return) with growing quantile
    0.99 (some slow queries are getting worse).
  prefs: []
  type: TYPE_NORMAL
- en: 'To plot the 0.95 quantile over a period of 5 minutes, the following query can
    be generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'When you run it, you should receive the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_13_9.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.9: Note how the metrics collection is much faster than the user-collection
    requests'
  prefs: []
  type: TYPE_NORMAL
- en: To plot times instead, the metric to use is the `django_http_requests_latency_seconds_by_view_method_bucket`
    one. The bucket metrics are generated in a way that can be combined with the `histogram_quantile`
    function to display a particular quantile, which is useful for giving a proper
    feeling of times.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics can also be filtered to display only specific labels, and a good number
    of functions to multiply, divide, add, create averages, and all kinds of operations
    are available.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus queries can be a bit long and complicated when trying to display
    the result of several metrics, such as the percentage of successful requests over
    the total. Be sure to test that the result is what you expect it to be and allocate
    time to tweak the queries later to keep improving them.
  prefs: []
  type: TYPE_NORMAL
- en: The interface has autocompleted, which can help you find certain metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prometheus is normally paired with Grafana. Grafana is an open source, interactive
    visualization tool that can be connected with Prometheus to create rich dashboards.
    This leverages the collection of metrics and helps visualize the state of the
    system in a much more understandable way. Describing how to use Grafana is out
    of scope for this book, but using it to display metrics is highly recommended:
    [https://grafana.com/](https://grafana.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the Prometheus documentation about queries to find out more: [https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/).'
  prefs: []
  type: TYPE_NORMAL
- en: Proactively working with metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've seen, metrics show an aggregated point of view for the status of the
    whole cluster. They allow you to detect trending problems, but it's difficult
    to pinpoint a single spurious error.
  prefs: []
  type: TYPE_NORMAL
- en: This shouldn't stop us from considering them as a critical tool for successful
    monitoring because they can tell whether the whole system is healthy. In some
    companies, the most critical metrics are on permanent display on screens so the
    operations team can see them and react quickly to any sudden problem.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the proper balance of what metrics are the key ones for a service is
    not as straightforward as it seems, and it will require time and experience, perhaps
    even trial and error.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are, though, four metrics for online services that are considered always
    important. They are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Latency**: How many milliseconds it takes for the system to respond to a
    request. Depending on the service, sometimes seconds can be used instead. In my
    experience, milliseconds are typically the adequate time scale, as most web applications
    take between 50 ms and 1 second to respond, depending on the request. Requests
    taking longer than 1 second are typically rarer, though there are always some,
    depending on the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traffic**: The number of requests flowing through the system per unit of
    time, for example, the number of requests per minute.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Errors**: The percentage of requests received that return an error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Saturation**: Describing whether the capacity of the cluster has enough headroom.
    This includes elements as available hard drive space, memory, and so on. For example,
    there''s 15% available RAM in the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main tool to check saturation is the multiple default exporters available
    to collect most of the hardware information automatically, like memory, CPU, and
    hard drive space. When using a cloud provider, normally they expose their own
    set of related metrics, like CloudWatch in AWS.
  prefs: []
  type: TYPE_NORMAL
- en: These metrics can be found in the Google SRE book as *the four golden signals*
    and are recognized as the most important high-level elements for successful monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Alerting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When problems are detected through the metrics, an automatic alert should be
    triggered. Prometheus has an alert system that will raise when a defined metric
    fulfills the defined alert.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the Prometheus documentation on alerting for more information: [https://prometheus.io/docs/alerting/latest/overview/](https://prometheus.io/docs/alerting/latest/overview/).'
  prefs: []
  type: TYPE_NORMAL
- en: Normally, alerts will be configured when the value of metrics is crossing some
    threshold. For example, the number of errors is higher than X, or the time to
    return a request is too high.
  prefs: []
  type: TYPE_NORMAL
- en: An alert could also be that some element is too low; for example, if the number
    of requests in a system falls to zero, that could be an indication that the system
    is down.
  prefs: []
  type: TYPE_NORMAL
- en: The built-in Alertmanager can alert in some ways, like sending an email, but
    it can also be connected to other tools to perform more complex actions. For example,
    connecting to an integrated incident solution like Opsgenie ([https://www.atlassian.com/software/opsgenie](https://www.atlassian.com/software/opsgenie))
    allows you to create alert flows, such as sending emails and SMS, calls.
  prefs: []
  type: TYPE_NORMAL
- en: While alerts can be generated directly from metrics, there are tools that allow
    you also to generate alerts from logs directly. For example, Sentry ([https://sentry.io/](https://sentry.io/))
    will aggregate errors based on logs and can set up thresholds to escalate toward
    more active alerts, like sending emails.Another alternative is to derivate metrics
    from logs using external logging systems. This allows you, for example, to create
    a counter based on the number of `ERROR` logs, or more complicated metrics. These
    systems, once more, allow you to trigger alerts based on these derived metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Alerting, as with metrics, is an ongoing process. Some key thresholds won't
    be evident at the start of the system, and only experience will allow you to discover
    them. In the same way, it's very likely that some alerts are created that don't
    require active monitoring, and should be disconnected to ensure that the alerts
    in the system are on point and have a high signal-to-noise ratio.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we described what metrics are and how they compare with logs.
    We described how metrics are useful to analyze the general state of the system,
    while logs describe specific tasks, being more difficult to describe the aggregated
    situation.
  prefs: []
  type: TYPE_NORMAL
- en: We enumerated different kinds of metrics that can be produced and described
    Prometheus, a common metrics system that uses the pull approach on how to capture
    metrics.
  prefs: []
  type: TYPE_NORMAL
- en: We set an example of how to generate metrics automatically in Django by installing
    and configuring the `django-prometheus` module, and how to start a Prometheus
    server that scrapes the generated metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keep in mind that you can also generate your own custom metrics, not having
    to only rely on the ones in an external module. Check the Prometheus client to
    see how, for example, for Python: [https://github.com/prometheus/client_python](https://github.com/prometheus/client_python).'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we described how to query metrics in Prometheus, introducing PromQL, and
    showed some common examples of how to display metrics, plot `rate` to see clearly
    how the metrics are changing over time, and how to use the `histogram_quantile`
    function to work with times.
  prefs: []
  type: TYPE_NORMAL
- en: We also showed in the chapter how to work proactively to detect common problems
    as soon as possible and what the four golden signals are, as described by Google.
    Finally, we introduced alerts as a way to be notified when metrics are out of
    a normal margin. Using alerts is a smart way to be notified without having to
    manually look at metrics.
  prefs: []
  type: TYPE_NORMAL
