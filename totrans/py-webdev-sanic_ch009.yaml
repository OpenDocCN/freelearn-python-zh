- en: 8 Running a Sanic Server
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 运行Sanic服务器
- en: 'In the time that I have been involved with the Sanic project—and specifically,
    in trying to assist other developers by answering their support questions—there
    is one topic that perhaps comes up more than any other: deployment. That one word
    is often bundled with a mixture of confusion and dread.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在我参与Sanic项目的时间里——特别是，通过回答其他开发者的支持问题来帮助他们——有一个主题似乎比其他任何主题都更频繁地出现：部署。这个单词常常与困惑和恐惧的混合情绪联系在一起。
- en: Building a web application can be a lot of fun. I suspect that I am not alone
    in finding a tremendous amount of satisfaction in the build process itself. One
    of the reasons that I love software development in general—and web development
    in particular—is that I enjoy the almost puzzle-like atmosphere of fitting solutions
    to a given problem. When the build is done and it is time to launch, that is where
    the anxiety kicks in.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 构建Web应用程序可以非常有趣。我怀疑我不是唯一一个在构建过程中本身就能找到巨大满足感的人。我喜欢软件开发的其中一个原因——尤其是Web开发——是因为我喜欢将解决方案与给定问题相匹配的几乎像谜一样的氛围。当构建完成，是时候启动时，焦虑就出现了。
- en: I cannot overemphasize this next point enough. One of Sanic’s biggest assets
    is its bundled web server. This is not just a gimmick, or some side feature to
    be ignored. The fact that Sanic comes bundled with its own web server truly does
    simplify the build process. Think about traditional Python web frameworks like
    Django or Flask, or about some of the newer ASGI frameworks. For them to become
    operational and connected to the web, you need a production-grade web server.
    Building the application is only one step. Deploying it requires knowledge and
    proficiency in another tool. Typically, the web server used to deploy your application
    built with one of those frameworks is not the same web server that you develop
    upon. For that, you have a development server. Not only is this an added complexity
    and dependency, but it also means you are not developing against the actual server
    that will be running your code in production. Is anyone else thinking what I am
    thinking? Bugs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我无法过分强调接下来的观点。Sanic最大的优势之一是其捆绑的Web服务器。这不仅仅是一个噱头，或者一些可以忽略的辅助功能。Sanic附带自己的Web服务器确实简化了构建过程。想想传统的Python
    Web框架，比如Django或Flask，或者一些较新的ASGI框架。为了使它们能够运行并连接到网络，你需要一个生产级的Web服务器。构建应用程序只是第一步。部署它需要另一项工具的知识和熟练度。通常，用于部署使用这些框架构建的应用程序的网络服务器与您开发时使用的服务器不同。为此，您有一个开发服务器。这不仅增加了复杂性和依赖性，还意味着您不是在针对将在生产中运行您代码的实际服务器进行开发。还有人在想我正在想的事情吗？错误。
- en: 'In this chapter, we will look at what is required to run Sanic. We will explore
    different ways to run Sanic both in development and production to make the deployment
    process as easy as possible. We will start by looking at the server lifecycle.
    Then, we will discuss setting up both a local and a production-grade scalable
    service. We will cover:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨运行Sanic所需的内容。我们将探索在开发和生产环境中运行Sanic的不同方法，以使部署过程尽可能简单。我们将首先查看服务器生命周期。然后，我们将讨论设置本地和具有生产级可扩展性的服务。我们将涵盖：
- en: Handling the server lifecycle
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理服务器生命周期
- en: Configuring an application
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置应用程序
- en: Running Sanic locally
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本地运行Sanic
- en: Deploying to production
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署到生产环境
- en: Securing your application with TLS
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TLS保护您的应用程序
- en: Deployment examples
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署示例
- en: When we are done, your days of deployment-induced anxiety should be a thing
    of the past.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们完成时，您因部署而产生的焦虑应该会成为过去式。
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will, of course, continue to build upon the tools and knowledge from previous
    chapters. Earlier in *Chapter 3*, *Routing and Intaking HTTP Requests*, we saw
    some implementations that used Docker. Specifically, we were using Docker to run
    an Nginx server for static content. While it is not required for deploying Sanic,
    knowledge of Docker and (to a lesser extent) Kubernetes will be helpful. In this
    Chapter, we will be exploring the usage of Docker with Sanic deployments. If you
    are not a black-belt Docker or Kubernetes expert, do not worry. There will be
    examples on the GitHub repository: [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08).
    All that we hope and expect is some basic understanding and familiarity with these
    tools.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们将继续构建前几章的工具和知识。在*第3章*，*路由和接收HTTP请求*中，我们看到了一些使用Docker的实现。具体来说，我们使用Docker运行Nginx服务器来提供静态内容。虽然这不是部署Sanic所必需的，但了解Docker和（在一定程度上）Kubernetes将有所帮助。在本章中，我们将探讨与Sanic部署一起使用Docker的方法。如果你不是黑带Docker或Kubernetes专家，不要担心。GitHub仓库中将有示例：[https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08)。我们希望和期望的是对这些工具有一些基本的理解和熟悉。
- en: 'If you do not have these tools installed, you will need them to follow along:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有安装这些工具，你需要它们来跟上进度：
- en: '`git`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git`'
- en: '`docker`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker`'
- en: '`doctl`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`doctl`'
- en: '`kubectl`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl`'
- en: Handling the server lifecycle
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理服务器生命周期
- en: Throughout this book, we have spent a lot of time talking about the lifecycle
    of an incoming HTTP request. In that time, we have seen how we can attach to modify,
    and run code at different points in that cycle. Well, the lifecycle of the application
    server as a whole is no different.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们花了很多时间讨论传入HTTP请求的生命周期。在那段时间里，我们看到了我们如何在生命周期中的不同点附加、修改和运行代码。嗯，整个应用服务器的生命周期也没有什么不同。
- en: Whereas we had middleware and signals, the server lifecycle has what are called
    “listeners”. In fact, listeners are in effect (with one small exception) signals
    themselves. Before we look at how to use them, we will take a look at what listeners
    are available.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们有中间件和信号，但服务器生命周期中有什么被称为“监听器”。实际上，监听器在本质上（有一个小的例外）就是信号本身。在我们探讨如何使用它们之前，我们将看看有哪些监听器可用。
- en: Server listeners
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务器监听器
- en: The basic premise of a **listener** is that you are attaching some function
    to an **event** in the server’s lifecycle. As the server progresses through the
    startup and shutdown process, Sanic will trigger these events, and therefore allow
    you to easily plug in your own functionality. Sanic triggers events at both the
    startup and shutdown phases. For any other event during the life of your server,
    you should refer to the *Leveraging signals for intra-worker communication* section
    on Signals in *Chapter 6*, *Outside the Response Cycle*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**监听器**的基本前提是你在服务器生命周期中的某个**事件**上附加了一个函数。随着服务器通过启动和关闭过程，Sanic将触发这些事件，因此你可以轻松地插入自己的功能。Sanic在启动和关闭阶段都会触发事件。对于服务器生命周期中的任何其他事件，你应该参考*第6章*，*响应周期之外*中的*利用信号进行工作进程间通信*部分。'
- en: 'The order of the events is as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 事件的顺序如下：
- en: '`before_server_start`: This event naturally begins runs before the server is
    started. It is a great place to connect to a database, or perform any other operations
    that need to happen at the beginning of your application lifecycle. Anything that
    you might be inclined to do in the global scope would almost always be better
    off done here. The only caveat worth knowing about is that if you are running
    in ASGI mode, the server is already running by the time Sanic is even triggered.
    In that case, there is no difference between `before_server_start` and `after_server_start`.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`before_server_start`：这个事件自然是在服务器启动之前运行的。这是一个连接数据库或执行任何需要在应用程序生命周期开始时进行的操作的绝佳地方。你可能会在全局范围内做的事情几乎总是在这里做得更好。唯一值得注意的注意事项是，如果你在ASGI模式下运行，服务器在Sanic被触发之前就已经运行了。在这种情况下，`before_server_start`和`after_server_start`之间没有区别。'
- en: '`after_server_start`: A common misconception about this event is that it could
    encounter a race condition where the event runs *while* your server begins responding
    to HTTP requests. That is *not* the case. What this event means is that there
    was an HTTP server created and attached to the OS. The infrastructure is in place
    to begin accepting requests, but it has not happened yet. Only once all of your
    listeners for `after_server_start` are complete will Sanic begin to accept HTTP
    traffic.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`after_server_start`：关于这个事件的常见误解是它可能会遇到一个竞态条件，其中事件在服务器开始响应 HTTP 请求时运行。这并不是情况。这个事件意味着已经创建并附加到操作系统上的
    HTTP 服务器。基础设施已经到位，可以开始接受请求，但还没有发生。只有当所有 `after_server_start` 的监听器都完成后，Sanic 才会开始接受
    HTTP 流量。'
- en: '`before_server_stop`: This is a good place to start any cleanup you need to
    do. While you are in this location, Sanic is still able to accept incoming traffic,
    so anything that you might need to handle that should still be available (like
    database connections).'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`before_server_stop`：这是一个开始任何你需要进行的清理工作的好地方。当你在这个位置时，Sanic 仍然能够接受传入的流量，所以你可能需要处理的所有东西仍然可用（比如数据库连接）。'
- en: '`after_server_stop`: Once the server has been closed, it is now safe to start
    any cleanup that is remaining. If you are in ASGI mode, like `before_server_start`,
    this event is not actually triggered after the server is off because Sanic does
    not control that. It will instead immediately follow any `before_server_stop`
    listeners to preserve their ordering.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`after_server_stop`：一旦服务器被关闭，现在可以安全地开始任何剩余的清理工作。如果你处于 ASGI 模式，就像 `before_server_start`，这个事件实际上在服务器关闭后并不会被触发，因为
    Sanic 不控制这一点。相反，它将立即跟随任何 `before_server_stop` 监听器以保持它们的顺序。'
- en: There are two more listeners that are available to you. However, these additional
    listeners are *only* available with the Sanic server since they are specific to
    the Sanic server lifecycle. This is due to how the server works. When you run
    Sanic with multiple workers, what happens is that there is the main process that
    acts as an orchestrator. It spins up multiple subprocesses for each of the workers
    that you have requested. If you want to tap into the lifecycle of each of those
    worker processes, then you already have the tools at your disposal with the four
    listeners we just saw.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 还有两个额外的监听器可供你使用。然而，这些额外的监听器仅在 Sanic 服务器上可用，因为它们是特定于 Sanic 服务器生命周期的。这是由于服务器的工作方式。当你使用多个工作者运行
    Sanic 时，发生的情况是有主进程充当指挥者。它为每个请求的工作者启动多个子进程。如果你想深入了解每个工作者进程的生命周期，那么你已经有了我们刚才看到的四个监听器所提供的工具。
- en: 'However, what if you wanted to run some bit of code not on each worker process,
    but once in the main process: that orchestrator? The answer is the Sanic server’s
    main process events. They are `main_process_start` and `main_process_stop`. Other
    than the fact that they run inside the main process and not the workers, they
    otherwise work like the other listeners. Remember how I said that the listeners
    are themselves signals, with an exception? This is that exception. These listeners
    are not signals in disguise. For all practical purposes, this distinction is not
    important.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你想在主进程而不是每个工作进程中运行一些代码：那个指挥者？答案是 Sanic 服务器的主进程事件。它们是 `main_process_start`
    和 `main_process_stop`。除了它们在主进程中运行而不是在工作者中，它们在其他方面的工作方式与其他监听器相同。记得我提到监听器本身就是信号，但有例外吗？这就是那个例外。这些监听器不是伪装成信号的。从所有实际目的来看，这种区别并不重要。
- en: It is also worth mentioning that even though these events are meant to allow
    code to be run in the main process and not the worker process when in multi-worker
    mode, they are still triggered when you are running with a single worker process.
    When this is the case, it will be run at the extreme beginning and extreme end
    of your lifecycle.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得一提的是，尽管这些事件旨在允许在多工作者模式下在主进程中而不是工作者进程中运行代码，但即使你在单个工作者进程中运行时，它们也会被触发。在这种情况下，它们将在你的生命周期的极端开始和极端结束时运行。
- en: 'This raises an interesting and often seen mistake: double execution. Before
    continuing with listeners, we will turn our attention to mistakenly running code
    multiple times.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这引发了一个有趣且经常出现的错误：双重执行。在继续处理监听器之前，我们将关注错误地多次运行代码。
- en: Running code in the global scope
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在全局作用域中运行代码
- en: When you are preparing your application to run, it is not uncommon to initialize
    various services, clients, interfaces, and so on. You likely will need to perform
    some operations on your application very early in the process before the server
    even begins to run.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当你准备应用程序运行时，初始化各种服务、客户端、接口等是很常见的。你很可能需要在服务器开始运行之前，在处理过程的早期对应用程序执行一些操作。
- en: 'For example, let’s imagine that you are looking for a solution to help you
    better track your exceptions. You find a third-party service where you can report
    all of your exceptions and tracebacks to help you to better analyze, debug, and
    repair your application. To get started, the service provides some documentation
    to use their **software development kit** (**SDK**) as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们假设你正在寻找一个解决方案来帮助你更好地跟踪你的异常。你发现了一个第三方服务，你可以将所有的异常和回溯报告给它，以帮助你更好地分析、调试和修复你的应用程序。要开始使用，该服务提供了一些文档，说明如何使用他们的**软件开发工具包**（**SDK**）如下：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You get this setup and running in your multi-worker application, and you immediately
    start noticing that it is running multiple times, and not in your worker processes
    as expected. What is going on?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你将这个设置和运行在你的多工作进程应用程序中，然后你立即开始注意到它运行了多次，而不是像预期的那样在你的工作进程中。这是怎么回事？
- en: Likely, the issue is that you ran your initialization code in the global scope.
    By *global scope* in Python we mean something that is executing outside of a function
    or method. It runs on the outermost level in a Python file. In the above example,
    `init_error_reporting` runs in the global scope because it is not wrapped inside
    another function. The problem is that when multiple workers are running, you need
    to be aware of where and when that code is running. Since multiple workers mean
    multiple processes, and each process is likely to run your global scope, you need
    to be careful about what you put there.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能的问题是你在全局范围内运行了初始化代码。在Python中，我们所说的“全局范围”是指不在函数或方法中执行的部分。它在Python文件的最外层运行。在上面的例子中，`init_error_reporting`
    在全局范围内运行，因为它没有被另一个函数包裹。问题是，当多个工作进程运行时，你需要意识到代码在哪里以及何时运行。由于多个工作进程意味着多个进程，并且每个进程都可能运行你的全局范围，因此你需要小心地放置其中的内容。
- en: As a very general rule, stick to putting *any* operable code inside a listener.
    This allows you to control the where and when and will operate in a more consistent
    and easily predictable manner.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一条非常普遍的规则，坚持将任何可操作的代码放在监听器中。这允许你控制位置和时机，并且将以更一致和易于预测的方式运行。
- en: Setting up listeners
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设置监听器
- en: 'Using listeners should look very familiar since they follow a similar pattern
    found elsewhere in Sanic. You create a listener handler (which is just a function)
    and then wrap it with a decorator. It should look like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用监听器应该看起来非常熟悉，因为它们遵循Sanic其他地方发现的类似模式。你创建一个监听器处理程序（它只是一个函数），然后使用装饰器将其包装起来。它应该看起来像这样：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: What we see here is something *incredibly important* in Sanic development. This
    pattern should be committed to memory because attaching elements to your application
    `ctx` object increases your overall flexibility in development. In this example,
    we set up our database client so that it can be accessed from anywhere that our
    application can be (which is literally anywhere in the code).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里看到的是Sanic开发中非常重要的一点。这个模式应该牢记在心，因为将元素附加到你的应用程序`ctx`对象中，可以增加你在开发中的整体灵活性。在这个例子中，我们设置了数据库客户端，以便可以从任何地方访问它，即代码中的任何地方。
- en: One important thing to know is that you can control the order in which the listeners
    execute depending upon when they are defined. For the “start” time listeners (`before_server_start`,
    `after_server_start`, and `main_process_start`), they are executed in the order
    in which they are declared.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个重要的事情要知道，你可以根据定义的时间来控制监听器的执行顺序。对于“启动”时间监听器（`before_server_start`、`after_server_start`
    和 `main_process_start`），它们按照声明的顺序执行。
- en: For the *stop* time listeners (`before_server_stop`, `after_server_stop`, and
    `main_process_stop`) the opposite is true. They are run in the reverse order of
    declaration.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于“停止”时间监听器（`before_server_stop`、`after_server_stop` 和 `main_process_stop`），情况正好相反。它们按照声明的相反顺序运行。
- en: How to decide to use a *before* listener or an *after* listener
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 如何决定使用“在...之前”监听器或“在...之后”监听器
- en: As stated above, there persists a common misconception that logic must be added
    to `before_server_start` in the case you want to perform some operation before
    requests start. The fear is that using `after_server_start` might cause some kind
    of a race condition where some requests might hit the server in the moments before
    that event is triggered.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，存在一个常见的误解，即在你想在请求开始之前执行某些操作的情况下，逻辑必须添加到 `before_server_start` 中。这种担忧是，使用
    `after_server_start` 可能会导致某种竞争条件，其中某些请求可能会在触发该事件之前的一瞬间击中服务器。
- en: This is incorrect. Both `before_server_start` and `after_server_start` run to
    completion before any requests are allowed to come in.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是不正确的。`before_server_start` 和 `after_server_start` 都会在允许任何请求进入之前运行完成。
- en: So, then the question becomes when should you favor one over the other? There
    are, of course, some personal and application-specific preferences that could
    be involved. Generally, however, I like to use the `before_server_start` event
    to set up my application context. If I need to initialize some object and persist
    it to `app.ctx`, then I will reach for `before_server_start`. For any other use
    case (like performing any other types of external calls, or configuration, I like
    to use `after_server_start`. This is by no means a hard and fast rule, and I often
    break it myself.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，问题就变成了何时应该优先考虑其中一个？当然，可能会有一些个人和特定于应用程序的偏好。然而，一般来说，我喜欢使用 `before_server_start`
    事件来设置我的应用程序上下文。如果需要初始化某个对象并将其持久化到 `app.ctx`，那么我会选择 `before_server_start`。对于任何其他用例（如执行其他类型的外部调用或配置），我喜欢使用
    `after_server_start`。这绝对不是一条不可更改的规则，我经常自己打破它。
- en: 'Now that we understand the lifecycle of the server, there is one more missing
    bit of information that we need before we can run the application: configuration.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了服务器的生命周期，但在我们可以运行应用程序之前，我们还需要了解一些其他的信息：配置。
- en: Configuring an application
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置应用程序
- en: Sanic tries to make some reasonable assumptions out of the box about your application.
    With this in mind, you can certainly spin up an application and it should already
    have some reasonable default settings in place. While this may be acceptable for
    a simple prototype, as soon as you start to build your application you will realize
    that you need to configure it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Sanic 尝试在默认情况下对你的应用程序做出一些合理的假设。考虑到这一点，你当然可以启动一个应用程序，并且它应该已经有一些合理的默认设置。虽然这可能适用于一个简单的原型，但当你开始构建应用程序时，你会意识到你需要对其进行配置。
- en: And this is where Sanic’s configuration system comes into play.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 正是这个时候，Sanic 的配置系统开始发挥作用。
- en: 'Configuration comes in two main flavors: tweaking the Sanic runtime operation,
    and declaring a state of global constants to be used across your application.
    Both types of configuration are important, and both follow the same general principles
    for applying values.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 配置主要有两种形式：调整 Sanic 运行时操作，以及声明一个全局常量的状态，以便在整个应用程序中使用。这两种类型的配置都很重要，并且都遵循应用值的一般原则。
- en: We will take a closer look at what the configuration object is, how we can access
    it, and how it can be updated or changed.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将更详细地探讨配置对象是什么，我们如何访问它，以及如何更新或更改它。
- en: What is the Sanic configuration object?
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Sanic 配置对象是什么？
- en: 'When you create a Sanic application instance, it will create a configuration
    object. That object is really just a fancy `dict` type. As you will see, it does
    have some special properties. Do not let that fool you. You should remember: *it
    is a* `dict`. You can work with it like you would any other `dict` object. This
    will come in handy in a little bit when we explore how we can use the object.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建一个 Sanic 应用程序实例时，它将创建一个配置对象。这个对象实际上只是一个花哨的 `dict` 类型。正如你将看到的，它确实有一些特殊属性。不要被它迷惑。你应该记住：*它是一个*
    `dict`。你可以像处理任何其他 `dict` 对象一样处理它。这在我们探索如何使用该对象时将非常有用。
- en: 'If you do not believe me, then pop the following code into your application:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不同意我的观点，那么请将以下代码放入你的应用程序中：
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This means that getting a configuration value with a default is no different
    than any other `dict` in Python:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，使用默认值获取配置值与 Python 中的任何其他 `dict` 没有区别：
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The configuration object is—however—much more important than any other `dict`.
    It contains a lot of settings that are critical to the operation of your application.
    We have, of course, already seen in *Chapter 6* that we can use it to modify our
    default error handling:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，配置对象比任何其他 `dict` 都要重要得多。它包含了许多对应用程序操作至关重要的设置。当然，我们在 *第 6 章* 中已经看到，我们可以用它来修改我们的默认错误处理：
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To understand the full scope of settings that you can tweak, you should take
    a look at the Sanic documentation: [https://sanicframework.org/en/guide/deployment/configuration.html#builtin-values.](https://sanicframework.org/en/guide/deployment/configuration.html#builtin-values.)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解您可以调整的全套设置，您应该查看 Sanic 文档：[https://sanicframework.org/en/guide/deployment/configuration.html#builtin-values.](https://sanicframework.org/en/guide/deployment/configuration.html#builtin-values.)
- en: How can an application’s configuration object be accessed?
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 如何访问应用程序的配置对象？
- en: 'The best way to access the configuration object is to first get access to the
    application instance. Depending upon the scenario you are tackling at the moment,
    there are three main ways to get access to an application instance:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 访问配置对象的最佳方式是首先获取访问应用程序实例的权限。根据您当前面临的场景，有三种主要方式可以获取应用程序实例的访问权限：
- en: Access the application instance using a request object (`request.app`)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用请求对象（`request.app`）访问应用程序实例
- en: Accessing applications from a Blueprint instance (`bp.apps`)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Blueprint 实例访问应用程序（`bp.apps`）
- en: Retrieving an application instance from the application registry (`Sanic.get_app()`)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从应用程序注册表中检索应用程序实例（`Sanic.get_app()`）
- en: 'Perhaps the most common way to obtain the application instance (and therefore
    the configuration object by extension) is to grab it from the request object inside
    of a handler:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 获取应用程序实例（以及由此扩展的配置对象）最常见的方式可能是从处理器内部的请求对象中获取：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If you are outside of a route handler (or middleware) where the request object
    is easily accessible, then the next best choice is probably to use the application
    registry. Rarely will it make sense to use the Blueprint `apps` property. It is
    a set of applications that the blueprint has been applied to. However, because
    it only exists *after* registration, and it could be ambiguous which application
    you need, I usually will not reach for that as a solution. It is, nonetheless,
    good to know that it exists.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不在易于访问请求对象的路由处理器（或中间件）外部，那么下一个最佳选择可能是使用应用程序注册表。很少会使用 Blueprint 的 `apps` 属性。它是蓝图应用到的应用程序集合。然而，因为它只存在于注册之后，并且可能不清楚您需要哪个应用程序，所以我通常不会将其作为解决方案。尽管如此，了解它的存在是好的。
- en: 'You may have seen us using the third option already. As soon as an application
    is instantiated, it is part of a global registry that can be looked up using:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经看到我们使用第三个选项了。一旦应用程序被实例化，它就成为了一个全局注册表的一部分，可以通过以下方式查找：
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Whenever I am not in a handler, this is the solution I usually reach for. The
    two caveats that you need to be aware of are:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我不在处理器中时，我通常会采用这个解决方案。您需要注意的两个限制是：
- en: Make sure that the application instance has already been instantiated. Using
    `app = Sanic.get_app()` in the global scope can be tricky if you are not careful
    with your import ordering. Later on, in *Chapter 11*, *A complete real-world example*
    when we build out a complete application I will show you a trick I use to get
    around this.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保应用程序实例已经实例化。如果您不小心处理导入顺序，使用 `app = Sanic.get_app()` 在全局范围内可能会很棘手。稍后，在 *第 11
    章*，*一个完整的真实世界示例* 中，当我们构建一个完整的应用程序时，我会向您展示我用来绕过这个问题的技巧。
- en: 'If you are building a runtime with multiple application instances, then you
    will need to differentiate them using the application name:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您正在构建包含多个应用程序实例的运行时，那么您需要使用应用程序名称来区分它们：
- en: '[PRE7]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Once you have the object, you will usually just access the configuration value
    as a property, for example, `app.config.FOOBAR`. As shown previously, you can
    also use a variety of Python accessors:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了这个对象，您通常会直接将其作为属性访问配置值，例如，`app.config.FOOBAR`。如前所述，您也可以使用各种 Python 访问器：
- en: '`app.config.FOOBAR`'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`app.config.FOOBAR`'
- en: ''
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`app.config.get("FOOBAR")`'
  id: totrans-82
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`app.config.get("FOOBAR")`'
- en: ''
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`app.config["FOOBAR"]`'
  id: totrans-84
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`app.config["FOOBAR"]`'
- en: ''
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`getattr(app.config, "FOOBAR")`'
  id: totrans-86
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`getattr(app.config, "FOOBAR")`'
- en: How can the configuration object be set?
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 如何设置配置对象？
- en: 'If you go to the Sanic documentation, you will see that there are a bunch of
    default values already set. These values can be updated in a variety of methods
    as well. Of course, you can use the `object` and `dict` setters:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您访问 Sanic 文档，您会看到已经设置了一堆默认值。这些值可以通过多种方法进行更新。当然，您可以使用 `object` 和 `dict` 设置器：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You will usually set values like this right after creating your application
    instance. For example, throughout this book, I have repeatedly used `curl` to
    access endpoints that I created. The easiest method to see an exception is to
    use the text-based exception renderer. Therefore, in most cases, I have used the
    following pattern to make sure that when there is an exception it is easily formatted
    for display in this book:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你通常会在创建应用程序实例后立即设置这些值。例如，在这本书中，我反复使用`curl`来访问我创建的端点。查看异常的最简单方法就是使用基于文本的异常渲染器。因此，在大多数情况下，我使用了以下模式来确保当出现异常时，它能够轻松地格式化以在本书中显示：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This is *not* usually ideal for a fully-built application. If you have been
    involved in web application development before, then you probably do not need
    me to tell you that configuration should be easily changeable depending upon your
    deployment environment. Therefore, Sanic will load environment variables as configuration
    values if they are prefixed with `SANIC_`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常**不是**一个完全构建的应用的理想选择。如果你之前参与过Web应用开发，那么你可能不需要我告诉你配置应该根据你的部署环境轻松更改。因此，Sanic会在配置值以`SANIC_`为前缀的情况下将其加载为环境变量。
- en: 'This means that the above `FALLBACK_ERROR_FORMAT` could also be set outside
    of the application with an environment variable:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着上述`FALLBACK_ERROR_FORMAT`也可以通过环境变量在应用程序外部设置：
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The best method to do this will obviously depend upon your deployment strategy.
    We go deeper into those strategies later in this Chapter, and the specifics of
    how to set those variables will differ and are outside the scope of this book.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一点的最佳方法显然取决于你的部署策略。我们将在本章的后面更深入地探讨这些策略，以及如何设置这些变量的具体细节将有所不同，并且超出了本书的范围。
- en: 'Another option that you may be familiar with is centralizing all of your configurations
    in a single location. Django does this with `settings.py`. While I am personally
    not a fan of this pattern, you might be. You can easily duplicate it like this:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个你可能熟悉的选择是将所有配置集中在一个位置。Django通过`settings.py`来实现这一点。虽然我个人并不喜欢这种模式，但你可能喜欢。你可以轻松地像这样复制它：
- en: Create a `settings.py` file.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`settings.py`文件。
- en: '[PRE11]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Apply the configuration to the application instance:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将配置应用到应用程序实例：
- en: '[PRE12]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Access the values as needed:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据需要访问值：
- en: '[PRE13]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: There is nothing special about the `settings.py` file name. You just need a
    module with a whole bunch of properties that are uppercased. In fact, you could
    replicate this with an object.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`settings.py`文件名并没有什么特殊之处。你只需要一个包含大量大写属性的全局模块。实际上，你可以通过一个对象来复制这个功能。'
- en: 'Put all of your constants into an object now:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在将所有常量放入一个对象中：
- en: '[PRE14]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Apply the configuration from that object.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用来自该对象的配置。
- en: '[PRE15]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The result will be the same.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将是相同的。
- en: Some general rules about configuration
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 关于配置的一些通用规则
- en: 'I have some general rules that I like to follow regarding configuration. I
    encourage you to adopt them since they have evolved from years of making mistakes.
    But, I just as strongly encourage you to break them when necessary:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一些关于配置的通用规则，我喜欢遵循。我鼓励你采用它们，因为它们是从多年的错误中演变而来的。但是，我也同样强烈地鼓励你在必要时打破这些规则：
- en: '*Use simple values*: If you have some sort of a complex object like a `datetime`,
    perhaps configuration is not the best location for it. Part of the flexibility
    of configuration is that it can be set in many different ways; including outside
    of your application in environment variables. While Sanic will be able to convert
    things like booleans and integers, everything else will be a string. Therefore,
    for the sake of consistency and flexibility, try to avoid anything but simple
    value types.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用简单值*：如果你有一些复杂的对象，比如`datetime`，那么配置可能不是放置它的最佳位置。配置的一部分灵活性在于它可以以多种不同的方式设置；包括在应用程序外部通过环境变量。虽然Sanic能够转换布尔值和整数，但其他所有内容都将是一个字符串。因此，为了保持一致性和灵活性，尽量只使用简单值类型。'
- en: '*Treat them as constants*: Yes, this is Python. That means everything is an
    object and everything is subject to runtime changes. But do not do this. If you
    have a value that needs to be changed *during* the running of your application,
    use `app.ctx` instead. In my opinion, once `before_server_start` has completed,
    your configuration object should be considered locked in stone.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*将它们视为常量*：是的，这是Python。这意味着一切都是对象，并且一切都会受到运行时变化的影响。但不要这样做。如果你有一个需要在应用程序运行时更改的值，请使用`app.ctx`。在我看来，一旦`before_server_start`完成，你的配置对象应该被视为固定不变。'
- en: '*Don’t hardcode values*: Or, at least try really hard not to. When building
    out your application, you will undoubtedly find the need to create some sort of
    constant value. It is hard to guess the scenario that this might come up in without
    knowing your specific application. But when you realize that you are about to
    create a constant, or some value, ask yourself whether the configuration is more
    appropriate. Perhaps the most concrete example of this is the settings that you
    might use to connect to a database, a vendor integration, or any other third-party
    service.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*不要硬编码值*：或者，至少要尽力避免。在构建你的应用程序时，你无疑会发现需要创建某种类型的常量值。如果不了解你的具体应用程序，很难猜测这种情况可能出现的场景。但当你意识到你即将创建一个常量或某个值时，问问自己这个配置是否更合适。最具体的例子可能是你用来连接数据库、供应商集成或任何其他第三方服务的设置。'
- en: Configuring your application is almost certainly something that will change
    over the lifetime of your application. As you build it, run it, and add new features
    (or fix broken features), it is not uncommon to return to configuration often.
    One marker of a professional-grade application is that it relies heavily upon
    this type of configuration. This is to provide you with the flexibility to run
    the application in different environments. You may, for example, have some features
    that are only beneficial in local development, but not in production. It may also
    be the other way around. Configuration is therefore almost always tightly coupled
    with the environment where you will be deploying your application.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 配置你的应用程序几乎肯定会在应用程序的生命周期中发生变化。随着你构建它、运行它并添加新功能（或修复损坏的功能），经常返回配置是很常见的。专业级应用程序的一个标志是它严重依赖于这种类型的配置。这是为了提供你在不同环境中运行应用程序的灵活性。例如，你可能有一些只在本地开发中才有益的功能，但在生产环境中没有。也可能相反。因此，配置通常总是与你要部署应用程序的环境紧密耦合。
- en: We now turn our attention to those deployment options to see how Sanic will
    behave when running in development and production environments.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将注意力转向这些部署选项，看看 Sanic 在开发和生产环境中的表现会如何。
- en: Running Sanic locally
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本地运行 Sanic
- en: We finally are at the point where it is time to run Sanic—well, locally that
    is. However, we also know we have been doing that all along since *Chapter 2,
    Organizing a project*. The Sanic CLI is already probably a fairly comfortable
    and familiar tool. But there are some things that you should know about it. Other
    frameworks have only development servers. Since we know that Sanic’s server is
    meant for both development and production environments, we need to understand
    how these environments differ.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于到了运行 Sanic 的时候了——好吧，是在本地。然而，我们也知道自从 *第 2 章，组织项目* 以来，我们一直在做这件事。Sanic CLI
    已经可能是一个相当舒适且熟悉的工具了。但还有一些事情你应该知道。其他框架只有开发服务器。由于我们知道 Sanic 的服务器旨在用于开发和生产环境，我们需要了解这些环境有何不同。
- en: How does running Sanic locally differ from production?
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本地运行 Sanic 与生产环境有何不同？
- en: 'The most common configuration change for local production is turning on debug
    mode. This can be accomplished in three ways:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 本地生产中最常见的配置更改是开启调试模式。这可以通过三种方式实现：
- en: 'It could be enabled directly on the application instance. You typically would
    see this inside of a factory pattern when Sanic is being run programmatically
    from a script (as opposed to the CLI). You can directly set the value as shown
    here:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它可以直接在应用程序实例上启用。你通常会在 Sanic 从脚本（而不是 CLI）以编程方式运行时看到这种工厂模式。你可以直接设置值，如下所示：
- en: '[PRE16]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: It is perhaps more common to see it set as an argument of `app.run`. A common
    use case for this might be when reading environment variables to determine how
    Sanic should initialize. In the following example, an environment value is read
    and applied when Sanic server begins to run.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它可能更常见的是将其设置为 `app.run` 的参数。这种用法的一个常见场景可能是当读取环境变量以确定 Sanic 应如何初始化时。在以下示例中，当
    Sanic 服务器开始运行时，会读取并应用环境值。
- en: '[PRE17]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The final option is to use the Sanic CLI. This is generally my preferred solution,
    and if you have been following along with the book, it is the one that we have
    been using all along. This method is straightforward as shown here:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终的选择是使用 Sanic CLI。这通常是我的首选解决方案，如果你一直跟随这本书学习，那么我们一直都在使用这个方案。这个方法如以下所示非常直接：
- en: '[PRE18]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The reason that I prefer this final option is that I like to keep the operational
    aspects of the server distinct from other configurations.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我更喜欢这个最终选项的原因是我喜欢将服务器的操作方面与其他配置区分开来。
- en: For example, timeouts are configuration values that are closely linked to the
    operation of the framework and not the server itself. They impact how the framework
    responds to requests. Usually, these values are going to be the same regardless
    of where the application is deployed.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，超时是配置值，这些值与框架的操作紧密相关，而不是服务器本身。它们影响框架对请求的响应。通常，这些值无论应用程序部署在哪里都会是相同的。
- en: Debug mode–on the other hand–is much more closely linked to the deployment environment.
    You will want to set it to `True` locally, but `False` in production. Therefore,
    since we will be controlling how Sanic is deployed with tools like Docker, controlling
    the server’s operational capacity outside of the application makes sense.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，调试模式与部署环境的关系更为紧密。你希望在本地将其设置为 `True`，但在生产环境中设置为 `False`。因此，由于我们将使用 Docker
    等工具来控制 Sanic 的部署，控制服务器在应用程序之外的操作能力是有意义的。
- en: “*Okay*”, you say, “*turning on debug mode is simple, but why should I?*” I’m
    glad that you asked. When you run Sanic in debug mode, it makes a couple of important
    changes. The most noticeable is that you begin to see debug logs and access logs
    dispatched from Sanic. This is, of course, very helpful to see while developing.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: “*好吧*”，你说，“*开启调试模式很简单，但我为什么要这么做呢？*”我很高兴你问了这个问题。当你以调试模式运行 Sanic 时，它会进行一些重要的更改。最明显的是，你开始看到来自
    Sanic 的调试日志和访问日志。当然，这在开发过程中是非常有帮助的。
- en: '**TIP**'
  id: totrans-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**'
- en: ''
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'When I sit down to work on a web application, I always have three windows in
    my view at all times:'
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当我坐下来开发一个网络应用程序时，我总是同时看到三个窗口：
- en: ''
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: My IDE
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我的集成开发环境（IDE）
- en: ''
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An API client like Insomnia or Postman
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 类似 Insomnia 或 Postman 的 API 客户端
- en: ''
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A terminal showing me my Sanic logs (in debug mode)
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个显示我的 Sanic 日志（在调试模式下）的终端
- en: ''
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The terminal with debug level logging is your window into what is happening
    with your application as you build it.
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 调试级别日志的终端是你了解应用程序构建过程中发生情况的窗口。
- en: Perhaps the biggest change that debug mode brings is that any exception will
    include its traceback in the response. In the next chapter, we will look at some
    examples of how you can make the most of this exception information.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 调试模式可能带来的最大变化是，任何异常都将包括其跟踪信息在响应中。在下一章中，我们将探讨一些如何充分利用这些异常信息的例子。
- en: This is hugely important and useful while you are developing. It is also a huge
    security issue to accidentally leave it on in production. *DO NOT leave debug
    mode on in a live web application*. This includes any instance of your application
    that is *not* on a local machine. So, for example, if you have a staging environment
    that is hosted somewhere on the Internet, it may not be your “production” environment.
    However, it still *MUST NOT* run debug mode. At best, it will leak details about
    how your application was built. At worst, it will make sensitive information available.
    Make sure to turn off debug mode in production.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这在开发过程中非常重要且有用。然而，在生产环境中意外地将其留下是一个巨大的安全问题。*绝对不要在实时网络应用程序中开启调试模式*。这包括任何不在本地机器上的应用程序实例。例如，如果你有一个托管在互联网上的测试环境，它可能不是你的“生产”环境。然而，它仍然*绝对不能*运行调试模式。最好的情况是，它会泄露有关应用程序构建的细节。最坏的情况是，它会使敏感信息可用。请确保在生产环境中关闭调试模式。
- en: Speaking of production, let’s move on over to what it takes to deploy Sanic
    into the wild world of production environments.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 说到生产环境，让我们继续探讨将 Sanic 部署到野外生产环境所需的内容。
- en: Deploying to production
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署到生产环境
- en: 'We have finally made it. After working your way through the application development
    process, there finally is a product to launch out into the ether of the World
    Wide Web. The obvious question then becomes: what are my options? There really
    are two sets of questions that need to be answered:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于做到了。在经历了应用程序开发过程后，终于有一个产品可以发布到万维网的浩瀚之中。那么，显而易见的问题就是：我的选择有哪些？实际上，有两个问题集需要回答：
- en: 'First question: which server should run Sanic? There are three options: Sanic
    server, an ASGI server, or Gunicorn.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个问题：哪个服务器应该运行 Sanic？有三个选项：Sanic 服务器、ASGI 服务器或 Gunicorn。
- en: 'Second question: where do you want to run the application? Some typical choices
    include: *bare metal* virtual machine, containerized image, **platform-as-a-service**
    (**PaaS**), or a self-hosted or fully managed orchestrated container cluster.
    Perhaps these choices might make more sense if we put some of the commonly used
    product names to them:'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个问题：你希望在何处运行应用程序？一些典型的选择包括：*裸机*虚拟机、容器化镜像、**平台即服务**（**PaaS**）、或自托管或完全管理的编排容器集群。如果我们把这些常用的产品名称加到这些选择上，可能更有意义：
- en: '| **Deployment type** | **Potential vendors** |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| **部署类型** | **潜在供应商** |'
- en: '| Virtual machine | Amazon EC2, Google Cloud, Microsoft Azure, Digital Ocean,
    Linode |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 虚拟机 | Amazon EC2, Google Cloud, Microsoft Azure, Digital Ocean, Linode |'
- en: '| Container | Docker |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 容器 | Docker |'
- en: '| Platform as a service | Heroku |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 平台即服务 | Heroku |'
- en: '| Orchestrated cluster | Kubernetes |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 编排集群 | Kubernetes |'
- en: Table 8.1 – Examples of common hosting providers and tools
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.1 – 常见托管提供商和工具的示例
- en: Choosing the right server option
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择正确的服务器选项
- en: 'As we stated, there are three main ways to run Sanic: the built-in server,
    with an ASGI compatible server, or with Gunicorn. Before we decide which server
    to run, we will look take a brief look at the pros and cons for each option starting
    with the least performant option.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所提到的，运行Sanic主要有三种方式：内置服务器、与ASGI兼容的服务器或使用Gunicorn。在我们决定运行哪种服务器之前，我们将简要地看看每种选项的优缺点，从性能最低的选项开始。
- en: Gunicorn
  id: totrans-156
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Gunicorn
- en: If you are coming to Sanic from the WSGI world, you may already be familiar
    with Gunicorn. Indeed, you may even be surprised to learn that Sanic can be run
    with Gunicorn since it is built for WSGI applications, not asynchronous applications
    like Sanic. Because of this, the biggest downside to running Sanic with Gunicorn
    is the *substantial* decrease in performance. Gunicorn effectively unravels much
    of the work done to leverage *concurrency* with the `asyncio` module. It is by
    far the slowest way to run Sanic, and in most use cases is not recommended.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是从WSGI世界来到Sanic的，你可能已经熟悉Gunicorn了。实际上，你可能甚至会对了解到Sanic可以用Gunicorn运行感到惊讶，因为它是为WSGI应用程序构建的，而不是像Sanic这样的异步应用程序。正因为如此，使用Gunicorn运行Sanic的最大缺点是性能的**显著**下降。Gunicorn实际上破坏了利用`asyncio`模块进行**并发**的大部分工作。这是运行Sanic最慢的方式，在大多数情况下并不推荐。
- en: It still could be a good choice in certain circumstances. Particularly, if you
    need a feature-rich set of configurations options, and cannot use something like
    Nginx, then this might be an approach. Gunicorn has a tremendous amount of options
    that can be leveraged for fine-tuning server operation. In my experience, however,
    I typically see people reaching for it out of habit and not out of necessity.
    People will use it simply because it is what they know. For people that are transitioning
    to Sanic from the Flash/Django world, they may be used to a particular deployment
    pattern that was centered around tools like Supervisor and Gunicorn. That’s fine,
    but it is a little old fashioned and should not be the go-to pattern for Sanic
    deployments.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，这仍然可能是一个不错的选择。特别是，如果你需要一组功能丰富的配置选项，而又不能使用像Nginx这样的工具，那么这可能是一个方法。Gunicorn提供了大量的选项，可以用来微调服务器操作。然而，根据我的经验，我通常看到人们出于习惯而不是必要性而选择它。人们只是因为熟悉而使用它。对于从Flash/Django世界过渡到Sanic的人来说，他们可能已经习惯了以像Supervisor和Gunicorn这样的工具为中心的特定部署模式。这当然是可以的，但它有点过时了，不应该成为Sanic部署的首选模式。
- en: For those people, I urge you to look at another option. You are building with
    a new framework, why not deploy it with a new strategy as well?
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些人，我强烈建议你们考虑另一个选择。你们正在使用一个新的框架进行构建，为什么不也用一个新的策略来部署呢？
- en: If, however, you do find yourself needing some of the more fine-tune controls
    offered by Gunicorn, I would recommend you take a look at Nginx, which has an
    equally (if not more) impressive set of features. Whereas Gunicorn would be set
    up to actually run Sanic, the Nginx implementation would rely upon Sanic running
    via one of the other two strategies and placing an Nginx proxy in front of it.
    More on Nginx proxying later in this Chapter. This option will allow you to retain
    a great deal of server control without sacrificing performance. It does, however,
    require some more complexity since you need to essentially run two servers instead
    of just one.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你确实发现自己需要Gunicorn提供的更多精细控制，我建议你看看Nginx，它拥有同样（如果不是更多）令人印象深刻的特性集。Gunicorn会设置为实际运行Sanic，而Nginx的实现将依赖于Sanic通过其他两种策略之一运行，并在其前面放置一个Nginx代理。关于Nginx代理的更多内容将在本章后面讨论。这个选项将允许你在不牺牲性能的情况下保留大量的服务器控制。然而，这确实需要更多的复杂性，因为你实际上需要运行两个服务器而不是一个。
- en: 'If in the end, you still decide the use Gunicorn, then the best way to do so
    is to use Uvicorn’s worker shim. Uvicorn is an ASGI server, which we will learn
    more about in the next section. In this context, however, it also ships with a
    worker class that allows Gunicorn to integrate with it. This effectively puts
    Sanic into ASGI mode. Gunicorn still runs as the webserver, but it will pass traffic
    off to Uvicorn, which will then reach into Sanic as if it were an ASGI application.
    This will retain much of the performance offered by Sanic and asynchronous programming
    (although still not as performant as the Sanic server by itself). You can accomplish
    this as shown next:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果最后你仍然决定使用Gunicorn，那么最好的方法就是使用Uvicorn的工作器适配器。Uvicorn是一个ASGI服务器，我们将在下一节中了解更多关于它的内容。然而，在这个上下文中，它还附带了一个工作器类，允许Gunicorn与之集成。这实际上将Sanic置于ASGI模式。Gunicorn仍然作为网络服务器运行，但它会将流量传递给Uvicorn，然后Uvicorn将像处理ASGI应用程序一样深入Sanic。这将保留Sanic提供的许多性能和异步编程（尽管仍然不如Sanic服务器本身高效）。你可以按照以下方式完成此操作：
- en: 'First, make sure both Gunicorn and Uvicorn are installed:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，确保Gunicorn和Uvicorn都已安装：
- en: '[PRE19]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next, run the application like this:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，按照以下方式运行应用程序：
- en: '[PRE20]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: You should now have the full span of Gunicorn configurations at your fingertips.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该已经掌握了Gunicorn配置的全套内容。
- en: ASGI server
  id: totrans-167
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ASGI服务器
- en: 'We visited ASGI briefly in *Chapter 1, Introduction to Sanic and async frameworks*.
    If you recall, **ASGI** stands for **Asynchronous Server Gateway Interface**,
    and it is a design specification for how servers and frameworks can communicate
    with each other asynchronously. It was developed as a replacement methodology
    for the older WSGI standard that is incompatible with modern asynchronous Python
    practices. This standard has given rise to three popular ASGI webservers: Uvicorn,
    Hypercorn, and Daphne. All three of them follow the ASGI protocol, and can therefore
    run any framework that adheres to that protocol. The goal, therefore, is to create
    a common language that allows one of these ASGI servers to run any ASGI framework.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第一章，Sanic和异步框架的介绍*中简要介绍了ASGI。如果你还记得，**ASGI**代表**异步服务器网关接口**，它是一种设计规范，说明了服务器和框架如何异步地相互通信。它是作为与较旧的、与现代异步Python实践不兼容的WSGI标准替代方法开发的。这个标准催生了三个流行的ASGI网络服务器：Uvicorn、Hypercorn和Daphne。所有这三个都遵循ASGI协议，因此可以运行任何遵循该协议的框架。因此，目标是创建一种通用语言，允许这些ASGI服务器之一运行任何ASGI框架。
- en: And this is where to discuss Sanic with regards to ASGI we must have a clear
    distinction in our mind of the difference between the server and the framework.
    *Chapter 1* discussed this difference in detail. As a quick refresher, the web
    server is the part of the application that is responsible for connecting to the
    operating system’s socket protocol and handling the translation of bytes into
    usable web requests. The framework takes the digested web requests and provides
    the application developer with the tools needed to respond and construct an appropriate
    HTTP response. The server then takes that response and sends the bytes back to
    the operating system for delivery back to the client.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们必须讨论Sanic与ASGI的关系，我们必须在心中清楚地区分服务器和框架之间的差异。*第一章*详细讨论了这种差异。作为一个快速回顾，网络服务器是应用程序中负责连接到操作系统的套接字协议并处理字节到可用网络请求转换的部分。框架接收处理过的网络请求，并为应用程序开发者提供响应和构建适当HTTP响应所需的工具。然后，服务器将此响应发送回操作系统，以便将其发送回客户端。
- en: Sanic handles this whole process, and when it does so, it operates outside the
    ASGI since that interface is not needed. However, it also has the ability to speak
    the language of an ASGI framework and thus can be used with any ASGI web server.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Sanic 处理整个流程，并且在执行时，它是在 ASGI 之外操作的，因为那个接口并不需要。然而，它也有能力使用 ASGI 框架的语言，因此可以与任何
    ASGI 网络服务器一起使用。
- en: One of the benefits of running Sanic as an ASGI application is that it standardizes
    the run-time environment with a broader set of Python tools. There is, for example,
    a set of ASGI middleware that could be implemented to add a layer of functionality
    between the server and the application.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Sanic 作为 ASGI 应用程序运行的一个好处是，它使用更广泛的 Python 工具集标准化了运行时环境。例如，有一组 ASGI 中间件可以实现，在服务器和应用程序之间添加一层功能。
- en: However, some of the standardization does come at the expense of performance.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一些标准化是以性能为代价的。
- en: Sanic server
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Sanic 服务器
- en: The default mechanism is to run Sanic with its built-in web server. It should
    come as no surprise that it is built with performance in mind. Therefore, what
    Sanic server gives up by forfeiting the standardization and interoperability of
    ASGI, it makes up in its ability to optimize itself as a single purpose server.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 默认机制是使用内置的网络服务器运行 Sanic。它是以性能为导向构建的，这一点并不令人意外。因此，Sanic 服务器通过放弃 ASGI 的标准化和互操作性所失去的，它通过作为单一用途服务器的优化能力来弥补。
- en: 'We have touched on some of the potential downsides of using Sanic server. One
    of them was static content. No Python server will be able to match the performance
    of Nginx in handling static content. If you are already using Nginx as a proxy
    for Sanic, and you have a known location of static assets, then it might make
    sense to use it also for those assets. However, if you are not using it, then
    you need to determine whether the performance difference warrants the additional
    operational expense. In my opinion, if you can easily add this to your Nginx configuration:
    great. However, if it would take a lot of complicated effort, or you are exposing
    Sanic directly, then the benefit might not be as great as just leaving it as is
    and serving that content from Sanic. Sometimes, for example, the easiest thing
    to do is to run your entire frontend and backend from a single server. This is
    certainly a case where I would suggest learning the competing interests and making
    an appropriate decision and not trying to make a *perfect* decision.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提到了使用 Sanic 服务器的一些潜在缺点。其中之一是静态内容。没有 Python 服务器能够在处理静态内容方面与 Nginx 相匹敌。如果你已经使用
    Nginx 作为 Sanic 的代理，并且你知道静态资源的已知位置，那么使用它来处理这些资源可能是有意义的。然而，如果你没有使用它，那么你需要确定性能差异是否值得额外的运营成本。在我看来，如果你可以轻松地将它添加到你的
    Nginx 配置中：很好。然而，如果需要大量的复杂努力，或者你直接暴露 Sanic，那么这种好处可能不如让它保持原样并从 Sanic 提供内容那么大。有时，例如，最简单的事情就是从单个服务器运行你的整个前端和后端。这确实是一个我会建议学习竞争利益并做出适当决定，而不是试图做出*完美*决定的案例。
- en: With this knowledge, you should now be able to decide which server is the right
    fit for your needs. We will assume for the remainder of this book that we are
    still deploying with the Sanic server, but since it is mainly a matter of changing
    the command line executable, the difference should not make a difference.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 带着这些知识，你现在应该能够决定哪个服务器最适合你的需求。我们假设这本书的剩余部分我们仍然使用 Sanic 服务器进行部署，但由于这主要是一个更改命令行可执行文件的问题，所以这种差异不应该造成影响。
- en: How to choose a deployment strategy?
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何选择部署策略？
- en: 'The last section laid out three potential web servers to use for Sanic applications.
    But that web server needs to run on a web host. But, before deciding on which
    web hosting company to use, there is still a very important missing component:
    how are you going to get your code from your local machine to the web host? In
    other words: how are you going to deploy your application? We will now look through
    some options for deploying Sanic applications.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节概述了三个用于 Sanic 应用的潜在网络服务器。但是，那个网络服务器需要在网络主机上运行。但是，在决定使用哪家网络托管公司之前，还有一个非常重要的缺失组件：你将如何将你的代码从你的本地机器传输到网络主机？换句话说：你将如何部署你的应用程序？现在，我们将探讨一些部署
    Sanic 应用程序的选择。
- en: There is some assumed knowledge, so if some of the technologies or terms here
    are unfamiliar, please feel free to stop and go look them up.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些假设的知识，所以如果这里的一些技术或术语不熟悉，请随时停下来查阅它们。
- en: Virtual machine
  id: totrans-180
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 虚拟机
- en: This is perhaps the easiest option. Well, the easiest besides PAAS. Setting
    up a **virtual machine** (**VM**) is super simple these days. With just a few
    clicks of a button, you can have a custom configuration for a VM. The reason this
    then becomes a simple option is that you just need to run your Sanic application
    the same way you might on your local machine. This is particularly appealing when
    using the Sanic server since it literally means that you can run Sanic in production
    with the same commands that you use locally. However, getting your code to the
    VM, maintaining it once it is there, and then ultimately scaling it will make
    this option the hardest. To be blunt, I almost would never recommend this solution.
    It is appealing to new beginners since it looks so simple from the outside. But
    looks can be deceiving.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是最简单的方法。好吧，除了PAAS之外，设置一个**虚拟机**（**VM**）现在非常简单。只需点击几个按钮，你就可以为VM配置一个自定义配置。这使得这成为一个简单选项的原因是，你只需以与你在本地机器上相同的方式运行你的Sanic应用程序。这在使用Sanic服务器时尤其吸引人，因为这实际上意味着你可以使用与本地相同的命令在生产环境中运行Sanic。然而，将你的代码部署到VM中，维护它，然后最终扩展它将使这个选项变得最困难。坦白说，我几乎永远不会推荐这个解决方案。它对新手来说很有吸引力，因为它看起来很简单。但外表可能会欺骗人。
- en: There may in fact be times when this is an appropriate solution. If that is
    the case, then what would deployment look like? Really, not that much different
    than running it locally. You run the server and bind it to an address and port.
    With the proliferation of cloud computing, service providers have made it such
    a trivial experience to stand up a virtual machine. I personally find platforms
    like Digital Ocean and Linode to be super user-friendly, and excellent choices.
    Other obvious choices include Amazon AWS, Google Cloud, and Microsoft Azure. In
    my opinion, however, they are a little less friendly to someone new to cloud computing.
    Armed with their good documentation, with Digital Ocean and Linode it is relatively
    inexpensive and painless to click a few buttons and get an instance running. Once
    they provide you with an IP address, it is now your responsibility for getting
    your code to the machine and running the application.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，可能会有这种解决方案是合适的时刻。如果是这样，那么部署会是什么样的呢？实际上，与本地运行并没有太大的不同。你运行服务器并将其绑定到地址和端口。随着云计算的普及，服务提供商已经使得建立虚拟机变得如此简单。我个人发现Digital
    Ocean和Linode这样的平台非常用户友好，是极佳的选择。其他明显的选择包括Amazon AWS、Google Cloud和Microsoft Azure。然而，在我看来，它们对云计算新手来说稍微不那么友好。有了它们良好的文档，使用Digital
    Ocean和Linode相对便宜且痛苦不大，只需点击几个按钮就可以运行一个实例。一旦他们给你提供了一个IP地址，现在就是你的责任将你的代码部署到机器上并运行应用程序。
- en: You might be thinking the simplest way to move your code to the server would
    be to use git. Then all you need to do is launch the application and you are done.
    But, what happens if you need more instances or redundancy? Yes, Sanic comes with
    the ability to spin up multiple worker processes. But what if that is not enough?
    Now you need another VM and some way to manage load balancing your incoming web
    traffic between them. How are you going to handle redeployments of bug patches
    or new features? What about changes to environment variables? These complexities
    could lead to a lot of sleepless nights if you are not careful.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，将你的代码移动到服务器的最简单方法就是使用git。然后你只需要启动应用程序就完成了。但是，如果你需要更多实例或冗余怎么办？是的，Sanic自带启动多个工作进程的能力。但如果这还不够怎么办？现在你需要另一个VM以及某种方式来管理在它们之间平衡你的传入Web流量。你将如何处理错误补丁或新功能的重新部署？环境变量的更改怎么办？如果你不小心，这些复杂性可能会导致许多不眠之夜。
- en: This is also somewhat ignoring the other fact that not all environments are
    equal. VMs could be built with different dependencies, leading to wasteful time
    maintaining servers and packages.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这也在一定程度上忽略了另一个事实，即并非所有环境都是平等的。虚拟机可能具有不同的依赖项，导致维护服务器和包的时间浪费。
- en: That is not to say this cannot or should not be a solution. Indeed, it might
    be a great solution if you are creating a simple service for your own use. Perhaps
    you need a webserver for connecting to a smart home network. But it is certainly
    a case of *developer beware*. Running a webserver on a *baremetal* virtual machine
    is rarely as simple as it appears at first glance.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着这不能或不应该是一个解决方案。实际上，如果你只是为了自己的使用创建一个简单的服务，这可能是一个非常棒的解决方案。也许你需要一个网络服务器来连接到智能家居网络。但无疑这是一个需要开发者小心的案例。在裸金属虚拟机上运行网络服务器通常不像乍一看那么简单。
- en: Containers with Docker
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Docker的容器
- en: One solution to the previous set of problems is using a Docker container. For
    those that have used Docker, you can probably skip to the next section because
    you already understand the power that it provides. If you are new to containers,
    then I highly recommend you learn about them.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 解决上述问题的方法之一是使用Docker容器。对于那些已经使用过Docker的人来说，你可能可以跳到下一节，因为你已经理解了它提供的强大功能。如果你是容器的新手，那么我强烈建议你了解它们。
- en: 'In brief, you write a simple manifest called a Dockerfile. That manifest describes
    an intended operating system and some instructions needed to build an ideal environment
    for running your application. An example manifest is available in the GitHub repository
    here: [https://github.com/PacktPublishing/Web-Development-with-Sanic/blob/main/chapters/08/k8s/Dockerfile](https://github.com/PacktPublishing/Web-Development-with-Sanic/blob/main/chapters/08/k8s/Dockerfile).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，你编写一个简单的清单，称为Dockerfile。这个清单描述了一个预期的操作系统以及构建运行应用程序的理想环境所需的指令。一个示例清单可以在GitHub仓库中找到：[https://github.com/PacktPublishing/Web-Development-with-Sanic/blob/main/chapters/08/k8s/Dockerfile](https://github.com/PacktPublishing/Web-Development-with-Sanic/blob/main/chapters/08/k8s/Dockerfile)。
- en: This might include installing some dependencies (including Sanic), copying source
    code, and defining a command that will be used to run your application. With that
    in place, docker then builds a single image with everything needed to run the
    application. That image can be uploaded to a repository and used to run irrespective
    of the environment. You could, for example, opt to use this instead of managing
    all those separate VM environments. It is much simpler to bundle all that together
    and simply run it.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能包括安装一些依赖项（包括Sanic），复制源代码，并定义一个用于运行应用程序的命令。有了这些准备，Docker随后构建一个包含运行应用程序所需所有内容的单个镜像。这个镜像可以被上传到仓库，并在任何环境中运行。例如，你可以选择使用这种方法来代替管理所有那些独立的虚拟机环境。将所有这些捆绑在一起并简单地运行它要简单得多。
- en: There is still some complexity involved in building our new versions and deciding
    where to run the image, but having consistent builds is a huge gain. This should
    really become a focal point of your deployment. So, although containers are part
    of the solution, there still is the problem of where to run it and the maintenance
    costs required to keep it running and up to date.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建我们的新版本和决定在哪里运行镜像方面，仍然存在一些复杂性，但保持一致的构建是一个巨大的收益。这应该真正成为你部署的重点。因此，尽管容器是解决方案的一部分，但仍然存在运行它和维护其运行和更新的成本问题。
- en: 'I almost *always* would recommend using Docker as part of your deployment practices.
    And if you know about Docker Compose, you might be thinking that is a great choice
    for managing deployments. I would agree with you, so long as we are talking about
    deployments on your local machine. Using Docker Compose for production is not
    something I would usually consider. The reason is simple: horizontal scaling.
    Just like the issue with running Sanic on a VM, or a single container on a VM,
    running Docker Compose on a single VM carries the same problem: horizontal scaling.
    The fix is orchestration.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我几乎**总是**会建议将Docker作为部署实践的一部分。如果你了解Docker Compose，你可能认为它是管理部署的一个很好的选择。我会同意你的看法，只要我们谈论的是在本地机器上的部署。在生产环境中使用Docker
    Compose通常不是我会考虑的事情。原因很简单：水平扩展。就像在虚拟机上运行Sanic，或者在单个虚拟机上运行单个容器一样，在单个虚拟机上运行Docker
    Compose也带来了相同的问题：水平扩展。解决方案是编排。
- en: Container orchestration with Kubernetes
  id: totrans-192
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Kubernetes进行容器编排
- en: 'The problem with containers is that they only solve the environmental problems
    by creating a consistent and repeatable strategy for your application. They still
    suffer from scalability problem. Again, what happens when your application needs
    to scale past the resources that are available on a single machine? Container
    orchestrators like Kubernetes (aka “K8S”) are a dream come true for anyone that
    has done DevOps work in the past. By creating a set of manifests, you will describe
    to Kubernetes what your ideal application will look like: the number of replicas,
    the number of resources they need, how traffic should be exposed, and so on. That
    is it! All you need to do is describe your application with some YAML files. Kubernetes
    will handle the rest. It has the added benefit of enabling rolling deployments
    where you can rollout new code with zero downtime for your application.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 容器的问题在于，它们只能通过为你的应用程序创建一个一致且可重复的策略来解决环境问题。但它们仍然面临着可扩展性问题。再次强调，当你的应用程序需要扩展到单台机器上可用的资源之外时，会发生什么？像
    Kubernetes（又称“K8S”）这样的容器编排器对于过去做过 DevOps 的人来说是一个梦想成真。通过创建一组清单，你将向 Kubernetes 描述你的理想应用程序将是什么样子：副本的数量、它们需要的资源数量、如何暴露流量等等。就是这样！你所需要做的就是用一些
    YAML 文件描述你的应用程序。Kubernetes 将处理其余的事情。它还有一个额外的优点，即允许滚动部署，这样你可以在应用程序零停机的情况下推出新代码。
- en: The downside, of course, is that this option is the most complex. It is suitable
    for more serious applications where the complexity is acceptable for the benefits
    added. It may, however, be overkill for a lot of projects. This is a go-to deployment
    strategy for any application that will have more than a trivial amount of traffic.
    Of course, the complexity and scale of a K8S cluster can expand based upon its
    needs. This dynamic quality is what makes it increasingly a standard deployment
    strategy that has been adopted by many industry professionals.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这个选项是最复杂的。它适用于更严肃的应用程序，其中复杂性是可接受的，并且可以带来额外的收益。然而，对于许多项目来说，这可能是一种过度设计。这是任何将会有大量流量的应用程序的默认部署策略。当然，K8S
    集群的复杂性和规模可以根据其需求进行扩展。这种动态特性使其成为越来越多行业专业人士采用的标准化部署策略。
- en: It is an ideal solution for platforms that consist of multiple services working
    together, or that require scaling beyond the boundaries of a single machine.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 它是适用于由多个服务协同工作或需要超出单台机器边界进行扩展的平台的理想解决方案。
- en: This does bring up an interesting question, however. We know that Sanic has
    the ability to scale horizontally on a single host by replicating its workers
    in multiple processes. Kubernetes is capable of scaling horizontally by spinning
    up replica **pods**. Let’s say you hypothetically have decided that you need four
    instances of your application to handle the load. Should you have two pods each
    running two workers or four pods each with one worker?
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这确实提出了一个有趣的问题。我们知道 Sanic 有能力通过在多个进程中复制其工作进程在单个主机上进行水平扩展。Kubernetes 通过启动副本**Pod**来具备水平扩展的能力。假设你假设你需要四个应用程序实例来处理负载。你应该有两个每个运行两个工作进程的
    Pod，还是四个每个只有一个工作进程的 Pod？
- en: I have heard both put forth as *ideal* solutions. Some people say that you should
    maximize the resources per container. Other people say that you should have no
    more than one process per container. From a performance perspective, it is a dead
    heat. The solutions effectively perform the same. Therefore, it comes down entirely
    to the choice of the application builder. There is no right or wrong answer.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我听说这两种方法都被提出作为*理想*的解决方案。有些人说你应该最大化每个容器的资源。另一些人则说每个容器不应有超过一个进程。从性能的角度来看，它们表现相同。这些解决方案实际上执行相同的操作。因此，这完全取决于应用程序构建者的选择。没有正确或错误答案。
- en: Later in this chapter, we will take a closer look at what it takes to launch
    a Sanic application with Kubernetes.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后面部分，我们将更详细地探讨使用 Kubernetes 启动 Sanic 应用程序所需的内容。
- en: Platform as a service
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 平台即服务
- en: Heroku is probably one of the most well-known **PAAS** offering. It has been
    around for a while and has become an industry leader in these low-touch deployment
    strategies. Heroku is not the only provider, both Google and AWS have PAAS services
    in their respective cloud platforms, and Digital Ocean has also launched their
    own competing service. What makes PAAS super convenient is that all you need to
    do is write the code. There is no container management, environment handling,
    or deployment struggles. It is intended to be a super easy low-touch solution
    for deploying code. Usually, deploying an application is as simple as pushing
    code is to a git repository.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Heroku可能是最知名的**PAAS**供应商之一。它已经存在了一段时间，并已成为这些低接触部署策略的行业领导者。Heroku并非唯一提供者，Google和AWS分别在各自的云平台上提供PAAS服务，Digital
    Ocean也推出了自己的竞争性服务。PAAS之所以非常方便，是因为你只需要编写代码。没有容器管理、环境处理或部署难题。它旨在成为部署代码的超简单低接触解决方案。通常，部署应用程序就像将代码推送到git仓库一样简单。
- en: This simple option is, therefore, ideal for proof-of-concept applications or
    other builds you need to deploy super quickly. I also do know plenty of people
    that run more robust and scalable applications through these services, and they
    really can be a great alternative. The huge selling point of these services is
    that by outsourcing the deployment, scaling, and service maintenance to the service
    provider, you are freed up to focus on the application logic.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个简单的选项非常适合原型应用或其他需要快速部署的构建。我也知道很多人通过这些服务运行更健壮和可扩展的应用程序，它们确实可以是一个很好的替代品。这些服务的一个巨大卖点是通过将部署、扩展和服务维护外包给服务提供商，你可以腾出时间专注于应用程序逻辑。
- en: Because of this simplicity, and ultimately flexibility, we will take a closer
    look at launching Sanic with a PAAS vendor later in this Chapter in the *Deployment
    examples* section. One of the things that is great about a PAAS is that it handles
    a lot of details like setting up a TLS certificate and enabling a `https://` address
    for your application. In the next section, however, we will learn what it takes
    to set up an `https://` address for your application in the absence of convenience
    from a PAAS.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种简单性和最终灵活性，我们将在本章的“部署示例”部分稍后更详细地探讨如何使用PAAS供应商启动Sanic。PAAS的一个优点是它处理了很多细节，比如设置TLS证书并为你的应用程序启用`https://`地址。然而，在下一节中，我们将学习在没有PAAS便利性的情况下如何为你的应用程序设置`https://`地址。
- en: Securing your application with TLS
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用TLS保护你的应用程序
- en: If you are not encrypting traffic to your web application, you are doing something
    wrong. In order to protect information while it is in transit between the web
    browser and your application, it is an absolute necessity to add encryption. The
    international standard for doing that is known as TLS (which stands for Transport
    Layer Security). It is a protocol for how data can be encrypted between two sources.
    Often, however, it will be referred to as *SSL* (which is an earlier protocol
    that TLS replaces) or *HTTPS* (which is technically an implementation of TLS,
    not TLS itself). Since it is not important for us *how* it works, and we only
    care that it does what it needs to do, we will use these terms somewhat interchangeably.
    Therefore, it is safe for you to think about TLS and HTTPS as the same thing.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有加密你的Web应用程序的流量，你就是在做错事。为了在浏览器和你的应用程序之间传输信息时保护信息，添加加密是绝对必要的。国际标准是TLS（代表传输层安全性）。它是一种数据可以在两个来源之间加密的协议。然而，它通常被称为*SSL*（这是一个较早的协议，TLS取代了它）或*HTTPS*（技术上它是TLS的实现，而不是TLS本身）。由于我们并不关心它是如何工作的，我们只关心它是否需要完成，因此我们可以将这些术语互换使用。因此，你可以安全地认为TLS和HTTPS是同一件事。
- en: So, what is it? The simple answer is that you request a pair of keys from some
    reputable source on the Internet. Your next step is to make them available to
    your web server, and expose your application over a secure port–typically, that
    is port 443\. After that, your web server should handle the rest, and you should
    now be able to access your application with an `https://` address instead of `http://`.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，它是什么呢？简单的答案是，你从互联网上某个信誉良好的来源请求一对密钥。你的下一步是让它们可供你的Web服务器使用，并在安全端口上公开你的应用程序——通常是端口443。之后，你的Web服务器应该处理剩下的工作，你现在应该能够通过`https://`地址而不是`http://`访问你的应用程序。
- en: Setting up TLS in Sanic
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Sanic中设置TLS
- en: There are two common scenarios you should be familiar with. If you are exposing
    your Sanic application directly, or if you are placing Sanic behind a proxy. This
    will determine where you want to *terminate* your TLS connection. This simply
    means where you should set up your public-facing certificates. We will assume
    for now that Sanic is exposed directly. We also will assume that you already have
    certificates. If you do not know how to obtain them, don’t worry, we will get
    to a potential solution for you in the next section.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该熟悉两种常见的场景。如果你直接公开你的 Sanic 应用程序，或者如果你将 Sanic 放在代理后面。这将决定你希望在何处 *终止* 你的 TLS
    连接。这仅仅意味着你应该在哪里设置你的面向公众的证书。我们目前假设 Sanic 是直接公开的。我们还假设你已经有了证书。如果你不知道如何获取它们，不要担心，我们将在下一节提供一个可能的解决方案。
- en: All we need to do is to tell the Sanic server how to access those certificates.
    Also, since Sanic will default to port `8000`, we need to make sure to set it
    to `443`.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的只是告诉 Sanic 服务器如何访问这些证书。此外，由于 Sanic 默认使用端口 `8000`，我们需要确保将其设置为 `443`。
- en: 'With this in mind, our new runtime command (in production) will be this:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到这一点，我们的新运行时命令（在生产环境中）将是这样的：
- en: '[PRE21]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It is largely the same operation if you are using `app.run` instead:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用 `app.run` 而不是 `app.run`，操作基本上是相同的：
- en: '[PRE22]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: When you are exposing your Sanic application directly, and therefore terminating
    your TLS with Sanic, there is often a desire to add HTTP to HTTPS redirect. For
    your users’ convenience, you probably want them to always be directed to HTTPS
    and for this redirection to happen *magically* for them without having to think
    about it.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 当你直接公开你的 Sanic 应用程序，并且因此通过 Sanic 终止 TLS 时，通常会希望添加 HTTP 到 HTTPS 的重定向。为了用户的方便，你可能希望他们始终被重定向到
    HTTPS，并且这个重定向对他们来说是 *神奇地* 发生的，而无需思考。
- en: 'The Sanic User Guide provides us with a simple solution that involves running
    a second Sanic application inside our main app. Its only purpose will be to bind
    to port 80 (which is the default HTTP non-encrypted port) and redirect all traffic.
    Let’s quickly examine that solution and step through it:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Sanic 用户指南为我们提供了一个简单的解决方案，该方案涉及在我们的主应用内部运行第二个 Sanic 应用程序。它的唯一目的将是绑定到端口 80（这是默认的非加密
    HTTP 端口）并重定向所有流量。让我们快速检查这个解决方案并逐步进行：
- en: 'First, in addition to our main application, we need a second that will be responsible
    for the redirects. So, we will set up two applications and some configuration
    details:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，除了我们的主应用程序外，我们还需要一个负责重定向的第二个应用程序。因此，我们将设置两个应用程序和一些配置细节：
- en: '[PRE23]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We add only one endpoint to the `http_app` that will be responsible for redirecting
    all traffic to the `main_app`.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只向 `http_app` 添加了一个端点，该端点将负责将所有流量重定向到 `main_app`。
- en: '[PRE24]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'To make running the HTTP redirect application easier, we will just piggyback
    off of the main application’s lifecycle so that there is not a need to create
    another executable. Therefore, when the main application starts up, it will also
    create and bind the HTTP application:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使运行 HTTP 重定向应用程序更容易，我们将利用主应用程序的生命周期，这样就不需要创建另一个可执行文件。因此，当主应用程序启动时，它也将创建和绑定
    HTTP 应用程序：
- en: '[PRE25]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: You should note how we are assigning that server to the `ctx` for our main application
    so we can use it again.
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该注意我们是如何将那个服务器分配给我们的主应用程序的 `ctx`，这样我们就可以再次使用它。
- en: 'Finally, when the main application shuts down, it will also be responsible
    for shutting down the HTTP application:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，当主应用程序关闭时，它也将负责关闭 HTTP 应用程序：
- en: '[PRE26]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: With this in place, any request to `http://example.com` should be automatically
    redirected to the `https://` version of the same page.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在此设置完成后，任何对 `http://example.com` 的请求都应自动重定向到同一页面的 `https://` 版本。
- en: Back in Step 1 and Step 2, this example sort of skipped over the fact that you
    need to obtain actual certificate files to be used to encrypt your web traffic.
    This is largely because you need to bring your own certificates to the table.
    If you are not familiar with *how* to do that, the next section provides a potential
    solution.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 1 和步骤 2 中，这个例子似乎跳过了这样一个事实，即你需要获取实际用于加密网络流量的证书文件。这主要是因为你需要自带证书到桌面上。如果你不熟悉
    *如何* 做这件事，下一节提供了一个可能的解决方案。
- en: Getting and renewing a certificate from Let’s Encrypt
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从 Let’s Encrypt 获取和更新证书
- en: 'Back in the olden days of the Internet, if you wanted to add HTTPS protection
    to your web application, it was going to cost you. Certificates were not cheap,
    and they were somewhat cumbersome and complicated to manage. Actually, certificates
    are still not cheap if you are to buy one yourself, especially if you want to
    buy a certificate that covers your subdomains. However, this is no longer your
    only option since several players came together looking for a method to create
    a safer online experience. The solution: free TLS certificates. These free (and
    reputable) certificates are available from *Let’s Encrypt*, and are the reason
    that *every* production website should be encrypted. Expense is no longer an excuse.
    At this point in time, if I see a website still running `http://` in a live environment,
    a part of me cringes as I go running for the hills.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 回到互联网的古老时代，如果您想为您的Web应用程序添加HTTPS保护，这将花费您一定的成本。证书并不便宜，而且管理起来有些繁琐和复杂。实际上，如果您自己购买证书，证书仍然不便宜，尤其是如果您想购买覆盖子域的证书。然而，这不再是您的唯一选择，因为一些参与者联合起来寻找创建更安全在线体验的方法。解决方案：免费TLS证书。这些免费（且信誉良好的）证书由*Let’s
    Encrypt*提供，也是为什么*每个*生产网站都应该加密的原因。成本不再是借口。在这个时候，如果我看到某个网站在实时环境中仍在运行`http://`，我的一部分会感到厌恶，就像我正在逃跑一样。
- en: If you do not currently have a TLS certificate for your application, head over
    to [https://letsencrypt.org](https://letsencrypt.org) to get one. The process
    to obtain a certificate from *Let’s Encrypt* requires you to follow some basic
    steps, and then prove that you own the domain. Because there are a lot of platform
    specifics, and it is outside the scope of this book, we will not really dive into
    the details of how to obtain one. Later on, this chapter does go through a step-by-step
    process to obtain a Let’s Encrypt certificate for use in a Kubernetes deployment
    in the *Kubernetes (as-a-service)* section.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您目前的应用程序还没有TLS证书，请前往[https://letsencrypt.org](https://letsencrypt.org)获取一个。从*Let’s
    Encrypt*获取证书的过程需要您遵循一些基本步骤，然后证明您拥有该域名。由于平台具体细节较多，且超出了本书的范围，我们不会深入探讨如何获取证书的细节。稍后，本章将在*Kubernetes
    (as-a-service)*部分逐步介绍如何获取用于Kubernetes部署的Let’s Encrypt证书。
- en: I do, however, highly encourage you to use Let’s Encrypt if the budget for your
    project does not allow for you to go out and purchase a certificate.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我强烈建议您在项目预算不允许您外出购买证书的情况下使用Let’s Encrypt。
- en: With a certificate in hand, it is finally time to look at some actual code and
    decide which deployment strategy is right for your project.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 拿到证书后，终于可以查看一些实际代码并决定哪种部署策略适合您的项目。
- en: Deployment examples
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署示例
- en: 'Earlier when discussing the various choices for deployment strategies, two
    options rose above the others: PAAS, and Kubernetes. When deploying Sanic into
    production, I would almost always recommend one of these solutions. There is no
    hard and fast rule here, but I generally think of Kubernetes as being the go-to
    solution for platforms that will be running multiple services, have the need for
    more controlled deployment configurations, and have more resources and a team
    of developers. On the other hand, PAAS is more appropriate for single developer
    projects or projects that do not have resources to devote to maintaining a richer
    deployment pipeline. We will now explore what it takes to get Sanic running in
    these two environments.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前讨论各种部署策略选择时，有两个选项脱颖而出：PAAS和Kubernetes。当部署Sanic到生产环境时，我几乎总是推荐这些解决方案之一。这里没有固定的规则，但我通常认为Kubernetes是适用于将运行多个服务、需要更多控制部署配置以及拥有更多资源和开发团队的平台的最佳选择。另一方面，PAAS更适合单开发者项目或没有资源维护更丰富部署管道的项目。现在，我们将探讨在两个环境中运行Sanic所需的条件。
- en: Platform-as-a-service
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平台即服务
- en: 'As we stated before, Heroku is a well-known industry leader in deploying applications
    via PAAS. This is for good reason as they have been in business providing these
    services since 2007, and have played a critical role in popularizing the concept.
    They have made the process super simple for both new and experienced developers.
    However, in this section, we are going to instead take a look at deploying a Sanic
    application with Digital Ocean’s PAAS offering. The steps should be nearly identical
    and applicable to Heroku, or any of the other services that are out there:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所述，Heroku 是通过 PAAS 部署应用程序的知名行业领导者。这有很好的原因，因为他们自 2007 年以来一直在提供这些服务，并在推广这一概念中发挥了关键作用。他们使新开发者和经验丰富的开发者都感到过程非常简单。然而，在本节中，我们将转而查看使用
    Digital Ocean 的 PAAS 提供的 Sanic 应用程序的部署。步骤应该几乎相同，并且适用于 Heroku 或其他任何现有的服务：
- en: First, you need to, of course, go to their website and signup for an account
    if you do not have one. Their PAAS is called **Apps**, which you can find on the
    left-hand side of their main dashboard once you are logged in.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，当然，你需要访问他们的网站并注册一个账户，如果你还没有的话。他们的 PAAS 被称为 **Apps**，你可以在登录后从主仪表板的左侧找到它。
- en: You will next be taken through a series of steps that will ask you to connect
    a git repository.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你将经历一系列步骤，这些步骤将要求你连接一个 git 仓库。
- en: 'You will next need to configure the app through their UI. Your screen will
    look probably something like this:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你需要通过他们的 UI 配置应用程序。你的屏幕可能看起来像这样：
- en: '![Figure 8.1 - Example settings for PAAS setup](img/file9.png)'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 8.1 - PAAS 设置的示例配置](img/file9.png)'
- en: Figure 8.1 - Example settings for PAAS setup
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.1 - PAAS 设置的示例配置
- en: A very important thing to note here is that we have set the `--host=0.0.0.0`.
    This means that we are telling Sanic that it should bind itself to any IP address
    that Digital Ocean provides it. Sanic will bind itself to the `127.0.0.1` address
    without this configuration. As anyone that has done web development knows, the
    127.0.0.1 address maps to localhost on most computers. This means that Sanic will
    be accessible only to web traffic on that specific computer. This is no good.
    If you ever deploy an application and cannot access it, one of the first things
    to check is that the port and host are set up properly. One of the easiest options
    is to just use `0.0.0.0`, which is like the equivalent of a wildcard IP address.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里需要注意的一个重要事项是，我们设置了 `--host=0.0.0.0`。这意味着我们正在告诉 Sanic 它应该绑定到 Digital Ocean
    提供的任何 IP 地址。没有此配置，Sanic 将绑定到 `127.0.0.1` 地址。正如任何做过网页开发的人都知道，127.0.0.1 地址映射到大多数计算机上的
    localhost。这意味着 Sanic 只能在该特定计算机上的网络流量中访问。这并不好。如果你部署的应用程序无法访问，首先要检查的是端口和主机是否设置正确。最简单的方法之一就是使用
    `0.0.0.0`，这就像通配符 IP 地址的等效物。
- en: Next, you will be asked to select a location for which data center it will live
    in. Usually, you want to pick one that will be close to where your intended audience
    will be to reduce latency.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你将被要求选择一个数据中心的位置。通常，你希望选择一个靠近你目标受众的位置，以减少延迟。
- en: You will then need to select an appropriate package. If you do not know what
    to choose, start small and then scale it up as needed.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你需要选择一个合适的包。如果你不知道该选择什么，从小规模开始，然后根据需要扩展。
- en: 'The only thing left to do is to setup the files in our repository. There is
    a sample in GitHub for you to follow: [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08/paas](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08/paas).'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 剩下的唯一事情就是设置我们仓库中的文件。GitHub 上有一个示例供你参考：[https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08/paas](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08/paas)。
- en: 'Finally, we need a `requirements.txt` file that lists out our dependencies:
    sanic and a `server.py` just like every other build we have done so far.'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们需要一个 `requirements.txt` 文件，列出我们的依赖项：sanic 和一个 `server.py`，就像我们迄今为止所做的每个构建一样。
- en: Once that is done, every time you push to the repository, your application should
    be rebuilt and available to you. One of the nice benefits of this is that you
    will get a TLS certificate with https out of the box. No configuration is needed.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，每次你向仓库推送时，你的应用程序都应该被重新构建并可供你使用。这个好处之一是，你将获得一个 TLS 证书，无需配置即可使用 https。
- en: Seems simple enough? Let’s look at a more complex setup with Kubernetes.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来很简单吗？让我们看看一个更复杂的 Kubernetes 设置。
- en: Kubernetes (as-a-service)
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes (作为服务)
- en: 'We are going to turn our attention to Kubernetes: one of the most widely adopted
    and utilized platforms for orchestrating the deployment of containers. You could,
    of course, spin up some virtual machines, install Kubernetes on them, and manage
    your own cluster. However, I find a much more worthwhile solution is to just take
    one of the Kubernetes-as-a-service solutions. You still have all of the power
    of Kubernetes (which we will use the common abbreviation: K8S), but none of the
    maintenance headaches.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把注意力转向Kubernetes：这是最广泛采用和使用的容器部署编排平台之一。当然，你也可以启动一些虚拟机，在上面安装Kubernetes，并管理你自己的集群。然而，我发现一个更有价值的解决方案是直接采用Kubernetes作为服务的解决方案。你仍然拥有Kubernetes的全部功能（我们将使用常见的缩写：K8S），但没有任何维护的烦恼。
- en: We will again look at Digital Ocean and use their platform for our example.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次查看Digital Ocean并使用他们的平台作为我们的示例。
- en: 'In our local directory we will need a few files:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的本地目录中，我们需要几个文件：
- en: '`Dockerfile` to describe out docker container'
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Dockerfile`用于描述我们的Docker容器'
- en: '`app.yml` a K8S config file described below'
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`app.yml`，下面将描述的K8S配置文件'
- en: '`ingress.yml` a K8S config file described below'
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ingress.yml`，下面将描述的K8S配置文件'
- en: '`load-balancer.yml` a K8S config file described below'
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load-balancer.yml`，下面将描述的K8S配置文件'
- en: '`server.py` which is again a Sanic applicationYou can follow along with the
    files in the GitHub repository: [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08/k8s](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08/k8s).'
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`server.py`，这同样是一个Sanic应用程序你可以通过GitHub仓库中的文件来跟进：[https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08/k8s](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/08/k8s)。'
- en: 'Our Dockerfile is the set of instructions to build our container. We will take
    a shortcut and use one of the Sanic community’s base images that has both Python
    and Sanic pre-installed:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的Dockerfile是构建我们容器的一组指令。我们将采取捷径，使用Sanic社区的一个预安装了Python和Sanic的基础镜像：
- en: '[PRE27]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Just like we saw with the PAAS solution, we are binding to host `0.0.0.0` for
    the same reason. We are *not* adding multiple workers per container here. Again,
    this is something you could do if you prefer.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 就像我们在PAAS解决方案中看到的那样，我们绑定到主机`0.0.0.0`出于相同的原因。我们在这里**不会**为每个容器添加多个工作进程。再次强调，如果你愿意，你也可以这样做。
- en: 'Next, we will need to build an image:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要构建一个镜像：
- en: '[PRE28]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Let’s try running it locally to make sure it works
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们尝试在本地运行它以确保它工作
- en: '[PRE29]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Do not forget to clean up your environment, and remove the container when you
    are done, like this:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不要忘记清理你的环境，并在完成时删除容器，如下所示：
- en: '[PRE30]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'And, you will of course need to push your container to some accessible repository.
    For ease of use and demonstration purposes, I will be pushing it to my public
    Docker Hub repository:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当然，你还需要将你的容器推送到某个可访问的仓库。为了方便使用和演示目的，我将将其推送到我的公共Docker Hub仓库：
- en: '[PRE31]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'For this next part, we will interact with Digital Ocean through their CLI tool.
    If you do not have it installed, head to [https://docs.digitalocean.com/reference/doctl/how-to/install/](https://docs.digitalocean.com/reference/doctl/how-to/install/).
    You will want to make sure you login:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将通过Digital Ocean的CLI工具与之交互。如果你还没有安装，请访问[https://docs.digitalocean.com/reference/doctl/how-to/install/](https://docs.digitalocean.com/reference/doctl/how-to/install/)。你需要确保你登录：
- en: '[PRE32]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We need a Digital Ocean K8S cluster. Login to their web portal, click on **Kubernetes**
    on the main dashboard and set up a cluster. For now, default settings are fine.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要一个Digital Ocean K8S集群。登录到他们的网络门户，在主仪表板上点击**Kubernetes**并设置一个集群。目前，默认设置是足够的。
- en: 'We next need to enable `kubectl` (the tool to interact with K8S) to be able
    to talk to our Digital Ocean K8S cluster. If `kubectl` is not installed, check
    out the instructions here: [https://kubernetes.io/docs/reference/kubectl/overview/](https://kubernetes.io/docs/reference/kubectl/overview/).
    The command you need will look something like this:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要启用`kubectl`（与K8S交互的工具）以便能够与我们的Digital Ocean K8S集群通信。如果`kubectl`未安装，请查看以下说明：[https://kubernetes.io/docs/reference/kubectl/overview/](https://kubernetes.io/docs/reference/kubectl/overview/)。你需要执行的命令可能看起来像这样：
- en: '[PRE33]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Once your cluster is available and `kubectl` is set up, you can verify it by
    running:'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦你的集群可用并且`kubectl`已设置，你可以通过运行以下命令来验证它：
- en: '[PRE34]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Of course, we have not set up anything, so there should not be anything to see
    just yet.
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当然，我们还没有设置任何东西，所以目前还没有任何东西可以查看。
- en: When configuring Kubernetes, we need to start by running `kubectl apply` on
    our `app.yml`.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当配置Kubernetes时，我们需要首先在我们的`app.yml`上运行`kubectl apply`。
- en: '**TIP**'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**'
- en: ''
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Before going further, you will see a lot of online tutorials that use this
    style of command:'
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在继续之前，您会看到很多在线教程使用这种命令风格：
- en: ''
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`$ kubectl create ...`'
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$ kubectl create ...`'
- en: ''
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'I generally try to avoid that in favor of this:'
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我通常尽量避免这样做，而是选择以下方式：
- en: ''
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`$ kubectl apply ...`'
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`$ kubectl apply ...`'
- en: ''
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: They essentially do the same thing, but the convenience is that resources that
    are created with apply can be continually modified by “applying” the same manifest
    over and over again.
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 它们基本上做的是同一件事，但便利之处在于使用 `apply` 创建的资源可以通过反复“应用”相同的清单进行持续修改。
- en: 'What is in `app.yml`? Check out the GitHub repository for the full versions.
    It is rather lengthy and includes some boilerplate that is not relevant to the
    current discussion, so I will show only relevant snippets here. This goes for
    all of the K8S manifests in our example. The file should contain the Kubernetes
    primitives needed to run the application: a **service** and a **deployment**.The
    service should look something like the following:'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`app.yml` 中有什么内容？查看 GitHub 仓库以获取完整版本。它相当长，包括一些与当前讨论无关的样板内容，所以在这里我只展示相关片段。这适用于我们示例中的所有
    K8S 清单。该文件应包含运行应用程序所需的 Kubernetes 基本组件：一个 **服务** 和一个 **部署**。该服务应该看起来像以下这样：'
- en: '[PRE35]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Notice how we are mapping port `7777` to `80`. This is because we will be terminating
    TLS in front of Sanic and our ingress controller will talk to Sanic over HTTP
    unencrypted. Because it is all in a single cluster, this is acceptable. Your needs
    might be more sensitive, and then you should look into encrypting that connection
    as well.The other thing in `app.yml` is the deployment, which should look something
    like the following:'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意我们是如何将端口 `7777` 映射到 `80` 的。这是因为我们将在 Sanic 前终止 TLS，并且我们的入口控制器将通过未加密的 HTTP 与
    Sanic 通信。由于所有这些都位于单个集群中，这是可以接受的。您的需求可能更为敏感，那么您应该考虑加密该连接。`app.yml` 中的另一件事是部署，它应该看起来像以下这样：
- en: '[PRE36]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Here, we are defining the number of replicas we want, as well as pointing the
    container to our docker image repository.
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们定义了我们想要的副本数量，并将容器指向我们的 Docker 镜像仓库。
- en: 'After creating that file, we will apply it, and you should see a result similar
    to this:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建该文件后，我们将应用它，您应该看到类似以下的结果：
- en: '[PRE37]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'You can now checkout to see that it worked:'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您现在可以检查以确认它是否成功：
- en: '[PRE38]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We will next use an off the shelf solution to create an NGINX ingress. This
    will be the proxy layer that terminates our TLS and feeds HTTP requests into Sanic.
    We will install it as follows:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接下来将使用现成的解决方案来创建一个 NGINX 入口。这将是我们终止 TLS 的代理层，并将 HTTP 请求馈入 Sanic。我们将按照以下方式安装它：
- en: '[PRE39]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Note, at the time of writing, v1.0.0 is the latest. That probably is not true
    by the time you are reading this, so you may need to change that. You can find
    the latest version on their GitHub page: [https://github.com/kubernetes/ingress-nginx](https://github.com/kubernetes/ingress-nginx).'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，在撰写本文时，v1.0.0 是最新版本。这可能不是您阅读本文时的真实情况，因此您可能需要更改它。您可以在他们的 GitHub 页面上找到最新版本：[https://github.com/kubernetes/ingress-nginx](https://github.com/kubernetes/ingress-nginx)。
- en: Next, we will setup our ingress. Create an `ingress.yml` following the pattern
    in our GitHub repository example.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将设置我们的入口。创建一个 `ingress.yml`，按照我们 GitHub 仓库示例中的模式进行。
- en: '[PRE40]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You will notice there are *intentionally* some lines commented out. We will
    get to that in a minute. Let’s just quickly verify that it worked:'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您会注意到有一些行被故意注释掉了。我们稍后会讨论这个问题。让我们快速验证它是否成功：
- en: '[PRE41]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: We should take a step back and jump over to the **Digital Ocean** dashboard.
    On the left is a tab called **Networking**. Go there and then in the tab for **Domains**
    follow the procedure to add your own domain there. In that example, in `ingress.yml`
    we added `example.com` as the ingress domain. Whatever domain you add to Digital
    Ocean’s portal is what should match your ingress. If you need to go back and update
    and re-apply the `ingress.yml` file with your domain, do that now.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该退一步，跳转到 **Digital Ocean** 控制台。在左侧有一个名为 **网络** 的标签页。转到那里，然后在 **域名** 标签页中按照以下步骤添加您自己的域名。在示例中，我们在
    `ingress.yml` 中添加了 `example.com` 作为入口域名。您添加到 Digital Ocean 站点的任何域名都应该与您的入口匹配。如果您需要返回并更新并重新应用带有域名的
    `ingress.yml` 文件，请现在就做。
- en: 'Once that is all configured, we should be able to see our application working:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有配置都完成，我们应该能够看到我们的应用程序正在运行：
- en: '[PRE42]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This is of course not ideal because it is still on `http://`. We will now get
    a Let’s Encrypt certificate and set up TLS.
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当然，这并不是理想的情况，因为它仍然位于 `http://` 上。我们现在将获取一个 Let’s Encrypt 证书并设置 TLS。
- en: 'The easiest method for this is to set up a tool called `cert-manager`. It will
    do all of the interfacing we need with Let’s Encrypt. Start by installing it:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最简单的方法是设置一个名为`cert-manager`的工具。它将为我们与Let’s Encrypt进行所有必要的接口操作。首先安装它：
- en: '[PRE43]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Again, please check to see what the most up-to-date version is and update this
    command accordingly.We can verify its installation here:'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 再次，请检查最新的版本是什么，并相应地更新此命令。我们可以在以下位置验证其安装：
- en: '[PRE44]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Next, create the `load-balancer.yml` following the example in the GitHub repository.
    It should look something like this:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，根据GitHub仓库中的示例创建`load-balancer.yml`。它应该看起来像这样：
- en: '[PRE45]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Apply that manifest and confirm that it worked:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用该清单并确认它已成功：
- en: '[PRE46]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Your K8S cluster will now start the process of obtaining a certificate.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的K8S集群现在将开始获取证书的过程。
- en: '**Tip**'
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**'
- en: ''
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'One thing that you might encounter is that the process gets stuck while requesting
    the certificate. If this happens to you, the solution is to turn on **Proxy Protocol**
    in your **Digital Ocean** dashboard. Go to the following setting and turn this
    on if you need to:'
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可能会遇到的一个问题是，在请求证书时进程会卡住。如果你遇到这种情况，解决方案是在你的**Digital Ocean**仪表板上开启**代理协议**。前往以下设置，如果需要就将其开启：
- en: ''
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Networking** > **Load Balancer** > **Manage Settings** > **Proxy Protocol**
    > **Enabled**'
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**网络** > **负载均衡器** > **管理设置** > **代理协议** > **启用**'
- en: We’re almost there! Open up that `ingress.yml` file and uncomment those few
    lines that were previously commented out. Then `apply` the file.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们几乎完成了！打开那个`ingress.yml`文件，取消注释之前注释掉的几行。然后`apply`该文件。
- en: '[PRE47]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Done! You should not automatically have a redirect from `http://` to `https://`,
    and your application is fully protected.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 完成！你不应该自动从`http://`重定向到`https://`，并且你的应用程序得到了完全保护。
- en: Better yet, you now have a deployable Sanic application with all the benefits,
    flexibility, and scalability that K8S container orchestration provides.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的是，你现在拥有了一个可部署的Sanic应用程序，它具有K8S容器编排提供的所有好处、灵活性和可扩展性。
- en: Summary
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Building a great Sanic application is only half of the job. Deploying it to
    make our application usable out in the wild is the other half. In this chapter,
    we explored some important concepts for you to consider. It is never too early
    to think about deployment as well. The sooner you know which server you will use,
    and where you will host your application, the sooner you can plan accordingly.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个优秀的Sanic应用程序只是工作的一半。将其部署以使我们的应用程序在野外可用是另一半。在本章中，我们探讨了你需要考虑的一些重要概念。考虑部署永远不会太早。你越早知道将使用哪个服务器，以及你的应用程序将托管在哪里，你就越早可以相应地规划。
- en: There are of course many combinations of deployment options, and I only provided
    you with a small sampling. As always, you will need to learn what works for your
    project and team. Take what you have learned here and adapt it.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，有许多部署选项的组合，我只为你提供了一小部分样本。一如既往，你需要了解对你项目和团队有效的方法。将你在这里学到的知识应用到实践中。
- en: 'However, if you were to ask me to boil all of this information down and ask
    my personal advice on how to deploy Sanic, I would tell you this:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你要问我如何将这些信息归纳起来，并询问我关于如何部署Sanic的个人建议，我会告诉你这一点：
- en: Run your applications using the built-in Sanic server
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内置的Sanic服务器运行你的应用程序
- en: Terminate TLS outside of your application
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在应用程序外部终止TLS
- en: For personal or smaller projects, or if you want a simpler deployment option,
    use a PAAS provider
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于个人或较小项目，或者如果你想要一个更简单的部署选项，使用PAAS提供商
- en: For larger projects that need to scale and have more developer-resources, use
    a hosted Kubernetes solution
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于需要扩展并拥有更多开发资源的较大项目，使用托管Kubernetes解决方案
- en: There you have it. You now should be able to build a Sanic application and run
    it on the Internet. Our time is done, right? You should have the skills and knowledge
    you need now to go out and build something great, so go ahead and do that now.
    In the remainder of this book, we will start to look at some more practical issues
    that arise while building web applications and look at some best-practice strategies
    in how to solve them.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。你现在应该能够构建一个Sanic应用程序并在互联网上运行它。我们的时间结束了，对吧？你现在应该具备走出去并构建一些伟大事物的技能和知识，所以现在就去做吧。在这本书的剩余部分，我们将开始探讨在构建Web应用程序时出现的更多实际问题，并查看一些最佳实践策略来解决这些问题。
