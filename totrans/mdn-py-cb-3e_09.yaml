- en: '9'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Functional Programming Features
  prefs: []
  type: TYPE_NORMAL
- en: The idea of functional programming is to focus on writing small, expressive
    functions that perform the required data transformations. Combinations of functions
    can often create code that is more succinct and expressive than long strings of
    procedural statements or the methods of complex, stateful objects. This chapter
    focuses on functional programming features of Python more than procedural or object-oriented
    programming.
  prefs: []
  type: TYPE_NORMAL
- en: This provides an avenue for software design distinct from the strictly object-oriented
    approach used elsewhere in this book. The combination of objects with functions
    permits flexibility in assembling an optimal collection of components.
  prefs: []
  type: TYPE_NORMAL
- en: Conventional mathematics defines many things as functions. Multiple functions
    can be combined to build up a complex result from previous transformations. When
    we think of mathematical operators as functions, an expression like p = f(n,g(n))
    can also be written as two separate functions. We might think of this as p = f(n,b),
    where b = g(n).
  prefs: []
  type: TYPE_NORMAL
- en: 'Ideally, we can also create a composite function from these two functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![p = f(n,g(n)) = g ∘f (n ) ](img/file58.png)'
  prefs: []
  type: TYPE_IMG
- en: Defining a new composite function, g ∘ f, instead of nested functions can help
    to clarify the intent behind a design. This re-framing of the components can allow
    us to take a number of small details and combine them into a larger chunk of knowledge
    that embodies the concept behind the design.
  prefs: []
  type: TYPE_NORMAL
- en: Since programming often works with collections of data, we’ll often be applying
    a function to all the items of a collection. This happens when doing database
    extraction and transformation to align data from diverse source applications.
    It also happens when summarizing data. Something as commonplace as transforming
    a CSV file into a statistical summary is a composition of transformation functions
    from rows of text to rows of data, and from rows of data to a mean and standard
    deviation. This fits nicely with the mathematical idea of a set builder or set
    comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three common patterns for applying one function to a set of data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mapping: This applies a function to all the elements of a collection, {m(x)|x
    ∈ S}. We apply some function, m(x), to each item, x, of a larger collection, S.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Filtering: This uses a function to select elements from a collection, {x|x
    ∈ S if f(x)}. We use a function, f(x), to determine whether to pass or reject
    each item, x, from the larger collection, S.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reducing: This summarizes the items of a collection. One of the most common
    reductions is creating a sum of all items in a collection, S, written as ∑ [x∈S]x.
    Other common reductions include finding the smallest item, the largest one, and
    the product of all items.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll often combine these patterns to create more complex composite applications.
    What’s important here is that small functions, such as m(x) and f(x), can be combined
    via the built-in higher-order functions such as map(), filter(), and reduce().
    The itertools module contains many additional higher-order functions that we can
    use to build an application. And, of course, we can define our own higher-order
    functions to combine smaller functions.
  prefs: []
  type: TYPE_NORMAL
- en: Some of these recipes will show computations that could also be defined as properties
    of a class definition created using the @property decorator. This is yet another
    design alternative that can limit the complexity of stateful objects. In this
    chapter, however, we’ll try to stick to a functional approach, that is, transformation
    to create new objects rather than using properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll look at the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Writing generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Applying transformations to a collection](ch013_split_000.xhtml#x1-5090002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Picking a subset – three ways to filter](ch013_split_000.xhtml#x1-5270004)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Summarizing a collection – how to reduce](ch013_split_000.xhtml#x1-5350005)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Combining the map and reduce transformations](ch013_split_001.xhtml#x1-5440006)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Implementing “there exists” processing](ch013_split_001.xhtml#x1-5500007)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Creating a partial function](ch013_split_001.xhtml#x1-5560008)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Writing recursive generator functions with the yield from statement](ch013_split_001.xhtml#x1-5640009)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll start with a recipe where we will create functions that yield an iterable
    sequence of values. Rather than creating an entire list (or set, or some other
    collection), a generator function yields the individual items of a collection
    as demanded by a client operation. This saves memory and may save time.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Writing generator functions with the yield statement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A generator function is often designed to apply some kind of transformation
    to each item of a collection. Generators can create data, too. A generator is
    called lazy because the values it yields must be consumed by a client; values
    are not computed until a client attempts to consume them. Client operations like
    the list() function or a for statement are common examples of consumers. Each
    time a function like list() demands a value, the generator function must yield
    a value using the yield statement.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, an ordinary function can be called eager. Without the yield statement,
    a function will compute the entire result and return it via the return statement.
  prefs: []
  type: TYPE_NORMAL
- en: A lazy approach is very helpful in cases where we can’t fit an entire collection
    in memory. For example, analyzing gigantic web log files can be done in small
    doses rather than by creating a vast in-memory collection.
  prefs: []
  type: TYPE_NORMAL
- en: In the language of Python’s type hints, we’ll often use the Iterator generic
    to describe generators. We’ll need to clarify this generic with a type, like Iterator[str],
    to show that the function yields string objects.
  prefs: []
  type: TYPE_NORMAL
- en: The items that are being consumed by a generator will often be from a collection
    described by the Iterable generic type. All of Python’s built-in collections are
    Iterable, as are files. A list of string values, for example, can be viewed as
    an Iterable[str].
  prefs: []
  type: TYPE_NORMAL
- en: Both the Iterable and Iterator types are available from the collections.abc
    module. They can also be imported from the typing module.
  prefs: []
  type: TYPE_NORMAL
- en: The yield statement is what changes an ordinary function into a generator. It
    will compute and yield results iteratively.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ll apply a generator to some web log data. We’ll design a generator that
    will transform raw text into more useful structured objects. The generator function
    serves to isolate transformation processing. This permits flexibility in applying
    filter or summary operations after the initial transformation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The entries start out as lines of text that look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We’ve seen other examples of working with this kind of log in the [Using more
    complex structures – maps of lists](ch012.xhtml#x1-4810005) recipe in Chapter [8](ch012.xhtml#x1-4520008).
    Using REs from the [String parsing with regular expressions](ch005_split_000.xhtml#x1-350003)
    recipe in Chapter [1](ch005_split_000.xhtml#x1-170001), we can decompose each
    line into a more useful structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s often helpful to capture the details of each line of the log in an object
    of a distinct type. This helps make the code more focused, and it helps us use
    the mypy tool to confirm that types are used properly. Here’s a NamedTuple class
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We’ll start with the transformation of an iterable source of strings string
    into an iterator over tuple of fields. After that, we’ll apply the recipe again
    to transform the date attribute from a string into a useful datetime object.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A generator function is a function, so the recipe is similar to those shown
    in Chapter [3](ch007_split_000.xhtml#x1-1610003). We’ll start by defining the
    function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the needed type hints from the collections.abc module. Import the re
    module to parse the line of the log file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that iterates over RawLog objects. It seems helpful to include
    _iter in the function name to emphasize that the result is an iterator, not a
    single value. The parameter is an iterable source of log lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The parse_line_iter() transformation function relies on a regular expression
    to decompose each line. We can define this inside the function to keep it tightly
    bound with the rest of the processing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A for statement will consume each line of the iterable source, allowing us
    to create and then yield each RawLog object in isolation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The body of the for statement can map each string instance that matches the
    pattern to a new RawLog object using the match groups:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Non-matching lines will be silently dropped. For the most part, this seems sensible
    because a log can be filled with messages from a variety of sources.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Without a yield statement, a function is “ordinary” and computes a single result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here’s how we use this function to emit a sequence of RawLog instances from
    the sample data shown above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We could also collect items into a list object using something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, the list() function consumes all of the items produced by
    the parse_line_iter() function. A generator is a relatively passive construct:
    until data is demanded, it doesn’t do any work.'
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each of Python’s built-in collection types implements a special method, __iter__(),
    to produce an iterator object. An iterator object implements the __next__() special
    method to both return an item and advance the state of the iterator to return
    the next item. This is the Iterator protocol. The built-in next() function evaluates
    this method of an iterator object.
  prefs: []
  type: TYPE_NORMAL
- en: While the Python built-in collections can create Iterator objects, a generator
    function also implements this protocol. A generator will return itself in response
    to the iter() function. In response to the next() function, a generator suspends
    execution at a yield statement, and provides a value that becomes the result of
    the next() function. Since the function is suspended, it can be resumed when another
    next() function is evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see how the yield statement works, look at this small function, which yields
    two objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s what happens when we evaluate the next() function on this generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The first time we evaluated the next() function, the first print() function
    was evaluated, and then the yield statement produced a value.
  prefs: []
  type: TYPE_NORMAL
- en: The use of the next() function resumed processing, and the statements between
    the two yield statements were evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: 'What happens next? Since there are no more yield statements in the function’s
    body, so we observe the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The StopIteration exception is raised at the end of a generator function. This
    is expected by the processing of a for statement. It is quietly absorbed to break
    from processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we don’t use a function like list() or a for statement to consume the data,
    we’ll see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The value returned by evaluating the parse_line_iter() function is a generator.
    It’s not a collection of items, but an object that will produce items, one at
    a time, on demand from a consumer.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can apply this recipe to convert the date attributes in each RawLog object.
    The more refined kind of data from each line will follow this class definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This has a more useful datetime.datetime object for the timestamp. The other
    fields remain as strings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a generator function – using a for statement and yield so that it’s
    an iterator – that’s used to refine each RawLog object into a DatedLog object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Breaking overall processing into small generator functions confers several significant
    advantages. First, the decomposition makes each function more succinct because
    it is focused on a specific task. This makes these functions easier to design,
    test, and maintain. Second, it makes the overall composition somewhat more expressive
    of the work being done.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can combine these two generators in the following kind of composition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The parse_line_iter() function will consume lines from the source data, creating
    RawLog objects when they are demanded by a consumer. The parse_date_iter() function
    is a consumer of RawLog objects; from these, it creates DatedLog objects when
    demanded by a consumer. The outer for statement is the ultimate consumer, demanding
    DatedLog objects.
  prefs: []
  type: TYPE_NORMAL
- en: At no time will there be a large collection of intermediate objects in memory.
    Each of these functions works with a single object, limiting the amount of memory
    used.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe, we’ll combine generator functions to build complex processing stacks from
    simple components.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the [Applying transformations to a collection](ch013_split_000.xhtml#x1-5090002)
    recipe, we’ll see how the built-in map() function can be used to create complex
    processing from a simple function and an iterable source of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the [Picking a subset – three ways to filter](ch013_split_000.xhtml#x1-5270004)
    recipe, we’ll see how the built-in filter() function can also be used to build
    complex processing from a simple function and an iterable source of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.2 Applying transformations to a collection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We often define generator functions with the intention apply the function to
    a collection of data items. There are a number of ways that generators can be
    used with collections.
  prefs: []
  type: TYPE_NORMAL
- en: In the [Writing generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)
    recipe in this chapter, we created a generator function to transform data from
    a string into a more complex object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generator functions have a common structure, and generally look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The yield statement means the results will be generated iteratively. The function’s
    type hints emphasize that it consumes items from the source collection. This template
    for writing a generator function exposes a common design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, we can summarize this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![N = {m (x ) | x ∈ S} ](img/file59.png)'
  prefs: []
  type: TYPE_IMG
- en: The new collection, N, is a transformation, m(x), applied to each item, x, of
    the source, S. This emphasizes the transformation function, m(x), separating it
    from the details of consuming the source and producing the result. In the Python
    example previously shown, this function was called some_transformation().
  prefs: []
  type: TYPE_NORMAL
- en: This mathematical summary suggests that the for statement can be understood
    as a kind of scaffold around the transformation function. There are two additional
    forms this scaffolding can take. We can write a generator expression or we can
    use the built-in map() function. This recipe will examine all three techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ll look at the web log data from the [Writing generator functions with the
    yield statement](ch013_split_000.xhtml#x1-5030001) recipe. This had dates as strings
    that we would like to transform into a proper datetime object to be used for further
    computations. We’ll make use of the DatedLog class definition from that earlier
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'The [Writing generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)
    recipe used a generator function like the following example to transform a sequence
    of RawLog objects into an iterator of more useful DatedLog instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This parse_date_iter() function has a significant amount of scaffolding code
    around an interesting function. The for and yield statements are examples of scaffolding.
    The date parsing, on the other hand, is the distinctive, interesting part of the
    function. We need to extract this distinct processing to permit use of more flexible
    scaffolding.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To make use of different approaches to applying a generator function, we’ll
    need to start by refactoring the original parse_date_iter() function. This will
    extract a parse_date() function that can be used in a variety of ways. After this
    initial step, we’ll show three separate mini-recipes for using the refactored
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Refactor the iterator to define a function that can be applied to a single
    row of the data. It should produce an item of the result type from an item of
    the source type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This transformation can be applied to a collection of data in three ways: a
    generator function, a generator expression, and via the map() function. We’ll
    start by rebuilding the original generator.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the for and yield statements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can apply a single-row parse_date() transformation function to each item
    of a collection using the for and yield statements. This was shown in the [Writing
    generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)
    recipe earlier in this chapter. Here’s what it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Using a generator expression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can apply the parse_date() function to each item of a collection using a
    generator expression. A generator expression includes two parts – the mapping
    function, and a for clause – enclosed by (). This follows the pattern of the [Building
    lists – literals, appending, and comprehensions](ch008_split_000.xhtml#x1-2310002)
    recipe in Chapter [4](ch008_split_000.xhtml#x1-2240004):'
  prefs: []
  type: TYPE_NORMAL
- en: Write the () brackets that surround the generator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Write a for clause for the source of the data, assigning each item to a variable,
    in this case, item:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prefix the for clause with the mapping function, applied to the variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expression can be the return value from a function that provides suitable
    type hints for the source and the resulting expression. Here’s the entire function,
    since it’s so small:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The function returns the generator expression that applies the parse_date()
    function to each item in the source iterable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Yes, this function is so small, it doesn’t seem to require the overhead of a
    def statement and a name. The type hints can be helpful in some contexts, making
    this a sensible choice.
  prefs: []
  type: TYPE_NORMAL
- en: Using the map() function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can apply the parse_date() function to each item of a collection using the
    map() built-in function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the map() function to apply the transformation to the source data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expression can be the return value from a function that provides suitable
    type hints for the source and the resulting expression. Here’s the entire function,
    since it’s so small:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The map() function is an iterator that applies the parse_date() function to
    each item from the source iterable. It yields the objects created by the parse_date()
    function.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that the parse_date name without () is a reference to
    a function object.
  prefs: []
  type: TYPE_NORMAL
- en: It’s a common error to think the function must be evaluated, and include extra,
    unnecessary uses of ().
  prefs: []
  type: TYPE_NORMAL
- en: All three techniques are equivalent.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The map() function replaces some common code that acts as a scaffold around
    the processing. It does the work of a for statement. It applies the given function
    to each item in the source iterable.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can define our own version of map() as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As we’ve seen, these are identical in their behavior. Different audiences for
    the code may have distinct preferences. The guidance we offer is to choose the
    style that makes the meaning and intention the most clear to the audience reading
    the code.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this example, we’ve used the map() function to apply a function that takes
    a single parameter to each item of a single iterable collection. It turns out
    that the map() function can do a bit more than this. The map() function can process
    several sequences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this function and these two sources of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We can apply the mul() function to the sequence of pairs drawn from each source
    of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This allows us to merge several sequences of values using different kinds of
    operations on argument values pulled from the sequences.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe later in this chapter, we will look at stacked generators. We will build
    a composite function from a number of individual mapping operations, written as
    various kinds of generator functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.3 Using stacked generator expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the [Writing generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)
    recipe earlier in this chapter, we created a simple generator function that performed
    a single transformation on a piece of data. As a practical matter, we often have
    several functions that we’d like to apply to incoming data.
  prefs: []
  type: TYPE_NORMAL
- en: How can we stack or combine multiple generator functions to create a composite
    function?
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe will apply several different kinds of transformations to source
    data. There will be restructuring of the rows to combine three rows into a single
    row, data conversions to convert the source strings into useful numbers or datetime
    stamps, and filtering to reject rows that aren’t useful.
  prefs: []
  type: TYPE_NORMAL
- en: We have a spreadsheet that is used to record fuel consumption on a large sailboat.
  prefs: []
  type: TYPE_NORMAL
- en: For details of this data, see the [Slicing and dicing a list](ch008_split_000.xhtml#x1-2400003)
    recipe in Chapter [4](ch008_split_000.xhtml#x1-2240004). We’ll look at parsing
    this in more detail in the [Reading delimited files with the CSV module](ch015_split_000.xhtml#x1-6320003)
    recipe in Chapter [11](ch015_split_000.xhtml#x1-61500011).
  prefs: []
  type: TYPE_NORMAL
- en: 'We’d like to apply a number of transformations to each row-level list of this
    list-of-lists-of-strings object:'
  prefs: []
  type: TYPE_NORMAL
- en: Exclude the three lines of headers (and any blank lines) that are present in
    the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Merge three physical lines of text strings into one logical row of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert the separated date and time strings into datetime objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert the fuel height from a string to a float, ideally in gallons (or liters)
    instead of inches.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our goal is to create a group of generator functions. Assuming we have assigned
    the results of a generator function to a variable, datetime_gen, the transformations
    allow us to have software that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We need to design a composite function that can create this datetime_gen generator.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll decompose this into three separate mini-recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Restructuring the rows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Excluding the header row.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating more useful row objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll start with restructuring three physical lines into a logical row.
  prefs: []
  type: TYPE_NORMAL
- en: Restructuring the rows
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We’ll start by creating a row_merge() function to restructure the data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use a named tuple to define a type for the combined logical rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The raw data has empty cells; we’ve called them filler_1, filler_2, and filler_3\.
    Preserving these junk columns can make it easier to debug problems.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The source rows created by a CSV reader will have a list[str] type; we’ll provide
    an alias for this type, RawRow. The function’s definition will accept an iterable
    of RawRow instances. It is an iterator over CombinedRow objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The body of the function will consume rows from the source iterator, skipping
    empty lines, building a cluster that defines a CombinedRow object. When the first
    column is non-empty, any previous cluster is complete, it is yielded, and a new
    cluster is started. The very last cluster also needs to be yielded:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This initial transformation can be used to convert a sequence of lines of CSV
    cell values into CombinedRow objects where each of the field values from three
    separate rows have their own unique attributes.
  prefs: []
  type: TYPE_NORMAL
- en: The first row output from this transformation will be a header row. The next
    part is a function to drop this row.
  prefs: []
  type: TYPE_NORMAL
- en: Excluding the header row
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first three lines of text from the source CSV file will create a CombinedRow
    object that’s not very useful. We’ll exclude a row with labels instead of data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a function to work with an iterable collection of CombinedRow objects,
    creating an iterator of CombinedRow objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The function’s body consumes each row of the source and yields the good rows.
    It uses a continue statement to reject the undesirable rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This can be combined with the row_merge() function shown in the previous recipe
    to provide an iterator over good data.
  prefs: []
  type: TYPE_NORMAL
- en: There are several transformation steps required to make the merged data truly
    useful. Next, we’ll look at one of these, creating proper datetime.datetime objects.
  prefs: []
  type: TYPE_NORMAL
- en: Creating more useful row objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The dates and times in each row aren’t very useful as separate strings. The
    function we’ll write can have a slightly different form than the previous two
    steps in this recipe because it applies to each row in isolation. The single-row
    transformation looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a new NamedTuple class that specifies a more useful type for the time
    values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a mapping function to convert one CombinedRow instance into a single
    DatetimeRow instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The body of this function will perform a number of date-time computations and
    create a new DatetimeRow instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now stack the transformation functions to merge rows, exclude the header,
    and perform date time conversions. The processing looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We’ve decomposed the reformatting, filtering, and transformation problems into
    three separate functions. Each of these three steps does a small part of the overall
    job. We can test each of the three functions separately. More important than being
    able to test is being able to fix or revise one step without completely breaking
    the entire stack of transformations.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we write a generator function, the argument value can be a collection of
    items, or it can be any other kind of iterable source of items. Since generator
    functions are iterators, it becomes possible to create a pipeline of generator
    functions by stacking them. The results of one generator are the input to the
    next one in the stack.
  prefs: []
  type: TYPE_NORMAL
- en: The datetime_gen object created by this recipe is a composition of three separate
    generators. A for statement can gather values from the datetime_gen generator
    expression. The body of that statement can print details and compute summaries
    of the objects being generated.
  prefs: []
  type: TYPE_NORMAL
- en: This design emphasizes small, incremental operations at each stage. Some stages
    of the pipeline will consume multiple source rows for a single result row, restructuring
    the data as it is processed. Other stages consume and transform a single row,
    making them amenable to being described by generator expressions.
  prefs: []
  type: TYPE_NORMAL
- en: The entire pipeline is driven by demand from the client. Note that there’s no
    concurrency in this processing. Each function is “suspended” at the yield statement
    until a client demands more data from it via the built-in next() function.
  prefs: []
  type: TYPE_NORMAL
- en: Most importantly, the individual transformation steps can be debugged and tested
    separately. This decomposition can help to create more robust and reliable software.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a number of other conversions required to make this data useful. We’ll
    want to transform the start and end timestamps into a duration. We also need to
    transform the fuel height values into floating-point numbers instead of strings.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a number of ways to handle these derived data computations:'
  prefs: []
  type: TYPE_NORMAL
- en: We can create additional transformation steps in our stack of generator functions.
    This reflects an eager computation approach.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can also add @property methods to the class definition. This is lazy computation;
    it’s only performed when the property value is required.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To compute additional fuel height and volume values eagerly, we can apply the
    design pattern again. First, define additional named tuple classes with the required
    fields. Then, define a transformation function to convert height from a string
    to a float. Also, define a transformation to convert height from inches to gallons.
    These additional functions will be small and easy to test.
  prefs: []
  type: TYPE_NORMAL
- en: We now have a sophisticated computation that’s defined in a number of small
    and (almost) completely independent chunks. Each function does the work required
    to create only one row, keeping the overheads to a minimum. We can modify one
    piece without having to think deeply about how the other pieces work.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: See the [Writing generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)
    recipe for an introduction to generator functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the [Slicing and dicing a list](ch008_split_000.xhtml#x1-2400003) recipe
    in Chapter [4](ch008_split_000.xhtml#x1-2240004), for more information on the
    fuel consumption dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the [Combining the map and reduce transformations](ch013_split_001.xhtml#x1-5440006)
    recipe for another way to combine operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [Picking a subset – three ways to filter](ch013_split_000.xhtml#x1-5270004)
    recipe covers the filter function in more detail.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.4 Picking a subset – three ways to filter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Choosing a subset of relevant rows can be termed filtering a collection of data.
    We can view a filter as rejecting bad rows or including the desirable rows. There
    are several ways to apply a filtering function to a collection of data items.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe, we wrote the skip_header_date() generator function to exclude some rows
    from a set of data. The skip_header_date() function combined two elements: a rule
    to pass or reject items, and a source of data. This generator function had a general
    pattern that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This data_filter_iter() function’s type hints emphasize that it is an iterable
    that consumes items of a type, T, from an iterable source collection. Some expression
    is applied to each item to determine if it’s valid. This expression can be defined
    as a separate function. We can define filters of considerable sophistication.
  prefs: []
  type: TYPE_NORMAL
- en: 'The design pattern can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![N = {x | x ∈ S if f(x)} ](img/file60.png)'
  prefs: []
  type: TYPE_IMG
- en: The new collection, N, is each item, x, in the source, S, where a filter function,
    f(x), is true. This summary emphasizes the filter function, f(x), separating it
    from minor technical details of consuming the source and producing the result.
  prefs: []
  type: TYPE_NORMAL
- en: This mathematical summary suggests the for statement is little more than scaffolding
    code. Because it’s less important than the filter rule, it can help to refactor
    a generator function and extract the filter from the other processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering the for statement as scaffolding, how else can we apply a filter
    to each item of a collection? There are two additional techniques we can use:'
  prefs: []
  type: TYPE_NORMAL
- en: We can write a generator expression.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use the built-in filter() function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these require refactoring the generator function — skip_header_date(),
    shown earlier in the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe — to extract the decision-making expression, separate from the for and
    if scaffolding around it. From this function, we can then move to creating a generator
    expression, and using the filter() function.
  prefs: []
  type: TYPE_NORMAL
- en: 9.4.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we’ll look at the fuel consumption data from the [Using stacked
    generator expressions](ch013_split_000.xhtml#x1-5180003) recipe in this chapter.
    For details of this data, see the [Slicing and dicing a list](ch008_split_000.xhtml#x1-2400003)
    recipe in Chapter [4](ch008_split_000.xhtml#x1-2240004).
  prefs: []
  type: TYPE_NORMAL
- en: We used two generator functions. The first, row_merge(), restructured the physical
    lines into logical rows. A named tuple, CombinedRow, was used to provide a more
    useful structure to the row data. The second generator function, skip_header_date(),
    rejected the heading rows of the data, passing the useful data rows.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll rewrite the skip_header_date() function to demonstrate three distinct
    approaches to extracting useful data.
  prefs: []
  type: TYPE_NORMAL
- en: 9.4.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first part of this recipe will refactor the “good data” rule out of the
    generator function to make it more widely useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with a draft version of a generator function with the following outline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expression in the if statement can be refactored into a function that can
    be applied to a single row of the data, producing a bool value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The original generator function can now be simplified:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The pass_non_date() function can be used in three ways. As shown here, it can
    be used by a generator function. It can also be used in a generator expression,
    and with the filter() function. Next, we’ll look at writing an expression.
  prefs: []
  type: TYPE_NORMAL
- en: Using a filter in a generator expression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A generator expression includes three parts – the item, a for clause, and an
    if clause – all enclosed by ():'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with a for clause that assigns objects to a variable. This source comes
    from some iterable collection, which is called source in this example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Because this is a filter, the result expression should be the variable from
    the for clause:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Write an if clause using the filter rule function, pass_non_date():'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This generator expression can be the return value from a function that provides
    suitable type hints for the source and the resulting expression. Here’s the entire
    function, since it’s so small:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This function returns the result of the generator expression. The function doesn’t
    do very much, but it does applying a name and a set of type hints to the expression.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The skip_header_gen() function uses a generator expression that applies the
    pass_non_date() function to each item in the source collection to determine whether
    it passes and is kept, or whether it is rejected.
  prefs: []
  type: TYPE_NORMAL
- en: The results are identical to the original skip_header_date() function, shown
    above.
  prefs: []
  type: TYPE_NORMAL
- en: Using the filter() function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using the filter() function includes two parts – the decision function and
    the source of data – as arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the filter() function to apply the function to the source data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The filter() function is an iterator that applies the given function, pass_non_date()
    as a rule to pass or reject each item from the given iterable, data. It yields
    the rows for which the pass_non_date() function returns True.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that the pass_non_date name without () is a reference
    to a function object.
  prefs: []
  type: TYPE_NORMAL
- en: It’s a common error to think the function must be evaluated, and include extra,
    unnecessary uses of ().
  prefs: []
  type: TYPE_NORMAL
- en: 9.4.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A generator expression must include a for clause to provide a source of data
    items. The optional if clause can apply a condition that preserves some items
    while rejecting others. Placing a filter condition in an if clause can make the
    expression clear and expressive of the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Generator expressions have an important limitation. As expressions, they cannot
    use statement-oriented features of Python. The try-except statement, used to handle
    exceptional data conditions, is often helpful.
  prefs: []
  type: TYPE_NORMAL
- en: 9.4.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, it’s difficult to write a simple rule to define the valid data or
    reject the invalid data. In many cases, it may be impossible to use a simple string
    comparison to identify rows to reject. This happens when a file is filled with
    extraneous information; manually prepared spreadsheets suffer from this. It some
    cases, there’s no trivial regular expression that helps to characterize valid
    data.
  prefs: []
  type: TYPE_NORMAL
- en: We can often encounter data where the easiest way to establish validity is to
    attempt a conversion, and transform the presence or absence of an exception into
    a Boolean condition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following function to ascertain if a row of data has a valid date:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: This will attempt a conversion of a date. It will reject invalid strings of
    characters that fail to follow the essential format rule. It will also reject
    2/31/24; while the string of digits is valid, this is not a real date.
  prefs: []
  type: TYPE_NORMAL
- en: 9.4.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe earlier in this chapter, we placed a function like this in a stack of generators.
    We built a composite function from a number of individual mapping and filtering
    operations written as generator functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.5 Summarizing a collection – how to reduce
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A reduction is the generalized concept behind computing a summmary like the
    total or the maximum of a collection of numbers. Computing statistical measures
    like mean or variance are also reductions. In this recipe, we’ll look at several
    summarization or reduction techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the introduction to this chapter, we noted that there are three processing
    patterns that Python supports elegantly: map, filter, and reduce. We saw examples
    of mapping in the [Applying transformations to a collection](ch013_split_000.xhtml#x1-5090002)
    recipe and examples of filtering in the [Picking a subset – three ways to filter](ch013_split_000.xhtml#x1-5270004)
    recipe.'
  prefs: []
  type: TYPE_NORMAL
- en: The third common pattern is reduction. In the [Designing classes with lots of
    processing](ch011_split_000.xhtml#x1-3890003) and the [Extending a built-in collection
    – a list that does statistics](ch011_split_001.xhtml#x1-4250009) recipes, we looked
    at class definitions that computed a number of statistical values. These definitions
    relied — almost exclusively — on the built-in sum() function. This is one of the
    more common reduce operations.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we’ll look at a way to generalize summation, leading to ways
    to write a number of different kinds of reductions that are similar. Generalizing
    the concept of reduction will let us build on a reliable foundation to create
    more sophisticated algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 9.5.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some of the most common reduce operations are the sum, minimum, maximum. These
    reductions are so common, they’re built in. The average and variance, on the other
    hand, are reductions defined in the statistics module. The math module has a variant
    on sum, fsum(), that works particularly well for collections of floating-point
    values.
  prefs: []
  type: TYPE_NORMAL
- en: Summations are the backbone of financial reporting. It is the essence of what
    a spreadsheet has been used for since the days of doing financial reports using
    pen and paper.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mathematics of summation help us to see how an operator is used to convert
    a collection of values into a single value. Here’s a way to think of the mathematical
    definition of the sum function using an operator, +, applied to the values in
    a collection, C = {c[0],c[1],c[2],…,c[n]}:'
  prefs: []
  type: TYPE_NORMAL
- en: '![∑ ci = c0 + c1 + c2 + ⋅⋅⋅+ cn + 0 ci∈C ](img/file61.png)'
  prefs: []
  type: TYPE_IMG
- en: We’ve expanded the definition of sum by folding the + operator into the sequence
    of values in C.
  prefs: []
  type: TYPE_NORMAL
- en: 'Folding involves two items: a binary operator and a base value. For sum, the
    operator was + and the base value was zero. For product, the operator is × and
    the base value is one. The base value needs to be the identity element for the
    given operator.'
  prefs: []
  type: TYPE_NORMAL
- en: We can apply this concept to many algorithms, potentially simplifying the definition.
    In this recipe, we’ll define a product function. This is the ![∏ ](img/file62.png)
    operator, similar to the ![∑ ](img/file63.png) operator.
  prefs: []
  type: TYPE_NORMAL
- en: 9.5.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here’s how we define a reduction that implements product of a collection of
    numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the reduce()) function from the functools module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Pick the operator. For sum, it’s +. For product, it will be ×. These can be
    defined in a variety of ways. Here’s the long version. Other ways to define the
    necessary binary operators will be shown later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Pick the base value required. The additive identity value for sum is zero.
    The multiplicative identity for a product is one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can use this prod() function to define other functions. One example is the
    factorial function. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'How many six-card cribbage hands are possible? The binomial calculation uses
    the factorial function to compute the number of ways 6 cards can be extracted
    from a 52 card deck:'
  prefs: []
  type: TYPE_NORMAL
- en: '![( ) 52 = ----52!--- 6 6!(52− 6)! ](img/file64.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here’s a Python implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: For any given shuffle, there are about 20 million different possible cribbage
    hands we might see.
  prefs: []
  type: TYPE_NORMAL
- en: 9.5.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The reduce() function behaves as though it has this definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: The type hints shows how there has to be a unifying type, T, that applies to
    the operator being folded, and the initial value for the folding. The given function,
    fn(), must combine two values of type T and return another value of the same type
    T. The result of the reduce() function will be a value of this type also.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, in Python, the reduce operation will iterate through the values
    from left to right. It will apply the given binary function, fn(), between the
    previous result and the next item from the source collection. This additional
    detail is important when thinking about non-commutative operators like subtraction
    or division.
  prefs: []
  type: TYPE_NORMAL
- en: 9.5.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll look at three additional topics. First, ways to define the operation.
    After that, we’ll look at applying reduce to Boolean values in [Logical reductions:
    any and all](ch013_split_001.xhtml#x1-5410004). Finally, in [Identity elements](ch013_split_001.xhtml#x1-5420004),
    we’ll look at the identity elements used by various operators.'
  prefs: []
  type: TYPE_NORMAL
- en: Operation definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When designing a new application for the reduce() function, we need to provide
    a binary operator. There are three ways to define the necessary binary operator.
    First, we can use a complete function definition, as shown above in the recipe.
    There are two other choices. We can use a lambda object instead of a complete
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'A lambda object is an anonymous function boiled down to just two essential
    elements: the parameters and the return expression. There are no statements inside
    a lambda, only a single expression.'
  prefs: []
  type: TYPE_NORMAL
- en: We assigned the lambda object to a variable, lmul, so that we can use the expression
    lmul(2, 3) to apply the lambda object to argument values.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the operation is one of Python’s built-in operators, we have another choice
    – import the definition from the operator module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: This works nicely for all the built-in arithmetic operators.
  prefs: []
  type: TYPE_NORMAL
- en: It’s essential to consider the complexity of the operator being used to reduce.
    Performing a reduce operation increases an operation’s complexity by a factor
    of n. An operation that’s O(1) becomes O(n) when applied to n items in a collection.
    For the operators we’ve shown, like add and mul, this fits our expectations. An
    operator with more complexity than O(1) can turn into a performance nightmare.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll look at the logical reduction functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Logical reductions: any and all'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Conceptually, it seems like we should be able to do reduce() operations using
    the Boolean operators and and or. It turns out this involves some additional consideration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python’s Boolean operators have a short-circuit feature: when we evaluate the
    expression False and 3 / 0, the result is only False. The expression on the right-hand
    side of the and operator, 3 / 0, is never evaluated. The or operator is similar:
    when the left side is True, the right-hand side is never evaluated.'
  prefs: []
  type: TYPE_NORMAL
- en: If we want to be sure that a sequence of bool values is all true, building our
    own reduce() will do far too much work. Once the initial False is seen, there’s
    no reason to process the remaining items. The short-circuit feature of and and
    or does not not fit with the reduce() function.
  prefs: []
  type: TYPE_NORMAL
- en: The built-in functions any() and all(), on the other hand, are reductions using
    logic operators. The any() function is, effectively, a kind of reduce() using
    the or operator. Similarly, the all() function behaves as if it’s a reduce() with
    the and operator.
  prefs: []
  type: TYPE_NORMAL
- en: Identity elements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Generally, an operator used for a reduction must have an identity element.
    This is provided to the reduce() function as the initial value. The identity element
    will also be the result when they’re applied against an empty sequence. Here are
    some common examples:'
  prefs: []
  type: TYPE_NORMAL
- en: sum([]) is zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: math.prod([]) is one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: any([]) is False.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: all([]) is True.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The identity value for the given operation is a matter of definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of any() and all() specifically, it can help to think of the fundamental
    fold operation. The identity element can always be folded in without changing
    the result. Here’s how all() would look with explicitly folded and operators:'
  prefs: []
  type: TYPE_NORMAL
- en: '![b0 and b1 and b2 and ... and bn and True ](img/file65.png)'
  prefs: []
  type: TYPE_IMG
- en: If all of the values b[0],b[1],b[2],...,b[n] are True, then the additional and
    True doesn’t change the value. If any of the values b[0],b[1],b[2],...,b[n] are
    are False, similarly, the additional and True has no impact.
  prefs: []
  type: TYPE_NORMAL
- en: When there are no values in a collection, the value for all() is the identity
    element, True.
  prefs: []
  type: TYPE_NORMAL
- en: 9.5.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: See the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe in this chapter for a context in which sum can be applied to compute total
    hours and total fuel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.6 Combining the map and reduce transformations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the other recipes in this chapter, we’ve been looking at map, filter, and
    reduce operations. We’ve looked at each of these functions in isolation:'
  prefs: []
  type: TYPE_NORMAL
- en: The [Applying transformations to a collection](ch013_split_000.xhtml#x1-5090002)
    recipe shows the map() function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [Picking a subset – three ways to filter](ch013_split_000.xhtml#x1-5270004)
    recipe shows the filter() function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [Summarizing a collection – how to reduce](ch013_split_000.xhtml#x1-5350005)
    recipe shows the reduce() function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many algorithms will involve creating composite functions that combine these
    more basic operations. Additionally, we’ll need to look at a profound limitation
    of working with iterators and generator functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of this limitation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: We created an iterator over a sequence of values by manually applying the iter()
    function to a literal list object. The first time that the sum() function consumed
    the values from typical_iterator, it consumed all five values. The next time we
    try to apply any function to typical_iterator, there will be no more values to
    be consumed; the iterator will appear empty. By definition, the identity value
    — 0 for summation — is the result.
  prefs: []
  type: TYPE_NORMAL
- en: An iterator can only produce values once.
  prefs: []
  type: TYPE_NORMAL
- en: After the values have been consumed, an iterator appears to be an empty collection.
  prefs: []
  type: TYPE_NORMAL
- en: This one-time-only constraint will force us to cache intermediate results when
    we need to perform multiple reductions on the data. Creating intermediate collection
    objects will consume memory, leading to the need for a careful design when working
    with very large collections of data. (Processing large collections of data is
    difficult. Python offers some ways to create workable solutions; it does not magically
    make the problem evaporate.)
  prefs: []
  type: TYPE_NORMAL
- en: To apply a complex transformation of a collection, we often find instances of
    map, filter, and reduce operations that can be implemented separately. These can
    then be combined into sophisticated composite operations.
  prefs: []
  type: TYPE_NORMAL
- en: 9.6.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe earlier in this chapter, we looked at some sailboat data. The spreadsheet
    was badly organized, and a number of steps were required to impose a more useful
    structure on the data.
  prefs: []
  type: TYPE_NORMAL
- en: In that recipe, we looked at a spreadsheet that is used to record fuel consumption
    on a large sailboat. For details of this data, see the [Slicing and dicing a list](ch008_split_000.xhtml#x1-2400003)
    recipe in Chapter [4](ch008_split_000.xhtml#x1-2240004). We’ll look at parsing
    this in more detail in the [Reading delimited files with the CSV module](ch015_split_000.xhtml#x1-6320003)
    recipe in Chapter [11](ch015_split_000.xhtml#x1-61500011).
  prefs: []
  type: TYPE_NORMAL
- en: The initial processing in the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe created a sequence of operations to change the organization of the data,
    filter out the headings, and compute some useful values. We’d need to supplement
    this with two more reductions to get some average and variance information. These
    statistics will help us understand the data more fully. We’ll build on that earlier
    processing with some additional steps.
  prefs: []
  type: TYPE_NORMAL
- en: 9.6.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ll start with a target line of code as the design goal. In this case, we’d
    like a function to sum the fuel use per hour. This follows a common three-step
    processing pattern. First, we normalize the data with row_merge(). Second, we
    use mapping and filtering to create more useful objects with clean_data_iter().
  prefs: []
  type: TYPE_NORMAL
- en: 'The third step should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Our target function, total_fuel(), is designed to work with a few other functions
    that clean and organize the raw data. We’ll start with the normalization and proceed
    to defining the final summary function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the functions from earlier recipes to reuse the initial preparation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the target data structure created by the cleaning and enrichment step.
    We’ll use a mutable dataclass in this example. The fields coming from the normalized
    CombinedRow object can be initialized directly. The other five fields will be
    computed eagerly by several separate functions. Fields not computed in the __init__()
    method must be given an initial value of field(init=False):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the overall data cleansing and enrichment data function. This will build
    the enriched Leg objects from the source CombinedRow objects. We’ll build this
    from seven simpler functions. The implementation is a stack of map() and filter()
    operations that will derive data from the source fields:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Each statement makes use of the iterator produced by the preceding statement.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Write the make_Leg() function to create Leg instances from CombinedRow instances:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Write the reject_date_header() function used by filter() to remove the heading
    rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Write the data conversion functions. We’ll start with the two date and time
    strings, which need to become a single datetime object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Mutate the Leg instances with additional values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This update-in-place approach is an optimization to avoid creating intermediate
    objects.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compute the derived duration from the timestamps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute any other metrics that are needed for the analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The final fuel_per_hour() function’s calculation depends on the entire preceding
    stack of calculations. Each of these computations is done separately to clarify
    and isolate the computation details. This approach permits changes to the isolated
    computations. Most importantly, it permits testing each computation as a separate
    unit.
  prefs: []
  type: TYPE_NORMAL
- en: 9.6.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The core concept is to build a composite transformation from a sequence of small
    steps. Since each step is conceptually distinct, it makes it somewhat easier to
    understand the composition.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we’ve used three kinds of transformations:'
  prefs: []
  type: TYPE_NORMAL
- en: Structural changes. An initial generator function grouped physical lines into
    logical rows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filters. A generator function rejected rows that were invalid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Enrichment. As we’ve seen, there are two design approaches to enriching data:
    lazy and eager. The lazy approach may involve methods or properties, computed
    only as needed. This design shows eager computation, where a number of fields
    had values built by the processing pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The various enrichment methods worked by updating stateful Leg objects, setting
    computed column values. Using stateful objects like this requires the various
    enrichment transformations be performed in a strict order because some (like duration())
    depend on others having been performed first.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now design the target computation functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: This meets our design goal of being able to perform meaningful computations
    on the raw data.
  prefs: []
  type: TYPE_NORMAL
- en: 9.6.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we noted, we can only perform one iteration of consuming the items from an
    iterable source of data. If we want to compute several averages, or the average
    as well as the variance, we’ll need to use a slightly different design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to compute multiple summaries of the data, it’s often best to create
    a concrete object of some kind that can be summarized repeatedly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Here, we’ve created a very large tuple from the cleaned and enriched data. From
    this tuple, we can can produce any number of iterators. This lets us compute any
    number of distinct summaries.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use the tee() function in the itertools module for this kind of
    processing. This can devolve to inefficient processing because of the way the
    cloned instances of the iterator maintain their internal state. It’s often better
    to create an intermediate structure like a list or tuple than to use itertools.tee().
  prefs: []
  type: TYPE_NORMAL
- en: The design pattern applies a number of transformations to the source data. We’ve
    built it using a stack of separate map, filter, and reduce operations.
  prefs: []
  type: TYPE_NORMAL
- en: 9.6.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: See the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe in this chapter for a context in which sum can be applied to compute total
    hours and total fuel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the [Summarizing a collection – how to reduce](ch013_split_000.xhtml#x1-5350005)
    recipe in this chapter for some background on the reduce() function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See [Python High Performance](https://www.packtpub.com/product/python-high-performance-second-edition-second-edition/9781787282896)
    for more on distributed map-reduce processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We look at lazy properties in the [Using properties for lazy attributes](ch011_split_001.xhtml#x1-43100010)
    recipe in Chapter [7](ch011_split_000.xhtml#x1-3760007). Also, this recipe looks
    at some important variations of map-reduce processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.7 Implementing “there exists” processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The processing patterns we’ve been looking at can all be summarized with the
    universal quantifier, ∀, meaning for all. It’s been an implicit part of all of
    the processing definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Map: For all items in the source, S, apply the map function, m(x). We can use
    the universal quantifier: ∀[x∈S]m(x).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Filter: This, also, means for all items in the source, S, pass those for which
    the filter function, f(x), is true. Here, also, we can use the universal quantifier:
    ∀[x∈S]x if f(x).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reduce: For all items in the source, use the given operator and base value
    to compute a summary. The universal quantification is implicit in the definition
    of operators ∑ [x∈S]x and ∏ [x∈S]x.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contrast these universal functions with the cases where we are only interested
    in locating a single item. We often describe these cases as a search to show there
    exists at least one item where a condition is true. This can be described with
    the existential quantifier, ∃, meaning there exists.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll need to use some additional features of Python to create generator functions
    that stop when the first value matches some predicate. We’d like to emulate the
    short-circuit capabilities of the built-in any() and all() functions.
  prefs: []
  type: TYPE_NORMAL
- en: 9.7.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For an example of an existence test, consider a function to determine if a number
    is prime or composite. A prime number has no factors other than 1 and itself.
    Numbers with multiple factors are called composite. The number 42 is composite
    because it has the numbers 2, 3, and 7 as prime factors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding if a number is prime number is the same as showing it is not composite.
    For any composite (or non-prime) number, n, the rule is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![¬P (n ) = ∃2≤i<n(n ≡ 0 mod i) ](img/file66.png)'
  prefs: []
  type: TYPE_IMG
- en: A number, n, is not prime if there exists a value, i, between 2 and the number
    itself, that divides the number evenly. For a test to see if a number is prime,
    we don’t need to know all the factors. The existence of a single factor shows
    the number is composite.
  prefs: []
  type: TYPE_NORMAL
- en: The overall idea is to iterate over the range of candidate numbers, breaking
    from the iteration when a factor is found. In Python, this early exit from a for
    statement is done with the break statement, shifting the semantics from “for all”
    to “there exists.” Because break is a statement, we can’t easily use a generator
    expression; we’re constrained to writing a generator function.
  prefs: []
  type: TYPE_NORMAL
- en: (The Fermat test is generally more efficient than what we’re using for these
    examples, but it doesn’t involve a simple search for the existence of a factor.
    We’re using this as an illustration of search, not as an illustration of good
    primality tests.)
  prefs: []
  type: TYPE_NORMAL
- en: 9.7.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to build this kind of search function, we’ll need to create a generator
    function that will complete processing when it finds the first match. One way
    to do this is with the break statement, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a generator function to skip items until a test is passed. The generator
    can yield the first value that passes the predicate test. The generator works
    by applying a predicate function, fn(), to the items in a sequence of items of
    some type, T:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the specific predicate function for this application. Since we’re testing
    for being prime, we’re looking for any value that divides the target number, n,
    evenly. Here’s the kind of expression that’s needed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the find_first() search function with the given range of values and predicate.
    If the factors iterable has an item, then n is composite. Otherwise, there are
    no values in the factors iterable, which means n is a prime number:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As a practical matter, we don’t need to test every number between two and n
    to see whether n is prime. It’s only necessary to test values, i, such that 2
    ≤ i < ⌊![√n-](img/file67.png)⌋.
  prefs: []
  type: TYPE_NORMAL
- en: 9.7.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the find_first() function, we introduce a break statement to stop processing
    the source iterable. When the for statement stops, the generator will reach the
    end of the function and return normally.
  prefs: []
  type: TYPE_NORMAL
- en: A client function consuming values from this generator will be given the StopIteration
    exception. The find_first() function can raise an exception, but it’s not an error;
    it’s the signal that an iterable has finished processing the input values.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the StopIteration exception means one of two things:'
  prefs: []
  type: TYPE_NORMAL
- en: If a value had been yielded previously, the value is a factor of n.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no value was yielded, then n is prime.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This small change of breaking early from the for statement makes a dramatic
    difference in the meaning of the generator function. Instead of processing all
    values from the source, the find_first() generator will stop processing as soon
    as the predicate is true.
  prefs: []
  type: TYPE_NORMAL
- en: 9.7.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the itertools module, there is an alternative to the find_first() function.
    The takewhile() function uses a predicate function to take values from the input
    while the predicate function is true. When the predicate becomes false, then the
    function stops consuming and producing values.
  prefs: []
  type: TYPE_NORMAL
- en: To use the takewhile() function, we need to invert our factor test. We need
    to consume values that are non-factors until we find the first factor. This leads
    to a change in the lambda from lambda i: n % i == 0 to lambda i: n % i != 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a test to see if 47 is prime. We need to check numbers in the
    range 2 to ![√ --- 49](img/file68.png) = 7:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: For a prime number, like 47, none of the test values are factors. All these
    non-factor test values pass the takewhile() predicate because it’s always true.
    The resulting list is the same as the original set of test values.
  prefs: []
  type: TYPE_NORMAL
- en: For a composite number, the non-factor test values will be a subset of the test
    values. Some values will have been excluded because a factor was found.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of additional functions in the itertools module that can
    be used to simplify complex map-reduce applications. We encourage you to look
    closely at this module.
  prefs: []
  type: TYPE_NORMAL
- en: 9.7.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe earlier in this chapter, we made extensive use of immutable class definitions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See [https://projecteuler.net/problem=10](https://projecteuler.net/problem=10)
    for a challenging problem related to prime numbers less than 2 million. Parts
    of the problem seem obvious. It can be difficult, however, to test all those numbers
    for being prime.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The itertools module provides numerous functions that can simplify functional
    design.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outside the standard library, packages like [Pyrsistent](https://pypi.org/project/pyrsistent/)
    offer functional programming components.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.8 Creating a partial function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we look at functions such as reduce(), sorted(), min(), and max(), we
    see that we’ll often have some argument values that change very rarely, if at
    all. In a particular context, they’re essentially fixed. For example, we might
    find a need to write something like this in several places:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: Of the three argument values for reduce(), only one – the iterable to process
    – actually changes. The operator and the initial value argument values are essentially
    fixed at operator.mul and 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Clearly, we can define a whole new function for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: Python has a few ways to simplify this pattern so we don’t have to repeat the
    boilerplate def and return statements.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of this recipe is different from providing general default values.
    A partial function doesn’t provide a way for us to override the defaults. A partial
    function has specific values bound when it is defined. The idea is to be able
    to create many partial functions, each with specific argument values bound in
    advance. This is also sometimes called a closure, but applied to some of the parameters.
    See [Picking an order for parameters based on partial functions](ch007_split_001.xhtml#x1-1940006)
    in Chapter [3](ch007_split_000.xhtml#x1-1610003) for more examples of partial
    function definition.
  prefs: []
  type: TYPE_NORMAL
- en: 9.8.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some statistical modeling is done with standardized values, sometimes called
    z-scores. The idea is to standardize a raw measurement onto a value that can be
    easily compared to a normal distribution, and easily compared to related numbers
    that may be measured in different units.
  prefs: []
  type: TYPE_NORMAL
- en: 'The calculation is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![z = x−-μ- σ ](img/file69.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, x is a raw value, μ is the population mean, and σ is the population standard
    deviation. The value z will have a mean of 0 and a standard deviation of 1, providing
    a standardized value. We can use this value to spot outliers – values that are
    suspiciously far from the mean. We expect that (approximately) 99.7% of our z
    values will be between -3 and +3.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could define a function to compute standard scores, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'This standardize() function will compute a z-score from a raw score, x. When
    we use this function in a practical context, we’ll see that there are two kinds
    of argument values for the parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: The argument values for the mean and stdev parameters are essentially fixed.
    Once we’ve computed the population values, we’ll have to provide the same two
    values to the standardize() function over and over again.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The value for the x parameter will vary each time we evaluate the standardize()
    function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s work with a collection of data samples with two variables, x and y. These
    pairs are defined by the DataPair class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'As an example, we’ll compute a standardized value for the x attribute. This
    means computing the mean and standard deviation for the x values. Then, we’ll
    need to apply the mean and standard deviation values to standardize the data in
    our collection. The computation looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Providing the mean_x, and stdev_x values each time we evaluate the standardize()
    function can clutter an algorithm with details that aren’t deeply important.
  prefs: []
  type: TYPE_NORMAL
- en: We can use a partial function to simplify this use of standardize() with two
    fixed argument values and one that is left to vary.
  prefs: []
  type: TYPE_NORMAL
- en: 9.8.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To simplify using a function with a number of fixed argument values, we can
    create a partial function. This recipe will show two ways to create a partial
    functions as separate mini-recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the partial() function from the functools module to build a new function
    from the full standardize() function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a lambda object to supply argument values that don’t change
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using functools.partial()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Import the partial() function from the functools module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new function using partial(). We provide the base function, plus the
    positional arguments that need to be included. Any parameters that are not supplied
    when the partial is defined must be supplied when the partial is evaluated: [firstline=79,lastline=79,gobble=4][python]src/ch09/recipe˙08.py'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We’ve provided fixed values for the first two parameters, mean and stdev, of
    the standardize() function. We can now use the z() function with a single value,
    z(a), and it will evaluate the expression standardize(mean_x, stdev_x, a).
  prefs: []
  type: TYPE_NORMAL
- en: Creating a lambda object
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Define a lambda object that binds the fixed parameters: [firstline=105,lastline=105,gobble=8][python]src/ch09/recipe˙08.py'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Assign this lambda to a variable to create a callable object, z(): [firstline=105,lastline=105,gobble=4][python]src/ch09/recipe˙08.py'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This provides fixed values for the first two parameters, mean and stdev, of
    the standardize() function. We can now use the z() lambda object with a single
    value, z(a), and it will evaluate the expression standardize(mean_x, stdev_x, a).
  prefs: []
  type: TYPE_NORMAL
- en: 9.8.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Both techniques create a callable object – a function – named z() that has
    the values for mean_x and stdev_x already bound to the first two positional parameters.
    With either approach, we can now have processing that can look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[firstline=107,lastline=108,gobble=4][python]src/ch09/recipe˙08.py'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve applied the z() function to each set of data. Because z() is a partial
    function and has some parameters already applied, its use is simplified.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s one significant difference between the two techniques for creating
    the z() function:'
  prefs: []
  type: TYPE_NORMAL
- en: The partial() function binds the actual values of the parameters. Any subsequent
    change to the variables that were used will not change the definition of the partial
    function that’s created.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The lambda object binds the variable name, not the value. Any subsequent change
    to the variable’s value will change the way the lambda behaves.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can modify the lambda slightly to bind specific values instead of names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[firstline=131,lastline=131,gobble=4][python]src/ch09/recipe˙08.py'
  prefs: []
  type: TYPE_NORMAL
- en: This extracts the current values of mean_x and stdev_x to create default values
    for the lambda object’s parameters. The values of mean_x and stdev_x are now irrelevant
    to the proper operation of the lambda object, z().
  prefs: []
  type: TYPE_NORMAL
- en: 9.8.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can provide keyword argument values as well as positional argument values
    when creating a partial function. While this works nicely in general, there are
    a few cases where it doesn’t work.
  prefs: []
  type: TYPE_NORMAL
- en: We started this recipe looking at the reduce() function. Interestingly, this
    function is one example of functions that can’t be trivially turned into a partial
    function. The parameters aren’t in the ideal order for creating a partial and
    it doesn’t permit providing argument values by name.
  prefs: []
  type: TYPE_NORMAL
- en: 'It appears as though the reduce() function is defined like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'If this were the actual definition, we could do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: Practically, the preceding example raises a TypeError. It doesn’t work because
    the definition of reduce() does not take keyword argument values. Consequently,
    we can’t easily create partial functions that use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that we’re forced to use the following lambda technique:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: In Python, a function is an object. We’ve seen numerous ways that functions
    can be arguments to other functions. A function that accepts or returns another
    function as an argument is sometimes called a higher-order function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, functions can also return a function object as a result. This means
    that we can create a function like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: Here, we’ve defined a function over a sequence of type DataPair, which are (x,y)
    samples. We’ve computed the mean and standard deviation of the x attribute of
    each sample. We then created a partial function that can standardize scores based
    on the computed statistics. The result of this function is a function we can use
    for data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how this newly created function is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: The result of the prepare_z() function is a callable object that will standardize
    a score based on the computed mean and standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: 9.8.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: See [Picking an order for parameters based on partial functions](ch007_split_001.xhtml#x1-1940006)
    in Chapter [3](ch007_split_000.xhtml#x1-1610003) for more examples of partial
    function definition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9.9 Writing recursive generator functions with the yield from statement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many algorithms can be expressed neatly as recursions. In the [Designing recursive
    functions around Python’s stack limits](ch007_split_001.xhtml#x1-2090008) recipe,
    we looked at some recursive functions that could be optimized to reduce the number
    of function calls.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at some data structures, we see that they involve recursion. In
    particular, JSON documents (as well as XML and HTML documents) can have a recursive
    structure. A JSON document is a complex object that can contain other complex
    objects within it.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, there are advantages to using generators for processing these
    kinds of structures. In this recipe, we’ll look at ways to handle recursive data
    structures with generator functions.
  prefs: []
  type: TYPE_NORMAL
- en: 9.9.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we’ll look at a way to search for all matching values in a complex,
    recursive data structure. When working with complex JSON documents, they often
    contain dict-of-dict, dict-of-list, list-of-dict, and list-of-list structures.
    Of course, a JSON document is not limited to two levels; dict-of-dict can really
    mean dict-of-dict-of.... Similarly, dict-of-list could mean dict-of-list-of....
    The search algorithm must descend through the entire structure looking for a particular
    key or value.
  prefs: []
  type: TYPE_NORMAL
- en: 'A document with a complex structure might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'The value "value" can be found in three places:'
  prefs: []
  type: TYPE_NORMAL
- en: '["array", 0, "array_item_key1"]: This path starts with the top-level field
    named array, then visits item zero of a list, then a field named array_item_key1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '["field2"]: This path has just a single field name where the value is found.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '["object", "attribute1"]: This path starts with the top-level field named object,
    then the child, attribute1, of that field.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A find_value() function should yield all these paths when it searches the overall
    document for the target value. The core algorithm for this is a depth-first search.
    The output from this function must be a list of paths that identify the target
    value. Each path will be a sequence of field names or field names mixed with index
    positions.
  prefs: []
  type: TYPE_NORMAL
- en: 9.9.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll start with an overview of the depth-first algorithm to visit all of the
    nodes in a JSON document:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with a sketch of the function to process each of the alternative structures
    in the overall data structure. Here are the imports and some type hints:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is the sketch of the function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here’s a starting version to look at each key of a dictionary. This replaces
    the # apply find_value to each key in dnode line in the preceding code. Test this
    to be sure the recursion works properly: [firstline=58,lastline=60,gobble=8][python]src/ch09/recipe˙10.py'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Replace the inner for with a yield from statement: [firstline=98,lastline=100,gobble=8][python]src/ch09/recipe˙10.py'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This has to be done for the list case as well. Start an examination of each
    item in the list: [firstline=62,lastline=64,gobble=8][python]src/ch09/recipe˙10.py'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Replace the inner for with a yield from statement: [firstline=102,lastline=104,gobble=8][python]src/ch09/recipe˙10.py'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The complete depth-first find_value() search function, when complete, will
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'When we use the find_value() function, it looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: The resulting list has three items. Each of these is a list of keys that form
    a path to an item with the target value of "value".
  prefs: []
  type: TYPE_NORMAL
- en: 9.9.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For background, see the [Writing generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)
    recipe in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The yield from statement is shorthand for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[firstline=135,lastline=136,gobble=8][python]src/ch09/recipe˙10.py'
  prefs: []
  type: TYPE_NORMAL
- en: The yield from statement lets us write a succinct recursive algorithm that will
    behave as an iterator and properly yield multiple values. It saves the overhead
    of a boilerplate for statement.
  prefs: []
  type: TYPE_NORMAL
- en: This can also be used in contexts that don’t involve a recursive function. It’s
    entirely sensible to use a yield from statement anywhere that an iterable result
    is involved. It’s a handy simplification for recursive functions because it preserves
    a clearly recursive structure.
  prefs: []
  type: TYPE_NORMAL
- en: 9.9.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another common style of definition assembles a list of items using append operations.
    We can rewrite this into an iterator and avoid the overhead of building and mutating
    a list object.
  prefs: []
  type: TYPE_NORMAL
- en: 'When factoring a number, we can define the set of prime factors of a number,
    x, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ ( |{ F(x) = x if x is prime |( x √-- n∪ F (n) if x ≡ 0 mod n and 2 ≤ n ≤
    x ](img/file70.png)'
  prefs: []
  type: TYPE_IMG
- en: If the value, x, is prime, it has only itself in the set of prime factors. Otherwise,
    there must be some prime number, n, which is the least factor of x. We can assemble
    a set of factors starting with this number n and then append all factors of ![xn](img/file71.png).
    To be sure that only prime factors are found, n must be prime. If we search ascending
    values of n, starting from 2, we’ll find prime factors before finding composite
    factors.
  prefs: []
  type: TYPE_NORMAL
- en: 'An eager approach builds a complete list of factors. A lazy approach be be
    a generator of factors for a consumer. Here’s an eager list-building function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: This factor_list() function will build a list object. If a factor, n, is found,
    it will start a list with that factor. It will then extend the list with the factors
    built from the value of x // n. If there are no factors of x, then the value is
    prime, and this returns a list with only the value of x.
  prefs: []
  type: TYPE_NORMAL
- en: (This has an inefficiency stemming from the way this searches for composite
    numbers as well as prime numbers. For example, after testing 2 and 3, this will
    also test 4 and 6, even though they’re composite and all of their factors have
    already been tested. The example is centered on list-building, not efficient factoring
    of numbers.)
  prefs: []
  type: TYPE_NORMAL
- en: 'We can rewrite this as an iterator by replacing the recursive calls with yield from
    statements. The function will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: When a factor is found, the function will yield the factor, n, followed by all
    other factors found via a recursive call to factor_iter(). If no factors are found,
    the function will yield the prime number, x, and nothing more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using an iterator allows the client of this function to build any kind of collection
    from the factors. Instead of being limited to always creating a list object, we
    can create a multiset using the collections.Counter class. It would look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows us that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![384 = 27 × 3 ](img/file72.png)'
  prefs: []
  type: TYPE_IMG
- en: In some cases, this kind of multiset can be easier to work with than a simple
    list of factors.
  prefs: []
  type: TYPE_NORMAL
- en: What’s important is that the multiset was created directly from the factor_iter()
    iterator without creating any intermediate list objects. This kind of optimization
    lets us build complex algorithms that aren’t forced to consume large volumes of
    memory.
  prefs: []
  type: TYPE_NORMAL
- en: 9.9.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [Designing recursive functions around Python’s stack limits](ch007_split_001.xhtml#x1-2090008)
    recipe, earlier in this chapter, we covered the core design patterns for recursive
    functions. This recipe provides an alternative way to create the results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For background, see the [Writing generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)
    recipe in this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Python Discord workspace to discuss and find out more about the book:
    [https://packt.link/dHrHU](https://packt.link/dHrHU)'
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file1.png)'
  prefs: []
  type: TYPE_IMG
