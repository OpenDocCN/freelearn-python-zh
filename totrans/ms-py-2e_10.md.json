["```py\ndef square(n: int) -> int:\n    '''\n    Returns the input number, squared\n    >>> square(0)\n    0\n    >>> square(1)\n    1\n    >>> square(2)\n    4\n    >>> square(3)\n    9\n    >>> square()\n    Traceback (most recent call last):\n    ...\n    TypeError: square() missing 1 required positional argument: 'n'\n    >>> square('x')\n    Traceback (most recent call last):\n    ...\n    TypeError: can't multiply sequence by non-int of type 'str'\n    Args:\n        n (int): The number to square\n\n    Returns:\n        int: The squared result\n    '''\n    return n * n\n\nif __name__ == '__main__':\n    import doctest\n    doctest.testmod() \n```", "```py\n$ python3 T_00_simple_doctest.py -v\nTrying:\n    square(0)\nExpecting:\n    0\nok\nTrying:\n    square(1)\nExpecting:\n    1\nok\nTrying:\n    square(2)\nExpecting:\n    4\nok\nTrying:\n    square(3)\nExpecting:\n    9\nok\nTrying:\n    square()\nExpecting:\n    Traceback (most recent call last):\n    ...\n    TypeError: square() missing 1 required positional argument: 'n'\nok\nTrying:\n    square('x')\nExpecting:\n    Traceback (most recent call last):\n    ...\n    TypeError: can't multiply sequence by non-int of type 'str'\nok\n1 items had no tests:\n    __main__\n1 items passed all tests:\n   6 tests in __main__.square\n6 tests in 2 items.\n6 passed and 0 failed.\nTest passed. \n```", "```py\ndef square(n: int) -> int:\n    '''\n    >>> square('x')\n    Traceback (most recent call last):\n    ...\n    TypeError: unsupported operand type(s) for ** or pow(): ...\n    '''\n    return n ** 2\n\nif __name__ == '__main__':\n    import doctest\n    doctest.testmod(optionflags=doctest.ELLIPSIS) \n```", "```py\n$ python3\n>>> from square import square\n\n>>> square(5)\n25\n>>> square()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: square() missing 1 required positional argument: 'n' \n```", "```py\ndef square(n: int) -> int:\n    '''\n    Returns the input number, squared\n    >>> square(2)\n    4\n    Args:\n        n (int): The number to square\n    Returns:\n        int: The squared result\n    '''\n    return n * n\n\nif __name__ == '__main__':\n    import doctest\n    doctest.testmod() \n```", "```py\nsquare module\n=============\n\n.. automodule:: square\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\nExamples:\n\n.. testsetup::\n\n    from square import square\n\n.. doctest::\n    # pytest does not recognize testsetup\n    >>> from square import square\n\n    >>> square(100)\n    10000\n    >>> square(0)\n    0\n    >>> square(1)\n    1\n    >>> square(3)\n    9\n    >>> square()\n    Traceback (most recent call last):\n    ...\n    TypeError: square() missing 1 required positional argument: 'n'\n\n    >>> square('x')\n    Traceback (most recent call last):\n    ...\n    TypeError: can't multiply sequence by non-int of type 'str' \n```", "```py\n$ make doctest\nRunning Sphinx v3.2.1\nloading pickled environment... done\nbuilding [mo]: targets for 0 po files that are out of date\nbuilding [doctest]: targets for 2 source files that are out of date\nupdating environment: 0 added, 0 changed, 0 removed\nlooking for now-outdated files... none found\nrunning tests...\n\nDocument: square\n----------------\n1 items passed all tests:\n   8 tests in default\n8 tests in 1 items.\n8 passed and 0 failed.\nTest passed.\n\nDoctest summary\n===============\n    8 tests\n    0 failures in tests\n    0 failures in setup code\n    0 failures in cleanup code\nbuild succeeded.\n\nTesting of doctests in the sources finished, look at the results in _build/doctest/output.txt. \n```", "```py\ndoctest_optionflags = ELLIPSIS NORMALIZE_WHITESPACE \n```", "```py\n'''\n>>> False\n0\n>>> True\n1\n'''\nif __name__ == '__main__':\n    import doctest\n    doctest.testmod()\n    doctest.testmod(optionflags=doctest.DONT_ACCEPT_TRUE_FOR_1) \n```", "```py\n$ python3 T_03_doctest_true_for_1_flag.py -v\nTrying:\n    False\nExpecting:\n    0\nok\nTrying:\n    True\nExpecting:\n    1\nok\n1 items passed all tests:\n   2 tests in __main__\n2 tests in 1 items.\n2 passed and 0 failed.\nTest passed.\nTrying:\n    False\nExpecting:\n    0\n**********************************************************************\nFile \"T_03_doctest_true_for_1_flag.py\", line 2, in __main__\nFailed example:\n    False\nExpected:\n    0\nGot:\n    False\nTrying:\n    True\nExpecting:\n    1\n**********************************************************************\nFile \"T_03_doctest_true_for_1_flag.py\", line 4, in __main__\nFailed example:\n    True\nExpected:\n    1\nGot:\n    True\n**********************************************************************\n1 items had failures:\n   2 of   2 in __main__\n2 tests in 1 items.\n0 passed and 2 failed.\n***Test Failed*** 2 failures. \n```", "```py\n>>> [list(range(5)) for i in range(3)]\n[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]] \n```", "```py\n>>> # doctest: +NORMALIZE_WHITESPACE\n... [list(range(5)) for i in range(3)]\n[[0, 1, 2, 3, 4],\n [0, 1, 2, 3, 4],\n [0, 1, 2, 3, 4]] \n```", "```py\n>>> {10: 'a', 20: 'b'}  # doctest: +ELLIPSIS\n{...}\n>>> [True, 1, 'a']  # doctest: +ELLIPSIS\n[...]\n>>> True,  # doctest: +ELLIPSIS\n(...)\n>>> [1, 2, 3, 4]  # doctest: +ELLIPSIS\n[1, ..., 4]\n>>> [1, 0, 0, 0, 0, 0, 4]  # doctest: +ELLIPSIS\n[1, ..., 4] \n```", "```py\n>>> class Spam(object):\n...     pass\n\n>>> Spam()  # doctest: +ELLIPSIS\n<__main__.Spam object at 0x...> \n```", "```py\nFailed example:\n    Spam()\nExpected:\n    <__main__.Spam object at 0x...>\nGot:\n    <__main__.Spam object at 0x10d9ad160> \n```", "```py\n>>> 1./7.\n0.14285714285714285\n\n>>> import time\n\n>>> time.time() - time.time()\n-9.5367431640625e-07 \n```", "```py\n>>> import pprint\n\n>>> data = dict.fromkeys('spam')\n>>> pprint.pprint(data)\n{'a': None, 'm': None, 'p': None, 's': None} \n```", "```py\n>>> data = dict.fromkeys('spam')\n>>> sorted(data.items())\n[('a', None), ('m', None), ('p', None), ('s', None)] \n```", "```py\n>>> data = dict.fromkeys('spam')\n>>> data == {'a': None, 'm': None, 'p': None, 's': None}\nTrue \n```", "```py\nFailed example:\n    data == {'a': None, 'm': None, 'p': None}\nExpected:\n    True\nGot:\n    False \n```", "```py\nFailed example:\n    sorted(data.items())\nExpected:\n    [('a', None), ('m', None), ('p', None)]\nGot:\n    [('a', None), ('m', None), ('p', None), ('s', None)]\n\nFailed example:\n    pprint.pprint(data)\nExpected:\n    {'a': None, 'm': None, 'p': None}\nGot:\n    {'a': None, 'm': None, 'p': None, 's': None} \n```", "```py\n>>> 1/3  # doctest: +ELLIPSIS\n0.333...\n>>> '%.3f' % (1/3)\n'0.333'\n>>> '{:.3f}'.format(1/3)\n'0.333'\n>>> round(1/3, 3)\n0.333\n>>> 0.333 < 1/3 < 0.334\nTrue \n```", "```py\n>>> import time\n\n>>> a = time.time()\n>>> b = time.time()\n>>> (b - a) < 0.01\nTrue \n```", "```py\n>>> import datetime\n\n>>> a = datetime.datetime.now()\n>>> b = datetime.datetime.now()\n>>> str(b - a)  # doctest: +ELLIPSIS\n'0:00:00.000... \n```", "```py\n$ pip3 install pytest pytest-flake8 \n```", "```py\n$ py.test --doctest-modules -v square.py\n===================== test session starts ======================\ncollected 2 items\n\nsquare.py::square.square PASSED [100%]\n\n====================== 1 passed in 0.03s ======================= \n```", "```py\ndef cube(n: int) -> int:\n    '''\n    Returns the input number, cubed\n    Args:\n        n (int): The number to cube\n    Returns:\n        int: The cubed result\n    '''\n    return n ** 3 \n```", "```py\nimport cube\nimport unittest\n\nclass TestCube(unittest.TestCase):\n    def test_0(self):\n        self.assertEqual(cube.cube(0), 0)\n\n    def test_1(self):\n        self.assertEqual(cube.cube(1), 1)\n\n    def test_2(self):\n        self.assertEqual(cube.cube(2), 8)\n\n    def test_3(self):\n        self.assertEqual(cube.cube(3), 27)\n\n    def test_no_arguments(self):\n        with self.assertRaises(TypeError):\n            cube.cube()\n\n    def test_exception_str(self):\n        with self.assertRaises(TypeError):\n            cube.cube('x')\n\nif __name__ == '__main__':\n    unittest.main() \n```", "```py\n$ python3 T_09_test_cube.py -v\ntest_0 (__main__.TestCube) ... ok\ntest_1 (__main__.TestCube) ... ok\ntest_2 (__main__.TestCube) ... ok\ntest_3 (__main__.TestCube) ... ok\ntest_exception_str (__main__.TestCube) ... ok\ntest_no_arguments (__main__.TestCube) ... ok\n\n----------------------------------------------------------------\nRan 6 tests in 0.000s\n\nOK \n```", "```py\n$ python3 -m unittest -v T_09_test_cube.py\n... \n```", "```py\n$ py.test -v T_09_test_cube.py\n===================== test session starts ======================\n\ncollected 7 items\n\nT_09_test_cube.py::FLAKE8 SKIPPED                        [ 14%]\nT_09_test_cube.py::TestCube::test_0 PASSED               [ 28%]\nT_09_test_cube.py::TestCube::test_1 PASSED               [ 42%]\nT_09_test_cube.py::TestCube::test_2 PASSED               [ 57%]\nT_09_test_cube.py::TestCube::test_3 PASSED               [ 71%]\nT_09_test_cube.py::TestCube::test_exception_str PASSED   [ 85%]\nT_09_test_cube.py::TestCube::test_no_arguments PASSED    [100%]\n\n================= 6 passed, 1 skipped in 0.08s ================= \n```", "```py\n$ pip3 install nose \n```", "```py\n$ nosetests -v T_09_test_cube.py\ntest_0 (T_09_test_cube.TestCube) ... ok\ntest_1 (T_09_test_cube.TestCube) ... ok\ntest_2 (T_09_test_cube.TestCube) ... ok\ntest_3 (T_09_test_cube.TestCube) ... ok\ntest_exception_str (T_09_test_cube.TestCube) ... ok\ntest_no_arguments (T_09_test_cube.TestCube) ... ok\n\n-------------------------------------------------------------\nRan 6 tests in 0.001s\n\nOK \n```", "```py\n$ python3 T_09_test_cube.py\n..FF..\n================================================================\nFAIL: test_2 (__main__.TestCube)\n----------------------------------------------------------------\nTraceback (most recent call last):\n  File \" T_09_test_cube.py\", line 14, in test_2\n    self.assertEqual(cube.cube(2), 8)\nAssertionError: 4 != 8\n\n================================================================\nFAIL: test_3 (__main__.TestCube)\n----------------------------------------------------------------\nTraceback (most recent call last):\n  File \" T_09_test_cube.py\", line 17, in test_3\n    self.assertEqual(cube.cube(3), 27)\nAssertionError: 9 != 27\n\n----------------------------------------------------------------\nRan 6 tests in 0.001s\n\nFAILED (failures=2) \n```", "```py\n$ py.test T_09_test_cube.py\n===================== test session starts ======================\ncollected 7 items\n\nT_09_test_cube.py s..FF..                                [100%]\n\n=========================== FAILURES ===========================\n_______________________ TestCube.test_2 ________________________\n\nself = <T_09_test_cube.TestCube testMethod=test_2>\n\n    def test_2(self):\n>       self.assertEqual(cube.cube(2), 8)\nE       AssertionError: 4 != 8\n\nT_09_test_cube.py:14: AssertionError\n_______________________ TestCube.test_3 ________________________\n\nself = <T_09_test_cube.TestCube testMeth\nod=test_3>\n\n    def test_3(self):\n>       self.assertEqual(cube.cube(3), 27)\nE       AssertionError: 9 != 27\n\nT_09_test_cube.py:17: AssertionError\n=================== short test summary info ====================\nFAILED T_09_test_cube.py::TestCube::test_2 - AssertionError: 4..\nFAILED T_09_test_cube.py::TestCube::test_3 - AssertionError: 9..\n============ 2 failed, 4 passed, 1 skipped in 0.17s ============ \n```", "```py\nimport unittest\nimport cube\n\nn = 2\nexpected = 8\n\n# Regular unit test\nclass TestCube(unittest.TestCase):\n    def test_2(self):\n        self.assertEqual(cube.cube(n), expected)\n\n    def test_no_arguments(self):\n        with self.assertRaises(TypeError):\n            cube.cube()\n\n# py.test class\nclass TestPyCube:\n    def test_2(self):\n        assert cube.cube(n) == expected\n\n# py.test functions\ndef test_2():\n    assert cube.cube(n) == expected \n```", "```py\n$ py.test T_10_simplifying_assertions.py\n...\n=========================== FAILURES ===========================\n_______________________ TestCube.test_2 ________________________\n\nself = <TestCube testMethod=test_2>\n\n    def test_2(self):\n>       self.assertEqual(cube.cube(n), expected)\nE       AssertionError: 4 != 8\n\nT_10_simplifying_assertions.py:12: AssertionError\n______________________ TestPyCube.test_2 _______________________\n\nself = <TestPyCube object at 0x...>\n\n    def test_2(self):\n>       assert cube.cube(n) == expected\nE       assert 4 == 8\nE        +  where 4 = <function cube at 0x...>(2)\nE        +    where <function cube at 0x...> = cube.cube\n\nT_10_simplifying_assertions.py:23: AssertionError\n____________________________ test_2 ____________________________\n\n    def test_2():\n>       assert cube.cube(n) == expected\nE       assert 4 == 8\nE        +  where 4 = <function cube at 0x...>(2)\nE        +    where <function cube at 0x...> = cube.cube\n\nT_10_simplifying_assertions.py:28: AssertionError\n=================== short test summary info ====================\nFAILED T_10_simplifying_assertions.py::TestCube::test_2 - Ass...\nFAILED T_10_simplifying_assertions.py::TestPyCube::test_2 - a...\nFAILED T_10_simplifying_assertions.py::test_2 - assert 4 == 8\n============ 3 failed, 1 passed, 1 skipped in 0.15s ============ \n```", "```py\nclass User:\n    def __init__(self, name):\n        self.name = name\n\n    def __eq__(self, other):\n        return self.name == other.name\n\ndef test_user_equal():\n    a = User('Rick')\n    b = User('Guido')\n\n    assert a == b \n```", "```py\n_______________________ test_user_equal ________________________\n\n    def test_user_equal():\n        a = User('Rick')\n        b = User('Guido')\n\n>       assert a == b\nE       assert <T_11_representing_assertions.User object at 0x...> == <T_11_representing_assertions.User object at 0x...>\n\nT_11_representing_assertions.py:13: AssertionError\n=================== short test summary info ====================\nFAILED T_11_representing_assertions.py::test_user_equal - asse...\n================= 1 failed, 1 skipped in 0.17s ================= \n```", "```py\nfrom T_12_assert_representation import User\n\ndef is_user(value):\n    return isinstance(value, User)\n\ndef pytest_assertrepr_compare(config, op, left, right):\n    if is_user(left) and is_user(right) and op == '==':\n        return [\n            'Comparing User instances:',\n            f'    name: {left.name} != {right.name}',\n        ] \n```", "```py\n def test_user_equal():\n        a = User('Rick')\n        b = User('Guido')\n\n>       assert a == b\nE       assert Comparing User instances:\nE             name: Rick != Guido\n\nT_12_assert_representation.py:13: AssertionError \n```", "```py\nimport cube\nimport pytest\n\ncubes = (\n    (0, 0),\n    (1, 1),\n    (2, 8),\n    (3, 27),\n)\n\n@pytest.mark.parametrize('n,expected', cubes)\ndef test_cube(n, expected):\n    assert cube.cube(n) == expected \n```", "```py\n=========================== FAILURES ===========================\n________________________ test_cube[2-8] ________________________\n\nn = 2, expected = 8\n    @pytest.mark.parametrize('n,expected', cubes)\n    def test_cube(n, expected):\n>       assert cube.cube(n) == expected\nE       assert 4 == 8\nE        +  where 4 = <function cube at 0x...>(2)\nE        +    where <function cube at 0x...> = cube.cube\n\nT_13_parameterizing_tests.py:15: AssertionError\n_______________________ test_cube[3-27] ________________________\n\nn = 3, expected = 27\n\n    @pytest.mark.parametrize('n,expected', cubes)\n    def test_cube(n, expected):\n>       assert cube.cube(n) == expected\nE       assert 9 == 27\nE        +  where 9 = <function cube at 0x...>(3)\nE        +    where <function cube at 0x...> = cube.cube\n\nT_13_parameterizing_tests.py:15: AssertionError\n=================== short test summary info ====================\nFAILED T_13_parameterizing_tests.py::test_cube[2-8] - assert ...\nFAILED T_13_parameterizing_tests.py::test_cube[3-27] - assert...\n============ 2 failed, 2 passed, 1 skipped in 0.16s ============ \n```", "```py\nimport pytest\n\n@pytest.fixture\ndef name():\n    return 'Rick'\n\ndef test_something(name):\n    assert name == 'Rick' \n```", "```py\n$ py.test --quiet --fixtures\n...\ncapsys\n    enables capturing of writes to sys.stdout/sys.stderr and\n    makes captured output available via ''capsys.readouterr()''\n    method calls which return a ''(out, err)'' tuple.\n...\nmonkeypatch\n    The returned ''monkeypatch'' funcarg provides these helper \n    methods to modify objects, dictionaries or os.environ::\n\n    monkeypatch.setattr(obj, name, value, raising=True)\n    monkeypatch.delattr(obj, name, raising=True)\n    monkeypatch.setitem(mapping, name, value)\n    monkeypatch.delitem(obj, name, raising=True)\n    monkeypatch.setenv(name, value, prepend=False)\n    monkeypatch.delenv(name, value, raising=True)\n    monkeypatch.syspath_prepend(path)\n    monkeypatch.chdir(path)\n    All modifications will be undone after the requesting\n    test function has finished. The ''raising''\n    parameter determines if a KeyError or AttributeError\n    will be raised if the set/deletion operation has no target.\n...\ntmpdir\n    return a temporary directory path object which is unique to\n    each test function invocation, created as a sub directory of\n    the base temporary directory. The returned object is a\n    'py.path.local'_ path object. \n```", "```py\n def test_cache(cache):\n    counter = cache.get('counter', 0) + 1\n    assert counter\n    cache.set('counter', counter) \n```", "```py\nimport pytest\n\n@pytest.yield_fixture\ndef some_yield_fixture():\n    with open(__file__ + '.txt', 'w') as fh:\n        # Before the function\n        yield fh\n        # After the function\n\n@pytest.fixture\ndef some_regular_fixture():\n    # Do something here\n    return 'some_value_to_pass_as_parameter'\n\ndef some_test(some_yield_fixture, some_regular_fixture):\n    some_yield_fixture.write(some_regular_fixture) \n```", "```py\nimport pytest\nimport sqlite3\n\n@pytest.fixture(params=[':memory:'])\ndef connection(request):\n    return sqlite3.connect(request.param)\n\n@pytest.yield_fixture\ndef transaction(connection):\n    with connection:\n        yield connection\n\ndef test_insert(transaction):\n    transaction.execute('create table test (id integer)')\n    transaction.execute('insert into test values (1), (2), (3)') \n```", "```py\nimport os\nimport sys\nimport logging\n\ndef test_print():\n    print('Printing to stdout')\n    print('Printing to stderr', file=sys.stderr)\n    logging.debug('Printing to debug')\n    logging.info('Printing to info')\n    logging.warning('Printing to warning')\n    logging.error('Printing to error')\n    # We don't want to display os.environ so hack around it\n    fail = 'FAIL' in os.environ\n    assert not fail \n```", "```py\n$ py.test -v T_15_print_statements_and_logging.py \nT_15_print_statements_and_logging.py::test_print PASSED  [100%]\n\n================= 1 passed, 1 skipped in 0.06s ================= \n```", "```py\n$ FAIL=true py.test -v T_15_print_statements_and_logging.py \n=========================== FAILURES ===========================\n__________________________ test_print __________________________\n\n    def test_print():\n        print('Printing to stdout')\n        print('Printing to stderr', file=sys.stderr)\n        logging.debug('Printing to debug')\n        logging.info('Printing to info')\n        logging.warning('Printing to warning')\n        logging.error('Printing to error')\n        # We don't want to display os.environ so hack around it\n        fail = 'FAIL' in os.environ\n>       assert not fail\nE       assert not True\n\nT_15_print_statements_and_logging.py:15: AssertionError\n--------------------- Captured stdout call ---------------------\nPrinting to stdout\n--------------------- Captured stderr call ---------------------\nPrinting to stderr\n---------------------- Captured log call -----------------------\nWARNING  root:T_15_print_statements_and_logging.py:11 Printing t\no warning\nERROR    root:T_15_print_statements_and_logging.py:12 Printing t\no error\n=================== short test summary info ====================\nFAILED T_15_print_statements_and_logging.py::test_print - ass...\n================= 1 failed, 1 skipped in 0.16s ================= \n```", "```py\n$ pip3 install pytest-cov \n```", "```py\n[report]\n# The test coverage you require. Keeping to 100% is not easily\n# possible for all projects but it's a good default for new projects.\nfail_under = 100\n\n# These functions are generally only needed for debugging and/or\n# extra safety so we want to ignore them in the coverage\n# requirements\nexclude_lines =\n    # Make it possible to ignore blocks of code\n    pragma: no cover\n\n    # Generally only debug code uses this\n    def __repr__\n\n    # If a debug setting is set, skip testing\n    if self\\.debug:\n    if settings.DEBUG\n\n    # Don't worry about safety checks and expected errors\n    raise AssertionError\n    raise NotImplementedError\n\n    # Do not complain about code that will never run\n    if 0:\n    if __name__ == .__main__.:\n    @abc.abstractmethod\n\n[run]\n# Make sure we require that all branches of the code are covered. \n# So both the if and the else\nbranch = True\n\n# No need to require coverage of testing code\nomit =\n    test_*.py \n```", "```py\n def cube_root(n: int) -> int:\n    '''\n    Returns the cube root of the input number\n\n    Args:\n        n (int): The number to cube root\n\n    Returns:\n        int: The cube root result\n    '''\n    if n >= 0:\n        return n ** (1 / 3)\n    else:\n        raise ValueError('A number larger than 0 was expected') \n```", "```py\nimport pytest\nimport cube_root\n\ncubes = (\n    (0, 0),\n    (1, 1),\n    (8, 2),\n    (27, 3),\n)\n\n@pytest.mark.parametrize('n,expected', cubes)\ndef test_cube_root(n, expected):\n    assert cube_root.cube_root(n) == expected \n```", "```py\n$ py.test --cov-report=html --cov-report=term-missing \\\n  --cov=cube_root --cov-branch T_16_test_cube_root.py\nName           Stmts   Miss Branch BrPart  Cover   Missing\n----------------------------------------------------------\ncube_root.py       4      1      2      1    67%   14\nCoverage HTML written to dir htmlcov\n================= 4 passed, 1 skipped in 0.12s ================= \n```", "```py\nfor i in range(10):  # pragma: no branch \n```", "```py\n# Previous test cases omitted\n...\ndef test_cube_root_below_zero():\n    with pytest.raises(ValueError):\n        cube_root.cube_root(-1) \n```", "```py\n$ py.test --cov-report=html --cov-report=term-missing \\\n  --cov=cube_root --cov-branch T_17_test_cube_root_subzero.py\nName           Stmts   Miss Branch BrPart  Cover   Missing\n----------------------------------------------------------\ncube_root.py       4      0      2      0   100%\nCoverage HTML written to dir htmlcov\n================= 5 passed, 1 skipped in 0.12s ================= \n```", "```py\n$ pip3 install pytest-flake8 \n```", "```py\nimport os\ndef test(a,b):\n    return c \n```", "```py\n$ py.test --flake8 T_18_bad_code.py\n=========================== FAILURES ===========================\n____________ FLAKE8-check(ignoring W391 E402 F811) _____________\nT_18_bad_code.py:1:1: F401 'os' imported but unused\nT_18_bad_code.py:2:1: E302 expected 2 blank lines, found 0\nT_18_bad_code.py:2:11: E231 missing whitespace after ','\nT_18_bad_code.py:3:12: F821 undefined name 'c'\n\n---------------------- Captured log call -----------------------\nWARNING  flake8.options.manager:manager.py:207 option --max-complexity: please update from optparse string 'type=' to argparse callable 'type=' -- this will be an error in the future\nWARNING  flake8.checker:checker.py:119 The multiprocessing module is not available. Ignoring --jobs arguments. \n```", "```py\n$ pip3 install pytest-mypy \n```", "```py\n$ py.test --mypy cube_root.py\n=========================== FAILURES ===========================\n_________________________ cube_root.py _________________________\n12: error: Incompatible return value type (got \"float\", expected\n \"int\") \n```", "```py\n[pytest]\npython_files =\n    your_project_source/*.py\n    tests/*.py\n\naddopts =\n    --doctest-modules\n    --cov your_project_source\n    --cov-report term-missing\n    --cov-report html\n    --flake8\n    --mypy\n\n# W391 is the error about blank lines at the end of a file\nflake8-ignore =\n    *.py W391 \n```", "```py\nfrom unittest import mock\nimport random\n\n@mock.patch('random.random')\ndef test_random(mock_random):\n    # Specify our mock return value\n    mock_random.return_value = 0.1\n    # Test for the mock return value\n    assert random.random() == 0.1\n    assert mock_random.call_count == 1\n\ndef test_random_with():\n    with mock.patch('random.random') as mock_random:\n        mock_random.return_value = 0.1\n        assert random.random() == 0.1 \n```", "```py\nimport os\nfrom unittest import mock\n\ndef delete_file(filename):\n    while os.path.exists(filename):\n        os.unlink(filename)\n\n@mock.patch('os.path.exists', side_effect=(True, False, False))\n@mock.patch('os.unlink')\ndef test_delete_file(mock_exists, mock_unlink):\n    # First try:\n    delete_file('some non-existing file')\n\n    # Second try:\n    delete_file('some non-existing file') \n```", "```py\nimport os\n\ndef test_chdir_monkeypatch(monkeypatch):\n    monkeypatch.chdir('/')\n    assert os.getcwd() == '/'\n\ndef test_chdir():\n    original_directory = os.getcwd()\n    try:\n        os.chdir('/')\n        assert os.getcwd() == '/'\n    finally:\n        os.chdir(original_directory) \n```", "```py\n$ pip3 install --upgrade tox \n```", "```py\n$ tox-quickstart\nWelcome to the tox 3.20.1 quickstart utility.\nThis utility will ask you a few questions and then generate a simple configuration file to help get you started using tox.\nPlease enter values for the following settings (just press Enter to accept a default value, if one is given in brackets).\n\nWhat Python versions do you want to test against?\n            [1] py37\n            [2] py27, py37\n            [3] (All versions) py27, py35, py36, py37, pypy, jython\n            [4] Choose each one-by-one\n> Enter the number of your choice [3]: 1\nWhat command should be used to test your project? Examples:            \n            - pytest\n            - python -m unittest discover\n            - python setup.py test\n            - trial package.module\n> Type the command to run your tests [pytest]:\nWhat extra dependencies do your tests have?\ndefault dependencies are: ['pytest']\n> Comma-separated list of dependencies: pytest-flake8,pytest-mypy,pytest-cov\nFinished: ./tox.ini has been created. For information on this file, see https://tox.readthedocs.io/en/latest/config.html\nExecute 'tox' to test your project. \n```", "```py\n[tox]\nenvlist = py37\n\n[testenv]\ndeps =\n    pytest-flake8\n    pytest-mypy\n    pytest-cov\n    pytest\ncommands =\n    pytest \n```", "```py\nenvlist = py27, py3{7,8,9}, docs, coverage, flake8 \n```", "```py\n[testenv:custom_env]\nbasepython = {[py39]basepython} \n```", "```py\n{env:NAME_OF_ENV_VARIABLE} \n```", "```py\n{env:NAME_OF_ENV_VARIABLE:some default value} \n```", "```py\n[tox]\nenvlist = py3{8,9}\nskipsdist = True\n\n[testenv]\ndeps =\n    pytest\ncommands =\n    pytest test.py \n```", "```py\ndef test_dict_merge():\n    a = dict(a=123)\n    b = dict(b=456)\n    assert a | b \n```", "```py\n$ tox\npy38 installed: ...\npy38 run-test: commands[0] | pytest test.py\n===================== test session starts ======================\n=========================== FAILURES ===========================\n_______________________ test_dict_merge ________________________\n    def test_dict_merge():\n        a = dict(a=123)\n        b = dict(b=456)\n>       assert a | b\nE       TypeError: unsupported operand type(s) for |: 'dict' and 'dict'\n...\nERROR:   py38: commands failed\n  py39: commands succeeded \n```", "```py\nimport logging\n\nlogging.debug('debug')\nlogging.info('info')\nlogging.warning('warning')\nlogging.error('error')\nlogging.critical('critical') \n```", "```py\n$ python3 T_23_logging_basic.py\nWARNING:root:warning\nERROR:root:error\nCRITICAL:root:critical \n```", "```py\nimport logging\n\nlog_format = '%(levelname)-8s %(name)-12s %(message)s'\n\nlogging.basicConfig(\n    filename='debug.log',\n    format=log_format,\n    level=logging.DEBUG,\n)\n\nformatter = logging.Formatter(log_format)\nhandler = logging.StreamHandler()\nhandler.setLevel(logging.WARNING)\nhandler.setFormatter(formatter)\nlogging.getLogger().addHandler(handler) \n```", "```py\nlogging.debug('debug')\nlogging.info('info')\nsome_logger = logging.getLogger('some')\nsome_logger.warning('warning')\nsome_logger.error('error')\nother_logger = some_logger.getChild('other')\nother_logger.critical('critical') \n```", "```py\n$ python3 T_24_logging_basic_formatted.py\nWARNING  some         warning\nERROR    some         error\nCRITICAL some.other   critical \n```", "```py\nDEBUG    root         debug\nINFO     root         info\nWARNING  some         warning\nERROR    some         error\nCRITICAL some.other   critical \n```", "```py\nfrom logging import config\n\nconfig.dictConfig({\n    'version': 1,\n    'formatters': {\n        'standard': {\n            'format': '%(levelname)-8s %(name)-12s %(message)s',\n        },\n    },\n    'handlers': {\n        'file': {\n            'filename': 'debug.log',\n            'level': 'DEBUG',\n            'class': 'logging.FileHandler',\n            'formatter': 'standard',\n        },\n        'stream': {\n            'level': 'WARNING',\n            'class': 'logging.StreamHandler',\n            'formatter': 'standard',\n        },\n    },\n    'loggers': {\n        '': {\n            'handlers': ['file', 'stream'],\n            'level': 'DEBUG',\n        },\n    },\n}) \n```", "```py\n{\n    \"version\": 1,\n    \"formatters\": {\n        \"standard\": {\n            \"format\": \"%(levelname)-8s %(name)-12s %(message)s\"\n        }\n    },\n    \"handlers\": {\n        \"file\": {\n            \"filename\": \"debug.log\",\n            \"level\": \"DEBUG\",\n            \"class\": \"logging.FileHandler\",\n            \"formatter\": \"standard\"\n        },\n        \"stream\": {\n            \"level\": \"WARNING\",\n            \"class\": \"logging.StreamHandler\",\n            \"formatter\": \"standard\"\n        }\n    },\n    \"loggers\": {\n        \"\": {\n            \"handlers\": [\"file\", \"stream\"],\n            \"level\": \"DEBUG\"\n        }\n    }\n} \n```", "```py\nimport json\nfrom logging import config\n\nwith open('T_26_logging_json_config.json') as fh:\n    config.dictConfig(json.load(fh)) \n```", "```py\n[formatters]\nkeys=standard\n\n[handlers]\nkeys=file,stream\n\n[loggers]\nkeys=root\n\n[formatter_standard]\nformat=%(levelname)-8s %(name)-12s %(message)s\n\n[handler_file]\nlevel=DEBUG\nclass=FileHandler\nformatter=standard\nargs=('debug.log',)\n\n[handler_stream]\nlevel=WARNING\nclass=StreamHandler\nformatter=standard\nargs=(sys.stderr,)\n\n[logger_root]\nhandlers=file,stream\nlevel=DEBUG \n```", "```py\nfrom logging import config\n\nconfig.fileConfig('T_27_logging_ini_config.ini') \n```", "```py\ndef verify(config):\n    if config.pop('secret', None) != 'some secret':\n        raise RuntimeError('Access denied')\n    return config \n```", "```py\nimport sys\n\ndef receive():\n    import time\n    import logging\n    from logging import config\n\n    listener = config.listen()\n    listener.start()\n\n    try:\n        while True:\n            logging.debug('debug')\n            logging.info('info')\n            some_logger = logging.getLogger('some')\n            some_logger.warning('warning')\n            some_logger.error('error')\n            other_logger = some_logger.getChild('other')\n            other_logger.critical('critical')\n\n            time.sleep(5)\n\n    except KeyboardInterrupt:\n        # Stop listening and finish the listening thread\n        config.stopListening()\n        listener.join()\n\ndef send():\n    import os\n    import struct\n    import socket\n    from logging import config\n\n    ini_filename = os.path.splitext(__file__)[0] + '.ini'\n    with open(ini_filename, 'rb') as fh:\n        data = fh.read()\n\n    # Open the socket\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    # Connect to the server\n    sock.connect(('127.0.0.1',\n                  config.DEFAULT_LOGGING_CONFIG_PORT))\n    # Send the magic logging packet\n    sock.send(struct.pack('>L', len(data)))\n    # Send the config\n    sock.send(data)\n    # And close the connection again\n    sock.close()\n\nif __name__ == '__main__':\n    if sys.argv[-1] == 'send':\n        send()\n    elif sys.argv[-1] == 'receive':\n        receive()\n    else:\n        print(f'Usage: {sys.argv[0]} [send/receive]') \n```", "```py\n$ python3 T_28_logging_network_config.py receive\nWARNING:some:warning\nERROR:some:error\nCRITICAL:some.other:critical\n# The send command was run here\nWARNING  some         warning\nERROR    some         error\nCRITICAL some.other   critical \n```", "```py\n$ python3 T_28_logging_network_config.py send \n```", "```py\nDEBUG    root         debug\nINFO     root         info\nWARNING  some         warning\nERROR    some         error\nCRITICAL some.other   critical \n```", "```py\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass MyClass(object):\n    def __init__(self, count):\n        self.logger = logger.getChild(self.__class__.__name__) \n```", "```py\nimport logging\n\nlogger = logging.getLogger('main_module.sub_module')\nlogger.addHandler(logging.FileHandler('sub_module.log')) \n```", "```py\nimport logging\n\nlogger = logging.getLogger('main_module.sub_module')\nlogger.setLevel(logging.DEBUG) \n```", "```py\nimport logging\n\nlogger = logging.getLogger()\nexception = 'Oops...'\nlogger.error('Some horrible error: %r', exception) \n```", "```py\nimport logging\n\nlogger = logging.getLogger()\nlogger.error('simple error', extra=dict(some_variable='my value')) \n```", "```py\nimport logging\n\nlogging.basicConfig(format='%(some_variable)s: %(message)s')\nlogger = logging.getLogger()\nlogger.error('the message', extra=dict(some_variable='my value')) \n```", "```py\n$ python3 T_30_formatting.py\nsimple error\nmy value: the message \n```", "```py\nimport logging\n\nlogging.basicConfig()\nlogger = logging.getLogger()\n\ntry:\n    raise RuntimeError('some runtime error')\nexcept Exception as exception:\n    logger.exception('Got an exception: %s', exception)\n\nlogger.error('And an error') \n```", "```py\n$ python3 T_31_exception.py\nERROR:root:Got an exception: some runtime error\nTraceback (most recent call last):\n  File \"T_31_exception.py\", line 7, in <module>\n    raise RuntimeError('some runtime error')\nRuntimeError: some runtime error\nERROR:root:And an error \n```", "```py\nimport logging\n\nformatter = logging.Formatter('{levelname} {message}', style='{')\nhandler = logging.StreamHandler()\nhandler.setFormatter(formatter)\n\nlogging.error('formatted message?') \n```", "```py\n$ python3 T_32_str_format.py\nERROR:root:formatted message? \n```", "```py\nimport logging\n\nclass FormattingMessage:\n    def __init__(self, message, kwargs):\n        self.message = message\n        self.kwargs = kwargs\n\n    def __str__(self):\n        return self.message.format(**self.kwargs)\n\nclass FormattingAdapter(logging.LoggerAdapter):\n    def process(self, msg, kwargs):\n        msg, kwargs = super().process(msg, kwargs)\n        return FormattingMessage(msg, kwargs), dict()\n\nlogger = FormattingAdapter(logging.root, dict())\nlogger.error('Hi {name}', name='Rick') \n```", "```py\n$ python3 T_33_logging_format.py\nHi Rick \n```", "```py\nimport logging\n\na = logging.getLogger('a')\nab = logging.getLogger('a.b')\n\nab.error('before setting level')\na.setLevel(logging.CRITICAL)\nab.error('after setting level') \n```", "```py\n$ python3 T_34_logging_pitfalls.py\nbefore setting level \n```", "```py\nimport logging\n\na = logging.getLogger('a')\nab = logging.getLogger('a.b')\n\nab.setLevel(logging.ERROR)\nab.error('before setting level')\na.setLevel(logging.CRITICAL)\nab.error('after setting level') \n```", "```py\n$ python3 T_35_logging_propagate_pitfalls.py\nbefore setting level\nafter setting level \n```", "```py\nimport logging\n\ndef get_handlers(logger):\n    handlers = []\n    # Walk through the loggers and their parents recursively to\n    # fetch the handlers\n    while logger:\n        handlers += logger.handlers\n\n        if logger.propagate:\n            logger = logger.parent\n        else:\n            break\n\n    # Python has a lastResort handler in case no handlers are\n    # defined\n    if not handlers and logging.lastResort:\n        handlers.append(logging.lastResort)\n\n    return handlers\n\ndef debug_loggers():\n    logger: logging.Logger\n    for name, logger in logging.root.manager.loggerDict.items():\n        # Placeholders are loggers without settings\n        if isinstance(logger, logging.PlaceHolder):\n            print('skipping', name)\n            continue\n\n        level = logging.getLevelName(logger.getEffectiveLevel())\n        handlers = get_handlers(logger)\n        print(f'{name}@{level}: {handlers}')\n\nif __name__ == '__main__':\n    a = logging.getLogger('a')\n    a.setLevel(logging.INFO)\n\n    handler = logging.StreamHandler()\n    handler.setLevel(logging.INFO)\n    ab = logging.getLogger('a.b')\n    ab.setLevel(logging.DEBUG)\n    ab.addHandler(handler)\n\n    debug_loggers() \n```", "```py\n$ python3 T_36_logger_debugging.py\na@INFO: [<_StderrHandler <stderr> (WARNING)>]\na.b@DEBUG: [<StreamHandler <stderr> (INFO)>] \n```"]