<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Microservice API Gateways</h1>
                </header>
            
            <article>
                
<p>As microservices are typically fine-grained, any large-scale application has to consist of many microservices. With hundreds of microservices in an IT environment, the IT complexity is bound to escalate. The operational, monitoring, measurement, and management complexities of microservices are definitely greater, and hence the idea of leveraging API gateways originated and has flourished for not only mitigating rising complexity, but also for abstracting away all kinds of common capabilities from microservice source code. In this best practices chapter, we explain the role and responsibility of API gateways in the microservice era. Further on, you can also see how the reliability of microservice applications is ensured through the smart leveraging of an API gateway infrastructure.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>This chapter mainly talks about the crucial contributions of API gateway solutions to empower microservices to be the right and rewarding ingredient for producing enterprise-scale, mission-critical, cloud-hosted, service-oriented, event-driven, innovation-filled, process-aware, production-grade, and business-centric applications. We discuss popular API gateway solutions in this chapter. We also implement an aggregation service through the API gateway. The source code for the microservices (order service, customer service, and aggregation service) are deposited in the book's GitHub. The GitHub link for the book is <a href="https://github.com/PacktPublishing/Hands-On-RESTful-API-Design-Patterns-and-Best-Practices">https://github.com/PacktPublishing/Hands-On-RESTful-API-Design-Patterns-and-Best-Practices</a>.<a href="https://github.com/PacktPublishing/Hands-On-RESTful-API-Design-Patterns-and-Best-Practices"/></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">About microservice architecture</h1>
                </header>
            
            <article>
                
<p>Legacy applications are inflexible, closed, monolithic, massive, and much more. Bringing forth business and technology modifications is beset with a number of issues and risks. Third-party service integration is a tough affair. Incorporating additional interfaces such as web, mobile, and cloud is another difficult thing for legacy systems. There are several access channels emerging these days, and our applications need to have the innate capability to work with multiple channels. In future, businesses will demand more with less from their IT teams and partners. In short, the development and operational complexities of legacy applications are prohibitively large. <strong>Microservice architecture</strong> (<strong>MSA</strong>) is all about achieving speed and safety at scale, and the MSA ecosystem is continuously growing to provide <span>scores of competent technologies, tools, and frameworks for efficiently implementing</span><span> </span><span>a range of business applications and IT services. This approach etches and elevates IT as a viable and value-adding business partner. That is, business-centric IT is the new normal owing to a raft of noteworthy advancements in the IT space. The previously held thought (IT is cost-centric) is changing fast, and IT is being proudly announced as the profit-centric paradigm.   </span></p>
<p>Any software application based on a microservice architecture simply consists of a suite of small, modular, and easily manageable services. Each service runs in a unique process and communicates through well-defined APIs. RESTful interfacing is the most popular and lightweight entrance for services to find, bind, and use one another. API-enabled microservices smoothly align with the business to deal with changes in an agile fashion, match business changes with an agile response, and deliver solutions in a decentralized manner. Microservices are independently deployable, horizontally scalable, composable, interoperable, publicly discoverable, network accessible, technology-agnostic, modular (loosely coupled and highly cohesive), fine-grained, and so now. The convergence of containerization and microservices results in big savings and benefits for businesses and technology professionals. All kinds of microservices are being methodically containerized and hosted in <strong>bare metal</strong> (<strong>BM</strong>) servers and <strong>virtual machines</strong> (<strong>VMs</strong>). The lightweight nature of containers along with business-centric and purpose-specific microservices brings a number of crucial advantages for the business world. There are other technological advancements in the form of container orchestration and management solutions in order to form container/service clusters to realize multi-container, business-aware, mission-critical, adaptive, and composite applications.</p>
<p class="mce-root"/>
<p>With microservices emerging and becoming established as the simple and optimal building block for designing, developing, deploying, and managing production-grade business applications and IT platforms, existing monolithic applications are being meticulously partitioned into a number of interactive and insightful microservices. The proven technique of divide and conquer is doing extremely well, even now through MSA conundrum. The individual yet interconnected microservices can be separately advanced and deployed without bringing down other microservices. There are a number of business, technical, and user advantages and hence there is a zeal among business executives, technology professionals, and IT operators to embrace MSA. New applications are being built using the salient features of the MSA from the ground up. In the following sections, we will see how an API gateway infrastructure is paramount for achieving the intended success of microservices architecture.</p>
<p><span>We have written about the widespread success of the RESTful service paradigm in the other chapters of this book with a bevy of practical examples. The gist is that RESTful APIs allow consumers/user applications to progress through an application (web, cloud, mobile, business, IoT, and so on) by appropriately selecting links (resources), such as <kbd>/product/book/</kbd>, and through specific HTTP operations (methods), such as <kbd>GET</kbd>, <kbd>DELETE</kbd>, <kbd>POST</kbd> or <kbd>PATCH</kbd>. This results in the next resource, which actually represents the next state of the application. REST stands for representational state transfer. And this new state gets transferred to the consumer for its subsequent use.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The prominent infrastructure modules in microservice-centric applications</h1>
                </header>
            
            <article>
                
<p>Horizontal scaling and independent deployment are being touted as the key hallmarks of microservices. Microservices and their instances can be easily replicated, replaced, refactored, and restored to adapt to incoming traffic. Fresh applications are being designed, developed, and deployed as microservices, while legacy applications are being systematically partitioned into a pool of microservices working together. It is therefore clear that MSA is the prime architectural pattern and style for next-generation software applications. In this section, we will discuss the key infrastructure components of MSA-compliant systems.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Service registry </h1>
                </header>
            
            <article>
                
<p>Microservices are increasingly dynamic and widely dispersed. Thus, for leveraging microservices and for enabling service discovery (static as well as automated), we need a centralized service registry/repository mechanism in place. The service registry is designed to keep track of the registered microservice instances in order to give correct information about the services and their latest locations. This registry is a sort of a database for accurately containing and maintaining the network locations of the service instances. If there is a movement, then the microservices have to consciously approach and update the service registry. The API gateway, on getting requests from client microservices, connects and tries to procure the location details of the serving microservices. If there is any deviation or deficiency, then there is the possibility of an unwanted failure. Every microservice instance has to register itself with the centralized service registry on startup and does the reverse by de-registering on shutdown. <span>The registration of service instances is typically refreshed periodically using a heartbeat mechanism. </span>The service registry module has to be highly available and for that high-availability requirement, the overwhelmingly recommended approach is to have a cluster of the service registry module. It is not recommended to cache the network location details obtained from the registry at the API gateway or the registry-aware client. If location details are cached at the API gateway, then it may turn out to be degrading the performance of the API gateway. It is the sole responsibility of microservice instances to update the registry about their changing status (availability). The role of the service registry is illustrated in the following figure:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1bf7d285-63f0-48a8-8866-7a00176e329a.png" style="width:40.17em;height:22.92em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The microservices, service registry, and API gateway interactions</div>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Service discovery</h1>
                </header>
            
            <article>
                
<p>We explained how the service registry solution comes in handy when pinpointing the location details of microservices and their instances. In a monolithic application, finding and calling application components happen through one of the language-level methods. If application components are being run in different process spaces, then there are <strong>remote method invocations</strong> (<strong>RMIs</strong>), <strong>remote procedure calls</strong> (<strong>RPCs</strong>), <strong>distributed component object model</strong> (<strong>DCOM</strong>), and so on. In a traditional legacy IT environment, applications run at fixed and well-known locations. That is, the hosts and ports are fixed in order to be found and used. Applications, therefore, can easily call one another using any one of the standard communication and data transmission protocols. However, in the agile and adept microservices era, the number of microservices and their instances are changing frequently. Further on, in order to bring about much-desired optimization, microservices and their instances are being redeployed in other locations. Therefore, client microservices need to use an advanced service discovery mechanism to get to know the latest status of microservice instances. For simplification, there are two main service discovery patterns—client-side discovery and server-side discovery.</p>
<p>For client-side discovery, the client will get the location of a service instance from service registry, as the registries has the information of latest locations of all the services. The client knows the address of the <strong>Service Registry</strong>. <span>The client then uses a load balancing algorithm to select the optimal service instances and makes a request.</span></p>
<p>For server-side discovery, the <strong>Client</strong> makes a request to the <strong>API Gateway</strong>. The <strong>API Gateway</strong> then queries the <strong>Service Registry</strong> to get the network location of the desired microservices. Based on that location information, the API gateway makes an attempt to connect and leverage the ability to serve microservices.</p>
<p class="mce-root"/>
<p>The following diagram illustrates the differences between client- and server-side service discovery:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9b3793fd-86aa-4572-acc2-bed05a76d40b.png" style="font-size: 1em;text-align: center;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Composition/orchestration </h1>
                </header>
            
            <article>
                
<p>Microservices primarily implement business functionality. For creating composite, business-centric, and process-aware applications, microservices must be linked together. For ensuring composition, there are two methods—orchestration and choreography. Also, there are static and dynamic compositions. The API gateway can act as the orchestration module. The other option is to code the orchestration logic and keep it as a separate utility service. The following diagram clearly depicts how service orchestration builds composite services, which are process-aware and business-centric:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/6f1dca5d-fa8c-4207-a45f-1020eb7fcd90.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Transformation </h1>
                </header>
            
            <article>
                
<p>There are several different types of, such as client applications on IoT devices, browsers for resource-constrained devices, web and mobile applications, and so on. With the input/output device ecosystem is consistently on the rise, the client side of any application and service has to be worked out separately. Client applications on heterogeneous devices follow different data representation, exchange, and persistence formats. Also, they follow different data transmission protocols. Then there are synchronous and asynchronous communication protocols. The data format and protocol translation requirements are bound to increase in a heterogeneous environment. The API gateway facilitates translation and other transformation needs quite comfortably. Transformation adapters can be freshly baked in, based on emerging needs, and deposited in a centralized place to be readily found and used. With purpose-agnostic and specific devices, optimal data formats and protocols are being continuously developed; there is a need for fresh data and protocol translators to enable them to join in mainstream computing.  </p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring </h1>
                </header>
            
            <article>
                
<p>Monitoring system resources and microservices is becoming vital for realizing the original benefits of MSA. There are service and application monitoring tools. As most microservices are being containerized, container monitoring tools have gained prominence recently. There are even monitoring tools for Kubernetes, which has gained the top slot and spot as the container life cycle management platform. As this chapter has been specially prepared to explain everything about API gateways, it is logical to write about API gateway monitoring. API gateways are paramount and pertinent for the intended success of microservices in delivering a variety of functionalities. Every service request/response gets routed through them. The monitoring and measurement of the API's operation, performance, health condition, scalability, security, and log data are critical for meeting the agreed SLA and OLA parameters. The much-insisted health monitoring is done to make sure the gateway is up and running all the time. Monitoring is indispensable for ensuring service reliability and stability. The aspect of observability is vital for service availability, adaptability, and analytics. For minutely monitoring the health of systems, resource parameters such as processing power, memory capacity, and I/O rates (network and storage) are the main focus. The other important things to be precisely monitored and measured are the connectivity (network), security alerts, secure backups, recovery (data and disaster), and so on. Finally, logging data plays a very important role in supplying a lot of useful and usable information to the concerned in solidifying and shaping up the distinct goal of business continuity.  </p>
<p>The other important factor is nothing but the traffic monitoring. Gathering and deeply analyzing traffic data will enable the operations team to consider, contemplate, and carry out correct  measures in time, with all the clarity and confidence. The essential metrics to be faithfully considered include the total number of requests being sent out for an API for a period of time, the performance/throughput value, the number of successful and exception messages received, the number of blocked messages by API gateway, and so on. Also, request categorization is taken into consideration. This deeper and deft analysis helps to easily predict traffic situations with greater accuracy so that any kind of spike and surge can be taken care of without any kind of breakdown or slowdown.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Load balancing and scaling </h1>
                </header>
            
            <article>
                
<p>This is an important ingredient for ensuring the extended availability of software systems. The goal of achieving application scalability (horizontal) through infrastructure elasticity is accomplished by leveraging a <strong>load balancer</strong> (<strong>LB</strong>) (software or hardware). We need traffic information to predict and prescribe the correct countermeasures in time. Deeper real-time analysis of traffic data helps us to understand and estimate the load on the applications. The insights from load data helps cloud administrators and operation teams to collectively and concisely formulate viable policies and rules for application scalability. Additional infrastructure modules can be readied in time in order to take up extra load. The API gateways can also scale horizontally as well as vertically so that the high availability of an API gateway solution is guaranteed. Otherwise, an API gateway can become a single point of failure. To have a clustered API gateway setup, we can have a LB in front of the API gateway. What this means is that multiple instances of an API gateway solution can be leveraged to ensure continuity, and all those instances can run the same configuration; this uniformity helps in virtualizing the same APIs and to execute the same policies. If there are multiple API gateway groups, then the capability (load balancing) can be elegantly extended and accurately accomplished across groups.</p>
<p> <span>The API gateway does not mandate any additional requirements on LBs. That is, t</span>he user and data loads are balanced based on widely recommended characteristics including the response time, the system load at that point of time, and so on. API gateways are maintained in a stateless fashion in order to ensure they are not weighed down by state information. This also enables service messages to take any route to reach the appropriate and assigned services. Some prominent components such as caches and counters, which are typically held on a distributed cache, are meticulously updated for every unique message. This setup ultimately helps the API gateway to complete its obligations without any problem across modes (sticky and non-sticky).</p>
<p class="mce-root"/>
<p>The distributed nature of API gateways poses a certain restriction during active/active and active/passive clustering. For example, to lose any counter and cache state, the system has to be designed in such a way that at least one API gateway is active at all times. Precisely speaking, to ensure high availability and reliability, as previously indicated, multiple API gateway instances have to run in a connected and clustered manner. The API gateway is able to maintain zero downtime by having the configuration deployment in a steady and continuous fashion. Generally, an API gateway instance in the cluster takes a few seconds to update its configuration. And when it is getting updated, that particular instance does not entertain any new request. Still, all the existing in-flight requests are fully honored. However, the other API gateway instances in the cluster can ceaselessly receive and process new requests and deliver the results. The key role of the <strong>Load Balancer</strong> here is to  ensure all the incoming requests are pushed to the correct API gateway instances that are receiving and processing fresh requests. Thus, API gateway clustering is important for continuously receiving and responding to service messages and the <strong>Load Balancer</strong> plays a vital role in fulfilling this, as illustrated in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c9719bc8-8ec0-4fce-abe3-774df110df00.png"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">High availability and failover </h1>
                </header>
            
            <article>
                
<p>In the era of microservices, guaranteeing high available through fault tolerance, fault detection, and isolation is an important thing for architects. In the recent past, API gateway solutions emerged as a critical component for the microeconomic era. Microservice architecture is being touted as as the soul and savior for facilitating the mandated business adaptivity, process optimization, and automation. API gateways are the only entry point for microservices to find and talk with one another to fulfill business tasks. This broker/middleware solution is blessed with a number of common features so that microservices can just focus on business functionalities. The <strong>non-functional requirements</strong> (<strong>NFRs</strong>) and the <strong>quality of service</strong> (<strong>QoS</strong>) attributes are achieved through gateway solutions. To achieve high availability and stability, the recommended action and approach is to deploy the API gateway in <strong>high availability</strong> (<strong>HA</strong>) mode. As previously described, API gateway instances are usually deployed behind a standard LB. The LB continuously probes the API gateway instances to understand whether they are alive or not. The health condition and performance level of each of the instances are captured and used by the LB to embark on the appropriate remedy in time, so that the continuity of the system does not get affected in any way. If the LB comes to know that an API gateway is not functioning, then the LB redirects and routes inbound traffic to the gateway instance that is functioning and delivering on its obligations.</p>
<p>Timely alerts are configured in order to get relevant notifications in the case of untoward incidents. If an alert is triggered, then the issue along with its metadata can be understood, as the data analytics capability is an important feature of any API gateway product. Generally, API gateways  are kept as a stateless entity as they are designed and destined to be bombarded with millions of service request messages every second. However, API gateways can maintain cached data, which can be replicated across a cluster of API gateways. Such an arrangement helps to maintain the peer-to-peer relationship among API gateway instances.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">HA and failover guidelines</h1>
                </header>
            
            <article>
                
<p>Experts have produced a series of guidelines and best practices to ensure the high availability of systems:</p>
<ul>
<li>In order to guarantee maximum availability, an API gateway has to be used in proven active/active mode. </li>
<li class="MsoNormalCxSpMiddle">There is a need for deeper and decisive analysis on traffic data. The insights from this analysis help operators and others manning production environments to plan and protect against message flooding. </li>
<li class="MsoNormalCxSpMiddle">Tool-supported automated network infrastructure monitoring and management are essential for ensuring the highest availability. Not only collecting operational and log data, but also subjecting them to a variety of investigations unravels a lot of useful and usable information. All the knowledge thus discovered and disseminated goes a long way in empowering the network infrastructure to work in prime and pristine condition. The analytics feature intrinsically embedded in an API gateway solution comes in handy in analyzing and articulating what to do to prevent any kind of failure and faltering. There are specific as well as agnostic monitoring tools, which can be integrated with knowledge visualization/report generation tools.  </li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Governance </h1>
                </header>
            
            <article>
                
<p>As the number of APIs keeps on increasing, it is essential to establish policies and to put other mechanisms in place for effective monitoring and management. The policies can broadly be categorized as design-time and runtime governance. The policies are highly influenced by business objectives and goals. Increasingly, IT is being upgraded to meet changes in business sentiments. Thus, IT policies have to be synced with business expectations to produce solid and smart governance.  </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">About API gateway solutions</h1>
                </header>
            
            <article>
                
<p>In a nutshell, an API gateway is a multifaceted proxy that accomplishes a variety of integration, intermediation, and enrichment tasks. It has all the information about the main microservice endpoints in order to correctly and cognitively mediate, route, and invoke a respective endpoint. This is performed after the initial request verification, content filtering, authentication, and authorization.</p>
<p>A typical API gateway has to have the following ingrained and serviceable competencies. The common features of any API gateway solution include a<span>uthentication and authorization, message enrichment, remediation, process-based composition, traffic routing and management, and service monitoring. </span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>An API gateway is bound to provide a single and unified API entry point across one or more internal APIs. There can be different distributed sources, such as client applications, services, and devices, trying to access the API gateway. Clients send a variety of requests and expect appropriate responses. The gateway is supposed to do a variety of initiation, intermediation, and implementation tasks. One of them is to <em>unify</em> these requests and work with the backend services. All kinds of proxy and aggregation activities are accomplished through API gateways, which also ensure rate limiting and security needs are met as well. In the microservice era, there can be hundreds of services, and hence the need for API gateways and management platforms is bound to grow further. In short, an API gateway can help provide a unified entry point for external consumers. The orchestration/choreography, brokerage, discovery, routing, enrichment, policy enforcement, governance, concierge jobs, and so on are performed by standardized API gateway solutions. On the other hand, API management adds additional capabilities such as analytics and life cycle management. In future, there will be attempts to meet QoS and NFRs such as availability, scalability, high performance/throughput, security, and reliability through replication and fault tolerance, through a combination of API gateways, cluster and orchestration platforms, service mesh solutions, and so on.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">API gateways for microservice-centric applications</h1>
                </header>
            
            <article>
                
<p>The unique contributions of API gateways for operationalizing microservices in a beneficial fashion are growing as days pass. The main features of an API gateway are  the following:</p>
<ol>
<li><strong>Adds flexibility</strong>: API gateways are supposed to hide internal concerns from external clients. An API gateway decouples external APIs from internal microservice APIs. This abstraction facilitates the addition, replacement, displacement, and substitution of advanced microservice implementations in place of legacy ones. The APIs of internal microservices can be changed without affecting the requesting microservices. Services can be freshly registered and referenced in a service registry or repository. The service discovery of newer services can be smooth and error free. Services can be versioned.</li>
<li><strong>Adds an additional layer</strong>: As microservices are not contacted directly, the security of services is greatly strengthened. Through using an API gateway, it is possible to stop all kinds of malicious attacks on internal microservices. Every microservice has its own data store. Thus, not only service security but also data security is enabled. Through rate limiting/throttling offered by API gateways, distributed DoS attacks can be thwarted easily.</li>
</ol>
<ol start="3">
<li><strong>Enables support for data and protocol translation</strong>: There are disparate data transmission and communication protocols. There are synchronous and asynchronous communications and their corresponding protocols. Besides HTTP, there are other protocols such as ProtoBuf (<a href="https://developers.google.com/protocol-buffers/docs/reference/overview">https://developers.google.com/protocol-buffers/docs/reference/overview</a>), AMQP (<a href="https://www.amqp.org/">https://www.amqp.org</a>), COAP, and more, for integrating with third-party applications and services in order to produce and sustain integrated applications. This is the essence of API gateway solutions. Precisely speaking, all the common capabilities of microservices are safely abstracted and incorporated into API gateways. The idea is to have the business logic in any microservice implementation. This best practice keeps microservices simple and easy to manipulate. All the security, networking, third-party integration, adding volumes, fulfilling QoS attributes, and other cross-cutting concerns are accumulated together and accomplished through API gateways, which act as a centralized and clustered middleware solution.</li>
</ol>
<p>The following diagram illustrates how an API gateway solution links microservices with service clients:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9bad64f2-f833-4b14-b6ea-42731efd5119.png" style="width:43.92em;height:29.50em;"/></p>
<p class="mce-root"/>
<p>Essentially, the <strong>API Gateway</strong> is a reverse proxy to microservices and serves as the single point of contact for the growing list of clients to enter into the system. This implements the age-old facade pattern for the microservice era. Further on, API gateway solutions simplify and standardize API design, implementation, and management. The consistency of microservices, their instances, and the software infrastructure is ensured. Because of this consistency, it is quite easy to establish and enforce the service level and security requirements of microservices. Formulating and firming up policies at different layers and levels of the system stack become vital for the intended success of microservice architecture. The gateway ultimately helps to address the key challenges and concerns such as security, caching, monitoring, and much more. It can handle heterogeneous clients, multiple backend microservices, and their instances. Service discovery is automated through the API gateway. The following diagram shows various features and functionalities of an API gateway solution:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a7ab56d3-964f-44cb-b01c-4319159595cb.png"/></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The issues with microservice API gateways</h1>
                </header>
            
            <article>
                
<p>We have listed several key benefits and contributions of API gateways toward microservice-centric business applications. However, there are a few drawbacks too. As we all know, this gateway infrastructure is an additional abstraction layer, so all the control and the data flows happen via this middleware solution; therefore, there is the possibility of system performance degradation. This introduces an additional hub through which service requests and responses pass. Not only is it a single point of contact but also a single point of failure. When the number of microservices goes up significantly, complications will increase steadily. Service-to-service communication resiliency is not provided by API gateways. There are service mesh solutions, which guarantee the much-needed service resiliency that, in turn, results in reliable applications. With the widespread use of technologically advanced cloud infrastructures, we can safely expect lots of reliable systems and environments.</p>
<p>Policy configuration in API gateways—we indicated in the preceding section that the API gateway is capable of doing <strong>content attack protection</strong> (<strong>CAP</strong>). By specifying and modifying security policies, API gateways can thwart any security attacks. Content attacks are primarily performed by inserting malicious data into service request messages. The most widely known content attacks include inserting special characters. The other prominent content attack methods are text patterns, and SQL and XPATH injections. The way to surmount this type of attack is to have appropriate CAP policies configured for inbound as well as outbound traffic. These measures can protect against SQL and XPATH injection attacks. The other considerations include security attacks being forbidden by limiting the HTTP versions, methods, and URL path. There are other ways, such as defining a whitelist of domain names, client IP addresses, limiting query parameters and HTTP headers.</p>
<p>The IoT device (client) sends a message request to microservice via an API gateway. An inbound CAP policy scans the service request message for any possible content-based attacks. If there is any violation, then the API gateway sends an error message back to the IoT device client. If everything is perfect, then the API gateway passes verified and validated messages to the service mediation layer for identity verification and authentication, authorization. Then, the right microservice endpoint is invoked and messages are processed. The microservice in turn calls one or more microservices. Then, the outbound CAP policy scans the reply message for any content-based attacks. If there is no violation, then the response is delivered to the requested client.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security features of API gateways</h1>
                </header>
            
            <article>
                
<p>Security plays a critical part in any distributed IT environment. Data integrity, confidentiality, and availability are the most important parameters for ensuring impenetrable data security. There are several mechanisms such as encryption and decryption, digital signature, hashing for securing data while in transit, persistence, and usage. For microservice-centric applications running on cloud infrastructures, the security aspect starts with identification, authentication, and authorization. Security policies are another solution widely used in public cloud environments. <strong>Hardware security modules</strong> (<strong>HSMs</strong>) are prevalent these days as it is not easy to break in while guaranteeing higher throughput. Then there are several security appliances such as firewalls, intrusion detection, and prevention systems. Unified threat modeling and management solutions are also getting a lot of attention these days, considering the severity of security threats and vulnerabilities in the microservice era. As mentioned previously, API gateways form an important phenomenon for the intended success of microservice architecture. Considering the strategically sound significance, API gateway solutions are being stuffed with security-enablement properties. A bevy of unique security characteristics are being incorporated into API gateways to ensure utmost and unbreakable security. Let's take a look at these security features. </p>
<p><strong>Federated identity</strong> is the widely preferred way for service authentication and authorization. As we all know, microservices exclusively focus on business functionality. The supporting functionalities and facilities are attached when needed. The proven technique of divide and conquer is still working wonders in the IT world, which is becoming hugely complicated yet sophisticated owing to the consistently evolving and erudite trends and transitions in the IT space. Especially, identity management, being the prime security requirement, is being delegated to third-party solutions and services. That is, each microservice does not need to obtain and store user credentials in order to authenticate them during subsequent requests.</p>
<p class="mce-root"/>
<p>Instead, the identity management system takes care of the authentication well. The following diagram shows the role authorization servers play in the authentication and authorization processes. The attached database stores all the user credentials in clustered mode. Also third-party authentication and authorization management systems are closely coupled with API gateways in order to seamlessly and smoothly do the initial security-enablement tasks:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e49899ac-1c98-4d2e-9b62-095d2d6c905b.png"/></p>
<p>There are three key protocols enabling the federated identity:</p>
<ul>
<li>OpenID</li>
<li>SAML</li>
<li>OAuth</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The flow is as follows. The application client first sends a request and grabs a <strong>JWT</strong> access token from the third-party authentication and  authorization server by supplying the mandated credentials. Once the mandated credentials are obtained, the client then embeds the access token in the Authorization HTTP header of the API request. The <strong>API Gateway</strong> then validates the access token supplied by the client with the authorization server.  Once validated by the third-party authentication server, the API gateway passes the <strong>JWT</strong> access token to the appropriate backend microservices to initiating the business tasks. If there is a need for other downstream microservices to fulfill the service request, then the same <strong>JWT</strong> token is shared across to all the participating and contributing microservices. Microservices that are in collaborating mode have to attach the <strong>JWT</strong> access token to their request messages: </p>
<ul>
<li><strong>Confidentiality</strong>: Data security and privacy are very much demanded owing to the remote storage. Also the pervasive, public, and open internet, which turns out to be the world's largest communication infrastructure and information powerhouse, is the data carrier. Keeping data safe and secure is the foremost requirement for business entities and their IT divisions. That is, the confidentiality of data cannot be compromised at any cost. Primary data protection is done by the API gateway. The other option is that the database server is totally insulated from other servers. As a way of ensuring data privacy while data is being persisted, data is encrypted and the encryption key is managed separately. Data servers are not allowed to be accessed by clients directly. Every data access request is routed through a frontend service.</li>
<li><strong>Integrity</strong>: The service messages comprising confidential, customer, and corporate information cannot be hacked and manipulated. A compromised message can be used for the wrong purposes, such as bringing down servers or stealing private information. To ensure better integrity for messages and data, a number of purpose-specific and agnostic checks are done on messages while the messages are passed through a host of intermediary servers from the source to the sink. Typically hashing algorithms are used in order to identify whether there has been any kind of data modification.</li>
<li><strong>Availability</strong>:<strong> </strong>Service availability is very important for attaining success with microservice architecture. There are hackers attempting to bring down services. The API gateway provides the first defense against this. Then, there are LBs to ensure the service continuity. Clustered and cloud servers come in handy in guaranteeing the high availability of services. <strong>Distributed denial of service</strong> (<strong>DDoS</strong>) attacks on services can be thwarted through the application of the throttling/rate limiting pattern.</li>
<li><strong>Secure communication</strong>: Communication has to be secured through the SSL/TLS mechanism. Microservices and API gateways are, therefore, mandated to be SSL/TLS-compliant. Such a setup easily safeguards against man-in-the-middle attacks. Also, the widely used message and data encryption method secures against peeking at and tampering with service messages and data.</li>
</ul>
<p>Apart from other functionalities, API gateways are predominantly leveraged to secure microservice-based applications. Security acquires special significance as microservices are deployed in geographically distributed server environments. Also, with web-scale applications, microservices and their distinct instances are being frontended by LBs. API gateways represent a growing collection of advanced services that enable microservices to contribute to business automation and augmentation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Prominent API gateway solutions</h1>
                </header>
            
            <article>
                
<p>There are a few competent API gateway solutions (open source as well as commercial grade).</p>
<p>Kong (<a href="https://konghq.com/">https://konghq.com/</a>) is an open source <strong>API</strong> gateway solution. The Kong server can run in front of any RESTful API. <span>Kong fully supports popular REST APIs. Due to their lightweight and versatile nature, RESTful is the widely used API standard for all kinds of web, mobile, embedded, and cloud applications. The current </span>capability of the Kong API gateway can be substantially extended through plug-ins, which bring in extra functionality to meet evolving needs. That is, the core features and facilities offered by Kong can be supplemented through additional functionalities provided by versatile plug-ins. That is, Kong natively supports plug and play architecture. Small, medium, and large-scale business enterprises across the globe are using this innovation-field product suite in production-grade IT environments. Kong can be deployed in on-demand, online, and off-premises clouds. Also, it can run on on-premises private clouds. As illustrated in the following diagram, <span>OpenResty and Nginx are the core engines of Kong. OpenResty is a high-performance web platform that integrates the standard <a href="https://openresty.org/en/nginx.html">Nginx</a> core, <a href="https://openresty.org/en/luajit.html">LuaJIT</a>, and a host of libraries. Kong uses either Cassandra or PostgreSQL as the data store. The popular features accentuated by Kong include authentication, monitoring and analytics, and request/response translation and logging. </span></p>
<p>To better understand how Kong works, here is a typical request workflow of an API that uses Kong:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a6fe7105-de72-4039-af77-19102a280b0f.png" style="width:37.50em;height:8.42em;"/></p>
<p>Once Kong has started to run, every request made to the <strong>API</strong> will hit the Kong server first.  And the Kong server acts as the proxy to send the request to the <strong>API</strong> of the requested service. In short, everything in the microservice world gets initiated and implemented through an API gateway. When everything uses an <strong>API</strong>, the role of API gateway, management, and analytics solutions is bound to escalate in the days to unfold: </p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/571d596e-1037-4983-ab51-567c24b22d7a.png" style="width:45.17em;height:13.75em;"/></p>
<p>Red Hat 3scale APIcast gateway (<a href="https://www.3scale.net/tag/open-source/">https://www.3scale.net/tag/open-source/</a>)—the APIcast gateway is also Nginx-based and made available as an <span class="MsoHyperlink">o</span><span class="MsoHyperlink">pen source software solution</span>. This API gateway is configured within 3scale's Admin Portal. The gateway is a crucial part of 3scale API management, which is a <strong>software as a service</strong> (<span class="MsoHyperlink"><strong>SaaS</strong>) offering</span>. The Admin Portal has a number of customization and configuration functionalities, such as allowing customers to define desired authentication methods, setting rate limits, getting analytics done on API usage data, and creating a developer portal for their API consumers. The <span>3scale APIcast gateway lets you deploy the API gateway service on a cloud environment with a few clicks. This deployment is much faster than others because there is no need for any kind of code modification at the backend. APIcast is emerging as the perfect solution for low or medium volume APIs. Enterprises widely use APIcast in staging environments and this speeds up the process of testing. </span></p>
<p class="mce-root"/>
<p>Tyk (<a href="https://tyk.io/">https://tyk.io/</a>) is also an open source API gateway. This solution intrinsically takes care of API management activities. The Tyk package consists of an API gateway and an API management dashboard. It also has the API analytics feature. A developer portal is another interesting module of this package. Tyk can be installed in on-premises clouds. It is available in leading public clouds and can be purchased and used as a cloud service. Not only that, it integrates private and public clouds to contribute as the API gateway solution for hybrid clouds. Under load, this API gateway can do the full key validation, security verification, quota management, and data analytics, without any hitch or hurdle. The developer portal is made available to empower the development community.</p>
<p>Moesif (<a href="https://www.moesif.com/">https://www.moesif.com/</a> <span class="MsoHyperlink">) is primarily an API an</span><span class="MsoHyperlink">alytics solution. This has the capability to understand how developers use APIs and to know why certain errors occur and repeat sometimes. Also, it helps to notify API providers of any hidden issues before the customers see them. Thus, this solution is a helping hand for service providers. As we tend toward the API economy, the API analytics solution plays an important role. Today,</span> thousands of developers process billions of API calls through Moesif for debugging, monitoring, and understanding API usage. The first and foremost requirement to build  a great API (whether it is REST, GraphQL, or JSON-RPC API) is to precisely and concisely measure how developers use the APIs. Product teams use the API analytics capability offered by this solution to understand how their APIs are being used. By leveraging the proven and potential <strong>machine learning</strong> (<strong>ML</strong>) techniques, Moesif API insights enable data-driven teams to continuously improve their API and <strong>developer experience</strong> (<strong>DX</strong>).</p>
<p>Ambassador (<a href="https://www.getambassador.io/">https://www.getambassador.io/</a><span class="MsoHyperlink">) is a popular open source and Kubernetes-native API gateway for the microservice world. This gateway solution can do several things for the container world. </span>Ambassador can authenticate all kinds of incoming requests before intelligently routing them to backend services. It natively supports TLS termination. In addition to that, Ambassador supports rate limiting/throttling via an external third-party service. This rate limiting is facilitated through the <span class="MsoHyperlink">Envoy proxy's rate limiting capabilities</span>. A key feature of Envoy is the observability feature, which is enabled  by exposing a multitude of statistics about its own operations. Ambassador makes it easy to disseminate that knowledge to statistics and monitoring tools such as Prometheus, Datadog, and so on. Ambassador generally relies on the fast-evolving Kubernetes platform for ensuring service reliability, availability, and scalability.</p>
<p class="mce-root"/>
<p>Envoy (<a href="https://www.envoyproxy.io/">https://www.envoyproxy.io/</a><span class="MsoHyperlink">) was originally</span> built by Lyft.<strong> </strong>Envoy is a high performance C++ distributed proxy designed for single services and applications. Envoy turns out to be a competent solution as a communication bus. For microservice-centric applications, this contributes as the universal data plane. Finally, it is a core engine for service mesh solutions. Envoy runs alongside every application and abstracts the networking complexity by providing all the common network features in a platform-agnostic manner. By leveraging the Envoy mesh solution, it is possible to visualize and pinpoint problem areas because features such as consistent observability, tuning overall performance, and adding a substrate are made available in a single place.</p>
<p>Tree gateway (<a href="http://treegateway.org/">http://treegateway.org/</a><span class="MsoHyperlink">) is</span> a free and open source solution. This can create a complete and customizable pipeline to handle service requests. Tree gateway makes it easy to create and sustain big clusters. In addition to this, it supports the ready formation of Redis clusters to share configurations, circuit-breaker states, and cached content. Any API configuration can be changed at any point in time, and all configurations get propagated to other tree gateway cluster nodes, without any problems. This comes with an advanced <span class="MsoHyperlink">circuit breaker</span> module that can <em>fast fail</em> responses when any API fails, falls, and falters.  Furthermore, it innately supports real-time monitoring and analytics. A pluggable engine allows any kinds of transformations or verifications to any API requests.</p>
<p>Gravitee.io (<a href="https://gravitee.io/">https://gravitee.io/</a><span class="MsoHyperlink">)</span> is a flexible, lightweight, blazingly fast, and open source API management solution. This tool helps any business enterprise to control who, when, and how users access the APIs in a finely grained manner.</p>
<p>API Umbrella (<a href="https://apiumbrella.io/">https://apiumbrella.io/</a><span class="MsoHyperlink">)</span> is a proxy solution that sits in front of any API. It can seamlessly add API gateway and analytics functionalities, such as API keys, rate limiting, and so on. </p>
<p>Express gateway (<a href="https://www.express-gateway.io/">https://www.express-gateway.io/</a>) is a microservice API gateway, which is built on Express.js. It is typically fast, flexible, and community driven.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>API gateway solutions are very important for API-enabled microservices. RESTful APIs are the most prevalent and powerful. RESTful APIs are overwhelmingly used by web, mobile, cloud, and IoT applications and services. Not only software applications but also resource-constrained and intensive embedded devices are being linked with one another via RESTful APIs. With microservices quickly proliferating and as everything is stuffed with APIs, there is a mandate for advanced API gateway solutions to form integrated and orchestrated applications, which businesses increasingly prefer these days. API management and analytics capabilities are also attached with gateway solutions to make them comprehensive. A variety of plugins and utility services are being built and incorporated on demand. Furthermore, API gateway solutions are being integrated with third-party tools for monitoring, measurement, management, and visualization. The well-intended approach is to have a dynamic pool of modular (loosely and lightly coupled and highly cohesive) API gateway services instead of a monolithic API gateway solution, which is difficult to manage, inflexible, and closed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Service mesh versus API gateway</h1>
                </header>
            
            <article>
                
<p>We have discussed API gateway solutions extensively in relation to the success of the MSA paradigm. We all know that in order to increase the resiliency of microservices, the service mesh solutions are being pampered. And in this section, we are to discuss the key differences between API gateways and service meshes.</p>
<p>Firstly, the API gateway, as explained in the preceding section, the key objective of using an API gateway is to express and expose microservices to the outside world. With the attachment of API management modules, APIs are managed well. API data is captured and subjected to a variety of investigations to produce insights to steer API gateways in the right direction:</p>
<ul>
<li>API services call the downstream microservices that can be atomic and composite. The noteworthy capability of API gateways is to fuse multiple downstream services into something that is useful for the requesting services. That is, services are blended as per the stated requirements to produce process-aware, mission-critical, and composite services. </li>
<li>API gateways also come with inbuilt support for service discovery, analytics, and security. The observability capability for capturing various metrics along with monitoring, distributed logging, and distributed tracing is the key differentiator for gateway solutions.</li>
<li>API gateways closely work with several other software solutions, such as API management, marketplace/store, and portals in order to be comprehensive for the microservice era.</li>
</ul>
<p class="mce-root"/>
<p>Secondly, service mesh—this is relatively a new solution type and approach for providing the resiliency characteristic, which is becoming an important one for microservice-based applications. As we all know, services ought to interact with one another in order to realize bigger and better business-scale services. When services talk to one another, several things can go wrong. In order to guarantee service communication resiliency, the IT industry is leaning towards embracing the new concept of a service mesh, which is a kind of network and communication infrastructure to ensure service resiliency. Service mesh implementations have embedded resiliency-enablement patterns such as circuit breaker, retry, timeout, and throttling/rate limiting. There are service mesh solutions such as Istio, Linkered, and Conduit. Advanced functionalities such as service discovery and observability are being incorporated into these solutions. The functionalities of API gateways and service mesh solutions are clearly demarcated. It is also possible to use both of them in a production environment.</p>
<p>The service mesh is used alongside most other service implementations as a sidecar. A service mesh provides a stream of utility and horizontal functionalities for enabling service resiliency.</p>
<p class="p1"><span class="s1">In conclusion, API gateways facilitate API communications between a client application and a server application. Also, microservices within an application can be integrated through the API gateway solution. An API gateway<span> operating at layer 7 (HTTP)</span> enables internal as well as external communication. Other noteworthy services include user authentication, throttling/rate limiting, transformations, logging, and so on.  </span></p>
<p class="p1"><span class="s1">Service mesh solutions such as Istio, Linkered, and Conduit are for enabling service communication resiliency. That is, they mainly focus on routing internal communications. A service mesh operates primarily at layer 4 (TCP). All the resiliency and reliability design patterns such as circuit breakers, timeouts, retries, and health checks are intrinsically implemented and incorporated into service mesh solutions.  </span></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Microservices are being proclaimed as a groundbreaking architectural style for producing and sustaining business and IT applications and platforms. Cloud environments are filled up with bare metal servers, virtual machines, and containers. Microservices can be hosted on these and run to extract and supply their unique functionalities. As the number of microservices is growing rapidly, we need technology-sponsored and complexity mitigation solutions and services. API gateway solutions are being presented as the viable and venerable infrastructure (software or hardware) solutions for that bring a kind of abstraction to reduce dependency-induced problems. This chapter detailed the various features of API gateway solutions and how they come in handy for resolving various microservice-specific issues. The key gateway solutions (open source and commercial grade) and their unique properties were documented for your benefit. The next chapter is about how microservices have to be tested in a systematic manner and speed up the testing needs through scores of automated testing tools. </p>


            </article>

            
        </section>
    </body></html>