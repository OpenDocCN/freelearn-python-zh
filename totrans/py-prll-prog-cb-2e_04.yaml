- en: Message Passing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息传递
- en: This chapter will briefly cover the **Message Passing Interface** (**MPI**),
    which is a specification for message exchange. The primary goal of the MPI is
    to establish an efficient, flexible, and portable standard for message exchange
    communication.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将简要介绍**消息传递接口**（**MPI**），这是一个用于消息交换的规范。MPI的主要目标是建立一个高效、灵活且可移植的消息交换通信标准。
- en: Mainly, we will show the functions of the library that include synchronous and
    asynchronous communication primitives, such as (send/receive) and (broadcast/all-to-all),
    the operations of combining the partial results of the calculation (gather/reduce), and
    finally, the synchronization primitives between processes (barriers).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 主要地，我们将展示库中的函数，包括同步和异步通信原语（如（发送/接收）和（广播/全对全）），组合计算部分结果的运算（收集/归约），以及最后，进程间的同步原语（屏障）。
- en: Furthermore, the control functions of the communication network will be presented
    by defining the topologies.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，将通过定义拓扑来展示通信网络的控制函数。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将介绍以下内容：
- en: Using the `mpi4py` Python module
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`mpi4py`Python模块
- en: Implementing point-to-point communication
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现点对点通信
- en: Avoiding deadlock problems
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免死锁问题
- en: Collective communication using a broadcast
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用广播进行集体通信
- en: Collective communication using the `scatter` function
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`scatter`函数进行集体通信
- en: Collective communication using the`gather` function
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`gather`函数进行集体通信
- en: Collective communication using `Alltoall`
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`Alltoall`进行集体通信
- en: The reduction operation
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 归约操作
- en: Optimizing communication
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化通信
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need the `mpich` and `mpi4py` libraries for this chapter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要为本章使用`mpich`和`mpi4py`库。
- en: The `mpich` library is a portable implementation of MPI. It is free software
    and is available for various versions of Unix (including Linux and macOS) and
    Microsoft Windows.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpich`库是MPI的可移植实现。它是免费软件，适用于Unix的各种版本（包括Linux和macOS）以及Microsoft Windows。'
- en: To install `mpich`, use the installer downloaded from the downloads page ([http://www.mpich.org/static/downloads/1.4.1p1/](http://www.mpich.org/static/downloads/1.4.1p1/)).
    Moreover, make sure to choose between the 32-bit or 64-bit versions to get the
    right one for your machine.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`mpich`，请使用从下载页面下载的安装程序（[http://www.mpich.org/static/downloads/1.4.1p1/](http://www.mpich.org/static/downloads/1.4.1p1/)）。此外，请确保选择32位或64位版本，以获取适合您机器的正确版本。
- en: The `mpi4py` Python module provides Python bindings for the MPI ([https://www.mpi-forum.org](https://www.mpi-forum.org))
    standard. It is implemented on top of the MPI-1/2/3 specification and exposes
    an API that is based on the standard MPI-2 C++ bindings.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py`Python模块为MPI标准（[https://www.mpi-forum.org](https://www.mpi-forum.org)）提供了Python绑定。它基于MPI-1/2/3规范实现，并公开了一个基于标准MPI-2
    C++绑定的API。'
- en: 'The installation procedure of `mpi4py` on a Windows machine is as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows机器上安装`mpi4py`的步骤如下：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Anaconda users must type the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda用户必须输入以下内容：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that for all the examples in this chapter, we used `mpi4py` installed by
    using the `pip` installer
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，本章中的所有示例都使用了通过`pip`安装器安装的`mpi4py`。
- en: 'This implies that the notation used to run the `mpi4py` examples is as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着运行`mpi4py`示例所使用的符号表示如下：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `mpiexec` command is the typical way to start parallel jobs: `x` is the
    total number of processes to use, while `mpi4py_script_name.py` is the name of
    the script to be executed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpiexec`命令是启动并行作业的典型方式：`x`是要使用的总进程数，而`mpi4py_script_name.py`是要执行的脚本的名称。'
- en: Understanding the MPI structure
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解MPI结构
- en: The MPI standard defines the primitives for the management of virtual topologies,
    synchronization, and communication between processes. There are several MPI implementations
    that differ in the version and features of the standard supported.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: MPI标准定义了管理虚拟拓扑、同步和进程间通信的原语。有几个MPI实现，它们在支持的标准的版本和功能上有所不同。
- en: We will introduce the MPI standard through the Python `mpi4py` library.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过Python的`mpi4py`库介绍MPI标准。
- en: Before the 1990s, writing parallel applications for different architectures
    was a more difficult job than what it is today. Many libraries facilitated the
    process, but there was not a standard way to do it. At that time, most parallel
    applications were destined for scientific research environments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪90年代之前，为不同的架构编写并行应用程序比今天更困难。许多库简化了这一过程，但没有一个标准的方法来做这件事。当时，大多数并行应用程序都是为科学研究环境而设计的。
- en: The model that was most commonly adopted by the various libraries was the message-passing
    model, in which the communication between the processes takes place through the
    exchange of messages and without the use of shared resources. For example, the
    master process can assign a job to the slaves simply by sending a message that
    describes the work to be done. A second, very simple, example here is a parallel
    application that performs a merge sort. The data is sorted locally to the processes
    and the results are passed to other processes that will deal with the merge.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 各个库最常采用的模型是消息传递模型，在这种模型中，进程间的通信是通过消息交换来进行的，而不使用共享资源。例如，主进程可以通过发送一个描述要完成的工作的消息来简单地分配一个任务给从属进程。另一个非常简单的例子是一个并行应用程序，它执行归并排序。数据在本地对进程进行排序，然后将结果传递给其他进程，这些进程将处理合并。
- en: Since the libraries largely used the same model, albeit with minor differences
    from each other, the authors of the various libraries met in 1992 to define a
    standard interface for the exchange of messages, and, from here, MPI was born.
    This interface had to allow programmers to write portable parallel applications
    on most parallel architectures, using the same features and models they were already
    used to.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于库在很大程度上使用了相同的模型，尽管彼此之间有细微的差异，但各个库的作者于1992年聚会，以定义一个用于消息交换的标准接口，从这里，MPI诞生了。这个接口必须允许程序员在大多数并行架构上编写可移植的并行应用程序，使用他们已经熟悉的相同特性和模型。
- en: 'Originally, MPI was designed for distributed memory architectures, which began
    to grow in popularity 20 years ago:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，MPI是为分布式内存架构设计的，这种架构20年前开始变得流行：
- en: '![](img/c5eade1c-0ee1-4194-a00c-d8686149c550.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c5eade1c-0ee1-4194-a00c-d8686149c550.png)'
- en: The distributed memory architecture schema
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式内存架构方案
- en: 'Over time, distributed memory systems began to be combined with each other,
    creating hybrid systems with distributed/shared memory:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，分布式内存系统开始相互结合，创建了具有分布式/共享内存的混合系统：
- en: '![](img/0ac1b93c-4e24-4612-b1d7-1935c8f0a661.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0ac1b93c-4e24-4612-b1d7-1935c8f0a661.png)'
- en: The hybrid system architecture schema
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 混合系统架构方案
- en: Today, MPI runs on distributed memory, shared memory, and hybrid systems. However,
    the programming model remains that of distributed memory, although the true architecture
    on which the calculation is performed may be different.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，MPI在分布式内存、共享内存和混合系统上运行。然而，编程模型仍然是分布式内存的，尽管实际执行计算的真正架构可能不同。
- en: 'The strengths of MPI can be summarized as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: MPI的强项可以总结如下：
- en: '**Standardization**: It is supported by all **High-Performance** **Computing**
    (**HPC**) platforms.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化**：它被所有**高性能计算**（**HPC**）平台所支持。'
- en: '**Portability**: The changes applied to the source code are minimal, which
    is useful if you decide to use the application on a different platform that also
    supports the same standard.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可移植性**：对源代码所做的更改最小，如果你决定在也支持相同标准的不同平台上使用应用程序，这将非常有用。'
- en: '**Performance**: Manufacturers can create implementations optimized for a specific
    type of hardware and get better performance.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：制造商可以创建针对特定类型硬件优化的实现，并获得更好的性能。'
- en: '**Functionality**: Over 440 routines are defined in MPI-3, but many parallel
    programs can be written using fewer than even 10 routines.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**功能性**：在MPI-3中定义了超过440个例程，但许多并行程序可以使用少于10个例程来编写。'
- en: 'In the following sections, we will examine the main Python library for message
    passing: the `mpi4py` library.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将检查用于消息传递的主要Python库：`mpi4py`库。
- en: Using the mpi4py Python module
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用mpi4py Python模块
- en: The Python programming language provides several MPI modules to write parallel
    programs. The most interesting of these is the `mpi4py` library. It is constructed
    on top of the MPI-1/2 specifications and provides an object-oriented interface,
    which closely follows the MPI-2 C++ bindings. A C MPI user could use this module
    without learning a new interface. Therefore, it is widely used as an almost-full
    package of an MPI library in Python.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Python编程语言提供了几个MPI模块来编写并行程序。其中最有趣的是`mpi4py`库。它建立在MPI-1/2规范之上，提供了一个面向对象的接口，该接口紧密遵循MPI-2
    C++绑定。C MPI用户可以使用这个模块而不需要学习新的接口。因此，它被广泛用作Python中MPI库的几乎完整的包。
- en: 'The main applications of the module, which will be described in this chapter,
    are as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将描述的模块的主要应用如下：
- en: Point-to-point communication
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点对点通信
- en: Collective communication
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集体通信
- en: Topologies
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通信拓扑
- en: How to do it...
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s start our journey to the MPI library by examining the classic code of
    a program that prints the phrase `Hello, world!` on each process that is instantiated:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过检查一个程序的经典代码开始我们的MPI库之旅，该程序在每个实例化的进程中打印短语`Hello, world!`：
- en: 'Import the `mpi4py` library:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`mpi4py`库：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In MPI, the processes involved in the execution of a parallel program are identified by
    a sequence of non-negative integers called **ranks**.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在MPI中，参与并行程序执行的进程通过称为**rank**的非负整数序列来标识。
- en: 'If we have a number (*p* of processes) that runs a program, then the processes
    will have a `rank` that goes from *0* to *p*-1\. In particular, in order to assess
    the rank of each process, we must use the `COMM_WORLD` MPI function in particular.
    This function is called a **communicator**, as it defines its own set of all processes
    that can communicate together:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们有一个运行程序的进程数（*p*），那么这些进程将有一个从*0*到*p*-1的`rank`。特别是，为了评估每个进程的rank，我们必须特别使用`COMM_WORLD`
    MPI函数。这个函数被称为**通信器**，因为它定义了可以一起通信的所有进程的集合：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, the following `Get_rank()` function returns `rank` of the process
    calling it:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，以下`Get_rank()`函数返回调用它的进程的`rank`：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once evaluated, `rank` is printed:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦评估，`rank`将被打印：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: How it works...
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: According to the MPI execution model, our application consists of *N* (5 in
    this example) autonomous processes, each with their own local memory able to communicate
    data through the exchange of messages.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 根据MPI执行模型，我们的应用程序由*N*（在这个例子中为5）个自主进程组成，每个进程都有自己的本地内存，能够通过消息交换来交换数据。
- en: The communicator defines a group of processes that can communicate with each
    other. The `MPI_COMM_WORLD` work used here is the default communicator and includes
    all processes.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通信器定义了一组可以相互通信的进程。这里使用的`MPI_COMM_WORLD`工作是一个默认的通信器，包括所有进程。
- en: The identification of a process is based on ranks. Each process is assigned
    a rank for each communicator to which it belongs. The rank is an integer that
    is assigned, which starts from zero and identifies each individual process in
    the context of a specific communicator. The common practice is to define the process
    with a global rank of *0* as the master process. Through the rank, the developer
    can specify what the sending process is and what the recipient processes are instead.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 进程的标识基于rank。每个进程为其所属的每个通信器分配一个rank。rank是一个整数，从零开始分配，用于在特定通信器的上下文中标识每个单独的进程。常见的做法是将具有全局rank
    *0* 的进程定义为主进程。通过rank，开发者可以指定发送进程是什么以及接收进程是什么。
- en: 'It should be noted that, for illustration purposes only, the `stdout` output
    will not always be ordered, as multiple processes can apply at the same time by
    writing on the screen and the OS arbitrarily chooses the order. So, we are ready
    for a fundamental observation: every process involved in the execution of MPI
    runs the same compiled binary, so each process receives the same instructions
    to be executed.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，为了说明目的，`stdout`输出将不会总是有序的，因为多个进程可以同时通过在屏幕上写入来应用，操作系统任意选择顺序。因此，我们准备好进行一个基本观察：每个参与MPI执行执行的进程都运行相同的编译后的二进制文件，因此每个进程接收相同的指令来执行。
- en: 'To execute the code, type the following command line:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行代码，请输入以下命令行：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This is the result that we will get after executing this code (notice how the
    order of execution of the processes *is not sequential*):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们执行此代码后得到的结果（注意进程执行的顺序*不是顺序的*）：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It should be noted that the number of processes to be used is strictly dependent
    on the characteristics of the machine on which the program must run.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，要使用的进程数量严格依赖于程序必须运行的机器的特性。
- en: There's more...
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: MPI belongs to the **Single Program Multiple Data** (**SPMD**) programming technique.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: MPI属于**单程序多数据**（**SPMD**）编程技术。
- en: SPMD is a programming technique in which all processes execute the same program,
    each on different data. The distinction in executions between different processes
    occurs by differentiating the flow of the program, based on the local rank of
    the process.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: SPMD是一种编程技术，其中所有进程执行相同的程序，但每个进程在不同的数据上。不同进程之间的执行区别是通过区分程序的流程来实现的，基于进程的本地rank。
- en: SPMD is a programming technique in which a single program is executed by several
    processes at the same time, but each process can operate on different data. At
    the same time, the processes can execute both the same instruction and different
    instructions. Obviously, the program will contain appropriate instructions that
    allow the execution of only parts of the code and/or to operate on a subset of
    the data. This can be implemented using different programming models, and all
    executables start at the same time.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: SPMD是一种编程技术，其中单个程序由多个进程同时执行，但每个进程可以操作不同的数据。同时，进程可以执行相同的指令和不同的指令。显然，程序将包含适当的指令，允许只执行代码的一部分和/或操作数据的一个子集。这可以使用不同的编程模型来实现，并且所有可执行文件都同时启动。
- en: See also
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The complete reference to the `mpi4py` library can be found at [https://mpi4py.readthedocs.io/en/stable/](https://mpi4py.readthedocs.io/en/stable/).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py`库的完整参考可以在[https://mpi4py.readthedocs.io/en/stable/](https://mpi4py.readthedocs.io/en/stable/)找到。'
- en: Implementing point-to-point communication
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现点对点通信
- en: Point-to-point operations consist of the exchange of messages between two processes.
    In a perfect world, every sending operation would be perfectly synchronized with
    the respective reception operation. Obviously, this is not the case, and the MPI
    implementation must be able to preserve the data sent when the sender and recipient
    processes are not synchronized. Typically, this occurs using a buffer, which is
    transparent to the developer and entirely managed by the `mpi4py` library.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 点对点操作包括两个进程之间的消息交换。在一个完美的世界中，每个发送操作都会与相应的接收操作完美同步。显然，这不是这种情况，MPI实现必须能够保留发送者和接收者进程不同步时发送的数据。通常，这会使用一个缓冲区来实现，该缓冲区对开发者来说是透明的，并且完全由`mpi4py`库管理。
- en: 'The `mpi4py` Python module enables point-to-point communication via two functions:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py` Python模块通过两个函数启用点对点通信：'
- en: '`Comm.Send(data, process_destination)`: This function sends data to the destination
    process identified by its rank in the communicator group.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Comm.Send(data, process_destination)`：此函数将数据发送到由通信器组中其rank标识的目标进程。'
- en: '`Comm.Recv(process_source)`: This function receives data from the sourcing process,
    which is also identified by its rank in the communicator group.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Comm.Recv(process_source)`：此函数从源进程接收数据，该源进程也在通信器组中通过其rank进行标识。'
- en: The `Comm` parameter, which is short for *communicator*, defines the group of
    processes that may communicate through message passing using `comm = MPI.COMM_WORLD`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`Comm`参数，简称*通信器*，定义了可能通过消息传递进行通信的进程组，即`comm = MPI.COMM_WORLD`。'
- en: How to do it...
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'In the following example, we will utilize the `comm.send` and `comm.recv` directives
    to exchange messages between different processes:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将利用`comm.send`和`comm.recv`指令在不同进程之间交换消息：
- en: 'Import the relevant `mpi4py` library:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关的`mpi4py`库：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, we define the communicator parameter, namely `comm`, through the `MPI.COMM_WORLD`
    statement:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过`MPI.COMM_WORLD`语句定义通信器参数，即`comm`：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `rank` parameter is used to identify the process itself:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rank`参数用于标识进程本身：'
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'It is useful to print out the `rank` of a process:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出进程的`rank`是有用的：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, we start considering the rank of the process. In this case, for the process
    of `rank` equal to `0`, we set `destination_process` and `data` (in this case
    `data = 10000000`) to be sent:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们开始考虑进程的rank。在这种情况下，对于rank等于`0`的进程，我们将`destination_process`和`data`（在这种情况下`data
    = 10000000`）设置为要发送的内容：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, by using the `comm.send` statement, the data that was previously set
    is sent to the destination process:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过使用`comm.send`语句，将之前设置的数据发送到目标进程：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'For the process of `rank` equal to `1`, the `destination_process` value is
    `8`, while the data to be sent is the `"hello"` string:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`rank`等于`1`的进程，`destination_process`的值是`8`，而要发送的数据是`"hello"`字符串：
- en: '[PRE15]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The process of `rank` equal to `4` is a receiver process. Indeed, the source
    process (that is, the process of `rank` equal to `0`) is set as a parameter in
    the `comm.recv` statement:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rank`等于`4`的进程是一个接收进程。确实，源进程（即`rank`等于`0`的进程）被设置为`comm.recv`语句中的参数：'
- en: '[PRE16]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, using the following code, the data received from the process of `0` must
    be displayed:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下代码，必须显示从`0`进程接收到的数据：
- en: '[PRE17]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The last process to be set is number `9`. Here, we define the source process
    of `rank` equal to `1` as a parameter in the `comm.recv` statement:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后设置的进程编号是`9`。在这里，我们将`rank`等于`1`的源进程定义为`comm.recv`语句中的参数：
- en: '[PRE18]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `data1` value is then printed:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后打印`data1`值：
- en: '[PRE19]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How it works...
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'We ran the example with a total number of processes equal to `9`. So, in the `comm` communicator
    group, we have nine tasks that can communicate with each other:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用总共`9`个进程的数量运行了示例。因此，在`comm`通信器组中，我们有九个可以相互通信的任务：
- en: '[PRE20]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Also, to identify a task or processes inside the group, we use their `rank` value:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了在组内识别任务或进程，我们使用它们的`rank`值：
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We have two sender processes and two receiver processes. The process of `rank`
    equal to `0` sends numerical data to the receiver process of `rank` equal to `4`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两个发送进程和两个接收进程。`rank`等于`0`的进程向`rank`等于`4`的接收进程发送数值数据：
- en: '[PRE22]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Similarly, we must specify the receiver process of `rank` equal to `4`. We
    also note that the `comm.recv` statement must contain, as an argument, the rank
    of the sender process:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们必须指定`rank`等于`4`的接收进程。我们还注意到，`comm.recv`语句必须包含发送进程的`rank`作为参数：
- en: '[PRE23]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: For the other sender and receiver processes (the process of `rank` equal to
    `1` and the process of `rank` equal to `8`, respectively), the situation is the
    same, the only difference being the type of data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他发送者和接收进程（`rank`等于`1`的进程和`rank`等于`8`的进程），情况相同，唯一的区别是数据类型。
- en: 'In this case, for the sender process, we have a string that is to be sent:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，对于发送进程，我们有一个要发送的字符串：
- en: '[PRE24]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'For the receiver process of `rank` equal to `8`, the rank of the sender process
    is pointed out:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`rank`等于`8`的接收进程，指出发送进程的`rank`：
- en: '[PRE25]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following diagram summarizes the point-to-point communication protocol
    in `mpi4py`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了`mpi4py`中的点对点通信协议：
- en: '![](img/c92bb67f-1f34-4624-9dd7-9907f38c32e1.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c92bb67f-1f34-4624-9dd7-9907f38c32e1.png)'
- en: The send/receive transmission protocol
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 发送/接收传输协议
- en: As you can see, it describes a two-step process, consisting of sending some **DATA**from
    one task (*sender*) and another task (*receiver*) receiving this data. The sending
    task must specify the data to be sent and its destination (the *receiver *process), while
    the receiving task has to specify the source of the message to be received.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，它描述了一个两步过程，包括从一项任务（*发送者*）发送一些**数据**，另一项任务（*接收者*）接收这些数据。发送任务必须指定要发送的数据及其目的地（*接收者*进程），而接收任务必须指定要接收的消息的来源。
- en: 'To run the script, we shall use `9` processes:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行脚本，我们将使用`9`个进程：
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This is the output that you''ll get after you run the script:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在运行脚本后你将得到的输出：
- en: '[PRE27]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: There's more...
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'The `comm.send()` and `comm.recv()` functions are blocking functions, which
    means that they block the caller until the buffered data involved can be used safely.
    Also, in MPI, there are two management methods of sending and receiving messages:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`comm.send()`和`comm.recv()`函数是阻塞函数，这意味着它们会阻塞调用者，直到涉及的数据缓冲区可以安全使用。此外，在MPI中，有两种发送和接收消息的管理方法：'
- en: '**Buffered mode**: The flow control returns to the program as soon as the data
    to be sent has been copied to a buffer. This does not mean that the message is
    sent or received.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓冲模式**：一旦要发送的数据被复制到缓冲区，流量控制就会返回程序。这并不意味着消息已被发送或接收。'
- en: '**Synchronous mode**: The function only gets terminated when the corresponding
    `receive` function begins receiving the message.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**同步模式**：函数只有在相应的`receive`函数开始接收消息时才会终止。'
- en: See also
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: An interesting tutorial on this topic can be found at [https://github.com/antolonappan/MPI_tutorial](https://github.com/antolonappan/MPI_tutorial).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[https://github.com/antolonappan/MPI_tutorial](https://github.com/antolonappan/MPI_tutorial)找到关于这个主题的有趣教程。
- en: Avoiding deadlock problems
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免死锁问题
- en: A common problem we face is deadlock. This is a situation where two (or more)
    processes block each other and wait for the other to perform a certain action
    that serves another and vice versa. The `mpi4py` module doesn't provide any specific
    functionality to resolve the deadlock problem, but there are some measures that
    the developer must follow in order to avoid the problem of deadlock.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们面临的一个常见问题是死锁。这是一种情况，其中两个（或更多）进程互相阻塞并等待对方执行某些动作，这些动作服务于对方，反之亦然。`mpi4py`模块不提供任何特定功能来解决死锁问题，但开发者必须遵循一些措施以避免死锁问题。
- en: How to do it...
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s first analyze the following Python code, which will introduce a typical
    deadlock problem. We have two processes—`rank` equal to `1` and `rank` equal to
    `5`—that communicate with each other and both have the data sender and data receiver
    functionalities:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先分析以下Python代码，它将介绍一个典型的死锁问题。我们有两个进程——`rank`等于`1`和`rank`等于`5`——它们相互通信，并且都具有数据发送和数据接收的功能：
- en: 'Import the `mpi4py` library:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`mpi4py`库：
- en: '[PRE28]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Define the communicator as `comm` and the `rank` parameter:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义通信器为`comm`和`rank`参数：
- en: '[PRE29]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The process of `rank` equal to `1` sends and receives data from the process of
    `rank` equal to `5`:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rank`等于`1`的进程从`rank`等于`5`的进程发送和接收数据：'
- en: '[PRE30]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In the same way, here, we define the process of `rank` equal to `5`:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，这里我们定义`rank`等于`5`的进程：
- en: '[PRE31]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The destination and sender processes are equal to `1`:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标和发送进程等于`1`：
- en: '[PRE32]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: How it works...
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'If we try to run this program (it makes sense to execute it with only two processes),
    then we note that none of the two processes can proceed:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试运行这个程序（只有两个进程执行是有意义的），那么我们会注意到两个进程中的任何一个都无法继续：
- en: '[PRE33]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Both the processes prepare to receive a message from the other and get stuck
    there. This happens because of the `comm.recv()` MPI function and the `comm.send()` MPI
    blocking them. This means that the calling process awaits their completion. As
    for the `comm.send()` MPI, the completion occurs when the data has been sent and
    may be overwritten without modifying the message.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 两个进程都准备从另一个进程接收消息，并卡在那里。这是因为`comm.recv()` MPI函数和`comm.send()` MPI函数阻止了它们。这意味着调用进程等待它们的完成。至于`comm.send()`
    MPI，完成发生在数据已发送并且可能被覆盖而不修改消息时。
- en: 'The completion of the `comm.recv()` MPI instead occurs when the data has been
    received and can be used. To solve this problem, the first idea is to invert the
    `comm.recv()` MPI with the `comm.send()` MPI, as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，`comm.recv()` MPI的完成是在数据被接收并可以使用时发生的。为了解决这个问题，第一个想法是将`comm.recv()` MPI与`comm.send()`
    MPI进行反转，如下所示：
- en: '[PRE34]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This solution, even if correct, does not guarantee that we will avoid deadlock.
    In fact, communication is performed through a buffer with the instruction of `comm.send()`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案，即使正确，也不能保证我们避免死锁。事实上，通信是通过带有`comm.send()`指令的缓冲区进行的。
- en: 'MPI copies the data to be sent. This mode works without problems, but only
    if the buffer is able to keep them all. If this does not happen, then there is
    a deadlock: the sender cannot finish sending the data because the buffer is busy,
    and the receiver cannot receive data because it is blocked by the `comm.send()` MPI
    call, which has not yet completed.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: MPI将待发送的数据复制到缓冲区。这种模式在没有问题的情况下工作，但仅当缓冲区能够保存所有数据时。如果这种情况没有发生，那么就会出现死锁：发送者无法完成发送数据，因为缓冲区正忙，接收者无法接收数据，因为它被`comm.send()`
    MPI调用阻塞，而这个调用尚未完成。
- en: 'At this point, the solution that allows us to avoid deadlocks is used to swap
    the sending and receiving functions so as to make them asymmetrical:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，允许我们避免死锁的解决方案是用来交换发送和接收函数，使它们不对称：
- en: '[PRE35]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, we get the correct output:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们得到正确的输出：
- en: '[PRE36]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: There's more...
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The solution proposed to the deadlock is not the only solution.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的解决死锁的方案并非唯一方案。
- en: 'There is, for example, a function that unifies the single call that sends a
    message to a given process and receives another message that comes from another
    process. This function is called `Sendrecv`:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，有一个函数可以将发送消息到给定进程的单个调用和接收来自另一个进程的消息的另一个调用统一。这个函数被称为`Sendrecv`：
- en: '[PRE37]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As you can see, the required parameters are the same as the `comm.send()`  and `comm.recv()` MPI
    (in this case, also the function blocks). However, `Sendrecv` offers the advantage
    of leaving the communication subsystem responsible for checking the dependencies
    between sending and receiving, thus avoiding the deadlock.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，所需的参数与`comm.send()`和`comm.recv()`MPI相同（在这种情况下，也是函数阻塞）。然而，`Sendrecv`提供了优势，即让通信子系统负责检查发送和接收之间的依赖关系，从而避免死锁。
- en: 'In this way, the code of the previous example becomes the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式，上一个示例的代码变为以下内容：
- en: '[PRE38]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: See also
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: An interesting analysis of how parallel programming is difficult due to deadlock
    management can be found at [https://codewithoutrules.com/2017/08/16/concurrency-python/](https://codewithoutrules.com/2017/08/16/concurrency-python/).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[https://codewithoutrules.com/2017/08/16/concurrency-python/](https://codewithoutrules.com/2017/08/16/concurrency-python/)找到关于由于死锁管理而使并行编程变得困难的有趣分析。
- en: Collective communication using a broadcast
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用广播进行集体通信
- en: During the development of parallel code, we often find ourselves in a situation
    where we must share, between multiple processes, the value of a certain variable
    at runtime or certain operations on variables that each process provides (presumably
    with different values).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行代码的开发过程中，我们经常发现自己处于必须在不同进程之间共享运行时某个变量的值或每个进程提供的变量上的某些操作（可能具有不同的值）的情况。
- en: To resolve these types of situations, communication trees are used (for example,
    process 0 sends data to the processes 1 and 2, which will, respectively, take
    care of sending them to processes 3, 4, 5, 6, and so on).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些类型的情况，使用通信树（例如，进程0向进程1和2发送数据，它们将分别负责将数据发送到进程3、4、5、6等等）。
- en: 'Instead, MPI libraries provide functions that are ideal for the exchange of
    information or the use of multiple processes that are clearly optimized for the
    machine in which they are performed:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，MPI库提供了理想的信息交换或使用多个进程的函数，这些函数明显针对它们运行的机器进行了优化：
- en: '![](img/48fa28e4-27d9-4ee6-981e-3c72d22b1c27.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/48fa28e4-27d9-4ee6-981e-3c72d22b1c27.png)'
- en: Broadcasting data from process 0 to processes 1, 2, 3, and 4
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 从进程0向进程1、2、3和4广播数据
- en: A communication method that involves all the processes that belong to a communicator
    is called a collective communication. Consequently, collective communication generally
    involves more than two processes. However, instead of this, we will call the collective
    communication broadcast, wherein a single process sends the same data to any other
    process.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及到属于通信器的所有进程的通信方法称为集体通信。因此，集体通信通常涉及超过两个进程。然而，我们将这种集体通信称为广播，其中单个进程将相同的数据发送到任何其他进程。
- en: Getting ready
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The `mpi4py` broadcast functionalities are offered by the following method:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py`的广播功能由以下方法提供：'
- en: '[PRE39]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This function sends the information contained in the message process root to
    every other process that belongs to the `comm` communicator.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将消息进程根中包含的信息发送到属于`comm`通信器的每个其他进程。
- en: How to do it...
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s now see an example in which we''ve used the `broadcast` function. We
    have a root process of `rank` equal to `0` that shares its own data, `variable_to_share`,
    with the other processes defined in the communicator group:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一个例子，我们使用了`broadcast`函数。我们有一个`rank`等于`0`的根进程，它将自己的数据`variable_to_share`与其他在通信器组中定义的进程共享：
- en: 'Let''s import the `mpi4py` library:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入`mpi4py`库：
- en: '[PRE40]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, let''s define the communicator and the `rank` parameter:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们定义通信器和`rank`参数：
- en: '[PRE41]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'As far as the process of `rank` equal to `0` is concerned, we define the variable
    to be shared among the other processes:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`rank`等于`0`的进程而言，我们定义要与其他进程共享的变量：
- en: '[PRE42]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Finally, we define a broadcast, having the `rank` process equal to zero as
    its `root`:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们定义一个广播，其`rank`进程等于零作为其`root`：
- en: '[PRE43]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: How it works...
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The root process of `rank` equal to `0` instantiates a variable, `variable_to_share`,
    which is equal to `100`. This variable will be shared with the other processes
    of the communication group:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`rank`等于`0`的根进程实例化一个变量`variable_to_share`，其值为`100`。这个变量将与其他通信组的进程共享：'
- en: '[PRE44]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'To perform this, we also introduce the broadcast communication statement:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行此操作，我们还引入了广播通信语句：
- en: '[PRE45]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Here, the parameters in the function are as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，函数中的参数如下：
- en: The data to be shared (`variable_to_share`).
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要共享的数据（`variable_to_share`）。
- en: The root process, that is, the process of rank equal to 0 (`root=0`).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根进程，即排名等于 0 的进程（`root=0`）。
- en: 'Running the code, we have a communication group of 10 processes, and `variable_to_share` is
    shared between the other processes in the group. Finally, the `print` statement
    visualizes the rank of the running process and the value of its variable:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码后，我们有一个包含 10 个进程的通信组，并且 `variable_to_share` 在组内的其他进程之间共享。最后，`print` 语句可视化运行进程的排名及其变量的值：
- en: '[PRE46]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'After setting `10` processes, the output obtained is as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 `10` 个进程后，得到的输出如下：
- en: '[PRE47]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: There's more...
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: Collective communication allows simultaneous data transmission between multiple
    processes in a group. The `mpi4py` library provides collective communications,
    but only in the blocking version (that is, it blocks the caller method until the
    buffered data involved can safely be used).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 集体通信允许组内多个进程之间同时进行数据传输。`mpi4py` 库提供了集体通信功能，但仅提供阻塞版本（即，它将调用方法阻塞，直到涉及的数据缓冲区可以安全使用）。
- en: 'The most commonly used collective communication operations are as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的集体通信操作如下：
- en: Barrier synchronization across the group's processes
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组内进程的屏障同步
- en: 'Communication functions:'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通信函数：
- en: Broadcasting data from one process to all processes in the group
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从一个进程向组内所有进程广播数据
- en: Gathering data from all processes to one process
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从所有进程收集数据到一个进程
- en: Scattering data from one process to all processes
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从一个进程向所有进程散射数据
- en: Reduction operations
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚合操作
- en: See also
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to this link ([https://nyu-cds.github.io/python-mpi/](https://nyu-cds.github.io/python-mpi/))
    to find a complete introduction to Python and MPI.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅此链接 ([https://nyu-cds.github.io/python-mpi/](https://nyu-cds.github.io/python-mpi/))
    以找到 Python 和 MPI 的完整介绍。
- en: Collective communication using the scatter function
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 `scatter` 函数进行集体通信
- en: 'The scatter functionality is very similar to a scatter broadcast, but with
    one major difference: while `comm.bcast` sends the same data to all listening
    processes, `comm.scatter` can send chunks of data in an array to different processes.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`scatter` 功能与散射广播非常相似，但有一个主要区别：虽然 `comm.bcast` 向所有监听进程发送相同的数据，但 `comm.scatter`
    可以将数组中的数据块发送到不同的进程。'
- en: 'The following diagram illustrates the scatter functionality:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示说明了 `scatter` 功能：
- en: '![](img/7a6e8b54-06df-43d5-ad30-aa1221ae3f85.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7a6e8b54-06df-43d5-ad30-aa1221ae3f85.png)'
- en: Scattering data from process 0 to processes 1, 2, 3, and 4
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 从进程 0 向进程 1、2、3 和 4 散射数据
- en: 'The **`comm.scatter`** function takes the elements of the array and distributes
    them to the processes according to their rank, for which the first element will
    be sent to process 0, the second element to process 1, and so on. The function
    implemented in **`mpi4py`** is as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '**`comm.scatter`** 函数将数组的元素分配给进程，根据它们的排名进行分配，其中第一个元素将被发送到进程 0，第二个元素发送到进程 1，依此类推。在
    **`mpi4py`** 中实现的功能如下：'
- en: '[PRE48]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: How to do it...
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'In the following example, we''ll see how to distribute data to different processes
    using the `scatter` functionality:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将看到如何使用 `scatter` 功能将数据分配给不同的进程：
- en: 'Import the `mpi4py` library:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `mpi4py` 库：
- en: '[PRE49]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Next, we define the `comm` and `rank` parameters in the usual way:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们以通常的方式定义 `comm` 和 `rank` 参数：
- en: '[PRE50]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'For the process of `rank` equal to `0`, the following array will be scattered:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 `rank` 等于 `0` 的进程，以下数组将被散射：
- en: '[PRE51]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then, `recvbuf` is set. The `root` process is the process of `rank` equal to `0`:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，设置 `recvbuf`。`root` 进程是 `rank` 等于 `0` 的进程：
- en: '[PRE52]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: How it works...
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The process of `rank` equal to `0` distributes the `array_to_share` data structure
    to other processes:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`rank` 等于 `0` 的进程将 `array_to_share` 数据结构分配给其他进程：'
- en: '[PRE53]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The `recvbuf` parameter indicates the value of the *i^(th)* variable that will
    be sent to the process through the `comm.scatter` statement:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`recvbuf` 参数表示将通过 `comm.scatter` 语句发送到进程的 *i^(th)* 变量的值：'
- en: '[PRE54]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output is as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE55]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We also remark that one of the restrictions to `comm.scatter` is that you can
    scatter as many elements as the processors you specify in the execution statement.
    In fact, if you attempt to scatter more elements than the processors specified
    (three, in this example), then you will get an error similar to the following:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还指出，`comm.scatter` 的一个限制是您可以将与执行语句中指定的处理器数量（在这个例子中是三个）一样多的元素进行散射。实际上，如果您尝试散射比指定的处理器数量更多的元素（在这个例子中是三个），那么您将得到类似于以下错误的错误：
- en: '[PRE56]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: There's more...
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: 'The `mpi4py` library provides two other functions that are used to scatter
    data:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py` 库提供了另外两个用于分散数据的函数：'
- en: '`comm.scatter(sendbuf, recvbuf, root=0)`: This function sends data from one
    process to all other processes in a communicator.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.scatter(sendbuf, recvbuf, root=0)`: 此函数将数据从一个进程发送到通信器中的所有其他进程。'
- en: '`comm.scatterv(sendbuf, recvbuf, root=0)`: This function scatters data from
    one process to all other processes in a given group that provide a different amount
    of data and displacements at the sending side.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.scatterv(sendbuf, recvbuf, root=0)`: 此函数将数据从给定组中的一个进程分散到所有其他提供不同数据量和位移的进程。'
- en: 'The `sendbuf` and `recvbuf` arguments must be given in terms of a list (as
    in the `comm.send` point-to-point function):'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '`sendbuf` 和 `recvbuf` 参数必须以列表的形式给出（如 `comm.send` 点对点函数中所示）：'
- en: '[PRE57]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Here, `data` must be a buffer-like object of the `data_size` size and of the `data_type` type.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`data` 必须是 `data_size` 大小和 `data_type` 类型的缓冲区对象。
- en: See also
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: An interesting tutorial on MPI broadcasting is presented at [https://pythonprogramming.net/mpi-broadcast-tutorial-mpi4py/](https://pythonprogramming.net/mpi-broadcast-tutorial-mpi4py/).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [https://pythonprogramming.net/mpi-broadcast-tutorial-mpi4py/](https://pythonprogramming.net/mpi-broadcast-tutorial-mpi4py/)
    提供了一个关于 MPI 广播的有趣教程。
- en: Collective communication using the gather function
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 gather 函数进行集体通信
- en: The `gather` function performs the inverse of the `scatter` function. In this
    case, all processes send data to a root process that collects the data received.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '`gather` 函数执行 `scatter` 函数的逆操作。在这种情况下，所有进程将数据发送到一个收集接收到的数据的根进程。'
- en: Getting ready
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The `gather` function, which is implemented in `mpi4py`, is as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `mpi4py` 中实现的 `gather` 函数如下：
- en: '[PRE58]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Here, `sendbuf` is the data that is sent, and `rank_of_root_process` represents
    the processing of the receiver of all the data:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`sendbuf` 是发送的数据，`rank_of_root_process` 代表接收所有数据的接收进程：
- en: '![](img/3fc357c4-5541-4c15-94f4-2dd7bee64b9b.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3fc357c4-5541-4c15-94f4-2dd7bee64b9b.png)'
- en: Gathering data from processes 1, 2, 3, and 4
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 从进程 1、2、3 和 4 收集数据
- en: How to do it...
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'In the following example, we''ll represent the condition shown in the preceding
    diagram, in which each process builds its own data, which is to be sent to the
    root processes that are identified with the `rank` zero:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将表示前面图中所示的条件，其中每个进程构建自己的数据，这些数据将被发送到以 `rank` 零标识的根进程：
- en: 'Type the necessary import:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入必要的导入：
- en: '[PRE59]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Next, we define the following three parameters. The `comm` parameter is the
    communicator, `rank` provides the rank of the process, and `size` is the total
    number of processes:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义以下三个参数。`comm` 参数是通信器，`rank` 提供进程的排名，`size` 是进程的总数：
- en: '[PRE60]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Here, we define the data to be gathered from the process of `rank` zero:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们定义从 `rank` 零的进程收集的数据：
- en: '[PRE61]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Finally, the gathering is provided through the `comm.gather` function. Also,
    note that the root process (the process that will gather the data from the other
    ones) is the zero rank process:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，通过 `comm.gather` 函数提供收集。注意，根进程（将收集其他进程数据的进程）是零排名进程：
- en: '[PRE62]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'For the `rank` equal to the `0` process, the data gathered and the sending
    process are printed out:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 `rank` 等于 `0` 的进程，收集的数据和发送进程将被打印出来：
- en: '[PRE63]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: How it works...
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The root process of `0` receives data from the other four processes, as represented
    in the previous diagram.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`0` 的根进程从其他四个进程接收数据，如前图所示。'
- en: 'We set *n (= 5)* processes sending their data:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设置了 *n*（= 5）个进程发送他们的数据：
- en: '[PRE64]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'If the `rank` of the process is `0`, then the data is collected in an array:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 如果进程的 `rank` 为 `0`，则数据将收集到一个数组中：
- en: '[PRE65]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The gathering of data is given, instead, by the following function:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集由以下函数给出：
- en: '[PRE66]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Finally, we run the code setting the group of processes equal to `5`:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们运行代码，将进程组设置为 `5`：
- en: '[PRE67]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: There's more...
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'To collect data, `mpi4py` provides the following functions:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 要收集数据，`mpi4py` 提供以下函数：
- en: Gathering to one task*:* `comm.Gather`, `comm.Gatherv`, and `comm.gather`
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向一个任务收集：`comm.Gather`、`comm.Gatherv` 和 `comm.gather`
- en: 'Gathering to all tasks: `comm.Allgather`, `comm.Allgatherv`, and `comm.allgather`'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向所有任务收集：`comm.Allgather`、`comm.Allgatherv` 和 `comm.allgather`
- en: See also
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: More information on `mpi4py` can be found at [http://www.ceci-hpc.be/assets/training/mpi4py.pdf](http://www.ceci-hpc.be/assets/training/mpi4py.pdf).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于 `mpi4py` 的信息可以在 [http://www.ceci-hpc.be/assets/training/mpi4py.pdf](http://www.ceci-hpc.be/assets/training/mpi4py.pdf)
    找到。
- en: Collective communication using Alltoall
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Alltoall 进行集体通信
- en: The `Alltoall` collective communication combines the `scatter` and `gather`
    functionalities.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`Alltoall` 集体通信结合了 `scatter` 和 `gather` 功能。'
- en: How to do it...
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In the following example, we''ll see an `mpi4py` implementation of `comm.Alltoall`.
    We''ll consider a communicator a group of processes, where each process sends
    and receives an array of numerical data from the other processes defined in the
    group:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将看到`mpi4py`对`comm.Alltoall`的实现。我们将通信者视为一组进程，其中每个进程从组中定义的其他进程发送和接收数值数据数组：
- en: 'For this example, the relevant `mpi4py` and `numpy` libraries must be imported:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于这个示例，必须导入相关的 `mpi4py` 和 `numpy` 库：
- en: '[PRE68]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'As in the previous example, we need to set the same parameters, `comm`, `size`,
    and `rank`:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与前一个示例一样，我们需要设置相同的参数，`comm`、`size` 和 `rank`：
- en: '[PRE69]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Hence, we must define the data that each process will send (`senddata`) and,
    at the same time, receive (`recvdata`) from the other processes:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们必须定义每个进程将发送的数据（`senddata`）以及同时从其他进程接收的数据（`recvdata`）：
- en: '[PRE70]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Finally, the `Alltoall` function is executed:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，执行 `Alltoall` 函数：
- en: '[PRE71]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The data that is sent and received for each process is displayed:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个进程发送和接收的数据显示如下：
- en: '[PRE72]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: How it works...
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `comm.alltoall` method takes the *i^(th)* object from the `sendbuf` argument
    of task `j` and copies it into the *j^(th)* object of the `recvbuf` argument of
    task `i`.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '`comm.alltoall` 方法将任务 `j` 的 `sendbuf` 参数的 *i*^(th) 对象复制到任务 `i` 的 `recvbuf`
    参数的 *j*^(th) 对象中。'
- en: 'If we run the code with a communicator group of `5` processes, then our output
    is as follows:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以 `5` 进程的通信者组运行代码，那么我们的输出如下：
- en: '[PRE73]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'We could also figure out what happened by using the following schema:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以通过以下模式来找出发生了什么：
- en: '![](img/ae2c13f2-c674-4f5e-a05b-bf8982a010bd.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ae2c13f2-c674-4f5e-a05b-bf8982a010bd.png)'
- en: The Alltoall collective communication
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: Alltoall 集体通信
- en: 'Our observations regarding the schema are as follows:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对模式的观察如下：
- en: The *P0* process contains the [**0 1 2 3 4**]  data array, where it assigns
    0 to itself, 1 to the *P1 *process, 2 to the *P2 *process, 3 to the *P3 *process,
    and 4 to the *P4 *process;
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P0* 进程包含 [**0 1 2 3 4**] 数据数组，其中它将 0 分配给自己，1 分配给 *P1* 进程，2 分配给 *P2* 进程，3 分配给
    *P3* 进程，并将 4 分配给 *P4* 进程；'
- en: The *P1* process contains the [**0 2 4 6 8**] data array, where it assigns 0
    to the *P0 *process, 2 to itself, 4 to the *P2 *process, 6 to the *P3 *process,
    and 8 to the *P4 *process;
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P1* 进程包含 [**0 2 4 6 8**] 数据数组，其中它将 0 分配给 *P0* 进程，2 分配给自己，4 分配给 *P2* 进程，6 分配给
    *P3* 进程，并将 8 分配给 *P4* 进程；'
- en: The *P2* process contains the [**0 3 6 9 12**] data array, where it assigns
    0 to the *P0 *process, 3 to the *P1 *process, 6 to itself, 9 to the *P3 *process, and
    12 to the *P4 *process;
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P2* 进程包含 [**0 3 6 9 12**] 数据数组，其中它将 0 分配给 *P0* 进程，3 分配给 *P1* 进程，6 分配给自己，9
    分配给 *P3* 进程，并将 12 分配给 *P4* 进程；'
- en: The *P3* process contains the [**0 4 8 12 16**] data array, where it assigns
    0 to the *P0 *process, 4 to the *P1 *process, 8 to the *P2* process, 12 to itself,
    and 16 to the *P4 *process;
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P3* 进程包含 [**0 4 8 12 16**] 数据数组，其中它将 0 分配给 *P0* 进程，4 分配给 *P1* 进程，8 分配给 *P2*
    进程，12 分配给自己，并将 16 分配给 *P4* 进程；'
- en: The *P4* process contains the [**0 5 10 15 20**] data array, where it assigns
    0 to the *P0* process, 5 to the *P1 *process, 10 to the *P2 *process, 15 to the
    *P3 *process, and 20 to itself.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P4* 进程包含 [**0 5 10 15 20**] 数据数组，其中它将 0 分配给 *P0* 进程，5 分配给 *P1* 进程，10 分配给 *P2*
    进程，15 分配给 *P3* 进程，并将 20 分配给自己。'
- en: There's more...
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: '`Alltoall` personalized communication is also known as a total exchange. This
    operation is used in a variety of parallel algorithms, such as the fast Fourier
    transform, matrix transpose, sample sort, and some parallel database join operations.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '`Alltoall` 个性化通信也称为完全交换。这种操作用于各种并行算法，如快速傅里叶变换、矩阵转置、样本排序以及一些并行数据库连接操作。'
- en: 'In `mpi4py`, there are *three types* of `Alltoall` collective communication:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `mpi4py` 中，有三种类型的 `Alltoall` 集体通信：
- en: '`comm.Alltoall(sendbuf, recvbuf)`: The `Alltoall` scatter/gather sends data
    from all-to-all processes in a group.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.Alltoall(sendbuf, recvbuf)`: `Alltoall` 散射/收集将数据从组中的所有进程发送到所有进程。'
- en: '`comm.Alltoallv(sendbuf, recvbuf)`: The `Alltoall` scatter/gather vector sends
    data from all-to-all processes in a group, providing a different amount of data
    and displacements.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.Alltoallv(sendbuf, recvbuf)`: `Alltoall` 散射/收集向量将数据从组中的所有进程发送到所有进程，提供不同数量的数据和位移。'
- en: '`comm.Alltoallw(sendbuf, recvbuf)`: Generalized `Alltoall` communication allows
    different counts, displacements, and datatypes for each partner.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.Alltoallw(sendbuf, recvbuf)`: 扩展的 `Alltoall` 通信允许每个伙伴有不同的计数、位移和数据类型。'
- en: See also
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: An interesting analysis of MPI Python modules can be downloaded from [https://www.duo.uio.no/bitstream/handle/10852/10848/WenjingLinThesis.pdf](https://www.duo.uio.no/bitstream/handle/10852/10848/WenjingLinThesis.pdf).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从 [https://www.duo.uio.no/bitstream/handle/10852/10848/WenjingLinThesis.pdf](https://www.duo.uio.no/bitstream/handle/10852/10848/WenjingLinThesis.pdf)
    下载对 MPI Python 模块的有意思的分析。
- en: The reduction operation
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 归约操作
- en: Similar to `comm.gather`, `comm.reduce` takes an array of input elements in
    each process and returns an array of output elements to the root process. The
    output elements contain the reduced result.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `comm.gather` 类似，`comm.reduce` 在每个进程中接收一个输入元素数组，并将一个输出元素数组返回给根进程。输出元素包含归约结果。
- en: Getting ready
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In `mpi4py`, we define the reduction operation through the following statement:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `mpi4py` 中，我们通过以下语句定义归约操作：
- en: '[PRE74]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We must note that the difference with the `comm.gather` statement resides in
    the `op` parameter, which is the operation that you wish to apply to your data,
    and the `mpi4py` module contains a set of reduction operations that can be used.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须注意，与 `comm.gather` 语句的区别在于 `op` 参数，这是你希望应用于你的数据的操作，而 `mpi4py` 模块包含一组可以使用的归约操作。
- en: How to do it...
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Now, we'll see how to implement the sum of an array of elements with the `MPI.SUM` reduction
    operation by using the reduction functionality. Each process will manipulate an
    array of size 10.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将通过使用归约功能来实现使用 `MPI.SUM` 归约操作对元素数组求和的方法。每个进程将操作大小为 10 的数组。
- en: 'For array manipulation, we use the functions provided by the `numpy` Python
    module:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数组操作，我们使用 `numpy` Python 模块提供的函数：
- en: 'Here, the relevant libraries, `mpi4py` and `numpy`, are imported:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，导入了相关的库，`mpi4py` 和 `numpy`：
- en: '[PRE75]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Define the `comm`, `size`, and `rank` parameters:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 `comm`、`size` 和 `rank` 参数：
- en: '[PRE76]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Then, the size of the array (`array_size`) is set:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，设置数组的大小 (`array_size`)：
- en: '[PRE77]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The data to be sent and received is defined:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义了要发送和接收的数据：
- en: '[PRE78]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The process sender and the sent data are printed out:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出进程发送者和发送的数据：
- en: '[PRE79]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Finally, the `Reduce` operation is executed. Note that the `root` process is set
    to `0` and the `op` parameter is set to `MPI.SUM`:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，执行 `Reduce` 操作。请注意，`root` 进程设置为 `0`，`op` 参数设置为 `MPI.SUM`：
- en: '[PRE80]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'The output of the reduction operation is then shown, as follows:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 归约操作的输出如下所示：
- en: '[PRE81]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: How it works...
  id: totrans-345
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'To perform the reduction sum, we use the `comm.Reduce` statement. Also, we
    identify with `rank` zero, which is the `root` process that will contain `recvbuf`,
    which represents the final result of the computation:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行求和操作，我们使用 `comm.Reduce` 语句。同时，我们以 `rank` 零的身份识别，这是包含 `recvbuf` 的 `root` 进程，它代表计算的最终结果：
- en: '[PRE82]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: It makes sense to run the code with a communicator group of `10` processes,
    as this is the size of the manipulated array.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `10` 进程的通信器组运行代码是有意义的，因为这正是操作数组的尺寸。
- en: 'The output appears as follows:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE83]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: There's more...
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Note that with the `op=MPI.SUM` option, we apply the sum operation to all the
    elements of the column array. To better understand how the reduction operates,
    let''s look at the following diagram:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，使用 `op=MPI.SUM` 选项时，我们对列数组的所有元素应用求和操作。为了更好地理解归约操作的工作原理，让我们看一下以下图表：
- en: '![](img/aa28bcc1-08cf-4699-b559-9f4f1e6e948c.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/aa28bcc1-08cf-4699-b559-9f4f1e6e948c.png)'
- en: Reduction in collective communication
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 集体通信中的归约
- en: 'The sending operation is as follows:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 发送操作如下：
- en: The **P0** process sends the [**0 1 2**] data array.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P0** 进程发送了 [**0 1 2**] 数据数组。'
- en: The **P1** process sends the [**0 2 4**] data array.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P1** 进程发送了 [**0 2 4**] 数据数组。'
- en: The **P2** process sends the [**0 3 6**] data array.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P2** 进程发送了 [**0 3 6**] 数据数组。'
- en: The reduction operation sums the *i^(th)* elements of each task and then puts
    the result in the *i^(th)* element of the array in the **P0** root process. For
    the receiving operation, the **P0** process receives the [**0 6 12**] data array.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 归约操作将每个任务的 *i^(th)* 元素相加，然后将结果放入 **P0** 根进程数组的 *i^(th)* 元素中。对于接收操作，**P0** 进程接收
    [**0 6 12**] 数据数组。
- en: 'Some of the reduction operations defined by MPI are as follows:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: MPI 定义的一些归约操作如下：
- en: '`MPI.MAX`: This returns the maximum element.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.MAX`：返回最大元素。'
- en: '`MPI.MIN`: This returns the minimum element.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.MIN`：返回最小元素。'
- en: '`MPI.SUM`: This sums up the elements.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.SUM`：将元素相加。'
- en: '`MPI.PROD`: This multiplies all elements.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.PROD`：将所有元素相乘。'
- en: '`MPI.LAND`: This performs the AND logical operation across the elements.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.LAND`：对元素执行 AND 逻辑操作。'
- en: '`MPI.MAXLOC`: This returns the maximum value and the rank of the process that
    owns it.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.MAXLOC`: 该函数返回最大值及其所属进程的排名。'
- en: '`MPI.MINLOC`: This returns the minimum value and the rank of the process that
    owns it.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.MINLOC`: 该函数返回最小值及其所属进程的排名。'
- en: See also
  id: totrans-368
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: At [http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/](http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/),
    you can find a good tutorial on this topic and much more.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 在[http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/](http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/)，你可以找到关于这个主题以及更多内容的良好教程。
- en: Optimizing communication
  id: totrans-370
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化通信
- en: An interesting feature that is provided by MPI regards virtual topologies. As
    already noted, all the communication functions (point-to-point or collective)
    refer to a group of processes. We have always used the `MPI_COMM_WORLD` group
    that includes all processes. It assigns a rank of *0* to *n-1* for each process
    that belongs to a communicator of the size *n*.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: MPI提供的一个有趣特性是虚拟拓扑。如前所述，所有通信函数（点对点或集体）都指的是一组进程。我们一直使用包含所有进程的`MPI_COMM_WORLD`组。它为每个属于大小为*n*的通信器的进程分配从*0*到*n-1*的排名。
- en: 'However, MPI allows us to assign a virtual topology to a communicator. It defines
    an assignment of labels to the different processes: by building a virtual topology,
    each node will communicate only with its virtual neighbor, improving performance
    because it reduces execution times.'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，MPI允许我们将虚拟拓扑分配给通信器。它定义了对不同进程的标签分配：通过构建虚拟拓扑，每个节点将只与其虚拟邻居通信，从而提高性能，因为它减少了执行时间。
- en: For example, if the rank was randomly assigned, then a message could be forced
    to pass to many other nodes before it reaches the destination. Beyond the question
    of performance, a virtual topology makes sure that the code is clearer and more
    readable.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果排名是随机分配的，那么消息可能需要在到达目的地之前强制通过许多其他节点。除了性能问题之外，虚拟拓扑确保代码更清晰、更易读。
- en: MPI provides two building topologies. The first construct creates Cartesian
    topologies, while the latter creates any kind of topologies. Specifically, in
    the second case, we must supply the adjacency matrix of the graph that you want
    to build. We will only deal with Cartesian topologies, through which it is possible
    to build several structures that are widely used, such as mesh, ring, and toroid.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: MPI提供了两种构建拓扑的方法。第一种结构创建笛卡尔拓扑，而后者创建任何类型的拓扑。具体来说，在第二种情况下，我们必须提供你想要构建的图的邻接矩阵。我们只处理笛卡尔拓扑，通过它可以构建许多广泛使用的结构，如网格、环形和环面。
- en: 'The `mpi4py` function used to create a Cartesian topology is as follows:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建笛卡尔拓扑的`mpi4py`函数如下：
- en: '[PRE84]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Here, `number_of_rows` and `number_of_columns` specify the rows and columns
    of the grid that is to be made.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`number_of_rows`和`number_of_columns`指定了要制作的网格的行和列。
- en: How to do it...
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'In the following example, we see how to implement a Cartesian topology of the
    size *M×N*. Also, we define a set of coordinates to understand how all the processes
    are disposed of:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们展示了如何实现大小为*M×N*的笛卡尔拓扑。我们还定义了一组坐标以了解所有进程是如何排列的：
- en: 'Import all the relevant libraries:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有相关库：
- en: '[PRE85]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Define the following parameter in order to move along the topology:'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义以下参数以在拓扑中移动：
- en: '[PRE86]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'For each process, the following array defines the neighbor processes:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个进程，以下数组定义了相邻进程：
- en: '[PRE87]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'In the `main` program, the `comm.rank` and `size` parameters are then defined:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`main`程序中，定义了`comm.rank`和`size`参数：
- en: '[PRE88]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Now, let''s build the topology:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们构建拓扑：
- en: '[PRE89]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The following conditions ensure that the processes are always within the topology:'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下条件确保进程始终在拓扑内：
- en: '[PRE90]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The `rank` equal to `0` process starts the topology construction:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rank`等于`0`的进程开始拓扑构建：'
- en: '[PRE91]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: How it works...
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'For each process, the output should read as follows: if `neighbour_processes
    = -1`, then it has no topological proximity, otherwise, `neighbour_processes`
    shows the rank of the process closely.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个进程，输出应如下所示：如果`neighbour_processes = -1`，则它没有拓扑邻近性，否则，`neighbour_processes`显示与进程紧密相关的排名。
- en: 'The resulting topology is a mesh of *2*×*2* (refer to the previous diagram
    for a mesh representation), the size of which is equal to the number of processes
    in the input; that is, four:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 结果拓扑是一个*2*×*2*的网格（参考前面的图以了解网格表示），其大小等于输入中的进程数；即四个：
- en: '[PRE92]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Then, the Cartesian topology is built using the `comm.Create_cart` function
    (note also the parameter, `periods = (False,False)`):'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用`comm.Create_cart`函数构建笛卡尔拓扑（注意参数，`periods = (False,False)`）：
- en: '[PRE93]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'To know the position of the process, we use the `Get_coords()` method in the
    following form:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 要知道进程的位置，我们使用以下形式的`Get_coords()`方法：
- en: '[PRE94]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'For the processes, in addition to getting their coordinates, we must calculate
    and find out which processes are topologically closer. For this purpose, we use
    the `comm.Shift (rank_source,rank_dest)` function:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 对于进程，除了获取它们的坐标外，我们还必须计算并找出哪些进程在拓扑上更接近。为此，我们使用`comm.Shift (rank_source,rank_dest)`函数：
- en: '[PRE95]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The topology obtained is as follows:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 获得的拓扑结构如下：
- en: '![](img/f716b5dc-9c4c-4e31-9fc3-b128b439f010.png)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f716b5dc-9c4c-4e31-9fc3-b128b439f010.png)'
- en: The virtual mesh 2x2 topology
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟网格2x2拓扑
- en: As the diagram shows, the *P0* process is chained to the **P1** `(RIGHT)` and
    **P2** `(DOWN)` processes. The **P1** process is chained to the **P3** `(DOWN)`
    and **P0** `(LEFT)` processes, the **P3** process is chained to the **P1** `(UP)`
    and **P2** `(LEFT)` processes, and the **P2** process is chained to the **P3**
    `(RIGHT)` and **P0** `(UP)` processes.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，进程*P0*被连接到**P1** `(RIGHT)`和**P2** `(DOWN)`进程。**P1**进程被连接到**P3** `(DOWN)`和**P0**
    `(LEFT)`进程，**P3**进程被连接到**P1** `(UP)`和**P2** `(LEFT)`进程，**P2**进程被连接到**P3** `(RIGHT)`和**P0**
    `(UP)`进程。
- en: 'Finally, by running the script, we obtain the following result:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过运行脚本，我们获得了以下结果：
- en: '[PRE96]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: There's more...
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'To obtain a toroidal topology of the size *M*×*N*, let''s use `comm.Create_cart`
    again, but, this time, let''s set the `periods` parameter to `periods=(True,True)`:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得大小为*M*×*N*的环面拓扑，让我们再次使用`comm.Create_cart`，但这次，让我们将`periods`参数设置为`periods=(True,True)`：
- en: '[PRE97]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'The following output is obtained:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 获得了以下输出：
- en: '[PRE98]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The output covers the topology represented here:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 输出覆盖了此处表示的拓扑：
- en: '![](img/0de01d9b-fe04-43f0-9700-68e7955534b8.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0de01d9b-fe04-43f0-9700-68e7955534b8.png)'
- en: The virtual toroidal 2x2 topology
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟的2x2环面拓扑
- en: The topology represented in the previous diagram indicates that the **P0** process
    is chained to the **P1** (`RIGHT` and `LEFT`) and **P2** (`UP` and `DOWN`) processes,
    the **P1** process is chained to the **P3** (`UP` and `DOWN`) and **P0** (`RIGHT`
    and `LEFT`) processes, the **P3** process is chained to the **P1** (`UP` and `DOWN`)
    and **P2** (`RIGHT` and `LEFT`) processes, and the **P2** process is chained to the
    **P3** (`LEFT` and `RIGHT`) and **P0** (`UP` and `DOWN`) processes.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张图中表示的拓扑表明，**P0**进程被连接到**P1**（`RIGHT`和`LEFT`）和**P2**（`UP`和`DOWN`）进程，**P1**进程被连接到**P3**（`UP`和`DOWN`）和**P0**（`RIGHT`和`LEFT`）进程，**P3**进程被连接到**P1**（`UP`和`DOWN`）和**P2**（`RIGHT`和`LEFT`）进程，**P2**进程被连接到**P3**（`LEFT`和`RIGHT`）和**P0**（`UP`和`DOWN`）进程。
- en: See also
  id: totrans-419
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: More information on MPI can be found at [http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-topo.html](http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-topo.html).
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于MPI的信息可以在[http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-topo.html](http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-topo.html)找到。
