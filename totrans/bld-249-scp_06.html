<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Shape Keys, IPOs, and Poses</h1></div></div></div><p>We already encountered IPOs in <a class="link" href="ch04.html" title="Chapter 4. Pydrivers and Constraints">Chapter 4</a>, <em>Pydrivers and Constraints</em> when we discussed Pydrivers, but there is more to IPOs than just driving one <strong>IPO</strong> by another one. For example, the Blender API provides us with the means to define IPOs from scratch, enabling the definition of movements not easily re-created by setting key frames by hand. Furthermore, some types of IPOs have a somewhat different behavior than the ones that we encountered so far. <strong>Shape keys</strong> and <strong>poses</strong> are examples of (collections of) IPOs that are quite different from, for example, a location IPO. We will encounter both shape keys and poses later on in this chapter, but we will start off with looking at how we might define an IPO from scratch.</p><p>In this chapter, you will learn how to:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Define IPOs</li><li class="listitem" style="list-style-type: disc">Define shape keys on a mesh</li><li class="listitem" style="list-style-type: disc">Define IPOs for those shape keys</li><li class="listitem" style="list-style-type: disc">Pose armatures</li><li class="listitem" style="list-style-type: disc">Group changes in poses into actions</li></ul></div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec49"/>A touchy subject—defining an IPO from scratch</h1></div></div></div><a class="indexterm" id="id370"/><p>Many paths of motion of objects are hard to model by hand, for example, when we want the object to follow a precise mathematical curve or if we want to coordinate the movement of multiple objects in a way that is not easily accomplished by copying IPOs or defining IPO drivers.</p><p>Imagine the following scenario: we want to interchange the position of some objects over the duration of some time in a fluid way without those objects passing through each other in the middle and without even touching each other. This would be doable by manually setting keys perhaps, but also fairly cumbersome, especially if we would want to repeat this for several sets of objects. The script that we will devise takes care of all of those details and can be applied to any two objects.</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec63"/>Code outline: orbit.py</h2></div></div></div><a class="indexterm" id="id371"/><a class="indexterm" id="id372"/><p>The <code class="literal">orbit.py</code> script that we will design will take the following steps:</p><div><ol class="orderedlist arabic"><li class="listitem">Determine the halfway point between the selected objects.</li><li class="listitem">Determine the extent of the selected objects.</li><li class="listitem">Define IPO for object one.</li><li class="listitem">Define IPO for object two.</li></ol></div><p>Determining the halfway point between the selected objects is easy enough: we will just take the average location of both objects. Determining the extent of the selected objects is a little bit more challenging though. An object may have an irregular shape and determining the shortest distance for any rotation of the objects along the path that the object will be taking is difficult to calculate. Fortunately, we can make a reasonable approximation, as each object has an associated <strong>bounding</strong> <strong>box</strong><a class="indexterm" id="id373"/>
<strong>.</strong>
</p><p>This bounding box is a rectangular box that just encapsulates all of the points of an object. If we take half the body diagonal as the extent of an object, then it is easy to see that this distance may be an exaggeration of how close we can get to another object without touching, depending on the exact form of the object. But it will ensure that we never get too close. This bounding box is readily available from an object's <code class="literal">getBoundBox()</code> method<a class="indexterm" id="id374"/> as a list of eight vectors, each representing one of the corners of the bounding box. The concept is illustrated in the following figure where the bounding boxes of two spheres are shown:</p><div><img alt="Code outline: orbit.py" src="img/0400-06-01.jpg"/></div><p>The length of the body diagonal of a bounding box can be calculated by determining both the maximum and minimum values for each x, y, and z coordinate. The components of the vector representing this body diagonal are the differences between these maximums and minimums. The length of the diagonal is subsequently obtained by taking the square root of the sum of squares of the x, y, and z components. The function <code class="literal">diagonal()</code><a class="indexterm" id="id375"/> is a rather terse implementation as it uses many built-in functions of Python. <a class="indexterm" id="id376"/>
<a class="indexterm" id="id377"/>It takes a list of vectors as an argument and then iterates over each component (highlighted. x, y, and z components of a Blender <code class="literal">Vector</code> may be accessed as 0, 1, and 2 respectively):</p><div><pre class="programlisting">def diagonal(bb):
   maxco=[]
   minco=[]
<strong>   for i in range(3):</strong>
      maxco.append(max(b[i] for b in bb))
      minco.append(min(b[i] for b in bb))
   return sqrt(sum((a-b)**2 for a,b in zip(maxco,minco)))</pre></div><p>It determines the extremes for each component by using the built-in <code class="literal">max()</code> and <code class="literal">min()</code> functions<a class="indexterm" id="id378"/>. Finally, it returns the length by pairing each minimum and maximum by using the <code class="literal">zip()</code> function.<a class="indexterm" id="id379"/>
<a class="indexterm" id="id380"/>
</p><p>The next step is to verify that we have exactly two objects selected and inform the user if this isn't the case by drawing a pop up (highlighted in the next code snippet). If we do have two objects selected, we retrieve their locations and bounding boxes. Then we calculate the maximum distance <code class="literal">w</code> each object has to veer from its path to be half the minimum distance between them, which is equal to a quarter of the sum of the lengths of the body diagonals of those objects:</p><div><pre class="programlisting">obs=Blender.Scene.GetCurrent().objects.selected

if len(obs)!=2:
<strong>   Draw.PupMenu('Please select 2 objects%t|Ok')</strong>
else:
   loc0 = obs[0].getLocation()
   loc1 = obs[1].getLocation()
   
   bb0 = obs[0].getBoundBox()
   bb1 = obs[1].getBoundBox()
   
   w = (diagonal(bb0)+diagonal(bb1))/4.0</pre></div><p>Before we can calculate the trajectories of both objects, we first create two new and empty Object IPOs:</p><div><pre class="programlisting">   ipo0 = Ipo.New('Object','ObjectIpo0')
   ipo1 = Ipo.New('Object','ObjectIpo1')</pre></div><a class="indexterm" id="id381"/><a class="indexterm" id="id382"/><p>We arbitrarily choose the start and end frames of our swapping operation to be 1 and 30 respectively, but the script could easily be adapted to prompt the user for these values. We iterate over each separate IPO curve for the <code class="literal">Location</code> IPO and create the first point (or key frame) and thereby the actual curve by assigning a tuple <code class="literal">(framenumber,</code> <code class="literal">value)</code> to the curve (highlighted lines of the next code). Subsequent points may be added to these curves by indexing them by frame number when assigning a value, as is done for frame 30 in the following code:</p><div><pre class="programlisting">   for i,icu in enumerate((Ipo.OB_LOCX,Ipo.OB_LOCY,Ipo.OB_LOCZ)):
<strong>      ipo0[icu]=(1,loc0[i])</strong>
      ipo0[icu][30]=loc1[i]
      
<strong>      ipo1[icu]=(1,loc1[i])</strong>
      ipo1[icu][30]=loc0[i]

      ipo0[icu].interpolation = IpoCurve.InterpTypes.BEZIER
      ipo1[icu].interpolation = IpoCurve.InterpTypes.BEZIER</pre></div><p>Note that the location of the first object keyframed at frame 1 is its current location and the location keyframed at frame 30 is the location of the second object. For the other object this is just the other way around. We set the interpolation modes of these curves to "Bezier" to get a smooth motion. We now have two IPO curves that do interchange the location of the two objects, but as calculated they will move right through each other.</p><a class="indexterm" id="id383"/><a class="indexterm" id="id384"/><p>Our next step therefore is to add a key at frame 15 with an adjusted z-component. Earlier, we calculated <code class="literal">w</code> to hold half the distance needed to keep out of each other's way. Here we add this distance to the z-component of the halfway point of the first object and subtract it for the other:</p><div><pre class="programlisting">   mid_z = (loc0[2]+loc1[2])/2.0
   ipo0[Ipo.OB_LOCZ][15] = mid_z + w
   ipo1[Ipo.OB_LOCZ][15] = mid_z - w</pre></div><p>Finally, we add the new IPOs to our objects:</p><div><pre class="programlisting">obs[0].setIpo(ipo0)
obs[1].setIpo(ipo1)</pre></div><p>The full code is available as <code class="literal">swap2.py</code> in the file <code class="literal">orbit.blend</code>. The resulting paths of the two objects are sketched in the next screenshot:</p><div><img alt="Code outline: orbit.py" src="img/0400-06-02.jpg"/></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec50"/>A lot to swallow—defining poses</h1></div></div></div><a class="indexterm" id="id385"/><p>Many cartoon characters seem to have difficulties trying to swallow their food, and even if they did enjoy a relaxing lunch, chances are they will be forced through a rain pipe too small to fit comfortably for no apparent reason.</p><p>It is difficult to animate swallowing or any other <strong>peristaltic movement</strong><a class="indexterm" id="id386"/> by using shape keys as it is not the shape of the overall mesh that changes in a uniform way: we want to move along a localized deformation. One way of doing that is to associate an armature consisting of a linear chain of bones with the mesh that we want to deform (shown in the illustration) and animate the scale of each individual bone in time. This way, we can control the movement of the 'lump' inside to a great extent. It is, for example, possible to make the movement a little bit halting as it moves from bone to bone to simulate something that is hard to swallow.</p><div><img alt="A lot to swallow—defining poses" src="img/0400-06-03.jpg"/></div><p>In order to synchronize the scaling of the individual bones in a way that follows the chain from parent to child, we have to sort our bones because the <code class="literal">bones</code> attribute<a class="indexterm" id="id387"/> of the <code class="literal">Pose</code> object that we get when calling <code class="literal">getPose()</code><a class="indexterm" id="id388"/> on an armature is a dictionary. Iterating over the keys or values of this dictionary will return those values in random order.</p><a class="indexterm" id="id389"/><p>Therefore, we define a function <code class="literal">sort_by_parent()</code><a class="indexterm" id="id390"/> that will take a list of <code class="literal">Pose</code> bones <code class="literal">pbones</code> and will return a list of strings, each the name of a <code class="literal">Pose</code> bone. The list is sorted with the parent as the first item followed by its children. Obviously, this will not return a meaningful list for armatures that have bones with more than one child, but for our linear chain of bones it works fine.</p><a class="indexterm" id="id391"/><p>In the following code, we maintain a list of names called <code class="literal">bones</code> that hold the names of the <code class="literal">Pose</code> bones in the correct order. We pop the list of <code class="literal">Pose</code> bones and add the name of the <code class="literal">Pose</code> bone as long as it is not already added (highlighted). We compare names instead of <code class="literal">Pose</code> bone objects because the current implementation of <code class="literal">Pose</code> bones does not reliably implement the <code class="literal">in</code> operator:</p><div><pre class="programlisting">def sort_by_parent(pbones):
   bones=[]
   if len(pbones)&lt;1 : return bones
   bone = pbones.pop(0)
<strong>   while(not bone.name in bones):</strong>
      bones.append(bone.name)</pre></div><p>We then get the parent of the bone that we just added to our list, and as long as we can traverse the chain of parents, we insert this parent (or rather its name) in our list in front of the current item (highlighted below). If the chain cannot be followed anymore we pop a new <code class="literal">Pose</code> bone. When there are no bones left, an <code class="literal">IndexError</code> exception is raised by the pop() method and we will exit our <code class="literal">while</code>-<code class="literal">loop</code>:</p><div><pre class="programlisting">      parent = bone.parent
      while(parent):
         if not parent.name in bones:
<strong>            bones.insert(bones.index(bone.name),parent.name)</strong>
         parent = parent.parent
         bone = parent
      try:
         bone = pbones.pop(0)
      except IndexError:
         break
   return bones</pre></div><p>The next step is to define the script itself. First, we get the active object in the current scene and verify if it is indeed an armature. If not, we alert the user with a pop up (highlighted part of the following code), otherwise we proceed and get the associated armature data with the <code class="literal">getData()</code> method<a class="indexterm" id="id392"/>:</p><div><pre class="programlisting">scn = Blender.Scene.GetCurrent()

arm = scn.objects.active

if arm.getType()!='Armature':
<strong>   Blender.Draw.PupMenu("Selected object is not an Armature%t|Ok")</strong>
else:
   adata = arm.getData()</pre></div><p>Then, we make the armature editable and make sure that each bone has the <code class="literal">HINGE</code> option set (highlighted). The business with the conversion of the list of options to a set and back again to a list once we added the <code class="literal">HINGE</code> option is a way to ensure that the option appears only once in the list.</p><div><pre class="programlisting">   adata.makeEditable()
   for ebone in adata.bones.values():
<strong>      ebone.options =list(set(ebone.options)|set([Blender.Armature.HINGE]))</strong>
   adata.update()</pre></div><a class="indexterm" id="id393"/><p>A pose is associated with an armature object, not with its data, so we get it from <code class="literal">arm</code> by using the <code class="literal">getPose()</code> method. Bone poses are very much like ordinary IPOs but they have to be associated with an <strong>action</strong> that groups those poses. When working interactively with the Blender an action gets created automatically once we insert a key frame on a pose, but in a script we have to create an action explicitly if it is not present already (highlighted):</p><div><pre class="programlisting">   pose = arm.getPose()
   action = arm.getAction()
<strong>   if not action:</strong>
      action = Blender.Armature.NLA.NewAction()
      action.setActive(arm)</pre></div><p>The next step is to sort the <code class="literal">Pose</code> bones as a chain of parenthood by using our previously defined function. What is left is to step along the frames in steps of ten at a time and set keys on the scale of each bone at each step, scaling up if the sequence number of the bone matches our step and resetting it if it doesn't. One of the resulting IPOs is shown in the screenshot. Note that by our setting the <code class="literal">HINGE</code> attribute<a class="indexterm" id="id394"/> on each bone previously, we prevent the scaling to propagate to the children of the bone:</p><div><pre class="programlisting">   bones = sort_by_parent(pose.bones.values())
   
   for frame in range(1,161,10):
      index = int(frame/21)-1
      n = len(bones)
      for i,bone in enumerate(bones):
         if i == index :
            size = 1.3
         else :
            size = 1.0
         pose.bones[bone].size=Vector(size,size,size)
         pose.bones[bone].insertKey(arm,frame,Blender.Object.Pose.SIZE)</pre></div><p>The full code is available as <code class="literal">peristaltic.py</code> in <code class="literal">peristaltic.blend</code>.</p><div><img alt="A lot to swallow—defining poses" src="img/0400-06-04.jpg"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec64"/>Application of peristaltic.py to an armature</h2></div></div></div><a class="indexterm" id="id395"/><a class="indexterm" id="id396"/><p>To use this script you will have to run it with an armature object selected. One recipe to show its application would be the following:</p><div><ol class="orderedlist arabic"><li class="listitem">Add an armature to a scene.</li><li class="listitem">Go to <em>edit</em> mode and extrude any number of bones from the tip of the first bone.</li><li class="listitem">Go to <em>object</em> mode and add a mesh centered on the position of the armature. Any mesh will do but for our illustration we use a cylinder with plenty of subdivisions.</li><li class="listitem">Select the mesh and then shift select the armature. Both armature and <code class="literal">Mesh</code> object are now selected while the armature is the active object.</li><li class="listitem">Press <em>Ctrl + P</em> and select <strong>armature</strong>. In next pop up, select <strong>Create from bone heat</strong>. That will create a vertex group on the mesh for each bone in the armature. These vertex groups will be used to deform the mesh when we associate the armature as a modifier with the mesh.</li><li class="listitem"><a class="indexterm" id="id397"/>Select the mesh and add an armature modifier. Type the name of the armature in the <strong>Ob:</strong> field and make sure that the <strong>Vert.Group</strong> toggle is selected and <strong>Envelopes</strong> is not.</li><li class="listitem">Select the armature and run the <code class="literal">peristaltic.py</code>.</li></ol></div><p>The result will be an animated <code class="literal">Mesh</code> object resembling a lump passing through a narrow flexible pipe. A few frames are shown in the illustration:</p><div><img alt="Application of peristaltic.py to an armature" src="img/0400-06-05.jpg"/></div><p>Rain pipes are of course not the only hollow objects fit for animating this way as shown in the following illustration:</p><div><img alt="Application of peristaltic.py to an armature" src="img/0400-06-06.jpg"/></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec51"/>Get down with the beat—syncing shape keys to sound</h1></div></div></div><p>Many a rock video today features an animation of speaker cones reverberating with the sound of the music. And although the features for the manipulation of <strong>sound</strong> in the Blender API are rather sparse, we will see that this effect is rather simple to achieve.</p><a class="indexterm" id="id398"/><p>The animation that we will construct depends mainly on the manipulation of <strong>shape keys</strong>. Shape keys can be understood as distortions of a base mesh. A mesh can have many of these distortions and each of them is given a distinct name. The fun part is that Blender provides us with the possibility to interpolate between the base shape and any of the distorted shapes in a continuous way, even allowing us to mix contributions from different shapes.</p><a class="indexterm" id="id399"/><p>One way to animate our speaker cone, for instance, is to model a basic, undistorted shape of the cone; add a shape key to this base mesh; and distort it to resemble a cone that is pushed outward. We can then blend between this "pop out" shape and the base's shape depending on the loudness of the sound.</p><p>Animating by setting key frames in Blender means creating IPOs and manipulating IPO curves as we have seen earlier. Indeed, <code class="literal">Shape</code> or <code class="literal">Key</code> IPOs are very similar to other kinds of IPOs and are manipulated very much in the same way. The main difference between for example an Object IPO and a Shape IPO is that the individual IPO curves of a Shape IPO are not indexed by some predefined numerical constant (such as <code class="literal">Ipo.OB_LOCX</code> for an Object) but by a string because the user may define any number of named shapes.</p><p>Also, a <code class="literal">Shape</code> IPO is not accessed via an Object but through its underlying <code class="literal">Mesh</code> object (or <code class="literal">Lattice</code> or <code class="literal">Curve</code>, as these may have shape keys as well).</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec65"/>Manipulating sound files</h2></div></div></div><a class="indexterm" id="id400"/><p>So now that we know how to animate shapes, our next goal is to find out how to add some sound to our mesh, or rather to determine at each frame how much the distorted shape should be visible.</p><p>As mentioned in the previous section, Blender's API does not provide many tools for manipulating sound files, Basically the <code class="literal">Sound</code> module<a class="indexterm" id="id401"/>
<a class="indexterm" id="id402"/> provides us with ways to load and play a sound file but that's as far as it gets. There is no way to access individual points of the waveform encoded in the file.</p><p>Fortunately, standard Python distributions come bundled with a <code class="literal">wave</code> module that provides us with the means to read files in the common <code class="literal">.wav</code> format. Although it supports only the uncompressed format, this will suffice as this format is very common and most audio tools, such as <strong>Audacity</strong><a class="indexterm" id="id403"/>, can convert to this format. With this module we can open a <code class="literal">.wav</code> file, determine the sample rate and duration of the sound clip, and access individual samples. As we will see in the explanation of the following code, we still have to convert these samples to values that we can use as key values for our shape keys but the heavy lifting is already done for us.</p><div><div><div><div><h3 class="title"><a id="ch06lvl3sec10"/>Code outline: Sound.py</h3></div></div></div><a class="indexterm" id="id404"/><a class="indexterm" id="id405"/><p>Armed with the knowledge on how to construct IPO curves and access <code class="literal">.wav</code> files, we might draw up the following code outline:</p><div><ol class="orderedlist arabic"><li class="listitem">Determine if the active object has suitable shapes defined and provide a choice.</li><li class="listitem">Let the user select a <code class="literal">.wav</code> file.</li><li class="listitem">Determine the number of sound samples per second present in the file.</li><li class="listitem">Calculate the number of animation frames needed based on the duration of the sound file and the video frame rate.</li><li class="listitem">Then, for each animation frame:<div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Average the sound samples occurring in this frame</li><li class="listitem" style="list-style-type: disc">Set the blend value of the chosen IPO curve to this (normalized) average</li></ul></div></li></ol></div><p>The full code is available as <code class="literal">Sound.py</code> in <code class="literal">sound000.blend</code> and explained as follows:</p><div><pre class="programlisting">import Blender
from Blender import Scene,Window,Draw
from Blender.Scene import Render
 
import struct
import wave</pre></div><p>We start off by importing the necessary modules including Python's <code class="literal">wave</code> module to access our <code class="literal">.wav</code> file and the <code class="literal">struct</code> module<a class="indexterm" id="id406"/> that provides functions to manipulate the actual binary data that we get from the <code class="literal">.wav</code> file.</p><p>Next, we define a utility function to pop up a menu in the middle of our screen. It behaves just like the regular <code class="literal">PupMenu()</code> function<a class="indexterm" id="id407"/> from the <code class="literal">Draw</code> module but sets the cursor to a position halfway across and along the screen with the help of the <code class="literal">GetScreenSize()</code><a class="indexterm" id="id408"/> and <code class="literal">SetMouseCoords()</code> function<a class="indexterm" id="id409"/>s from Blender's <code class="literal">Window</code> module:</p><div><pre class="programlisting">def popup(msg):
   (w,h)=Window.GetScreenSize()
   Window.SetMouseCoords(w/2,h/2)
   return Draw.PupMenu(msg)</pre></div><p>The bulk of the work will be done by the function <code class="literal">sound2active()</code><a class="indexterm" id="id410"/>. It will take two arguments—the filename of the <code class="literal">.wav</code> file to use and the name of the shape key to animate based on the information in the <code class="literal">.wav</code> file. First, we attempt to create a <code class="literal">WaveReader</code> object by calling the <code class="literal">open()</code> function<a class="indexterm" id="id411"/> of the <code class="literal">wave</code> module (highlighted). If this fails, we show the error in a pop up and quit:</p><div><pre class="programlisting">def sound2active(filename,shapekey='Pop out'):
   try:
<strong>      wr = wave.open(filename,'rb')</strong>
   except wave.Error,e:
      return popup(str(e)+'%t|Ok')</pre></div><p>Then we do some sanity checks: we first check if the <code class="literal">.wav</code> file is a <code class="literal">MONO</code> file. If you want to use a stereo file, convert it to mono first, for example with the free Audacity package (<a class="ulink" href="http://audacity.sourceforge.net/)">http://audacity.sourceforge.net/)</a>. Then we check if we are dealing with an uncompressed <code class="literal">.wav</code> file because the <code class="literal">wave</code> module cannot handle other types. (most <code class="literal">.wav</code>
<strong> </strong>files are uncompressed but if needed, Audacity can convert them as well) and we verify that the samples are 16-bits. If any of these checks fail, we pop up an appropriate error message:</p><div><pre class="programlisting">   c = wr.getnchannels()
   if c!=1 : return popup('Only mono files are supported%t|Ok')
   t = wr.getcomptype()
   w = wr.getsampwidth()
   if t!='NONE' or w!=2 : 
     return popup('Only 16-bit, uncompresses files are supported%t|Ok')</pre></div><p>Now that we can process the file, we get its <strong>frame</strong> <strong>rate</strong> (the number of audio samples per second) and the total number of bytes (oddly enough by using the awkwardly named function <code class="literal">getnframes()</code><a class="indexterm" id="id412"/> from the <code class="literal">wave</code> module). Then, we read all of these bytes and store them in the variable <code class="literal">b</code>.</p><div><pre class="programlisting">   fr= wr.getframerate()
   n = wr.getnframes()
   
   b = wr.readframes(n)</pre></div><p>Our next task is to get the rendering context from the current scene to retrieve the number of video frames per second. The number of seconds our animation will play is determined by the length of our audio sample, something we can calculate by dividing the total number of audio frames in the <code class="literal">.wav</code> file by the number of audio frames per second (highlighted in the following piece of code). We then define a constant <code class="literal">sampleratio</code>—the number of audio frames per video frame:</p><div><pre class="programlisting">   scn         = Scene.GetCurrent()
   context     = scn.getRenderingContext()
<strong>   seconds     = float(n)/fr</strong>
   sampleratio = fr/float(context.framesPerSec())</pre></div><p>As mentioned before, the <code class="literal">wave</code> module gives us access to a number of properties of a <code class="literal">.wav</code> file and the raw audio samples, but provides no functions to convert these raw samples to usable integer values. We therefore need to do this ourselves. Fortunately, this is not as hard as it may seem. Because we know that the 16-bit audio samples are present as 2 byte integers in the "little-endian" format, we can use the <code class="literal">unpack()</code> function<a class="indexterm" id="id413"/> from Python's <code class="literal">struct</code> module to efficiently convert the list of bytes to a list of integers by passing a fitting format specification. (You can read more about the way <code class="literal">.wav</code> files are laid out on <a class="ulink" href="https://ccrma.stanford.edu/courses/422/projects/WaveFormat/">https://ccrma.stanford.edu/courses/422/projects/WaveFormat/</a>.)</p><div><pre class="programlisting">   samples  = struct.unpack('&lt;%dh'%n,b)</pre></div><p>Now we can start animating the shape key. We get the start frame from the rendering context and calculate the end frame by multiplying the number of seconds in the <code class="literal">.wav</code>
<strong> </strong>file with the video frame rate. Note that this may be longer or shorter than the end frame that we may get from the rendering context. The latter determines the last frame that will get rendered when the user clicks on the <strong>Anim</strong> button, but we will animate the movement of our active object regardless of this value.</p><p>Then for each frame we calculate from start frame to end frame (exclusive) the average value of the audio samples that occur in each video frame by summing these audio samples (present in the <code class="literal">samples</code> list) and dividing them by the number of audio samples per video frame (highlighted in the next code snippet).</p><p>We will set the chosen shape key to a value in the range [0:1] so we will have to normalize the calculated averages by determining the minimum and maximum values and calculate a scale:</p><div><pre class="programlisting">   staframe = context.startFrame()
   endframe = int(staframe + seconds*context.framesPerSec())
   
   popout=[]
   for i in range(staframe,endframe):
<strong>      popout.append(sum(samples[int((i-1)*sampleratio):int(i*sampleratio)])/sampleratio)</strong>
   minvalue = min(popout)
   maxvalue = max(popout)
   scale = 1.0/(maxvalue-minvalue)</pre></div><p>Finally, we get the active object in the current scene and get its <code class="literal">Shape</code> IPO (highlighted). We conclude by setting the value of the shape key for each frame in the range we are considering to the scaled average of the audio samples:</p><div><pre class="programlisting">   ob=Blender.Scene.GetCurrent().objects.active
   
<strong>   ipo = ob.getData().getKey().getIpo()</strong>
   
   for i,frame in enumerate(range(staframe,endframe)):
      ipo[shapekey][frame]=(popout[i]-minvalue)*scale</pre></div><p>The remaining script itself is now rather simple. It fetches the active object and then tries to retrieve a list of shape key names from it (highlighted in the next part). This may fail (hence the <code class="literal">try … except</code> clause) if for example the active object is not a mesh or has no associated shape keys, in which case we alert the user with a pop up:</p><div><pre class="programlisting">if __name__ == "__main__":
   ob=Blender.Scene.GetCurrent().objects.active
   
   try:
<strong>      shapekeys = ob.getData().getKey().getIpo().curveConsts</strong>
      key = popup('Select a shape key%t|'+'|'.join(shapekeys))
      if key&gt;0:
<strong>          Window.FileSelector </strong>
<strong>         (lambda f:sound2active(f,shapekeys[key-1]), </strong>
<strong>         "Select a .wav file",</strong>
<strong>          Blender.Get('soundsdir'))</strong>
   except:
      popup('Not a mesh or no shapekeys defined%t|Ok')</pre></div><p>If we were able to retrieve a list of shape keys, we present the user with a pop-up menu to choose from this list. If the user selects one of the items, <code class="literal">key</code> will be positive and we present the user with a file selector dialog (highlighted). This file selector dialog is passed a <code class="literal">lambda</code> function that will be called if the user selects a file, passing the name of this selected file as an argument. In our case we construct this <code class="literal">lambda</code> function<a class="indexterm" id="id414"/> to call the <code class="literal">sound2active()</code> function<a class="indexterm" id="id415"/> defined previously with this filename and the selected shape key.</p><p>The initial directory that will be presented to the user in the file selector to pick a file from is determined by the last argument to the <code class="literal">FileSelector()</code> function<a class="indexterm" id="id416"/>. We set it to the contents of Blender's <code class="literal">soundsdir</code> parameter. This usually is <code class="literal">//</code> (that is, a relative path pointing to the same directory as the <code class="literal">.blend</code> file the user is working on) but may be set in the user preferences window (<strong>File</strong> <strong>Paths</strong> section) to something else.</p></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec66"/>Animating a mesh by a .wav file: the workflow</h2></div></div></div><a class="indexterm" id="id417"/><a class="indexterm" id="id418"/><p>Now that we have our <code class="literal">Sounds.py</code> script we can apply it as follows:<a class="indexterm" id="id419"/>
</p><div><ol class="orderedlist arabic"><li class="listitem"><a class="indexterm" id="id420"/><a class="indexterm" id="id421"/><a class="indexterm" id="id422"/><a class="indexterm" id="id423"/><a class="indexterm" id="id424"/><a class="indexterm" id="id425"/><a class="indexterm" id="id426"/><a class="indexterm" id="id427"/>Select a <code class="literal">Mesh</code> object.</li><li class="listitem">Add a "Basis" shape key to it (<strong>Buttons</strong> <strong>window</strong>, <strong>Editing</strong> <strong>context</strong>, <strong>Shapes</strong> <strong>panel</strong>). This will correspond to the least distorted shape of the mesh.</li><li class="listitem">Add a second shape key and give it a meaningful name.</li><li class="listitem">Edit this mesh to represent the most distorted shape.</li><li class="listitem">In <em>object</em> mode, run <code class="literal">Sound.py</code> from the text editor by pressing <em>Alt + P.</em></li><li class="listitem">Select the shape key name defined earlier (not the "Basis" one) from the pop up.</li><li class="listitem">Select the <code class="literal">.wav</code> file to apply.</li></ol></div><p>The result will be an object with an <code class="literal">IPOcurve</code> for the chosen shape key that will fluctuate according to the beat of the sound as shown in the next screenshot:</p><div><img alt="Animating a mesh by a .wav file: the workflow" src="img/0400-06-07.jpg"/></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec52"/>Summary</h1></div></div></div><p>In this chapter we saw how to associate shape keys with a mesh and how to add an IPO to animate transitions between those shape keys. Specifically, we learned how to:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Define IPOs</li><li class="listitem" style="list-style-type: disc">Define shape keys on a mesh</li><li class="listitem" style="list-style-type: disc">Define IPOs for those shape keys</li><li class="listitem" style="list-style-type: disc">Pose armatures</li><li class="listitem" style="list-style-type: disc">Group changes in poses into actions</li></ul></div><p>In the next chapter, we shall learn how to create custom textures and shaders.</p></div></body></html>