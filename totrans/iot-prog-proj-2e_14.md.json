["```py\n    mkdir -p Chapter14/images\n    ```", "```py\n    images subdirectory, we can run the following command:\n\n    ```", "```py\n    python -m venv ch14-env --system-site-packages\n    ```", "```py\n\n    ```", "```py\n    opencv-python library. We can install this library with the following Terminal command:\n\n    ```", "```py\n\n    ```", "```py\n    exit\n    ```", "```py\n    import cv2 as cv\n    img = cv.imread('images/Toronto.png')\n    cv.imshow('Downtown Toronto', img)\n    cv.waitKey(0)\n    cv.destroyAllWindows()\n    ```", "```py\n    import cv2\n    stream_url = '<<rtsp address>>'\n    cap = cv2.VideoCapture(stream_url)\n    if not cap.isOpened():\n        print(\"Error: Could not open stream\")\n        exit()\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            print(\"Error: Can't receive frame. Exiting ...\")\n            break\n        cv2.imshow('A.R.E.S. Stream', frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    cap.release()\n    cv2.destroyAllWindows()\n    ```", "```py\n    cd Chapter14\n    ```", "```py\n    coco.names, yolov4.cfg, and yolov4.weights files from the YOLO directory of this chapter’s GitHub repository to our local YOLO directory using whichever method suits us.\n    ```", "```py\n    import cv2\n    import numpy as np\n    ```", "```py\n    net = cv2.dnn.readNet(\"YOLO/yolov4.weights\", \"YOLO/yolov4.cfg\")\n    classes = []\n    layer_names = net.getLayerNames()\n    ```", "```py\n    output_layer_indices = net.getUnconnectedOutLayers()\n    ```", "```py\n    output_layers = [layer_names[i - 1] for i in output_layer_indices]\n    ```", "```py\n    with open(\"YOLO/coco.names\", \"r\") as f:\n        classes = [line.strip() for line in f.readlines()]\n    dog_class_id = classes.index(\"dog\")\n    ```", "```py\n    img = cv2.imread('images/dog.png')\n    img = cv2.resize(img, None, fx=0.4, fy=0.4)\n    height, width, channels = img.shape\n    ```", "```py\n    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0),\n    True, crop=False)\n    net.setInput(blob)\n    outs = net.forward(output_layers)\n    ```", "```py\n    class_ids = []\n    confidences = []\n    boxes = []\n    for out in outs:\n        for detect in out:\n            scores = detect[5:]\n            class_id = np.argmax(scores)\n            confidence = scores[class_id]\n            if confidence > 0.5 and class_id == dog_class_id:\n                center_x = int(detection[0] * width)\n                center_y = int(detection[1] * height)\n                w = int(detection[2] * width)\n                h = int(detection[3] * height)\n                x = int(center_x - w / 2)\n                y = int(center_y - h / 2)\n                boxes.append([x, y, w, h])\n                confidences.append(float(confidence))\n                class_ids.append(class_id)\n    ```", "```py\n    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,\n    0.4)\n    for i in indexes.flatten():\n        x, y, w, h = boxes[i]\n        label = str(classes[class_ids[i]])\n    cv2.rectangle(img, (x, y), (x + w, y + h), (0,\n    255, 0), 2)\n        cv2.putText(img, label, (x, y + 30),\n    cv2.FONT_HERSHEY_PLAIN, 3,\n    (0, 255, 0), 3)\n    ```", "```py\n    cv2.imshow(\"Image\", img)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n    ```", "```py\n    import cv2\n    import numpy as np\n    ```", "```py\n    class DogDetector:\n        def __init__(self, model_weights, model_cfg, class_file):\n            self.net = cv2.dnn.readNet(model_weights, model_cfg)\n            self.layer_names = self.net.getLayerNames()\n            output_layer_indices = self.net.getUnconnectedOutLayers()\n            if output_layer_indices.ndim == 1:\n                self.output_layers = [self.layer_names[\n    i - 1] for i in output_layer_indices]\n            else:\n                self.output_layers = [self.layer_names[\n    i[0] - 1] for i in output_layer_indices]\n            with open(class_file, \"r\") as f:\n                self.classes = [line.strip() for line in f.readlines()]\n            self.dog_class_id = self.classes.index(\"dog\")\n    ```", "```py\n       def detect_dogs(self, frame):\n            img_resized = cv2.resize(frame, None, fx=0.4, fy=0.4)\n            height, width, channels = img_resized.shape\n            dog_detected = False\n             blob = cv2.dnn.blobFromImage(img_resized, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n            self.net.setInput(blob)\n            outs = self.net.forward(self.output_layers)\n            class_ids = []\n            confidences = []\n            boxes = []\n            for out in outs:\n                for detection in out:\n                    scores = detection[5:]\n                    class_id = np.argmax(scores)\n                    confidence = scores[class_id]\n                    if confidence > 0.5 and class_id ==\n    self.dog_class_id:\n                        center_x = int(detection[0] * width)\n                        center_y = int(detection[1] * height)\n                        w = int(detection[2] * width)\n                        h = int(detection[3] * height)\n                        x = int(center_x - w / 2)\n                        y = int(center_y - h / 2)\n                        boxes.append([x, y, w, h])\n                        confidences.append(float(confidence))\n                        class_ids.append(class_id)\n            indexes = cv2.dnn.NMSBoxes(boxes, confidences,\n    0.5, 0.4)\n            if indexes is not None and len(indexes) > 0:\n                dog_detected = True\n                indexes = indexes.flatten()\n                for i in indexes:\n                    x, y, w, h = boxes[i]\n                    label = str(self.classes[class_ids[i]])\n                    cv2.rectangle(img_resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n                    cv2.putText(img_resized, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n            return img_resized, dog_detected\n    ```", "```py\n    import cv2\n    from DogDetector import DogDetector\n    import time\n    ```", "```py\n    detector = DogDetector(\"YOLO/yolov4.weights\", \"YOLO/yolov4.cfg\", \"YOLO/coco.names\")\n    stream_url = '<<rtsp address>>'\n    cap = cv2.VideoCapture(stream_url)\n    cv2.namedWindow(\"Dog Detector\", cv2.WINDOW_NORMAL)\n    cv2.resizeWindow(\"Dog Detector\", 800, 600)\n    last_time = time.time()\n    ```", "```py\n    try:\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break\n            current_time = time.time()\n            if current_time - last_time >= 1.0:  # 1.0 seconds\n                result_frame, dog_detected = detector.detect_dogs(frame)\n                last_time = current_time\n                cv2.imshow(\"Dog Detector\", result_frame)\n                if dog_detected:\n                    print('Dog detected!')\n            if cv2.waitKey(1) & 0xFF == ord('q'):\n                break\n    finally:\n        cap.release()\n        cv2.destroyAllWindows()\n    ```", "```py\n    pip install twilio\n    ```", "```py\n    from twilio.rest import Client\n    class TwilioMessage:\n        def __init__(self, account_sid, auth_token, from_number):\n            self.client = Client(account_sid, auth_token)\n            self.from_number = from_number\n        def send_sms(self, to_number, message):\n            sms = self.client.messages.create(\n                body=message,\n                from_=self.from_number,\n                to=to_number\n            )\n            print(f\"Message sent with SID: {sms.sid}\")\n    if __name__ == \"__main__\":\n        twilio_message = TwilioMessage(\n    ' account_sid', ' auth_token', '+twilio_number')\n        twilio_message.send_sms('+our_number', 'Hello from A.R.E.S.')\n    ```", "```py\n    import cv2\n    from DogDetector import DogDetector\n    from TwilioMessage import TwilioMessage\n    import time\n    detector = DogDetector(\"YOLO/yolov4.weights\", \"YOLO/yolov4.cfg\", \"YOLO/coco.names\")\n    twilio_message = TwilioMessage('account_sid', 'auth_token', '+twilio_number')\n    stream_url = '<<rtsp address>>'\n    cap = cv2.VideoCapture(stream_url)\n    cv2.namedWindow(\"Dog Detector\", cv2.WINDOW_NORMAL)\n    cv2.resizeWindow(\"Dog Detector\", 800, 600)\n    last_time = time.time()\n    try:\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break\n            # Check if 1 second has passed\n            current_time = time.time()\n            if current_time - last_time >= 5.0:\n                result_frame, dog_detected = detector.detect_dogs(frame)\n                last_time = current_time\n                cv2.imshow(\"Dog Detector\", result_frame)\n                if dog_detected:\n                    twilio_message.send_sms(' +phone_num', 'Dog(s) detected!')\n            if cv2.waitKey(1) & 0xFF == ord('q'):\n                break\n    finally:\n        cap.release()\n        cv2.destroyAllWindows()\n    ```"]