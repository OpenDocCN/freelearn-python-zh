- en: Heterogeneous Computing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异构计算
- en: This chapter will help us to explore the **Graphics Processing Unit** (**GPU**) programming
    techniques through the Python language. The continuous evolution of GPUs is revealing
    how these architectures can bring great benefits to performing complex calculations.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将帮助我们通过 Python 语言探索 **Graphics Processing Unit**（**GPU**）编程技术。GPU 的持续进化揭示了这些架构如何为执行复杂计算带来巨大好处。
- en: GPUs certainly cannot replace CPUs. However, they are a well-structured and
    heterogeneous code that is able to exploit the strengths of both types of processors
    that can, in fact, bring considerable advantages.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，GPU 不能取代 CPU。然而，它们是结构良好且异构的代码，能够利用两种处理器（实际上）的优势，从而带来相当大的优势。
- en: We will examine the main development environments for heterogeneous programming,
    namely, the **PyCUDA** and **Numba** environments for **Compute Unified Device
    Architecture** (**CUDA**) and **PyOpenCL** environments, which are for**Open Computing
    Language** (**OpenCL**) frameworks in their Python version.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将检查异构编程的主要开发环境，即用于 **Compute Unified Device Architecture**（**CUDA**）的 **PyCUDA**
    和 **Numba** 环境，以及用于 **Open Computing Language**（**OpenCL**）框架的 Python 版本的 **PyOpenCL**
    环境。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下食谱：
- en: Understanding heterogeneous computing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解异构计算
- en: Understanding the GPU architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 GPU 架构
- en: Understanding GPU programming
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 GPU 编程
- en: Dealing with PyCUDA
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理 PyCUDA
- en: Heterogeneous programming with PyCUDA
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 PyCUDA 进行异构编程
- en: Implementing memory management with PyCUDA
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 PyCUDA 实现内存管理
- en: Introducing PyOpenCL
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 PyOpenCL
- en: Building applications with PyOpenCL
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 PyOpenCL 构建应用程序
- en: Element-wise expressions with PyOpenCL
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 PyOpenCL 的元素级表达式
- en: Evaluating PyOpenCL applications
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估 PyOpenCL 应用程序
- en: GPU programming with Numba
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Numba 进行 GPU 编程
- en: Let's start with understanding heterogeneous computing in detail.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从详细了解异构计算开始。
- en: Understanding heterogeneous computing
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解异构计算
- en: Over the years, the search for better performance for increasingly complex calculations
    has led to the adoption of new techniques in the use of computers. One of these
    techniques is called *heterogeneous computing*, which aims to cooperate with different
    (or heterogeneous) processors in such a way as to have advantages (in particular)
    in terms of temporal computational efficiency.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，为了提高日益复杂的计算性能，人们采用了计算机使用的新技术。其中一种技术被称为 *异构计算*，其目的是以合作的方式与不同（或异构）的处理器协同工作，从而在时间计算效率方面具有优势（特别是）。
- en: In this context, the processor on which the main program is run (generally the
    CPU) is called the *h**ost*, while the coprocessors (for example, the GPUs) are
    called *d**evices*. The latter are generally physically separated from the host and
    manage their own memory space, which is also separated from the host's memory.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，运行主程序的处理器的（通常为 CPU）被称为 **主机**，而协处理器（例如 GPU）被称为 **设备**。后者通常与主机物理分离，并管理自己的内存空间，该空间也独立于主机的内存。
- en: In particular, following significant market demand, the GPU has evolved into
    a highly parallel processor, transforming the GPU from devices for graphics rendering to
    devices for parallelizable and computationally intensive general-purpose calculations.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是在显著的市场需求下，GPU 已经发展成为一个高度并行的处理器，将 GPU 从图形渲染设备转变为可并行化和计算密集型通用计算的设备。
- en: In fact, the use of GPU for tasks other than rendering graphics on the screen
    is called heterogeneous computing.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，将 GPU 用于屏幕渲染图形以外的任务被称为异构计算。
- en: Finally, the task of good GPU programming is to make the most of the great level
    of parallelism and mathematical capabilities offered by the graphics card, minimizing
    all the disadvantages presented by it, such as the delay of the physical connection
    between the host and device.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，良好的 GPU 编程任务是要充分利用图形卡提供的并行性和数学能力，同时最小化它所呈现的所有不利因素，例如主机和设备之间物理连接的延迟。
- en: Understanding the GPU architecture
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 GPU 架构
- en: A GPU is a specialized CPU/core for vector processing of graphical data to render
    images from polygonal primitives. The task of a good GPU program is to make the
    most of the great level of parallelism and mathematical capabilities offered by
    the graphics card and minimize all the disadvantages presented by it, such as
    the delay in the physical connection between the host and device.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 是一种专门用于图形数据处理以从多边形原语渲染图像的 CPU/core。一个好的 GPU 程序的任务是充分利用图形卡提供的并行性和数学能力，并最大限度地减少它所呈现的所有缺点，例如主机和设备之间物理连接的延迟。
- en: GPUs are characterized by a highly parallel structure that allows you to manipulate
    large datasets in an efficient manner. This feature is combined with rapid improvements
    in hardware performance programs, bringing the attention of the scientific world
    to the possibility of using GPUs for purposes other than just rendering images.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 以高度并行结构为特征，允许你以高效的方式操作大量数据集。这一特性与硬件性能程序的快速改进相结合，将科学界的注意力吸引到使用 GPU 进行除渲染图像之外的其他用途的可能性。
- en: 'A GPU (refer to the following diagram) is composed of several processing units
    called **Streaming Multiprocessors **(**SMs**), which represent the first logic
    level of parallelism. In fact, each SM works simultaneously and independently
    from the others:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: GPU（参见图表）由几个称为 **流多处理器**（**SMs**）的处理单元组成，它们代表了并行逻辑的第一级。实际上，每个 SM 都与其他 SM 同时独立工作：
- en: '![](img/12715105-d093-49e4-8e05-cdb976bc755c.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/12715105-d093-49e4-8e05-cdb976bc755c.png)'
- en: GPU architecture
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 架构
- en: Each SM is divided into a group of **Streaming Processors** (**SPs**), which
    have a core that can run a thread sequentially. The SP represents the smallest
    unit of execution logic and the level of finer parallelism.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 SM 被划分为一组 **流处理器**（**SPs**），它们有一个可以顺序运行线程的核心。SP 代表执行逻辑的最小单元和更细粒度的并行级别。
- en: In order to best program this type of architecture, we need to introduce GPU
    programming, which is described in the next section.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最好地编程这种架构，我们需要介绍 GPU 编程，这在下一节中将有描述。
- en: Understanding GPU programming
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 GPU 编程
- en: GPUs have become increasingly programmable. In fact, their set of instructions
    has been extended to allow the execution of a greater number of tasks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 的可编程性越来越高。实际上，它们的指令集已经扩展，允许执行更多的任务。
- en: Today, on a GPU, it is possible to execute classic CPU programming instructions,
    such as cycles and conditions, memory access, and floating-point calculations.
    The two major discrete video card manufacturers—**NVIDIA** and **AMD**—have developed
    their GPU architectures, providing developers with related development environments
    that allow programming in different programming languages, including Python.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，在 GPU 上可以执行经典的 CPU 编程指令，如循环和条件、内存访问和浮点运算。两大独立显卡制造商——**NVIDIA** 和 **AMD**——已经开发了他们的
    GPU 架构，为开发者提供了相关的开发环境，允许使用不同的编程语言进行编程，包括 Python。
- en: At present, developers have valuable tools for programming software that uses
    GPUs in contexts that aren't purely graphics-related. Among the main development
    environments for heterogeneous computing, we have CUDA and OpenCL.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，开发者拥有在非纯图形相关环境中编程使用 GPU 的软件的有价值工具。在异构计算的主要开发环境中，我们有 CUDA 和 OpenCL。
- en: Let's now have a look at them in detail.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细地看看它们。
- en: CUDA
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA
- en: CUDA is a proprietary hardware architecture of NVIDIA, which also gives its
    name to the related development environment. Currently, CUDA has a pool of hundreds
    of thousands of active developers, which demonstrates the growing interest that
    is developing around this technology in the parallel programming environment.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA 是 NVIDIA 的专有硬件架构，同时也为其相关的开发环境命名。目前，CUDA 拥有数十万活跃的开发者，这表明在并行编程环境中，对这项技术的兴趣正在不断增长。
- en: 'CUDA offers extensions for the most commonly used programming languages, including
    Python. The most well known CUDA Python extensions are as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA 为最常用的编程语言提供了扩展，包括 Python。最著名的 CUDA Python 扩展如下：
- en: PyCUDA ([https://mathema.tician.de/software/PyCUDA/](https://mathema.tician.de/software/pycuda/))
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyCUDA ([https://mathema.tician.de/software/PyCUDA/](https://mathema.tician.de/software/pycuda/))
- en: Numba ([http://numba.pydata.org](http://numba.pydata.org))
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Numba ([http://numba.pydata.org](http://numba.pydata.org))
- en: We'll use these extensions in the coming sections.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中使用这些扩展。
- en: OpenCL
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL
- en: The second protagonist in parallel computing is OpenCL, which (unlike its NVIDIA
    counterpart) is open standard and can be used not only with GPUs of different
    manufacturers but also with microprocessors of different types.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 并行计算的第二大主角是 OpenCL，与它的 NVIDIA 对应版本不同，OpenCL 是一个开放标准，不仅可以用在不同制造商的 GPU 上，还可以用于不同类型的微处理器。
- en: However, OpenCL is a more complete and versatile solution as it does not boast
    the maturity and simplicity of use that CUDA has.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，OpenCL 是一个更完整、更通用的解决方案，因为它不具备 CUDA 所具有的成熟度和易用性。
- en: The OpenCL Python extension is PyOpenCL ([https://mathema.tician.de/software/pyopencl/](https://mathema.tician.de/software/pyopencl/)).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 的 Python 扩展是 PyOpenCL（[https://mathema.tician.de/software/pyopencl/](https://mathema.tician.de/software/pyopencl/））。
- en: In the following sections, the CUDA and OpenCL programming models will be analyzed
    in their Python extension and will be accompanied by some interesting application
    examples.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，将分析 CUDA 和 OpenCL 的编程模型，并伴随一些有趣的应用示例。
- en: Dealing with PyCUDA
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理 PyCUDA
- en: PyCUDA is a binding library that provides access to CUDA's Python API by Andreas
    Klöckner. The main features include automatic cleanup, which is tied to an object's
    lifetime, thus preventing leaks, convenient abstraction over modules and buffers,
    full access to the driver, and built-in error handling. It is also very light.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA 是一个绑定库，由安德烈亚斯·克洛克纳（Andreas Klöckner）提供，它通过 Python API 访问 CUDA。主要特性包括与对象生命周期相关的自动清理，从而防止泄漏，方便的模块和缓冲区抽象，对驱动程序的完全访问，以及内置的错误处理。它也非常轻量。
- en: The project is open source under the MIT license, the documentation is very
    clear, and many different sources found online can provide help and support. The
    main purpose of PyCUDA is to let a developer invoke CUDA with minimal abstraction
    from Python, and it also supports CUDA metaprogramming and templatization.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目在 MIT 许可证下开源，文档非常清晰，许多在线找到的不同来源可以提供帮助和支持。PyCUDA 的主要目的是让开发者以最小的抽象从 Python
    调用 CUDA，它还支持 CUDA 元编程和模板化。
- en: Getting ready
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Please follow the instructions on the Andreas Klöckner home page ([https://mathema.tician.de/software/pycuda/](https://mathema.tician.de/software/pycuda/))
    to install PyCUDA.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照安德烈亚斯·克洛克纳（Andreas Klöckner）主页上的说明（[https://mathema.tician.de/software/pycuda/](https://mathema.tician.de/software/pycuda/））安装
    PyCUDA。
- en: 'The next programming example has a dual function:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个编程示例具有双重功能：
- en: The first is to verify that PyCUDA is properly installed.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一件事是验证 PyCUDA 是否正确安装。
- en: The second is to read and to print the characteristics of the GPU cards.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二步是读取并打印 GPU 卡的特性。
- en: How to do it...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s look at the steps, as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下步骤：
- en: 'With the first instruction, we import the Python driver (that is, `pycuda.driver`)
    to the CUDA library installed on our PC:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过第一条指令，我们将 Python 驱动程序（即 `pycuda.driver`）导入到我们 PC 上安装的 CUDA 库中：
- en: '[PRE0]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Initialize CUDA. Note also that the following instruction must be called before
    any other instruction in the `pycuda.driver` module:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 CUDA。注意，以下指令必须在 `pycuda.driver` 模块中的任何其他指令之前调用：
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Enumerate the number of GPU cards on the PC:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出 PC 上的 GPU 卡数量：
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For each of the GPU cards present, print the model name, the computing capability,
    and the total amount of memory on the device in kilobytes:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每块现有的 GPU 卡，打印出型号名称、计算能力和设备上的总内存量（以千字节为单位）：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works...
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The execution is pretty simple. In the first line of code, `pycuda.driver`
    is imported and then initialized:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 执行相当简单。在代码的第一行，导入 `pycuda.driver` 并初始化：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `pycuda.driver` module exposes the driver level to the programming interface
    of CUDA, which is more flexible than the CUDA C runtime-level programming interface,
    and it has a few features that are not present in the runtime.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`pycuda.driver` 模块将驱动程序级别暴露给 CUDA 的编程接口，这比 CUDA C 运行时级别的编程接口更灵活，并且它有一些运行时不具备的特性。'
- en: 'Then, it cycles into the `drv.Device.count()` function and, for each GPU card,
    the name of the card and its main characteristics (computing capability and total
    memory) are printed:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它循环进入 `drv.Device.count()` 函数，并为每块 GPU 打印卡名及其主要特性（计算能力和总内存）：
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Execute the following code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下代码：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'When you''ve done so, the installed GPU will be shown on the screen, as in
    the following example:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些操作后，安装的 GPU 将显示在屏幕上，如下例所示：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: There's more...
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: The CUDA programming model (and consequently PyCUDA, which is a Python wrapper)
    is implemented through specific extensions to the standard library of the C language.
    These extensions have been created just like function calls in the standard C
    library, allowing a simple approach to a heterogeneous programming model that
    includes the host and device code. The management of the two logical parts is
    done by the `nvcc` compiler.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA编程模型（以及随之而来的PyCUDA，它是一个Python包装器）是通过针对C语言标准库的特定扩展来实现的。这些扩展就像标准C库中的函数调用一样被创建，允许采用一种简单的方法来实现包含主机和设备代码的异构编程模型。这两个逻辑部分的管理是通过`nvcc`编译器完成的。
- en: 'Here is a brief description of how this works:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这里简要描述了它是如何工作的：
- en: '*Separate* device code from the host code.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*分离*设备代码和主机代码。'
- en: '*Invoke* a default compiler (for example, GCC) to compile the host code.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*调用*默认编译器（例如，GCC）来编译主机代码。'
- en: '*Build* the device code in binary form (`.cubin` objects) or in assembly form
    (`PTX` objects):'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*构建*设备代码的二进制形式（`.cubin`对象）或汇编形式（`PTX`对象）：'
- en: '![](img/6c16c259-1075-4eb4-bf70-ad0b6ac78a12.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6c16c259-1075-4eb4-bf70-ad0b6ac78a12.png)'
- en: PyCUDA execution model
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA执行模型
- en: All the preceding steps are performed by PyCUDA during execution, with an increase
    in the application loading time compared to a CUDA application.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的前述步骤都是在PyCUDA执行过程中完成的，与CUDA应用程序相比，应用程序的加载时间有所增加。
- en: See also
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The CUDA programming guide is available here: [https://docs.nvidia.com/CUDA/CUDA-c-programming-guide/](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA编程指南在此处可用：[https://docs.nvidia.com/CUDA/CUDA-c-programming-guide/](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- en: The PyCUDA documentation is available here: [https://documen.tician.de/PyCUDA/](https://documen.tician.de/pycuda/)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyCUDA文档在此处可用：[https://documen.tician.de/PyCUDA/](https://documen.tician.de/pycuda/)
- en: Heterogeneous programming with PyCUDA
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyCUDA进行异构编程
- en: The CUDA programming model (and, hence, that of PyCUDA) is designed for the
    joint execution of a software application on a CPU and GPU, in order to perform
    the sequential parts of the application on the CPU and those that can be parallelized
    on the GPU. Unfortunately, the computer is not smart enough to understand how
    to distribute the code autonomously, so it is up to the developer to indicate
    which parts should be run by the CPU and by the GPU.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA编程模型（以及PyCUDA的模型）旨在在CPU和GPU上联合执行软件应用程序，以便在CPU上执行应用程序的串行部分，在GPU上执行可并行化的部分。不幸的是，计算机还不够智能，无法自主地理解如何分配代码，因此需要开发者指出哪些部分应由CPU和GPU执行。
- en: In fact, a CUDA application is composed of serial components, which are executed
    by the system CPU or host, or by parallel components called kernels, which are
    executed by the GPU or by the device instead.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，CUDA应用程序由串行组件组成，这些组件由系统CPU或主机执行，或者由并行组件，即内核执行，这些内核由GPU或设备执行。
- en: A kernel is defined as a *grid* and can, in turn, be decomposed into blocks
    that are sequentially assigned to the various multiprocessors, thus implementing *coarse-grained
    parallelism*. Inside the blocks, there is the fundamental computational unit,
    the thread, with a very *fine parallel granularity*. A thread can belong to only
    one block and is identified by a unique index for the whole kernel. For convenience,
    there is the possibility of using two-dimensional indexes for blocks and three-dimensional
    indexes for threads. The kernels are executed sequentially between them. Blocks
    and threads, on the other hand, are executed in parallel. The number of threads
    running (in parallel) depends on their organization in blocks and on their requests
    in terms of resources, with respect to the resources available in the device.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 内核被定义为*网格*，可以进一步分解成块，这些块依次分配给各个多处理器，从而实现*粗粒度并行性*。在块内部，有基本的计算单元，即线程，具有非常*细粒度*的并行性。一个线程只能属于一个块，并且在整个内核中通过一个唯一的索引来识别。为了方便，可以使用二维索引来表示块，使用三维索引来表示线程。内核在它们之间按顺序执行。另一方面，块和线程是并行执行的。运行的线程数（并行运行）取决于它们在块中的组织以及它们对资源的请求，相对于设备中可用的资源。
- en: To visualize the concepts expressed previously, please refer to (*Figure 5*)
    at [https://sites.google.com/site/computationvisualization/programming/cuda/article1](https://sites.google.com/site/computationvisualization/programming/cuda/article1).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化之前表达的概念，请参考[https://sites.google.com/site/computationvisualization/programming/cuda/article1](https://sites.google.com/site/computationvisualization/programming/cuda/article1)中的(*图5*)。
- en: The blocks are designed to guarantee scalability. In fact, if you have an architecture
    with two multiprocessors and another with four, then, a GPU application can be
    performed on both architectures, obviously with different times and levels of
    parallelism.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 块被设计成保证可扩展性。事实上，如果你有一个具有两个多处理器的架构，另一个具有四个多处理器的架构，那么，GPU 应用程序可以在这两种架构上执行，显然，时间和并行化水平会有所不同。
- en: 'The execution of a heterogeneous program according to the PyCUDA programming
    model is thus structured as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 根据PyCUDA编程模型执行异构程序的结构如下：
- en: '*Allocate* memory on the host.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在主机上* 分配内存。'
- en: '*Transfer* data from the hostmemory to the device memory.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将* 数据从主机内存传输到设备内存。'
- en: '*Run* the device through the invocation of the kernel functions.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*运行* 设备，通过调用内核函数。'
- en: '*Transfer* the results from the device memory to the host memory.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将* 结果从设备内存传输到主机内存。'
- en: '*Release* the memory allocated on the device.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*释放* 设备上分配的内存。'
- en: 'The following diagram shows the execution flow of a program according to the
    PyCUDA programming model:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图显示了根据 PyCUDA 编程模型执行的程序执行流程：
- en: '![](img/d58c37c0-992d-4f12-b1e3-b152038611bc.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d58c37c0-992d-4f12-b1e3-b152038611bc.png)'
- en: PyCUDA programming model
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA 编程模型
- en: In the next example, we will go through a concrete example of the programming
    methodology to follow in order to build PyCUDA applications.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个例子中，我们将通过一个具体的编程方法示例来展示如何构建 PyCUDA 应用程序。
- en: How to do it...
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'In order to show the PyCUDA programming model, we consider the task of having
    to double all the elements of a 5 × 5 matrix:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示 PyCUDA 编程模型，我们考虑了这样一个任务：需要将一个 5 × 5 矩阵的所有元素都加倍：
- en: 'We import the libraries needed for the task we want to perform:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入执行任务所需的库：
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `numpy` library, which we imported, allows us to construct the input to
    our problem, that is, a 5 × 5 matrix whose values are chosen randomly:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入的 `numpy` 库允许我们构建问题的输入，即一个 5 × 5 矩阵，其值是随机选择的：
- en: '[PRE9]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The matrix, thus built, must be copied from the memory of the host to the memory
    of the device. For this, we allocate a memory space (`a*_*gpu`) on the device that
    is necessary to contain matrix `a`. For this purpose, we use the `mem_alloc` function,
    which has the allocated memory space as its subject. In particular, the number
    of bytes of matrix `a`, as expressed by the `a.nbytes` parameter, is as follows:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此构建的矩阵必须从主机内存复制到设备内存。为此，我们在设备上分配了一个内存空间 (`a*_*gpu`)，这是包含矩阵 `a` 所必需的。为此，我们使用
    `mem_alloc` 函数，该函数的主题是分配的内存空间。特别是，矩阵 `a` 的字节数，由 `a.nbytes` 参数表示，如下所示：
- en: '[PRE10]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After that, we can transfer the matrix from the host to the memory area, created
    specifically on the device by using the `memcpy_htod` function:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们可以使用 `memcpy_htod` 函数将矩阵从主机传输到设备上专门创建的内存区域：
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Inside the device, the `doubleMatrix` kernel function will operate. Its purpose
    will be to multiply each element of the input matrix by `2`. As you can see, the
    syntax of the `doubleMatrix` function is C-like, while the `SourceModule` statement
    is a real directive for the NVIDIA compiler (the `nvcc` compiler), which creates
    a module that, in this case, consists of the `doubleMatrix` function only:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在设备内部，`doubleMatrix` 内核函数将运行。其目的是将输入矩阵的每个元素乘以 `2`。正如你所见，`doubleMatrix` 函数的语法类似于
    C 语言，而 `SourceModule` 语句是 NVIDIA 编译器（`nvcc` 编译器）的一个真实指令，它创建了一个模块，在这个例子中，该模块只包含
    `doubleMatrix` 函数：
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'With the `func` parameter, we identify the `doubleMatrix` function, which is
    contained in the `mod` module:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 `func` 参数，我们识别出包含在 `mod` 模块中的 `doubleMatrix` 函数：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, we run the kernel function. In order to successfully execute a kernel
    function on the device, the CUDA user must specify the input for the kernel and
    the size of the execution thread block. In the following case, the input is the
    `a_gpu` matrix that was previously copied to the device, while the dimension of
    the thread block is `(5,5,1)`:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们运行内核函数。为了在设备上成功执行内核函数，CUDA 用户必须指定内核的输入和执行线程块的大小。在以下情况下，输入是之前复制到设备的 `a_gpu`
    矩阵，而线程块的大小是 `(5,5,1)`：
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Therefore, we allocate an area of memory of size equal to that of the input
    matrix `a`:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们分配了一个与输入矩阵 `a` 大小相等的内存区域：
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, we copy the contents of the memory area allocated to the device—that
    is, the `a_gpu` matrix—to the previously defined memory area, `a_doubled`:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将分配给设备的内存区域的内容（即 `a_gpu` 矩阵）复制到之前定义的内存区域 `a_doubled`：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Finally, we print the contents of the input matrix `a` and the output matrix
    in order to verify the quality of the implementation:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们打印输入矩阵 `a` 和输出矩阵的内容，以验证实现的品质：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: How it works...
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s start with looking at which libraries are imported for this example:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从查看此示例中导入的哪些库开始：
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In particular, the `autoinit` import automatically identifies which GPU on our
    system is available for execution, while `SourceModule` is the directive for the
    compiler of NVIDIA (`nvcc`) that allows us to identify the objects that must be
    compiled and uploaded to the device.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，`autoinit` 导入自动识别我们系统上哪个 GPU 可用于执行，而 `SourceModule` 是 NVIDIA (`nvcc`) 编译器的指令，允许我们识别必须编译并上传到设备的对象。
- en: 'Then, we build the 5 × 5 input matrix by using the `numpy` library:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 `numpy` 库构建 5 × 5 输入矩阵：
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In this case, the elements in the matrix are converted to single-precision
    mode (since the graphics card on which this example is executed only supports
    single precision):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，矩阵中的元素被转换为单精度模式（因为执行此示例的图形卡只支持单精度）：
- en: '[PRE20]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then, we copy the array from the host to the device, using the following two
    operations:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用以下两个操作将数组从主机复制到设备：
- en: '[PRE21]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that the device and host memory may never communicate during the execution
    of a kernel function. For this reason, in order to parallel execute the kernel
    function on the device, all input data relating to the kernel function must also
    be present in the memory of the device.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在内核函数执行过程中，设备和主机内存可能永远不会通信。因此，为了在设备上并行执行内核函数，所有与内核函数相关的输入数据也必须存在于设备的内存中。
- en: It should also be noted that the `a_gpu` matrix is linearized, that is, it is
    one-dimensional, and therefore we must manage it as such.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 还应注意的是，`a_gpu` 矩阵是线性化的，也就是说，它是一维的，因此我们必须这样管理它。
- en: Moreover, all these operations do not require kernel invocation. This means
    that they are made directly by the host.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，所有这些操作都不需要内核调用。这意味着它们是由主机直接执行的。
- en: 'The `SourceModule` entity allows the definition of the `doubleMatrix` kernel
    function. `__global__`, which is an `nvcc` directive, indicates that the `doubleMatrix`
    function will be processed by the device:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`SourceModule` 实体允许定义 `doubleMatrix` 内核函数。`__global__` 是一个 `nvcc` 指令，表示 `doubleMatrix`
    函数将由设备处理：'
- en: '[PRE22]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let''s consider the kernel''s body. The `idx` parameter is the matrix index,
    which is identified by the `threadIdx.x` and `threadIdx.y` thread coordinates:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑内核的主体。`idx` 参数是矩阵索引，由 `threadIdx.x` 和 `threadIdx.y` 线程坐标标识：
- en: '[PRE23]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, `mod.get_function("doubleMatrix")` returns an identifier to the `func`
    parameter:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`mod.get_function("doubleMatrix")` 返回一个指向 `func` 参数的标识符：
- en: '[PRE24]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In order to execute the kernel, we need to configure the execution context.
    This means setting the three-dimensional structure of the threads that belong
    to the block grid by using the block parameter inside the `func` call:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行内核，我们需要配置执行上下文。这意味着通过在 `func` 调用内部使用块参数设置属于块网格的线程的三维结构：
- en: '[PRE25]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`block = (5, 5, 1)` tells us that we are calling a kernel function with the
    `a_gpu` linearized input matrix and a single thread block of size `5` (that is, `5`
    threads) in the *x*-direction, `*5*` threads in the *y*-direction, and 1 thread
    in the *z*-direction, which makes *16* threads in total. Note that each thread
    executes the same kernel code (25 threads in total).'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`block = (5, 5, 1)` 告诉我们正在调用一个内核函数，该函数使用 `a_gpu` 线性化输入矩阵，并且有一个大小为 `5` 的单个线程块（即
    `5` 个线程）在 *x* 方向上，*5* 个线程在 *y* 方向上，以及 *1* 个线程在 *z* 方向上，总共 *16* 个线程。请注意，每个线程执行相同的内核代码（总共
    25 个线程）。'
- en: 'After the computation in the GPU device, we use an array to store the results:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GPU 设备上的计算完成后，我们使用一个数组来存储结果：
- en: '[PRE26]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To run the example, type the following on Command Prompt:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此示例，请在命令提示符中键入以下内容：
- en: '[PRE27]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output should be like this:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该是这样的：
- en: '[PRE28]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: There's more...
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The key feature of CUDA that makes this programming model substantially different
    from other parallel models (normally used on CPUs) is that in order to be efficient,
    it requires thousands of threads to be active. This is made possible by the typical
    structure of GPUs, which use light threads and also allow the creation and modification
    of execution contexts in a very fast and efficient way.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA 的关键特性使得这种编程模型与其他并行模型（通常用于 CPU）有显著不同，它要求为了高效，需要成千上万的线程处于活动状态。这是由 GPU 的典型结构实现的，它使用轻量级线程，并且允许非常快速和高效地创建和修改执行上下文。
- en: Note that the scheduling of threads is directly linked to the GPU architecture
    and its intrinsic parallelism. In fact, a block of threads is assigned to a single
    SM. Here, the threads are further divided into groups, called warps. The threads
    that belong to the same warp are managed by the *warp scheduler*. To take full
    advantage of the inherent parallelism of the SM, the threads of the same warp
    must execute the same instruction. If this condition does not occur, then we speak
    of *threads divergence.*
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，线程的调度直接与GPU架构及其固有的并行性相关联。实际上，一个线程块被分配给单个SM。在这里，线程被进一步分为组，称为warp。属于同一warp的线程由*线程调度器*管理。为了充分利用SM的固有并行性，同一warp中的线程必须执行相同的指令。如果这个条件不成立，那么我们称之为*线程发散*。
- en: See also
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The complete tutorial on using PyCUDA is available at the following site: [https://documen.tician.de/pycuda/tutorial.html](https://documen.tician.de/pycuda/tutorial.html).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyCUDA的完整教程可在以下网站找到：[https://documen.tician.de/pycuda/tutorial.html](https://documen.tician.de/pycuda/tutorial.html)。
- en: 'To install PyCUDA on Windows 10, take a look at the following link: [https://github.com/kdkoadd/Win10-PyCUDA-Install](https://github.com/kdkoadd/Win10-PyCUDA-Install).'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要在Windows 10上安装PyCUDA，请查看以下链接：[https://github.com/kdkoadd/Win10-PyCUDA-Install](https://github.com/kdkoadd/Win10-PyCUDA-Install)。
- en: Implementing memory management with PyCUDA
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyCUDA实现内存管理
- en: 'PyCUDA programs should respect the rules dictated by the structure and the
    internal organization of SM that impose constraints on thread performances. In
    fact, the knowledge and the correct use of various types of memory that the GPU
    makes available are fundamental in order to achieve maximum efficiency. In those
    GPU cards, enabled for CUDA use, there are four types of memory, which are as
    follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA程序应遵守由SM的结构和内部组织规定的规则，这些规则对线程性能施加了限制。实际上，了解并正确使用GPU提供的各种类型的内存对于实现最大效率是基本的。在这些为CUDA使用而启用的GPU卡上，有四种类型的内存，如下所示：
- en: '**Registers**: Each thread is assigned a memory register which only the assigned
    thread can access, even if the threads belong to the same block.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**寄存器**：每个线程都被分配了一个内存寄存器，只有分配的线程可以访问，即使线程属于同一块。'
- en: '**Shared memory**: Each block has its own shared memory between the threads
    that belong to it. Even this memory is extremely fast.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享内存**：每个块都有其自己的共享内存，属于该块中的线程。即使这种内存也极其快速。'
- en: '**Constant memory**: All threads in a grid have constant access to the memory,
    but can only be accessed in reading. The data present in it persists for the entire
    duration of the application.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常量内存**：网格中的所有线程都可以常量访问内存，但只能读取。其中存在的数据在整个应用程序的整个持续期间保持不变。'
- en: '**Global memory**: All the threads of the grid, and therefore all the kernels,
    have access to the global memory. Moreover, data persistence is exactly like a
    constant memory:'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局内存**：网格中的所有线程，因此所有内核，都可以访问全局内存。此外，数据持久性正好像常量内存：'
- en: '![](img/b43f49cb-fad9-4e64-8752-610540f62d30.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b43f49cb-fad9-4e64-8752-610540f62d30.png)'
- en: GPU memory model
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: GPU内存模型
- en: Getting ready
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中
- en: For best performance, a PyCUDA program must, therefore, make the most of every
    type of memory. In particular, it must make the most of shared memory, minimizing
    access to memory on a global level.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得最佳性能，PyCUDA程序必须充分利用每种类型的内存。特别是，它必须充分利用共享内存，最小化对全局级别内存的访问。
- en: To do this, the problem domain is typically subdivided so that a single block
    of threads is able to execute its processing in a closed subset of data. In this
    way, the threads operating on the single block will all work together on the same
    shared memory area, optimizing access.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，通常将问题域细分，以便单个线程块能够在数据的一个封闭子集中执行其处理。这样，在单个块上操作的线程都将一起在相同的共享内存区域工作，优化访问。
- en: 'The basic steps for each thread are as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 每个线程的基本步骤如下：
- en: '*Load* data from global memory to shared memory.'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*从*全局内存中加载数据到共享内存。'
- en: '*Synchronize* all threads of the block so that everyone can read safety positions
    and shared memory filled by other threads.'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*同步*块中的所有线程，以便每个人都可以读取由其他线程填充的安全位置和共享内存。'
- en: '*Process* the data of the shared memory. Making a new synchronization is necessary
    to ensure that the shared memory has been updated with the results.'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*处理*共享内存中的数据。创建新的同步是必要的，以确保共享内存已更新为结果。'
- en: '*Write* the results in global memory.'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*写入*结果到全局内存中。'
- en: To clarify this approach, in the following section, we will present an example
    based on the calculation of the product of two matrices.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了阐明这种方法，在下一节中，我们将基于两个矩阵乘积的计算提供一个示例。
- en: How to do it...
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The following code fragment shows the calculation of the product of two matrices,
    *M×N*, in the standard method, which is based on a sequential approach. Each element
    of the output matrix, `P`, is obtained by taking a row element from matrix `M`,
    and a column element from matrix `N`:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了使用标准方法计算两个矩阵 *M×N* 的乘积，该方法基于顺序方法。输出矩阵 `P` 的每个元素是通过从矩阵 `M` 中取一行元素和从矩阵
    `N` 中取一列元素得到的：
- en: '[PRE29]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In this case, if each thread had been given the task of calculating each element
    of the matrix, then access to the memory would have dominated the execution time
    of the algorithm.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，如果每个线程都被分配计算矩阵每个元素的任务，那么对内存的访问将主导算法的执行时间。
- en: 'What we can do is rely on a block of threads to calculate one output submatrix
    at a time. In this way, the threads that access the same memory block cooperate
    to optimize accesses, thereby minimizing the total calculation time:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以依赖一个线程块一次计算一个输出子矩阵。这样，访问相同内存块的线程可以合作优化访问，从而最小化总计算时间：
- en: 'The first step is to load all the necessary modules to implement the algorithm:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是加载实现算法所需的所有模块：
- en: '[PRE30]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, initialize the GPU device:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，初始化 GPU 设备：
- en: '[PRE31]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We implement `kernel_code_template`, which implements the product of two matrices
    that are respectively indicated with `a` and `b`, while the resulting matrix is
    indicated with the parameter `c`. Note that the `MATRIX_SIZE` parameter will be
    defined in the next step:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实现 `kernel_code_template`，它实现了分别用 `a` 和 `b` 指示的两个矩阵的乘积，而结果矩阵用参数 `c` 指示。请注意，`MATRIX_SIZE`
    参数将在下一步定义：
- en: '[PRE32]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following parameter will be used to set the dimensions of the matrices.
    In this case, the size is 5 × 5:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下参数将用于设置矩阵的维度。在这种情况下，大小是 5 × 5：
- en: '[PRE33]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We define the two input matrices, `a_cpu` and `b_cpu`, that will contain random
    floating-point values:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义两个输入矩阵 `a_cpu` 和 `b_cpu`，它们将包含随机浮点值：
- en: '[PRE34]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Then, we calculate the product of the two matrices, `a` and `b`, on the host
    device:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在主机设备上计算两个矩阵 `a` 和 `b` 的乘积：
- en: '[PRE35]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We allocate memory areas on the device (GPU), equal in size to the input matrices:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在设备（GPU）上分配与输入矩阵大小相等的内存区域：
- en: '[PRE36]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We allocate a memory area on the GPU, equal in size to the output matrix resulting
    from the product of the two matrices. In this case, the resulting matrix, `c_gpu`,
    will have a size of 5 × 5:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在 GPU 上分配一个内存区域，其大小与两个矩阵乘积得到的输出矩阵大小相同。在这种情况下，得到的矩阵 `c_gpu` 的大小将是 5 × 5：
- en: '[PRE37]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The following `kernel_code` redefines `kernel_code_template`, but with the
    `matrix_size` parameter set:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下 `kernel_code` 重新定义了 `kernel_code_template`，但设置了 `matrix_size` 参数：
- en: '[PRE38]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The `SourceModule` directive tells `nvcc` (*NVIDIA CUDA Compiler)* that it
    will have to create a module—that is, a collection of functions—containing the previously
    defined `kernel_code`:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SourceModule` 指令告诉 `nvcc`（*NVIDIA CUDA 编译器*）它需要创建一个模块——即包含之前定义的 `kernel_code`
    的函数集合：'
- en: '[PRE39]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Finally, we take the `MatrixMulKernel` function from the module, `mod`, to
    which we give the name `matrixmul`:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们从模块 `mod` 中取出 `MatrixMulKernel` 函数，并将其命名为 `matrixmul`：
- en: '[PRE40]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We execute the product between two matrices, `a_gpu` and `b_gpu`, resulting
    in the `c_gpu` matrix. The size of the thread block is defined as `MATRIX_SIZE,
    MATRIX_SIZE, 1`:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们执行两个矩阵 `a_gpu` 和 `b_gpu` 的乘积，得到 `c_gpu` 矩阵。线程块的大小定义为 `MATRIX_SIZE, MATRIX_SIZE,
    1`：
- en: '[PRE41]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Print the input matrices:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印输入矩阵：
- en: '[PRE42]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'To check the validity of the calculation performed on the GPU, we compare the
    results of the two implementations, which are the one performed on the host device
    (CPU) and the one performed on the device (GPU). To do this, we use the `numpy
    allclose` directive, which verifies that two element-wise arrays are equal within
    a tolerance equal to `1e-05`:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了检查在 GPU 上执行的计算的有效性，我们比较两种实现的计算结果，即主机设备（CPU）上执行的和在设备（GPU）上执行的计算。为此，我们使用 `numpy
    allclose` 指令，该指令验证两个逐元素数组在等于 `1e-05` 的容差内是否相等：
- en: '[PRE43]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: How it works...
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s consider the PyCUDA programming workflow. Let''s prepare the input matrix,
    the output matrix, and where to store the results:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑 PyCUDA 编程工作流程。让我们准备输入矩阵、输出矩阵以及存储结果的位置：
- en: '[PRE44]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Then, we transfer these matrices to the GPU device by using the `gpuarray.to_gpu()`
    PyCUDA function:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 `gpuarray.to_gpu()` PyCUDA 函数将这些矩阵传输到 GPU 设备：
- en: '[PRE45]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The core of the algorithm is the following kernel function. Let''s remark that
    the `__global__` keyword specifies that this function is a kernel function, which
    means that it will be executed by the device (GPU) following a call from the host
    code (CPU):'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的核心是以下内核函数。请注意，`__global__` 关键字指定此函数是一个内核函数，这意味着它将在设备（GPU）上执行，随后是主机代码（CPU）的调用：
- en: '[PRE46]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '`threadIdx.x` and `threadIdy.y` are coordinates that allow the identification
    of the threads in the grid of two-dimensional blocks. Note that the threads within
    the grid block execute the same kernel code but on different pieces of data. If
    we compare the parallel version with the sequential one, then we immediately notice
    that the cycle indexes, *i* and *j*, have been replaced by the `threadIdx.x` and
    `threadIdx.y` indexes.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`threadIdx.x` 和 `threadIdy.y` 是坐标，允许识别二维块网格中的线程。请注意，网格块内的线程执行相同的内核代码，但处理不同的数据。如果我们比较并行版本和顺序版本，那么我们立即会注意到循环索引
    *i* 和 *j* 已经被 `threadIdx.x` 和 `threadIdx.y` 索引所取代。'
- en: This means that in the parallel version, we will have only one iteration of
    the cycle. In fact, the `MatrixMulKernel` kernel will be executed on a grid of
    dimensions of 5 × 5 parallel threads.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在并行版本中，我们将只有一个循环迭代。实际上，`MatrixMulKernel` 内核将在一个 5 × 5 并行线程的网格上执行。
- en: 'This condition is expressed in the following diagram:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这种条件在以下图中表示：
- en: '![](img/65aa99d1-d699-4329-883c-543cb7ef15de.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](img/65aa99d1-d699-4329-883c-543cb7ef15de.png)'
- en: Grid and block of thread organization for the example
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 示例的线程网格和块组织
- en: 'Then, we verify the product computation just by comparing the two resulting
    matrices:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过比较两个结果矩阵来验证乘积计算：
- en: '[PRE47]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE48]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: There's more...
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The data allocated in shared memory has limited visibility in the single-threaded
    block. It is easy to see that the PyCUDA programming model adapts to specific
    classes of applications.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在共享内存中分配的数据在单线程块中的可见性有限。很容易看出 PyCUDA 编程模型适应特定的应用程序类别。
- en: In particular, the features that these applications must present concern the
    presence of many mathematical operations, with a high degree of data parallelism
    (that is, the same sequence of operations being repeated on large amounts of data).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，这些应用程序必须展示的特性包括许多数学运算，具有高度的数据并行性（即，相同的操作序列在大量的数据上重复进行）。
- en: 'The application fields that possess these characteristics all belong to the
    following sciences: cryptography, computational chemistry, and image and signal
    analysis.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有这些特性的应用程序领域都属于以下科学：密码学、计算化学、图像和信号分析。
- en: See also
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: More examples of using PyCUDA can be found at [https://github.com/zamorays/miniCursoPycuda](https://github.com/zamorays/miniCursoPycuda).
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多使用 PyCUDA 的示例可以在[https://github.com/zamorays/miniCursoPycuda](https://github.com/zamorays/miniCursoPycuda)找到。
- en: Introducing PyOpenCL
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 PyOpenCL
- en: PyOpenCL is a sister project to PyCUDA. It is a binding library that provides
    full access to OpenCL's API from Python and is also by Andreas Klöckner. It features
    many of the same concepts as PyCUDA, including cleanup for out-of-scope objects,
    partial abstraction over data structures, and error handling, all with minimal
    overhead. The project is available under the MIT license; its documentation is
    very good and plenty of guides and tutorials can be found online.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: PyOpenCL 是 PyCUDA 的一个姐妹项目。它是一个绑定库，提供从 Python 对 OpenCL API 的完全访问，也是由 Andreas
    Klöckner 开发的。它具有与 PyCUDA 相似的多项概念，包括对超出作用域的对象的清理、对数据结构的部分抽象以及错误处理，所有这些都具有最小的开销。该项目在
    MIT 许可证下可用；其文档非常好，可以在网上找到大量的指南和教程。
- en: The main focus of PyOpenCL is to provide a lightweight connection between Python
    and OpenCL, but it also includes support for templates and metaprograms. The flow
    of a PyOpenCL program is almost exactly the same as a C or C++ program for OpenCL.
    The host program prepares the call of the device program, launches it, and then
    waits for the result.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: PyOpenCL 的主要重点是提供一个轻量级的连接，将 Python 和 OpenCL 连接起来，但它还包括对模板和元程序的支援。PyOpenCL 程序的流程几乎与
    OpenCL 的 C 或 C++ 程序完全相同。主机程序准备调用设备程序，启动它，然后等待结果。
- en: Getting ready
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The main reference for the PyOpenCL installation is the Andreas Klöckner home
    page: [https://mathema.tician.de/software/pyopencl/](https://mathema.tician.de/software/pyopencl/).'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: PyOpenCL 安装的官方参考是 Andreas Klöckner 的主页：[https://mathema.tician.de/software/pyopencl/](https://mathema.tician.de/software/pyopencl/)。
- en: 'If you are using Anaconda, then it is advisable to perform the following steps:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用Anaconda，那么建议执行以下步骤：
- en: Install the latest Anaconda distribution with Python 3.7 from the following
    link: [https://www.anaconda.com/distribution/#download-section](https://www.anaconda.com/distribution/#download-section). For
    this section, the Anaconda 2019.07 for Windows Installer has been installed.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下链接安装最新的Anaconda发行版，Python 3.7：[https://www.anaconda.com/distribution/#download-section](https://www.anaconda.com/distribution/#download-section)。对于本节，已安装Windows安装程序的Anaconda
    2019.07。
- en: 'Get the PyOpenCL prebuilt binary from Christoph Gohlke from this link: [https://www.lfd.uci.edu/~gohlke/pythonlibs/](https://www.lfd.uci.edu/~gohlke/pythonlibs/).
    Select the right combination of OS and CPython versions. Here, we use `pyopencl-2019.1+cl12-cp37-cp37m-win_amd64.whl`.'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下链接获取Christoph Gohlke的PyOpenCL预构建二进制文件：[https://www.lfd.uci.edu/~gohlke/pythonlibs/](https://www.lfd.uci.edu/~gohlke/pythonlibs/)。选择正确的操作系统和CPython版本组合。在这里，我们使用`pyopencl-2019.1+cl12-cp37-cp37m-win_amd64.whl`。
- en: 'Use `pip` to install the previous package. Simply type this in your Anaconda
    Prompt:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pip`安装上一个包。只需在Anaconda提示符中输入以下内容：
- en: '[PRE49]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '`<directory>` is the folder where the PyOpenCL package is located.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '`<directory>`是PyOpenCL包所在的文件夹。'
- en: 'Moreover, the following notation indicates that we are operating on the Anaconda
    Prompt:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下符号表示我们正在操作Anaconda提示符：
- en: '[PRE50]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: How to do it...
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: In the following example, we will use a function of PyOpenCL that allows us
    to enumerate the features of the GPU on which it will operate.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将使用PyOpenCL的一个功能，该功能允许我们枚举它将运行的GPU的特性。
- en: 'The code we implement is very simple and logical:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现的代码非常简单且逻辑清晰：
- en: 'In the first step, we import the `pyopencl` library:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步中，我们导入`pyopencl`库：
- en: '[PRE51]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We build a function whose output will provide us with the characteristics of
    the GPU hardware in use:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们构建一个函数，其输出将为我们提供正在使用的GPU硬件的特性：
- en: '[PRE52]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'So, we implement the `main` function, which calls the previously implemented `print_device_info` function:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们实现`main`函数，该函数调用之前实现的`print_device_info`函数：
- en: '[PRE53]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: How it works...
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The following command is used to import the `pyopencl` library:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于导入`pyopencl`库：
- en: '[PRE54]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'This allows us to use the **`get_platforms` **method, which returns a list
    of platform instances, that is, a list of devices in the system:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够使用**`get_platforms`**方法，该方法返回一个平台实例列表，即系统中的设备列表：
- en: '[PRE55]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Then, for each device found, the following main features are shown:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于每个找到的设备，以下主要特性将被显示：
- en: Name and device type
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称和设备类型
- en: Max clock speed
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大时钟速度
- en: Compute units
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算单元
- en: Local/constant/global memory
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 局部/常量/全局内存
- en: 'The output for this example is as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的输出如下：
- en: '[PRE56]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: There's more...
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: OpenCL is currently managed by the Khronos Group, a non-profit consortium of
    companies that collaborate in defining the specifications of this (and many other)
    standards and compliance parameters for the creation of OpenCL-specific drivers for
    each type of platform.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL目前由Khronos Group管理，这是一个非营利性公司联盟，它们合作定义了本（以及许多其他）标准的规范和合规参数，以创建针对每种平台类型的OpenCL特定驱动程序。
- en: 'These drivers also provide functions for compiling programs that are written
    in the kernel language: these are converted into programs in some form of intermediate
    language that is usually vendor-specific, and then executed on the reference architectures.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这些驱动程序还提供了编译用内核语言编写的程序的功能：这些程序被转换为某种形式的中间语言，通常是供应商特定的，然后在这些参考架构上执行。
- en: 'More info on OpenCL can be found at the following link: [https://www.khronos.org/registry/OpenCL/](https://www.khronos.org/registry/OpenCL/).'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下链接中可以找到有关OpenCL的更多信息：[https://www.khronos.org/registry/OpenCL/](https://www.khronos.org/registry/OpenCL/)。
- en: See also
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'PyOpenCL documentation is available here: [https://documen.tician.de/pyopencl/](https://documen.tician.de/pyopencl/).'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyOpenCL文档可在以下链接找到：[https://documen.tician.de/pyopencl/](https://documen.tician.de/pyopencl/)。
- en: 'One of the best introductions to PyOpenCL, even if somewhat dated, can be found
    at the following link: [http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614](http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使有些过时，以下链接提供了PyOpenCL的最佳介绍之一：[http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614](http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614)。
- en: Building applications with PyOpenCL
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyOpenCL构建应用程序
- en: The first step in the construction of a program for PyOpenCL is the coding of
    the host application. This is performed on the CPU and has the task of managing
    the possible execution of the kernel on the GPU card (that is, the device).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 构建PyOpenCL程序的第一步是编写主机应用程序的代码。这是在CPU上执行的，其任务是管理在GPU卡（即设备）上可能执行的内核。
- en: A *kernel* is a basic unit of executable code, similar to a C function. It can
    be data-parallel or task-parallel. However, the cornerstone of PyOpenCL is the
    exploitation of parallelism.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核**是可执行代码的基本单元，类似于C函数。它可以进行数据并行或任务并行。然而，PyOpenCL的基石是并行性的利用。'
- en: A fundamental concept is a *program*, which is a collection of kernels and other
    functions, analogous to dynamic libraries. So, we can group instructions in a
    kernel and group different kernels into a program.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基本概念是*程序*，它是一组内核和其他函数的集合，类似于动态库。因此，我们可以将内核中的指令分组，并将不同的内核分组到程序中。
- en: Programs can be called from applications. We have the execution queues that
    indicate the order in which the kernels are executed. However, in some cases,
    these can be launched without following the original order.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 程序可以从应用程序中调用。我们有执行队列，指示内核执行的顺序。然而，在某些情况下，这些可以不按原始顺序启动。
- en: 'We can finally list the fundamental elements for developing an application
    with PyOpenCL:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以最终列出使用PyOpenCL开发应用程序的基本元素：
- en: '**Device**: This identifies the hardware in which the kernel code is to be
    executed. Note that the PyOpenCL application can be run on both CPU and GPU boards
    (as well as PyCUDA) but also on embedded devices such as**Field-Programmable Gate
    Arrays**(**FPGAs**).'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备**: 这标识了内核代码将要执行的硬件。请注意，PyOpenCL应用程序可以在CPU和GPU板上（以及PyCUDA）以及嵌入式设备上运行，例如**现场可编程门阵列**(**FPGAs**)。'
- en: '**Program**: This is a group of kernels that has the task of selecting which
    kernel must be run on the device.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**程序**: 这是一个具有选择必须在设备上运行的哪个内核的任务的内核组。'
- en: '**Kernel**: This is the code to execute on the device. A kernel is a C-like
    function, which means it can be compiled on any device that supports PyOpenCL
    drivers.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内核**: 这是将在设备上执行的代码。内核是一个类似于C的函数，这意味着它可以在支持PyOpenCL驱动程序的任何设备上编译。'
- en: '**Command queue**: This orders the execution of kernels on the device.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命令队列**: 这在设备上对内核的执行进行排序。'
- en: '**Context**: This is a group of devices that allows devices to receive kernels
    and transfer data.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文**: 这是一个允许设备接收内核和传输数据的设备组。'
- en: 'The following diagram shows how this data structure can work in a host application:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示显示了这种数据结构如何在主机应用程序中工作：
- en: '![](img/60b38941-28e9-4b2f-a920-d59c4f426b1e.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/60b38941-28e9-4b2f-a920-d59c4f426b1e.png)'
- en: PyOpenCL programming model
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: PyOpenCL编程模型
- en: Again, we observe that a program can contain more functions to run on the device
    and that each kernel encapsulates only a single function from the program.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们观察到程序可以包含更多要在设备上运行的函数，并且每个内核只封装程序中的一个函数。
- en: How to do it...
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'In the following example, we show the basic steps to build an application with
    PyOpenCL: the task to be performed is the sum of two vectors. In order to have
    a readable output, we''ll consider two vectors that each have 100 elements: each
    *i-th* element of the resulting vector will be equal to the sum of the *i-th*
    element of **`vector_a`**, plus the *i-th* element of **`vector_b`**:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们展示了使用PyOpenCL构建应用程序的基本步骤：要执行的任务是两个向量的和。为了有一个可读的输出，我们将考虑两个各有100个元素的向量：结果向量的每个*i*元素将等于**`vector_a`**的*i*元素与**`vector_b`**的*i*元素的和：
- en: 'Let''s start by importing all the necessary libraries:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们先导入所有必要的库：
- en: '[PRE57]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We define the size of the vectors to be added, as follows:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义要添加的向量的大小，如下所示：
- en: '[PRE58]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Here, the input vectors, `vector_a` and `vector_b`, are defined:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，定义了输入向量`vector_a`和`vector_b`：
- en: '[PRE59]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'In sequence, we define **`platform`**, **`device`**, **`context`**, and **`queue`**:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按顺序，我们定义**`platform`**、**`device`**、**`context`**和**`queue`**：
- en: '[PRE60]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Now, it''s time to organize the memory areas that will contain the input vectors:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，是时候组织包含输入向量的内存区域了：
- en: '[PRE61]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Finally, we build the application kernel by using the `Program` method:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用`Program`方法构建应用程序内核：
- en: '[PRE62]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Then, we allocate the memory of the resulting matrix:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们分配结果矩阵的内存：
- en: '[PRE63]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Then, we call the kernel function:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们调用内核函数：
- en: '[PRE64]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The memory space used to store the result is allocated in the host memory area
    *(*`res_np`*)*:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用于存储结果的内存空间在主机内存区域(*`res_np`*)中分配：
- en: '[PRE65]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Copy the result of the computation into the memory area created:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将计算结果复制到创建的内存区域：
- en: '[PRE66]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Finally, we print the results:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们打印结果：
- en: '[PRE67]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Then, we perform a simple check in order to verify that the sum operation is
    correct:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们执行一个简单的检查，以验证求和操作是否正确：
- en: '[PRE68]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: How it works...
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the following lines, after the relevant import, we define the input vectors*:*
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下行中，在相关导入之后，我们定义输入向量*：
- en: '[PRE69]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Each vector contains 100 integer items, which are randomly selected through
    the `numpy` function:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 每个向量包含100个整数项，这些项通过`numpy`函数随机选择：
- en: '[PRE70]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Then, we select the platform to achieve the computation by using the `get_platform()` method:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`get_platform()`方法选择平台以使用该平台进行计算：
- en: '[PRE71]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Then, select the corresponding device. Here, `platform.get_devices()[0]` corresponds
    to the Intel(R) HD Graphics 5500 graphics card:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，选择相应的设备。在这里，`platform.get_devices()[0]`对应于Intel(R) HD Graphics 5500显卡：
- en: '[PRE72]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'In the following steps, the context and the queue are defined; PyOpenCL provides
    the method context (device selected) and queue (context selected):'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下步骤中，定义了上下文和队列；PyOpenCL提供了context（选定的设备）和queue（选定的上下文）方法：
- en: '[PRE73]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'In order to perform the computation in the selected device, the input vector
    is copied to the device''s memory:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在选定的设备上执行计算，输入向量被复制到设备的内存：
- en: '[PRE74]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Then, we prepare the buffer for the resulting vector:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们为结果向量准备缓冲区：
- en: '[PRE75]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Here, the kernel code is defined:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，内核代码被定义：
- en: '[PRE76]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '`vectorSum` is the name of the kernel, and the parameter list defines the data
    types of the input arguments and output data type (both are integer vectors).
    Inside the kernel body, the sum of two vectors is defined in the following steps:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '`vectorSum`是内核的名称，参数列表定义了输入参数的数据类型和输出数据类型（两者都是整数向量）。在内核体内部，两个向量的和按照以下步骤定义：'
- en: '*Initialize* the vector''s index: `int gid = get_global_id(0)`.'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*初始化*向量的索引：`int gid = get_global_id(0)`。'
- en: '*Sum* the vector''s components: `res_g[gid] = a_g[gid] + b_g[gid]`.'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*求和*向量的分量：`res_g[gid] = a_g[gid] + b_g[gid]`。'
- en: In OpenCL (hence, in PyOpenCL), the buffers are attached to a context ([https://documen.tician.de/pyopencl/runtime.html#pyopencl.Context](https://documen.tician.de/pyopencl/runtime.html#pyopencl.Context)),
    which are moved to a device once the buffer is used on that device.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCL（因此，在PyOpenCL中），缓冲区被附加到一个上下文（[https://documen.tician.de/pyopencl/runtime.html#pyopencl.Context](https://documen.tician.de/pyopencl/runtime.html#pyopencl.Context)），一旦缓冲区在该设备上使用，上下文就会移动到设备上。
- en: 'Finally, we execute `vectorSum` in the device:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在设备上执行`vectorSum`：
- en: '[PRE77]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'To check the result, we use the `assert` statement. This tests the result and
    triggers an error if the condition is false:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查结果，我们使用`assert`语句。这测试结果，如果条件为假，则触发错误：
- en: '[PRE78]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The output should be as follows:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该是以下内容：
- en: '[PRE79]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: There's more...
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In this section, we have seen that the PyOpenCL execution model, like PyCUDA,
    involves a host processor that manages one or more heterogeneous devices. In particular,
    each PyOpenCL command is sent to the devices from the host in the form of source
    code that is defined through the kernel function.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了PyOpenCL执行模型，类似于PyCUDA，涉及一个主机处理器，该处理器管理一个或多个异构设备。特别是，每个PyOpenCL命令以通过内核函数定义的源代码形式从主机发送到设备。
- en: The source code is then loaded into a program object for the reference architecture,
    the program is compiled into the reference architecture, and the kernel object that
    is relative to the program is created.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将源代码加载到参考架构的程序对象中，程序被编译到参考架构中，并创建了与程序相关的内核对象。
- en: A kernel object can be executed in a variable number of workgroups, creating
    an *n*-dimensional computation matrix that allows it to effectively subdivide
    the workload for a problem in *n*-dimensions (1, 2, or 3) in each workgroup. In
    turn, they are composed of a number of work items that work in parallel.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 内核对象可以在可变数量的工作组中执行，创建一个*n*-维计算矩阵，允许它在每个工作组中有效地将*n*-维（1、2或3）的问题工作负载细分。反过来，它们由多个并行工作的工作项组成。
- en: Balancing the workload for each workgroup based on the parallel computing capability
    of a device is one of the critical parameters for achieving good application performance.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 根据设备并行计算能力平衡每个工作组的负载是实现良好应用性能的关键参数之一。
- en: A wrong balancing of the workload, together with the specific characteristics
    of each device (such as transfer latency, throughput, and bandwidth), can lead
    to a substantial loss of performance or compromise the portability of the code
    when executed without considering any system of dynamic acquisition of information
    in terms of device calculation capacities.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 工作负载的不当分配，以及每个设备的特定特性（例如传输延迟、吞吐量和带宽），可能导致性能显著下降，或者在未考虑任何基于设备计算能力的动态信息获取系统的情况下执行代码时，会损害代码的可移植性。
- en: However, the accurate use of these technologies allows us to reach high levels
    of performance by combining the results of the calculation of different computational
    units.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些技术的准确使用使我们能够通过结合不同计算单元的计算结果，达到高性能水平。
- en: See also
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: More on PyOpenCL programming can be found at [https://pydanny-event-notes.readthedocs.io/en/latest/PyConPL2012/async_via_pyopencl.html](https://pydanny-event-notes.readthedocs.io/en/latest/PyConPL2012/async_via_pyopencl.html).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于 PyOpenCL 编程的信息可以在 [https://pydanny-event-notes.readthedocs.io/en/latest/PyConPL2012/async_via_pyopencl.html](https://pydanny-event-notes.readthedocs.io/en/latest/PyConPL2012/async_via_pyopencl.html)
    找到。
- en: Element-wise expressions with PyOpenCL
  id: totrans-349
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PyOpenCL 的逐元素表达式
- en: The element-wise functionality allows us to evaluate kernels on complex expressions
    (which are made of more operands) into a single computational pass.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 逐元素功能允许我们将复杂表达式（由更多操作数组成）评估为单个计算过程。
- en: Getting started
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: The `ElementwiseKernel (context, argument, operation, name, optional_parameters)` method is
    implemented in PyOpenCL to handle element-wise expressions.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '`ElementwiseKernel (context, argument, operation, name, optional_parameters)`
    方法是在 PyOpenCL 中实现的，用于处理逐元素表达式。'
- en: 'The main parameters are as follows:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 主要参数如下：
- en: '`context` is the device or the group of devices to which the element-wise operation
    will be executed.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`context` 是执行逐元素操作的设备或设备组。'
- en: '`argument` is a C-like argument list of all the parameters involved in the
    computation.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`argument` 是所有涉及计算的参数的类似于 C 语言的参数列表。'
- en: '`operation` is a string that represents the operation to perform on the argument
    list.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`operation` 是一个表示对参数列表执行的操作的字符串。'
- en: '`name` is the kernel''s name that is associated with `Elementwisekernel`.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name` 是与 `Elementwisekernel` 关联的内核的名称。'
- en: '`optional_parameters` is not important in this recipe.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optional_parameters` 在此配方中不是很重要。'
- en: How to do it...
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Here, we consider the task of adding two integer vectors again:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们再次考虑添加两个整数向量的任务：
- en: 'Start importing the relevant libraries:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始导入相关库：
- en: '[PRE80]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Define the context element (`context`) and the command queue (`queue`) :'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义上下文元素（`context`）和命令队列（`queue`）：
- en: '[PRE81]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Here, we set the vector dimension and the space allocation for the input and
    output vectors:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们设置了向量的维度以及输入和输出向量的空间分配：
- en: '[PRE82]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'We set `elementwiseSum` as the application of `ElementwiseKernel`, and then
    set it to a set of arguments that define the operations to be applied to the input
    vectors:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将 `elementwiseSum` 设置为 `ElementwiseKernel` 的应用，然后将其设置为定义对输入向量应用的操作的参数集：
- en: '[PRE83]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Finally, we print the result:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们打印结果：
- en: '[PRE84]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: How it works...
  id: totrans-371
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the first lines of the script, we import all the requested modules.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在脚本的最初几行中，我们导入所有请求的模块。
- en: 'In order to initialize the context, we use the `cl.create_some_context()` method.
    This asks the user which context must be used to perform the calculation:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 为了初始化上下文，我们使用 `cl.create_some_context()` 方法。这要求用户选择用于执行计算的上下文：
- en: '[PRE85]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Then, we need to instantiate the queue that will receive `ElementwiseKernel`:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要实例化接收 `ElementwiseKernel` 的队列：
- en: '[PRE86]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Input and output vectors are instantiated. The input vectors, `vector_a` and
    `vector_b`, are integer vectors of random values obtained using the `random.randint`
    NumPy function. These vectors are then copied into the device by using the PyOpenCL
    statement:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化输入和输出向量。输入向量 `vector_a` 和 `vector_b` 是使用 `random.randint` NumPy 函数获得的随机整数向量。然后，使用
    PyOpenCL 语句将这些向量复制到设备上：
- en: '[PRE87]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'In `ElementwiseKernel`, an object is created:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `ElementwiseKernel` 中，创建了一个对象：
- en: '[PRE88]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Note that all the arguments are in the form of a string formatted as a C argument
    list (they are all integers).
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，所有参数都是以 C 语言参数列表的字符串格式表示的（它们都是整数）。
- en: The operation is a C-like code snippet that carries out the operation, that
    is, the sum of the input vector elements.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 操作是一个类似于 C 语言的代码片段，执行操作，即输入向量元素的求和。
- en: The name of the function with which the kernel will be compiled is `sum`.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 将要编译的内核的函数名是 `sum`。
- en: 'Finally, we call the `elementwiseSum` function with the arguments defined previously:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用之前定义的参数调用`elementwiseSum`函数：
- en: '[PRE89]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The example ends by printing the input vectors and the result obtained. The
    output looks like this:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 示例最后通过打印输入向量和获得的结果结束。输出看起来像这样：
- en: '[PRE90]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: There's more...
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'PyCUDA also has element-wise functionality:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA也有逐元素的功能：
- en: '[PRE91]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'This feature has pretty much the same arguments as the function built for PyOpenCL,
    except for the context parameter. The same example this section, which is implemented
    through PyCUDA, has the following listing:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 这个功能几乎与为PyOpenCL构建的函数有相同的参数，除了上下文参数。本节中实现的相同示例，通过PyCUDA实现，如下所示：
- en: '[PRE92]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: See also
  id: totrans-393
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: In the following link, you'll find interesting examples of PyOpenCL applications: [https://github.com/romanarranz/PyOpenCL](https://github.com/romanarranz/PyOpenCL).
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下链接中，你可以找到PyOpenCL应用的有趣示例：[https://github.com/romanarranz/PyOpenCL](https://github.com/romanarranz/PyOpenCL)。
- en: Evaluating PyOpenCL applications
  id: totrans-395
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估PyOpenCL应用
- en: In this section, we are doing a comparative test of performance between CPU
    and GPU by using the PyOpenCL library.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们使用PyOpenCL库在CPU和GPU之间进行性能比较测试。
- en: In fact, before studying the performance of the algorithms to be implemented,
    it is also important to understand the computational advantages offered by the
    computing platform you have.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在研究要实现的算法的性能之前，了解你拥有的计算平台提供的计算优势也很重要。
- en: Getting started
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: The specific characteristics of a computing system interfere with the computational
    time, and hence they represent an aspect of primary importance.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 计算系统的具体特性会干扰计算时间，因此它们代表了首要重要性的一个方面。
- en: 'In the following example, we will perform a test in order to monitor performance
    on such a system:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将进行测试以监控此类系统的性能：
- en: 'GPU: GeForce 840 M'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU：GeForce 840 M
- en: 'CPU: Intel Core i7 – 2.40 GHz'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU：Intel Core i7 – 2.40 GHz
- en: 'RAM: 8 GB'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAM：8 GB
- en: How to do it...
  id: totrans-404
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: In the following test, the calculation time of a mathematical operation, as
    the sum of two vectors with floating-point elements, will be evaluated and compared.
    To make the comparison, the same operation will be performed on two separate functions.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下测试中，将评估数学运算的计算时间，例如具有浮点元素的向量之和，并将其进行比较。为了进行比较，相同的操作将在两个不同的函数上执行。
- en: The first function is computed by the CPU only, while the second function is
    written by using the PyOpenCL library to use the GPU card. The test is performed
    on vectors with a size of 10,000 elements.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个函数仅由CPU计算，而第二个函数则是使用PyOpenCL库来利用GPU卡编写的。测试是在大小为10,000个元素的向量上进行的。
- en: 'Here is the code:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是代码：
- en: 'Import the relevant libraries. Note the import of the `time` library to calculate
    the computation times, and the `linalg` library, which is a tool of linear algebra
    tools of the `numpy` library:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关库。注意导入`time`库来计算计算时间，以及`linalg`库，它是`numpy`库的线性代数工具：
- en: '[PRE93]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Then, we define the input vectors. They both contain `10000` random elements
    of floating-point numbers:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义输入向量。它们都包含`10000`个浮点数的随机元素：
- en: '[PRE94]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'The following function computes the sum of the two vectors working on the CPU
    (host):'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下函数是在CPU（主机）上计算两个向量的和：
- en: '[PRE95]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The following function computes the sum of the two vectors working on the GPU
    (device):'
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下函数是在GPU（设备）上计算两个向量的和：
- en: '[PRE96]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Within the `test_gpu_vector_sum` function, we prepare the memory buffers to
    contain the input vectors and the output vector:'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`test_gpu_vector_sum`函数中，我们准备内存缓冲区以包含输入向量和输出向量：
- en: '[PRE97]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Still, within the `test_gpu_vector_sum` function, we define the kernel that
    will computerize the sum of the two vectors on the device:'
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽管如此，在`test_gpu_vector_sum`函数中，我们定义了将在设备上计算两个向量之和的内核：
- en: '[PRE98]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Then, we reset the `gpu_start_time` variable before starting the calculation.
    After this, we calculate the sum of two vectors and then we evaluate the calculation
    time:'
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在开始计算之前重置`gpu_start_time`变量。之后，我们计算两个向量的和，然后评估计算时间：
- en: '[PRE99]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Finally, we perform the test, recalling the two functions defined previously:'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们执行测试，回忆之前定义的两个函数：
- en: '[PRE100]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: How it works...
  id: totrans-424
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: As explained previously, the test consists of executing the calculation task,
    both on the CPU via the `test_cpu_vector_sum` function, and then on the GPU via
    the `test_gpu_vector_sum` function.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，测试包括通过`test_cpu_vector_sum`函数在CPU上执行计算任务，然后通过`test_gpu_vector_sum`函数在GPU上执行。
- en: Both functions report the execution time.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 两个函数都报告执行时间。
- en: 'Regarding the testing function on the CPU, `test_cpu_vector_sum`, it consists
    of a double calculation loop on `10000` vector elements:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 关于CPU上的测试函数`test_cpu_vector_sum`，它由对`10000`个向量元素的两次计算循环组成：
- en: '[PRE101]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'The total CPU time is the difference between the following:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 总CPU时间是以下两者的差值：
- en: '[PRE102]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'As for the `test_gpu_vector_sum` function, you can see the following by looking
    at the execution kernel:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`test_gpu_vector_sum`函数，您可以通过查看执行内核看到以下内容：
- en: '[PRE103]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: The sum of the two vectors is performed through a single calculation loop.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量的和通过单个计算循环执行。
- en: 'The result, as can be imagined, is a substantial reduction in the execution
    time for the `test_gpu_vector_sum` function:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，正如可以想象的那样，`test_gpu_vector_sum`函数的执行时间显著减少：
- en: '[PRE104]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: Even if the test is not computationally expansive, it provides useful indications
    of the potential of a GPU card.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 即使测试的计算量不大，它也提供了关于GPU卡潜力的有用指示。
- en: There's more...
  id: totrans-437
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: OpenCL is a standardized cross-platform API for developing applications that
    exploit parallel computing in heterogeneous systems. The similarities with CUDA
    are remarkable, including everything from the memory hierarchy to the direct correspondence
    between threads and work items.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL是一个标准化的跨平台API，用于开发利用异构系统并行计算的应用程序。它与CUDA的相似之处非常显著，包括从内存层次结构到线程与工作项之间的直接对应关系。
- en: Even at the programming level, there are many similar aspects and extensions
    with the same functionality.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在编程层面，也有许多具有相同功能相似方面和扩展。
- en: However, OpenCL has a much more complex device management model due to its ability
    to support a wide variety of hardware. On the other hand, OpenCL is designed to
    have code portability between products from different manufacturers.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于OpenCL能够支持广泛的硬件，它具有更复杂的设备管理模型。另一方面，OpenCL旨在实现不同制造商产品之间的代码可移植性。
- en: CUDA, thanks to its greater maturity and dedicated hardware, offers simplified
    device management and higher-level APIs that make it preferable, but only if you
    are dealing with specific architectures (that is, NVIDIA graphic cards).
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CUDA的成熟度和专用硬件，它提供了简化的设备管理和高级API，使其更受欢迎，但仅限于处理特定架构（即NVIDIA显卡）。
- en: The pros and cons of the CUDA and OpenCL libraries, as well as the PyCUDA and
    PyOpenCL libraries, are explained in the following sections.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中解释了CUDA和OpenCL库以及PyCUDA和PyOpenCL库的优缺点。
- en: Pros of OpenCL and PyOpenCL
  id: totrans-443
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL和PyOpenCL的优点
- en: 'The pros are as follows:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 优点如下：
- en: They allow the use of heterogeneous systems with different types of microprocessors.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们允许使用不同类型微处理器的异构系统。
- en: The same code runs on different systems.
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一段代码可以在不同的系统上运行。
- en: Cons of OpenCL and PyOpenCL
  id: totrans-447
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL和PyOpenCL的缺点
- en: 'The cons are as follows:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点如下：
- en: Complex device management
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂的设备管理
- en: APIs not fully stable
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API尚未完全稳定
- en: Pros of CUDA and PyCUDA
  id: totrans-451
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA和PyCUDA的优点
- en: 'The pros are as follows:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 优点如下：
- en: APIs with very high abstraction levels
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高抽象层的API
- en: Extensions for many programming languages
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多种编程语言的扩展
- en: Huge documentation and a very large community
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丰富的文档和庞大的社区
- en: Cons of CUDA and PyCUDA
  id: totrans-456
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA和PyCUDA的缺点
- en: 'The cons are as follows:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点如下：
- en: Supports only the latest NVIDIA GPUs as devices
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅支持最新的NVIDIA GPU作为设备
- en: Reduces heterogeneity to CPUs and GPUs
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将异构性降低到CPU和GPU
- en: See also
  id: totrans-460
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Andreas Klöckner has made a series of lectures on GPU programming with PyCuda
    and PyOpenCL available at [https://www.bu.edu/pasi/courses/gpu-programming-with-pyopencl-and-pycuda/](https://www.bu.edu/pasi/courses/gpu-programming-with-pyopencl-and-pycuda/)
    and [https://www.youtube.com/results?search_query=pyopenCL+and+pycuda](https://www.youtube.com/results?search_query=pyopenCL+and+pycuda).
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 安德烈亚斯·克洛克纳（Andreas Klöckner）在[https://www.bu.edu/pasi/courses/gpu-programming-with-pyopencl-and-pycuda/](https://www.bu.edu/pasi/courses/gpu-programming-with-pyopencl-and-pycuda/)和[https://www.youtube.com/results?search_query=pyopenCL+and+pycuda](https://www.youtube.com/results?search_query=pyopenCL+and+pycuda)上提供了一系列关于使用PyCuda和PyOpenCL进行GPU编程的讲座。
- en: GPU programming with Numba
  id: totrans-462
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Numba进行GPU编程
- en: Numba is a Python compiler that provides CUDA-based APIs. It has been designed
    primarily for numerical computing tasks, just like the NumPy library. In particular,
    the `numba` library manages and processes the array data types provided by NumPy.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: Numba是一个提供基于CUDA的API的Python编译器。它主要设计用于数值计算任务，就像NumPy库一样。特别是，`numba`库管理和处理NumPy提供的数组数据类型。
- en: In fact, the exploitation of data parallelism, which is inherent in numerical
    computation involving arrays, is a natural choice for GPU accelerators.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，利用数据并行性，这是涉及数组的数值计算中固有的，对于 GPU 加速器来说是一个自然的选择。
- en: The Numba compiler works by specifying the signature types (or decorators) for
    Python functions and enabling the compilation at runtime (this type of compilation
    is also called *Just In Time*).
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: Numba 编译器通过指定 Python 函数的签名类型（或装饰器）并在运行时启用编译（这种编译也称为 *即时* 编译）来工作。
- en: 'The most important decorators are as follows:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的装饰器如下：
- en: '`jit`: This allows the developer to write CUDA-like functions. When encountered,
    the compiler translates the code under the decorator into the pseudo-assembly
    PTX language, so that it can be executed by the GPU.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jit`：这允许开发者编写类似 CUDA 的函数。当遇到时，编译器将装饰器下的代码转换为伪汇编 PTX 语言，以便它可以由 GPU 执行。'
- en: '`autojit`: This annotates a function for a *deferred compilation* procedure,
    which means that the function with this signature is compiled exactly once.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autojit`：这为 *延迟编译* 过程注解了一个函数，这意味着具有此签名的函数只编译一次。'
- en: '`vectorize`: This creates a so-called** NumPy Universal Function** (**ufunc**)
    that takes a function and executes it in parallel with vector arguments.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vectorize`：这创建了一个所谓的 **NumPy 通用函数**（**ufunc**），它接受一个函数并在具有向量参数的情况下并行执行它。'
- en: '`guvectorize`: This builds a so-called **NumPy Generalized Universal Function**
    (**gufunc**). A `gufunc` object may operate on entire sub-arrays.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guvectorize`：这构建了一个所谓的 **NumPy 广义通用函数**（**gufunc**）。一个 `gufunc` 对象可以操作整个子数组。'
- en: Getting ready
  id: totrans-471
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Numba (release 0.45) is compatible with Python 2.7 and 3.5 or later, as well
    as NumPy versions 1.7 to 1.16.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: Numba（版本 0.45）与 Python 2.7 和 3.5 或更高版本兼容，以及 NumPy 版本 1.7 到 1.16。
- en: 'To install `numba`, it is recommended as per `pyopencl` to use the Anaconda
    framework, so, from the Anaconda Prompt, just type the following:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 `pyopencl` 的建议，为了安装 `numba`，建议使用 Anaconda 框架，因此，从 Anaconda Prompt 中，只需输入以下命令：
- en: '[PRE105]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'In addition, to use the full potential of `numba`, the `cudatoolkit` library
    must be installed:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了充分利用 `numba` 的全部潜力，必须安装 `cudatoolkit` 库：
- en: '[PRE106]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: After that, it's possible to verify whether the CUDA library and GPU are properly
    detected.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，可以验证 CUDA 库和 GPU 是否正确检测到。
- en: 'Open the Python interpreter from the Anaconda Prompt:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Anaconda Prompt 打开 Python 解释器：
- en: '[PRE107]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'The first test entails checking whether the CUDA library (`cudatoolkit`) is
    properly installed:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次测试涉及检查 CUDA 库 (`cudatoolkit`) 是否正确安装：
- en: '[PRE108]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'The following output shows the quality of the installation, where all the checks
    returned a positive result:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示了安装的质量，其中所有检查都返回了正值：
- en: '[PRE109]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'In the second test, we verify the presence of a graphics card:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次测试中，我们验证了图形卡的存在：
- en: '[PRE110]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'The output shows the graphic card found and whether it is supported:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了找到的图形卡以及它是否受支持：
- en: '[PRE111]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: How to do it...
  id: totrans-488
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: In this example, we provide a demonstration of the Numba compiler using the `@guvectorize` annotation.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们提供了一个使用 `@guvectorize` 注解的 Numba 编译器的演示。
- en: 'The task to execute is matrix multiplication:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行的任务是矩阵乘法：
- en: 'Import `guvectorize` from the `numba` library and the `numpy` module:'
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `numba` 库和 `numpy` 模块导入 `guvectorize`：
- en: '[PRE112]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Using the `@guvectorize` decorator, we define the `matmul` function, which
    will perform the matrix multiplication task:'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `@guvectorize` 装饰器，我们定义了 `matmul` 函数，该函数将执行矩阵乘法任务：
- en: '[PRE113]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'The input matrices are 10 × 10 in size, while the elements are integers:'
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入矩阵的大小为 10 × 10，而元素为整数：
- en: '[PRE114]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'Finally, we call the `matmul` function on the previously defined input matrices:'
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们在先前定义的输入矩阵上调用 `matmul` 函数：
- en: '[PRE115]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'We print the input matrices and the resulting matrix:'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们打印输入矩阵和结果矩阵：
- en: '[PRE116]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: How it works...
  id: totrans-501
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The `@guvectorize` decorator works on array arguments, taking four arguments in
    order to specify the `gufunc` signature:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '`@guvectorize` 装饰器作用于数组参数，按照顺序接受四个参数以指定 `gufunc` 签名：'
- en: The first three arguments specify the types of data to be managed and arrays
    of integers: `void(int64[:,:], int64[:,:], int64[:,:])`.
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前三个参数指定了要管理的数据类型和整数数组：`void(int64[:,:], int64[:,:], int64[:,:])`。
- en: The last argument of `@guvectorize` specifies how to manipulate the matrix dimensions: `(m,n),(n,p)->(m,p)`.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@guvectorize` 的最后一个参数指定了如何操作矩阵维度：`(m,n),(n,p)->(m,p)`。'
- en: Then, the matrix multiplication operation is defined, where `A` and `B` are
    the input matrices and `C` is the output matrix: *A(m,n)* B(n,p) = C(m,p)*, where *m*, *n*,
    and *p* are the matrix dimensions.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，定义了矩阵乘法操作，其中 `A` 和 `B` 是输入矩阵，`C` 是输出矩阵：`A(m,n) * B(n,p) = C(m,p)`，其中 `m`、`n`
    和 `p` 是矩阵的维度。
- en: 'The matrix product is performed through three `for` loops along with the matrix
    indices:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法是通过三个 `for` 循环以及矩阵索引来执行的：
- en: '[PRE117]'
  id: totrans-507
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'The `randint` NumPy function is used here to build the input matrices of 10
    × 10 dimensions:'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用 `randint` NumPy 函数构建了 10 × 10 维度的输入矩阵：
- en: '[PRE118]'
  id: totrans-509
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'Finally, the `matmul` function is called with these matrices as arguments,
    and the resultant `C` matrix is printed out:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用这些矩阵作为参数调用 `matmul` 函数，并打印出结果矩阵 `C`：
- en: '[PRE119]'
  id: totrans-511
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'To execute this example, type the following:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行此示例，请输入以下：
- en: '[PRE120]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'The result shows the two matrices given as input and the matrix resulting from
    their product:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示了作为输入的两个矩阵以及它们乘积得到的矩阵：
- en: '[PRE121]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: There's more...
  id: totrans-516
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: Writing an algorithm for a reduction operation using PyCUDA can be quite complex.
    For this purpose, Numba provides the `@reduce` decorator for converting simple
    binary operations into *reduction kernels*.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PyCUDA 编写一个用于降维操作的算法可能相当复杂。为此，Numba 提供了 `@reduce` 装饰器，用于将简单的二进制操作转换为 *降维内核*。
- en: 'Reduction operations reduce a set of values to a single value. A typical example
    of a reduction operation is to calculate the sum of all the elements of an array.
    As an example, consider the following array of elements: 1, 2, 3, 4, 5, 6, 7,
    8.'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 降维操作将一组值减少到一个值。一个典型的降维操作示例是计算一个数组所有元素的总和。例如，考虑以下元素数组：1, 2, 3, 4, 5, 6, 7, 8。
- en: 'The sequential algorithm operates in the way shown in the diagram, that is,
    adding the elements of the array one after the other:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序算法按照图中所示的方式运行，即逐个添加数组的元素：
- en: '![](img/7e5ea317-7653-4c24-96f3-8ea106d866df.png)'
  id: totrans-520
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7e5ea317-7653-4c24-96f3-8ea106d866df.png)'
- en: Sequential sum
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序求和
- en: 'A parallel algorithm operates according to the following schema:'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 并行算法按照以下方案运行：
- en: '![](img/3704575d-6b42-4dc7-b4f9-01093cb44870.png)'
  id: totrans-523
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3704575d-6b42-4dc7-b4f9-01093cb44870.png)'
- en: Parallel sum
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 并行求和
- en: It is clear that the latter has the advantage of shorter execution time.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，后者具有更短的执行时间优势。
- en: 'By using Numba and the `@reduce` decorator, we can write an algorithm, in a
    few lines of code, for the parallel sum on an array of integers ranging from 1
    to 10,000:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 Numba 和 `@reduce` 装饰器，我们可以用几行代码编写一个算法，用于对从 1 到 10,000 的整数数组进行并行求和：
- en: '[PRE122]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'The previous example can be performed by typing the following command:'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过输入以下命令执行前面的示例：
- en: '[PRE123]'
  id: totrans-529
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: 'The following result is provided:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 以下结果提供：
- en: '[PRE124]'
  id: totrans-531
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: See also
  id: totrans-532
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: In the following repository, you can find many examples of Numba: [https://github.com/numba/numba-examples](https://github.com/numba/numba-examples). 
    An interesting introduction to Numba and CUDA programming can be found at [https://nyu-cds.github.io/python-numba/05-cuda/](https://nyu-cds.github.io/python-numba/).
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下仓库中，您可以找到许多 Numba 的示例：[https://github.com/numba/numba-examples](https://github.com/numba/numba-examples)。在
    [https://nyu-cds.github.io/python-numba/05-cuda/](https://nyu-cds.github.io/python-numba/05-cuda/)
    可以找到对 Numba 和 CUDA 编程的有趣介绍。
