["```py\nwhile not iterator.done(): \n    item = iterator.next() \n    # do something with the item \n```", "```py\nfrom typing import Iterable, Iterator\nclass CapitalIterable(Iterable[str]):\n    def __init__(self, string: str) -> None:\n        self.string = string\n    def __iter__(self) -> Iterator[str]:\n        return CapitalIterator(self.string)\nclass CapitalIterator(Iterator[str]):\n    def __init__(self, string: str) -> None:\n        self.words = [w.capitalize() for w in string.split()]\n        self.index = 0\n    def __next__(self) -> str:\n        if self.index == len(self.words):\n            raise StopIteration()\n        word = self.words[self.index]\n        self.index += 1\n        return word \n```", "```py\n>>> iterable = CapitalIterable('the quick brown fox jumps over the lazy dog')\n>>> iterator = iter(iterable)\n>>> while True:\n...     try:\n...         print(next(iterator))\n...     except StopIteration:\n...         break\n...     \nThe\nQuick\nBrown\nFox\nJumps\nOver\nThe\nLazy\nDog \n```", "```py\n>>> for i in iterable:\n...     print(i)\n...     \nThe\nQuick\nBrown\nFox\nJumps\nOver\nThe\nLazy\nDog \n```", "```py\n>>> input_strings = [\"1\", \"5\", \"28\", \"131\", \"3\"]\n\n>>> output_integers = [] \n>>> for num in input_strings: \n...    output_integers.append(int(num)) \n```", "```py\n>>> output_integers = [int(num) for num in input_strings] \n```", "```py\n>>> output_integers = [int(num) for num in input_strings if len(num) < 3]\n>>> output_integers\n[1, 5, 28, 3] \n```", "```py\n>>> from pathlib import Path\n>>> source_path = Path('src') / 'iterator_protocol.py'\n>>> with source_path.open() as source:\n...     examples = [line.rstrip() \n...         for line in source \n...         if \">>>\" in line] \n```", "```py\n>>> with source_path.open() as source:\n...     examples = [(number, line.rstrip()) \n...         for number, line in enumerate(source, start=1) \n...         if \">>>\" in line] \n```", "```py\n>>> from typing import NamedTuple\n>>> class Book(NamedTuple):\n...     author: str\n...     title: str\n...     genre: str\n>>> books = [\n...     Book(\"Pratchett\", \"Nightwatch\", \"fantasy\"),\n...     Book(\"Pratchett\", \"Thief Of Time\", \"fantasy\"),\n...     Book(\"Le Guin\", \"The Dispossessed\", \"scifi\"),\n...     Book(\"Le Guin\", \"A Wizard Of Earthsea\", \"fantasy\"),\n...     Book(\"Jemisin\", \"The Broken Earth\", \"fantasy\"),\n...     Book(\"Turner\", \"The Thief\", \"fantasy\"),\n...     Book(\"Phillips\", \"Preston Diamond\", \"western\"),\n...     Book(\"Phillips\", \"Twice Upon A Time\", \"scifi\"),\n... ] \n```", "```py\n>>> fantasy_authors = {b.author for b in books if b.genre == \"fantasy\"} \n```", "```py\n>>> fantasy_authors\n{'Pratchett', 'Le Guin', 'Turner', 'Jemisin'} \n```", "```py\nfantasy_titles = {b.title: b for b in books if b.genre == \"fantasy\"} \n```", "```py\nApr 05, 2021 20:03:29 DEBUG This is a debugging message.\nApr 05, 2021 20:03:41 INFO This is an information method.\nApr 05, 2021 20:03:53 WARNING This is a warning. It could be serious.\nApr 05, 2021 20:03:59 WARNING Another warning sent.\nApr 05, 2021 20:04:05 INFO Here's some information.\nApr 05, 2021 20:04:17 DEBUG Debug messages are only useful if you want to figure something out.\nApr 05, 2021 20:04:29 INFO Information is usually harmless, but helpful.\nApr 05, 2021 20:04:35 WARNING Warnings should be heeded.\nApr 05, 2021 20:04:41 WARNING Watch for warnings. \n```", "```py\n>>> from pathlib import Path\n>>> full_log_path = Path.cwd() / \"data\" / \"sample.log\"\n>>> warning_log_path = Path.cwd() / \"data\" / \"warnings.log\"\n>>> with full_log_path.open() as source:\n...     warning_lines = (line for line in source if \"WARN\" in line)\n...     with warning_log_path.open('w') as target:\n...         for line in warning_lines:\n...             target.write(line) \n```", "```py\nApr 05, 2021 20:03:53 WARNING This is a warning. It could be serious.\nApr 05, 2021 20:03:59 WARNING Another warning sent.\nApr 05, 2021 20:04:35 WARNING Warnings should be heeded.\nApr 05, 2021 20:04:41 WARNING Watch for warnings. \n```", "```py\nimport csv\nimport re\nfrom pathlib import Path\nfrom typing import Match, cast\ndef extract_and_parse_1(\n        full_log_path: Path, warning_log_path: Path\n)-> None:\n    with warning_log_path.open(\"w\") as target:\n        writer = csv.writer(target, delimiter=\"\\t\")\n        pattern = re.compile(\n            r\"(\\w\\w\\w \\d\\d, \\d\\d\\d\\d \\d\\d:\\d\\d:\\d\\d) (\\w+) (.*)\")\n        with full_log_path.open() as source:\n            for line in source:\n                if \"WARN\" in line:\n                    line_groups = cast(\n                        Match[str], pattern.match(line)).groups()\n                    writer.writerow(line_groups) \n```", "```py\nimport csv\nimport re\nfrom pathlib import Path\nfrom typing import Match, cast, Iterator, Tuple, TextIO\nclass WarningReformat(Iterator[Tuple[str, ...]]):\n    pattern = re.compile(\n        r\"(\\w\\w\\w \\d\\d, \\d\\d\\d\\d \\d\\d:\\d\\d:\\d\\d) (\\w+) (.*)\")\n    def __init__(self, source: TextIO) -> None:\n        self.insequence = source\n    def __iter__(self) -> Iterator[tuple[str, ...]]:\n        return self\n    def __next__(self) -> tuple[str, ...]:\n        line = self.insequence.readline()\n        while line and \"WARN\" not in line:\n            line = self.insequence.readline()\n        if not line:\n            raise StopIteration\n        else:\n            return tuple(\n                cast(Match[str], \n                     self.pattern.match(line)\n                ).groups()\n            )\ndef extract_and_parse_2(\n        full_log_path: Path, warning_log_path: Path\n) -> None:\n    with warning_log_path.open(\"w\") as target:\n        writer = csv.writer(target, delimiter=\"\\t\")\n        with full_log_path.open() as source:\n            filter_reformat = WarningReformat(source)\n            for line_groups in filter_reformat:\n                writer.writerow(line_groups) \n```", "```py\nfrom __future__ import annotations\nimport csv\nimport re\nfrom pathlib import Path\nfrom typing import Match, cast, Iterator, Iterable\ndef warnings_filter(\n        source: Iterable[str]\n) -> Iterator[tuple[str, ...]]:\n    pattern = re.compile(\n        r\"(\\w\\w\\w \\d\\d, \\d\\d\\d\\d \\d\\d:\\d\\d:\\d\\d) (\\w+) (.*)\")\n    for line in source:\n        if \"WARN\" in line:\n            yield tuple(\n                cast(Match[str], pattern.match(line)).groups())\ndef extract_and_parse_3(\n        full_log_path: Path, warning_log_path: Path\n) -> None:\n    with warning_log_path.open(\"w\") as target:\n        writer = csv.writer(target, delimiter=\"\\t\")\n        with full_log_path.open() as infile:\n            filter = warnings_filter(infile)\n            for line_groups in filter:\n                writer.writerow(line_groups) \n```", "```py\n>>> print(warnings_filter([]))\n<generator object warnings_filter at 0xb728c6bc> \n```", "```py\nwarnings_filter = (\n    tuple(cast(Match[str], pattern.match(line)).groups())\n    for line in source\n    if \"WARN\" in line\n) \n```", "```py\ndef file_extract(\n        path_iter: Iterable[Path]\n) -> Iterator[tuple[str, ...]]:\n    for path in path_iter:\n        with path.open() as infile:\n            yield from warnings_filter(infile)\ndef extract_and_parse_d(\n        directory: Path, warning_log_path: Path) -> None:\n    with warning_log_path.open(\"w\") as target:\n        writer = csv.writer(target, delimiter=\"\\t\")\n        log_files = list(directory.glob(\"sample*.log\"))\n        for line_groups in file_extract(log_files):\n            writer.writerow(line_groups) \n```", "```py\nwarnings_filter = (\n    tuple(cast(Match[str], pattern.match(line)).groups())\n    for line in source\n    if \"WARN\" in line\n) \n```", "```py\nJan 26, 2015 11:26:01 INFO This is a multi-line information\nmessage, with misleading content including WARNING\nand it spans lines of the log file WARNING used in a confusing way\nJan 26, 2015 11:26:13 DEBUG Debug messages are only useful if you want to figure something out. \n```", "```py\ndef warnings_filter(source: Iterable[str]\n) -> Iterator[Sequence[str]]:\n    pattern = re.compile\n        (r\"(\\w\\w\\w \\d\\d, \\d\\d\\d\\d \\d\\d:\\d\\d:\\d\\d) (\\w+) (.*)\")\n    for line in source:\n        if match := pattern.match(line):\n            if \"WARN\" in match.group(2):\n                yield match.groups() \n```", "```py\npossible_match_iter = (pattern.match(line) for line in source)\ngroup_iter = (\n    match.groups() for match in possible_match_iter if match)\nwarnings_filter = (\n    group for group in group_iter if \"WARN\" in group[1]) \n```", "```py\npattern = re.compile(\n    r\"(?P<dt>\\w\\w\\w \\d\\d, \\d\\d\\d\\d \\d\\d:\\d\\d:\\d\\d)\"\n    r\"\\s+(?P<level>\\w+)\"\n    r\"\\s+(?P<msg>.*)\"\n) \n```", "```py\npossible_match_iter = (\n    pattern.match(line) for line in source)\ngroup_iter = (\n    match.groupdict() for match in possible_match_iter if match)\nwarnings_iter = (\n    group for group in group_iter if \"WARN\" in group[\"level\"])\ndt_iter = (\n    (\n        datetime.datetime.strptime(g[\"dt\"], \"%b %d, %Y %H:%M:%S\"),\n        g[\"level\"],\n        g[\"msg\"],\n    )\n    for g in warnings_iter\n)\nwarnings_filter = (\n    (g[0].isoformat(), g[1], g[2]) for g in dt_iter) \n```", "```py\npossible_match_iter = map(pattern.match, source)\ngood_match_iter = filter(None, possible_match_iter)\ngroup_iter = map(lambda m: m.groupdict(), good_match_iter)\nwarnings_iter = filter(lambda g: \"WARN\" in g[\"level\"], group_iter)\ndt_iter = map(\n    lambda g: (\n        datetime.datetime.strptime(g[\"dt\"], \"%b %d, %Y %H:%M:%S\"),\n        g[\"level\"],\n        g[\"msg\"],\n    ),\n    warnings_iter,\n)\nwarnings_filter = map(\n    lambda g: (g[0].isoformat(), g[1], g[2]), dt_iter) \n```", "```py\nimport itertools\nfrom typing import DefaultDict, Iterator\nModuloDict = DefaultDict[int, List[KnownSample]]\ndef partition_2(\n    samples: Iterable[KnownSample], \n    training_rule: Callable[[int], bool]\n) -> tuple[TrainingList, TestingList]:\n    rule_multiple = 60\n    partitions: ModuloDict = collections.defaultdict(list)\n    for s in samples:\n        partitions[hash(s) % rule_multiple].append(s)\n    training_partitions: list[Iterator[TrainingKnownSample]] = []\n    testing_partitions: list[Iterator[TestingKnownSample]] = []\n    for i, p in enumerate(partitions.values()):\n        if training_rule(i):\n            training_partitions.append(\n                TrainingKnownSample(s) for s in p)\n        else:\n            testing_partitions.append(\n                TestingKnownSample(s) for s in p)\n    training = list(itertools.chain(*training_partitions))\n    testing = list(itertools.chain(*testing_partitions))\n    return training, testing \n```", "```py\n>>> p1 = range(1, 10, 2)\n>>> p2 = range(2, 10, 2)\n>>> itertools.chain(p1, p2)\n<itertools.chain object at ...>\n>>> list(itertools.chain(p1, p2))\n[1, 3, 5, 7, 9, 2, 4, 6, 8] \n```", "```py\nlambda i: i % 4 != 0 \n```", "```py\nClassifier = Callable[\n    [int, DistanceFunc, TrainingList, AnySample], str]\nclass Hyperparameter(NamedTuple):\n    k: int\n    distance_function: DistanceFunc\n    training_data: TrainingList\n    classifier: Classifier\n    def classify(self, unknown: AnySample) -> str:\n        classifier = self.classifier\n        return classifier(\n            self.k, self.distance_function,             self.training_data, \n            unknown\n        )\n    def test(self, testing: TestingList) -> int:\n        classifier = self.classifier\n        test_results = (\n            ClassifiedKnownSample(\n                t.sample,\n                classifier(\n                    self.k, self.distance_function, \n                    self.training_data, t.sample\n                ),\n            )\n            for t in testing\n        )\n        pass_fail = map(\n            lambda t: (\n                1 if t.sample.species == t.classification else 0),\n            test_results\n        )\n        return sum(pass_fail) \n```", "```py\nh = Hyperparameter(1, manhattan, training_data, k_nn_1)\nh.test(testing_data) \n```", "```py\nclass Measured(NamedTuple):\n    distance: float\n    sample: TrainingKnownSample\ndef k_nn_1(\n    k: int, dist: DistanceFunc, training_data: TrainingList, \n    unknown: AnySample\n) -> str:\n    distances = sorted(\n        map(\n           lambda t: Measured(dist(t, unknown), t), training_data\n        )\n    )\n    k_nearest = distances[:k]\n    k_frequencies: Counter[str] = collections.Counter(\n        s.sample.sample.species for s in k_nearest\n    )\n    mode, fq = k_frequencies.most_common(1)[0]\n    return mode \n```", "```py\ndef k_nn_b(\n    k: int, dist: DistanceFunc, training_data: TrainingList, \n    unknown: AnySample\n) -> str:\n    k_nearest = [\n        Measured(float(\"inf\"), cast(TrainingKnownSample, None)) \n        for _ in range(k)\n    ]\n    for t in training_data:\n        t_dist = dist(t, unknown)\n        if t_dist > k_nearest[-1].distance:\n            continue\n        new = Measured(t_dist, t)\n        k_nearest.insert(bisect.bisect_left(k_nearest, new), new)\n        k_nearest.pop(-1)\n    k_frequencies: Counter[str] = collections.Counter(\n        s.sample.sample.species for s in k_nearest\n    )\n    mode, fq = k_frequencies.most_common(1)[0]\n    return mode \n```", "```py\ndef k_nn_q(\n    k: int, dist: DistanceFunc, training_data: TrainingList, \n    unknown: AnySample\n) -> str:\n    measured_iter = (\n        Measured(dist(t, unknown), t) for t in training_data)\n    k_nearest = heapq.nsmallest(k, measured_iter)\n    k_frequencies: Counter[str] = collections.Counter(\n        s.sample.sample.species for s in k_nearest\n    )\n    mode, fq = k_frequencies.most_common(1)[0]\n    return mode \n```", "```py\ndef test_classifier(\n        training_data: List[TrainingKnownSample],\n        testing_data: List[TestingKnownSample],\n        classifier: Classifier) -> None:\n    h = Hyperparameter(\n        k=5,\n        distance_function=manhattan,\n        training_data=training_data,\n        classifier=classifier)\n    start = time.perf_counter()\n    q = h.test(testing_data)\n    end = time.perf_counter()\n    print(\n        f'| {classifier.__name__:10s} '\n        f'| q={q:5}/{len(testing_data):5} '\n        f'| {end-start:6.3f}s |') \n```", "```py\ndef main() -> None:\n    test, train = a_lot_of_data(5_000)\n    print(\"| algorithm  | test quality  | time    |\")\n    print(\"|------------|---------------|---------|\")\n    test_classifier(test, train, k_nn_1)\n    test_classifier(test, train, k_nn_b)\n    test_classifier(test, train, k_nn_q) \n```", "```py\n>>> import timeit\n>>> m = timeit.timeit(\n...     \"manhattan(d1, d2)\",\n...     \"\"\"\n... from model import Sample, KnownSample, TrainingKnownSample, TestingKnownSample\n... from model import manhattan, euclidean\n... d1 = TrainingKnownSample(KnownSample(Sample(1, 2, 3, 4), \"x\"))\n... d2 = KnownSample(Sample(2, 3, 4, 5), \"y\")\n... \"\"\") \n```", "```py\ndef __init__(self, source: TextIO) -> None:\n    self.insequence = iter(source) \n```"]