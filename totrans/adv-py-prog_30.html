<html><head></head><body>
<div><div><div><h1 id="_idParaDest-400"><a id="_idTextAnchor381"/>Assessments</h1>
			<h1 id="_idParaDest-401"><a id="_idTextAnchor382"/>Chapter 1</h1>
			<ol>
				<li value="1">In the order of importance: functionality, correctness, and efficiency.</li>
				<li>An <code>assert</code> statement raises an error when the condition it checks for is not satisfied. As such, these statements are used in tests, where we determine whether a program computes and outputs values as it is supposed to.</li>
				<li>A benchmark is a small but representative use case that can be used to estimate the speed of a program. Benchmarks can be used to compare different versions of a program to see if a new implementation leads to an improvement in efficiency.</li>
				<li>In IPython or Jupyter notebooks, the <code>timeit</code> magic command, when placed in front of a code snippet, will run that code several times and record the running time of each run. The output of the command will show summary statistics of the recorded times so that we can estimate the average running time of the code we are interested in.</li>
				<li><code>cProfile</code> includes the following in its output:<ol><li><code>ncalls</code>: The number of times the function was called.</li><li><code>tottime</code>: The total time spent in the function without considering the calls to other functions.</li><li><code>cumtime</code>: The time in the function, including other function calls.</li><li><code>percall</code>: The time spent for a single call of the function, which can be obtained by dividing the total or cumulative time by the number of calls.</li><li><code>filename:lineno</code>: The filename and corresponding line numbers. This information is not available when calling C extensions modules.</li></ol></li>
				<li>The <code>dis</code> module analyzes the low-level bytecode and shows how Python code is converted. This is helpful when we are interested in the number of low-level instructions that correspond to a specific statement.</li>
				<li>Using IPython, we may profile the function as follows:<pre>In [1]: %load_ext line_profiler
In [2]: from exercise import close, benchmark
In [3]: %lprun -f close benchmark()
Function: close at line 5
Line #      Hits         Time  Per Hit   % Time  Line 
Contents
=========================================================
=====
     5                                           def 
close(particles, eps=1e-5):
     6         1          6.0      6.0     66.7      p0, 
p1 = particles
     7
     8         1          2.0      2.0     22.2      x_
dist = abs(p0.x - p1.x)
     9         1          1.0      1.0     11.1      y_
dist = abs(p0.y - p1.y)
    10
    11         1          0.0      0.0      0.0      
return x_dist &lt; eps and y_dist &lt; eps</pre></li>
			</ol>
			<p>Perhaps surprisingly, the unpacking and <code>p0</code> and <code>p1</code> takes two thirds of the execution time of the <code>close()</code> function.</p>
			<h1 id="_idParaDest-402"><a id="_idTextAnchor383"/>Chapter 2</h1>
			<ol>
				<li value="1">The most appropriate data structure for each of the following use cases is as follows:<ol><li>Mapping items to another set of items (with set being used in the most general sense): dictionaries.</li><li>Accessing, modifying, and appending elements: lists.</li><li>Maintaining a collection of unique elements: sets.</li><li>Keeping track of the minimum/maximum of a set (in the most general sense): heaps.</li><li>Appending and removing elements at the endpoints of a sequence (in the most general sense): deques.</li><li>Fast searching according to some similarity criterion (used by, for example, autocompletion engines): tries.</li></ol></li>
				<li>Caching is a design where we store expensive results in a temporary location, which can be in memory, on-disk, or a remote location. Memoization is specifically about storing and reusing the results of previous function calls in an application. As such, memoization is a form of caching.</li>
				<li>Comprehensions and generators are optimized under the hood, so they are generally more efficient than explicit for loops. They are also more compact in code and are more readable.</li>
				<li>A dictionary would be a more appropriate data structure. If the numbers represented the counts, a <code>Counter</code> data structure would be the best data structure to use.</li>
			</ol>
			<h1 id="_idParaDest-403"><a id="_idTextAnchor384"/>Chapter 3</h1>
			<ol>
				<li value="1">NumPy offers efficient operations on multidimensional arrays, such as array creation, accessing elements (indexing) and slicing along specific axes, and optimized mathematical operations.</li>
				<li>Using pandas, you can apply "mapping" operations to data, group, aggregate, and summarize data.</li>
				<li>NumPy cannot handle labeled data, while pandas cannot process multidimensional data. <code>xarray</code> combines the best features of the two libraries to offer APIs the ability to handle multi-dimensional, labeled data.</li>
			</ol>
			<h1 id="_idParaDest-404"><a id="_idTextAnchor385"/>Chapter 4</h1>
			<ol>
				<li value="1">Static types allow the compiler to generate type-specific optimization, making the compiled code more efficient.</li>
				<li>A memory view belongs to Cython's interface, which helps it work with different data types such as <code>byte</code>, <code>bytearray</code>, or <code>array.array</code> easier. Specifically, it offers a universal interface that simplifies the process of accessing the values that are stored in these different data types.</li>
				<li>To profile Cython, we can use the annotated view to identify hard-to-find interpreter-related calls, as well as the familiar <code>cProfile</code> tool.</li>
			</ol>
			<h1 id="_idParaDest-405"><a id="_idTextAnchor386"/>Chapter 5</h1>
			<ol>
				<li value="1">JIT compilers perform compilation at runtime rather than before running the code. This allows a piece of code that is expected to run many times to become more efficient, as recompilation is no longer necessary.</li>
				<li>We use the signature of an <code>nb.jit</code> function to specify the data types that the function works with, which allows for further optimization for specific numerical data types. When Numba encounters other, unsupported types, it simply registers them as the generic <code>pyobject</code> type.</li>
				<li>Tracing JIT compilation refers to the process of identifying the most intensive loops in a program, tracing the operations involved, and compiling the corresponding optimized, interpreter-free code. This allows us to actively optimize the most inefficient part of our code.</li>
			</ol>
			<h1 id="_idParaDest-406"><a id="_idTextAnchor387"/>Chapter 6</h1>
			<ol>
				<li value="1">The main components of a typical machine learning pipeline are the predictive model (model assumptions, parameters), the loss function, and the optimization of the model parameters to minimize the loss function.</li>
				<li>The loss function may be minimized using gradient descent, in which we compute the gradient of the loss with the current values of the model parameters and adjust those values in the opposite direction of the gradient. JAX can compose this gradient loss function using <code>grad</code>.</li>
				<li>In our example, we utilized kernels to create nonlinear features from the features we were given. Naïve implementations of kernels are hard to vectorize, which may lead to inefficient for loops. JAX can automatically vectorize these kernels to address this problem.</li>
			</ol>
			<h1 id="_idParaDest-407"><a id="_idTextAnchor388"/>Chapter 7</h1>
			<ol>
				<li value="1">At a high level, asynchronous programming aims to avoid idle waiting for unavailable resources. This typically involves interacting with slow and unpredictable resources.</li>
				<li>A callback is a function that will be called at a given, later time. A future, on the other hand, is a more convenient abstraction that helps us keep track of requested resources and whether they are available. Futures are generally easier to use than callbacks.</li>
				<li>A reactive application should be responsive, elastic, resilient, and message-driven.</li>
			</ol>
			<h1 id="_idParaDest-408"><a id="_idTextAnchor389"/>Chapter 8</h1>
			<ol>
				<li value="1">Multithreading cannot possibly speed up Python code due to the <strong class="bold">global interpreter lock</strong> (<strong class="bold">GIL</strong>). In this chapter, we examined different approaches to multiprocessing; that is, running code using multiple processes.</li>
				<li>Using the <code>Process</code> interface, we can have more low-level control by subclassing it. The <code>Pool</code> interface, on the other hand, offers a convenient way to distribute tasks across processes using the <code>apply</code> and <code>map</code> methods.</li>
				<li>Theano and TensorFlow automatically translate our code into a parallelized version by taking advantage of special operations such as matrix multiplication.</li>
			</ol>
			<h1 id="_idParaDest-409"><a id="_idTextAnchor390"/>Chapter 9</h1>
			<ol>
				<li value="1"><strong class="bold">HTML</strong> stands for <strong class="bold">Hypertext Markup Language</strong>, which is the standard and most common language for developing web pages and applications.</li>
				<li>Most of the communication that's done via the internet (more specifically, the <strong class="bold">World Wide Web</strong> (<strong class="bold">WWW</strong>)) uses HTTP. In HTTP, request methods are used to convey information on what data is being requested and should be sent back from a server.</li>
				<li>HTTP response status codes are three-digit numbers that signify the state of communication between a server and its client. They are split into five categories, each indicating a specific state.</li>
				<li>The <code>requests</code> module manages the communication between a Python program and a web server through HTTP requests.</li>
				<li>A ping test is a tool that's typically used by web administrators to make sure that their sites are still available to clients. A ping test does this by making requests to the websites and analyzing the returned response status code.</li>
				<li>Both the process of making different requests to a web server and parsing the processing downloaded HTML source code are independent across separate requests.</li>
				<li>The following considerations should be made when you're developing applications that make concurrent web requests:<ol><li>The terms of service and data-collecting policies</li><li>Error handling</li><li>Updating your program regularly</li><li>Avoiding over-scraping</li></ol></li>
			</ol>
			<h1 id="_idParaDest-410"><a id="_idTextAnchor391"/>Chapter 10</h1>
			<ol>
				<li value="1">Image processing is the task of analyzing and manipulating digital image files to create new versions of the images, or to extract important data from them.</li>
				<li>The smallest unit of a digital image is a pixel, which typically contains an RGB value: a tuple of integers between 0 and 255.</li>
				<li>Grayscaling is the processing of converting an image into gray colors by considering only the intensity of each pixel, represented by the amount of light available. It reduces the dimensionality of the image pixel matrix by mapping traditional three-dimensional color data to one-dimensional gray data.</li>
				<li>Thresholding replaces each pixel in an image with a white pixel if the pixel's intensity is greater than a previously specified threshold, and with a black pixel if the pixel's intensity is less than that threshold. After performing thresholding on an image, each pixel of that image can only hold two possible values, significantly reducing the complexity of image data.</li>
				<li>Heavy computational number-crunching processes are typically involved when it comes to image processing, as each image is a matrix of integer tuples. However, these processes can be executed independently, which suggests that the whole task should be made concurrent.</li>
				<li>Some good practices for concurrent image processing are as follows:<ol><li>Choose the correct method (out of many)</li><li>Spawn an appropriate number of processes</li><li>Process the input/output concurrently</li></ol></li>
			</ol>
			<h1 id="_idParaDest-411"><a id="_idTextAnchor392"/>Chapter 11</h1>
			<ol>
				<li value="1">Communication channels are used to denote both the physical wiring connection between different systems and the logical communication of data that facilitates computer networks. The latter is related to computing and is more relevant to the idea of asynchronous programming. Asynchronous programming can provide functionalities that complement the process of facilitating communication channels efficiently.</li>
				<li>The media layers contain fairly low-level operations that interact with the underlying process of the communication channel, while the host layers deal with high-level data communication and manipulation.</li>
				<li>The transport layer is often viewed as the conceptual transition between the media layers and the host layers. It is responsible for sending data along end-to-end connections between different systems.</li>
				<li>Server-wise, the <code>asyncio</code> module combines the abstraction of transport with the implementation of an asynchronous program. Specifically, via its <code>BaseTransport</code> and <code>BaseProtocol</code> classes, <code>asyncio</code> provides different ways to customize the underlying architecture of a communication channel.</li>
				<li>Together with the <code>aiohttp</code> module and, specifically, <code>aiohttp.ClientSession</code>, <code>asyncio</code> also offers efficiency and flexibility regarding client-side communication processes, via asynchronously making requests and reading the returned responses.</li>
				<li>The <code>aiofiles</code> module, which can work in conjunction with <code>asyncio</code> and <code>aiohttp</code>, helps facilitate asynchronous file reading/writing.</li>
			</ol>
			<h1 id="_idParaDest-412"><a id="_idTextAnchor393"/>Chapter 12</h1>
			<ol>
				<li value="1">A lack of (or mishandled) coordination between different lock objects can cause a deadlock, in which no progress can be made, and the program is locked in its current state.</li>
				<li>In the dining philosophers problem, since each philosopher is holding only one fork with their left hand, they cannot proceed to eat or put down the fork they are holding. The only way a philosopher gets to eat their food is for their neighbor philosopher to put their fork down, which is only possible if they can eat their food; this creates a never-ending circle of conditions that can never be satisfied. This situation is, in essence, the nature of a deadlock, in which all the elements of a system are stuck in place and no progress can be made.</li>
				<li>A deadlock is also defined by the necessary conditions that a concurrent program needs to have at the same time for a deadlock to occur. These conditions were first proposed by the computer scientist Edward G. Coffman Jr, and are therefore known as the Coffman conditions. These conditions are as follows:<ol><li>At least one resource has to be in a non-shareable state. This means that the resource is being held by an individual process (or thread) and cannot be accessed by others; the resource can only be accessed and held by a single process (or thread) at any given time. This condition is also known as mutual exclusion.</li><li>One process (or thread) exists that is simultaneously accessing a resource and waiting for another that's held by other processes (or threads). In other words, this process (or thread) needs access to two resources to execute its instructions, one of which it is already holding, and the other of which it is waiting for from other processes (or threads). This condition is called hold and wait.</li><li>Resources can only be released by a process (or a thread) holding them if there are specific instructions for the process (or thread) to do so. This is to say that unless the process (or thread) voluntarily and actively releases the resource, the resource remains in a non-shareable state. This is the no preemption condition.</li><li>The final condition is called circular wait. As its name suggests, this condition specifies that a set of processes (or threads) exists where the first process (or thread) in the set is waiting for a resource to be released by the second process (or thread), which, in turn, needs to be waiting for the third process (or thread); finally, the last process (or thread) in the set is waiting for the first one.</li></ol></li>
				<li>Instead of accessing the resources arbitrarily, if the processes (or threads) are to access them in a predetermined, static order, the circular nature of the way that they acquire and wait for the resources will be eliminated. However, if you place enough locks on the resources of your concurrent program, it will become entirely sequential in its execution, and, combined with the overhead of concurrent programming functionalities, it will have an even worse speed than the purely sequential version of the program.</li>
				<li>By ignoring locks, our program resources effectively become shareable among different processes/threads in a concurrent program, thus eliminating the first of the four Coffman conditions: mutual exclusion. Doing this, however, can be seen as misunderstanding the problem completely. We know that locks are utilized so that processes and threads can access the shared resources in a program in a systematic, coordinated way, to avoid mishandling the data. Removing any locking mechanisms in a concurrent program means that the likelihood of the shared resources, which are now free from accessing limitations, being manipulated in an uncoordinated way (and therefore becoming corrupted) increases significantly.</li>
				<li>In a livelock situation, the processes (or threads) in the concurrent program can switch their states, yet they simply switch back and forth infinitely, and no progress can be made.</li>
			</ol>
			<h1 id="_idParaDest-413"><a id="_idTextAnchor394"/>Chapter 13</h1>
			<ol>
				<li value="1">Starvation is a problem in concurrent systems in which a process (or thread) cannot gain access to the necessary resources to proceed with its execution, which means it cannot make any progress.</li>
				<li>Most of the time, a poorly coordinated set of scheduling instructions is the main cause of starvation. Some high-level causes for starvation may include the following:<ol><li>Processes (or threads) with high priorities dominate the execution flow in the CPU, so low-priority processes (or threads) are not allowed to execute their instructions.</li><li>Processes (or threads) with high priorities dominate the usage of non-shareable resources, so low-priority processes (or threads) are not allowed to execute their instructions. This situation is similar to the first one but addresses the priority of accessing resources, instead of the priority of execution itself.</li><li>Processes (or threads) with low priorities are waiting for resources to execute their instructions, but as soon as the resources become available, other processes (or threads) with higher priorities are immediately given access to them, so the low-priority processes (or threads) wait infinitely.</li></ol></li>
				<li>Deadlock situations can also lead to starvation, as the definition of starvation states that if a process (or thread) exists that is unable to make any progress because it cannot gain access to the necessary process, the process (or thread) is experiencing starvation. This is also illustrated in the dining philosophers' problem.</li>
				<li>The readers-writers problem asks for a scheduling algorithm so that readers and writers can access the text file appropriately and efficiently, without mishandling/corrupting the data that's included.</li>
				<li>The first approach allows for multiple readers to access the text file simultaneously since readers simply read in the text file and do not alter the data in it. The problem with the first approach is that when a reader is accessing the text file and a writer is waiting for the file to be unlocked, if another reader starts its execution and wants to access the file, it will be given priority over the writer, who has already been waiting. Additionally, if more and more readers keep requesting access to the file, the writer will be waiting infinitely.</li>
				<li>This approach implements the specification that once a writer requests to access the file, no reader should be able to jump in line and access the file before that writer. As opposed to what we see in the first solution to the readers-writers problem, this solution is giving priority to writers and, as a consequence, the readers are starved.</li>
				<li>This approach implements a lock on both readers and writers. All threads will then be subject to the constants of the lock, so equal priority will be achieved among separate threads.</li>
				<li>Some common solutions to starvation include the following:<ol><li>Increasing the priority of low-priority threads.</li><li>Implementing a first-in-first-out thread queue.</li><li>Implementing a priority queue that also gives gradually increasing priority to threads that have been waiting in the queue for a long time.</li><li>If a thread has been able to access the shared resource many times, it should be given less priority.</li></ol></li>
			</ol>
			<h1 id="_idParaDest-414"><a id="_idTextAnchor395"/>Chapter 14</h1>
			<ol>
				<li value="1">Critical sections indicate shared resources that are accessed by multiple processes or threads in a concurrent application, which can lead to unexpected, and even erroneous, behaviors.</li>
				<li>A race condition occurs when two or more threads/processes access and alter a shared resource simultaneously, resulting in mishandled and corrupted data.</li>
				<li>The root cause of a race condition is multiple threads/processes reading in and altering a shared resource simultaneously. When all of the threads/processes finish their execution, only the result of the last thread/process is registered.</li>
				<li>Since race conditions arise when multiple threads or processes access and write to a shared resource simultaneously, the solution is to isolate the execution of different threads/processes, especially when interacting with the shared resource. With locks, we can turn a shared resource in a concurrent program into a critical section, whose data integrity is guaranteed to be protected.</li>
				<li>There are several disadvantages to using locks: with enough locks implemented in a concurrent program, the whole program may become entirely sequential; locks don't lock anything.</li>
				<li>The problems that race conditions raise in real-life systems and applications are as follows:<ol><li>Security: A race condition can be both exploited as a security vulnerability (to give external agents illegal access to a system) and used as random key generation, for security processes.</li><li>Operating systems: A race condition occurring when two agents (users and applications) interact with the same memory space can lead to unpredictable behaviors.</li><li>Networking: In networking, a race condition can lead to giving multiple users powerful privileges in a network.</li></ol></li>
			</ol>
			<h1 id="_idParaDest-415"><a id="_idTextAnchor396"/>Chapter 15</h1>
			<ol>
				<li value="1">C++ associates a variable with its value by simply writing the value to the memory location of the variable; Python has its variables reference point to the memory location of the values that they hold. For this reason, Python needs to maintain a reference count for every value in its memory space.</li>
				<li>To avoid race conditions and, consequently, value reference counts from being corrupted, the GIL is implemented so that only one thread can access and mutate the counts at any given time.</li>
				<li>The GIL effectively prevents multiple threads from taking advantage of the CPU and executing CPU-bound instructions at the same time. This means that if multiple threads that are meant to be executed concurrently are CPU-bound, they will be executed sequentially.</li>
				<li>There are a few ways to deal with the GIL in your Python applications; namely, implementing multiprocessing instead of multithreading and utilizing other, alternative Python interpreters.</li>
			</ol>
			<h1 id="_idParaDest-416"><a id="_idTextAnchor397"/>Chapter 16</h1>
			<ol>
				<li value="1">The factory pattern makes it easy to keep track of the objects that are created within a program. Another benefit lies in the separation of code, which creates an object and the code that the object uses.</li>
				<li>There are two forms of the factory pattern: the factory method and the abstract method. The former is used to handle the creation of a single object, while the latter is a group of factory methods.</li>
				<li>You should start with the factory method first since it is the simpler of the two. If you find yourself needing many factory methods, then you should start thinking about grouping them into different abstract methods.</li>
			</ol>
			<h1 id="_idParaDest-417"><a id="_idTextAnchor398"/>Chapter 17</h1>
			<ol>
				<li value="1">The builder pattern helps manage objects that contain many individual components that need to be created sequentially. The pattern allows you to reuse a construction multiple times as well since it decouples an object's construction and the object itself.</li>
				<li>Many applications, such as HTML page generators, document converters, and UI form creators, are implemented with the builder pattern.</li>
				<li>The builder pattern uses a director to create an object via multiple steps sequentially, while the factory pattern creates an object in a single step.</li>
			</ol>
			<h1 id="_idParaDest-418"><a id="_idTextAnchor399"/>Chapter 18</h1>
			<ol>
				<li value="1">The prototype pattern helps us create objects that are based on an existing object (or prototype) via cloning. This can easily be done in Python using the <code>copy</code> function.</li>
				<li>Objects in a database need to be duplicated many times, depending on the application and its users. This may be an expensive operation without prototypes.</li>
				<li>The singleton pattern is helpful when we want to implement a class that should only have one instance. This is useful, for example, when we'd like to maintain the global state of a Python program.</li>
				<li>The singleton pattern may be used to control concurrent access to a shared resource, preventing many concurrency-based bugs and errors.</li>
			</ol>
			<h1 id="_idParaDest-419"><a id="_idTextAnchor400"/>Chapter 20</h1>
			<ol>
				<li value="1">The decorator pattern specifies the usage and responsibilities of an object dynamically in a transparent and readable way.</li>
				<li>Python has a built-in decorator feature, allowing programmers to extend the functionalities of a function, method, or class.</li>
				<li>With the decorator pattern, we can implement memoization with minimal code, which, as we have seen in the main text, helps keep the computation of Fibonacci numbers fast and its code readable.</li>
			</ol>
			<h1 id="_idParaDest-420"><a id="_idTextAnchor401"/>Chapter 21</h1>
			<ol>
				<li value="1">The bridge pattern is useful when there is a need to share an implementation among different objects without having to implement individual specialized classes. This is typically done with either an abstract class that generalizes the different use cases or the individual specialized classes themselves.</li>
				<li>The adapter is generally used to make two incompatible interfaces compatible, while the bridge abstracts out the generalization of different classes.</li>
				<li>We define an abstract content fetcher class, from which two specialized classes inherit: a local file fetcher and a URL fetcher.</li>
			</ol>
			<h1 id="_idParaDest-421"><a id="_idTextAnchor402"/>Chapter 22</h1>
			<ol>
				<li value="1">The façade pattern helps hide the inner implementation of an application and only exposing the necessary interface. This is particularly important when we are working with a large code base but our user only needs to interact with a small portion of our code.</li>
				<li>When we need to make a change to an application, the abstraction that the façade pattern provides helps keep the client code separate and safe, which is useful in making the client side unaffected by pending software changes.</li>
				<li>The operating system class works as a façade, hiding access to the different server classes from client code.</li>
			</ol>
			<h1 id="_idParaDest-422"><a id="_idTextAnchor403"/>Chapter 23</h1>
			<ol>
				<li value="1">The flyweight pattern is designed to keep memory usage at a minimum by sharing resources among similar objects.</li>
				<li>The MVC pattern generalizes a common structure among different applications with a model, a view, and a controller. This helps prevent mixing the backend logic with user interfaces.</li>
				<li>The proxy pattern is useful in requiring the necessary code to be run before an important object is accessed.</li>
			</ol>
			<h1 id="_idParaDest-423"><a id="_idTextAnchor404"/>Chapter 24</h1>
			<ol>
				<li value="1">The chain of responsibility pattern gracefully handles an unknown number of requests or events that our program needs to process. This is useful in event-based logic such as purchase applications and shipping systems.</li>
				<li>In our system, if an object does not know how to handle a given request, it passes the request along the chain. As we have seen, a <code>close</code> event cannot be handled directly by <code>SendDialog</code> and <code>MsgText</code> and is passed to <code>MainWindow</code>.</li>
				<li>The chain of responsibility pattern may not be useful if there are multiple requests, but they may be processed by a single object. This renders all the bookkeeping that's done by the pattern useless.</li>
			</ol>
			<h1 id="_idParaDest-424"><a id="_idTextAnchor405"/>Chapter 25</h1>
			<ol>
				<li value="1">The command pattern helps encapsulate operational logic (copy, paste, undo, redo, and so on) in an object. This leads to better abstraction and management of the logical steps to be taken for each operation, such as grouping multiple operations and implementing macros.</li>
				<li>The command pattern abstracts out the implementation of the operations that are used, so any client code that executes it does not need to know about the details of their implementation.</li>
				<li>In our example, we implemented an abstraction on top of various functionalities provided by the <code>os</code> module. A particular feature is its undoing function. Moreover, as commands have a consistent interface, grouping them can be done with ease.</li>
			</ol>
			<h1 id="_idParaDest-425"><a id="_idTextAnchor406"/>Chapter 26</h1>
			<ol>
				<li value="1">The observer pattern maintains a list of objects that are interested in the state of a target object and notifies the former when the latter changes.</li>
				<li>While the MVC pattern may implement the same function logic of updating views when the model changes, the observer pattern is more effective at maintaining and managing the list of subscribers for a given publisher, making it easy to, for example, add or remove subscribers.</li>
				<li>We implement data formatters that display an object in different ways. Here, we have multiple subscribing formatters that are interested in a publishing default formatter. When the default formatter is updated, the subscribers are notified and proceed with their respective logic.</li>
			</ol>
		</div>
	</div>
</div>
</body></html>