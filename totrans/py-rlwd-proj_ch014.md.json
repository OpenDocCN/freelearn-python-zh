["```py\nNOAA/NOS/CO-OPS\nDisclaimer: These data are based upon the latest information available ...\nAnnual Tide Predictions\nStationName: EL JOBEAN, MYAKKA RIVER\nState: FL\nStationid: 8725769\nReferencedToStationName: St. Petersburg, Tampa Bay\nReferencedToStationId: 8726520\nHeightOffsetLow: * 0.83\nHeightOffsetHigh: * 0.83\nTimeOffsetLow: 116\nTimeOffsetHigh: 98\nPrediction Type: Subordinate\nFrom: 20230101 06:35 - 20231231 19:47\nUnits: Feet and Centimeters\nTime Zone: LST_LDT\nDatum: MLLW\nInterval Type: High/Low\n\nDate  Day Time Pred(Ft) Pred(cm) High/Low\n2023/01/01 Sun 06:35 AM -0.13 -4 L\n2023/01/01 Sun 01:17 PM 0.87 27 H\netc.\n```", "```py\nfrom dataclasses import dataclass\n\n@dataclass\nclass TidePrediction:\n    date: str\n    day: str\n    time: str\n    pred_ft: str\n    pred_cm: str\n    high_low: str\n\n    @classmethod\n    def from_row(\n        cls: type[\"TidePrediction\"],\n        row: list[str]\n    ) -> \"TidePrediction\":\n        ...\n```", "```py\nfrom enum import StrEnum\n\nclass HighLow(StrEnum):\n    high = ’H’\n    low = ’L’\n```", "```py\nimport datetime\nfrom typing import Annotated, TypeAlias\n\nfrom pydantic import BaseModel\nfrom pydantic.functional_validators import AfterValidator, BeforeValidator\n\n# See below for the type aliases.\n\nclass TidePrediction(BaseModel):\n    date: TideCleanDateTime\n    pred_ft: float\n    pred_cm: float\n    high_low: TideCleanHighLow\n\n    @classmethod\n    def from_acquire_dataclass(\n            cls,\n            acquired: acquire_model.TidePrediction\n    ) -> \"TidePrediction\":\n        source_timestamp = f\"{acquired.date} {acquired.time}\"\n        return TidePrediction(\n            date=source_timestamp,\n            pred_ft=acquired.pred_ft,\n            pred_cm=acquired.pred_cm,\n            high_low=acquired.high_low\n        )\n```", "```py\nTideCleanDateTime: TypeAlias = Annotated[\n    datetime.datetime, BeforeValidator(clean_date)]\nTideCleanHighLow: TypeAlias = Annotated[\n    HighLow, BeforeValidator(lambda text: text.upper())]\n```", "```py\ndef clean_date(v: str | datetime.datetime) -> datetime.datetime:\n    match v:\n        case str():\n            return datetime.datetime.strptime(v, \"%Y/%m/%d %I:%M %p\")\n        case _:\n            return v\n```", "```py\nimport enum\n\nclass HighLow(StrEnum):\n    high = 'H'\n    low = 'L'\n```", "```py\nTideCleanHighLow: TypeAlias = Annotated[\n    HighLow, BeforeValidator(lambda text: text.upper())]\n```", "```py\nimport csv\nimport enum\nfrom pathlib import Path\n\ndef zip_code_values() -> list[tuple[str, str]]:\n    source_path = Path.home() / \"Downloads\" / \"georef-united-states-of-\n      america-zc-point@public.csv\"\n    with source_path.open(encoding=’utf_8_sig’) as source:\n        reader = csv.DictReader(source, delimiter=’;’)\n        values = [\n            (f\"ZIP_{zip[’Zip Code’]:0>5s}\", f\"{zip[’Zip Code’]:0>5s}\")\n            for zip in reader\n        ]\n    return values\n\nZipCode = enum.Enum(\"ZipCode\", zip_code_values())\n```", "```py\nimport csv\nfrom pathlib import Path\nimport re\nfrom typing import TextIO, TypeAlias, Annotated\n\nfrom pydantic import BaseModel, Field\nfrom pydantic.functional_validators import BeforeValidator, AfterValidator\n\n# See below for the type aliases.\n\nValidZip: TypeAlias = Annotated[\n    str,\n    BeforeValidator(zip_format_valid),\n    AfterValidator(zip_lookup_valid)]\n\nclass SomethingWithZip(BaseModel):\n    # Some other fields\n    zip: ValidZip\n```", "```py\ndef zip_format_valid(zip: str) -> str:\n    assert re.match(r’\\d{5}|\\d{5}-d{4}’, zip) is not None,\n    f\"ZIP invalid format {zip!r}\"\n    return zip\n```", "```py\nclass ZipLookupValidator:\n    \"\"\"Compare a code against a list.\"\"\"\n    def __init__(self) -> None:\n        self.zip_set: set[str] = set()\n\n    def load(self, source: TextIO) -> None:\n        reader = csv.DictReader(source, delimiter=’;’)\n        self.zip_set = {\n            f\"{zip[’Zip Code’]:0>5s}\"\n            for zip in reader\n        }\n\n    def __call__(self, zip: str) -> str:\n        if zip in self.zip_set:\n            return zip\n        raise ValueError(f\"invalid ZIP code {zip}\")\n\nzip_lookup_valid = ZipLookupValidator()\n```", "```py\ndef prepare_validator() -> None:\n    source_path = (\n        Path.home() / \"Downloads\" /\n        \"georef-united-states-of-america-zc-point@public.csv\"\n    )\n    with source_path.open(encoding=’utf_8_sig’) as source:\n        zip_lookup_valid.load(source)\n```", "```py\nfrom pydantic import BaseModel\n\nclass InitialSample(BaseModel):\n    x: float\n    y: float\n\nclass SeriesSample(InitialSample):\n    z_x: float\n    z_y: float\n\n    @classmethod\n    def build_sample(cls, m_x: float, s_x: float,\n    m_y: float, s_y: float, init:\n      InitialSample)-> \"SeriesSample\":\n        return SeriesSample(\n            x=init.x, y=init.y,\n            z_x=(init.x - m_x) / s_x,\n            z_y=(init.y - m_y) / s_y\n        )\n```", "```py\nimport math\n\nclass Variance:\n    def __init__(self):\n        self.k: float | None = None\n        self.e_x = 0.0\n        self.e_x2 = 0.0\n        self.n = 0\n\n    def add(self, x: float) -> None:\n        if self.k is None:\n            self.k = x\n        self.n += 1\n        self.e_x += x - self.k\n        self.e_x2 += (x - self.k) ** 2\n\n    @property\n    def mean(self) -> float:\n        return self.k + self.e_x / self.n\n\n    @property\n    def variance(self) -> float:\n        return (self.e_x2 - self.e_x ** 2 / self.n) / (self.n - 1)\n\n    @property\n    def stdev(self) -> float:\n        return math.sqrt(self.variance)\n```", "```py\nvar_compute = Variance()\nfor d in data:\n    var_compute.add(d)\n\nprint(f\"Mean = {var_compute.mean}\")\nprint(f\"Standard Deviation = {var_compute.stdev}\")\n```", "```py\n% python src/acquire.py -s Series_1Pair --csv source.csv | python src/clean.py -o analysis/Series_1.ndjson\n```", "```py\nif options.output:\n    with options.output.open(’w’) as output:\n        process(options.source, output)\nelse:\n    process(options.source, sys.stdout)\n```", "```py\ncat some_mock_file.ndj | python src/clean.py -o analysis/some_file.ndj\n```", "```py\nfrom multiprocessing import get_logger\n\nimport acquire_model\nimport analysis_model\n\ndef clean_sample(\n        acquired: acquire_model.SeriesSample\n) -> analysis_model.SeriesSample:\n    try:\n        return analysis_model.SeriesSample.from_acquire_dataclass(acquired)\n    except ValueError as ex:\n        logger = get_logger()\n        logger.error(\"Bad sample: %r\\n%r\\n\", acquired, ex)\n        return None\n```", "```py\nwith target_path.open(’w’) as target_file:\n    with concurrent.futures.ProcessPoolExecutor() as executor:\n        with source_path.open() as source:\n            acquire_document_iter = get_series(\n                source, builder\n            )\n            clean_samples = executor.map(\n                clean.clean_sample,\n                acquire_document_iter\n            )\n            count = clean.persist_samples(target_file, clean_samples)\n```"]