- en: Chapter 8. Creating Projects with the Raspberry Pi Camera Module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with the Raspberry Pi camera module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the camera with Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating a time-lapse video
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a stop frame animation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making a QR code reader
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering and experimenting with OpenCV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Color detection with OpenCV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing motion tracking with OpenCV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Raspberry Pi camera module is a special add-on of the Raspberry Pi that
    makes use of the **Camera Serial Interface** (**CSI**) **connector**. This connects
    directly to the GPU core of the Raspberry Pi processor, allowing images to be
    captured directly on the unit.
  prefs: []
  type: TYPE_NORMAL
- en: We shall create a basic **graphical user interface** (**GUI**) using the `tkinter`
    library we used in [Chapter 3](ch03.html "Chapter 3. Using Python for Automation
    and Productivity"), *Using Python for Automation and Productivity*, and [Chapter
    4](ch04.html "Chapter 4. Creating Games and Graphics"), *Creating Games and Graphics*.
    This will form the basis of the following three examples where we extend the GUI
    with additional controls so that we can put the camera to various uses for a range
    of different projects.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we set up the powerful **Open Computer Vision** (**OpenCV**) library
    to perform some advanced image processing. We will learn the basics of OpenCV
    and use it to track objects based on their color or detect movement.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter uses the Raspberry Pi camera module, which is available from most
    retailers listed in the *Makers, hobbyists, and Raspberry Pi specialists* section
    of the [Appendix](apa.html "Appendix A. Hardware and Software List"), *Hardware
    and Software List*.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with the Raspberry Pi camera module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will start by installing and setting up the Raspberry Pi camera module;
    then we will create a small camera GUI that enables us to preview and take photos.
    The first GUI we will create is shown in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting started with the Raspberry Pi camera module](img/6623OT_08_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A basic camera GUI for the Raspberry Pi camera module
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Raspberry Pi camera module consists of a camera mounted on a small **Printed
    Circuit Board** (**PCB**) attached to a small ribbon cable. The ribbon cable can
    be attached directly to the CSI port of the Raspberry Pi board (marked as **S5**,
    the port is located between the USB and the HDMI port on the Raspberry Pi). The
    following image shows the Raspberry Pi camera module:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/6623OT_08_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Raspberry Pi camera module
  prefs: []
  type: TYPE_NORMAL
- en: 'The Raspberry Pi Foundation provides detailed instructions (and a video) on
    how to install the camera at [http://www.raspberrypi.org/archives/3890](http://www.raspberrypi.org/archives/3890);
    carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, fit the camera as shown in the following image (ensure that you have
    disconnected the Raspberry Pi from any power sources first):![Getting ready](img/6623OT_08_003.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The ribbon connector for the camera module is located next to the HDMI socket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To fit the ribbon cable into the CSI socket, you need to gently lift up and
    loosen the tab of the ribbon socket. Insert the ribbon into the slot with the
    metal contacts facing towards the HDMI port. Take care not to bend or fold the
    ribbon cable, and ensure that it is seated firmly and level in the socket before
    pushing the tab back into place.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Finally, enable the camera. You can do this via the Raspberry Pi Configuration
    GUI on the Raspbian desktop (open this via the **Interfaces** menu).![Getting
    ready](img/6623OT_08_004.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enable the Raspberry Pi camera via the Interfaces tab in the Raspberry Pi Configuration
    screen
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Alternatively, you can do this via the command line, using `raspi-config`. Use
    `sudo raspi-config` to run it, find the menu entry for **Enable Camera**, and
    enable it. You will be prompted to reboot afterwards.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can use two programs that are also installed as part of the upgrade—`raspivid`
    and `raspistill`—to test the camera.
  prefs: []
  type: TYPE_NORMAL
- en: 'To take a single picture, use the following command (`-t 0` takes the picture
    immediately):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To take a short, 10-second video in the H.264 format, use the following command
    (the `-t` value is in milliseconds):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The full documentation of the camera and the `raspivid` and `raspistill` utilities
    is available on the Raspberry Pi site at [http://www.raspberrypi.org/wp-content/uploads/2013/07/RaspiCam-Documentation.pdf](http://www.raspberrypi.org/wp-content/uploads/2013/07/RaspiCam-Documentation.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To get more information on each of the programs, you can use the `less` command
    to view the instructions (use `q` to quit) as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Each command provides full control of the camera settings, such as exposure,
    white balance, sharpness, contrast, brightness, and the resolution.
  prefs: []
  type: TYPE_NORMAL
- en: Using the camera with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The camera module on the Raspberry Pi is more than just a standard webcam. Since
    we have full access to the controls and settings from within our own programs,
    it allows us to take control and create our own camera applications.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will use the Python module called `picamera` created by
    Dave Hughes to control the camera module, which performs all the functions `raspivid`
    and `raspistill` support.
  prefs: []
  type: TYPE_NORMAL
- en: See [http://picamera.readthedocs.org](http://picamera.readthedocs.org) for additional
    documentation and lots of useful examples.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Raspberry Pi camera module should be connected and installed as detailed
    in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we will also need to install the Python 3 Pillow Library (the details
    of how to do this have been covered in the *Displaying photo information in an
    application* recipe in [Chapter 3](ch03.html "Chapter 3. Using Python for Automation
    and Productivity"), *Using Python for Automation and Productivity*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, install `picamera` for Python 3 using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create the following `cameraGUI.py` script that shall contain the main class
    for the GUI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create the following `cameraGUI1normal.py` file to use the GUI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the example with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the `cameraGUI.py` file, we use a class called `SET` to contain the settings
    for the application (you will see in the following example why this is particularly
    helpful and allows us to keep all of the references to the settings in one place).
  prefs: []
  type: TYPE_NORMAL
- en: We will define a base class called `cameraGUI` (so we can attach `Tkinter` objects
    to it), which inherits a `TK.Frame` class. The `cameraGUI` class will contain
    all the methods to create the Tkinter application, including laying out the controls
    and providing all the required functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We define the following three utility functions for the class to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '`run()`: This function will allow us to send commands to be run on the command
    line using `subprocess.call` (we will use `subprocess.call` in the following examples
    to perform video encoding and other applications).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`getTKImage()`: This function will allow us to create a `TK.PhotoImage` object
    suitable to display on the Tkinter canvas. The Tkinter canvas is unable to directly
    display JPG images, so we use the **Pillow library** (**PIL**) to resize it for
    display and convert it into a **PPM** file (the **Portable PixMap** format, which
    supports more colors than GIF). Since this conversion and resize process can take
    a few seconds, we will use GIF images to provide a quick camera preview images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timestamp()`: This function will allow us to generate a timestamp string that
    we can use to automatically name any images we take.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Within the class initializer (`__init__()`), we define all the control variables,
    generate all the GUI objects and controls we want to use, and use the `grid()`
    functions to position the objects. The layout of the GUI is shown in the following
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The layout of the camera GUI
  prefs: []
  type: TYPE_NORMAL
- en: 'We define the following control variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`self.previewUpdate`: This is linked to the status of the **Preview** checkbox
    (`previewChk`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`self.filename`: This is linked to text displayed by the `labelFilename` widget'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also link the **Shutter** button (`shutterBtn`) to `self.shutter()`, which
    will be called whenever the **Shutter** button is pressed, and the **Exit** button
    (`exitBtn`) to the `self.exit()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in the `__init__()` function, we call `self.preview()`, which will
    ensure that **Camera GUI** takes a picture and displays it as soon as the application
    has started.
  prefs: []
  type: TYPE_NORMAL
- en: When the **Shutter** button is pressed, `self.shutter()` is called. This calls
    `this.btnState("disabled")` to disable the **Shutter** button while we are taking
    new pictures. This prevents any pictures being taken while the camera is already
    in use. When the rest of the actions have been completed, `this.btnState("active")`
    is used to re-enable the button.
  prefs: []
  type: TYPE_NORMAL
- en: The `self.shutter()` function will call either the `self.normal()` or `self.preview()`
    function, depending on the status of the **Preview** checkbox (by getting the
    value of `self.previewUpdate`).
  prefs: []
  type: TYPE_NORMAL
- en: The `cameraGUI.camCapture()` function uses `pycamera` to create a camera object,
    set the resolution, and capture an image using the required filename. The `self.preview()`
    function takes an image called `PREVIEW_FILE` with a resolution of `PV_SIZE` as
    defined in the `SET` class.
  prefs: []
  type: TYPE_NORMAL
- en: Next, `self.updateDisp(PREVIEW_FILE)` is called and will use `cameraGUI.getTKImage()`
    to open the generated `PREVIEW.gif` file as a `TK.PhotoImage` object and apply
    it to the `Canvas` object in the GUI. We now call `self.update()`, which is a
    function inherited from the `TK.Frame` class; `self.update()` will allow the Tkinter
    display to be updated (in this case, with the new image). Finally, the `self.preview()`
    function will also call `self.msg()`, which will update the `self.filename` value
    with the filename of the image being displayed (`PREVIEW.gif`). Again, this also
    uses `self.update()` to update the display.
  prefs: []
  type: TYPE_NORMAL
- en: If the **Preview** checkbox is unchecked, then the `self.shutter()` function
    will call `self.normal()`. However, this time it will take a much larger 2,592
    x 1,944 (5 megapixel) JPG image with the filename set to the latest `<timestamp>`
    value obtained from `self.timestamp()`. The resultant image is also resized and
    converted to a PPM image so it can be loaded as a `TK.PhotoImage` object that
    will be displayed in the application window.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The camera application makes use of class structures to organize the code and
    make it easy to extend. In the following sections, we explain the types of methods
    and functions we have defined to allow this.
  prefs: []
  type: TYPE_NORMAL
- en: The Raspberry Pi can also make use of standard USB cameras or webcams. Alternatively,
    we can use additional Video4Linux drivers to allow the camera module to work like
    a standard webcam.
  prefs: []
  type: TYPE_NORMAL
- en: Class member and static functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `cameraGUI` class has two types of function defined. First, we define some
    static methods (`run()`, `getTKImage()`, and `timestamp()`). These methods are
    tied to the class rather than to a specific instance; this means that we can use
    them without referring to a particular `cameraGUI` object but to the class itself.
    This is useful to define utility functions that are related to the class, since
    they may be useful in other parts of the program as well and may not need to access
    the data/objects contained within a `cameraGUI` object. The functions can be called
    using `cameraGUI.run("command")`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we define the class member functions that, as in the previous classes
    we have used, include a reference to `self`. This means that they are only accessible
    to instances of the class (objects of the type `cameraGUI`) and can use the data
    contained within the object (using the `self` reference).
  prefs: []
  type: TYPE_NORMAL
- en: Using a USB webcam instead
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Raspberry Pi camera module is not the only way you can add a camera to the
    Raspberry Pi; in most cases, you can use a USB webcam as well. The current Raspberry
    Pi Raspbian image should detect the most common webcam devices automatically when
    you plug them in; however, the support can vary.
  prefs: []
  type: TYPE_NORMAL
- en: 'To determine if your webcam has been detected, check to see if the following
    device file has been created on your system by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If detected successfully, you will see `/dev/video0` or something similar, which
    is the reference you will use to access your webcam.
  prefs: []
  type: TYPE_NORMAL
- en: 'Install a suitable image capture program, such as `fswebcam`, using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You can test it with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Or alternatively, you can test it using `dd` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Webcams can require additional power from the USB ports of the Raspberry Pi;
    if you get errors, you may find that using a powered USB hub helps. For a list
    of supported devices and for troubleshooting, see the Raspberry Pi wiki page at
    [http://elinux.org/RPi_USB_Webcams](http://elinux.org/RPi_USB_Webcams).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous example, change the following functions in the `cameraGUI`
    class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove `camCapture()` and remove `import picamera as picam` from the start of
    the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Within `normal()`, replace `cameraGUI.camCapture(name,SET.NORM_SIZE)` with
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Within `preview()`, replace `cameraGUI.camCapture(SET.PREVIEW_FILE,SET.PV_SIZE)`
    with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Within the `SET` class, define the following variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: By making the previous changes to the `cameraGUI` class, the connected USB webcam
    will take the images instead.
  prefs: []
  type: TYPE_NORMAL
- en: Additional drivers for the Raspberry Pi camera
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Video4Linux drivers are available for the Raspberry Pi camera module. While
    these additional drivers are not quite official yet, it is likely that they will
    be included in the Raspbian image when they are. For more details, see [http://www.linux-projects.org/uv4l/](http://www.linux-projects.org/uv4l/).
  prefs: []
  type: TYPE_NORMAL
- en: The driver will allow you to use the camera module like you would a USB webcam,
    as a `/dev/video*` device, although you will not need this for the examples in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to install the additional drivers:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, download the `apt` keys and add the source to the `apt` sources list.
    You can do this with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following into the file (on a single line):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the drivers with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To use the `uv4l` driver, load it using the following command (on a single
    line):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The Raspberry Pi will then be accessible through `/dev/video0` (depending on
    whether you have other video devices installed). It can be used with standard
    webcam programs.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For more examples on using the Tkinter library, see [Chapter 3](ch03.html "Chapter 3. Using
    Python for Automation and Productivity"), *Using Python for Automation and Productivity*,
    and [Chapter 4](ch04.html "Chapter 4. Creating Games and Graphics"), *Creating
    Games and Graphics*.
  prefs: []
  type: TYPE_NORMAL
- en: Generating a time-lapse video
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having a camera attached to a computer provides us with a great way to take
    pictures at controlled intervals and automatically process them into a video to
    create a time-lapse sequence. The `pycamera` Python module has a special `capture_continuous()`
    function that will create a series of images. For the time-lapse video, we will
    specify the time between each image and the total number of images that need to
    be taken. To help the user, we will also calculate the overall duration of the
    video to provide an indication of how long it will take.
  prefs: []
  type: TYPE_NORMAL
- en: 'We shall add to our previous GUI interface to provide controls to run time
    lapses and also automatically generate a video clip from the results. The GUI
    will now look similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating a time-lapse video](img/6623OT_08_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The time-lapse application
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You will need everything set up as it was for the previous example, including
    the `cameraGUI.py` file that we created in the same directory and `pycamera`,
    which we installed. We shall also use `mencoder`, which will allow us to take
    the time-lapse images and combine them into a video clip.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install `mencoder`, use `apt-get`, as shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: An explanation of the command-line options can be found in the `mencoder` man
    pages.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create `timelapseGUI.py` in the same directory as `cameraGUI.py` by performing
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by importing the supporting modules (including `cameraGUI`) as shown
    in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extend the `cameraGUI.SET` class with settings for the time lapse and encoding
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extend the main `cameraGUI` class with an additional function to perform the
    time lapse as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the extra controls for the time-lapse GUI as shown in the following code
    snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add supporting functions to calculate the settings and handle the time lapse
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add supporting functions to handle and generate the time-lapse video as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create the following `cameraGUI2timelapse.py` script to use the GUI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We import `timelapseGUI` instead of `cameraGUI`; this will add the `timelapseGUI`
    module to the `cameraGUI` script.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the example with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `timelapseGUI.py` script allows us to take the classes defined in `cameraGUI.py`
    and extend them. The previous `cameraGUI` class inherits all of the content of
    the `TK.Frame` class, and using the same technique we can also inherit the `SET`
    and `cameraGUI` classes in our application.
  prefs: []
  type: TYPE_NORMAL
- en: We add some additional settings to the `SET` class to provide the settings for
    `mencoder` (to encode the video).
  prefs: []
  type: TYPE_NORMAL
- en: 'We shall extend the basic `cameraGUI` class by inheriting from `camGUI.cameraGUI`
    and defining a new version of `__init__()` for the class. Using `super()`, we
    can include the functionality from the original `__init__()` function and then
    define the extra controls we want to add to the GUI. The extended GUI is shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The time-lapse GUI layout that extends the base camera GUI
  prefs: []
  type: TYPE_NORMAL
- en: 'We define the following control variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`self.numImageTL`: This is linked to the value of the `numImgSpn` spinbox control
    to specify the number of images we want to take in our time lapse (and also provide
    the `numimages` value for `camTimelapse`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`self.peroidTL`: This is linked to the value of the `peroidSpn` spinbox control;
    it determines how many seconds there should be between the time-lapse images (and
    also provides the `timedelay` value for `camTimelapse`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`self.totalTimeTL`: This is linked to the `totalTime` label object. It is calculated
    using the number of images and the `timedelay` time between each to indicate how
    long the time lapse will run for.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`self.genVideoTL`: This controls the state of the `genChk` checkbox control.
    It is used to determine whether the video has been generated after the time-lapse
    images have been taken.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We link both of the spinbox controls to `self.calcTLTotalTime()` so that when
    they are changed, the `totalTimeTL` value is also updated (although it is not
    called if they are edited directly). We link `genChk` to `self.genVideoChk()`
    and `TLBtn` to `self.timelapse()`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we specify the positions of the controls using `grid()` and set some
    defaults for the time-lapse settings.
  prefs: []
  type: TYPE_NORMAL
- en: The `self.genVideoChk()` function is called when the `genChk` checkbox is ticked
    or cleared. This allows us to inform the user of the effect that this checkbox
    has by generating a pop-up message box to say if the video will be generated at
    the end of the time lapse or if just images will be created.
  prefs: []
  type: TYPE_NORMAL
- en: When the **TL GO!** button is pressed (`TLBtn`), `self.timelapse()` is called;
    this will disable the **Shutter** and **TL GO!** buttons (since we have also extended
    the `self.btnState()` function). The `self.timelapse()` function will also set
    the `self.tstamp` value so the same timestamp can be used for the images and the
    resulting video file (if generated).
  prefs: []
  type: TYPE_NORMAL
- en: 'The time lapse is run using the `camTimelapse()` function as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We create a new `PiCamera` object, set the image resolution, and start a `for…in`
    loop for `capture_continuous()`. Each time an image is taken, we print the filename
    and then wait for the required `timedelay` value. Finally, when the required number
    of images have been taken, we break out of the loop and continue.
  prefs: []
  type: TYPE_NORMAL
- en: Once this is complete, we check the value of `self.genVideoTL` to determine
    if we want to generate the video (which is handled by `genTLVideo()`).
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate the video, we first run the following command to create an `image_list.txt`
    file of the images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we run `mencoder` with the suitable settings (see the `mencoder` man pages
    for what each item does) to create an MPEG4-encoded (8 Mbps) AVI file with 24
    `frames per second (fps)` from the list of time-lapse images. The equivalent command
    (defined by `ENC_PROG`) is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Long commands can be split into several lines on the command terminal by using
    the `\` character. This allows you to continue writing the command on another
    line, only executing it when you finish a line without the `\` character.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter uses methods such as class inheritance and function overriding
    to structure and reuse our code in a number of different ways. When used correctly,
    these methods could enable us to design complex systems in a logical and flexible
    way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, when generating your own time-lapse sequences, you can opt to
    switch off the LED on the camera module or make use of the low-light version of
    the Raspberry Pi camera: the NoIR camera.'
  prefs: []
  type: TYPE_NORMAL
- en: Class inheritance and function overriding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous example, we used some clever coding in order to reuse our original
    `cameraGUI` class and create a plugin file that extends its features.
  prefs: []
  type: TYPE_NORMAL
- en: 'The class name does not have to be the same as `cameraGUI` (we just use it
    in this case so we can swap out the additional GUI components just by changing
    the file we import). In fact, we could define one basic class that contains several
    general functions and then extend the class by inheritance into a number of subclasses;
    here, each subclass defines specific behaviors, functions, and data. The extending
    and structuring of the subclasses is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Class inheritance and function overriding](img/6623OT_08_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This diagram shows how classes can be extended and structured
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this, we will take a non-code example in which we have written
    a general recipe for preparing a cake. You can then extend the `basicCake` recipe
    by inheriting all the `basicCake` elements and add some additional steps (equivalent
    code functions) to perhaps add icing/frosting on top to make an `icedCake(basicCake)`
    class. We did this with our `SET` class by adding additional items to an existing
    class (we just chose not to change the name).
  prefs: []
  type: TYPE_NORMAL
- en: We can also add in some additional elements to the existing steps (add some
    currants at the `addIngredients` step and create `currantCake(basicCake)`). We
    have done this using the `super()` function in our code by adding additional parts
    to the `__init__()` function. For example, we would use `super(basicCake.self).addIngredients()`
    to include all the steps in the `addIngredients()` function defined in the `basicCake`
    class, and then add an extra step to include currants. The advantage is if we
    then change the basic cake ingredients, it will also flow through to all the other
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: You could even override some of the original functions by replacing them with
    new ones; for instance, you could replace the original recipe for `basicCake`
    with one to make `chocolateCake(basicCake)` while still using the same instructions
    to cook, and so on. We can do this by defining replacement functions with the
    same names without using `super()`.
  prefs: []
  type: TYPE_NORMAL
- en: Using structured design in this way can become very powerful since we can easily
    create many variants of the same sort of object but have all the common elements
    defined in the same place. This has many advantages when it comes to testing,
    developing, and maintaining large and complex systems. The key here is to take
    an overall view of your project and try to identify the common elements before
    you begin. You will find that the better the structure you have, the easier it
    is to develop and improve it.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on this, it is worth reading up on object-oriented design
    methods and how to use **Unified Modelling Language** (**UML**) to help you describe
    and understand your system.
  prefs: []
  type: TYPE_NORMAL
- en: Disabling the camera LED
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you want to create time-lapse videos at night or next to windows, you may
    notice that the red camera LED (which lights up for every shot) adds unwanted
    light or reflections. Fortunately, the camera LED can be controlled through the
    GPIO. The LED is controlled using `GPIO.BCM` Pin 5; unfortunately, there isn't
    an equivalent `GPIO.BOARD` pin number for it.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add it to a Python script, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Alternatively, you could use the LED for something else, for example, as an
    indicator as part of a delay timer that provides a countdown and warning that
    the camera is about to take an image.
  prefs: []
  type: TYPE_NORMAL
- en: Pi NoIR – taking night shots
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There is also a variant of the Raspberry Pi camera module available called **Pi
    NoIR**. This version of the camera is the same as the original, except that the
    internal infrared filter has been removed. Among other things, this allows you
    to use infrared lighting to illuminate areas at night time (just like most night
    security cameras do) and see everything that is happening in the dark!
  prefs: []
  type: TYPE_NORMAL
- en: '*The MagPi* Issue 18 ([https://www.raspberrypi.org/magpi/](https://www.raspberrypi.org/magpi/))
    has published an excellent feature explaining the other uses of the Pi NoIR camera
    module.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a stop frame animation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stop frame (or stop motion) animation is the process of taking a series of still
    images of items, while making very small movements (typically of an easily moveable
    object such as a doll or plasticine model) in each frame. When the frames are
    assembled into a video, the small movements combine to produce an animation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a stop frame animation](img/6623OT_08_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Multiple images can be combined into an animation
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, such animations were made by taking hundreds or even thousands
    of individual photos on a film camera (such as a Cine Super 8 movie camera) and
    then sending the film off to be developed and playing back the results some weeks
    later. Despite the inspiring creations by Nick Park at Aardman Animations, including
    Wallace and Gromit (which are full-length, stop frame animation films), this was
    a hobby that was a little out of reach for most.
  prefs: []
  type: TYPE_NORMAL
- en: In the modern digital age, we can take multiple images quickly and easily with
    the luxury of reviewing the results almost instantly. Now anyone can try their
    hand at their own animated masterpieces with very little cost or effort.
  prefs: []
  type: TYPE_NORMAL
- en: We will extend our original **Camera GUI** with some extra features that will
    allow us to create our own stop frame animations. It will allow us to take images
    and try them out in a sequence before generating a finished video for us.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The software setup for this example will be the same as the previous time-lapse
    example. Again, we will need `mencoder` to be installed and we need the `cameraGUI.py`
    file in the same directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will also need something to animate, ideally something you can put in different
    poses, like the two dolls shown in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/6623OT_08_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Two potential stars for our stop frame animation
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create `animateGUI.py` in the same directory as `cameraGUI.py` by performing
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by importing the supporting modules (including `cameraGUI`), as shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extend the `cameraGUI.SET` class with settings for the image size and encoding
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extend the main `cameraGUI` class with the functions required for the animation
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add functions to list the images that were taken and remove them from the list
    using the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Include functions to perform the test animation using the image list as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create the following `cameraGUI3animate.py` file to use the GUI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the example with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once again, we create a new class based on the original `cameraGUI` class.
    This time, we define the following GUI with six extra controls:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The animation GUI layout
  prefs: []
  type: TYPE_NORMAL
- en: We create a listbox control (`imageListbox`) that will contain a list of the
    `.jpg` images in the current directory (`self.theList`). This control has a vertical
    scroll bar (`yscroll`) linked to it to allow easy scrolling of the list, and `selectmode=TK.EXTENDED`
    is used to allow multiple selections using *Shift* and *Ctrl* (for block and group
    selections).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we add a **Trim** button (`timeBtn`) that will call `self.trim()`. This
    will remove any items that have not been selected in the list. We use `curselection()`
    to get a list of the currently selected items from the `imageListbox` control.
    The `curselection()` function normally returns a list of indexes that are numerical
    strings, so we use `map(int,...)` to convert the result into a list of integers.
  prefs: []
  type: TYPE_NORMAL
- en: We use this list to get all the indexes that have not been selected using our
    utility `diff(a,b)` function. The function compares a full list of indexes against
    the selected ones and returns any that haven't been selected.
  prefs: []
  type: TYPE_NORMAL
- en: The `self.trim()` function uses `os.rename()` to change the filename extensions
    from `.jpg` to `.jpg.bak` for all the non-selected images. We could delete them
    using `os.remove()`, but we only really want to rename them to stop them from
    appearing in the list and final video. The list is repopulated using `self.updateList()`,
    which updates `self.theList` with a list of all the `.jpg` files available.
  prefs: []
  type: TYPE_NORMAL
- en: We add a scale control (`speedScale`) that is linked to `self.speed` and is
    used to control the playback speed of the animation test. As earlier, we add a
    **Generate** button (`genBtn`) that calls `self.generate()`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we add the **Animate** button (`animateBtn`). The text for the button
    is linked to `self.btnAniTxt` (making it easy to change within our program), and
    when pressed, the button calls `self.animate()`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We override the original `shutter()` function from the original `cameraGUI`
    script by adding a call to `self.updateList()`. This ensures that after an image
    has been taken, the list of images is updated with the new image automatically.
    Again, we use `super()` to ensure that the original functionality is also performed.
  prefs: []
  type: TYPE_NORMAL
- en: The `animate()` function (called by clicking on the **Animate** button) allows
    us to test a selection of images to see whether they will make a good animation
    or not. When the button is clicked on, we change the text of the button to **STOP**,
    the `self.animating` flag to **True** (to indicate that the animation mode is
    running), and call `doAnimate()`.
  prefs: []
  type: TYPE_NORMAL
- en: The `doAnimate()` function first gets a list of currently selected images in
    the `imageListbox` control, generates a list of `TK.PhotoImage` objects, and attaches
    them to the `self.canvas` object in the GUI. However, if only one image has been
    selected, we display it directly using `self.updateDisp()`. Alternatively, if
    no images have been selected, it will try to use them all (unless the list is
    empty, in which case it will inform the user that there are no images to animate).
    When we have more than one `TK.PhotoImage` object linked to the canvas, we can
    loop through them using the `cycleImages()` function.
  prefs: []
  type: TYPE_NORMAL
- en: The `TK.PhotoImage` objects are all created with their states set to `TK.HIDDEN`,
    which means they are not visible on the canvas. To produce the animation effect,
    the `cycleImages()` function will set each image to `TK.NORMAL` and then `TK.HIDDEN`
    again, allowing each frame to be displayed for 1 divided by `self.speed` (the
    fps value set by the Scale control) seconds before showing the next.
  prefs: []
  type: TYPE_NORMAL
- en: The `cycleImages()` function will perform the animation as long as `self.animating`
    is **True**, that is, until the `animateBtn` object is clicked on again.
  prefs: []
  type: TYPE_NORMAL
- en: Once the user is happy with their animation, they can generate the video using
    the **Generate** button (`genBtn`). The `generate()` function will call `mencoder`
    to generate the final video of all the images in the `imageListbox` control.
  prefs: []
  type: TYPE_NORMAL
- en: If you really want to get into producing animations, you should consider adding
    some extra features to help you, such as the ability to duplicate and reorder
    frames. You may want to add some manual adjustments for the camera to avoid white
    balance and lighting fluctuations caused by the automatic settings of the camera.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The camera module is ideal for close-up photography due to its small size and
    ability to be remotely controlled. By using small lenses or adding hardware controls,
    you could make a purpose-built animation machine.
  prefs: []
  type: TYPE_NORMAL
- en: Improving the focus
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Raspberry Pi camera lens has been designed mainly for middle to long distance
    photography, and it therefore has trouble focusing on objects that are closer
    than 25 cm (10 inches). However, using some basic lenses, we can adjust the effective
    focal length and make it more suitable for macro photography. You can use add-on
    lenses that are available for mobile phones or credit card-style magnifier lenses
    to adjust the focus, as shown in the following images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Improving the focus](img/6623OT_08_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: An add-on macro lens (right) and a credit card magnifier (left) can improve
    the focus of close-up items
  prefs: []
  type: TYPE_NORMAL
- en: Creating a hardware shutter
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Of course, while it is useful to have a display available to review the images
    taken, it is often useful to be able to simply press a physical button to take
    an image. Fortunately, this is just a matter of attaching a button (and resistor)
    to a GPIO pin, as we have done previously (see the *Responding to a button* recipe
    in [Chapter 6](ch06.html "Chapter 6. Using Python to Drive Hardware"), *Using
    Python to Drive Hardware*), and creating suitable GPIO control code to call our
    `cameraGUI.camCapture()` function. The code for this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous code will take a picture when the button is pressed. The following
    diagram shows the connections and circuit diagram required to achieve this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a hardware shutter](img/6623OT_08_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The button (and 1K ohm resistor) should be connected between pins 12 and 6 (GND)
  prefs: []
  type: TYPE_NORMAL
- en: You don't even have to stop here since you can add buttons and switches for
    any of the controls or settings for the camera if you want to. You can even use
    other hardware (such as infrared sensors and so on) to trigger the camera to take
    an image or video.
  prefs: []
  type: TYPE_NORMAL
- en: Making a QR code reader
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have probably seen QR codes in various places, and perhaps even used a few
    to pick up links from posters or adverts. However, they can be far more useful
    if you make your own. The following example discusses how we can use the Raspberry
    Pi to read QR codes and the hidden content (or even link to an audio file or video).
  prefs: []
  type: TYPE_NORMAL
- en: 'This could be used to create your own personalized Raspberry Pi QR code jukebox,
    perhaps as an aid for children to provide solutions to math problems, or even
    to play an audio file of you reading your kid''s favorite book as they follow
    along page by page. The following screenshot is an example of a QR code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Making a QR code reader](img/6623OT_08_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You can use QR codes to make magical self-reading books
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example requires a setup similar to the previous examples (except we won't
    need `mencoder` this time). We will need to install **ZBar**, which is a cross-platform
    QR code and barcode reader, and **flite** (a text-to-speech utility that we used
    in [Chapter 6](ch06.html "Chapter 6. Using Python to Drive Hardware"), *Using
    Python to Drive Hardware*).
  prefs: []
  type: TYPE_NORMAL
- en: 'To install ZBar and flite, use `apt-get` as shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are Python 2.7 libraries available for Zbar, but they are not currently
    compatible with Python 3\. Zbar also includes a real-time scanner (`zbarcam`)
    that uses video input to detect barcodes and QR codes automatically. Unfortunately,
    this isn't compatible with the Raspberry Pi camera either.
  prefs: []
  type: TYPE_NORMAL
- en: This isn't a big problem for us since we can use the `zbarimg` program directly
    to detect the QR codes from images taken with `picamera`.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have the software installed, you will need some QR codes to scan (see
    the *There's more…* section in *Generating QR codes*) and some suitably named
    MP3 files (these could be recordings of you reading the pages of a book or music
    tracks).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create the following `qrcodeGUI.py` script in the same directory as `cameraGUI.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create a copy of `cameraGUItimelapse.py` or `cameraGUIanimate.py` and
    call it `cameraGUIqrcode.py`. Again, make sure you import the new file for the
    GUI using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The GUI with QR code will look as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/6623OT_08_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The QR code GUI
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The new `qrcodeGUI.py` file adds the **Read** and **Play** checkbox controls
    and a button control to start scanning for QR codes. When **QR GO!** is clicked
    on, `self.qrGet()` will start a cycle of taking images and checking the result
    with `zbarimg`. If `zbarimg` finds a QR code in the image, then the scanning will
    stop and the result will be displayed. Otherwise, it will continue to scan until
    the **STOP** button is clicked on. While the scanning is taking place, the text
    for `QRBtn` is changed to **STOP**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to capture the output of `zbarimg`, we have to change how we run the
    command slightly. To do this, we define `run_p()`, which uses the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This returns `stdout` as part of the `proc` object, which contains the output
    of the `zbarimg` program. We then extract the resulting QR code that was read
    from the image (if one was found).
  prefs: []
  type: TYPE_NORMAL
- en: When **Read** is selected, `flite` is used to read out the QR code, and if **Play**
    is selected, `omxplayer` is used to play the file (assuming the QR code contains
    a suitable link).
  prefs: []
  type: TYPE_NORMAL
- en: For the best results, it is recommended that you take a preview shot first to
    ensure that you have lined up the target QR code correctly before running the
    QR scanner.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Example QR code page markers (page001.mp3 and page002.mp3)
  prefs: []
  type: TYPE_NORMAL
- en: The previous QR codes contain `page001.mp3` and `page002.mp3`. These QR codes
    allow us to play files with the same name if placed in the same directory as our
    script. You can generate your own QR codes by following the instructions in the
    *There's more…* section in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: You could even use the book's ISBN barcode to select a different directory of
    MP3s based on the barcode read; the barcode allows you to reuse the same set of
    page-numbered QR codes for any book you like.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To make use of the previous example, you can use the example in the next section
    to generate a range of QR codes to use.
  prefs: []
  type: TYPE_NORMAL
- en: Generating QR codes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can create QR codes using **PyQRCode** (see [https://pypi.python.org/pypi/PyQRCode](https://pypi.python.org/pypi/PyQRCode)
    for more information).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can install PyQRCode using the PIP Python manager as follows (see the *Getting
    ready* section of the *Displaying photo information in an application* recipe
    in [Chapter 3](ch03.html "Chapter 3. Using Python for Automation and Productivity"),
    *Using Python for Automation and Productivity*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'To encode QR codes in the PNG format, PyQrCode uses PyPNG ([https://github.com/drj11/pypng](https://github.com/drj11/pypng)),
    which can be installed with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following `generateQRCodes.py` script to generate QR codes to link
    to files, such as the `page001.mp3` and `page002.mp3` files that you have recorded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Run this code using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The previous code will create a set of QR codes that can be used to activate
    the required MP3 file and read the page out loud (or play the file that you have
    linked to it).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Open Source Computer Vision** (**OpenCV**) project is a very powerful
    image and video processing engine; more details are available at [http://opencv.org](http://opencv.org).
  prefs: []
  type: TYPE_NORMAL
- en: By combining the camera with OpenCV, the Raspberry Pi is able to recognize and
    interact with its environment.
  prefs: []
  type: TYPE_NORMAL
- en: An excellent example of this is Samuel Matos's RS4 OpenCV Self-balancing Robot
    ([http://roboticssamy.blogspot.pt](http://roboticssamy.blogspot.pt)) that can
    seek out and respond to various custom signs; the camera module can be used to
    navigate and control the robot.
  prefs: []
  type: TYPE_NORMAL
- en: Discover and experiment with OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The OpenCV library is an extensive library aimed at providing real-time computer
    vision processing across multiple platforms. Essentially, if you want to do any
    serious image processing, object recognition, or analysis, then OpenCV is a perfect
    place to get started.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, the latest release of OpenCV (version 3) has added support for
    interfacing via Python 3\. Although performing real-time video processing can
    often require a computer with a powerful CPU, it will run on relativity limited
    devices such as the original Raspberry Pi (version 1). Using the more powerful
    Raspberry Pi 2 is highly recommended for the following recipes.
  prefs: []
  type: TYPE_NORMAL
- en: The concepts and underlying methods behind image and video processing can get
    rather complicated. This first recipe shall demonstrate how to work with OpenCV
    and most importantly provide an easy way to visualize various stages that may
    be used for processing images.
  prefs: []
  type: TYPE_NORMAL
- en: '![Discover and experiment with OpenCV](img/6623OT_08_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: When performing tests with the camera ensure you have suitable test subjects
    available
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The OpenCV library is written in C++ and needs to be compiled before we can
    use it on the Raspberry Pi. To do this, we will need to install all the required
    packages and then download a release from the OpenCV Git repository. OpenCV can
    require around 2.5 GB of space while it compiles; however, a standard installation
    of Raspbian from NOOBS can use around 5.5 GB. This means there may be insufficient
    space available on an 8 GB SD card. It may be possible to squeeze OpenCV onto
    a smaller SD card (by installing a custom Raspbian image or utilizing a USB flash
    device); however, to avoid complications, it is recommended you use at least a
    16 GB SD card to compile and install OpenCV on.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, while the majority of recipes in this book can be run using SSH
    and X11-forwarding over a network connection, the OpenCV display window appears
    to function far more effectively if you are connected to a local screen (via HDMI)
    and controlled directly with a local input devices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Installing OpenCV is quite a long process, but I feel the results are well
    worth the effort:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ensure that the Raspberry Pi is as up to date as possible, using the following
    commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And perform a reboot to apply the changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before we compile OpenCV, we need to install a number of dependencies to support
    the build process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We also need to install a number of supporting libraries and packages used
    by OpenCV (we may not use all of these, but they form part of the build process).
    These will also provide support for a wide range of image and video formats from
    within OpenCV:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also install NumPy, which is very useful when manipulating image arrays
    within OpenCV, **Automatically Tuned Linear Algebra Software** (**ATLAS**), and
    GFortran for additional mathematic functionality:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that we have the supporting packages, we can download OpenCV and OpenCV
    Contributed (extra modules) directly from GitHub. We will also create a build
    location ready for the next step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: You can download the latest version using the following links and
    selecting a specific release tag; however, you may find you require additional
    dependencies or modules for the package to compile successfully. Ensure you select
    the same release for OpenCV and the contributed modules.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[https://github.com/Itseez/opencv/](https://github.com/Itseez/opencv/)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[https://github.com/Itseez/opencv_contrib/](https://github.com/Itseez/opencv_contrib/)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `make` file can be created using the following commands. This takes around
    10 minutes to finish (see the following screenshot):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Getting ready](img/6623OT_08_018.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Ensure that the Python 2.7 and Python 3 sections match this screenshot
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We are now ready to compile OpenCV; be warned this will take a considerable
    amount of time to complete. Fortunately, if you have to stop the process or if
    there is a problem, you can resume the `make` command, checking and skip ping
    any components that have already been completed. To restart the `make` from the
    start, use `make clean` to clear the build and start afresh.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: By using all four processing cores on the Raspberry Pi 2, the build
    time can be reduced to just over an hour. Use the `–j4` switch to enable the four
    cores, which will allow multiple jobs to be run during the build process.'
  prefs: []
  type: TYPE_NORMAL
- en: The build can take almost three hours to complete. If you have the Raspbian
    desktop loaded or you are running other tasks in the background, it is recommended
    you log out to the command line and stop any additional jobs, otherwise the process
    may take even longer to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a Raspberry Pi 1, use a single-threaded `make` job with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'For a Raspberry Pi 2, enable up to four simultaneous jobs by using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '![Getting ready](img/6623OT_08_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A completed build should look like this
  prefs: []
  type: TYPE_NORMAL
- en: 'With OpenCV compiled successfully, it can be installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that is all completed, we can quickly test that OpenCV is now available
    to use with Python 3\. Run the following command to open the Python 3 terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'At the Python 3 terminal, enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: This will display the version of the OpenCV you have just installed!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: The OpenCV library is updated regularly, which can cause problems
    with the build process. Therefore, if you have issues, the Py Image Search website
    ([http://www.pyimagesearch.com](http://www.pyimagesearch.com)) is an excellent
    resource that contains the latest guides and video tutorials for installing OpenCV
    on the Raspberry Pi.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For our first OpenCV test, we will use it to display a captured image. Create
    the following `openimage.py` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Ensure before you run the script, that you capture an image to display using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the script with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The simple test program starts by importing OpenCV (`cv2`) and loading the image
    using `cv2.imread()`. We then use `cv2.imshow()` to display our image (`img`)
    in an image box with the title `'Frame'`. We then wait for a press of any key
    (`cv2.waitKey(0)`) before closing the display window.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The image is displayed in a standard frame as a grayscale image
  prefs: []
  type: TYPE_NORMAL
- en: Color detection with OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We shall begin experimenting with OpenCV by performing some basic operations
    on live image data. In this recipe, we shall perform some basic image processing
    to allow detection of different colored objects and track their location on screen.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to the setup from the previous recipe, you will need a suitable
    colored object to track. For example, a small colored ball, a suitable colored
    mug, or a pencil with a square of colored paper taped to it is ideal. The example
    should allow you to detect the location (indicated by a color spot) of blue, green,
    red, magenta (pink) or yellow objects.
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/6623OT_08_021.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We can use OpenCV to detect colored objects in an image
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create the following `opencv_display.py` script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the following `opencv_color_detect.py` script in the same directory
    as `opencv_display.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the example, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Use the *M* key to cycle through the available display modes, the *C* key to
    change the particular color we want to detect (blue, green, red, magenta or yellow),
    and the *I* key to display information about the detected contours and hierarchy
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/6623OT_08_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The raw image (top left) is processed with Blur (top right), Threshold (bottom
    left) and Contour (bottom right) operations.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first script (`opencv_display.py`) provides us with a common base for running
    our OpenCV examples from. The script consists of two functions, `begin_capture()`
    and `show_images()`.
  prefs: []
  type: TYPE_NORMAL
- en: The `begin_capture()` function sets up the PiCamera to take continuous frames
    (at 50 fps and a resolution of 640x480), converting them into a raw image format
    suitable for OpenCV to process. We use relatively low resolution images here since
    we do not need a lot of detail to perform the kind of processing we are aiming
    for. In fact, the smaller the images the less memory they use and the less intensive
    the processing that we need to perform is.
  prefs: []
  type: TYPE_NORMAL
- en: By using the `camera.capture_continuous()` function of the PiCamera library,
    we will get an image frame ready for us to process. We shall pass each new frame
    to the `process_image()` function, which will be provided by the `opencv_color_detect.py`
    file along with any captured key presses (to allow the user a little control).
    The `process_image()` function (which we will go through in further detail later
    on) returns two arrays (images and text).
  prefs: []
  type: TYPE_NORMAL
- en: We pass both the images and text arrays to the `show_images()` function, along
    with the selected `MODE` (which is controlled by the user pressing the `M` key
    to cycle through them). Within the `show_images()` function we use the text for
    the given MODE and use `putText()` to add it to the image we are displaying (again,
    whichever image corresponds to the selected `MODE`). Finally, we display the image
    in a separate window using `cv2.imshow()`.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_023.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The raw image is displayed by the script (including the tracking marker)
  prefs: []
  type: TYPE_NORMAL
- en: All the real fun is contained within the `opencv_color_detect.py` script, which
    performs all the required image processing to our raw video stream. The aim is
    to simplify the source image and then identify the middle of any area that matches
    our required color.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: The script purposely retains each stage of the processing so you
    can see the effect of each step on the previous image yourself. This is by far
    the best way to understand how we can go from a standard video image to something
    that the computer is able to comprehend. To achieve this, we use an array to collect
    the images as we produce them (using `images.append()` to add each new image and
    we use a *Pythonic* way to refer to the last item in an array, the `[-1]` notation.
    In other programming languages this would produce an error, but with Python it
    is perfectly acceptable to use negative numbers to count backwards from the end
    of an array (so it follows -1 is the first item from the end of the array, and
    -2 would be the second from the end).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `process_image()` image function shall produce four different images (which
    we provide references to in our `images` array). In the first image we simply
    keep a copy of our raw image (displayed as `0: Raw Image [Color]`). Since this
    is a full color untouched image, this shall be the image with which we shall show
    the location of the detected object (this is added at the end of function).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next image we produce is a blurred version of the original (displayed as
    `1: with Blur…[Color]`) by using the `cv2.blur()` function with the `BLUR` tuple
    to specify the amount on the (*x,y*) axes. By slightly blurring the image, we
    hope to eliminate any unnecessary detail or erroneous noise in the image; this
    is ideal since we are only interested in large blocks of color, so fine detail
    is irrelevant.'
  prefs: []
  type: TYPE_NORMAL
- en: The third image (displayed as `2:with Threshold…[color]`) is the result of applying
    the given upper and lower threshold using the `cv2.inRange()` function. This produces
    a simple black and white image, where any parts of the image that are between
    the upper and lower color thresholds are displayed in white. Hopefully, you will
    be able to clearly see your test object as you move it in front of the camera
    as a large white patch. You can check this image to ensure that your background
    is not confused with your target object. If the threshold image is mostly white
    then try a different color target, moving the camera to a different location,
    or adjusting the colors used in the threshold arrays (`THRESH_LOW/HI`).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note: The color mapping used in this example is OpenCV''s **BGR** format. This
    means that the pixel colors are stored as an array of three integers, for Blue,
    Green, and Red. The color thresholds are therefore specified in this format; this
    is contrary to the more typical RGB color format used for example in HTML web
    colors.'
  prefs: []
  type: TYPE_NORMAL
- en: The last image provides the final piece of the puzzle; displayed as `3:with
    Contours...[color]`, it shows the result of the `cv2.findContours()` function.
    OpenCV will calculate the contours in the image. This will discover all the edges
    of the shapes that were in the threshold image and return them in a list (contours).
    Each individual contour is an array of the (*x,y*) coordinates of the boundary
    points of each shape in the image.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: The contours are applied directly to the supplied image by the `cv2.findContours()`
    function, which is why we make a copy of the threshold image (using `images[-1].copy()`)
    so we can see both steps in our process. We also use `cv2.CHAIN_APPROX_SIMPLE`,
    which attempts to simplify the stored coordinates so any points that aren''t needed
    are skipped (for example, any along a straight line can be removed as long as
    we have the start and end points). Alternatively, we could use `cv2.CHAIN_APPROX_NONE`,
    which keeps all the points.'
  prefs: []
  type: TYPE_NORMAL
- en: We can use the list of contours to determine the area of each; in our case,
    we are most interested in the largest one (which will hopefully contain the object
    we are tracking as the largest area of the image that has colors within the given
    thresholds). We shall use `cv2.contourArea()` on each contour discovered to calculate
    the area and keep whichever one ends up being the largest.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can list the moments, which are a list of numbers that provide a
    mathematical approximation of the shape. The moments provide us with a simple
    calculation to obtain the centroid of the shape. The centroid is like the *center
    of mass* of the shape; for example, if it was made out of a flat solid piece of
    material, it would be the point at which you could balance it on the end of your
    finger.
  prefs: []
  type: TYPE_NORMAL
- en: '*cx, cy = M[''m10''] / M[''m00''], M[''m01''] / M[''m00''])*'
  prefs: []
  type: TYPE_NORMAL
- en: We display a small marker (consisting of the upper and lower threshold colors)
    using the calculated coordinates to indicate the detected location of the object.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_024.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The location of the object is marked with a colored spot as it tracked within
    the image
  prefs: []
  type: TYPE_NORMAL
- en: For additional information about OpenCV's contours and moments, see OpenCV-Python
    Tutorials ([http://goo.gl/eP9Cn3](http://goo.gl/eP9Cn3)).
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe allows us to track an object by detecting the required colors within
    the camera frame, which will provide a relative *x* and *y* position of the object.
  prefs: []
  type: TYPE_NORMAL
- en: We can mount the Raspberry Pi camera on a movable platform, for example a rover/bug
    robot platform (like the ones described in [Chapter 9](ch09.html "Chapter 9. Building
    Robots")) or by using a servo-controlled tilt and pan camera mount (as shown in
    the following image).
  prefs: []
  type: TYPE_NORMAL
- en: '![There''s more…](img/6623OT_08_025.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Raspberry Pi camera can be controlled using a servo mount
  prefs: []
  type: TYPE_NORMAL
- en: By combining the camera input and the object coordinates, we can make the Raspberry
    Pi track the object wherever it goes. If we detect that the object has moved to
    one side of the camera frame, we can use the Raspberry Pi hardware control to
    re-center the object within the camera frame (either by steering the robot or
    tilting and panning the camera).
  prefs: []
  type: TYPE_NORMAL
- en: '![There''s more…](img/6623OT_08_026.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The object has been detected in the top-right of the screen, so turn the camera
    to the right and up to follow the object
  prefs: []
  type: TYPE_NORMAL
- en: Performing motion tracking with OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While it is useful to be able to track objects of a specific color, sometimes
    we are just interested in the actual motion taking place. This is particularly
    true when the objects we wish to track could blend in with the background.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: Security cameras often use IR detectors to act as triggers; however,
    these rely upon detecting a change in detected heat across the sensor. This means
    they will not work if the object does not give off additional heat relative to
    the background and they will not track the direction of the motion.'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://learn.adafruit.com/pir-passive-infrared-proximity-motion-sensor/how-pirs-work](https://learn.adafruit.com/pir-passive-infrared-proximity-motion-sensor/how-pirs-work)'
  prefs: []
  type: TYPE_NORMAL
- en: The following recipe will demonstrate how OpenCV can be used to detect motion
    and also provide a record of where the object has been over a period of time.
  prefs: []
  type: TYPE_NORMAL
- en: '![Performing motion tracking with OpenCV](img/6623OT_08_027.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The motion of an object within the frame is traced on screen, allowing the pattern
    of movement to be recorded and studied
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following script will allow us to track an object and display its path on
    the screen. For this task, I have volunteered our family tortoise; however, any
    object that moves can be used.
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/6623OT_08_028.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Our tortoise made an excellent test subject; it was very interesting to see
    where she wandered during the day
  prefs: []
  type: TYPE_NORMAL
- en: The setup in this case works particularly well for the following reasons. Firstly,
    since the tortoise is of a similar color to the background we can't use the previous
    method of color detection (unless we stuck some markers on her). Secondly, the
    tortoise house has a useful shelf above it, allowing the Raspberry Pi and camera
    to be mounted directly above it. Finally, the enclosure is artificially lit, so
    other than the movement of the tortoise, the image observed should remain relatively
    constant during our testing. When performing this task with external factors such
    as natural light, you may find that they interfere with the moment detection (making
    it difficult to determine what is changes due to movement compared to changes
    in the environment – see the *There's more...* section for tips on overcoming
    this).
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the setup will be the same as the previous OpenCV recipe (see *Color
    detection with OpenCV*).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create the following script, called `opencv_detect_motion.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, find the following line in the `opencv_display.py` file (from the previous
    recipe):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the example, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Use the *M* key to cycle through the available display modes, the *G* key to
    toggle gray scale mode, the *I* key to display information about the detected
    contours and hierarchy data, and the *B* key to reset the image we set as the
    background.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The principle behind this motion detection method is elegantly simple. First,
    we take an initial image as our golden image (where no moment is taking place);
    we shall treat this as our static background. Now we simply compare any subsequent
    image to this original background image. If there is any significant difference
    from the first image, we assume the difference is due to movement. Once we have
    detected motion, we will then generate a trace of the movement over time and display
    it on the frame.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The golden image (right) is a gray-scale version of the raw image (left) with
    a Gaussian blur applied
  prefs: []
  type: TYPE_NORMAL
- en: When the script is run we ensure that the reset flag is set to `True`, which
    ensures we use the first image captured as the golden image (also, if the user
    presses *R* we allow the golden image to be refreshed with a new image). We also
    detect if the user presses *G*, which will switch between processing the image
    in grayscale or in color. The default is grayscale since this is more efficient
    to process and the colors do not matter when detecting motion (but it is interesting
    to see the result of the same processing when the images are still in color too).
  prefs: []
  type: TYPE_NORMAL
- en: Just like the previous recipe, we will keep a copy of each image to allow better
    understanding of each stage in the process. The first image that is displayed
    is `0:Raw Image`, which is a direct copy of the camera image (we will overlay
    the detected motion on this image).
  prefs: []
  type: TYPE_NORMAL
- en: In the next image, `1:with Gaussian Blur…`, we use `cv2.GaussianBlur(raw_image,
    GAUSSIAN, 0)`, providing a smoothed out version of the original (hopefully removing
    Gaussian noise from the image). Like the `blur` function, we provide the image
    to be processed and the *x,y* magnitudes (which for the Gaussian algorithm have
    to be positive and odd).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note: You can compare the Gaussian Blur with the standard blur method by inserting
    the following code (just before the Gaussian Blur section) and cycling between
    the modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: The background image is set using this blurred image (if it has not been set
    previously or it has been reset).
  prefs: []
  type: TYPE_NORMAL
- en: We use `cv2.absdiff(imageBG,images[-1])` to determine what differences there
    are between the `imageBG` (the original background image) and the latest Gaussian
    blurred image to provide `2:with image delta...`.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_030.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This image (inverted here to make it clearer) shows the difference from the
    golden image. The tortoise has moved near the middle of the image
  prefs: []
  type: TYPE_NORMAL
- en: Next, we apply a binary threshold mask (displayed as `3:with threshold mask…`),
    which will set any pixel between the upper (255) and lower (25) threshold to 255,
    resulting in a black and white image displaying the main areas of movement.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_031.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A threshold filter is applied to the delta image, highlighting the largest changes
    in the image
  prefs: []
  type: TYPE_NORMAL
- en: Now, we dilate the threshold image (displayed as `4:with dilation…`) using `cv2.dilate(images[-1],
    None, iterations=3)`. The `dilate` operation works by growing the white section
    of the image by a pixel in each iteration. By using `None` as the second parameter,
    we are setting the kernel to use a default value (alternatively, an array of 0s
    and 1s can be used to fully control how the dilation is applied).
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_032.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The dilated image grows the spots of detected movement
  prefs: []
  type: TYPE_NORMAL
- en: We use the `cv2.contours()` function, like we did in the previous recipe, to
    detect the outline of the detected shapes; the result is displayed as `5:with
    contours…`. We must convert the image to grayscale, if it isn't already, since
    this function works best with a binary image (an image that is black and white).
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/6623OT_08_033.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The area of the contours are calculated and used to determine the location of
    the main area of movement
  prefs: []
  type: TYPE_NORMAL
- en: As before, we calculate the area of each contour and discover which is the largest
    by using `cv2.contourAera()`. Then we determine the coordinates of the middle
    of the selected contour by finding the moments (via `cv2.moments()`). Finally,
    we add these coordinates to the moment array so we can display a trace of the
    detected movement on our original image.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, to trace relatively slow-moving objects we can also average several
    of the detected coordinates to provide a smoother trace of movement.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned at the start, external factors can interfere with this simple algorithm
    where even subtle changes in the environment can cause errors in the movement
    detection. Fortunately, techniques such as applying long term averaging to the
    background image (rather than a single onetime snapshot) will cause any gradual
    changes, such as lighting, to be incorporated into the background image.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although we have only briefly touched on a small aspect of the OpenCV library,
    it should be clear that it is perfect for use with the Raspberry Pi. We have seen
    OpenCV provides some very powerful processing with relative ease and the Raspberry
    Pi (particularly the Raspberry Pi model 2) is an ideal platform on which to run
    it.
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, it simply isn't practical to cover everything OpenCV is
    able to do within a few examples, but I hope it has at least whetted your appetite
    (and provided you with a ready-to-go setup from which you can experiment with
    and create your own projects).
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, not only are there lots of tutorials and guides available online,
    but there are also several books that cover OpenCV in great detail; in particular,
    the following Packt books are recommended:'
  prefs: []
  type: TYPE_NORMAL
- en: '*OpenCV Computer Vision with Python* by *Joseph Howse*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Raspberry Pi Computer Vision Programming* by *Ashwin Pajankar*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the last two examples, I've attempted to keep the code as brief as possible
    while ensuring it is easy to observe the inner workings behind the recipe. It
    should be very easy to adapt them or add your own simply by importing different
    modules with your own `process_images()` function in.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more ideas and projects, there is an excellent list on the following site:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.intorobotics.com/20-hand-picked-raspberry-pi-tutorials-in-computer-vision/](http://www.intorobotics.com/20-hand-picked-raspberry-pi-tutorials-in-computer-vision/)'
  prefs: []
  type: TYPE_NORMAL
