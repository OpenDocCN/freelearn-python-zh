<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Coroutines and Asynchronous I/O</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we looked at how to use multiple processes to increase the rate of data processing in our programs. This is great for CPU-bound programs because it allows them to use more than one CPU.</p>
<p>In this chapter, we'll look at the inverse of this case; we'll use a single CPU to handle multiple data processing tasks at once within a single process, which is great for I/O-bound programs. We'll see some of the nuts and bolts of working with asyncio. We'll also discuss asyncio's <kbd>future</kbd> class and how it's used. Then we'll move on to synchronization and communication between asynchronous coroutine tasks. Lastly, we'll see how to use asyncio and coroutines to write a client-server program to communicate over a network.</p>
<p>We will cover the following topics:</p>
<ul style="padding-left: 5px">
<li>The difference between asynchronous processing and parallel processing</li>
<li>Using the asyncio event loop and coroutine scheduler</li>
<li>Waiting for data to become available</li>
<li>Synchronizing multiple tasks</li>
<li>Communicating across a network</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The difference between asynchronous processing and parallel processing</h1>
                </header>
            
            <article>
                
<p>When we worked with the <kbd>concurrent.futures</kbd> module in <a href="4ce9ba50-f543-43ef-ba28-82c8833dfbcb.xhtml"><span class="ChapterrefPACKT">Chapter 6</span></a>, <em>Parallel Processing</em>, we saw a way to make two or more streams of code run at the same time. For reference, have a look at the code example we used in the previous chapter:</p>
<div class="CDPAlignCenter CDPAlign"><img height="391" width="475" class="aligncenter size-full wp-image-945 image-border" src="assets/47709d60-41fe-4ebd-a503-8e9b46bec5c7.jpg"/></div>
<p>This code helps you create an executor object. Now if you ever wish to run some code in parallel, you could just tell the executor to do it. The executor would give us a future object that we could use later to get the result of the code, and it would then run the code in a separate process. Our original code will keep on running in the original process.</p>
<p>We talked about how this could improve the performance of CPU-bound programs—it divides the code into multiple computer cores. Therefore, it's a technique that would be convenient in a lot of other circumstances.</p>
<p>It's handy to be able to tell the computer to "go do this and let me know when you're done".</p>
<p>One place where this ability seems particularly useful is in network server programs, where having a separate stream of execution for each connected client makes the logic and structure of the code much easier to grasp; it's easier to write bug-free servers when they're structured this way.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multithreading is not good for servers</h1>
                </header>
            
            <article>
                
<p>There are ways to write a server that would use only a single stream of execution, but if we have a way of writing servers that would probably introduce fewer bugs, why not? The problem is resource overhead.</p>
<p>Every process running on a computer uses up memory and CPU time, of course; however, in addition to the memory and CPU time, the process needs to run its code as well. The operating system also needs to expend some resources to manage the process. As it happens, the time spent on switching between processes is significant.</p>
<p>Memory overhead is enough; it becomes a limiting factor for how many clients a multiprocess server can handle simultaneously; other internal operating system resources may be even more limiting.</p>
<p>For CPU-bound programs, there's a sweet spot that produces optimal results, where the program has one process per CPU core. For an I/O-bound program, which most servers are, any process beyond the first is nothing but overhead. As mentioned, there are ways to write single-process servers that can handle multiple clients at once with much lower overhead per connected client.</p>
<p>These techniques allow a server to handle many more clients at once than what the multiprocess server program could manage. Even when not operating at full capacity, a single-process server leaves the majority of a computer's resources available for other uses.</p>
<p>So, on one hand, we have a way of writing servers that is logically structured and less prone to bugs but wastes resources. On the other hand, we have a way of writing servers that is resource efficient but easy to get wrong.</p>
<p>Can we somehow get the best of both the worlds? The answer is, yes!</p>
<p>Fortunately, Python's standard <kbd>asyncio</kbd> module combines low-level techniques that allow a single process to service multiple clients with a cooperative coroutine scheduler. Refer to the following code example:</p>
<div class="CDPAlignCenter CDPAlign"><img height="143" width="232" class="image-border" src="assets/e8baa894-4303-4f66-9f95-37acb23b76b8.jpg"/></div>
<p>The end result is a programming interface<span> that looks and acts a lot like <kbd>concurrent.futures</kbd> but with much lower overhead per stream of code execution. That's great, but what's a cooperative coroutine scheduler? For that matter, what's a coroutine?</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cooperative coroutine scheduler versus coroutine</h1>
                </header>
            
            <article>
                
<p>Before we get into detail, let's define these two terms:</p>
<ul style="padding-left: 5px">
<li>A coroutine is a computer science concept, a function that can be paused and resumed at certain intervals within it. Each time it is paused, it sends data out, and each time it is resumed, it receives data.</li>
</ul>
<p style="padding-left: 30px">Python programs can define coroutines using the async and await keywords, and asyncio makes extensive use of them.</p>
<ul style="padding-left: 5px">
<li>A cooperative coroutine scheduler is a piece of code that picks up the execution each time a coroutine pauses and decides which coroutine to run next. It's called a scheduler because it keeps track of multiple streams of execution and decides which one gets to run at any given time.</li>
</ul>
<p style="padding-left: 30px">It's called cooperative because the scheduler can't run from one coroutine to another while the first one is still running. It has to wait until the running coroutine pauses itself, then it can select another coroutine to run.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Python coroutines</h1>
                </header>
            
            <article>
                
<p>In Python coroutines, the pause and resume points are <kbd>await</kbd> expressions; this is how we call other coroutines. Every time we want to perform a function, we call a coroutine from inside another coroutine. We wait for the coroutine we want to call.</p>
<p>The semantics of the code work as if they call a function from inside another function. The other coroutine runs until it returns and we get back the return value. That's how the code behaves, but what it actually does is quite a bit more interesting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The coroutine scheduler</h1>
                </header>
            
            <article>
                
<p>With the coroutine scheduler, the code behaves in the following manner:</p>
<ul style="padding-left: 5px">
<li>The first thing that happens is that the coroutine we're running is paused. The coroutine we want to call is handed on to the scheduler, which places it in its list of coroutines that it needs to run.</li>
<li>Then, the scheduler checks whether a coroutine is waiting and why: for example, new data coming from across the network, or a coroutine being returned; if it's the latter, it adds the waiting coroutines to the list as well.</li>
<li>After this, the scheduler picks one of the coroutines that needs to be run and resumes it. This means that if a coroutine has a long-running loop that doesn't contain any <kbd>await</kbd> expressions, it will block any other coroutine from running. It will also keep the program from checking for new incoming data and prevent other assorted input and output operations from being serviced.</li>
</ul>
<p>If we have such a loop and there's just no reason to call any other coroutine inside it, we can place the <kbd>await asyncio.sleep(0)</kbd> statement inside the loop body, which simply gives the scheduler a chance to do its thing.</p>
<p>This little bit of extra complexity that comes from the requirement of having <kbd>await</kbd> expressions is the price of cooperative scheduling, but since the payoff is efficient and logical code for I/O-bound programs, it's often worth it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using the asyncio event loop and coroutine scheduler</h1>
                </header>
            
            <article>
                
<p>So far, you have learned about Python's coroutines and a bit about how a cooperative coroutine scheduler works. Now, let's try our hand at writing some asynchronous code using Python coroutines and asyncio. We start this by creating a coroutine.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a coroutine</h1>
                </header>
            
            <article>
                
<p>It's easy to create a coroutine—all we have to do is use the <kbd>async</kbd> keyword on a function and use <kbd>await</kbd> anytime we want to call other coroutines, as shown in following code example:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="83" width="193" class="aligncenter size-full wp-image-927 image-border" src="assets/769b4bbf-c77b-4daa-a570-211ef1c350bc.jpg"/></div>
<p>Once we have a coroutine though, we can't just call it to get the ball rolling. If we try to call it, it immediately returns a <kbd>coroutine</kbd> object, as shown in the following code example—that's not much use:</p>
<div class="CDPAlignCenter CDPAlign"><img height="68" width="343" class="image-border" src="assets/9b09c416-6948-4da3-aaa2-4ea04f1b23c0.jpg"/></div>
<p>Instead, we need to add the coroutine to the asyncio's scheduler as a new task. Next, the scheduler runs arranging for coroutines to execute and handling input and output events.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The asyncio scheduler - event_loop</h1>
                </header>
            
            <article>
                
<p>The <kbd>asyncio</kbd> package automatically creates a default scheduler, also called <kbd>event_loop</kbd>.</p>
<p>While it's possible to create new <kbd>event_loop</kbd> objects or replace the default one, for our purposes, the default <kbd>event_loop</kbd> scheduler will work just fine. We could get a reference to it by calling asyncio's <kbd>get_event_loop</kbd> function to tell the scheduler that we want it to start a new task, as shown here:</p>
<div class="CDPAlignCenter CDPAlign"><img height="114" width="539" class="image-border" src="assets/4c92c495-7c39-4d37-abe0-df461275a94c.jpg"/></div>
<p>When we run the preceding coroutine, we call asyncio's <kbd>ensure_future</kbd> function. By default, this will create the task in the default scheduler.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ensure_future</h1>
                </header>
            
            <article>
                
<p>We can also override default scheduler by passing an explicit <kbd>event_loop</kbd> scheduler to the loop keyword-only parameter of the <kbd>ensure_future</kbd> function.</p>
<pre>
<strong>f = asyncio.ensure_future(coroutine.example(),  loop = scheduler)</strong>
</pre>
<p>Notice that we didn't just pass the <kbd>coroutine</kbd> function to <kbd>ensure_future</kbd>; we actually invoked it right there inside <kbd>ensure_future</kbd> arguments. We did this because the <kbd>ensure_future</kbd> function doesn't actually want to refer to the <kbd>coroutine</kbd> function. The <kbd>ensure_future</kbd> function is only interested in the <kbd>coroutine</kbd> object that we saw the <kbd>coroutine</kbd> function return earlier. The name <kbd>ensure_future</kbd> might seem somewhat odd. If it's used for launching tasks, why is it called that?</p>
<p>The fact of the matter is that launching tasks is basically just a side effect of what the function conceptually does, which is <strong>wrapping</strong>. Wrap the function's parameter in a future object if necessary. It just so happens that having a future object for the return value of our coroutine would be useless if the coroutine is never scheduled to run; <kbd>ensure_future</kbd> makes sure that it does.</p>
<p>The <kbd>ensure_future</kbd> function adds a new task to the scheduler, whether it's called from normal code or within a coroutine. This means that any time we want the code to run in its own stream of execution, we can use <kbd>ensure_future</kbd> to get it going.</p>
<p>Even in the preceding code example, where we added a coroutine to the scheduler as a new task, nothing happened. That's because the scheduler itself is still not running. However, this is an easily solvable problem. We just need to call either the <kbd>run_forever</kbd> or <kbd>run_until_complete</kbd> method of the loop. Finally, our coroutine would actually execute, as shown here:</p>
<pre>
<strong>scheduler.run_until_complete(f)</strong><br/><strong>5</strong>
</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The run_forever/run_until_complete methods</h1>
                </header>
            
            <article>
                
<p>As the names implies, <kbd>run_forever</kbd> causes <kbd>event_loop</kbd> to run forever or at least until it's explicitly stopped by calling its <kbd>stop</kbd> method. On the other hand, the <kbd>run_until_complete</kbd> method causes the loop to keep going until a particular future object is ready to provide a value (refer to the following code example):</p>
<div class="CDPAlignCenter CDPAlign"><img height="338" width="343" class="aligncenter size-full wp-image-929 image-border" src="assets/ca25e002-02f0-484d-8227-d2fb3a1ab00b.jpg"/></div>
<p>The return value of <kbd>ensure_future</kbd> is a future object, so you can easily run the scheduler until a particular task is done. The preceding code example runs two coroutines simultaneously as two separate tasks in the same scheduler. The <kbd>coro1()</kbd> coroutine contains an infinite loop, so it will never finish; however, the <kbd>coro2()</kbd> coroutine not only finishes, it also causes the <kbd>event_loop</kbd> stop method's (<kbd>loop.stop ()</kbd>) to force <kbd>run_forever</kbd> to terminate eventually. This is shown in the following code example:</p>
<div class="CDPAlignCenter CDPAlign"><img height="305" width="351" class="aligncenter size-full wp-image-930 image-border" src="assets/b0ec700d-397f-4ab0-acd6-b4264d0d3fde.jpg"/></div>
<p>The preceding example behaves in exactly the same way, except it uses <kbd>run_until_complete</kbd> to automatically stop the scheduler once <kbd>coro2</kbd> is finished instead of explicitly calling <kbd>stop</kbd>.</p>
<p>The code looks a little cleaner this way. So, as a rule of thumb, it's probably better to only use stop when some sort of error makes it necessary to dump out of <kbd>event_loop</kbd>. In both the examples we just saw, there's a line of code to set the logging level to critical. This is because <kbd>event_loop</kbd> issues an error message if it is stopped while there are tasks, such as <kbd>coro1</kbd>, still running. In this case, we know it's still running and we don't care, so we suppress the message.</p>
<div class="packt_infobox">It's usually better to arrange for all our running tasks to exit cleanly, instead of just killing them. This is why the error message is printed. But, in our case, there's no problem, so we just keep the message from printing.</div>
<p>Regardless of how we choose to run and stop <kbd>event_loop</kbd>, once we're completely finished with it, we should call its <kbd>close</kbd> method. It closes any open files, network sockets, and other I/O channels that <kbd>event_loop</kbd> is managing and generally cleans up after itself.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Closing event_loop</h1>
                </header>
            
            <article>
                
<p>A good way to close <kbd>event_loop</kbd> is to use the <kbd>contextlib.closing</kbd> context manager, which guarantees that the <kbd>close</kbd> method will be called once the <kbd>with</kbd> block ends. The following code example shows <kbd>event_loop</kbd> closing:</p>
<div class="CDPAlignCenter CDPAlign"><img height="322" width="421" class="aligncenter size-full wp-image-931 image-border" src="assets/20894b8c-08c6-4ec8-a1f0-74639e09c582.jpg"/></div>
<p>Even in error situations, the <kbd>close</kbd> method should be called when we're completely done with an <kbd>event_loop</kbd>, but this doesn't necessarily mean that it should be called right after the <kbd>run_forever</kbd> or <kbd>run_until_complete</kbd> call is finished. The <kbd>event_loop</kbd> is still in a valid state at that point, and it's perfectly OK to, for example, add some new tasks or start the loop again.</p>
<p>As you may have probably noticed, an <kbd>asyncio event_loop</kbd> object basically fulfills the same role as a <kbd>concurrent.futures executor</kbd> object. From a programming interface point of view, that's not the only similarity.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Awaiting data availability</h1>
                </header>
            
            <article>
                
<p>asyncio's future objects look and behave pretty much like <kbd>concurrent.futures</kbd> future objects, but they're not interchangeable. They have subtle differences in behavior and, of course, major differences in how they interact with the underlying systems, which are completely different. Still, each future is a way of referencing the value that may or may not have been computed yet and, if necessary, a way of waiting for that value to become available.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">asyncio's future objects</h1>
                </header>
            
            <article>
                
<p>The most commonly used feature of a future object is to wait for its value to be determined and then retrieve it. For asyncio's future objects, this is done by simply waiting for the future, as shown in the following code example:</p>
<div class="CDPAlignCenter CDPAlign"><img height="94" width="442" class="aligncenter size-full wp-image-932 image-border" src="assets/afd5cf75-8b4e-4016-ab08-8305bad580b4.jpg"/></div>
<p>This will tell the scheduler to pause the coroutine until the value of the future becomes available, after which the future's value is set in the coroutine as the result of the <kbd>await</kbd> expression.</p>
<p>If the future represents a raised exception, instead of a value, that exception is raised again from the <kbd>await</kbd> expression, as shown in the preceding code example. If we don't want to wait, we could call the <kbd>done</kbd> method to check whether a future is ready; if it is, we could call the <kbd>result</kbd> method to retrieve the value.</p>
<p>So, the syntax and semantics are a little different, but the basic idea of a future is the same in asyncio and <kbd>concurrent.futures</kbd>. When we work with asyncio, we use future objects in all the same places we would in <kbd>concurrent.futures</kbd>.</p>
<p>There's one scenario where even using future objects doesn't make it simple to wait for data; this is when we should process a stream of data values as they arrive, as shown here:</p>
<div class="CDPAlignCenter CDPAlign"><img height="421" width="407" class="aligncenter size-full wp-image-933 image-border" src="assets/417630f9-c240-4e9b-bdee-55b8735dde8a.jpg"/></div>
<p>Sure, we could loop over an iterator of future objects and wait for each one of them to become ready to provide their values, but that's clumsy and suffers from problems in regard to knowing when to stop the iteration.</p>
<p>Instead, Python provides us with an asynchronous iteration protocol, which allows us to write or fetch the next value function as a coroutine. This means that the iterator can wait for each value to arrive and simply return it. Now our loop will work properly and we will avoid all the confusion about when to stop.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous iterations</h1>
                </header>
            
            <article>
                
<p>Why do we need a special asynchronous iteration for a looping statement and a separate asynchronous iteration protocol?</p>
<p>It's because an asynchronous iteration only makes sense inside of a coroutine. Having a separate looping statement and protocol keeps us from stumbling into ambiguous situations, where the computer isn't sure what we want it to do.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Synchronizing multiple tasks</h1>
                </header>
            
            <article>
                
<p>In this section, we'll take a look at more ways to share data between tasks and synchronize their operations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Synchronization primitives</h1>
                </header>
            
            <article>
                
<p>The <kbd>asyncio</kbd> package provides <kbd>lock</kbd>, <kbd>semaphore</kbd>, <kbd>event</kbd>, and <kbd>condition</kbd> classes that are pretty similar to the ones we looked at in the context of <kbd>concurrent.futures</kbd>. They provide the same method names and fulfill the same roles. The important difference is that for asyncio's versions, some of the methods are coroutines and some are not, as shown here:</p>
<div class="CDPAlignCenter CDPAlign"><img height="163" width="390" class="image-border" src="assets/ab063608-d987-4a1a-89ad-613691f67f0c.jpg"/></div>
<p>Specifically, in each case, the <kbd>acquire</kbd> and <kbd>wait</kbd> methods, if they exist, are coroutines that must be called by <kbd>await</kbd>.</p>
<p>This is because they need to be able to pause until some specific thing happens, and only a coroutine can pause and hand over control to the scheduler. Having mentioned lock and the rest, I want to point out that while they are sometimes necessary, they are less often needed under asyncio than they would be in concurrent.futures or other systems that provide multiple streams of execution.</p>
<p>This is because asyncio's scheduling is cooperative. It's only possible to switch between execution streams and <kbd>await</kbd> expressions, which means that if there are no await expressions within a critical section of code, it can't be interrupted.</p>
<div class="packt_infobox">No other task can modify the same data at the same time because no other task has an opportunity to run any code during that time. Plus, Lock and the rest are only needed when a critical section of the code does, in fact, use <kbd>await</kbd> at least once.</div>
<p>We've seen the <kbd>as_completed</kbd> and <kbd>wait</kbd> functions before when we discussed concurrent.futures in the previous chapter. asyncio's versions are coroutines because they too need to suspend until it's time to continue executing, but there's not much of a difference in how we use them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The wait coroutine</h1>
                </header>
            
            <article>
                
<p>The wait coroutine still waits for a group of futures to end with an optional timeout and returns a list of futures that are ready and a list of futures that are not ready when the time expires. The <kbd>as_completed</kbd> function still takes a list of futures and produces futures of the results in the order that the results become available. Then, we extract the actual values from the futures with wait and we are good to go.</p>
<p>As shown in the following code example, there's no telling in which order the results will become available; however, each time a value does become available, it gets printed:</p>
<div class="CDPAlignCenter CDPAlign"><img height="333" width="410" class="aligncenter size-full wp-image-934 image-border" src="assets/bc87e32c-2f88-44bb-9b06-29ad565672bf.jpg"/></div>
<p>asyncio provides some other interesting coroutines for collecting data from futures, particularly: <kbd>wait_for</kbd> and <kbd>gather</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The wait_for coroutine</h1>
                </header>
            
            <article>
                
<p>The <kbd>wait_for</kbd> coroutine lets us wait for another coroutine to finish but with a timeout. The first two coroutines in the following code example do the same thing except that if <kbd>foo</kbd> doesn't finish within <kbd>5</kbd> seconds, the second version will raise an asyncio timeout error:</p>
<div class="CDPAlignCenter CDPAlign"><img height="166" width="404" class="aligncenter size-full wp-image-935 image-border" src="assets/e1053535-cd6a-4d79-9ed8-021c4e8f72d4.jpg"/></div>
<p>In the third code block, we're still doing the same thing, except if <kbd>foo</kbd> times out, we print a message. Then, there's the <kbd>gather</kbd> coroutine.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The gather coroutine</h1>
                </header>
            
            <article>
                
<p>What the <kbd>gather</kbd> coroutine does is it takes a bunch of futures and converts them into a single future that will be completed when all the subfutures are completed along with the result in the list of the subfutures' results, as shown in the following code example:</p>
<div class="CDPAlignCenter CDPAlign"><img height="223" width="295" class="aligncenter size-full wp-image-938 image-border" src="assets/8a9053d9-16fc-44ef-83bb-ba1aaa16509d.jpg"/></div>
<p>There are a bunch of uses for something like that, but one very nice thing we can do with it is use it to construct the future that we pass into <kbd>run_until_complete</kbd>.</p>
<p>In effect, we're telling asyncio that it should run until all these futures are complete. Futures are great for communicating a one-off value between tasks, and events objects are good for sending simple signals. However, sometimes, we want a fully featured communication channel. Fortunately, asyncio provides us with the <kbd>Queue</kbd> class and a few variants based on it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The asyncio Queue class</h1>
                </header>
            
            <article>
                
<p>The asyncio's <kbd>Queue</kbd> has both <kbd>put</kbd> and <kbd>get</kbd> methods as coroutines. So, we need to call them with <kbd>await</kbd> and we have to already be in a coroutine to call them, unless we were to actually use the <kbd>ensure_future</kbd> function to launch them as separate tasks as shown in the following code example of the <kbd>Queue</kbd> class:</p>
<div class="CDPAlignCenter CDPAlign"><img height="235" width="217" class="aligncenter size-full wp-image-939 image-border" src="assets/af1cc589-95d4-47ff-8c71-5cbdb3806950.jpg"/></div>
<p>However, the <kbd>Queue</kbd> class also has methods called <kbd>put_nowait</kbd> and <kbd>get_nowait</kbd>, which are not coroutines, and can be called from anywhere. This makes the <kbd>Queue</kbd> class quite useful for communicating new data to a system of coroutines as well as sending data between coroutine tasks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Queue types</h1>
                </header>
            
            <article>
                
<p>asyncio provides a couple of variant <kbd>Queue</kbd> types that return their stored values in different orders.</p>
<p>Instances of <kbd>PriorityQueue</kbd> give back the smallest object they contain according to a less than comparison when we call <kbd>get</kbd> or <kbd>get_nowait</kbd>. So, if our priority queue contains <kbd>34</kbd>, <kbd>2</kbd>, <kbd>5</kbd>, and <kbd>97</kbd>, calling its get coroutine would return <kbd>2</kbd>. The next time, it would return <kbd>5</kbd>, then <kbd>34</kbd>, and then <kbd>97</kbd>.</p>
<p>A <kbd>LifoQueue</kbd> method, on the other hand, always gives back the most recently added object. It is, in other words, a stack data structure. asyncio also provides a joinable <kbd>Queue</kbd> class, which adds an extra join coroutine and a method called <kbd>task_done</kbd>. With a little bit of extra work, using a joinable queue allows coroutines to pause and wait until the queue is emptied.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Communicating across the network</h1>
                </header>
            
            <article>
                
<p>So, we've covered how asyncio works and a bunch of tools that could be used to manage the execution of multiple streams of code. That's all great, but what about doing some actual I/O with it?</p>
<p>The primary motivation for people to use asynchronous I/O is because it helps when writing network clients and servers, although that's certainly not the only possible use. So, asyncio not only makes network communications efficient, it also makes them easy.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a simple client in asyncio</h1>
                </header>
            
            <article>
                
<p>Here, we have the code for a simple client-server pair of programs (refer to the following code example):</p>
<div class="CDPAlignCenter CDPAlign"><img height="340" width="865" class="aligncenter size-full wp-image-940 image-border" src="assets/289f4dd2-d05b-4a40-8c71-76de750c8996.jpg"/></div>
<p>They not only read and write the same few bytes over and over, but they also serve to demonstrate everything needed to communicate across the network.</p>
<p>There will be little information about the client that is mysterious.</p>
<p>Run the following command:</p>
<pre>
<strong>python3 client.py</strong>
</pre>
<p>It runs only a single task that uses asyncio's high-level API to open a connection and then send and receive data through it. The data is just a string of numbers as shown:</p>
<div class="CDPAlignCenter CDPAlign"><img height="100" width="64" class="image-border" src="assets/9d680910-da40-49f5-ac7b-fdbd666e084f.jpg"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a simple server in asyncio</h1>
                </header>
            
            <article>
                
<p>The server can handle simultaneous connections from many clients at once because the <kbd>start_server</kbd> coroutine we called launches a new task to run the <kbd>start_serve</kbd> coroutine each time a client connects to the server.</p>
<p>Each task has the job of handling a connection to a single client, so the server coroutine is almost as simple as the client coroutine.</p>
<p>There's a little bit of extra code to handle a connection reset error, which is the exception that gets raised if the client suddenly disconnects while the server's trying to read data from it, and a little more to handle the class where the request is an empty string, which the readline coroutine can only produce if the client has closed the connection in a less precipitous manner.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Handling client disconnections</h1>
                </header>
            
            <article>
                
<p>In both previous cases, we want the server to stop worrying about a particular client, which we can do simply by returning from the client handling coroutine. The task running the coroutine finishes and that's that.</p>
<p>In the launched coroutine on the server, we called another coroutine called <kbd>wait_closed</kbd>. That pretty much does what it says-it waits for the server to be closed. Without this call, our launched coroutine will immediately terminate and, since we used <kbd>run_until_complete</kbd>, the whole program will terminate immediately afterward.</p>
<p>This would happen because <kbd>start_server</kbd> launches a background task and then returns rather than manage the server directly, and that's about it.</p>
<p>There's a lower-level communication API that asyncio provides, but for the vast majority of cases, this lower-level API is unnecessary. asyncio makes network communications simple.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In the earlier sections of this chapter, we learned about coroutines, data exchange between coroutine tasks, and asynchronization. We had a look at using a future to wait for a single value or an asynchronous iterator, which may well use futures internally to wait for a sequence of values. We also looked at tools that we can use to transmit data to and from asynchronous coroutine tasks and force synchronization on them when necessary.</p>
<p>Now we've seen how to get a payoff from coroutines and asynchronization using these tools to write a network client or server. In the next chapter, we'll look at various parts of Python that can be redefined within our program source code and how to use them.</p>


            </article>

            
        </section>
    </body></html>