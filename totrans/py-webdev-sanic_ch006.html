<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-US">
<head>
<meta charset="utf-8"/>
<meta name="generator" content="packt"/>
<title>5 Handling and Responding Views</title>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet2.css"/>

</head>
<body>
<section id="handling-and-responding-views" class="level1 pkt" data-number="6">
<h1 data-number="6">5 Handling and Responding Views</h1>
<p>Up until this point, our applications have largely been reactive. We worked on different parts of web applications to learn about how to manage the incoming HTTP request. If we imagine the HTTP request/response cycle as a conversation, up until this point, we have been only listening. Our applications have been built to hear what the incoming client has to say.</p>
<p>Now, it is our turn to talk. In this Chapter, we begin to explore different facets of the HTTP response. Just as we began our learning of the HTTP request by looking at a raw request object, we will look at the raw response. It looks nearly identical, and at this point should be familiar. We go on to explore some of the powerful tools Sanic has to offer. Of course, there are mechanisms for JSON and HTML responses, which are probably the most popular types of content to be delivered on the Web today. Sanic, however, has an advantage by being an async framework: it is super easy to implement server driven responses like: websockets, server-sent events (SSE), and streaming responses. We will explore these in this chapter as well:</p>
<ul>
<li>Examining the HTTP response structure</li>
<li>Rendering HTML content</li>
<li>Serializing JSON content</li>
<li>Streaming data</li>
<li>Server-Sent Events for push communication</li>
<li>Websockets for two-way communication</li>
<li>Setting response headers and cookies</li>
</ul>
<section id="technical-requirements-4" class="level2" data-number="6.1">
<h2 data-number="6.1">Technical requirements</h2>
<p>Some of our examples are going to start getting a little longer than what we have previously seen. For the sake of convenience, you may want to keep the GitHub repository handy as you read through this chapter: <a href="https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/05.">https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/05.</a></p>
</section>
<section id="examining-the-http-response-structure" class="level2" data-number="6.2">
<h2 data-number="6.2">Examining the HTTP response structure</h2>
<p>Back in <em>Chapter 3, Routing and intaking HTTP requests</em>, we looked at the structure of the HTTP request. When a web server is ready to send back a response, the format is very similar to what we already saw. The HTTP response will look something like this:</p>
<pre><code>HTTP 1.1 200 OK
Content-Length: 13
Connection: keep-alive
Content-Type: text/plain; charset=utf-8
Hello, world.</code></pre>
<p>What we see is the following:</p>
<ol>
<li>First line containing HTTP protocol used, a status code, and a status description</li>
<li>Response headers in <code>key: value</code> format and separated by a line break</li>
<li>A blank row</li>
<li>Response body</li>
</ol>
<p>We are looking at this here not because it is something we must know to build a web application. After all, building these response objects to a valid HTTP specification is precisely one of the reasons that we use web frameworks. Without them, building these blobs would be tedious and error prone. Instead, it is helpful for us to review and understand what is happening so that we can increase our grasp of HTTP and web application development.</p>
<p>A lot of the structure is duplicative of what we have already learned.</p>
<section id="http-response-status" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1">HTTP response status</h3>
<p>If you compare the HTTP request and response objects, perhaps the most identifying difference is the first line. Whereas the request first line had three distinct parts, it is easier to think of the response as having only two: the HTTP protocol in use, and the response status. We discussed the HTTP protocol earlier in this book, for example see <em>Chapter 3</em>, <em>Routing and intaking HTTP requests</em>, so we will skip it here and focus on the response status. The response status is meant to be both a computer-friendly and human-friendly tool to let the client know what happened to the request. Did it succeed? Was the request wrong? Did the server make a mistake? These questions, and more, are answered by the HTTP response status.</p>
<p>Likely you have a basic understanding of different response codes if you have built a website in the past. Even people who have never built an application have surely at some time landed on a web page that said <strong>404 Not Found</strong> or <strong>500 Internal Server Error</strong>. These are response statuses. HTTP response statuses consist of a number, and a description. The meanings of these numbers and the specific descriptions associated with them are defined in <em>RFC 7231 § 6</em>. <a href="https://datatracker.ietf.org/doc/html/rfc7231#section-6.">https://datatracker.ietf.org/doc/html/rfc7231#section-6.</a></p>
<p>To clarify, if you see the term <em>response status</em>, <em>status code</em>, or <em>response code</em>, they are all describing the same thing. I generally prefer to use <em>response status</em> to describe the general concept, and <em>status code</em> when talking about the numeric value of the status. However, they are fairly interchangeable, and this book uses the terms interchangeably as well.</p>
<p>The three most common statuses are:</p>
<ul>
<li>200 OK</li>
<li>404 Not Found</li>
<li>500 Internal Server Error</li>
</ul>
<p>In general, Sanic will attempt to respond with the most appropriate status. If there is an error, you will likely get a <code>500</code>. If the path does not exist, it will be a <code>404</code>. And, if the server can respond properly, Sanic uses <code>200</code>. Let’s dig a little deeper to see how the statuses are organized.</p>
</section>
<section id="response-groupings" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2">Response groupings</h3>
<p>The standard responses are grouped in series of 100s as follows:</p>
<ul>
<li><strong>100s</strong>: <em>Informational</em> - provisional responses with information about how the client should proceed</li>
<li><strong>200s</strong>: <em>Successful</em> - responses that indicate the request was processed as expected</li>
<li><strong>300s</strong>: <em>Redirection</em> - responses that indicate the client must take further action</li>
<li><strong>400s</strong>: <em>Client error</em> - responses where it appears the client made a mistake in trying to access or proceed with some resource</li>
<li><strong>500s</strong>: <em>Server error</em> - responses where the server made a mistake and a response as expected could not be generated</li>
</ul>
<p>Beyond the big three, there are some other important responses you should be familiar with:</p>
<table>
<tbody>
<tr class="odd">
<td><strong>Code</strong></td>
<td><strong>Description</strong></td>
<td><strong>Use case</strong></td>
</tr>
<tr class="even">
<td><code>201</code></td>
<td>Created</td>
<td>Endpoint successfully created a new resource; often the response will include the new data and/or an ID that can be used to look it up</td>
</tr>
<tr class="odd">
<td><code>202</code></td>
<td>Accepted</td>
<td>The application has taken the request and pushed it to a queue or background process for further operation</td>
</tr>
<tr class="even">
<td><code>204</code></td>
<td>No Content</td>
<td>There is no body; typical on an OPTIONS request</td>
</tr>
<tr class="odd">
<td><code>301</code></td>
<td>Moved Permanently</td>
<td>The target resource is now located at a new permanent URI</td>
</tr>
<tr class="even">
<td><code>302</code></td>
<td>Found</td>
<td>The target resource is temporarily located at a different URI</td>
</tr>
<tr class="odd">
<td><code>400</code></td>
<td>Bad Request</td>
<td>The server is refusing to respond to the request because of something improper by the client</td>
</tr>
<tr class="even">
<td><code>401</code></td>
<td>Unauthorized</td>
<td>The request lacks valid authentication credentials to be allowed access</td>
</tr>
<tr class="odd">
<td><code>403</code></td>
<td>Forbidden</td>
<td>The request is authenticated, but the server does not recognize valid authorization to proceed with the response</td>
</tr>
</tbody>
</table>
Table 5.1 – Common status codes
</section>
<section id="response-through-exceptions" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3">Response through exceptions</h3>
<p>Many of Sanic’s built-in exceptions are associated with a specific status code. This means that we can raise an exception and Sanic will automatically catch that exception and provide an appropriate response with the proper status code. This makes it super convenient, and simple to respond.</p>
<p>For example, let’s imagine that we are building a music player application. One of our endpoints allows users that are logged in to see their playlist. However, it is protected behind authentication and only users that the playlist has been shared with are able to access it. Something like this:</p>
<pre><code>from sanic.exceptions import NotFound
@app.get(&quot;/playlist/&lt;playlist_name:str&gt;&quot;)
async def show_playlist(request, playlist_name: str):
    can_view = async check_if_current_user_can_see_playlist(
        request,
        playlist_name
    )
    if not can_view:
        raise NotFound(&quot;Oops, that page does not exist&quot;)
    ...</code></pre>
<p>By raising <code>NotFound</code>, Sanic will automatically know that it should return a <code>404 Not Found</code> response:</p>
<pre><code>$ curl localhost:7777/playlist/adams-awesome-music -i
HTTP/1.1 404 Not Found
content-length: 83
connection: keep-alive
content-type: application/json
{&quot;description&quot;:&quot;Not Found&quot;,&quot;status&quot;:404,&quot;message&quot;:&quot;Oops, that page does not exist&quot;}</code></pre>
<p>We also could extend this concept with our own custom exception handlers.</p>
<pre><code>from sanic.exceptions import SanicException
class NotAcceptable(SanicException):
    status_code = 406
    quiet = True
@app.post(&quot;/&quot;)
async def handler(request):
    if &quot;foobar&quot; not in request.headers:
        raise NotAcceptable(&quot;You must supply a Foobar header&quot;)
    return text(&quot;OK&quot;)</code></pre>
<p>In this example, by subclassing <code>SanicException</code> we can associate the exception with a status code. We also set a class property: <code>quiet=True</code>. This is not necessary, but may be desirable. What it means is that the exception and its traceback (the details about the type and location of an exception) will not appear in your logging. This is a particular feature to <code>SanicException</code>. It is helpful for exceptions that may be expected (but otherwise uncaught) in the regular course of your application.</p>
</section>
<section id="custom-status" class="level3" data-number="6.2.4">
<h3 data-number="6.2.4">Custom status</h3>
<p>Just as we saw with HTTP methods, it is possible to make-up your own status codes as long as they have three digits. I am not suggesting this is a <em>good</em> idea, merely pointing out that it is possible and Sanic will let you do it, even though you probably should not. Creating your own status codes might confuse browsers or clients that are using your application. Throwing caution to the wind, we will try it anyway just to see that Sanic allows us to do it.</p>
<ol>
<li><p>Add a new status type to an otherwise “private” variable (remember, its just Python so we can hack it if we want):</p>
<pre><code>from sanic.headers import _HTTP1_STATUSLINES
_HTTP1_STATUSLINES[999] = b&quot;HTTP/1.1 999 ROCK ON\r\n&quot;
@app.get(&quot;/rockon&quot;)
async def handler(request):
    return empty(status=999)</code></pre>
<p>Nice. Now let’s see what happens.</p></li>
<li><p>Check the HTTP return making sure to use <code>-i</code> so we see the raw response:</p>
<pre><code>$ curl localhost:7777/rockon -i
HTTP/1.1 999 ROCK ON
content-length: 0
connection: keep-alive
content-type: None</code></pre>
<p>To wrap up, here is a fun little experiment, and a quirk of the HTTP spec. Enter this route into your application:</p>
<pre><code>@app.get(&quot;/coffee&quot;)
async def handler(request):
    return text(&quot;Coffee?&quot;, status=418)</code></pre></li>
</ol>
<p>Now, query it using <code>curl</code> so you can see the response (don’t forget the <code>-i</code>):</p>
<pre><code>$ curl localhost:7777/coffee -i</code></pre>
</section>
<section id="headers" class="level3" data-number="6.2.5">
<h3 data-number="6.2.5">Headers</h3>
<p>The second part of the HTTP response is the same as the second part of the HTTP request: headers arranged one per line in a <code>key: value</code> format. Like before, the keys are case insensitive, and can be repeated more than once in the response.</p>
<p>One interesting thing to keep in mind is that when a webserver responds with an informational status (series 100), it does <em>not</em> include headers. These responses are generally used only in the context of <em>upgrading</em> an HTTP connection to a websocket connection. Since this is a responsibility of the framework, we can safely ignore this, and just file it away as good information to have.</p>
<p>Headers are generally pretty simple to use in Sanic. We will dig into them a little bit later on, but for now we need to keep in mind that we can simply pass a dictionary with values.</p>
<ol>
<li><p>Add a <code>headers</code> argument with a dictionary of values into any response function. Here we use <code>empty</code> because we are not sending any body response, just the headers:</p>
<pre><code>@app.get(&quot;/&quot;)
async def handler(request):
    return empty(headers={&quot;the-square-root-of-four&quot;: &quot;two&quot;})</code></pre></li>
<li><p>Let’s see what the response looks like using curl, and making sure to use -i so that we see the headers:</p>
<pre><code>$ curl localhost:7777/ -i
HTTP/1.1 204 No Content
the-square-root-of-four: two
connection: keep-alive</code></pre>
<p>The astute mathematician looking at my example will notice that I got it only partially correct. Two is not the only value. How can we have duplicate header keys? Since Python regular dictionaries will not allow us to duplicate keys, we can use a special data type that Sanic offers us to do the job.</p></li>
<li><p>Using the same response as before, insert a <code>Header</code> object with two of the same keys as shown:</p>
<pre><code>from sanic.compat import Header
@app.get(&quot;/&quot;)
async def handler(request):
    return empty(
        headers=Header(
            [
                (&quot;the-square-root-of-four&quot;, &quot;positive two&quot;),
                (&quot;the-square-root-of-four&quot;, &quot;negative two&quot;),
            ]
        )
    )</code></pre></li>
<li><p>We hopefully will now see our more mathematically correct response headers; the same key twice, but each time with a different value:</p>
<pre><code>$ curl localhost:7777/ -i
HTTP/1.1 204 No Content
the-square-root-of-four: positive two
the-square-root-of-four: negative two
connection: keep-alive</code></pre></li>
</ol>
</section>
<section id="response-body" class="level3" data-number="6.2.6">
<h3 data-number="6.2.6">Response Body</h3>
<p>The last part of the HTTP response is the body. It is arguably the most important part of this whole business we call HTTP. We can realistically state that the HTTP response body is what the whole driving force of the web is after: the sharing of content. The remainder of this chapter will focus on some of the different and more popular ways that we can structure data in the HTTP response body. Whether it is HTML, JSON, or raw bytes, what we are about to dive into will be part of the cornerstone of every web application you build. First up is HTML content where we will explore methodologies for sending both static HTML content and generating dynamic HTML content.</p>
</section>
</section>
<section id="rendering-html-content" class="level2" data-number="6.3">
<h2 data-number="6.3">Rendering HTML content</h2>
<p>The foundation of the Web is HTML. It is the media that enables browsers to function, and therefore it is fundamental that a web server must be capable of delivering HTML content. Whether building a traditional page-based application, or a single-page application, HTML delivery will be necessary. In <em>Chapter 3</em>, <em>Routing and Intaking HTTP Requests</em>, we discussed how we could route web requests to our static files. If you have static HTML files, then this is a great option. But, what if you need to generate dynamic HTML for your application?</p>
<p>Since there are multitudes of ways that this could be accomplished, we will take a look at some of the general patterns that could be used with Sanic.</p>
<section id="delivering-html-files" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1">Delivering HTML files</h3>
<p>Serving HTML content is generally a simple operation. We need to send back a response to the client with HTML text and a header that tells the recipient that the document should be treated as HTML. Ultimately, the raw HTTP response is going to look like this:</p>
<pre><code>HTTP/1.1 200 OK
content-length: 70
connection: keep-alive
content-type: text/html; charset=utf-8
&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Hello&lt;/title&gt;&lt;div&gt;Hi!&lt;/div&gt;
Notice the critical HTTP response header: content-type: text/html; charset=utf-8. Sanic has a convenient reponse function:
from sanic import html, HTTPResponse
@app.route(&quot;/&quot;)
async def handler(request) -&gt; HTTPResponse:
    return html(
        &#39;&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Hello&lt;/title&gt;&lt;div&gt;Hi!&lt;/div&gt;&#39;
    )</code></pre>
<p>Quick side note, while the preceding example may be valid HTML, not all the following examples will be. Getting 100% HTML semantics is not the aim of this book, so we might break a few rules.</p>
<p>Let’s imagine now that we are building a music player application. The first thing that needs to happen when someone lands on our website is to login. If that person already has an active session, we want them to go to the <strong>What’s new</strong> page. In Chapter 6 and 7 we will look at how to use middleware and integrate it with authentication. For now, we will assume our application has already determined authentication and authorization. It has stored those values as <code>request.ctx.user</code>:</p>
<pre><code>@app.route(&quot;/&quot;)
async def handler(request) -&gt; HTTPResponse:
    path = &quot;/path/to/whatsnew.html&quot; if request.ctx.user else &quot;/path/to/login.html&quot;
    with open(path, &quot;r&quot;) as f:
        doc = f.read()
    return html(doc)</code></pre>
<p>Have you noticed a pattern so far? All we really need to do to generate HTML content with Sanic is basic string building! So, if we can inject values into a string with string interpolation, then we have dynamic HTML. Here’s a simple illustration:</p>
<pre><code>@app.route(&quot;/&lt;name:str&gt;&quot;)
async def handler(request, name: str) -&gt; HTTPResponse:
    return html(f&quot;&lt;div&gt;Hi {name}&lt;/div&gt;&quot;)</code></pre>
<p>Instead of using <code>curl</code>, let’s see what it looks like in a browser this time:</p>
<figure>
<img src="../media/file4.png" alt="Figure 5.1 - Browser screenshot of interpolated HTML" /><figcaption aria-hidden="true">Figure 5.1 - Browser screenshot of interpolated HTML</figcaption>
</figure>
<p>String interpolation of HTML is just a fancy way of saying templating.</p>
</section>
<section id="basic-templating" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2">Basic templating</h3>
<p>In the past, I have presented at a couple Python web conferences. While preparing my talks I looked for tools that would make it super simple to generate a slide presentation. Since I am most comfortable working in my text editor, I was particularly interested in solutions that would translate markdown to slides. I found a tool called <code>remark.js</code>. If you want to learn more about remark: <a href="https://remarkjs.com/.">https://remarkjs.com/.</a></p>
<p>In order to render slides from markdown, all I needed was an HTML file and some markdown text:</p>
<pre><code>&lt;!-- Boilerplate HTML here --&gt;
    &lt;textarea id=&quot;source&quot;&gt;
class: center, middle
# Title
---
# Agenda
1. Introduction
2. Deep-dive
3. ...
---
# Introduction
    &lt;/textarea&gt;
    &lt;script src=&quot;https://remarkjs.com/downloads/remark-latest.min.js&quot;&gt;
&lt;!-- Boilerplate HTML and here --&gt;</code></pre>
<p>This was super simple and exactly what I was looking for. However, there was a problem because my IDE did not know the text inside the <code>&lt;textarea&gt;</code> was markdown. Therefore, I had no syntax highlighting. Bummer.</p>
<p>The solution was quite simple really. I just needed a way to inject my markdown into the HTML file and serve that.</p>
<p>A quick fix to the HTML:</p>
<pre><code>&lt;!-- Boilerplate HTML here --&gt;
    &lt;textarea id=&quot;source&quot;&gt;
__SLIDES__
    &lt;/textarea&gt;
    &lt;script src=&quot;https://remarkjs.com/downloads/remark-latest.min.js&quot;&gt;
&lt;!-- Boilerplate HTML and here --&gt;</code></pre>
<p>Voila! An HTML template. Now, let’s <em>render</em> it.</p>
<pre><code>from pathlib import Path
PRESENTATION = Path(__file__).parent / &quot;presentation&quot;
@app.get(&quot;/&quot;)
def index(_):
    with open(PRESENTATION / &quot;index.html&quot;, &quot;r&quot;) as f:
        doc = f.read()
    with open(PRESENTATION / &quot;slides.md&quot;, &quot;r&quot;) as f:
        slides = f.read()
    return html(doc.replace(&quot;__SLIDES__&quot;, slides))</code></pre>
<p>Just like that, we built a templating engine. The basic idea of any templating engine is that there is some protocol for telling the application how to convert and inject dynamic content. Python does this with its multiple forms of string interpolations. In my super simple solution engine, all I needed to do was replace the <code>__SLIDES__</code> value. I am sure you can start to formulate ideas on how you could build your own simple engine.</p>
<p>In fact, maybe you should try that now. Here is a HTML template:</p>
<pre><code>&lt;p&gt;
    Hi, my name is &lt;strong&gt;__NAME__&lt;/strong&gt;.
&lt;/p&gt;
&lt;p&gt;
    I am &lt;em&gt;__AGE__&lt;/em&gt; years old.
&lt;/p&gt;</code></pre>
<p>Now for the start:</p>
<pre><code>def render(template: str, context: Dict[str, Any]) -&gt; str:
    ...
@app.get(&quot;/hello&quot;)
async def hello(request) -&gt; HTTPResponse:
    return html(
        render(&quot;hello.html&quot;, {&quot;name&quot;: &quot;Adam&quot;, &quot;age&quot;: 38})
    )</code></pre>
<p>It is your turn now to fill in the rest by building the rendering agent. Try to build a <code>render</code> function to work with <em>any</em> variable names, not just <code>name</code> and <code>age</code>. We want this to be reusable in more than just one location.</p>
</section>
<section id="using-a-templating-engine" class="level3" data-number="6.3.3">
<h3 data-number="6.3.3">Using a templating engine</h3>
<p>Of course, you do not need to always make your own templating engine. There are many great choices already built. Popular template engines in Python are Genshi, Mako, and Jinja2. But remember, all we really need to do is build a string. So any tools that you have that can do this will work. These packages can be thought of as fancy versions of the Python format function. They take strings and inject data into them to generate a bigger string. Any Python templating tool that you pick up will work with Sanic. Specifically regarding Jinja2, there are some Sanic plugins already out there that make interactions between Sanic and Jinja2 super simple. Feel free to check them out on your own time. On the basic level, templating with Jinja2 can be as lightweight as this:</p>
<pre><code>from jinja2 import Template
template = Template(&quot;&lt;b&gt;Hello {{name}}&lt;/b&gt;&quot;)
@app.get(&quot;/&lt;name&gt;&quot;)
async def handler(request, name):
    return html(template.render(name=name))</code></pre>
<p>And now to see the result:</p>
<pre><code>$ curl localhost:7777/Adam
&lt;b&gt;Hello Adam&lt;/b&gt;</code></pre>
<p>To move our templates out of Python and into their own HTML files, we can use Jinja2’s <code>Environment</code> construct.</p>
<ol>
<li><p>Create some HTML using Jinja2 syntax. This will be saved as <code>index.html</code> in a <code>templates</code> directory. You can see the structure used in the GitHub repository:</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;Adam&#39;s Top Songs&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;h1&gt;Adam&#39;s Top Songs&lt;/h1&gt;
        &lt;ul&gt;
            {% for song in songs %}
                &lt;li&gt;{{song}}&lt;/li&gt;
            {% endfor %}
        &lt;/ul&gt;
    &lt;/body&gt;
&lt;/html&gt;</code></pre></li>
<li><p>Now setup the <code>Environment</code> and attach it to our application context so that it is easily available throughout our application:</p>
<pre><code>from pathlib import Path
from jinja2.loaders import FileSystemLoader
from jinja2 import Environment
@app.before_server_start
def setup_template_env(app, _):
    app.ctx.env = Environment(
        loader=FileSystemLoader(Path(__file__).parent / &quot;templates&quot;),
        autoescape=True,
    )</code></pre></li>
<li><p>Finally, grab the template by filename in our route handler, and inject some content into it:</p>
<pre><code>@app.get(&quot;/&quot;)
async def handler(request):
    template = request.app.ctx.env.get_template(&quot;index.html&quot;)
    output = template.render(
        songs=[
            &quot;Stairway to Heaven&quot;,
            &quot;Kashmir&quot;,
            &quot;All along the Watchtower&quot;,
            &quot;Black Hole Sun&quot;,
            &quot;Under the Bridge&quot;,
        ]
    )
    return html(output)</code></pre></li>
</ol>
<p>With that all done, we should be able to visit our application in a web browser and see the rendered HTML.</p>
<blockquote>
<p><strong>TIP</strong></p>
<p>When building with Sanic, you may have noticed how handy it is to have <code>auto_reload</code> enabled. Every time you hit the save button, the application restarts and is available for you to test immediately. Wouldn’t it be great if the same were true when building HTML files? There is a tool that does this called <strong>livereload</strong>. Essentially it injects some Javascript into your HTML to make it listen to commands to refresh the page. When building that slide presentation I talked about earlier, I made a livereload server so that I could keep the browser open side-by-side with my IDE while I typed. Every time I hit <strong>Save</strong>, my browser refreshed, and I could see the rendered content without having to lift my fingers off the keyboard. If you are interested in more detail on this topic, checkout <em>Chapter 11</em>.</p>
</blockquote>
</section>
</section>
<section id="serializing-json-content" class="level2" data-number="6.4">
<h2 data-number="6.4">Serializing JSON content</h2>
<p>Next to HTML content, JSON is one of the most common forms of data transferred on the web. If you are building a <strong>single-page application</strong> (<strong>SPA</strong>),( also known as a <strong>progressive web application</strong> or <strong>PWA</strong>), likely your backend server <em>only</em> or <em>mostly</em> returns JSON content. A common build pattern for a modern web application is to build a frontend user-interface with a Javascript framework powered by a backend server that feeds the frontend with dynamic JSON documents.</p>
<section id="choosing-on-a-serializer" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1">Choosing on a serializer</h3>
<p>The Python standard library, of course, ships with a JSON package that makes serializing Python objects to JSON strings (and the reverse) very simple. However, it is not the most performant implementation. In fact, it is quite slow. Many third-party packages have popped up to attempt to fix this problem. We will explore two of the common packages often used with Sanic.</p>
<p>When talking about response serialization, what we care about is the operation of the <code>dumps()</code> method. Each of these projects provides an interface with this method. To select a serializer, what we need to do is to set the dumps() method in one of two locations: at the response level, or application wide. We will see how to do both shortly.</p>
<section id="ujson" class="level4" data-number="6.4.1.1">
<h4 data-number="6.4.1.1">UJSON</h4>
<p><strong>UltraJSON</strong> (aka <strong>ujson</strong>) is an alternative JSON implementation that is written in C. Because of its emphasis on performance, it was adopted as the default JSON tool for Sanic. If you do nothing else, this is the package that Sanic will use.</p>
<p>It includes some helpful encoder options such as: <code>encode_html_chars</code>, <code>ensure_ascii</code>, and <code>escape_forward_slashes</code>. Consider the following example:</p>
<pre><code>    return json(
        {
            &quot;homepage&quot;: request.app.url_for(
                &quot;index&quot;,
                _external=True,
                _server=&quot;example.com&quot;,
            )
        },
    )</code></pre>
<p>When we access this endpoint, <code>ujson</code> will by default escape our slashes:</p>
<pre><code>$ curl localhost:7777
{&quot;homepage&quot;:&quot;http:\/\/example.com\/index.html&quot;}</code></pre>
<p>We can use <code>functools.partial</code> to change the behavior.</p>
<pre><code>dumps = partial(ujson.dumps, escape_forward_slashes=False)
@app.get(&quot;/&quot;)
async def handler(request):
    return json(
        {
            &quot;homepage&quot;: request.app.url_for(
                &quot;index&quot;,
                _external=True,
                _server=&quot;example.com&quot;,
            )
        },
        dumps=dumps,
    )</code></pre>
<p>By using the <code>dumps</code> keyword argument, we have told Sanic to use a different serializer. The result should be what we want:</p>
<pre><code>$ curl localhost:7777 
{&quot;homepage&quot;:&quot;http://example.com/index.html&quot;}</code></pre>
<p>If you do not want to use ujson in your projects, then you can force Sanic to skip installation of ujson:</p>
<pre><code>$ export SANIC_NO_UJSON=true
$ pip install --no-binary :all: sanic</code></pre>
<p>While ujson is a great project that adds some much needed performance to JSON string manipulation in Python, it <em>might</em> not actually be the fastest. Next, we will look at another relatively new package that attempts to bring performance to JSON manipulation.</p>
</section>
<section id="orjson" class="level4" data-number="6.4.1.2">
<h4 data-number="6.4.1.2">ORJSON</h4>
<p>A newer player to the game is orjson. It is written in Rust and claims to be the fastest alternative according to benchmarks. For this reason, many people like to swap out ujson for orjson.</p>
<p>An interesting thing to note about orjson is that it has built-in support for serializing common Python objects like <code>datetime.datetime</code> and <code>uuid.UUID</code>. Since these are both very common when building web applications, it is super convenient to not have to think about how to handle these object types. It also should be noted that whereas the standard library and ujson return a <code>str</code> value, orjson returns a <code>bytes</code> string.</p>
<p>We can easily tell Sanic to use orjson everywhere:</p>
<pre><code>import orjson
app = Sanic(__name__, dumps=orjson.dumps)</code></pre>
</section>
</section>
<section id="serializing-custom-objects" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2">Serializing custom objects</h3>
<p>In the last two sections, you may have noticed there are two ways to override the default dumps method. The first is by changing a single response:</p>
<pre><code>return json(..., dumps=orjson.dumps)</code></pre>
<p>The second, will apply to all routes globally:</p>
<pre><code>Sanic(..., dumps=orjson.dumps)</code></pre>
<p>Feel free to mix and match both the handler-specific method, and the application-wide method to meet your application needs.</p>
<p>We quickly looked at two alternative packages. There are of course others. So how should you decide which package to use? When deciding on an implementation, often one of the biggest considerations is how to handle custom non-scalar objects. That is to say, how do we want objects that do not have an obvious and built-in mapping to JSON types (like strings, integers, floats, booleans, lists, and dictionaries) to behave when rendered to JSON. To make this point clear, consider this example:</p>
<p>Let’s say we have a Thing.It looks like this:</p>
<pre><code>class Thing:
    ...
data = {&quot;thing&quot;: Thing()}</code></pre>
<p>If we do nothing, serializing a <code>Thing </code>object is not so straightforward, and JSON tools usually will throw an error because they do not know what to do with it. Without resorting to manual intervention, we can rely upon each of the tools’ methodology to explicitly provide instructions when coming across a <code>Thing </code>object. We will consider each alternative to see how we can reduce <code>Thing </code>to a JSON accessible object.</p>
<p>Perhaps, the most simple is <code>ujson</code>. Besides its performance, this happens to be one of my favorite features. If an object has a <code>__json__</code> method, ujson will call it when converting the object to JSON:</p>
<pre><code>class Thing:
    def __json__(self):
        return json.dumps(&quot;something&quot;)
ujson.dumps(data)</code></pre>
<p>Because of this functionality, when I am working on a project one of the things I often do is identify some base models for my objects and include a <code>__json__</code> method. But what about the other tools?</p>
<p>Orjson allows us to pass a <code>default function</code> to the serializer. If it does not know how to render an object, it will call this. While ujson opts to handle this on the object/model, orjson opts to handle it in each individual serializer. The sky is really the limit to the complexity you want to add. Since I am a fan of using <code>__json__</code> methods on my custom objects, we can achieve the same functionality with orjson like this:</p>
<pre><code>def default(obj):
    if hasattr(obj, &quot;__json__&quot;):
        return json.loads(obj.__json__())
    raise TypeError
orjson.dumps(data, default=default)</code></pre>
<p>This might get a bit repetitive if you are constantly redefining the serializer method in response handlers. Instead, maybe it is worth it to use the standard library to help. We can create a partial function with the <code>default </code>argument already populated.</p>
<pre><code>from functools import partial
odumps = partial(orjson.dumps, default=default)
odumps(data)</code></pre>
<p>The most cumbersome implementation is the standard library that requires you to pass it a custom encoder class. It is very similar to the orjson method, albeit with a little more boilerplate needed.</p>
<pre><code>class CustomEncoder(json.JSONEncoder):
    def default(self, obj):
        return default(obj)
json.dumps(data, cls=CustomEncoder)</code></pre>
<p>Seeing the above example, you should now be able to add the <code>__json__ </code>approach to the <code>CustomEncoder</code>.</p>
<p>No matter the project, you are very likely to come up against this issue. Having a standard and consistent way to handle non-scalar objects is important. Assess how you plan to build and look for meaningful patterns. I generally find this to be more of an important decision than raw performance. The incremental performance changes from one package to the next are likely not going to be as impactful as making a decision based upon how your application will be built and maintained. For example, what if you need to render an integer that is larger than 64 bits? Both ujson and orjson have a limitation where they will raise exceptions and not be capable of handling your data. The standard library implementation, however does have this capacity. As we stated back in the beginning, make the right decisions that are the most obvious to your needs. But, let’s turn to some common practices and see what we might be able to learn from.</p>
</section>
<section id="best-practices" class="level3" data-number="6.4.3">
<h3 data-number="6.4.3">Best practices</h3>
<p>There are a number of common practices for what <em>typical</em> JSON responses look like. Of course, the content and your organization is something that will be determined by your application’s needs. But, there is one common question you will find often discussed on developer forums: “<em>How should I format an array of objects?</em>”</p>
<p>Coming back to our earlier example, let’s imagine we are still building our music app. We now want to build an endpoint that lists out all of the available songs. Each individual song “object” will look something like this:</p>
<pre><code>{
    &quot;name&quot;: &quot;Kashmir&quot;,
    &quot;song_uid&quot;: &quot;75b723e3-1132-4f73-931b-78bbaf2a7c04&quot;,
    &quot;released&quot;: &quot;1975-02-24&quot;,
    &quot;runtime&quot;: 581
}</code></pre>
<p>How should we organize an array of songs? There are two schools of thought: only use top level objects, use whatever structure fits your data best. What we are talking about is the difference between:</p>
<pre><code>{
    &quot;songs&quot;: [
        {...},
        {...}
    ]
}</code></pre>
<p>And:</p>
<pre><code>[
    {...},
    {...}
]</code></pre>
<p>Why is there even a debate? And, why do some people strictly only use top level objects? There was a JSON security flaw in browsers uncovered in 2006 that would allow attackers to execute code based upon the second option, the top-level JSON array. For this reason, many people suggested that using the first structure was more secure.</p>
<p>While this is no longer a concern since the impacted browsers are long out of date, I still like the top-level object pattern. It still provides one critical benefit over the second option: flexibility without compromising on compatibility.</p>
<p>If our array of objects is nested inside of a top-level object, then we can easily modify our endpoints in the future to add new keys to the top-level without impacting anyone using that endpoint. One pattern that I like to include is to have a <code>meta</code> object that includes some of the details of the query, and contains pagination information.</p>
<pre><code>{
    &quot;meta&quot;: {
        &quot;search_term&quot;: &quot;Led Zeppelin&quot;,
        &quot;results&quot;: 74,
        &quot;limit&quot;: 2,
        &quot;offset&quot;: 0
    },
    &quot;songs&quot;: [
        {...},
        {...}
    ]
}</code></pre>
<p>Therefore, I suggest that when given the choice, you nest your objects like this. Some people also like to nest single objects:</p>
<pre><code>{
    &quot;song&quot;: {
        &quot;name&quot;: &quot;Kashmir&quot;,
        &quot;song_uid&quot;: &quot;75b723e3-1132-4f73-931b-78bbaf2a7c04&quot;,
        &quot;released&quot;: &quot;1975-02-24&quot;,
        &quot;runtime&quot;: 581
    }
}</code></pre>
<p>The argument goes that the same principle applies. The endpoint is more easily extensible if the objects are nested. However, this argument seems less convincing and practical when dealing with single objects. Generally, any change in the endpoint would be related to the object itself. So, perhaps this is a use-case for versioning, which we explored in Chapter 3.</p>
<p>No matter your decision on how to structure the data, sending information about our songs in JSON format is still just a structural decision that will be dictated by the constraints of the application being built. Now we want to move onto the next step: actually sending the song itself. Let’s see how we can do that next.</p>
</section>
</section>
<section id="streaming-data" class="level2" data-number="6.5">
<h2 data-number="6.5">Streaming data</h2>
<p>When introducing the concept of streaming in <em>Chapter 4</em>, I said that request streaming was probably the less popular of the two types. I do not have any empirical data to confirm this, but it seems readily apparent to me that when most people hear the term “streaming”—whether they are a developer or a layperson—the implication is that there is a consumption of some form of media from “the cloud.”</p>
<p>What we are looking to achieve in this section is to learn how we can accomplish this. How exactly does this work? When building a streaming response, Sanic will add the same <code>Transfer Encoding: chunked</code> header that we saw with streaming requests. This is the indication to the client that the server is about to send incomplete data. Therefore, it should leave the connection open.</p>
<p>Once this happens, it is time for the server to send data at its discretion. What is a chunk of data? It follows a protocol whereby the server sends the number of bytes it is about to send (in hexidecimal format), followed by a <code>\r\n</code> line break, followed by some bytes, and another <code>\r\n</code> line break:</p>
<pre><code>1a\r\n
Now I&#39;m free, free-falling\r\n&quot;</code></pre>
<p>When the server is done, it needs to send a <code>0</code> length chunk:</p>
<pre><code>0\r\n
\r\n</code></pre>
<p>As you can probably guess, Sanic will take care of much of the plumbing in setting up the headers, determining chunk sizes, and adding the appropriate line breaks. Our job is to control the business logic. Let’s see what a super simple implementation looks like, and then we can build from there:</p>
<pre><code>@app.get(&quot;/&quot;)
async def handler(request: Request):
    resp = await request.respond()
    await resp.send(b&quot;Now I&#39;m free, free-falling&quot;)
    await resp.eof()</code></pre>
<p>When we were consuming streaming requests, we needed to use the <code>stream</code> keyword argument or decorator. For responses, the simplest method is to generate the response up front: <code>resp = await request.respond()</code>. In our example, <code>resp</code> is a <code>&lt;class 'sanic.response.HTTPResponse'&gt;</code> type object.</p>
<p>Once we have a response object, we can write to it whenever, and however we want using either regular strings <code>("hello")</code> or bytes strings <code>(b"hello").</code> When there is no more data to be transferred, we tell the client using <code>resp.eof(),</code> and we are done.</p>
<p>This asynchronous behavior of sending data at will does bring up an interesting question about the lifecycle of the request. Since we are slightly getting ahead of ourselves, if you are interested to see how middleware behaves with streaming responses, jump ahead to Chapter 6 now.</p>
<p>As I am sure you can probably imagine from our simple example, by having the <code>resp.send()</code> method available to us, we now have the freedom to execute asynchronous calls as desired. Of course, a silly example to illustrate our point would be to add a loop with some time delays:</p>
<pre><code>@app.get(&quot;/&quot;)
async def handler(request: Request):
    resp = await request.respond()
    for _ in range(4):
        await resp.send(b&quot;Now I&#39;m free, free-falling&quot;)
        await asyncio.sleep(1)
    await resp.eof()</code></pre>
<p>In the next section, we will see a more useful and complex example when we start sending server sent events (SSE). But first, let’s get back to our goal. We wanted to send the actual song. Not just meta data, not just the lyrics: the actual music file so we can listen to it through our web application.</p>
<section id="file-streaming" class="level3" data-number="6.5.1">
<h3 data-number="6.5.1">File streaming</h3>
<p>The simplest method to do this is with the <code>file_stream</code> convenience wrapper. This method takes care of all the work for us. It will asynchronously read the file contents, send the data in chunks to the client, and wrap up the response.</p>
<pre><code>from sanic.response import file_stream
@app.route(&quot;/herecomesthesun&quot;)
async def handler(request):
    return file_stream(&quot;/path/to/herecomesthesun.mp4&quot;)</code></pre>
<p>Now it is time to open the browser, turn up the volume, hit our webpage, and enjoy.</p>
<p>Okay, so perhaps relying upon the browser to be our media player is not the best UI. What if we want to embed the song content and have an actual player UI inside of our frontend? HTML and design is outside the scope of the book, obviously. But you can at least get a started using:</p>
<pre><code>&lt;audio controls src=&quot;http://localhost:7777/herecomesthesun&quot; /&gt;</code></pre>
<p>Sanic will default to sending chunks of 4096 bytes with this method. You may find it desirable to increase or decrease that number:</p>
<pre><code>return file_stream(&quot;/path/to/herecomesthesun.mp4&quot;, chunk_size=8192)</code></pre>
<p>It is also worth mentioning that Sanic does some work under the hood to attempt to figure out what kind of file you are sending. This is so that it can properly setup the content-type header. If it is unable to figure it out, then it will fallback to text/plain. Sanic will look at the file extension and try and match it against the operating system’s mime type definitions.</p>
</section>
</section>
<section id="server-sent-events-for-push-communication" class="level2" data-number="6.6">
<h2 data-number="6.6">Server-Sent Events for push communication</h2>
<p>Now that we know that we can control the flow of information from the server, we are entering the territory of being able to build some great features for our web applications.</p>
<p>In the old days, when our application wanted to check the state of something, it would need to poll the web server by repeatedly sending the same request over and over again. We talked about building a music web application. We saw how we could display content, get information, and even stream some content to listen to music. The next step of course is to make the application social, because we of course want to share our music with our friends. We want to add a feature that will list out who is online, and the name of the song they are listening to. Refreshing the page constantly would work, but is a bad experience. Polling constantly by sending the same request over and over again also works, but this eats up resources and is also not a great experience.</p>
<p>What would be better is if our server simply notified the browser when someone came online or when their music player changes. This is what server-sent events (SSE) provides: a super simple set of instructions for our server to send push notifications to the browser.</p>
<p>The basic unit of the SSE protocol is the <em>event</em>, which is a single-line of text that contains a field and some body:</p>
<pre><code>data: foo</code></pre>
<p>In this case the field is: <code>data</code> and the body is <code>foo</code>. A message can consist of one or more events separated by a single new line character: <code>\n</code>. Here is an example:</p>
<pre><code>data: foo
data: bar</code></pre>
<p>When a browser receives this message, it will be decoded as: <code>foo\nbar</code>. A message should be terminated by the server by sending two (2) new line characters: <code>\n\n</code>.</p>
<p>The SSE protocol has five basic fields:</p>
<table>
<tbody>
<tr class="odd">
<td><strong>Field</strong></td>
<td><strong>Description</strong></td>
<td><strong>Example</strong></td>
</tr>
<tr class="even">
<td><code>&lt;null&gt;</code></td>
<td>Should be treated as a comment</td>
<td><code>: This is a comment</code></td>
</tr>
<tr class="odd">
<td><code>event</code></td>
<td>A description of the type of event being sent</td>
<td><code>event: songplaying</code></td>
</tr>
<tr class="even">
<td><code>data</code></td>
<td>he body of the message, often this is either plain text or JSON</td>
<td><code>data: All Along the Watchtower</code></td>
</tr>
<tr class="odd">
<td><code>id</code></td>
<td>A self-created event ID for tracking</td>
<td><code>id: 123456ABC</code></td>
</tr>
<tr class="even">
<td><code>retry</code></td>
<td>Reconnection time in milliseconds</td>
<td><code>retry: 1000</code></td>
</tr>
</tbody>
</table>
Figure 5.2 - Overview of the allowed SSE fields
<section id="starting-with-the-basics" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1">Starting with the basics</h3>
<p>Before diving into how we can implement SSE from Sanic, we need a frontend application that can understand how to process these events. We are not too concerned about how to build the SSE client. There is a prebuild frontend HTML client that you can find in the GitHub repo: … Just grab the code to follow along.</p>
<p>To deliver the client, we will store that HTML as <code>index.html</code> and use the existing tools we know to serve that file. To make sure that we cover the blank root path (<code>/</code>), we will also redirect it to our <code>index.html</code>:</p>
<pre><code>app.static(&quot;/index.html&quot;, &quot;./index.html&quot;, name=&quot;index&quot;)
@app.route(&quot;/&quot;)
def home(request: Request):
    return redirect(request.app.url_for(&quot;index&quot;))</code></pre>
<p>Now that we have a simple client, let’s build the simple server to go along with it:</p>
<pre><code>@app.get(&quot;/sse&quot;)
async def simple_sse(request: Request):
    headers = {&quot;Cache-Control&quot;: &quot;no-cache&quot;}
    resp = await request.respond(
        headers=headers,
        content_type=&quot;text/event-stream&quot;
    )
    await resp.send(&quot;data: hello\n\n&quot;)
    await asyncio.sleep(1)
    await resp.send(&quot;event: bye\ndata: goodbye\n\n&quot;)
    await resp.eof()</code></pre>
<p>Most of this should look familiar. We already saw how we can control the sending of chunks to the client, here we are just doing it in a more structured pattern. Of course, however, this super simple proof-of-concept is far from a feature complete build to be used for our music application. Let’s see how we can make it a bit better by creating a mini framework.</p>
</section>
<section id="building-some-sse-objects" class="level3" data-number="6.6.2">
<h3 data-number="6.6.2">Building some SSE objects</h3>
<p>To create our SSE framework, we will start by building some basic objects to help in creating our messages. SSE messages are indeed super simple, so perhaps this is a bit overkill. On the other hand, making sure we use line breaks and field names appropriately sounds like a recipe for disaster. So, a few thoughtful steps up front should go a long way for us.</p>
<p>The first thing we will build are some objects for creating properly formatted fields:</p>
<pre><code>class BaseField(str):
    name: str
    def __str__(self) -&gt; str:
        return f&quot;{self.name}: {super().__str__()}\n&quot;
class Event(BaseField):
    name = &quot;event&quot;
class Data(BaseField):
    name = &quot;data&quot;
class ID(BaseField):
    name = &quot;id&quot;
class Retry(BaseField):
    name = &quot;retry&quot;
class Heartbeat(BaseField):
    name = &quot;&quot;</code></pre>
<p>Notice how we are starting our inheritance with <code>str</code>. This will make our objects operate as strings, just with some auto-formatting involved:</p>
<pre><code>&gt;&gt;&gt; print(Event(&quot;foo&quot;))
event: foo</code></pre>
<p>Moving on, we need a convenient way to compose fields together into a single message. It also would need to have proper string formatting, which means the additional <code>\n</code> at the end:</p>
<pre><code>def message(*fields: BaseField):
    return &quot;&quot;.join(map(str, fields)) + &quot;\n&quot;</code></pre>
<p>Now, looking at this, we should see a properly formatter SSE message:</p>
<pre><code>&gt;&gt;&gt; print(f&quot;{message(Event(&#39;foo&#39;), Data(&#39;thing&#39;))}&quot;.encode())
b&#39;event: foo\ndata: thing\n\n&#39;</code></pre>
<p>The next step is to try out our new building blocks and see if they send messages as expected to the frontend:</p>
<pre><code>@app.get(&quot;/sse&quot;)
async def simple_sse(request: Request):
    headers = {&quot;Cache-Control&quot;: &quot;no-cache&quot;}
    resp = await request.respond(headers=headers, content_type=&quot;text/event-stream&quot;)
    await resp.send(message(Data(&quot;hello!&quot;)))
    for i in range(4):
        await resp.send(message(Data(f&quot;{i=}&quot;)))
        await asyncio.sleep(1)
    await resp.send(message(Event(&quot;bye&quot;), Data(&quot;goodbye!&quot;)))
    await resp.eof()</code></pre>
<p>Let’s pause for a moment and recap what it is we are trying to achieve. The goal is to send notifications to the browser when a certain event happens. So far, we have identified two events: another user logs into (or out of) the system, and a user starts (or stops) listening to a song. When one of these events are triggered, our stream should broadcast the notification back to the browser. To achieve this we will build a pubsub.</p>
<p>A pubsub is a design paradigm where you have two actors: a publisher and a subscriber. It is the job of the publisher to send messages, and the job of the subscriber to listen for messages. In our scenario, we want the stream to be the subscriber. It will listen for incoming messages, and when it receives one, it will know that it should dispatch the SSE.</p>
<p>Since we are still working out exactly how we want our notification system to work, we are going to keep it simple. The mechanism for our pubsub will be a simple <code>asyncio.Queue</code>. Messages can come in, and messages can be consumed. It should be noted that this design pattern will be limited. Remember way back at the beginning we decided that we were going to run our development server with two workers? The reason for doing that was to keep horizontal scaling in mind. What we are about to do will absolutely break this, and will not work on a distributed system. Therefore, to make this production worthy, we will need a new plan for how to distribute messages across a cluster. We will get there later in this book in our <em>Chapter 11</em> complete example.</p>
<ol>
<li><p>First, we need to setup a single queue. We will do this with a listener:</p>
<pre><code>@app.after_server_start
async def setup_notification_queue(app: Sanic, _):
    app.ctx.notification_queue = asyncio.Queue()</code></pre>
<p>Now, when our application starts, anywhere we have access to the application instance, we can also access the notification queue.</p>
<blockquote>
<p><strong>IMPORTANT NOTE</strong></p>
<p>As we start building more complex applications, we are going to see more usage of <code>ctx</code> objects. These are convenient locations that Sanic provides for us–the developers–to do with as necessary. It is a storage location for “stuff”. Sanic almost never makes use of them directly. Therefore, we are free to set any properties we want on the object.</p>
</blockquote></li>
<li><p>Next, we will create our subscriber. This instance will listen to the queue, and send messages when it finds a message on the queue that has not been dispatched:</p>
<pre><code>class Notifier:
    def __init__(
        self,
        send: Callable[..., Coroutine[None, None, None]],
        queue: asyncio.Queue,
    ):
        self.send = send
        self.queue = queue
    async def run(self):
        await self.send(message(Heartbeat()))
        while True:
            fields = await self.queue.get()
            if fields:
                if not isinstance(fields, (list, tuple)):
                    fields = [fields]
                await self.send(message(*fields))</code></pre>
<p>As you can see, our <code>run </code>operation consists of an infinite loop. Inside of that loop the <code>Notifier </code>will pause and wait until there is something inside of the queue. When there is, it removes the item from the queue and continues through the current iteration of the loop, which is to send that item. But, before our loop, we are going to send a single heartbeat message. This will flush out any startup events so that our client will clear out its own queue. It is not necessary, but I think it is a helpful practice to get into.</p></li>
<li><p>To implement this in our endpoint, it will look like this:</p>
<pre><code>@app.get(&quot;/sse&quot;)
async def simple_sse(request: Request):
    headers = {&quot;Cache-Control&quot;: &quot;no-cache&quot;}
    resp = await request.respond(
        headers=headers,
        content_type=&quot;text/event-stream&quot;
    )
    notifier = Notifier(resp.send, request.app.ctx.notification_queue)
    await notifier.run()
    await resp.eof()</code></pre></li>
</ol>
<p>A response object is created using request.respond. Then, we create the <code>Notifier </code>and let it run. At the very end, <code>eof </code>is called to close out the connection.</p>
<blockquote>
<p><strong>IMPORTANT NOTE</strong></p>
<p>To be entirely up-front, the previous code sample is somewhat flawed. I intentionally left it simple for the sake of making a point. However, since there is no way to break out of the infinite loop, there is really no way the server would ever close out the connection itself. This makes the inclusion of <code>eof </code>a bit of a moot point. It is nice to have there as an example, but this code as written will only ever be stopped client side by navigating away from the endpoint.</p>
</blockquote>
<ol>
<li><p>The easy part should now be pushing messages into the queue. We can do it like this on a separate endpoint:</p>
<pre><code>@app.post(&quot;login&quot;)
async def login(request: Request):
    request.app.ctx.notification_queue.put_nowait(
        [Event(&quot;login&quot;), Data(&quot;So-and-so just logged in&quot;)]
    )
    return text(&quot;Logged in. Imagine we did something here.&quot;)</code></pre></li>
<li><p>We can now test this out! Open your browser and go to: <code>http://localhost:7777/index.html</code>You should see something like this:</p>
<figure>
<img src="../media/file5.png" alt="Figure 5.3 - Screenshot of HTML to test out SSE" /><figcaption aria-hidden="true">Figure 5.3 - Screenshot of HTML to test out SSE</figcaption>
</figure></li>
<li><p>Once we “start” the stream by clicking the button, switch back to a terminal and we will hit our fake login endpoint:</p>
<pre><code>$ curl localhost:7777/login -X POST
Logged in. Imagine we did something here.</code></pre></li>
</ol>
<p>Did you see what just happened in the browser? Go ahead and do it again. Feel free to play around with this example to get a feel for how the different components are working.</p>
<p>Do you think you can build the fake “start playing music” endpoint? Just make sure that if you are going to use <code>Event</code> that your frontend application knows about it by using <code>eventSource.addEventListener</code>. Take a look at the <code>index.html </code>and you will see the <code>login</code> event. I suggest you pause and take some time to dig into this code to see how the different components are working together to facilitate the exchange of data. What kinds of amazing things could you build using this?</p>
<p>In <em>Chapter 6,</em> we will come back to this same example and see another way we could achieve it through the use of signals. I should also probably point out that using <code>asyncio.Queue</code> in this instance has another disadvantage: it will really only work in a single browser. Since our consumer (the <code>Notifier</code>) drains down the queue, what happens when multiple browsers are running simultaneously? Well, only the first one gets the message. Again, this solution is much too simplistic for real world usage, but hopefully it has gotten the ideas flowing for how you could build something more robust. To be entirely transparent, in situations like this I really like to fallback to Redis. If you are familiar with Redis, you might know that it has a pubsub built into it. With the right Python library interface, you can easily solve both the problems the <code>asyncio.Queue</code> implementation gave us: it can be used to push messages to multiple subscribers at once, and it can be used in a distributed system where multiple publishers are pushing into it. Maybe before coming to <em>Chapter 11</em> you want to see if you can make it work in our current example?</p>
<p>If nothing else, I hope you got excited when you saw the message pop-up in your browser. For me, it is still really interesting and fun to see messages being pushed into a browser session. SSE are a super simple solution that can solve some potentially complex problems, that ultimately lead to a powerful feature set. Being able to push data into a web browser truly helps an application feel like it is transforming from a web page to a web application.</p>
<p>The downside of this implementation is that they are still only one-sided. To get two-way asynchronous communication, we need websockets.</p>
</section>
</section>
<section id="websockets-for-two-way-communication" class="level2" data-number="6.7">
<h2 data-number="6.7">Websockets for two-way communication</h2>
<p>You have almost definitely experienced websockets on your favorite web applications before. They are a tool that helps create a super-rich layer of user experience, and can be used in a wide variety of contexts. While SSEs are essentially just an open stream that has not yet been terminated, websockets are something different completely.</p>
<p>Plain vanilla HTTP is just a specification (or protocol) for how messages can be formatted and transmitted over a TCP connection between machines. Websockets are a separate protocol complete with directions on how messages should be formatted, sent, received, etc. The specification for them is really quite involved, and we could probably devote an entire book to just discussing websockets. So instead we will simply focus on their implementation within Sanic. The one technical detail about websockets that worth mentioning is that they begin their life as a normal HTTP connection. The request comes in and asks the server for permission to upgrade its connection to a websocket. Then, the client and server do a bit of a dance together to iron out the details. When the negotiations are all done, we have an open socket where messages can be passed back and forth. Think of it as a two-lane highway where messages can pass by each other on their way to either end.</p>
<p>Perhaps the easiest way to conceptualize a websocket is to think of a chat application. We have a single endpoint on the backend server. Two separate web browsers connect to the server, and each are connected somehow so that when one pushes a message in, the server pushes that message out the other side. In this way, both clients are able to send and receive messages irrespective of what else is happening.</p>
<p>This is true asynchronous web behavior. Sanic uses <code>async/await</code> to leverage and optimize server efficiency for performance. But, the side benefit is that it also allows Sanic to offer an almost effortless mechanism to implementing websockets. While we will not get into the details of how this works, you should be aware that Sanic makes uses of the Python <code>websockets</code> package under the hood. It is a fantastic project, and it might be helpful to look at their documentation when building your own websocket endpoint in Sanic: <a href="https://websockets.readthedocs.io">https://websockets.readthedocs.io</a>.</p>
<p>In the last section we started to make our music player application social by sharing information about who was logged in. Let’s turn up the social aspect by adding in chat. Our goal here is to have two browsers open side by side and be able to pass text messages back and forth between them. Just like with the SSE example, you can grab the frontend code from the GitHub repository so we do not have to worry about those implementation details. <a href="https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/05/websockets">https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/05/websockets</a></p>
<ol>
<li><p>First thing we are going to create is a <code>Client</code>. When someone enters the application, the frontend will immediately open the websocket. The <code>Client </code>will be a holding place for us to be able to keep track of who is in the application, and how we can send them messages. Therefore we need a unique identifier, and the callable to send messages:</p>
<pre><code>class Client:
    def __init__(self, send) -&gt; None:
        self.uid = uuid4()
        self.send = send
    def __hash__(self) -&gt; int:
        return self.uid.int</code></pre>
<p>As you can see above, we are going to keep track of the incoming session by assigning each client a <code>UUID</code>.</p></li>
<li><p>Instantiate this <code>Client </code>object inside of the <code>websocket</code> handler.</p>
<pre><code>@app.websocket(&quot;/chat&quot;)
async def feed(request, ws):
    client = Client(ws.send)</code></pre></li>
<li><p>Next, we need to create our <code>ChatRoom</code>. This will be a global instance that exists during the lifetime of the application. Its role will be to keep track of all of the clients that have entered or exited. When someone tries to send a message, it will be responsible for publishing that message to the rest of the clients. Just like with our SSE example, the implementation I am about to show you is limited in that it cannot be run across a distributed cluster. It will function great on just a single instance. This is because we are registering the clients on a single instance in memory. To build a more scalable application to be used in a production environment, we should use something like Redis or RabbitMQ to distribute the message across multiple Sanic instances. For now, this will do:</p>
<pre><code>class ChatRoom:
    def __init__(self) -&gt; None:
        self.clients: Set[Client] = set()
    def enter(self, client: Client):
        self.clients.add(client)
    def exit(self, client: Client):
        self.clients.remove(client)
    async def push(self, message: str, sender: UUID):
        recipients = (client for client in self.clients if client.uid != sender)
        await asyncio.gather(*[client.send(message) for client in recipients])</code></pre>
<p>There is a mechanism to add and remove clients, and a method to push events to registered clients. One thing that is important to point out here is that we do not want to send the message back to the person that sent it. That would be a little bit awkward and a bit annoying for the user to constantly have their own messages fed back to them. Therefore, we will filter out the sending client.</p></li>
<li><p>Remember, the <code>ChatRoom </code>instance is a single object lives for the lifetime of the application instance. So, where do you think it should be instantiated? That’s right, a listener!</p>
<pre><code>@app.before_server_start
async def setup_chatroom(app, _):
    app.ctx.chatroom = ChatRoom()</code></pre></li>
<li><p>Now all we need to do is wire it up!</p>
<pre><code>@app.websocket(&quot;/chat&quot;)
async def feed(request, ws):
    try:
        client = Client(ws.send)
        request.app.ctx.chatroom.enter(client)
        while True:
            message = await ws.recv()
            if not message:
                break
            await request.app.ctx.chatroom.push(message, client.uid)
    finally:
        request.app.ctx.chatroom.exit(client)</code></pre></li>
</ol>
<p>When the user enters, we add them to the chatroom. Then it enters and infinite loop and waits for a message to be received. This is very similar in concept to the SSE implementation we saw in the last section. When a message is received on the current websocket, it is passed to the <code>ChatRoom </code>object that is responsible for sending it to all of the other registered clients. Seems too easy, right?! Now to test it out. Open two browsers side by side, and start adding messages. Have fun chatting with yourself!</p>
<figure>
<img src="../media/file6.png" alt="Figure 5.4 - Screenshot of two side-by-side HTML websocket-enabled applications: me talking to myself" /><figcaption aria-hidden="true">Figure 5.4 - Screenshot of two side-by-side HTML websocket-enabled applications: me talking to myself</figcaption>
</figure>
<p>The code that you need to run the above websocket HTML application (and the backend chatroom code we just looked at) is available on GitHub: _____.</p>
</section>
<section id="setting-response-headers-and-cookies" class="level2" data-number="6.8">
<h2 data-number="6.8">Setting Response Headers and Cookies</h2>
<p>We have talked a lot about headers. They are super important when building web applications and are generally a fundamental part of application design. When building your application responses, you will likely find reasons to add handlers to your response objects. This could be for security purposes like CORS headers or a Content-Security-Policy, or for informational and tracking purposes. And, of course there are cookies, which are their own special kind of headers that receive special treatment in Sanic.</p>
<p>You may have noticed back in some earlier examples (like the SSE example) where we actually set the headers. It is such an easy and intuitive process, perhaps you did not even notice. Whenever we build a response object, all we need to do is pass a dictionary with key/value pairs:</p>
<pre><code>text(&quot;some message&quot;, headers={
    &quot;X-Foobar&quot;: &quot;Hello&quot;
})</code></pre>
<p>That’s really all there is to it! Keep in mind you will not be required to set your own headers all the time. Sanic takes care of some of them for you, including:</p>
<ul>
<li><code>content-length</code></li>
<li><code>content-type</code></li>
<li><code>connection</code></li>
<li><code>transfer-encoding</code></li>
</ul>
<section id="responding-with-a-request-id" class="level3" data-number="6.8.1">
<h3 data-number="6.8.1">Responding with a request ID</h3>
<p>One pattern that is particularly helpful is to set an <code>x-request-id</code> header on every response. If then make a habit of using <code>request.id</code> in logging or tracing a request through your application, it becomes easier to track what is happening when you inevitability need to debug something.</p>
<p>We want to make sure our response includes the header:</p>
<pre><code>@app.route(&quot;/&quot;)
async def handler(request):
    ...
    return text(&quot;...&quot;, headers={&quot;x-request-id&quot;: request.id})</code></pre>
<p>That is the simple example. As you have probably come to realize by now, that simple example might get tedious if we want to do it on all of our requests. Do you want to try to come up with a solution for adding that to all responses? Decorators and middleware are again potential tools. We will come back to this and you will see some implementations for setting this globally in the full example in <em>Chapter 11</em>.</p>
<p>To truly make this useful, we should setup our logging to include the request ID. We have not talked too much about it yet, but Sanic includes a default logger for you to use. It may be helpful for you to piggyback onto it, but to override the default logging format to include that request ID. If you want to know more about how to set this up, jump ahead to <em>Chapter 6</em>.</p>
</section>
<section id="setting-response-cookies" class="level3" data-number="6.8.2">
<h3 data-number="6.8.2">Setting response cookies</h3>
<p>One of the most important types of headers you can set on an individual response would be the cookie headers. Since they are so prominent, and they could include a bit of complexity to set them up, you can avoid having to use <code>Set-Cookie</code> directly.</p>
<p>Response cookies are basically a key/value pair that gets concatenated into a single string in the response, but then interpreted by the browser. It is yet another shared language in the conversation of the web. So, while a single cookie could be as simple as <code>flavor=chocolatechip</code>, that shared language allows us to set a whole bunch of meta data on top of the simple example.</p>
<p>Before we get to the meta data, let’s look at the simple example:</p>
<pre><code>@app.get(&quot;/ilikecookies&quot;)
async def cookie_setter(request):
    resp = text(&quot;Yum!&quot;)
    resp.cookies[&quot;flavor&quot;] = &quot;chocolatechip&quot;
    return resp</code></pre>
<p>Seems fairly straightforward. Let’s see what it does to our response:</p>
<pre><code>$ curl localhost:7777/ilikecookies -i
HTTP/1.1 200 OK
Set-Cookie: flavor=chocolatechip; Path=/
content-length: 4
connection: keep-alive
content-type: text/plain; charset=utf-8
Yum!</code></pre>
<p>Our response headers now have: <code>Set-Cookie: flavor=chocolatechip; Path=/.</code> So, what’s the deal with that <code>Path</code>? That is the cookie meta data at play. Here are some of the various meta values that we can add:</p>
<table>
<tbody>
<tr class="odd">
<td><code>expires: datetime</code></td>
<td>The time at which a browser should discard the cookie</td>
</tr>
<tr class="even">
<td><code>path: str</code></td>
<td>The path in which the cookie will be applied</td>
</tr>
<tr class="odd">
<td><code>comment: str</code></td>
<td>Comment</td>
</tr>
<tr class="even">
<td><code>domain: str</code></td>
<td>The domain in which the cookie will be applied</td>
</tr>
<tr class="odd">
<td><code>max-age: str</code></td>
<td>Number of seconds before a browser should discard the cookie</td>
</tr>
<tr class="even">
<td><code>secure: bool</code></td>
<td>Whether it should only be sent over HTTPS</td>
</tr>
<tr class="odd">
<td><code>httponly: bool</code></td>
<td>Whether it can be accessed by Javascript</td>
</tr>
<tr class="even">
<td><code>samesite: str</code></td>
<td>Where it can be sent from, values can be: lax, strict, none</td>
</tr>
</tbody>
</table>
Table 5.2 - Cookie meta-fields
<p>When we setup our <code>flavor</code> cookie, it seemed like we were just adding a string value to a dictionary that looked like this:</p>
<pre><code>{
    &quot;flavor&quot;: &quot;chocolatechip&quot;
}</code></pre>
<p>That is not really the case. The <code>response.cookies</code> object is in fact a <code>CookieJar</code> object, which is itself a special kind of <code>dict</code>. When we setup a new key/value on that <code>CookieJar</code>, it is in fact creating a <code>Cookie</code> object. Huh?</p>
<p>When we do this:</p>
<pre><code>resp.cookies[&quot;flavor&quot;] = &quot;chocolatechip&quot;</code></pre>
<p>It is more like you are creating a <code>Cookie("flavor", "chocolatechip")</code>, and then putting it into a <code>CookieJar()</code>. To cleanup some of the complexity involved with managing these instances, Sanic let’s us just work with strings. We should keep this in mind when we go to set the meta data, which is what we will do next.</p>
<p>Let’s imagine we have a cookie that should timeout. After some period of time, we want the browser session to forget it existed. This might–for example–be useful with a session cookie. We set some value that identifies a browser session with a particular user. Storing it in a cookie means that on subsequent requests we can identify who the person is. However, by setting a max-age, we can control the length of time that person can use the application before they need to login again.</p>
<pre><code>resp.cookies[&quot;session&quot;] = &quot;somesessiontoken&quot;
resp.cookies[&quot;session&quot;][&quot;max-age&quot;] = 3600</code></pre>
<p>The same applies for all the other meta fields:</p>
<pre><code>resp.cookies[&quot;session&quot;][&quot;secure&quot;] = True
resp.cookies[&quot;session&quot;][&quot;httponly&quot;] = True
resp.cookies[&quot;session&quot;][&quot;samesite&quot;] = &quot;Strict&quot;</code></pre>
<p>If we put this all together, our cookie headers will ultimately look like this:</p>
<pre><code>Set-Cookie: flavor=chocolatechip; Path=/
Set-Cookie: session=somesessiontoken; Path=/; Max-Age=3600; Secure; HttpOnly; SameSite=Strict</code></pre>
<p>The last thing we should look at is how we should delete cookies. When you want to remove a cookie, it is tempting to just use del like you might with any other dictionary object. The problem is this only works so far. Usually, what you want to do instead is tell the browser that it needs to remove the cookie so that the browser does not send it back in future requests. The easiest method to accomplish this is by setting the max-age of the cookie to 0.</p>
<pre><code>resp.cookies[&quot;session&quot;][&quot;max-age&quot;] = 0</code></pre>
<p>You should now feel comfortable adding and deleting cookies to responses. It might be a good opportunity to create a response handler and use your browser’s cookie inspection tools to see how cookies can be set, manipulated, and deleted from your server.</p>
</section>
</section>
<section id="summary-4" class="level2" data-number="6.9">
<h2 data-number="6.9">Summary</h2>
<p>Now that we have seen how to manipulate both the request and the response, it is entirely possible for us to build some really powerful applications. Whether we are building an HTML-based website, a JSON powered web API, a streaming content application, or some combination of them all, Sanic provides us with the tools we need.</p>
<p>One of the first things we discussed is that Sanic tries hard to not obstruct the build of an application. We as the developers have the freedom to build with different tools, and layer them together to build a truly unique platform. This is very much prevalent when we realize the freedom given to the developer with the response object. Need to write bytes directly? Sure. Want to use a specific templating engine? Not a problem.</p>
<p>Now that we have the basic understanding on how to handle the lifecycle of an HTTP connection from request through to response, we can start to see what else we have at our disposal. In the next chapter we will take a deeper dive into some of the concepts already introduced like middleware, background tasks, and signals. Combining these basic building blocks will help us build not only a powerful application, but also one that is easy to maintain, update, and expand.</p>
</section>
</section>
</body>
</html>
