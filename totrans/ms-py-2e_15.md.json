["```py\n$ pip3 install <package> \n```", "```py\n$ docker run -p 8888:8888 jupyter/scipy-notebook \n```", "```py\n# A commonly used shorthand for numpy is np\n>>> import numpy as np\n\n# Generate a list of numbers from 0 up to 1 million\n>>> a = np.arange(1000000)\n>>> a\narray([     0,      1,      2, ..., 999997, 999998, 999999])\n\n# Change the shape (still references the same data) to a\n# 2-dimensional 1000x1000 array\n>>> b = a.reshape((1000, 1000))\n>>> b\narray([[     0,      1,      2, ...,    997,    998,    999],\n       [  1000,   1001,   1002, ...,   1997,   1998,   1999],\n       ...,\n       [998000, 998001, 998002, ..., 998997, 998998, 998999],\n       [999000, 999001, 999002, ..., 999997, 999998, 999999]])\n\n# The first row of the matrix\n>>> b[0]\narray([  0,   1,   2,   3, ..., 995, 996, 997, 998, 999])\n\n# The first column of the matrix\n>>> b[:, 0]\narray([     0,   1000,   2000,   ..., 997000, 998000, 999000])\n\n# Row 10 up to 12, the even columns between 20 and 30\n>>> b[10:12, 20:30:2]\narray([[10020, 10022, 10024, 10026, 10028],\n       [11020, 11022, 11024, 11026, 11028]])\n\n# Row 10, columns 5 up to 10:\n>>> b[10, 5:10]\narray([10005, 10006, 10007, 10008, 10009])\n\n# Alternative syntax for the last slice\n>>> b[10][5:10]\narray([10005, 10006, 10007, 10008, 10009]) \n```", "```py\n>>> b[0] *= 10\n>>> b[:, 0] *= 20\n\n>>> a\narray([     0,     10,     20, ..., 999997, 999998, 999999])\n>>> b[0:2]\narray([[    0,    10,    20, ...,  9970,  9980,  9990],\n       [20000,  1001,  1002, ...,  1997,  1998,  1999]]) \n```", "```py\nIn [1]: import numpy\n\nIn [2]: a = list(range(1000000))\nIn [3]: b = numpy.array(a)\n\nIn [4]: def dot(xs, ys):\n   ...:     total = 0\n   ...:     for x, y in zip(xs, ys):\n   ...:         total += x * y\n   ...:     return total\n   ...:\n\nIn [5]: %timeit dot(a, a)\n78.7 ms ± 1.03 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\nIn [6]: %timeit numpy.dot(b, b)\n518 µs ± 27.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) \n```", "```py\n>>> import numpy\n>>> import numba\n\n>>> numbers = numpy.arange(500, dtype=numpy.int64)\n\n>>> @numba.vectorize([numba.int64(numba.int64)])\n... def add_one(x):\n...     return x + 1\n\n>>> numbers\narray([  0,   1,   2, ..., 498, 499])\n\n>>> add_one(numbers)\narray([  1,   2,   3, ..., 499, 500]) \n```", "```py\n@numba.vectorize([\n    numba.int64(numba.float32, numba.float32), \n    numba.int64(numba.float64, numba.float64),\n]) \n```", "```py\n>>> import numpy\n>>> from scipy import sparse\n\n>>> x = numpy.identity(10000)\n>>> y = sparse.identity(10000)\n\n>>> x.data.nbytes\n800000000\n\n# Summing the memory usage of scipy.sparse objects requires the summing\n# of all internal arrays. We can test for these arrays using the\n# nbytes attribute.\n>>> arrays = [a for a in vars(y).values() if hasattr(a, 'nbytes')]\n\n# Sum the bytes from all arrays\n>>> sum(a.nbytes for a in arrays)\n80004 \n```", "```py\n# A commonly used shorthand for pandas is pd\n>>> import re\n>>> import io\n\n>>> import pandas as pd\n\n>>> data = '''\n... Version\\tLatest micro version\\tRelease date\\tEnd of full support\\tEnd ...\n... 0.9\\t0.9.9[2]\\t1991-02-20[2]\\t1993-07-29[a][2]\n... ...\n... 3.9\\t3.9.5[60]\\t2020-10-05[60]\\t2022-05[61]\\t2025-10[60][61]\n... 3.10\\t\\t2021-10-04[62]\\t2023-05[62]\\t2026-10[62]\n... '''.strip()\n\n# Slightly clean up data by removing references\n>>> data = re.sub(r'\\[.+?\\]', '', data)\n\n# df is often used as a shorthand for pandas.DataFrame\n>>> df = pd.read_table(io.StringIO(data)) \n```", "```py\n# List the columns\n>>> df.columns\nIndex(['Version', ..., 'Release date', ...], dtype='object')\n# List the versions:\n>>> df['Version']\n0     0.9\n...\n25    3.9\n26    3.1\nName: Version, dtype: float64\n\n# Oops... where did Python 3.10 go in the output above? The\n# conversion to float trimmed the 0 so we need to disable that.\n>>> df = pd.read_table(io.StringIO(data), dtype=dict(Version=str))\n\n# Much better, we didn't lose the version info this time\n>>> df['Version']\n0      0.9\n...\n25     3.9\n26     3.10\nName: Version, dtype: object \n```", "```py\n# The release date is read as a string by default, so we convert\n# it to a datetime:\n>>> df['Release date'] = pd.to_datetime(df['Release date'])\n\n>>> df['Release date']\n0      1991-02-20\n...\n26     2021-10-04\nName: Release date, dtype: datetime64[ns]\n\n# Let's see which month is the most popular for Python releases.\n# First we run groupby() on the release month and after that we\n# run a count() on the version:\n>>> df.groupby([df['Release date'].dt.month])['Version'].count()\nRelease date\n1     2\n2     2\n3     1\n4     2\n6     3\n7     1\n9     4\n10    8\n11    1\n12    3\nName: Version, dtype: int64 \n```", "```py\n>>> import pandas as pd\n>>> import numpy as np\n\n>>> df = pd.DataFrame(dict(\n...     building=['x', 'x', 'y', 'x', 'x', 'y', 'z', 'z', 'z'],\n...     rooms=['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c'],\n...     hours=[10, 11, 12, 10, 11, 12, 10, 11, 12],\n...     \n...     temperatures=np.arange(0.0, 9.0),\n... ))\n\n>>> df\n  building rooms  hours  temperatures\n0        x     a     10           0.0\n1        x     a     11           1.0\n...\n7        z     c     11           7.0\n8        z     c     12           8.0 \n```", "```py\n>>> pd.pivot_table(\n...     df, values='temperatures', index=['rooms'],\n...     columns=['hours'], aggfunc=np.mean)\nhours   10   11   12\nrooms\na      0.0  1.0  2.0\nb      3.0  4.0  5.0\nc      6.0  7.0  8.0 \n```", "```py\n>>> pd.pivot_table(\n...     df, values='temperatures', index=['building', 'rooms'],\n...     columns=['hours'], aggfunc=np.mean)\nhours            10   11   12\nbuilding rooms\nx        a      0.0  1.0  NaN\n         b      3.0  4.0  NaN\ny        a      NaN  NaN  2.0\n         b      NaN  NaN  5.0\nz        c      6.0  7.0  8.0 \n```", "```py\n>>> df.groupby(pd.Grouper(key='hours')).mean()\n       temperatures\nhours\n10              3.0\n11              4.0\n12              5.0 \n```", "```py\n>>> import pandas as pd\n>>> import numpy as np\n\n>>> pd_series = pd.Series(np.arange(100))  # [0, 1, 2, ... 99]\n\n>>> # Create a rolling window with size 10\n>>> window = pd_series.rolling(10)\n>>> # Calculate the running mean and ignore the N/A values at the\n>>> # beginning before the window is full\n>>> window.mean().dropna()\n9      4.5\n10     5.5\n      ...\n99    94.5\nLength: 91, dtype: float64 \n```", "```py\n# The common shorthand for statsmodels is sm\n>>> import statsmodels.api as sm\n>>> import numpy as np\n\n>>> Y = np.arange(8)\n>>> X = np.ones(8)\n\n# Create the weighted-least-squares model\n>>> model = sm.WLS(Y, X)\n\n# Fit the model and generate the regression results\n>>> fit = model.fit()\n\n# Show the estimated parameters and the t-values:\n>>> fit.params\narray([3.5])\n>>> fit.tvalues\narray([4.04145188]) \n```", "```py\n# The common shorthand for xarray is xr\n>>> import xarray as xr\n\n>>> ds = xr.Dataset.from_dataframe(df)\n\n# For reference, the pandas version of the groupby\n# df.groupby([df['Release date'].dt.month])['Version'].count()\n>>> ds.groupby('Release date.month').count()['Version']\n\n<xarray.DataArray 'Version' (month: 10)>\narray([2, 2, 1, 2, 3, 1, 4, 8, 1, 3])\nCoordinates:\n  * month    (month) int64 1 2 3 4 6 7 9 10 11 12 \n```", "```py\ndf.groupby([df['Release date'].dt.month]).count()['Version'] \n```", "```py\n>>> import xarray as xr\n>>> import numpy as np\n\n>>> points = np.arange(27).reshape((3, 3, 3))\n>>> triangles = np.arange(27).reshape((3, 3, 3))\n>>> ds = xr.Dataset(dict(\n...     triangles=(['p0', 'p1', 'p2'], triangles),\n... ), coords=dict(\n...     points=(['x', 'y', 'z'], points),\n... ))\n\n>>> ds\n<xarray.Dataset>\nDimensions:    (p0: 3, p1: 3, p2: 3, x: 3, y: 3, z: 3)\nCoordinates:\n    points     (x, y, z) int64 0 1 2 3 4 5 ... 21 22 23 24 25 26\nDimensions without coordinates: p0, p1, p2, x, y, z\nData variables:\n    triangles  (p0, p1, p2) int64 0 1 2 3 4 ... 21 22 23 24 25 26 \n```", "```py\n>>> import numpy as np\n>>> import stumpy\n\n>>> temperatures = np.array([22., 21., 22., 21., 22., 23.])\n\n>>> window_size = 3\n\n# Calculate a Euclidean distance matrix between the windows\n>>> stump = stumpy.stump(temperatures, window_size)\n\n# Show the distance matrix. The row number is the index in the\n# input array. The first column is the distance; the next columns\n# are the indices of the nearest match, the left match, and the\n# right match.\n>>> stump\narray([[0.0, 2, -1, 2],\n      [2.449489742783178, 3, -1, 3],\n      [0.0, 0, 0, -1],\n      [2.449489742783178, 1, 1, -1]], dtype=object)\n\n# As we can see in the matrix above, the first window has a\n# distance of 0 to the window at index 2, meaning that they are\n# identical. We can easily verify that by showing both windows:\n\n# The first window:\n>>> temperatures[0:window_size]\narray([22., 21., 22.])\n\n# The window at index 2:\n>>> temperatures[2:2 + window_size]\narray([22., 21., 22.]) \n```", "```py\n>>> import gmpy2\n\n>>> gmpy2.const_pi(1000)\nmpfr('3.14159265358979...33936072602491412736',1000) \n```", "```py\nsage: x, y, z = var('x, y, z')\nsage: solve([x + y == 10, x - y == 5, x + y + z == 1], x, y, z)\n[[x == (15/2), y == (5/2), z == -9]] \n```", "```py\n>>> N = 10\n>>> x = 0.1\n\n# Regular addition\n>>> a = 0.0\n>>> for _ in range(N):\n...     a += x  \n\n>>> a\n0.9999999999999999\n\n# Using sum, the same result as addition\n>>> sum(x for _ in range(N))\n0.9999999999999999 \n```", "```py\n# Sum using Python's optimized fsum:\n>>> import math\n\n>>> math.fsum(x for _ in range(N))\n1.0 \n```", "```py\n>>> import mpmath\n\n# Increase the mpmath precision to 100 decimal places\n>>> mpmath.mp.dps = 100\n>>> y = mpmath.mpf('0.1')\n\n# Using mpmath with addition:\n>>> b = mpmath.mpf('0.0')\n>>> for _ in range(N):\n...     b += y\n\n>>> b\nmpf('1.00000000000000000000000000...00000000000000000000000014')\n\n# Or a regular sum with mpmath:\n>>> sum(y for _ in range(N))\nmpf('1.00000000000000000000000000...00000000000000000000000014') \n```", "```py\n>>> from sympy import *\n\n>>> init_printing(use_unicode=True)\n>>> x, y, z = symbols('x y z')\n\n>>> integral = Integral(x * cos(x), x)\n>>> integral\n⌠\n| x cos(x) dx\n⌡\n>>> integral.doit()\nx sin(x) + cos(x) \n```", "```py\n>>> import patsy\n>>> import numpy as np\n\n>>> array = np.arange(2, 6)\n\n>>> data = dict(a=array, b=array, c=array)\n>>> patsy.dmatrix('a + np.square(b) + np.power(c, 3)', data)\nDesignMatrix with shape (4, 4)\n  Intercept  a  np.square(b)  np.power(c, 3)\n          1  2             4               8\n          1  3             9              27\n          1  4            16              64\n          1  5            25             125\n  Terms:\n    'Intercept' (column 0)\n    'a' (column 1)\n    'np.square(b)' (column 2)\n    'np.power(c, 3)' (column 3) \n```", "```py\n# The common shorthand for pyplot is plt\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Enable in-line rendering for the Jupyter notebook\n%matplotlib inline\n\na = np.arange(100) ** 2\nplt.plot(a) \n```", "```py\n%matplotlib notebook\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport ipywidgets as widgets\n\n# Using interact, we create 2 sliders here for size and step.\n# In this case we have size which goes from 1 to 25 with increments\n# of 1, and step, which goes from 0.1 to 1 with increments of 0.1\n@widgets.interact(size=(1, 25, 1), step=(0.1, 1, 0.1))\ndef plot(size, step):\n    # Create a matplotlib figure\n    # We will render everything onto this figure\n    fig = plt.figure()\n\n    # Add a subplot. You could add multiple subplots but only one will \n    # be shown when using '%matplotlib notebook'\n    ax = fig.add_subplot(projection='3d')\n\n    # We want X and Y to be the same, so generate a single range\n    XY = np.arange(-size, size, step)\n\n    # Convert the vectors into a matrix\n    X, Y = np.meshgrid(XY, XY)\n\n    R = np.sqrt(X**2 + Y**2)\n\n    # Plot using sine\n    Z = np.sin(R)\n    ax.plot_surface(X, Y, Z)\n\n    # Plot using cosine with a Z-offset of 10 to plot above each other\n    Z = np.cos(R)\n    ax.plot_surface(X, Y, Z + 10) \n```", "```py\n%matplotlib notebook\n\nimport seaborn as sns\n\nsns.pairplot(\n    # Load the bundled Penguin dataset\n    sns.load_dataset('penguins'),\n    # Show a different \"color\" for each species\n    hue='species',\n    # Specify the markers (matplotlib.markers)\n    markers=['o', 's', 'v'],\n    # Gray was chosen due to the book being printed in black and white\n    palette='Greys',\n    # Specify which rows and columns to show. The default is to show all\n    y_vars=['body_mass_g', 'flipper_length_mm'],\n    x_vars=['body_mass_g', 'flipper_length_mm', 'bill_length_mm']) \n```", "```py\n%matplotlib notebook\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split as tts\n\nfrom yellowbrick.datasets import load_concrete\nfrom yellowbrick.regressor import residuals_plot\n\n# Load the dataset and split into train/test (pandas.DataFrame) splits\nX, y = load_concrete()\n\nX_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, shuffle=True)\n\n# Create the visualizer, fit, score, and show it\nviz = residuals_plot(RandomForestRegressor(), X_train, y_train, X_test, y_test) \n```", "```py\nimport seaborn as sns\nimport plotly.express as px\n\nfig = px.scatter_matrix(\n    # Load the Penguin dataset from seaborn\n    sns.load_dataset('penguins'),\n    # Show a different \"color\" for each species\n    color='species',\n    # Specify that the symbols/markers are species-dependent\n    symbol='species',\n    # Specify which rows and columns to show. The default is to show all\n    dimensions=['body_mass_g', 'flipper_length_mm', 'bill_length_mm'],\n)\nfig.show() \n```", "```py\nimport plotly\nimport numpy as np\nimport ipywidgets as widgets\nimport plotly.graph_objects as go\n\n# Using interact, we create 2 sliders here for size and step.\n# In this case we have size which goes from 1 to 25 with increments\n# of 1, and step, which goes from 0.1 to 1 with increments of 0.1\n@widgets.interact(size=(1, 25, 1), step=(0.1, 1, 0.1))\ndef plot(size, step):\n    # Create a plotly figure, we will render everything onto this figure\n    fig = go.Figure()\n\n    # We want X and Y to be the same, so generate a single range\n    XY = np.arange(-size, size, step)\n\n    # Convert the vectors into a matrix\n    X, Y = np.meshgrid(XY, XY)\n\n    R = np.sqrt(X**2 + Y**2)\n\n    # Plot using sine\n    Z = np.sin(R)\n    fig.add_trace(go.Surface(x=X, y=Y, z=Z))\n\n    # Plot using cosine with a Z-offset of 10 to plot above each other\n    Z = np.cos(R)\n    fig.add_trace(go.Surface(x=X, y=Y, z=Z + 10))\n    fig.show() \n```", "```py\nimport numpy as np\n\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\n\n# Load all javascript/css for bokeh\noutput_notebook()\n\n# Create a numpy array of length 100 from 0 to 4 pi\nx = np.linspace(0, 4*np.pi, 100)\n\n# Create a bokeh figure to draw on\np = figure()\n# Draw both a sine and a cosine\np.line(x, np.sin(x), legend_label='sin(x)', line_dash='dotted')\np.line(x, np.cos(x), legend_label='cos(x)')\n\n# Render the output\nshow(p) \n```", "```py\nimport numpy as np\nimport seaborn as sns\n\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.layouts import gridplot\nfrom bokeh.transform import factor_cmap, factor_mark\n\noutput_notebook()\n\n# Load the seaborn penguin dataset (pandas.DataFrame)\npenguins = sns.load_dataset('penguins')\n# Get the unique list of species for the marker and color mapping\nspecies = penguins['species'].unique()\n# Specify the marker list which will be mapped to the 3 species\nmarkers = ['circle', 'square', 'triangle']\n# Create a list of rows so we can build the grid of plots\nrows = []\n\nfor y in ('body_mass_g', 'flipper_length_mm'):\n    row = []\n    rows.append(row)\n\n    for x in ('body_mass_g', 'flipper_length_mm', 'bill_length_mm'):\n        # Create a figure with a fixed size and pass along the labels\n        p = figure(width=250, height=250,\n            x_axis_label=x, y_axis_label=y)\n        row.append(p)\n\n        if x == y:\n            # Calculate the histogram using numpy and make sure to drop\n            # the NaN values\n            hist, edges = np.histogram(penguins[x].dropna(), bins=250)\n            # Draw the histograms as quadrilaterals (rectangles)\n            p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:])\n        else:\n            # Create a scatter-plot\n            p.scatter(\n                # Specify the columns of the dataframe to show on the\n                # x and y axis\n                x, y,\n                # Specify the datasource, the pandas.DataFrame is\n                # natively supported by bokeh\n                source=penguins,\n                # Specify the column that contains the legend data\n                legend_field='species',\n                # Map the species onto our list of markers\n                marker=factor_mark('species', markers, species),\n                # Map the species to the Greys4 color palette\n                color=factor_cmap('species', 'Greys4', factors=species),\n                # Add transparency to the markers to make them easier\n                # to see\n                fill_alpha=0.2,\n            )\n\n# Show a grid of plots. Expects a 2D array\nshow(gridplot(rows)) \n```", "```py\nimport numpy as np, pandas as pd, datashader as ds\nfrom datashader import transfer_functions as tf\nfrom datashader.colors import inferno, viridis\nfrom numba import jit\nfrom math import sin, cos, sqrt, fabs\n\n# Set the number of points to calculate, takes about a second with\n# 10 million\nn=10000000\n\n# The Clifford attractor code, JIT-compiled using numba\n@jit(nopython=True)\ndef Clifford(x, y, a, b, c, d, *o):\n    return sin(a * y) + c * cos(a * x), \\\n           sin(b * x) + d * cos(b * y)\n\n# Coordinate calculation, also JIT-compiled\n@jit(nopython=True)\ndef trajectory_coords(fn, x0, y0, a, b=0, c=0, d=0, e=0, f=0, n=n):\n    x, y = np.zeros(n), np.zeros(n)\n    x[0], y[0] = x0, y0\n    for i in np.arange(n-1):\n        x[i+1], y[i+1] = fn(x[i], y[i], a, b, c, d, e, f)\n    return x,y\n\ndef trajectory(fn, x0, y0, a, b=0, c=0, d=0, e=0, f=0, n=n):\n    x, y = trajectory_coords(fn, x0, y0, a, b, c, d, e, f, n)\n    return pd.DataFrame(dict(x=x,y=y))\n\n# Calculate the pandas.DataFrame\ndf = trajectory(Clifford, 0, 0, -1.7, 1.5, -0.5, 0.7)\n\n# Create a canvas and render\ncvs = ds.Canvas()\nagg = cvs.points(df, 'x', 'y')\ntf.shade(agg, cmap=[\"white\", \"black\"]) \n```"]