<html><head></head><body>
        

                            
                    <h1 class="header-title">SDN Concepts in Network Automation</h1>
                
            
            
                
<p>As we have seen on our journey so far, there are numerous scenarios where we can automate a network, from daily or routine tasks, to managing infrastructure from a single controller-based architecture.  Building upon those concepts, we will now gain some additional insights for working in <strong>software-defined networks</strong> (<strong>SDNs</strong>) and look at some examples of working with cloud platforms.</p>
<p>Some of the key components we are going to cover are:</p>
<ul>
<li>Cloud platform automation</li>
<li>Network automation tools</li>
<li>Controller-based network fabric</li>
<li>Programmable network devices</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Managing cloud platforms</h1>
                
            
            
                
<p>We can use network automation techniques through Python to work on various cloud providers. From working on cloud instances, to spinning up new VMs, controlling full access like ACLs, and creating specific network layer tasks like VPNs, and network configurations of each instance, we can automate just about anything using available connectors or APIs in Python. Let's see some basic configuration and connections on the most popular cloud platform, <strong>Amazon Web Services</strong> (<strong>AWS</strong>) using Python.</p>
<p>AWS provides an extensive API through its SDK called Boto 3. Boto 3 provides two types of APIs to be used, a low-level API set that is used to interact with direct AWS services, and a high-layer Python friendly API set for quick interactions with AWS. Along with Boto 3, we also would need to have the AWS CLI that is used as a <strong>command-line interface</strong> (<strong>CLI</strong>) to interact with AWS from the local machine. Think of this as a CLI based tool that is equally like DOS is to Windows from a CLI perspective.</p>
<p>The installation of both the AWS CLI and Boto 3 is done using <kbd>pip</kbd>:</p>
<ul>
<li>To install from AWS CLI, use the following command:</li>
</ul>
<pre style="padding-left: 90px"><strong>pip install awscli</strong></pre>
<ul>
<li>To install from Boto 3, use the following command:</li>
</ul>
<pre style="padding-left: 90px"><strong>pip install boto3</strong></pre>
<p>Once installed, the packages are ready to use. However, we need to configure an access key in the AWS Web Management Console which will have a certain level of restrictions (that we will define while creating the access key).</p>
<p>Let's quickly set up a new access key to manage the AWS in Python from our local machine:</p>
<ol>
<li>Log in to the AWS web console and select IAM as the option:</li>
</ol>
<div><img src="img/d6dd3bb0-93e1-416b-b09b-dde6bf496236.jpg" style="width:48.92em;height:19.83em;"/></div>
<ol start="2">
<li>Click on Add user to create a username and password pair shown as follows:</li>
</ol>
<div><img src="img/c34f5d6f-8428-4a07-b5db-5a6fd36980d4.jpg" style="width:36.50em;height:18.17em;"/></div>
<ol start="3">
<li>Select username and ensure to check Programmatic access to get the access ID and secret key to be used in our Python calls:</li>
</ol>
<div><img src="img/201f9356-8f61-4288-8a8d-049d4ac83921.jpg" style="width:43.17em;height:26.75em;"/></div>
<ol start="4">
<li>We also need the user to be part of a certain group (for security restrictions). In our case we make it part of the admin group which has full rights on the AWS instance:</li>
</ol>
<div><img src="img/e6bc8d59-f148-4f45-8f9a-2fb4acf477ad.jpg" style="width:28.00em;height:24.92em;"/></div>
<ol start="5">
<li>If we made our selections correctly, a user is created with the username we selected (<kbd>booktest</kbd>) with an access key and a secret access key:</li>
</ol>
<div><img src="img/d2158071-32a0-469e-911e-fbc96cb771bf.jpg" style="width:61.75em;height:22.83em;"/></div>
<ol start="6">
<li>Once we have this key, we go back to our Python installation and on the Command Prompt, call the AWS CLI command <kbd>aws configure</kbd>:</li>
</ol>
<div><img src="img/b067f6ad-1546-486b-b4d8-baf6c6038c1d.jpg" style="width:36.25em;height:10.83em;"/></div>
<ol start="7">
<li>As per the questions asked, we fetch the values from the AWS web console and paste them in the CLI. The final question of <kbd>Default output format</kbd> can be <kbd>text</kbd> or <kbd>json</kbd>. However, for our purpose of automation and working with Python, we would select <kbd>json</kbd> instead of <kbd>text</kbd>.</li>
</ol>
<p>Once we are done with this backend configuration, we are ready to test our scripts by calling the Boto 3 API in Python.</p>
<p>Let's see an example of getting all running instances on the current AWS account for which we have the key:</p>
<pre>import boto3<br/>ec2 = boto3.resource('ec2')<br/>for instance in ec2.instances.all():<br/>    print (instance)<br/>    print (instance.id, instance.state)</pre>
<p class="mce-root">Since we have already configured the backend credentials and key with the <kbd>aws configure</kbd> CLI command, we do not need to specify any credentials in our scripts. </p>
<p>The output of the preceding code is as follows:</p>
<div><img src="img/0ab7156c-653b-4bbf-9abc-0da74b8ae3a2.jpg" style="width:31.08em;height:14.75em;"/></div>
<p>As we see in the preceding output, we get back two instances which are EC2 instances with their instance IDs. Additionally, we also get some other parameters for the currently configured instances. In some cases, if we do not want to use the current preconfigured keys, we can call the Python program by passing the values directly into Boto 3 functions as follows:</p>
<pre>import boto3<br/> <br/>aws_access_key_id = 'accesskey'<br/>aws_secret_access_key = 'secretaccesskey'<br/>region_name = 'us-east-2'<br/> <br/>ec2 = boto3.client('ec2',aws_access_key_id=aws_access_key_id,aws_secret_access_key=aws_secret_access_key,region_name=region_name)</pre>
<p class="mce-root">Let's see another example of fetching the private IP address and instance ID for each of the instances:</p>
<pre>import boto3<br/><br/>ec2 = boto3.client('ec2')<br/>response = ec2.describe_instances()<br/>for item in response['Reservations']:<br/>    for eachinstance in item['Instances']:<br/>        print (eachinstance['InstanceId'],eachinstance['PrivateIpAddress'])</pre>
<p>The preceding code gives the following output:</p>
<div><img src="img/e72a2534-f0bc-4b04-8209-2037ee842087.jpg" style="width:37.25em;height:13.58em;"/></div>
<p>Using the Boto 3 API, we can also spin up new instances in our subscription. Let's see a final example of spinning up a new <strong>Virtual Machine</strong>(<strong>VM</strong>) with EC2 using Boto 3.</p>
<p>Before we call the Python to spin a new VM, we need to select which <strong>Amazon Machine Image</strong> (<strong>AMI</strong>) image to use for the instance. To find out the AMI image value, we need to open AMI in the AWS web console shown as follows:</p>
<div><img src="img/b89b8f02-0d74-4548-968d-aa99cb7e16ce.jpg" style="width:81.83em;height:34.83em;"/></div>
<p>Once we have finalized the AMI, we call the easy part, spinning the new VM:</p>
<pre>import boto3<br/>ec2 = boto3.resource('ec2')<br/>ec2.create_instances(ImageId='amid-imageid', MinCount=1, MaxCount=5)</pre>
<p>It will take some time for the script to execute, and the result value would be the instance with all its configured parameters based upon the AMI image ID selected. Similarly, we can spin up various type of instances or even new security filters using Boto 3 and ensure we have cloud controlling automation in place.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Programmable network devices</h1>
                
            
            
                
<p class="mce-root">Looking back at historic implementations, we had a fixed set of hardware or networks geared for catering services to the end users. End users also had a limited set of connection options to access a limited set of networks or connected resources. As the number of users increased, a simple solution was to add additional hardware or network gear. However, with the surge of different end user devices, such as mobile phones, and high data demand and up time requirements for end users, managing the increasing amount of hardware and additional connections becomes a complex task.</p>
<p>A simple device failure or cable failure might impact the entire set of connected hardware or network gears, which would create a widespread downtime for end users, resulting in a loss of man hours both in terms of productivity and trust. Think of a large <strong>internet service provider</strong> (<strong>ISP</strong>) with recurring outages, with each outage affecting a large set of both enterprise and home users. If a new ISP were to enter the market with reliability as its unique selling point, people would not think twice before jumping to the new provider. Effectively, this could result in a loss of business and ultimately, a closure situation for the earlier provider because of the decreasing reliability and trust among its current set of users.</p>
<p>To handle this type of situation, one solution that has emerged is the usability of the same set of devices or network hardware to perform different functions using the same hardware platform. This has been made possible through a combination of SDN<strong> </strong>and <strong>programmable networks</strong> (<strong>PNs</strong>).</p>
<p>SDN takes care of control plane configurations for data to automatically reroute to a path that is the best available for a specific source to the destination. For example, let's say we need to reach destination D from source A. The best path to reach D is A -&gt; C -&gt; D.</p>
<p>Now, in the case of legacy traffic flow, unless C is down or practically shut, the traffic will not flow from A -&gt; B -&gt; D (unless special complex configurations are done on each network gear/device). In an SDN environment, using OpenFlow as the underlying protocol, the controller will detect any issues in the path of A -&gt; C -&gt; D, and based upon certain issues (like packet drop or congestion in the path), would make an intelligent decision to ensure there is a new path for the data to flow from A -&gt; B -&gt; D.</p>
<p>As we see in this case, even with no physical issues on C, SDN already takes care of identifying the best path for the data to flow on, which effectively results in the best achievable performance for end users with reliability.</p>
<p>PN is an addition which is a collection of hardware devices in the network layer that can be programmed to behave in a different way based upon the requirements. Think of a switch acting as a router by changing its functionality through a written piece of code. Let's say we get an influx of new end users and we need to have a high switching capacity in the network layer. Some of the devices can now act as a switch rather than a router. This ensures a two-fold benefit:</p>
<ul>
<li>Using the same set of hardware based upon the demand and requirements, the hardware can be reused to handle new scenarios without introducing more complexity into the network by adding an additional set of hardware.</li>
<li>Better control over the flow of traffic with the additional capability of securing traffic through the same set of devices. This is introduced by adding ACLs for traffic to flow from a certain set of devices, and even ensuring that a device handles only a particular type of traffic and sends the remaining traffic to other devices that are specifically programmed to handle that particular traffic. Think of it, as video with voice traffic going from a different set of devices to ensure optimal performance and load on specific devices using the same set of hardware that we currently have.</li>
</ul>
<p>A major component of PNs (the collective name for programmable network devices), is the use of APIs that are provided by various network vendors like Cisco, Arista, and Juniper. By calling these APIs we can ensure that each of the devices from specific vendors can easily talk to each other (exchange information is a unified format), and can change the behavior of a specific hardware based upon the API calls. One example that is common in today's market is Cisco Nexus 9000 series devices. These are modular or fixed switches (with different variations), and by using OpenFlow gives us the ability to programmatically alter their behavior based upon dynamic requirements.</p>
<p>Taking this switch as an example, direct access to <strong>application-specific integrated circuit</strong> (<strong>ASIC</strong>) chip-level programming is also exposed, which ensures that the ASICs can also be programmed based upon the requirement along with the software-level variations. With SDN in place, controllers can take advantage of OpenFlow and the APIs exposed on these switches to control the role of these switches.</p>
<p>Cisco also provides a <strong>Power on Auto Provisioning</strong> (<strong>PoAP</strong>) feature to multiple devices (primarily on the Nexus platform) that helps achieve auto provisioning and commissioning as soon as a new device boots. A basic overview of this process is, if a Nexus device with the PoAP feature enabled boots and is unable to find any startup config, it locates a <strong>Dynamic Host Configuration Protocol</strong> (<strong>DHCP</strong>) server in the network and bootstraps using the IP address and DNS information obtained from that DHCP server. It also fetches a customized script that is executed on the device that has instructions to download and install the relevant software image files and specific configurations for that device.</p>
<p>A big advantage of this type of feature is that we can spin up new devices within one to two minutes by just powering it up and connecting it to a network which has DHCP functionality to fetch relevant information to new devices in the network. Think of the legacy way of bringing a router live with multiple hours of human intervention versus the current way of booting up a router, and the router taking care of itself without any human intervention.</p>
<p class="mce-root">Similarly, using the APIs (<strong>NX-API</strong> is the underlying terminology used for <strong>Nexus API</strong>), better visibility in terms of packet flow and monitoring is also being exposed from Cisco, and, using simple scripts written in any language (like Python), the path and flow of traffic can be modified based upon the results returned back through the call of those APIs.</p>
<p>Taking another example, we have network device vendor Arista. Arista has introduced Arista <strong>Extensible Operating System</strong> (<strong>EOS</strong>), which is a highly modular and Linux-based network OS. Using Arista EOS, managing multiple devices becomes easy as it has the ability to provide extensive APIs (Linux kernel-based and additional ones related to Arista), and call APIs for various vendors to configure and deploy numerous end nodes. A feature introduced by Arista called <strong>Smart System Upgrade</strong> (<strong>SSU</strong>), ensures that as we perform OS upgrades on Arista devices, it restarts its services with the upgraded OS versions but without rebooting to ensure minimal traffic interruption during upgrades. These features ensure that we have resiliency and up time even when we have new patches and OS upgrades rolled out on the data centers or multiple devices at once.</p>
<p>Arista EOS provides extended functionality for the devices to be managed through APIs by providing a set of APIs call <strong>eAPI</strong>. eAPI can be used to configure Arista devices by calling the eAPI framework from any scripting or programmable language. Let's see a very basic example of how to manage an Arista switch using eAPI. </p>
<p>We need to configure eAPI on the Arista switch:</p>
<pre>Arista&gt; enable<br/>Arista# configure terminal<br/>Arista(config)# management api http-commands<br/>Arista(config-mgmt-api-http-cmds)# no shutdown<br/>Arista(config-mgmt-api-http-cmds)# protocol http<br/>Arista(config-mgmt-api-http-cmds)#end</pre>
<p>This ensures that the Arista eAPI functionality is enabled on the router, and we can use HTTP protocol to interact with the API. We can also switch between the options of eAPI available over HTTPS, by using the command <kbd>protocol https</kbd>.</p>
<p>To verify if our configuration is correct, we use the command <kbd>show management api http-commands</kbd>, as follows:</p>
<pre>Arista# show management api http-commands <br/>Enabled: Yes <br/>HTTPS server: shutdown, set to use port 443 <br/>HTTP server: running, set to use port 80</pre>
<p>We can check if the eAPI framework is now accessible using the browser command <kbd>http://&lt;ip of router&gt;</kbd>.</p>
<p>A couple of examples from Arista depict the output that we get using the URL (in this case we have HTTPS enabled instead of HTTP):</p>
<div><img src="img/8f8c0913-3109-4155-98bc-94f1f4da9513.jpg" style="width:55.50em;height:32.75em;"/></div>
<p>Here we see a set of commands passed (<kbd>show version</kbd> and <kbd>show hostname</kbd>), and the response from the API confirms the result set. Additionally, the Command Response Documentation tab shows us the available APIs that can be used for reference:</p>
<div><img src="img/8693d414-a4dc-4b05-b348-f0e4ab76c21e.jpg" style="width:62.75em;height:31.17em;"/></div>
<p>Let's see how to call the same in Python:</p>
<p>As a prerequisite we need to install <kbd>jsonrpclib</kbd>, which can be found at URL <a href="https://pypi.python.org/pypi/jsonrpclib" target="_blank">https://pypi.python.org/pypi/jsonrpclib. </a>This is used to parse the <strong>remote procedure call</strong> (<strong>RPC</strong>) in JSON format. Once done, the following code will result in the same set of values that we got using the browser:</p>
<pre>from jsonrpclib import Server <br/>switch = Server( "https://admin:admin@172.16.130.16/command-api" ) <br/>response = switch.runCmds( 1, [ "show hostname" ] ) <br/>print ("Hello, my name is: ", response[0][ "hostname" ] )<br/>response = switch.runCmds( 1, [ "show version" ] ) <br/>print ("My MAC address is: ", response[0][ "systemMacAddress" ] )<br/>print ("My version is: ", response[0][ "version" ])</pre>
<p>The preceding code gives the following output:</p>
<pre>Hello, my name is: Arista <br/>My MAC address is: 08:00:27:0e:bf:31 <br/>My version is: 4.14.5F</pre>
<p>In a similar way, Arista has also introduced a library for Python that can be used as an alternate to <kbd>jsonrpclib</kbd>. The library <kbd>pyeapi</kbd>, which can be found at URL <a href="https://pypi.python.org/pypi/pyeapi" target="_blank">https://pypi.python.org/pypi/pyeapi, </a>is a Python wrapper for the Arista EOS eAPI. Going by the example, here is how we can access the same set of devices using <kbd>pyeapi</kbd>.</p>
<p>From the developer page, here is an example that depicts how we can use <kbd>pyeapi</kbd> for API handling on Arista:</p>
<pre>&gt;&gt;&gt; from pprint import pprint as pp<br/>&gt;&gt;&gt; node = pyeapi.connect(transport='https', host='veos03', username='eapi', password='secret', return_node=True)<br/>&gt;&gt;&gt; pp(node.enable('show version'))<br/>[{'command': 'show version',<br/>  'encoding': 'json',<br/>  'result': {u'architecture': u'i386',<br/>             u'bootupTimestamp': 1421765066.11,<br/>             u'hardwareRevision': u'',<br/>             u'internalBuildId': u'f590eed4-1e66-43c6-8943-cee0390fbafe',<br/>             u'internalVersion': u'4.14.5F-2209869.4145F',<br/>             u'memFree': 115496,<br/>             u'memTotal': 2028008,<br/>             u'modelName': u'vEOS',<br/>             u'serialNumber': u'',<br/>             u'systemMacAddress': u'00:0c:29:f5:d2:7d',<br/>             u'version': u'4.14.5F'}}]</pre>
<p class="mce-root">Looking at both Cisco and Arista (which are two major players in the cloud and SDN marketplace), we can combine both Arista eAPI and Cisco NX-API to manage our entire data center inventory, and work on some tasks like the provisioning of new devices or upgrading of current devices with no or minimal impact, which in turn ensures scalability, reliability, and uptime in the business processes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Controller-based network fabric</h1>
                
            
            
                
<p>As we come out of the legacy hardware era in which each physical path was connected and designed to take traffic from one point to another, and where a packet had limited availability to reach from one device to another, SDN is ensuring that we have a network fabric for our data to reach between different sources and destinations.</p>
<p>A <strong>network fabric</strong> is a collection of different network devices connected to each other by a common controller ensuring that each component in the network is optimized to send traffic among each of the nodes. The underlying switch fabric, which is a physical switchboard with ports (like Ethernet, ATM, and DSL), is also controlled and programmed by a controller which can ensure (by creating a path or specific port(s)) that a particular type of data can traverse through to reach its destinations.</p>
<p>In a typical network design we have Layer 2 (or switching domains) and Layer 3 (or routing domains). If we do not have a controller-based approach, each network component can learn the behavior of traffic from its next connected component (like <strong>Spanning Tree Protocol</strong> (<strong>STP</strong>) for Layer 2) or some routing protocol (like OSPF for Layer 3). In this case, each device acts as its own controller and only has limited visibility to devices that it is directly connected to (also termed <strong>neighbor devices</strong>). There is no single view of the entire network on any device, and additionally, each component (or individual controller) acts as a single point of failure for its neighbor devices. A failure on any component would result in its neighbor devices re converging or even getting isolated owing to the failure of their connected component. </p>
<p>Comparing that to a controller-based environment, theoretically each device has as many connections as it has number of ports connected. Hence, if we think of even three devices connected in a controller-based environment, we have multiple connections between each device owing to their physical connectivity to each other. In case of the failure of a component (or device), the controller can quickly make an intelligent decision to reconfigure a new path and alter the behavior of the other two network devices to ensure minimal disruption to traffic, keeping the same throughput and distributed load on all the other available links. A controller in theory eliminates the control plane behavior of each device and ensures an optimized forwarding table (to forward data to specific destinations) is updated on each device the controller is managing. This is because the controller starts acting as the main component which has the visibility of every device, with every entry and exit point of each device and the granularity of the data type that is flowing from each managed network device.</p>
<p>Going by the vendors, major players such as Cisco (with its open network environment), Juniper (with its QFabric switch), and Avaya (with its VENA switch), have provided the ability to act as controllers or be configured to be managed by a controller. Additionally, with the introduction of controller-to-manager network components, each network device can now virtually become a dump client with the controller making all the intelligent decisions, from learning to forwarding tables.</p>
<p>A controller acts as an abstraction layer between multi-vendor network devices and network tasks. As an end user, someone can configure specific tasks to be performed by the controller, and, using the underlying API model from different vendors (using JSON or XML), the controller can convert those specific tasks into various vendor-specific API calls, and devices can be configured by sending those specific instructions using those APIs to each of the vendor devices. The <strong>Application Policy Infrastructure Controller</strong> (<strong>APIC</strong>) component is responsible for controlling and programming the fabric on each network device component.</p>
<p>Let's see an example of Cisco APIC and some basics on how we can use it. Cisco APIC is used to manage, automate, monitor, and program <strong>Application Centric Infrastructure</strong> (<strong>ACI</strong>). ACI is a collection of objects with each object representing a tenant. A tenant can be called a group of specific customers, groups, or business units based upon the business classifications. As an example, a single organization may covert its entire infrastructure into a single tenant, whereas an organization can separate out its tenants based upon its functions like HR and Finance. Tenants can further be divided into contexts, with each context as a separate forwarding plane, hence the same set of IP addresses can be used in each context as each set of IP addresses will be treated differently in each context.</p>
<p>Contexts contain <strong>Endpoints</strong> (<strong>EPs</strong>) and <strong>Endpoint Groups</strong> (<strong>EPGs</strong>). These EPs are physical components like hardware NICs, and EPGs are collections of items like DNSs, IP addresses, and so on, that dictate a similar functionality for a specific application (like a web application). </p>
<p>For programming with APIC, the major components required are as follows:</p>
<ul>
<li class="mce-root"><strong>APIC Rest Python Adaptor</strong> (<strong>ARYA</strong>)</li>
</ul>
<p style="padding-left: 90px">This is a tool created by Cisco to convert the APIC object returned in XML or JSON to direct Python code. Underlying, this leverages the COBRA SDK to perform this task. This can be installed in Python using <kbd>pip install arya</kbd>.</p>
<ul>
<li class="mce-root"><strong>ACI SDK</strong></li>
</ul>
<p style="padding-left: 90px">This is the SDK that contains the API to directly call the APIs of the controller. We need to install <kbd>acicobra</kbd>, which can be found at <a href="https://www.cisco.com/c/en/us/td/docs/switches/datacenter/aci/apic/sw/1-x/api/python/install/b_Install_Cisco_APIC_Python_SDK_Standalone.html" target="_blank">https://www.cisco.com/c/en/us/td/docs/switches/datacenter/aci/apic/sw/1-x/api/python/install/b_Install_Cisco_APIC_Python_SDK_Standalone.html, </a>from Cisco to be able to call it into Python.</p>
<p>Once we have this installed, here are some examples from Cisco which can be found at the URL <a href="https://github.com/CiscoDevNet/python_code_samples_network/blob/master/acitoolkit_show_tenants/aci-show-tenants.py" target="_blank">https://github.com/CiscoDevNet/python_code_samples_network/blob/master/acitoolkit_show_tenants/aci-show-tenants.py.</a> This can help us understand creating an object:</p>
<pre>#!/usr/bin/env python<br/>"""<br/>Simple application that logs on to the APIC and displays all<br/>of the Tenants. <br/>Leverages the DevNet Sandbox - APIC Simulator Always On <br/>    Information at https://developer.cisco.com/site/devnet/sandbox/available-labs/data-center/index.gsp <br/>    <br/>Code sample based off the ACI-Toolkit Code sample<br/>https://github.com/datacenter/acitoolkit/blob/master/samples/aci-show-tenants.py <br/>"""<br/><br/>import sys<br/>import acitoolkit.acitoolkit as ACI<br/><br/># Credentials and information for the DevNet ACI Simulator Always-On Sandbox<br/>APIC_URL = "https://sandboxapicdc.cisco.com/"<br/>APIC_USER = "admin"<br/>APIC_PASSWORD = "C1sco12345"<br/><br/>def main():<br/>    """<br/>    Main execution routine<br/>    :return: None<br/>    """<br/><br/>    # Login to APIC<br/>    session = ACI.Session(APIC_URL, APIC_USER, APIC_PASSWORD)<br/>    resp = session.login()<br/>    if not resp.ok:<br/>        print('%% Could not login to APIC')<br/>        sys.exit(0)<br/><br/>    # Download all of the tenants<br/>    print("TENANT")<br/>    print("------")<br/>    tenants = ACI.Tenant.get(session)<br/>    for tenant in tenants:<br/>        print(tenant.name)<br/><br/>if __name__ == '__main__':<br/>    main()</pre>
<p>Looking at the preceding concepts, we can enhance and ensure that our managed nodes in the controller can be controlled based on the application requirements rather than hardware limitations. This also ensures that the infrastructure is now tweaked as per application, and not vice versa, with the application performance restricted by hardware.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Network automation tools</h1>
                
            
            
                
<p>As we have seen throughout the previous chapters, we have multiple choices regarding automating a network. From a basic configuration for any device using Netmiko to deploying and creating configurations across various devices in a network using Ansible,<strong> </strong>there are many options for engineers to automate networks based upon various needs.</p>
<p>Python is extensively used in creating automation scenarios, owing to its open community support for various vendors and protocols. Nearly every major player in the industry has support for Python programming, tweaking their own tools or any supporting technology that they have. Another major aspect of network automation are the custom-based solutions that could be made for organization requirements. The self-service API model is a good start to ensuring that some of the tasks that are done manually can be converted to APIs, which can then be leveraged into any language based upon the automation needs.</p>
<p>Let's see an example that can be used as a basic guide to understand the advantage of self or custom-created automation tools. The output of <kbd>show ip bgp summary</kbd><strong> </strong> in Cisco is the same as <kbd>show bgp summary</kbd> in Juniper. Now, as an engineer who needs to validate the BGP on both the vendors, I need to understand both the commands and interpret the output.</p>
<p>Think of this situation by adding more vendors which have their own unique way of fetching BGP output. This becomes complex and a network engineer needs to be trained on a multi-vendor environment to be able to fetch the same type of output from each vendor.</p>
<p>Now, let's say we create an API (for example, <kbd>getbgpstatus</kbd><strong> </strong>), which takes the input as some hostname. The API at the backend is intelligent enough to fetch the vendor model using SNMP, and based upon the vendor sends a specific command (like <kbd>show ip bgp summary</kbd> for Cisco or <kbd>show ip summary</kbd> for Juniper), and parses that output to a human-readable format, like only the IP address and status of that BGP neighbor.</p>
<p>For example, instead of printing the raw output of <kbd>show ip bgp summary</kbd> or <kbd>show bgp summary</kbd>, it parses the output like this:</p>
<pre>IPaddress1 : Status is UP<br/>IPaddress2 : Status is Down (Active)</pre>
<p>This output can be returned as a JSON value back to the call of the API.</p>
<p>Hence, let's say we can call the API as <kbd>http://localhost/networkdevices/getbgpstatus?device=devicex</kbd> and the API from the backend will identify if <kbd>devicex</kbd> is Juniper or Cisco or any other vendor, and based upon this the vendor will fetch and parse the output relevant to that vendor. A return of that API call will be JSON text as we saw in the preceding example, that we can parse in our automation language. </p>
<p>Let us see a basic example of another popular tool, SolarWinds. There are many aspects of SolarWinds; it can auto-discover a device (based upon MIBs and SNMP), identify the vendor, and fetch relevant information from the device. </p>
<p>Let's see some of the following screenshots for basic SolarWinds device management. SolarWinds is freely available as a trial download.</p>
<p>The prerequisite for SolarWinds device management is as follows:</p>
<ol>
<li>We need to add a device in SolarWinds, shown as below:</li>
</ol>
<div><img src="img/d9163428-3e8e-45d1-aad5-c056a4ba0d2e.jpg" style="width:76.25em;height:34.58em;"/></div>
<p style="padding-left: 60px">As we can see, SolarWinds has the ability to discover devices (using network discovery), or we can add a specific IP address/hostname with the correct SNMP string for SolarWinds to detect the device.</p>
<ol start="2">
<li>Once the device is detected it will show as the monitored node, as in the below screenshot:</li>
</ol>
<div><img src="img/8bc6e99c-2d59-43d2-baee-ddd63462bdf9.jpg" style="width:65.08em;height:16.67em;"/></div>
<p style="padding-left: 60px">Notice the green dot next to the IP address (or hostname). This signifies that the node is alive (reachable) and SolarWinds can interact with the node correctly.</p>
<p><strong>Additional task(s) that can be performed post device discovery is as follows:</strong></p>
<p>Once we have the node available or detected in SolarWinds, here are some of the additional tasks that can be performed in SolarWinds (as shown in screenshot below):</p>
<div><img src="img/2be18c1d-a31d-4045-8593-d0a06638e4e8.jpg" style="width:36.67em;height:18.42em;"/></div>
<p>We have selected the CONFIGS menu, under which we can perform config management for the devices. Additionally, as we can see in the following screenshot, we have the ability to create small scripts, (like we did here to <kbd>show running config</kbd>), which we can use to execute against a certain set of devices from SolarWinds itself (as in screenshot below):</p>
<div><img src="img/e4aaef49-e77f-4c58-957e-8899d6f19977.jpg" style="width:74.92em;height:14.33em;"/></div>
<p>The result is retrieved and can be stored as a text file, or can even be sent as a report back to any email client if configured. Similarly, there are certain tasks (called <strong>jobs</strong> in SolarWinds), that can be done on a scheduled basis, as we can see in the following screenshot:</p>
<div><img src="img/2935a92f-e6ad-4ea6-9ec5-7aa7ea9da9e1.jpg" style="width:54.58em;height:36.42em;"/></div>
<p>As we can see in the preceding screenshot, we can Download Configs from Devices, and then select all or certain devices in the next step and schedule the job. This is very useful in terms of fetching a config from a previous date or in case a rollback is needed to a last known good config scenario. Also, there are times when auditing needs to be performed regarding who changed what and what was changed in configurations, and SolarWinds can extend this ability by sending reports and alerts. Programmatically, we have the additional ability to call the SolarWinds API to fetch the results from Python.</p>
<p>It is assumed that OrionSDK is already installed in Python. If not, we can install it using <kbd>pip install orionsdk</kbd>.</p>
<p>Consider the following example:</p>
<pre>from orionsdk import SwisClient<br/>import requests<br/><br/>npm_server = 'myserver'<br/>username = "username"<br/>password = "password"<br/><br/>verify = False<br/>if not verify:<br/>    from requests.packages.urllib3.exceptions import InsecureRequestWarning<br/>    requests.packages.urllib3.disable_warnings(InsecureRequestWarning)<br/><br/>swis = SwisClient(npm_server, username, password)<br/><br/>results = swis.query("SELECT NodeID, DisplayName FROM Orion.Nodes Where Vendor= 'Cisco'")<br/><br/>for row in results['results']:<br/>    print("{NodeID:&lt;5}: {DisplayName}".format(**row))<br/><br/></pre>
<p>Since SolarWinds supports a direct SQL query, we use the query:</p>
<pre>SELECT NodeID, DisplayName FROM Orion.Nodes Where Vendor= 'Cisco'</pre>
<p>We are trying to fetch the <kbd>NodeID</kbd> and <kbd>DisplayName</kbd> (or the device name) for all the devices which have the vendor Cisco. Once we have the result, we print the result in a formatted way. In our case, the output will be (let's assume our Cisco devices in SolarWinds are added as <kbd>mytestrouter1</kbd> and <kbd>mytestrouter2</kbd>):</p>
<pre>&gt;&gt;&gt; <br/>===================== RESTART: C:\a1\checksolarwinds.py =====================<br/>101 : mytestrouter1<br/>102 : mytestrouter2<br/>&gt;&gt;&gt;</pre>
<p>Using some of these automation tools and APIs, we can ensure that our tasks are focused on actual work with some of the basic or core tasks (like fetching values from devices and so on) being offloaded to the tools or APIs to take care of.</p>
<p>Let's now create a basic automation tool from scratch that monitors the reachability of any node that is part of that monitoring tool, using a ping test. We can call it PingMesh or PingMatrix, as the tool will generate a web-based matrix to show the reachability of the routers.</p>
<p>The topology that we would be using is as follows:</p>
<div><img src="img/730b75ac-2225-4408-b7e7-0b043391c012.jpg" style="width:32.92em;height:25.58em;"/></div>
<p>Here, we would be using four routers (<kbd>R1</kbd> to <kbd>R4</kbd>), and the <kbd>Cloud1</kbd> as our monitoring source. Each of the routers will try to reach each other through ping, and will report back to the script running on <kbd>Cloud1</kbd> which will interpret the results and display the web-based matrix through a web-based URL.</p>
<p>The explanation of the preceding topology is as follows:</p>
<ol>
<li>What we are trying to do is log in to each router (preferably in parallel), ping each destination from each source, and report back the reachability status of each destination.</li>
<li>As an example, if we want to do the task manually, we would log in to <kbd>R1</kbd> and try to ping <kbd>R2</kbd>, <kbd>R3</kbd>, and <kbd>R4</kbd> from the source to check the reachability of each router from <kbd>R1</kbd>. The main script on <kbd>Cloud1</kbd> (acting as the controller) will interpret the result and update the web matrix accordingly.</li>
<li>In our case all the routers (and the controller) are residing in <kbd>192.168.255.x</kbd> subnet, hence they are reachable to each other using a simple ping.</li>
</ol>
<p>We are going to create two separate Python programs (one to be called as the library for invoking the commands on various nodes, fetching the results from the nodes, interpreting the results, and sending the parsed data to the main program). The main program will be responsible for calling the library, and will use the results we get back to create the HTML web matrix.</p>
<p>Let's create the library or the program to be called in the main program first (we called it <kbd>getmeshvalues.py</kbd>):</p>
<pre>#!/usr/bin/env python<br/>import re<br/>import sys<br/>import os<br/>import time<br/>from netmiko import ConnectHandler<br/>from threading import Thread<br/>from random import randrange<br/>username="cisco"<br/>password="cisco"<br/><br/>splitlist = lambda lst, sz: [lst[i:i+sz] for i in range(0, len(lst), sz)]<br/><br/>returns = {}<br/>resultoutput={}<br/>devlist=[]<br/>cmdlist=""<br/>       <br/>def fetchallvalues(sourceip,sourcelist,delay,cmddelay):<br/>    print ("checking for....."+sourceip)<br/>    cmdend=" repeat 10" # this is to ensure that we ping for 10 packets<br/>    splitsublist=splitlist(sourcelist,6) # this is to ensure we open not more than 6 sessions on router at a time<br/>    threads_imagex= []<br/>    for item in splitsublist:<br/>        t = Thread(target=fetchpingvalues, args=(sourceip,item,cmdend,delay,cmddelay,))<br/>        t.start()<br/>        time.sleep(randrange(1,2,1)/20)<br/>        threads_imagex.append(t)<br/><br/>    for t in threads_imagex:<br/>        t.join() <br/>  <br/>def fetchpingvalues(devip,destips,cmdend,delay,cmddelay):<br/>    global resultoutput<br/>    ttl="0"<br/>    destip="none"<br/>    command=""<br/>    try:<br/>        output=""<br/>        device = ConnectHandler(device_type='cisco_ios', ip=devip, username=username, password=password, global_delay_factor=cmddelay)<br/>        time.sleep(delay)<br/>        device.clear_buffer()<br/>        for destip in destips:<br/>            command="ping "+destip+" source "+devip+cmdend<br/>            output = device.send_command_timing(command,delay_factor=cmddelay)<br/>            if ("round-trip" in output):<br/>                resultoutput[devip+":"+destip]="True"<br/>            elif ("Success rate is 0 percent" in output):<br/>                resultoutput[devip+":"+destip]="False"<br/>        device.disconnect()<br/>    except:<br/>        print ("Error connecting to ..."+devip)<br/>        for destip in destips:<br/>            resultoutput[devip+":"+destip]="False"<br/><br/>def getallvalues(allips):<br/>    global resultoutput<br/>    threads_imagex= []<br/>    for item in allips:<br/>        #print ("calling "+item)<br/>        t = Thread(target=fetchallvalues, args=(item,allips,2,1,))<br/>        t.start()<br/>        time.sleep(randrange(1,2,1)/30)<br/>        threads_imagex.append(t)<br/>    for t in threads_imagex:<br/>        t.join()<br/>    dnew=sorted(resultoutput.items()) <br/>    return dnew<br/><br/>#print (getallvalues(["192.168.255.240","192.168.255.245","192.168.255.248","192.168.255.249","4.2.2.2"]))</pre>
<p>In the preceding code, we have created three main functions that we call in a thread (for parallel execution). The <kbd>getallvalues()</kbd> contains the list of IP addresses that we want to get the data from.  It then passes this information to <kbd>fetchallvalues()</kbd> with specific device information to fetch the ping values again in parallel execution. For executing the command on the router and fetching the results, we call the <kbd>fetchpingvalues()</kbd> function.</p>
<p>Let's see the result of this code (by removing the remark on the code that calls the function). We need to pass the device IPs that we want to validate as a list. In our case, we have all the valid routers in the <kbd>192.168.255.x</kbd> range, and <kbd>4.2.2.2</kbd> is taken as an example of a non-reachable router:</p>
<pre>print(getallvalues(["192.168.255.240","192.168.255.245","192.168.255.248","192.168.255.249","4.2.2.2"]))</pre>
<p>The preceding code gives the following output:</p>
<div><img src="img/27db4bff-4119-4e85-9d9f-015ca58654d2.jpg" style="width:33.08em;height:23.83em;"/></div>
<p>As we can see in the result, we get the reachability in terms of <kbd>True</kbd> or <kbd>False</kbd> from each node to the other node.</p>
<p>For example, the first item in the list (<kbd>'192.168.255.240:192.168.255.240','True'</kbd>)<strong> </strong>interprets that from the source <kbd>192.168.255.240</kbd> to destination <kbd>192.168.255.240</kbd> (which is the same self IP) is reachable.  Similarly, the next item in the same list (<kbd>'192.168.255.240:192.168.255.245','True'</kbd>)<strong> </strong> confirms that from source IP <kbd>192.168.255.240</kbd> the destination <kbd>192.168.255.245</kbd> we have reachability from ping. This information is required to create a matrix based upon the results. Next we see the main code where we fetch these results and create a web-based matrix page.</p>
<p>Next, we need to create the main file (we're calling it <kbd>pingmesh.py</kbd>):</p>
<pre>import getmeshvalue<br/>from getmeshvalue import getallvalues<br/><br/>getdevinformation={}<br/>devicenamemapping={}<br/>arraydeviceglobal=[]<br/>pingmeshvalues={}<br/><br/>arraydeviceglobal=["192.168.255.240","192.168.255.245","192.168.255.248","192.168.255.249","4.2.2.2"]<br/><br/>devicenamemapping['192.168.255.240']="R1"<br/>devicenamemapping['192.168.255.245']="R2"<br/>devicenamemapping['192.168.255.248']="R3"<br/>devicenamemapping['192.168.255.249']="R4"<br/>devicenamemapping['4.2.2.2']="Random"<br/><br/>def getmeshvalues():<br/>        global arraydeviceglobal<br/>        global pingmeshvalues<br/>        arraydeviceglobal=sorted(set(arraydeviceglobal))<br/>        tval=getallvalues(arraydeviceglobal)<br/>        pingmeshvalues = dict(tval)<br/><br/>getmeshvalues()<br/><br/>def createhtml():<br/>    global arraydeviceglobal<br/>    fopen=open("C:\pingmesh\pingmesh.html","w") ### this needs to be changed as web path of the html location<br/><br/>    head="""&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="refresh" content="60" &gt;&lt;/head&gt;"""<br/>    head=head+"""&lt;script type="text/javascript"&gt;<br/>function updatetime() {<br/>    var x = new Date(document.lastModified);<br/>    document.getElementById("modified").innerHTML = "Last Modified: "+x+" ";<br/>}<br/>&lt;/script&gt;"""+"&lt;body onLoad='updatetime();'&gt;"<br/>    head=head+"&lt;div style='display: inline-block;float: right;font-size: 80%'&gt;&lt;h4&gt;&lt;h4&gt;&lt;p id='modified'&gt;&lt;/p&gt;&lt;/div&gt;"<br/>    head=head+"&lt;div style='display: inline-block;float: left;font-size: 90%'&gt;&lt;/h4&gt;&lt;center&gt;&lt;h2&gt;Network Health Dashboard&lt;h2&gt;&lt;/div&gt;"<br/>    head=head+"&lt;br&gt;&lt;div&gt;&lt;table border='1' align='center'&gt;&lt;caption&gt;&lt;b&gt;Ping Matrix&lt;/b&gt;&lt;/caption&gt;"<br/>    head=head+"&lt;center&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;"<br/>    fopen.write(head)<br/>    dval=""<br/>    fopen.write("&lt;tr&gt;&lt;td&gt;Devices&lt;/td&gt;")<br/>    for fromdevice in arraydeviceglobal:<br/>        fopen.write("&lt;td&gt;&lt;b&gt;"+devicenamemapping[fromdevice]+"&lt;/b&gt;&lt;/td&gt;")<br/>    fopen.write("&lt;/tr&gt;")<br/>    for fromdevice in arraydeviceglobal:<br/>        fopen.write("&lt;tr&gt;")<br/>        fopen.write("&lt;td&gt;&lt;b&gt;"+devicenamemapping[fromdevice]+"&lt;/b&gt;&lt;/td&gt;")<br/>        for todevice in arraydeviceglobal:<br/>            askvalue=fromdevice+":"+todevice<br/>            if (askvalue in pingmeshvalues):<br/>                getallvalues=pingmeshvalues.get(askvalue)<br/>                bgcolor='lime'<br/>                if (getallvalues == "False"):<br/>                    bgcolor='salmon'<br/>            fopen.write("&lt;td align='center' font size='2' height='2' width='2' bgcolor='"+bgcolor+"'title='"+askvalue+"'&gt;"+"&lt;font color='white'&gt;&lt;b&gt;"+getallvalues+"&lt;/b&gt;&lt;/font&gt;&lt;/td&gt;")<br/>        fopen.write("&lt;/tr&gt;\n")<br/>    fopen.write("&lt;/table&gt;&lt;/div&gt;")<br/>    fopen.close()<br/>    <br/>createhtml()<br/><br/><br/>print("All done!!!!")</pre>
<p>In this case, we have the following mappings in place:</p>
<pre>devicenamemapping['192.168.255.240']="R1"<br/>devicenamemapping['192.168.255.245']="R2"<br/>devicenamemapping['192.168.255.248']="R3"<br/>devicenamemapping['192.168.255.249']="R4"<br/>devicenamemapping['4.2.2.2']="Random"</pre>
<p>The last device named <kbd>Random</kbd>,<strong> </strong>is a test device which is not in our network and is non-reachable for test purposes. Once executed, it creates a file named <kbd>pingmesh.html</kbd> with standard HTML formats and a last-refreshed clock (from JavaScript) to confirm when the last refresh occurred. This is required if we want the script to be executed from the task scheduler (Let's say every five minutes), and anybody opening the HTML page will know when the probe occurred. The HTML file needs to be placed or saved in a folder which is mapped to a web folder so that it can be accessed using the URL <kbd>http://&lt;server&gt;/pingmesh.html</kbd>.</p>
<p>When executed, here is the output from the Python script:</p>
<div><img src="img/9f1a81d1-b0b1-4f46-94d4-7ab8c48f8af6.jpg" style="width:47.50em;height:18.00em;"/></div>
<p>The HTML file, when placed in the web-mapped URL and called, looks like this:</p>
<div><img src="img/73a2b511-4c71-4ff9-bf5b-bc6376482369.jpg" style="width:73.50em;height:24.58em;"/></div>
<p>As we can see, in the PingMatrix there is an entire red row and column, which means that any connectivity between any router to the random router and from the random router to any router is not there. Green means that all the connectivity between all other routers is fine.</p>
<p>Additionally, we have also configured a tooltip on each cell, and hovering the mouse over that specific cell would also show the source and destination IP address mapping for that particular cell, as shown in the following screenshot:</p>
<div><img src="img/d5dd0c8b-dd5d-422c-9916-151750f43c15.jpg" style="width:25.17em;height:15.67em;"/></div>
<p class="mce-root">Let's see another screenshot, in which we shut down R2 to make it unreachable:</p>
<div><img src="img/b5b0edb8-bf44-4e23-8c27-f06c5f150f82.jpg" style="width:26.58em;height:15.83em;"/></div>
<p>Now, as we can see, the entire row and column of <kbd>R2</kbd> is red, and hence the PingMatrix shows that <kbd>R2</kbd> is now unreachable from everywhere else, and <kbd>R2</kbd> also cannot reach anyone else in the network.</p>
<p>Let's see a final example, in which for test purposes we intentionally block the ping traffic from <kbd>R2</kbd> to <kbd>R4</kbd> (and vice versa) using an extended Cisco ACL, which in turn reports that <kbd>R4</kbd> and <kbd>R2</kbd> have reachability issues in the PingMatrix:</p>
<div><img src="img/2ee3fc82-d864-4bbe-89ff-b2de50f9edb5.jpg" style="width:24.50em;height:16.08em;"/></div>
<p>As we see can in the preceding screenshot, the Random router is still a red or false, since it is not in our network, but now it is showing red/false between <kbd>R2</kbd> and <kbd>R4</kbd> and also between <kbd>R4</kbd> and <kbd>R2</kbd>. This gives us a quick view that even with multiple paths to reach each node with another node, we have a connectivity issue between the two nodes.</p>
<p>Going by the preceding examples, we can enhance the tool to easily monitor and understand any routing/reachability issues, or even link down connectivity problems using a holistic view of all of the connections in our network. PingMesh/Matrix can be extended to check latency, and even packet drops in each connection between various nodes. Additionally, using syslog or email functionality (specific Python libraries are available for sending syslog messages from Python or even emails from Python code), alerts or tickets can also be generated in case of failures detected or high latency observed from the Python script itself. </p>
<p>This tool can easily become a central monitoring tool in any organization, and based upon patterns (such as green or red, and other color codes if needed), engineers can make decisions on the actual issues and take proactive actions instead of reactive actions to ensure the high reliability and uptime of the network.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we learned about the basic functionality of SDN controllers, programmable fabric, and some network automation tools. We have also seen how to work with cloud platforms and, with reference to a live example of managing AWS Cloud from Python, understood how we can control cloud operations using automation.</p>
<p>We gained a deep understanding about the role of controllers, and with some examples of Cisco controllers, went into details on how a controller can be programmed or called in programs/scripts to perform certain tasks. We also saw the basics of some popular network automation tools, such as SolarWinds, and created an in-house web-based automation tool for monitoring our network, called PingMatrix or PingMesh.</p>
<p class="mce-root"/>


            

            
        
    </body></html>