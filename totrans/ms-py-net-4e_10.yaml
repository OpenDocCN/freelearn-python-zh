- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Introduction to Async IO
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步IO简介
- en: In the previous chapters, we have been interacting with the network devices
    directly via API or other Python libraries that abstracted us from low-level interactions
    with a remote device. When we need to interact with multiple devices, we use loops
    to allow us to pragmatically execute commands. One issue that we might start to
    see is that the end-to-end process begins to slow down when we need to interact
    with many devices. The bottleneck is usually the time spent waiting between the
    time we send the command until we receive the proper response from the remote
    device. If we need to spend 5 seconds of wait time per operation, we could wait
    for a few minutes when we need to operate on 30 devices.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们通过API或其他Python库直接与网络设备交互，这些库抽象了我们对远程设备的低级交互。当我们需要与多个设备交互时，我们使用循环来允许我们实用地执行命令。我们可能会开始看到的一个问题是，当我们需要与许多设备交互时，端到端过程开始变慢。瓶颈通常是我们在发送命令直到从远程设备收到适当响应之间等待的时间。如果我们每个操作需要5秒钟的等待时间，当我们需要操作30个设备时，我们可能需要等待几分钟。
- en: This is partially true because our operations are sequential. We are only operating
    on one device at a time, in sequence. What if we can process multiple devices
    at the same time? That would speed things up, right? Yes, you are correct. But
    it is not as simple as “telling” our Python script to “go for” many devices simultaneously.
    We must consider the way computers schedule tasks, the language limitation, and
    the available tools at hand.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分是正确的，因为我们的操作是顺序的。我们一次只操作一个设备，按顺序进行。如果我们能够同时处理多个设备呢？这样会加快速度，对吧？是的，你是对的。但是，告诉我们的Python脚本“同时”去处理多个设备并不像听起来那么简单。我们必须考虑计算机调度任务的方式、语言限制以及手头的可用工具。
- en: In this chapter, we will discuss Async IO, the Python package that allows us
    to perform multiple tasks at the same time. We will also discuss related topics
    such as multiprocessing, parallelism, threading, and others. Asynchronous operations
    in Python is a topic that I would consider medium to advanced level. The async
    IO module itself was only introduced in Python 3.4\. It also went through rapid
    changes between Python 3.4 to Python 3.7\. Regardless, it is a very relatable
    topic for network automation. I believe it is worth a study for any network engineer
    looking to be familiar with network automation.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论Async IO，这是一个Python包，允许我们同时执行多个任务。我们还将讨论相关主题，如多进程、并行性、线程等。Python中的异步操作是一个我认为中等到高级水平的话题。async
    IO模块本身是在Python 3.4中引入的。它也在Python 3.4到Python 3.7之间经历了快速的变化。不管怎样，它对于网络自动化来说是一个非常相关的主题。我相信，对于任何希望熟悉网络自动化的网络工程师来说，这都是一个值得研究的话题。
- en: 'In this chapter, we will discuss the following topics related to Async IO:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下与Async IO相关的话题：
- en: Asynchronous operations overview
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步操作概述
- en: Multiprocessing and threading
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多进程和线程
- en: Python asyncio module
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python asyncio模块
- en: The `Scrapli` project
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Scrapli`项目'
- en: For more information on Python-related asynchronous operations, Real Python
    ([https://realpython.com/search?q=asyncio](https://realpython.com/search?q=asyncio))
    and Python documentation ([https://docs.python.org/3/library/asyncio.html](https://docs.python.org/3/library/asyncio.html))
    both offer good resources for learning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Python相关异步操作的信息，Real Python（[https://realpython.com/search?q=asyncio](https://realpython.com/search?q=asyncio)）和Python文档（[https://docs.python.org/3/library/asyncio.html](https://docs.python.org/3/library/asyncio.html)）都提供了良好的学习资源。
- en: Let’s start by looking at an overview of asynchronous operations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从异步操作概述开始看起。
- en: Asynchronous operations overview
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步操作概述
- en: In the *Zen of Python;* we know one of the guiding principles in Python is to
    preferably have “one best way to do something.” When it comes to asynchronous
    operations, it is a bit complicated. We know it would help if we could do multiple
    tasks simultaneously but determining the correct solution might not be straightforward.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在《Python之禅》中；我们知道Python的一个指导原则是最好有“做某事的一种最佳方式。”当涉及到异步操作时，这有点复杂。我们知道如果我们能够同时执行多个任务会很有帮助，但确定正确的解决方案可能并不直接。
- en: First, we will need to determine what is slowing down our program. Typically,
    the bottleneck can be either CPU-bound or I/O-bound. In a CPU-bound situation,
    the program pushes the CPU to its limit. Operations such as solving mathematical
    questions or image processing are examples of CPU-bound programs. For example,
    when we pick an encryption algorithm for VPN, we know the more complex the algorithm,
    the more CPU it will consume. For CPU-bound tasks, the way to mitigate the bottleneck
    is to increase the CPU power or allow the task to use multiple CPUs simultaneously.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要确定是什么减慢了我们的程序。通常，瓶颈可以是CPU密集型或I/O密集型。在CPU密集型情况下，程序将CPU推到极限。例如，解决数学问题或图像处理等操作是CPU密集型程序的例子。例如，当我们为VPN选择加密算法时，我们知道算法越复杂，CPU消耗就越多。对于CPU密集型任务，减轻瓶颈的方法是增加CPU功率或允许任务同时使用多个CPU。
- en: In an IO-bound operation, the program spends most of its time waiting for some
    output from an input it has completed. When we make an API call to a device, we
    cannot move on to the next step until we receive what we need as the answer. If
    time is significant, this is time that otherwise could have been useful in doing
    something else. The way to mitigate IO-bound tasks is to work on multiple tasks
    simultaneously.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在I/O密集型操作中，程序的大部分时间都花在等待从已完成的输入中获取一些输出上。当我们向设备发起API调用时，我们必须等到收到所需的答案才能进行下一步。如果时间很重要，那么这将是本可以用于做其他事情的时间。减轻I/O密集型任务的方法是同时处理多个任务。
- en: 'If the work at hand is limited by CPU power or Input-Output latency, we can
    try to run multiple operations at once. This is called parallelism. Of course,
    not all tasks can be parallelized. As the great Warren Buffet saying goes, “You
    can’t produce a baby in one month by getting nine women pregnant.” However, if
    your task can be parallelized, we have a few parallel processing options: multiprocessing,
    threading, or the new asyncio module.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果当前的工作受CPU功率或输入输出延迟的限制，我们可以尝试同时运行多个操作。这被称为并行化。当然，并不是所有任务都可以并行化。正如伟大的沃伦·巴菲特所说：“你不能通过让九个女人怀孕一个月来生一个孩子。”然而，如果你的任务可以并行化，我们有一些并行处理选项：multiprocessing、threading或新的asyncio模块。
- en: Python multiprocessing
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python multiprocessing
- en: Python’s multiprocessing allows CPU-bound tasks to be broken up into sub-tasks
    and spawning subprocesses to handle them. This is well-suited for CPU-bound tasks
    because it allows multiple CPUs to work simultaneously. If we look back at the
    history of computing, we notice that around 2005, a single CPU can no longer get
    any faster. We simply cannot fit more transistors onto a single CPU due to interference
    and heat issues. The way we have gotten more computing power is by having multi-core
    CPUs. This is beneficial in allowing us to spread our tasks among the multi-core
    CPUs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Python的multiprocessing允许将CPU密集型任务分解成子任务，并创建子进程来处理它们。这对于CPU密集型任务非常合适，因为它允许多个CPU同时工作。如果我们回顾一下计算历史，我们会注意到大约在2005年，单个CPU的运行速度就不再提高了。由于干扰和散热问题，我们无法在单个CPU上放置更多的晶体管。我们获得更多计算能力的方法是使用多核CPU。这使我们能够将任务分散到多核CPU上。
- en: 'In Python’s multiprocessing module, processes are spawned by creating a `Process`
    object and then calling its `start()` method. Let’s see a simple example, `multiprocess_1.py`:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python的multiprocessing模块中，通过创建一个`Process`对象并调用其`start()`方法来创建进程。让我们看一个简单的例子，`multiprocess_1.py`：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the example, we have a worker function that calls another `process_info()`
    function to get the process ID. Then we start the Process object five times, each
    one targeting the worker function. The output for the execution is below:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们有一个工作函数，它调用另一个`process_info()`函数来获取进程ID。然后我们启动Process对象五次，每次都针对工作函数。执行输出如下：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As we can see, each process has its process and process ID. Multiprocessing
    is great for CPU-bound tasks. If the work is IO-bound, before the asyncio module,
    our best bet is to use the threading module.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，每个进程都有自己的进程和进程ID。Multiprocessing非常适合CPU密集型任务。如果工作是I/O密集型，在asyncio模块出现之前，我们最好的选择是使用threading模块。
- en: Python multithreading
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python multithreading
- en: As many of us know, Python has a **Global Interpreter Lock**, or **GIL**. It
    is used by the Python interpreter (CPython, to be exact) to assure that only one
    thread executes Python byte code at a time. This is mainly a safety measure to
    protect against race conditions in memory leaks. But it can become a performance
    bottleneck for IO-bound tasks.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，Python有一个**全局解释器锁**，或称为**GIL**。Python解释器（确切地说是CPython）使用它来确保一次只有一个线程执行Python字节码。这主要是为了防止内存泄漏中的竞态条件而采取的安全措施。但它可能会成为IO密集型任务的性能瓶颈。
- en: For more information, check out the article at [https://realpython.com/python-gil/](https://realpython.com/python-gil/).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解更多信息，请查看[https://realpython.com/python-gil/](https://realpython.com/python-gil/)上的文章。
- en: 'One way to allow multiple threads to run is by using the `threading` module.
    It allows a program to run multiple operations concurrently. We can see a simple
    example in `threading_1.py`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 允许多个线程运行的一种方法是通过使用`threading`模块。它允许程序并发运行多个操作。我们可以在`threading_1.py`中看到一个简单的例子：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The script is similar to our multiprocess example, with the exception of displaying
    the thread ID instead of the process ID. The output for the script execution is
    below:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本与我们的多进程示例类似，只是显示的是线程ID而不是进程ID。脚本执行的输出如下：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The threading module is a good option to mitigate the Python GIL with multiple
    threads. However, when Python passes the task to a thread, the main process has
    limited visibility in the threading process. The threads are harder to deal with,
    especially when coordinating between different threads and handling errors if
    they arise. For IO-bound tasks, instead of threads, asyncio in Python 3 is another
    great option.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 线程模块是缓解Python GIL的多个线程的好选择。然而，当Python将任务传递给线程时，主进程在线程过程中可见性有限。线程处理起来更困难，尤其是在协调不同线程和处理可能出现的错误时。对于IO密集型任务，Python
    3中的asyncio是另一个不错的选择。
- en: '![Graphical user interface, diagram, application  Description automatically
    generated](img/B18403_10_01.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，图表，应用程序描述自动生成](img/B18403_10_01.png)'
- en: 'Figure 10.1: CPU-bound vs. IO-bound Python modules'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：CPU密集型与IO密集型Python模块
- en: Let’s dig deeper into the asyncio module.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地了解asyncio模块。
- en: Python asyncio module
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python asyncio模块
- en: We can think of the asyncio module as Python’s way of allowing us to write code
    to run tasks concurrently. It uses the newly introduced `async` and `await` keywords.
    It can help us improve performance for many operations that might be IO-bound,
    such as web servers, databases, and, of course, communication toward devices over
    a network. The asyncio module is the foundation of popular new frameworks, such
    as FastAPI ([https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将asyncio模块视为Python允许我们编写并发运行任务的代码的方式。它使用了新引入的`async`和`await`关键字。它可以帮助我们提高许多可能受IO限制的操作的性能，例如Web服务器、数据库，当然还有通过网络与设备通信。asyncio模块是FastAPI等流行新框架的基础([https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/))。
- en: However, it is important to point out that asyncio is neither multiprocessing
    nor multithreaded. It is designed to be single-threaded with a single process.
    Python asyncio uses *cooperative multiprocessing* to give the feeling of concurrency.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，重要的是要指出，asyncio既不是多进程也不是多线程。它被设计为单线程单进程。Python asyncio使用**协作多进程**来提供并发的感觉。
- en: Unlike threading, Python controls the process from end to end instead of passing
    the threading process to the operating system. This lets Python know when the
    task is started and completed, thus coordinating between the processes. When we
    “pause” part of the code while waiting for results, Python will move on to other
    parts of the code before coming back to the “paused” code.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与线程不同，Python从始至终控制着整个过程，而不是将线程过程传递给操作系统。这使得Python知道任务何时开始和完成，从而在进程之间进行协调。当我们“暂停”部分代码等待结果时，Python会在返回“暂停”代码之前先继续执行其他代码部分。
- en: This is an important concept to grasp before writing our asyncio code. We need
    to decide which part of the code can be paused to allow Python to temporarily
    move on from it. We have to tell Python, “Hey, I am just waiting for something.
    Go do something else and come back to check on me.”
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写我们的asyncio代码之前，这是一个需要掌握的重要概念。我们需要决定代码的哪一部分可以被暂停，以便Python可以暂时从它那里移开。我们必须告诉Python，“嘿，我只是在等待某事。去做其他事情，然后回来检查我。”
- en: 'Let us start with a simple example of the asyncio module syntax in `asyncio_1.py`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从`asyncio_1.py`中asyncio模块语法的简单示例开始：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When we execute it, here is the output:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们执行它时，这里是这个输出：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'There are several things we can take note of in this example:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: The asyncio module is in the standard library for Python 3.10\.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `async` keyword is used in front of the function. In asyncio, this is called
    a coroutine.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `await` keyword is waiting for the return of some operations.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Instead of simply calling the function/coroutine, we use `asyncio.run()` to
    do so.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At the heart of the asyncio module are coroutines, defined with the `async`
    keyword. A coroutine is a specialized version of a Python generator function that
    can temporarily give back control to the Python interpreter while waiting.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'Generator functions are a type of function that can be iterated over like a
    list but do so without loading the content into memories first. This is useful
    when, for example, the dataset is so large that it might overwhelm a computer’s
    memory. For more information, check out this documentation: [https://wiki.python.org/moin/Generators](https://wiki.python.org/moin/Generators).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18403_10_02.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.2: Coroutine with async and await'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take this example further and see how we can build on it. The following
    examples were taken from the excellent tutorial from *RealPython.com* ([https://realpython.com/async-io-python/#the-asyncio-package-and-asyncawait](https://realpython.com/async-io-python/#the-asyncio-package-and-asyncawait)).
    We will start with a synchronous count function with `sync_count.py`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Upon execution, we can see the script executes in three seconds by faithfully
    executing the function three times sequentially:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, let’s see if we can build an asynchronous version of it, `async_count.py`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'When we execute this file, we see that similar tasks were completed in 1/3
    of the time:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Why is that? It is because now when we are counting and hit the sleep pause,
    we give the control back to the interpreter to allow it to process other tasks.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text  Description automatically generated](img/B18403_10_03.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.3: Event Loop'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few important points to note in this example:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: The `sleep()` function is changed to an `asyncio.sleep()` function. It is an
    `awaitable` function.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both the `count()` and `main()` functions are now coroutines.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We used `ansyncio.gather()` to collect all the coroutines.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `asyncio.run()` is a loop that runs until everything is completed.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the example, we can see there are several changes we need to make to regular
    functions to allow the performance gain offered by asyncio. Remember we talked
    about cooperative multiprocessing? Asyncio requires all components within the
    Python programs to work together to achieve this goal.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B18403_10_04.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.4: Event loop'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at the Scrapli project that helps us speed
    up the network device interaction process by taking advantage of the Python 3
    asyncio feature.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: The Scrapli project
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Scrapli is an open-source network library ([https://github.com/carlmontanari/scrapli](https://github.com/carlmontanari/scrapli))
    that uses Python 3’s asyncio capabilities to help connect to network devices faster.
    It was created by Carl Montanari ([https://github.com/carlmontanari](https://github.com/carlmontanari))
    while working on his network automation projects. The installation is straightforward:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Let’s go ahead and start using Scrapli for our network device communication.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Scrapli example
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can use the following example, `scrapli_example_1.py`, to perform a `show`
    command on our lab NX-OS device, `lax-cor-r1`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Executing the script will give us the `show` `version` output. Notice this
    is in a string format:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'On the surface, it might not look any different than some of the other libraries
    we have seen. But underneath the hood, the core drivers and associated platforms
    are using the asyncio module that can be turned into an `awaitable` coroutine:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B18403_10_05.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.5: Scrapli Core Drivers (source: https://carlmontanari.github.io/scrapli/user_guide/basic_usage/)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: We can verify the code by going to the project’s GitHub page, [https://github.com/carlmontanari/scrapli](https://github.com/carlmontanari/scrapli).
    The NXOS Async driver, [https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/core/cisco_nxos/async_driver.py](https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/core/cisco_nxos/async_driver.py),
    can be traced back to the base async driver, [https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/async_driver.py](https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/async_driver.py),
    as well as the base driver, [https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/base_driver.py](https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/base_driver.py).
    This is part of the beauty of open-source projects, and we have the freedom to
    explore and build on each other’s knowledge. Thank you, Carl!
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: The core drivers include Cisco IOS-XE, Cisco NX-OS, Cisco IOS-XR, Arista EOS,
    and Juniper JunOS. By simply specifying the platform, Scrapli is able to correlate
    it with the particular driver. There is also a `scrapli_community` project ([https://github.com/scrapli/scrapli_community](https://github.com/scrapli/scrapli_community))
    that extends beyond the core drivers.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'In our lab, we specify additional `ssh` configurations. Therefore, we need
    to set `ssh_config_file` to be `true`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Scrapli’s documentation, [https://carlmontanari.github.io/scrapli/](https://carlmontanari.github.io/scrapli/),
    is a good place to start. Packet Coders, [https://www.packetcoders.io/](https://www.packetcoders.io/),
    also offers good network automation classes, including Scrapli.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: We can now put this awaitable task into an asyncio run loop.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Scrapli async example
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we will be more precise about the driver and transport. We
    will install the `asyncssh` plugin ([https://carlmontanari.github.io/scrapli/api_docs/transport/plugins/asyncssh/](https://carlmontanari.github.io/scrapli/api_docs/transport/plugins/asyncssh/))
    from Scrapli to be used:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将更精确地讨论驱动器和传输。我们将从Scrapli安装`asyncssh`插件（[https://carlmontanari.github.io/scrapli/api_docs/transport/plugins/asyncssh/](https://carlmontanari.github.io/scrapli/api_docs/transport/plugins/asyncssh/))以供使用：
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The script, `scraplie_example_2.py`, is listed below:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 下面列出了脚本`scraplie_example_2.py`：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The script creates two new coroutines, one for gathering device information
    and the other for collecting the coroutine tasks within the `main()` function.
    We also created an `asyncio.run()` loop to run the `main()` function when the
    script is executed by itself. Let’s execute the script:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本创建了两个新的协程，一个用于收集设备信息，另一个用于在`main()`函数中收集协程任务。我们还创建了一个`asyncio.run()`循环，当脚本独立执行时运行`main()`函数。让我们执行这个脚本：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Besides the `show` `version` output from the two devices, we also saw that the
    execution was completed in little over 1 second.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 除了两个设备输出的`show version`信息外，我们还看到执行完成仅用了1秒多一点的时间。
- en: 'Let’s compare the performance difference between synchronous and asynchronous
    operations. Scrapli provides a `GenericDriver` for synchronous operations. In
    the example script `scrapli_example_3_sync.py`, we will use the `GenericDriver`
    to gather the information repeatedly. Just for illustration purposes, the script
    connects to each of the devices three times:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较同步和异步操作的性能差异。Scrapli为同步操作提供了一个`GenericDriver`。在示例脚本`scrapli_example_3_sync.py`中，我们将使用`GenericDriver`来反复收集信息。仅为了说明目的，该脚本连接到每个设备三次：
- en: '[PRE17]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'There is also a comparable async version, `scrapli_example_3_async.py`. When
    we run the two scripts, here is the performance difference:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一个可比较的异步版本，`scrapli_example_3_async.py`。当我们运行这两个脚本时，这里显示了性能差异：
- en: '[PRE18]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This might not seem much of an improvement, but as we scale up our operations,
    the performance gain will become more significant.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来改进不大，但随着我们扩大运营规模，性能提升将变得更加显著。
- en: Summary
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the concepts of asynchronous processing. We
    touched on the concepts behind CPU-bound and IO-bound tasks. We previously addressed
    the bottlenecks caused by them with multiprocessing and multithreading.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了异步处理的概念。我们简要介绍了CPU密集型和I/O密集型任务背后的概念。我们之前通过多进程和多线程解决了由它们引起的瓶颈。
- en: Starting with Python 3.4, the new asyncio module was introduced to address IO-bound
    tasks. It is similar to multithreading but uses a special cooperative multitasking
    design. They use special keywords – the `async` keyword to create functions that
    are special types of Python generators and the `await` keyword to specify tasks
    that can be temporarily “paused.” The asyncio module can then collect these tasks
    and run them in a loop until completed.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 从Python 3.4开始，引入了新的asyncio模块来解决I/O密集型任务。它与多线程类似，但使用了一种特殊的协作多任务设计。它们使用特殊的关键字——`async`关键字用于创建特殊类型的Python生成器函数，`await`关键字用于指定可以暂时“暂停”的任务。asyncio模块可以收集这些任务并在循环中运行，直到完成。
- en: In the latter part of the chapter, we learned about using Scrapli, a project
    created by Carl Montanari for the network engineering community. It is designed
    to utilize the asyncio feature in Python 3 for network device management.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后半部分，我们学习了使用Scrapli，这是一个由Carl Montanari为网络工程社区创建的项目。它旨在利用Python 3中的asyncio特性进行网络设备管理。
- en: Asyncio is not easy. The new terminology of async, await, loop, and generators
    can feel overwhelming. The asyncio module has also been under rapid development
    from Python version 3.4 to 3.7, making some online documents outdated. Hopefully,
    the information presented in this chapter can help us understand this useful feature.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Asyncio并不容易。异步、await、loop和生成器等新术语可能会让人感到压倒性。从Python 3.4到3.7版本，asyncio模块也经历了快速的发展，使得一些在线文档已经过时。希望本章提供的信息能帮助我们理解这个有用的特性。
- en: In the next chapter, we will switch gears toward cloud computing and the network
    features surrounding cloud computing.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将转向云计算及其周围的网络特性。
- en: Join our book community
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的书籍社区
- en: 'To join our community for this book – where you can share feedback, ask questions
    to the author, and learn about new releases – follow the QR code below:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要加入我们这本书的社区——在那里你可以分享反馈，向作者提问，并了解新版本——请扫描下面的二维码：
- en: '[https://packt.link/networkautomationcommunity](https://packt.link/networkautomationcommunity)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/networkautomationcommunity](https://packt.link/networkautomationcommunity)'
- en: '![](img/QR_Code2903617220506617062.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code2903617220506617062.png)'
