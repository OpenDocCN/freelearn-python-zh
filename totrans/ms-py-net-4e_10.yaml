- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction to Async IO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we have been interacting with the network devices
    directly via API or other Python libraries that abstracted us from low-level interactions
    with a remote device. When we need to interact with multiple devices, we use loops
    to allow us to pragmatically execute commands. One issue that we might start to
    see is that the end-to-end process begins to slow down when we need to interact
    with many devices. The bottleneck is usually the time spent waiting between the
    time we send the command until we receive the proper response from the remote
    device. If we need to spend 5 seconds of wait time per operation, we could wait
    for a few minutes when we need to operate on 30 devices.
  prefs: []
  type: TYPE_NORMAL
- en: This is partially true because our operations are sequential. We are only operating
    on one device at a time, in sequence. What if we can process multiple devices
    at the same time? That would speed things up, right? Yes, you are correct. But
    it is not as simple as “telling” our Python script to “go for” many devices simultaneously.
    We must consider the way computers schedule tasks, the language limitation, and
    the available tools at hand.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss Async IO, the Python package that allows us
    to perform multiple tasks at the same time. We will also discuss related topics
    such as multiprocessing, parallelism, threading, and others. Asynchronous operations
    in Python is a topic that I would consider medium to advanced level. The async
    IO module itself was only introduced in Python 3.4\. It also went through rapid
    changes between Python 3.4 to Python 3.7\. Regardless, it is a very relatable
    topic for network automation. I believe it is worth a study for any network engineer
    looking to be familiar with network automation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following topics related to Async IO:'
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous operations overview
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiprocessing and threading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python asyncio module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Scrapli` project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information on Python-related asynchronous operations, Real Python
    ([https://realpython.com/search?q=asyncio](https://realpython.com/search?q=asyncio))
    and Python documentation ([https://docs.python.org/3/library/asyncio.html](https://docs.python.org/3/library/asyncio.html))
    both offer good resources for learning.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by looking at an overview of asynchronous operations.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous operations overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the *Zen of Python;* we know one of the guiding principles in Python is to
    preferably have “one best way to do something.” When it comes to asynchronous
    operations, it is a bit complicated. We know it would help if we could do multiple
    tasks simultaneously but determining the correct solution might not be straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will need to determine what is slowing down our program. Typically,
    the bottleneck can be either CPU-bound or I/O-bound. In a CPU-bound situation,
    the program pushes the CPU to its limit. Operations such as solving mathematical
    questions or image processing are examples of CPU-bound programs. For example,
    when we pick an encryption algorithm for VPN, we know the more complex the algorithm,
    the more CPU it will consume. For CPU-bound tasks, the way to mitigate the bottleneck
    is to increase the CPU power or allow the task to use multiple CPUs simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: In an IO-bound operation, the program spends most of its time waiting for some
    output from an input it has completed. When we make an API call to a device, we
    cannot move on to the next step until we receive what we need as the answer. If
    time is significant, this is time that otherwise could have been useful in doing
    something else. The way to mitigate IO-bound tasks is to work on multiple tasks
    simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the work at hand is limited by CPU power or Input-Output latency, we can
    try to run multiple operations at once. This is called parallelism. Of course,
    not all tasks can be parallelized. As the great Warren Buffet saying goes, “You
    can’t produce a baby in one month by getting nine women pregnant.” However, if
    your task can be parallelized, we have a few parallel processing options: multiprocessing,
    threading, or the new asyncio module.'
  prefs: []
  type: TYPE_NORMAL
- en: Python multiprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python’s multiprocessing allows CPU-bound tasks to be broken up into sub-tasks
    and spawning subprocesses to handle them. This is well-suited for CPU-bound tasks
    because it allows multiple CPUs to work simultaneously. If we look back at the
    history of computing, we notice that around 2005, a single CPU can no longer get
    any faster. We simply cannot fit more transistors onto a single CPU due to interference
    and heat issues. The way we have gotten more computing power is by having multi-core
    CPUs. This is beneficial in allowing us to spread our tasks among the multi-core
    CPUs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python’s multiprocessing module, processes are spawned by creating a `Process`
    object and then calling its `start()` method. Let’s see a simple example, `multiprocess_1.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In the example, we have a worker function that calls another `process_info()`
    function to get the process ID. Then we start the Process object five times, each
    one targeting the worker function. The output for the execution is below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, each process has its process and process ID. Multiprocessing
    is great for CPU-bound tasks. If the work is IO-bound, before the asyncio module,
    our best bet is to use the threading module.
  prefs: []
  type: TYPE_NORMAL
- en: Python multithreading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As many of us know, Python has a **Global Interpreter Lock**, or **GIL**. It
    is used by the Python interpreter (CPython, to be exact) to assure that only one
    thread executes Python byte code at a time. This is mainly a safety measure to
    protect against race conditions in memory leaks. But it can become a performance
    bottleneck for IO-bound tasks.
  prefs: []
  type: TYPE_NORMAL
- en: For more information, check out the article at [https://realpython.com/python-gil/](https://realpython.com/python-gil/).
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to allow multiple threads to run is by using the `threading` module.
    It allows a program to run multiple operations concurrently. We can see a simple
    example in `threading_1.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The script is similar to our multiprocess example, with the exception of displaying
    the thread ID instead of the process ID. The output for the script execution is
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The threading module is a good option to mitigate the Python GIL with multiple
    threads. However, when Python passes the task to a thread, the main process has
    limited visibility in the threading process. The threads are harder to deal with,
    especially when coordinating between different threads and handling errors if
    they arise. For IO-bound tasks, instead of threads, asyncio in Python 3 is another
    great option.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, diagram, application  Description automatically
    generated](img/B18403_10_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.1: CPU-bound vs. IO-bound Python modules'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dig deeper into the asyncio module.
  prefs: []
  type: TYPE_NORMAL
- en: Python asyncio module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can think of the asyncio module as Python’s way of allowing us to write code
    to run tasks concurrently. It uses the newly introduced `async` and `await` keywords.
    It can help us improve performance for many operations that might be IO-bound,
    such as web servers, databases, and, of course, communication toward devices over
    a network. The asyncio module is the foundation of popular new frameworks, such
    as FastAPI ([https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: However, it is important to point out that asyncio is neither multiprocessing
    nor multithreaded. It is designed to be single-threaded with a single process.
    Python asyncio uses *cooperative multiprocessing* to give the feeling of concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike threading, Python controls the process from end to end instead of passing
    the threading process to the operating system. This lets Python know when the
    task is started and completed, thus coordinating between the processes. When we
    “pause” part of the code while waiting for results, Python will move on to other
    parts of the code before coming back to the “paused” code.
  prefs: []
  type: TYPE_NORMAL
- en: This is an important concept to grasp before writing our asyncio code. We need
    to decide which part of the code can be paused to allow Python to temporarily
    move on from it. We have to tell Python, “Hey, I am just waiting for something.
    Go do something else and come back to check on me.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us start with a simple example of the asyncio module syntax in `asyncio_1.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'When we execute it, here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'There are several things we can take note of in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: The asyncio module is in the standard library for Python 3.10\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `async` keyword is used in front of the function. In asyncio, this is called
    a coroutine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `await` keyword is waiting for the return of some operations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Instead of simply calling the function/coroutine, we use `asyncio.run()` to
    do so.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At the heart of the asyncio module are coroutines, defined with the `async`
    keyword. A coroutine is a specialized version of a Python generator function that
    can temporarily give back control to the Python interpreter while waiting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generator functions are a type of function that can be iterated over like a
    list but do so without loading the content into memories first. This is useful
    when, for example, the dataset is so large that it might overwhelm a computer’s
    memory. For more information, check out this documentation: [https://wiki.python.org/moin/Generators](https://wiki.python.org/moin/Generators).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18403_10_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.2: Coroutine with async and await'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take this example further and see how we can build on it. The following
    examples were taken from the excellent tutorial from *RealPython.com* ([https://realpython.com/async-io-python/#the-asyncio-package-and-asyncawait](https://realpython.com/async-io-python/#the-asyncio-package-and-asyncawait)).
    We will start with a synchronous count function with `sync_count.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon execution, we can see the script executes in three seconds by faithfully
    executing the function three times sequentially:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s see if we can build an asynchronous version of it, `async_count.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'When we execute this file, we see that similar tasks were completed in 1/3
    of the time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Why is that? It is because now when we are counting and hit the sleep pause,
    we give the control back to the interpreter to allow it to process other tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text  Description automatically generated](img/B18403_10_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.3: Event Loop'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few important points to note in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: The `sleep()` function is changed to an `asyncio.sleep()` function. It is an
    `awaitable` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both the `count()` and `main()` functions are now coroutines.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We used `ansyncio.gather()` to collect all the coroutines.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `asyncio.run()` is a loop that runs until everything is completed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the example, we can see there are several changes we need to make to regular
    functions to allow the performance gain offered by asyncio. Remember we talked
    about cooperative multiprocessing? Asyncio requires all components within the
    Python programs to work together to achieve this goal.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B18403_10_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.4: Event loop'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at the Scrapli project that helps us speed
    up the network device interaction process by taking advantage of the Python 3
    asyncio feature.
  prefs: []
  type: TYPE_NORMAL
- en: The Scrapli project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Scrapli is an open-source network library ([https://github.com/carlmontanari/scrapli](https://github.com/carlmontanari/scrapli))
    that uses Python 3’s asyncio capabilities to help connect to network devices faster.
    It was created by Carl Montanari ([https://github.com/carlmontanari](https://github.com/carlmontanari))
    while working on his network automation projects. The installation is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Let’s go ahead and start using Scrapli for our network device communication.
  prefs: []
  type: TYPE_NORMAL
- en: Scrapli example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can use the following example, `scrapli_example_1.py`, to perform a `show`
    command on our lab NX-OS device, `lax-cor-r1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing the script will give us the `show` `version` output. Notice this
    is in a string format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'On the surface, it might not look any different than some of the other libraries
    we have seen. But underneath the hood, the core drivers and associated platforms
    are using the asyncio module that can be turned into an `awaitable` coroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B18403_10_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.5: Scrapli Core Drivers (source: https://carlmontanari.github.io/scrapli/user_guide/basic_usage/)'
  prefs: []
  type: TYPE_NORMAL
- en: We can verify the code by going to the project’s GitHub page, [https://github.com/carlmontanari/scrapli](https://github.com/carlmontanari/scrapli).
    The NXOS Async driver, [https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/core/cisco_nxos/async_driver.py](https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/core/cisco_nxos/async_driver.py),
    can be traced back to the base async driver, [https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/async_driver.py](https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/async_driver.py),
    as well as the base driver, [https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/base_driver.py](https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/base_driver.py).
    This is part of the beauty of open-source projects, and we have the freedom to
    explore and build on each other’s knowledge. Thank you, Carl!
  prefs: []
  type: TYPE_NORMAL
- en: The core drivers include Cisco IOS-XE, Cisco NX-OS, Cisco IOS-XR, Arista EOS,
    and Juniper JunOS. By simply specifying the platform, Scrapli is able to correlate
    it with the particular driver. There is also a `scrapli_community` project ([https://github.com/scrapli/scrapli_community](https://github.com/scrapli/scrapli_community))
    that extends beyond the core drivers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our lab, we specify additional `ssh` configurations. Therefore, we need
    to set `ssh_config_file` to be `true`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Scrapli’s documentation, [https://carlmontanari.github.io/scrapli/](https://carlmontanari.github.io/scrapli/),
    is a good place to start. Packet Coders, [https://www.packetcoders.io/](https://www.packetcoders.io/),
    also offers good network automation classes, including Scrapli.
  prefs: []
  type: TYPE_NORMAL
- en: We can now put this awaitable task into an asyncio run loop.
  prefs: []
  type: TYPE_NORMAL
- en: Scrapli async example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we will be more precise about the driver and transport. We
    will install the `asyncssh` plugin ([https://carlmontanari.github.io/scrapli/api_docs/transport/plugins/asyncssh/](https://carlmontanari.github.io/scrapli/api_docs/transport/plugins/asyncssh/))
    from Scrapli to be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The script, `scraplie_example_2.py`, is listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The script creates two new coroutines, one for gathering device information
    and the other for collecting the coroutine tasks within the `main()` function.
    We also created an `asyncio.run()` loop to run the `main()` function when the
    script is executed by itself. Let’s execute the script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Besides the `show` `version` output from the two devices, we also saw that the
    execution was completed in little over 1 second.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s compare the performance difference between synchronous and asynchronous
    operations. Scrapli provides a `GenericDriver` for synchronous operations. In
    the example script `scrapli_example_3_sync.py`, we will use the `GenericDriver`
    to gather the information repeatedly. Just for illustration purposes, the script
    connects to each of the devices three times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'There is also a comparable async version, `scrapli_example_3_async.py`. When
    we run the two scripts, here is the performance difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This might not seem much of an improvement, but as we scale up our operations,
    the performance gain will become more significant.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the concepts of asynchronous processing. We
    touched on the concepts behind CPU-bound and IO-bound tasks. We previously addressed
    the bottlenecks caused by them with multiprocessing and multithreading.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with Python 3.4, the new asyncio module was introduced to address IO-bound
    tasks. It is similar to multithreading but uses a special cooperative multitasking
    design. They use special keywords – the `async` keyword to create functions that
    are special types of Python generators and the `await` keyword to specify tasks
    that can be temporarily “paused.” The asyncio module can then collect these tasks
    and run them in a loop until completed.
  prefs: []
  type: TYPE_NORMAL
- en: In the latter part of the chapter, we learned about using Scrapli, a project
    created by Carl Montanari for the network engineering community. It is designed
    to utilize the asyncio feature in Python 3 for network device management.
  prefs: []
  type: TYPE_NORMAL
- en: Asyncio is not easy. The new terminology of async, await, loop, and generators
    can feel overwhelming. The asyncio module has also been under rapid development
    from Python version 3.4 to 3.7, making some online documents outdated. Hopefully,
    the information presented in this chapter can help us understand this useful feature.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will switch gears toward cloud computing and the network
    features surrounding cloud computing.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book community
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To join our community for this book – where you can share feedback, ask questions
    to the author, and learn about new releases – follow the QR code below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/networkautomationcommunity](https://packt.link/networkautomationcommunity)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code2903617220506617062.png)'
  prefs: []
  type: TYPE_IMG
