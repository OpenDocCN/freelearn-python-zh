<html><head></head><body>
		<div id="_idContainer133">
			<h1 id="_idParaDest-299" class="chapter-number"><a id="_idTextAnchor306"/><st c="0">11</st></h1>
			<h1 id="_idParaDest-300"><a id="_idTextAnchor307"/><st c="3">Deploying Flask Applications</st></h1>
			<p><st c="32">When the development of a Flask application is over, you can always decide to deploy it somewhere outside Werkzeug’s HTTP server. </st><st c="163">The final application needs a production server that is fast and reliable, with minimal or no potential security risks, configurable, and easy to manage. </st><st c="317">Instead of utilizing the built-in Werkzeug server, the product needs a non-development server not for development, debugging, or testing but for running the software product. </st><st c="492">Flask deployment requires a stable and independent Python server or a </st><span class="No-Break"><st c="562">hosting platform.</st></span></p>
			<p><st c="579">This chapter will focus on different approaches, options, and procedures for deploying Flask applications to production servers suited for the product’s scope, environment, </st><span class="No-Break"><st c="753">and objectives.</st></span></p>
			<p><st c="768">The following topics will be covered in </st><span class="No-Break"><st c="809">this chapter:</st></span></p>
			<ul>
				<li><st c="822">Running the application on Gunicorn </st><span class="No-Break"><st c="859">and uWSGI</st></span></li>
				<li><st c="868">Running the application </st><span class="No-Break"><st c="893">on Uvicorn</st></span></li>
				<li><st c="903">Deploying the application to the Apache </st><span class="No-Break"><st c="944">HTTP Server</st></span></li>
				<li><st c="955">Deploying the application </st><span class="No-Break"><st c="982">to Docker</st></span></li>
				<li><st c="991">Deploying the application </st><span class="No-Break"><st c="1018">to Kubernetes</st></span></li>
				<li><st c="1031">Creating an API gateway </st><span class="No-Break"><st c="1056">using NGINX</st></span></li>
			</ul>
			<h1 id="_idParaDest-301"><a id="_idTextAnchor308"/><st c="1067">Technical requirements</st></h1>
			<p><st c="1090">Our application will be using PostgreSQL to manage its data. </st><st c="1152">The projects will also be applying the </st><strong class="source-inline"><st c="1191">Blueprint</st></strong><st c="1200"> approach of managing Flask components. </st><st c="1240">The project prototype will focus on simple e-commerce, inventory, and stocking transactions for a small-scale grocery store, and it will be called an </st><em class="italic"><st c="1390">Online Grocery</st></em><st c="1404"> application. </st><st c="1418">All these applications can be found </st><span class="No-Break"><st c="1454">at </st></span><a href="https://github.com/PacktPublishing/Mastering-Flask-Web-Development/tree/main/ch11"><span class="No-Break"><st c="1457">https://github.com/PacktPublishing/Mastering-Flask-Web-Development/tree/main/ch11</st></span></a><span class="No-Break"><st c="1538">.</st></span></p>
			<h1 id="_idParaDest-302"><a id="_idTextAnchor309"/><st c="1539">Getting ready for deployment</st></h1>
			<p><st c="1568">In this chapter, we’ll create an </st><em class="italic"><st c="1602">Online Grocery</st></em><st c="1616"> application that can be deployed to different platforms. </st><st c="1674">The </st><a id="_idIndexMarker1006"/><st c="1678">application is an API-based type with administration, login, inventory, stocking, order, and purchase modules designed for small business transactions of a small shopping or </st><span class="No-Break"><st c="1852">grocery store.</st></span></p>
			<p><st c="1866">The Peewee ORM builds the application’s model and repository layer. </st><st c="1935">To utilize the standard </st><strong class="source-inline"><st c="1959">Peewee</st></strong><st c="1965"> module, install it and the </st><strong class="source-inline"><st c="1993">psycopg2</st></strong><st c="2001"> driver using the following </st><span class="No-Break"><strong class="source-inline"><st c="2029">pip</st></strong></span><span class="No-Break"><st c="2032"> command:</st></span></p>
			<pre class="console"><st c="2041">
pip install psycopg2 peewee</st></pre>			<p><st c="2069">The Peewee ORM provides the standard </st><em class="italic"><st c="2107">INSERT</st></em><st c="2113">, </st><em class="italic"><st c="2115">UPDATE</st></em><st c="2121">, </st><em class="italic"><st c="2123">DELETE</st></em><st c="2129">, and </st><em class="italic"><st c="2135">SELECT</st></em><st c="2141"> transactions, thus including the </st><strong class="source-inline"><st c="2175">psycopg2</st></strong><st c="2183"> driver as a dependency library. </st><st c="2216">Let’s begin structuring the model layer of the </st><span class="No-Break"><st c="2263">Peewee ORM.</st></span></p>
			<h2 id="_idParaDest-303"><a id="_idTextAnchor310"/><st c="2274">Classes and methods for the standard Peewee ORM</st></h2>
			<p><st c="2322">Our </st><em class="italic"><st c="2327">Online Grocery</st></em><st c="2341"> application </st><a id="_idIndexMarker1007"/><st c="2354">is deployed to a </st><strong class="bold"><st c="2371">Gunicorn</st></strong><st c="2379"> server </st><a id="_idIndexMarker1008"/><st c="2387">and uses the standard </st><a id="_idIndexMarker1009"/><st c="2409">Peewee helper classes and methods to establish the model layer and the repository classes. </st><st c="2500">Here is a typical Peewee configuration for the PostgreSQL </st><span class="No-Break"><st c="2558">database connection:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="2578">(app/models/config.py)</st></strong><st c="2601">
from peewee import PostgresqlDatabase
</st><strong class="bold"><st c="2640">database = PostgresqlDatabase(</st></strong><st c="2670">
     'ogs', user='postgres', password='admin2255', </st><strong class="bold"><st c="2717">autocommit=False</st></strong><st c="2733">, host='localhost', port=5432</st><strong class="bold"><st c="2762">)</st></strong></pre>			<p><st c="2764">Peewee has </st><strong class="source-inline"><st c="2775">PostgresqlDatabase</st></strong><st c="2793">, </st><strong class="source-inline"><st c="2795">MySQLDatabase</st></strong><st c="2808">, and </st><strong class="source-inline"><st c="2814">SqliteDatabase</st></strong><st c="2828"> driver classes that will create a connection object for the application. </st><st c="2902">Our option is </st><strong class="source-inline"><st c="2916">PostgresqlDatabase</st></strong><st c="2934">, as shown in the preceding code, since our application uses the </st><strong class="bold"><st c="2999">PostgreSQL</st></strong><st c="3009"> database </st><a id="_idIndexMarker1010"/><st c="3019">platform. </st><st c="3029">Note that you should always set the </st><strong class="source-inline"><st c="3065">autocommit</st></strong><st c="3075"> constructor parameter to </st><strong class="source-inline"><st c="3101">False</st></strong><st c="3106"> to enable transaction </st><a id="_idIndexMarker1011"/><st c="3129">management for </st><span class="No-Break"><st c="3144">CRUD operations.</st></span></p>
			<p><st c="3160">The </st><strong class="source-inline"><st c="3165">database</st></strong><st c="3173"> connection object will map Peewee’s model classes to their actual table schemas. </st><st c="3255">The </st><a id="_idIndexMarker1012"/><st c="3259">following are some model classes of </st><span class="No-Break"><st c="3295">our applications:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="3312">(app/models/db.py)</st></strong>
<strong class="bold"><st c="3331">from app.models.config import database</st></strong><st c="3370">
from peewee import Model, CharField, IntegerField, BigIntegerField, ForeignKeyField, DateField
</st><strong class="bold"><st c="3466">class Product(Model):</st></strong><st c="3487">
    id = BigIntegerField(</st><strong class="bold"><st c="3509">primary_key=True</st></strong><st c="3526">, null=False, </st><strong class="bold"><st c="3540">sequence="product_id_seq"</st></strong><st c="3565">)
    code = CharField(max_length="20", unique="True", null=False)
    name = CharField(max_length="100", null=False)
    </st><strong class="bold"><st c="3676">btype = ForeignKeyField(model=Brand, null=False,</st></strong> <strong class="bold"><st c="3724">to_field="code", backref="brand")</st></strong><strong class="bold"><st c="3758">ctype = ForeignKeyField(model=Category, null=False,</st></strong> <strong class="bold"><st c="3810">to_field="code", backref="category")</st></strong><st c="3847">
    … … … … … …
    </st><strong class="bold"><st c="3859">discount = ForeignKeyField(model=Discount, null=False,</st></strong> <strong class="bold"><st c="3913">to_field="code", backref="discount")</st></strong><strong class="bold"><st c="3950">class Meta:</st></strong><strong class="bold"><st c="3962">db_table = "product"</st></strong><strong class="bold"><st c="3983">database = database</st></strong></pre>			<p><st c="4003">The given </st><strong class="source-inline"><st c="4014">Product</st></strong><st c="4021"> model class represents the record details of a product sold by the grocery store, while the following </st><strong class="source-inline"><st c="4124">Stock</st></strong><st c="4129"> model creates stock information about </st><span class="No-Break"><st c="4168">a product:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="4178">class Stock(Model):</st></strong><st c="4198">
    id = BigIntegerField(</st><strong class="bold"><st c="4220">primary_key=True</st></strong><st c="4237">, null=False, </st><strong class="bold"><st c="4251">sequence="stock_id_seq"</st></strong><st c="4274">)
    </st><strong class="bold"><st c="4277">sid = ForeignKeyField(model=Supplier, null=False,</st></strong> <strong class="bold"><st c="4326">to_field="sid", backref="supplier")</st></strong><strong class="bold"><st c="4362">invcode = ForeignKeyField(model=InvoiceRequest,</st></strong> <strong class="bold"><st c="4410">null=False, to_field="code", backref="invoice")</st></strong><st c="4458">
    qty = IntegerField(null=False)
    payment_date = DateField(null=True)
    received_date = DateField(null=False)
    recieved_by = CharField(max_length="100")
    </st><strong class="bold"><st c="4606">class Meta:</st></strong><strong class="bold"><st c="4617">db_table = "stock"</st></strong><strong class="bold"><st c="4636">database = database</st></strong><st c="4656">
    … … … … … …</st></pre>			<p><st c="4667">All model </st><a id="_idIndexMarker1013"/><st c="4678">classes must </st><a id="_idIndexMarker1014"/><st c="4691">subclass Peewee’s </st><strong class="source-inline"><st c="4709">Model</st></strong><st c="4714"> class to become the logical representations of the database tables. </st><st c="4783">The Peewee model classes, like the given </st><strong class="source-inline"><st c="4824">Product</st></strong><st c="4831"> and </st><strong class="source-inline"><st c="4836">Stock</st></strong><st c="4841">, have the </st><strong class="source-inline"><st c="4852">Meta</st></strong><st c="4856"> class, which holds the </st><strong class="source-inline"><st c="4880">database</st></strong><st c="4888"> and </st><strong class="source-inline"><st c="4893">db_table</st></strong><st c="4901"> attributes responsible for mapping them to the physical tables of our database. </st><st c="4982">Peewee’s column helper classes build the column attributes of the model classes. </st><st c="5063">Now, the </st><strong class="source-inline"><st c="5072">main.py</st></strong><st c="5079"> module must enable the </st><strong class="source-inline"><st c="5103">before_request()</st></strong><st c="5119"> glocal event of Flask to handle the database connection. </st><st c="5177">The following snippet shows the implementation of the </st><strong class="source-inline"><st c="5231">before_request()</st></strong> <span class="No-Break"><st c="5247">global event:</st></span></p>
			<pre class="source-code"><st c="5261">
from app import create_app
from app.models.config import database
app = create_app('../config_dev.toml')
</st><strong class="bold"><st c="5367">@app.before_request</st></strong><st c="5386">
def db_connect():
    </st><strong class="bold"><st c="5405">database.connect()</st></strong>
<strong class="bold"><st c="5423">@app.teardown_request</st></strong><st c="5445">
def db_close(exc):
    </st><strong class="bold"><st c="5465">if not database.is_closed():</st></strong><strong class="bold"><st c="5493">database.close()</st></strong></pre>			<p><st c="5510">Here, </st><strong class="source-inline"><st c="5517">teardown_request()</st></strong><st c="5535"> closes the connection during </st><span class="No-Break"><st c="5565">server shutdown.</st></span></p>
			<p><st c="5581">Like </st><a id="_idIndexMarker1015"/><st c="5587">in SQLAlchemy, the Peewee ORM needs the model classes to create the transaction layer to </st><a id="_idIndexMarker1016"/><st c="5676">perform the CRUD operations. </st><st c="5705">The following is a </st><strong class="source-inline"><st c="5724">ProductRepository</st></strong><st c="5741"> class that manages and executes SQL statements using the standard </st><span class="No-Break"><st c="5808">Peewee transactions:</st></span></p>
			<pre class="source-code"><st c="5828">
from app.models.db import Product
from app.models.db import database
from typing import Dict, Any
class ProductRepository:
    def insert_product(self, details:Dict[str, Any]) -&gt; bool:
        try:
            </st><strong class="bold"><st c="6015">with database.atomic() as tx:</st></strong><strong class="bold"><st c="6044">Product.create(**details)</st></strong><strong class="bold"><st c="6070">tx.commit()</st></strong><st c="6082">
                return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="6139">The Peewee repository class derives its transaction management from the </st><strong class="source-inline"><st c="6212">database</st></strong><st c="6220"> connection object. </st><st c="6240">Its emitted </st><strong class="source-inline"><st c="6252">atomic()</st></strong><st c="6260"> method provides a transaction object that performs </st><strong class="source-inline"><st c="6312">commit()</st></strong><st c="6320"> and </st><strong class="source-inline"><st c="6325">rollback()</st></strong><st c="6335"> during SQL execution. </st><st c="6358">The given </st><strong class="source-inline"><st c="6368">insert_product()</st></strong><st c="6384"> function performs an </st><strong class="source-inline"><st c="6406">INSERT</st></strong><st c="6412"> operation of a </st><strong class="source-inline"><st c="6428">Product</st></strong><st c="6435"> record by calling the model’s </st><strong class="source-inline"><st c="6466">create()</st></strong><st c="6474"> class method with the </st><strong class="source-inline"><st c="6497">kwargs</st></strong><st c="6503"> variable of details and returns </st><strong class="source-inline"><st c="6536">True</st></strong><st c="6540"> if the operation is successful. </st><st c="6573">Otherwise, it </st><span class="No-Break"><st c="6587">returns </st></span><span class="No-Break"><strong class="source-inline"><st c="6595">False</st></strong></span><span class="No-Break"><st c="6600">.</st></span></p>
			<p><st c="6601">On the </st><a id="_idIndexMarker1017"/><st c="6609">other hand, an </st><strong class="source-inline"><st c="6624">UPDATE</st></strong><st c="6630"> operation in standard Peewee requires a transaction layer to retrieve the </st><a id="_idIndexMarker1018"/><st c="6705">record object that needs an update, access its concerned field(s), and replace them with new values. </st><st c="6806">The following </st><strong class="source-inline"><st c="6820">update_product()</st></strong><st c="6836"> function shows the implementation of a </st><span class="No-Break"><strong class="source-inline"><st c="6876">Product</st></strong></span><span class="No-Break"><st c="6883"> update:</st></span></p>
			<pre class="source-code"><st c="6891">
    def update_product(self, details:Dict[str,Any]) -&gt; bool:
       try:
           </st><strong class="bold"><st c="6954">with database.atomic() as tx:</st></strong><strong class="bold"><st c="6983">prod = Product.get(</st></strong> <strong class="bold"><st c="7003">Product.code==details["code"])</st></strong><st c="7034">
                prod.rate = details["name"]
                prod.code = details["btype"]
                prod.rate = details["ctype"]
                prod.code = details["unit_type"]
                prod.rate = details["sell_price"]
                prod.code = details["purchase_price"]
                prod.rate = details["discount"]
                </st><strong class="bold"><st c="7258">prod.save()</st></strong><strong class="bold"><st c="7269">tx.commit()</st></strong><st c="7281">
                return True
       except Exception as e:
           print(e)
       return False</st></pre>			<p><st c="7338">The </st><strong class="source-inline"><st c="7343">get()</st></strong><st c="7348"> method of the </st><a id="_idIndexMarker1019"/><st c="7363">model class retrieves a single instance matching the given query constraint. </st><st c="7440">The goal is to update only one record, so be sure that the constraint parameters in the record object retrieval only involve the </st><strong class="source-inline"><st c="7569">unique</st></strong><st c="7575"> or </st><strong class="source-inline"><st c="7579">primary key</st></strong> <span class="No-Break"><st c="7590">column fields.</st></span></p>
			<p><st c="7605">Now, the </st><strong class="source-inline"><st c="7615">save()</st></strong><st c="7621"> method of the </st><a id="_idIndexMarker1020"/><st c="7636">record object will eventually merge the new record object with the old one linked to the database. </st><st c="7735">This </st><strong class="source-inline"><st c="7740">commit()</st></strong><st c="7748"> will finally persist and flush the updated record to </st><span class="No-Break"><st c="7802">the table.</st></span></p>
			<p><st c="7812">When </st><a id="_idIndexMarker1021"/><st c="7818">it comes to deletion, the initial step is similar to updating a record, which involves retrieving the record </st><a id="_idIndexMarker1022"/><st c="7927">object for deletion. </st><st c="7948">The following </st><strong class="source-inline"><st c="7962">delete_product_code()</st></strong><st c="7983"> repository method depicts this </st><span class="No-Break"><st c="8015">initial process:</st></span></p>
			<pre class="source-code"><st c="8031">
    def delete_product_code(self, code:str) -&gt; bool:
        try:
           </st><strong class="bold"><st c="8086">with database.atomic() as tx:</st></strong><strong class="bold"><st c="8115">prod = Product.get(Product.code==code)</st></strong><strong class="bold"><st c="8154">prod.delete_instance()</st></strong><strong class="bold"><st c="8177">tx.commit()</st></strong><st c="8189">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="8246">The record object has a </st><strong class="source-inline"><st c="8271">delete_instance()</st></strong><st c="8288"> function that removes the record from the schema. </st><st c="8339">In the case of </st><strong class="source-inline"><st c="8354">delete_product_code()</st></strong><st c="8375">, it deletes a </st><strong class="source-inline"><st c="8390">Product</st></strong><st c="8397"> record through the record object retrieved by its </st><span class="No-Break"><st c="8448">product code.</st></span></p>
			<p><st c="8461">When </st><a id="_idIndexMarker1023"/><st c="8467">retrieving records, the </st><a id="_idIndexMarker1024"/><st c="8491">Peewee ORM has a </st><strong class="source-inline"><st c="8508">select()</st></strong><st c="8516"> method that builds variations of query implementations. </st><st c="8573">The following </st><strong class="source-inline"><st c="8587">select_product_code()</st></strong><st c="8608"> and </st><strong class="source-inline"><st c="8613">select_product_id()</st></strong><st c="8632"> functions show how to retrieve single records based on unique or primary </st><span class="No-Break"><st c="8706">key constraints:</st></span></p>
			<pre class="source-code"><st c="8722">
    def select_product_code(self, code:str):
        </st><strong class="source-inline"><st c="8764">prod = Product.select(Product.code==code)</st></strong><st c="8805">
        return </st><strong class="source-inline"><st c="8813">prod.to_json()</st></strong><st c="8827">
    def select_product_id(self, id:int):
        </st><strong class="source-inline"><st c="8865">prod = Product.select(Product.id==id)</st></strong><st c="8902">
        return </st><strong class="source-inline"><st c="8910">prod.to_json()</st></strong></pre>			<p><st c="8924">On the other hand, the following </st><strong class="source-inline"><st c="8958">select_all_product()</st></strong><st c="8978"> function retrieves all records in the </st><span class="No-Break"><strong class="source-inline"><st c="9017">product</st></strong></span><span class="No-Break"><st c="9024"> table:</st></span></p>
			<pre class="source-code"><st c="9031">
    def select_all_product(self):
        </st><strong class="bold"><st c="9062">prods = Product.select()</st></strong><strong class="bold"><st c="9086">records = [log.to_json() for log in prods]</st></strong><st c="9129">
        return records</st></pre>			<p><st c="9144">All model classes retrieved by the </st><strong class="source-inline"><st c="9180">select()</st></strong><st c="9188"> method are non-serializable or non-JSONable. </st><st c="9234">So, in the implementation, be sure to include the conversion of all model objects into JSON records using any accepted method. </st><st c="9361">In the given sample, all our model classes have a </st><strong class="source-inline"><st c="9411">to_json()</st></strong><st c="9420"> method that returns a JSON object containing all the </st><strong class="source-inline"><st c="9474">Product</st></strong><st c="9481"> fields and values. </st><st c="9501">The query transactions include a list comprehension in its procedure to generate a list of JSONable records of </st><strong class="source-inline"><st c="9612">Product</st></strong><st c="9619"> details using the </st><span class="No-Break"><strong class="source-inline"><st c="9638">to_json()</st></strong></span><span class="No-Break"><st c="9647"> method.</st></span></p>
			<h2 id="_idParaDest-304"><a id="_idTextAnchor311"/><st c="9655">Classes and methods for the Async Peewee ORM</st></h2>
			<p><st c="9700">Some parts of </st><a id="_idIndexMarker1025"/><st c="9715">our deployed </st><em class="italic"><st c="9728">Online Grocery</st></em><st c="9742"> application runs on the </st><strong class="bold"><st c="9767">asyncio</st></strong><st c="9774"> platform with async API endpoints and async repository transactions. </st><st c="9844">Peewee </st><a id="_idIndexMarker1026"/><st c="9851">has an async version </st><a id="_idIndexMarker1027"/><st c="9872">that supports asynchronous request transactions in Flask. </st><st c="9930">To utilize the </st><strong class="bold"><st c="9945">Async Peewee ORM</st></strong><st c="9961">, install the </st><strong class="source-inline"><st c="9975">peewee-async</st></strong><st c="9987"> module using the </st><a id="_idIndexMarker1028"/><st c="10005">following </st><span class="No-Break"><strong class="source-inline"><st c="10015">pip</st></strong></span><span class="No-Break"><st c="10018"> command:</st></span></p>
			<pre class="console"><st c="10027">
pip install aiopg peewee-async</st></pre>			<p><st c="10058">Also, include the </st><strong class="source-inline"><st c="10077">aiopg</st></strong><st c="10082"> module, which provides PostgreSQL asynchronous database access through the </st><em class="italic"><st c="10158">DB </st></em><span class="No-Break"><em class="italic"><st c="10161">API</st></em></span><span class="No-Break"><st c="10164"> specification.</st></span></p>
			<p><st c="10179">Async Peewee has </st><strong class="source-inline"><st c="10197">PooledPostgresqlDatabase</st></strong><st c="10221">, </st><strong class="source-inline"><st c="10223">AsyncPostgresqlConnection</st></strong><st c="10248">, and </st><strong class="source-inline"><st c="10254">AsyncMySQLConnection</st></strong><st c="10274"> driver classes that create database connection objects in </st><strong class="source-inline"><st c="10333">async</st></strong><st c="10338"> mode. </st><st c="10345">Our configuration uses the </st><strong class="source-inline"><st c="10372">PooledPostgresqlDatabase</st></strong><st c="10396"> driver class to include the creation of a </st><span class="No-Break"><st c="10439">connection pool:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="10455">from peewee_async import PooledPostgresqlDatabase</st></strong>
<strong class="bold"><st c="10505">database = PooledPostgresqlDatabase(</st></strong><st c="10542">
        'ogs', user='postgres', password='admin2255',
        host='localhost', port='5432', </st><strong class="bold"><st c="10620">max_connections = 3</st></strong><st c="10639">,
        connect_timeout = 3, </st><strong class="bold"><st c="10662">autocommit=False)</st></strong></pre>			<p><st c="10679">The given configuration has a maximum pool size of </st><strong class="source-inline"><st c="10731">3</st></strong><st c="10732"> with </st><strong class="source-inline"><st c="10738">autocommit</st></strong><st c="10748"> set </st><span class="No-Break"><st c="10753">to </st></span><span class="No-Break"><strong class="source-inline"><st c="10756">False</st></strong></span><span class="No-Break"><st c="10761">.</st></span></p>
			<p><st c="10762">The Async Peewee ORM handles database connectivity differently: it does not use the </st><strong class="source-inline"><st c="10847">before_request()</st></strong><st c="10863"> and </st><strong class="source-inline"><st c="10868">teardown_request()</st></strong><st c="10886"> events but rather uses configuration with the </st><strong class="source-inline"><st c="10933">create_app()</st></strong><st c="10945"> factory method. </st><st c="10962">The following snippet shows how to establish a PostgreSQL database connection using the </st><span class="No-Break"><strong class="source-inline"><st c="11050">peewee-async</st></strong></span><span class="No-Break"><st c="11062"> module:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="11070">from app.models.config import database</st></strong>
<strong class="bold"><st c="11109">from peewee_async import Manager</st></strong><st c="11142">
def create_app(config_file):
    app = Flask(__name__)
    app.config.from_file(config_file, toml.load)
    global conn_mgr
    </st><strong class="bold"><st c="11255">conn_mgr = Manager(database)</st></strong><strong class="bold"><st c="11283">database.set_allow_sync(False)</st></strong><st c="11314">
    … … … … … …</st></pre>			<p><st c="11325">Here, </st><strong class="source-inline"><st c="11332">Manager</st></strong><st c="11339"> establishes an </st><strong class="source-inline"><st c="11355">asyncio</st></strong><st c="11362"> database connection pattern without using </st><strong class="source-inline"><st c="11405">before_request()</st></strong><st c="11421"> to connect to and </st><strong class="source-inline"><st c="11440">teardown_request()</st></strong><st c="11458"> to disconnect from the </st><a id="_idIndexMarker1029"/><st c="11482">database. </st><st c="11492">However, it can emit the </st><strong class="source-inline"><st c="11517">connect()</st></strong><st c="11526"> and </st><strong class="source-inline"><st c="11531">close()</st></strong><st c="11538"> methods to manage the database connection </st><a id="_idIndexMarker1030"/><st c="11581">during query execution explicitly. </st><st c="11616">Instantiating the </st><strong class="source-inline"><st c="11634">Manager</st></strong><st c="11641"> class requires the database connection object and an optional </st><strong class="source-inline"><st c="11704">asyncio</st></strong><st c="11711"> event loop. </st><st c="11724">Through the </st><strong class="source-inline"><st c="11736">Manager</st></strong><st c="11743"> object, you can invoke its </st><strong class="source-inline"><st c="11771">set_allow_sync()</st></strong><st c="11787"> method and set it to </st><strong class="source-inline"><st c="11809">False</st></strong><st c="11814"> to restrict the usage of non-async utility </st><span class="No-Break"><st c="11858">Peewee methods.</st></span></p>
			<p><st c="11873">The </st><strong class="source-inline"><st c="11878">conn_mgr</st></strong><st c="11886"> and </st><strong class="source-inline"><st c="11891">database</st></strong><st c="11899"> objects are equally essential for building the repository layer, as depicted in the following </st><span class="No-Break"><strong class="source-inline"><st c="11994">DiscountRepository</st></strong></span><span class="No-Break"><st c="12012"> implementation:</st></span></p>
			<pre class="source-code"><st c="12028">
from app.models.db import Discount
from app.models.db import database
from app import conn_mgr
from typing import Dict, Any
class DiscountRepository:
    async def insert_discount(self, details:Dict[str, Any]) -&gt; bool:
        try:
            </st><strong class="bold"><st c="12249">async with database.atomic_async() as tx:</st></strong><strong class="bold"><st c="12290">await conn_mgr.create(Discount, **details)</st></strong><strong class="bold"><st c="12333">await tx.commit()</st></strong><st c="12351">
                return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="12408">Although the implementation of the model layer is similar to the standard Peewee, its repository </st><a id="_idIndexMarker1031"/><st c="12506">layer is not the same </st><a id="_idIndexMarker1032"/><st c="12528">because of the </st><strong class="source-inline"><st c="12543">asyncio</st></strong><st c="12550"> platform used by the ORM to perform the CRUD transactions. </st><st c="12610">For instance, the following </st><strong class="source-inline"><st c="12638">insert_discount()</st></strong><st c="12655"> function emits </st><strong class="source-inline"><st c="12671">atomic_async()</st></strong><st c="12685"> from the </st><strong class="source-inline"><st c="12695">conn_mgr</st></strong><st c="12703"> instance to generate an async transaction layer, which will commit the inserted </st><strong class="source-inline"><st c="12784">Discount</st></strong><st c="12792"> record performed by the </st><strong class="source-inline"><st c="12817">create()</st></strong><st c="12825"> method of </st><strong class="source-inline"><st c="12836">conn_mgr</st></strong><st c="12844">, not by </st><strong class="source-inline"><st c="12853">Discount</st></strong><st c="12861">. The use of the </st><strong class="source-inline"><st c="12878">async</st></strong><st c="12883">/</st><strong class="source-inline"><st c="12885">await</st></strong><st c="12890"> keywords is present in </st><span class="No-Break"><st c="12914">the implementations.</st></span></p>
			<p><st c="12934">On the </st><strong class="source-inline"><st c="12942">UPDATE</st></strong><st c="12948"> operation, the </st><strong class="source-inline"><st c="12964">get()</st></strong><st c="12969"> method of </st><strong class="source-inline"><st c="12980">conn_mgr</st></strong><st c="12988"> retrieves the record object that needs updating, and its </st><strong class="source-inline"><st c="13046">update()</st></strong><st c="13054"> method flushes the newly updated fields to the table. </st><st c="13109">Again, the async </st><strong class="source-inline"><st c="13126">Manager</st></strong><st c="13133"> methods operate the transaction, not the model class. </st><st c="13188">The following </st><strong class="source-inline"><st c="13202">update_discount()</st></strong><st c="13219"> function showcases Peewee’s async approach to updating </st><span class="No-Break"><st c="13275">table records:</st></span></p>
			<pre class="source-code"><st c="13289">
    async def update_discount(self, details:Dict[str,Any]) -&gt; bool:
       try:
           </st><strong class="bold"><st c="13359">async with database.atomic_async():</st></strong><strong class="bold"><st c="13394">discount = await conn_mgr.get(Discount,</st></strong> <strong class="bold"><st c="13434">code=details["code"])</st></strong><st c="13456">
                discount.rate = details["rate"]
                </st><strong class="bold"><st c="13489">await conn_mgr.update(discount,</st></strong> <strong class="bold"><st c="13520">only=("rate", ))</st></strong><st c="13537">
                return True
       except Exception as e:
           print(e)
       return False</st></pre>			<p><st c="13594">The local </st><a id="_idIndexMarker1033"/><st c="13605">parameters of the </st><strong class="source-inline"><st c="13623">update()</st></strong><st c="13631"> method of </st><strong class="source-inline"><st c="13642">conn_mgr</st></strong><st c="13650"> include the record object with the updated fields </st><a id="_idIndexMarker1034"/><st c="13701">and the </st><strong class="source-inline"><st c="13709">only</st></strong><st c="13713"> parameter for controlling a tuple of field names that need updating in </st><span class="No-Break"><st c="13785">the table.</st></span></p>
			<p><st c="13795">On the other hand, the </st><strong class="source-inline"><st c="13819">DELETE</st></strong><st c="13825"> operation uses the same async </st><strong class="source-inline"><st c="13856">get()</st></strong><st c="13861"> method of </st><strong class="source-inline"><st c="13872">conn_mgr</st></strong><st c="13880"> in </st><strong class="source-inline"><st c="13884">update_discount()</st></strong><st c="13901"> to retrieve the record object for deletion. </st><st c="13946">As shown in the following </st><strong class="source-inline"><st c="13972">delete_discount_code()</st></strong><st c="13994"> function, the async </st><strong class="source-inline"><st c="14015">delete()</st></strong><st c="14023"> method of </st><strong class="source-inline"><st c="14034">conn_mgr</st></strong><st c="14042"> deletes the record from the table using the </st><span class="No-Break"><st c="14087">record object:</st></span></p>
			<pre class="source-code"><st c="14101">
    async def delete_discount_code(self, code:str) -&gt; bool:
        try:
           </st><strong class="bold"><st c="14163">async with database.atomic_async():</st></strong><strong class="bold"><st c="14198">discount = await conn_mgr.get(Discount,</st></strong> <strong class="bold"><st c="14238">code=code)</st></strong><strong class="bold"><st c="14249">await conn_mgr.delete(discount)</st></strong><st c="14281">
            return True
        except Exception as e:
            print(e)
        return False</st></pre>			<p><st c="14338">When implementing async query transactions, the Async Peewee ORM uses the </st><strong class="source-inline"><st c="14413">Manager</st></strong><st c="14420"> class’s async </st><strong class="source-inline"><st c="14435">get()</st></strong><st c="14440"> method to retrieve a single record and the </st><strong class="source-inline"><st c="14484">execute()</st></strong><st c="14493"> method to </st><a id="_idIndexMarker1035"/><st c="14504">wrap and run the </st><strong class="source-inline"><st c="14521">select()</st></strong><st c="14529"> statement for retrieving a single or all the records asynchronously. </st><st c="14599">The </st><a id="_idIndexMarker1036"/><st c="14603">following snippets show the query implementation </st><span class="No-Break"><st c="14652">for </st></span><span class="No-Break"><strong class="source-inline"><st c="14656">DiscountRepository</st></strong></span><span class="No-Break"><st c="14674">:</st></span></p>
			<pre class="source-code"><st c="14676">
    async def select_discount_code(self, code:str):
        </st><strong class="bold"><st c="14725">discount = await conn_mgr.get(Discount, code=code)</st></strong><st c="14775">
        return discount.to_json()
    async def select_discount_id(self, id:int):
        </st><strong class="bold"><st c="14846">discount = await conn_mgr.get(Discount, id=id)</st></strong><st c="14892">
        return discount.to_json()
    async def select_all_discount(self):
        </st><strong class="bold"><st c="14956">discounts = await conn_mgr.execute(</st></strong> <strong class="bold"><st c="14991">Discount.select())</st></strong><st c="15010">
        records = [log.to_json() for log in discounts]
        return records</st></pre>			<p><st c="15072">So, all these bundled methods in the </st><strong class="source-inline"><st c="15110">Manager</st></strong><st c="15117"> class’s instance provide the operations for implementing the CRUD transactions in the asynchronous </st><span class="No-Break"><st c="15217">transaction layer.</st></span></p>
			<p><st c="15235">Peewee is a simple and flexible ORM for small to middle-scale Flask applications. </st><st c="15318">Although SQLAlchemy offers more powerful utilities, it is not suited for a small application like our </st><em class="italic"><st c="15420">Online Grocery</st></em><st c="15434"> application, which has less scope </st><span class="No-Break"><st c="15469">and complexity.</st></span></p>
			<p><st c="15484">Next, we’ll deploy our applications that utilize both the standard and asynchronous Peewee ORM for their </st><span class="No-Break"><st c="15590">repository layers.</st></span></p>
			<h1 id="_idParaDest-305"><a id="_idTextAnchor312"/><st c="15608">Running the application on Gunicorn and uWSGI</st></h1>
			<p><st c="15654">The main </st><a id="_idIndexMarker1037"/><st c="15664">reason why Flask applications start by running the </st><strong class="source-inline"><st c="15715">flask run</st></strong><st c="15724"> command or by calling </st><strong class="source-inline"><st c="15747">app.run()</st></strong><st c="15756"> in </st><strong class="source-inline"><st c="15760">main.py</st></strong><st c="15767"> during </st><a id="_idIndexMarker1038"/><st c="15775">development is because of the built-in WSGI server that the </st><strong class="source-inline"><st c="15835">werkzeug</st></strong><st c="15843"> module has. </st><st c="15856">However, there are limitations that this server possesses, such as its inability to respond to more requests from clients without slowing down </st><a id="_idIndexMarker1039"/><st c="15999">and its incapability to maximize </st><a id="_idIndexMarker1040"/><st c="16032">the resources of the production server. </st><st c="16072">Moreover, the built-in server has several vulnerabilities, which pose security risks. </st><st c="16158">For </st><a id="_idIndexMarker1041"/><st c="16162">standard Flask applications, it is best to use another WSGI server </st><a id="_idIndexMarker1042"/><st c="16229">for production, such as </st><strong class="bold"><st c="16253">Gunicorn</st></strong> <span class="No-Break"><st c="16261">or </st></span><span class="No-Break"><strong class="bold"><st c="16265">uWSGI</st></strong></span><span class="No-Break"><st c="16270">.</st></span></p>
			<p><st c="16271">Let’s start by deploying our application to the </st><span class="No-Break"><em class="italic"><st c="16320">Gunicorn</st></em></span><span class="No-Break"><st c="16328"> server.</st></span></p>
			<h2 id="_idParaDest-306"><a id="_idTextAnchor313"/><st c="16336">Using the Gunicorn server</st></h2>
			<p><strong class="bold"><st c="16362">Gunicorn</st></strong><st c="16371"> is the most common WSGI-based HTTP server that runs on a POSIX environment. </st><st c="16448">If Windows is the environment that’s used for development, it will be a requirement </st><a id="_idIndexMarker1043"/><st c="16532">to deploy our application to a UNIX-based server with the installed Gunicorn server. </st><st c="16617">In our case, we will use WSL on Windows PowerShell to access the Ubuntu running on Windows and deploy our </st><strong class="source-inline"><st c="16723">ch11-guni</st></strong><st c="16732"> application. </st><st c="16746">But first, we must install the </st><strong class="source-inline"><st c="16777">gunicorn</st></strong><st c="16785"> module in the application’s virtual environment using the following </st><span class="No-Break"><strong class="source-inline"><st c="16854">pip</st></strong></span><span class="No-Break"><st c="16857"> command:</st></span></p>
			<pre class="console"><st c="16866">
pip install gunicorn</st></pre>			<p><st c="16887">Then, run the </st><strong class="source-inline"><st c="16902">gunicorn</st></strong><st c="16910"> command with the module name and the </st><strong class="source-inline"><st c="16948">app</st></strong><st c="16951"> instance </st><span class="No-Break"><st c="16961">in </st></span><span class="No-Break"><strong class="source-inline"><st c="16964">{module}</st></strong></span><strong class="source-inline"><st c="16972">
:{flask_app}</st></strong><st c="16985"> format, the binding host address, and the port. </st><st c="17034">The following is the complete command to run a standard Flask application on the Gunicorn server with a </st><span class="No-Break"><st c="17138">single worker:</st></span></p>
			<pre class="console"><st c="17152">
gunicorn --bind 127.0.0.1:8000 main:app</st></pre>			<p><span class="No-Break"><em class="italic"><st c="17192">Figure 11</st></em></span><em class="italic"><st c="17202">.1</st></em><st c="17204"> shows the server log after successfully running the given command with the default </st><span class="No-Break"><st c="17288">single worker:</st></span></p>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/B19383_11_001.jpg" alt="Figure 11.1 – Server log after starting the Gunicorn server"/><st c="17302"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="17670">Figure 11.1 – Server log after starting the Gunicorn server</st></p>
			<p><st c="17729">A </st><em class="italic"><st c="17732">Gunicorn</st></em><st c="17740"> worker is a Python process that manages one HTTP request-response transaction at a time. </st><st c="17830">A default Gunicorn server has one worker process running in the background. </st><st c="17906">Logically, the more workers that are spawned to manage the requests and responses, the better the application’s performance. </st><st c="18031">However, for Gunicorn, the number of </st><a id="_idIndexMarker1044"/><st c="18068">workers depends on the count of CPU processors on the server machine and is derived using the </st><strong class="source-inline"><st c="18162">(2*CPU)+1</st></strong><st c="18171"> formula. </st><st c="18181">These child processes will manage HTTP requests simultaneously, utilizing the maximum level of resources that the hardware can provide. </st><st c="18317">One of the advantages of Gunicorn is its capability to leverage the resources efficiently to manage the </st><span class="No-Break"><st c="18421">runtime performance:</st></span></p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B19383_11_002.jpg" alt="Figure 11.2 – The CPU utilization dashboard of a Windows system"/><st c="18441"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="18863">Figure 11.2 – The CPU utilization dashboard of a Windows system</st></p>
			<p><span class="No-Break"><em class="italic"><st c="18926">Figure 11</st></em></span><em class="italic"><st c="18936">.2</st></em><st c="18938"> shows that our production server machine has </st><strong class="source-inline"><st c="18984">4</st></strong><st c="18985"> CPU cores, which means that the acceptable number of workers that our Gunicorn server can utilize is </st><strong class="source-inline"><st c="19087">9</st></strong><st c="19088">. Thus, the following command runs a Gunicorn server with </st><span class="No-Break"><strong class="source-inline"><st c="19146">9</st></strong></span><span class="No-Break"><st c="19147"> workers:</st></span></p>
			<pre class="console"><st c="19156">
gunicorn --bind 127.0.0.1:8000 main:app --workers 9</st></pre>			<p><st c="19208">Adding the </st><strong class="source-inline"><st c="19220">--workers</st></strong><st c="19229"> setting in the command statement allows us to include the appropriate worker count in the HTTP </st><span class="No-Break"><st c="19325">request processing.</st></span></p>
			<p><st c="19344">Adding workers to the Gunicorn server that does not improve the total CPU-bound performance of the application is a waste of resources. </st><st c="19481">A remedy is to add more threads to a worker rather than add </st><span class="No-Break"><st c="19541">unhelpful workers.</st></span></p>
			<p><st c="19559">Workers or processes consume more memory space. </st><st c="19608">Additionally, no two workers can share memory space, unlike with threads. </st><st c="19682">A </st><em class="italic"><st c="19684">thread</st></em><st c="19690"> consumes less memory space since it is more lightweight than a worker. </st><st c="19762">To experience the best server performance, each worker must spawn at least </st><strong class="source-inline"><st c="19837">2</st></strong><st c="19838"> threads that will work concurrently on HTTP requests and responses. </st><st c="19907">So, running the following Gunicorn command can start a server with </st><strong class="source-inline"><st c="19974">1</st></strong><st c="19975"> worker with </st><span class="No-Break"><strong class="source-inline"><st c="19988">2</st></strong></span><span class="No-Break"><st c="19989"> threads:</st></span></p>
			<pre class="console"><st c="19998">
gunicorn --bind 127.0.0.1:8000 main:app --workers 1 --threads 2</st></pre>			<p><st c="20062">The </st><strong class="source-inline"><st c="20067">--threads</st></strong><st c="20076"> setting allows us to add at least </st><strong class="source-inline"><st c="20111">2</st></strong><st c="20112"> threads </st><span class="No-Break"><st c="20121">per worker.</st></span></p>
			<p><st c="20132">Although setting threads in a worker connotes concurrency, the threads are still within the bounds </st><a id="_idIndexMarker1045"/><st c="20232">of their workers, which run synchronously. </st><st c="20275">So, the blocking limitation of the workers hinders threads from performing their actual concurrent performance. </st><st c="20387">However, having threads can manage the overhead of handling I/O transactions compared to the pure worker setup because the concurrency that’s applied to the I/O blockings will not consume </st><span class="No-Break"><st c="20575">more space.</st></span></p>
			<p><st c="20586">The server log shown in </st><span class="No-Break"><em class="italic"><st c="20611">Figure 11</st></em></span><em class="italic"><st c="20620">.3</st></em><st c="20622"> depicts the change from the </st><strong class="source-inline"><st c="20651">sync</st></strong><st c="20655"> worker to </st><strong class="source-inline"><st c="20666">gthread</st></strong><st c="20673"> since all spawned Python threads become gthreads when used in the </st><span class="No-Break"><st c="20740">Gunicorn platform:</st></span></p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/B19383_11_003.jpg" alt="Figure 11.3 – Server log after running Gunicorn with threads"/><st c="20758"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="21045">Figure 11.3 – Server log after running Gunicorn with threads</st></p>
			<p><st c="21105">Now, when the number of features that require I/O transactions increases, Gunicorn, along with workers and servers, will not help speed up the processing of HTTP requests and responses. </st><st c="21292">Another solution is to add </st><em class="italic"><st c="21319">pseudo-threads</st></em><st c="21333"> or </st><em class="italic"><st c="21337">green-threads</st></em><st c="21350">, through the </st><strong class="source-inline"><st c="21364">eventlet</st></strong><st c="21372"> and </st><strong class="source-inline"><st c="21377">gevent</st></strong><st c="21383"> libraries, to the Gunicorn server as worker classes. </st><st c="21437">Both libraries use asynchronous utilities and </st><strong class="source-inline"><st c="21483">greenlet</st></strong><st c="21491"> threads to interface and execute the standard Flask components, especially I/O transactions, for more efficiency. </st><st c="21606">They use the </st><em class="italic"><st c="21619">monkey-patching</st></em><st c="21634"> mechanism to </st><a id="_idIndexMarker1046"/><st c="21648">replace the standard or blocking components with their </st><span class="No-Break"><st c="21703">asynchronous counterparts.</st></span></p>
			<p><st c="21729">To deploy our application to Gunicorn with the </st><strong class="source-inline"><st c="21777">eventlet</st></strong><st c="21785"> library, install the </st><strong class="source-inline"><st c="21807">greenlet</st></strong><st c="21815"> module first using the following </st><strong class="source-inline"><st c="21849">pip</st></strong><st c="21852"> command, followed </st><span class="No-Break"><st c="21871">by </st></span><span class="No-Break"><strong class="source-inline"><st c="21874">eventlet</st></strong></span><span class="No-Break"><st c="21882">:</st></span></p>
			<pre class="console"><st c="21884">
pip install greenlet eventlet</st></pre>			<p><st c="21914">For </st><strong class="source-inline"><st c="21919">psycopg2</st></strong><st c="21927"> or database-related monkey-patching, install the </st><strong class="source-inline"><st c="21977">psycogreen</st></strong><st c="21987"> module with the following </st><span class="No-Break"><strong class="source-inline"><st c="22014">pip</st></strong></span><span class="No-Break"><st c="22017"> command:</st></span></p>
			<pre class="console"><st c="22026">
pip install psycogreen</st></pre>			<p><st c="22049">Then, apply </st><a id="_idIndexMarker1047"/><st c="22062">monkey-patching for Peewee and </st><strong class="source-inline"><st c="22093">psycopg2</st></strong><st c="22101"> transactions by calling the </st><strong class="source-inline"><st c="22130">patch_psycopg()</st></strong><st c="22145"> function of the </st><strong class="source-inline"><st c="22162">psycogreen.eventlet</st></strong><st c="22181"> module in the uppermost portion of the </st><strong class="source-inline"><st c="22221">main.py</st></strong><st c="22228"> file before calling the </st><strong class="source-inline"><st c="22253">create_app()</st></strong><st c="22265"> method. </st><st c="22274">The following snippet shows the portion of the </st><strong class="source-inline"><st c="22321">main.py</st></strong><st c="22328"> file with the </st><span class="No-Break"><strong class="source-inline"><st c="22343">psycogreen</st></strong></span><span class="No-Break"><st c="22353"> setup:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="22360">import psycogreen.eventlet</st></strong>
<strong class="bold"><st c="22387">psycogreen.eventlet.patch_psycopg()</st></strong><st c="22423">
from app import create_app
from app.models.config import database
app = create_app('../config_dev.toml')
… … … … … …</st></pre>			<p><st c="22540">The </st><strong class="source-inline"><st c="22545">psycogreen</st></strong><st c="22555"> module provides a blocking interface or wrapper for </st><strong class="source-inline"><st c="22608">psycopg2 </st></strong><st c="22617">transactions to interact with coroutines or asynchronous components of the </st><strong class="source-inline"><st c="22692">eventlet</st></strong><st c="22700"> worker without altering the standard </st><span class="No-Break"><st c="22738">Peewee codes.</st></span></p>
			<p><st c="22751">To deploy our </st><em class="italic"><st c="22766">Online Grocery</st></em><st c="22780"> application (</st><strong class="source-inline"><st c="22794">ch11-guni-eventlet</st></strong><st c="22813">) to the Gunicorn server that uses </st><strong class="source-inline"><st c="22849">1</st></strong> <strong class="source-inline"><st c="22850">eventlet</st></strong><st c="22858"> worker with </st><strong class="source-inline"><st c="22871">2</st></strong><st c="22872"> threads, run the </st><span class="No-Break"><st c="22890">following command:</st></span></p>
			<pre class="console"><st c="22908">
gunicorn --bind 127.0.0.1:8000 main:app --workers 1 --worker-class  eventlet --threads 2</st></pre>			<p><span class="No-Break"><em class="italic"><st c="22996">Figure 11</st></em></span><em class="italic"><st c="23006">.4</st></em><st c="23008"> shows the server log after running the </st><span class="No-Break"><st c="23048">Gunicorn server:</st></span></p>
			<div>
				<div id="_idContainer117" class="IMG---Figure">
					<img src="image/B19383_11_004.jpg" alt="Figure 11.4 – Server log after starting the Gunicorn server using the eventlet worker"/><st c="23064"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="23522">Figure 11.4 – Server log after starting the Gunicorn server using the eventlet worker</st></p>
			<p><st c="23607">The log depicts </st><a id="_idIndexMarker1048"/><st c="23624">that the worker that was used by the server is an </st><strong class="source-inline"><st c="23674">eventlet</st></strong> <span class="No-Break"><st c="23682">worker type.</st></span></p>
			<p><st c="23695">The </st><strong class="source-inline"><st c="23700">eventlet</st></strong><st c="23708"> library provides </st><a id="_idIndexMarker1049"/><st c="23726">concurrent utilities that run standard or non-async Flask components asynchronously using task switching, a shift from sync to async tasks internally without explicitly </st><span class="No-Break"><st c="23895">programming it.</st></span></p>
			<p><st c="23910">Aside from </st><strong class="source-inline"><st c="23922">eventlet</st></strong><st c="23930">, </st><strong class="source-inline"><st c="23932">gevent</st></strong><st c="23938"> can also manage concurrent requests from I/O-bound tasks of the applications. </st><st c="24017">Like </st><strong class="source-inline"><st c="24022">eventlet</st></strong><st c="24030">, </st><strong class="source-inline"><st c="24032">gevent</st></strong><st c="24038"> is a coroutine-based library but relies more on its stack of </st><strong class="source-inline"><st c="24100">greenlet</st></strong><st c="24108"> objects and their event loops. </st><st c="24140">The </st><strong class="source-inline"><st c="24144">gevent</st></strong><st c="24150"> library’s </st><strong class="source-inline"><st c="24161">greenlet</st></strong><st c="24169"> is a lightweight and powerful thread that executes in a cooperative scheduling fashion. </st><st c="24258">To operate a </st><strong class="source-inline"><st c="24271">gevent</st></strong><st c="24277"> worker in the Gunicorn server, install the </st><strong class="source-inline"><st c="24321">greenlet</st></strong><st c="24329">, </st><strong class="source-inline"><st c="24331">eventlet</st></strong><st c="24339">, and </st><strong class="source-inline"><st c="24345">gevent</st></strong><st c="24351"> modules using the following </st><span class="No-Break"><strong class="source-inline"><st c="24380">pip</st></strong></span><span class="No-Break"><st c="24383"> command:</st></span></p>
			<pre class="console"><st c="24392">
pip install greenlet eventlet gevent</st></pre>			<p><st c="24429">Also, install </st><strong class="source-inline"><st c="24444">psycogreen</st></strong><st c="24454"> to monkey-patch the database-related transactions of the application using its </st><strong class="source-inline"><st c="24534">gevent</st></strong> <strong class="source-inline"><st c="24540">patch_psycopg()</st></strong><st c="24556">. The following snippet shows a portion of the </st><strong class="source-inline"><st c="24603">main.py</st></strong><st c="24610"> file of the </st><strong class="source-inline"><st c="24623">ch11-guni-gevent</st></strong><st c="24639"> project, a version of our </st><em class="italic"><st c="24666">Online Grocery</st></em><st c="24680"> application that needs to run on Gunicorn with </st><span class="No-Break"><strong class="source-inline"><st c="24728">gevent</st></strong></span><span class="No-Break"><st c="24734"> workers:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="24743">import gevent.monkey</st></strong>
<strong class="bold"><st c="24764">gevent.monkey.patch_all()</st></strong>
<strong class="bold"><st c="24790">import psycogreen.gevent</st></strong>
<strong class="bold"><st c="24815">psycogreen.gevent.patch_psycopg()</st></strong><st c="24849">
import gevent
from app import create_app
… … … … … …
app = create_app('../config_dev.toml')
… … … … … …</st></pre>			<p><st c="24953">In </st><strong class="source-inline"><st c="24957">gevent</st></strong><st c="24963">, the main module must call its </st><strong class="source-inline"><st c="24995">patch_all()</st></strong><st c="25006"> method from the </st><strong class="source-inline"><st c="25023">gevent.monkey</st></strong><st c="25036"> module, above anything else, to explicitly interface all the events at runtime to run asynchronously like coroutines. </st><st c="25155">Afterward, it needs to call the </st><strong class="source-inline"><st c="25187">psycogreen</st></strong><st c="25197"> module’s </st><strong class="source-inline"><st c="25207">patch_psycopg()</st></strong><st c="25222">, but this time under the </st><span class="No-Break"><strong class="source-inline"><st c="25248">gevent</st></strong></span><span class="No-Break"><st c="25254"> sub-module.</st></span></p>
			<p><st c="25266">To start the </st><a id="_idIndexMarker1050"/><st c="25280">Gunicorn server using the </st><strong class="source-inline"><st c="25306">2</st></strong> <strong class="source-inline"><st c="25307">gevent</st></strong><st c="25313"> workers with </st><strong class="source-inline"><st c="25327">2</st></strong><st c="25328"> thread utilization each, run the </st><span class="No-Break"><st c="25362">following command:</st></span></p>
			<pre class="console"><st c="25380">
gunicorn --bind 127.0.0.1:8000 main:app --workers 2 --worker-class gevent --threads 2</st></pre>			<p><span class="No-Break"><em class="italic"><st c="25466">Figure 11</st></em></span><em class="italic"><st c="25476">.5</st></em><st c="25478"> shows the server log after starting up the </st><span class="No-Break"><st c="25522">Gunicorn server:</st></span></p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="image/B19383_11_005.jpg" alt="Figure 11.5 – Server log after starting the Gunicorn server using the gevent workers"/><st c="25538"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="26061">Figure 11.5 – Server log after starting the Gunicorn server using the gevent workers</st></p>
			<p><st c="26145">The worker used by the Gunicorn is now a </st><strong class="source-inline"><st c="26187">gevent</st></strong><st c="26193"> worker, as depicted in the preceding </st><span class="No-Break"><st c="26231">server log.</st></span></p>
			<p><st c="26242">Now, let’s use uWSGI as our production </st><span class="No-Break"><st c="26282">application server.</st></span></p>
			<h2 id="_idParaDest-307"><a id="_idTextAnchor314"/><st c="26301">Using uWSGI</st></h2>
			<p><strong class="bold"><st c="26313">uWSGI</st></strong><st c="26319"> is a highly </st><a id="_idIndexMarker1051"/><st c="26332">configurable, fast, and flexible server that can run any WSGI-based application. </st><st c="26413">This server container can only operate in a POSIX-based operating system such as Gunicorn. </st><st c="26504">To utilize uWSGI, install the </st><strong class="source-inline"><st c="26534">pyuwsgi</st></strong><st c="26541"> module using the following </st><span class="No-Break"><strong class="source-inline"><st c="26569">pip</st></strong></span><span class="No-Break"><st c="26572"> command:</st></span></p>
			<pre class="console"><st c="26581">
pip install pyuwsgi</st></pre>			<p><st c="26601">uWSGI has several required and optional setting options. </st><st c="26659">One is the </st><strong class="source-inline"><st c="26670">-w</st></strong><st c="26672"> setting, which requires the WSGI module that the server needs to run. </st><st c="26743">The </st><strong class="source-inline"><st c="26747">-p</st></strong><st c="26749"> setting indicates the number of workers or processes that can manage HTTP requests. </st><st c="26834">The </st><strong class="source-inline"><st c="26838">--http</st></strong><st c="26844"> setting denotes the address and the port the server will be listening to. </st><st c="26919">The </st><strong class="source-inline"><st c="26923">--enable-threads</st></strong><st c="26939"> setting allows the server to utilize Python threads for </st><span class="No-Break"><st c="26996">background processes.</st></span></p>
			<p><st c="27017">To deploy our </st><em class="italic"><st c="27032">Online Grocery</st></em><st c="27046"> application (</st><strong class="source-inline"><st c="27060">ch11-uwsgi</st></strong><st c="27071">) to a uWSGI server with </st><strong class="source-inline"><st c="27097">4</st></strong><st c="27098"> workers and background Python threads, run the </st><span class="No-Break"><st c="27146">following command:</st></span></p>
			<pre class="console"><st c="27164">
uwsgi --http 127.0.0.1:8000 --master -p 4 -w main:app --enable-threads</st></pre>			<p><st c="27235">Here, </st><strong class="source-inline"><st c="27242">--master</st></strong><st c="27250"> is an optional setting that allows the master process and its workers to shut down and </st><span class="No-Break"><st c="27338">restart gracefully.</st></span></p>
			<p><st c="27357">Unlike Gunicorn, uWSGI generates a long server log mentioning the several manageable configuration </st><a id="_idIndexMarker1052"/><st c="27457">details it consists of to improve the application’s performance. </st><span class="No-Break"><em class="italic"><st c="27522">Figure 11</st></em></span><em class="italic"><st c="27531">.6</st></em><st c="27533"> shows the server log of uWSGI after </st><span class="No-Break"><st c="27570">its startup:</st></span></p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/B19383_11_006.jpg" alt="Figure 11.6 – Server log after starting the uWSGI server with 4 workers"/><st c="27582"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="29113">Figure 11.6 – Server log after starting the uWSGI server with 4 workers</st></p>
			<p><st c="29184">Shutting down the uWSGI server with the </st><strong class="source-inline"><st c="29225">--master</st></strong><st c="29233"> setting allows us to send the master process and its workers the </st><strong class="source-inline"><st c="29299">SIGTERM</st></strong><st c="29306"> signal to impose graceful shutdown, restart, or reload, which is better than the abrupt kill process. </st><span class="No-Break"><em class="italic"><st c="29409">Figure 11</st></em></span><em class="italic"><st c="29418">.7</st></em><st c="29420"> shows the advantage of having the </st><strong class="source-inline"><st c="29455">--master</st></strong><st c="29463"> setting in </st><span class="No-Break"><st c="29475">the command:</st></span></p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/B19383_11_007.jpg" alt="Figure 11.7 – Server log after shutting down the uWSGI server with the --master setting"/><st c="29487"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="29792">Figure 11.7 – Server log after shutting down the uWSGI server with the --master setting</st></p>
			<p><st c="29879">Managing uWSGI is </st><a id="_idIndexMarker1053"/><st c="29898">complex compared to the easy-to-configure Gunicorn. </st><st c="29950">So far, Gunicorn is still the recommended server to use when deploying standard </st><span class="No-Break"><st c="30030">Flask applications.</st></span></p>
			<p><st c="30049">Now, let’s deploy </st><em class="italic"><st c="30068">Flask[async]</st></em><st c="30080"> to an ASGI server </st><span class="No-Break"><st c="30099">called </st></span><span class="No-Break"><em class="italic"><st c="30106">Uvicorn</st></em></span><span class="No-Break"><st c="30113">.</st></span></p>
			<h1 id="_idParaDest-308"><a id="_idTextAnchor315"/><st c="30114">Deploying the application to Uvicorn</st></h1>
			<p><strong class="bold"><st c="30151">Uvicorn</st></strong><st c="30159"> is a popular </st><a id="_idIndexMarker1054"/><st c="30173">ASGI-based HTTP server that’s used by the Starlette </st><a id="_idIndexMarker1055"/><st c="30225">and FastAPI frameworks. </st><st c="30249">But Uvicorn </st><a id="_idIndexMarker1056"/><st c="30261">remains an easy-to-use ASGI development server. </st><st c="30309">It is </st><a id="_idIndexMarker1057"/><st c="30315">still ideal to deploy </st><strong class="bold"><st c="30337">Flask[async]</st></strong><st c="30349"> or </st><strong class="bold"><st c="30353">FastAPI</st></strong><st c="30360"> applications </st><a id="_idIndexMarker1058"/><st c="30374">to the production server using Gunicorn with </st><strong class="source-inline"><st c="30419">uvicorn.workers.UvicornWorker</st></strong><st c="30448"> as its </st><span class="No-Break"><st c="30456">HTTP server.</st></span></p>
			<p><st c="30468">Even though Gunicorn is a WSGI-based server, it can support running Flask applications in standard and async mode through its </st><strong class="source-inline"><st c="30595">--worker-class</st></strong><st c="30609"> setting. </st><st c="30619">For Flask[async] applications, Gunicorn can utilize the </st><strong class="source-inline"><st c="30675">aiohttp</st></strong><st c="30682"> or </st><strong class="source-inline"><st c="30686">uvicorn</st></strong><st c="30693"> worker </st><span class="No-Break"><st c="30701">class types.</st></span></p>
			<p><st c="30713">Our async </st><em class="italic"><st c="30724">Online Grocery</st></em><st c="30738"> application (</st><strong class="source-inline"><st c="30752">ch11-async</st></strong><st c="30763">) uses Gunicorn with a </st><strong class="source-inline"><st c="30787">uvicorn</st></strong><st c="30794"> worker as its deployment platform. </st><st c="30830">Before applying the worker type, install the </st><strong class="source-inline"><st c="30875">uvicorn</st></strong><st c="30882"> module first by running the following </st><span class="No-Break"><strong class="source-inline"><st c="30921">pip</st></strong></span><span class="No-Break"><st c="30924"> command:</st></span></p>
			<pre class="console"><st c="30933">
pip install uvicorn</st></pre>			<p><st c="30953">Then, import </st><strong class="source-inline"><st c="30967">WsgiToAsgi</st></strong><st c="30977"> from the </st><strong class="source-inline"><st c="30987">uvicorn</st></strong><st c="30994"> module’s </st><strong class="source-inline"><st c="31004">asgiref.wsgi</st></strong><st c="31016"> module to wrap the Flask app instance. </st><st c="31056">The following snippet shows how to transform a WSGI application into an </st><span class="No-Break"><st c="31128">ASGI type:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="31138">from asgiref.wsgi import WsgiToAsgi</st></strong><st c="31174">
from app import create_app
app = create_app('../config_dev.toml')
</st><strong class="bold"><st c="31241">asgi_app = WsgiToAsgi(app)</st></strong></pre>			<p><st c="31267">The Gunicorn </st><a id="_idIndexMarker1059"/><st c="31281">server will run </st><strong class="source-inline"><st c="31297">asgi_app</st></strong><st c="31305"> instead </st><a id="_idIndexMarker1060"/><st c="31314">of the original Flask </st><strong class="source-inline"><st c="31336">app</st></strong><st c="31339">. To start Gunicorn using two Uvicorn workers with two threads each, run the </st><span class="No-Break"><st c="31416">following command:</st></span></p>
			<pre class="console"><st c="31434">
gunicorn main:asgi_app --bind 0.0.0.0:8000 --workers 2 --worker-class uvicorn.workers.UvicornWorker --threads 2</st></pre>			<p><st c="31546">Here, </st><strong class="source-inline"><st c="31553">UvicornWorker</st></strong><st c="31566">, a Gunicorn-compatible worker class from the </st><strong class="source-inline"><st c="31612">uvicorn</st></strong><st c="31619"> library, provides an interface to an ASGI-based application so that Gunicorn can communicate with all the HTTP requests from the coroutines of the applications and eventually handle </st><span class="No-Break"><st c="31802">those requests.</st></span></p>
			<p><span class="No-Break"><em class="italic"><st c="31817">Figure 11</st></em></span><em class="italic"><st c="31827">.8</st></em><st c="31829"> shows the server log after running the </st><span class="No-Break"><st c="31869">Gunicorn server:</st></span></p>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="image/B19383_11_008.jpg" alt="Figure 11.8 – Server log after starting the Gunicorn server using UvicornWorker"/><st c="31885"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="33005">Figure 11.8 – Server log after starting the Gunicorn server using UvicornWorker</st></p>
			<p><st c="33084">The server log depicts the use of </st><strong class="source-inline"><st c="33119">uvicorn.workers.UvicornWorker</st></strong><st c="33148"> as the Gunicorn worker, and it also shows the “</st><em class="italic"><st c="33196">ASGI ‘lifespan’ protocol appears unsupported.</st></em><st c="33242">” log message, which means Flask does not yet support ASGI with the lifespan </st><a id="_idIndexMarker1061"/><st c="33320">protocol used to manage server startup </st><a id="_idIndexMarker1062"/><span class="No-Break"><st c="33359">and shutdown.</st></span></p>
			<p><st c="33372">The Apache HTTP Server, a popular production server for most PHP applications, can also host and run standard Flask applications. </st><st c="33503">So, let’s explore the process of migrating our applications to the </st><em class="italic"><st c="33570">Apache </st></em><span class="No-Break"><em class="italic"><st c="33577">HTTP Server</st></em></span><span class="No-Break"><st c="33588">.</st></span></p>
			<h1 id="_idParaDest-309"><a id="_idTextAnchor316"/><st c="33589">Deploying the application on the Apache HTTP Server</st></h1>
			<p><strong class="bold"><st c="33641">Apache HTTP Server</st></strong><st c="33660"> is an </st><a id="_idIndexMarker1063"/><st c="33667">open source server under the Apache </st><a id="_idIndexMarker1064"/><st c="33703">projects that can </st><a id="_idIndexMarker1065"/><st c="33721">run on Windows and UNIX-based platforms to provide an efficient, simple, and flexible HTTP server for </st><span class="No-Break"><st c="33823">various applications.</st></span></p>
			<p><st c="33844">Before anything else, download the latest server from </st><a href="https://httpd.apache.org/download.cgi"><st c="33899">https://httpd.apache.org/download.cgi</st></a><st c="33936"> and unzip the file to the production server’s installation directory. </st><st c="34007">Then, download the latest </st><em class="italic"><st c="34033">Microsoft Visual C++ Redistributable</st></em><st c="34069"> from </st><a href="https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist"><st c="34075">https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist</st></a><st c="34147">, install it, and run the server through the </st><strong class="source-inline"><st c="34192">httpd.exe</st></strong><st c="34201"> file of its </st><strong class="source-inline"><st c="34214">/</st></strong><span class="No-Break"><strong class="source-inline"><st c="34215">bin</st></strong></span><span class="No-Break"><st c="34218"> folder.</st></span></p>
			<p><st c="34226">After the installation, follow these steps to deploy our application to the Apache </st><span class="No-Break"><st c="34310">HTTP Server:</st></span></p>
			<ol>
				<li><st c="34322">Build your Flask application, as we did with our </st><em class="italic"><st c="34372">Online Grocery</st></em><st c="34386"> application, run it using the built-in WSGI server, and refine the components using </st><span class="No-Break"><strong class="source-inline"><st c="34471">pytest</st></strong></span><span class="No-Break"><st c="34477"> testing.</st></span></li>
				<li><st c="34486">Next, install the </st><strong class="source-inline"><st c="34505">mod_wsgi</st></strong><st c="34513"> module, which enables the Apache HTTP Server’s support to run WSGI applications. </st><st c="34595">Install the module using the following </st><span class="No-Break"><strong class="source-inline"><st c="34634">pip</st></strong></span><span class="No-Break"><st c="34637"> command:</st></span><pre class="source-code"><st c="34646">
pip install mod_wsgi</st></pre></li>				<li><st c="34667">If the installation encounters an error similar to what’s shown in the error log in </st><span class="No-Break"><em class="italic"><st c="34752">Figure 11</st></em></span><em class="italic"><st c="34761">.9</st></em><st c="34763">, run the </st><strong class="source-inline"><st c="34773">set</st></strong><st c="34776"> command to assign the </st><strong class="bold"><st c="34799">Apache HTTP Server’s installation directory</st></strong><st c="34842"> to the </st><strong class="source-inline"><st c="34850">MOD_WSGI_APACHE_ROOTDIR</st></strong> <span class="No-Break"><st c="34873">environment variable:</st></span><pre class="source-code"><st c="34895">
set "MOD_WSGI_APACHE_ROOTDIR= C:/.../Server/Apache24"</st></pre></li>				<li><st c="34949">Apply </st><em class="italic"><st c="34956">forward slashes</st></em><st c="34971"> (</st><strong class="source-inline"><st c="34973">/</st></strong><st c="34974">) to create the directory path. </st><st c="35006">Afterward, re-install the </st><span class="No-Break"><strong class="source-inline"><st c="35032">mod_wsgi</st></strong></span><span class="No-Break"><st c="35040"> module:</st></span></li>
			</ol>
			<div>
				<div id="_idContainer122" class="IMG---Figure">
					<img src="image/B19383_11_009.jpg" alt="Figure 11.9 – No MOD_WSGI_APACHE_ROOTDIR error"/><st c="35048"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="35501">Figure 11.9 – No MOD_WSGI_APACHE_ROOTDIR error</st></p>
			<ol>
				<li value="5"><st c="35547">Again, if the </st><a id="_idIndexMarker1066"/><st c="35562">re-installation </st><a id="_idIndexMarker1067"/><st c="35578">of </st><strong class="source-inline"><st c="35581">mod_wsgi</st></strong><st c="35589"> gives another </st><a id="_idIndexMarker1068"/><st c="35604">error stating the required </st><strong class="bold"><st c="35631">Microsoft Visual C++ tool</st></strong><st c="35656">, do </st><span class="No-Break"><st c="35661">the following:</st></span><ol><li class="upper-roman"><st c="35675">Download </st><strong class="source-inline"><st c="35685">VisualStudioSetup.exe</st></strong> <span class="No-Break"><st c="35706">from</st></span><span class="No-Break"> </span><a href="https://visualstudio.microsoft.com/downloads"><span class="No-Break"><st c="35711">https://visualstudio.microsoft.com/downloads</st></span></a><span class="No-Break"><st c="35756">.</st></span></li><li class="upper-roman"><st c="35757">Run the </st><strong class="source-inline"><st c="35766">VisualStudioSetup.exe</st></strong><st c="35787"> file; a menu dashboard will appear, as shown in </st><span class="No-Break"><em class="italic"><st c="35836">Figure 11</st></em></span><span class="No-Break"><em class="italic"><st c="35845">.10</st></em></span><span class="No-Break"><st c="35848">.</st></span></li><li class="upper-roman"><st c="35849">Click the </st><strong class="bold"><st c="35860">Desktop Development with C++</st></strong><st c="35888"> menu option to show the installation details on the right-hand side of </st><span class="No-Break"><st c="35960">the dashboard:</st></span></li></ol></li>
			</ol>
			<div>
				<div id="_idContainer123" class="IMG---Figure">
					<img src="image/B19383_11_010.jpg" alt="Figure 11.10 – Microsoft Visual Studio Library dashboard"/><st c="35974"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="37920">Figure 11.10 – Microsoft Visual Studio Library dashboard</st></p>
			<p class="list-inset"><st c="37976">This </st><a id="_idIndexMarker1069"/><st c="37982">installation </st><a id="_idIndexMarker1070"/><st c="37995">is different from the previous Microsoft Visual C++ Redistributable </st><span class="No-Break"><st c="38063">installation procedure.</st></span></p>
			<ol>
				<li value="6"><st c="38086">Now, select </st><strong class="bold"><st c="38099">C++ build tools</st></strong><st c="38114"> from the left-hand side menu and choose the </st><strong class="bold"><st c="38159">Windows 10 SDK</st></strong><st c="38173"> or </st><strong class="bold"><st c="38177">Windows 11 SDK</st></strong><st c="38191"> and the </st><strong class="bold"><st c="38200">MSVC 142 ***</st></strong><st c="38212"> options from the list of checkboxes. </st><st c="38250">It is optional to select the other libraries if they are crucial to the </st><span class="No-Break"><strong class="source-inline"><st c="38322">mod_wsgi</st></strong></span><span class="No-Break"><st c="38330"> installation.</st></span></li>
				<li><st c="38344">After choosing the necessary components, click the </st><strong class="bold"><st c="38396">Install</st></strong><st c="38403"> button at the bottom right of </st><span class="No-Break"><st c="38434">the dashboard.</st></span></li>
				<li><st c="38448">After installing </st><strong class="bold"><st c="38466">Microsoft Visual C++ tool</st></strong><st c="38491">, run </st><strong class="source-inline"><st c="38497">pip install mod_wsgi</st></strong><st c="38517"> once more. </st><st c="38529">This time, the </st><strong class="source-inline"><st c="38544">mod_wsgi</st></strong><st c="38552"> installation must </st><span class="No-Break"><st c="38571">proceed successfully.</st></span></li>
				<li><st c="38592">The </st><strong class="source-inline"><st c="38597">mod_wsgi</st></strong><st c="38605"> module needs a configuration file inside the project that the Apache HTTP Server needs to load during startup. </st><st c="38717">This file should be in a separate folder, say </st><strong class="source-inline"><st c="38763">wsgi</st></strong><st c="38767">, and must be in the main project folder. </st><st c="38809">In our </st><strong class="source-inline"><st c="38816">ch11-apache</st></strong><st c="38827"> project, the configuration file is </st><strong class="source-inline"><st c="38863">conf.wsgi</st></strong><st c="38872"> and has been placed in the </st><strong class="source-inline"><st c="38900">wsgi</st></strong><st c="38904"> folder. </st><st c="38913">Be sure to add the </st><strong class="source-inline"><st c="38932">__init__.py</st></strong><st c="38943"> file to this folder too. </st><st c="38969">The following is the content </st><span class="No-Break"><st c="38998">of </st></span><span class="No-Break"><strong class="source-inline"><st c="39001">conf.wsgi</st></strong></span><span class="No-Break"><st c="39010">:</st></span><pre class="source-code"><st c="39012">
import sys
sys.path.insert(0, 'C:/Alibata/Training/ Source/flask/mastering/ch11-apache')
</st><strong class="bold"><st c="39102">from main import app as application</st></strong></pre><p class="list-inset"><st c="39137">The </st><strong class="source-inline"><st c="39142">conf.wsgi</st></strong><st c="39151"> configuration file provides the Apache HTTP Server a channel to access the Flask </st><strong class="source-inline"><st c="39233">app</st></strong><st c="39236"> instance for deployment and execution through the </st><span class="No-Break"><strong class="source-inline"><st c="39287">mod_wsgi</st></strong></span><span class="No-Break"><st c="39295"> module.</st></span></p></li>				<li><st c="39303">Run the </st><strong class="source-inline"><st c="39312">mod_wsgi-express module-config</st></strong><st c="39342"> command to generate the </st><strong class="source-inline"><st c="39367">LoadModule</st></strong><st c="39377"> configuration statements that the Apache HTTP Server needs to integrate </st><a id="_idIndexMarker1071"/><st c="39450">with the project </st><a id="_idIndexMarker1072"/><st c="39467">directory. </st><st c="39478">The following are the </st><strong class="source-inline"><st c="39500">LoadModule</st></strong><st c="39510"> snippets that have been generated for our </st><em class="italic"><st c="39553">Online </st></em><span class="No-Break"><em class="italic"><st c="39560">Grocery</st></em></span><span class="No-Break"><st c="39567"> application:</st></span><pre class="source-code"><st c="39580">
LoadFile "C:/Alibata/Development/Language/ Python/Python311/python311.dll"
LoadModule wsgi_module "C:/Alibata/Training/Source/ flask/mastering/ch11-apache-env/Lib/site-packages/mod_wsgi/server/mod_wsgi.cp311-win_amd64.pyd"
WSGIPythonHome "C:/Alibata/Training/Source/ flask/mastering/ch11-apache-env"</st></pre></li>				<li><st c="39880">Place these </st><strong class="source-inline"><st c="39893">LoadModule</st></strong><st c="39903"> configuration statements in the Apache HTTP Server’s </st><strong class="source-inline"><st c="39957">/conf/http.conf</st></strong><st c="39972"> file, specifically anywhere in the </st><strong class="source-inline"><st c="40008">LoadModule</st></strong><st c="40018"> area under the </st><strong class="bold"><st c="40034">Dynamic Shared Object (DSO) </st></strong><span class="No-Break"><strong class="bold"><st c="40062">Support</st></strong></span><span class="No-Break"> </span><span class="No-Break"><st c="40069">segment.</st></span></li>
				<li><st c="40078">At the end of the </st><strong class="source-inline"><st c="40097">/conf/http.conf</st></strong><st c="40112"> file, import the custom </st><strong class="source-inline"><st c="40137">VirtualHost </st></strong><st c="40149">configuration file of the project. </st><st c="40184">The following is a sample import statement for our </st><em class="italic"><st c="40235">Online </st></em><span class="No-Break"><em class="italic"><st c="40242">Grocery</st></em></span><span class="No-Break"><st c="40249"> application:</st></span><pre class="source-code"><st c="40262">
Include conf/</st><strong class="bold"><st c="40276">ch11_apache.conf</st></strong></pre></li>				<li><st c="40293">Now, create the </st><strong class="source-inline"><st c="40310">VirtualHost</st></strong><st c="40321"> configuration file referenced in </st><em class="italic"><st c="40355">Step 10</st></em><st c="40362">. The following is a sample configuration setup in our </st><span class="No-Break"><strong class="source-inline"><st c="40417">ch11_apache.conf</st></strong></span><span class="No-Break"><st c="40433"> file:</st></span><pre class="source-code"><st c="40439">
&lt;VirtualHost *:</st><strong class="bold"><st c="40455">8080</st></strong><st c="40460">&gt;
    </st><strong class="bold"><st c="40463">ServerName localhost</st></strong><st c="40483">
    WSGIScriptAlias / C</st><strong class="bold"><st c="40503">:/Alibata/Training/Source/ flask/mastering/ch11-apache/wsgi/conf.wsgi</st></strong><st c="40573">
    &lt;Directory C:/Alibata/Training/Source/ flask/mastering/ch11-apache&gt;
        </st><strong class="bold"><st c="40642">Require all granted</st></strong><st c="40661">
    &lt;/Directory&gt;
&lt;/VirtualHost&gt;</st></pre><p class="list-inset"><st c="40689">The </st><strong class="source-inline"><st c="40694">VirtualHost</st></strong><st c="40705"> configuration defines the host address and port that the server </st><a id="_idIndexMarker1073"/><st c="40770">will listen </st><a id="_idIndexMarker1074"/><st c="40782">to so that it can run our application. </st><st c="40821">Its </st><strong class="source-inline"><st c="40825">WSGIScriptAlias</st></strong><st c="40840"> directive gives reference to the </st><strong class="source-inline"><st c="40874">mod_wsgi</st></strong><st c="40882"> configuration file of the application. </st><st c="40922">Moreover, the configuration permits the server to access all files in the </st><span class="No-Break"><strong class="source-inline"><st c="40996">ch11-apache</st></strong></span><span class="No-Break"><st c="41007"> project.</st></span></p></li>				<li><st c="41016">Now, open a terminal and run or restart the server through </st><strong class="source-inline"><st c="41076">httpd.exe</st></strong><st c="41085">. Access all the APIs using </st><strong class="source-inline"><st c="41113">pytest</st></strong><st c="41119"> or </st><span class="No-Break"><st c="41123">API clients.</st></span></li>
			</ol>
			<p><st c="41135">Choosing the Apache HTTP Server as the production server is a common approach in many deployment plans for Flask projects involving the standalone server platform. </st><st c="41300">Although the deployment process is tricky and lengthy, the server’s fast and stable performance, once configured and managed well, makes it a better choice for setting up a significantly effective production environment for </st><span class="No-Break"><st c="41524">Flask applications.</st></span></p>
			<p><st c="41543">There is another way of deploying Flask applications that involves fewer tweaks and configurations </st><a id="_idIndexMarker1075"/><st c="41643">but provides an enterprise-grade production setup: </st><strong class="bold"><st c="41694">the containerized deployment approach</st></strong><st c="41731">. Let’s discuss how to deploy the application to </st><span class="No-Break"><em class="italic"><st c="41780">Docker </st></em></span><span class="No-Break"><st c="41787">containers.</st></span></p>
			<h1 id="_idParaDest-310"><a id="_idTextAnchor317"/><st c="41798">Deploying the application on Docker</st></h1>
			<p><strong class="bold"><st c="41834">Docker</st></strong><st c="41841"> is a </st><a id="_idIndexMarker1076"/><st c="41847">powerful tool for deploying and running applications using software </st><a id="_idIndexMarker1077"/><st c="41915">units instead of hardware setups. </st><st c="41949">Each </st><a id="_idIndexMarker1078"/><st c="41954">independent, lightweight, standalone, and executable </st><a id="_idIndexMarker1079"/><st c="42007">unit, called a </st><strong class="bold"><st c="42022">container</st></strong><st c="42031">, must contain all the files of the applications that it needs to run. </st><st c="42102">Docker is the core container engine that manages all the containers </st><a id="_idIndexMarker1080"/><st c="42170">and packages applications in their appropriate containers. </st><st c="42229">To download Docker, download the </st><strong class="bold"><st c="42262">Docker Desktop</st></strong><st c="42276"> installer that’s appropriate for your system from </st><a href="https://docs.docker.com/engine/install/"><st c="42327">https://docs.docker.com/engine/install/</st></a><st c="42366">. Be sure to enable the Window’s </st><strong class="bold"><st c="42399">Hyper-V service</st></strong><st c="42414"> before </st><a id="_idIndexMarker1081"/><st c="42422">installing Docker. </st><st c="42441">Use your Docker credentials to log in to the application. </st><span class="No-Break"><em class="italic"><st c="42499">Figure 11</st></em></span><em class="italic"><st c="42508">.11</st></em><st c="42511"> shows a sample account dashboard of the Docker </st><span class="No-Break"><st c="42559">Desktop application:</st></span></p>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="image/B19383_11_011.jpg" alt="Figure 11.11 – A Desktop Docker profile"/><st c="42579"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="43320">Figure 11.11 – A Desktop Docker profile</st></p>
			<p><st c="43359">Docker requires some rules when deploying applications to its containers. </st><st c="43434">The first requirement is to create a Dockerfile inside the project’s </st><em class="italic"><st c="43503">main</st></em><st c="43507"> directory, on the same level as the </st><strong class="source-inline"><st c="43544">main.py</st></strong><st c="43551"> and </st><strong class="source-inline"><st c="43556">.toml</st></strong><st c="43561"> configuration files. </st><st c="43583">The following is the content of the </st><strong class="source-inline"><st c="43619">ch11-asgi</st></strong> <span class="No-Break"><st c="43628">file’s Dockerfile:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="43647">FROM python:3.11</st></strong><st c="43664">
WORKDIR /usr/src/ch11-asgi
RUN pip install --upgrade pip
COPY ./requirements.txt /usr/src/ch11-asgi/requirements.txt
RUN pip install -r requirements.txt
COPY . </st><st c="43825">/usr/src/ch11-asgi
EXPOSE 8000
CMD ["gunicorn", "main:asgi_app", "--bind", "0.0.0.0:8000", "--worker-class", "uvicorn.workers.UvicornWorker", "--threads", "2"]</st></pre>			<p><st c="43984">A </st><strong class="bold"><st c="43987">Dockerfile</st></strong><st c="43997"> contains a </st><a id="_idIndexMarker1082"/><st c="44009">series of instructions made by Docker commands that the engine will use to assemble an image. </st><st c="44103">A </st><strong class="bold"><st c="44105">Docker image</st></strong><st c="44117"> is a software </st><a id="_idIndexMarker1083"/><st c="44132">template containing the needed project files, folders, Python modules, server details, and commands to start the Flask server. </st><st c="44259">Docker will run the image to generate a running image instance called </st><span class="No-Break"><st c="44329">a container.</st></span></p>
			<p><st c="44341">The first </st><a id="_idIndexMarker1084"/><st c="44352">line of our Dockerfile is the </st><strong class="source-inline"><st c="44382">FROM</st></strong><st c="44386"> instruction, which </st><a id="_idIndexMarker1085"/><st c="44406">creates a stage or a copy of the base image from the Docker repository. </st><st c="44478">Here are the guidelines to follow when choosing the </st><span class="No-Break"><st c="44530">base image:</st></span></p>
			<ul>
				<li><st c="44541">Ensure it is complete with libraries, tools, filesystem structure, and network structures so that the container will </st><span class="No-Break"><st c="44659">be stable.</st></span></li>
				<li><st c="44669">Ensure it can be updated in terms of operating system plugins </st><span class="No-Break"><st c="44732">and libraries.</st></span></li>
				<li><st c="44746">Ensure it’s equipped with up-to-date and stable Python compilers and </st><span class="No-Break"><st c="44816">core libraries.</st></span></li>
				<li><st c="44831">Ensure it’s loaded with extensions and additional plugins for additional </st><span class="No-Break"><st c="44905">complex integrations.</st></span></li>
				<li><st c="44926">Ensure it has a smaller </st><span class="No-Break"><st c="44951">file size.</st></span></li>
			</ul>
			<p><st c="44961">Choosing the right base image is crucial for the application to avoid problems during </st><span class="No-Break"><st c="45048">production phases.</st></span></p>
			<p><st c="45066">The next instruction is the </st><strong class="source-inline"><st c="45095">WORKDIR</st></strong><st c="45102"> command, which creates and sets the new application’s working directory. </st><st c="45176">The first </st><strong class="source-inline"><st c="45186">RUN</st></strong><st c="45189"> command updates the container’s </st><strong class="source-inline"><st c="45222">pip</st></strong><st c="45225"> command, which will install all the libraries from the </st><strong class="source-inline"><st c="45281">requirements.txt</st></strong><st c="45297"> file copied by the </st><strong class="source-inline"><st c="45317">COPY</st></strong><st c="45321"> command from our local project folder. </st><st c="45361">After installing the modules in the container, the next instruction is to </st><strong class="source-inline"><st c="45435">COPY</st></strong><st c="45439"> all the project files from the local folder to </st><span class="No-Break"><st c="45487">the container.</st></span></p>
			<p><st c="45501">The </st><strong class="source-inline"><st c="45506">EXPOSE</st></strong><st c="45512"> command defines the port the application will listen on. </st><st c="45570">The </st><strong class="source-inline"><st c="45574">CMD </st></strong><st c="45578">command, on the other hand, tells Docker how to start the Gunicorn server with </st><strong class="source-inline"><st c="45657">UvicornWorker</st></strong><st c="45670"> when the </st><span class="No-Break"><st c="45680">container starts.</st></span></p>
			<p><st c="45697">After composing the Dockerfile, open a terminal to run the </st><strong class="source-inline"><st c="45757">docker login</st></strong><st c="45769"> CLI command </st><a id="_idIndexMarker1086"/><st c="45782">and input your credentials. </st><st c="45810">The </st><strong class="source-inline"><st c="45814">docker login</st></strong><st c="45826"> command enables access to your Docker repository using other Docker’s </st><a id="_idIndexMarker1087"/><st c="45897">CLI commands, such as </st><strong class="source-inline"><st c="45919">docker run</st></strong><st c="45929"> to execute the instructions from the Dockerfile. </st><st c="45979">By the way, aside from our Flask[async] application, there is a need to pull an image to generate a container for the PostgreSQL database of our application. </st><st c="46137">Conventionally, to connect these containers, such as our PostgreSQL and Redis containers, to the Python container with the Flask application, Docker networking, through running the </st><strong class="source-inline"><st c="46318">docker network</st></strong><st c="46332"> command, creates the network connections that will link these containers to establish the needed connectivity. </st><st c="46444">But this becomes complex if there are more containers to attach. </st><st c="46509">As a replacement to save time and effort, </st><em class="italic"><st c="46551">Docker Compose</st></em><st c="46565"> can establish all these step-by-step networking procedures by only running the </st><strong class="source-inline"><st c="46645">docker-compose</st></strong><st c="46659"> command. </st><st c="46669">There is no need to install Docker Compose since it is part of the bundle that’s installed by the Docker Desktop installer. </st><st c="46793">Docker Compose uses Docker Engine, so installing the engine also includes Compose. </st><st c="46876">To start Docker Compose, just run </st><strong class="source-inline"><st c="46910">docker login</st></strong><st c="46922"> and enter a valid </st><span class="No-Break"><st c="46941">Docker account.</st></span></p>
			<h2 id="_idParaDest-311"><a id="_idTextAnchor318"/><st c="46956">Using Docker Compose</st></h2>
			<p><strong class="bold"><st c="46977">Docker Compose</st></strong><st c="46992"> is an </st><a id="_idIndexMarker1088"/><st c="46999">open source orchestration tool that manages and deploys multiple containers to one server host using a single service implemented in a series of rules in its configuration file, </st><strong class="source-inline"><st c="47177">docker-compose.yaml</st></strong><st c="47196">. The following is the configuration file that’s used by our </st><span class="No-Break"><strong class="source-inline"><st c="47257">ch11-asgi-deployment</st></strong></span><span class="No-Break"><st c="47277"> project:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="47286">version: '3.0'</st></strong>
<strong class="bold"><st c="47301">services</st></strong><st c="47310">:
  </st><strong class="bold"><st c="47313">api</st></strong><st c="47316">:
    </st><strong class="bold"><st c="47319">build: ./ch11-asgi</st></strong><st c="47337">
    volumes:
      - ./ch11-asgi/:/usr/src/ch11-asgi/
    ports:
      - 8000:8000
    </st><strong class="bold"><st c="47401">depends_on</st></strong><st c="47411">:
      - postgres
   </st><strong class="bold"><st c="47425">postgres</st></strong><st c="47433">:
    </st><strong class="bold"><st c="47436">image: «bitnami/postgresql:latest»</st></strong><st c="47470">
    ports:
      - 5432:5432
    env_file:
      - db.env # configure postgres
    </st><strong class="bold"><st c="47530">volumes</st></strong><st c="47537">:
      - </st><strong class="bold"><st c="47542">database-data:/var/lib/postgresql/data/</st></strong>
<strong class="bold"><st c="47581">volumes</st></strong><st c="47589">:
    </st><strong class="bold"><st c="47592">database-data:</st></strong></pre>			<p><st c="47606">The </st><strong class="source-inline"><st c="47611">version</st></strong><st c="47618"> directive indicates the Compose syntax version the configuration will use in the Compose </st><a id="_idIndexMarker1089"/><st c="47708">instructions. </st><st c="47722">Our Compose configuration file uses version </st><strong class="source-inline"><st c="47766">3.0</st></strong><st c="47769">, which is the latest at the time of writing this book. </st><st c="47825">Lower versions mean deprecated keywords </st><span class="No-Break"><st c="47865">and commands.</st></span></p>
			<p><st c="47878">Now, the </st><strong class="source-inline"><st c="47888">services</st></strong><st c="47896"> directive defines all the containers that Compose will create and run. </st><st c="47968">Ours include the </st><em class="italic"><st c="47985">Online Grocery</st></em><st c="47999"> application (</st><strong class="source-inline"><st c="48013">api</st></strong><st c="48017">) and the PostgreSQL database platform (</st><strong class="source-inline"><st c="48058">postgres</st></strong><st c="48067">). </st><st c="48071">Here, </st><strong class="source-inline"><st c="48077">api</st></strong><st c="48080"> is the name of the service for our application. </st><st c="48129">It contains the following </st><span class="No-Break"><st c="48155">required sub-directives:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="48179">build</st></strong><st c="48185">: Points to the location of the local project folder containing </st><span class="No-Break"><st c="48250">the Dockerfile.</st></span></li>
				<li><strong class="source-inline"><st c="48265">ports</st></strong><st c="48271">: Maps the container’s ports to the host’s ports, either TCP </st><span class="No-Break"><st c="48333">or UDP.</st></span></li>
				<li><strong class="source-inline"><st c="48340">volumes</st></strong><st c="48348">: Attaches the local project files to the specified directory of the container, which spares the image from rebuilding if there are changes in the </st><span class="No-Break"><st c="48496">project files.</st></span></li>
				<li><strong class="source-inline"><st c="48510">depends_on</st></strong><st c="48521">: Mentions the service name considered as one of the </st><span class="No-Break"><st c="48575">container’s dependencies.</st></span></li>
			</ul>
			<p><st c="48600">Another service is </st><strong class="source-inline"><st c="48620">postgres</st></strong><st c="48628">, which provides the database platform for the </st><strong class="source-inline"><st c="48675">api </st></strong><st c="48679">service, thus the </st><a id="_idIndexMarker1090"/><st c="48697">dependency between the two services. </st><st c="48734">Instead of using the </st><strong class="source-inline"><st c="48755">build</st></strong><st c="48760"> directive, its </st><strong class="source-inline"><st c="48776">image</st></strong><st c="48781"> directive will pull the latest </st><strong class="source-inline"><st c="48813">bitnami/postgresql</st></strong><st c="48831"> image to create a container for the PostgreSQL platform with an empty database schema. </st><st c="48919">Its </st><strong class="source-inline"><st c="48923">ports</st></strong><st c="48928"> directive indicates that the container will use port </st><strong class="source-inline"><st c="48982">5432</st></strong><st c="48986"> to listen for database connectivity. </st><st c="49024">The database credentials are in the </st><strong class="source-inline"><st c="49060">db.env</st></strong><st c="49066"> file indicated by the </st><strong class="source-inline"><st c="49089">env_file</st></strong><st c="49097"> directive. </st><st c="49109">The following snippet shows the content of the </st><span class="No-Break"><strong class="source-inline"><st c="49156">db.env</st></strong></span><span class="No-Break"><st c="49162"> file:</st></span></p>
			<pre class="source-code"><st c="49168">
POSTGRES_USER=postgres
POSTGRES_PASSWORD=admin2255
POSTGRES_DB=ogs</st></pre>			<p><st c="49235">The </st><strong class="source-inline"><st c="49240">volumes</st></strong><st c="49247"> directive for the </st><strong class="source-inline"><st c="49266">postgres</st></strong><st c="49274"> service is essential for data persistence because its absence in the configuration means data cleanup after the </st><span class="No-Break"><st c="49387">container restarts.</st></span></p>
			<p><st c="49406">After finalizing the </st><strong class="source-inline"><st c="49428">docker-compose.yaml</st></strong><st c="49447"> file, run the </st><strong class="source-inline"><st c="49462">docker-compose --build</st></strong><st c="49484"> command to build or rebuild the services, then once again after the </st><strong class="source-inline"><st c="49553">docker-compose up</st></strong><st c="49570"> command to create and run the containers. </st><span class="No-Break"><em class="italic"><st c="49613">Figure 11</st></em></span><em class="italic"><st c="49622">.12</st></em><st c="49625"> shows the command logs after running the </st><strong class="source-inline"><st c="49667">docker-compose up --</st></strong><span class="No-Break"><strong class="source-inline"><st c="49687">build</st></strong></span><span class="No-Break"><st c="49693"> commands:</st></span></p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="image/B19383_11_012.jpg" alt="Figure 11.12 – Logs when running the docker-compose up --build command"/><st c="49703"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="50912">Figure 11.12 – Logs when running the docker-compose up --build command</st></p>
			<p><st c="50982">The Docker </st><a id="_idIndexMarker1091"/><st c="50994">Desktop dashboard, on the other hand, will display the following container structure in </st><span class="No-Break"><em class="italic"><st c="51082">Figure 11</st></em></span><em class="italic"><st c="51091">.13</st></em><st c="51094"> after successfully running the </st><span class="No-Break"><st c="51126">generated containers:</st></span></p>
			<div>
				<div id="_idContainer126" class="IMG---Figure">
					<img src="image/B19383_11_013.jpg" alt="Figure 11.13 – Docker Desktop showing ch11-asgi and the PostgreSQL containers"/><st c="51147"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="51293">Figure 11.13 – Docker Desktop showing ch11-asgi and the PostgreSQL containers</st></p>
			<p><st c="51370">Here, </st><strong class="source-inline"><st c="51377">ch11-asgi-deployment</st></strong><st c="51397"> in the given container structure is the name of the deployment folder containing the </st><strong class="source-inline"><st c="51483">db.env</st></strong><st c="51489"> and </st><strong class="source-inline"><st c="51494">docker-compose.yaml</st></strong><st c="51513"> files, and the directory where the terminal invocation of the </st><strong class="source-inline"><st c="51576">docker-compose</st></strong><st c="51590"> commands happened. </st><st c="51610">Inside the Compose container structure are the two containers that were generated by the services. </st><st c="51709">Clicking the </st><strong class="source-inline"><st c="51722">api-1</st></strong><st c="51727"> container will provide us with the Gunicorn server logs presented in </st><span class="No-Break"><em class="italic"><st c="51797">Figure 11</st></em></span><span class="No-Break"><em class="italic"><st c="51806">.14</st></em></span><span class="No-Break"><st c="51809">:</st></span></p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="image/B19383_11_014.jpg" alt="Figure 11.14 – The Gunicorn server log from ch11-asgi app in the api-1 container"/><st c="51811"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="52764">Figure 11.14 – The Gunicorn server log from ch11-asgi app in the api-1 container</st></p>
			<p><st c="52844">On the </st><a id="_idIndexMarker1092"/><st c="52852">other hand, clicking the </st><strong class="source-inline"><st c="52877">postgres-1</st></strong><st c="52887"> container will show the logs shown in </st><span class="No-Break"><em class="italic"><st c="52926">Figure 11</st></em></span><span class="No-Break"><em class="italic"><st c="52935">.15</st></em></span><span class="No-Break"><st c="52938">:</st></span></p>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/B19383_11_015.jpg" alt="Figure 11.15 – The PostgreSQL server log in the postgres-1 container"/><st c="52940"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="54308">Figure 11.15 – The PostgreSQL server log in the postgres-1 container</st></p>
			<p><st c="54376">Now, the database schema in the </st><strong class="source-inline"><st c="54409">postgres-1</st></strong><st c="54419"> container is empty. </st><st c="54440">To populate the database with the tables and data from the local PostgreSQL server, run </st><strong class="source-inline"><st c="54528">pg_dump</st></strong><st c="54535"> to create a </st><strong class="source-inline"><st c="54548">.sql</st></strong><st c="54552"> dump file. </st><st c="54564">Then, in the directory location of the </st><strong class="source-inline"><st c="54603">.sql</st></strong><st c="54607"> backup file, run the following </st><strong class="source-inline"><st c="54639">docker copy</st></strong><st c="54650"> command to copy the backup file, say </st><strong class="source-inline"><st c="54688">ogs.sql</st></strong><st c="54695">, to the </st><strong class="source-inline"><st c="54704">entrypoint</st></strong><st c="54714"> directory of </st><span class="No-Break"><st c="54728">the container:</st></span></p>
			<pre class="console"><st c="54742">
docker cp ogs.sql ch11-asgi-deployment-postgres-1:/docker-entrypoint-initdb.d/ogs.sql</st></pre>			<p><st c="54828">Then, access the container’s server using valid credentials, such as </st><strong class="source-inline"><st c="54898">postgres</st></strong><st c="54906"> and its password, to spool or execute the </st><strong class="source-inline"><st c="54949">.sql</st></strong><st c="54953"> file using the </st><strong class="source-inline"><st c="54969">docker </st></strong><span class="No-Break"><strong class="source-inline"><st c="54976">exec</st></strong></span><span class="No-Break"><st c="54980"> command:</st></span></p>
			<pre class="console"><st c="54989">
docker exec -it ch11-asgi-deployment-postgres-1 psql -U postgres -d ogs -f docker-entrypoint-initdb.d/ogs.sql</st></pre>			<p><st c="55099">Finally, log in to the </st><strong class="source-inline"><st c="55123">ch11-asgi-deployment-postgres-1</st></strong><st c="55154"> server using the </st><strong class="source-inline"><st c="55172">docker exec</st></strong><st c="55183"> command with the database </st><span class="No-Break"><st c="55210">admin credentials:</st></span></p>
			<pre class="console"><st c="55228">
docker exec -it ch11-asgi-deployment-postgres-1 psql -U postgres</st></pre>			<p><st c="55293">Also, don’t forget </st><a id="_idIndexMarker1093"/><st c="55313">to replace the </st><strong class="source-inline"><st c="55328">host</st></strong><st c="55332"> parameter of the </st><strong class="source-inline"><st c="55350">PooledPostgresqlDatabase</st></strong><st c="55374"> driver class with the container’s name instead of </st><strong class="source-inline"><st c="55425">localhost</st></strong><st c="55434"> and its </st><strong class="source-inline"><st c="55443">port</st></strong><st c="55447"> to </st><strong class="source-inline"><st c="55451">5432</st></strong><st c="55455">. The following snippet shows the changes in the driver class configuration that can be found in the </st><span class="No-Break"><strong class="source-inline"><st c="55556">app/models/config</st></strong></span><span class="No-Break"><st c="55573"> module:</st></span></p>
			<pre class="source-code"><st c="55581">
from peewee_async import PooledPostgresqlDatabase
database = PooledPostgresqlDatabase(
        'ogs',
        user='postgres',
        password='admin2255',
        </st><strong class="bold"><st c="55715">host='ch11-asgi-deployment-postgres-1',</st></strong><strong class="bold"><st c="55754">port='5432',</st></strong><st c="55767">
        max_connections = 3,
        connect_timeout = 3
    )</st></pre>			<p><st c="55810">Now, problems arise when one or some of the containers fail during production. </st><st c="55890">By default, it does support automatic container restart when there are runtime errors in the application or some memory-related issues. </st><st c="56026">Moreover, Compose cannot perform container orchestration in a </st><span class="No-Break"><st c="56088">distributed setup.</st></span></p>
			<p><st c="56106">Another powerful approach to deploying applications to different hosts rather than to a single server is through </st><em class="italic"><st c="56220">Kubernetes</st></em><st c="56230">. In the next section, we’ll use Kubernetes to deploy our </st><strong class="source-inline"><st c="56288">ch11-asgi</st></strong><st c="56297"> application with Gunicorn as </st><span class="No-Break"><st c="56327">the server.</st></span></p>
			<h1 id="_idParaDest-312"><a id="_idTextAnchor319"/><st c="56338">Deploying the application on Kubernetes</st></h1>
			<p><st c="56378">Like Compose, </st><strong class="bold"><st c="56393">Kubernetes</st></strong><st c="56403"> or </st><strong class="bold"><st c="56407">K8</st></strong><st c="56409"> manages multiple containers with or without dependencies </st><a id="_idIndexMarker1094"/><st c="56467">on each other. </st><st c="56482">Kubernetes can utilize volume storage </st><a id="_idIndexMarker1095"/><st c="56520">for data persistence and has CLI </st><a id="_idIndexMarker1096"/><st c="56553">commands to manage the life cycle of the containers. </st><st c="56606">The only difference is that Kubernetes can run containers in a distributed setup and uses Pods to manage </st><span class="No-Break"><st c="56711">its containers.</st></span></p>
			<p><st c="56726">Among the many ways to install Kubernetes, this chapter utilizes the </st><strong class="bold"><st c="56796">Kubernetes</st></strong><st c="56806"> feature in Docker Desktop’s </st><strong class="bold"><st c="56835">Settings</st></strong><st c="56843">, as shown in </st><span class="No-Break"><em class="italic"><st c="56857">Figure 11</st></em></span><span class="No-Break"><em class="italic"><st c="56866">.16</st></em></span><span class="No-Break"><st c="56869">:</st></span></p>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="image/B19383_11_016.jpg" alt="Figure 11.16 – Kubernetes in Desktop Docker"/><st c="56871"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="57377">Figure 11.16 – Kubernetes in Desktop Docker</st></p>
			<p><st c="57420">Check the </st><strong class="bold"><st c="57431">Enable Kubernetes</st></strong><st c="57448"> checkbox from the </st><strong class="bold"><st c="57467">Settings</st></strong><st c="57475"> area and click the </st><strong class="bold"><st c="57495">Apply &amp; restart</st></strong><st c="57510"> button in the lower right portion of the dashboard. </st><st c="57563">It will take a while for Kubernetes to appear running or </st><em class="italic"><st c="57620">green</st></em><st c="57625"> in the lower left corner of the dashboard, depending on the number of containers running on </st><span class="No-Break"><st c="57718">Docker Engine.</st></span></p>
			<p><st c="57732">When the Kubernetes engine fails, click the </st><strong class="bold"><st c="57777">Reset Kubernetes Cluster</st></strong><st c="57801"> button to remove all containers and files of the Kubernetes stack. </st><st c="57869">Additionally, for Windows users, delete the Docker fragment files in the </st><strong class="source-inline"><st c="57942">C:\Users\alibatasys\AppData\Local\Temp</st></strong><st c="57980"> folder before restarting </st><span class="No-Break"><st c="58006">Docker Desktop.</st></span></p>
			<p><st c="58021">Kubernetes uses YAML files to define and create Kubernetes objects, such as </st><strong class="bold"><st c="58098">Deployment</st></strong><st c="58108">, </st><strong class="bold"><st c="58110">Pods</st></strong><st c="58114">, </st><strong class="bold"><st c="58116">Services</st></strong><st c="58124">, and </st><strong class="bold"><st c="58130">PersistentVolume</st></strong><st c="58146">, all of which are required to establish </st><a id="_idIndexMarker1097"/><st c="58187">some container rules, manage the host resources, and build </st><a id="_idIndexMarker1098"/><st c="58246">containerized </st><a id="_idIndexMarker1099"/><st c="58260">applications. </st><st c="58274">An object definition in YAML format </st><a id="_idIndexMarker1100"/><st c="58310">always consists of the following </st><span class="No-Break"><st c="58343">manifest fields:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="58359">apiVersion</st></strong><st c="58370">: The field that indicates the appropriate and stable Kubernetes API for a Kubernetes object creation. </st><st c="58474">This field must always appear first in the file. </st><st c="58523">Kubernetes has several APIs, such as </st><strong class="source-inline"><st c="58560">batch/v1</st></strong><st c="58568">, </st><strong class="source-inline"><st c="58570">apps/v1</st></strong><st c="58577">, </st><strong class="source-inline"><st c="58579">v1</st></strong><st c="58581">, and </st><strong class="source-inline"><st c="58587">rbac.authorization.k8s.io/v1</st></strong><st c="58615">, but the more common is </st><strong class="source-inline"><st c="58640">v1</st></strong><st c="58642"> for </st><strong class="source-inline"><st c="58647">PersistentVolume</st></strong><st c="58663">, </st><strong class="source-inline"><st c="58665">PersistentVolumeClaims</st></strong><st c="58687">, </st><strong class="source-inline"><st c="58689">Service</st></strong><st c="58696">, </st><strong class="source-inline"><st c="58698">Secret</st></strong><st c="58704">, and </st><strong class="source-inline"><st c="58710">Pod</st></strong><st c="58713"> object creation and </st><strong class="source-inline"><st c="58734">apps/v1</st></strong><st c="58741"> for </st><strong class="source-inline"><st c="58746">Deployment</st></strong><st c="58756"> and </st><strong class="source-inline"><st c="58761">ReplicaSets</st></strong><st c="58772"> objects. </st><st c="58782">So far, </st><strong class="source-inline"><st c="58790">v1</st></strong><st c="58792"> is the first stable release of </st><span class="No-Break"><st c="58824">Kubernetes API.</st></span></li>
				<li><strong class="source-inline"><st c="58839">kind</st></strong><st c="58844">: The field that identifies the Kubernetes object the file needs to create. </st><st c="58921">Here, </st><strong class="source-inline"><st c="58927">kind</st></strong><st c="58931"> can be </st><strong class="source-inline"><st c="58939">Secret</st></strong><st c="58945">, </st><strong class="source-inline"><st c="58947">Service</st></strong><st c="58954">, </st><strong class="source-inline"><st c="58956">Deployment</st></strong><st c="58966">, </st><strong class="source-inline"><st c="58968">Role</st></strong><st c="58972">, </st><span class="No-Break"><st c="58974">or </st></span><span class="No-Break"><strong class="source-inline"><st c="58977">Pod</st></strong></span><span class="No-Break"><st c="58980">.</st></span></li>
				<li><strong class="source-inline"><st c="58981">metadata</st></strong><st c="58990">: This field specifies the properties of the Kubernetes object defined in the file. </st><st c="59075">The properties may include the </st><em class="italic"><st c="59106">name</st></em><st c="59110">, </st><em class="italic"><st c="59112">labels</st></em><st c="59118">, </st><span class="No-Break"><st c="59120">and </st></span><span class="No-Break"><em class="italic"><st c="59124">namespace</st></em></span><span class="No-Break"><st c="59133">.</st></span></li>
				<li><strong class="source-inline"><st c="59134">spec</st></strong><st c="59139">: This field provides the specification of the object in key-value format. </st><st c="59215">The same object type with a different </st><strong class="source-inline"><st c="59253">apiVersion</st></strong><st c="59263"> can have different </st><span class="No-Break"><st c="59283">specification details.</st></span></li>
			</ul>
			<p><st c="59305">In this </st><a id="_idIndexMarker1101"/><st c="59314">chapter, the Kubernetes deployment </st><a id="_idIndexMarker1102"/><st c="59349">involves pulling our </st><strong class="source-inline"><st c="59370">ch11-asgi</st></strong><st c="59379"> file’s Docker image and the latest </st><strong class="source-inline"><st c="59415">bitnami/postgresql</st></strong><st c="59433"> image from the Docker registry hub. </st><st c="59470">But before creating the deployment file, our first manifest focuses on containing the </st><strong class="source-inline"><st c="59556">Secret</st></strong><st c="59562"> object definition, which aims to store and secure the database PostgreSQL credentials. </st><st c="59650">The following is our </st><strong class="source-inline"><st c="59671">kub-secrets.yaml</st></strong><st c="59687"> file, which contains our </st><strong class="source-inline"><st c="59713">Secret</st></strong> <span class="No-Break"><st c="59719">object definition:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="59738">apiVersion: v1</st></strong>
<strong class="bold"><st c="59753">kind: Secret</st></strong>
<strong class="bold"><st c="59766">metadata:</st></strong><strong class="bold"><st c="59776">name: postgres-credentials</st></strong><st c="59803">
data:
  # replace this with your base4-encoded username
  user: cG9zdGdyZXM=
  # replace this with your base4-encoded password
  password: YWRtaW4yMjU1</st></pre>			<p><st c="59947">A </st><strong class="source-inline"><st c="59950">Secret</st></strong><st c="59956"> object contains protected data such as a password, user token, or access key. </st><st c="60035">Instead of hardcoding these confidential data in the applications, it is safe to store them in Pods so that they can be accessed by other Pods in </st><span class="No-Break"><st c="60181">the cluster.</st></span></p>
			<p><st c="60193">Our second </st><a id="_idIndexMarker1103"/><st c="60205">YAML file, </st><strong class="source-inline"><st c="60216">kub-postgresql-pv.yaml</st></strong><st c="60238">, defines the object that will create persistent storage resources </st><a id="_idIndexMarker1104"/><st c="60305">for our PostgreSQL, the </st><strong class="source-inline"><st c="60329">PersistentVolume</st></strong><st c="60345"> object. </st><st c="60354">Since our Kubernetes runs on a single-node server, the default storage class is </st><strong class="source-inline"><st c="60434">hostpath</st></strong><st c="60442">. This storage will hold the data of the PostgreSQL permanently, even after the removal of our containerized application. </st><st c="60564">The following </st><strong class="source-inline"><st c="60578">kub-postgresql-pv.yaml</st></strong><st c="60600"> file defines the </st><strong class="source-inline"><st c="60618">PersistentVolume</st></strong><st c="60634"> object that will manage our application’s </st><span class="No-Break"><st c="60677">data storage:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="60690">apiVersion: v1</st></strong>
<strong class="bold"><st c="60705">kind: PersistentVolume</st></strong>
<strong class="bold"><st c="60728">metadata:</st></strong><strong class="bold"><st c="60738">name: postgres-pv-volume</st></strong><st c="60763">
   labels:
      type: local
</st><strong class="bold"><st c="60784">spec:</st></strong><strong class="bold"><st c="60789">storageClassName: manual</st></strong><st c="60814">
   capacity:
      storage: 5Gi
   accessModes:
       - ReadWriteOnce
   hostPath:
      path: "/mnt/data"</st></pre>			<p><st c="60894">In Kubernetes, utilizing storage from the </st><strong class="source-inline"><st c="60937">PersistentVolume</st></strong><st c="60953"> object requires a </st><strong class="source-inline"><st c="60972">PersistentVolumeClaims</st></strong><st c="60994"> object. </st><st c="61003">This object requests a portion of the cluster storage </st><a id="_idIndexMarker1105"/><st c="61057">that Kubernetes </st><em class="italic"><st c="61073">Pods</st></em><st c="61077"> will use </st><a id="_idIndexMarker1106"/><st c="61087">for the application’s read and write. </st><st c="61125">The following </st><strong class="source-inline"><st c="61139">kub-postgresql-pvc.yaml</st></strong><st c="61162"> file creates an </st><strong class="source-inline"><st c="61179">PersistentVolumeClaims</st></strong><st c="61201"> object for the </st><span class="No-Break"><st c="61217">deployment’s storage:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="61238">kind: PersistentVolumeClaim</st></strong>
<strong class="bold"><st c="61266">apiVersion: v1</st></strong>
<strong class="bold"><st c="61281">metadata:</st></strong><strong class="bold"><st c="61291">name: postgresql-db-claim</st></strong>
<strong class="bold"><st c="61317">spec:</st></strong><st c="61323">
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi</st></pre>			<p><st c="61386">The </st><strong class="source-inline"><st c="61391">PersistentVolumeClaims</st></strong><st c="61413"> and </st><strong class="source-inline"><st c="61418">PersistentVolume</st></strong><st c="61434"> objects work together to dynamically claim a new volume storage for the </st><strong class="source-inline"><st c="61507">bitnami/postgresql</st></strong><st c="61525"> container. </st><st c="61537">The </st><em class="italic"><st c="61541">manual</st></em> <strong class="source-inline"><st c="61547">StorageClass</st></strong><st c="61560"> type indicates that there is a binding from </st><strong class="source-inline"><st c="61605">PersistentVolumeClaims</st></strong><st c="61627"> to </st><strong class="source-inline"><st c="61631">PersistentVolume</st></strong><st c="61647"> for the request of </st><span class="No-Break"><st c="61667">the storage.</st></span></p>
			<p><st c="61679">After creating the configuration files for the </st><strong class="source-inline"><st c="61727">Secret</st></strong><st c="61733">, </st><strong class="source-inline"><st c="61735">PersistentVolume</st></strong><st c="61751">, and </st><strong class="source-inline"><st c="61757">PersistentVolumeClaims</st></strong><st c="61779"> objects, the next crucial step is to create the deployment configuration files that will connect the </st><strong class="source-inline"><st c="61881">ch11-asgi</st></strong><st c="61890"> and </st><strong class="source-inline"><st c="61895">bitnami/postgresql</st></strong><st c="61913"> Docker images with database configuration details from the </st><strong class="source-inline"><st c="61973">Secret</st></strong><st c="61979"> object, utilize the volume claims for PostgreSQL data persistency, and deploy and run them all together with Kubernetes Services and Pods. </st><st c="62119">Here, </st><strong class="source-inline"><st c="62125">Deployment</st></strong><st c="62135"> manages a set of Pods to run an application workload. </st><st c="62190">A Pod, as Kubernetes’ fundamental building block, represents a single running process within the Kubernetes cluster. </st><st c="62307">The following </st><strong class="source-inline"><st c="62321">kub-postgresql-deployment.yaml</st></strong><st c="62351"> file tells Kubernetes to manage an instance that will hold the </st><span class="No-Break"><st c="62415">PostgreSQL container:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="62436">apiVersion: apps/v1</st></strong>
<strong class="bold"><st c="62456">kind: Deployment</st></strong>
<strong class="bold"><st c="62473">metadata:</st></strong><strong class="bold"><st c="62483">name: ch11-postgresql</st></strong></pre>			<p><st c="62505">For this </st><a id="_idIndexMarker1107"/><st c="62515">deployment configuration, </st><strong class="source-inline"><st c="62541">v1</st></strong><st c="62543"> or </st><strong class="source-inline"><st c="62547">apps/v1</st></strong><st c="62554"> is the proper choice for the </st><strong class="source-inline"><st c="62584">apiVersion</st></strong><st c="62594"> metadata. </st><st c="62605">The </st><strong class="source-inline"><st c="62609">kub-postgresql-deployment.yaml</st></strong><st c="62639"> file is a </st><strong class="source-inline"><st c="62650">Deployment</st></strong><st c="62660"> type of Kubernetes </st><a id="_idIndexMarker1108"/><st c="62680">document, as indicated in the </st><strong class="source-inline"><st c="62710">kind</st></strong><st c="62714"> metadata, which will generate a container </st><span class="No-Break"><st c="62757">named </st></span><span class="No-Break"><strong class="source-inline"><st c="62763">ch11-postgresql</st></strong></span><span class="No-Break"><st c="62778">:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="62780">spec:</st></strong><st c="62785">
  replicas: 1
  selector:
    matchLabels:
      app: ch11-postgresql
  template:
    metadata:
      labels:
        app: ch11-postgresql
    spec:
      terminationGracePeriodSeconds: 180
      </st><strong class="bold"><st c="62932">containers:</st></strong><st c="62943">
        - name: ch11-postgresql
          image: bitnami/postgresql:latest
          imagePullPolicy: IfNotPresent
          ports:
            - name: tcp-5432
              containerPort: 5432</st></pre>			<p><st c="63074">From the </st><a id="_idIndexMarker1109"/><st c="63084">overall state indicated </st><a id="_idIndexMarker1110"/><st c="63108">in the </st><strong class="source-inline"><st c="63115">spec</st></strong><st c="63119"> metadata, the deployment will create </st><em class="italic"><st c="63157">1 replica</st></em><st c="63166"> in a Kubernetes pod, with </st><strong class="source-inline"><st c="63193">ch11-postgresql</st></strong><st c="63208"> as its label, to run the PostgreSQL server. </st><st c="63253">Moreover, the deployment will pull the </st><strong class="source-inline"><st c="63292">bitnami/postgresql:latest</st></strong><st c="63317"> image to create the PostgreSQL container, bearing the </st><strong class="source-inline"><st c="63372">ch11-postgresql</st></strong><st c="63387"> label also. </st><st c="63400">The configuration also includes a </st><strong class="source-inline"><st c="63434">terminationGracePeriodSeconds</st></strong><st c="63463"> value of </st><strong class="source-inline"><st c="63473">180</st></strong><st c="63476"> to shut down the database </st><span class="No-Break"><st c="63503">server safely:</st></span></p>
			<pre class="source-code"><st c="63517">
          env:
          - name: POSTGRES_USER
            valueFrom:
              secretKeyRef:
                </st><strong class="bold"><st c="63570">name: postgres-credentials</st></strong><st c="63596">
                key: user
          - name: POSTGRES_PASSWORD
            valueFrom:
              secretKeyRef:
                </st><strong class="bold"><st c="63658">name: postgres-credentials</st></strong><st c="63684">
                key: password
          - name: POSTGRES_DB
            value: ogs
          - name: PGDATA
            value: /var/lib/postgresql/data/pgdata</st></pre>			<p><st c="63783">The </st><strong class="source-inline"><st c="63788">env</st></strong><st c="63791"> or environment variables portion provides the database credentials, </st><strong class="source-inline"><st c="63860">POSTGRES_USER</st></strong><st c="63873"> and </st><strong class="source-inline"><st c="63878">POSTGRES_DB</st></strong><st c="63889">, to the database, which are base64-encoded values </st><a id="_idIndexMarker1111"/><st c="63940">from the previously created </st><strong class="source-inline"><st c="63968">Secret</st></strong><st c="63974"> object, </st><strong class="source-inline"><st c="63983">postgres-credentials</st></strong><st c="64003">. Note that this deployment will also </st><a id="_idIndexMarker1112"/><st c="64041">auto-generate the database with the </st><span class="No-Break"><st c="64077">name </st></span><span class="No-Break"><strong class="source-inline"><st c="64082">ogs</st></strong></span><span class="No-Break"><st c="64085">:</st></span></p>
			<pre class="source-code"><st c="64087">
          volumeMounts:
            - name: data-storage-volume
              mountPath: /var/lib/postgresql/data
          resources:
            requests:
              cpu: "50m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "256Mi"
      volumes:
        - name: data-storage-volume
          persistentVolumeClaim:
            claimName: postgresql-db-claim</st></pre>			<p><st c="64340">The deployment will also allow us to save all data files in the </st><strong class="source-inline"><st c="64405">/var/lib/postgresql/data</st></strong><st c="64429"> file of the generated container in the </st><strong class="source-inline"><st c="64469">ch11-postgresql</st></strong><st c="64484"> pod, as indicated in the </st><strong class="source-inline"><st c="64510">volumeMounts</st></strong><st c="64522"> metadata. </st><st c="64533">Specifying the </st><strong class="source-inline"><st c="64548">volumeMounts</st></strong><st c="64560"> metadata avoids data loss when the database shuts down and makes the database and tables accessible across the network. </st><st c="64681">The pod will access the volume storage created by the </st><strong class="source-inline"><st c="64735">postgres-pv-volume</st></strong><st c="64753"> and </st><span class="No-Break"><strong class="source-inline"><st c="64758">postgresql-db-claim</st></strong></span><span class="No-Break"><st c="64777"> objects.</st></span></p>
			<p><st c="64786">Aside from the </st><strong class="source-inline"><st c="64802">Deployment</st></strong><st c="64812"> object, this document defines a </st><strong class="source-inline"><st c="64845">Service</st></strong><st c="64852"> type that will expose our PostgreSQL container to other Pods within the cluster at port </st><strong class="source-inline"><st c="64941">5432</st></strong><st c="64945"> through </st><span class="No-Break"><st c="64954">a </st></span><span class="No-Break"><em class="italic"><st c="64956">ClusterIP</st></em></span><span class="No-Break"><st c="64965">:</st></span></p>
			<pre class="source-code"><st c="64967">
---
</st><strong class="bold"><st c="64972">apiVersion: v1</st></strong>
<strong class="bold"><st c="64986">kind: Service</st></strong>
<strong class="bold"><st c="65000">metadata:</st></strong><strong class="bold"><st c="65010">name: ch11-postgresql-service</st></strong><st c="65040">
  labels:
    </st><strong class="bold"><st c="65049">name: ch11-postgresql</st></strong>
<strong class="bold"><st c="65070">spec:</st></strong><strong class="bold"><st c="65076">ports:</st></strong><strong class="bold"><st c="65083">- port: 5432</st></strong><st c="65096">
  selector:
    app: ch11-postgresql</st></pre>			<p><st c="65127">The </st><strong class="source-inline"><st c="65132">---</st></strong><st c="65135"> symbol is a valid separator syntax separating the </st><strong class="source-inline"><st c="65186">Deployment</st></strong><st c="65196"> and </st><span class="No-Break"><strong class="source-inline"><st c="65201">Service</st></strong></span><span class="No-Break"><st c="65208"> definitions.</st></span></p>
			<p><st c="65221">Our last </st><a id="_idIndexMarker1113"/><st c="65231">deployment file, </st><strong class="source-inline"><st c="65248">kub-app-deployment.yaml</st></strong><st c="65271">, pulls the </st><strong class="source-inline"><st c="65283">ch11-asgi</st></strong><st c="65292"> Docker image and assigns the generated </st><a id="_idIndexMarker1114"/><st c="65332">container to </st><span class="No-Break"><st c="65345">the Pods:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="65354">apiVersion: apps/v1</st></strong>
<strong class="bold"><st c="65374">kind: Deployment</st></strong>
<strong class="bold"><st c="65391">metadata:</st></strong><strong class="bold"><st c="65401">name: ch11-app</st></strong><st c="65416">
  labels:
      name: ch11-app</st></pre>			<p><st c="65439">The </st><strong class="source-inline"><st c="65444">apiVersion</st></strong><st c="65454"> field of our deployment configuration file is </st><strong class="source-inline"><st c="65501">v1</st></strong><st c="65503">, an appropriate Kubernetes version for deployment. </st><st c="65555">In this case, our container will be labeled </st><strong class="source-inline"><st c="65599">ch11-app</st></strong><st c="65607">, as indicated in the </st><span class="No-Break"><strong class="source-inline"><st c="65629">metadata/name</st></strong></span><span class="No-Break"><st c="65642"> configuration:</st></span></p>
			<pre class="source-code">
<strong class="bold"><st c="65657">spec:</st></strong><st c="65663">
  replicas: 1
  selector:
    matchLabels:
      app: ch11-app</st></pre>			<p><st c="65712">The </st><strong class="source-inline"><st c="65717">spec</st></strong><st c="65721"> field </st><a id="_idIndexMarker1115"/><st c="65728">describes the overall </st><a id="_idIndexMarker1116"/><st c="65750">state of the deployment, starting with the number of </st><strong class="source-inline"><st c="65803">replicas</st></strong><st c="65811"> the deployment will create, how many </st><strong class="source-inline"><st c="65849">containers</st></strong><st c="65859"> the Pods will run, the environment variables – namely </st><strong class="source-inline"><st c="65914">username</st></strong><st c="65922">, </st><strong class="source-inline"><st c="65924">password</st></strong><st c="65932">, and </st><strong class="source-inline"><st c="65938">SERVICE_POSTGRES_SERVICE_HOST</st></strong><st c="65967"> – that </st><strong class="source-inline"><st c="65975">ch11-app</st></strong><st c="65983"> will use to connect to the PostgreSQL container, and the </st><strong class="source-inline"><st c="66041">containerPort</st></strong><st c="66054"> variable the container will </st><span class="No-Break"><st c="66083">listen to:</st></span></p>
			<pre class="source-code"><st c="66093">
  template:
    metadata:
      labels:
        app: ch11-app
    spec:
      containers:
      - </st><strong class="bold"><st c="66156">name: ch11-app</st></strong><strong class="bold"><st c="66170">image: sjctrags/ch11-app:latest</st></strong><st c="66202">
        env:
            - name: SERVICE_POSTGRES_SERVICE_HOST
              value: ch11-postgresql-service. </st><st c="66278">default.svc.cluster.local
            - name: POSTGRES_DB_USER
              valueFrom:
                secretKeyRef:
                  </st><strong class="bold"><st c="66354">name: postgres-credentials</st></strong><st c="66380">
                  key: user
            - name: POSTGRES_DB_PSW
              valueFrom:
                secretKeyRef:
                  </st><strong class="bold"><st c="66440">name: postgres-credentials</st></strong><st c="66466">
                  key: password
        ports:
        - containerPort: 8000</st></pre>			<p><st c="66509">Also </st><a id="_idIndexMarker1117"/><st c="66515">included in the YAML file </st><a id="_idIndexMarker1118"/><st c="66541">is the </st><strong class="source-inline"><st c="66548">Service</st></strong><st c="66555"> type that will make the application to </st><span class="No-Break"><st c="66595">the users:</st></span></p>
			<pre class="source-code"><st c="66605">
---
</st><strong class="bold"><st c="66610">apiVersion: v1</st></strong>
<strong class="bold"><st c="66624">kind: Service</st></strong>
<strong class="bold"><st c="66638">metadata:</st></strong><strong class="bold"><st c="66648">name: ch11-app-service</st></strong>
<strong class="bold"><st c="66671">spec:</st></strong><strong class="bold"><st c="66677">type: LoadBalancer</st></strong><st c="66696">
  selector:
    app: ch11-app
  </st><strong class="bold"><st c="66721">ports:</st></strong><st c="66727">
    - </st><strong class="bold"><st c="66730">protocol: TCP</st></strong><strong class="bold"><st c="66743">port: 8000</st></strong><st c="66754">
      targetPort: 8000</st></pre>			<p><st c="66771">The definition links the </st><strong class="source-inline"><st c="66797">postgres-credentials</st></strong><st c="66817"> object to the pod’s environment variables that refer to the </st><a id="_idIndexMarker1119"/><st c="66878">database credentials. </st><st c="66900">It also defines a </st><em class="italic"><st c="66918">LoadBalancer </st></em><strong class="source-inline"><st c="66931">Service</st></strong><st c="66938"> to expose our containerized Flask[async] to the HTTP client at </st><span class="No-Break"><st c="67002">port </st></span><span class="No-Break"><strong class="source-inline"><st c="67007">8000</st></strong></span><span class="No-Break"><st c="67011">.</st></span></p>
			<p><st c="67012">To apply </st><a id="_idIndexMarker1120"/><st c="67022">these configuration files, Kubernetes has a </st><strong class="source-inline"><st c="67066">kubectl</st></strong><st c="67073"> client command to communicate with Kubernetes </st><a id="_idIndexMarker1121"/><st c="67120">and run its APIs defined in the manifest files. </st><st c="67168">Here is the order of applying the given </st><span class="No-Break"><st c="67208">YAML files:</st></span></p>
			<ol>
				<li><strong class="source-inline"><st c="67219">kubectl apply -</st></strong><span class="No-Break"><strong class="source-inline"><st c="67235">f kub-secrets.yaml</st></strong></span><span class="No-Break"><st c="67254">.</st></span></li>
				<li><strong class="source-inline"><st c="67255">kubectl apply -</st></strong><span class="No-Break"><strong class="source-inline"><st c="67271">f kub-postgresql-pv.yaml</st></strong></span><span class="No-Break"><st c="67296">.</st></span></li>
				<li><strong class="source-inline"><st c="67297">kubectl apply -</st></strong><span class="No-Break"><strong class="source-inline"><st c="67313">f kub-postgresql-pvc.yaml</st></strong></span><span class="No-Break"><st c="67339">.</st></span></li>
				<li><strong class="source-inline"><st c="67340">kubectl apply -</st></strong><span class="No-Break"><strong class="source-inline"><st c="67356">f kub-postgresql-deployment.yaml</st></strong></span><span class="No-Break"><st c="67389">.</st></span></li>
				<li><strong class="source-inline"><st c="67390">kubectl apply -</st></strong><span class="No-Break"><strong class="source-inline"><st c="67406">f kub-app-deployment</st></strong></span><span class="No-Break"><st c="67427">.</st></span></li>
			</ol>
			<p><st c="67428">To learn about the status and instances that run the applications, run </st><strong class="source-inline"><st c="67500">kubectl get pods</st></strong><st c="67516">. To view the Services that have been created, run </st><strong class="source-inline"><st c="67567">kubectl get services</st></strong><st c="67587">. </st><span class="No-Break"><em class="italic"><st c="67589">Figure 11</st></em></span><em class="italic"><st c="67598">.17</st></em><st c="67601"> shows the list of Services after applying all our </st><span class="No-Break"><st c="67652">deployment files:</st></span></p>
			<div>
				<div id="_idContainer130" class="IMG---Figure">
					<img src="image/B19383_11_017.jpg" alt="Figure 11.17 – Listing all Kubernetes Services with their details"/><st c="67669"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="67994">Figure 11.17 – Listing all Kubernetes Services with their details</st></p>
			<p><st c="68059">To learn all the details about the Services and Pods that have been deployed and the status of each pod, run </st><strong class="source-inline"><st c="68169">kubectl get all</st></strong><st c="68184">. The result will be similar to what’s shown in </st><span class="No-Break"><em class="italic"><st c="68232">Figure 11</st></em></span><span class="No-Break"><em class="italic"><st c="68241">.18</st></em></span><span class="No-Break"><st c="68244">:</st></span></p>
			<div>
				<div id="_idContainer131" class="IMG---Figure">
					<img src="image/B19383_11_018.jpg" alt="Figure 11.18 – Listing all the Kubernetes cluster details"/><st c="68246"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="68901">Figure 11.18 – Listing all the Kubernetes cluster details</st></p>
			<p><st c="68958">All the </st><a id="_idIndexMarker1122"/><st c="68967">Pods and the containerized </st><a id="_idIndexMarker1123"/><st c="68994">applications can be viewed on Docker Desktop, as shown in </st><span class="No-Break"><em class="italic"><st c="69052">Figure 11</st></em></span><span class="No-Break"><em class="italic"><st c="69061">.19</st></em></span><span class="No-Break"><st c="69064">:</st></span></p>
			<div>
				<div id="_idContainer132" class="IMG---Figure">
					<img src="image/B19383_11_019.jpg" alt="Figure 11.19 – Docker Desktop view of all Pods and applications"/><st c="69066"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="69586">Figure 11.19 – Docker Desktop view of all Pods and applications</st></p>
			<p><st c="69649">Before accessing the </st><strong class="source-inline"><st c="69671">ch11-asgi</st></strong><st c="69680"> container, populate the empty PostgreSQL database with the </st><strong class="source-inline"><st c="69740">.sql</st></strong><st c="69744"> dump file from the local database. </st><st c="69780">Use the </st><strong class="source-inline"><st c="69788">Pod</st></strong><st c="69791"> name (for example, </st><strong class="source-inline"><st c="69811">ch11-postgresql-b7fc578f4-6g4nc</st></strong><st c="69842">) of the deployed PostgreSQL container and copy the </st><strong class="source-inline"><st c="69895">.sql</st></strong><st c="69899"> file to the </st><strong class="source-inline"><st c="69912">/temp</st></strong><st c="69917"> directory of the container (for example, </st><strong class="source-inline"><st c="69959">ch11-postgresql-b7fc578f4-6g4nc:/temp/ogs.sql</st></strong><st c="70004">) using the </st><strong class="source-inline"><st c="70017">kubectl cp</st></strong><st c="70027"> command and the pod. </st><st c="70049">Be sure to run the command in the location of the </st><strong class="source-inline"><st c="70099">.</st></strong><span class="No-Break"><strong class="source-inline"><st c="70100">sql</st></strong></span><span class="No-Break"><st c="70104"> file:</st></span></p>
			<pre class="console"><st c="70110">
kubectl cp ogs.sql ch11-postgresql-b7fc578f4-6g4nc:/tmp/ogs.sql</st></pre>			<p><st c="70174">Run the </st><strong class="source-inline"><st c="70183">.sql</st></strong><st c="70187"> file in the </st><strong class="source-inline"><st c="70200">/temp</st></strong><st c="70205"> folder of the container using the </st><strong class="source-inline"><st c="70240">kubectl exec</st></strong><st c="70252"> command and </st><span class="No-Break"><st c="70265">the pod:</st></span></p>
			<pre class="console"><st c="70273">
kubectl exec -it ch11-postgresql-b7fc578f4-6g4nc -- psql -U postgres -d ogs -f /tmp/ogs.sql</st></pre>			<p><st c="70365">Also, replace the </st><strong class="source-inline"><st c="70384">user</st></strong><st c="70388">, </st><strong class="source-inline"><st c="70390">password</st></strong><st c="70398">, </st><strong class="source-inline"><st c="70400">port</st></strong><st c="70404">, and </st><strong class="source-inline"><st c="70410">host</st></strong><st c="70414"> parameters of </st><span class="No-Break"><st c="70429">Peewee’s </st></span><span class="No-Break"><strong class="source-inline"><st c="70438">Pooled</st></strong></span><strong class="source-inline"><st c="70444">
PostgresqlDatabase</st></strong><st c="70463"> with the environment variables declared in the </st><strong class="source-inline"><st c="70511">kub-app-deployment.yaml</st></strong><st c="70534"> file. </st><st c="70541">The following snippet shows the changes in the driver </st><a id="_idIndexMarker1124"/><st c="70595">class configuration found </st><a id="_idIndexMarker1125"/><st c="70621">in the </st><span class="No-Break"><strong class="source-inline"><st c="70628">app/models/config</st></strong></span><span class="No-Break"><st c="70645"> module:</st></span></p>
			<pre class="source-code"><st c="70653">
from peewee_async import PooledPostgresqlDatabase
import os
database = PooledPostgresqlDatabase(
        'ogs',
        </st><strong class="bold"><st c="70758">user=os.environ.get('POSTGRES_DB_USER'),</st></strong><strong class="bold"><st c="70798">password=os.environ.get('POSTGRES_DB_PSW'),</st></strong><strong class="bold"><st c="70842">host=os.environ.get(</st></strong> <strong class="bold"><st c="70863">'SERVICE_POSTGRES_SERVICE_HOST'),</st></strong><strong class="bold"><st c="70897">port='5432',</st></strong><st c="70910">
        max_connections = 3,
        connect_timeout = 3
    )</st></pre>			<p><st c="70953">After migrating the tables and the data, the client application can now access the API endpoints of our </st><em class="italic"><st c="71058">Online Grocery</st></em> <span class="No-Break"><st c="71072">application (</st></span><span class="No-Break"><strong class="source-inline"><st c="71086">ch11-asgi</st></strong></span><span class="No-Break"><st c="71096">).</st></span></p>
			<p><st c="71099">A Kubernetes pod undergoes </st><strong class="bold"><st c="71127">Running</st></strong><st c="71134">, </st><strong class="bold"><st c="71136">Waiting</st></strong><st c="71143">, and </st><strong class="bold"><st c="71149">Terminated</st></strong><st c="71159"> states. </st><st c="71168">The goal is for the Pods to stay </st><em class="italic"><st c="71201">Running</st></em><st c="71208">. But when problems arise, such as encountering database configuration errors, binding to existing ports, lack of Kubernetes objects, lack of permission on files, and applications throwing memory and runtime errors, Pods emit </st><strong class="source-inline"><st c="71434">CrashLoopBackOff</st></strong><st c="71450"> and stay in </st><strong class="bold"><st c="71463">Awaiting</st></strong><st c="71471"> mode. </st><st c="71478">To avoid Pods crashing, always carefully review the definitions files before applying them and monitor the logs of running Pods from time </st><span class="No-Break"><st c="71616">to time.</st></span></p>
			<p><st c="71624">Sometimes, a Docker or Kubernetes deployment requires adding a reverse proxy server to manage all the incoming requests of the deployed applications. </st><st c="71775">In the next section, we’ll add the </st><em class="italic"><st c="71810">NGINX</st></em><st c="71815"> gateway server to our containerized </st><span class="No-Break"><strong class="source-inline"><st c="71852">ch11-asgi</st></strong></span><span class="No-Break"><st c="71861"> application.</st></span></p>
			<h1 id="_idParaDest-313"><a id="_idTextAnchor320"/><st c="71874">Creating an API gateway using NGINX</st></h1>
			<p><st c="71910">Our deployment needs </st><strong class="bold"><st c="71932">NGINX</st></strong><st c="71937"> to manage the high traffic of incoming requests from clients, load </st><a id="_idIndexMarker1126"/><st c="72005">balance the requests across the server groups, add some HTTP caches, or add security to filter suspicious access. </st><st c="72119">NGINX is a stable </st><a id="_idIndexMarker1127"/><st c="72137">HTTP server that can be installed on Linux-based operating systems. </st><st c="72205">In this chapter, NGINX is part of our Docker deployment, which consists of our </st><strong class="source-inline"><st c="72284">ch11-asgi</st></strong><st c="72293"> app and PostgreSQL database platform. </st><st c="72332">It will serve as the facade of the Gunicorn server running </st><span class="No-Break"><st c="72391">our application.</st></span></p>
			<p><st c="72407">Here, </st><strong class="source-inline"><st c="72414">ch11-asgi-dep-nginx</st></strong><st c="72433"> is a Docker Compose folder consisting of the </st><strong class="source-inline"><st c="72479">ch11-asgi</st></strong><st c="72488"> project directory, which contains a Dockerfile, the </st><strong class="source-inline"><st c="72541">docker-compose.yaml</st></strong><st c="72560"> file, and the </st><strong class="source-inline"><st c="72575">nginx</st></strong><st c="72580"> folder containing a Dockerfile and our NGINX configuration settings. </st><st c="72650">The following is the </st><strong class="source-inline"><st c="72671">nginx.conf</st></strong><st c="72681"> file that’s used by Compose to set up our </st><span class="No-Break"><st c="72724">NGINX server:</st></span></p>
			<pre class="source-code"><st c="72737">
server {
    </st><strong class="bold"><st c="72747">listen 80</st></strong><st c="72756">;
    </st><strong class="bold"><st c="72759">server_name localhost</st></strong><st c="72780">;
    </st><strong class="bold"><st c="72783">location /</st></strong><st c="72793"> {
        </st><strong class="bold"><st c="72796">proxy_pass</st></strong><st c="72806"> http://ch11-asgi-dep-nginx-api-1:8000/;
        proxy_set_header </st><strong class="bold"><st c="72864">X-Forwarded-For</st></strong><st c="72879"> $proxy_add_x_forwarded_for;
        proxy_set_header </st><strong class="bold"><st c="72925">X-Forwarded-Proto</st></strong><st c="72942"> $scheme;
        proxy_set_header </st><strong class="bold"><st c="72969">X-Forwarded-Host</st></strong><st c="72985"> $host;
        proxy_set_header </st><strong class="bold"><st c="73010">X-Forwarded-Prefix</st></strong><st c="73028"> /;
    }
}</st></pre>			<p><st c="73035">The NGINX configuration depends on its installation setup, the applications that have been deployed to the servers, and the server architecture. </st><st c="73181">Ours is for a reverse proxy NGINX </st><a id="_idIndexMarker1128"/><st c="73215">server of our application deployed on a single server. </st><st c="73270">NGINX </st><a id="_idIndexMarker1129"/><st c="73276">will allow access to our application through </st><strong class="source-inline"><st c="73321">localhost</st></strong><st c="73330"> and port </st><strong class="source-inline"><st c="73340">80</st></strong><st c="73342"> instead of </st><strong class="source-inline"><st c="73354">http://ch11-asgi-dep-nginx-api-1:8000</st></strong><st c="73391">, as indicated in </st><strong class="source-inline"><st c="73409">proxy_pass</st></strong><st c="73419">. Since we don’t have a new domain name, </st><strong class="source-inline"><st c="73460">localhost</st></strong><st c="73469"> will be the proxy’s hostname. </st><st c="73500">The de facto request headers, such as </st><strong class="source-inline"><st c="73538">X-Forwarded-Host</st></strong><st c="73554">, </st><strong class="source-inline"><st c="73556">X-Forwarded-Proto</st></strong><st c="73573">, </st><strong class="source-inline"><st c="73575">X-Forwarded-Host</st></strong><st c="73591">, and </st><strong class="source-inline"><st c="73597">X-Forwarded-Prefix</st></strong><st c="73615">, will collectively help the load balancing mechanism during NGINX’s interference on </st><span class="No-Break"><st c="73700">a request.</st></span></p>
			<p><st c="73710">When the </st><strong class="source-inline"><st c="73720">docker-compose</st></strong><st c="73734"> command runs the YAML file, NGINX’s Dockerfile will pull the latest </st><strong class="source-inline"><st c="73803">nginx</st></strong><st c="73808"> image and copy the given </st><strong class="source-inline"><st c="73834">nginx.conf</st></strong><st c="73844"> settings to the </st><strong class="source-inline"><st c="73861">/etc/nginx/conf.d/</st></strong><st c="73879"> directory of its container. </st><st c="73908">Then, it will instruct the container to run the NGINX server using the </st><strong class="source-inline"><st c="73979">nginx -g daemon </st></strong><span class="No-Break"><strong class="source-inline"><st c="73995">off</st></strong></span><span class="No-Break"><st c="73998"> command.</st></span></p>
			<p><st c="74007">Adding NGINX makes the deployed application manageable, scalable, and maintainable. </st><st c="74092">It can also centralize user request traffic in a microservice architecture, ensuring that the access reaches the expected API endpoints, containers, </st><span class="No-Break"><st c="74241">or sub-modules.</st></span></p>
			<h1 id="_idParaDest-314"><a id="_idTextAnchor321"/><st c="74256">Summary</st></h1>
			<p><st c="74264">There are several solutions and approaches to migrating a Flask application from the development to the production stage. </st><st c="74387">The most common server that’s used to run Flask’s WSGI applications in production is Gunicorn. </st><st c="74482">uWSGI, on the other hand, can run WSGI applications in more complex and refined settings. </st><st c="74572">Flask[async] applications can run on Uvicorn workers with a </st><span class="No-Break"><st c="74632">Gunicorn server.</st></span></p>
			<p><st c="74648">For external server-based deployment, the Apache HTTP Server with Python provides a stable and reliable container for running Flask applications with the support of Python’s </st><span class="No-Break"><strong class="source-inline"><st c="74823">mod_wsgi</st></strong></span><span class="No-Break"><st c="74831"> module.</st></span></p>
			<p><st c="74839">Flask applications can also run on containers through Docker and Docker Compose to avoid the nitty gritty configuration and installations in the Apache HTTP Server. </st><st c="75005">In Dockerization, what matters is the Dockerfile for a single deployment or the </st><strong class="source-inline"><st c="75085">docker-compose.yaml</st></strong><st c="75104"> file for multiple deployments and the combinations of Docker instructions that will contain these configuration files. </st><st c="75224">For a more distributed, flexible, and complex orchestration, Kubernetes’s Pods and Services can aid a better deployment scheme for </st><span class="No-Break"><st c="75355">multiple deployments.</st></span></p>
			<p><st c="75376">To manage incoming requests across the servers, the Gunicorn servers running in containers can work with NGINX for reverse proxy, load balancing, and additional HTTP security protocols. </st><st c="75563">A good NGINX setting can provide a better facade for the entire </st><span class="No-Break"><st c="75627">production setup.</st></span></p>
			<p><st c="75644">Generally, the deployment procedures that were created, applied, and utilized in this chapter are translatable, workable, and reversible to other more modern and advanced approaches, such as deploying Flask applications to Google Cloud and AWS cloud services. </st><st c="75905">Apart from deployment, Flask has the edge to compete with other frameworks when dealing with innovation and building </st><span class="No-Break"><st c="76022">enterprise-grade solutions.</st></span></p>
			<p><st c="76049">In the next chapter, we will showcase the use of the Flask platform in providing middleware solutions to many </st><span class="No-Break"><st c="76160">popular integrations.</st></span></p>
		</div>
	<div id="charCountTotal" value="76181"/></body></html>