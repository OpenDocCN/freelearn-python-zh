- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators and Coroutines – Infinity, One Step at a Time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generator functions are functions that behave like iterators by generating the
    return values one by one. While traditional methods build and return a `list` or
    `tuple` of items with a fixed length, a generator will `yield` a single value
    only when requested by the caller. The side effect is that these generators can
    be infinitely large because you can keep yielding forever.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to generators, there is a variation to the generator’s syntax that
    creates coroutines. Coroutines are functions that allow multitasking without requiring
    multiple threads or processes. Whereas generators can only yield values to the
    caller based on the initial arguments, coroutines enable two-way communication
    with the calling function while running. The modern implementation of coroutines
    in Python is through the `asyncio` module, which is covered extensively in *Chapter
    13,* *asyncio – Multithreading without Threads*, but the basics stem from the
    coroutines discussed in this chapter. If coroutines or `asyncio` work for your
    case, they can offer a tremendous performance improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and disadvantages of generators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The characteristics and quirks of generators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating generators using regular functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generator comprehensions similar to `list`, `dict`, and `set` comprehensions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating generators using classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generators bundled with Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A basic implementation of coroutines and a few of their quirks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators are a very useful tool but they come with a set of rules to keep
    in mind.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s explore the advantages of generators:'
  prefs: []
  type: TYPE_NORMAL
- en: Generators are often simpler to write than list-generating functions. Instead
    of having to declare a `list`, `list.append(value)`, and `return`, you only need
    `yield value`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory usage. Items can be processed one at a time, so there is generally no
    need to keep the entire list in memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Results can depend on outside factors. Instead of having a static list, you
    generate the value when it is being requested. Think of processing a queue/stack,
    for example.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generators are lazy. This means that if you’re using only the first five results
    of a generator, the rest won’t even be calculated. Additionally, between fetching
    the items, the generator is completely frozen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The most important disadvantages are:'
  prefs: []
  type: TYPE_NORMAL
- en: Results are available only once. After processing the results of a generator,
    it cannot be used again.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The size is unknown. Until you are done processing, you cannot get any information
    about the size of the generator. It might even be infinite. This makes `list(some_infinite_generator)`
    a dangerous operation. It can quickly crash your Python interpreter or even your
    entire system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slicing is not possible, so `some_generator[10:20]` will not work. You can work
    around this using `itertools.islice` as you will see later in this chapter, but
    that effectively discards the unused indices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Indexing generators, similar to slicing, is also not possible. This means that
    the following will not work: `some_generator[5]`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you know what to expect, let’s create a few generators.
  prefs: []
  type: TYPE_NORMAL
- en: Creating generators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The simplest generator is a function containing a `yield` statement instead
    of a `return` statement. The key difference with regular functions containing
    a `return` is that you can have many `yield` statements in your function.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of a generator with a few fixed `yield` statements and how it behaves
    with several operations is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: A few of the downsides of generators become immediately apparent in this example.
    The `result` does not offer much meaningful information when looking at its `repr()`,
    getting `len()` (length), or slicing. And trying to do `list()` to get the values
    a second time does not work because the generator is already exhausted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, you may have noticed that the `return` value of the function
    appears to have completely disappeared. This is actually not the case; the value
    of `return` is still used, but as the value for the `StopIteration` exception
    raised by the generator to indicate that the generator has been exhausted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The following example demonstrates the lazy execution of generators:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in this example, the code after the `yield` isn’t executed.
    This is caused by the `StopIteration` exception; if we properly catch this exception,
    the code will be executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: To properly handle generators, you always need to either catch the `StopIteration`
    yourself, or use a loop or another structure that handles the `StopIteration`
    implicitly.
  prefs: []
  type: TYPE_NORMAL
- en: Creating infinite generators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating an endless generator (such as the `itertools.count` iterator discussed
    in *Chapter 5*, *Functional Programming – Readability Versus Brevity*) is easy
    as well. If, instead of having the fixed `yield <value>` lines like in the previous
    function, we `yield` from inside of an infinite loop, we can easily make an infinite
    generator.
  prefs: []
  type: TYPE_NORMAL
- en: 'As opposed to the `itertools.count()` generator, we will add a `stop` parameter
    to make testing easier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Due to the potentially infinite nature of generators, caution is required. Without
    the `stop` variable, simply doing `list(count())` would result in an infinite
    loop that results in an out-of-memory situation quite fast.
  prefs: []
  type: TYPE_NORMAL
- en: So, how does this work? Essentially it is just a normal loop, but the big difference
    between this and the regular method of returning a list of items is that the `yield` statement
    returns the items one at a time, which means you only have to calculate the requested
    items and you don’t have to keep all results in memory.
  prefs: []
  type: TYPE_NORMAL
- en: Generators wrapping iterables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While generators are already quite useful when generating values from scratch,
    the real power comes when wrapping other iterables. To illustrate this, we will
    create a generator that automatically squares all numbers from the given input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Naturally, there is nothing stopping you from adding extra `yield` statements
    outside of the loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Because these generators are iterable, you can chain them together by wrapping
    them as many times as you like. A basic example of chaining a `square()` and an
    `odd()` generator together is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'If we analyze how the code is executed, we need to start from the inside to
    the outside:'
  prefs: []
  type: TYPE_NORMAL
- en: The `range(10)` statement generates 10 numbers for us.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `odd()` generator filters the input values, so from the `[0, 1, 2 … ]` values
    it only returns `[1, 3, 5, 7, 9]`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `square()` function squares the given input, which is the list of odd numbers
    as generated by `odd()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The real power of chaining is that the generators will only do something when
    we request a value. If we request a single value with `next()` instead of `list()`,
    it will mean that only the first iteration of the loop in `square()` will be run.
    For `odd()` and `range()`, however, it will have to process two values because
    `odd()` will discard the first value given by `range()` and not `yield` anything.
  prefs: []
  type: TYPE_NORMAL
- en: Generator comprehensions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous chapters, you saw `list`, `dict`, and `set` comprehensions,
    which generate collections. With a generator comprehension we can make similar
    collections, but make them lazy so they are only evaluated as needed. The basic
    premise is identical to the `list` comprehension but using round brackets/parentheses
    instead of square brackets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This is very useful when you need to wrap the results of a different generator
    because it only calculates the values you asked for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As you can probably surmise from this result, this can be dangerous with infinite-sized
    generators such as `itertools.count()`. The order of operations is very important
    because the `itertools.islice()` function slices the result at that point, not
    the original generator. This means that if we replace `odd()` with a function
    that never evaluates to `True` for the given collection, it will run forever because
    it will never `yield` any results.
  prefs: []
  type: TYPE_NORMAL
- en: Class-based generators and iterators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to creating generators as regular functions and through generator
    comprehensions, we can also create generators using classes. This can be beneficial
    for more complex generators where you need to remember the state or where inheritance
    can be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s look at an example of creating a basic generator `class` that
    mimics the behavior of `itertools.count()` with an added `stop` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s convert the generator class into an iterator with more features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The most important distinction between the generator and the iterator is that
    instead of a simple iterable object, we now have a fully fledged class that acts
    as an iterator, which means we can also expand it beyond the capabilities of regular
    generators.
  prefs: []
  type: TYPE_NORMAL
- en: 'A few of the limitations of regular generators are that they don’t have a length
    and we cannot slice them. With an iterator, we can explicitly define the behavior
    in these scenarios if needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have our advanced count iterator with support for features such
    as `len()`, `in`, and `repr()`, we can test to see if it works as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In addition to working around some of the limitations, in the last example,
    you can also see a very useful feature of generators. We can exhaust the items
    one by one and stop/start whenever we want. And since we still have full access
    to the object, we could alter `count.i` to restart the iterator.
  prefs: []
  type: TYPE_NORMAL
- en: Generator examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you know how generators can be created, let’s look at a few useful
    generators and examples of how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Before you start writing a generator for your project, always make sure to look
    at the Python `itertools` module. It features a host of useful generators that
    cover a vast array of use cases. The following sections show some custom generators
    and a few of the most useful generators in the standard library.
  prefs: []
  type: TYPE_NORMAL
- en: These generators work on all iterables, not just generators. So, you could also
    apply them to a `list`, `tuple`, `string`, or other kinds of iterables.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking an iterable up into chunks/groups
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When executing large amounts of queries in a database or when running tasks
    via multiple processes, it is often more efficient to chunk the operations. Having
    a single huge operation could result in out-of-memory issues; having many tiny
    operations can be slow due to start-up/teardown sequences.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make things more efficient, a good method is to split the input into chunks.
    The Python documentation ([https://docs.python.org/3/library/itertools.html?highlight=chunk#itertools-recipes](https://docs.python.org/3/library/itertools.html?highlight=chunk#itertools-recipes))
    already comes with an example of how to do this by using `itertools.zip_longest()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This code is a very nice example of how easy it is to chunk your data, but
    it has to hold the entire chunk in memory. To work around that, we can create
    a version that generates sub-generators for the chunks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Because we need to catch the `StopIteration` exceptions, this example does not
    look very pretty in my opinion. Part of the code could be improved by using `itertools.islice()`
    (which is covered next) but that will still leave us with the problem that we
    cannot know when we have reached the end.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are interested, an implementation using `itertools.islice()` and `itertools.chains()`
    can be found on this book’s GitHub: [https://github.com/mastering-python/code_2](https://github.com/mastering-python/code_2).'
  prefs: []
  type: TYPE_NORMAL
- en: itertools.islice – Slicing iterables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One limitation of generators is that they cannot be sliced. You can work around
    this by converting the generator into a `list` before slicing, but that is not
    possible with infinite generators, and it can be inefficient if you only need
    a few values.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this, the `itertools` library has an `islice()` function, which can
    slice any iterable object. The function is the generator version of the slicing
    operators and similarly to slicing supports a `start`, `stop`, and `step` parameter.
    The following illustrates how regular slicing and `itertools.islice()` compare:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: It is very important to note that while the output is identical, these methods
    are far from equivalent internally. Regular slicing only works on objects that
    are sliceable; effectively, this means the object has to implement the `__getitem__(self,
    slice)` method.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we expect that slicing objects is a fast and efficient operation.
    For `list` and `tuple` this is certainly the case, but for a given generator this
    might not be the case.
  prefs: []
  type: TYPE_NORMAL
- en: If for a list with size `n=1000` we take any slice of any `k=10` elements, we
    can expect the time complexity of that to be only `O(k)`; that is, 10 steps. It
    doesn’t matter whether we do `some_list[:10]` or `some_list[900:920:2]`.
  prefs: []
  type: TYPE_NORMAL
- en: For `itertools.islice()` this is not the case because the only assumption it
    makes is that the input is iterable. That means that getting the first 10 items
    is easy; simply loop through the items, return the first 10, and stop. So `itertools.islice(some_list,
    10)` also takes 10 steps. Getting items 900 to 920, however, means walking through
    and discarding the first 900 items, and only returning 10 of the next 20 items.
    So that is 920 steps instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this, here’s a slightly simplified implementation of `itertools.islice()`
    that expects to always have a `stop` available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, both the `start` and the `step` sections discard items that
    are not needed. This does not mean you should not use `itertools.islice()`, but
    be wary of the internals. Also, as you might expect, this generator does not support
    negative values for the indices and expects all values to be positive.
  prefs: []
  type: TYPE_NORMAL
- en: itertools.chain – Concatenating multiple iterables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `itertools.chain()` generator is one of the simplest yet one of the most
    useful generators in the Python library. It simply returns every item from every
    passed iterable in sequential order and can be implemented in just three lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'As you might notice, this also introduces a feature not yet discussed: the
    `yield from` expression. `yield from` does exactly what you can expect from the
    name and yields all items from the given iterable. So `itertools.chain()` can
    also be replaced with the slightly more verbose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Interestingly, this method is more powerful than adding the collections because
    it doesn’t care about the types as long as they are iterable—duck typing at its
    finest.
  prefs: []
  type: TYPE_NORMAL
- en: itertools.tee – Using an output multiple times
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned before, one of the biggest disadvantages of generators is that
    the results are usable only once. Luckily, Python has a function that allows you
    to copy the output to several generators. The name `tee` might be familiar to
    you if you are used to working in a Linux/Unix command-line shell. The `tee` program
    allows you to write outputs to both the screen and a file, so you can store an
    output while still maintaining a live view of it.
  prefs: []
  type: TYPE_NORMAL
- en: The Python version, `itertools.tee()`, does a similar thing except that it returns
    several iterators, allowing you to process the results separately.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, `tee` will split your generator into a tuple containing two different
    generators, which is why tuple unpacking works nicely here. By passing along the `n` parameter,
    you can tell `itertools.tee()` to create more than two generators. Here is an
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: After seeing this code, you might be wondering about the memory usage of `tee`.
    Does it need to store the entire list for you? Luckily, no. The `tee` function
    is pretty smart in handling this. Assume you have a generator that contains 1,000
    items, and you read the first 100 items from `a` and the first `75` items from `b` simultaneously.
    Then `tee` will only keep the difference (`100 - 75 = 25` items) in memory and
    drop the rest while you are iterating the results.
  prefs: []
  type: TYPE_NORMAL
- en: Whether `tee` is the best solution in your case or not depends, of course. If
    instance `a` is read from the beginning to (nearly) the end before instance `b` is
    read, then it would not be a great idea to use `tee`. Simply converting the generator
    into a `list` would be faster since it involves much fewer operations.
  prefs: []
  type: TYPE_NORMAL
- en: contextlib.contextmanager – Creating context managers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You have already seen context managers in *Chapter 5*, *Functional Programming
    – Readability Versus Brevity*, and *Chapter 6*, *Decorators – Enabling Code Reuse
    by Decorating*, but there are many more useful things to be done with context
    managers. While the `contextlib.contextmanager()` generator is not meant to be
    a result-generating generator like the examples you saw earlier in this chapter,
    it does use `yield`, so it’s a nice example of non-standard generator usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some useful examples to log your output to a file and measure function execution
    time are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This all works perfectly, but the code could be prettier. Having three levels
    of context managers tends to get a bit unreadable, which is something you could
    generally solve using decorators, as covered in *Chapter 6*. In this case, however,
    we need the output from one context manager as the input for the next, which would
    make for a more complicated decorator setup.
  prefs: []
  type: TYPE_NORMAL
- en: 'That’s where the `ExitStack` context manager comes in. It allows the easy combining
    of multiple context managers without increasing the indentation level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Looks a bit simpler, doesn’t it? While this example is still reasonably legible
    without the `ExitStack` context manager, the convenience of `ExitStack` becomes
    quickly apparent when you need to do specific teardowns. In addition to the automatic
    handling, as seen before, it’s also possible to transfer the contexts to a new `ExitStack` to
    manually handle the closing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Most of the `contextlib` functions have extensive documentation available in
    the Python manual. `ExitStack` in particular is documented using many examples
    at [https://docs.python.org/3/library/contextlib.html#contextlib.ExitStack](https://docs.python.org/3/library/contextlib.html#contextlib.ExitStack).
    I recommend keeping an eye on the `contextlib` documentation as it is improving
    greatly with every Python version.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have covered regular generators, it is time to continue with coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Coroutines are subroutines that offer non-pre-emptive multitasking through multiple
    entry points. The basic premise is that coroutines allow two functions to communicate
    with each other while running within a single thread. Normally, this type of communication
    is reserved only for multitasking or multithreading solutions, but coroutines
    offer a relatively simple way of achieving this at almost no added performance
    cost.
  prefs: []
  type: TYPE_NORMAL
- en: Since generators are lazy by default, you might be able to guess how coroutines
    function. Until a result is consumed, the generator sleeps; but while consuming
    a result, the generator becomes active. The difference between regular generators
    and coroutines is that with coroutines the communication goes both ways; the coroutine
    can receive values as well as `yield` them to the calling function.
  prefs: []
  type: TYPE_NORMAL
- en: If you are familiar with `asyncio` you might notice a strong similarity between
    `asyncio` and coroutines. That is because `asyncio` is built on the idea of coroutines
    and has evolved from a little bit of syntactic sugar into a whole ecosystem. For
    practical purposes I would suggest using `asyncio` instead of the coroutine syntax
    explained here; for educational purposes, however, it is very useful to understand
    how they work. The `asyncio` module is under very active development and has a
    much less awkward syntax.
  prefs: []
  type: TYPE_NORMAL
- en: A basic example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous sections, you saw how regular generators can `yield` values.
    But generators can do more; they can actually receive values through `yield` as
    well. The basic usage is fairly simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: And that’s all there is to it. The function is frozen until the `send` method
    is called, at which point it will process up to the next `yield` statement. One
    limitation you can see from this is that the coroutine can’t wake up by itself.
    The value exchanges can only happen when the calling code runs `next(generator)`
    or `generator.send()`.
  prefs: []
  type: TYPE_NORMAL
- en: Priming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since generators are lazy, you can’t just send a value to a brand-new generator.
    Before a value can be sent to the generator, either a result must be fetched using `next()` or
    a `send(None)` has to be issued so that the code is actually reached. This is
    understandable, but a bit tedious at times. Let’s create a simple decorator to
    omit the need for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As you’ve probably noticed, even though the generator is still lazy, it now
    automatically executes all of the code until it reaches the `yield` statement
    again. At that point, it will stay dormant until new values are sent.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `coroutine` decorator will be used throughout this chapter from
    this point onward. For brevity, the coroutine function definition will be omitted
    from the following examples.
  prefs: []
  type: TYPE_NORMAL
- en: Closing and throwing exceptions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike regular generators, which simply exit as soon as the input sequence is exhausted,
    coroutines generally employ infinite `while` loops, which means that they won’t
    be torn down the normal way. That’s why coroutines also support both the `close` and `throw` methods,
    which will exit the function. The important thing here is not the closing but
    the possibility of adding a teardown method. Essentially, it is very comparable
    to how context wrappers function with an `__enter__` and `__exit__` method, but
    with coroutines in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows a coroutine with normal and exception exit cases
    using the `coroutine` decorator from the previous paragraph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This `simple_coroutine()` function can show us some of the internal flow of
    coroutines and how they are interrupted. The `try`/`finally` behavior might surprise
    you in particular:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Most of this output is as you would expect, but as was the case with the `StopIteration`
    in generators, you have to catch the exception to be sure the teardown is handled
    correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Mixing generators and coroutines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While generators and coroutines appear to be very similar due to the `yield`
    statements, they are somewhat different beasts. Let’s create a two-way pipeline
    to process the given input and pass this along to multiple coroutines along the
    way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Given this example, you might be wondering why we are now printing the value
    instead of yielding it. We can `yield` the value, but remember that generators
    freeze until a value is yielded. Let’s see what will happen if we simply `yield` the
    value instead of calling `print`. By default, you might be tempted to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Half of the values have disappeared now; our “`really really new`" line has
    disappeared. Notice that the second `yield` isn’t storing the results, and that
    `yield` effectively makes this a generator and not a coroutine. We need to store
    the results from that `yield` as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: But even this is far from optimal. We are essentially using coroutines to mimic
    the behavior of generators right now. It works, but it is a bit pointless and
    offers no real benefit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make a real pipeline this time where the coroutines send the data to
    the next coroutine or coroutines. This demonstrates the real power of coroutines,
    which is being able to chain multiple coroutines together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have our coroutine functions, let’s see how we can link these together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This makes the code much simpler and more readable and shows how you can send
    a single input source to multiple destinations simultaneously. At first glance,
    this example does not look that exciting, but the exciting part is that even though
    we split the input using `tee()` and processed it through two separate `replace()`
    instances, we still ended up at the same `print_()` function with the same state.
    This means that it’s possible to route and modify your data along whichever way
    is convenient for you while still having it end up at the same endpoint with no
    effort whatsoever.
  prefs: []
  type: TYPE_NORMAL
- en: For now, the most important takeaway is that mixing generators and coroutines
    is not a good idea in most cases since it can have very strange side effects if
    used incorrectly. Even though both use the `yield` statement, they are significantly
    different creatures with different behavior. The next section will demonstrate
    one of the few cases where mixing coroutines and generators can be useful.
  prefs: []
  type: TYPE_NORMAL
- en: Using the state
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that you know how to write basic coroutines and which pitfalls you have
    to take care of, how about writing a function where remembering the state is required?
    That is, a function that always gives you the average value of all sent values.
    This is one of the few cases where it is still relatively safe and useful to combine
    the coroutine and generator syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'It still requires some extra logic to work properly, though. We need to prime
    our coroutine using `yield`, but we don’t send any data at that point because
    the first `yield` is the primer and is executed before we get the value. Once
    that’s all set up, we can easily yield the average value while summing. It’s not
    all that bad, but the pure coroutine version is slightly simpler to understand
    since we only have a single execution path because we don’t have to worry about
    priming. To illustrate this, here is the pure coroutine version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'While that example is a few lines longer than the version that includes a generator,
    it is much easier to understand. Let’s analyze it to make sure the workings are
    clear:'
  prefs: []
  type: TYPE_NORMAL
- en: We set `total` to `0` to start counting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We keep track of the measurement count by using `itertools.count()`, which we
    configure to start counting from 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We fetch the next value using `yield`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We send the average to the given coroutine instead of returning the value to
    make the code less confusing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Another nice example is `itertools.groupby`, which is also quite simple to
    recreate using coroutines. For comparison, I will once again show both the generator
    coroutine and the pure coroutine version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this function uses a few tricks. Firstly, we store the previous `key` and `value` so
    that we can detect when the group (`key`) changes. Secondly, we obviously cannot
    recognize a group until the group has changed, so only after the group has changed
    will the results be returned. This means that the last group will be sent only
    if a different group is sent after it, hence the `(None, None)`.
  prefs: []
  type: TYPE_NORMAL
- en: The example uses tuple unpacking for the string, splitting `'a1'` into group
    `'a'` and value `'1'`. Alternatively, you could also use `grouper.send(('a', 1))`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now here is the pure coroutine version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: While the functions are fairly similar, the coroutine version has a less complex
    control path and only needs to `yield` in one spot. This is because we don’t have
    to think about priming and potentially losing values.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generators have a multitude of uses so you can probably start using them in
    your own code right away. Nevertheless, the following exercises might help you
    understand the features and the limitations a bit better:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a generator similar to `itertools.islice()` that allows for a negative
    step so you can execute `some_list[20:10:-1]`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a class that wraps a generator so it becomes sliceable by using `itertools.islice()`
    internally.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write a generator for the Fibonacci numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write a generator that uses the sieve of Eratosthenes to generate prime numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example answers for these exercises can be found on GitHub: [https://github.com/mastering-python/exercises](https://github.com/mastering-python/exercises).
    You are encouraged to submit your own solutions and learn about alternative solutions
    from others.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter showed you how to create generators and both the strengths and
    weaknesses that they possess. Additionally, it should now be clear how to work
    around their limitations and the implications of doing so.
  prefs: []
  type: TYPE_NORMAL
- en: In general, I would always recommend the use of generators over traditional
    collection-generating functions. They are easier to write, consume less memory,
    and, if needed, the downsides can be mitigated by replacing `some_generator()`
    with `list(some_generator())`, or a decorator that handles that for you.
  prefs: []
  type: TYPE_NORMAL
- en: While the paragraphs about coroutines provided some insights into what they
    are and how they can be used, they were just a mild introduction to coroutines.
    Both the pure coroutines and the coroutine generator combinations are still somewhat
    clunky, which is why the `asyncio` library was created. *Chapter 13,* *- asyncio
    – Multithreading without Threads,* covers `asyncio` in detail and also introduces
    the `async` and `await` statements, which make coroutine usage much more intuitive
    compared to `yield`.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, you saw how we can modify classes using class decorators.
    In the next chapter, we will cover the creation of classes using metaclasses.
    Using metaclasses, you can modify classes during the creation of the class itself.
    Note that I am not talking about the instances of the class, but the actual class
    object. Using this technique, you can create automatically registering plugin
    systems, add extra attributes to classes, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers: [https://discord.gg/QMzJenHuJf](https://discord.gg/QMzJenHuJf)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code156081100001293319171.png)'
  prefs: []
  type: TYPE_IMG
