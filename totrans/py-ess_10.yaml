- en: Chapter 10. Files, Databases, Networks, and Contexts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Files and the filesystem are central to the way modern OSs work. Many OS resources
    are visible as part of the filesystem. For example, the Linux `/dev/mem` is a
    view into the processor's memory, implemented as a device visible in the filesystem.
    Python provides file objects that map to these OS features.
  prefs: []
  type: TYPE_NORMAL
- en: At a fundamental level, OS files are simply collections of bytes. In practice,
    we often work with files that are collections of Unicode characters. Python offers
    both views of files. With some file formats, we need to process the bytes. With
    text files, we expect Python to properly decode Unicode characters from the bytes.
  prefs: []
  type: TYPE_NORMAL
- en: A Python file object will generally be entangled with an OS resource. In order
    to be sure that an application doesn't leak OS resources, we often use a context
    manager. This allows us to be sure that OS resources are released when Python
    files are closed. The `with` statement provides a tidy way to work with a context
    manager to allocate and de-allocate resources.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to ordinary files, we'll look at TCP/IP sockets. The `urllib` module
    allows us to open a socket to a remote host. The socket is used like a file to
    read the data from the remote host.
  prefs: []
  type: TYPE_NORMAL
- en: A file has a physical format; all but the simplest formats require a `library`
    module to read and write the content properly. Additionally, within the constraints
    of a physical format, there may be variations in the logical layout of the data.
    A **comma-separated values** (**CSV**) file, for example, may use field names
    in the first line of the file to describe the logical layout of the columns.
  prefs: []
  type: TYPE_NORMAL
- en: A SQLite database or a `shelve` database relies on one (or more) file to make
    the data persistent. We'll look briefly at higher-level constructs which rely
    on files.
  prefs: []
  type: TYPE_NORMAL
- en: The essential file concept
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modern OSs rely on files and device drivers for a variety of services and features.
    Bytes on a disk drive are only one type of file.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since many storage devices use or include **Solid State Drives** (**SSD**) the
    term "disk" is technically a misnomer; we'll use the outdated term.
  prefs: []
  type: TYPE_NORMAL
- en: A network adapter is another kind of file; one in which bytes are available
    continuously, instead of appearing at rest. In addition to disk and network files,
    the Linux filesystem includes the `/dev` directory, which describes all of the
    devices on a given computer. These devices include serial ports, references to
    memory, and even a device which accumulates an entropy pool to provide random
    bytes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Python file object wraps an OS file. The `open()` function binds a Python
    file object to an OS file. In addition to a name, the function expects a mode
    string for access. The mode string combines two features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Characters versus bytes**: By default, a file is opened in text mode; we
    can make this explicit by using `t`. When reading, the OS bytes are decoded to
    create Unicode characters. When writing, the Unicode characters are encoded into
    bytes. To use bytes instead of text, we include `b` in the mode; no encoding or
    decoding will be done.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Allowed operations**: By default, a file is opened in `r` mode which allows
    reading only. We can open a file in `w` mode which will remove any previous content
    and allow writing only. We can open a file in `a` mode which will search to the
    end of the previous content so that new content can be appended. The `+` modifier
    allows both reading and writing; this means that `w+` removes any previous content
    and allows reading and writing; `r+` leaves the previous content in place and
    allows reading and writing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we open a text file, we provide explicit encoding. In some cases, explicit
    encoding is required because the encoding expected by the OS isn't in the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, we may also need to specify how newline characters should be
    handled. On input, we rarely need to specify line endings: Python handles them
    gracefully by translating Windows `\r\n` to `\n`. On output, however, we might
    need to explicitly provide the line ending. If we set `newline=""`, then no translation
    is performed; we''ll need this so that we can create CSV files with `\r\n` line
    endings. If we set `newline=None` when opening a file, then `\n` from our program''s
    output translates the platform-specific value in the `os.linesep` variable. This
    is the default behavior. Any other values for `newline` replace the `\n` characters
    in our output.'
  prefs: []
  type: TYPE_NORMAL
- en: We can specify buffering. We can also specify how Unicode decoding errors are
    handled. There are seven choices for Unicode errors, including `strict`, `ignore`,
    `replace`, `xmlcharrefreplace`, `backslashreplace`, and `surrogateescape`. The
    `strict` error handling raises an exception. The `ignore` error handling quietly
    drops the illegal character. The other choices offer different kinds of replacement
    strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Opening text files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For processing text files, here''s how to create the file object using the
    `open()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We've opened a file using all of the default settings. The mode will be read-only.
    The file must use the system's default encoding (Mac-Roman, for example). We'll
    rely on the default buffering and the default Unicode error handling, which is
    `strict`.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we read the entire file into a giant string and then split
    that single string into a sequence of individual lines. We assigned the list of
    strings to the `text` variable. We only displayed the first five items from this
    list. By default, the string `split()` method does not preserve the split character.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering text lines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll look at two key concepts in the following examples. We''ll start by
    opening a file that''s encoded using `"utf-8"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We've opened a file with the mode `"rt",` which means read-only and text. This
    is the default, so it could have been omitted. We've explicitly provided `"utf-8"`
    encoding, which is not the OS default.
  prefs: []
  type: TYPE_NORMAL
- en: 'We used the `list()` function to convert the file object into a sequence of
    lines. When we use a file object as if it is an iterable, we''ll see that the
    file iterates over lines. If we don''t change the newline setting for the file,
    then the "universal newlines" rules are used: `\n`, `\r`, or `\r\n` will end a
    line; they''re normalized to `\n`. When we process a file as lines, the line ending
    characters are preserved.'
  prefs: []
  type: TYPE_NORMAL
- en: We often want to remove newline characters from the end of each line. This is
    a kind of mapping from raw lines to lines with trailing whitespace stripped. We
    can use a generator expression or the `map()` function and the `str.rstrip()`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, an empty line has no meaning and can be removed. This, too,
    can be done with a generator expression that has an `if` clause to reject empty
    lines. We can also do it with a `filter()` function. It''s easier if we write
    these map and filter operations in two lines, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We've broken down the input cleanup into two generator expressions. The first
    generator expression, `txt_stripped`, maps raw lines to lines with trailing whitespace
    stripped. The second generator expression, `txt_non_empty`, is a filter which
    rejects lines that are empty. We could easily add other filter conditions to the
    `if` clause. Since generator expressions are lazy, nothing is really done until
    the final `list()` function consumes all of the lines from the generators.
  prefs: []
  type: TYPE_NORMAL
- en: In this way, we can design fairly sophisticated file parsing as a collection
    of generator expressions. We can apply a number of mapping and filtering operations
    so that the main suite of statements has only clean data.
  prefs: []
  type: TYPE_NORMAL
- en: Working with raw bytes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here''s how we open a file and see the raw bytes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We've opened this file in binary mode. The input we get will be `bytes` instead
    of `str`. Since a `bytes` object has many similar features to a `str` object,
    we can do a great deal of string-like processing on these bytes. We've dumped
    the first 22 bytes from the file. Bytes are shown as a mixture of hex values and
    ASCII characters.
  prefs: []
  type: TYPE_NORMAL
- en: We'll need to look at the description of the ICO file format to see what the
    bytes mean. Here's some background at [http://en.wikipedia.org/wiki/ICO_(file_format)](http://en.wikipedia.org/wiki/ICO_(file_format)).
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to decode this block of bytes is by using the `struct` module.
    We can do the following to pick apart the header on the file and the header on
    the first image of the file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `unpack()` function requires a format that specifies different kinds of
    conversions to perform on the stream of bytes. In this case, the format contains
    three codes for groups of bytes: `h` means two-byte half worlds, `b` means single
    bytes, and `i` means four-byte integers. The bytes are assembled into numeric
    values and the resulting structure is a tuple of proper Python `int` values. The
    leading `<` in the format specifies that the conversion to integers uses **little-endian**
    byte ordering.'
  prefs: []
  type: TYPE_NORMAL
- en: Using file-like objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because of the way objects work in Python, any object that offers an interface
    similar to the `file` class can be used in place of a file. This leads to the
    term "file-like object". We can use a file object, or any other object which is
    designed to behave like a file. For example, the `io` module has the `StringIO`
    class, which allows us to work with a string as if it were the contents of a file.
  prefs: []
  type: TYPE_NORMAL
- en: We often use this for creating test data. Note that an `io.StringIO` object
    is a lot like an open file. When we think about designing for testability—the
    subject of [Chapter 14](ch14.html "Chapter 14. Fit and Finish – Unit Testing,
    Packaging, and Documentation"), *Fit and Finish – Unit Testing, Packaging, and
    Documentation*—we need to design functions to work with file objects, not filenames.
  prefs: []
  type: TYPE_NORMAL
- en: Here's a function that applies simple pattern matching to lines of a file to
    yield numeric values extracted from complex lines of text. For more information
    on regular expressions, see [Chapter 3](ch03.html "Chapter 3. Expressions and
    Output"), *Expressions and Output*.
  prefs: []
  type: TYPE_NORMAL
- en: 'This function uses a pattern to filter the lines of a file or file-like object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve defined a generator function, which will reduce a log file to the few
    lines that match the given pattern. We''ve used the `re` module to define a pattern,
    `data_pat`, that looks for a string of words (`[\w ]+`), a `:` character, and
    a number that could be an integer or floating-point (`\d+\.?\d*`). The `data_pat.findall(line)`
    expression will locate all of these *words: number* pairs in a given line. A resulting
    list of match results is produced for each matching line.'
  prefs: []
  type: TYPE_NORMAL
- en: The matches are strings. We'll need to apply additional functions to the results
    to convert the numeric group from a string to a proper number.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important when defining our function to use a filename; the function
    doesn''t open the file. A function that opens a file is slightly more difficult
    to test. Instead, we defined our `tests_run()` function to use any file-like object.
    This allows us to write unit tests like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We've imported the `io` module so that we can create an `io.StringIO` object
    that contains simulated input. We can provide this file-like object to the `tests_run()`
    function. Since `StringIO` behaves like a file, we can use it in place of an actual
    file to test our function to be sure that it properly locates the `Tests run`
    lines and ignores other lines. We'll look at unit testing in [Chapter 14](ch14.html
    "Chapter 14. Fit and Finish – Unit Testing, Packaging, and Documentation"), *Fit
    and Finish – Unit Testing, Packaging, and Documentation*.
  prefs: []
  type: TYPE_NORMAL
- en: Using a context manager via the with statement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A Python file object is generally entangled with OS resources. When we''re
    done using the file, we need to be sure that the file is properly closed so that
    the OS resources can be released. For small command-line applications, this consideration
    is not that important: when we exit from Python, and the reference counts for
    all objects are decreased to zero, the files will be closed during object delete
    processing.'
  prefs: []
  type: TYPE_NORMAL
- en: For a large, long-running server, however, files that are not properly closed
    will accumulate OS resources. Since pools of OS resources are finite, a file handle
    leak will, eventually, cause problems.
  prefs: []
  type: TYPE_NORMAL
- en: As a general practice, we can use a context manager to be sure that files are
    closed when we're done using them. The idea is to constrain an open file to the
    suite of statements within the context manager. Once that suite of statements
    is finished, the context manager will ensure that the file is closed.
  prefs: []
  type: TYPE_NORMAL
- en: We specify the context using the `with` statement. A file object is a context
    manager; the `with` statement uses the file as a manager. At the end of the `with`
    statement, the context manager will exit and the file will be closed. Some more
    complex file structures are also context managers. For example, a `ZipFile` object,
    defined in the `zipfile` module, is a proper context manager; when used in a `with`
    statement, the file will be neatly closed.
  prefs: []
  type: TYPE_NORMAL
- en: 'It should be considered a best practice to wrap all file input-output processing
    in a `with` statement to be absolutely sure that the file is properly closed.
    Here''s an example of how we can use the `tests_run()` function (shown earlier)
    using a context manager:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We've opened two files to serve as context managers. The file which is opened
    for reading, `"Chapter_10/log_example.txt"`, is assigned to the `source` variable.
    The file opened for writing, `"Chapter_10/summary.txt"`, is assigned to the `target`
    variable. We can then process these files knowing that they will close properly.
  prefs: []
  type: TYPE_NORMAL
- en: If an exception is raised, the files will be closed. This is very important.
    Each of these context managers is notified if an exception occurs in the suite
    of statements inside the `with` statement. In this case, both of the managers
    are file objects. Each will see the exception and close the file—releasing all
    OS resources—and allow the exception handling to continue. Our application will
    crash with an exception, but the files will also close properly.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Always wrap file processing in a `with` statement.
  prefs: []
  type: TYPE_NORMAL
- en: Closing file-like objects with contextlib
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In some cases, we want to be sure that our application closes a file-like object
    that does not implement the context manager methods. Modules such as `http.client`
    will create an `HTTPConnection` object that may be entangled with network resources.
    We'd like to ensure that any network resources are released when we're done using
    the connection object. However, since this object is not a proper context manager,
    it won't be closed automatically when used in a `with` statement.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, trying to use an `HTTPConnection` object as context manager in a `with`
    statement will raise an `AttributeError` exception. This error will show that
    the `HTTPConnection` object does not implement the correct methods to behave as
    a context manager.
  prefs: []
  type: TYPE_NORMAL
- en: We can leverage a generic context manager in the `contextlib` module. The `contextlib.closing()`
    function will wrap any object that has a `close()` method with the required special
    methods to make the wrapped object into a context manager.
  prefs: []
  type: TYPE_NORMAL
- en: 'A RESTful web services request might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We're interested in making a GET request to a web service. The `http.client.HTTPConnection`
    object isn't a context manager; there's no guarantee that it will be closed if
    an exception occurs. By wrapping it with the `contextlib.closing()` function,
    we've made it into a proper context manager. We can make requests and process
    responses, in the knowledge that the `HTTPConnection` object will have its `close()`
    method called properly.
  prefs: []
  type: TYPE_NORMAL
- en: Using the shelve module as a database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Files offer us persistent storage. The simple use of files is limited by the
    fact that the data must be accessed sequentially. How can we access items in an
    arbitrary order?
  prefs: []
  type: TYPE_NORMAL
- en: We'll use the term "database" for a file (a set of files) on which we're going
    to perform **Create, Retrieve, Update, and Delete** (**CRUD**) operations on data
    elements in an arbitrary order. If we create objects of a consistent size, we
    can open an ordinary text file in `r+` mode and use the `seek()` method to position
    at the start of any particular record. This is rather complex, however, and we
    can do better.
  prefs: []
  type: TYPE_NORMAL
- en: The core database concept of readable and writable storage can be extended with
    a seemingly endless list of ancillary features. We'll ignore locking, logging,
    auditing, journaling, distributed transaction management, and many other features,
    for now to focus on the core feature of persistence.
  prefs: []
  type: TYPE_NORMAL
- en: The `shelve` module provides us with a very flexible database. A shelf object
    behaves like an ordinary Python mapping with the bonus feature that the content
    is persistent. One additional constraint is that keys used for a shelf must be
    strings.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, we use multi-part strings as shelf keys so that we can include some
    class information along with a unique identifier for the instance of the class.
    We can use a simple `class:id` format to include both the class name and an object's
    identifier value as the composite key for the shelf.
  prefs: []
  type: TYPE_NORMAL
- en: Here's an example of creating a shelf that maps a key to a list of values. In
    this example, the input file has a sequence of words, plus some blank lines and
    a trailer line that we want to ignore. The shelf has keys which are the initial
    letters of words. The value associated with each key is a list of words that share
    that common first letter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the entire function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We've opened the shelf object using `shelve.open()`. The `"n"` mode creates
    a new, empty shelf file each time the application runs. Since a shelf is not a
    proper context manager, we need to wrap it with the `contextlib.closing()` function.
  prefs: []
  type: TYPE_NORMAL
- en: The `shelve` module relies on a platform-specific database module. This may
    necessitate one or more underlying files to support the shelf. We've provided
    a base filename of `"Chapter_10/shelf"`. We may see a `.dat` or `.db` file get
    created, depending on the OS we're using.
  prefs: []
  type: TYPE_NORMAL
- en: The `for` loop traverses the input sequence of words generated by the `txt_non_empty`
    expression. The suite starts by building a two-part key. The first part is the
    string `word_list`; this is clearly not the Python data class, but it serves as
    a summary of what the data means. After the colon, we've put the first character
    of the word.
  prefs: []
  type: TYPE_NORMAL
- en: We fetch the current list of words associated with this key. If there is no
    such key in the shelf, we handle the `KeyError` exception by creating a fresh,
    empty list. Once we have a list—either new or fetched from the shelf—we can update
    the list by appending our new word. We then save the word list in the shelf.
  prefs: []
  type: TYPE_NORMAL
- en: To query words with a certain first letter, we can use `shelf["word_list:"+letter]`.
    We need to create a complete key string that includes a classifier so that we
    have a shelf with multiple collections.
  prefs: []
  type: TYPE_NORMAL
- en: 'To retrieve and summarize the data, we use a simple loop based on this generator
    expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This will select only the keys from our `word_list` collection in the shelf
    database. In a more sophisticated database, there may be other collections with
    other key prefixes.
  prefs: []
  type: TYPE_NORMAL
- en: Using the sqlite database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `sqlite` module provides us with a SQL-based database. An application that
    leverages SQL is—in principle—portable. We should be able to use MySQL or PostgreSQL
    as our database instead of SQLite without making dramatic changes to our Python
    application.
  prefs: []
  type: TYPE_NORMAL
- en: While there are several applicable standards for SQL, each implementation seems
    to suffer from its own particular problems. SQL-based applications are therefore
    rarely perfectly portable between database platforms.
  prefs: []
  type: TYPE_NORMAL
- en: 'SQL databases require a formal schema definition. This means that SQL applications
    must always include some provision for creating or confirming the schema. As in
    the previous example, we''ll work with a database that has a single table with
    two columns: a non-unique key which is the initial letter of a word, and the word
    which has that initial letter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the table definition in SQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This defines a table that has two columns, `letter` and `word`. To find all
    of the words which have a common first letter, we'll need to retrieve multiple
    rows from this table. This is a common type of SQL design. It doesn't fit neatly
    with Python's object-oriented design, a common limitation when using SQL.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to execute the SQL `CREATE TABLE` statement to create (or confirm the
    existence of) the table in a SQLite database. Here''s a function that will establish
    (or confirm) the schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The essential statement is the `execute()` method of the SQLite connection object.
    We've provided the SQL with a triple-quoted string. If there's a problem, an exception
    will be raised.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a function that will load this table with data from a text file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that we begin by deleting all the rows from the `word` table. This parallels
    the way that our previous example worked by creating a fresh, empty `shelve` database.
    There may be high overheads in creating an empty SQL database; this example expects
    an established database with a table already defined, and deletes rows from the
    defined table.
  prefs: []
  type: TYPE_NORMAL
- en: As with the previous example, we've used two generator expressions to filter
    out these lines of junk from the input file. The loop traverses the words generated
    by the `no_summary` expression. The suite executes a SQL `INSERT` statement binding
    two values for the `letter` and `word` columns of the table. This statement creates
    a new row in the word table in our database.
  prefs: []
  type: TYPE_NORMAL
- en: To see counts of words which begin with a given letter, we can use SQL aggregation.
    We would execute the following `SELECT` statement.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: When we execute this, we get a SQL iterator (called a "cursor") that yields
    a sequence of two-tuples based on the `SELECT` clause. Each tuple will have the
    letter and the number of words that share that letter. We can use this to display
    a summary of counts of words with a given initial letter.
  prefs: []
  type: TYPE_NORMAL
- en: Using object-relational mapping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many popular SQL databases offer Python drivers. Some have better levels of
    support than others. When working with SQL databases, it's sometimes difficult
    to locate SQL syntax that is effective and portable. A feature on one database
    may be a problem on another.
  prefs: []
  type: TYPE_NORMAL
- en: More importantly, however, there's a mismatch between the completely flat column-and-row
    structure of a SQL table and the requirements of more complex class definitions
    in an object-oriented language like Python. This impedance mismatch is often addressed
    with an **object-relational mapping** (**ORM**) package. Two popular packages
    are SQLAlchemy or SQLObject.
  prefs: []
  type: TYPE_NORMAL
- en: These packages help with the mapping of complex objects to simple SQL tables.
    It also helps by divorcing the application programming for the details of a particular
    SQL database.
  prefs: []
  type: TYPE_NORMAL
- en: Databases which don't use SQL, such as `shelve`, MongoDB, CouchDB, and other
    NoSQL databases, don't have the same object-relational impedance mismatch problem
    that SQL databases have. We have many choices for persistence technology; Python
    can be used with a wide variety of databases.
  prefs: []
  type: TYPE_NORMAL
- en: Web services and Internet protocols
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we noted earlier, many TCP/IP protocols, like HTTP, depend on the socket
    abstraction. Sockets are designed to be file-like: we can use ordinary file operations
    to read or write a socket. At a very low level, we can use the Python `socket`
    module. We can create, read, and write sockets to connect client and server programs.'
  prefs: []
  type: TYPE_NORMAL
- en: Rather than work directly with sockets, however, we'll make use of higher-level
    modules, such as `urllib` and `http.client`. These give us the client-side operations
    of the HTTP protocol, allowing us to connect to a web server, make requests, and
    get replies. We looked briefly at the `http.client` module in the previous *Closing
    file-like objects with contextlib* section.
  prefs: []
  type: TYPE_NORMAL
- en: To implement a server, we can use `http.server`. In practice, though, we'll
    often leverage a frontend application, such as Apache HTTPD or NGINX, to provide
    the static content of a website. For the dynamic content, we'll often use a WSGI
    gateway to pass web requests from the frontend to a Python framework. There are
    several Python web server frameworks, each with a variety of features, strengths,
    and weaknesses.
  prefs: []
  type: TYPE_NORMAL
- en: Physical format considerations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Python library offers us a number of modules to help process common physical
    file formats. *Chapter 13*, *File Formats*, of the *Python Standard Library* describes
    file compression and archiving; this includes modules to handle files compressed
    using zip or BZip2\. *Chapter 14*, *Cryptographic Services* describes modules
    which handle file formats such as CSV, configuration files, and PLIST files. *Chapter
    19*, *Structured Markup Processing Tools* describes Internet data handling, which
    includes the JSON file format. *Chapter 20*, *Internet Protocols and Support*
    describes modules to handle markup languages such as HTML and XML. For modules
    that are not part of the standard library, the **Python Package Index** (**PyPI**)
    may have a package that handles the file format. See [http://pypi.python.org](http://pypi.python.org).
  prefs: []
  type: TYPE_NORMAL
- en: We'll look quickly at the CSV module because it is often used when working on
    "big data" problems. For example, the Apache Hadoop software library—a framework
    that allows for the distributed processing of large datasets—leverages simple
    programming models. We can use Python with Hadoop streaming.
  prefs: []
  type: TYPE_NORMAL
- en: A Hadoop file is often a CSV-formatted file. In some instances, it will have
    "`|`" instead of a comma, and quoting or escapes won't be used. In other cases,
    an `\x01` (ASCII SOH) character could be used as a separator. This is relatively
    simple to handle with the Python CSV module.
  prefs: []
  type: TYPE_NORMAL
- en: When we create a CSV file from a spreadsheet, the first row may have header
    information. This can be very helpful. The `csv.DictReader()` class uses the first
    line of a CSV file as the header. Each remaining line is transformed into a `dict`.
    The keys in this `dict` will be the column names from the first line.
  prefs: []
  type: TYPE_NORMAL
- en: When working with other CSV files, a header line may not be present. This means
    that we'll need a separate schema definition to determine the meaning of each
    column. In most cases, we can simply represent the schema as a list or tuple of
    column names.
  prefs: []
  type: TYPE_NORMAL
- en: 'We might have a line like this to provide the missing column names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This gives us pleasant Python-friendly column names in a simple tuple. We've
    included a gratuitous comma at the end of the items in the tuple to make it easier
    to add new columns without getting a syntax error. In general, we can simply put
    this into a file and import this schema definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume that we have a function named `log_parser()` that can parse a
    complex log file to extract the fields shown earlier. This function will use regular
    expressions to locate lines with the test results, the module name, and the time
    stamp in the log. The data from a log will be used to build a simple dictionary
    with the keys defined by the `TEST_LOG_SUMMARY` global variable. The parser will
    return a sequence of `dict` objects which looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use this `log_parser()` function to write a CSV summary file from a
    log. We''ll call this function `mapper()` because it maps a sequence of filenames
    to file to a sequence of data rows, preserving the relevant details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This function expects two parameters: an iterator which yields log file names,
    and an open file into which the results are written. This function will create
    a CSV `DictWriter` object using the output file, the set of field names that will
    be part of each dictionary to be written, and finally, a delimiter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For each name, the log is opened and parsed. The results of the parse, `dict`,
    are written to the CSV file to summarize the processing. We might use this function
    in a script that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We've written the output to the OS standard out. This allows us to pipe these
    results into a separate program which computes statistics on the log summaries.
    We might call the statistical summary a reducer, since it reduces a large number
    of values to single results. The reducer would share the `TEST_LOG_SUMMARY` variable
    to assure that both programs agree on the content of the file that passes between
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've seen how we can use Python exceptions to write programs
    which work with files of various kinds. We've focused on text files, since they
    are easy to work with. We've also looked at parsing binary files, which often
    require support from the `struct` module.
  prefs: []
  type: TYPE_NORMAL
- en: A file is also a context manager. The best practice is to use files in a `with`
    statement so that the file is closed properly and all OS resources are released.
    In a command-line program, this may not be that important; in long-running servers,
    it's absolutely essential to be sure that resources don't leak from improperly
    closed files.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve also looked at more complex persistence mechanisms, including the `shelve`
    module and the SQLite database. These provide us with ways to perform CRUD operations
    on data objects in a file. The SQLite database requires us to use the SQL language
    to describe data access: this can make our programs more portable to other databases.
    It can also be confusing to leverage SQL in addition to Python. We can overcome
    that small problem by using a library such as SQLAlchemy so that we can work entirely
    in Python, and leave it to SQLAlchemy to create the SQL appropriate for our database.'
  prefs: []
  type: TYPE_NORMAL
- en: The standard library has numerous packages to handle different physical file
    formats. One of these can help to create and retrieve data in the CSV format.
    The role of the comma delimiter can be any sequence of characters, extending the
    concept so that many kinds of delimited files can be read or written by this module.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 11](ch11.html "Chapter 11. Class Definitions"), *Class Definitions*,
    we'll look at how we can define our own customized classes in Python. Class definitions
    are the heart of object-oriented programming. We'll touch on several of the class
    design patterns that are common in Python programming.
  prefs: []
  type: TYPE_NORMAL
