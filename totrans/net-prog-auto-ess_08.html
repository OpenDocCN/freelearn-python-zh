<html><head></head><body>
<div class="IMG---Figure" id="_idContainer053">
<h1 class="chapter-number" id="_idParaDest-194"><a id="_idTextAnchor195"/><span class="koboSpan" id="kobo.1.1">8</span></h1>
<h1 id="_idParaDest-195"><a id="_idTextAnchor196"/><span class="koboSpan" id="kobo.2.1">Scaling Your Code</span></h1>
<p><span class="koboSpan" id="kobo.3.1">Now that we know how to interact with network devices, we should start thinking about building a solution that scales. </span><span class="koboSpan" id="kobo.3.2">But why do we need to scale our code? </span><span class="koboSpan" id="kobo.3.3">You might be thinking that the answer is obvious and it is just because it will allow your solution to grow easily as your network grows. </span><span class="koboSpan" id="kobo.3.4">But scaling is not just about going up but scaling down too. </span><span class="koboSpan" id="kobo.3.5">So, scaling your code means that you are going to build a solution that can follow demand easily, saving resources when not required and using more </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">when required.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">You should consider adding scaling capabilities adding scaling capabilities to your network automation solution before writing the code. </span><span class="koboSpan" id="kobo.5.2">It should be planned during design time and then executed during development time. </span><span class="koboSpan" id="kobo.5.3">The scaling capabilities have to be one of the requirements for building your solution. </span><span class="koboSpan" id="kobo.5.4">It also should be a clear milestone during implementation </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">and testing.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">In this chapter, we are going to check some techniques used today to scale your code up and down effectively. </span><span class="koboSpan" id="kobo.7.2">This will allow your solution to adapt easily to follow network growth and, if necessary, easily scale down to </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">save resources.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">We are going to cover the following topics in </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">this chapter:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.11.1">Dealing with multitasking, threads, </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">and coroutines</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Adding schedulers and </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">job dispatchers</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">Using microservices </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">and containers</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.17.1">By the end of this chapter, you should have enough information to choose the best scaling solution for </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">your code.</span></span></p>
<h1 id="_idParaDest-196"><a id="_idTextAnchor197"/><span class="koboSpan" id="kobo.19.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.20.1">The source code described in this chapter is stored in the GitHub repository </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">at </span></span><a href="https://github.com/PacktPublishing/Network-Programming-and-Automation-Essentials/tree/main/Chapter08"><span class="No-Break"><span class="koboSpan" id="kobo.22.1">https://github.com/PacktPublishing/Network-Programming-and-Automation-Essentials/tree/main/Chapter08</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.23.1">.</span></span></p>
<h1 id="_idParaDest-197"><a id="_idTextAnchor198"/><span class="koboSpan" id="kobo.24.1">Dealing with multitasking, threads, and coroutines</span></h1>
<p><span class="koboSpan" id="kobo.25.1">Multitasking, as the</span><a id="_idIndexMarker920"/><span class="koboSpan" id="kobo.26.1"> name suggests, is the capability of doing several tasks at the same time. </span><span class="koboSpan" id="kobo.26.2">In computers, a task is also known as a job or a process and there are different techniques for running tasks at the </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">same time.</span></span></p>
<p><span class="koboSpan" id="kobo.28.1">The capability to run code at the same time allows your system to scale up and down whenever necessary. </span><span class="koboSpan" id="kobo.28.2">If you have to communicate with more network devices, just run more code in parallel; if you need fewer devices, just run less code. </span><span class="koboSpan" id="kobo.28.3">That will enable your system to scale up </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">and down.</span></span></p>
<p><span class="koboSpan" id="kobo.30.1">But running code in parallel will have an impact on the available machine resources, and some of these resources will be limited by how your code is consuming them. </span><span class="koboSpan" id="kobo.30.2">For instance, if your code is using the network interface to download files, and running one single line of code is already consuming 50 Mbps of the network interface (which is 50% of the 100 Mbps interface), it is not advised to run multiple lines of code in parallel to increase the speed, as the limitation is on the network interface and not in </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">the CPU.</span></span></p>
<p><span class="koboSpan" id="kobo.32.1">Other factors are also important to be considered when running code in parallel, that is, the other shared resources besides the network, such as the CPU, disk, and memory. </span><span class="koboSpan" id="kobo.32.2">In some cases, bottlenecks in the disk might cause more limitations for code parallelism than the CPU, especially using disks mounted over the network. </span><span class="koboSpan" id="kobo.32.3">In other cases, a large program consuming lots of memory would block the execution of any other program running in parallel because of a lack of free memory. </span><span class="koboSpan" id="kobo.32.4">Therefore, the resources that your process will touch and how they interact will have an impact on how much parallelism </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">is possible.</span></span></p>
<p><span class="koboSpan" id="kobo.34.1">One thing we should clarify here is the term </span><strong class="bold"><span class="koboSpan" id="kobo.35.1">I/O</span></strong><span class="koboSpan" id="kobo.36.1">, which is an acronym for computer </span><strong class="bold"><span class="koboSpan" id="kobo.37.1">input/output</span></strong><span class="koboSpan" id="kobo.38.1">. </span><span class="koboSpan" id="kobo.38.2">I/O is</span><a id="_idIndexMarker921"/><span class="koboSpan" id="kobo.39.1"> used to designate any communication between the CPU of the machine and the external world, such as accessing the disk, writing to memory, or sending data to the network. </span><span class="koboSpan" id="kobo.39.2">If your code requires lots of external access and it is, most of the time, waiting to receive a response from external communication, we normally say the code</span><a id="_idIndexMarker922"/><span class="koboSpan" id="kobo.40.1"> is </span><strong class="bold"><span class="koboSpan" id="kobo.41.1">I/O bound</span></strong><span class="koboSpan" id="kobo.42.1">. </span><span class="koboSpan" id="kobo.42.2">An example of slow I/O can be found when accessing remote networks and, in some cases, remote disks. </span><span class="koboSpan" id="kobo.42.3">On the other hand, if your code requires more CPU computation than I/O, we normally say the code </span><a id="_idIndexMarker923"/><span class="koboSpan" id="kobo.43.1">is </span><strong class="bold"><span class="koboSpan" id="kobo.44.1">CPU bound</span></strong><span class="koboSpan" id="kobo.45.1">. </span><span class="koboSpan" id="kobo.45.2">Most network automation systems will be I/O bound because of network </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">device access.</span></span></p>
<p><span class="koboSpan" id="kobo.47.1">Let’s now investigate a few techniques to run code at the same time in Go </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">and Python.</span></span></p>
<h2 id="_idParaDest-198"><a id="_idTextAnchor199"/><span class="koboSpan" id="kobo.49.1">Multiprocessing</span></h2>
<p><span class="koboSpan" id="kobo.50.1">In computers, when a program </span><a id="_idIndexMarker924"/><span class="koboSpan" id="kobo.51.1">is loaded in memory to run, it’s called a</span><a id="_idIndexMarker925"/><span class="koboSpan" id="kobo.52.1"> process. </span><span class="koboSpan" id="kobo.52.2">The program can be either a script or a binary file, but it is normally represented by one single file. </span><span class="koboSpan" id="kobo.52.3">This file will be loaded into memory and it is seen by the operating system as a process. </span><span class="koboSpan" id="kobo.52.4">The capability of running multiple processes at the same time is called multiprocessing, and it is normally managed by the </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">operating system.</span></span></p>
<p><span class="koboSpan" id="kobo.54.1">The number of CPUs of the hardware where the processes are running is irrelevant to the multiprocessing capability. </span><span class="koboSpan" id="kobo.54.2">The operating system is responsible for allocating the CPU time for all processes that are in memory and ready to run. </span><span class="koboSpan" id="kobo.54.3">However, as the number of CPUs, speed of the CPU, and memory are limited, the number of processes that can run at the same time will also be limited. </span><span class="koboSpan" id="kobo.54.4">Normally, it depends on the size of the process and how much CPU </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">it consumes.</span></span></p>
<p><span class="koboSpan" id="kobo.56.1">In most computer languages, multiprocessing is implemented using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.57.1">fork()</span></strong><span class="koboSpan" id="kobo.58.1"> system call implemented by the operating system to create a complete copy of the currently </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">running process.</span></span></p>
<p><span class="koboSpan" id="kobo.60.1">Let’s investigate how we can use multiprocessing in Go </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">and Python.</span></span></p>
<h3><span class="koboSpan" id="kobo.62.1">Multiprocessing in Python</span></h3>
<p><span class="koboSpan" id="kobo.63.1">In Python, multiprocessing is </span><a id="_idIndexMarker926"/><span class="koboSpan" id="kobo.64.1">accomplished by the standard library called </span><strong class="source-inline"><span class="koboSpan" id="kobo.65.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.66.1">. </span><span class="koboSpan" id="kobo.66.2">Full </span><a id="_idIndexMarker927"/><span class="koboSpan" id="kobo.67.1">documentation on </span><a id="_idIndexMarker928"/><span class="koboSpan" id="kobo.68.1">Python </span><strong class="source-inline"><span class="koboSpan" id="kobo.69.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.70.1"> can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">at </span></span><a href="http://docs.python.org/3/library/multiprocessing"><span class="No-Break"><span class="koboSpan" id="kobo.72.1">docs.python.org/3/library/multiprocessing</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.73.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.74.1">In the first example, we are going to use the operating system program called </span><strong class="source-inline"><span class="koboSpan" id="kobo.75.1">ping</span></strong><span class="koboSpan" id="kobo.76.1"> to target one network node. </span><span class="koboSpan" id="kobo.76.2">Then, we are going to make it parallel for </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">multiple targets.</span></span></p>
<p><span class="koboSpan" id="kobo.78.1">The following is an example for one target </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1">network node:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.80.1">
import subprocess
TARGET = "yahoo.com"
command = ["ping", "-c", "1", TARGET]
response = subprocess.call(
    command,
    stdout=subprocess.DEVNULL,
)
if response == 0:
    print(TARGET, "OK")
else:
    print(TARGET, "FAILED")</span></pre>
<p><span class="koboSpan" id="kobo.81.1">It is important to note that calling </span><strong class="source-inline"><span class="koboSpan" id="kobo.82.1">ping</span></strong><span class="koboSpan" id="kobo.83.1"> from Python is not efficient. </span><span class="koboSpan" id="kobo.83.2">It will cause more overhead because Python will have to invoke an external program that resides in the filesystem. </span><span class="koboSpan" id="kobo.83.3">In order to make the example more efficient, we need to use the ICMP </span><strong class="source-inline"><span class="koboSpan" id="kobo.84.1">echo request</span></strong><span class="koboSpan" id="kobo.85.1"> and receive an ICMP </span><strong class="source-inline"><span class="koboSpan" id="kobo.86.1">echo reply</span></strong><span class="koboSpan" id="kobo.87.1"> from the Python network sockets, instead of invoking an external program such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.88.1">ping</span></strong><span class="koboSpan" id="kobo.89.1">. </span><span class="koboSpan" id="kobo.89.2">One solution is to use the Python third-party library </span><a id="_idIndexMarker929"/><span class="koboSpan" id="kobo.90.1">called </span><strong class="source-inline"><span class="koboSpan" id="kobo.91.1">pythonping</span></strong><span class="koboSpan" id="kobo.92.1"> (</span><a href="https://pypi.org/project/pythonping/"><span class="koboSpan" id="kobo.93.1">https://pypi.org/project/pythonping/</span></a><span class="koboSpan" id="kobo.94.1">). </span><span class="koboSpan" id="kobo.94.2">But there is one caveat: the </span><strong class="source-inline"><span class="koboSpan" id="kobo.95.1">ping</span></strong><span class="koboSpan" id="kobo.96.1"> program has </span><strong class="source-inline"><span class="koboSpan" id="kobo.97.1">setuid</span></strong><span class="koboSpan" id="kobo.98.1"> to allow ICMP packets to be sent by a non-privileged user. </span><span class="koboSpan" id="kobo.98.2">Thus, in order to run with </span><strong class="source-inline"><span class="koboSpan" id="kobo.99.1">pythonping</span></strong><span class="koboSpan" id="kobo.100.1">, you need admin/root privileges (accomplished in Linux </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.102.1">sudo</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.103.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.104.1">The following is the</span><a id="_idIndexMarker930"/><span class="koboSpan" id="kobo.105.1"> same example using </span><strong class="source-inline"><span class="koboSpan" id="kobo.106.1">pythonping</span></strong><span class="koboSpan" id="kobo.107.1"> for </span><a id="_idIndexMarker931"/><span class="koboSpan" id="kobo.108.1">one target </span><span class="No-Break"><span class="koboSpan" id="kobo.109.1">network node:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.110.1">
import pythonping
TARGET = "yahoo.com"
response = pythonping.ping(TARGET, count=1)
if response.success:
    print(TARGET, "OK")
else:
    print(TARGET, "FAILED")</span></pre>
<p><span class="koboSpan" id="kobo.111.1">Running this program should generate the </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">following output:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.113.1">
% sudo python3 single-pyping-example.py
yahoo.com OK</span></pre>
<p><span class="koboSpan" id="kobo.114.1">If you want to </span><a id="_idIndexMarker932"/><span class="koboSpan" id="kobo.115.1">send ICMP requests to multiple targets, you will have to</span><a id="_idIndexMarker933"/><span class="koboSpan" id="kobo.116.1"> send them sequentially one after the other. </span><span class="koboSpan" id="kobo.116.2">However, a better solution would be to run them in parallel using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.117.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.118.1"> Python library. </span><span class="koboSpan" id="kobo.118.2">The following is an example of four targets </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.120.1">multiprocessing</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.122.1">
from pythonping import ping
from multiprocessing import Process
TARGETS = ["yahoo.com", "google.com", "cisco.com", "cern.ch"]
def myping(host):
    response = ping(host, count=1)
    if response.success:
        print("%s OK, latency is %.2fms" % (host, response.rtt_avg_ms))
    else:
        print(host, "FAILED")
def main():
    for host in TARGETS:
        Process(target=myping, args=(host,)).start()
if __name__ == "__main__":
    main()</span></pre>
<p><span class="koboSpan" id="kobo.123.1">If you run the preceding program, you should get an output similar to </span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">the following:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.125.1">
% sudo python3 multiple-pyping-example.py
google.com OK, latency is 45.31ms
yahoo.com OK, latency is 192.17ms
cisco.com OK, latency is 195.44ms
cern.ch OK, latency is 272.97ms</span></pre>
<p><span class="koboSpan" id="kobo.126.1">Note that the response of each target does not depend on the response of others. </span><span class="koboSpan" id="kobo.126.2">Therefore, the output should always be in order from low latency to high latency. </span><span class="koboSpan" id="kobo.126.3">In the preceding example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.127.1">google.com</span></strong><span class="koboSpan" id="kobo.128.1"> finished first, showing a latency of just </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">45.31 ms.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.130.1">Important note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.131.1">It is important to call </span><strong class="source-inline"><span class="koboSpan" id="kobo.132.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.133.1"> inside the </span><strong class="source-inline"><span class="koboSpan" id="kobo.134.1">main()</span></strong><span class="koboSpan" id="kobo.135.1"> function, or a function that is called from </span><strong class="source-inline"><span class="koboSpan" id="kobo.136.1">main()</span></strong><span class="koboSpan" id="kobo.137.1">. </span><span class="koboSpan" id="kobo.137.2">Also, make sure </span><strong class="source-inline"><span class="koboSpan" id="kobo.138.1">main()</span></strong><span class="koboSpan" id="kobo.139.1"> can be safely imported by a Python interpreter (use </span><strong class="source-inline"><span class="koboSpan" id="kobo.140.1">__name__</span></strong><span class="koboSpan" id="kobo.141.1"> ). </span><span class="koboSpan" id="kobo.141.2">You can find more details on why </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">at </span></span><a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming"><span class="No-Break"><span class="koboSpan" id="kobo.143.1">https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.144.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.145.1">Python has additional methods to </span><a id="_idIndexMarker934"/><span class="koboSpan" id="kobo.146.1">invoke code parallelism besides the preceding</span><a id="_idIndexMarker935"/><span class="koboSpan" id="kobo.147.1"> example using </span><strong class="source-inline"><span class="koboSpan" id="kobo.148.1">Process()</span></strong><span class="koboSpan" id="kobo.149.1">, called </span><strong class="source-inline"><span class="koboSpan" id="kobo.150.1">multiprocessing.Pool()</span></strong><span class="koboSpan" id="kobo.151.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.152.1">multiprocessing.Queue()</span></strong><span class="koboSpan" id="kobo.153.1">. </span><span class="koboSpan" id="kobo.153.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.154.1">Pool()</span></strong><span class="koboSpan" id="kobo.155.1"> class is used to instantiate a pool of workers that can do a job without the need to communicate with each other. </span><span class="koboSpan" id="kobo.155.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.156.1">Queue()</span></strong><span class="koboSpan" id="kobo.157.1"> class is used when communication between processes is required. </span><span class="koboSpan" id="kobo.157.2">More on that can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">at </span></span><a href="https://docs.python.org/3/library/multiprocessing.html"><span class="No-Break"><span class="koboSpan" id="kobo.159.1">https://docs.python.org/3/library/multiprocessing.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.160.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.161.1">Let’s see how we can use multiprocessing </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">in Go.</span></span></p>
<h3><span class="koboSpan" id="kobo.163.1">Multiprocessing in Go</span></h3>
<p><span class="koboSpan" id="kobo.164.1">To create processes from a </span><a id="_idIndexMarker936"/><span class="koboSpan" id="kobo.165.1">program, you need to create a copy of the data of the current </span><a id="_idIndexMarker937"/><span class="koboSpan" id="kobo.166.1">running program to a new process. </span><span class="koboSpan" id="kobo.166.2">That is what Python’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.167.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.168.1"> does. </span><span class="koboSpan" id="kobo.168.2">However, Go implements parallelism very differently. </span><span class="koboSpan" id="kobo.168.3">Go was designed to work with routines similar to coroutines, they are called goroutines, which manage parallelism at runtime. </span><span class="koboSpan" id="kobo.168.4">As goroutines are much more efficient, there is no need to implement multiprocessing natively </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">in Go.</span></span></p>
<p><span class="koboSpan" id="kobo.170.1">Note that using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.171.1">exec</span></strong><span class="koboSpan" id="kobo.172.1"> library, by calling </span><strong class="source-inline"><span class="koboSpan" id="kobo.173.1">exec.Command()</span></strong><span class="koboSpan" id="kobo.174.1"> and then </span><strong class="source-inline"><span class="koboSpan" id="kobo.175.1">Cmd.Start()</span></strong><span class="koboSpan" id="kobo.176.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.177.1">Cmd.Wait()</span></strong><span class="koboSpan" id="kobo.178.1">, will allow you to create multiple processes at the same time, but it is a call to the operating system to execute an external program. </span><span class="koboSpan" id="kobo.178.2">Therefore, it is </span><a id="_idIndexMarker938"/><span class="koboSpan" id="kobo.179.1">not </span><a id="_idIndexMarker939"/><span class="koboSpan" id="kobo.180.1">considered native multiprocessing and is </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">not efficient.</span></span></p>
<p><span class="koboSpan" id="kobo.182.1">For these reasons, we don’t have an example of multi-processing </span><span class="No-Break"><span class="koboSpan" id="kobo.183.1">in Go.</span></span></p>
<p><span class="koboSpan" id="kobo.184.1">Let’s see now how we </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">do multithreading.</span></span></p>
<h2 id="_idParaDest-199"><a id="_idTextAnchor200"/><span class="koboSpan" id="kobo.186.1">Multithreading</span></h2>
<p><span class="koboSpan" id="kobo.187.1">In computer languages, a thread is a smaller part of a process, which can have one or multiple threads. </span><span class="koboSpan" id="kobo.187.2">The memory is shared between the threads in the same process, in contrast with a process that does not share memory with another process. </span><span class="koboSpan" id="kobo.187.3">Therefore, a thread is known as a </span><a id="_idIndexMarker940"/><span class="koboSpan" id="kobo.188.1">lightweight process because it requires less memory, and communication between threads within a process is faster. </span><span class="koboSpan" id="kobo.188.2">In consequence, spawning new threads is much faster in comparison with </span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">new processes.</span></span></p>
<p><span class="koboSpan" id="kobo.190.1">A CPU with multithreading capability is a CPU that has the ability to run multiple threads in a single core by providing instruction-level parallelism or thread-level parallelism. </span><span class="koboSpan" id="kobo.190.2">This capability is also known </span><a id="_idIndexMarker941"/><span class="koboSpan" id="kobo.191.1">as </span><strong class="bold"><span class="koboSpan" id="kobo.192.1">Simultaneous </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.193.1">Multithreading</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.194.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.195.1">SMT</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.197.1">One example of SMT is the Intel CPU i9-10900K, which has 10 cores and the capability to run 2 threads at the same time per core, which allows up to 20 simultaneous threads. </span><span class="koboSpan" id="kobo.197.2">Intel has created a trademark name for SMT, which they</span><a id="_idIndexMarker942"/><span class="koboSpan" id="kobo.198.1"> call </span><strong class="bold"><span class="koboSpan" id="kobo.199.1">hyper-threading</span></strong><span class="koboSpan" id="kobo.200.1">. </span><span class="koboSpan" id="kobo.200.2">Normally, AMD and Intel x86 CPU architectures can run up to two threads </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">per core.</span></span></p>
<p><span class="koboSpan" id="kobo.202.1">In contrast, the Oracle SPARC M8 processor has 32 cores that can run 8 threads each, allowing a staggering number of 256 simultaneous threads. </span><span class="koboSpan" id="kobo.202.2">More on this amazing CPU can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">at </span></span><a href="https://www.oracle.com/us/products/servers-storage/sparc-m8-processor-ds-3864282.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.204.1">https://www.oracle.com/us/products/servers-storage/sparc-m8-processor-ds-3864282.pdf</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.205.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.206.1">But for the CPU to perform its best using threads, two other requirements are necessary, an operating</span><a id="_idIndexMarker943"/><span class="koboSpan" id="kobo.207.1"> system that allows CPU-level multithreading and a computer language that allows the creation of </span><span class="No-Break"><span class="koboSpan" id="kobo.208.1">simultaneous threads.</span></span></p>
<p><span class="koboSpan" id="kobo.209.1">Let’s see how we can use multithreading </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">in Python.</span></span></p>
<h3><span class="koboSpan" id="kobo.211.1">Multithreading in Python</span></h3>
<p><span class="koboSpan" id="kobo.212.1">Multithreading is the </span><a id="_idIndexMarker944"/><span class="koboSpan" id="kobo.213.1">Achilles’ heel of Python. </span><span class="koboSpan" id="kobo.213.2">The main reason is that the Python</span><a id="_idIndexMarker945"/><span class="koboSpan" id="kobo.214.1"> interpreter called</span><a id="_idIndexMarker946"/><span class="koboSpan" id="kobo.215.1"> CPython (discussed in </span><a href="B18165_06.xhtml#_idTextAnchor166"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.216.1">Chapter 6</span></em></span></a><span class="koboSpan" id="kobo.217.1">) uses</span><a id="_idIndexMarker947"/><span class="koboSpan" id="kobo.218.1"> a </span><strong class="bold"><span class="koboSpan" id="kobo.219.1">Global Interpreter Lock</span></strong><span class="koboSpan" id="kobo.220.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.221.1">GIL</span></strong><span class="koboSpan" id="kobo.222.1">) to make it thread-safe. </span><span class="koboSpan" id="kobo.222.2">This has a consequence of not allowing Python code to run multiple threads at the same time in a multithread CPU. </span><span class="koboSpan" id="kobo.222.3">GIL also adds overhead and using multithreading might cause the program to run slower in comparison with multiprocessing when more CPU work </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">is required.</span></span></p>
<p><span class="koboSpan" id="kobo.224.1">Therefore, in Python, multithreading is not recommended for programs that are CPU bound. </span><span class="koboSpan" id="kobo.224.2">For network and other I/O-bound programs, multithreading might be faster to spawn and easier to communicate with and save runtime memory. </span><span class="koboSpan" id="kobo.224.3">But it is important to note that only one thread will run at a time using the CPython interpreter, so if you require true parallelism, use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.225.1">multiprocessing</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.226.1">library instead.</span></span></p>
<p><span class="koboSpan" id="kobo.227.1">In Python, the standard library offers multithreading by using the library called </span><strong class="source-inline"><span class="koboSpan" id="kobo.228.1">threading</span></strong><span class="koboSpan" id="kobo.229.1">. </span><span class="koboSpan" id="kobo.229.2">So, let’s create one example using multithreading in Python by taking the same targets for ICMP tests used in the code example in the previous section. </span><span class="koboSpan" id="kobo.229.3">The following is the same example using ICMP but </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">using threading:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.231.1">
from pythonping import ping
import threading
TARGETS = ["yahoo.com", "google.com", "cisco.com", "cern.ch"]
class myPing(threading.Thread):
    def __init__(self, host):
        threading.Thread.__init__(self)
        self.host = host
    def run(self):
        response = ping(self.host)
        if response.success:
            print("%s OK, latency is %.2fms" % (self.host, response.rtt_avg_ms))
        else:
            print(self.host, "FAILED")
def main():
    for host in TARGETS:
        myPing(host).start()
if __name__ == "__main__":
    main()</span></pre>
<p><span class="koboSpan" id="kobo.232.1">The </span><a id="_idIndexMarker948"/><span class="koboSpan" id="kobo.233.1">output of running the preceding program will look </span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">as</span></span><span class="No-Break"><a id="_idIndexMarker949"/></span><span class="No-Break"><span class="koboSpan" id="kobo.235.1"> follows:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.236.1">
% sudo python3 threads-pyping-example.py
google.com OK, latency is 36.21ms
yahoo.com OK, latency is 136.16ms
cisco.com OK, latency is 144.67ms
cern.ch OK, latency is 215.81ms</span></pre>
<p><span class="koboSpan" id="kobo.237.1">As you can see, the output is quite similar using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.238.1">threading</span></strong><span class="koboSpan" id="kobo.239.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.240.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.241.1"> libraries, but which one </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">runs faster?</span></span></p>
<p><span class="koboSpan" id="kobo.243.1">Let’s now run a</span><a id="_idIndexMarker950"/><span class="koboSpan" id="kobo.244.1"> test program to compare the speed of using </span><strong class="source-inline"><span class="koboSpan" id="kobo.245.1">threading</span></strong><span class="koboSpan" id="kobo.246.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.247.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.248.1"> for the ICMP tests. </span><span class="koboSpan" id="kobo.248.2">The source code of this program is</span><a id="_idIndexMarker951"/><span class="koboSpan" id="kobo.249.1"> included in the GitHub repository for this chapter. </span><span class="koboSpan" id="kobo.249.2">The name of the program </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">is </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.251.1">performance-thread-process-example.py</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.253.1">Here is the output of this program running for 10, 20, 50, and 100 </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">ICMP probes:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.255.1">
% sudo python3 performance-thread-process-example.py 10
Multi-threading test --- duration 0.015 seconds
Multi-processing test--- duration 0.193 seconds
% sudo python3 performance-thread-process-example.py 20
Multi-threading test --- duration 0.030 seconds
Multi-processing test--- duration 0.315 seconds
% sudo python3 performance-thread-process-example.py 50
Multi-threading test --- duration 2.095 seconds
Multi-processing test--- duration 0.765 seconds
% sudo python3 performance-thread-process-example.py 100
Multi-threading test --- duration 2.273 seconds
Multi-processing test--- duration 1.507 seconds</span></pre>
<p><span class="koboSpan" id="kobo.256.1">As shown in the preceding output, running multithreading in Python for a certain number of threads might be faster. </span><span class="koboSpan" id="kobo.256.2">However, as we get close to the number 50, it becomes less effective and runs much slower. </span><span class="koboSpan" id="kobo.256.3">It is important to notice that this will depend on where you are running your code. </span><span class="koboSpan" id="kobo.256.4">The Python interpreter running on Windows is different from in Linux or even in macOS, but the general idea is the same: more threads mean more overhead for </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">the GIL.</span></span></p>
<p><span class="koboSpan" id="kobo.258.1">The recommendation is not to use Python multithreading unless you are spawning a small number of threads and are not </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">CPU bound.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.260.1">Important note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.261.1">Because of the CPython GIL, it is not possible to run parallel threads in Python. </span><span class="koboSpan" id="kobo.261.2">Therefore, if your program is CPU bound and requires CPU parallelism, the way to go is to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.262.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.263.1"> library instead of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.264.1">threading</span></strong><span class="koboSpan" id="kobo.265.1"> library. </span><span class="koboSpan" id="kobo.265.2">More details can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.266.1">at </span></span><a href="http://docs.python.org/3/library/threading"><span class="No-Break"><span class="koboSpan" id="kobo.267.1">docs.python.org/3/library/threading</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.268.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.269.1">But if you still</span><a id="_idIndexMarker952"/><span class="koboSpan" id="kobo.270.1"> want to use Python with multithreading, there are other </span><a id="_idIndexMarker953"/><span class="koboSpan" id="kobo.271.1">Python interpreters that might provide some capability. </span><span class="koboSpan" id="kobo.271.2">One example </span><a id="_idIndexMarker954"/><span class="koboSpan" id="kobo.272.1">is </span><strong class="bold"><span class="koboSpan" id="kobo.273.1">PyPy-STM</span></strong><span class="koboSpan" id="kobo.274.1"> (PyPy was introduced and explained in </span><a href="B18165_06.xhtml#_idTextAnchor166"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.275.1">Chapter 6</span></em></span></a><span class="koboSpan" id="kobo.276.1">). </span><span class="koboSpan" id="kobo.276.2">However, to allow the usage of PyPy-STM, you will have to rewrite your code and not use the default </span><strong class="source-inline"><span class="koboSpan" id="kobo.277.1">threading</span></strong><span class="koboSpan" id="kobo.278.1"> module. </span><span class="koboSpan" id="kobo.278.2">With PyPy-STM, it is possible for simultaneous threads to run, but you will have to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.279.1">transaction</span></strong><span class="koboSpan" id="kobo.280.1"> module, specifically the </span><strong class="source-inline"><span class="koboSpan" id="kobo.281.1">TransactionQueue</span></strong><span class="koboSpan" id="kobo.282.1"> class. </span><span class="koboSpan" id="kobo.282.2">More on multithreading using </span><a id="_idIndexMarker955"/><span class="koboSpan" id="kobo.283.1">PyPy-STM can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">at </span></span><a href="http://doc.pypy.org/en/latest/stm.html#user-guide"><span class="No-Break"><span class="koboSpan" id="kobo.285.1">doc.pypy.org/en/latest/stm.html#user-guide</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.286.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.287.1">Now, let’s see how we can do multithreading </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">in Go.</span></span></p>
<h3><span class="koboSpan" id="kobo.289.1">Multithreading in Go</span></h3>
<p><span class="koboSpan" id="kobo.290.1">Writing code that</span><a id="_idIndexMarker956"/><span class="koboSpan" id="kobo.291.1"> scales in Go</span><a id="_idIndexMarker957"/><span class="koboSpan" id="kobo.292.1"> does not require the creation of threads or processes. </span><span class="koboSpan" id="kobo.292.2">Go implements parallelism very efficiently using goroutines, which are presented as threads to the operating system by the Go runtime. </span><span class="koboSpan" id="kobo.292.3">Goroutines will be explained in more detail in the following section, which talks </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">about coroutines.</span></span></p>
<p><span class="koboSpan" id="kobo.294.1">We will also see how we can run multiple lines of code at the same time </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">using coroutines.</span></span></p>
<h2 id="_idParaDest-200"><a id="_idTextAnchor201"/><span class="koboSpan" id="kobo.296.1">Coroutines</span></h2>
<p><span class="koboSpan" id="kobo.297.1">The term </span><em class="italic"><span class="koboSpan" id="kobo.298.1">coroutine</span></em><span class="koboSpan" id="kobo.299.1"> was </span><a id="_idIndexMarker958"/><span class="koboSpan" id="kobo.300.1">coined back in 1958 by Melvin Conway and Joel Erdwinn. </span><span class="koboSpan" id="kobo.300.2">Then, the idea was officially introduced in a paper published in the </span><em class="italic"><span class="koboSpan" id="kobo.301.1">ACM</span></em><span class="koboSpan" id="kobo.302.1"> magazine </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">in 1963.</span></span></p>
<p><span class="koboSpan" id="kobo.304.1">Despite being very old, the adoption of the term came later with some modern computer languages. </span><span class="koboSpan" id="kobo.304.2">Coroutines are essentially code that can be suspended. </span><span class="koboSpan" id="kobo.304.3">The concept is like a thread (in multithreading), because it is a small part of the code, and has local variables and its own stack. </span><span class="koboSpan" id="kobo.304.4">But the main difference between threads and coroutines in a multitasking system is threads can run in parallel and coroutines are collaborative. </span><span class="koboSpan" id="kobo.304.5">Some like to describe the difference as the same as between task concurrency and </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">task parallelism.</span></span></p>
<p><span class="koboSpan" id="kobo.306.1">Here is the definition taken from </span><em class="italic"><span class="koboSpan" id="kobo.307.1">Oracle Multithreaded </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.308.1">Programming Guide</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">:</span></span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.310.1">In a multithreaded process on a single processor, the processor can switch execution resources between threads, resulting in concurrent execution. </span><span class="koboSpan" id="kobo.310.2">Concurrency indicates that more than one thread is making progress, but the threads are not actually running simultaneously. </span><span class="koboSpan" id="kobo.310.3">The switching between threads happens quickly enough that the threads might appear to run simultaneously. </span><span class="koboSpan" id="kobo.310.4">In the same multithreaded process in a shared-memory multiprocessor environment, each thread in the process can run concurrently on a separate processor, resulting in parallel execution, which is true </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.311.1">simultaneous execution.</span></em></span></p>
<p><span class="koboSpan" id="kobo.312.1">The source can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">at </span></span><a href="https://docs.oracle.com/cd/E36784_01/html/E36868/mtintro-6.html"><span class="No-Break"><span class="koboSpan" id="kobo.314.1">https://docs.oracle.com/cd/E36784_01/html/E36868/mtintro-6.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.315.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.316.1">So, let’s now check how we can use coroutines in Python and then </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">in Go.</span></span></p>
<h3><span class="koboSpan" id="kobo.318.1">Adding coroutines in Python</span></h3>
<p><span class="koboSpan" id="kobo.319.1">Python has </span><a id="_idIndexMarker959"/><span class="koboSpan" id="kobo.320.1">recently added coroutines to the standard library. </span><span class="koboSpan" id="kobo.320.2">They</span><a id="_idIndexMarker960"/><span class="koboSpan" id="kobo.321.1"> are part of the module called </span><strong class="source-inline"><span class="koboSpan" id="kobo.322.1">asyncio</span></strong><span class="koboSpan" id="kobo.323.1">. </span><span class="koboSpan" id="kobo.323.2">Because of that, you won’t find this capability for older versions of Python; you need at least Python </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">version 3.7.</span></span></p>
<p><span class="koboSpan" id="kobo.325.1">But when do we use coroutines in Python? </span><span class="koboSpan" id="kobo.325.2">The best fit is when you require lots of parallel tasks that are I/O bound, such as a network. </span><span class="koboSpan" id="kobo.325.3">For CPU-bound applications, it is always recommended to use </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.326.1">multiprocessing</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.327.1"> instead.</span></span></p>
<p><span class="koboSpan" id="kobo.328.1">In comparison to </span><strong class="source-inline"><span class="koboSpan" id="kobo.329.1">threading</span></strong><span class="koboSpan" id="kobo.330.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.331.1">asyncio</span></strong><span class="koboSpan" id="kobo.332.1"> is more useful for our network automation work, because it is I/O bound and scales up more than using </span><strong class="source-inline"><span class="koboSpan" id="kobo.333.1">threading</span></strong><span class="koboSpan" id="kobo.334.1">. </span><span class="koboSpan" id="kobo.334.2">In addition, it is even lighter than threads </span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">and processes.</span></span></p>
<p><span class="koboSpan" id="kobo.336.1">Let’s then create the same ICMP probe test using coroutines in Python. </span><span class="koboSpan" id="kobo.336.2">The following is an example of the code for the same network targets used in previous examples (you can find this code in  </span><strong class="source-inline"><span class="koboSpan" id="kobo.337.1">Chapter08/Python/asyncio-example.py</span></strong><span class="koboSpan" id="kobo.338.1"> in the GitHub repo of </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">the book):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.340.1">
from </span><strong class="bold"><span class="koboSpan" id="kobo.341.1">pythonping</span></strong><span class="koboSpan" id="kobo.342.1"> import ping
import asyncio
TARGETS = ["yahoo.com", "google.com", "cisco.com", "cern.ch"]
</span><strong class="bold"><span class="koboSpan" id="kobo.343.1">async def myping(host)</span></strong><span class="koboSpan" id="kobo.344.1">:
    response = ping(host)
    if response.success:
        print("%s OK, latency is %.3fms" % (host, response.rtt_avg_ms))
    else:
        print(host, "FAILED")
async def main():
    coroutines = []
    for target in TARGETS:
        coroutines.append(
            asyncio.ensure_future(myping(target)))
    for coroutine in coroutines:
        await coroutine
if __name__ == "__main__":
    asyncio.run(main())</span></pre>
<p><span class="koboSpan" id="kobo.345.1">Running the </span><a id="_idIndexMarker961"/><span class="koboSpan" id="kobo.346.1">preceding program example will generate the </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">following</span></span><span class="No-Break"><a id="_idIndexMarker962"/></span><span class="No-Break"><span class="koboSpan" id="kobo.348.1"> output:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.349.1">
% sudo python3 asyncio-example.py
yahoo.com OK, latency is 192.75ms
google.com OK, latency is 29.93ms
cisco.com OK, latency is 162.89ms
cern.ch OK, latency is 339.76ms</span></pre>
<p><span class="koboSpan" id="kobo.350.1">Note that now, the </span><a id="_idIndexMarker963"/><span class="koboSpan" id="kobo.351.1">first ping reply to be printed is not actually the one that </span><a id="_idIndexMarker964"/><span class="koboSpan" id="kobo.352.1">has the least latency, which shows the program is running sequentially, following the order of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.353.1">TARGETS</span></strong><span class="koboSpan" id="kobo.354.1"> variable in the loop. </span><span class="koboSpan" id="kobo.354.2">That means the </span><strong class="source-inline"><span class="koboSpan" id="kobo.355.1">asyncio</span></strong><span class="koboSpan" id="kobo.356.1"> coroutines are not being suspended to allow others to run when they are blocked. </span><span class="koboSpan" id="kobo.356.2">Therefore, this is not a good example of using coroutines if we want to scale up. </span><span class="koboSpan" id="kobo.356.3">This is because the library used in the example is </span><strong class="source-inline"><span class="koboSpan" id="kobo.357.1">pythonping</span></strong><span class="koboSpan" id="kobo.358.1">, which is not </span><strong class="source-inline"><span class="koboSpan" id="kobo.359.1">asyncio</span></strong><span class="koboSpan" id="kobo.360.1"> compatible and is not suspending the coroutine when it is waiting for the network </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">ICMP response.</span></span></p>
<p><span class="koboSpan" id="kobo.362.1">We added this example to show how bad it is to use </span><strong class="source-inline"><span class="koboSpan" id="kobo.363.1">asyncio</span></strong><span class="koboSpan" id="kobo.364.1"> with coroutines that have code that is incompatible with </span><strong class="source-inline"><span class="koboSpan" id="kobo.365.1">asyncio</span></strong><span class="koboSpan" id="kobo.366.1">. </span><span class="koboSpan" id="kobo.366.2">To fix this issue, let’s now use a third-party library for the ICMP probe that is compatible with </span><strong class="source-inline"><span class="koboSpan" id="kobo.367.1">asyncio</span></strong><span class="koboSpan" id="kobo.368.1">, which is </span><span class="No-Break"><span class="koboSpan" id="kobo.369.1">called </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.370.1">aioping</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.371.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.372.1">The following code only shows the change on the import to add </span><strong class="source-inline"><span class="koboSpan" id="kobo.373.1">aioping</span></strong><span class="koboSpan" id="kobo.374.1"> instead of </span><strong class="source-inline"><span class="koboSpan" id="kobo.375.1">pythonping</span></strong><span class="koboSpan" id="kobo.376.1"> and the change on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.377.1">myping()</span></strong><span class="koboSpan" id="kobo.378.1"> function, where we added an </span><strong class="source-inline"><span class="koboSpan" id="kobo.379.1">await</span></strong><span class="koboSpan" id="kobo.380.1"> statement before the </span><strong class="source-inline"><span class="koboSpan" id="kobo.381.1">ping()</span></strong><span class="koboSpan" id="kobo.382.1">function. </span><span class="koboSpan" id="kobo.382.2">The other difference is that </span><strong class="source-inline"><span class="koboSpan" id="kobo.383.1">aioping</span></strong><span class="koboSpan" id="kobo.384.1"> works with the exception called </span><strong class="source-inline"><span class="koboSpan" id="kobo.385.1">TimeoutError</span></strong><span class="koboSpan" id="kobo.386.1"> to detect a non-response of an </span><span class="No-Break"><span class="koboSpan" id="kobo.387.1">ICMP request:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.388.1">
from </span><strong class="bold"><span class="koboSpan" id="kobo.389.1">aioping</span></strong><span class="koboSpan" id="kobo.390.1"> import ping
async def myping(host):
    </span><strong class="bold"><span class="koboSpan" id="kobo.391.1">try:</span></strong><span class="koboSpan" id="kobo.392.1">
        delay = </span><strong class="bold"><span class="koboSpan" id="kobo.393.1">await</span></strong><span class="koboSpan" id="kobo.394.1"> ping(host)
        print("%s OK, latency is %.3f ms" % (host, delay * 1000))
    </span><strong class="bold"><span class="koboSpan" id="kobo.395.1">except TimeoutError:</span></strong><span class="koboSpan" id="kobo.396.1">
        print(host, "FAILED")</span></pre>
<p><span class="koboSpan" id="kobo.397.1">The complete program with the fixes shown previously can be found in the GitHub repository of this book </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">at </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.399.1">Chapter08/Python/asyncio-example-fixed.py</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.401.1">If you run this code now with the fix, it should show something like the </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1">following output:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.403.1">
% sudo python3 asyncio-example-fixed.py
google.com OK, latency is 40.175 ms
cisco.com OK, latency is 170.222 ms
yahoo.com OK, latency is 181.696 ms
cern.ch OK, latency is 281.662 ms</span></pre>
<p><span class="koboSpan" id="kobo.404.1">Note that, now, the output is based on how fast the targets answer the ICMP request and the output does not follow the </span><strong class="source-inline"><span class="koboSpan" id="kobo.405.1">TARGETS</span></strong><span class="koboSpan" id="kobo.406.1"> list order like in the </span><span class="No-Break"><span class="koboSpan" id="kobo.407.1">previous example.</span></span></p>
<p><span class="koboSpan" id="kobo.408.1">The important difference in the preceding code is the usage of </span><strong class="source-inline"><span class="koboSpan" id="kobo.409.1">await</span></strong><span class="koboSpan" id="kobo.410.1"> before </span><strong class="source-inline"><span class="koboSpan" id="kobo.411.1">ping</span></strong><span class="koboSpan" id="kobo.412.1">, which indicates to the Python </span><strong class="source-inline"><span class="koboSpan" id="kobo.413.1">asyncio</span></strong><span class="koboSpan" id="kobo.414.1"> module that the coroutine may stop and allow another coroutine </span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">to run.</span></span></p>
<p><span class="koboSpan" id="kobo.416.1">Now, you may be wondering whether you could, instead of using the new library, </span><strong class="source-inline"><span class="koboSpan" id="kobo.417.1">aioping</span></strong><span class="koboSpan" id="kobo.418.1">, just add </span><strong class="source-inline"><span class="koboSpan" id="kobo.419.1">await</span></strong><span class="koboSpan" id="kobo.420.1"> to the previous example in front of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.421.1">ping</span></strong><span class="koboSpan" id="kobo.422.1"> statement in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.423.1">pythonping</span></strong><span class="koboSpan" id="kobo.424.1"> library. </span><span class="koboSpan" id="kobo.424.2">But that will not work and will generate the </span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">following exception:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.426.1">
TypeError: object ResponseList can't be used in 'await' expression</span></pre>
<p><span class="koboSpan" id="kobo.427.1">That is because the </span><strong class="source-inline"><span class="koboSpan" id="kobo.428.1">pythonping</span></strong><span class="koboSpan" id="kobo.429.1"> library is not compatible with the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.430.1">asyncio</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.431.1"> module.</span></span></p>
<p><span class="koboSpan" id="kobo.432.1">Use </span><strong class="source-inline"><span class="koboSpan" id="kobo.433.1">asyncio</span></strong><span class="koboSpan" id="kobo.434.1"> whenever</span><a id="_idIndexMarker965"/><span class="koboSpan" id="kobo.435.1"> you need to have lots of tasks running because it is very </span><a id="_idIndexMarker966"/><span class="koboSpan" id="kobo.436.1">cheap to use coroutines as a task, much faster and lighter than processes and threads. </span><span class="koboSpan" id="kobo.436.2">However, it requires that your application be I/O bound to take advantage of the concurrency of the coroutines. </span><span class="koboSpan" id="kobo.436.3">Access to network devices is a good example of a slow I/O-bound application and may be a perfect fit for our network </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">automation cases.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.438.1">Important note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.439.1">To allow efficient use of coroutines in Python, you have to make sure that the coroutine is suspending execution when there is a wait in I/O (such as a network) to allow other coroutines to run. </span><span class="koboSpan" id="kobo.439.2">This is normally indicated by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.440.1">asyncio</span></strong><span class="koboSpan" id="kobo.441.1"> statement called </span><strong class="source-inline"><span class="koboSpan" id="kobo.442.1">await</span></strong><span class="koboSpan" id="kobo.443.1">. </span><span class="koboSpan" id="kobo.443.2">Indeed, using the third-party library in your coroutine needs to be compatible with </span><strong class="source-inline"><span class="koboSpan" id="kobo.444.1">asyncio</span></strong><span class="koboSpan" id="kobo.445.1">. </span><span class="koboSpan" id="kobo.445.2">As the </span><strong class="source-inline"><span class="koboSpan" id="kobo.446.1">asyncio</span></strong><span class="koboSpan" id="kobo.447.1"> module is quite new, there are not many third-party libraries that are compatible with </span><strong class="source-inline"><span class="koboSpan" id="kobo.448.1">asyncio</span></strong><span class="koboSpan" id="kobo.449.1">. </span><span class="koboSpan" id="kobo.449.2">Without this compatibility, your code will run coroutines sequentially instead of concurrently, and using </span><strong class="source-inline"><span class="koboSpan" id="kobo.450.1">asyncio</span></strong><span class="koboSpan" id="kobo.451.1"> will not be a </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">good idea.</span></span></p>
<p><span class="koboSpan" id="kobo.453.1">Let’s see how coroutines can be used </span><span class="No-Break"><span class="koboSpan" id="kobo.454.1">in Go.</span></span></p>
<h3><span class="koboSpan" id="kobo.455.1">Coroutines in Go</span></h3>
<p><span class="koboSpan" id="kobo.456.1">The Go language is special</span><a id="_idIndexMarker967"/><span class="koboSpan" id="kobo.457.1"> and shines best when it requires code to scale up with </span><a id="_idIndexMarker968"/><span class="koboSpan" id="kobo.458.1">performance, and that is accomplished in Go </span><span class="No-Break"><span class="koboSpan" id="kobo.459.1">using goroutines.</span></span></p>
<p><span class="koboSpan" id="kobo.460.1">Goroutines are not the same as coroutines, because they can run like threads in parallel. </span><span class="koboSpan" id="kobo.460.2">But they are not like threads either, because they are much smaller (starting with only 8 KB for Go version 1.4) and use channels for communication. </span><span class="koboSpan" id="kobo.460.3">This may be confusing at first, but I promise you that goroutines are not difficult to understand and use. </span><span class="koboSpan" id="kobo.460.4">Indeed, they are easier to understand and use compared to coroutines </span><span class="No-Break"><span class="koboSpan" id="kobo.461.1">in Python.</span></span></p>
<p><span class="koboSpan" id="kobo.462.1">Since Go version 1.14, goroutines are implemented using asynchronously preemptible scheduling. </span><span class="koboSpan" id="kobo.462.2">That means the tasks are no longer in the control of the developer and are entirely managed by Go’s runtime (you can find details at </span><a href="https://go.dev/doc/go1.14#runtime"><span class="koboSpan" id="kobo.463.1">https://go.dev/doc/go1.14#runtime</span></a><span class="koboSpan" id="kobo.464.1">). </span><span class="koboSpan" id="kobo.464.2">Go’s runtime is responsible for presenting to the operating system the threads that are going to run, which can run simultaneously in </span><span class="No-Break"><span class="koboSpan" id="kobo.465.1">some cases.</span></span></p>
<p><span class="koboSpan" id="kobo.466.1">Go’s runtime is responsible for creating and destroying the threads that correspond to a goroutine. </span><span class="koboSpan" id="kobo.466.2">These operations would be much heavier when implemented by the operating system using a native multithreading language, but in Go, they are light as Go’s runtime maintains a pool of threads for the goroutines. </span><span class="koboSpan" id="kobo.466.3">The fact that Go’s runtime controls the mapping between goroutines and threads makes the operating system completely unaware </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">of goroutines.</span></span></p>
<p><span class="koboSpan" id="kobo.468.1">In summary, Go doesn’t use coroutines, but instead uses goroutines, which are not the same and are more like a blend between coroutines and threads, with better performance than </span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">the two.</span></span></p>
<p><span class="koboSpan" id="kobo.470.1">Let’s now go through a simple example of an ICMP probe </span><span class="No-Break"><span class="koboSpan" id="kobo.471.1">using goroutines:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.472.1">
import (
    "fmt"
    "time"
    "github.com/go-ping/ping"
)
func myPing(host string) {
    p, err := ping.NewPinger(host)
    if err != nil {
        panic(err)
    }
    p.Count = 1
    p.SetPrivileged(true)
    if err = p.Run(); err != nil {
        panic(err)
    }
    stats := p.Statistics()
    fmt.Println(host, "OK, latency is", stats.AvgRtt)
}
func main() {
    targets := []string{"yahoo.com", "google.com", "cisco.com", "cern.ch"}
    for _, target := range targets {
        </span><strong class="bold"><span class="koboSpan" id="kobo.473.1">go</span></strong><span class="koboSpan" id="kobo.474.1"> myPing(target)
    }
    time.Sleep(time.Second * 3) //Wait 3 seconds
}</span></pre>
<p><span class="koboSpan" id="kobo.475.1">If you</span><a id="_idIndexMarker969"/><span class="koboSpan" id="kobo.476.1"> run this </span><a id="_idIndexMarker970"/><span class="koboSpan" id="kobo.477.1">program, it should output something like </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">the following:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.479.1">
$ go run goroutine-icmp-probe.go
google.com OK, latency is 15.9587ms
cisco.com OK, latency is 163.6334ms
yahoo.com OK, latency is 136.3522ms
cern.ch OK, latency is 225.0571ms</span></pre>
<p><span class="koboSpan" id="kobo.480.1">To use a goroutine, you just need to add </span><strong class="source-inline"><span class="koboSpan" id="kobo.481.1">go</span></strong><span class="koboSpan" id="kobo.482.1"> in front of the function you want to call as a goroutine. </span><span class="koboSpan" id="kobo.482.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.483.1">go</span></strong><span class="koboSpan" id="kobo.484.1"> statement indicates that the function can be executed in the background with its own stack and variables. </span><span class="koboSpan" id="kobo.484.2">The program then executes the line after the </span><strong class="source-inline"><span class="koboSpan" id="kobo.485.1">go</span></strong><span class="koboSpan" id="kobo.486.1"> statement and continues the flow normally without waiting for anything to return from the goroutine. </span><span class="koboSpan" id="kobo.486.2">As the ICMP probe request takes a few milliseconds to receive an ICMP response, the program will exit before it can print anything by the goroutines. </span><span class="koboSpan" id="kobo.486.3">Therefore, we need to add a sleep time of 3 seconds before finishing the program to make sure all the goroutines that send ICMP requests have received and printed the results. </span><span class="koboSpan" id="kobo.486.4">Otherwise, you won’t be able to see any output, because the program will end before the goroutines finish printing </span><span class="No-Break"><span class="koboSpan" id="kobo.487.1">the results.</span></span></p>
<p><span class="koboSpan" id="kobo.488.1">If you want to wait until the goroutines end, Go has mechanisms to communicate and wait until they end. </span><span class="koboSpan" id="kobo.488.2">One simple one is using </span><strong class="source-inline"><span class="koboSpan" id="kobo.489.1">sync.WaitGroup</span></strong><span class="koboSpan" id="kobo.490.1">. </span><span class="koboSpan" id="kobo.490.2">Let’s now rewrite our previous example, removing the sleep time and adding </span><strong class="source-inline"><span class="koboSpan" id="kobo.491.1">WaitGroup</span></strong><span class="koboSpan" id="kobo.492.1"> to wait for the goroutines to finish. </span><span class="koboSpan" id="kobo.492.2">The following is the same example that waits until all </span><span class="No-Break"><span class="koboSpan" id="kobo.493.1">goroutines end:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.494.1">
import (
    "fmt"
    "sync"
    "github.com/go-ping/ping"
)
func myping(host string, </span><strong class="bold"><span class="koboSpan" id="kobo.495.1">wg *sync.WaitGroup</span></strong><span class="koboSpan" id="kobo.496.1">) {
    </span><strong class="bold"><span class="koboSpan" id="kobo.497.1">defer wg.Done()</span></strong><span class="koboSpan" id="kobo.498.1">
    p, err := ping.NewPinger(host)
    if err != nil {
        panic(err)
    }
    p.Count = 1
    p.SetPrivileged(true)
    if err = p.Run(); err != nil {
        panic(err)
    }
    stats := p.Statistics()
    fmt.Println(host, "OK, latency is", stats.AvgRtt)
}
func main() {
    var targets = []string{"yahoo.com", "google.com", "cisco.com", "cern.ch"}
    </span><strong class="bold"><span class="koboSpan" id="kobo.499.1">var wg sync.WaitGroup</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.500.1">    wg.Add(len(targets))</span></strong><span class="koboSpan" id="kobo.501.1">
    for _, target := range targets {
        go myping(target, </span><strong class="bold"><span class="koboSpan" id="kobo.502.1">&amp;wg</span></strong><span class="koboSpan" id="kobo.503.1">)
    }
    </span><strong class="bold"><span class="koboSpan" id="kobo.504.1">wg.Wait(</span></strong><span class="koboSpan" id="kobo.505.1">)
}</span></pre>
<p><span class="koboSpan" id="kobo.506.1">If you run the </span><a id="_idIndexMarker971"/><span class="koboSpan" id="kobo.507.1">preceding code, it should end faster than the previous one because it</span><a id="_idIndexMarker972"/><span class="koboSpan" id="kobo.508.1"> does not sleep for 3 seconds; it only waits until all goroutines end, which should be less than half </span><span class="No-Break"><span class="koboSpan" id="kobo.509.1">a second.</span></span></p>
<p><span class="koboSpan" id="kobo.510.1">To allow </span><strong class="source-inline"><span class="koboSpan" id="kobo.511.1">sync.WaitGroup</span></strong><span class="koboSpan" id="kobo.512.1"> to work, you have to set a value to it at the beginning using </span><strong class="source-inline"><span class="koboSpan" id="kobo.513.1">Add()</span></strong><span class="koboSpan" id="kobo.514.1">. </span><span class="koboSpan" id="kobo.514.2">In the preceding example, it adds </span><strong class="source-inline"><span class="koboSpan" id="kobo.515.1">4</span></strong><span class="koboSpan" id="kobo.516.1">, which is the number of goroutines that will run. </span><span class="koboSpan" id="kobo.516.2">Then, you pass the pointer of the variable to each goroutine function (</span><strong class="source-inline"><span class="koboSpan" id="kobo.517.1">&amp;wg</span></strong><span class="koboSpan" id="kobo.518.1">), which will be marked as </span><strong class="source-inline"><span class="koboSpan" id="kobo.519.1">Done()</span></strong><span class="koboSpan" id="kobo.520.1"> as the function ends using </span><strong class="source-inline"><span class="koboSpan" id="kobo.521.1">defer</span></strong><span class="koboSpan" id="kobo.522.1"> (explained in </span><a href="B18165_07.xhtml#_idTextAnchor183"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.523.1">Chapter 7</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.524.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.525.1">In the preceding example, we did not generate any communication between the goroutines, as they use the terminal to print. </span><span class="koboSpan" id="kobo.525.2">We only passed a pointer to the workgroup variable, called </span><strong class="source-inline"><span class="koboSpan" id="kobo.526.1">wg</span></strong><span class="koboSpan" id="kobo.527.1">. </span><span class="koboSpan" id="kobo.527.2">If you want to communicate between goroutines, you can do that by using </span><strong class="source-inline"><span class="koboSpan" id="kobo.528.1">channel</span></strong><span class="koboSpan" id="kobo.529.1">, which can be unidirectional </span><span class="No-Break"><span class="koboSpan" id="kobo.530.1">or bidirectional.</span></span></p>
<p><span class="koboSpan" id="kobo.531.1">More on goroutines</span><a id="_idIndexMarker973"/><span class="koboSpan" id="kobo.532.1"> can be found at the </span><span class="No-Break"><span class="koboSpan" id="kobo.533.1">following links:</span></span></p>
<ul>
<li><em class="italic"><span class="koboSpan" id="kobo.534.1">Google I/O 2012 - Go Concurrency </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.535.1">Patterns</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.536.1">: </span></span><a href="https://www.youtube.com/watch?v=f6kdp27TYZs"><span class="No-Break"><span class="koboSpan" id="kobo.537.1">https://www.youtube.com/watch?v=f6kdp27TYZs</span></span></a></li>
<li><em class="italic"><span class="koboSpan" id="kobo.538.1">Google I/O 2013 – Advanced Go Concurrency </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.539.1">Patterns</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.540.1">: </span></span><a href="https://www.youtube.com/watch?v=QDDwwePbDtw"><span class="No-Break"><span class="koboSpan" id="kobo.541.1">https://www.youtube.com/watch?v=QDDwwePbDtw</span></span></a></li>
<li><span class="koboSpan" id="kobo.542.1">More documentation on Goroutines can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">at </span></span><a href="http://go.dev/doc/effective_go#concurrency"><span class="No-Break"><span class="koboSpan" id="kobo.544.1">go.dev/doc/effective_go#concurrency</span></span></a></li>
</ul>
<p><span class="koboSpan" id="kobo.545.1">Before going to the next section, let’s summarize how we scale up in Python and Go. </span><span class="koboSpan" id="kobo.545.2">In Python, to make the right choice, use </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.546.1">Figure 8</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.547.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.548.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer052">
<span class="koboSpan" id="kobo.549.1"><img alt="Figure 8.1 – Python decision-making for scaling your code" src="image/B18165_08_001.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.550.1">Figure 8.1 – Python decision-making for scaling your code</span></p>
<p><span class="koboSpan" id="kobo.551.1">The diagram in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.552.1">Figure 8</span></em></span><em class="italic"><span class="koboSpan" id="kobo.553.1">.1</span></em><span class="koboSpan" id="kobo.554.1"> shows which Python library to use when scaling your code. </span><span class="koboSpan" id="kobo.554.2">If CPU bound, use </span><strong class="source-inline"><span class="koboSpan" id="kobo.555.1">multiprocessing</span></strong><span class="koboSpan" id="kobo.556.1">. </span><span class="koboSpan" id="kobo.556.2">If you have too many connections with slow I/O, use </span><strong class="source-inline"><span class="koboSpan" id="kobo.557.1">asyncio</span></strong><span class="koboSpan" id="kobo.558.1">, and if the number of connections is small, </span><span class="No-Break"><span class="koboSpan" id="kobo.559.1">use </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.560.1">threading</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.561.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.562.1">For Go, there is only one option, which is a goroutine. </span><span class="No-Break"><span class="koboSpan" id="kobo.563.1">Easy answer!</span></span></p>
<p><span class="koboSpan" id="kobo.564.1">Let’s now check how we can scale the system using schedulers </span><span class="No-Break"><span class="koboSpan" id="kobo.565.1">and dispatchers.</span></span></p>
<h1 id="_idParaDest-201"><a id="_idTextAnchor202"/><span class="koboSpan" id="kobo.566.1">Adding schedulers and job dispatchers</span></h1>
<p><span class="koboSpan" id="kobo.567.1">A scheduler </span><a id="_idIndexMarker974"/><span class="koboSpan" id="kobo.568.1">is a system that selects a job for </span><a id="_idIndexMarker975"/><span class="koboSpan" id="kobo.569.1">running, where a </span><strong class="bold"><span class="koboSpan" id="kobo.570.1">job</span></strong><span class="koboSpan" id="kobo.571.1"> can be understood as a program or part of code that requires running. </span><span class="koboSpan" id="kobo.571.2">A dispatcher, on the other hand, is the system that takes the job and places it in the execution queue of a machine. </span><span class="koboSpan" id="kobo.571.3">They are complementary, and in some cases, they are treated as the same system. </span><span class="koboSpan" id="kobo.571.4">So, for the purpose of this section, we are going to talk about some systems that can do both scheduling and </span><span class="No-Break"><span class="koboSpan" id="kobo.572.1">dispatching jobs.</span></span></p>
<p><span class="koboSpan" id="kobo.573.1">The main objective of using systems that can schedule and dispatch jobs is to gain scale by adding machines that can run more jobs in parallel. </span><span class="koboSpan" id="kobo.573.2">It is kind of similar to a single program using multiprocessing but with the difference that the new processes are being executed on </span><span class="No-Break"><span class="koboSpan" id="kobo.574.1">another machine.</span></span></p>
<p><span class="koboSpan" id="kobo.575.1">You could do lots of work to improve the performance of your program, but in the end, you will be bound by the machine’s limitations, and if your application is CPU bound, it will be limited by the number of cores, the number of concurrent threads, and the speed of the CPU used. </span><span class="koboSpan" id="kobo.575.2">You could work hard to improve the performance of your code, but to grow more, the only solution is to add more CPU hardware, which can be accomplished by adding machines. </span><span class="koboSpan" id="kobo.575.3">The group of machines that are dedicated to running jobs for schedulers and dispatchers is normally</span><a id="_idIndexMarker976"/><span class="koboSpan" id="kobo.576.1"> called </span><span class="No-Break"><span class="koboSpan" id="kobo.577.1">a </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.578.1">cluster</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.579.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.580.1">A cluster of machines that are ready to run jobs in parallel can be installed locally or can be installed in separate locations. </span><span class="koboSpan" id="kobo.580.2">The distance between the machines in a cluster adds latency to the communication between the machines and delays data synchronization. </span><span class="koboSpan" id="kobo.580.3">Quick synchronization between machines may or may not be relevant, depending on how fast the results are required and how they need to be combined if they depend on each other in time. </span><span class="koboSpan" id="kobo.580.4">Quicker results might require a local cluster. </span><span class="koboSpan" id="kobo.580.5">A more relaxed time frame for getting results would allow clusters to be located </span><span class="No-Break"><span class="koboSpan" id="kobo.581.1">further apart.</span></span></p>
<p><span class="koboSpan" id="kobo.582.1">Let’s now discuss how we can use a classical scheduler </span><span class="No-Break"><span class="koboSpan" id="kobo.583.1">and dispatcher.</span></span></p>
<h2 id="_idParaDest-202"><a id="_idTextAnchor203"/><span class="koboSpan" id="kobo.584.1">Using classical schedulers and dispatchers</span></h2>
<p><span class="koboSpan" id="kobo.585.1">The classical scheduler</span><a id="_idIndexMarker977"/><span class="koboSpan" id="kobo.586.1"> and</span><a id="_idIndexMarker978"/><span class="koboSpan" id="kobo.587.1"> dispatcher would be any system that takes one job, deploys it to a machine in the cluster, and executes it. </span><span class="koboSpan" id="kobo.587.2">In a classical case, the job is just a program that is ready to run on a machine. </span><span class="koboSpan" id="kobo.587.3">The program can be written in any language; however, there are differences in how the installation would be compared between Python </span><span class="No-Break"><span class="koboSpan" id="kobo.588.1">and Go.</span></span></p>
<p><span class="koboSpan" id="kobo.589.1">Let’s investigate what the differences are between using a cluster ready to run Python scripts and ready to run </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">Go-compiled code.</span></span></p>
<h3><span class="koboSpan" id="kobo.591.1">Considerations for using Go and Python</span></h3>
<p><span class="koboSpan" id="kobo.592.1">If the program was written in </span><a id="_idIndexMarker979"/><span class="koboSpan" id="kobo.593.1">Python, it is required that all machines in the cluster have the Python interpreter version that is compatible with the Python code. </span><span class="koboSpan" id="kobo.593.2">For instance, if code was written for Python 3.10, the CPython interpreter to be installed must be at least version 3.10. </span><span class="koboSpan" id="kobo.593.3">Another important point here is that all third-party libraries used in the Python script will also have to be installed on all machines. </span><span class="koboSpan" id="kobo.593.4">The version of each third-party library must be compatible with the Python</span><a id="_idIndexMarker980"/><span class="koboSpan" id="kobo.594.1"> script, as newer versions of a particular third-party library might break the execution of your code. </span><span class="koboSpan" id="kobo.594.2">You might need to maintain a table somewhere containing the versions of each third-party library used to avoid wrong machine updates. </span><span class="koboSpan" id="kobo.594.3">In conclusion, using Python complicates your cluster installation, management, and updates </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1">a lot.</span></span></p>
<p><span class="koboSpan" id="kobo.596.1">On the other hand, using the </span><a id="_idIndexMarker981"/><span class="koboSpan" id="kobo.597.1">Go language is much simpler for deploying in a cluster. </span><span class="koboSpan" id="kobo.597.2">You just need to compile the Go program to the same CPU architecture that the code will run. </span><span class="koboSpan" id="kobo.597.3">All third-party libraries used will be added to the compiled code. </span><span class="koboSpan" id="kobo.597.4">The versions of each third-party library used in your program will be controlled automatically by your local development environment with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.598.1">go.sum</span></strong><span class="koboSpan" id="kobo.599.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.600.1">go.mod</span></strong><span class="koboSpan" id="kobo.601.1"> files. </span><span class="koboSpan" id="kobo.601.2">In summary, you don’t need to install an interpreter on the machines and don’t need to worry about installing or updating any third-party libraries, which is </span><span class="No-Break"><span class="koboSpan" id="kobo.602.1">much simpler.</span></span></p>
<p><span class="koboSpan" id="kobo.603.1">Let’s now see a few examples of a scheduler and dispatcher for a cluster </span><span class="No-Break"><span class="koboSpan" id="kobo.604.1">of machines.</span></span></p>
<h3><span class="koboSpan" id="kobo.605.1">Using Nomad</span></h3>
<p><span class="koboSpan" id="kobo.606.1">Nomad is an </span><a id="_idIndexMarker982"/><span class="koboSpan" id="kobo.607.1">implementation for job scheduling that was built using Go and is supported by a company called HashiCorp (</span><a href="https://www.nomadproject.io/"><span class="koboSpan" id="kobo.608.1">https://www.nomadproject.io/</span></a><span class="koboSpan" id="kobo.609.1">). </span><span class="koboSpan" id="kobo.609.2">Nomad</span><a id="_idIndexMarker983"/><span class="koboSpan" id="kobo.610.1"> is also very popular for scheduling and launching Docker containers in a cluster of machines, as we are going to see in the </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">next section.</span></span></p>
<p><span class="koboSpan" id="kobo.612.1">With Nomad, you are able to define a job by writing a configuration file that describes the job and how you want to run it. </span><span class="koboSpan" id="kobo.612.2">The job description can be written in any formatted file, such as YAML or TOML, but the default supported format is </span><strong class="bold"><span class="koboSpan" id="kobo.613.1">HCL</span></strong><span class="koboSpan" id="kobo.614.1">. </span><span class="koboSpan" id="kobo.614.2">Once you have the job description completed, it is then translated to JSON, which will be used on the Nomad API (more details can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.615.1">at </span></span><a href="https://developer.hashicorp.com/nomad/docs/job-specification"><span class="No-Break"><span class="koboSpan" id="kobo.616.1">https://developer.hashicorp.com/nomad/docs/job-specification</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.617.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.618.1">Nomad supports several task drivers, which allows you to schedule different kinds of programs. </span><span class="koboSpan" id="kobo.618.2">If you are using a Go-compiled program, you will have to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.619.1">Fork/Exec</span></strong><span class="koboSpan" id="kobo.620.1"> driver (further details are available at </span><a href="https://developer.hashicorp.com/nomad/docs/drivers/exec"><span class="koboSpan" id="kobo.621.1">https://developer.hashicorp.com/nomad/docs/drivers/exec</span></a><span class="koboSpan" id="kobo.622.1">). </span><span class="koboSpan" id="kobo.622.2">Using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.623.1">Fork/Exec</span></strong><span class="koboSpan" id="kobo.624.1"> driver, you can execute any program, including Python scripts, but with the caveat of having all third-party libraries and the Python interpreter previously installed on all machines of the cluster, which is not managed by Nomad and must be done on your </span><span class="No-Break"><span class="koboSpan" id="kobo.625.1">own separately.</span></span></p>
<p><span class="koboSpan" id="kobo.626.1">The following is an</span><a id="_idIndexMarker984"/><span class="koboSpan" id="kobo.627.1"> example of a job specification for an ICMP </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">probe program:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.629.1">
job "probe-icmp" {
  region = "us"
  datacenters = ["us-1", "us-12"]
  type = "service"
  update {
    stagger      = "60s"
    max_parallel = 4
  }
  task "probe" {
    driver = "exec"
    config {
      command = "/usr/local/bin/icmp-probe"
    }
    env {
      TARGETS = "cisco.com,yahoo.com,google.com"
    }
    resources {
      cpu    = 700 # approximated in MHz
      memory = 16 # in MBytes
    }
}</span></pre>
<p><span class="koboSpan" id="kobo.630.1">Note that the preceding program example is called </span><strong class="source-inline"><span class="koboSpan" id="kobo.631.1">icmp-probe</span></strong><span class="koboSpan" id="kobo.632.1"> and would have to accept the operating system environment variable as input. </span><span class="koboSpan" id="kobo.632.2">In our example, the variable is </span><span class="No-Break"><span class="koboSpan" id="kobo.633.1">called </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.634.1">TARGETS</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.635.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.636.1">Once you have defined your job, you can dispatch</span><a id="_idIndexMarker985"/><span class="koboSpan" id="kobo.637.1"> it by issuing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.638.1">nomad job dispatch &lt;job-description-file&gt;</span></strong><span class="koboSpan" id="kobo.639.1"> command (more details can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.640.1">at </span></span><a href="http://developer.hashicorp.com/nomad/docs/commands/job/dispatch"><span class="No-Break"><span class="koboSpan" id="kobo.641.1">developer.hashicorp.com/nomad/docs/commands/job/dispatch</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.642.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.643.1">Let’s now check how we could use another </span><span class="No-Break"><span class="koboSpan" id="kobo.644.1">popular scheduler.</span></span></p>
<h3><span class="koboSpan" id="kobo.645.1">Using Cronsun</span></h3>
<p><span class="koboSpan" id="kobo.646.1">Cronsun is </span><a id="_idIndexMarker986"/><span class="koboSpan" id="kobo.647.1">another scheduler and dispatcher that works in a similar way to the popular Unix cron but for multiple machines. </span><span class="koboSpan" id="kobo.647.2">The goal of Cronsun is to be easy and simple for managing jobs on lots of machines. </span><span class="koboSpan" id="kobo.647.3">It is developed in the Go language but can also launch jobs in any language by invoking a shell on the remote machine, such as in the Nomad </span><strong class="source-inline"><span class="koboSpan" id="kobo.648.1">Fork/Exec</span></strong><span class="koboSpan" id="kobo.649.1"> driver (more details can be found at </span><a href="https://github.com/shunfei/cronsun"><span class="koboSpan" id="kobo.650.1">https://github.com/shunfei/cronsun</span></a><span class="koboSpan" id="kobo.651.1">). </span><span class="koboSpan" id="kobo.651.2">It also has a graphical interface that allows easy visualization of the running jobs. </span><span class="koboSpan" id="kobo.651.3">Cronsun was built and designed based on another Go third-party package, called </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.652.1">robfig/cron</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.653.1"> (</span></span><a href="https://github.com/robfig/cron"><span class="No-Break"><span class="koboSpan" id="kobo.654.1">https://github.com/robfig/cron</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.655.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.656.1">Using Cronsun, you will be able to launch several jobs on multiple machines, but there is no machine cluster management like in Nomad. </span><span class="koboSpan" id="kobo.656.2">Another important point is Cronsun does not work with Linux containers, so it purely focuses on executing Unix shell programs in the remote machine by doing </span><span class="No-Break"><span class="koboSpan" id="kobo.657.1">process forking.</span></span></p>
<p><span class="koboSpan" id="kobo.658.1">Let’s now look at a more </span><span class="No-Break"><span class="koboSpan" id="kobo.659.1">complex scheduler.</span></span></p>
<h3><span class="koboSpan" id="kobo.660.1">Using DolphinScheduler</span></h3>
<p><span class="koboSpan" id="kobo.661.1">DolphinScheduler</span><a id="_idIndexMarker987"/><span class="koboSpan" id="kobo.662.1"> is a complete system for scheduling and dispatching jobs that is supported by the Apache Software Foundation. </span><span class="koboSpan" id="kobo.662.2">It has many more features compared to Nomad and Cronsun, with workflow capabilities that allow a job to wait for input from another job before executing. </span><span class="koboSpan" id="kobo.662.3">It also has a graphical interface that helps to visualize running jobs and dependencies (more </span><a id="_idIndexMarker988"/><span class="koboSpan" id="kobo.663.1">details can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.664.1">at </span></span><a href="https://dolphinscheduler.apache.org/"><span class="No-Break"><span class="koboSpan" id="kobo.665.1">https://dolphinscheduler.apache.org/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.666.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.667.1">Although DolphinScheduler is primarily written in Java, it can dispatch jobs in Python and Go. </span><span class="koboSpan" id="kobo.667.2">It is much more complex and has many capabilities that might not be necessary for your requirements to </span><span class="No-Break"><span class="koboSpan" id="kobo.668.1">scale up.</span></span></p>
<p><span class="koboSpan" id="kobo.669.1">There are several other job schedulers and dispatchers that you could use, but some of them are used for specific languages, such as Quartz.NET, used for .NET applications (</span><a href="https://www.quartz-scheduler.net/"><span class="koboSpan" id="kobo.670.1">https://www.quartz-scheduler.net/</span></a><span class="koboSpan" id="kobo.671.1">), and </span><a id="_idIndexMarker989"/><span class="koboSpan" id="kobo.672.1">Bree, used for Node.js </span><span class="No-Break"><span class="koboSpan" id="kobo.673.1">applications (</span></span><a href="https://github.com/breejs/bree"><span class="No-Break"><span class="koboSpan" id="kobo.674.1">https://github.com/breejs/bree</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.675.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.676.1">Let’s see now how we can use big data schedulers and dispatchers for  carrying out computation at scale in </span><span class="No-Break"><span class="koboSpan" id="kobo.677.1">network automation.</span></span></p>
<h2 id="_idParaDest-203"><a id="_idTextAnchor204"/><span class="koboSpan" id="kobo.678.1">Working with big data</span></h2>
<p><span class="koboSpan" id="kobo.679.1">There are specific </span><a id="_idIndexMarker990"/><span class="koboSpan" id="kobo.680.1">applications that require lots of CPU for data processing. </span><span class="koboSpan" id="kobo.680.2">These applications require a system that allows running code with very specialized algorithms focused on data analysis. </span><span class="koboSpan" id="kobo.680.3">These are normally referred to as systems and applications for </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.681.1">big data</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.682.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.683.1">Big data is a collection of datasets that are too large to be analyzed on just one computer. </span><span class="koboSpan" id="kobo.683.2">It is a field that is dominated by data scientists, data engineers, and artificial intelligence engineers. </span><span class="koboSpan" id="kobo.683.3">The reason is that they normally analyze a lot of data to extract information, and their work requires a system that scales up a lot in terms of CPU processing. </span><span class="koboSpan" id="kobo.683.4">Such scale can only be achieved by using systems that can schedule and dispatch jobs over many computers in </span><span class="No-Break"><span class="koboSpan" id="kobo.684.1">a cluster.</span></span></p>
<p><span class="koboSpan" id="kobo.685.1">The algorithm model used for big data is</span><a id="_idIndexMarker991"/><span class="koboSpan" id="kobo.686.1"> called </span><strong class="bold"><span class="koboSpan" id="kobo.687.1">MapReduce</span></strong><span class="koboSpan" id="kobo.688.1">. </span><span class="koboSpan" id="kobo.688.2">A MapReduce programming model is used to implement analysis on large datasets using an algorithm that runs on several machines in a cluster. </span><span class="koboSpan" id="kobo.688.3">Originally, the term MapReduce was related to a Google product, but now it is a term used for programs that deal with </span><span class="No-Break"><span class="koboSpan" id="kobo.689.1">big data.</span></span></p>
<p><span class="koboSpan" id="kobo.690.1">The original paper published by Jeffrey Dean and Sanjay Ghemawat called </span><em class="italic"><span class="koboSpan" id="kobo.691.1">MapReduce: Simplified Data Processing on Large Clusters</span></em><span class="koboSpan" id="kobo.692.1"> is a good reference and good reading to dive deeper into the subject. </span><span class="koboSpan" id="kobo.692.2">The paper is public and can be downloaded from the Google Research page </span><span class="No-Break"><span class="koboSpan" id="kobo.693.1">at </span></span><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.694.1">https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.695.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.696.1">Let’s see how we can use big data in our </span><span class="No-Break"><span class="koboSpan" id="kobo.697.1">network automation.</span></span></p>
<h3><span class="koboSpan" id="kobo.698.1">Big data and network automation</span></h3>
<p><span class="koboSpan" id="kobo.699.1">Big data is used in network </span><a id="_idIndexMarker992"/><span class="koboSpan" id="kobo.700.1">automation to help with traffic engineering </span><a id="_idIndexMarker993"/><span class="koboSpan" id="kobo.701.1">and optimization. </span><span class="koboSpan" id="kobo.701.2">MapReduce</span><a id="_idIndexMarker994"/><span class="koboSpan" id="kobo.702.1"> is used to calculate better traffic paths over a combination of traffic demands and routing paths. </span><span class="koboSpan" id="kobo.702.2">Traffic demands are collected and stored using the IP source and IP destination, then MapReduce is used to calculate a traffic demand matrix. </span><span class="koboSpan" id="kobo.702.3">For this work, routing and traffic information is collected from all network devices using BGP, SNMP, and a flow-based collection such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.703.1">sflow</span></strong><span class="koboSpan" id="kobo.704.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.705.1">ipfix</span></strong><span class="koboSpan" id="kobo.706.1">, or </span><strong class="source-inline"><span class="koboSpan" id="kobo.707.1">netflow</span></strong><span class="koboSpan" id="kobo.708.1">. </span><span class="koboSpan" id="kobo.708.2">The data collected is normally big and real-time results are required to allow for proper network optimization and traffic engineering </span><span class="No-Break"><span class="koboSpan" id="kobo.709.1">on time.</span></span></p>
<p><span class="koboSpan" id="kobo.710.1">One example would be the collection of IP data flow from the transit routers and peering routers (discussed in </span><a href="B18165_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.711.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.712.1">). </span><span class="koboSpan" id="kobo.712.2">This flow information would then be analyzed in conjunction with the routing information obtained from the routers. </span><span class="koboSpan" id="kobo.712.3">Then, a better routing policy can be applied in real time to select better external paths or network interfaces that are </span><span class="No-Break"><span class="koboSpan" id="kobo.713.1">less congested.</span></span></p>
<p><span class="koboSpan" id="kobo.714.1">Let’s now investigate some popular systems that can be used for </span><span class="No-Break"><span class="koboSpan" id="kobo.715.1">big data.</span></span></p>
<h3><span class="koboSpan" id="kobo.716.1">Using systems for big data</span></h3>
<p><span class="koboSpan" id="kobo.717.1">The two </span><a id="_idIndexMarker995"/><span class="koboSpan" id="kobo.718.1">most </span><a id="_idIndexMarker996"/><span class="koboSpan" id="kobo.719.1">popular open source systems </span><a id="_idIndexMarker997"/><span class="koboSpan" id="kobo.720.1">for big </span><a id="_idIndexMarker998"/><span class="koboSpan" id="kobo.721.1">data</span><a id="_idIndexMarker999"/><span class="koboSpan" id="kobo.722.1"> are </span><strong class="bold"><span class="koboSpan" id="kobo.723.1">Apache Hadoop</span></strong><span class="koboSpan" id="kobo.724.1"> (</span><a href="https://hadoop.apache.org/"><span class="koboSpan" id="kobo.725.1">https://hadoop.apache.org/</span></a><span class="koboSpan" id="kobo.726.1">) and </span><strong class="bold"><span class="koboSpan" id="kobo.727.1">Apache Spark</span></strong><span class="koboSpan" id="kobo.728.1"> (</span><a href="https://spark.apache.org/"><span class="koboSpan" id="kobo.729.1">https://spark.apache.org/</span></a><span class="koboSpan" id="kobo.730.1">). </span><span class="koboSpan" id="kobo.730.2">Both systems are supported and maintained by the Apache Software </span><a id="_idIndexMarker1000"/><span class="koboSpan" id="kobo.731.1">Foundation (</span><a href="https://www.apache.org/"><span class="koboSpan" id="kobo.732.1">https://www.apache.org/</span></a><span class="koboSpan" id="kobo.733.1">) and are used to build large cluster systems to run </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">big data.</span></span></p>
<p><span class="koboSpan" id="kobo.735.1">The difference between Hadoop and Spark is related to how they perform big data analysis. </span><span class="koboSpan" id="kobo.735.2">Hadoop is used for batch job scheduling without real-time requirements. </span><span class="koboSpan" id="kobo.735.3">It uses more disk capacity and the response time is more relaxed, so the cluster machines don’t need to be local, and the machines need to have large disks. </span><span class="koboSpan" id="kobo.735.4">On the other hand, Spark uses more memory and less disk space, the machines need to be located closer, and the response time is more predictable, therefore it is used for </span><span class="No-Break"><span class="koboSpan" id="kobo.736.1">real-time applications.</span></span></p>
<p><span class="koboSpan" id="kobo.737.1">For our network automation on traffic analysis, either option can be used, but Spark would be preferred for faster and more periodic results. </span><span class="koboSpan" id="kobo.737.2">Hadoop would be used to generate monthly and daily reports, but not to interact with real-time </span><span class="No-Break"><span class="koboSpan" id="kobo.738.1">routing policies.</span></span></p>
<p><span class="koboSpan" id="kobo.739.1">Let’s now look at a common problem with having your </span><span class="No-Break"><span class="koboSpan" id="kobo.740.1">own cluster.</span></span></p>
<h4><span class="koboSpan" id="kobo.741.1">Resource allocation and cloud services</span></h4>
<p><span class="koboSpan" id="kobo.742.1">One of the problems with using Hadoop and Spark is that you will need to create your own cluster of machines. </span><span class="koboSpan" id="kobo.742.2">That means installing and maintaining the hardware and operating system software. </span><span class="koboSpan" id="kobo.742.3">But that is not the main problem. </span><span class="koboSpan" id="kobo.742.4">The main problem is that resource utilization will vary throughout the day and </span><span class="No-Break"><span class="koboSpan" id="kobo.743.1">the year.</span></span></p>
<p><span class="koboSpan" id="kobo.744.1">As an example, imagine you are using a big data system in your company to calculate the best path for a particular group of routers during the day. </span><span class="koboSpan" id="kobo.744.2">The problem is the collected data to be analyzed will change; in busy hours, you will need more CPU processing to calculate compared to non-busy hours. </span><span class="koboSpan" id="kobo.744.3">The difference can be hundreds of CPUs, which will lead to lots of idle CPU hours at the end of </span><span class="No-Break"><span class="koboSpan" id="kobo.745.1">the month.</span></span></p>
<p><span class="koboSpan" id="kobo.746.1">How do you </span><a id="_idIndexMarker1001"/><span class="koboSpan" id="kobo.747.1">solve this issue? </span><span class="koboSpan" id="kobo.747.2">By using a cloud-based service provider to allocate machines for your cluster. </span><span class="koboSpan" id="kobo.747.3">With it, you can add and remove machines during the day and throughout the week, allowing growth when needed and releasing computing power when not needed. </span><span class="koboSpan" id="kobo.747.4">One example is to use AWS’ product called </span><strong class="bold"><span class="koboSpan" id="kobo.748.1">Elastic MapReduce</span></strong><span class="koboSpan" id="kobo.749.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.750.1">EMR</span></strong><span class="koboSpan" id="kobo.751.1">), which can</span><a id="_idIndexMarker1002"/><span class="koboSpan" id="kobo.752.1"> be used with easy machine allocation for your cluster, scaling </span><a id="_idIndexMarker1003"/><span class="koboSpan" id="kobo.753.1">up and down by software (more details can be found at </span><a href="https://aws.amazon.com/emr/"><span class="koboSpan" id="kobo.754.1">https://aws.amazon.com/emr/</span></a><span class="koboSpan" id="kobo.755.1">). </span><span class="koboSpan" id="kobo.755.2">Similar services can be obtained from other cloud service providers, such as Google, Oracle, </span><span class="No-Break"><span class="koboSpan" id="kobo.756.1">or Microsoft.</span></span></p>
<p><span class="koboSpan" id="kobo.757.1">One important point to observe is that big data systems do not allow running any program or language, but only code that has the MapReduce concept capabilities. </span><span class="koboSpan" id="kobo.757.2">So, it is much more specific compared to Nomad or Cronsun, and focuses only on </span><span class="No-Break"><span class="koboSpan" id="kobo.758.1">data analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.759.1">Let’s now check how we can scale using microservices and </span><span class="No-Break"><span class="koboSpan" id="kobo.760.1">Linux containers.</span></span></p>
<h1 id="_idParaDest-204"><a id="_idTextAnchor205"/><span class="koboSpan" id="kobo.761.1">Using microservices and containers</span></h1>
<p><span class="koboSpan" id="kobo.762.1">When software is built based on a combination of small, independent services, we normally say the software was built using microservices architecture. </span><span class="koboSpan" id="kobo.762.2">Microservices architecture is a way</span><a id="_idIndexMarker1004"/><span class="koboSpan" id="kobo.763.1"> to develop applications by combining small services that might belong or not to the same software </span><span class="No-Break"><span class="koboSpan" id="kobo.764.1">development team.</span></span></p>
<p><span class="koboSpan" id="kobo.765.1">The success of this approach is due to the isolation between each service, which is accomplished by using Linux containers (described in </span><a href="B18165_02.xhtml#_idTextAnchor041"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.766.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.767.1">). </span><span class="koboSpan" id="kobo.767.2">Using Linux containers</span><a id="_idIndexMarker1005"/><span class="koboSpan" id="kobo.768.1"> is a good way to isolate memory, CPU, networks, and disks. </span><span class="koboSpan" id="kobo.768.2">Each Linux container can’t interact with other Linux containers in the same host unless a pre-defined communication channel is established. </span><span class="koboSpan" id="kobo.768.3">The communication channels of a service have to use </span><span class="No-Break"><span class="koboSpan" id="kobo.769.1">well-documented APIs.</span></span></p>
<p><span class="koboSpan" id="kobo.770.1">The machine that runs microservices is normally called</span><a id="_idIndexMarker1006"/><span class="koboSpan" id="kobo.771.1"> a </span><strong class="bold"><span class="koboSpan" id="kobo.772.1">container host</span></strong><span class="koboSpan" id="kobo.773.1"> or just a host. </span><span class="koboSpan" id="kobo.773.2">A host can have multiple microservices that may or may not communicate with each other. </span><span class="koboSpan" id="kobo.773.3">A combination of hosts is called a cluster of container hosts. </span><span class="koboSpan" id="kobo.773.4">Some orchestration software is able to spawn several copies of a service in one host or different hosts. </span><span class="koboSpan" id="kobo.773.5">Using microservices architecture is a good way to scale </span><span class="No-Break"><span class="koboSpan" id="kobo.774.1">your system.</span></span></p>
<p><span class="koboSpan" id="kobo.775.1">One very popular place to build and publish a microservice</span><a id="_idIndexMarker1007"/><span class="koboSpan" id="kobo.776.1"> is </span><strong class="bold"><span class="koboSpan" id="kobo.777.1">Docker</span></strong><span class="koboSpan" id="kobo.778.1"> (</span><a href="https://www.docker.com/"><span class="koboSpan" id="kobo.779.1">https://www.docker.com/</span></a><span class="koboSpan" id="kobo.780.1">). </span><span class="koboSpan" id="kobo.780.2">A Docker container</span><a id="_idIndexMarker1008"/><span class="koboSpan" id="kobo.781.1"> is normally referred to as a service that is built using a Linux container. </span><span class="koboSpan" id="kobo.781.2">A Docker host</span><a id="_idIndexMarker1009"/><span class="koboSpan" id="kobo.782.1"> is where a Docker container can run, and in a similar way, a Docker cluster is a group of hosts that can run </span><span class="No-Break"><span class="koboSpan" id="kobo.783.1">Docker containers.</span></span></p>
<p><span class="koboSpan" id="kobo.784.1">Let’s see now how we can use Docker containers to scale </span><span class="No-Break"><span class="koboSpan" id="kobo.785.1">our code.</span></span></p>
<h2 id="_idParaDest-205"><a id="_idTextAnchor206"/><span class="koboSpan" id="kobo.786.1">Building a scalable solution by example</span></h2>
<p><span class="koboSpan" id="kobo.787.1">Let’s build a </span><a id="_idIndexMarker1010"/><span class="koboSpan" id="kobo.788.1">solution using microservices architecture by creating our own Docker container and then launching it multiple times. </span><span class="koboSpan" id="kobo.788.2">Our service has a few requirements, </span><span class="No-Break"><span class="koboSpan" id="kobo.789.1">as follows:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.790.1">It needs to have an API to </span><span class="No-Break"><span class="koboSpan" id="kobo.791.1">accept requests</span></span></li>
<li><span class="koboSpan" id="kobo.792.1">The API needs to accept a list </span><span class="No-Break"><span class="koboSpan" id="kobo.793.1">of targets</span></span></li>
<li><span class="koboSpan" id="kobo.794.1">An ICMP probe will be sent to each target to verify </span><span class="No-Break"><span class="koboSpan" id="kobo.795.1">latency concurrently</span></span></li>
<li><span class="koboSpan" id="kobo.796.1">The API will respond using HTTP </span><span class="No-Break"><span class="koboSpan" id="kobo.797.1">plain text</span></span></li>
<li><span class="koboSpan" id="kobo.798.1">Each service can accept up to </span><span class="No-Break"><span class="koboSpan" id="kobo.799.1">1,000 targets</span></span></li>
<li><span class="koboSpan" id="kobo.800.1">The timeout for each ICMP probe must be </span><span class="No-Break"><span class="koboSpan" id="kobo.801.1">2 seconds</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.802.1">Based on these requirements, let’s write some code that will be used in </span><span class="No-Break"><span class="koboSpan" id="kobo.803.1">our service.</span></span></p>
<h3><span class="koboSpan" id="kobo.804.1">Writing the service code</span></h3>
<p><span class="koboSpan" id="kobo.805.1">With the previous</span><a id="_idIndexMarker1011"/><span class="koboSpan" id="kobo.806.1"> requirements, let’s write some code in Go to build our service. </span><span class="koboSpan" id="kobo.806.2">We are going to use the Go third-party package for ICMP that we used before in this chapter called </span><strong class="source-inline"><span class="koboSpan" id="kobo.807.1">go-ping/ping</span></strong><span class="koboSpan" id="kobo.808.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.809.1">sync.WaitGroup</span></strong><span class="koboSpan" id="kobo.810.1"> to wait for the goroutines </span><span class="No-Break"><span class="koboSpan" id="kobo.811.1">to end.</span></span></p>
<p><span class="koboSpan" id="kobo.812.1">Let’s break the code into two blocks. </span><span class="koboSpan" id="kobo.812.2">The second block of code is as follows, describing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.813.1">probeTargets()</span></strong><span class="koboSpan" id="kobo.814.1"> and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.815.1">main()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.816.1"> functions:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.817.1">
func </span><strong class="bold"><span class="koboSpan" id="kobo.818.1">probeTargets</span></strong><span class="koboSpan" id="kobo.819.1">(w http.ResponseWriter, r *http.Request) {
    httpTargets := r.URL.Query().Get("targets")
    targets := strings.Split(httpTargets, ",")
    if len(httpTargets) == 0 || len(targets) &gt; 1000{
        fmt.Fprintf(w, "error: 0 &lt; targets &lt; 1000\n")
        return
    }
    var wg sync.WaitGroup
    wg.Add(len(targets))
    for _, target := range targets {
        log.Println("requested ICMP probe for", target)
        go </span><strong class="bold"><span class="koboSpan" id="kobo.820.1">probe</span></strong><span class="koboSpan" id="kobo.821.1">(target, w, &amp;wg)
    }
    wg.Wait()
}
func main() {
    http.HandleFunc("/latency", </span><strong class="bold"><span class="koboSpan" id="kobo.822.1">probeTargets</span></strong><span class="koboSpan" id="kobo.823.1">)
    log.Fatal(http.ListenAndServe(":9900", nil))
}</span></pre>
<p><span class="koboSpan" id="kobo.824.1">The preceding block represents the last two functions of our service. </span><span class="koboSpan" id="kobo.824.2">In the </span><strong class="source-inline"><span class="koboSpan" id="kobo.825.1">main()</span></strong><span class="koboSpan" id="kobo.826.1"> function, we just need to call </span><strong class="source-inline"><span class="koboSpan" id="kobo.827.1">http.HandleFunc</span></strong><span class="koboSpan" id="kobo.828.1">, passing the API reference used for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.829.1">GET</span></strong><span class="koboSpan" id="kobo.830.1"> method and the name of the function that will be invoked. </span><span class="koboSpan" id="kobo.830.2">Then, </span><strong class="source-inline"><span class="koboSpan" id="kobo.831.1">http.ListenAndServe</span></strong><span class="koboSpan" id="kobo.832.1"> is called using port </span><strong class="source-inline"><span class="koboSpan" id="kobo.833.1">9900</span></strong><span class="koboSpan" id="kobo.834.1"> to listen for API requests. </span><span class="koboSpan" id="kobo.834.2">Note that </span><strong class="source-inline"><span class="koboSpan" id="kobo.835.1">log.Fatal</span></strong><span class="koboSpan" id="kobo.836.1"> is used with </span><strong class="source-inline"><span class="koboSpan" id="kobo.837.1">ListenAndServe</span></strong><span class="koboSpan" id="kobo.838.1"> because it should never end unless it has a problem. </span><span class="koboSpan" id="kobo.838.2">The following is an API </span><strong class="source-inline"><span class="koboSpan" id="kobo.839.1">GET</span></strong><span class="koboSpan" id="kobo.840.1"> client </span><span class="No-Break"><span class="koboSpan" id="kobo.841.1">request example:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.842.1">
GET /latency?targets=google.com,cisco.com HTTP/1.0</span></pre>
<p><span class="koboSpan" id="kobo.843.1">The preceding API request will call </span><strong class="source-inline"><span class="koboSpan" id="kobo.844.1">probeTargets()</span></strong><span class="koboSpan" id="kobo.845.1">, which will run the loop invoking the goroutines (called </span><strong class="source-inline"><span class="koboSpan" id="kobo.846.1">probe()</span></strong><span class="koboSpan" id="kobo.847.1">) two times, which will send ICMP requests to </span><strong class="source-inline"><span class="koboSpan" id="kobo.848.1">google.com</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.849.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.850.1">cisco.com</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.851.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.852.1">Let’s now have a</span><a id="_idIndexMarker1012"/><span class="koboSpan" id="kobo.853.1"> look at the last block of code containing the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.854.1">probe()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.855.1"> function:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.856.1">
func probe(host string, w http.ResponseWriter, wg *sync.WaitGroup) {
    defer wg.Done()
    p, err := ping.NewPinger(host)
    if err != nil {
        fmt.Fprintf(w, "error ping creation: %v\n", err)
        return
    }
    p.Count = 1
    p.Timeout = time.Second * 2
    p.SetPrivileged(true)
    if err = p.Run(); err != nil {
        fmt.Fprintf(w, "error ping sent: %v\n", err)
        return
    }
    stats := p.Statistics()
    if stats.PacketLoss == 0 {
        fmt.Fprintf(w, "%s latency is %s\n", host, stats.AvgRtt)
    } else {
        fmt.Fprintf(w, "%s no response timeout\n", host)
    }
}</span></pre>
<p><span class="koboSpan" id="kobo.857.1">Note that the </span><strong class="source-inline"><span class="koboSpan" id="kobo.858.1">probe()</span></strong><span class="koboSpan" id="kobo.859.1"> function does not return a value, a </span><strong class="source-inline"><span class="koboSpan" id="kobo.860.1">log</span></strong><span class="koboSpan" id="kobo.861.1"> message, or a print message. </span><span class="koboSpan" id="kobo.861.2">All messages, including errors, are returned to the HTTP client requesting the ICMP probes. </span><span class="koboSpan" id="kobo.861.3">To allow the return to the client, we have to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.862.1">fmt.Fprintf()</span></strong><span class="koboSpan" id="kobo.863.1"> function, passing the reference </span><strong class="source-inline"><span class="koboSpan" id="kobo.864.1">w</span></strong><span class="koboSpan" id="kobo.865.1">, which points to an </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.866.1">http.ResponseWriter</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.867.1"> type.</span></span></p>
<p><span class="koboSpan" id="kobo.868.1">Before we</span><a id="_idIndexMarker1013"/><span class="koboSpan" id="kobo.869.1"> continue with our example, let’s make a modification to our </span><strong class="source-inline"><span class="koboSpan" id="kobo.870.1">main()</span></strong><span class="koboSpan" id="kobo.871.1"> function to allow reading the port number from the operating system environment variable. </span><span class="koboSpan" id="kobo.871.2">So, the service can be called with different port numbers when being invoked, just needing to change the operating system environment variable called </span><strong class="source-inline"><span class="koboSpan" id="kobo.872.1">PORT</span></strong><span class="koboSpan" id="kobo.873.1">, as </span><span class="No-Break"><span class="koboSpan" id="kobo.874.1">shown here:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.875.1">
func main() {
    listen := ":9900"
    if port, ok := os.LookupEnv("PORT"); ok {
        listen = ":" + port
    http.HandleFunc("/latency", probeTargets)
    log.Fatal(http.ListenAndServe(listen, nil))
}</span></pre>
<p><span class="koboSpan" id="kobo.876.1">Let’s now build our Docker container using </span><span class="No-Break"><span class="koboSpan" id="kobo.877.1">a Dockerfile.</span></span></p>
<h3><span class="koboSpan" id="kobo.878.1">Building our Docker container</span></h3>
<p><span class="koboSpan" id="kobo.879.1">To build the Docker container, we are going</span><a id="_idIndexMarker1014"/><span class="koboSpan" id="kobo.880.1"> to use Dockerfile definitions. </span><span class="koboSpan" id="kobo.880.2">Then, we just need to run </span><strong class="source-inline"><span class="koboSpan" id="kobo.881.1">docker build</span></strong><span class="koboSpan" id="kobo.882.1"> to create our container. </span><span class="koboSpan" id="kobo.882.2">Before you install the Docker engine in your environment, check the documentation on how to install it </span><span class="No-Break"><span class="koboSpan" id="kobo.883.1">at </span></span><a href="https://docs.docker.com/engine/install/"><span class="No-Break"><span class="koboSpan" id="kobo.884.1">https://docs.docker.com/engine/install/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.885.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.886.1">The following is the Dockerfile used in our example of an ICMP </span><span class="No-Break"><span class="koboSpan" id="kobo.887.1">probe service:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.888.1">
FROM golang:1.19-alpine
WORKDIR /usr/src/app
COPY go.mod go.sum ./
RUN go mod download &amp;&amp; go mod verify
COPY icmp-probe-service.go ./
RUN go build -v -o /usr/local/bin/probe-service
CMD ["/usr/local/bin/probe-service"]</span></pre>
<p><span class="koboSpan" id="kobo.889.1">To build the Docker container, you just need to run </span><strong class="source-inline"><span class="koboSpan" id="kobo.890.1">docker build . </span><span class="koboSpan" id="kobo.890.2">–t probe-service</span></strong><span class="koboSpan" id="kobo.891.1">. </span><span class="koboSpan" id="kobo.891.2">After running the build, you should be able to see the image by using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.892.1">docker image</span></strong><span class="koboSpan" id="kobo.893.1"> command, </span><span class="No-Break"><span class="koboSpan" id="kobo.894.1">as follows:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.895.1">
% docker images
REPOSITORY      TAG   IMAGE ID CREATED              SIZE
probe-service   latest  e9c2   About a minute ago   438MB</span></pre>
<p><span class="koboSpan" id="kobo.896.1">The Docker container name is </span><strong class="source-inline"><span class="koboSpan" id="kobo.897.1">probe-service</span></strong><span class="koboSpan" id="kobo.898.1"> and you can run the service by using the </span><span class="No-Break"><span class="koboSpan" id="kobo.899.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.900.1">
docker run -p 9900:9900 probe-service</span></pre>
<p><span class="koboSpan" id="kobo.901.1">To listen to a different port, you need to set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.902.1">PORT</span></strong><span class="koboSpan" id="kobo.903.1"> environment variable. </span><span class="koboSpan" id="kobo.903.2">An example for port </span><strong class="source-inline"><span class="koboSpan" id="kobo.904.1">7700</span></strong><span class="koboSpan" id="kobo.905.1"> is </span><span class="No-Break"><span class="koboSpan" id="kobo.906.1">as follows:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.907.1">
docker run -e PORT=7700 -p 7700:7700 probe-service</span></pre>
<p><span class="koboSpan" id="kobo.908.1">Note that you could map different host ports to port </span><strong class="source-inline"><span class="koboSpan" id="kobo.909.1">9900</span></strong><span class="koboSpan" id="kobo.910.1"> if you want to run multiple services in the same host without changing the port that the container listens to. </span><span class="koboSpan" id="kobo.910.2">You just need to specify a different port for the host when mapping, as in the following example running three services on the </span><span class="No-Break"><span class="koboSpan" id="kobo.911.1">same machine:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.912.1">
% docker run -d -p 9001:9900 probe-service
% docker run -d -p 9002:9900 probe-service
% docker run -d -p 9003:9900 probe-service</span></pre>
<p><span class="koboSpan" id="kobo.913.1">Running the</span><a id="_idIndexMarker1015"/><span class="koboSpan" id="kobo.914.1"> preceding three commands will start three services on the host ports: </span><strong class="source-inline"><span class="koboSpan" id="kobo.915.1">9001</span></strong><span class="koboSpan" id="kobo.916.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.917.1">9002</span></strong><span class="koboSpan" id="kobo.918.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.919.1">9003</span></strong><span class="koboSpan" id="kobo.920.1">. </span><span class="koboSpan" id="kobo.920.2">The service inside the container still uses port </span><strong class="source-inline"><span class="koboSpan" id="kobo.921.1">9900</span></strong><span class="koboSpan" id="kobo.922.1">. </span><span class="koboSpan" id="kobo.922.2">To check the services running in a host, use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.923.1">docker ps</span></strong><span class="koboSpan" id="kobo.924.1"> command, </span><span class="No-Break"><span class="koboSpan" id="kobo.925.1">as follows:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.926.1">
% docker ps
CONTAINER ID   IMAGE           COMMAND                  CREATED         STATUS         PORTS                    NAMES
6266c895f11a   probe-service   "/usr/local/bin/prob…"   2 minutes ago   Up 2 minutes   0.0.0.0:</span><strong class="bold"><span class="koboSpan" id="kobo.927.1">9003</span></strong><span class="koboSpan" id="kobo.928.1">-&gt;9900/tcp   gallant_heisenberg
270d73163d19   probe-service   "/usr/local/bin/prob…"   2 minutes ago   Up 2 minutes   0.0.0.0:</span><strong class="bold"><span class="koboSpan" id="kobo.929.1">9002</span></strong><span class="koboSpan" id="kobo.930.1">-&gt;9900/tcp   intelligent_clarke
4acc6162e821   probe-service   "/usr/local/bin/prob…"   2 minutes ago   Up 2 minutes   0.0.0.0:</span><strong class="bold"><span class="koboSpan" id="kobo.931.1">9001</span></strong><span class="koboSpan" id="kobo.932.1">-&gt;9900/tcp   hardcore_bhabha</span></pre>
<p><span class="koboSpan" id="kobo.933.1">The preceding output shows that</span><a id="_idIndexMarker1016"/><span class="koboSpan" id="kobo.934.1"> there are three services running on the host, listening to ports </span><strong class="source-inline"><span class="koboSpan" id="kobo.935.1">9001</span></strong><span class="koboSpan" id="kobo.936.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.937.1">9002</span></strong><span class="koboSpan" id="kobo.938.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.939.1">9003</span></strong><span class="koboSpan" id="kobo.940.1">. </span><span class="koboSpan" id="kobo.940.2">You can access the APIs for each of them and probe up to 3,000 targets, 1,000 </span><span class="No-Break"><span class="koboSpan" id="kobo.941.1">per service.</span></span></p>
<p><span class="koboSpan" id="kobo.942.1">Let’s now see how we can automate launching multiple services using </span><span class="No-Break"><span class="koboSpan" id="kobo.943.1">Docker Compose.</span></span></p>
<h3><span class="koboSpan" id="kobo.944.1">Scaling up using Docker Compose</span></h3>
<p><span class="koboSpan" id="kobo.945.1">Using Docker</span><a id="_idIndexMarker1017"/><span class="koboSpan" id="kobo.946.1"> Compose will help you to add services that will run at the same time without needing to invoke the </span><strong class="source-inline"><span class="koboSpan" id="kobo.947.1">docker run</span></strong><span class="koboSpan" id="kobo.948.1"> command. </span><span class="koboSpan" id="kobo.948.2">In our example, we are going to use Docker Compose to launch five ICMP probe services. </span><span class="koboSpan" id="kobo.948.3">The following is the Docker Compose file example in YAML format (described in </span><a href="B18165_04.xhtml#_idTextAnchor100"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.949.1">Chapter 4</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.950.1">,):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.951.1">
version: "1.0"
services:
  probe1:
    image: "probe-service:latest"
    ports: ["9001:9900"]
  probe2:
    image: "probe-service:latest"
    ports: ["9002:9900"]
  probe3:
    image: "probe-service:latest"
    ports: ["9003:9900"]
  probe4:
    image: "probe-service:latest"
    ports: ["9004:9900"]
  probe5:
    image: "probe-service:latest"
    ports: ["9005:9900"]</span></pre>
<p><span class="koboSpan" id="kobo.952.1">To run the</span><a id="_idIndexMarker1018"/><span class="koboSpan" id="kobo.953.1"> services, just type </span><strong class="source-inline"><span class="koboSpan" id="kobo.954.1">docker compose up –d</span></strong><span class="koboSpan" id="kobo.955.1">, and to stop them, just run </span><strong class="source-inline"><span class="koboSpan" id="kobo.956.1">docker compose down</span></strong><span class="koboSpan" id="kobo.957.1">. </span><span class="koboSpan" id="kobo.957.2">The following is an example of the output of </span><span class="No-Break"><span class="koboSpan" id="kobo.958.1">the command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.959.1">
% docker compose up –d
[+] Running 6/6
⠿ Network probe-service_default     Created   1.4s
⠿ Container probe-service-probe5-1  Started   1.1s
⠿ Container probe-service-probe4-1  Started   1.3s
⠿ Container probe-service-probe3-1  Started   1.5s
⠿ Container probe-service-probe1-1  Started   1.1s
⠿ Container probe-service-probe2-1  Started</span></pre>
<p><span class="koboSpan" id="kobo.960.1">Now, let’s see how we can scale up using multiple machines with a </span><span class="No-Break"><span class="koboSpan" id="kobo.961.1">Docker container.</span></span></p>
<h3><span class="koboSpan" id="kobo.962.1">Scaling up with clusters</span></h3>
<p><span class="koboSpan" id="kobo.963.1">To scale </span><a id="_idIndexMarker1019"/><span class="koboSpan" id="kobo.964.1">even more, you could set up a cluster of Docker host containers. </span><span class="koboSpan" id="kobo.964.2">This will allow you to launch thousands of services, allowing our ICMP probe service to scale to millions of targets. </span><span class="koboSpan" id="kobo.964.3">You could build the cluster yourself by managing a group of machines and running the services, or you could use a system to do all that </span><span class="No-Break"><span class="koboSpan" id="kobo.965.1">for you.</span></span></p>
<p><span class="koboSpan" id="kobo.966.1">Let’s now investigate a few systems that are used to manage and launch services for a cluster of machines running </span><span class="No-Break"><span class="koboSpan" id="kobo.967.1">container services.</span></span></p>
<h4><span class="koboSpan" id="kobo.968.1">Using Docker Swarm</span></h4>
<p><span class="koboSpan" id="kobo.969.1">With </span><strong class="bold"><span class="koboSpan" id="kobo.970.1">Docker Swarm</span></strong><span class="koboSpan" id="kobo.971.1">, you are </span><a id="_idIndexMarker1020"/><span class="koboSpan" id="kobo.972.1">able to launch containers on several machines. </span><span class="koboSpan" id="kobo.972.2">It is easy to use because it only requires installing Docker. </span><span class="koboSpan" id="kobo.972.3">Once you have installed it, it is easy to create a Docker Swarm cluster. </span><span class="koboSpan" id="kobo.972.4">You just have to run the </span><span class="No-Break"><span class="koboSpan" id="kobo.973.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.974.1">
Host-1$ </span><strong class="bold"><span class="koboSpan" id="kobo.975.1">docker swarm init</span></strong><span class="koboSpan" id="kobo.976.1">
Swarm initialized: current node (9f2777swvj1gmqegbxabahxm3) is now a manager.
</span><span class="koboSpan" id="kobo.976.2">To add a worker to this swarm, run the following command:
    docker swarm join --token </span><strong class="bold"><span class="koboSpan" id="kobo.977.1">SWMTKN-1-1gdb6i88ubq5drnigbwq2rh51fmyordkkpljjtwefwo2nk3ddx-6nwz531o6lqtkun4gagvrl7ws</span></strong><span class="koboSpan" id="kobo.978.1"> 192.168.86.158:2377
To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.</span></pre>
<p><span class="koboSpan" id="kobo.979.1">Once you have </span><a id="_idIndexMarker1021"/><span class="koboSpan" id="kobo.980.1">started the first Docker Swarm host, it will then take the lead place, and to add another host, you just need to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.981.1">docker swarm join</span></strong><span class="koboSpan" id="kobo.982.1"> command. </span><span class="koboSpan" id="kobo.982.2">To avoid any host joining the Docker Swarm cluster, a token is used. </span><span class="koboSpan" id="kobo.982.3">The preceding example starts with </span><strong class="source-inline"><span class="koboSpan" id="kobo.983.1">SWMTKN-1</span></strong><span class="koboSpan" id="kobo.984.1">. </span><span class="koboSpan" id="kobo.984.2">Note that a host in a Docker Swarm cluster is also called </span><a id="_idIndexMarker1022"/><span class="koboSpan" id="kobo.985.1">a </span><strong class="bold"><span class="koboSpan" id="kobo.986.1">node</span></strong><span class="koboSpan" id="kobo.987.1">. </span><span class="koboSpan" id="kobo.987.2">So, let’s add more nodes to </span><span class="No-Break"><span class="koboSpan" id="kobo.988.1">our cluster:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.989.1">
host-2$ </span><strong class="bold"><span class="koboSpan" id="kobo.990.1">docker swarm join</span></strong><span class="koboSpan" id="kobo.991.1"> --token SWMTKN-1-1gdb6i88ubq5drnigbwq2rh51fmyordkkpljjtwefwo2nk3ddx-6nwz531o6lqtkun4gagvrl7ws 192.168.86.158:2377
host-3$ </span><strong class="bold"><span class="koboSpan" id="kobo.992.1">docker swarm join</span></strong><span class="koboSpan" id="kobo.993.1"> --token SWMTKN-1-1gdb6i88ubq5drnigbwq2rh51fmyordkkpljjtwefwo2nk3ddx-6nwz531o6lqtkun4gagvrl7ws 192.168.86.158:2377
host-4$ </span><strong class="bold"><span class="koboSpan" id="kobo.994.1">docker swarm join</span></strong><span class="koboSpan" id="kobo.995.1"> --token SWMTKN-1-1gdb6i88ubq5drnigbwq2rh51fmyordkkpljjtwefwo2nk3ddx-6nwz531o6lqtkun4gagvrl7ws 192.168.86.158:2377</span></pre>
<p><span class="koboSpan" id="kobo.996.1">Now, we have four nodes in the cluster, with </span><strong class="source-inline"><span class="koboSpan" id="kobo.997.1">host-1</span></strong><span class="koboSpan" id="kobo.998.1"> as the leader. </span><span class="koboSpan" id="kobo.998.2">You can check the status of the cluster nodes by typing the </span><span class="No-Break"><span class="koboSpan" id="kobo.999.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.1000.1">
$ docker node ls
ID          HOSTNAME  STATUS  AVAILABILITY MANAGER
9f2777swvj* host-1    Ready   Active       Leader
a34f25affg* host-2    Ready   Active
7fdd77wvgf* host-4    Ready   Active
8ad531vabj* host-3    Ready   Active</span></pre>
<p><span class="koboSpan" id="kobo.1001.1">Once you have your cluster, you can launch a service by running the </span><span class="No-Break"><span class="koboSpan" id="kobo.1002.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.1003.1">
$ </span><strong class="bold"><span class="koboSpan" id="kobo.1004.1">docker service create</span></strong><span class="koboSpan" id="kobo.1005.1"> --replicas 1 --name probe probe-service
7sv66ytzq0te92dkndz5pg5q2
overall progress: 1 out of 1 tasks
1/1: running
[==================================================&gt;]
verify: Service converged</span></pre>
<p><span class="koboSpan" id="kobo.1006.1">In the preceding</span><a id="_idIndexMarker1023"/><span class="koboSpan" id="kobo.1007.1"> example, we just launched a Swarm service called </span><strong class="source-inline"><span class="koboSpan" id="kobo.1008.1">probe</span></strong><span class="koboSpan" id="kobo.1009.1"> using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1010.1">probe-service</span></strong><span class="koboSpan" id="kobo.1011.1"> image, the same image used in previous examples. </span><span class="koboSpan" id="kobo.1011.2">Note that we’ve only launched one replica to later show how easy it is to scale up. </span><span class="koboSpan" id="kobo.1011.3">Let’s check now how the service is installed by running the </span><span class="No-Break"><span class="koboSpan" id="kobo.1012.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.1013.1">
$ </span><strong class="bold"><span class="koboSpan" id="kobo.1014.1">docker service ls</span></strong><span class="koboSpan" id="kobo.1015.1">
ID          NAME  MODE       REPLICAS IMAGE
7sv66ytzq0  probe replicated 1/1      probe-service:latest</span></pre>
<p><span class="koboSpan" id="kobo.1016.1">Let’s now scale up for 10 probes by running the </span><span class="No-Break"><span class="koboSpan" id="kobo.1017.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.1018.1">
$ </span><strong class="bold"><span class="koboSpan" id="kobo.1019.1">docker service scale probe=10</span></strong><span class="koboSpan" id="kobo.1020.1">
probe scaled to 10
overall progress: 10 out of 10 tasks
1/10: running
[==================================================&gt;]
2/10: running
[==================================================&gt;]
3/10: running
[==================================================&gt;]
4/10: running
[==================================================&gt;]
5/10: running
[==================================================&gt;]
6/10: running
[==================================================&gt;]
7/10: running
[==================================================&gt;]
8/10: running
[==================================================&gt;]
9/10: running
[==================================================&gt;]
10/10: running
[==================================================&gt;]
verify: Service converged</span></pre>
<p><span class="koboSpan" id="kobo.1021.1">Now, if you check the service, it will show 10 replicas, as in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1022.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.1023.1">
$ </span><strong class="bold"><span class="koboSpan" id="kobo.1024.1">docker service ls</span></strong><span class="koboSpan" id="kobo.1025.1">
ID          NAME  MODE       REPLICAS IMAGE
7sv66ytzq0  probe replicated </span><strong class="bold"><span class="koboSpan" id="kobo.1026.1">10/10</span></strong><span class="koboSpan" id="kobo.1027.1">    probe-service:latest</span></pre>
<p><span class="koboSpan" id="kobo.1028.1">You can also </span><a id="_idIndexMarker1024"/><span class="koboSpan" id="kobo.1029.1">check where each replica is running by running the </span><span class="No-Break"><span class="koboSpan" id="kobo.1030.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.1031.1">
$ </span><strong class="bold"><span class="koboSpan" id="kobo.1032.1">docker service ps probe</span></strong><span class="koboSpan" id="kobo.1033.1">
ID      NAME    IMAGE                NODE  DESIRED STATE
y38830 probe.1 probe-service:latest host-1 Running Running v4493s probe.2 probe-service:latest host-2 Running Running
zhzbnj probe.3 probe-service:latest host-3 Running Running
i84s4g probe.4 probe-service:latest host-3 Running Running 3emx3f probe.5 probe-service:latest host-1 Running Running
rd1vp1 probe.6 probe-service:latest host-2 Running Running
p1oq0w probe.7 probe-service:latest host-3 Running Running ro0foo probe.8 probe-service:latest host-4 Running Running
l6prr4 probe.9 probe-service:latest host-4 Running Running
dwdr43 probe.10 probe-service:latest host-1 Running Running</span></pre>
<p><span class="koboSpan" id="kobo.1034.1">As you can see in the output of the preceding command, there are 10 probes running as replicas on nodes </span><strong class="source-inline"><span class="koboSpan" id="kobo.1035.1">host-1</span></strong><span class="koboSpan" id="kobo.1036.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1037.1">host-2</span></strong><span class="koboSpan" id="kobo.1038.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1039.1">host-3</span></strong><span class="koboSpan" id="kobo.1040.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1041.1">host-4</span></strong><span class="koboSpan" id="kobo.1042.1">. </span><span class="koboSpan" id="kobo.1042.2">You can also specify where you want the replica to run, among other parameters. </span><span class="koboSpan" id="kobo.1042.3">In this example, we are able to scale up our ICMP probe service to 10,000 targets by using </span><span class="No-Break"><span class="koboSpan" id="kobo.1043.1">4 hosts.</span></span></p>
<p><span class="koboSpan" id="kobo.1044.1">One important point we missed on these commands was allocating the ports to listen for our replicas. </span><span class="koboSpan" id="kobo.1044.2">As replicas can run in the same host, they can’t use the same port. </span><span class="koboSpan" id="kobo.1044.3">We then need to make sure each replica is assigned with a different port number to listen to. </span><span class="koboSpan" id="kobo.1044.4">A client accessing our </span><strong class="source-inline"><span class="koboSpan" id="kobo.1045.1">probe-service</span></strong><span class="koboSpan" id="kobo.1046.1"> cluster needs to know the IP addresses of the hosts and the port numbers that are listening before connecting </span><span class="No-Break"><span class="koboSpan" id="kobo.1047.1">for requests.</span></span></p>
<p><span class="koboSpan" id="kobo.1048.1">A better and </span><a id="_idIndexMarker1025"/><span class="koboSpan" id="kobo.1049.1">more controlled way to deploy Docker Swarm is to use a YAML configuration file like we did when using Docker Compose. </span><span class="koboSpan" id="kobo.1049.2">More details on the configuration file for Docker Swarm can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.1050.1">at </span></span><a href="https://github.com/docker/labs/blob/master/beginner/chapters/votingapp.md"><span class="No-Break"><span class="koboSpan" id="kobo.1051.1">https://github.com/docker/labs/blob/master/beginner/chapters/votingapp.md</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1052.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.1053.1">More documentation</span><a id="_idIndexMarker1026"/><span class="koboSpan" id="kobo.1054.1"> on Docker Swarm can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.1055.1">at </span></span><a href="https://docs.docker.com/engine/swarm/swarm-mode/"><span class="No-Break"><span class="koboSpan" id="kobo.1056.1">https://docs.docker.com/engine/swarm/swarm-mode/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1057.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.1058.1">Now let’s investigate how to use multiple hosts </span><span class="No-Break"><span class="koboSpan" id="kobo.1059.1">using Kubernetes.</span></span></p>
<h4><span class="koboSpan" id="kobo.1060.1">Using Kubernetes</span></h4>
<p><span class="koboSpan" id="kobo.1061.1">Kubernetes is </span><a id="_idIndexMarker1027"/><span class="koboSpan" id="kobo.1062.1">perhaps one of the most popular systems to manage the microservices architecture in a cluster. </span><span class="koboSpan" id="kobo.1062.2">Its popularity is also due to it being backed by</span><a id="_idIndexMarker1028"/><span class="koboSpan" id="kobo.1063.1"> the </span><strong class="bold"><span class="koboSpan" id="kobo.1064.1">Cloud Native Computing Foundation</span></strong><span class="koboSpan" id="kobo.1065.1"> (</span><a href="https://www.cncf.io/"><span class="koboSpan" id="kobo.1066.1">https://www.cncf.io/</span></a><span class="koboSpan" id="kobo.1067.1">), which is part of</span><a id="_idIndexMarker1029"/><span class="koboSpan" id="kobo.1068.1"> the </span><strong class="bold"><span class="koboSpan" id="kobo.1069.1">Linux Foundation</span></strong><span class="koboSpan" id="kobo.1070.1"> (</span><a href="https://www.linuxfoundation.org/"><span class="koboSpan" id="kobo.1071.1">https://www.linuxfoundation.org/</span></a><span class="koboSpan" id="kobo.1072.1">). </span><span class="koboSpan" id="kobo.1072.2">Large companies use Kubernetes, such as Amazon, Google, Apple, Cisco, and Huawei, </span><span class="No-Break"><span class="koboSpan" id="kobo.1073.1">among others.</span></span></p>
<p><span class="koboSpan" id="kobo.1074.1">Kubernetes provides </span><a id="_idIndexMarker1030"/><span class="koboSpan" id="kobo.1075.1">many more capabilities than Docker Swarm, such as service orchestration, load-balancing, service monitoring, self-healing, and auto-scaling by traffic, among other features. </span><span class="koboSpan" id="kobo.1075.2">Despite the large community and vast capabilities, you might not want to use Kubernetes if your requirement is simple and needs to scale in large quantities. </span><span class="koboSpan" id="kobo.1075.3">Kubernetes provides a lot of capabilities that might be an overhead to your development. </span><span class="koboSpan" id="kobo.1075.4">For our </span><strong class="source-inline"><span class="koboSpan" id="kobo.1076.1">probe-service</span></strong><span class="koboSpan" id="kobo.1077.1">, I would not recommend using Kubernetes, because it is too complex for our purposes of ICMP </span><span class="No-Break"><span class="koboSpan" id="kobo.1078.1">probing targets.</span></span></p>
<p><span class="koboSpan" id="kobo.1079.1">You can also use a </span><a id="_idIndexMarker1031"/><span class="koboSpan" id="kobo.1080.1">Docker Compose file to configure Kubernetes, which is done by using a service translator such as Kompose (</span><a href="https://kompose.io/"><span class="koboSpan" id="kobo.1081.1">https://kompose.io/</span></a><span class="koboSpan" id="kobo.1082.1">). </span><span class="koboSpan" id="kobo.1082.2">More details can </span><a id="_idIndexMarker1032"/><span class="koboSpan" id="kobo.1083.1">be found </span><span class="No-Break"><span class="koboSpan" id="kobo.1084.1">at </span></span><a href="https://kubernetes.io/docs/tasks/configure-pod-container/translate-compose-kubernetes/"><span class="No-Break"><span class="koboSpan" id="kobo.1085.1">https://kubernetes.io/docs/tasks/configure-pod-container/translate-compose-kubernetes/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1086.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.1087.1">If you want to start using Kubernetes, you can find plenty of examples and documentation on the internet. </span><span class="koboSpan" id="kobo.1087.2">The best place to start is </span><span class="No-Break"><span class="koboSpan" id="kobo.1088.1">at </span></span><a href="https://kubernetes.io/docs/home/"><span class="No-Break"><span class="koboSpan" id="kobo.1089.1">https://kubernetes.io/docs/home/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1090.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.1091.1">Let’s now check how we can use another cluster based </span><span class="No-Break"><span class="koboSpan" id="kobo.1092.1">on Nomad.</span></span></p>
<h4><span class="koboSpan" id="kobo.1093.1">Using Nomad</span></h4>
<p><span class="koboSpan" id="kobo.1094.1">Nomad </span><a id="_idIndexMarker1033"/><span class="koboSpan" id="kobo.1095.1">is also used to implement Docker clustering (</span><a href="https://www.nomadproject.io/"><span class="koboSpan" id="kobo.1096.1">https://www.nomadproject.io/</span></a><span class="koboSpan" id="kobo.1097.1">). </span><span class="koboSpan" id="kobo.1097.2">Nomad</span><a id="_idIndexMarker1034"/><span class="koboSpan" id="kobo.1098.1"> also has several capabilities that are comparable to Kubernetes, such as monitoring, self-healing, and auto-scaling. </span><span class="koboSpan" id="kobo.1098.2">However, the features list is not as long and complete </span><span class="No-Break"><span class="koboSpan" id="kobo.1099.1">as Kubernetes.</span></span></p>
<p><span class="koboSpan" id="kobo.1100.1">So, why would we use Nomad instead of Kubernetes? </span><span class="koboSpan" id="kobo.1100.2">There are three main reasons that you might want to use Nomad, as </span><span class="No-Break"><span class="koboSpan" id="kobo.1101.1">listed here:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.1102.1">Simpler to deploy and easy to configure in comparison </span><span class="No-Break"><span class="koboSpan" id="kobo.1103.1">to Kubernetes.</span></span></li>
<li><span class="koboSpan" id="kobo.1104.1">Kubernetes can scale up to 5,000 nodes with 300,000 containers. </span><span class="koboSpan" id="kobo.1104.2">Nomad, on the other hand, is able to scale to 10,000 nodes and more than 2 million </span><span class="No-Break"><span class="koboSpan" id="kobo.1105.1">containers (</span></span><a href="https://www.javelynn.com/cloud/the-two-million-container-challenge/"><span class="No-Break"><span class="koboSpan" id="kobo.1106.1">https://www.javelynn.com/cloud/the-two-million-container-challenge/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1107.1">)</span></span><span class="No-Break"><span class="koboSpan" id="kobo.1108.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.1109.1">Can support other services besides Linux containers, such </span><a id="_idIndexMarker1035"/><span class="koboSpan" id="kobo.1110.1">as </span><strong class="bold"><span class="koboSpan" id="kobo.1111.1">QEMU</span></strong><span class="koboSpan" id="kobo.1112.1"> virtual machines, Java, Unix processes, and </span><span class="No-Break"><span class="koboSpan" id="kobo.1113.1">Windows containers.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1114.1">More documentation on Nomad can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.1115.1">at </span></span><a href="https://developer.hashicorp.com/nomad/docs"><span class="No-Break"><span class="koboSpan" id="kobo.1116.1">https://developer.hashicorp.com/nomad/docs</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1117.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.1118.1">Let’s now have a brief look at how to use microservice architectures provided by cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.1119.1">service providers.</span></span></p>
<h4><span class="koboSpan" id="kobo.1120.1">Using cloud service providers</span></h4>
<p><span class="koboSpan" id="kobo.1121.1">There </span><a id="_idIndexMarker1036"/><span class="koboSpan" id="kobo.1122.1">are also proprietary</span><a id="_idIndexMarker1037"/><span class="koboSpan" id="kobo.1123.1"> solutions that are provided by cloud</span><a id="_idIndexMarker1038"/><span class="koboSpan" id="kobo.1124.1"> service providers, such as </span><strong class="bold"><span class="koboSpan" id="kobo.1125.1">Azure Container Instances</span></strong><span class="koboSpan" id="kobo.1126.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.1127.1">Google Kubernetes Engine</span></strong><span class="koboSpan" id="kobo.1128.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1129.1">GKE</span></strong><span class="koboSpan" id="kobo.1130.1">), and Amazon </span><strong class="bold"><span class="koboSpan" id="kobo.1131.1">Elastic Container Service</span></strong><span class="koboSpan" id="kobo.1132.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1133.1">ECS</span></strong><span class="koboSpan" id="kobo.1134.1">). </span><span class="koboSpan" id="kobo.1134.2">The advantage of using a cloud service provider is you </span><a id="_idIndexMarker1039"/><span class="koboSpan" id="kobo.1135.1">don’t need physical machines in your infrastructure to create the cluster. </span><span class="koboSpan" id="kobo.1135.2">There are also products where you don’t even need to care about the cluster and the nodes in it, such as a product from Amazon called AWS Fargate. </span><span class="koboSpan" id="kobo.1135.3">With AWS Fargate, you just need the Docker container published in a Docker registry and a service specification without the need to specify the nodes or </span><span class="No-Break"><span class="koboSpan" id="kobo.1136.1">the cluster.</span></span></p>
<p><span class="koboSpan" id="kobo.1137.1">I hope this section has given you a good idea of how to scale your code by using Linux containers and host clustering. </span><span class="koboSpan" id="kobo.1137.2">Microservice architecture is a hot topic that has gotten lots of attention from developers and cloud service providers in recent years. </span><span class="koboSpan" id="kobo.1137.3">Several acronyms might be used to describe this technology, but we have covered the basics here. </span><span class="koboSpan" id="kobo.1137.4">You now have enough knowledge to dive even deeper into </span><span class="No-Break"><span class="koboSpan" id="kobo.1138.1">this subject.</span></span></p>
<h1 id="_idParaDest-206"><a id="_idTextAnchor207"/><span class="koboSpan" id="kobo.1139.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.1140.1">This chapter has shown you a good summary of how you can improve and use systems to scale your code. </span><span class="koboSpan" id="kobo.1140.2">We also demonstrated how we can use standard and third-party libraries to add capabilities to our code </span><span class="No-Break"><span class="koboSpan" id="kobo.1141.1">to scale.</span></span></p>
<p><span class="koboSpan" id="kobo.1142.1">Now, you are probably much more familiar with the technologies that you could use to interact with large networks. </span><span class="koboSpan" id="kobo.1142.2">You are now in a better position to choose a language, a library, and a system that will support your network automation to scale to handle thousands or even millions of </span><span class="No-Break"><span class="koboSpan" id="kobo.1143.1">network devices.</span></span></p>
<p><span class="koboSpan" id="kobo.1144.1">In the next chapter, we are going to cover how to test your code and your system, which will allow you to build solutions for network automation that are less prone </span><span class="No-Break"><span class="koboSpan" id="kobo.1145.1">to failures.</span></span></p>
</div>


<div class="Content" id="_idContainer054">
<h1 id="_idParaDest-207"><a id="_idTextAnchor208"/><span class="koboSpan" id="kobo.1.1">Part 3: Testing, Hands-On, and Going Forward</span></h1>
<p><span class="koboSpan" id="kobo.2.1">The third part of the book will discuss what has to be considered when building a framework for testing your code and how to do so, We will do some real hands-on testing and, finally, describe what to do to move forward in the network automation realm. </span><span class="koboSpan" id="kobo.2.2">We will provide the details on creating a testing framework and do hands-on work using an emulated network, which will help to put into practice all the information learned in previous parts.</span></p>
<p><span class="koboSpan" id="kobo.3.1">This part has the following chapters:</span></p>
<ul>
<li><a href="B18165_09.xhtml#_idTextAnchor209"><em class="italic"><span class="koboSpan" id="kobo.4.1">Chapter 9</span></em></a><span class="koboSpan" id="kobo.5.1">, </span><em class="italic"><span class="koboSpan" id="kobo.6.1">Network Code Testing Frameworks</span></em></li>
<li><a href="B18165_10.xhtml#_idTextAnchor227"><em class="italic"><span class="koboSpan" id="kobo.7.1">Chapter 10</span></em></a><span class="koboSpan" id="kobo.8.1">, </span><em class="italic"><span class="koboSpan" id="kobo.9.1">Hands-On and Going Forward</span></em></li>
</ul>
</div>
<div>
<div id="_idContainer055">
</div>
</div>
<div>
<div id="_idContainer056">
</div>
</div>
</body></html>