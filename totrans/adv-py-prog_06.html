<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer054">
			<h1 id="_idParaDest-92"><em class="italic"><a id="_idTextAnchor085"/>Chapter 5</em>: Exploring Compilers</h1>
			<p>Python is a mature and widely used language, and there is great interest in improving its performance by compiling functions and methods directly to machine code rather than executing instructions in the interpreter. We have already seen a compiler example in <a href="B17499_04_Final_SS_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 4</em></a>, <em class="italic">C Performance with Cython</em>, where Python code is enhanced with types, compiled to efficient C code, and the interpreter calls are sidestepped.</p>
			<p>In this chapter, we will explore two projects, Numba and PyPy, that approach compilation in a slightly different way. <strong class="bold">Numba</strong> is a library designed to compile small functions on the fly. Instead of transforming Python code to C, Numba analyzes and compiles Python functions directly to machine code. <strong class="bold">PyPy</strong> is a replacement interpreter that works by analyzing the code at runtime and optimizing the slow loops automatically.</p>
			<p>These tools are called <strong class="bold">Just-In-Time</strong> (<strong class="bold">JIT</strong>) compilers because the compilation is performed at runtime rather than before running the code (in other cases, the compiler is called <strong class="bold">Ahead-Of-Time</strong> or <strong class="bold">AOT</strong>).</p>
			<p>The list of topics to be covered in this chapter is as follows:</p>
			<ul>
				<li>Getting started with Numba</li>
				<li>The PyPy project</li>
				<li>Other interesting projects</li>
			</ul>
			<p>Overall, Numba and PyPy offer us flexibility in leveraging JIT compilation to accelerate our programs. This chapter adds another instrument to our toolbox for improving the speed of Python applications.</p>
			<h1 id="_idParaDest-93"><a id="_idTextAnchor086"/>Technical requirements</h1>
			<p>The code files for this chapter can be accessed through this link: <a href="https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter05">https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter05</a>.</p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor087"/>Getting started with Numba</h1>
			<p>Numba <a id="_idIndexMarker352"/>was started in 2012 by Travis Oliphant, the original author of NumPy, as a library for compiling individual Python functions at runtime using the <strong class="bold">Low-Level Virtual Machine</strong> (<strong class="bold">LLVM</strong>) toolchain.</p>
			<p>LLVM is<a id="_idIndexMarker353"/> a set of tools designed to write compilers. LLVM is language-agnostic and is used to write compilers for a wide range of languages (an important example is the Clang compiler). One of the core aspects of LLVM is the intermediate representation (the LLVM IR), a very low-level, platform-agnostic language-like assembly, that can be compiled to machine code for the specific target platform.</p>
			<p>Numba works by inspecting Python functions and compiling them, using LLVM, to the IR. As we saw in the last chapter, speed gains can be obtained when we introduce types for variables and functions. Numba implements clever algorithms to guess the types (this is called <strong class="bold">type inference</strong>) and <a id="_idIndexMarker354"/>compiles type-aware versions of the functions for fast execution.</p>
			<p>Note that Numba was developed to improve the performance of numerical code. The development efforts often prioritize the optimization of applications that intensively use NumPy arrays.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Numba is evolving fast and can have substantial improvements between releases and, sometimes, backward-incompatible changes. To keep up, ensure that you refer to the release notes for each version. In the rest of this chapter, we will use Numba version 0.53.1; ensure that you install the correct version to avoid any error by using <strong class="source-inline">pip install numba==0.53.1</strong>. The complete code examples in this chapter can be found in the <strong class="source-inline">Numba.ipynb</strong> notebook.</p>
			<p>For the rest of this section, we will explore different aspects of Numba usage such as type specializations and JIT classes, as well as its limitations. First, we will discuss how to integrate Numba into a Python program via decorators.</p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor088"/>Using Numba decorators</h2>
			<p>In most cases, the way we <a id="_idIndexMarker355"/>point Numba to specific Python functions is <a id="_idIndexMarker356"/>via decorators. Let's see how to do this:</p>
			<ol>
				<li>As a first example, we will implement a function that calculates the sum of the squares of an array. The function definition is as follows:<p class="source-code">    def sum_sq(a):</p><p class="source-code">        result = 0</p><p class="source-code">        N = len(a)</p><p class="source-code">        for i in range(N):</p><p class="source-code">            result += a[i]</p><p class="source-code">        return result</p></li>
				<li>To set up this function with Numba, it is sufficient to apply the <strong class="source-inline">nb.jit</strong> decorator:<p class="source-code">    from numba import nb</p><p class="source-code">    @nb.jit</p><p class="source-code">    def sum_sq(a):</p><p class="source-code">        ...</p></li>
			</ol>
			<p>The <strong class="source-inline">nb.jit</strong> decorator won't do much when applied. However, when the function is invoked for the first time, Numba will detect the type of the input argument, <strong class="source-inline">a</strong>, and compile a specialized, performant version of the original function.</p>
			<ol>
				<li value="3">To measure the performance gain obtained by the Numba compiler, we can compare the timings of the original and the specialized functions. The original, undecorated function can be easily accessed through the <strong class="source-inline">py_func</strong> attribute. The timings for the two functions are as follows:<p class="source-code">    import numpy as np</p><p class="source-code">    x = np.random.rand(10000)</p><p class="source-code">    # Original</p><p class="source-code">    %timeit sum_sq.py_func(x)</p><p class="source-code">    4.3 ms ± 81.6 µs per loop</p><p class="source-code">    # Numba</p><p class="source-code">    %timeit sum_sq(x)</p><p class="source-code">    12.8 µs ± 5.41 µs per loop</p></li>
			</ol>
			<p>From the<a id="_idIndexMarker357"/> previous code, you can see how the Numba version (12.8 µs) is one order of magnitude faster than the Python version (4.3 ms).</p>
			<ol>
				<li value="4">We<a id="_idIndexMarker358"/> can also compare how this implementation stacks up against NumPy standard operators:<p class="source-code">    %timeit (x**2).sum()</p><p class="source-code">    9.44 µs ± 93.7 ns per loop</p></li>
			</ol>
			<p>In this case, the Numba compiled function is marginally slower than NumPy vectorized operations, although this difference might change across different runs.</p>
			<p>Considering that all we needed to do was apply a simple decorator to obtain an incredible speed up over different data types, it's no wonder that what Numba does looks like magic. In the following sections, we will dig deeper to understand how Numba works and evaluate the benefits and limitations of the Numba compiler.</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor089"/>Type specializations</h2>
			<p>As <a id="_idIndexMarker359"/>shown earlier, the <strong class="source-inline">nb.jit</strong> decorator works by compiling a specialized version<a id="_idIndexMarker360"/> of the function once it encounters a new argument type. To better understand how this works, we can inspect the decorated function in the <strong class="source-inline">sum_sq</strong> example:</p>
			<ol>
				<li value="1">Numba exposes the specialized types using the <strong class="source-inline">signatures</strong> attribute. Right after the <strong class="source-inline">sum_sq</strong> definition, we can inspect the available specialization by accessing <strong class="source-inline">sum_sq.signatures</strong>, as follows:<p class="source-code">    sum_sq.signatures</p><p class="source-code">    # Output:</p><p class="source-code">    # []</p></li>
				<li>If we call this function with a specific argument, for instance, an array of <strong class="source-inline">float64</strong> numbers, we can see how Numba compiles a specialized version on the fly. If we also apply the function on an array of <strong class="source-inline">float32</strong>, we can see how a new entry is added to the <strong class="source-inline">sum_sq.signatures</strong> list:<p class="source-code">    x = np.random.rand(1000).astype('float64')</p><p class="source-code">    sum_sq(x)</p><p class="source-code">    sum_sq.signatures</p><p class="source-code">    # Result:</p><p class="source-code">    # [(array(float64, 1d, C),)]</p><p class="source-code">    x = np.random.rand(1000).astype('float32')</p><p class="source-code">    sum_sq(x)</p><p class="source-code">    sum_sq.signatures</p><p class="source-code">    # Result:</p><p class="source-code">    # [(array(float64, 1d, C),), (array(float32, 1d, </p><p class="source-code">        C),)]</p></li>
			</ol>
			<p>It is possible to explicitly compile the function for certain types by passing a signature to the <strong class="source-inline">nb.jit</strong> function.</p>
			<ol>
				<li value="3">An<a id="_idIndexMarker361"/> individual signature can be passed as a tuple that contains the type we would like to accept. Numba provides a great variety of types that can be found in the <strong class="source-inline">nb.types</strong> module, and they are also available in the top-level <strong class="source-inline">nb</strong> namespace. If we want to specify an array of a specific type, we can use the slicing operator, <strong class="source-inline">[:]</strong>, on the type itself. In the following example, we demonstrate <a id="_idIndexMarker362"/>how to declare a function that takes an array of <strong class="source-inline">float64</strong> as its only argument:<p class="source-code">    @nb.jit((nb.float64[:],))</p><p class="source-code">    def sum_sq(a):</p></li>
				<li>Note that when we explicitly declare a signature, we are prevented from using other types, as demonstrated in the following example. If we try to pass an array, <strong class="source-inline">x</strong>, as <strong class="source-inline">float32</strong>, Numba will raise a <strong class="source-inline">TypeError</strong> exception: <p class="source-code">    sum_sq(x.astype('float32'))</p><p class="source-code">    # TypeError: No matching definition for argument </p><p class="source-code">      type(s) </p><p class="source-code">    array(float32, 1d, C)</p></li>
				<li>Another way to declare signatures is through type strings. For example, a function that takes <strong class="source-inline">float64</strong> as input and returns <strong class="source-inline">float64</strong> as output can be declared with the <strong class="source-inline">float64(float64)</strong> string. Array types can be declared using a <strong class="source-inline">[:]</strong> suffix. To put this together, we can declare a signature for our <strong class="source-inline">sum_sq</strong> function, as follows:<p class="source-code">    @nb.jit("float64(float64[:])")</p><p class="source-code">    def sum_sq(a):</p></li>
				<li>You can also pass multiple signatures by passing a list:<p class="source-code">    @nb.jit(["float64(float64[:])",</p><p class="source-code">             "float64(float32[:])"])</p><p class="source-code">    def sum_sq(a):</p></li>
			</ol>
			<p>These APIs<a id="_idIndexMarker363"/> ensure<a id="_idIndexMarker364"/> that Numba has the correct information about what data type a function works with.</p>
			<h2 id="_idParaDest-97"><a id="_idTextAnchor090"/>Object mode versus native mode</h2>
			<p>So far, we<a id="_idIndexMarker365"/> have shown how Numba behaves when handling a simple function. In this case, Numba worked exceptionally well, and we obtained great performance on arrays and lists.</p>
			<p>The degree <a id="_idIndexMarker366"/>of optimization obtainable from Numba depends on how well Numba can infer the variable types and how well it can translate those standard Python operations to fast type-specific versions. If this happens, the interpreter is sidestepped, and we can get performance gains such as those of Cython.</p>
			<p>When Numba cannot infer variable types, it will still try and compile the code, reverting to the interpreter when the types can't be determined or when certain operations are unsupported. In Numba, this is <a id="_idIndexMarker367"/>called <strong class="bold">object mode</strong> and contrasts with the interpreter-free scenario<a id="_idIndexMarker368"/> called <strong class="bold">native mode</strong>.</p>
			<p>Numba provides a function<a id="_idIndexMarker369"/> called <strong class="source-inline">inspect_types</strong> that helps understand how effective the type inference was and which operations were optimized. Let's see how to use the following function:</p>
			<ol>
				<li value="1">As an example, we can look at the types inferred for our <strong class="source-inline">sum_sq</strong> function:<p class="source-code">    sum_sq.inspect_types()</p></li>
				<li>When this function is called, Numba will print the type inferred for each specialized version of the function. The output consists of blocks that contain information about variables and types associated with them. For example, we can examine the <strong class="source-inline">N = len(a)</strong> line:<p class="source-code">    # --- LINE 4 --- </p><p class="source-code">    #  label  0</p><p class="source-code">    #   a = arg(0, name=a)  :: array(float64, 1d, A)</p><p class="source-code">    #   $2load_global.0 = global(len: &lt;built-in  \</p><p class="source-code">          function len&gt;) :: Function (&lt;built-in  \</p><p class="source-code">            function len&gt;)</p><p class="source-code">    #   N = call $2load_global.0(a, func= \</p><p class="source-code">          $2load_global.0, args=[Var(a, \</p><p class="source-code">            &lt;ipython-in put-19-4687c4bff0ac&gt;:4)], \</p><p class="source-code">              kws=(), vararg=None)  :: (array( \</p><p class="source-code">                float64, 1d, A),) -&gt; int64</p><p class="source-code">    N = len(a)</p></li>
			</ol>
			<p>For each line, Numba prints a thorough description of variables, functions, and intermediate results. In <a id="_idIndexMarker370"/>the preceding example, you can see (on the second line) that the <strong class="source-inline">a</strong> argument is correctly identified as an array of <strong class="source-inline">float64</strong> numbers. At <strong class="source-inline">LINE 4</strong>, the input and return type of the <strong class="source-inline">len</strong> function is also correctly identified (and likely optimized) as taking an array of <strong class="source-inline">float64</strong> numbers and returning <strong class="source-inline">int64</strong>.</p>
			<p>If you scroll through the output, you can see how all the variables have a well-defined type. Therefore, we can be certain that Numba is able to compile the code quite efficiently. This form of compilation<a id="_idIndexMarker371"/> is called <strong class="bold">native mode</strong>.</p>
			<p>As a counterexample, we can see what happens if we write a function with unsupported operations. For example, as of version 0.53.1, Numba has limited support for string operations.</p>
			<ol>
				<li value="3">We can implement a function that concatenates a series of strings and compiles it as follows:<p class="source-code">    @nb.jit</p><p class="source-code">    def concatenate(strings):</p><p class="source-code">        result = ''</p><p class="source-code">        for s in strings:</p><p class="source-code">            result += s</p><p class="source-code">        return result</p></li>
				<li>Now, we can invoke this function with a list of strings and inspect the types:<p class="source-code">    concatenate(['hello', 'world'])</p><p class="source-code">    concatenate.signatures</p><p class="source-code">    # Output: concatenate (reflected </p><p class="source-code">      list(unicode_type)&lt;iv=None&gt;,)</p><p class="source-code">    concatenate.inspect_types()</p></li>
				<li>Numba <a id="_idIndexMarker372"/>will return the output of the function for the <strong class="source-inline">reflected list (unicode type)</strong> type. We can, for instance, examine how the third line gets inferred. The output of <strong class="source-inline">concatenate.inspect_types()</strong> is reproduced here:<p class="source-code">    </p><p class="source-code">    # --- LINE 3 --- </p><p class="source-code">    # label 0</p><p class="source-code">    #   strings = arg(0, name=strings)  :: reflected \</p><p class="source-code">     list(unicode_type)&lt;iv=None&gt;</p><p class="source-code">    #   result = const(str, )  :: Literal[str]()</p><p class="source-code">    result = ''</p></li>
			</ol>
			<p>You can see that this time, each variable, or function is of the <strong class="source-inline">unicode</strong> or <strong class="source-inline">str</strong> type. Once again by timing the original and compiled function, we can note a significant improvement in performance:</p>
			<p class="source-code">    x = ['hello'] * 1000</p>
			<p class="source-code">    %timeit concatenate.py_func(x)</p>
			<p class="source-code">    81.9 µs ± 1.25 µs per loop</p>
			<p class="source-code">    %timeit concatenate(x)</p>
			<p class="source-code">    1.27 ms ± 23.3 µs per loop</p>
			<p>This is <a id="_idIndexMarker373"/>because the Numba compiler is not able to optimize the code and adds some extra overhead to the function call.</p>
			<p class="callout-heading">An Equivalent Decorator</p>
			<p class="callout">Note that from version 0.12, the more concise <strong class="source-inline">@nb.njit</strong> decorator could be used instead.</p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor091"/>Numba and NumPy</h2>
			<p>Numba <a id="_idIndexMarker374"/>was originally developed to easily increase the performance of code that uses NumPy arrays. Currently, many NumPy features are implemented efficiently by the compiler. Here, we will see how to combine the two tools to achieve even better performance for universal functions.</p>
			<h3 id="_idParaDest-99">Universal functions with Numba</h3>
			<p>Universal functions <a id="_idIndexMarker375"/>are special functions defined in NumPy that <a id="_idIndexMarker376"/>can operate on arrays of different sizes and shapes according to the broadcasting rules. One of the best features of Numba is the<a id="_idIndexMarker377"/> implementation of fast <strong class="source-inline">ufunc</strong> instances.</p>
			<p>We have already seen some <strong class="source-inline">ufunc</strong> examples in <a href="B17499_03_Final_SS_ePub.xhtml#_idTextAnchor047"><em class="italic">Chapter 3</em></a>, <em class="italic">Fast Array Operations with NumPy, Pandas, and Xarray</em>. For instance, the <strong class="source-inline">np.log</strong> function is a <strong class="source-inline">ufunc</strong> instance because it can accept scalars and arrays of different sizes and shapes. Also, universal functions that take multiple arguments still work according to the broadcasting rules. Examples of universal functions that take multiple arguments are <strong class="source-inline">np.sum</strong> and <strong class="source-inline">np.difference</strong>.</p>
			<p>Universal functions can be defined in standard NumPy by implementing the scalar version and using the <strong class="source-inline">np.vectorize</strong> function to enhance the function with the broadcasting feature. As an <a id="_idIndexMarker378"/>example, let's see how to write<a id="_idIndexMarker379"/> the <em class="italic">Cantor pairing function</em>:</p>
			<ol>
				<li value="1">A pairing function is a function that encodes two natural numbers into a single natural number so that you can easily interconvert between the two representations. The Cantor pairing function can be written as follows:<p class="source-code">    import numpy as np</p><p class="source-code">    def cantor(a, b):</p><p class="source-code">        return  int(0.5 * (a + b)*(a + b + 1) + b)</p></li>
				<li>As already mentioned, it is possible to create a <strong class="source-inline">ufunc</strong> instance in pure Python using the <strong class="source-inline">np.vectorized</strong> decorator:<p class="source-code">    @np.vectorize</p><p class="source-code">    def cantor(a, b):</p><p class="source-code">        return  int(0.5 * (a + b)*(a + b + 1) + b)</p><p class="source-code">    cantor(np.array([1, 2]), 2)</p><p class="source-code">    # Result:</p><p class="source-code">    # array([ 8, 12])</p></li>
			</ol>
			<p>Except for the convenience, defining universal functions in pure Python is not very useful, as it requires a lot of function calls affected by interpreter overhead. For this reason, <strong class="source-inline">ufunc</strong> implementation is usually done in C or Cython, but Numba beats all these methods with its convenience.</p>
			<p>All that is needed in order to perform the conversion is to use the equivalent decorator, <strong class="source-inline">nb.vectorize</strong>.</p>
			<ol>
				<li value="3">We can compare the speed of the standard <strong class="source-inline">np.vectorized</strong> version, which, in the <a id="_idIndexMarker380"/>following code, is called <strong class="source-inline">cantor_py</strong>, and the same function is implemented using standard NumPy operations:<p class="source-code">    # Pure Python</p><p class="source-code">    %timeit cantor_py(x1, x2)</p><p class="source-code">    2.4 ms ± 23.7 µs per loop</p><p class="source-code">    # Numba</p><p class="source-code">    %timeit cantor(x1, x2)</p><p class="source-code">    9.1 µs ± 204 ns per loop</p><p class="source-code">    # NumPy</p><p class="source-code">    %timeit (0.5 * (x1 + x2)*(x1 + x2 + 1) + \</p><p class="source-code">      x2).astype(int)</p><p class="source-code">    33.2 µs ± 1.12 µs per loop</p></li>
			</ol>
			<p>You can see how the Numba version beats all the other options by a large margin! Numba works extremely well because the function is simple and type inference is possible.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">An additional <a id="_idIndexMarker381"/>advantage of universal functions is that, since they depend on individual values, their evaluation can also be executed in parallel. Numba provides an easy way to parallelize such functions by passing the <strong class="source-inline">target="cpu"</strong> or <strong class="source-inline">target="gpu"</strong> keyword argument to the <strong class="source-inline">nb.vectorize</strong> decorator.</p>
			<h3 id="_idParaDest-100">Generalized universal functions</h3>
			<p>One of the main limitations of universal functions is that they must be defined on scalar values. A <strong class="bold">generalized universal function</strong>, abbreviated<a id="_idIndexMarker382"/> as <strong class="source-inline">gufunc</strong>, is<a id="_idIndexMarker383"/> an extension of universal functions to procedures that take arrays. Let's see how we can apply Numba to these functions:</p>
			<ol>
				<li value="1">A classic example is matrix multiplication. In NumPy, matrix multiplication can be <a id="_idIndexMarker384"/>applied using the <strong class="source-inline">np.matmul</strong> function, which takes two 2D arrays and returns another 2D array. An example of the usage of <strong class="source-inline">np.matmul</strong> is as follows:<p class="source-code">    a = np.random.rand(3, 3)</p><p class="source-code">    b = np.random.rand(3, 3)</p><p class="source-code">    c = np.matmul(a, b)</p><p class="source-code">    c.shape</p><p class="source-code">    # Result:</p><p class="source-code">    # (3, 3)</p></li>
			</ol>
			<p>As we saw in the previous subsection, a <strong class="source-inline">ufunc</strong> instance broadcasts the operation over arrays of <em class="italic">scalars</em>; its natural generalization will be to broadcast over an array of <em class="italic">arrays</em>. If, for instance, we take two arrays of 3 by 3 matrices, we will expect <strong class="source-inline">np.matmul</strong> to match the matrices and take their product.</p>
			<ol>
				<li value="2">In the following example, we take two arrays containing 10 matrices of the <strong class="source-inline">(3, 3)</strong> shape. If we apply <strong class="source-inline">np.matmul</strong>, the product will be applied <em class="italic">matrix-wise</em> to obtain a new array containing the 10 results (which are, again, <strong class="source-inline">(3, 3)</strong> matrices):<p class="source-code">    a = np.random.rand(10, 3, 3)</p><p class="source-code">    b = np.random.rand(10, 3, 3)</p><p class="source-code">    c = np.matmul(a, b)</p><p class="source-code">    c.shape</p><p class="source-code">    # Output</p><p class="source-code">    # (10, 3, 3)</p></li>
				<li>The usual rules for broadcasting will work in a similar way. For example, if we have an array of <strong class="source-inline">(3, 3)</strong> matrices, which will have a shape of <strong class="source-inline">(10, 3, 3)</strong>, we can use <strong class="source-inline">np.matmul</strong> to calculate the matrix multiplication of each element with a <a id="_idIndexMarker385"/>single <strong class="source-inline">(3, 3)</strong> matrix. According<a id="_idIndexMarker386"/> to the broadcasting rules, we find that the single matrix will be repeated to obtain a size of <strong class="source-inline">(10, 3, 3)</strong>:<p class="source-code">    a = np.random.rand(10, 3, 3)</p><p class="source-code">    b = np.random.rand(3, 3) # Broadcasted to shape  </p><p class="source-code">     (10, 3, 3)</p><p class="source-code">    c = np.matmul(a, b)</p><p class="source-code">    c.shape</p><p class="source-code">    # Result:</p><p class="source-code">    # (10, 3, 3)</p></li>
			</ol>
			<p>Numba supports the implementation of efficient generalized universal functions through the <strong class="source-inline">nb.guvectorize</strong> decorator. As an example, we will implement a function that computes the Euclidean distance between two arrays as a <strong class="source-inline">gufunc</strong> instance. To create a <strong class="source-inline">gufunc</strong> instance, we must define a function that takes the input arrays, plus an output array where we will store the result of our calculation.</p>
			<p>The <strong class="source-inline">nb.guvectorize</strong> decorator requires two arguments: </p>
			<ul>
				<li>The types of input and output – two 1D arrays as input and a scalar as output.</li>
				<li>The so-called layout string, which is a representation of the input and output sizes; in our case, we take two arrays of the same size (denoted arbitrarily by <strong class="source-inline">n</strong>) and output a scalar.</li>
			</ul>
			<ol>
				<li value="4">In the following example, we can see the implementation of the <strong class="source-inline">euclidean</strong> function using the <strong class="source-inline">nb.guvectorize</strong> decorator:<p class="source-code">    @nb.guvectorize(['float64[:], float64[:], \</p><p class="source-code">      float64[:]'], '(n), (n) -&gt; ()')</p><p class="source-code">    def euclidean(a, b, out):</p><p class="source-code">        N = a.shape[0]</p><p class="source-code">        out[0] = 0.0</p><p class="source-code">        for i in range(N):</p><p class="source-code">            out[0] += (a[i] - b[i])**2</p></li>
			</ol>
			<p>There<a id="_idIndexMarker387"/> are a few very important points<a id="_idIndexMarker388"/> to be made. Predictably, we declared the <strong class="source-inline">a</strong> and <strong class="source-inline">b</strong> input types as <strong class="source-inline">float64[:]</strong> because they are 1D arrays. However, what about the output argument? Wasn't it supposed to be a scalar? Yes, but <em class="italic">Numba treats a scalar argument as arrays of size 1</em>. That's why it was declared as <strong class="source-inline">float64[:]</strong>.</p>
			<p>Similarly, the layout string indicates that we have two arrays of size <strong class="source-inline">(n)</strong> and the output is a scalar, denoted by empty brackets – <strong class="source-inline">()</strong>. However, the array out will be passed as an array of size 1. Also, note that we don't return anything from the function; all the output must be written in the <strong class="source-inline">out</strong> array.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">The letter <strong class="source-inline">n</strong> in the layout string is completely arbitrary; you may choose to use <strong class="source-inline">k</strong> or other letters of your liking. Also, if you want to combine arrays of uneven sizes, you can use layout strings, such as <strong class="source-inline">(n, m)</strong>.</p>
			<ol>
				<li value="5">Our brand-new <strong class="source-inline">euclidean</strong> function can be conveniently used on arrays of different shapes, as shown in the following example:<p class="source-code">    a = np.random.rand(2)</p><p class="source-code">    b = np.random.rand(2)</p><p class="source-code">    c = euclidean(a, b) # Shape: (1,)</p><p class="source-code">    a = np.random.rand(10, 2)</p><p class="source-code">    b = np.random.rand(10, 2)</p><p class="source-code">    c = euclidean(a, b) # Shape: (10,)</p><p class="source-code">    a = np.random.rand(10, 2)</p><p class="source-code">    b = np.random.rand(2)</p><p class="source-code">    c = euclidean(a, b) # Shape: (10,)</p></li>
				<li>How <a id="_idIndexMarker389"/>does the speed of <strong class="source-inline">euclidean</strong> compare to standard NumPy? In the following code, we will benchmark a NumPy<a id="_idIndexMarker390"/> vectorized version with our previously defined <strong class="source-inline">euclidean</strong> function:<p class="source-code">    a = np.random.rand(10000, 2)</p><p class="source-code">    b = np.random.rand(10000, 2)</p><p class="source-code">    %timeit ((a - b)**2).sum(axis=1)</p><p class="source-code">    153 µs ± 13.2 µs per loop</p><p class="source-code">    %timeit euclidean(a, b)</p><p class="source-code">    47.1 µs ± 3.19 µs per loop</p></li>
			</ol>
			<p>The Numba version, again, beats the NumPy version by a large margin!</p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor092"/>JIT classes</h2>
			<p>As of<a id="_idIndexMarker391"/> today, Numba doesn't support the optimization of generic Python objects. This limitation, however, doesn't have a huge impact on numerical codes, as they usually involve arrays and math operations exclusively.</p>
			<p>Nevertheless, certain data structures are much more naturally implemented using objects; therefore, Numba provides support for defining classes that can be used and compiled to fast native code. Bear in mind that this is one of the newest (and almost experimental) features, and it is extremely useful, as it allows us to extend Numba to support fast data structures that are not easily implemented with arrays.</p>
			<p>As an example, we will <a id="_idIndexMarker392"/>show how to implement a simple linked list using <em class="italic">JIT classes</em>. A linked list can be implemented by defining a <strong class="source-inline">Node</strong> class that contains two fields – a value and the next item in the list. As you can see in the following figure, each <strong class="bold">Node</strong> connects to the next and holds a value, and the last <strong class="bold">Node</strong> contains a broken link, to which we assign a value of <strong class="bold">None</strong>:</p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/Figure_5.1_B17499.jpg" alt="Figure 5.1 – An illustration of a linked list " width="522" height="77"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.1 – An illustration of a linked list</p>
			<p>We will explore <a id="_idIndexMarker393"/>various JIT-related features in the following steps:</p>
			<ol>
				<li value="1">In Python, we can define the <strong class="source-inline">Node</strong> class as follows:<p class="source-code">    class Node:</p><p class="source-code">        def __init__(self, value):</p><p class="source-code">            self.next = None</p><p class="source-code">            self.value = value</p></li>
				<li>We can manage the collection of <strong class="source-inline">Node</strong> instances by creating another class, called <strong class="source-inline">LinkedList</strong>. This class will keep track of the head of the list (in the preceding figure, this corresponds to the <strong class="bold">Node</strong> instance with <strong class="bold">value 3</strong>). To insert an element in the front of the list, we can simply create a new <strong class="source-inline">Node</strong> instance and link it to the current head.</li>
			</ol>
			<p>In the <a id="_idIndexMarker394"/>following code, we develop the initialization <a id="_idIndexMarker395"/>function for <strong class="source-inline">LinkedList</strong> and the <strong class="source-inline">LinkedList.push_back</strong> method that inserts an element in the front of the list using the strategy outlined earlier:</p>
			<p class="source-code">    class LinkedList:</p>
			<p class="source-code">    </p>
			<p class="source-code">        def __init__(self):</p>
			<p class="source-code">            self.head = None</p>
			<p class="source-code">    </p>
			<p class="source-code">        def push_front(self, value):</p>
			<p class="source-code">            if self.head == None:</p>
			<p class="source-code">                self.head = Node(value)</p>
			<p class="source-code">            else:</p>
			<p class="source-code">                # We replace the head</p>
			<p class="source-code">                new_head = Node(value)</p>
			<p class="source-code">                new_head.next = self.head</p>
			<p class="source-code">                self.head = new_head</p>
			<ol>
				<li value="3">For debugging purposes, we can also implement the <strong class="source-inline">LinkedList.show </strong>method that traverses and prints each element in the list. The method is shown in the following snippet:<p class="source-code">        def show(self):</p><p class="source-code">            node = self.head</p><p class="source-code">            while node is not None:</p><p class="source-code">                print(node.value)</p><p class="source-code">                node = node.next</p></li>
				<li>At this point, we can test our <strong class="source-inline">LinkedList</strong> and see whether it behaves correctly. We <a id="_idIndexMarker396"/>can create an empty list, add a few elements, and <a id="_idIndexMarker397"/>print its content. Note that since we are pushing elements to the front of the list, the last elements inserted will be the first to be printed:<p class="source-code">    lst = LinkedList()</p><p class="source-code">    lst.push_front(1)</p><p class="source-code">    lst.push_front(2)</p><p class="source-code">    lst.push_front(3)</p><p class="source-code">    lst.show()</p><p class="source-code">    # Output:</p><p class="source-code">    # 3</p><p class="source-code">    # 2</p><p class="source-code">    # 1</p></li>
				<li>Finally, we can implement a function, <strong class="source-inline">sum_list</strong>, that returns the sum of the elements in the linked list. We will use this method to time differences between the Numba and pure Python versions:<p class="source-code">    @nb.jit</p><p class="source-code">    def sum_list(lst):</p><p class="source-code">        result = 0</p><p class="source-code">        node = lst.head</p><p class="source-code">        while node is not None: </p><p class="source-code">            result += node.value</p><p class="source-code">            node = node.next</p><p class="source-code">        return result</p></li>
				<li>If we measure the execution time of the original <strong class="source-inline">sum_list</strong> version and the <strong class="source-inline">nb.jit</strong> version, we <a id="_idIndexMarker398"/>see that there is not much difference. The reason<a id="_idIndexMarker399"/> is that Numba cannot infer the type of classes:<p class="source-code">    lst = LinkedList()</p><p class="source-code">    [lst.push_front(i) for i in range(10000)]</p><p class="source-code">    </p><p class="source-code">    %timeit sum_list(lst)</p><p class="source-code">    1.73 ms ± 159 µs per loop</p><p class="source-code">    %timeit sum_list.py_func(lst)</p><p class="source-code">    1.01 ms ± 175 µs per loop</p></li>
				<li>We can improve the performance of <strong class="source-inline">sum_list</strong> by compiling the <strong class="source-inline">Node</strong> and <strong class="source-inline">LinkedList</strong> classes using the <strong class="source-inline">nb.jitclass</strong> decorator.</li>
			</ol>
			<p>The <strong class="source-inline">nb.jitclass</strong> decorator takes a single argument that contains the attribute types. In the <strong class="source-inline">Node</strong> class, the attribute types are <strong class="source-inline">int64</strong> for <strong class="source-inline">value</strong> and <strong class="source-inline">Node</strong> for <strong class="source-inline">next</strong>. The <strong class="source-inline">nb.jitclass</strong> decorator will also compile all the methods defined for the class. Before delving into the code, we need to make two observations.</p>
			<p>First, the attribute declaration must be done before the class is defined, but how do we declare a type that we haven't defined yet? Numba provides the <strong class="source-inline">nb.deferred_type()</strong> function that can be used for this purpose.</p>
			<p>Second, the <strong class="source-inline">next</strong> attribute can be either <strong class="source-inline">None</strong> or a <strong class="source-inline">Node</strong> instance. This is what is called an optional type, and Numba provides a utility called <strong class="source-inline">nb.optional</strong> that lets you declare variables that can be (optionally) <strong class="source-inline">None</strong>.</p>
			<p>This <strong class="source-inline">Node</strong> class is illustrated in the following code sample. As you can see, <strong class="source-inline">node_type</strong> is predeclared using <strong class="source-inline">nb.deferred_type()</strong>. The attributes are declared <a id="_idIndexMarker400"/>as a list of pairs containing the attribute name<a id="_idIndexMarker401"/> and the type (also note the use of <strong class="source-inline">nb.optional</strong>). After the class declaration, we are required to declare the deferred type:</p>
			<p class="source-code">    node_type = nb.deferred_type()</p>
			<p class="source-code">    node_spec = [</p>
			<p class="source-code">        ('next', nb.optional(node_type)),</p>
			<p class="source-code">        ('value', nb.int64)</p>
			<p class="source-code">    ]</p>
			<p class="source-code">    @nb.jitclass(node_spec)</p>
			<p class="source-code">    class Node:</p>
			<p class="source-code">        # Body of Node is unchanged</p>
			<p class="source-code">    node_type.define(Node.class_type.instance_type)</p>
			<ol>
				<li value="8">The <strong class="source-inline">LinkedList</strong> class can be easily compiled, as follows. All that's needed is to define the <strong class="source-inline">head</strong> attribute and to apply the <strong class="source-inline">nb.jitclass</strong> decorator:<p class="source-code">    ll_spec = [</p><p class="source-code">        ('head', nb.optional(Node.class_type. \</p><p class="source-code">          instance_type))</p><p class="source-code">    ]</p><p class="source-code">    @jitclass(ll_spec)</p><p class="source-code">    class LinkedList:</p><p class="source-code">        # Body of LinkedList is unchanged</p></li>
				<li>We <a id="_idIndexMarker402"/>can <a id="_idIndexMarker403"/>now measure the execution time of the <strong class="source-inline">sum_list</strong> function when we pass a JIT <strong class="source-inline">LinkedList</strong>:<p class="source-code">    lst = LinkedList()</p><p class="source-code">    [lst.push_front(i) for i in range(10000)]</p><p class="source-code">    %timeit sum_list(lst)</p><p class="source-code">    106 µs ± 2.64 µs per loop</p><p class="source-code">    %timeit sum_list.py_func(lst)</p><p class="source-code">    2.42 ms ± 51.8 µs per loop</p></li>
			</ol>
			<p>Interestingly, when using a JIT class from a compiled function, we obtain a substantial performance improvement against the pure Python version. However, using the JIT class from the original <strong class="source-inline">sum_list.py_func</strong> actually results in a worse performance. Ensure that you use JIT classes only inside compiled functions!</p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor093"/>Limitations in Numba</h2>
			<p>There are <a id="_idIndexMarker404"/>some instances where Numba cannot properly infer the variable types. In the following example, we define a function that takes a nested list of integers and returns the sum of the element in every sublist. In this case, Numba will raise a warning:</p>
			<p class="source-code">    a = [[0, 1, 2], </p>
			<p class="source-code">         [3, 4], </p>
			<p class="source-code">         [5, 6, 7, 8]]</p>
			<p class="source-code">    @nb.jit</p>
			<p class="source-code">    def sum_sublists(a):</p>
			<p class="source-code">        result = []</p>
			<p class="source-code">        for sublist in a:</p>
			<p class="source-code">            result.append(sum(sublist))</p>
			<p class="source-code">        return result</p>
			<p class="source-code">    sum_sublists(a)</p>
			<p class="source-code">    # NumbaWarning: Compilation is falling back to object </p>
			<p class="source-code">      mode WITH looplifting enabled because Function </p>
			<p class="source-code">        "sum_sublists" failed type inference...</p>
			<p>The problem<a id="_idIndexMarker405"/> with this code is that Numba is not able to determine the list type and fails. A way to fix this problem is to help the compiler determine the right type by initializing the list with a sample element and removing it at the end:</p>
			<p class="source-code">    @nb.jit</p>
			<p class="source-code">    def sum_sublists(a):</p>
			<p class="source-code">        result = [0]</p>
			<p class="source-code">        for sublist in a:</p>
			<p class="source-code">            result.append(sum(sublist))</p>
			<p class="source-code">        return result[1:]</p>
			<p>Among other features that are not yet implemented in the Numba compiler are function and class definitions, <strong class="source-inline">list</strong>, <strong class="source-inline">set</strong>, and <strong class="source-inline">dict</strong> comprehensions, generators, the <strong class="source-inline">with</strong> statement, and <strong class="source-inline">try</strong> and <strong class="source-inline">except</strong> blocks. Note, however, that many of these features may become supported in the future.</p>
			<p>Overall, we have seen multiple approaches of working with Numba to speed up our applications, such as type specializations, NumPy's universal functions, and JIT classes. We will now move on to our second main topic in this chapter – PyPy.</p>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor094"/>The PyPy project</h1>
			<p>PyPy is <a id="_idIndexMarker406"/>a very ambitious project at improving the performance of the Python interpreter. The way PyPy improves performance is by automatically compiling slow sections of the code at runtime.</p>
			<p>PyPy is written in a special language <a id="_idIndexMarker407"/>called <strong class="bold">RPython</strong> (rather than C) that allows developers to implement advanced features and improvements quickly and reliably. RPython means <strong class="bold">Restricted Python</strong> because it implements a restricted subset of the Python language targeted to the compiler development.</p>
			<p>As of today, PyPy version 7.3.5 supports a lot of Python features and is a possible choice for a large variety of applications, such as game and web development. PyPy compiles code using a very clever <a id="_idIndexMarker408"/>strategy called <strong class="bold">tracing JIT compilation</strong>. At first, the code is executed normally using interpreter calls. PyPy then starts to profile the code and identifies the most intensive loops. After the identification takes place, the compiler then observes (<em class="italic">traces</em>) the operations and can compile its optimized, interpreter-free version.</p>
			<p>Once an optimized version of the code is present, PyPy can run the slow loop much faster than the interpreted version.</p>
			<p>This strategy can be contrasted with what Numba does. In Numba, the units of compilation are methods and functions, while the PyPy focus is just slow loops. Overall, the focus of the projects is also very different, as Numba has limited scope for numerical code and requires a lot of instrumentation, while PyPy aims at replacing the CPython interpreter.</p>
			<p>In this section, we will demonstrate and benchmark PyPy on our particle simulator application. We will begin by setting up Python and then look at running a particle simulator in PyPy.</p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor095"/>Setting up PyPy</h2>
			<p>PyPy is <a id="_idIndexMarker409"/>distributed as a precompiled binary that can be downloaded<a id="_idIndexMarker410"/> from <a href="http://pypy.org/download.html">http://pypy.org/download.html</a>, and it currently supports Python versions 2.7 and 3.7. In this chapter, we will demonstrate the usage of the 3.7 version.</p>
			<p>Once PyPy is downloaded and unpacked, you can locate the interpreter in the <strong class="source-inline">bin/pypy</strong> directory relative to the unpacked archive. You can initialize a new virtual environment, where we can install additional packages using the following command:</p>
			<p class="source-code">$ /path/to/bin/pypy -m ensurepip</p>
			<p class="source-code">$ /path/to/bin/pypy -m pip install virtualenv</p>
			<p class="source-code">$ /path/to/bin/virtualenv my-pypy-env</p>
			<p>To activate the environment, we will use the following command:</p>
			<p class="source-code">$ source my-pypy-env/bin/activate</p>
			<p>At this <a id="_idIndexMarker411"/>point, you can verify that the binary Python is linked to the PyPy executable by typing <strong class="source-inline">python -V</strong>. At this point, we can go ahead and install some packages we may need. Note that PyPy may have limited support for software that uses the Python C API (most notably, packages such as <strong class="source-inline">numpy</strong> and <strong class="source-inline">matplotlib</strong>). We can go ahead and install them in the usual way:</p>
			<p class="source-code">(my-pypy-env) $ pip install numpy matplotlib</p>
			<p>On certain platforms, the installation of <strong class="source-inline">numpy</strong> and <strong class="source-inline">matplotlib</strong> can be tricky. You can skip the installation step and remove any imports on these two packages from the scripts we will run.</p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor096"/>Running a particle simulator in PyPy</h2>
			<p>Now that <a id="_idIndexMarker412"/>we have successfully set up the PyPy installation, we can go ahead and run our particle simulator. As a first step, we will time the particle simulator from <a href="B17499_01_Final_SS_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Benchmarking and Profiling</em>, on the standard Python interpreter. If the virtual environment is still active, you can issue the <strong class="source-inline">deactivate</strong> command to exit the environment:</p>
			<p class="source-code">(my-pypy-env) $ deactivate</p>
			<p>At this point, we can time our code using the <strong class="source-inline">timeit</strong> command-line interface:</p>
			<p class="source-code">$ python -m timeit --setup "from simul import benchmark" </p>
			<p class="source-code">  "benchmark()"</p>
			<p class="source-code">10 loops, best of 3: 886 msec per loop</p>
			<p>We can reactivate the environment and run the exact same code from PyPy. On Ubuntu, you may have problems importing the <strong class="source-inline">matplotlib.pyplot</strong> module. You can try issuing<a id="_idIndexMarker413"/> the following <strong class="source-inline">export</strong> command to fix the issue or removing the <strong class="source-inline">matplotlib</strong> imports from <strong class="source-inline">simul.py</strong>:</p>
			<p class="source-code">$ export MPLBACKEND='agg'</p>
			<p>Now, we can go ahead and time the code using PyPy:</p>
			<p class="source-code">$ source my-pypy-env/bin/activate</p>
			<p class="source-code">(my-pypy-env) $ python -m timeit --setup "from simul import </p>
			<p class="source-code">  benchmark" "benchmark()"</p>
			<p class="source-code">WARNING: timeit is a very unreliable tool. use perf or </p>
			<p class="source-code">something else for real measurements</p>
			<p class="source-code">10 loops, average of 7: 106 +- 0.383 msec per loop (using </p>
			<p class="source-code">standard deviation)</p>
			<p>Note that we obtained a large (more than eight times) speed-up! PyPy, however, warns us that the <strong class="source-inline">timeit</strong> module can be unreliable. We can confirm our timings using the <strong class="source-inline">perf</strong> module, as suggested by PyPy:</p>
			<p class="source-code">(my-pypy-env) $ pip install perf</p>
			<p class="source-code">(my-pypy-env) $ python -m perf timeit --setup 'from simul </p>
			<p class="source-code">  import benchmark' 'benchmark()'</p>
			<p class="source-code">.......</p>
			<p class="source-code">Median +- std dev: 97.8 ms +- 2.3 ms</p>
			<p>This gives us a more reliable assurance that our speed-up is consistent. Overall, we can see that with a simple reinstallation of Python, we are able to achieve significant speed-up via PyPy.</p>
			<p class="callout-heading">Advanced PyPy</p>
			<p class="callout">Although not within the scope of this chapter, for <a id="_idIndexMarker414"/>more advanced usage of PyPy, one could integrate it with Pyglet for game development and PyLongs and Django for web development.</p>
			<p>Overall, Numba and PyPy together <a id="_idIndexMarker415"/>offer us many options regarding how we might want to go about leveraging JIT compilers to supercharge our Python programs. In the next section, we examine several other options that may be of interest.</p>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor097"/>Other interesting projects</h1>
			<p>Over the years, many projects attempted to improve Python performance through several strategies, and, sadly, many of them failed. As of today, there are a few projects that survive and hold the promise for a faster Python.</p>
			<p>Numba and PyPy are mature projects that are steadily improving over the years. Features are continuously being added, and they hold great promise for the future of Python:</p>
			<ul>
				<li><strong class="bold">Nuitka</strong> is a<a id="_idIndexMarker416"/> program developed by Kay Hayen that compiles Python code to C. At the time of writing (version 0.6.15), it provides extreme compatibility with the Python language and produces efficient code that results in moderate performance improvements over CPython.</li>
			</ul>
			<p>Nuitka is quite different than Cython in the sense that it focuses on extreme compatibility with the Python language, and it doesn't extend the language with additional constructs.</p>
			<ul>
				<li><strong class="bold">Pyston</strong> is a <a id="_idIndexMarker417"/>new interpreter developed by Dropbox that powers JIT compilers. It differs substantially from PyPy as it doesn't employ a tracing JIT but rather a method-at-a-time JIT (similar to what Numba does). Pyston, like Numba, is also built on top of the LLVM compiler infrastructure.</li>
			</ul>
			<p>Pyston is in active development and supports both <strong class="bold">Python 2.7</strong> and <strong class="bold">3.8</strong>. Benchmarks show that it is faster than CPython but slower than PyPy; that said, it is still an interesting project to follow as new features are added and compatibility<a id="_idIndexMarker418"/> is increased.</p>
			<p>At this point, we have been introduced to four different JIT compilers. You may find in your own experience that, when developing an application, different situations and use cases may call for different compilers. It is, therefore, important to explore our options when it comes to using a JIT compiler to speed up our Python code.</p>
			<h1 id="_idParaDest-107"><a id="_idTextAnchor098"/>Summary</h1>
			<p>Numba is a tool that compiles fast, specialized versions of Python functions at runtime. In this chapter, we learned how to compile, inspect, and analyze functions compiled by Numba. We also learned how to implement fast NumPy universal functions that are useful in a wide array of numerical applications. Finally, we implemented more complex data structures using the <strong class="source-inline">nb.jitclass</strong> decorator. Overall, Numba is built to accelerate numeric loops that are common in scientific computing. As we have seen, Numba works seamlessly with the popular NumPy library.</p>
			<p>Tools such as PyPy allow us to run Python programs unchanged to obtain significant speed improvements. We demonstrated how to set up PyPy, and we assessed the performance improvements on our particle simulator application. We have also seen that, unlike Numba, PyPy doesn't operate on a function level but instead seeks to implement a more efficient interpreter for a whole Python program.</p>
			<p>We also, briefly, described the current ecosystem of the Python compilers and compared them with each other. These discussions will give you the confidence to explore and work with different JIT compilers and select the most appropriate for your applications. In the next chapter, we will see a specialized version of a JIT compiler that is optimized for machine learning operations and tasks.</p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor099"/>Questions</h1>
			<ol>
				<li value="1">What are JIT compilers and why are they useful?</li>
				<li>How does Numba determine the types of variables in a Python program? What happens when these variables are not of the type that Numba works well with?</li>
				<li>What is the high-level idea of tracing a JIT compilation of PyPy?</li>
			</ol>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor100"/>Further reading</h1>
			<ul>
				<li>More on JIT compilers: <a href="https://www.freecodecamp.org/news/just-in-time-compilation-explained/">https://www.freecodecamp.org/news/just-in-time-compilation-explained/</a></li>
			</ul>
		</div>
	</div>
</div>
</body></html>