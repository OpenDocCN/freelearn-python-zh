<html><head></head><body>
<div><div><div><h1 id="_idParaDest-92"><em class="italic"><a id="_idTextAnchor085"/>Chapter 5</em>: Exploring Compilers</h1>
			<p>Python is a mature and widely used language, and there is great interest in improving its performance by compiling functions and methods directly to machine code rather than executing instructions in the interpreter. We have already seen a compiler example in <a href="B17499_04_Final_SS_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 4</em></a>, <em class="italic">C Performance with Cython</em>, where Python code is enhanced with types, compiled to efficient C code, and the interpreter calls are sidestepped.</p>
			<p>In this chapter, we will explore two projects, Numba and PyPy, that approach compilation in a slightly different way. <strong class="bold">Numba</strong> is a library designed to compile small functions on the fly. Instead of transforming Python code to C, Numba analyzes and compiles Python functions directly to machine code. <strong class="bold">PyPy</strong> is a replacement interpreter that works by analyzing the code at runtime and optimizing the slow loops automatically.</p>
			<p>These tools are called <strong class="bold">Just-In-Time</strong> (<strong class="bold">JIT</strong>) compilers because the compilation is performed at runtime rather than before running the code (in other cases, the compiler is called <strong class="bold">Ahead-Of-Time</strong> or <strong class="bold">AOT</strong>).</p>
			<p>The list of topics to be covered in this chapter is as follows:</p>
			<ul>
				<li>Getting started with Numba</li>
				<li>The PyPy project</li>
				<li>Other interesting projects</li>
			</ul>
			<p>Overall, Numba and PyPy offer us flexibility in leveraging JIT compilation to accelerate our programs. This chapter adds another instrument to our toolbox for improving the speed of Python applications.</p>
			<h1 id="_idParaDest-93"><a id="_idTextAnchor086"/>Technical requirements</h1>
			<p>The code files for this chapter can be accessed through this link: <a href="https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter05">https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter05</a>.</p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor087"/>Getting started with Numba</h1>
			<p>Numba <a id="_idIndexMarker352"/>was started in 2012 by Travis Oliphant, the original author of NumPy, as a library for compiling individual Python functions at runtime using the <strong class="bold">Low-Level Virtual Machine</strong> (<strong class="bold">LLVM</strong>) toolchain.</p>
			<p>LLVM is<a id="_idIndexMarker353"/> a set of tools designed to write compilers. LLVM is language-agnostic and is used to write compilers for a wide range of languages (an important example is the Clang compiler). One of the core aspects of LLVM is the intermediate representation (the LLVM IR), a very low-level, platform-agnostic language-like assembly, that can be compiled to machine code for the specific target platform.</p>
			<p>Numba works by inspecting Python functions and compiling them, using LLVM, to the IR. As we saw in the last chapter, speed gains can be obtained when we introduce types for variables and functions. Numba implements clever algorithms to guess the types (this is called <strong class="bold">type inference</strong>) and <a id="_idIndexMarker354"/>compiles type-aware versions of the functions for fast execution.</p>
			<p>Note that Numba was developed to improve the performance of numerical code. The development efforts often prioritize the optimization of applications that intensively use NumPy arrays.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Numba is evolving fast and can have substantial improvements between releases and, sometimes, backward-incompatible changes. To keep up, ensure that you refer to the release notes for each version. In the rest of this chapter, we will use Numba version 0.53.1; ensure that you install the correct version to avoid any error by using <code>pip install numba==0.53.1</code>. The complete code examples in this chapter can be found in the <code>Numba.ipynb</code> notebook.</p>
			<p>For the rest of this section, we will explore different aspects of Numba usage such as type specializations and JIT classes, as well as its limitations. First, we will discuss how to integrate Numba into a Python program via decorators.</p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor088"/>Using Numba decorators</h2>
			<p>In most cases, the way we <a id="_idIndexMarker355"/>point Numba to specific Python functions is <a id="_idIndexMarker356"/>via decorators. Let's see how to do this:</p>
			<ol>
				<li>As a first example, we will implement a function that calculates the sum of the squares of an array. The function definition is as follows:<pre>    def sum_sq(a):
        result = 0
        N = len(a)
        for i in range(N):
            result += a[i]
        return result</pre></li>
				<li>To set up this function with Numba, it is sufficient to apply the <code>nb.jit</code> decorator:<pre>    from numba import nb
    @nb.jit
    def sum_sq(a):
        ...</pre></li>
			</ol>
			<p>The <code>nb.jit</code> decorator won't do much when applied. However, when the function is invoked for the first time, Numba will detect the type of the input argument, <code>a</code>, and compile a specialized, performant version of the original function.</p>
			<ol>
				<li value="3">To measure the performance gain obtained by the Numba compiler, we can compare the timings of the original and the specialized functions. The original, undecorated function can be easily accessed through the <code>py_func</code> attribute. The timings for the two functions are as follows:<pre>    import numpy as np
    x = np.random.rand(10000)
    # Original
    %timeit sum_sq.py_func(x)
    4.3 ms ± 81.6 µs per loop
    # Numba
    %timeit sum_sq(x)
    12.8 µs ± 5.41 µs per loop</pre></li>
			</ol>
			<p>From the<a id="_idIndexMarker357"/> previous code, you can see how the Numba version (12.8 µs) is one order of magnitude faster than the Python version (4.3 ms).</p>
			<ol>
				<li value="4">We<a id="_idIndexMarker358"/> can also compare how this implementation stacks up against NumPy standard operators:<pre>    %timeit (x**2).sum()
    9.44 µs ± 93.7 ns per loop</pre></li>
			</ol>
			<p>In this case, the Numba compiled function is marginally slower than NumPy vectorized operations, although this difference might change across different runs.</p>
			<p>Considering that all we needed to do was apply a simple decorator to obtain an incredible speed up over different data types, it's no wonder that what Numba does looks like magic. In the following sections, we will dig deeper to understand how Numba works and evaluate the benefits and limitations of the Numba compiler.</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor089"/>Type specializations</h2>
			<p>As <a id="_idIndexMarker359"/>shown earlier, the <code>nb.jit</code> decorator works by compiling a specialized version<a id="_idIndexMarker360"/> of the function once it encounters a new argument type. To better understand how this works, we can inspect the decorated function in the <code>sum_sq</code> example:</p>
			<ol>
				<li value="1">Numba exposes the specialized types using the <code>signatures</code> attribute. Right after the <code>sum_sq</code> definition, we can inspect the available specialization by accessing <code>sum_sq.signatures</code>, as follows:<pre>    sum_sq.signatures
    # Output:
    # []</pre></li>
				<li>If we call this function with a specific argument, for instance, an array of <code>float64</code> numbers, we can see how Numba compiles a specialized version on the fly. If we also apply the function on an array of <code>float32</code>, we can see how a new entry is added to the <code>sum_sq.signatures</code> list:<pre>    x = np.random.rand(1000).astype('float64')
    sum_sq(x)
    sum_sq.signatures
    # Result:
    # [(array(float64, 1d, C),)]
    x = np.random.rand(1000).astype('float32')
    sum_sq(x)
    sum_sq.signatures
    # Result:
    # [(array(float64, 1d, C),), (array(float32, 1d, 
        C),)]</pre></li>
			</ol>
			<p>It is possible to explicitly compile the function for certain types by passing a signature to the <code>nb.jit</code> function.</p>
			<ol>
				<li value="3">An<a id="_idIndexMarker361"/> individual signature can be passed as a tuple that contains the type we would like to accept. Numba provides a great variety of types that can be found in the <code>nb.types</code> module, and they are also available in the top-level <code>nb</code> namespace. If we want to specify an array of a specific type, we can use the slicing operator, <code>[:]</code>, on the type itself. In the following example, we demonstrate <a id="_idIndexMarker362"/>how to declare a function that takes an array of <code>float64</code> as its only argument:<pre>    @nb.jit((nb.float64[:],))
    def sum_sq(a):</pre></li>
				<li>Note that when we explicitly declare a signature, we are prevented from using other types, as demonstrated in the following example. If we try to pass an array, <code>x</code>, as <code>float32</code>, Numba will raise a <code>TypeError</code> exception: <pre>    sum_sq(x.astype('float32'))
    # TypeError: No matching definition for argument 
      type(s) 
    array(float32, 1d, C)</pre></li>
				<li>Another way to declare signatures is through type strings. For example, a function that takes <code>float64</code> as input and returns <code>float64</code> as output can be declared with the <code>float64(float64)</code> string. Array types can be declared using a <code>[:]</code> suffix. To put this together, we can declare a signature for our <code>sum_sq</code> function, as follows:<pre>    @nb.jit("float64(float64[:])")
    def sum_sq(a):</pre></li>
				<li>You can also pass multiple signatures by passing a list:<pre>    @nb.jit(["float64(float64[:])",
             "float64(float32[:])"])
    def sum_sq(a):</pre></li>
			</ol>
			<p>These APIs<a id="_idIndexMarker363"/> ensure<a id="_idIndexMarker364"/> that Numba has the correct information about what data type a function works with.</p>
			<h2 id="_idParaDest-97"><a id="_idTextAnchor090"/>Object mode versus native mode</h2>
			<p>So far, we<a id="_idIndexMarker365"/> have shown how Numba behaves when handling a simple function. In this case, Numba worked exceptionally well, and we obtained great performance on arrays and lists.</p>
			<p>The degree <a id="_idIndexMarker366"/>of optimization obtainable from Numba depends on how well Numba can infer the variable types and how well it can translate those standard Python operations to fast type-specific versions. If this happens, the interpreter is sidestepped, and we can get performance gains such as those of Cython.</p>
			<p>When Numba cannot infer variable types, it will still try and compile the code, reverting to the interpreter when the types can't be determined or when certain operations are unsupported. In Numba, this is <a id="_idIndexMarker367"/>called <strong class="bold">object mode</strong> and contrasts with the interpreter-free scenario<a id="_idIndexMarker368"/> called <strong class="bold">native mode</strong>.</p>
			<p>Numba provides a function<a id="_idIndexMarker369"/> called <code>inspect_types</code> that helps understand how effective the type inference was and which operations were optimized. Let's see how to use the following function:</p>
			<ol>
				<li value="1">As an example, we can look at the types inferred for our <code>sum_sq</code> function:<pre>    sum_sq.inspect_types()</pre></li>
				<li>When this function is called, Numba will print the type inferred for each specialized version of the function. The output consists of blocks that contain information about variables and types associated with them. For example, we can examine the <code>N = len(a)</code> line:<pre>    # --- LINE 4 --- 
    #  label  0
    #   a = arg(0, name=a)  :: array(float64, 1d, A)
    #   $2load_global.0 = global(len: &lt;built-in  \
          function len&gt;) :: Function (&lt;built-in  \
            function len&gt;)
    #   N = call $2load_global.0(a, func= \
          $2load_global.0, args=[Var(a, \
            &lt;ipython-in put-19-4687c4bff0ac&gt;:4)], \
              kws=(), vararg=None)  :: (array( \
                float64, 1d, A),) -&gt; int64
    N = len(a)</pre></li>
			</ol>
			<p>For each line, Numba prints a thorough description of variables, functions, and intermediate results. In <a id="_idIndexMarker370"/>the preceding example, you can see (on the second line) that the <code>a</code> argument is correctly identified as an array of <code>float64</code> numbers. At <code>LINE 4</code>, the input and return type of the <code>len</code> function is also correctly identified (and likely optimized) as taking an array of <code>float64</code> numbers and returning <code>int64</code>.</p>
			<p>If you scroll through the output, you can see how all the variables have a well-defined type. Therefore, we can be certain that Numba is able to compile the code quite efficiently. This form of compilation<a id="_idIndexMarker371"/> is called <strong class="bold">native mode</strong>.</p>
			<p>As a counterexample, we can see what happens if we write a function with unsupported operations. For example, as of version 0.53.1, Numba has limited support for string operations.</p>
			<ol>
				<li value="3">We can implement a function that concatenates a series of strings and compiles it as follows:<pre>    @nb.jit
    def concatenate(strings):
        result = ''
        for s in strings:
            result += s
        return result</pre></li>
				<li>Now, we can invoke this function with a list of strings and inspect the types:<pre>    concatenate(['hello', 'world'])
    concatenate.signatures
    # Output: concatenate (reflected 
      list(unicode_type)&lt;iv=None&gt;,)
    concatenate.inspect_types()</pre></li>
				<li>Numba <a id="_idIndexMarker372"/>will return the output of the function for the <code>reflected list (unicode type)</code> type. We can, for instance, examine how the third line gets inferred. The output of <code>concatenate.inspect_types()</code> is reproduced here:<pre>    
    # --- LINE 3 --- 
    # label 0
    #   strings = arg(0, name=strings)  :: reflected \
     list(unicode_type)&lt;iv=None&gt;
    #   result = const(str, )  :: Literal[str]()
    result = ''</pre></li>
			</ol>
			<p>You can see that this time, each variable, or function is of the <code>unicode</code> or <code>str</code> type. Once again by timing the original and compiled function, we can note a significant improvement in performance:</p>
			<pre>    x = ['hello'] * 1000
    %timeit concatenate.py_func(x)
    81.9 µs ± 1.25 µs per loop
    %timeit concatenate(x)
    1.27 ms ± 23.3 µs per loop</pre>
			<p>This is <a id="_idIndexMarker373"/>because the Numba compiler is not able to optimize the code and adds some extra overhead to the function call.</p>
			<p class="callout-heading">An Equivalent Decorator</p>
			<p class="callout">Note that from version 0.12, the more concise <code>@nb.njit</code> decorator could be used instead.</p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor091"/>Numba and NumPy</h2>
			<p>Numba <a id="_idIndexMarker374"/>was originally developed to easily increase the performance of code that uses NumPy arrays. Currently, many NumPy features are implemented efficiently by the compiler. Here, we will see how to combine the two tools to achieve even better performance for universal functions.</p>
			<h3 id="_idParaDest-99">Universal functions with Numba</h3>
			<p>Universal functions <a id="_idIndexMarker375"/>are special functions defined in NumPy that <a id="_idIndexMarker376"/>can operate on arrays of different sizes and shapes according to the broadcasting rules. One of the best features of Numba is the<a id="_idIndexMarker377"/> implementation of fast <code>ufunc</code> instances.</p>
			<p>We have already seen some <code>ufunc</code> examples in <a href="B17499_03_Final_SS_ePub.xhtml#_idTextAnchor047"><em class="italic">Chapter 3</em></a>, <em class="italic">Fast Array Operations with NumPy, Pandas, and Xarray</em>. For instance, the <code>np.log</code> function is a <code>ufunc</code> instance because it can accept scalars and arrays of different sizes and shapes. Also, universal functions that take multiple arguments still work according to the broadcasting rules. Examples of universal functions that take multiple arguments are <code>np.sum</code> and <code>np.difference</code>.</p>
			<p>Universal functions can be defined in standard NumPy by implementing the scalar version and using the <code>np.vectorize</code> function to enhance the function with the broadcasting feature. As an <a id="_idIndexMarker378"/>example, let's see how to write<a id="_idIndexMarker379"/> the <em class="italic">Cantor pairing function</em>:</p>
			<ol>
				<li value="1">A pairing function is a function that encodes two natural numbers into a single natural number so that you can easily interconvert between the two representations. The Cantor pairing function can be written as follows:<pre>    import numpy as np
    def cantor(a, b):
        return  int(0.5 * (a + b)*(a + b + 1) + b)</pre></li>
				<li>As already mentioned, it is possible to create a <code>ufunc</code> instance in pure Python using the <code>np.vectorized</code> decorator:<pre>    @np.vectorize
    def cantor(a, b):
        return  int(0.5 * (a + b)*(a + b + 1) + b)
    cantor(np.array([1, 2]), 2)
    # Result:
    # array([ 8, 12])</pre></li>
			</ol>
			<p>Except for the convenience, defining universal functions in pure Python is not very useful, as it requires a lot of function calls affected by interpreter overhead. For this reason, <code>ufunc</code> implementation is usually done in C or Cython, but Numba beats all these methods with its convenience.</p>
			<p>All that is needed in order to perform the conversion is to use the equivalent decorator, <code>nb.vectorize</code>.</p>
			<ol>
				<li value="3">We can compare the speed of the standard <code>np.vectorized</code> version, which, in the <a id="_idIndexMarker380"/>following code, is called <code>cantor_py</code>, and the same function is implemented using standard NumPy operations:<pre>    # Pure Python
    %timeit cantor_py(x1, x2)
    2.4 ms ± 23.7 µs per loop
    # Numba
    %timeit cantor(x1, x2)
    9.1 µs ± 204 ns per loop
    # NumPy
    %timeit (0.5 * (x1 + x2)*(x1 + x2 + 1) + \
      x2).astype(int)
    33.2 µs ± 1.12 µs per loop</pre></li>
			</ol>
			<p>You can see how the Numba version beats all the other options by a large margin! Numba works extremely well because the function is simple and type inference is possible.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">An additional <a id="_idIndexMarker381"/>advantage of universal functions is that, since they depend on individual values, their evaluation can also be executed in parallel. Numba provides an easy way to parallelize such functions by passing the <code>target="cpu"</code> or <code>target="gpu"</code> keyword argument to the <code>nb.vectorize</code> decorator.</p>
			<h3 id="_idParaDest-100">Generalized universal functions</h3>
			<p>One of the main limitations of universal functions is that they must be defined on scalar values. A <code>gufunc</code>, is<a id="_idIndexMarker383"/> an extension of universal functions to procedures that take arrays. Let's see how we can apply Numba to these functions:</p>
			<ol>
				<li value="1">A classic example is matrix multiplication. In NumPy, matrix multiplication can be <a id="_idIndexMarker384"/>applied using the <code>np.matmul</code> function, which takes two 2D arrays and returns another 2D array. An example of the usage of <code>np.matmul</code> is as follows:<pre>    a = np.random.rand(3, 3)
    b = np.random.rand(3, 3)
    c = np.matmul(a, b)
    c.shape
    # Result:
    # (3, 3)</pre></li>
			</ol>
			<p>As we saw in the previous subsection, a <code>ufunc</code> instance broadcasts the operation over arrays of <em class="italic">scalars</em>; its natural generalization will be to broadcast over an array of <em class="italic">arrays</em>. If, for instance, we take two arrays of 3 by 3 matrices, we will expect <code>np.matmul</code> to match the matrices and take their product.</p>
			<ol>
				<li value="2">In the following example, we take two arrays containing 10 matrices of the <code>(3, 3)</code> shape. If we apply <code>np.matmul</code>, the product will be applied <em class="italic">matrix-wise</em> to obtain a new array containing the 10 results (which are, again, <code>(3, 3)</code> matrices):<pre>    a = np.random.rand(10, 3, 3)
    b = np.random.rand(10, 3, 3)
    c = np.matmul(a, b)
    c.shape
    # Output
    # (10, 3, 3)</pre></li>
				<li>The usual rules for broadcasting will work in a similar way. For example, if we have an array of <code>(3, 3)</code> matrices, which will have a shape of <code>(10, 3, 3)</code>, we can use <code>np.matmul</code> to calculate the matrix multiplication of each element with a <a id="_idIndexMarker385"/>single <code>(3, 3)</code> matrix. According<a id="_idIndexMarker386"/> to the broadcasting rules, we find that the single matrix will be repeated to obtain a size of <code>(10, 3, 3)</code>:<pre>    a = np.random.rand(10, 3, 3)
    b = np.random.rand(3, 3) # Broadcasted to shape  
     (10, 3, 3)
    c = np.matmul(a, b)
    c.shape
    # Result:
    # (10, 3, 3)</pre></li>
			</ol>
			<p>Numba supports the implementation of efficient generalized universal functions through the <code>nb.guvectorize</code> decorator. As an example, we will implement a function that computes the Euclidean distance between two arrays as a <code>gufunc</code> instance. To create a <code>gufunc</code> instance, we must define a function that takes the input arrays, plus an output array where we will store the result of our calculation.</p>
			<p>The <code>nb.guvectorize</code> decorator requires two arguments: </p>
			<ul>
				<li>The types of input and output – two 1D arrays as input and a scalar as output.</li>
				<li>The so-called layout string, which is a representation of the input and output sizes; in our case, we take two arrays of the same size (denoted arbitrarily by <code>n</code>) and output a scalar.</li>
			</ul>
			<ol>
				<li value="4">In the following example, we can see the implementation of the <code>euclidean</code> function using the <code>nb.guvectorize</code> decorator:<pre>    @nb.guvectorize(['float64[:], float64[:], \
      float64[:]'], '(n), (n) -&gt; ()')
    def euclidean(a, b, out):
        N = a.shape[0]
        out[0] = 0.0
        for i in range(N):
            out[0] += (a[i] - b[i])**2</pre></li>
			</ol>
			<p>There<a id="_idIndexMarker387"/> are a few very important points<a id="_idIndexMarker388"/> to be made. Predictably, we declared the <code>a</code> and <code>b</code> input types as <code>float64[:]</code> because they are 1D arrays. However, what about the output argument? Wasn't it supposed to be a scalar? Yes, but <em class="italic">Numba treats a scalar argument as arrays of size 1</em>. That's why it was declared as <code>float64[:]</code>.</p>
			<p>Similarly, the layout string indicates that we have two arrays of size <code>(n)</code> and the output is a scalar, denoted by empty brackets – <code>()</code>. However, the array out will be passed as an array of size 1. Also, note that we don't return anything from the function; all the output must be written in the <code>out</code> array.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">The letter <code>n</code> in the layout string is completely arbitrary; you may choose to use <code>k</code> or other letters of your liking. Also, if you want to combine arrays of uneven sizes, you can use layout strings, such as <code>(n, m)</code>.</p>
			<ol>
				<li value="5">Our brand-new <code>euclidean</code> function can be conveniently used on arrays of different shapes, as shown in the following example:<pre>    a = np.random.rand(2)
    b = np.random.rand(2)
    c = euclidean(a, b) # Shape: (1,)
    a = np.random.rand(10, 2)
    b = np.random.rand(10, 2)
    c = euclidean(a, b) # Shape: (10,)
    a = np.random.rand(10, 2)
    b = np.random.rand(2)
    c = euclidean(a, b) # Shape: (10,)</pre></li>
				<li>How <a id="_idIndexMarker389"/>does the speed of <code>euclidean</code> compare to standard NumPy? In the following code, we will benchmark a NumPy<a id="_idIndexMarker390"/> vectorized version with our previously defined <code>euclidean</code> function:<pre>    a = np.random.rand(10000, 2)
    b = np.random.rand(10000, 2)
    %timeit ((a - b)**2).sum(axis=1)
    153 µs ± 13.2 µs per loop
    %timeit euclidean(a, b)
    47.1 µs ± 3.19 µs per loop</pre></li>
			</ol>
			<p>The Numba version, again, beats the NumPy version by a large margin!</p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor092"/>JIT classes</h2>
			<p>As of<a id="_idIndexMarker391"/> today, Numba doesn't support the optimization of generic Python objects. This limitation, however, doesn't have a huge impact on numerical codes, as they usually involve arrays and math operations exclusively.</p>
			<p>Nevertheless, certain data structures are much more naturally implemented using objects; therefore, Numba provides support for defining classes that can be used and compiled to fast native code. Bear in mind that this is one of the newest (and almost experimental) features, and it is extremely useful, as it allows us to extend Numba to support fast data structures that are not easily implemented with arrays.</p>
			<p>As an example, we will <a id="_idIndexMarker392"/>show how to implement a simple linked list using <em class="italic">JIT classes</em>. A linked list can be implemented by defining a <code>Node</code> class that contains two fields – a value and the next item in the list. As you can see in the following figure, each <strong class="bold">Node</strong> connects to the next and holds a value, and the last <strong class="bold">Node</strong> contains a broken link, to which we assign a value of <strong class="bold">None</strong>:</p>
			<div><div><img src="img/Figure_5.1_B17499.jpg" alt="Figure 5.1 – An illustration of a linked list " width="522" height="77"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.1 – An illustration of a linked list</p>
			<p>We will explore <a id="_idIndexMarker393"/>various JIT-related features in the following steps:</p>
			<ol>
				<li value="1">In Python, we can define the <code>Node</code> class as follows:<pre>    class Node:
        def __init__(self, value):
            self.next = None
            self.value = value</pre></li>
				<li>We can manage the collection of <code>Node</code> instances by creating another class, called <code>LinkedList</code>. This class will keep track of the head of the list (in the preceding figure, this corresponds to the <code>Node</code> instance and link it to the current head.</li>
			</ol>
			<p>In the <a id="_idIndexMarker394"/>following code, we develop the initialization <a id="_idIndexMarker395"/>function for <code>LinkedList</code> and the <code>LinkedList.push_back</code> method that inserts an element in the front of the list using the strategy outlined earlier:</p>
			<pre>    class LinkedList:
    
        def __init__(self):
            self.head = None
    
        def push_front(self, value):
            if self.head == None:
                self.head = Node(value)
            else:
                # We replace the head
                new_head = Node(value)
                new_head.next = self.head
                self.head = new_head</pre>
			<ol>
				<li value="3">For debugging purposes, we can also implement the <code>LinkedList.show </code>method that traverses and prints each element in the list. The method is shown in the following snippet:<pre>        def show(self):
            node = self.head
            while node is not None:
                print(node.value)
                node = node.next</pre></li>
				<li>At this point, we can test our <code>LinkedList</code> and see whether it behaves correctly. We <a id="_idIndexMarker396"/>can create an empty list, add a few elements, and <a id="_idIndexMarker397"/>print its content. Note that since we are pushing elements to the front of the list, the last elements inserted will be the first to be printed:<pre>    lst = LinkedList()
    lst.push_front(1)
    lst.push_front(2)
    lst.push_front(3)
    lst.show()
    # Output:
    # 3
    # 2
    # 1</pre></li>
				<li>Finally, we can implement a function, <code>sum_list</code>, that returns the sum of the elements in the linked list. We will use this method to time differences between the Numba and pure Python versions:<pre>    @nb.jit
    def sum_list(lst):
        result = 0
        node = lst.head
        while node is not None: 
            result += node.value
            node = node.next
        return result</pre></li>
				<li>If we measure the execution time of the original <code>sum_list</code> version and the <code>nb.jit</code> version, we <a id="_idIndexMarker398"/>see that there is not much difference. The reason<a id="_idIndexMarker399"/> is that Numba cannot infer the type of classes:<pre>    lst = LinkedList()
    [lst.push_front(i) for i in range(10000)]
    
    %timeit sum_list(lst)
    1.73 ms ± 159 µs per loop
    %timeit sum_list.py_func(lst)
    1.01 ms ± 175 µs per loop</pre></li>
				<li>We can improve the performance of <code>sum_list</code> by compiling the <code>Node</code> and <code>LinkedList</code> classes using the <code>nb.jitclass</code> decorator.</li>
			</ol>
			<p>The <code>nb.jitclass</code> decorator takes a single argument that contains the attribute types. In the <code>Node</code> class, the attribute types are <code>int64</code> for <code>value</code> and <code>Node</code> for <code>next</code>. The <code>nb.jitclass</code> decorator will also compile all the methods defined for the class. Before delving into the code, we need to make two observations.</p>
			<p>First, the attribute declaration must be done before the class is defined, but how do we declare a type that we haven't defined yet? Numba provides the <code>nb.deferred_type()</code> function that can be used for this purpose.</p>
			<p>Second, the <code>next</code> attribute can be either <code>None</code> or a <code>Node</code> instance. This is what is called an optional type, and Numba provides a utility called <code>nb.optional</code> that lets you declare variables that can be (optionally) <code>None</code>.</p>
			<p>This <code>Node</code> class is illustrated in the following code sample. As you can see, <code>node_type</code> is predeclared using <code>nb.deferred_type()</code>. The attributes are declared <a id="_idIndexMarker400"/>as a list of pairs containing the attribute name<a id="_idIndexMarker401"/> and the type (also note the use of <code>nb.optional</code>). After the class declaration, we are required to declare the deferred type:</p>
			<pre>    node_type = nb.deferred_type()
    node_spec = [
        ('next', nb.optional(node_type)),
        ('value', nb.int64)
    ]
    @nb.jitclass(node_spec)
    class Node:
        # Body of Node is unchanged
    node_type.define(Node.class_type.instance_type)</pre>
			<ol>
				<li value="8">The <code>LinkedList</code> class can be easily compiled, as follows. All that's needed is to define the <code>head</code> attribute and to apply the <code>nb.jitclass</code> decorator:<pre>    ll_spec = [
        ('head', nb.optional(Node.class_type. \
          instance_type))
    ]
    @jitclass(ll_spec)
    class LinkedList:
        # Body of LinkedList is unchanged</pre></li>
				<li>We <a id="_idIndexMarker402"/>can <a id="_idIndexMarker403"/>now measure the execution time of the <code>sum_list</code> function when we pass a JIT <code>LinkedList</code>:<pre>    lst = LinkedList()
    [lst.push_front(i) for i in range(10000)]
    %timeit sum_list(lst)
    106 µs ± 2.64 µs per loop
    %timeit sum_list.py_func(lst)
    2.42 ms ± 51.8 µs per loop</pre></li>
			</ol>
			<p>Interestingly, when using a JIT class from a compiled function, we obtain a substantial performance improvement against the pure Python version. However, using the JIT class from the original <code>sum_list.py_func</code> actually results in a worse performance. Ensure that you use JIT classes only inside compiled functions!</p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor093"/>Limitations in Numba</h2>
			<p>There are <a id="_idIndexMarker404"/>some instances where Numba cannot properly infer the variable types. In the following example, we define a function that takes a nested list of integers and returns the sum of the element in every sublist. In this case, Numba will raise a warning:</p>
			<pre>    a = [[0, 1, 2], 
         [3, 4], 
         [5, 6, 7, 8]]
    @nb.jit
    def sum_sublists(a):
        result = []
        for sublist in a:
            result.append(sum(sublist))
        return result
    sum_sublists(a)
    # NumbaWarning: Compilation is falling back to object 
      mode WITH looplifting enabled because Function 
        "sum_sublists" failed type inference...</pre>
			<p>The problem<a id="_idIndexMarker405"/> with this code is that Numba is not able to determine the list type and fails. A way to fix this problem is to help the compiler determine the right type by initializing the list with a sample element and removing it at the end:</p>
			<pre>    @nb.jit
    def sum_sublists(a):
        result = [0]
        for sublist in a:
            result.append(sum(sublist))
        return result[1:]</pre>
			<p>Among other features that are not yet implemented in the Numba compiler are function and class definitions, <code>list</code>, <code>set</code>, and <code>dict</code> comprehensions, generators, the <code>with</code> statement, and <code>try</code> and <code>except</code> blocks. Note, however, that many of these features may become supported in the future.</p>
			<p>Overall, we have seen multiple approaches of working with Numba to speed up our applications, such as type specializations, NumPy's universal functions, and JIT classes. We will now move on to our second main topic in this chapter – PyPy.</p>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor094"/>The PyPy project</h1>
			<p>PyPy is <a id="_idIndexMarker406"/>a very ambitious project at improving the performance of the Python interpreter. The way PyPy improves performance is by automatically compiling slow sections of the code at runtime.</p>
			<p>PyPy is written in a special language <a id="_idIndexMarker407"/>called <strong class="bold">RPython</strong> (rather than C) that allows developers to implement advanced features and improvements quickly and reliably. RPython means <strong class="bold">Restricted Python</strong> because it implements a restricted subset of the Python language targeted to the compiler development.</p>
			<p>As of today, PyPy version 7.3.5 supports a lot of Python features and is a possible choice for a large variety of applications, such as game and web development. PyPy compiles code using a very clever <a id="_idIndexMarker408"/>strategy called <strong class="bold">tracing JIT compilation</strong>. At first, the code is executed normally using interpreter calls. PyPy then starts to profile the code and identifies the most intensive loops. After the identification takes place, the compiler then observes (<em class="italic">traces</em>) the operations and can compile its optimized, interpreter-free version.</p>
			<p>Once an optimized version of the code is present, PyPy can run the slow loop much faster than the interpreted version.</p>
			<p>This strategy can be contrasted with what Numba does. In Numba, the units of compilation are methods and functions, while the PyPy focus is just slow loops. Overall, the focus of the projects is also very different, as Numba has limited scope for numerical code and requires a lot of instrumentation, while PyPy aims at replacing the CPython interpreter.</p>
			<p>In this section, we will demonstrate and benchmark PyPy on our particle simulator application. We will begin by setting up Python and then look at running a particle simulator in PyPy.</p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor095"/>Setting up PyPy</h2>
			<p>PyPy is <a id="_idIndexMarker409"/>distributed as a precompiled binary that can be downloaded<a id="_idIndexMarker410"/> from <a href="http://pypy.org/download.html">http://pypy.org/download.html</a>, and it currently supports Python versions 2.7 and 3.7. In this chapter, we will demonstrate the usage of the 3.7 version.</p>
			<p>Once PyPy is downloaded and unpacked, you can locate the interpreter in the <code>bin/pypy</code> directory relative to the unpacked archive. You can initialize a new virtual environment, where we can install additional packages using the following command:</p>
			<pre>$ /path/to/bin/pypy -m ensurepip
$ /path/to/bin/pypy -m pip install virtualenv
$ /path/to/bin/virtualenv my-pypy-env</pre>
			<p>To activate the environment, we will use the following command:</p>
			<pre>$ source my-pypy-env/bin/activate</pre>
			<p>At this <a id="_idIndexMarker411"/>point, you can verify that the binary Python is linked to the PyPy executable by typing <code>python -V</code>. At this point, we can go ahead and install some packages we may need. Note that PyPy may have limited support for software that uses the Python C API (most notably, packages such as <code>numpy</code> and <code>matplotlib</code>). We can go ahead and install them in the usual way:</p>
			<pre>(my-pypy-env) $ pip install numpy matplotlib</pre>
			<p>On certain platforms, the installation of <code>numpy</code> and <code>matplotlib</code> can be tricky. You can skip the installation step and remove any imports on these two packages from the scripts we will run.</p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor096"/>Running a particle simulator in PyPy</h2>
			<p>Now that <a id="_idIndexMarker412"/>we have successfully set up the PyPy installation, we can go ahead and run our particle simulator. As a first step, we will time the particle simulator from <a href="B17499_01_Final_SS_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Benchmarking and Profiling</em>, on the standard Python interpreter. If the virtual environment is still active, you can issue the <code>deactivate</code> command to exit the environment:</p>
			<pre>(my-pypy-env) $ deactivate</pre>
			<p>At this point, we can time our code using the <code>timeit</code> command-line interface:</p>
			<pre>$ python -m timeit --setup "from simul import benchmark" 
  "benchmark()"
10 loops, best of 3: 886 msec per loop</pre>
			<p>We can reactivate the environment and run the exact same code from PyPy. On Ubuntu, you may have problems importing the <code>matplotlib.pyplot</code> module. You can try issuing<a id="_idIndexMarker413"/> the following <code>export</code> command to fix the issue or removing the <code>matplotlib</code> imports from <code>simul.py</code>:</p>
			<pre>$ export MPLBACKEND='agg'</pre>
			<p>Now, we can go ahead and time the code using PyPy:</p>
			<pre>$ source my-pypy-env/bin/activate
(my-pypy-env) $ python -m timeit --setup "from simul import 
  benchmark" "benchmark()"
WARNING: timeit is a very unreliable tool. use perf or 
something else for real measurements
10 loops, average of 7: 106 +- 0.383 msec per loop (using 
standard deviation)</pre>
			<p>Note that we obtained a large (more than eight times) speed-up! PyPy, however, warns us that the <code>timeit</code> module can be unreliable. We can confirm our timings using the <code>perf</code> module, as suggested by PyPy:</p>
			<pre>(my-pypy-env) $ pip install perf
(my-pypy-env) $ python -m perf timeit --setup 'from simul 
  import benchmark' 'benchmark()'
.......
Median +- std dev: 97.8 ms +- 2.3 ms</pre>
			<p>This gives us a more reliable assurance that our speed-up is consistent. Overall, we can see that with a simple reinstallation of Python, we are able to achieve significant speed-up via PyPy.</p>
			<p class="callout-heading">Advanced PyPy</p>
			<p class="callout">Although not within the scope of this chapter, for <a id="_idIndexMarker414"/>more advanced usage of PyPy, one could integrate it with Pyglet for game development and PyLongs and Django for web development.</p>
			<p>Overall, Numba and PyPy together <a id="_idIndexMarker415"/>offer us many options regarding how we might want to go about leveraging JIT compilers to supercharge our Python programs. In the next section, we examine several other options that may be of interest.</p>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor097"/>Other interesting projects</h1>
			<p>Over the years, many projects attempted to improve Python performance through several strategies, and, sadly, many of them failed. As of today, there are a few projects that survive and hold the promise for a faster Python.</p>
			<p>Numba and PyPy are mature projects that are steadily improving over the years. Features are continuously being added, and they hold great promise for the future of Python:</p>
			<ul>
				<li><strong class="bold">Nuitka</strong> is a<a id="_idIndexMarker416"/> program developed by Kay Hayen that compiles Python code to C. At the time of writing (version 0.6.15), it provides extreme compatibility with the Python language and produces efficient code that results in moderate performance improvements over CPython.</li>
			</ul>
			<p>Nuitka is quite different than Cython in the sense that it focuses on extreme compatibility with the Python language, and it doesn't extend the language with additional constructs.</p>
			<ul>
				<li><strong class="bold">Pyston</strong> is a <a id="_idIndexMarker417"/>new interpreter developed by Dropbox that powers JIT compilers. It differs substantially from PyPy as it doesn't employ a tracing JIT but rather a method-at-a-time JIT (similar to what Numba does). Pyston, like Numba, is also built on top of the LLVM compiler infrastructure.</li>
			</ul>
			<p>Pyston is in active development and supports both <strong class="bold">Python 2.7</strong> and <strong class="bold">3.8</strong>. Benchmarks show that it is faster than CPython but slower than PyPy; that said, it is still an interesting project to follow as new features are added and compatibility<a id="_idIndexMarker418"/> is increased.</p>
			<p>At this point, we have been introduced to four different JIT compilers. You may find in your own experience that, when developing an application, different situations and use cases may call for different compilers. It is, therefore, important to explore our options when it comes to using a JIT compiler to speed up our Python code.</p>
			<h1 id="_idParaDest-107"><a id="_idTextAnchor098"/>Summary</h1>
			<p>Numba is a tool that compiles fast, specialized versions of Python functions at runtime. In this chapter, we learned how to compile, inspect, and analyze functions compiled by Numba. We also learned how to implement fast NumPy universal functions that are useful in a wide array of numerical applications. Finally, we implemented more complex data structures using the <code>nb.jitclass</code> decorator. Overall, Numba is built to accelerate numeric loops that are common in scientific computing. As we have seen, Numba works seamlessly with the popular NumPy library.</p>
			<p>Tools such as PyPy allow us to run Python programs unchanged to obtain significant speed improvements. We demonstrated how to set up PyPy, and we assessed the performance improvements on our particle simulator application. We have also seen that, unlike Numba, PyPy doesn't operate on a function level but instead seeks to implement a more efficient interpreter for a whole Python program.</p>
			<p>We also, briefly, described the current ecosystem of the Python compilers and compared them with each other. These discussions will give you the confidence to explore and work with different JIT compilers and select the most appropriate for your applications. In the next chapter, we will see a specialized version of a JIT compiler that is optimized for machine learning operations and tasks.</p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor099"/>Questions</h1>
			<ol>
				<li value="1">What are JIT compilers and why are they useful?</li>
				<li>How does Numba determine the types of variables in a Python program? What happens when these variables are not of the type that Numba works well with?</li>
				<li>What is the high-level idea of tracing a JIT compilation of PyPy?</li>
			</ol>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor100"/>Further reading</h1>
			<ul>
				<li>More on JIT compilers: <a href="https://www.freecodecamp.org/news/just-in-time-compilation-explained/">https://www.freecodecamp.org/news/just-in-time-compilation-explained/</a></li>
			</ul>
		</div>
	</div>
</div>
</body></html>