<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Storing and Processing Users' Data</h1></div></div></div><p>There are several pieces of data that need to be persisted and that don't fit very well into the Datastore or similar storage systems, such as images and media files in general; these are usually big and their size impacts application costs and how they should be uploaded, stored, and served back when requested. In addition, sometimes we need to modify these contents on the server side and the operation can take a long time.</p><p>We will add some features to the Notes application that will raise these kinds of problems, and we will see how App Engine provides everything we need to face them effectively.</p><p>In this chapter, we will cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Adding a form to our application to let users upload images</li><li class="listitem" style="list-style-type: disc">Serving the files uploaded back to the clients</li><li class="listitem" style="list-style-type: disc">Transforming images with the Images service</li><li class="listitem" style="list-style-type: disc">Performing long jobs with the task queue</li><li class="listitem" style="list-style-type: disc">Scheduling tasks</li><li class="listitem" style="list-style-type: disc">Handling e-mail messages from our application</li></ul></div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec25"/>Uploading files to Google Cloud Storage</h1></div></div></div><p>It's<a id="id173" class="indexterm"/> extremely common for a web application<a id="id174" class="indexterm"/> to deal with image files or PDF documents, and Notes is not an exception. It could be very useful for users to attach an image or a document to one or more notes in addition to the title and the description text.</p><p>Storing big chunks of binary data in the Datastore would be inefficient and rather expensive, so we need to use a different, dedicated system: Google Cloud Storage. Cloud Storage lets us <a id="id175" class="indexterm"/>store large files in locations called <strong>buckets</strong>. An application can read and write from multiple buckets and we can set up an <strong>Access Control List</strong> (<strong>ACL</strong>) to <a id="id176" class="indexterm"/>determine who can access a certain bucket and with what permissions. Every App Engine application has its default <a id="id177" class="indexterm"/>bucket associated but we can create, manage, and browse any number of them<a id="id178" class="indexterm"/> through the Developer Console.</p><div><div><div><div><h2 class="title"><a id="ch03lvl2sec19"/>Installing Cloud Storage Client Library</h2></div></div></div><p>To <a id="id179" class="indexterm"/>better interact with <a id="id180" class="indexterm"/>Cloud Storage, we need an external piece of software that is not included in the App Engine runtime environment, which is the <a id="id181" class="indexterm"/>
<strong>GCS Client Library</strong>. This Python library implements functions to easily read and write files inside buckets, handling errors and retries. The following is the detailed list of these functions:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>The</strong> <code class="literal">open()</code> <strong>method</strong>: This <a id="id182" class="indexterm"/>allows us to operate with a file-like buffer on bucket contents</li><li class="listitem" style="list-style-type: disc"><strong>The</strong> <code class="literal">listbucket()</code> <strong>method</strong>: This <a id="id183" class="indexterm"/>retrieves the contents of a bucket</li><li class="listitem" style="list-style-type: disc"><strong>The</strong> <code class="literal">stat()</code> <strong>method</strong>: This <a id="id184" class="indexterm"/>gets metadata for a file in a bucket</li><li class="listitem" style="list-style-type: disc"><strong>The</strong> <code class="literal">delete()</code> <strong>method</strong>: This<a id="id185" class="indexterm"/> removes files from buckets</li></ul></div><p>To install<a id="id186" class="indexterm"/> GCS Client Library, we can use pip:</p><div><pre class="programlisting">
<strong>pip install GoogleAppEngineCloudStorageClient -t &lt;app_root&gt;</strong>
</pre></div><p>It's important to specify the destination directory for the package with the <code class="literal">-t</code> option, as it is the only way to install third-party packages that are not provided by App Engine on the production server. When we deploy the application, all content in the application root will be copied on the remote server, including the <code class="literal">cloudstorage</code> package.</p><p>It's also possible<a id="id187" class="indexterm"/> to clone the <strong>Subversion</strong> (<strong>SVN</strong>) executable and check out the latest version of the source code, provided that we have the <code class="literal">svn</code> repository installed on our system:</p><div><pre class="programlisting">
<strong>svn checkout http://appengine-gcs- client.googlecode.com/svn/trunk/python gcs-client</strong>
</pre></div><p>To check whether the library is working, we can issue the following from the command line and verify that no errors are printed out:</p><div><pre class="programlisting">
<strong>python -c"import cloudstorage"</strong>
</pre></div><div><div><h3 class="title"><a id="note07"/>Note</h3><p>An alternative way to interact with Google Cloud Storage is the <strong>Blobstore API</strong>, bundled <a id="id188" class="indexterm"/>with the App Engine Environment. Blobstore was the first App Engine service to provide cheap and effective storage for big files, and it's still available even though Cloud Storage is more recent and more actively developed. Even if we do not store any data in Blobstore, we will use the Blobstore API with Cloud Storage later in this chapter.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec20"/>Adding a form to upload images</h2></div></div></div><p>We <a id="id189" class="indexterm"/>start adding a field in the HTML<a id="id190" class="indexterm"/> form that we use to create notes so that the user can specify a file to upload. Before the submit button, we insert an input tag:</p><div><pre class="programlisting">&lt;div class="form-group"&gt;
  &lt;label for="uploaded_file"&gt;Attached file:&lt;/label&gt;
  &lt;input type="file" id="uploaded_file" name="uploaded_file"&gt;
&lt;/div&gt;</pre></div><p>We will store all the files for every user in the default bucket under a folder named after the user ID; our application is the only way to access that file if we do not alter the default access control list, so we can enforce security and privacy at the application level. In order to access the uploaded file from the <code class="literal">webapp2</code> request object, we need to rewrite the <code class="literal">post</code> method for the <code class="literal">MainHandler</code> class, but first, we need these import statements at the top of the <code class="literal">main.py</code> module:</p><div><pre class="programlisting">from google.appengine.api import app_identity
import cloudstorage
import mimetypes</pre></div><p>We will see in a moment where to use these modules; this is the code that will be added to the <code class="literal">MainHandler</code> class:</p><div><pre class="programlisting">def post(self):
    user = users.get_current_user()
    if user is None:
        self.error(401)

    bucket_name = app_identity.get_default_gcs_bucket_name()
    uploaded_file = self.request.POST.get('uploaded_file')
    file_name = getattr(uploaded_file, 'filename', None)
    file_content = getattr(uploaded_file, 'file', None)
    real_path = ''
    if file_name and file_content:
        content_t = mimetypes.guess_type(file_name)[0]
        real_path = os.path.join('/', bucket_name, user.user_id(),
                                 file_name)

        with cloudstorage.open(real_path, 'w',
                               content_type=content_t) as f:
            f.write(file_content.read())

    self._create_note(user, file_name)

    logout_url = users.create_logout_url(self.request.uri)
    template_context = {
        'user': user.nickname(),
        'logout_url': logout_url,
    }
    self.response.out.write(
        self._render_template('main.html', template_context))</pre></div><p>We<a id="id191" class="indexterm"/> first retrieve the name of the <a id="id192" class="indexterm"/>default bucket for our application through the <code class="literal">app_identity</code> service by calling its <code class="literal">get_default_gcs_bucket_name()</code>method. Then, we access the <code class="literal">request</code> object to get the value of the <code class="literal">uploaded_file</code> field. When users specify a file to upload, <code class="literal">self.request.POST.get('uploaded_file')</code> returns an instance of the <code class="literal">FileStorage</code> class defined in the <code class="literal">cgi</code> module of the Python standard library. The <code class="literal">FieldStorage</code> object has two fields, <code class="literal">filename</code> and <code class="literal">file</code>, that contain the name and the content of the uploaded file, respectively. If users don't specify a file to be uploaded, the value of the <code class="literal">uploaded_file</code> field becomes an empty string.</p><p>When dealing with an uploaded file, we try to guess its type with the help of the <code class="literal">mimetypes</code> module from the Python standard library, and then we build the full path of the file according to the <code class="literal">/&lt;bucket_name&gt;/&lt;user_id&gt;/&lt;filename&gt;</code> scheme. The last part involves the GCS Client Library; in fact, it lets us open a file for writing on Cloud Storage as we would do on a regular filesystem. We write the content of the uploaded file by calling the <code class="literal">read</code> method on the <code class="literal">file_name</code> object. We finally call the <code class="literal">_create_note</code> method, passing the name of the file as well, so it will be stored inside a <code class="literal">Note</code> instance.</p><div><div><h3 class="title"><a id="note08"/>Note</h3><p>If users upload a file with the same name as another file that's already present in Cloud Storage, the latter will be overwritten with the new data. If we want to handle this issue, some logic should be added, such as either renaming the new file or asking users how to proceed.</p></div></div><p>Before refactoring the <code class="literal">_create_note()</code> method to accept and handle the name of the file attached to a note, we need to add a property to our <code class="literal">Note</code> model class to store the name of the files attached. The model becomes as follows:</p><div><pre class="programlisting">class Note(ndb.Model):
    title = ndb.StringProperty()
    content = ndb.TextProperty(required=True)
    date_created = ndb.DateTimeProperty(auto_now_add=True)
    checklist_items = ndb.KeyProperty("CheckListItem",
                                      repeated=True)
    files = ndb.StringProperty(repeated=True)

    @classmethod
    def owner_query(cls, parent_key):
        return cls.query(ancestor=parent_key).order(
            -cls.date_created)</pre></div><p>Even if <a id="id193" class="indexterm"/>we only support the addition<a id="id194" class="indexterm"/> of a single file during the note creation, we store a list of filenames so that we already provide support for multiple attachments in a single note.</p><p>Back in the <code class="literal">main.py</code> module, we refactor the <code class="literal">_create_note()</code> method as follows:</p><div><pre class="programlisting">@ndb.transactional
def _create_note(self, user, file_name):
    note = Note(parent=ndb.Key("User", user.nickname()),
                title=self.request.get('title'),
                content=self.request.get('content'))
    note.put()

    item_titles = self.request.get('checklist_items').split(',')
    for item_title in item_titles:
        item = CheckListItem(parent=note.key, title=item_title)
        item.put()
        note.checklist_items.append(item.key)

    if file_name:
       note.files.append(file_name)

   note.put()</pre></div><p>When the <code class="literal">file_name</code> parameter is not set to the <code class="literal">None</code> value, we add the name of the file and update the <code class="literal">Note</code> entity. We can now run the code and try to upload a file when creating a note. The code we wrote so far only stores the uploaded file without any feedback, so to check whether everything is working, we need to use the Blobstore viewer on the local Development Console. If we're running the application on production servers, we can use the Cloud Storage interface on Google Developer Console to list the contents of the default bucket.</p><div><div><h3 class="title"><a id="note09"/>Note</h3><p>At the time of writing this, the local development server emulates Cloud Storage in the very same way as it emulates Blobstore, and this is why we will only find a Blobstore viewer in the Development Console.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec21"/>Serving files from Cloud Storage</h2></div></div></div><p>As we<a id="id195" class="indexterm"/> didn't specify an<a id="id196" class="indexterm"/> Access Control List for the default bucket, it is only<a id="id197" class="indexterm"/> accessible from the Developer Console upon authentication or through the Notes application. This is fine as long as we want to keep files private to the user who performed the upload but we need to provide a URL for our application where these files can be retrieved. For example, if a user wants to retrieve the file named <code class="literal">example.png</code>, the URL could be <code class="literal">/media/example.png</code>. We need to provide a request handler for such URLs, checking whether the currently logged-in user has uploaded the requested file or not and provide a response accordingly. In the <code class="literal">main.py</code> module, we add the following class:</p><div><pre class="programlisting">class MediaHandler(webapp2.RequestHandler):
    def get(self, file_name):
        user = users.get_current_user()
        bucket_name = app_identity.get_default_gcs_bucket_name()
        content_t = mimetypes.guess_type(file_name)[0]
        real_path = os.path.join('/', bucket_name, user.user_id(),
                                 file_name)

        try:
            with cloudstorage.open(real_path, 'r') as f:
                self.response.headers.add_header('Content-Type',
                                                 content_t)
                self.response.out.write(f.read())
        except cloudstorage.errors.NotFoundError:
            self.abort(404)</pre></div><p>After determining the currently logged-in user, we build the full path to the requested file using the same scheme we used to store the <code class="literal">/&lt;bucket_name&gt;/&lt;user_id&gt;/&lt;filename&gt;</code> file. If the file does not exist, GCS Client Library raises a <code class="literal">NotFoundError</code> error and we serve a <strong>404: Not Found</strong> courtesy page using the <code class="literal">abort()</code> method of the request handler. If the file is actually in Cloud Storage, we open it to read with the usual file-like interface provided by GCS Client Library, and we write its content in the response body after setting the right <code class="literal">Content-Type</code> HTTP header. This way, we cannot access any file uploaded by other users even if we know the name of the file, because our user ID will be used to determine the full path of the file.</p><p>To use the <code class="literal">MediaHandler</code> class, we add a tuple to the <code class="literal">WSGIApplication</code> constructor:</p><div><pre class="programlisting">app = webapp2.WSGIApplication([
    (r'/', MainHandler),
    (r'/media/(?P&lt;file_name&gt;[\w.]{0,256})', MediaHandler),
], debug=True)</pre></div><p>The regular expression tries to match any URL that starts with the <code class="literal">/media/</code> path followed by a filename. When matching, the regular expression group named <code class="literal">file_name</code> is passed to the <code class="literal">get()</code> method of the <code class="literal">MediaHandler</code> class as a parameter.</p><p>The last <a id="id198" class="indexterm"/>step is to add a link for <a id="id199" class="indexterm"/>each file attached to a note in the main page so<a id="id200" class="indexterm"/> that users can download them. We simply add a <code class="literal">for</code> iteration on the <code class="literal">main.html</code> template right before the iteration of the checklist items:</p><div><pre class="programlisting">{% if note.files %}
&lt;ul&gt;
  {% for file in note.files %}
  &lt;li class="file"&gt;&lt;a href="/media/{{ file }}"&gt;{{ file }}&lt;/a&gt;&lt;/li&gt;
  {% endfor %}
&lt;/ul&gt;
{% endif %}</pre></div><p>We finally add the CSS <code class="literal">file</code> class to <code class="literal">li</code> elements to distinguish files from checklist items; we add the corresponding styles to the <code class="literal">note.css</code> file:</p><div><pre class="programlisting">div.note &gt; ul &gt; li.file {
    border: 0;
    background: #0070B3;
}

li.file &gt; a {
    color: white;
    text-decoration: none;
}</pre></div><p>With this updated style sheet, the background for file items has a different color from checklist items and the link text color is white.</p></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec22"/>Serving files through Google's Content Delivery Network</h2></div></div></div><p>We are currently serving<a id="id201" class="indexterm"/> files attached to the notes with our WSGI application through<a id="id202" class="indexterm"/> the <code class="literal">MediaHandler</code> request handler class, and this is very convenient because we can perform security checks and ensure that users only get files they have previously updated. This approach has several drawbacks, though: the application is less efficient compared to a regular web server and we consume resources such as memory and bandwidth, which could potentially cost us a lot of money.</p><p>There is an alternative, however; if we relax the requirements for our Notes application and allow the contents to be publicly available, we can deliver such files with low latency from a highly optimized and cookie-less infrastructure: the <strong>Google Content Delivery Network (CDN)</strong>. How to do this depends on which kind of files we have to deliver: images <a id="id203" class="indexterm"/>or <a id="id204" class="indexterm"/>any other <strong>MIME</strong> type.</p><div><div><div><div><h3 class="title"><a id="ch03lvl3sec06"/>Serving images</h3></div></div></div><p>If we are <a id="id205" class="indexterm"/>dealing with an image<a id="id206" class="indexterm"/> file, we can use the Images service to generate a URL, which is public but not guessable, to reach content stored in Cloud Storage. First, we need to compute an encoded key representing the file in Cloud Storage that we want to serve; to do this, we use the <code class="literal">create_gs_key()</code> method provided by the Blobstore API. We then use the <code class="literal">get_serving_url()</code> method provided by the Images service to generate a serving URL for the encoded key. If we need to serve the same image with different sizes—for example, to provide a thumbnail—there is no need to store the same file multiple times; in fact, we can specify a size for the image we want to deliver and the CDN will take care of it. We need to import the packages needed at the top of the <code class="literal">main.py</code> module:</p><div><pre class="programlisting">from google.appengine.api import images
from google.appengine.ext import blobstore</pre></div><p>For convenience, we add a <code class="literal">_get_urls_for()</code> method to the <code class="literal">MainHandler</code> class we can call whenever we want to get serving URLs for a file in Cloud Storage:</p><div><pre class="programlisting">def _get_urls_for(self, file_name):
    user = users.get_current_user()
    if user is None:
        return

    bucket_name = app_identity.get_default_gcs_bucket_name()
    path = os.path.join('/', bucket_name, user.user_id(),
                        file_name)
    real_path = '/gs' + path
    key = blobstore.create_gs_key(real_path)
    url = images.get_serving_url(key, size=0)
    thumbnail_url = images.get_serving_url(key, size=150,
                                           crop=True)
    return url, thumbnail_url</pre></div><p>The method takes the filename as a parameter and builds the full path to Cloud Storage with the slightly different <code class="literal">/gs/&lt;bucket_name&gt;/&lt;user_id&gt;/&lt;filename&gt;</code> scheme (notice the <code class="literal">/gs</code> string that we need to prefix only when generating the encoded key). The real path to the file is then passed to the <code class="literal">create_gs_key()</code> function, which generates an encoded key, and then we call the <code class="literal">get_serving_url()</code> method twice: once to generate the URL for the full-sized image and then to generate the URL for a cropped thumbnail with a size of 150 pixels. Finally, both the URLs are returned. These URLs will be permanently available unless we call the <code class="literal">delete_serving_url()</code> method from the Images service passing the same key. If we don't specify the <code class="literal">size</code> parameter, the CDN will serve an optimized version of the image that is smaller in size by default; explicitly passing the <code class="literal">size=0</code> parameter to the first call to the <code class="literal">get_serving_url()</code> function will make the CDN serve the original image.</p><p>We can improve the data model by providing a new kind that describes a file attached to a note. In the <code class="literal">models.py</code> module, we add the following:</p><div><pre class="programlisting">class NoteFile(ndb.Model):
    name = ndb.StringProperty()
    url = ndb.StringProperty()
    thumbnail_url = ndb.StringProperty()
    full_path = ndb.StringProperty()</pre></div><p>We store the name, the two URLs, and the full path in Cloud Storage for each file. We then reference a <code class="literal">NoteFile</code> instance instead of the plain filename from the <code class="literal">Note</code> model:</p><div><pre class="programlisting">class Note(ndb.Model):
    title = ndb.StringProperty()
    content = ndb.TextProperty(required=True)
    date_created = ndb.DateTimeProperty(auto_now_add=True)
    checklist_items = ndb.KeyProperty("CheckListItem",
                                      repeated=True)
    files = ndb.KeyProperty("NoteFile",
                            repeated=True)

    @classmethod
    def owner_query(cls, parent_key):
        return cls.query(ancestor=parent_key).order(
            -cls.date_created)</pre></div><p>To store data according to the new model, we refactor the <code class="literal">_create_note()</code> method:</p><div><pre class="programlisting">@ndb.transactional
def _create_note(self, user, file_name, file_path):
    note = Note(parent=ndb.Key("User", user.nickname()),
                title=self.request.get('title'),
                content=self.request.get('content'))
    note.put()

    item_titles = self.request.get('checklist_items').split(',')
    for item_title in item_titles:
        item = CheckListItem(parent=note.key, title=item_title)
        item.put()
        note.checklist_items.append(item.key)
    
    if file_name and file_path:
        url, thumbnail_url = self._get_urls_for(file_name)

        f = NoteFile(parent=note.key, name=file_name,
                     url=url, thumbnail_url=thumbnail_url,
                     full_path=file_path)
        f.put()
        note.files.append(f.key)

        note.put()</pre></div><p>We <a id="id207" class="indexterm"/>generate the URLs and create <a id="id208" class="indexterm"/>the <code class="literal">NoteFile</code> instance, adding it to the <code class="literal">Note</code> entity group. In the <code class="literal">post()</code> method of the <code class="literal">MainHandler</code> class, we now call the <code class="literal">_create_note()</code> method as follows:</p><div><pre class="programlisting">self._create_note(user, file_name, real_path)</pre></div><p>In the HTML template, we add this code:</p><div><pre class="programlisting">{% if note.files %}
&lt;ul&gt;
  {% for file in note.files %}
  &lt;li class="file"&gt;
    &lt;a href="{{ file.get().url }}"&gt;
      &lt;img src="img/{{ file.get().thumbnail_url }}"&gt;
    &lt;/a&gt;
  &lt;/li&gt;
  {% endfor %}
&lt;/ul&gt;
{% endif %}</pre></div><p>Instead of the name of the file, we show the thumbnail inside a link pointing to the full-sized version of the image.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec07"/>Serving other types of files</h3></div></div></div><p>We<a id="id209" class="indexterm"/> cannot use the Images service on file types that are not images, so we need to follow a different strategy in this case. Files stored in Cloud Storage that are publicly accessible can be reached by composing the URL of Google CDN with their full path.</p><p>The first thing to do, then, is to change the default ACL when we save the files in the <code class="literal">post()</code> method of the <code class="literal">MainHandler</code> class:</p><div><pre class="programlisting">with cloudstorage.open(real_path, 'w', content_type=content_t,
                      options={'x-goog-acl': 'public-read'}) as f:
    f.write(file_content.read())</pre></div><p>The <code class="literal">options</code> parameter<a id="id210" class="indexterm"/> for the <code class="literal">open()</code> method of GCS Client Library lets us specify a dictionary of strings containing additional headers to pass to the Cloud Storage service: in this case, we set the <code class="literal">x-goog-acl</code> header to the <code class="literal">public-read</code> value so that the file will be publicly available. From now on, we could reach that file with a URL of the <code class="literal">http://storage.googleapis.com/&lt;bucket_name&gt;/&lt;file_path&gt;</code> type, so let's add the code to <a id="id211" class="indexterm"/>compose and store such URLs for files that are not images.</p><p>In the <code class="literal">_get_urls_for()</code> method, we catch errors of the <code class="literal">TransformationError</code> or <code class="literal">NotImageError</code> type assuming that if the Images service failed to handle a certain file, that file is not an image:</p><div><pre class="programlisting">def _get_urls_for(self, file_name):
    user = users.get_current_user()
    if user is None:
        return

    bucket_name = app_identity.get_default_gcs_bucket_name()
    path = os.path.join('/', bucket_name, user.user_id(),
                        file_name)
    real_path = '/gs' + path
    key = blobstore.create_gs_key(real_path)
    try:
        url = images.get_serving_url(key, size=0)
        thumbnail_url = images.get_serving_url(key, size=150,
                                               crop=True)
    except images.TransformationError, images.NotImageError:
        url = "http://storage.googleapis.com{}".format(path)
        thumbnail_url = None

    return url, thumbnail_url</pre></div><p>If the file type is not supported by the Images service, we compose the <code class="literal">url</code> parameter as stated before and set the <code class="literal">thumbnail_url</code> variable to the <code class="literal">None</code> value.</p><p>In the HTML template, we will show the filename instead of the thumbnail for files that are not images:</p><div><pre class="programlisting">{% if note.files %}
&lt;ul&gt;
  {% for file in note.files %}
  {% if file.get().thumbnail_url %}
  &lt;li class="file"&gt;
    &lt;a href="{{ file.get().url }}"&gt;
      &lt;img src="img/{{ file.get().thumbnail_url }}"&gt;
    &lt;/a&gt;
  &lt;/li&gt;
  {% else %}
  &lt;li class="file"&gt;
    &lt;a href="{{ file.get().url }}"&gt;{{ file.get().name }}&lt;/a&gt;
  &lt;/li&gt;
  {% endif %}
  {% endfor %}
&lt;/ul&gt;
{% endif %}</pre></div></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec26"/>Transforming images with the Images service</h1></div></div></div><p>We<a id="id212" class="indexterm"/> already used the App Engine Images<a id="id213" class="indexterm"/> service to serve images through Google's CDN, but there's a lot more it can do. It can resize, rotate, flip, crop images, and composite multiple images into a single file. It can enhance pictures using a predefined algorithm. It can convert an image from and to several formats. The service can also provide information about an image, such as its format, width, height, and a histogram of color values.</p><div><div><h3 class="title"><a id="note10"/>Note</h3><p>To <a id="id214" class="indexterm"/>use the Images service on the local development server, we need to download and install the <strong>Python Imaging Library</strong> (<strong>PIL</strong>) package or, alternatively, the <code class="literal">pillow</code> package.</p></div></div><p>We <a id="id215" class="indexterm"/>can pass the image data to the service <a id="id216" class="indexterm"/>directly from our application or specifying a resource stored in Cloud Storage. To see how this works, we add a function to our Notes application that users can trigger to shrink all the images attached to any note in order to save space in Cloud Storage. To do this, we add a dedicated request handler to the <code class="literal">main.py</code> module, which will be invoked when users hit the <code class="literal">/shrink</code> URL:</p><div><pre class="programlisting">class ShrinkHandler(webapp2.RequestHandler):
    def _shrink_note(self, note):
        for file_key in note.files:
            file = file_key.get()
            try:
                with cloudstorage.open(file.full_path) as f:
                    image = images.Image(f.read())
                    image.resize(640)
                    new_image_data = image.execute_transforms()

                content_t = images_formats.get(str(image.format))
                with cloudstorage.open(file.full_path, 'w',
                                     content_type=content_t) as f:
                    f.write(new_image_data)

            except images.NotImageError:
                pass

    def get(self):
        user = users.get_current_user()
        if user is None:
            login_url = users.create_login_url(self.request.uri)
            return self.redirect(login_url)

        ancestor_key = ndb.Key("User", user.nickname())
        notes = Note.owner_query(ancestor_key).fetch()

        for note in notes:
            self._shrink_note(note)

        self.response.write('Done.')</pre></div><p>In the <code class="literal">get()</code> method, we load all the notes belonging to the current logged in user from the Datastore, and then we invoke the <code class="literal">_shrink_note()</code> method on each of them. For each file attached to a note, we check whether it is an image; if not, we catch the error and pass to the next one. If the file is actually an image, we open the file with GCS Client Library<a id="id217" class="indexterm"/> and pass the image data to the <code class="literal">Image</code> class constructor. Image objects wrap image data and provide an interface to manipulate <a id="id218" class="indexterm"/>and get information for the wrapped image. Transformations are not applied immediately; they are added to a queue that is processed when we invoke the <code class="literal">execute_transforms()</code> method on the <code class="literal">Image</code> instance. In our case, we apply just one transformation, resizing the image to 640 pixel width. The <a id="id219" class="indexterm"/>
<code class="literal">execute_transforms()</code> method returns the transformed image data we use to overwrite the original file. When writing the new image data on Cloud Storage, we need to specify the content type for the file again: we derive the right content type from the <code class="literal">format</code> property of the <code class="literal">image</code> object. This value is an integer that has to be mapped to a content type string; we do this by adding this dictionary at the top of the <code class="literal">main.py</code> module:</p><div><pre class="programlisting">images_formats = {
    '0': 'image/png',
    '1': 'image/jpeg',
    '2': 'image/webp',
    '-1': 'image/bmp',
    '-2': 'image/gif',
    '-3': 'image/ico',
    '-4': 'image/tiff',
}</pre></div><p>We cast the <code class="literal">image.format</code> value to the string and access the right string to pass to the <code class="literal">open()</code> method from GCS Client Library.</p><p>We add the mapping for the <code class="literal">/shrink</code> URL in the <code class="literal">main.py</code> module:</p><div><pre class="programlisting">app = webapp2.WSGIApplication([
    (r'/', MainHandler),
    (r'/media/(?P&lt;file_name&gt;[\w.]{0,256})', MediaHandler),
    (r'/shrink', ShrinkHandler),
], debug=True)</pre></div><p>To let users access this functionality, we add a hyperlink on the main page. We take the opportunity to provide a main menu for our application, changing the <code class="literal">main.html</code> template as follows:</p><div><pre class="programlisting">&lt;h1&gt;Welcome to Notes!&lt;/h1&gt;

&lt;ul class="menu"&gt;
  &lt;li&gt;Hello, &lt;b&gt;{{ user }}&lt;/b&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="{{ logout_url }}"&gt;Logout&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="/shrink"&gt;Shrink images&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;form action="" method="post" enctype="multipart/form-data"&gt;</pre></div><p>To make the menu lay out horizontally, we add these lines to the <code class="literal">notes.css</code> file:</p><div><pre class="programlisting">ul.menu &gt; li {
    display: inline;
    padding: 5px;
    border-left: 1px solid;
}

ul.menu &gt; li &gt; a {
    text-decoration: none;
}</pre></div><p>Users <a id="id220" class="indexterm"/>can now shrink the space taken by images <a id="id221" class="indexterm"/>attached to their notes clicking the corresponding action in the menu on the main page.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec27"/>Processing long jobs with the task queue</h1></div></div></div><p>App<a id="id222" class="indexterm"/> Engine provides a mechanism called <strong>request timer</strong> to<a id="id223" class="indexterm"/> ensure that requests from a client have a finite lifespan, avoiding infinite<a id="id224" class="indexterm"/> loops and preventing an overly aggressive use of the resources from an application. In particular, the request timer raises a <code class="literal">DeadlineExceededError</code> error whenever a request takes more than 60 seconds to complete. We have to take this into consideration if our application provides functionalities that involve complex queries, I/O operations, or image processing. This is the case of the <code class="literal">ShrinkHandler</code> class from the previous paragraph: the number of notes to be loaded and the attached images to be processed could be big enough to make the request last more than 60 seconds. In such cases, we can use the <strong>task queue</strong>, which is a service provided by App Engine that lets us execute operations outside the request / response cycle with a wider time limit of 10 minutes.</p><p>There are<a id="id225" class="indexterm"/> two types of task queue: <strong>push queues</strong>, which are used <a id="id226" class="indexterm"/>for tasks that are automatically processed by the App Engine<a id="id227" class="indexterm"/> infrastructure, and <strong>pull queues</strong>, which let developers<a id="id228" class="indexterm"/> build their own task-consuming strategy either with another App Engine application or externally from another infrastructure. We will use push queues so that we have a turnkey solution from App Engine without worrying about the setup and scalability of external components.</p><p>We will run the shrink images functionality inside a task queue, and to do so, we need to refactor the <code class="literal">ShrinkHandler</code> class: in the <code class="literal">get()</code> method, we will start the task, moving the execution of the query and the image processing to the <code class="literal">post()</code> method. The <code class="literal">post()</code> method<a id="id229" class="indexterm"/> will be invoked by the task queue consumer<a id="id230" class="indexterm"/> infrastructure to process the task.</p><p>We first <a id="id231" class="indexterm"/>need to import the <code class="literal">taskqueue</code> package to use the task queue Python API:</p><div><pre class="programlisting">from google.appengine.api import taskqueue</pre></div><p>Then, we add the <code class="literal">post()</code> method to the <code class="literal">ShrinkHandler</code> class:</p><div><pre class="programlisting">def post(self):
    if not 'X-AppEngine-TaskName' in self.request.headers:
        self.error(403)

    user_email = self.request.get('user_email')
    user = users.User(user_email)

    ancestor_key = ndb.Key("User", user.nickname())
    notes = Note.owner_query(ancestor_key).fetch()

    for note in notes:
        self._shrink_note(note)</pre></div><p>To ensure that we have received a task queue request, we check whether the <code class="literal">X-AppEngine-TaskName</code> HTTP header was set; App Engine strips these kinds of headers if requests come from outside the platform, so we can trust the client. If this header is missing, we set the <code class="literal">HTTP 403: Forbidden</code> response code.</p><p>The request contains a <code class="literal">user_email</code> parameter containing the e-mail of the user who added this task to the queue (we'll see where this parameter has to be set in a moment); we instance a <code class="literal">User</code> object by passing the e-mail address to match a valid user and proceed with image processing.</p><p>The <code class="literal">get()</code> method of the <code class="literal">ShrinkHandler</code> class has to be refactored as follows:</p><div><pre class="programlisting">def get(self):
    user = users.get_current_user()
    if user is None:
        login_url = users.create_login_url(self.request.uri)
        return self.redirect(login_url)

    taskqueue.add(url='/shrink',
                  params={'user_email': user.email()})
    self.response.write('Task successfully added to the queue.')</pre></div><p>After checking whether the user is logged in, we add a task to the queue using the task queue API. We pass the URL mapped to the handler that will perform the job as a parameter and a dictionary containing the parameters we want to pass to the handler. In this case, we set the <code class="literal">user_email</code> parameter we use in the <code class="literal">post()</code> method to load a valid <code class="literal">User</code> instance. After the task is added to the queue, a response is immediately returned, and<a id="id232" class="indexterm"/> when executed, the actual shrinking operation <a id="id233" class="indexterm"/>could last up to 10 minutes.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec28"/>Scheduling tasks with Cron</h1></div></div></div><p>We have<a id="id234" class="indexterm"/> designed the shrink operation as an optional<a id="id235" class="indexterm"/> functionality triggered by users, but we could run it at a determined time interval for every user in order to lower the costs of Cloud Storage. App Engine supports the scheduled execution of jobs with the Cron service; every application has a limited number of Cron jobs available, depending on our billing plan. Cron jobs have the same restrictions as tasks in a task queue, so the request can last up to 10 minutes.</p><p>We first prepare a request handler that will implement the job:</p><div><pre class="programlisting">class ShrinkCronJob(ShrinkHandler):
    def post(self):
        self.abort(405, headers=[('Allow', 'GET')])

    def get(self):
        if 'X-AppEngine-Cron' not in self.request.headers:
            self.error(403)

        notes = Note.query().fetch()
        for note in notes:
            self._shrink_note(note)</pre></div><p>We derive the <code class="literal">ShrinkCronJob</code> class from the <code class="literal">ShrinkHandler</code> class to inherit the <code class="literal">_shrink_note()</code> method. The cron service performs an HTTP request of type <code class="literal">GET</code>, so we should override the <code class="literal">post()</code> method, simply returning a <strong>HTTP 405: Method not allowed</strong> error, thus avoiding someone hitting our handler with an HTTP <code class="literal">POST</code> request. All the logic is implemented in the <code class="literal">get()</code> method of the handler class. To ensure the handler was triggered by the Cron service and not by an external client, we first check whether the request contains the <code class="literal">X-AppEngine-Cron</code> header that is normally stripped by App Engine; if this is not the case, we return a <strong>HTTP 403: Unauthorized</strong> error. Then, we load all the Note entities from the Datastore and invoke the <code class="literal">_shrink_note()</code> method on each of them.</p><p>We then map the <code class="literal">ShrinkCronJob</code> handler to the <code class="literal">/shrink_all</code> URL:</p><div><pre class="programlisting">app = webapp2.WSGIApplication([
    (r'/', MainHandler),
    (r'/media/(?P&lt;file_name&gt;[\w.]{0,256})', MediaHandler),
    (r'/shrink', ShrinkHandler),
    (r'/shrink_all', ShrinkCronJob),
], debug=True)</pre></div><p>Cron jobs<a id="id236" class="indexterm"/> are listed in a <code class="literal">YAML</code> file in the application root, so <a id="id237" class="indexterm"/>we create the <code class="literal">cron.yaml</code> file with the following content:</p><div><pre class="programlisting">cron:
- description: shrink images in the GCS
  url: /shrink_all
  schedule: every day 00:00</pre></div><p>The file contains a list of job definitions with some properties: for each job, we must specify the URL and <code class="literal">schedule</code> properties, containing the URL mapped to the handler implementing the job and the time interval at which the job is executed, respectively, every<a id="id238" class="indexterm"/> day at midnight. We also add the optional <code class="literal">description</code> property containing a string to detail the job.</p><p>The list <a id="id239" class="indexterm"/>of scheduled Cron jobs is updated every time we deploy the application; we can check for jobs' details and status by accessing the Developer Console or the local Development Console.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec29"/>Sending notification e-mails</h1></div></div></div><p>It's very<a id="id240" class="indexterm"/> common for web applications to send notifications to the users, and e-mails are a cheap and effective channel for delivering. The Notes application could benefit from a notification system as well: early in this chapter, we modified the <code class="literal">shrink</code> image function so that it runs in a task queue. Users receive a response immediately, but the actual job is put in a queue and they don't know if and when shrink operations complete successfully.</p><p>As we can send e-mail messages from an App Engine application on behalf of the administrators or users with Google Accounts, we send a message to the user as soon as the shrink operation is completed.</p><p>We first import the mail package in the <code class="literal">main.py</code> module:</p><div><pre class="programlisting">from google.appengine.api import mail</pre></div><p>Then we append the following code to the end of the <code class="literal">post()</code> method in the <code class="literal">ShrinkHandler</code> class:</p><div><pre class="programlisting">sender_address = "Notes Team &lt;notes@example.com&gt;"
subject = "Shrink complete!"
body = "We shrunk all the images attached to your notes!"
mail.send_mail(sender_address, user_email, subject, body)</pre></div><p>All we have to do is invoke the <code class="literal">send_mail()</code> method, passing in the sender address, the destination address, the subject of the e-mail, and the body of the message.</p><p>If we are<a id="id241" class="indexterm"/> running the application on the production server, the <code class="literal">sender_address</code> parameter must contain the registered address on App Engine of one of the administrators, or the message won't be delivered.</p><p>If the application is running on the local development server, App Engine will not send out real e-mails and will show a detailed message on the console instead.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec30"/>Receiving users' data as e-mail messages</h1></div></div></div><p>A less <a id="id242" class="indexterm"/>common but useful feature for a web <a id="id243" class="indexterm"/>application is the ability to receive e-mail messages from its users: for example, a <strong>Customer Relationship Management</strong> (<strong>CRM)</strong> application <a id="id244" class="indexterm"/>could open a support ticket after receiving an e-mail sent out from a user to a certain address, say, <code class="literal">support@example.com</code>.</p><p>To show how this works on App Engine, we add the ability for our users to create notes by sending e-mail messages to the Notes application: the e-mail subject will be used for the title, the message body for the note content, and every file attached to the e-mail message will be stored on Cloud Storage and be attached to the note as well.</p><p>App Engine applications can receive e-mail messages at any address of the <code class="literal">&lt;string&gt;@&lt;appid&gt;.appspotmail.com</code> form; messages are then transformed to HTTP requests to the <code class="literal">/_ah/mail/&lt;address&gt;</code> URL, where a request handler will process the data.</p><p>Before we start, we need to enable the incoming e-mail service, which is disabled by default, so we add the following in our <code class="literal">app.yaml</code> file:</p><div><pre class="programlisting">inbound_services:
- mail</pre></div><p>Then, we need to implement a handler for the e-mail messages, deriving from a specialized <code class="literal">InboundMailHandler</code> request handler class provided by App Engine. Our subclass must override the <code class="literal">receive()</code> method that takes a parameter containing an instance of the <code class="literal">InboundEmailMessage</code> class that we can use to access all the details from the e-mail message we received. We add this new handler to the <code class="literal">main.py</code> module but before proceeding, we need to import the modules and packages required:</p><div><pre class="programlisting">from google.appengine.ext.webapp import mail_handlers
import re</pre></div><p>Then, we start implementing our <code class="literal">CreateNoteHandler</code> class; this is the first part of the code:</p><div><pre class="programlisting">class CreateNoteHandler(mail_handlers.InboundMailHandler):
    def receive(self, mail_message):
        email_pattern = re.compile(
            r'([\w\-\.]+@(\w[\w\-]+\.)+[\w\-]+)')
        match = email_pattern.findall(mail_message.sender)
        email_addr = match[0][0] if match else ''

        try:
            user = users.User(email_addr)
            user = self._reload_user(user)
        except users.UserNotFoundError:
            return self.error(403)

        title = mail_message.subject
        content = ''
        for content_t, body in mail_message.bodies('text/plain'):
            content += body.decode()

        attachments = getattr(mail_message, 'attachments', None)

        self._create_note(user, title, content, attachments)</pre></div><p>The <a id="id245" class="indexterm"/>first part of the code implements a simple<a id="id246" class="indexterm"/> security check: we actually create a note for a certain user only if the e-mail message comes from the same address users registered for their account. We first extract the e-mail address from the <code class="literal">sender</code> field of the <code class="literal">InboundEmailMessage</code> instance contained in the <code class="literal">mail_message</code> parameter with a regular expression. We then instance a <code class="literal">User</code> object representing the owner of the e-mail address that sent the message. If the sender does not correspond to a registered user, App Engine raises a <code class="literal">UserNotFoundError</code> error and we return a <code class="literal">403: Forbidden</code> HTTP response code, otherwise we call the <code class="literal">_reload_user()</code> method.</p><p>If users want to attach a file to their notes, the Notes application needs to know the user ID of the note owner to build the path when storing files on Cloud Storage; the problem is that when we programmatically instance a <code class="literal">User</code> class without calling the <code class="literal">get_current_user()</code> method from the <code class="literal">users</code> API, the <code class="literal">user_id()</code> method of the instance always returns the <code class="literal">None</code> value. At the time of writing this, App Engine does not provide a clean method to determine the user ID from an instance of the <code class="literal">User</code> class, so we implement a workaround by following these steps:</p><div><ol class="orderedlist arabic"><li class="listitem">Assign the <code class="literal">User</code> instance to a field of a Datastore entity, which is called the <code class="literal">UserLoader entity.</code></li><li class="listitem">Store the <code class="literal">UserLoader</code> entity in the Datastore.</li><li class="listitem">Immediately after, load the entity again.</li></ol></div><p>This way, we force the <code class="literal">Users</code> service to fill in all the user data; by accessing the field containing the <code class="literal">User</code> instance in the <code class="literal">UserLoader</code> entity, we will get all the user properties, including the <code class="literal">id</code> property. We perform this operation in a utility method of the handler class:</p><div><pre class="programlisting">def _reload_user(self, user_instance):
    key = UserLoader(user=user_instance).put()
    key.delete(use_datastore=False)
    u_loader = UserLoader.query(
        UserLoader.user == user_instance).get()
    return UserLoader.user</pre></div><p>To force <a id="id247" class="indexterm"/>a clean reload of the entity from the <a id="id248" class="indexterm"/>Datastore, we first need to purge the NDB cache, and we do this by calling the <code class="literal">delete()</code> method on the key passing the <code class="literal">use_datastore=False</code> parameter. We then reload the entity from the Datastore and return the <code class="literal">user</code> property, now containing all the data we need. We add the <code class="literal">UserLoader</code> model class to our <code class="literal">models.py</code> module:</p><div><pre class="programlisting">class UserLoader(ndb.Model):
    user = ndb.UserProperty()</pre></div><p>Back in the <code class="literal">receive()</code> method, we proceed to extract all the data we need from the e-mail message after reloading the <code class="literal">User</code> instance; in order to extract all the data, we need to create a note: the message subject is a simple string that we will use as the note title. Accessing the body is a little bit more complex because e-mail messages might have multiple bodies with different content types, typically plain text or HTML; in this case, we extract only the plain text body and use it as the note content.</p><p>In the case, the e-mail messages have attachments, and the <code class="literal">mail_message</code> instance provides the <code class="literal">attachments</code> attribute: we pass it as a <a id="id249" class="indexterm"/>parameter to the method dedicated to note creation, that is the <code class="literal">_create_note()</code> method. The <code class="literal">_create_note()</code> method runs in a transaction and encapsulates all the logic needed to create a <code class="literal">Note</code> entity:</p><div><pre class="programlisting">@ndb.transactional
def _create_note(self, user, title, content, attachments):

    note = Note(parent=ndb.Key("User", user.nickname()),
                title=title,
                content=content)
    note.put()

    if attachments:
        bucket_name = app_identity.get_default_gcs_bucket_name()
        for file_name, file_content in attachments:
            content_t = mimetypes.guess_type(file_name)[0]
            real_path = os.path.join('/', bucket_name,
                                     user.user_id(), file_name)

            with cloudstorage.open(real_path, 'w',
                    content_type=content_t,
                    options={'x-goog-acl': 'public-read'}) as f:
                f.write(file_content.decode())

            key = blobstore.create_gs_key('/gs' + real_path)
            try:
                url = images.get_serving_url(key, size=0)
                thumbnail_url = images.get_serving_url(key,
                    size=150, crop=True)
            except images.TransformationError,
                   images.NotImageError:
                url = "http://storage.googleapis.com{}".format(
                    real_path)
                thumbnail_url = None

            f = NoteFile(parent=note.key, name=file_name,
                         url=url, thumbnail_url=thumbnail_url,
                         full_path=real_path)
            f.put()
            note.files.append(f.key)

        note.put()</pre></div><p>The <a id="id250" class="indexterm"/>method is quite similar to the method <a id="id251" class="indexterm"/>that has the same name in the <code class="literal">MainHandler</code> class; the main difference is the way in which we access data from the files attached <a id="id252" class="indexterm"/>to the e-mail message. The <code class="literal">attachments</code> parameter is a list of tuples of two elements: one is a string containing the file name and the other is an instance of a <strong>wrapper</strong> class containing the message payload. We use the filename to build the full path to the file in Cloud Storage, and we use the <code class="literal">decode()</code> method to access <a id="id253" class="indexterm"/>the payload data and store it in a file.</p><p>Finally, we map the URL to the handler:</p><div><pre class="programlisting">app = webapp2.WSGIApplication([
    (r'/', MainHandler),
    (r'/media/(?P&lt;file_name&gt;[\w.]{0,256})', MediaHandler),
    (r'/shrink', ShrinkHandler),
    (r'/shrink_all', ShrinkCronJob),
    (r'/_ah/mail/&lt;appid&gt;\.appspotmail\.com', CreateNoteHandler),
], debug=True)</pre></div><p>When testing the application on the local development server, we can use the development console to simulate e-mail sending from a web interface; this function is available<a id="id254" class="indexterm"/> from the bar on the left-hand side by clicking on the <strong>Inbound Mail</strong> menu item.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec31"/>Summary</h1></div></div></div><p>In this chapter, we pushed a lot of features in our Notes application, and we should now be able to leverage the Cloud Storage and use it to store and serve static contents from our applications. We saw the Images API in action, and we should now know how to deal with requests that take a long time, and we also learned how to schedule recurrent tasks. In the last part, we delved into the Mail API capabilities and we learned how App Engine provides a turnkey solution to send and receive e-mail messages.</p><p>In the next chapter, we will take a look at the performance of our application and see where and how we can improve, using advanced features of components we are already using together with more services provided by App Engine.</p></div></body></html>