["```py\n# thread1.py to create simple threads with function\nfrom threading import current_thread, Thread as Thread\nfrom time import sleep\ndef print_hello():\n    sleep(2)\n    print(\"{}: Hello\".format(current_thread().name))\ndef print_message(msg):\n    sleep(1)\n    print(\"{}: {}\".format(current_thread().name, msg))\n# create threads\nt1 = Thread(target=print_hello, name=\"Th 1\")\nt2 = Thread(target=print_hello, name=\"Th 2\")\nt3 = Thread(target=print_message, args=[\"Good morning\"], \n        name=\"Th 3\")\n# start the threads\nt1.start()\nt2.start()\nt3.start()\n# wait till all are done\nt1.join()\nt2.join()\nt3.join()\n```", "```py\nTh 3: Good morning\nTh 2: Hello\nTh 1: Hello\n```", "```py\n#thread2.py to create daemon and non-daemon threads\nfrom threading import current_thread, Thread as Thread\nfrom time import sleep\ndef daeom_func():\n    #print(threading.current_thread().isDaemon())\n    sleep(3)\n    print(\"{}: Hello from daemon\".format           (current_thread().name))\ndef nondaeom_func():\n    #print(threading.current_thread().isDaemon())\n    sleep(1)\n    print(\"{}: Hello from non-daemon\".format(        current_thread().name))\n#creating threads\nt1 = Thread(target=daeom_func, name=\"Daemon Thread\",     daemon=True)\nt2 = Thread(target=nondaeom_func, name=\"Non-Daemon Thread\")\n# start the threads\nt1.start()\nt2.start()\nprint(\"Exiting the main program\")\n```", "```py\nExiting the main program\nNon-Daemon Thread: Hello from non-daemon \n```", "```py\nExiting the main program\nDaemon Thread: Hello from daemon\nNon-Daemon Thread: Hello from non-daemon\n```", "```py\n# thread3a.py when no thread synchronization used\nfrom threading import Thread as Thread\ndef inc():\n    global x\n    for _ in range(1000000):\n        x+=1\n#global variabale\nx = 0\n# creating threads\nt1 = Thread(target=inc, name=\"Th 1\")\nt2 = Thread(target=inc, name=\"Th 2\")\n# start the threads\nt1.start()\nt2.start()\n#wait for the threads\nt1.join()\nt2.join()\nprint(\"final value of x :\", x)\n```", "```py\n# thread3b.py when thread synchronization is used\nfrom threading import Lock, Thread as Thread\ndef inc_with_lock (lock):\n    global x\n    for _ in range(1000000):\n        lock.acquire()\n        x+=1\n        lock.release()\nx = 0\nmylock = Lock()\n# creating threads\nt1 = Thread(target= inc_with_lock, args=(mylock,), name=\"Th     1\")\nt2 = Thread(target= inc_with_lock, args=(mylock,), name=\"Th     2\")\n# start the threads\nt1.start()\nt2.start()\n#wait for the threads\nt1.join()\nt2.join()\nprint(\"final value of x :\", x)\n```", "```py\n# thread5.py with queue and custom Thread class\nfrom queue import Queue\nfrom threading import Thread as Thread\nfrom time import sleep\nclass MyWorker (Thread):\n   def __init__(self, name, q):\n      threading.Thread.__init__(self)\n      self.name = name\n      self.queue = q\n   def run(self):\n      while True:\n          item = self.queue.get()\n          sleep(1)\n          try:\n              print (\"{}: {}\".format(self.name, item))\n          finally:\n            self.queue.task_done()\n#filling the queue\nmyqueue = Queue()\nfor i in range (10):\n    myqueue.put(\"Task {}\".format(i+1))\n# creating threads\nfor i in range (5):\n    worker = MyWorker(\"Th {}\".format(i+1), myqueue)\n    worker.daemon = True\n    worker.start()\nmyqueue.join()\n```", "```py\nresource = {\n    \"api_key\": \"AIzaSyDYKmm85kebxddKrGns4z0\",\n    \"id\": \"0B8TxHW2Ci6dbckVwTRtTl3RUU\",\n    \"fields\": \"files(name, id, webContentLink)\",\n}\n'''API key and id used in the examples are not original, so should be replaced as per your account and shared directory id''' \n```", "```py\n#threads_casestudy.py\nfrom queue import Queue\nfrom threading import Thread\nimport time\nfrom getfilelistpy import getfilelist\nimport gdown\nTHREAD_POOL_SIZE = 1\nresource = {\n    \"api_key\": \"AIzaSyDYKmm85kea2bxddKrGns4z0\",\n    \"id\": \"0B8TxHW2Ci6dbckVweTRtTl3RUU \",\n    \"fields\": \"files(name,id,webContentLink)\",\n}\nclass DownlaodWorker(Thread):\n    def __init__(self, name, queue):\n        Thread.__init__(self)\n        self.name = name\n        self.queue = queue\n    def run(self):\n        while True:\n            # Get the file id and name from the queue\n            item1 = self.queue.get()\n            try:\n                gdown.download( item1['webContentLink'], \n                    './files/{}'.format(item1['name']), \n                    quiet=False)\n            finally:\n                self.queue.task_done()\n```", "```py\ndef get_files(resource):\n        #global files_list\n        res = getfilelist.GetFileList(resource)\n        files_list = res['fileList'][0]\n        return files_list\n```", "```py\ndef main():\n    start_time = time.monotonic()\n    files = get_files(resource)\n    #add files info into the queue\n    queue = Queue()\n    for item in files['files']:\n        queue.put(item)\n    for i in range (THREAD_POOL_SIZE):\n        worker = DownlaodWorker(\"Thread {}\".format(i+1), \n                queue)\n        worker.daemon = True\n        worker.start()\n    queue.join()\n    end_time = time.monotonic()\n    print('Time taken to download: {} seconds'.\n          format( end_time - start_time))\nmain()\n```", "```py\n# process1.py to create simple processes with function\nimport os\nfrom multiprocessing import Process, current_process as cp\nfrom time import sleep\ndef print_hello():\n    sleep(2)\n    print(\"{}-{}: Hello\".format(os.getpid(), cp().name))\ndef print_message(msg):\n    sleep(1)\n    print(\"{}-{}: {}\".format(os.getpid(), cp().name, msg))\ndef main():\n    processes = []\n    # creating process\n    processes.append(Process(target=print_hello, name=\"Process       1\"))\n    processes.append(Process(target=print_hello, name=\"Process       2\"))\n    processes.append(Process(target=print_message,      args=[\"Good morning\"], name=\"Process 3\"))\n    # start the process\n    for p in processes:\n        p.start()\n    # wait till all are done\n    for p in processes:\n        p.join()\n    print(\"Exiting the main process\")\nif __name__ == '__main__':\n    main()\n```", "```py\n# process2.py to create processes using a pool\nimport os\nfrom multiprocessing import Process, Pool, current_process     as cp\nfrom time import sleep\ndef print_message(msg):\n    sleep(1)\n    print(\"{}-{}: {}\".format(os.getpid(), cp().name, msg))\ndef main():\n    # creating process from a pool\n    with Pool(3) as proc:\n        proc.map(print_message, [\"Orange\", \"Apple\", \"Banana\",\n                                 \"Grapes\",\"Pears\"])\n    print(\"Exiting the main process\")\nif __name__ == '__main__':\n    main()\n```", "```py\nmylist = multiprocessing.Array('i', 5)\n```", "```py\nmylist = multiprocessing.Array('i', [1,2,3,4,5])\n```", "```py\nobj = multiprocessing.Value('i')\n```", "```py\n# process3.py to use shared memory ctype objects\nimport multiprocessing\nfrom multiprocessing import Process, Pool, current_process   as cp\ndef inc_sum_list(list, inc_list, sum):\n    sum.value = 0\n    for index, num in enumerate(list):\n        inc_list[index] = num + 1\n        sum.value = sum.value + inc_list[index]\ndef main():\n    mylist = [2, 5, 7]\n    inc_list = multiprocessing.Array('i', 3)\n    sum = multiprocessing.Value('i')\n    p = Process(target=inc_sum_list,                args=(mylist, inc_list, sum))\n    p.start()\n    p.join()\n    print(\"incremented list: \", list(inc_list))\n    print(\"sum of inc list: \", sum.value)\n    print(\"Exiting the main process\")\nif __name__ == '__main__':\n    main()\n```", "```py\n# process4.py to use shared memory using the server process\nimport multiprocessing\nfrom multiprocessing import Process, Manager\ndef insert_data (dict1, code, subject):\n    dict1[code] =  subject\ndef output(dict1):\n    print(\"Dictionary data: \", dict1)\ndef main():\n    with multiprocessing.Manager() as mgr:\n        # create a dictionary in the server process\n        mydict = mgr.dict({100: \"Maths\", 200: \"Science\"})\n        p1 = Process(target=insert_data, args=(mydict, 300,           \"English\"))\n        p2 = Process(target=insert_data, args=(mydict, 400,           \"French\"))\n        p3 = Process(target=output, args=(mydict,))\n        p1.start()\n        p2.start()\n        p1.join()\n        p2.join()\n        p3.start()\n        p3.join()\n    print(\"Exiting the main process\")\nif __name__ == '__main__':\n    main()\n```", "```py\n# process5.py to use queue to exchange data\nimport multiprocessing\nfrom multiprocessing import Process, Queue\ndef copy_data (list, myqueue):\n    for num in list:\n        myqueue.put(num)\ndef output(myqueue):\n    while not myqueue.empty():\n        print(myqueue.get())\ndef main():\n    mylist = [2, 5, 7]\n    myqueue = Queue()\n    p1 = Process(target=copy_data, args=(mylist, myqueue))\n    p2 = Process(target=output, args=(myqueue,))\n    p1.start()\n    p1.join()\n    p2.start()\n    p2.join()\n    print(\"Queue is empty: \",myqueue.empty())\n    print(\"Exiting the main process\")\nif __name__ == '__main__':\n    main()\n```", "```py\n# process6.py to use Pipe to exchange data\nfrom multiprocessing import Process, Pipe\ndef mysender (s_conn):\n    s_conn.send({100, \"Maths\"})\n    s_conn.send({200, \"Science\"})\n    s_conn.send(\"BYE\")\ndef myreceiver(r_conn):\n    while True:\n        msg = r_conn.recv()\n        if msg == \"BYE\":\n            break\n        print(\"Received message : \", msg)\ndef main():\n    sender_conn, receiver_conn= Pipe()\n    p1 = Process(target=mysender, args=(sender_conn, ))\n    p2 = Process(target=myreceiver, args=(receiver_conn,))\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n    print(\"Exiting the main process\")\nif __name__ == '__main__':\n    main()\n```", "```py\n# process7.py to show synchronization and locking\nfrom functools import partial\nfrom multiprocessing import Pool, Manager\ndef printme (lock, msg):\n    lock.acquire()\n    try:\n        print(msg)\n    finally:\n        lock.release()\ndef main():\n    with Pool(3) as proc:\n        lock = Manager().Lock()\n        func = partial(printme,lock)\n        proc.map(func, [\"Orange\", \"Apple\", \"Banana\",\n                                 \"Grapes\",\"Pears\"])\n    print(\"Exiting the main process\")\nif __name__ == '__main__':\n    main()\n```", "```py\n#processes_casestudy.py\nimport time\nfrom multiprocessing import Process, JoinableQueue\nfrom getfilelistpy import getfilelist\nimport gdown\nPROCESSES_POOL_SIZE = 5\nresource = {\n    \"api_key\": \"AIzaSyDYKmm85keqnk4bF1Da2bxddKrGns4z0\",\n    \"id\": \"0B8TxHW2Ci6dbckVwetTlV3RUU\",\n    \"fields\": \"files(name,id,webContentLink)\",\n}\ndef mydownloader( queue):\n    while True:\n        # Get the file id and name from the queue\n        item1 =  queue.get()\n        try:\n            gdown.download(item1['webContentLink'],\n                           './files/{}'.format(item1['name']),\n                           quiet=False)\n        finally:\n            queue.task_done()\n```", "```py\ndef get_files(resource):\n    res = getfilelist.GetFileList(resource)\n    files_list = res['fileList'][0]\n    return files_list\n```", "```py\ndef main ():\n    files = get_files(resource)\n    #add files info into the queue\n    myqueue = JoinableQueue()\n    for item in files['files']:\n        myqueue.put(item)\n    processes = []\n    for id in range(PROCESSES_POOL_SIZE):\n        p = Process(target=mydownloader, args=(myqueue,))\n        p.daemon = True\n        p.start()\n    start_time = time.monotonic()\n    myqueue.join()\n    total_exec_time = time.monotonic() - start_time\n    print(f'Time taken to download: {total_exec_time:.2f}         seconds')\nif __name__ == '__main__':\n    main()\n```", "```py\n#asyncio1.py to build a basic coroutine\nimport asyncio\nimport time\nasync def say(delay, msg):\n    await asyncio.sleep(delay)\n    print(msg)\nprint(\"Started at \", time.strftime(\"%X\"))\nasyncio.run(say(1,\"Good\"))\nasyncio.run(say(2, \"Morning\"))\nprint(\"Stopped at \", time.strftime(\"%X\"))\n```", "```py\nStarted at 15:59:55\nGood\nMorning\nStopped at 15:59:58\n```", "```py\n#asyncio2.py to build and run coroutines in parallel\nimport asyncio\nimport time\nasync def say(delay, msg):\n    await asyncio.sleep(delay)\n    print(msg)\nasync def main ():\n    task1 = asyncio.create_task( say(1, 'Good'))\n    task2 = asyncio.create_task( say(1, 'Morning'))\n    print(\"Started at \", time.strftime(\"%X\"))\n    await task1\n    await task2\n    print(\"Stopped at \", time.strftime(\"%X\"))\nasyncio.run(main())\n```", "```py\nStarted at 16:04:40\nGood\nMorning\nStopped at  16:04:41\n```", "```py\n#asyncio3.py to distribute work via queue\nimport asyncio\nimport random\nimport time\nasync def executer(name, queue):\n    while True:\n        exec_time = await queue.get()\n        await asyncio.sleep(exec_time)\n        queue.task_done()\n        #print(f'{name} has taken  {exec_time:.2f} seconds')\nasync def main ():\n    myqueue = asyncio.Queue()\n    calc_exuection_time = 0\n    for _ in range(10):\n        sleep_for = random.uniform(0.4, 0.8)\n        calc_exuection_time += sleep_for\n        myqueue.put_nowait(sleep_for)\n    tasks = []\n    for id in range(3):\n        task = asyncio.create_task(executer(f'Task-{id+1}',                 myqueue))\n        tasks.append(task)\n    start_time = time.monotonic()\n    await myqueue.join()\n    total_exec_time = time.monotonic() - start_time\n    for task in tasks:\n        task.cancel()\n    await asyncio.gather(*tasks, return_exceptions=True)\n    print(f\"Calculated execution time         {calc_exuection_time:0.2f}\")\n    print(f\"Actual execution time {total_exec_time:0.2f}\")\nasyncio.run(main())\n```", "```py\nCalculated execution time 5.58\nActual execution time 2.05\n```", "```py\n#asyncio_casestudy.py\nimport asyncio\nimport time\nimport aiofiles, aiohttp\nfrom getfilelistpy import getfilelist\nTASK_POOL_SIZE = 5\nresource = {\n    \"api_key\": \"AIzaSyDYKmm85keqnk4bF1DpYa2dKrGns4z0\",\n    \"id\": \"0B8TxHW2Ci6dbckVwetTlV3RUU\",\n    \"fields\": \"files(name, id, webContentLink)\",\n}\nasync def mydownloader(name, queue):\n    while True:\n        # Get the file id and name from the queue\n        item = await queue.get()\n        try:\n            async with aiohttp.ClientSession() as sess:\n                async with sess.get(item['webContentLink']) \n                    as resp:\n                    if resp.status == 200:\n                       f = await aiofiles.open('./files/{}'                         .format(\n                            item['name']), mode='wb')\n                        await f.write(await resp.read())\n                        await f.close()\n        finally:\n            print(f\"{name}: Download completed for \n                        \",item['name'])\n            queue.task_done()\n```", "```py\ndef get_files(resource):\n    res = getfilelist.GetFileList(resource)\n    files_list = res['fileList'][0]\n    return files_list\nasync def main ():\n    files = get_files(resource)\n    #add files info into the queue\n    myqueue = asyncio.Queue()\n    for item in files['files']:\n        myqueue.put_nowait(item)\n    tasks = []\n    for id in range(TASK_POOL_SIZE):\n        task = asyncio.create_task(\n            mydownloader(f'Task-{id+1}', myqueue))\n        tasks.append(task)\n    start_time = time.monotonic()\n    await myqueue.join()\n    total_exec_time = time.monotonic() - start_time\n    for task in tasks:\n        task.cancel()\n    await asyncio.gather(*tasks, return_exceptions=True)\n    print(f'Time taken to download: {total_exec_time:.2f}         seconds')\nasyncio.run(main())\n```"]