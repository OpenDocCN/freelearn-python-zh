["```py\n[2016-06-15 17:57:54,715] INFO in ch10_r10: Sample Message One \n\n[2016-06-15 17:57:54,716] DEBUG in ch10_r10: Debugging \n\n[2016-06-15 17:57:54,720] WARNING in ch10_r10: Something might have gone wrong\n```", "```py\nfrom typing import NamedTuple \n\nclass RawLog(NamedTuple): \n\n    date: str \n\n    level: str \n\n    module: str \n\n    message: str\n```", "```py\n    import re \n\n    from collections.abc import Iterable, Iterator\n    ```", "```py\n    def parse_line_iter( \n\n        source: Iterable[str] \n\n    ) -> Iterator[RawLog]:\n    ```", "```py\n     pattern = re.compile( \n\n            r\"\\[(?P<date>.*?)\\]\\s+\" \n\n            r\"(?P<level>\\w+)\\s+\" \n\n            r\"in\\s+(?P<module>.+?)\" \n\n            r\":\\s+(?P<message>.+)\", \n\n            re.X \n\n        )\n    ```", "```py\n        for line in source:\n    ```", "```py\n            if match := pattern.match(line): \n\n                yield RawLog(*match.groups())\n    ```", "```py\n>>> from pprint import pprint \n\n>>> for item in parse_line_iter(log_lines): \n\n...     pprint(item) \n\nRawLog(date=’2016-04-24 11:05:01,462’, level=’INFO’, module=’module1’, message=’Sample Message One’) \n\nRawLog(date=’2016-04-24 11:06:02,624’, level=’DEBUG’, module=’module2’, message=’Debugging’) \n\nRawLog(date=’2016-04-24 11:07:03,246’, level=’WARNING’, module=’module1’, message=’Something might have gone wrong’)\n```", "```py\n>>> details = list(parse_line_iter(log_lines))\n```", "```py\ntest_example_4_3 = \"\"\" \n\n>>> def gen_func(): \n\n...     print(\"pre-yield\") \n\n...     yield 1 \n\n...     print(\"post-yield\")\n```", "```py\n>>> y = gen_func() \n\n>>> next(y) \n\npre-yield \n\n1 \n\n>>> next(y) \n\npost-yield\n```", "```py\n>>> next(y) \n\nTraceback (most recent call last): \n\n...\n```", "```py\n>>> parse_line_iter(data) \n\n<generator object parse_line_iter at ...>\n```", "```py\nimport datetime \n\nfrom typing import NamedTuple \n\nclass DatedLog(NamedTuple): \n\n    date: datetime.datetime \n\n    level: str \n\n    module: str \n\n    message: str\n```", "```py\ndef parse_date_iter( \n\n    source: Iterable[RawLog] \n\n) -> Iterator[DatedLog]: \n\n    for item in source: \n\n        date = datetime.datetime.strptime( \n\n            item.date, \"%Y-%m-%d %H:%M:%S,%f\" \n\n        ) \n\n        yield DatedLog( \n\n            date, item.level, item.module, item.message \n\n        )\n```", "```py\n>>> for item in parse_date_iter(parse_line_iter(log_lines)): \n\n...     print(item) \n\nDatedLog(date=datetime.datetime(2016, 4, 24, 11, 5, 1, 462000), level=’INFO’, module=’module1’, message=’Sample Message One’) \n\nDatedLog(date=datetime.datetime(2016, 4, 24, 11, 6, 2, 624000), level=’DEBUG’, module=’module2’, message=’Debugging’) \n\nDatedLog(date=datetime.datetime(2016, 4, 24, 11, 7, 3, 246000), level=’WARNING’, module=’module1’, message=’Something might have gone wrong’)\n```", "```py\ndef new_item_iter(source: Iterable[X]) -> Iterator[Y]: \n\n    for item in source: \n\n        new_item: Y = some_transformation(item) \n\n        yield new_item\n```", "```py\nimport datetime \n\nfrom recipe_01 import RawLog, DatedLog \n\ndef parse_date_iter( \n\n    source: Iterable[RawLog] \n\n) -> Iterator[DatedLog]: \n\n    for item in source: \n\n        date = datetime.datetime.strptime( \n\n            item.date, \"%Y-%m-%d %H:%M:%S,%f\" \n\n        ) \n\n        yield DatedLog( \n\n            date, item.level, item.module, item.message \n\n        )\n```", "```py\ndef parse_date(item: RawLog) -> DatedLog: \n\n    date = datetime.datetime.strptime( \n\n        item.date, \"%Y-%m-%d %H:%M:%S,%f\") \n\n    return DatedLog( \n\n        date, item.level, item.module, item.message)\n```", "```py\ndef parse_date_iter_y( \n\n    source: Iterable[RawLog] \n\n) -> Iterator[DatedLog]: \n\n    for item in source: \n\n        yield parse_date(item)\n```", "```py\n    (... for item in source)\n    ```", "```py\n    (parse_date(item) for item in source)\n    ```", "```py\n    def parse_date_iter_g( \n\n        source: Iterable[RawLog] \n\n    ) -> Iterator[DatedLog]: \n\n      return (parse_date(item) for item in source)\n    ```", "```py\n    map(parse_date, source)\n    ```", "```py\n    def parse_date_iter_m( \n\n        source: Iterable[RawLog] \n\n    ) -> Iterator[DatedLog]: \n\n        return map(parse_date, source)\n    ```", "```py\ndef my_map2(f: Callable[[P], Q], source: Iterable[P]) -> Iterator[Q]: \n\n    return (f(item) for item in source) \n```", "```py\n>>> def mul(a, b): \n\n...     return a * b \n\n>>> list_1 = [2, 3, 5, 7] \n\n>>> list_2 = [11, 13, 17, 23]\n```", "```py\n>>> list(map(mul, list_1, list_2)) \n\n[22, 39, 85, 161]\n```", "```py\n>>> total_time = datetime.timedelta(0) \n\n>>> total_fuel = 0 \n\n>>> for row in datetime_gen: \n\n...     total_time += row.engine_off - row.engine_on \n\n...     total_fuel += ( \n\n...         float(row.engine_on_fuel_height) - \n\n...         float(row.engine_off_fuel_height) \n\n... ) \n\n>>> print( \n\n... f\"{total_time.total_seconds()/60/60 = :.2f}, \" \n\n... f\"{total_fuel = :.2f}\")\n```", "```py\n    from typing import NamedTuple \n\n    class CombinedRow(NamedTuple): \n\n        # Line 1 \n\n        date: str \n\n        engine_on_time: str \n\n        engine_on_fuel_height: str \n\n        # Line 2 \n\n        filler_1: str \n\n        engine_off_time: str \n\n        engine_off_fuel_height: str \n\n        # Line 3 \n\n        filler_2: str \n\n        other_notes: str \n\n        filler_3: str\n    ```", "```py\n    from typing import TypeAlias \n\n    from collections.abc import Iterable, Iterator \n\n    RawRow: TypeAlias = list[str] \n\n    def row_merge( \n\n        source: Iterable[RawRow] \n\n    ) -> Iterator[CombinedRow]: \n    ```", "```py\n     cluster: RawRow = [] \n\n        for row in source: \n\n            if all(len(col) == 0 for col in row): \n\n                continue \n\n            elif len(row[0]) != 0: \n\n                # Non-empty column 1: line 1 \n\n                if len(cluster) == 9: \n\n                    yield CombinedRow(*cluster) \n\n                cluster = row.copy() \n\n            else: \n\n                # Empty column 1: line 2 or line 3 \n\n                cluster.extend(row) \n\n        if len(cluster) == 9: \n\n            yield CombinedRow(*cluster)\n    ```", "```py\n    def skip_header_date( \n\n        source: Iterable[CombinedRow] \n\n    ) -> Iterator[CombinedRow]:\n    ```", "```py\n      for row in source: \n\n        if row.date == \"date\": \n\n            continue \n\n        yield row\n    ```", "```py\n    import datetime \n\n    from typing import NamedTuple \n\n    class DatetimeRow(NamedTuple): \n\n        date: datetime.date \n\n        engine_on: datetime.datetime \n\n        engine_on_fuel_height: str \n\n        engine_off: datetime.datetime \n\n        engine_off_fuel_height: str \n\n        other_notes: str\n    ```", "```py\n    def convert_datetime(row: CombinedRow) -> DatetimeRow:\n    ```", "```py\n        travel_date = datetime.datetime.strptime( \n\n            row.date, \"%m/%d/%y\").date() \n\n        start_time = datetime.datetime.strptime( \n\n            row.engine_on_time, \"%I:%M:%S %p\").time() \n\n        start_datetime = datetime.datetime.combine( \n\n            travel_date, start_time) \n\n        end_time = datetime.datetime.strptime( \n\n            row.engine_off_time, \"%I:%M:%S %p\").time() \n\n        end_datetime = datetime.datetime.combine( \n\n            travel_date, end_time) \n\n        return DatetimeRow( \n\n            date=travel_date, \n\n            engine_on=start_datetime, \n\n            engine_off=end_datetime, \n\n            engine_on_fuel_height=row.engine_on_fuel_height, \n\n            engine_off_fuel_height=row.engine_off_fuel_height, \n\n            other_notes=row.other_notes \n\n        )\n    ```", "```py\n>>> row_gen = row_merge(log_rows) \n\n>>> tail_gen = skip_header_date(row_gen) \n\n>>> datetime_gen = (convert_datetime(row) for row in tail_gen)\n```", "```py\nfrom collections.abc import Iterable, Iterator \n\nfrom typing import TypeVar \n\nT = TypeVar(\"T\")\n```", "```py\n def data_filter_iter( \n\n    source: Iterable[T] \n\n) -> Iterator[T]: \n\n    for item in source: \n\n        if should_be_passed(item): \n\n            yield item\n```", "```py\n    def skip_header_date( \n\n        source: Iterable[CombinedRow] \n\n    ) -> Iterator[CombinedRow]: \n\n      for row in source: \n\n        if row.date == \"date\": \n\n            continue \n\n        yield row\n    ```", "```py\n    def pass_non_date(row: CombinedRow) -> bool: \n\n        return row.date != \"date\"\n    ```", "```py\n    def skip_header_date_iter( \n\n        source: Iterable[CombinedRow] \n\n    ) -> Iterator[CombinedRow]: \n\n        for item in source: \n\n            if pass_non_date(item): \n\n                yield item\n    ```", "```py\n    (... for item in source)\n    ```", "```py\n    (item for item in source)\n    ```", "```py\n    (item for item in source if pass_non_date(source))\n    ```", "```py\n    def skip_header_gen( \n\n        source: Iterable[CombinedRow] \n\n    ) -> Iterator[CombinedRow]: \n\n        return ( \n\n            item \n\n            for item in source \n\n            if pass_non_date(item) \n\n        )\n    ```", "```py\n    filter(pass_non_date, source)\n    ```", "```py\nimport datetime \n\ndef row_has_date(row: CombinedRow) -> bool: \n\n    try: \n\n        datetime.datetime.strptime(row.date, \"%m/%d/%y\") \n\n        return True \n\n    except ValueError as ex: \n\n        return False\n```", "```py\n    from functools import reduce\n    ```", "```py\n    def mul(a: int, b: int) -> int: \n\n        return a * b\n    ```", "```py\n    def prod(values: Iterable[float]) -> float: \n\n        return reduce(mul, values, 1)\n    ```", "```py\n     def prod(values: Iterable[int]) -> int: \n\n        return reduce(mul, values, 1)\n    ```", "```py\ndef factorial(n: int) -> int: \n\n    return prod(range(1, n+1))\n```", "```py\n>>> factorial(52) // (factorial(6) * factorial(52 - 6)) \n\n20358520\n```", "```py\nT = TypeVar(\"T\") \n\ndef my_reduce( \n\n    fn: Callable[[T, T], T], \n\n    source: Iterable[T], \n\n    initial: T | None = None \n\n) -> T:\n```", "```py\nfrom collections.abc import Callable\n```", "```py\nlmul: Callable[[int, int], int] = lambda a, b: a * b\n```", "```py\nfrom itertools import takewhile\n```", "```py\n>>> typical_iterator = iter([0, 1, 2, 3, 4]) \n\n>>> sum(typical_iterator) \n\n10 \n\n>>> sum(typical_iterator) \n\n0\n```", "```py\n>>> round( \n\n...     total_fuel(clean_data_iter(row_merge(log_rows))), \n\n...     3 \n\n... ) \n\n7.0\n```", "```py\n    from recipe_03 import row_merge, CombinedRow\n    ```", "```py\n    import datetime \n\n    from dataclasses import dataclass, field \n\n    @dataclass \n\n    class Leg: \n\n        date: str \n\n        start_time: str \n\n        start_fuel_height: str \n\n        end_time: str \n\n        end_fuel_height: str \n\n        other_notes: str \n\n        start_timestamp: datetime.datetime = field(init=False) \n\n        end_timestamp: datetime.datetime = field(init=False) \n\n        travel_hours: float = field(init=False) \n\n        fuel_change: float = field(init=False) \n\n        fuel_per_hour: float = field(init=False)\n    ```", "```py\n    from collections.abc import Iterable, Iterator \n\n    def clean_data_iter( \n\n        source: Iterable[CombinedRow] \n\n    ) -> Iterator[Leg]: \n\n        leg_iter = map(make_Leg, source) \n\n        fitered_source = filter(reject_date_header, leg_iter) \n\n        start_iter = map(start_datetime, fitered_source) \n\n        end_iter = map(end_datetime, start_iter) \n\n        delta_iter = map(duration, end_iter) \n\n        fuel_iter = map(fuel_use, delta_iter) \n\n        per_hour_iter = map(fuel_per_hour, fuel_iter) \n\n        return per_hour_iter\n    ```", "```py\n    def make_Leg(row: CombinedRow) -> Leg: \n\n        return Leg( \n\n            date=row.date, \n\n            start_time=row.engine_on_time, \n\n            start_fuel_height=row.engine_on_fuel_height, \n\n            end_time=row.engine_off_time, \n\n            end_fuel_height=row.engine_off_fuel_height, \n\n            other_notes=row.other_notes, \n\n        )\n    ```", "```py\n    def reject_date_header(row: Leg) -> bool: \n\n        return not (row.date == \"date\")\n    ```", "```py\n    def timestamp( \n\n        date_text: str, time_text: str \n\n    ) -> datetime.datetime: \n\n        date = datetime.datetime.strptime( \n\n            date_text, \"%m/%d/%y\").date() \n\n        time = datetime.datetime.strptime( \n\n            time_text, \"%I:%M:%S %p\").time() \n\n        timestamp = datetime.datetime.combine( \n\n            date, time) \n\n        return timestamp\n    ```", "```py\n    def start_datetime(row: Leg) -> Leg: \n\n          row.start_timestamp = timestamp( \n\n            row.date, row.start_time) \n\n          return row \n\n    def end_datetime(row: Leg) -> Leg: \n\n          row.end_timestamp = timestamp( \n\n            row.date, row.end_time) \n\n          return row\n    ```", "```py\n    def duration(row: Leg) -> Leg: \n\n        travel_time = row.end_timestamp - row.start_timestamp \n\n        row.travel_hours = round( \n\n            travel_time.total_seconds() / 60 / 60, \n\n            1 \n\n        ) \n\n        return row\n    ```", "```py\n    def fuel_use(row: Leg) -> Leg: \n\n        end_height = float(row.end_fuel_height) \n\n        start_height = float(row.start_fuel_height) \n\n        row.fuel_change = start_height - end_height \n\n        return row \n\n    def fuel_per_hour(row: Leg) -> Leg: \n\n        row.fuel_per_hour = row.fuel_change / row.travel_hours \n\n        return row\n    ```", "```py\nfrom statistics import * \n\ndef avg_fuel_per_hour(source: Iterable[Leg]) -> float: \n\n    return mean(row.fuel_per_hour for row in source) \n\ndef stdev_fuel_per_hour(source: Iterable[Leg]) -> float: \n\n    return stdev(row.fuel_per_hour for row in source)\n```", "```py\ndef summary(raw_data: Iterable[list[str]]) -> None: \n\n    data = tuple(clean_data_iter(row_merge(raw_data))) \n\n    m = avg_fuel_per_hour(data) \n\n    s = 2 * stdev_fuel_per_hour(data) \n\n    print(f\"Fuel use {m:.2f} {s:.2f}\")\n```", "```py\n    from collections.abc import Callable, Iterable, Iterator \n\n    from typing import TypeVar \n\n    T = TypeVar(\"T\") \n\n    def find_first( \n\n        fn:  Callable[[T], bool], source: Iterable[T] \n\n    ) -> Iterator[T]: \n\n        for item in source: \n\n            if fn(item): \n\n                yield item \n\n                break \n    ```", "```py\n    lambda i: n % i == 0\n    ```", "```py\n    import math \n\n    def prime(n: int) -> bool: \n\n        factors = find_first( \n\n            lambda i: n % i == 0, \n\n            range(2, int(math.sqrt(n) + 1)) ) \n\n        return len(list(factors)) == 0\n    ```", "```py\n>>> from itertools import takewhile \n\n>>> n = 47 \n\n>>> list(takewhile(lambda i: n % i != 0, range(2, 8))) \n\n[2, 3, 4, 5, 6, 7]\n```", "```py\nreduce(operator.mul, ..., 1)\n```", "```py\nfrom collections.abc import Iterable \n\nfrom functools import reduce \n\nimport operator \n\ndef prod(iterable: Iterable[float]) -> float: \n\n    return reduce(operator.mul, iterable, 1)\n```", "```py\ndef standardize(mean: float, stdev: float, x: float) -> float: \n\n    return (x - mean) / stdev\n```", "```py\nfrom dataclasses import dataclass \n\n@dataclass \n\nclass DataPair: \n\n    x: float \n\n    y: float \n```", "```py\n>>> import statistics \n\n>>> mean_x = statistics.mean(item.x for item in data_1) \n\n>>> stdev_x = statistics.stdev(item.x for item in data_1) \n\n>>> for DataPair in data_1: \n\n...     z_x = standardize(mean_x, stdev_x, DataPair.x) \n\n...     print(DataPair, z_x)\n```", "```py\n    from functools import partial\n    ```", "```py\ndef reduce(function, iterable, initializer=None)\n```", "```py\nprod = partial(reduce(mul, initializer=1))\n```", "```py\n>>> from operator import mul \n\n>>> from functools import reduce \n\n>>> prod = lambda x: reduce(mul, x, 1)\n```", "```py\nfrom collections.abc import Sequence, Callable \n\nimport statistics \n\ndef prepare_z(data: Sequence[DataPair]) -> Callable[[float], float]: \n\n    mean_x = statistics.mean(item.x for item in data_1) \n\n    stdev_x = statistics.stdev(item.x for item in data_1) \n\n    return partial(standardize, mean_x, stdev_x)\n```", "```py\n>>> z = prepare_z(data_1) \n\n>>> for DataPair in data_1: \n\n...     print(DataPair, z(DataPair.x))\n```", "```py\ndocument = { \n\n    \"field\": \"value1\", \n\n    \"field2\": \"value\", \n\n    \"array\": [ \n\n        {\"array_item_key1\": \"value\"}, \n\n        {\"array_item_key2\": \"array_item_value2\"} \n\n    ], \n\n    \"object\": { \n\n        \"attribute1\": \"value\", \n\n        \"attribute2\": \"value2\" \n\n    }, \n\n}\n```", "```py\n    from collections.abc import Iterator \n\n    from typing import Any, TypeAlias \n\n    JSON_DOC: TypeAlias = ( \n\n        None | str | int | float | bool | dict[str, Any] | list[Any] \n\n    ) \n\n    Node_Id: TypeAlias = Any\n    ```", "```py\n    def find_value_sketch( \n\n        value: Any, \n\n        node: JSON_DOC, \n\n        path: list[Node_Id] | None = None \n\n    ) -> Iterator[list[Node_Id]]: \n\n        if path is None: \n\n            path = [] \n\n        match node: \n\n            case dict() as dnode: \n\n                pass  # apply find_value to each key in dnode \n\n            case list() as lnode: \n\n                pass  # apply find_value to each item in lnode \n\n            case _ as pnode: # str, int, float, bool, None \n\n                if pnode == value: \n\n                    yield path\n    ```", "```py\ndef find_value( \n\n    value: Any, \n\n    node: JSON_DOC, \n\n    path: list[Node_Id] | None = None \n\n) -> Iterator[list[Node_Id]]: \n\n    if path is None: \n\n        path = [] \n\n    match node: \n\n        case dict() as dnode: \n\n            for key in sorted(dnode.keys()): \n\n                yield from find_value( \n\n                    value, node[key], path + [key]) \n\n        case list() as lnode: \n\n            for index, item in enumerate(lnode): \n\n                yield from find_value( \n\n                    value, item, path + [index]) \n\n        case _ as pnode: \n\n            # str, int, float, bool, None \n\n            if pnode == value: \n\n                yield path\n```", "```py\n>>> places = list(find_value(’value’, document)) \n\n>>> places \n\n[[’array’, 0, ’array_item_key1’], [’field2’], [’object’, ’attribute1’]]\n```", "```py\nimport math \n\ndef factor_list(x: int) -> list[int]: \n\n    limit = int(math.sqrt(x) + 1) \n\n    for n in range(2, limit): \n\n        q, r = divmod(x, n) \n\n        if r == 0: \n\n            return [n] + factor_list(q) \n\n    return [x]\n```", "```py\ndef factor_iter(x: int) -> Iterator[int]: \n\n    limit = int(math.sqrt(x) + 1) \n\n    for n in range(2, limit): \n\n        q, r = divmod(x, n) \n\n        if r == 0: \n\n            yield n \n\n            yield from factor_iter(q) \n\n            return \n\n    yield x\n```", "```py\n>>> from collections import Counter \n\n>>> Counter(factor_iter(384)) \n\nCounter({2: 7, 3: 1})\n```"]