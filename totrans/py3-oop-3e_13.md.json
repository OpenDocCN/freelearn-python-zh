["```py\nfrom threading import Thread\n\nclass InputReader(Thread):\n    def run(self):\n        self.line_of_text = input()\n\nprint(\"Enter some text and press enter: \")\nthread = InputReader()\nthread.start()\n\ncount = result = 1\nwhile thread.is_alive():\n    result = count * count\n    count += 1\n\nprint(\"calculated squares up to {0} * {0} = {1}\".format(count, result))\nprint(\"while you typed '{}'\".format(thread.line_of_text))\n```", "```py\nEnter some text and press enter:\nhello world\ncalculated squares up to 2448265 * 2448265 = 5993996613696\n```", "```py\n    Enter some text and press enter:\n    hello world\n    calculated squares up to 1 * 1 = 1\n    while you typed 'hello world'  \n```", "```py\nfrom threading import Thread\nimport time\nfrom urllib.request import urlopen\nfrom xml.etree import ElementTree\n\nCITIES = {\n    \"Charlottetown\": (\"PE\", \"s0000583\"),\n    \"Edmonton\": (\"AB\", \"s0000045\"),\n    \"Fredericton\": (\"NB\", \"s0000250\"),\n    \"Halifax\": (\"NS\", \"s0000318\"),\n    \"Iqaluit\": (\"NU\", \"s0000394\"),\n    \"Québec City\": (\"QC\", \"s0000620\"),\n    \"Regina\": (\"SK\", \"s0000788\"),\n    \"St. John's\": (\"NL\", \"s0000280\"),\n    \"Toronto\": (\"ON\", \"s0000458\"),\n    \"Victoria\": (\"BC\", \"s0000775\"),\n    \"Whitehorse\": (\"YT\", \"s0000825\"),\n    \"Winnipeg\": (\"MB\", \"s0000193\"),\n    \"Yellowknife\": (\"NT\", \"s0000366\"),\n}\n\nclass TempGetter(Thread):\n    def __init__(self, city):\n        super().__init__()\n        self.city = city\n        self.province, self.code = CITIES[self.city]\n\n    def run(self):\n        url = (\n            \"http://dd.weatheroffice.ec.gc.ca/citypage_weather/xml/\"\n            f\"{self.province}/{self.code}_e.xml\"\n        )\n        with urlopen(url) as stream:\n            xml = ElementTree.parse(stream)\n            self.temperature = xml.find(\n                \"currentConditions/temperature\"\n            ).text\n\nthreads = [TempGetter(c) for c in CITIES]\nstart = time.time()\nfor thread in threads:\n    thread.start()\n\nfor thread in threads:\n    thread.join()\n\nfor thread in threads:\n    print(f\"it is {thread.temperature}°C in {thread.city}\")\nprint(\n    \"Got {} temps in {} seconds\".format(\n        len(threads), time.time() - start\n    )\n)\n```", "```py\nit is 18.5°C in Charlottetown\nit is 1.6°C in Edmonton\nit is 16.6°C in Fredericton\nit is 18.0°C in Halifax\nit is -2.4°C in Iqaluit\nit is 18.4°C in Québec City\nit is 7.4°C in Regina\nit is 11.8°C in St. John's\nit is 20.4°C in Toronto\nit is 9.2°C in Victoria\nit is -5.1°C in Whitehorse\nit is 5.1°C in Winnipeg\nit is 1.6°C in Yellowknife\nGot 13 temps in 0.29401135444641113 seconds\n```", "```py\nfrom multiprocessing import Process, cpu_count\nimport time\nimport os\n\nclass MuchCPU(Process):\n    def run(self):\n        print(os.getpid())\n        for i in range(200000000):\n            pass\n\nif __name__ == \"__main__\":\n    procs = [MuchCPU() for f in range(cpu_count())]\n    t = time.time()\n    for p in procs:\n        p.start()\n    for p in procs:\n        p.join()\n    print(\"work took {} seconds\".format(time.time() - t))\n```", "```py\n25812\n25813\n25814\n25815\n25816\n25817\n25818\n25819\nwork took 6.97506308555603 seconds\n```", "```py\n26083\n26083\n26083\n26083\n26083\n26083\n26083\n26083\nwork took 26.710845470428467 seconds\n```", "```py\nimport random\nfrom multiprocessing.pool import Pool\n\ndef prime_factor(value):\n    factors = []\n    for divisor in range(2, value - 1):\n        quotient, remainder = divmod(value, divisor)\n        if not remainder:\n            factors.extend(prime_factor(divisor))\n            factors.extend(prime_factor(quotient))\n            break\n    else:\n        factors = [value]\n    return factors\n\nif __name__ == \"__main__\":\n pool = Pool()\n\n    to_factor = [random.randint(100000, 50000000) for i in range(20)]\n results = pool.map(prime_factor, to_factor)\n    for value, factors in zip(to_factor, results):\n        print(\"The factors of {} are {}\".format(value, factors))\n```", "```py\ndef search(paths, query_q, results_q): \n    lines = [] \n    for path in paths: \n        lines.extend(l.strip() for l in path.open()) \n\n    query = query_q.get() \n    while query: \n        results_q.put([l for l in lines if query in l]) \n        query = query_q.get() \n```", "```py\nif __name__ == '__main__': \n    from multiprocessing import Process, Queue, cpu_count \n    from path import path \n    cpus = cpu_count() \n    pathnames = [f for f in path('.').listdir() if f.isfile()] \n    paths = [pathnames[i::cpus] for i in range(cpus)] \n    query_queues = [Queue() for p in range(cpus)] \n    results_queue = Queue() \n\n    search_procs = [ \n        Process(target=search, args=(p, q, results_queue)) \n        for p, q in zip(paths, query_queues) \n    ] \n    for proc in search_procs: proc.start() \n```", "```py\n    for q in query_queues:\n        q.put(\"def\")\n        q.put(None) # Signal process termination\n\n    for i in range(cpus):\n        for match in results_queue.get():\n            print(match)\n    for proc in search_procs:\n        proc.join()\n```", "```py\nfrom concurrent.futures import ThreadPoolExecutor \nfrom pathlib import Path \nfrom os.path import sep as pathsep \nfrom collections import deque \n\ndef find_files(path, query_string): \n    subdirs = [] \n    for p in path.iterdir(): \n        full_path = str(p.absolute()) \n        if p.is_dir() and not p.is_symlink(): \n            subdirs.append(p) \n        if query_string in full_path: \n                print(full_path) \n\n    return subdirs \n\nquery = '.py' \nfutures = deque() \nbasedir = Path(pathsep).absolute() \n\nwith ThreadPoolExecutor(max_workers=10) as executor: \n    futures.append( \n        executor.submit(find_files, basedir, query)) \n    while futures: \n        future = futures.popleft() \n        if future.exception(): \n            continue \n        elif future.done(): \n            subdirs = future.result() \n            for subdir in subdirs: \n                futures.append(executor.submit( \n                    find_files, subdir, query)) \n        else: \n            futures.append(future) \n```", "```py\nimport asyncio\nimport random\n\nasync def random_sleep(counter):\n    delay = random.random() * 5\n    print(\"{} sleeps for {:.2f} seconds\".format(counter, delay))\n    await asyncio.sleep(delay)\n    print(\"{} awakens\".format(counter))\n\nasync def five_sleepers():\n    print(\"Creating five tasks\")\n    tasks = [asyncio.create_task(random_sleep(i)) for i in range(5)]\n    print(\"Sleeping after starting five tasks\")\n    await asyncio.sleep(2)\n    print(\"Waking and waiting for five tasks\")\n    await asyncio.gather(*tasks)\n\nasyncio.get_event_loop().run_until_complete(five_sleepers())\nprint(\"Done five tasks\")\n```", "```py\nCreating five tasks\nSleeping after starting five tasks\n0 sleeps for 3.42 seconds\n1 sleeps for 4.16 seconds\n2 sleeps for 0.75 seconds\n3 sleeps for 3.55 seconds\n4 sleeps for 0.39 seconds\n4 awakens\n2 awakens\nWaking and waiting for five tasks\n0 awakens\n3 awakens\n1 awakens\nDone five tasks\n```", "```py\nimport asyncio\nfrom contextlib import suppress\n\nip_map = {\n    b\"facebook.com.\": \"173.252.120.6\",\n    b\"yougov.com.\": \"213.52.133.246\",\n    b\"wipo.int.\": \"193.5.93.80\",\n    b\"dataquest.io.\": \"104.20.20.199\",\n}\n\ndef lookup_dns(data):\n    domain = b\"\"\n    pointer, part_length = 13, data[12]\n    while part_length:\n        domain += data[pointer : pointer + part_length] + b\".\"\n        pointer += part_length + 1\n        part_length = data[pointer - 1]\n\n    ip = ip_map.get(domain, \"127.0.0.1\")\n\n    return domain, ip\n\ndef create_response(data, ip):\n    ba = bytearray\n    packet = ba(data[:2]) + ba([129, 128]) + data[4:6] * 2\n    packet += ba(4) + data[12:]\n    packet += ba([192, 12, 0, 1, 0, 1, 0, 0, 0, 60, 0, 4])\n    for x in ip.split(\".\"):\n        packet.append(int(x))\n    return packet\n\nclass DNSProtocol(asyncio.DatagramProtocol):\n    def connection_made(self, transport):\n        self.transport = transport\n\n    def datagram_received(self, data, addr):\n        print(\"Received request from {}\".format(addr[0]))\n        domain, ip = lookup_dns(data)\n        print(\n            \"Sending IP {} for {} to {}\".format(\n                domain.decode(), ip, addr[0]\n            )\n        )\n        self.transport.sendto(create_response(data, ip), addr)\n\nloop = asyncio.get_event_loop()\ntransport, protocol = loop.run_until_complete(\n    loop.create_datagram_endpoint(\n        DNSProtocol, local_addr=(\"127.0.0.1\", 4343)\n    )\n)\nprint(\"DNS Server running\")\n\nwith suppress(KeyboardInterrupt):\n    loop.run_forever()\ntransport.close()\nloop.close()\n```", "```py\n    nslookup -port=4343 facebook.com localhost  \n```", "```py\nimport asyncio\nimport json\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef sort_in_process(data):\n    nums = json.loads(data.decode())\n    curr = 1\n    while curr < len(nums):\n        if nums[curr] >= nums[curr - 1]:\n            curr += 1\n        else:\n            nums[curr], nums[curr - 1] = nums[curr - 1], nums[curr]\n            if curr > 1:\n                curr -= 1\n\n    return json.dumps(nums).encode()\n\nasync def sort_request(reader, writer):\n    print(\"Received connection\")\n    length = await reader.read(8)\n    data = await reader.readexactly(int.from_bytes(length, \"big\"))\n    result = await asyncio.get_event_loop().run_in_executor(\n        None, sort_in_process, data\n    )\n    print(\"Sorted list\")\n    writer.write(result)\n    writer.close()\n    print(\"Connection closed\")\n\nloop = asyncio.get_event_loop()\nloop.set_default_executor(ProcessPoolExecutor())\nserver = loop.run_until_complete(\n    asyncio.start_server(sort_request, \"127.0.0.1\", 2015)\n)\nprint(\"Sort Service running\")\n\nloop.run_forever()\nserver.close()\nloop.run_until_complete(server.wait_closed())\nloop.close()\n```", "```py\nimport asyncio\nimport random\nimport json\n\nasync def remote_sort():\n reader, writer = await asyncio.open_connection(\"127.0.0.1\", 2015)\n    print(\"Generating random list...\")\n    numbers = [random.randrange(10000) for r in range(10000)]\n    data = json.dumps(numbers).encode()\n    print(\"List Generated, Sending data\")\n    writer.write(len(data).to_bytes(8, \"big\"))\n    writer.write(data)\n\n    print(\"Waiting for data...\")\n data = await reader.readexactly(len(data))\n    print(\"Received data\")\n    sorted_values = json.loads(data.decode())\n    print(sorted_values)\n    print(\"\\n\")\n    writer.close()\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(remote_sort())\nloop.close()\n```", "```py\nfrom bitarray import bitarray \ndef compress_chunk(chunk): \n    compressed = bytearray() \n    count = 1 \n    last = chunk[0] \n    for bit in chunk[1:]: \n        if bit != last: \n            compressed.append(count | (128 * last)) \n            count = 0 \n            last = bit \n        count += 1 \n    compressed.append(count | (128 * last)) \n    return compressed\n```", "```py\ndef compress_row(row): \n    compressed = bytearray() \n    chunks = split_bits(row, 127) \n    for chunk in chunks: \n        compressed.extend(compress_chunk(chunk)) \n    return compressed\n```", "```py\ndef split_bits(bits, width): \n    for i in range(0, len(bits), width): \n        yield bits[i:i+width]\n```", "```py\ndef compress_in_executor(executor, bits, width): \n    row_compressors = [] \n    for row in split_bits(bits, width): \n        compressor = executor.submit(compress_row, row) \n        row_compressors.append(compressor) \n\n    compressed = bytearray() \n    for compressor in row_compressors: \n        compressed.extend(compressor.result()) \n    return compressed\n```", "```py\nfrom PIL import Image \ndef compress_image(in_filename, out_filename, executor=None): \n    executor = executor if executor else ProcessPoolExecutor() \n    with Image.open(in_filename) as image: \n        bits = bitarray(image.convert('1').getdata()) \n        width, height = image.size \n\n    compressed = compress_in_executor(executor, bits, width) \n\n    with open(out_filename, 'wb') as file: \n        file.write(width.to_bytes(2, 'little')) \n        file.write(height.to_bytes(2, 'little')) \n        file.write(compressed) \n\ndef single_image_main(): \n    in_filename, out_filename = sys.argv[1:3] \n    #executor = ThreadPoolExecutor(4) \n    executor = ProcessPoolExecutor() \n    compress_image(in_filename, out_filename, executor) \n```", "```py\nfrom pathlib import Path \ndef compress_dir(in_dir, out_dir): \n    if not out_dir.exists(): \n        out_dir.mkdir() \n\n    executor = ProcessPoolExecutor() \n    for file in ( \n            f for f in in_dir.iterdir() if f.suffix == '.bmp'): \n        out_file = (out_dir / file.name).with_suffix('.rle') \n        executor.submit( \n            compress_image, str(file), str(out_file)) \n\ndef dir_images_main(): \n    in_dir, out_dir = (Path(p) for p in sys.argv[1:3]) \n    compress_dir(in_dir, out_dir)\n```", "```py\nfrom PIL import Image \nimport sys \n\ndef decompress(width, height, bytes): \n    image = Image.new('1', (width, height)) \n\n    col = 0 \n    row = 0 \n    for byte in bytes: \n        color = (byte & 128) >> 7 \n        count = byte & ~128 \n        for i in range(count): \n            image.putpixel((row, col), color) \n            row += 1 \n        if not row % width: \n            col += 1 \n            row = 0 \n    return image \n\nwith open(sys.argv[1], 'rb') as file: \n    width = int.from_bytes(file.read(2), 'little') \n    height = int.from_bytes(file.read(2), 'little') \n\n    image = decompress(width, height, file.read()) \n    image.save(sys.argv[2], 'bmp') \n```"]