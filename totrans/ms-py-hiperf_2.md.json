["```py\nimport cProfile\nimport re\ncProfile.run('re.compile(\"foo|bar\")')\n```", "```py\n    197 function calls (192 primitive calls) in 0.002 seconds\n\nOrdered by: standard name\n\nncalls  tottime  percall  cumtime  percall filename:lineno(function)\n     1    0.000    0.000    0.001    0.001 <string>:1(<module>)\n     1    0.000    0.000    0.001    0.001 re.py:212(compile)\n     1    0.000    0.000    0.001    0.001 re.py:268(_compile)\n     1    0.000    0.000    0.000    0.000 sre_compile.py:172(_compile_charset)\n     1    0.000    0.000    0.000    0.000 sre_compile.py:201(_optimize_charset)\n     4    0.000    0.000    0.000    0.000 sre_compile.py:25(_identityfunction)\n   3/1    0.000    0.000    0.000    0.000 sre_compile.py:33(_compile)\n```", "```py\nrun(command, filename=None, sort=-1)\n```", "```py\nexec(command, __main__.__dict__, __main__.__dict__)\n```", "```py\nimport cProfile\nimport re\ncProfile.run('re.compile(\"foo|bar\")', 'stats', 'cumtime')\n```", "```py\nrunctx(command, globals, locals, filename=None)\n```", "```py\nexec(command, globals, locals)\n```", "```py\nimport cProfile\ndef runRe():\n    import re \n    cProfile.run('re.compile(\"foo|bar\")')\nrunRe()\n```", "```py\nTraceback (most recent call last): \n  File \"cprof-test1.py\", line 7, in <module> \n    runRe() ...\n  File \"/usr/lib/python2.7/cProfile.py\", line 140, in runctx \n    exec cmd in globals, locals \n  File \"<string>\", line 1, in <module> \nNameError: name 're' is not defined \n```", "```py\nimport cProfile\ndef runRe():\n    import re \n    cProfile.runctx('re.compile(\"foo|bar\")', None, locals())\nrunRe()\n```", "```py\n         194 function calls (189 primitive calls) in 0.000 seconds \n  Ordered by: standard name \n   ncalls  tottime  percall  cumtime  percall filename:lineno(function) \n        1    0.000    0.000    0.000    0.000 <string>:1(<module>) \n        1    0.000    0.000    0.000    0.000 re.py:188(compile) \n        1    0.000    0.000    0.000    0.000 re.py:226(_compile) \n        1    0.000    0.000    0.000    0.000 sre_compile.py:178(_compile_charset) \n        1    0.000    0.000    0.000    0.000 sre_compile.py:207(_optimize_charset) \n        4    0.000    0.000    0.000    0.000 sre_compile.py:24(_identityfunction) \n      3/1    0.000    0.000    0.000    0.000 sre_compile.py:32(_compile) \n        1    0.000    0.000    0.000    0.000 sre_compile.py:359(_compile_info) \n        2    0.000    0.000    0.000    0.000 sre_compile.py:472(isstring) \n        1    0.000    0.000    0.000    0.000 sre_compile.py:478(_code) \n        1    0.000    0.000    0.000    0.000 sre_compile.py:493(compile) \n        5    0.000    0.000    0.000    0.000 sre_parse.py:126(__len__) \n       12    0.000    0.000    0.000    0.000 sre_parse.py:130(__getitem__) \n        7    0.000    0.000    0.000    0.000 sre_parse.py:138(append) \n      3/1    0.000    0.000    0.000    0.000 sre_parse.py:140(getwidth) \n        1    0.000    0.000    0.000    0.000 sre_parse.py:178(__init__) \n       10    0.000    0.000    0.000    0.000 sre_parse.py:182(__next) \n        2    0.000    0.000    0.000    0.000 sre_parse.py:195(match) \n        8    0.000    0.000    0.000    0.000 sre_parse.py:201(get) \n        1    0.000    0.000    0.000    0.000 sre_parse.py:301(_parse_sub) \n        2    0.000    0.000    0.000    0.000 sre_parse.py:379(_parse) \n        1    0.000    0.000    0.000    0.000 sre_parse.py:67(__init__) \n        1    0.000    0.000    0.000    0.000 sre_parse.py:675(parse) \n        3    0.000    0.000    0.000    0.000 sre_parse.py:90(__init__) \n        1    0.000    0.000    0.000    0.000 {_sre.compile} \n       15    0.000    0.000    0.000    0.000 {isinstance} \n    38/37    0.000    0.000    0.000    0.000 {len} \n        2    0.000    0.000    0.000    0.000 {max} \n       48    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects} \n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects} \n        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects} \n        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects} \n        8    0.000    0.000    0.000    0.000 {min} \n        6    0.000    0.000    0.000    0.000 {ord} \n```", "```py\nimport cProfile\n\ndef runRe():\n    import re\n    re.compile(\"foo|bar\")\n\nprof = cProfile.Profile() \nprof.enable() \nrunRe()\nprof.create_stats()\nprof.print_stats()\n```", "```py\n$ python -m cProfile your_script.py -o your_script.profile\n\n```", "```py\nimport pstats\np = pstats.Stats('stats')\np.strip_dirs().sort_stats(-1).print_stats()\n```", "```py\nimport cProfile\nimport pstats\n\ndef runRe():\n    import re\n    re.compile(\"foo|bar\")\nprof = cProfile.Profile()\nprof.enable()\nrunRe()\nprof.create_stats()\n\np = pstats.Stats(prof)\np.print_stats(10, 1.0, '.*.py.*') #print top 10 lines that match the given reg exp.\n\n```", "```py\nimport cProfile\nimport pstats\n\ndef runRe():\n    import re\n    re.compile(\"foo|bar\")\nprof = cProfile.Profile()\nprof.enable()\nrunRe()\nprof.create_stats()\n\np = pstats.Stats(prof)\np.print_callers()\n```", "```py\nimport profile\n\ndef fib(n):\n    if n <= 1:\n  return n\n    else:\n        return fib(n-1) + fib(n-2)\n\ndef fib_seq(n):\n    seq = [ ]\n    if n > 0:\n        seq.extend(fib_seq(n-1))\n    seq.append(fib(n))\n    return seq\n\nprofile.run('print fib_seq(20); print')\n```", "```py\nimport profile\n\nclass cached:\n    def __init__(self, fn):\n        self.fn = fn\n        self.cache = {}\n\n    def __call__(self, *args):\n        try:\n            return self.cache[args]\n        except KeyError:\n            self.cache[args] = self.fn(*args)\n            return self.cache[args]\n\n@cached\ndef fib(n):\n    if n <= 1:\n        return n\n    else:\n        return fib(n-1) + fib(n-2)\n\ndef fib_seq(n):\n    seq = [ ]\n    if n > 0: \n\n        seq.extend(fib_seq(n-1))\n    seq.append(fib(n))\n    return seq\n\nprofile.run('print fib_seq(20); print')\n```", "```py\nimport cProfile\nimport pstats\nfrom fibo4 import fib, fib_seq\n\nfilenames = []\nprofiler = cProfile.Profile()\nprofiler.enable()\nfor i in range(5):\n    print fib_seq(1000); print\nprofiler.create_stats()\nstats = pstats.Stats(profiler)\nstats.strip_dirs().sort_stats('cumulative').print_stats()\nstats.print_callers()\n```", "```py\nimport profile\ndef fib(n):\n    a, b = 0, 1 \n    for i in range(0, n):\n        a,b = b, a+b\n    return a\n\ndef fib_seq(n):\n    seq = [ ]\n    for i in range(0, n + 1):\n        seq.append(fib(i))\n    return seq\n\nprint fib_seq(1000)\n```", "```py\nimport cProfile\nimport pstats\nfrom fibo_iter import fib, fib_seq\n\nfilenames = []\nprofiler = cProfile.Profile()\nprofiler.enable()\nfor i in range(5):\n    print fib_seq(1000); print\nprofiler.create_stats()\nstats = pstats.Stats(profiler)\nstats.strip_dirs().sort_stats('cumulative').print_stats()\nstats.print_callers()\n```", "```py\nimport profile\n\nclass cached:\n    def __init__(self, fn):\n        self.fn = fn\n        self.cache = {}\n\n    def __call__(self, *args):\n        try:\n            return self.cache[args]\n        except KeyError:\n            self.cache[args] = self.fn(*args)\n            return self.cache[args]\n\n@cached\ndef fib(n):\n    a, b = 0, 1 \n    for i in range(0, n):\n        a,b = b, a+b\n    return a\n\ndef fib_seq(n):\n    seq = [ ]\n    for i in range(0, n + 1):\n        seq.append(fib(i))\n    return seq\n\nprint fib_seq(1000)\n```", "```py\ndef build_twit_stats():\n    STATS_FILE = './files/tweets.csv'\n    STATE = {\n        'replies': 0,\n        'from_web': 0,\n        'from_phone': 0,\n        'lines_parts': [],\n        'total_tweets': 0\n    }\n    read_data(STATE, STATS_FILE)\n    get_stats(STATE)\n    print_results(STATE)\n\ndef get_percentage(n, total):\n    return (n * 100) / total\n\ndef read_data(state, source):\n    f = open(source, 'r')\n\n    lines = f.read().strip().split(\"\\\"\\n\\\"\")\n    for line in lines:\n\n       state['lines_parts'].append(line.strip().split(',')) \n    state['total_tweets'] = len(lines)\n\ndef inc_stat(state, st):\n    state[st] += 1\n\ndef get_stats(state):\n    for i in state['lines_parts']:\n        if(i[1] != '\"\"'):\n            inc_stat(state, 'replies')\n        if(i[4].find('Twitter Web Client') > -1):\n            inc_stat(state, 'from_web')\n        else:\n            inc_stat(state, 'from_phone')\n\ndef print_results(state):\n    print \"-------- My twitter stats -------------\"\n    print \"%s%% of tweets are replies\" % (get_percentage(state['replies'], state['total_tweets']))\n    print \"%s%% of tweets were made from the website\" % (get_percentage(state['from_web'], state['total_tweets']))\n    print \"%s%% of tweets were made from my phone\" % (get_percentage(state['from_phone'], state['total_tweets']))\n```", "```py\nimport cProfile\nimport pstats\n\nfrom B02088_02_14 import build_twit_stats\nprofiler = cProfile.Profile()\n\nprofiler.enable()\n\nbuild_twit_stats()\n\nprofiler.create_stats()\nstats = pstats.Stats(profiler)\nstats.strip_dirs().sort_stats('cumulative').print_stats()\n```", "```py\n  def read_data(state, source):\n    f = open(source)\n\n    buffer_parts = []\n    for line in f:\n      #Multi line tweets are saved in several lines in the file, so we need to\n      #take that into account.\n      parts = line.split('\",\"')\n      buffer_parts += parts\n      if len(parts) == 10:\n        state['lines_parts'].append(buffer_parts) \n        get_line_stats(state, buffer_parts)\n        buffer_parts = []\n    state['total_tweets'] = len(state['lines_parts'])\n```", "```py\ndef get_line_stats(state, line_parts):\n  if line_parts[1] != '' :\n      state['replies'] += 1\n  if 'Twitter Web Client' in line_parts[4]:\n      state['from_web'] += 1\n  else:\n      state['from_phone'] += 1\n```", "```py\ndef read_data(state, source):\n    f = open(source)\n\n    buffer_parts = []\n    for line in f:\n      #Multi line tweets are saved in several lines in the file, so we need to\n      #take that into account.\n      parts = line.split('\",\"')\n      buffer_parts += parts\n      if len(parts) == 10:\n        state['lines_parts'].append(buffer_parts) \n        if buffer_parts[1] != '' :\n          state['replies'] += 1\n        if 'Twitter Web Client' in buffer_parts[4]:\n          state['from_web'] += 1\n        else:\n          state['from_phone'] += 1\n        buffer_parts = []\n    state['total_tweets'] = len(state['lines_parts'])\n```", "```py\ndef build_twit_stats():\n    STATS_FILE = './files/tweets.csv'\n    STATE = {\n        'replies': 0,\n        'from_web': 0,\n        'from_phone': 0,\n        'lines_parts': [],\n        'total_tweets': 0\n    }\n    read_data(STATE, STATS_FILE)\n    print_results(STATE)\n\ndef get_percentage(n, total):\n    return (n * 100) / total\n\ndef read_data(state, source):\n    f = open(source)\n\n    buffer_parts = []\n    for line in f:\n      #Multi line tweets are saved in several lines in the file, so we need to\n      #take that into account.\n      parts = line.split('\",\"')\n      buffer_parts += parts\n      if len(parts) == 10:\n        state['lines_parts'].append(buffer_parts) \n        if buffer_parts[1] != '' :\n          state['replies'] += 1\n        if 'Twitter Web Client' in buffer_parts[4]:\n          state['from_web'] += 1\n        else:\n          state['from_phone'] += 1\n        buffer_parts = []\n    state['total_tweets'] = len(state['lines_parts'])\n\ndef print_results(state):\n    print \"-------- My twitter stats -------------\"\n\n    print \"%s%% of tweets are replies\" % (get_percentage(state['replies'], state['total_tweets']))\n\n    print \"%s%% of tweets were made from the website\" % (get_percentage(state['from_web'], state['total_tweets']))\n\n    print \"%s%% of tweets were made from my phone\" % (get_percentage(state['from_phone'], state['total_tweets']))\n```", "```py\n$ pip install line_profiler\n\n```", "```py\n$ kernprof -l script_to_profile.py\n\n```", "```py\n@profile\ndef fib(n):\n    a, b = 0, 1 \n    for i in range(0, n):\n        a,b = b, a+b\n    return a\n```", "```py\n$ kernprof -l -v script_to_profile.py\n\n```", "```py\nimport line_profiler\nimport sys\n\ndef test():\n    for i in range(0, 10):\n        print i**2\n    print \"End of the function\"\n\nprof = line_profiler.LineProfiler(test) #pass in the function to profile\n\nprof.enable() #start profiling\ntest()\nprof.disable() #stop profiling\n\nprof.print_stats(sys.stdout) #print out the results\n```", "```py\n    $ python -m pstats stats_file.py.prof\n\n    ```", "```py\n    $ python -m line_profiler stats_file.py.lprof\n\n    ```", "```py\n//With these files:\nfile1.txt = \"This is a file\"\nfile2.txt = \"This is another file\"\n//We get the following index:\nThis, (file1.txt, 0), (file2.txt, 0)\nis, (file1.txt, 5), (file2.txt, 5)\na, (file1.txt, 8)\nanother, (file2.txt, 8)\nfile, (file1.txt, 10), (file2.txt, 16)\n```", "```py\n#!/usr/bin/env python\n\nimport sys\nimport os\nimport glob\n\ndef getFileNames(folder):\n  return glob.glob(\"%s/*.txt\" % folder)\n\ndef getOffsetUpToWord(words, index):\n  if not index:\n    return 0\n    subList = words[0:index]\n    length = sum(len(w) for w in subList)\n    return length + index + 1\n\ndef getWords(content, filename, wordIndexDict):\n  STRIP_CHARS = \",.\\t\\n |\"\n  currentOffset = 0\n\n  for line in content:\n    line = line.strip(STRIP_CHARS)\n    localWords = line.split()\n    for (idx, word) in enumerate(localWords):\n      word = word.strip(STRIP_CHARS)\n      if word not in wordIndexDict:\n        wordIndexDict[word] = []\n\n      line_offset = getOffsetUpToWord(localWords, idx) \n      index = (line_offset) + currentOffset\n      currentOffset = index \n      wordIndexDict[word].append([filename, index])\n\n  return wordIndexDict\n\ndef readFileContent(filepath):\n    f = open(filepath, 'r')\n    return f.read().split( ' ' )\n\ndef list2dict(list):\n  res = {}\n  for item in list:\n    if item[0] not in res:\n      res[item[0]] = []\n    res[item[0]].append(item[1])\n  return res\n\ndef saveIndex(index):\n  lines = []\n  for word in index:\n    indexLine = \"\"\n    glue = \"\"\n    for filename in index[word]:\n      indexLine += \"%s(%s, %s)\" % (glue, filename, ','.join(map(str, index[word][filename])))\n     glue = \",\"\n    lines.append(\"%s, %s\" % (word, indexLine))\n\n  f = open(\"index-file.txt\", \"w\")\n  f.write(\"\\n\".join(lines))\n  f.close()\n\ndef __start__():\n  files = getFileNames('./files')\n  words = {}\n  for f in files:\n    content = readFileContent(f)\n    words = getWords(content, f, words)\n  for word in (words):\n    words[word] = list2dict(words[word])\n  saveIndex(words)\n\n__start__()\n```", "```py\ndef getOffsetUpToWord(words, index):\n  if(index == 0):\n    return 0\n  length =  reduce(lambda curr, w: len(w) + curr, words[0:index], 0)\n  return length + index + 1\n```", "```py\ndef addWordLength(curr, w):\n  return len(w) + curr\n\n@profile\ndef getOffsetUpToWord(words, index):\n  if not index:\n    return 0\n  length = reduce(addWordLength, words[0:index], 0)\n  return length + index + 1\n```", "```py\ndef addWordLength(curr, w):\n  return len(w) + curr\n\n@profile\ndef getOffsetUpToWord(words, index):\n  return reduce(addWordLength, words[0:index], 0) + index + 1\n```", "```py\n    35    313868      1266039      4.0     62.9        line_offset = getOffsetUpToWord(localWords, idx) \n    36    313868       108729      0.3      5.4        index = (line_offset) + currentOffset\n    37    313868       101932      0.3      5.1        currentOffset = index \n```", "```py\n      currentOffset = getOffsetUpToWord(localWords, idx) + currentOffset\n```", "```py\ndef getWords(content, filename, wordIndexDict):\n  currentOffset = 0\n  for line in content:\n    localWords = line.split()\n    for (idx, word) in enumerate(localWords):\n      currentOffset = getOffsetUpToWord(localWords, idx) + currentOffset\n      wordIndexDict[word].append([filename, currentOffset])])])\n  return wordIndexDict\n```", "```py\ndef list2dict(list):\n  res = defaultdict(lambda: [])\n  for item in list:\n    res[item[0]].append(item[1])\n  return res\n```", "```py\ndef saveIndex(index):\n  lines = []\n  for word in index:\n    indexLines = []\n    for filename in index[word]:\n      indexLines.append(\"(%s, %s)\" % (filename, ','.join(index[word][filename])))\n    lines.append(word + \",\" +  ','.join(indexLines))\n\n  f = open(\"index-file.txt\", \"w\")\n  f.write(\"\\n\".join(lines))\n  f.close()\n```"]