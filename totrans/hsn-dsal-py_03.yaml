- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Algorithm Design Techniques and Strategies
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法设计技术和策略
- en: In the field of computing, algorithm design is very important for IT professionals
    for improving their skills and enabling growth in the industry. The algorithm
    design process starts with a substantial number of real-world computing problems,
    which must be clearly formulated for efficiently building the solution using one
    of the possible techniques from the range of algorithm design techniques available.
    The world of algorithms contains a plethora of techniques and design principles,
    mastery of which is required to tackle more difficult problems in the field. Algorithm
    designs are important in computer science, in general, to efficiently design the
    solution for a precisely formulated problem since a very sophisticated and complex
    problem can easily be solved with an appropriate algorithm design technique.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算领域，算法设计对于IT专业人士来说非常重要，因为它有助于提高他们的技能并促进行业的发展。算法设计过程从大量的现实世界计算问题开始，这些问题的表述必须清晰，以便使用算法设计技术范围中的一种可能技术有效地构建解决方案。算法的世界包含大量的技术和设计原则，掌握这些是解决该领域更困难问题的必要条件。算法设计在计算机科学中非常重要，因为它有助于为精确表述的问题高效地设计解决方案，因为一个非常复杂和困难的问题可以通过适当的算法设计技术轻松解决。
- en: In this chapter, we will discuss the ways in which different kinds of algorithms
    can be categorized. Design techniques will be described and illustrated, and we
    will further discuss the analysis of algorithms. Finally, we will provide detailed
    implementations for a few very important algorithms.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论不同类型的算法如何被分类。我们将描述并展示设计技术，并进一步讨论算法分析。最后，我们将为几个非常重要的算法提供详细的实现。
- en: 'In this chapter, we will look at the following algorithm design techniques:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下算法设计技术：
- en: Divide and conquer
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分而治之
- en: Dynamic programming
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态规划
- en: Greedy algorithms
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贪心算法
- en: Algorithm design techniques
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法设计技术
- en: Algorithm design is a powerful tool for viewing and clearly understanding well-posed,
    real-world problems. A straightforward, or **brute-force**, approach is available
    that is very simple, yet effective, for many problems. The brute-force approach
    is trying all possible combinations of solutions in order to solve any problem.
    For example, suppose a salesperson has to visit 10 cities across the country.
    In which order should the cities be visited in order to minimize the total distance
    traveled? The brute-force approach to this problem will be to calculate the total
    distance for all possible combinations of routes, and then select the route that
    provides the smallest distance.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 算法设计是观察和清晰理解良好设定的、现实世界问题的强大工具。对于许多问题，存在一种简单而有效的直接方法，即**暴力法**。暴力法尝试所有可能的解决方案组合以解决任何问题。例如，假设一位销售人员需要访问全国10个城市。为了使总行程距离最小化，应该按什么顺序访问这些城市？解决这个问题的暴力法将是计算所有可能路线的总距离，然后选择提供最小距离的路线。
- en: As you might guess, the brute-force algorithm is not efficient.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所料，暴力算法效率不高。
- en: 'It can provide useful solutions for limited input sizes, but it becomes very
    inefficient when the input size becomes large. Therefore, we will break the process
    down into two fundamental components for finding the optimal solution for a computing
    problem:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以为有限输入大小提供有用的解决方案，但当输入大小变得很大时，它变得非常低效。因此，我们将过程分解为两个基本组件，以找到计算问题的最优解决方案：
- en: Formulate the problem clearly
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 明确表述问题
- en: Identify the appropriate algorithm design technique based on the structure of
    the problem for an efficient solution
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据问题的结构选择合适的算法设计技术以获得高效的解决方案
- en: 'That is why the study of algorithm design becomes very important when developing
    scalable and robust systems. Design and analysis are important in the first instance
    because they assist in developing algorithms that are organized and easy to understand.
    Design technique guidelines also help in developing new algorithms easily for
    complex problems. Moreover, design techniques can also be used to categorize the
    algorithms and this also helps to understand them better. There are several algorithm
    paradigms as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 正因如此，在开发可扩展和健壮的系统时，算法设计的研究变得非常重要。设计和分析首先很重要，因为它们有助于开发组织良好且易于理解的算法。设计技术指南还有助于轻松地为复杂问题开发新算法。此外，设计技术还可以用于对算法进行分类，这也有助于更好地理解它们。以下是一些算法范式：
- en: Recursion
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 递归
- en: Divide and conquer
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分而治之
- en: Dynamic programming
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态规划
- en: Greedy algorithms
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贪心算法
- en: Since we will be using recursion many times while discussing different algorithm
    design techniques, let us first understand the concept of recursion, and thereafter,
    we will discuss different algorithm design techniques.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在讨论不同的算法设计技术时，我们将多次使用递归，让我们首先了解递归的概念，然后我们将讨论不同的算法设计技术。
- en: Recursion
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归
- en: 'A recursive algorithm calls itself repeatedly in order to solve the problem
    until a certain condition is fulfilled. Each recursive call itself spins off other
    recursive calls. A recursive function can be in an infinite loop; therefore, it
    is required that each recursive function adheres to certain properties. At the
    core of a recursive function are two types of cases:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 递归算法通过反复调用自身来解决一个问题，直到满足某个条件。每个递归调用本身会产生其他递归调用。递归函数可能陷入无限循环；因此，每个递归函数都必须遵循某些属性。递归函数的核心是两种类型的案例：
- en: '**Base cases**: These tell the recursion when to terminate, meaning the recursion
    will be stopped once the base condition is met'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**基本案例**：这些告诉递归何时终止，意味着一旦满足基本条件，递归就会停止'
- en: '**Recursive cases**: The function calls itself recursively, and we progress
    toward achieving the base criteria'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**递归案例**：函数递归调用自身，我们朝着实现基本标准前进'
- en: 'A simple problem that naturally lends itself to a recursive solution is calculating
    factorials. The recursive factorial algorithm defines two cases: the base case
    when *n* is zero (the terminating condition) and the recursive case when *n* is
    greater than zero (the call of the function itself). A typical implementation
    is as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一个自然适合递归解决方案的简单问题就是计算阶乘。递归阶乘算法定义了两种情况：当*n*为零（终止条件）时的基本案例，以及当*n*大于零（函数自身的调用）时的递归案例。一个典型的实现如下：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This produces the following output:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下输出：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To calculate the factorial of `4`, we require four recursive calls, plus the
    initial parent call, as can be seen in *Figure 3.1*. The details of how these
    recursive calls work is as follows. Initially, the number `4` is passed to the
    factorial function, which will return the value `4` multiplied by the factorial
    of (4-1=3). For this, the number `3` is again passed to the factorial function,
    which will return the value `3` multiplied by the factorial of (3-1=2). Similarly,
    in the next iteration, the value `2` is multiplied by the factorial of (2-1 =1).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算`4`的阶乘，我们需要四个递归调用，加上最初的父调用，如*图3.1*所示。这些递归调用的工作细节如下。最初，数字`4`被传递给阶乘函数，该函数将返回`4`乘以`(4-1=3)`的阶乘。为此，数字`3`再次传递给阶乘函数，该函数将返回`3`乘以`(3-1=2)`的阶乘。同样，在下一个迭代中，值`2`乘以`(2-1
    =1)`的阶乘。
- en: This continues until we reach the factorial of `0`, which returns `1`. Now,
    each function returns the value to finally compute `1*1*2*3*4=24`, which is the
    final output of the function.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这一直持续到我们达到`0`的阶乘，它返回`1`。现在，每个函数都返回值，最终计算`1*1*2*3*4=24`，这是函数的最终输出。
- en: '![](img/B17217_03_01.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17217_03_01.png)'
- en: 'Figure 3.1: The flow of execution of the factorial 4'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1：阶乘4的执行流程
- en: We discussed the concept of recursion, which will be very useful in understanding
    the implementation of different algorithm paradigms. So, now let us move on to
    the distinct algorithm design strategies in turn, starting with the divide-and-conquer
    technique in the next section.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了递归的概念，这将在理解不同算法范式的实现时非常有用。因此，现在让我们依次讨论独特的算法设计策略，从下一节的分而治之技术开始。
- en: Divide and conquer
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分而治之
- en: One of the important and effective techniques for solving a complex problem
    is divide and conquer. The divide-and-conquer paradigm divides a problem into
    smaller sub-problems, and then solves these; finally, it combines the results
    to obtain a global, optimal solution. More specifically, in divide-and-conquer
    design, the problem is divided into two smaller sub-problems, with each of them
    being solved recursively. The partial solutions are merged to obtain a final solution.
    This is a very common problem-solving technique, and is, arguably, the most commonly
    used approach in algorithm design.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 解决复杂问题的一个重要且有效的技术是分而治之。分而治之范式将问题分解成更小的子问题，然后解决这些子问题；最后，将结果合并以获得全局、最优的解决方案。更具体地说，在分而治之设计中，问题被分解成两个更小的子问题，每个子问题都递归地解决。部分解决方案被合并以获得最终解决方案。这是一种非常常见的问题解决技术，可以说是算法设计中最常用的方法之一。
- en: 'Some examples of the divide-and-conquer design technique are as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 分而治之设计技术的几个例子如下：
- en: Binary search
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二分查找
- en: Merge sort
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 归并排序
- en: Quick sort
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速排序
- en: Algorithm for fast multiplication
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速乘法算法
- en: Strassen’s matrix multiplication
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 施特拉森矩阵乘法
- en: Closest pair of points
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点对最近距离
- en: Let’s have a look at two examples, the binary search and merge sort algorithms,
    to understand how the divide-and-conquer design technique works.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过两个例子，二分查找和归并排序算法，来了解分而治之的设计技术是如何工作的。
- en: Binary search
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二分查找
- en: The binary search algorithm is based on the divide-and-conquer design technique.
    This algorithm is used to find a given element from a sorted list of elements.
    It first compares the search element with the middle element of the list; if the
    search element is smaller than the middle element, then the half of the list of
    elements greater than the middle element is discarded; the process repeats recursively
    until the search element is found or we reach the end of the list. It is important
    to note that in each iteration, half of the search space is discarded, which improves
    the performance of the overall algorithm because there are fewer elements to search
    through.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 二分查找算法基于分而治之的设计技术。此算法用于从有序元素列表中查找给定元素。它首先将搜索元素与列表的中间元素进行比较；如果搜索元素小于中间元素，则丢弃大于中间元素的元素列表的一半；这个过程递归重复，直到找到搜索元素或达到列表的末尾。需要注意的是，在每次迭代中，搜索空间的一半被丢弃，这提高了整体算法的性能，因为需要搜索的元素更少。
- en: Take the example shown in *Figure 3.2*; let’s say we want to search for element
    4 in the given sorted list of elements. The list is divided in half in each iteration;
    with the divide-and-conquer strategy, the element is searched *O*(*logn*) times.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以*图3.2*中显示的例子为例；假设我们想在给定的有序元素列表中搜索元素4。列表在每次迭代中都被分成两半；使用分而治之策略，元素被搜索*O*(*logn*)次。
- en: '![](img/B17217_03_02.1.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17217_03_02.1.png)'
- en: 'Figure 3.2: The process of searching for an element using a binary search algorithm'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2：使用二分查找算法搜索元素的过程
- en: 'The Python code for searching for an element in a sorted list of elements is
    shown here:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在此展示了在有序元素列表中搜索元素的Python代码：
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: When we search for `13` in the given list of elements, the output of the preceding
    code is `3`, which is the position of the searched item.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在给定的元素列表中搜索`13`时，前面代码的输出是`3`，这是搜索项的位置。
- en: In the code, initially, the start and end index give the position of the first
    and last index of the input array `[4, 6, 9, 13, 14, 18, 21, 24, 38]`. The item
    to be searched that is stored in the variable `key` is firstly matched with the
    mid element of the array, and then we discard half of the list and search for
    the item in another half of the list. The process is iterated until we find the
    item to be searched, or we reach the end of the list, and we don’t find the element.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，最初，起始和结束索引给出了输入数组 `[4, 6, 9, 13, 14, 18, 21, 24, 38]` 的第一个和最后一个索引的位置。存储在变量
    `key` 中的要搜索的项首先与数组的中间元素匹配，然后我们丢弃列表的一半，并在列表的另一半中搜索该项。这个过程重复迭代，直到找到要搜索的项，或者达到列表的末尾，并且我们没有找到元素。
- en: When analyzing the workings of the binary search algorithm in the worst case,
    we can see that for a given array of 8 elements, following the first unsuccessful
    attempt, the list is halved, and then again for an unsuccessful search attempt,
    the list is of length 2, and finally, only 1 element is left. So, the binary search
    requires 4 searches. If the size of the list is doubled, in other words, to 16,
    following the first unsuccessful search, we will have a list of size 8, and that
    will take a total of 4 searches. Therefore, the binary search algorithm will require
    5 searches for a list of 16 items. Thus, we can observe that when we double the
    number of items in the list, the number of searches required also increments by
    1\. We can say this as when we have a list of length n, the total number of searches
    required will be the number of times we repeated halving the list until we are
    left with 1 element plus 1, which is mathematically equivalent to (log[2] *n*
    + 1). For example, if n=8, the output will be 3, meaning the number of searches
    required will be 4\. The list is divided in half in each iteration; with the divide-and-conquer
    strategy, the worst-case time complexity of the binary search algorithm is *O(log*
    *n)*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当分析二分查找算法在最坏情况下的工作原理时，我们可以看到，对于一个包含8个元素的给定数组，在第一次不成功的尝试之后，列表被减半，然后在不成功的搜索尝试之后，列表长度变为2，最后只剩下1个元素。因此，二分查找需要4次搜索。如果列表的大小加倍，换句话说，变为16，在第一次不成功的搜索之后，我们将有一个大小为8的列表，这将需要总共4次搜索。因此，二分查找算法将需要5次搜索来处理16个元素的列表。因此，我们可以观察到，当我们加倍列表中的项目数量时，所需的搜索次数也增加1。我们可以这样说，当我们有一个长度为n的列表时，所需的搜索总数将是我们将列表减半直到只剩下一个元素所需的次数加上1，这在数学上等同于(log[2]
    *n* + 1)。例如，如果n=8，输出将是3，这意味着所需的搜索次数将是4。在每次迭代中，列表被分成一半；使用分治策略，二分查找算法的最坏情况时间复杂度是*O(log*
    *n)*。
- en: Merge sort is another popular algorithm that is based on the divide-and-conquer
    design strategy. We will be discussing merge sort in more detail in the next section.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 归并排序是另一种基于分治设计策略的流行算法。我们将在下一节更详细地讨论归并排序。
- en: Merge sort
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 归并排序
- en: Merge sort is an algorithm for sorting a list of *n* natural numbers in increasing
    order. Firstly, the given list of elements is divided iteratively into equal parts
    until each sublist contains one element, and then these sublist are combined to
    create a new list in a sorted order. This programming approach to problem-solving
    is based on the divide-and-conquer methodology and emphasizes the need to break
    down a problem into smaller sub-problems of the same type or form as the original
    problem. These sub-problems are solved separately and then results are combined
    to obtain the solution of the original problem.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 归并排序是一种用于按升序排序自然数列表的算法。首先，给定的元素列表被迭代地分成相等的部分，直到每个子列表只包含一个元素，然后这些子列表被合并以创建一个新列表，并按排序顺序排列。这种编程方法基于分治方法，强调将问题分解成与原始问题相同类型或形式的更小的子问题。这些子问题被单独解决，然后结果被组合起来以获得原始问题的解决方案。
- en: In this case, given a list of unsorted elements, we split the list into two
    approximate halves. We continue to divide the list into halves recursively.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，给定一个未排序的元素列表，我们将列表分成两个大致相等的部分。我们继续递归地将列表分成两半。
- en: 'After a while, the sublist created as a result of the recursive call will contain
    only one element. At that point, we begin to merge the solutions in the conquer
    or merge step. This process is shown in *Figure 3.3*:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一段时间后，由递归调用创建的子列表将只包含一个元素。在那个时刻，我们开始合并征服或合并步骤中的解决方案。这个过程在*图3.3*中显示：
- en: '![](img/B17217_03_03.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17217_03_03.png)'
- en: 'Figure 3.3: Overview of the merge sort algorithm'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：归并排序算法概述
- en: 'The implementation of the merge sort algorithm is implemented using primarily
    two methods, namely, the `merge_sort` method, which recursively divides the list.
    Afterward, we will introduce the `merge` method to combine the results:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 归并排序算法的实现主要使用两种方法，即`merge_sort`方法，它递归地划分列表。之后，我们将介绍`merge`方法来合并结果：
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The implementation starts by accepting the list of unsorted elements into the
    `merge_sort` function. The `if` statement is used to establish the base case,
    where, if there is only one element in the `unsorted_list`, we simply return that
    list again. If there is more than one element in the list, we find the approximate
    middle using `mid_point = len(unsorted_list)//2`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 实现过程首先将未排序的元素列表传入`merge_sort`函数。使用`if`语句来建立基本情况，即如果`unsorted_list`中只有一个元素，我们直接返回该列表。如果列表中有多个元素，我们使用`mid_point
    = len(unsorted_list)//2`来找到大约的中间位置。
- en: 'Using this `mid_point`, we divide the list into two sublists, namely, `first_half`
    and `second_half`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个`mid_point`，我们将列表分为两个子列表，即`first_half`和`second_half`：
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'A recursive call is made by passing the two sublist to the `merge_sort` function
    again:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将两个子列表再次传递给`merge_sort`函数进行递归调用：
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, for the merge step, `half_a` and `half_b` are sorted. When `half_a` and
    `half_b` have passed their values, we call the `merge` function, which will merge
    or combine the two solutions stored in `half_a` and `half_b`, which are lists:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，对于合并步骤，`half_a`和`half_b`都是已排序的。当`half_a`和`half_b`传递了它们的值后，我们调用`merge`函数，该函数将合并或组合存储在`half_a`和`half_b`中的两个解决方案，它们都是列表：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `merge` function takes the two lists we want to merge, `first_sublist` and
    `second_sublist`. The `i` and `j` variables are initialized to 0 and are used
    as pointers to tell us where we are in the two lists with respect to the merging
    process.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`merge`函数接受我们想要合并的两个列表，`first_sublist`和`second_sublist`。`i`和`j`变量被初始化为0，并用作指针，告诉我们合并过程中在两个列表中的位置。'
- en: The final `merged_list` will contain the merged list.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的`merged_list`将包含合并后的列表。
- en: 'The `while` loop starts comparing the elements in `first_sublist` and `second_sublist`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`while`循环开始比较`first_sublist`和`second_sublist`中的元素：'
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `if` statement selects the smaller of the two, `first_sublist[i]` or `second_sublist[j]`,
    and appends it to `merged_list`. The `i` or `j` index is incremented to reflect
    where we are with the merging step. The `while` loop stops when either sublist
    is empty.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`if`语句选择两个中的较小者，`first_sublist[i]`或`second_sublist[j]`，并将其追加到`merged_list`中。`i`或`j`索引增加以反映合并步骤的位置。`while`循环在任一子列表为空时停止。'
- en: 'There may be elements left behind in either `first_sublist` or `second_sublist`.
    The last two `while` loops make sure that those elements are added to `merged_list`
    before it is returned. The last call to `merge(half_a, half_b)` will return the
    sorted list. The following code shows how to pass an array to sort the elements
    using merge sort:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会有元素遗留在`first_sublist`或`second_sublist`中。最后的两个`while`循环确保在返回之前将这些元素添加到`merged_list`中。最后的`merge(half_a,
    half_b)`调用将返回排序后的列表。以下代码展示了如何使用归并排序对数组进行排序：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output will be:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将是：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Let’s give the algorithm a dry run by merging the two sublists `[4, 6, 8]` and
    `[5, 7, 11, 40]`, shown in *Table 3.1*. In this example, initially, the two sorted
    sublists are given, and then the, first elements are matched, and since the first
    element of the first list is smaller, it is moved to `merge_list`. Next, in *step
    2*, again, the starting elements from both of the lists are matched, and the smaller
    element, which is from the second list, is moved to `merge_list`. The same process
    is repeated until one of the lists becomes empty.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过合并两个子列表`[4, 6, 8]`和`[5, 7, 11, 40]`来实际运行这个算法，如*表3.1*所示。在这个例子中，最初给出两个已排序的子列表，然后匹配第一个元素，由于第一个列表的第一个元素较小，它被移动到`merge_list`中。接下来，在*步骤2*中，再次从两个列表中匹配起始元素，较小元素（来自第二个列表）被移动到`merge_list`中。这个过程一直重复，直到其中一个列表为空。
- en: '| **Step** | `first_sublist` | `second_sublist` | `merged_list` |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| **步骤** | `first_sublist` | `second_sublist` | `merged_list` |'
- en: '| 0 | [4 6 8] | [5 7 11 40] | [] |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 0 | [4 6 8] | [5 7 11 40] | [] |'
- en: '| 1 | [ 6 8] | [5 7 11 40] | [4] |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 1 | [ 6 8] | [5 7 11 40] | [4] |'
- en: '| 2 | [ 6 8] | [ 7 11 40] | [4 5] |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 2 | [ 6 8] | [ 7 11 40] | [4 5] |'
- en: '| 3 | [ 8] | [ 7 11 40] | [4 5 6] |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 3 | [ 8] | [ 7 11 40] | [4 5 6] |'
- en: '| 4 | [ 8] | [ 11 40] | [4 5 6 7] |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 4 | [ 8] | [ 11 40] | [4 5 6 7] |'
- en: '| 5 | [ ] | [ 11 40] | [4 5 6 7 8] |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 5 | [ ] | [ 11 40] | [4 5 6 7 8] |'
- en: '| 6 | [] | [ ] | [4 5 6 7 8 11 40] |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 6 | [] | [ ] | [4 5 6 7 8 11 40] |'
- en: 'Table 3.1: Example of merging two lists'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.1：合并两个列表的示例
- en: 'This process can also be seen in *Figure 3.4*:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程也可以在*图3.4*中看到：
- en: '![](img/B17217_03_04.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17217_03_04.png)'
- en: 'Figure 3.4: The process of merging the two sublists'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4：合并两个子列表的过程
- en: After one of the lists becomes empty, like after *step 4* in this example, at
    this point in the execution, the third `while` loop in the `merge` function kicks
    in to move `11` and `40` into `merged_list`. The returned `merged_list` will contain
    the fully sorted list.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在其中一个列表变为空之后，例如在本例中的 *步骤 4* 之后，在执行的这个点上，`merge` 函数中的第三个 `while` 循环开始工作，将 `11`
    和 `40` 移动到 `merged_list` 中。返回的 `merged_list` 将包含完全排序的列表。
- en: 'The worst-case running time complexity of the merge sort will depend on the
    following steps:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 归并排序的最坏情况运行时间复杂度将取决于以下步骤：
- en: Firstly, the divide step will take a constant time since it just computes the
    midpoint, which can be done in *O*(*1*) time
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，划分步骤将花费常数时间，因为它只是计算中点，这可以在 *O*(*1*) 时间内完成。
- en: Then, in each iteration, we divide the list into half recursively, which will
    take *O*(*log n*), which is quite similar to what we have seen in the binary search
    algorithm
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在每次迭代中，我们将列表递归地分成两半，这将花费 *O*(*log n*) 的时间，这与我们在二分搜索算法中看到的情况非常相似。
- en: Further, the combine/merge step merges all the *n* elements into the original
    array, which will take (*n*) time.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，合并/归并步骤将所有 *n* 个元素合并到原始数组中，这将花费 (*n*) 的时间。
- en: Hence, the merge sort algorithm has a runtime complexity of *O*(*log n*) *T*(*n*)
    = *O*(*n*) * *O*(*log n*) = *O*(*n log n*).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，归并排序算法的时间复杂度为 *O*(*log n*) *T*(*n*) = *O*(*n*) * *O*(*log n*) = *O*(*n log
    n*)。
- en: 'We have discussed the divide-and-conquer algorithm design technique with the
    help of a few examples. In the next section, we will discuss another algorithm
    design technique: dynamic programming.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过几个示例讨论了分而治之算法设计技术。在下一节中，我们将讨论另一种算法设计技术：动态规划。
- en: Dynamic programming
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态规划
- en: Dynamic programming is the most powerful design technique for solving optimization
    problems. Such problems generally have many possible solutions. The basic idea
    of dynamic programming is based on the intuition of the divide-and-conquer technique.
    Here, essentially, we explore the space of all the possible solutions by decomposing
    the problem into a series of sub-problems and then combining the results to compute
    the correct solution for the large problem. The divide-and-conquer algorithm is
    used to solve a problem by combining the solutions of the non-overlapping (disjoint)
    sub-problems, whereas dynamic programming is used when the sub-problems are overlapping,
    meaning that the sub-problems share sub-sub-problems. The dynamic programming
    technique is similar to divide and conquer in that a problem is broken down into
    smaller problems. However, in divide and conquer, each sub-problem has to be solved
    before its results can be used to solve bigger problems. In contrast, dynamic
    programming-based techniques solve each sub-sub-problems only once and do not
    recompute the solution to an already-encountered sub-problem. Rather, it uses
    a remembering technique to avoid the re-computation.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 动态规划是解决优化问题最强大的设计技术。这类问题通常有多个可能的解决方案。动态规划的基本思想基于分而治之的直觉。在这里，我们通过将问题分解为一系列子问题并组合结果来计算大问题的正确解，从而探索所有可能解决方案的空间。分而治之算法通过组合非重叠（不相交）子问题的解来解决问题，而动态规划用于子问题重叠的情况，这意味着子问题共享子子问题。动态规划技术与分而治之类似，因为问题被分解为更小的问题。然而，在分而治之中，必须先解决每个子问题，然后才能使用其结果来解决更大的问题。相比之下，基于动态规划的技术只解决每个子子问题一次，并且不会重新计算已遇到的子问题的解。相反，它使用记忆技术来避免重新计算。
- en: 'Dynamic programming problems have two important characteristics:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 动态规划问题有两个重要特征：
- en: '**Optimal substructure**: Given any problem, if the solution can be obtained
    by combining the solutions of its sub-problems, then the problem is said to have
    an optimal substructure. In other words, an optimal substructure means that the
    optimal solution of the problem can be obtained from the optimal solution of its
    sub-problems. For example, the i^(th) Fibonacci number from its series can be
    computed from (i-1)^(th) and (i-2)^(th) Fibonacci numbers; for example, fib(6)
    can be computed from fib(5) and fib(4).'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最优子结构**：对于任何问题，如果其解可以通过组合其子问题的解来获得，则称该问题具有最优子结构。换句话说，最优子结构意味着问题的最优解可以从其子问题的最优解中获得。例如，可以从(i-1)和(i-2)个斐波那契数计算得到第i个斐波那契数；例如，fib(6)可以通过fib(5)和fib(4)来计算。'
- en: '**Overlapping sub-problem**: If an algorithm has to repeatedly solve the same
    sub-problem again and again, then the problem has overlapping sub-problems. For
    example, fib(5) will have multiple time computations for fib(3) and fib(2).'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重叠子问题**：如果一个算法需要反复解决相同的子问题，那么这个问题就有重叠的子问题。例如，fib(5)将会多次计算fib(3)和fib(2)。'
- en: If a problem has these characteristics, then the dynamic programming approach
    is useful, since the implementation can be improved by reusing the same solution
    computed before. In a dynamic programming strategy, the problem is broken down
    into independent sub-problems, and the intermediate results are cached, which
    can then be used in subsequent operations.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个问题具有这些特征，那么动态规划方法是有用的，因为可以通过重用之前计算过的相同解来改进实现。在动态规划策略中，问题被分解成独立的子问题，中间结果被缓存，这样就可以在后续操作中使用。
- en: In the dynamic approach, we divide a given problem into smaller sub-problems.
    In recursion also, we divide the problem into sub-problems. However, the difference
    between recursion and dynamic programming is that similar sub-problems can be
    solved any number of times, but in dynamic programming, we keep track of previously
    solved sub-problems, and care is taken not to recompute any of the previously
    encountered sub-problems. One property that makes a problem an ideal candidate
    for being solved with dynamic programming is that it has an **overlapping set
    of sub-problems**. Once we realize that the form of sub-problems has repeated
    itself during computation, we need not compute it again. Instead, we return a
    pre computed result for that previously encountered sub-problem.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在动态方法中，我们将给定问题分解成更小的子问题。在递归中，我们也将问题分解成子问题。然而，递归和动态规划之间的区别在于，相似的子问题可以解决任意次数，但在动态规划中，我们跟踪之前解决的子问题，并注意不要重新计算之前遇到的任何子问题。一个问题成为动态规划理想候选解决的一个特性是它有一个**重叠的子问题集**。一旦我们意识到在计算过程中子问题的形式已经重复，我们就不需要再次计算它。相反，我们为之前遇到的那个子问题返回预先计算的结果。
- en: 'Dynamic programming takes account of the fact that each sub-problem should
    be solved only once, and to ensure that we never re-evaluate a sub-problem, we
    need an efficient way to store the results of each sub-problem. The following
    two techniques are readily available:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 动态规划考虑到了每个子问题只应该解决一次的事实，并且为了确保我们不会重新评估子问题，我们需要一种有效的方式来存储每个子问题的结果。以下两种技术是现成的：
- en: '**Top-down with memoization**: This technique starts from the initial problem
    set and divides it into small sub-problems. After the solution to a sub-program
    has been determined, we store the result of that particular sub-problem. In the
    future, when this sub-problem is encountered, we only return its pre computed
    result. Therefore, if the solution to a given problem can be formulated recursively
    using the solution of the sub-problems, then the solution of the overlapping sub-problems
    can easily be memoized.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自顶向下缓存化**：这种技术从初始问题集开始，将其分解成小子问题。一旦确定了子程序的解，我们就存储该特定子问题的结果。在将来，当遇到这个子问题时，我们只返回其预先计算的结果。因此，如果给定问题的解可以用子问题的解递归地表示，那么重叠子问题的解可以很容易地被缓存化。'
- en: Memoization means storing the solution of the sub-problem in an array or hash
    table. Whenever a solution to a sub-problem needs to be computed, it is first
    referred to the saved values if it is already computed, and if it is not stored,
    then it is computed in the usual manner. This procedure is called *memoized*,
    which means it “remembers” the results of the operation that has been computed
    before.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存化意味着将子问题的解存储在数组或哈希表中。每当需要计算子问题的解时，首先会参考已保存的值，如果已经计算过，则直接使用；如果没有存储，则按常规方式计算。这个过程被称为*缓存化*，意味着它“记住”了之前计算过的操作结果。
- en: '**Bottom-up approach**: This approach depends upon the “size” of the sub-problems.
    We solve the smaller sub-problems first, and then while solving a particular sub-problem,
    we already have a solution of the smaller sub-problems on which it depends. Each
    sub-problem is solved only once, and whenever we try to solve any sub-problem,
    solutions to all the prerequisite smaller sub-problems are available, which can
    be used to solve it. In this approach, a given problem is solved by dividing it
    into sub-problems recursively, with the smallest possible sub-problems then being
    solved. Furthermore, the solutions to the sub-problems are combined in a bottom-up
    fashion to arrive at the solution to the bigger sub-problem in order to recursively
    reach the final solution.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自底向上的方法**：这种方法依赖于子问题的“大小”。我们首先解决较小的子问题，然后在解决特定子问题时，我们已经有了依赖于它的较小子问题的解决方案。每个子问题只解决一次，并且每次尝试解决任何子问题时，所有先决的较小子问题的解决方案都可用，可以用来解决它。在这种情况下，给定问题通过将其递归地划分为子问题来解决，然后解决可能的最小子问题。此外，子问题的解决方案以自底向上的方式组合，以便递归地达到较大子问题的解决方案，从而最终达到最终解决方案。'
- en: Let’s consider an example to understand how dynamic programming works. Let us
    solve the problem of the Fibonacci series using dynamic programming.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来了解动态规划是如何工作的。让我们使用动态规划来解决斐波那契数列的问题。
- en: Calculating the Fibonacci series
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算斐波那契数列
- en: 'The Fibonacci series can be demonstrated using a recurrence relation. Recurrence
    relations are recursive functions that are used to define mathematical functions
    or sequences. For example, the following recurrence relation defines the Fibonacci
    sequence `[1, 1, 2, 3, 5, 8 ...]`:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 斐波那契数列可以用递推关系来表示。递推关系是递归函数，用于定义数学函数或序列。例如，以下递推关系定义了斐波那契序列 `[1, 1, 2, 3, 5, 8
    ...]`：
- en: '[PRE10]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Note that the Fibonacci sequence can be generated by putting the values of
    *n* in sequence `[0, 1, 2, 3, 4, ...]`. Let’s take an example to generate the
    Fibonacci series to the fifth term:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，斐波那契数列可以通过将 *n* 的值按顺序放入 `[0, 1, 2, 3, 4, ...]` 来生成。让我们举一个例子来生成到第五项的斐波那契数列：
- en: '[PRE11]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'A recursive-style program to generate the sequence would be as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 生成序列的递归风格程序如下：
- en: '[PRE12]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This will produce output like the following:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '[PRE13]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In this code, we can see that the recursive calls are being called in order
    to solve the problem. When the base case is met, the `fib()` function returns
    `1`. If *n* is equal to or less than 1, the base case is met. If the base case
    is not met, we call the `fib()` function again. The recursion tree to solve up
    to the fifth term in the Fibonacci sequence is shown in *Figure 3.5*:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，我们可以看到递归调用是为了解决问题而进行的。当遇到基本情况时，`fib()` 函数返回 `1`。如果 *n* 等于或小于 1，则满足基本情况。如果不满足基本情况，我们再次调用
    `fib()` 函数。解决斐波那契数列前五项的递归树如图 *3.5* 所示：
- en: '![](img/B17217_03_05.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17217_03_05.png)'
- en: 'Figure 3.5: Recursion tree for fib(5)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5：fib(5) 的递归树
- en: We can observe from the overlapping sub-problems from the recursion tree as
    shown in *Figure 3.6* that the call to **fib(1)** happens twice, the call to **fib(2)**
    happens three times, and the call to **fib(3)** occurs twice. The return values
    of the same function call never change; for example, the return value for **fib(2)**
    will always be the same whenever we call it. Likewise, it will also be the same
    for **fib(1)** and **fib(3)**. So, they are overlapping problems, thus, computational
    time will be wasted if we compute the same function again whenever it is encountered.
    These repeated calls to a function with the same parameters and output suggest
    that there is an overlap. Certain computations reoccur down in the smaller sub-problem.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 从如图 *3.6* 所示的递归树中的重叠子问题中，我们可以观察到对 **fib(1)** 的调用发生了两次，对 **fib(2)** 的调用发生了三次，对
    **fib(3)** 的调用发生了两次。相同函数调用的返回值永远不会改变；例如，**fib(2)** 的返回值将始终相同，无论何时调用它。同样，**fib(1)**
    和 **fib(3)** 也将如此。因此，它们是重叠问题，所以如果我们每次遇到相同的函数时都重新计算，将会浪费计算时间。这些具有相同参数和输出的重复函数调用表明存在重叠。某些计算在较小的子问题中会重复出现。
- en: '![](img/B17217_03_06.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17217_03_06.png)'
- en: 'Figure 3.6: Overlapping sub-problems shown in the recursion tree for fib(5)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6：递归树中 fib(5) 的重叠子问题
- en: 'In dynamic programming using the memoization technique, we store the results
    of the computation of **fib(1)** the first time it is encountered. Similarly,
    we store return values for **fib(2)** and **fib(3)**. Later, whenever we encounter
    a call to **fib(1)**, **fib(2)**, or **fib(3)**, we simply return their respective
    results. The recursive tree diagram is shown in *Figure 3.7*:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用记忆化技术的动态规划中，我们首次遇到时存储**fib(1)**的计算结果。同样，我们存储**fib(2)**和**fib(3)**的返回值。后来，每当遇到对**fib(1)**、**fib(2)**或**fib(3)**的调用时，我们只需返回它们各自的结果。递归树图如图*3.7*所示：
- en: '![Diagram  Description automatically generated](img/B17217_03_07.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B17217_03_07.png)'
- en: 'Figure 3.7: Recursion tree for fib(5) showing re-use of the already computed
    values'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7：fib(5)的递归树，显示了已计算值的重用
- en: Thus, in dynamic programming, we have eliminated the need to compute **fib(3)**,
    **fib(2)**, and **fib(1)** if they are encountered multiple times. This is called
    the memoization technique, wherein there is no recomputation of overlapping calls
    to functions when breaking a problem down into its sub-problems.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在动态规划中，我们消除了在遇到多次时重新计算**fib(3)**、**fib(2)**和**fib(1)**的需求。这被称为记忆化技术，其中在将问题分解为其子问题时，没有重新计算函数的重复调用。
- en: Hence, the overlapping function calls in our Fibonacci example are **fib(1)**,
    **fib(2)**, and **fib(3)**. Below is the code for the dynamic programming-based
    implementation for the Fibonacci series.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在我们的斐波那契示例中，重叠的函数调用是**fib(1)**、**fib(2)**和**fib(3)**。以下是基于动态规划的斐波那契数列实现的代码。
- en: '[PRE14]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This will produce an output like the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '[PRE15]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In the dynamic implementation of the Fibonacci series, we store the results
    of previously solved sub-problems in a list (in other words, a lookup in this
    example code). We first check whether the Fibonacci of any number is already computed;
    if it is already computed, then we return the stored value from the `lookup[n]`.
    Otherwise, when we compute its value, it is done through the following code:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在斐波那契数列的动态实现中，我们将已解决的子问题的结果存储在一个列表中（换句话说，在这个示例代码中是一个查找）。我们首先检查任何数字的斐波那契数是否已经计算过；如果是，则从`lookup[n]`返回存储的值。否则，当我们计算其值时，是通过以下代码完成的：
- en: '[PRE16]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'After computing the solution of the sub-problem, it is again stored in the
    lookup list. The Fibonacci number of the given value is returned as shown in the
    following code snippet:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算子问题的解决方案后，它再次存储在查找列表中。给定的斐波那契数值如以下代码片段所示返回：
- en: '[PRE17]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Furthermore, in order to store a list of 1,000 elements, we create a list lookup
    using the `dyna_fib` function:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了存储1,000个元素的列表，我们使用`dyna_fib`函数创建一个查找列表：
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: So, in dynamic programming-based solutions, we use the precomputed solutions
    in order to compute the final results.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在基于动态规划的解决方案中，我们使用预计算的解决方案来计算最终结果。
- en: Dynamic programming improves the running time complexity of the algorithm. In
    the recursive approach, for every value, two functions are called; for example,
    **fib(5)** calls **fib(4)** and **fib(3)**, and then **fib(4)** calls **fib(3)**
    and **fib(2)**, and so on. Thus, the time complexity for the recursive approach
    is O(2^n), whereas, in the dynamic programming approach, we do not recompute the
    sub-problems, so for **fib(n)**, we have *n* total values to be computed, in other
    words, **fib(0)**, **fib(1)**, **fib(2)**… **fib(n)**. Thus, we only solve these
    values once, so the total running time complexity is O(n). Thus, dynamic programming
    in general improves performance.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 动态规划提高了算法的运行时间复杂度。在递归方法中，对于每个值，都会调用两个函数；例如，**fib(5)**调用**fib(4)**和**fib(3)**，然后**fib(4)**调用**fib(3)**和**fib(2)**，依此类推。因此，递归方法的复杂度是O(2^n)，而在动态规划方法中，我们不重新计算子问题，所以对于**fib(n)**，我们有*n*个总值需要计算，换句话说，**fib(0)**、**fib(1)**、**fib(2)**…
    **fib(n)**。因此，我们只解决这些值一次，所以总运行时间复杂度是O(n)。因此，动态规划通常提高了性能。
- en: In this section, we have discussed the dynamic programming design technique,
    and in the next section, we discuss the design techniques for greedy algorithms.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了动态规划设计技术，在下一节中，我们将讨论贪婪算法的设计技术。
- en: Greedy algorithms
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贪婪算法
- en: Greedy algorithms often involve optimization and combinatorial problems. In
    greedy algorithms, the objective is to obtain the optimum solution from many possible
    solutions in each step. We try to get the local optimum solution, which may eventually
    lead us to obtain the global optimum solution. The greedy strategy does not always
    produce the optimal solution. However, the sequence of locally optimal solutions
    generally approximates the globally optimal solution.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 贪心算法通常涉及优化和组合问题。在贪心算法中，目标是每一步从许多可能的解决方案中获得最优解。我们试图获得局部最优解，这最终可能使我们获得全局最优解。贪心策略并不总是产生最优解。然而，局部最优解的序列通常近似于全局最优解。
- en: 'For example, consider that you are given some random digits, say `1`, `4`,
    `2`, `6`, `9`, and `5`. Now you have to make the biggest number by using all the
    digits without repeating any digit. To create the biggest number from the given
    digits using the greedy strategy, we perform the following steps. Firstly, we
    select the largest digit from the given digits, and then append it to the number
    and remove the digit from the list until we have no digits left in the list. Once
    all the digits have been used, we get the largest number that can be formed by
    using these digits: `965421`. The stepwise solution to this problem is shown in
    *Figure 3.8*:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你被给出一些随机数字，比如`1`、`4`、`2`、`6`、`9`和`5`。现在你必须使用所有这些数字，不重复任何数字，来组成最大的数字。要使用贪心策略从给定的数字中创建最大的数字，我们执行以下步骤。首先，我们从给定的数字中选择最大的数字，并将其附加到数字上，然后从列表中删除该数字，直到列表中没有剩余的数字。一旦所有数字都被使用，我们就得到了可以使用这些数字组成的最大数字：`965421`。该问题的逐步解决方案如*图3.8*所示：
- en: '![](img/B17217_03_08.png)![](img/B17217_03_08.1.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图片1](img/B17217_03_08.png)![图片2](img/B17217_03_08.1.png)'
- en: 'Figure 3.8: Example of a greedy algorithm'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8：贪心算法的示例
- en: Let us consider another example to better understand the greedy approach. Say
    you have to give 29 Indian rupees to someone in the minimum number of notes, giving
    one note at a time, but never exceeding the owed amount. Assume that we have notes
    in denominations of 1, 2, 5, 10, 20, and 50\. To solve this using the greedy approach,
    we will start by handing over the 20-rupee note, then for the remaining 9 rupees,
    we will give a 5-rupee note; for the remaining 4 rupees, we will give the 2-rupee
    note, and then another 2-rupee note.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑另一个例子，以更好地理解贪心方法。比如说，你必须以最少的纸币数量给某人29印度卢比，一次给一张纸币，但不要超过欠款金额。假设我们有1元、2元、5元、10元、20元和50元的纸币。要使用贪心方法解决这个问题，我们将首先
    handing over the 20-rupee note，然后对于剩余的9卢比，我们将给一张5卢比的纸币；对于剩余的4卢比，我们将给一张2卢比的纸币，然后另一张2卢比的纸币。
- en: In this approach, at each step, we chose the best possible solution and gave
    the largest available note. Assume that, for this example, we have to use the
    notes of 1, 14, and 25\. Then, using the greedy approach, we will pick the 25-rupee
    note, and then four 1-rupee notes, which makes a total of 5 notes. However, this
    is not the minimum number of notes possible . The better solution would be to
    give notes of 14, 14, and 1\. Thus, it is also clear that the greedy approach
    does not always give the best solution, but a feasible and simple one.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，在每一步，我们选择最佳可能的解决方案，并给出最大的可用纸币。假设，对于这个例子，我们必须使用1元、14元和25元的纸币。然后，使用贪心方法，我们将选择25元的纸币，然后是四张1元的纸币，这样总共是5张纸币。然而，这并不是可能的最少纸币数量。更好的解决方案是给出14元、14元和1元的纸币。因此，这也清楚地表明，贪心方法并不总是给出最佳解决方案，但是一个可行且简单的解决方案。
- en: The classic example is to apply the greedy algorithm to the traveling salesperson
    problem, where a greedy approach always chooses the closest destination first.
    In this problem, a greedy approach always chooses the closest unvisited city in
    relation to the current city; in this way, we are not sure that we will get the
    best solution, but we surely get an optimal solution. This shortest-path strategy
    involves finding the best solution to a local problem in the hope that this will
    lead to a global solution.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的例子是将贪心算法应用于旅行商问题，其中贪心方法总是首先选择最近的目的地。在这个问题中，贪心方法总是选择与当前城市相关的最近未访问城市；这样，我们无法确定我们会得到最佳解决方案，但我们确实得到了一个最优解决方案。这种最短路径策略涉及找到局部问题的最佳解决方案，希望这会导致全局解决方案。
- en: 'Listed here are many popular standard problems where we can use greedy algorithms
    to obtain the optimum solution:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 列出许多流行的标准问题，在这些问题中我们可以使用贪心算法来获得最优解：
- en: Kruskal’s minimum spanning tree
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克鲁斯卡尔最小生成树
- en: Dijkstra’s shortest path problem
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迪杰斯特拉最短路径问题
- en: The Knapsack problem
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 背包问题
- en: Prim’s minimal spanning tree algorithm
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prim的最小生成树算法
- en: The traveling salesperson problem
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旅行商问题
- en: Let us discuss one of the popular problems, in other words, the shortest path
    problem, which can be solved using the greedy approach, in the next section.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一个流行的问题，换句话说，最短路径问题，该问题可以使用贪婪方法解决，我们将在下一节中进行讨论。
- en: Shortest path problem
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最短路径问题
- en: The shortest path problem requires us to find out the shortest possible route
    between nodes on a graph. Dijkstra’s algorithm is a very popular method for solving
    this using the greedy approach. The algorithm is used to find the shortest distance
    from a source to a destination node in a graph.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 最短路径问题要求我们找出图中节点之间的最短可能路径。Dijkstra算法是解决此问题的贪婪方法中非常流行的方法。该算法用于在图中从源节点到目标节点找到最短距离。
- en: 'Dijkstra’s algorithm works for weighted directed and undirected graphs. The
    algorithm produces the output of a list of the shortest path from a given source
    node, A, in a weighted graph. The algorithm works as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Dijkstra算法适用于加权有向和无向图。该算法生成从给定源节点A在加权图中的最短路径列表的输出。算法的工作方式如下：
- en: Initially, mark all the nodes as unvisited, and set their distance from the
    given source node to infinity (the source node is set to zero).
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始时，将所有节点标记为未访问，并将它们从给定源节点的距离设置为无穷大（源节点设置为0）。
- en: Set the source node as the current one.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将源节点设置为当前节点。
- en: For the current node, look for all the unvisited adjacent nodes, and compute
    the distance to that node from the source node through the current node. Compare
    the newly computed distance to the currently assigned distance, and if it is smaller,
    set this as the new value.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于当前节点，查找所有未访问的相邻节点，并计算从源节点通过当前节点到该节点的距离。将新计算的距离与当前分配的距离进行比较，如果它更小，则将其设置为新的值。
- en: Once we have considered all the unvisited adjacent nodes of the current node,
    we mark it as visited.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们考虑了当前节点的所有未访问相邻节点，我们就将其标记为已访问。
- en: If the destination node has been marked visited, or if the list of unvisited
    nodes is empty, meaning we have considered all the unvisited nodes, then the algorithm
    is finished.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果目标节点已被标记为已访问，或者未访问节点的列表为空，这意味着我们已经考虑了所有未访问的节点，那么算法就完成了。
- en: We next consider the next unvisited node that has the shortest distance from
    the source node. Repeat *steps 2* to *6*.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们考虑下一个距离源节点最近的未访问节点。重复*步骤2*到*6*。
- en: Consider the example in *Figure 3.9* of a weighted graph with six nodes [A,
    B, C, D, E, and F] to understand how Dijkstra’s algorithm works.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑*图3.9*中的加权图示例，其中有六个节点[A, B, C, D, E和F]，以了解Dijkstra算法的工作原理。
- en: '![A picture containing text, clock, watch  Description automatically generated](img/B17217_03_09.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本、时钟、手表的图片，自动生成描述](img/B17217_03_09.png)'
- en: 'Figure 3.9: Example weighted graph with six nodes'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9：具有六个节点的示例加权图
- en: By manual inspection, the shortest path between nodes **A** and **D**, at first
    glance, seems to be the direct line with a distance of 9\. However, the shortest
    route means the lowest total distance, even if this comprises several parts. By
    comparison, traveling from node **A** to **E**, then from **E** to **F**, and
    finally to **D** will incur a total distance of 7, making it a shorter route.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 通过手动检查，节点**A**和**D**之间的最短路径看起来是距离为9的直接线路。然而，最短路径意味着最低的总距离，即使这包括几个部分。通过比较，从节点**A**到**E**，然后从**E**到**F**，最后到**D**的总距离为7，这使得它成为一条更短的路线。
- en: 'We would implement the shortest path algorithm with a single source. It would
    determine the shortest path from the origin, which in this case is **A**, to any
    other node in the graph. In *Chapter 9*, *Graphs and Other Algorithms*, we will
    discuss how to represent a graph with an adjacency list. We use an adjacency list
    along with the weight/cost/distance on every edge to represent the graph, as shown
    in the following Python code. The adjacency list for the diagram and table is
    as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用单源最短路径算法。它将确定从起点到图中任何其他节点的最短路径。在本例中，起点是**A**。在*第9章*，*图和其他算法*中，我们将讨论如何使用邻接表表示图。我们使用邻接表以及每条边的权重/成本/距离来表示图，如下面的Python代码所示。该图和表的邻接表如下：
- en: '[PRE19]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We will return to the rest of the code after a visual demonstration, but don’t
    forget to declare the graph to ensure the code runs correctly.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行视觉演示后，我们将返回代码的其余部分，但不要忘记声明图以确保代码正确运行。
- en: 'The nested dictionary holds the distance and adjacent nodes. A table is used
    to keep track of the shortest distance from the source in the graph to any other
    node. *Table 3.2* is the starting table:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌套字典包含距离和相邻节点。一个表用于跟踪图中从源节点到任何其他节点的最短距离。*表3.2*是起始表：
- en: '| **Node** | **Shortest distance from source** | **Previous node** |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| **节点** | **从源节点到最短距离** | **前一个节点** |'
- en: '| **A** | 0 | None |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| **A** | 0 | None |'
- en: '| **B** | ![](img/B17217_03_001.png) | None |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| **B** | ![](img/B17217_03_001.png) | None |'
- en: '| **C** | ![](img/B17217_03_002.png) | None |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| **C** | ![](img/B17217_03_002.png) | None |'
- en: '| **D** | ![](img/B17217_03_003.png) | None |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| **D** | ![](img/B17217_03_003.png) | None |'
- en: '| **E** | ![](img/B17217_03_004.png) | None |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| **E** | ![](img/B17217_03_004.png) | None |'
- en: '| **F** | ![](img/B17217_03_005.png) | None |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| **F** | ![](img/B17217_03_005.png) | None |'
- en: 'Table 3.2: Initial table showing the shortest distance from the source'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.2：显示从源节点到最短距离的初始表
- en: When the algorithm starts, the shortest distance from the given source node
    (**A**) to any of the nodes is unknown. Thus, we initially set the distance to
    all other nodes to infinity, with the exception of node **A**, as the distance
    from node **A** to node **A** is **0**. No prior nodes have been visited when
    the algorithm begins. Therefore, we mark the previous node column of node **A**
    as **None**.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当算法开始时，从给定的源节点（**A**）到任何其他节点的最短距离都是未知的。因此，我们最初将所有其他节点的距离设置为无穷大，除了节点**A**，因为从节点**A**到节点**A**的距离是**0**。算法开始时还没有访问过任何前一个节点。因此，我们将节点**A**的前一个节点列标记为**None**。
- en: 'In *step 1* of the algorithm, we start by examining the adjacent nodes to node
    **A**. To find the shortest distance from node **A** to node **B**, we need to
    find the distance from the start node to the previous node of node **B**, which
    happens to be **A**, and add it to the distance from node **A** to node **B**.
    We do this for the other adjacent nodes of **A**, these being **B**, **E**, and
    **D**. This is shown in *Figure 3.10*:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在算法的*第一步*中，我们首先检查节点**A**的相邻节点。为了找到从节点**A**到节点**B**的最短距离，我们需要找到从起始节点到节点**B**的前一个节点的距离，恰好是**A**，并将其加到从节点**A**到节点**B**的距离上。我们对**A**的其他相邻节点也这样做，这些节点是**B**、**E**和**D**。这如图*3.10*所示：
- en: '![A picture containing text, watch, clock  Description automatically generated](img/B17217_03_10.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本、手表、时钟的图片，描述自动生成](img/B17217_03_10.png)'
- en: 'Figure 3.10: A sample graph for Dijkstra’s algorithm'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10：Dijkstra算法的示例图
- en: Firstly, we take the adjacent node **E** as its distance from node **A** is
    the minimum; the distance from the start node (**A**) to the previous node (**None**)
    is 0, and the distance from the previous node to the current node (**E**) is **2**.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们选择相邻节点**E**，因为从节点**A**到它的距离是最小的；从起始节点（**A**）到前一个节点（**None**）的距离是0，从前一个节点到当前节点（**E**）的距离是**2**。
- en: This sum is compared with the data in the shortest distance column of node **E**
    (refer to *Table 3.3*). Since **2** is less than infinity (![](img/B17217_03_006.png)),
    we replace ![](img/B17217_03_007.png) with the smaller of the two, in other words,
    **2**. Similarly, the distance from node **A** to nodes **B** and **D** is compared
    with the existing shortest distance to these nodes from node **A**. Any time the
    shortest distance of a node is replaced by a smaller value, we need to update
    the previous node column for all the adjacent nodes of the current node.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这个总和与节点**E**的最短距离列中的数据进行比较（参见图*3.3*）。由于**2**小于无穷大(![](img/B17217_03_006.png))，我们将![](img/B17217_03_007.png)替换为两个数中的较小者，即**2**。同样，从节点**A**到节点**B**和**D**的距离与从节点**A**到这些节点的现有最短距离进行比较。每当一个节点的最短距离被替换为较小的值时，我们需要更新当前节点的所有相邻节点的前一个节点列。
- en: 'After this, we mark node **A** as visited (represented in blue in *Figure 3.11*):'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将节点**A**标记为已访问（在*图3.11*中以蓝色表示）：
- en: '![Chart  Description automatically generated](img/B17217_03_11.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图表描述自动生成](img/B17217_03_11.png)'
- en: 'Figure 3.11: Shortest distance graph after visiting node A using Dijkstra’s
    algorithm'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11：使用Dijkstra算法访问节点A后的最短距离图
- en: At the end of *step 1*, the table looks like that shown in *Table 3.3*, in which
    the shortest distance from node **A** to nodes **B**, **D**,and **E** are updated.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤1*结束时，表格看起来像*表3.3*中所示的那样，其中节点**A**到节点**B**、**D**和**E**的最短距离已更新。
- en: '| **Node** | **Shortest distance from source** | **Previous node** |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| **节点** | **从源节点到最短距离** | **前一个节点** |'
- en: '| **A*** | 0 | None |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| **A*** | 0 | None |'
- en: '| **B** | 5 | A |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| **B** | 5 | A |'
- en: '| **C** | ![](img/B17217_03_008.png) | None |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| **C** | ![](img/B17217_03_008.png) | None |'
- en: '| **D** | 9 | A |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| **D** | 9 | A |'
- en: '| **E** | 2 | A |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| **E** | 2 | A |'
- en: '| **F** | ![](img/B17217_03_009.png) | None |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| **F** | ![图片](img/B17217_03_009.png) | 无 |'
- en: 'Table 3.3: Shortest distance table after visiting node A'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.3：访问节点A后的最短距离表
- en: At this point, node **A** is considered visited. As such, we add node **A**
    to the list of visited nodes. In the table, we show that node **A** has been visited
    by appending an asterisk sign to it.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，节点**A**被认为已被访问。因此，我们将节点**A**添加到已访问节点的列表中。在表格中，我们通过在节点**A**旁边添加星号来表示节点**A**已被访问。
- en: In the second step, we find the node with the shortest distance using *Table
    3.3* as a guide. Node **E**, with its value of 2, has the shortest distance. To
    reach node **E**, we must visit node **A** and cover a distance of **2**.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步中，我们使用*表3.3*作为指南找到具有最短距离的节点。节点**E**具有最短距离的值为2。为了到达节点**E**，我们必须访问节点**A**并覆盖**2**的距离。
- en: 'Now, the adjacent nodes of node **E** are nodes **A** and **F**. Since node
    **A** has already been visited, we will only consider node **F**. To find the
    shortest route or distance to node **F**, we must find the distance from the starting
    node to node **E** and add it to the distance between nodes **E** and **F**. We
    can find the distance from the starting node to node **E** by looking at the shortest
    distance column of node **E**, which has a value of **2**. The distance from nodes
    **E** to **F** can be obtained from the adjacency list, which is **3**. These
    two total 5, which is less than infinity. Remember that we are examining the adjacent
    node **F**. Since there are no more adjacent nodes to node **E**, we mark node
    **E** as visited. Our updated table and the figure will have the following values,
    shown in *Table 3.4* and *Figure 3.12*:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，节点**E**的相邻节点是节点**A**和**F**。由于节点**A**已经被访问，我们只考虑节点**F**。为了找到到节点**F**的最短路径或距离，我们必须找到从起始节点到节点**E**的距离，并将其添加到节点**E**和**F**之间的距离。我们可以通过查看节点**E**的最短距离列来找到从起始节点到节点**E**的距离，其值为**2**。从节点**E**到**F**的距离可以从邻接表中获得，其值为**3**。这两个数加起来是5，小于无穷大。记住，我们正在检查相邻节点**F**。由于节点**E**没有更多的相邻节点，我们标记节点**E**为已访问。我们的更新后的表格和图形将具有以下值，如*表3.4*和*图3.12*所示：
- en: '| **Node** | **Shortest distance from source** | **Previous node** |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| **节点** | **从源点到最短距离** | **前一个节点** |'
- en: '| **A*** | 0 | None |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| **A*** | 0 | 无 |'
- en: '| **B** | 5 | A |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| **B** | 5 | A |'
- en: '| **C** | ![](img/B17217_03_010.png) | None |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| **C** | ![图片](img/B17217_03_010.png) | 无 |'
- en: '| **D** | 9 | A |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| **D** | 9 | A |'
- en: '| **E*** | 2 | A |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| **E*** | 2 | A |'
- en: '| **F** | 5 | E |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| **F** | 5 | E |'
- en: 'Table 3.4: Shortest distance table after visiting node E'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.4：访问节点E后的最短距离表
- en: '![Chart  Description automatically generated](img/B17217_03_12.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![图表描述自动生成](img/B17217_03_12.png)'
- en: 'Figure 3.12: Shortest distance graph after visiting node E using Dijkstra’s algorithm'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12：使用Dijkstra算法访问节点E后的最短距离图
- en: After visiting node **E**, we find the smallest value in the Shortest distance
    column of *Table 3.4*, which is 5 for nodes **B** and **F**. Let us choose **B**
    instead of **F** for alphabetical reasons. The adjacent nodes of **B** are nodes
    **A** and **C** since node **A** has already been visited. Using the rule we established
    earlier, the shortest distance from **A** to **C** is 7, which is computed as
    the distance from the starting node to node **B**, which is 5, while the distance
    from node **B** to **C** is 2\. Since 7 is less than infinity, we update the shortest
    distance to 7 and update the previous node column with node **B** in *Table 3.4*.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 访问节点**E**后，我们在*表3.4*的最短距离列中找到最小值，对于节点**B**和**F**，其值为5。由于字母顺序的原因，我们选择**B**而不是**F**。**B**的相邻节点是节点**A**和**C**，因为节点**A**已经被访问。使用我们之前建立的规则，从**A**到**C**的最短距离是7，这是通过从起始节点到节点**B**的距离（5）加上从节点**B**到**C**的距离（2）计算得出的。由于7小于无穷大，我们更新最短距离为7，并在*表3.4*中更新前一个节点列为节点**B**。
- en: Now, **B** is also marked as visited (represented in blue in *Figure 3.13*).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，**B**也被标记为已访问（在*图3.13*中以蓝色表示）。
- en: '| **Node** | **Shortest distance from source** | **Previous node** |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| **节点** | **从源点到最短距离** | **前一个节点** |'
- en: '| **A*** | 0 | None |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| **A*** | 0 | 无 |'
- en: '| **B*** | 5 | A |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| **B*** | 5 | A |'
- en: '| **C** | 7 | B |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| **C** | 7 | B |'
- en: '| **D** | 9 | A |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| **D** | 9 | A |'
- en: '| **E*** | 2 | A |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| **E*** | 2 | A |'
- en: '| **F** | 5 | E |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| **F** | 5 | E |'
- en: 'Table 3.5: Shortest distance table after visiting node B'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.5：访问节点B后的最短距离表
- en: 'The new state of the table is as follows, in *Table 3.5*:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 表格的新状态如下，见*表3.5*：
- en: '![Chart, schematic  Description automatically generated](img/B17217_03_13.png)Figure
    3.13: Shortest distance graph after visiting node B using Dijkstra’s algorithm'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '![图表，示意图  自动生成的描述](img/B17217_03_13.png)图3.13：使用Dijkstra算法访问节点B后的最短距离图'
- en: The node with the shortest distance yet unvisited is node **F**. The adjacent
    nodes to **F** are nodes **D** and **E**. Since node **E** has already been visited,
    we will focus on node **D**. To find the shortest distance from the starting node
    to node **D**, we calculate this distance by adding the distance from nodes **A**
    to **F** to the distance from nodes **F** to **D**. This totals 7, which is less
    than **9**. Thus, we update the **9** with **7** and replace **A** with **F**
    in node **D**’s previous node column of *Table 3.5*.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 尚未访问的最短距离节点是节点**F**。**F**的相邻节点是节点**D**和**E**。由于节点**E**已经访问过，我们将重点关注节点**D**。为了找到从起始节点到节点**D**的最短距离，我们通过将节点**A**到**F**的距离与节点**F**到**D**的距离相加来计算这个距离。总计为7，小于**9**。因此，我们将**9**更新为**7**，并在节点**D**的前一个节点列的*表3.5*中将**A**替换为**F**。
- en: Node **F** is now marked as visited (represented in blue in *Figure 3.14*).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 节点**F**现在已被标记为已访问（在*图3.14*中以蓝色表示）。
- en: '![Chart  Description automatically generated](img/B17217_03_14.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图表  自动生成的描述](img/B17217_03_14.png)'
- en: 'Figure 3.14: Shortest distance graph after visiting node F using Dijkstra’s
    algorithm'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14：使用Dijkstra算法访问节点F后的最短距离图
- en: 'Here is the updated table, as shown in *Table 3.6*:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这是更新后的表格，如*表3.6*所示：
- en: '| **Node** | **Shortest distance from source** | **Previous node** |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| **节点** | **从源节点到最短距离** | **前一个节点** |'
- en: '| **A*** | 0 | None |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| **A*** | 0 | 无 |'
- en: '| **B*** | 5 | A |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| **B*** | 5 | A |'
- en: '| **C** | 7 | B |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| **C** | 7 | B |'
- en: '| **D** | 7 | F |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| **D** | 7 | F |'
- en: '| **E*** | 2 | A |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| **E*** | 2 | A |'
- en: '| **F*** | 5 | E |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| **F*** | 5 | E |'
- en: 'Table 3.6: Shortest distance table after visiting node F'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.6：访问节点F后的最短距离表
- en: Now, only two unvisited nodes are left, **C** and **D**, both with a distance
    cost of **7**. In alphabetical order, we choose to consider node **C** because
    both nodes have the same shortest distance from the starting node **A**.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，只剩下两个未访问的节点，**C**和**D**，它们的距离成本都是**7**。按字母顺序排列，我们选择考虑节点**C**，因为这两个节点从起始节点**A**到最短距离相同。
- en: However, all the adjacent nodes to **C** have been visited (represented in blue
    in *Figure 3.15*). Thus, we have nothing to do but mark node **C** as visited.
    The table remains unchanged at this point.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，所有与**C**相邻的节点都已访问（在*图3.15*中以蓝色表示）。因此，我们除了将节点**C**标记为已访问外，别无他法。此时表格保持不变。
- en: '![Chart, diagram  Description automatically generated](img/B17217_03_15.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![图表，示意图  自动生成的描述](img/B17217_03_15.png)'
- en: 'Figure 3.15: Shortest distance graph after visiting node C using Dijkstra’s
    algorithm'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15：使用Dijkstra算法访问节点C后的最短距离图
- en: Lastly, we take node **D** and find out that all its adjacent nodes have been
    visited too. We only mark it as visited (represented in blue in *Figure 3.16*).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们取节点**D**，并发现它的所有相邻节点也已访问过。我们只需将其标记为已访问（在*图3.16*中以蓝色表示）。
- en: '![Chart, diagram  Description automatically generated](img/B17217_03_16.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图表，示意图  自动生成的描述](img/B17217_03_16.png)'
- en: 'Figure 3.16: Shortest distance graph after visiting node D using Dijkstra’s
    algorithm'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16：使用Dijkstra算法访问节点D后的最短距离图
- en: 'The table remains unchanged, as shown in *Table 3.7*:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 表格保持不变，如*表3.7*所示：
- en: '| **Node** | **Shortest distance from source** | **Previous node** |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| **节点** | **从源节点到最短距离** | **前一个节点** |'
- en: '| A* | 0 | None |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| **A*** | 0 | 无 |'
- en: '| B* | 5 | A |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| **B*** | 5 | A |'
- en: '| C* | 7 | B |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| **C*** | 7 | B |'
- en: '| D* | 7 | F |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| **D*** | 7 | F |'
- en: '| E* | 2 | A |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| **E*** | 2 | A |'
- en: '| F* | 5 | E |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| **F*** | 5 | E |'
- en: 'Table 3.7: Shortest distance table after visiting node F'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.7：访问节点F后的最短距离表
- en: Let’s verify *Table 3.7* with our initial graph. From the graph, we know that
    the shortest distance from **A** to **F** is **5**.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用我们的初始图来验证*表3.7*。从图中我们知道，从**A**到**F**的最短距离是**5**。
- en: According to the table, the shortest distance from the source column for node
    **F** is 5\. This is true. It also tells us that to get to node **F**, we need
    to visit node **E**, and from **E** to node **A**, which is our starting node.
    This is actually the shortest path from node **A** to node **F**.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 根据表格，节点**F**从源节点到最短距离的列是5。这是正确的。它还告诉我们，要到达节点**F**，我们需要访问节点**E**，然后从**E**到我们的起始节点**A**。这实际上是节点**A**到节点**F**的最短路径。
- en: 'Now, we will discuss the Python implementation of Dijkstra’s algorithm to find
    the shortest path. We begin the program for finding the shortest distance by representing
    the table that enables us to track the changes in the graph. For the initial *Figure
    3.8* that we used, here is a dictionary representation of the table to accompany
    the graph representation we showed earlier in the section:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将讨论 Dijkstra 算法的 Python 实现，以找到最短路径。我们通过表示一个表来开始寻找最短距离的程序，该表使我们能够跟踪图中变化。对于我们在本节中使用的初始
    *图 3.8*，以下是表的字典表示，以配合我们之前在节中展示的图表示：
- en: '[PRE20]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The initial state of the table uses `float("inf")` to represent infinity. Each
    key in the dictionary maps to a list. At the first index of the list, the shortest
    distance from the source, node A is stored. At the second index, the previous
    node is stored:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 表的初始状态使用 `float("inf")` 来表示无穷大。字典中的每个键都映射到一个列表。列表的第一个索引存储从源点到节点的最短距离，节点 A 存储在列表的第一个索引处。在第二个索引处，存储前一个节点：
- en: '[PRE21]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Here, the shortest path’s column index is referenced by `DISTANCE`. The previous
    node column’s index is referenced by `PREVIOUS_NODE`.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，最短路径的列索引由 `DISTANCE` 引用，前一个节点的列索引由 `PREVIOUS_NODE` 引用。
- en: 'Firstly, we discuss the helper methods that we will be using while implementing
    the main function to find the shortest path, in other words, `find_shortest_path`.
    The first helper method is `get_shortest_distance`, which returns the shortest
    distance of a node from the source node:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们讨论在实现主函数以找到最短路径时将使用的辅助方法，换句话说，`find_shortest_path`。第一个辅助方法是 `get_shortest_distance`，它返回节点从源节点的最短距离：
- en: '[PRE22]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `get_shortest_distance` function returns the value stored in index 0 of
    the table. At that index, we always store the shortest distance from the starting
    node up to `vertex`. The `set_shortest_distance` function only sets this value
    as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_shortest_distance` 函数返回表中索引 0 存储的值。在该索引处，我们始终存储从起始节点到 `vertex` 的最短距离。`set_shortest_distance`
    函数只设置此值如下：'
- en: '[PRE23]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'When we update the shortest distance of a node, we update its previous node
    using the following method:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们更新一个节点的最短距离时，我们使用以下方法更新其前一个节点：
- en: '[PRE24]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Remember that the `PREVIOUS_NODE` constant equals 1\. In the table, we store
    the value of `previous_node` at `table[vertex][PREVIOUS_NODE]`. To find the distance
    between any two nodes, we use the `get_distance` function:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，`PREVIOUS_NODE` 常量等于 1。在表中，我们在 `table[vertex][PREVIOUS_NODE]` 存储前一个节点的值。要找到任何两个节点之间的距离，我们使用
    `get_distance` 函数：
- en: '[PRE25]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The last helper method is the `get_next_node` function:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个辅助方法是 `get_next_node` 函数：
- en: '[PRE26]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `get_next_node` function resembles a function to find the smallest item
    in a list. The function starts off by finding the unvisited nodes in our table
    by using `visited_nodes` to obtain the difference between the two sets of lists.
    The very first item in the list of `unvisited_nodes` is assumed to be the smallest
    in the shortest distance column of `table`.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_next_node` 函数类似于一个在列表中找到最小项的函数。该函数首先通过使用 `visited_nodes` 获取两个列表集之间的差集来找到表中未访问的节点。`unvisited_nodes`
    列表中的第一个项目被假定为最短距离列中最小的。'
- en: If a lesser value is found while the `for` loop runs, `min_vertex` will be updated.
    The function then returns `min_vertex` as the unvisited vertex or node with the
    smallest shortest distance from the source.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在 `for` 循环运行时找到较小的值，则更新 `min_vertex`。然后函数返回 `min_vertex` 作为未访问的顶点或节点，它从源节点具有最小的最短距离。
- en: 'Now all is set up for the main function of the algorithm, in other words, `find_shortest_path`,
    as shown here:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在所有设置都已就绪，算法的主函数，即 `find_shortest_path`，如下所示：
- en: '[PRE27]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In the preceding code, the function takes the graph, represented by the adjacency
    list, the table, and the starting node as input parameters. We keep the list of
    visited nodes in the `visited_nodes` list. The `current_node` and `starting_node`
    variables both point to the node in the graph that we choose to make our starting
    node. The `origin` value is the reference point for all other nodes with respect
    to finding the shortest path.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，该函数以图（由邻接表表示）、表和起始节点作为输入参数。我们保持 `visited_nodes` 列表中的已访问节点列表。`current_node`
    和 `starting_node` 变量都指向图中我们选择的起始节点。`origin` 值是相对于找到最短路径的所有其他节点的参考点。
- en: The main process of the function is implemented by the `while` loop. Let’s break
    down what the `while` loop is doing. In the body of the `while` loop, we consider
    the current node in the graph that we want to investigate and initially get all
    the adjacent nodes of the current node with `adjacent_nodes = graph[current_node]`.
    The `if` statement is used to find out whether all the adjacent nodes of `current_node`
    have been visited.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的主要过程是通过 `while` 循环实现的。让我们分析一下 `while` 循环正在做什么。在 `while` 循环体中，我们考虑我们想要调查的图中的当前节点，并最初通过
    `adjacent_nodes = graph[current_node]` 获取当前节点的所有相邻节点。`if` 语句用于找出 `current_node`
    的所有相邻节点是否都已访问。
- en: When the `while` loop is executed for the first time, `current_node` will contain
    node **A** and `adjacent_nodes` will contain nodes **B**, **D**, and **E**. Furthermore,
    `visited_nodes` will be empty. If all nodes have been visited, we only move on
    to the statements further down the program, otherwise, we begin a whole new step.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `while` 循环第一次执行时，`current_node` 将包含节点 **A**，`adjacent_nodes` 将包含节点 **B**、**D**
    和 **E**。此外，`visited_nodes` 将为空。如果所有节点都已访问，我们只需继续执行程序中的其他语句，否则，我们开始一个新的步骤。
- en: 'The `set(adjacent_nodes).difference(set(visited_nodes))` statement returns
    the nodes that have not been visited. The loop iterates over this list of unvisited
    nodes:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '`set(adjacent_nodes).difference(set(visited_nodes))` 语句返回未访问的节点。循环遍历这个未访问节点的列表：'
- en: '[PRE28]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The `get_shortest_distance(table, vertex)` helper method will return the value
    stored in the shortest distance column of our table, using one of the unvisited
    nodes referenced by `vertex`:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_shortest_distance(table, vertex)` 辅助方法将返回我们表中存储的最短距离列的值，使用由 `vertex` 引用的未访问节点之一：'
- en: '[PRE29]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'When we are examining the adjacent nodes of the starting node, `distance_from_starting_node
    == INFINITY and current_node == starting_node` will evaluate to `True`, in which
    case we only have to find the distance between the starting node and vertex by
    referencing the graph:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们检查起始节点的相邻节点时，`distance_from_starting_node == INFINITY and current_node ==
    starting_node` 将评估为 `True`，在这种情况下，我们只需要通过引用图来找到起始节点和顶点之间的距离：
- en: '[PRE30]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The `get_distance` method is another helper method we use to obtain the value
    (distance) of the edge between `vertex` and `current_node`. If the condition fails,
    then we assign to `total_distance` the sum of the distance from the starting node
    to `current_node` and the distance between `current_node` and `vertex`.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_distance` 方法是我们使用的另一个辅助方法，用于获取 `vertex` 和 `current_node` 之间边的值（距离）。如果条件不满足，那么我们将从起始节点到
    `current_node` 的距离和 `current_node` 到 `vertex` 之间的距离之和赋值给 `total_distance`。'
- en: 'Once we have our total distance, we need to check whether `total_distance`
    is less than the existing data in the shortest distance column of our table. If
    it is less, then we use the two helper methods to update that row:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们得到总距离，我们需要检查 `total_distance` 是否小于我们表中最短距离列中现有的数据。如果是的话，那么我们使用两个辅助方法来更新那一行：
- en: '[PRE31]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'At this point, we add `current_node` to the list of visited nodes:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们将 `current_node` 添加到已访问节点列表中：
- en: '[PRE32]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: If all nodes have been visited, then we must exit the `while` loop. To check
    whether this is the case, we compare the length of the `visited_nodes` list with
    the number of keys in our table. If they have become equal, we simply exit the
    `while` loop.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所有节点都已访问，那么我们必须退出 `while` 循环。为了检查这是否是情况，我们比较 `visited_nodes` 列表的长度与表中键的数量。如果它们已经相等，我们简单地退出
    `while` 循环。
- en: 'The `get_next_node` helper method is used to fetch the next node to visit.
    It is this method that helps us find the minimum value in the shortest distance
    column from the starting nodes using our table. The whole method ends by returning
    the updated table. To print the table, we use the following statements:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_next_node` 辅助方法用于获取下一个要访问的节点。正是这个方法帮助我们使用我们的表从起始节点找到最短距离列中的最小值。整个方法通过返回更新后的表结束。为了打印表，我们使用以下语句：'
- en: '[PRE33]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This is the output for the preceding code snippet:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这是前面代码片段的输出：
- en: '[PRE34]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The running time complexity of Dijkstra’s algorithm depends on how the vertices
    are stored and retrieved. Generally, the min-priority queue is used to store the
    vertices of the graph, thus, the time complexity of Dijkstra’s algorithm depends
    on how the min-priority queue is implemented.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: Dijkstra 算法的运行时间复杂度取决于顶点的存储和检索方式。通常，最小优先队列用于存储图中的顶点，因此，Dijkstra 算法的时间复杂度取决于最小优先队列的实现方式。
- en: In the first case, the vertices are stored numbered from 1 to |*V*| in an array.
    Here, each operation for searching a vertex from the entire array will take O(V)
    time, making the total time complexity O(V2 V² + E) = O(V²). Furthermore, if the
    min-priority queue is implemented using the Fibonacci heap, the time taken for
    each iteration of the loop and extracting the minimum node will take O(|*V*|)
    time. Further, iterating over all the vertices’ adjacent nodes and updating the
    shortest distance takes O(|*E*|) time, and each priority value update takes O(log|*V*|)
    time, which makes O(|*E*| + log|*V*|). Thus, the total running time complexity
    of the algorithm becomes O(|*E*| + |*V*|*log* |*V*|), where |*V*| is the number
    of vertices and |*E*| is the number of edges.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下，顶点以从1到|*V*|的编号存储在数组中。在这里，从整个数组中搜索顶点的每个操作将花费O(V)的时间，使得总的时间复杂度为O(V² +
    E) = O(V²)。此外，如果使用斐波那契堆实现最小优先队列，则循环的每次迭代和提取最小节点所需的时间为O(|*V*|)时间。进一步地，遍历所有顶点的相邻节点并更新最短距离需要O(|*E*|)时间，每个优先值更新需要O(log|*V*|)时间，这使得O(|*E*|
    + log|*V*|)。因此，算法的总运行时间复杂度变为O(|*E*| + |*V*|*log* |*V*|)，其中|*V*|是顶点的数量，|*E*|是边的数量。
- en: Summary
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Algorithm design techniques are very important in order to formulate, understand,
    and develop an optimal solution to a complex problem. In this chapter, we have
    discussed algorithm design techniques, which are very important in the field of
    computer science. Important categories of algorithm design, such as dynamic programming,
    greedy approach, and divide and conquer, we discussed in detail along with implementations
    of important algorithms.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 算法设计技术在制定、理解和开发复杂问题的最优解方面非常重要。在本章中，我们讨论了算法设计技术，这在计算机科学领域非常重要。我们详细讨论了重要的算法设计类别，如动态规划、贪婪方法和分治，并附上了重要算法的实现。
- en: The dynamic programming and divide-and-conquer techniques are quite similar
    in the sense that both solve a bigger problem by combining the solutions of the
    sub-problems. Here, the divide-and-conquer technique partitions the problem into
    disjointed sub-problems, solving them recursively, and then combines the solutions
    of the sub-problems to obtain the solution of the original problem, whereas, in
    dynamic programming, this technique is employed when sub-problems overlap, and
    recomputation of the same sub-problem is avoided. Furthermore, in the greedy approach-based
    algorithm design technique, at each step in the algorithm, the best choice is
    taken that looks likely to attain the solution.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 动态规划和分治技术在某种程度上是相似的，因为它们都是通过组合子问题的解来解决更大的问题。在这里，分治技术将问题划分为不相交的子问题，递归地解决它们，然后将子问题的解组合起来以获得原始问题的解，而在动态规划中，当子问题重叠时采用这种技术，以避免对相同子问题的重复计算。此外，在基于贪婪方法的算法设计技术中，在算法的每一步中，都会选择看起来可能达到解的最佳选择。
- en: In the next chapter, we will be discussing important data structures such as
    `Linked` `Lists` and `Pointer` `Structures`.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论重要的数据结构，例如`链表`和`指针结构`。
- en: Exercises
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Which of the following options will be correct when a top-down approach of dynamic
    programming will be applied to solve a given problem related to the space and
    time complexity?
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当应用自顶向下的动态规划方法来解决与空间和时间复杂度相关的问题时，以下哪个选项将是正确的？
- en: It will increase both time and space complexity.
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将同时增加时间和空间复杂度。
- en: It will increase the time complexity, and decrease the space complexity
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将增加时间复杂度，并减少空间复杂度
- en: It will increase the space complexity, and decrease the time complexity
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将增加空间复杂度，并减少时间复杂度
- en: It will decrease both time and space complexities.
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将同时减少时间和空间复杂度。
- en: Dijkstra’s single shortest path algorithm is applied on edge weighted directed
    graph shown in Figure 3.17\. What will be the order of the nodes for the shortest
    path distance path (Assume A as source) ?
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迪杰斯特拉单源最短路径算法应用于图3.17所示的带权有向图。假设A为源点，节点最短路径距离的顺序将是什么？
- en: '![](img/B17217_03_17.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17217_03_17.png)'
- en: 'Figure 3.17: An edge-weighted directed graph'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17：一个带权有向图
- en: Consider the weights and values of the items listed in *Table 3.8*. Note that
    there is only one unit of each item.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑*表3.8*中列出的物品的重量和价值。请注意，每种物品只有一个单位。
- en: '| **Item** | **Weight** | **Value** |'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **物品** | **重量** | **价值** |'
- en: '| A | 2 | 10 |'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| A | 2 | 10 |'
- en: '| B | 10 | 8 |'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| B | 10 | 8 |'
- en: '| C | 4 | 5 |'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| C | 4 | 5 |'
- en: '| D | 7 | 6 |'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| D | 7 | 6 |'
- en: 'Table 3.8: The weights and values of different items'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 表3.8：不同物品的重量和价值
- en: We need to maximize the value; the maximum weight should be 11 kg. No item may
    be split. Establish the values of the items using a greedy approach.
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要最大化价值；最大重量应为11公斤。任何物品不得分割。使用贪婪算法确定物品的价值。
- en: Join our community on Discord
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers: [https://packt.link/MEvK4](https://packt.link/MEvK4)'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的Discord空间，与作者和其他读者进行讨论：[https://packt.link/MEvK4](https://packt.link/MEvK4)
- en: '![](img/QR_Code1421249772551223062.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code1421249772551223062.png)'
