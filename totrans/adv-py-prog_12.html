<html><head></head><body>
<div><div><div><h1 id="_idParaDest-189"><em class="italic"><a id="_idTextAnchor180"/>Chapter 10</em>: Concurrent Image Processing</h1>
			<p>This chapter discusses the task of processing and manipulating images via concurrent programming, specifically multiprocessing. Since images are processed independently of one another, concurrent programming is an attractive option for achieving a significant speedup. This chapter lays out the basics behind image processing techniques, illustrates the improvements that concurrent programming provides, and goes over some of the best practices that are used in image processing applications. This discussion will consolidate our knowledge of how to leverage concurrent and parallel processing tools in Python.</p>
			<p>The following topics will be covered in this chapter:</p>
			<ul>
				<li>Image processing fundamentals</li>
				<li>Applying concurrency to image processing</li>
				<li>Good concurrent image processing practices</li>
			</ul>
			<h1 id="_idParaDest-190"><a id="_idTextAnchor181"/>Technical requirements</h1>
			<p>The following is a list of prerequisites for this chapter:</p>
			<ul>
				<li>You must have Python 3 installed on your computer.</li>
				<li>You must have OpenCV and NumPy installed for your Python 3 distribution.</li>
			</ul>
			<p>The code for this chapter can be found in the following GitHub repository: <a href="https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter10">https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter10</a>.</p>
			<h1 id="_idParaDest-191"><a id="_idTextAnchor182"/>Image processing fundamentals</h1>
			<p><strong class="bold">Digital/computational image processing</strong> (which we will refer to as <strong class="bold">image processing</strong> from this point forward) has <a id="_idIndexMarker812"/>become so popular in the modern era that it exists in numerous aspects of our everyday life. Image processing and manipulation are involved when you take a picture with your camera or phone using different filters, such as when advanced image editing software such as Adobe Photoshop is used, or even when you simply edit images using Microsoft Paint.</p>
			<p>Many of the techniques and algorithms that are used in image processing were developed in the early 1960s for various purposes such as medical imaging, satellite image analysis, character recognition, and so on. However, these image processing techniques required significant computing power, and the fact that the available computer equipment at the time was unable to accommodate the need for fast number-crunching slowed down the use of image processing.</p>
			<p>Fast-forwarding to the future, when powerful computers with fast, multicore processors were developed, image processing techniques became much more accessible, and research on image processing increased significantly. Nowadays, numerous image processing <a id="_idIndexMarker813"/>applications are being actively developed <a id="_idIndexMarker814"/>and studied, including pattern recognition, classification, feature <a id="_idIndexMarker815"/>extraction, and more. Some of <a id="_idIndexMarker816"/>the specific image processing techniques that take advantage of concurrent and parallel programming, and would otherwise be extremely computationally time-consuming, include <strong class="bold">Hidden Markov models</strong>, <strong class="bold">independent component analysis</strong>, and even <strong class="bold">neural network models</strong>.</p>
			<p>The following is one <a id="_idIndexMarker817"/>of the simplest forms of image processing, where we convert a fully colored image into a grayscale one. This process is called <strong class="bold">grayscaling</strong>:</p>
			<div><div><img src="img/B17499_Figure_10.1.jpg" alt="Figure 10.1 – An example use of image processing – grayscaling " width="1088" height="150"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.1 – An example use of image processing – grayscaling</p>
			<p>Later in this chapter, we will see how grayscaling, along with other processing techniques, can be done using Python. To do this, we must install the necessary libraries and packages.</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor183"/>Python as an image processing tool</h2>
			<p>As we have stated multiple times throughout this book, the Python programming language is on <a id="_idIndexMarker818"/>its way to becoming the most popular programming<a id="_idIndexMarker819"/> language. This is especially true in the field of computational image processing, which, most of the time, requires fast prototyping and designing, as well as significant automation capabilities.</p>
			<p>As we will find out in the following section, digital images are represented in two-dimensional and three-dimensional matrices so that computers can process them easily. Consequently, most of the time, digital image processing involves matrix calculation. Multiple Python libraries and modules not only provide efficient matrix calculation options but also interact seamlessly with other libraries that handle image reading/writing.</p>
			<p>As we already know, automating tasks and making them concurrent is Python's strong suit. This makes Python <a id="_idIndexMarker820"/>the prime candidate to implement your image processing applications. For this chapter, we will be working with two main Python libraries: <strong class="bold">OpenCV</strong> (which stands for <strong class="bold">Open Source Computer Vision</strong>), which is a library that provides image processing and computer vision options in C++, Java, and Python, and NumPy, which, as we know, is one of the most popular Python modules and performs efficient and parallelizable number-crunching calculations. Let's see how we can install these libraries.</p>
			<h3 id="_idParaDest-193">Installing OpenCV and NumPy</h3>
			<p>To install NumPy for <a id="_idIndexMarker821"/>your Python <a id="_idIndexMarker822"/>distribution using the <code>pip</code> package manager, run the following command:</p>
			<pre>pip install numpy</pre>
			<p>If you are using Anaconda/Miniconda to manage your packages, you must run the following command instead:</p>
			<pre>conda install numpy</pre>
			<p>Installing OpenCV might be more complicated, depending on your operating system. The easiest option is to have Anaconda handle the installation process by following the guide at <a href="https://anaconda.org/conda-forge/opencv">https://anaconda.org/conda-forge/opencv</a> after installing Anaconda (<a href="https://www.anaconda.com/download/">https://www.anaconda.com/download/</a>) as your main Python package manager. If, however, you <a id="_idIndexMarker823"/>are not using Anaconda, the main option for installing OpenCV is to follow its official documentation guide, which can be found at <a href="https://docs.opencv.org/master/df/d65/tutorial_table_of_content_introduction.html">https://docs.opencv.org/master/df/d65/tutorial_table_of_content_introduction.html</a>. After successfully installing OpenCV, open a Python interpreter and try importing the library, as follows:</p>
			<pre>&gt;&gt;&gt; import cv2
&gt;&gt;&gt; print(cv2.__version__)
4.5.2</pre>
			<p>We will import OpenCV <a id="_idIndexMarker824"/>using the name <code>cv2</code>, which is <a id="_idIndexMarker825"/>the library alias of OpenCV in Python. The success message indicates the version of the OpenCV library that has been downloaded (4.5.2).</p>
			<h2 id="_idParaDest-194"><a id="_idTextAnchor184"/>Computer image basics</h2>
			<p>Before we jump into processing and manipulating digital image files, we need to discuss the fundamentals of <a id="_idIndexMarker826"/>those files and how computers interpret data from them. Specifically, we need to understand how data regarding the colors and coordinates of individual pixels in an image file is represented, as well as how to extract it using Python.</p>
			<h3 id="_idParaDest-195">RGB values</h3>
			<p>RGB values are the basics of how colors are represented digitally. Standing for <strong class="bold">red</strong>, <strong class="bold">green</strong>, and <strong class="bold">blue</strong> (<strong class="bold">RGB</strong>), these values are constructed from the fact that all colors can be generated from a <a id="_idIndexMarker827"/>specific combination of red, green, and <a id="_idIndexMarker828"/>blue. So, an RGB value is a tuple of three integer numbers, each of which ranges from 0 (which indicates no color at all) to 255 (which indicates the deepest shade of that specific color).</p>
			<p>For example, red corresponds to the tuple (255, 0, 0); in this tuple, there is only the highest value for red and no values for the other colors, so the whole tuple represents the pure color red. Similarly, blue is represented by (0, 0, 255), while green is represented by (0, 255, 0). Yellow is the result of mixing equal amounts of red and green and is therefore represented by (255, 255, 0) (the maximum amount of red and green, with no blue). White, which <a id="_idIndexMarker829"/>is the combination of <a id="_idIndexMarker830"/>all three colors, is (255, 255, 255), while black, which is the opposite of white and therefore lacks all colors, is represented by (0, 0, 0). </p>
			<p>This is illustrated by the following diagram:</p>
			<div><div><img src="img/B17499_Figure_10.2.jpg" alt="Figure 10.2 – Illustration of RGB values " width="914" height="225"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.2 – Illustration of RGB values</p>
			<h3 id="_idParaDest-196">Pixels and image files</h3>
			<p>So, an RGB value indicates a specific color, but how do we connect this to a computer image? If we <a id="_idIndexMarker831"/>were to view an image on our computer and try to <a id="_idIndexMarker832"/>zoom in as much as we could, we would observe <a id="_idIndexMarker833"/>that as we zoom in deeper and deeper, the image will start <a id="_idIndexMarker834"/>breaking apart into increasingly discernible colored squares. These squares are called pixels, which are the smallest units of color on a computer display or in a digital image:</p>
			<div><div><img src="img/B17499_Figure_10.3.jpg" alt="Figure 10.3 – Examples of pixels in digital images " width="453" height="183"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.3 – Examples of pixels in digital images</p>
			<p>A set of different pixels arranged in a tabular format (rows and columns of pixels) makes up a computer image. Each pixel, in turn, is an RGB value; in other words, a pixel is a tuple of three integers. This means that a computer image is simply a two-dimensional array of tuples, whose sides correspond to the size of the image. For example, a 128 x 128 image has 128 rows and 128 columns of RGB tuples for its data.</p>
			<h3 id="_idParaDest-197">Coordinates inside an image</h3>
			<p>Like indexing two-dimensional arrays, the coordinate for a digital image pixel is a pair of two integers, representing the <em class="italic">x</em>- and <em class="italic">y</em>-coordinates of that pixel; the <em class="italic">x</em>-coordinate indicates the pixel's <a id="_idIndexMarker835"/>location along the horizontal axis starting from the left, while the <em class="italic">y</em>-coordinate indicates the pixel's location along the vertical axis starting from the top.</p>
			<p>Here, we can see how heavy computational number-crunching processes are typically involved when it comes to image processing since each image is a matrix of integer tuples. This also suggests that, with the help of the NumPy library and concurrent programming, we can achieve significant improvements in execution time for Python image processing applications.</p>
			<p>Following the convention of indexing two-dimensional arrays in NumPy, the location of a pixel is still a pair of integers, but the first number indicates the index of the row containing the pixel, which corresponds to the <em class="italic">y</em>-coordinate, and similarly, the second number indicates the <em class="italic">x</em>-coordinate of the pixel.</p>
			<h2 id="_idParaDest-198"><a id="_idTextAnchor185"/>OpenCV API</h2>
			<p>There are a surprising number of methods for reading in, performing image processing, and displaying a <a id="_idIndexMarker836"/>digital image file in Python. However, OpenCV provides some of the easiest and most intuitive options to do this. One important thing to note regarding OpenCV is that it inverts RGB values as BGR values when interpreting its images. So, instead of red, green, and blue in order, the tuples in an image matrix will represent blue, green, and red, in that order.</p>
			<p>Let's look at an example of interacting with OpenCV in Python:</p>
			<pre>import cv2
im = cv2.imread('input/ship.jpg')
cv2.imshow('Test', im)
cv2.waitKey(0) # press any key to move forward here
print(im)
print('Type:', type(im))
print('Shape:', im.shape)
print('Top-left pixel:', im[0, 0])
print('Done.')</pre>
			<p>There are a few methods from OpenCV that have been used in this script that we need to discuss:</p>
			<ul>
				<li><code>cv2.imread()</code>: This method takes in a path to an image file (compatible file extensions include <code>.jpeg</code>, <code>.jpg</code>, <code>.png</code>, and so on) and returns an image object, which, as we will see later, is represented by a NumPy array.</li>
				<li><code>cv2.imshow()</code>: This method takes in a string and an image object and displays it in a separate <a id="_idIndexMarker837"/>window. The title of the window is specified by the passed-in string. The method should always be followed by the <code>cv2.waitKey()</code> method.</li>
				<li><code>cv2.waitKey()</code>: This method takes in a number and blocks the program for a corresponding number of milliseconds unless the number <code>0</code> is passed in, in which case it will block indefinitely until the user presses a key on their keyboard. This method should always follow the <code>cv2.imshow()</code> method.</li>
			</ul>
			<p>After calling <code>cv2.imshow()</code> on the <code>ship.jpg</code> file inside the input subfolder so that it's displayed from the Python interpreter, the program will stop until a key is pressed, at which point it will execute the rest of the program. If run successfully, the script will display the following output:</p>
			<div><div><img src="img/B17499_Figure_10.4.jpg" alt="Figure 10.4 – Displaying an image using OpenCV " width="1296" height="795"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.4 – Displaying an image using OpenCV</p>
			<p>You should also <a id="_idIndexMarker838"/>obtain the following output for the rest of the main program after pressing any key to close the displayed picture:</p>
			<pre>&gt; python example1.py
[[[199 136 86]
  [199 136 86]
  [199 136 86]
  ..., 
  [198 140 81]
  [197 139 80]
  [201 143 84]]
[...Truncated for readability...]
 [[ 56 23 4]
  [ 59 26 7]
  [ 60 27 7]
  ..., 
  [ 79 43 7]
  [ 80 44 8]
  [ 75 39 3]]]
Type: &lt;class 'numpy.ndarray'&gt;
Shape: (1118, 1577, 3)
Top-left pixel: [199 136 86]
Done.</pre>
			<p>The output confirms a few of the things that we discussed earlier:</p>
			<ul>
				<li>First, when printing out the image object that was returned by the <code>cv2.imread()</code> function, we obtained a matrix of numbers.</li>
				<li>Using the <code>type()</code> method from Python, we found that the class of this matrix is indeed a NumPy array: <code>numpy.ndarray</code>.</li>
				<li>Calling the <code>shape</code> attribute of the array, we can see that the image is a three-dimensional matrix <a id="_idIndexMarker839"/>of the shape (<code>1118</code>, <code>1577</code>, <code>3</code>), which corresponds to a table with <code>1118</code> rows and <code>1577</code> columns, each element of which is a pixel (three-number tuple). The numbers for the rows and columns also correspond to the size of the image.</li>
				<li>Focusing on the top-left pixel in the matrix (the first pixel in the first row; that is, <code>im[0, 0]</code>), we obtained the BGR value of (<code>199</code>, <code>136</code>, <code>86</code>) – <code>199</code> blue, <code>136</code> green, and <code>86</code> red. By looking up this BGR value through any online converter, we can see that this is a light blue that corresponds to the sky, which is the upper part of the image.</li>
			</ul>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor186"/>Image processing techniques</h2>
			<p>We have already seen some Python APIs that are provided by OpenCV to read data from image files. Before we <a id="_idIndexMarker840"/>can use OpenCV to perform various image processing tasks, let's discuss the theoretical foundation for several techniques that are commonly used in image processing.</p>
			<h3 id="_idParaDest-200">Grayscaling</h3>
			<p>We saw an example of grayscaling earlier in this chapter. Arguably one of the most widely used image processing <a id="_idIndexMarker841"/>techniques, grayscaling is the <a id="_idIndexMarker842"/>process of reducing the dimensionality of the image pixel matrix by only considering the intensity information of each pixel, which is represented by the amount of light available.</p>
			<p>As a result, the pixels of grayscale images no longer hold three-dimensional information (red, green, and blue), and only one-dimensional black-and-white data. These images are exclusively composed of shades of gray, with black indicating the weakest light intensity and white indicating the strongest.</p>
			<p>Grayscaling serves many important purposes in image processing. Firstly, as we mentioned previously, it reduces the dimensionality of the image pixel matrix by mapping traditional three-dimensional color data to one-dimensional gray data. So, instead of having to analyze and process three layers of color data, image processing programs only have to do one-third of the job with grayscale images. Additionally, by only representing colors using one spectrum, important patterns in the image are more likely to be recognized with just black and white data.</p>
			<p>There are multiple algorithms for converting color into grayscale: colorimetric conversion, luma coding, single-channel, and more. Luckily, we do not have to implement one ourselves, as the OpenCV library provides a one-line method to convert normal images into grayscale ones. Still using the image of a ship from the previous example, let's look at another example:</p>
			<pre>import cv2
im = cv2.imread('input/ship.jpg')
gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
cv2.imshow('Grayscale', gray_im)
cv2.waitKey(0) # press any key to move forward here
print(gray_im)
print('Type:', type(gray_im))
print('Shape:', gray_im.shape)
cv2.imwrite('output/gray_ship.jpg', gray_im)
print('Done.')</pre>
			<p>In this example, we <a id="_idIndexMarker843"/>are using the <code>cvtColor()</code> method from OpenCV to convert our original <a id="_idIndexMarker844"/>image into a grayscale one. After running this script, the following output should be displayed on your computer:</p>
			<div><div><img src="img/B17499_Figure_10.5.jpg" alt="Figure 10.5 – Output from grayscaling " width="1650" height="1096"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.5 – Output from grayscaling</p>
			<p>By pressing any <a id="_idIndexMarker845"/>key to unblock your program, you <a id="_idIndexMarker846"/>should obtain the following output:</p>
			<pre>&gt; python example2.py
[[128 128 128 ..., 129 128 132]
 [125 125 125 ..., 129 128 130]
 [124 125 125 ..., 129 129 130]
 ..., 
 [ 20 21 20 ..., 38 39 37]
 [ 19 22 21 ..., 41 42 37]
 [ 21 24 25 ..., 36 37 32]]
Type: &lt;class 'numpy.ndarray'&gt;
Shape: (1118, 1577)
Done.</pre>
			<p>Here, we can see that the structure of our grayscale image object is different from what we saw with our <a id="_idIndexMarker847"/>original image object. Even though it is still <a id="_idIndexMarker848"/>represented by a NumPy array, it is now a two-dimensional array of integers, each of which ranges from 0 (for black) to 255 (for white). The table of pixels, however, still consists of <code>1118</code> rows and <code>1577</code> columns.</p>
			<p>In this example, we also used the <code>cv2.imwrite()</code> method, which saves the image object to your local computer. This means that the grayscale image can be found in the output subfolder of this chapter's folder, as specified in our code.</p>
			<h3 id="_idParaDest-201">Thresholding</h3>
			<p>Another important technique in image processing is <strong class="bold">thresholding</strong>. Intending to categorize each pixel in <a id="_idIndexMarker849"/>a digital image into different <a id="_idIndexMarker850"/>groups (also known as <strong class="bold">image segmentation</strong>), thresholding provides <a id="_idIndexMarker851"/>a quick and intuitive way to create binary images (with just black and white pixels).</p>
			<p>The idea behind thresholding is to replace each pixel in an image with a white pixel if the pixel's intensity is greater than a previously specified threshold, and with a black pixel if the pixel's intensity is less than that threshold. Similar to the goal of grayscaling, thresholding amplifies the differences between high- and low-intensity pixels, and from that, important features and patterns in an image can be recognized and extracted.</p>
			<p>Recall that grayscaling converts a fully colored image into a version that only has different shades of gray; in this case, each pixel has a value of an integer ranging from 0 to 255. From a grayscale image, thresholding can convert it into a fully black-and-white one, each pixel of which is now only either 0 (black) or 255 (white). So, after performing thresholding on an image, each pixel of that image can only hold two possible values, further reducing the complexity of our image data.</p>
			<p>So, the key to an effective thresholding process is finding an appropriate threshold so that the pixels in an image are segmented in a way that allows separate regions in the image to become more obvious. The simplest form of thresholding is to use a constant threshold to process all the pixels throughout a whole image. Let's consider an example of this method:</p>
			<pre>import cv2
im = cv2.imread('input/ship.jpg')
gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
ret, custom_thresh_im = cv2.threshold(gray_im, 127, 255, \
  cv2.THRESH_BINARY)
cv2.imwrite('output/custom_thresh_ship.jpg', \
  custom_thresh_im)
print('Done.')</pre>
			<p>In this example, after <a id="_idIndexMarker852"/>converting the image of a ship that we <a id="_idIndexMarker853"/>have been using to grayscale, we called the <code>threshold(src, thresh, maxval, type)</code> function from OpenCV, which takes in the following arguments:</p>
			<ul>
				<li><code>src</code>: This argument takes in the input/source image.</li>
				<li><code>thresh</code>: This is the constant threshold to be used throughout the image. Here, we are using <code>127</code>, as it is simply the middle point between 0 and 255.</li>
				<li><code>maxval</code>: Pixels whose original values are greater than the constant threshold will take this value after the thresholding process. We pass in 255 to specify that those pixels should be completely white.</li>
				<li><code>type</code>: This value indicates the thresholding type that's used by OpenCV. We are performing simple binary thresholding, so we pass in <code>cv2.THRESH_BINARY</code>.</li>
			</ul>
			<p>After running the script, you should be able to find the following image in the output with the name <code>custom_thresh_ship.jpg</code>:</p>
			<div><div><img src="img/B17499_Figure_10.6.jpg" alt="" width="1485" height="1053"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.6 – Output from simple thresholding</p>
			<p>Here, we can see that with a simple threshold (<code>127</code>), we have obtained an image that highlights separate regions of the image: the sky, the ship, and the sea. However, there are several problems that this simple thresholding method poses, the most common of which is finding the appropriate constant threshold. Since different images have different color tones, lighting conditions, and so on, it is undesirable to use a static value across different images as their thresholds.</p>
			<p>This issue is addressed <a id="_idIndexMarker854"/>by adaptive thresholding methods, which <a id="_idIndexMarker855"/>use different thresholds whose values are dynamically <a id="_idIndexMarker856"/>determined for small regions of an image. This process <a id="_idIndexMarker857"/>allows the threshold to adjust according to the input image, and not depend solely on a static value. Let's consider two examples of these adaptive thresholding methods, namely <strong class="bold">Adaptive Mean Thresholding</strong> and <strong class="bold">Adaptive Gaussian Thresholding</strong>:</p>
			<pre>import cv2
im = cv2.imread('input/ship.jpg')
im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
mean_thresh_im = cv2.adaptiveThreshold(im, 255, 
  cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
cv2.imwrite('output/mean_thresh_ship.jpg', mean_thresh_im)
gauss_thresh_im = cv2.adaptiveThreshold(im, 255, 
  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
cv2.imwrite('output/gauss_thresh_ship.jpg', \
  gauss_thresh_im)
print('Done.')</pre>
			<p>Similar to what we did with the <code>cv2.threshold()</code> method earlier, here, we are converting the original image into its grayscale version, and then we are passing it to the <code>adaptiveThreshold()</code> method from OpenCV. This method takes in similar arguments to the <code>cv2.threshold()</code> method, except that instead of taking in a constant to be the threshold, it takes in an argument for the adaptive method. We used <code>cv2.ADAPTIVE_THRESH_MEAN_C</code> and <code>cv2.ADAPTIVE_THRESH_GAUSSIAN_C</code>, respectively.</p>
			<p>The second to last argument specifies the size of the window to perform thresholding on; this number <a id="_idIndexMarker858"/>has to be an odd positive integer. Specifically, we used 11 in our example, so for each pixel in the image, the algorithm will consider <a id="_idIndexMarker859"/>the neighboring pixels (in an 11 x 11 square surrounding the original pixel). The last argument specifies the adjustment to make for each pixel in the final output. These two arguments, again, help localize the threshold for different regions of the image, thus making the thresholding process more dynamic and, as its name suggests, adaptive.</p>
			<p>After running the script, you should be able to find the following images as output with the names <code>mean_thresh_ship.jpg</code> and <code>gauss_thresh_ship.jpg</code>. The output for <code>mean_thresh_ship.jpg</code> is as follows:</p>
			<div><div><img src="img/B17499_Figure_10.7.jpg" alt="Figure 10.7 – Output from mean thresholding " width="1650" height="969"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.7 – Output from mean thresholding</p>
			<p>The <a id="_idIndexMarker860"/>output for <code>gauss_thresh_ship.jpg</code> is <a id="_idIndexMarker861"/>as follows:</p>
			<div><div><img src="img/B17499_Figure_10.8.jpg" alt="Figure 10.8 – Output from Gaussian thresholding " width="1650" height="959"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.8 – Output from Gaussian thresholding</p>
			<p>Here, we can see that with adaptive thresholding, details in specific regions will be thresholded and highlighted in the final output image. These techniques are useful when we need to recognize small details in an image, while simple thresholding is useful when we only want to extract big regions of an image.</p>
			<p>We have talked a lot about the basics of image processing and some common image processing techniques. We also know why image processing is a heavy number-crunching task, and <a id="_idIndexMarker862"/>that concurrent and parallel <a id="_idIndexMarker863"/>programming can be applied to speed up independent processing tasks. In the next section, we will look at a specific example of how to implement a concurrent image processing application that can handle a large number of input images.</p>
			<h1 id="_idParaDest-202"><a id="_idTextAnchor187"/>Applying concurrency to image processing</h1>
			<p>First, head to the <a id="_idIndexMarker864"/>current folder for this chapter's <a id="_idIndexMarker865"/>code. Inside the <code>input</code> folder, there is a subfolder called <code>large_input</code>, which contains 400 images that we will be using for this example. These pictures are of different regions in our original ship image, and they have been cropped from it using the <em class="italic">array-indexing</em> and <em class="italic">-slicing</em> options that NumPy provides for slicing OpenCV image objects. If you are curious as to how these images were generated, check out the <code>generate_input.py</code> file.</p>
			<p>Our goal in this section is to implement a program that can concurrently process these images using thresholding. To do this, let's look at the <code>example5.py</code> file:</p>
			<pre>from multiprocessing import Pool
import cv2
    
import sys
from timeit import default_timer as timer
    
    
THRESH_METHOD = cv2.ADAPTIVE_THRESH_GAUSSIAN_C
INPUT_PATH = 'input/large_input/'
OUTPUT_PATH = 'output/large_output/'
    
n = 20
names = ['ship_%i_%i.jpg' % (i, j) for i in range(n) \
for j in range(n)]
    
    
def process_threshold(im, output_name, thresh_method):
    gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
    thresh_im = cv2.adaptiveThreshold(
      gray_im, 255, thresh_method, \
        cv2.THRESH_BINARY, 11, 2
    )
    
    cv2.imwrite(OUTPUT_PATH + output_name, thresh_im)
    
    
if __name__ == '__main__':
    
    for n_processes in range(1, 7):
        start = timer()
    
        with Pool(n_processes) as p:
            p.starmap(
              process_threshold, 
              [(
                cv2.imread(INPUT_PATH + name), \
                name,THRESH_METHOD) 
                  for name in names
              ],
            )
    
        print('Took %.4f seconds with %i process(es). \
              ' % (timer() - start, n_processes))
    
    print('Done.')</pre>
			<p>In this example, we are using the <code>Pool</code> class from the <code>multiprocessing</code> module to manage our processes. As a refresher, a <code>Pool</code> object supplies convenient options to map a sequence of inputs to separate processes using the <code>Pool.map()</code> method. We are using the <code>Pool.starmap()</code> method in our example, however, to pass multiple arguments to the target function.</p>
			<p>At the beginning of our program, we make several housekeeping assignments: the thresholding method to perform adaptive thresholding when processing the images, the paths for the input and output folders, and the names of the images to process. The <code>process_threshold()</code> function is what we use to process the images; it takes in an image object, the name for the processed version of the image, and which thresholding method to use. Again, this is why we need to use the <code>Pool.starmap()</code> method instead of the traditional <code>Pool.map()</code> method.</p>
			<p>In the main program, to demonstrate the difference in performance between sequential and multiprocessing <a id="_idIndexMarker866"/>image processing, we <a id="_idIndexMarker867"/>want to run our program with different numbers of processes, specifically from one single process to six different processes. In each iteration of the <code>for</code> loop, we initialize a <code>Pool</code> object and map the necessary arguments of each image to the <code>process_threshold()</code> function, while keeping track of how much time it takes to process and save all of the images.</p>
			<p>After running the script, the processed images can be found in the <code>output/large_output/</code> subfolder in our current chapter's folder. You should obtain an output similar to the following:</p>
			<pre>&gt; python example5.py
Took 0.6590 seconds with 1 process(es).
Took 0.3190 seconds with 2 process(es).
Took 0.3227 seconds with 3 process(es).
Took 0.3360 seconds with 4 process(es).
Took 0.3338 seconds with 5 process(es).
Took 0.3319 seconds with 6 process(es).
Done.</pre>
			<p>We can see a big difference in execution time when we go from one single process to two separate processes. However, there is negligible or even negative speedup after going from two to higher numbers of processes. Generally, this is because of the heavy overhead, which is the product of implementing many separate processes, in comparison to a relatively low number of inputs.</p>
			<p>So far, we have seen that concurrent programming could provide a significant speedup for image processing applications. However, if we take a look at our preceding program, we can see that there are additional adjustments that we can make to improve the execution time even further. Specifically, in the preceding program, we are sequentially reading in images by using list comprehension in the following line:</p>
			<pre>with Pool(n_processes) as p:
    p.starmap(process_threshold, [(
        cv2.imread(INPUT_PATH + name), \
          name,THRESH_METHOD)
         for name in names])</pre>
			<p>Theoretically, if we were to make the process of reading in different image files concurrent, we <a id="_idIndexMarker868"/>could also gain additional <a id="_idIndexMarker869"/>speedup with our program. This is especially true in an image processing application that deals with large input files, where significant time is spent waiting for input to be read. With that in mind, let's consider the following example, in which we will implement concurrent input/output processing:</p>
			<pre>from multiprocessing import Pool
import cv2
    
import sys
from functools import partial
from timeit import default_timer as timer
    
    
THRESH_METHOD = cv2.ADAPTIVE_THRESH_GAUSSIAN_C
INPUT_PATH = 'input/large_input/'
OUTPUT_PATH = 'output/large_output/'
    
n = 20
names = ['ship_%i_%i.jpg' % (i, j) for i in range(n) for \
  j in range(n)]
    
    
def process_threshold(name, thresh_method):
    im = cv2.imread(INPUT_PATH + name)
    gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
    thresh_im = cv2.adaptiveThreshold( \
      gray_im, 255, thresh_method, cv2.THRESH_BINARY, 11, 2 \
     )
    
    cv2.imwrite(OUTPUT_PATH + name, thresh_im)
    
if __name__ == '__main__':
    
    for n_processes in range(1, 7):
        start = timer()
    
        with Pool(n_processes) as p:
            p.map(partial(process_threshold, \
              thresh_method=THRESH_METHOD), names)
    
        print('Took %.4f seconds with %i process(es).' % \
          (timer() - start, n_processes))
        
    print('Done.')</pre>
			<p>The structure of this program is similar to that of the previous one. However, instead of preparing the <a id="_idIndexMarker870"/>necessary images to be processed and <a id="_idIndexMarker871"/>other relevant input information, we implement them inside the <code>process_threshold()</code> function, which now only takes the name of the input image and handles reading the image itself.</p>
			<p>As a side note, we are using Python's built-in <code>functools.partial()</code> method in our main program to pass in a partial argument (hence the name), specifically <code>thresh_method</code>, to the <code>process_threshold()</code> function, as this argument is fixed across <a id="_idIndexMarker872"/>all images and processes. More information about this tool can be found at <a href="https://docs.python.org/3/library/functools.html">https://docs.python.org/3/library/functools.html</a>.</p>
			<p>After running the script, you should obtain an output similar to the following:</p>
			<pre>&gt; python example6.py
Took 0.5300 seconds with 1 process(es).
Took 0.4133 seconds with 2 process(es).
Took 0.2154 seconds with 3 process(es).
Took 0.2147 seconds with 4 process(es).
Took 0.2213 seconds with 5 process(es).
Took 0.2329 seconds with 6 process(es).
Done.</pre>
			<p>Compared to <a id="_idIndexMarker873"/>our previous output, this implementation <a id="_idIndexMarker874"/>of the application gives us a significantly better execution time!</p>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor188"/>Good concurrent image processing practices</h1>
			<p>So far, you have most likely realized that image processing is quite an involved process and that implementing <a id="_idIndexMarker875"/>concurrent and parallel programming in an image processing application can add more complexity to our work. There are, however, good practices that will guide us in the right direction while developing our image processing applications. The following sections discuss some of the most common practices that we should keep in mind.</p>
			<h2 id="_idParaDest-204"><a id="_idTextAnchor189"/>Choosing the correct way (out of many)</h2>
			<p>We have hinted at this practice briefly when we learned about thresholding. How an image processing <a id="_idIndexMarker876"/>application handles and processes its image data heavily depends on the problems it is supposed to solve, and what kind of data will be fed to it. Therefore, there is significant variability when it comes to choosing specific parameters when processing your image.</p>
			<p>For example, as we saw <a id="_idIndexMarker877"/>earlier, there are various ways to threshold an image, and each will result in a very different output: if you want to focus on only the large, distinct regions of an image, <strong class="bold">simple constant thresholding</strong> will prove to be more beneficial than <strong class="bold">adaptive thresholding</strong>; if, however, you want to <a id="_idIndexMarker878"/>highlight small changes in the details of an image, adaptive thresholding will be significantly better.</p>
			<p>Let's consider another example, in which we will see how tuning a specific parameter for an image processing function <a id="_idIndexMarker879"/>results in better output. In this example, we are using a simple <strong class="bold">Haar Cascade model</strong> to detect faces in images. We will not go too deeply into how the model handles and processes its data since it is already built into OpenCV; again, we are only using this model at a high level, changing its parameters to obtain different results.</p>
			<p>Navigate to the <code>example7.py</code> file in this chapter's folder. The script is designed to detect the faces in the <code>obama1.jpeg</code> and <code>obama2.jpg</code> images in our input folder:</p>
			<pre>import cv2
    
face_cascade = cv2.CascadeClassifier \
  ('input/haarcascade_frontalface_default.xml')
    
for filename in ['obama1.jpeg', 'obama2.jpg']:
    im = cv2.imread('input/' + filename)
    gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(im)
    
    for (x, y, w, h) in faces:
        cv2.rectangle(im, (x, y), (x + w, y + h), \
          (0, 255, 0), 2)
    
    cv2.imshow('%i face(s) found' % len(faces), im)
    cv2.waitKey(0)
    
print('Done.')</pre>
			<p>First, the program loads the pre-trained Haar Cascade model from the <code>input</code> folder using the <code>cv2.CascadeClassifier</code> class. For each input image, the script converts it into grayscale <a id="_idIndexMarker880"/>and feeds it to the pre-trained model. The script then draws a green rectangle around each face it found in the image and displays it in a separate window.</p>
			<p>Run the program; you will see the following image with the title <code>5 face(s) found</code>:</p>
			<div><div><img src="img/B17499_Figure_10.9.jpg" alt="Figure 10.9 – Correct face detection " width="310" height="190"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.9 – Correct face detection</p>
			<p>It looks <a id="_idIndexMarker881"/>like our program is working well so far. Press any key to continue. You should see the following image with the title <code>7 face(s) found</code>:</p>
			<div><div><img src="img/B17499_Figure_10.10.jpg" alt="Figure 10.10 – Incorrect face detection " width="1040" height="522"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.10 – Incorrect face detection</p>
			<p>Now, our program is mistaking some other objects as actual faces, resulting in two false positives. The reason behind this involves how the pre-trained model was created. Specifically, the Haar Cascade model used a training dataset with images of specific (pixel) sizes, and when an input image contains faces of different sizes – which is common when it is a group picture with some people being close to the camera, while others being far away – is fed into this model, it will cause false positives in the output.</p>
			<p>The <code>scaleFactor</code> parameter in the <code>detectMultiScale</code> method of the <code>cv2.CascadeClassifier</code> class addresses this issue. This parameter will scale down different areas of the input image before trying to predict whether those areas contain a face or not – doing this negates the potential difference in face sizes. To implement this, change the line where we pass the input images to the model to the following to specify the <code>scaleFactor</code> parameter as <code>1.2</code>:</p>
			<pre>faces = face_cascade.detectMultiScale(im, scaleFactor=1.2)</pre>
			<p>Run the <a id="_idIndexMarker882"/>program; you will see that this time, our application can correctly detect all of the faces in our input images without making any false positives.</p>
			<p>From this example, we can see that it is important to know about the potential challenges that the input images will pose to your image processing application in execution, as well as to try different methods or parameters within one method of processing to achieve the best results.</p>
			<h2 id="_idParaDest-205"><a id="_idTextAnchor190"/>Spawning an appropriate number of processes</h2>
			<p>One point we noticed in our example of concurrent image processing is that the task of spawning processes <a id="_idIndexMarker883"/>takes a considerable amount of time. Due to this, if the number of processes available to analyze the data is too high in comparison to the amount of input, the improvement in execution time that's obtained from increasing the number of working processes will diminish and sometimes even become negative.</p>
			<p>However, there is no concrete way to tell whether a specific number of separate processes is appropriate for a program unless we also take into account its input images. For example, if the input images are relatively large files, and it takes a significant amount of time for the program to load them from storage, having a larger number of processes might be beneficial; when some processes are waiting for their images to load, others can proceed to perform processing on theirs. In other words, having a larger <a id="_idIndexMarker884"/>number of processes will allow for some overlapping between loading and processing time, which will result in better speedup.</p>
			<p>In short, it is important to test out different processes that are available for your image processing application to see what the optimal number for scalability is.</p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor191"/>Processing input/output concurrently</h2>
			<p>We saw that <a id="_idIndexMarker885"/>loading input images in a sequential way might harm the execution time of an image processing application, as opposed to allowing separate processes to load their inputs. This is specifically true if the image files are significantly large, as the loading time in separate processes might overlap with the loading/processing time in other processes. The same is applicable for writing output images to files.</p>
			<h1 id="_idParaDest-207"><a id="_idTextAnchor192"/>Summary</h1>
			<p>Image processing is the task of analyzing and manipulating digital image files to create new versions of the images or to extract important data from them. These digital images are represented by tables of pixels, which are RGB values or, in essence, tuples of numbers. Therefore, digital images are simply multi-dimensional matrices of numbers, which results in the fact that image processing tasks typically come down to heavy number-crunching.</p>
			<p>Since images can be analyzed and processed independently from each other in an image processing application, concurrent and parallel programming – specifically, multiprocessing – provides a way for us to make significant improvements to the execution time of the application. Additionally, there are several good practices to follow while implementing a concurrent image processing program.</p>
			<p>We have seen how we can apply parallel programming to accelerate the task of image processing. The exercises in this chapter allowed us to examine various aspects of the workflow and how each of them could be parallelized, thus allowing us to build up more confidence in implementing concurrent applications in Python.</p>
			<p>In the next chapter, we will go through a similar exercise, where we aim to use asynchronous programming to build communication channels.</p>
			<h1 id="_idParaDest-208"><a id="_idTextAnchor193"/>Questions</h1>
			<ol>
				<li>What is an image processing task?</li>
				<li>What is the smallest unit of digital imaging? How is it represented in computers?</li>
				<li>What is grayscaling? What purpose does this technique serve?</li>
				<li>What is thresholding? What purpose does this technique serve?</li>
				<li>Why should image processing be made concurrent?</li>
				<li>What are some good practices for concurrent image processing?</li>
			</ol>
			<h1 id="_idParaDest-209"><a id="_idTextAnchor194"/>Further reading</h1>
			<ul>
				<li><em class="italic">Automate the Boring Stuff with Python: Practical Programming for Total Beginners</em>, Al Sweigart, No Starch Press, 2015.</li>
				<li><em class="italic">Learning Image Processing with OpenCV</em>, Garcia, Gloria Bueno, et al, Packt Publishing Ltd, 2015.</li>
				<li><em class="italic">A Computational Introduction to Digital Image Processing</em>, Alasdair McAndrew, Chapman and Hall/CRC, 2015.</li>
				<li>Howse, J., P. Joshi, and M. Beyeler. OpenCV: <em class="italic">Computer Vision Projects with Python.</em> Packt Publishing Ltd, 2016.</li>
			</ul>
		</div>
	</div>
</div>
</body></html>