- en: Chapter 6. Web Scraping with Python Requests and BeautifulSoup
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 使用Python Requests和BeautifulSoup进行网页抓取
- en: We have become experts in how to communicate with the Web through `Requests`.
    Everything progressed flamboyantly while working with the APIs. However, there
    are some conditions where we need to be aware of API folklore.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成为了如何通过 `Requests` 与网络进行通信的专家。在与 API 一起工作时，一切进展得非常热烈。然而，有些情况下我们需要注意 API
    传说。
- en: The first thing that concerns us is not all web services have built an API for
    the sake of their third-party customers. Also, there is no statute that the API
    should be maintained perfectly. Even tech giants such as Google, Facebook, and
    Twitter tend to change their APIs abruptly without prior notice. So, it's better
    to understand that it is not always the API that comes to the rescue when we are
    looking for some vital information from a web resource.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先关注的问题是并非所有网络服务都为第三方客户构建了API。此外，也没有法律规定API必须得到完美的维护。即使是像谷歌、Facebook和Twitter这样的技术巨头，也倾向于在没有事先通知的情况下突然更改他们的API。因此，我们最好理解，当我们从网络资源中寻找一些关键信息时，并不总是API会及时伸出援手。
- en: The concept of **web scraping** stands as a savior when we really turn imperative
    to access some information from a web resource that does not maintain an API.
    In this chapter, we will discuss tricks of the trade to extract information from
    web resources by following all the principles of web scraping.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**网络爬虫**这一概念在我们迫切需要从没有提供API的网页资源中获取信息时，就像一位救星。在本章中，我们将讨论如何遵循网络爬虫的所有原则，从网页资源中提取信息的技巧。'
- en: 'Before we begin, let''s get to know some important concepts that will help
    us to reach our goal. Take a look at the response content format of a request,
    which will introduce us to a particular type of data:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们了解一些重要的概念，这些概念将帮助我们实现目标。看看请求的响应内容格式，这将向我们介绍一种特定的数据类型：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the preceding example, the response content is rendered in the form of semistructured
    data, which is represented using HTML tags; this in turn helps us to access the
    information about the different sections of a web page individually.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，响应内容以半结构化数据的形式呈现，使用HTML标签进行表示；这反过来又帮助我们分别访问网页不同部分的信息。
- en: Now, let's get to know the different types of data that the Web generally deals
    with.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们了解网络通常处理的不同类型的数据。
- en: Types of data
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据类型
- en: 'In most cases, we deal with three types of data when working with web sources.
    They are as follows:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理网络资源时，我们通常会遇到三种类型的数据。具体如下：
- en: Structured data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化数据
- en: Unstructured data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: Semistructured Data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半结构化数据
- en: Structured data
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构化数据
- en: Structured data is a type of data that exists in an organized form. Normally,
    structured data has a predefined format and it is machine readable. Each piece
    of data that lies in structured data has a relation with every other data as a
    specific format is imposed on it. This makes it easier and faster to access different
    parts of data. The structured data type helps in mitigating redundant data while
    dealing with huge amounts of data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据是一种以组织形式存在的数据类型。通常，结构化数据具有预定义的格式，并且是机器可读的。结构化数据中的每一份数据都与其它数据以特定格式相关联。这使得访问数据的不同部分更加容易和快捷。处理大量数据时，结构化数据类型有助于减少冗余数据。
- en: Databases always contain structured data, and SQL techniques can be used to
    access data from them. We can regard census records as an example of structured
    data. They contain information about the date of birth, gender, place, income,
    and so on, of the people of a country.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库总是包含结构化数据，可以使用SQL技术来访问这些数据。我们可以将人口普查记录视为结构化数据的例子。它们包含关于一个国家人民出生日期、性别、地点、收入等信息。
- en: Unstructured data
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: In contrast to structured data, unstructured data either misses out on a standard
    format or stays unorganized even though a specific format is imposed on it. Due
    to this reason, it becomes difficult to deal with different parts of the data.
    Also, it turns into a tedious task. To handle unstructured data, different techniques
    such as text analytics, Natural Language Processing (NLP), and data mining are
    used. Images, scientific data, text-heavy content (such as newspapers, health
    records, and so on), come under the unstructured data type.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与结构化数据相比，非结构化数据要么缺少标准格式，要么即使施加了特定格式也保持无序。由于这个原因，处理数据的各个部分变得困难。此外，它变成了一项繁琐的任务。为了处理非结构化数据，使用了不同的技术，如文本分析、自然语言处理（NLP）和数据挖掘。图像、科学数据、内容繁多的文本（如报纸、健康记录等）都属于非结构化数据类型。
- en: Semistructured data
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 半结构化数据
- en: Semistructured data is a type of data that follows an irregular trend or has
    a structure which changes rapidly. This data can be a self described one, it uses
    tags and other markers to establish a semantic relationship among the elements
    of the data. Semistructured data may contain information that is transferred from
    different sources. **Scraping** is the technique that is used to extract information
    from this type of data. The information available on the Web is a perfect example
    of semistructured data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 半结构化数据是一种遵循不规则趋势或具有快速变化结构的数据类型。这种数据可以是自我描述的，它使用标签和其他标记来建立数据元素之间的语义关系。半结构化数据可能包含来自不同来源的信息。"抓取"是用于从这类数据中提取信息的技巧。网络上的信息是半结构化数据的完美例子。
- en: What is web scraping?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是网络爬取？
- en: In simple words, web scraping is the process of extracting desired data from
    a web resource. This method involves different procedures such as interacting
    with the web resource, choosing the appropriate data, obtaining information from
    the data, and converting the data to the desired format. With all the previous
    methods considered, a major spotlight will be thrown on the process of pulling
    the required data from the semistructured data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，网络爬虫是从网络资源中提取所需数据的过程。这种方法涉及不同的步骤，如与网络资源交互、选择合适的数据、从数据中获取信息，以及将数据转换为所需格式。在考虑了所有之前的方法之后，主要关注点将集中在从半结构化数据中提取所需数据的过程。
- en: Dos and don'ts of web scraping
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络爬取的注意事项与禁忌
- en: 'Scraping a web resource is not always welcomed by the owners. Some companies
    put a restriction on using bots against them. It''s etiquette to follow certain
    rules while scraping. The following are the dos and don''ts of web scraping:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 爬取网络资源并不总是受到所有者的欢迎。一些公司会对使用针对他们的机器人进行限制。在爬取时遵循某些规则是一种礼仪。以下是一些关于网络爬取的应该做和不应该做的事情：
- en: '**Do refer to the terms and conditions**: The first thing that should come
    to our mind before we begin scraping is terms and conditions. Do visit the website''s
    terms and conditions page and get to know whether they prohibit scraping from
    their site. If so, it''s better to back off.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**请务必查阅条款和条件**：在我们开始抓取数据之前，应该首先想到的是条款和条件。请访问网站的条款和条件页面，了解他们是否禁止从其网站抓取数据。如果是这样，最好是退而求其次。'
- en: '**Don''t bombard the server with a lot of requests**: Every website runs on
    a server that can serve only a specific amount of workload. It is equivalent to
    being rude if we bombard the server with lots of requests in a specific span of
    time, which may result in sever breakdown. Wait for some time between requests
    instead of bombarding the server with too many requests at once.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要向服务器发送大量请求**：每个网站都运行在只能处理特定工作量负载的服务器上。如果在特定时间段内向服务器发送大量请求，这相当于是一种无礼行为，可能会导致服务器崩溃。请等待一段时间后再发送请求，而不是一次性向服务器发送过多请求。'
- en: Note
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意事项
- en: Some sites put a restriction on the maximum number of requests processed per
    minute and will ban the request sender's IP address if this is not adhered to.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一些网站对每分钟处理的最大请求数量有限制，如果不遵守这一规定，将会禁止请求发送者的IP地址。
- en: '**Do track the web resource from time to time**: A website doesn''t always
    stay the same. According to its usability and the requirement of users, they tend
    to change from time to time. If any alteration has taken place in the website,
    our code to scrape may fail. Do remember to track the changes made to the site,
    modify the scrapper script, and scrape accordingly.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定期跟踪网络资源**：一个网站并不总是保持不变。根据其可用性和用户需求，它们往往会不时地进行更改。如果网站有任何变动，我们用于抓取的代码可能会失效。请务必跟踪网站所做的更改，修改抓取脚本，并相应地进行抓取。'
- en: Predominant steps to perform web scraping
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行网络爬取的主要步骤
- en: 'Generally, the process of web scraping requires the use of different tools
    and libraries such as the following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，网络爬取的过程需要使用以下不同的工具和库：
- en: '**Chrome DevTools or FireBug Add-on**: This can be used to pinpoint the pieces
    of information in an HTML/XML page.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Chrome DevTools 或 FireBug 插件**：这可以用来定位 HTML/XML 页面中的信息片段。'
- en: '**HTTP libraries**: These can be used to interact with the server and to pull
    a response document. An example of this is `python-requests`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HTTP库**：这些库可以用来与服务器交互并获取响应文档。一个例子是`python-requests`。'
- en: '**Web scraping tools**: These are used to pull data from a semistructured document.
    Examples include `BeautifulSoup` or `Scrappy`.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网页抓取工具**：这些工具用于从半结构化文档中提取数据。例如包括 `BeautifulSoup` 或 `Scrappy`。'
- en: 'The overall picture of web scraping can be observed in the following steps:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 网络爬取的整体流程可以观察以下步骤：
- en: Identify the URL(s) of the web resource to perform the web scraping task.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定执行网络爬取任务的网页资源的URL（s）。
- en: Use your favorite HTTP client/library to pull the semistructured document.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您喜欢的HTTP客户端/库来提取半结构化文档。
- en: Before extracting the desired data, discover the pieces of data that are in
    semistructured format.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Utilize a web scraping tool to parse the acquired semistructured document into
    a more structured one.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网络爬虫工具将获取的半结构化文档解析成更结构化的形式。
- en: Draw the desired data that we are hoping to use. That's all, we are done!
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制我们希望使用的所需数据。这就完成了！
- en: Key web scraping tasks
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键网络爬取任务
- en: 'While pulling the required data from a semistructured document, we perform
    various tasks. The following are the basic tasks that we adopt for scraping:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '**Searching a semistructured document:** Accessing a particular element or
    a specific type of element in a document can be accomplished using its `tag` name
    and `tag` attributes, such as `id`, `class`, and so on.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Navigating within a semistructured document**: We can navigate through a
    web document to pull different types of data in four ways, which are navigating
    down, navigating sideways, navigating up, and navigating back and forth. We can
    get to know more about these in detail later in this chapter.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modifying a semistructured document:** By modifying the `tag` name or the
    `tag` attributes of a document, we can streamline and pull the required data.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is BeautifulSoup?
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `BeautifulSoup` library is a simple yet powerful web scraping library. It
    has the capability to extract the desired data when provided with an HTML or XML
    document. It is charged with some superb methods, which help us to perform web
    scraping tasks effortlessly.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Document parsers
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Document parsers aid us in parsing and serializing the semistructured documents
    that are written using HTML5, lxml, or any other markup language. By default,
    `BeautifulSoup` has Python's standard `HTMLParser` object. If we are dealing with
    different types of documents, such as HTML5 and lxml, we need to install them
    explicitly.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, our prime focus will be laid only on particular parts of the
    library, which help us to understand the techniques to develop a practical scraping
    bot that we will build at the end of this chapter.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Installation
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Installing `BeautifulSoup` is pretty straightforward. We can use `pip` to install
    it with ease:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Whenever we intend to scrape a web resource using `BeautifulSoup`, we need
    to create a `BeautifulSoup` object for it. The following are the commands to do
    this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Objects in BeautifulSoup
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `BeautifulSoup` object parses the given HTML/XML document and converts it
    into a tree of Python objects, which are discussed in the following sections.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Tags
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The word "tag" represents an HTML/XML tag in the provided document. Each `tag`
    object has a name and a lot of attributes and methods. The following example showcases
    the way to deal with a `tag` object:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In order to access the type, name, and attributes of the `BeautifulSoup` object,
    with `soup`, that we created in the preceding example, use the following commands:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'For accessing the `tag type`:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'For accessing the `tag name`:'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For accessing the `tag` attribute (`'id'` in the given html string)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: BeautifulSoup
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The object that gets created when we intend to scrape a web resource is called
    a `BeautifulSoup` object. Put simply, it is the complete document that we are
    planning to scrape. This can be done using the following commands:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: NavigableString
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A `NavigableString` object represents the contents of `tag`. We use the `.string`
    attribute of the `tag` object to access it:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Comments
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `comment` object illustrates the comment part of the web document. The
    following lines of code exemplify a `comment` object:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Web scraping tasks related to BeautifulSoup
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As cited in the previous section of *Key web scraping tasks*, `BeautifulSoup`
    always follows those basic tasks in the process of web scraping. We can get to
    know these tasks in detail with the help of a practical example, using an HTML
    document. We will be using the following HTML document that is `scraping_example.html`,
    as an example through out the chapter:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To give a crystal clear understanding of the preceding web document, we showcased
    it as a document tree. The following diagram represents the preceding HTML document:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![Web scraping tasks related to BeautifulSoup](img/B03661_06_01.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: When we create the `BeautifulSoup` object for the previously shown web document,
    it will result in a tree of Python objects.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform different tasks with the previous document, `scraping_example.html`,
    we need to create a `BeautifulSoup` object. To create it, open the Python shell
    and run the following commands:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: From now, we will use the preceding `BeautifulSoup` object to execute different
    tasks. Let's perform the web scraping tasks on the `scraping_example.html` document
    and get an overall idea on all the tasks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Searching the tree
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To identify the different tags in an HTML/XML document, we need to search the
    whole document. In similar situations, we can use `BeautifulSoup` methods such
    as `find`, `find_all`, and so on.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the syntax to search the whole document to identify the tags:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '`find(name, attributes, recursive, text, **kwargs)`'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: This is the first occurring tag name that appears in the process of
    discovery. It can be a string, a regular expression, a list, a function, or the
    value `True`.'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`find_all(name, attributes, recursive, text, limit, **kwargs)`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: This is used to access specific types of tags with their name. It can
    be a string, a regular expression, a list, a function, or the value `True`.'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`limit`: This is the maximum number of results in the output.'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The common attributes for the preceding two methods are as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '`attributes`: These are the attributes of an HTML/XML tag.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`recursive`: This takes a Boolean value. If it is set to `True`, the `BeautifulSoup`
    library checks all the children of a specific tag. Vice versa, if it is set to
    `false`, the `BeautifulSoup` library checks the child at the next level only.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text`: This parameter identifies tags that consist of the string content.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Navigating within the tree
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Different tasks are involved in navigating the document tree with the `Beautifulsoup4`
    module; they are discussed in the following section.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Navigating down
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We can access a particular element's data by moving down in a document. If we
    consider the document tree in the previous figure, we can access different elements
    by moving downward from the top element—`html`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'Every element can be accessed using its `tag` name. Here is a way to access
    the contents of the `html` attribute:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here are the ways in which we can access the elements of the preceding document
    tree by navigating down. In order to access the `title` element, we should go
    from top to bottom, that is, from `html` to `head` and from `head` to `title`,
    as shown in the following command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Similarly, you can access the `meta` element, as shown in the following command:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Navigating sideways
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To access the siblings in a document tree, we should navigate sideways. The
    `BeautifulSoup` library provides various `tag` object properties such as `.next_sibling`,
    `.previous_sibling`, `.next_siblings`, and `.previous_siblings`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look at the preceding diagram containing the document tree, the different
    siblings at different levels of the tree, when navigated sideways, are as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '`head` and `body`'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`div1`, `div2`, and `div3`'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the document tree, the `head` tag is the first child of `html`, and `body`
    is the next child of `html`. In order to access the children of the `html` tag,
    we can use its `children` property:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To access the next sibling of `head` element we can use `.find_next_sibling`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To access the previous sibling of `body`, we can use `.find_previous_sibling`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Navigating up
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We can access a particular element's parent by moving toward the top of the
    document tree. The `BeautifulSoup` library provides two properties—`.parent` and
    `.parents`—to access the first parent of the `tag` element and all its ancestors,
    respectively.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Navigating back and forth
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To access the previously parsed element, we navigate back in the node of a
    tree, and to access the immediate element that gets parsed next, we navigate forward
    in the node of a tree. To deal with this, the `tag` object provides the `.find_previous_element`
    and `.find_next_element` properties, as shown in the following example:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Modifying the Tree
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The BeautifulSoup library also facilitates us to make changes to the web document
    according to our requirements. We can alter a tag's properties using its attributes,
    such as the `.name`, `.string`, and `.append()` method. We can also add new tags
    and strings to an existing tag with the help of the `.new_string()` and `.new_tag()`
    methods. There are also other methods, such as `.insert()`, `.insert_before()`,
    `.insert_after()`, and so on, to make various modifications to the document tree.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of changing the `title` tag''s `.string` attribute:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'Before modifying the `title` tag the title contents are:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This is the way to modify the contents of a `title` tag:'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'After the modifications the contents of the `tilte` tag looks like this:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Building a web scraping bot – a practical example
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point of time, our minds got enlightened with all sorts of clues to
    scrape the Web. With all the information acquired, let's look at a practical example.
    Now, we will create a web scraping bot, which will pull a list of words from a
    web resource and store them in a JSON file.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Let's turn on the scraping mode!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: The web scraping bot
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, the web scraping bot is an automated script that has the capability to
    extract words from a website named majortests.com. This website consists of various
    tests and **Graduate Record Examinations** (**GRE**) word lists. With this web
    scraping bot, we will scrape the previously mentioned website and create a list
    of GRE words and their meanings in a JSON file.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image is the sample page of the website that we are going to
    scrape:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '![The web scraping bot](img/B03661_06_03.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
- en: 'Before we kick start the scraping process, let''s revise the dos and don''t
    of web scraping as mentioned in the initial part of the chapter. Believe it or
    not they will definitely leave us in peace:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '**Do refer to the terms and conditions**: Yes, before scraping majortests.com,
    refer to the terms and conditions of the site and obtain the necessary legal permissions
    to scrape it.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Don''t bombard the server with a lot of requests**: Keeping this in mind,
    for every request that we are going to send to the website, a delay has been instilled
    using Python''s `time.sleep` function.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Do track the web resource from time to time**: We ensured that the code runs
    perfectly with the website that is running on the server. Do check the site once
    before starting to scrape, so that it won''t break the code. This can be made
    possible by running some unit tests, which conform to the structure we expected.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's start the implementation by following the steps to scrape that we
    discussed previously.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Identifying the URL or URLs
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step in web scraping is to identify the URL or a list of URLs that
    will result in the required resources. In this case, our intent is to find all
    the URLs that result in the expected list of GRE words. The following is the list
    of the URLs of the sites that we are going to scrape:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.majortests.com/gre/wordlist_01](http://www.majortests.com/gre/wordlist_01),'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.majortests.com/gre/wordlist_02](http://www.majortests.com/gre/wordlist_02),'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.majortests.com/gre/wordlist_03](http://www.majortests.com/gre/wordlist_03),
    and so on'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Our aim is to scrape words from nine such URLs, for which we found a common
    pattern. This will help us to crawl all of them. The common URL pattern for all
    those URLs is written using Python''s `string` object, as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '`http://www.majortests.com/gre/wordlist_0%d`'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'In our implementation, we defined a method called `generate_urls`, which will
    generate the required list of URLs using the preceding URL string. The following
    snippet demonstrates the process in a Python shell:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Using an HTTP client
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will use the `requests` module as an HTTP client to get the web resources:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the preceding code, the `get_resource` function takes `url` as an argument
    and uses the `requests` module to get the resource.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Discovering the pieces of data to scrape
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, it is time to analyze and classify the contents of the web page. The content
    in this context is a list of words with their definitions. In order to identify
    the elements of the words and their definitions, we used Chrome DevTools. The
    perceived information of the elements (HTML elements) can help us to identify
    the word and its definition, which can be used in the process of scraping.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'To carry this out open the URL ([http://www.majortests.com/gre/wordlist_01](http://www.majortests.com/gre/wordlist_01))
    in the Chrome browser and access the **Inspect element** option by right-clicking
    on the web page:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![Discovering the pieces of data to scrape](img/B03661_06_02.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
- en: 'From the preceding image, we can identify the structure of the word list, which
    appears in the following manner:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'By looking at the parts of the previously referred to web page, we can interpret
    the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Each web page consists of a word list
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every word list has many word groups that are defined in the same `div` tag
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the words in a word group are described in a table having the class attribute—`wordlist`
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each and every table row (`tr`) in the table represents a word and its definition
    using the `th` and `td` tags, respectively
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing a web scraping tool
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s use `BeautifulSoup4` as a web scraping tool to parse the obtained web
    page contents that we received using the `requests` module in one of the previous
    steps. By following the preceding interpretations, we can direct `BeautifulSoup`
    to access the required content of the web page and deliver it as an object:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In the preceding lines of code, the `make_soup` method takes the `html` content
    in the form of a string and returns a `BeautifulSoup` object.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Drawing the desired data
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `BeautifulSoup` object that we obtained in the previous step is used to
    extract the required words and their definitions from it. Now, with the methods
    available in the `BeautifulSoup` object, we can navigate through the obtained
    HTML response, and then we can extract the list of words and their definitions:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In the preceding lines of code, `get_words_from_soup` takes a `BeautifulSoup`
    object and then looks for all the words contained in the `wordlists` class using
    the instance's `find_all()` method, and then returns a dictionary of words.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: 'The dictionary of words obtained previously will be saved in a JSON file using
    the following `helper` method:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'On the whole, the process can be depicted in the following program:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here is the content of the `words.json` file:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Summary
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about different types of data that we encountered
    with web sources and tweaked some ideas. We came to know about the need for web
    scraping, the legal issues, and the goodies that it offers. Then, we jumped deep
    into web scraping tasks and their potential. You learned about a new library called
    `BeautifulSoup`, and its ins and outs, with examples.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: We came to know the capabilities of `BeautifulSoup` in depth and worked on some
    examples to get a clear idea on it. At last, we created a practical scraping bot
    by applying the knowledge that we gained from the previous sections, which enlightened
    us with an experience to scrape a website in real time.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn about the Flask microframework and we will
    build an application using it by following the best practices.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
