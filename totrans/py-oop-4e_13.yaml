- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Testing Object-Oriented Programs
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试面向对象程序
- en: 'Skilled Python programmers agree that testing is one of the most important
    aspects of software development. Even though this chapter is placed near the end
    of the book, it is not an afterthought; everything we have studied so far will
    help us when writing tests. In this chapter, we''ll look at the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 熟练的 Python 程序员都认为测试是软件开发最重要的方面之一。尽管这一章节被放置在书的末尾附近，但这并非是事后想起的；我们迄今为止所学的所有内容都将有助于我们编写测试。在本章中，我们将探讨以下主题：
- en: The importance of unit testing and test-driven development
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单元测试和测试驱动开发的重要性
- en: The standard library `unittest` module
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准库 `unittest` 模块
- en: The `pytest` tool
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pytest` 工具'
- en: The `mock` module
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mock` 模块'
- en: Code coverage
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码覆盖率
- en: In the case study for this chapter, we'll focus – no surprise – on writing some
    tests for the case study examples.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的案例研究中，我们将聚焦——不出所料——为案例研究示例编写一些测试。
- en: We'll start with some of the fundamental reasons why automated software testing
    is so important.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一些基本原因开始，解释为什么自动化软件测试如此重要。
- en: Why test?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么进行测试？
- en: Many programmers already know how important it is to test their code. If you're
    among them, feel free to skim this section. You'll find the next section – where
    we actually see how to create tests in Python – much more scintillating.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 许多程序员已经知道测试代码的重要性。如果你是其中之一，请随意浏览这一节。你会发现下一节——我们将实际看到如何在Python中创建测试——要有趣得多。
- en: If you're not convinced of the importance of testing, we remind you that without
    any tests, code will be broken, and no one has any way to know it. Read on!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有确信测试的重要性，我们提醒你，如果没有任何测试，代码将会出错，而且没有人有任何方法知道这一点。继续阅读！
- en: Some people argue that testing is more important in Python code because of its
    dynamic nature; compiled languages such as Java and C++ are occasionally thought
    to be somehow *safer* because they enforce type checking at compile time. However,
    Python tests rarely check types. They check values. They make sure that the right
    attributes have been set at the right time or that the sequence has the right
    length, order, and values. These higher-level concepts need to be tested in any
    language. The real reason Python programmers test more than programmers of other
    languages is that it is so easy to test in Python!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人认为在Python代码中测试更为重要，因为其动态特性；人们有时会认为像Java和C++这样的编译语言在某些方面更*安全*，因为它们在编译时强制进行类型检查。然而，Python测试很少检查类型。它们检查值。它们确保在正确的时间设置了正确的属性，或者序列具有正确的长度、顺序和值。这些高级概念在任何语言中都需要进行测试。Python程序员比其他语言的程序员测试得更多，真正的原因是Python进行测试非常容易！
- en: But why test? Do we really need to test? What if we didn't test? To answer those
    questions, reflect on the last time you wrote any code. Did it run correctly the
    first time? Free of syntax errors? Free of logic problems? It's possible, in principle,
    to type in code that's perfect once in a while. As a practical matter, the number
    of obvious syntax errors that had to be corrected is an indicator that perhaps
    there are more subtle logic errors that also had to be corrected.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但为什么要测试？我们真的需要测试吗？如果我们不测试会怎样？为了回答这些问题，回想一下你上次编写代码的时候。它第一次运行正确了吗？没有语法错误？没有逻辑问题？原则上来说，偶尔输入一次完美的代码是可能的。但从实际的角度来看，需要纠正的明显语法错误数量可能是一个指标，表明可能还有更多需要纠正的微妙逻辑错误。
- en: We don't need a formal, separate test to make sure our code works. Running the
    program, as we generally do, and fixing the errors is a crude form of testing.
    Python's interactive interpreter and near-zero compile times makes it easy to
    write a few lines of code and run the program to make sure those lines are doing
    what is expected. While acceptable at the beginning of a project, this turns into
    a liability that grows over time. Attempting to change a few lines of code can
    affect parts of the program that we haven't realized will be influenced by the
    changes, and without tests, we don't know what we broke. Attempts at redesigns
    or even small optimization rewrites can be plagued with problems. Furthermore,
    as a program grows, the number of paths that the interpreter can take through
    that code also grows, and it quickly becomes impossible or a crude manual test
    to exercise all of them.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要一个正式的、独立的测试来确保我们的代码能够正常工作。像我们通常做的那样运行程序，并修复错误，这是一种粗略的测试形式。Python的交互式解释器和几乎为零的编译时间使得编写几行代码并运行程序来确保这些代码按预期工作变得非常容易。虽然这在项目开始时是可以接受的，但随着时间的推移，这会变成一个不断增长的负担。试图更改几行代码可能会影响到我们没有意识到会受到这些更改影响的程序部分，而没有测试，我们就不知道我们破坏了什么。试图进行重新设计或甚至小的优化重写可能会遇到问题。此外，随着程序的增长，解释器可以通过该代码的路径数量也会增长，很快就会变得不可能或手动测试变得非常粗糙，以至于无法测试所有这些路径。
- en: To assure ourselves and others that our software works, we write automated tests.
    These are programs that automatically run certain inputs through other programs
    or parts of programs. We can run these test programs in seconds and cover far
    more potential input situations than one programmer would think to test every
    time they change something.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们自己和他人我们的软件能够正常工作，我们编写了自动化测试。这些是自动将某些输入通过其他程序或程序的部分运行的程序。我们可以在几秒钟内运行这些测试程序，覆盖比一个程序员每次更改时想要测试的更多潜在输入情况。
- en: Software features that can't be demonstrated by automated tests simply don't
    exist.
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 无法通过自动化测试演示的软件特性实际上是不存在的。
- en: '- Extreme Programming Explained, Kent Beck'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '- 极限编程详解，肯特·贝克'
- en: 'There are four main reasons to write tests:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 编写测试的四个主要原因：
- en: To ensure that code is working the way the developer thinks it should
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保代码按照开发者的预期工作
- en: To ensure that code continues working when we make changes
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保在做出更改后代码仍然可以继续工作
- en: To ensure that the developer understood the requirements
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保开发者理解了需求
- en: To ensure that the code we are writing has a maintainable interface
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保我们编写的代码具有可维护的接口
- en: When we have automated tests, we can run them every time we change code, whether
    it is during initial development or maintenance releases. Testing can confirm
    that we didn't inadvertently break anything when adding or extending features.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有自动化测试时，我们可以在每次更改代码时运行它们，无论是初始开发阶段还是维护版本发布。测试可以确认我们在添加或扩展功能时没有无意中破坏任何东西。
- en: The last two of the preceding points have interesting consequences. When we
    write tests, it helps us design the API, interface, or pattern that code takes.
    Thus, if we misunderstood the requirements, writing a test can help highlight
    the misunderstanding. From the other side, if we're not certain how we want to
    design a class, we can write a test that interacts with that class so we have
    an idea of the most natural way to confirm that the interface works. In fact,
    it is often beneficial to write the tests before we write the code we are testing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 前述最后两点具有有趣的后果。当我们编写测试时，它有助于我们设计代码所采用的API、接口或模式。因此，如果我们对需求理解有误，编写测试可以帮助突出显示这种误解。从另一方面来看，如果我们不确定我们想要如何设计一个类，我们可以编写一个与该类交互的测试，这样我们就有了一个关于最自然地确认接口工作的想法。实际上，在我们编写要测试的代码之前编写测试通常是很有益的。
- en: 'There are some other interesting consequences of focusing on software testing.
    We''ll look at three of these consequences:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于软件测试还有一些其他有趣的后果。我们将探讨这三个后果：
- en: Using tests to drive development
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用测试驱动开发
- en: Managing different objectives for testing
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理测试的不同目标
- en: Having a consistent pattern for test scenarios
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为测试场景制定一个一致的模板
- en: Let's start with using tests to drive the development effort.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从使用测试来驱动开发工作开始。
- en: Test-driven development
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试驱动开发
- en: '*Write tests first* is the mantra of test-driven development. Test-driven development
    takes the *untested code is broken code* concept one step further and suggests
    that only unwritten code should be untested. We don''t write any code until after
    we have written the tests that will prove it works. The first time we run a test,
    it should fail, since the code hasn''t been written. Then, we write the code that
    ensures the test passes, and then write another test for the next segment of code.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*先写测试*是测试驱动开发的箴言。测试驱动开发将*未经测试的代码是错误的代码*这一概念进一步深化，并建议只有未编写的代码才应该是未经测试的。我们不会编写任何代码，直到我们写出了能够证明其工作的测试。第一次运行测试时，它应该失败，因为代码还没有编写。然后，我们编写确保测试通过的代码，接着为下一段代码编写另一个测试。'
- en: Test-driven development can be fun; it allows us to build little puzzles to
    solve. Then, we implement the code to solve those puzzles. After that, we make
    a more complicated puzzle, and we write code that solves the new puzzle without
    unsolving the previous one.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 测试驱动开发可以很有趣；它允许我们构建小谜题来解决。然后，我们编写代码来解决这些谜题。之后，我们制作一个更复杂的谜题，并编写代码来解决新谜题，同时不解决之前的谜题。
- en: There are two goals of the test-driven methodology. The first is to ensure that
    tests really get written.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 测试驱动方法有两个目标。第一个是确保真正编写了测试。
- en: Secondly, writing tests first forces us to consider exactly how the code will
    be used. It tells us what methods objects need to have and how attributes will
    be accessed. It helps us break up the initial problem into smaller, testable problems,
    and then recombine the tested solutions into larger, also tested, solutions. Writing
    tests can thus become a part of the design process. Often, when we're writing
    a test for a new object, we discover anomalies in the design that force us to
    consider new aspects of the software.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，先编写测试迫使我们必须仔细考虑代码将如何被使用。它告诉我们对象需要有哪些方法以及属性将如何被访问。它帮助我们将初始问题分解成更小、可测试的问题，然后将经过测试的解决方案重新组合成更大、同样经过测试的解决方案。因此，编写测试可以成为设计过程的一部分。通常，当我们为新的对象编写测试时，我们会发现设计中的异常，这迫使我们考虑软件的新方面。
- en: Testing makes software better. Writing tests before we release the software
    makes it better before the final code is written.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 测试让软件变得更好。在我们发布软件之前编写测试，可以让它在最终代码编写之前就变得更好。
- en: All of the code examined in the book has been run through an automated test
    suite. It's the only way to be absolutely sure the examples are rock-solid, working
    code.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 书中所有检查的代码都已通过自动化测试套件运行。这是确保示例是坚如磐石、可正常工作的唯一方法。
- en: Testing objectives
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试目标
- en: 'We have a number of distinct objectives for running tests. These are often
    called types of testing, but the word "type" is heavily overused in the software
    industry. In this chapter, we''ll look at only two of these testing goals:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在运行测试时有许多不同的目标。这些通常被称为测试类型，但“类型”这个词在软件行业中过度使用。在本章中，我们将探讨这些测试目标中的两个：
- en: '**Unit tests** confirm that software components work in isolation. We''ll focus
    on this first, since Fowler''s Test Pyramid seems to suggest unit testing creates
    the most value. If the various classes and functions each adhere to their interfaces
    and produce the expected results, then integrating them is also going to work
    nicely and have relatively few surprises. It''s common to use the **coverage**
    tool to be sure all the lines of code are exercised as part of the unit test suite.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单元测试**确认软件组件在独立状态下能够正常工作。我们将首先关注这一点，因为福勒的测试金字塔似乎表明单元测试能够创造最大的价值。如果各个类和函数都遵循它们的接口并产生预期的结果，那么将它们集成起来也将运行良好，并且惊喜相对较少。通常使用**覆盖率**工具来确保所有代码行都是作为单元测试套件的一部分被测试的。'
- en: '**Integration tests** – unsurprisingly – confirm software components work when
    integrated. Integration tests are sometimes called system tests, functional tests,
    and acceptance tests, among others. When an integration test fails, it often means
    an interface wasn''t defined properly, or a unit test didn''t include some edge
    case that''s exposed through the integration with other components. Integration
    testing seems to depend on having good unit testing, making it secondary in importance.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成测试** - 令人意外的是 - 确认软件组件在集成后能够正常工作。集成测试有时被称为系统测试、功能测试和验收测试等。当集成测试失败时，通常意味着接口定义不正确，或者单元测试没有包含一些通过与其他组件集成而暴露的边缘情况。集成测试似乎依赖于良好的单元测试，因此在重要性上似乎处于次要地位。'
- en: We note that "unit" isn't formally defined by the Python language. This is an
    intentional choice. A unit of code is often a single function or a single class.
    It can be a single module, also. The definition gives us a little flexibility
    to identify isolated, individual units of code.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，“单位”在 Python 语言中并没有正式定义。这是一个有意的选择。一个代码单位通常是一个单独的函数或一个单独的类。它也可以是一个单独的模块。这个定义给我们提供了一定的灵活性，以便识别独立的、单个的代码单位。
- en: While there are many distinct objectives for tests, the techniques used tend
    to be similar. For additional material, see [https://www.softwaretestinghelp.com/types-of-software-testing/](https://www.softwaretestinghelp.com/types-of-software-testing/)
    for a list of over 40 different types of testing objectives; this is overwhelming,
    which is why we will only focus on unit tests and integration tests. All tests
    have a common pattern to them, and we'll look at a general pattern of testing
    next.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管测试有许多不同的目标，但所使用的技巧往往相似。有关更多资料，请参阅[https://www.softwaretestinghelp.com/types-of-software-testing/](https://www.softwaretestinghelp.com/types-of-software-testing/)，其中列出了40多种不同的测试目标；这可能会让人感到压倒性，这就是为什么我们将只关注单元测试和集成测试。所有测试都有一种共同的模式，我们将在下一节中探讨测试的一般模式。
- en: Testing patterns
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试模式
- en: Writing code is often challenging. We need to figure out what the internal state
    of the object is, what state changes it undergoes, and determine the other objects
    it collaborates with. Throughout the book, we've provided a number of common patterns
    for designing classes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 编写代码通常具有挑战性。我们需要弄清楚对象的内部状态是什么，它经历了哪些状态变化，以及确定它与其他哪些对象协作。在整个书中，我们提供了一系列设计类的常见模式。
- en: 'Tests, in a way, are simpler than class definitions, and all have essentially
    the same pattern:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 测试，从某种意义上说，比类定义简单，并且所有测试都具有基本相同的模式：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In some cases, the preconditions can be complex or perhaps the state changes
    or side effects are complex. They might be so complex that we have to break them
    into multiple steps. What''s important about this three-part pattern is how it
    disentangles the setup, execution, and expected results from each other. This
    model applies to a wide variety of tests. If we want to make sure the water''s
    hot enough to make another cup of tea, we''ll follow a similar set of steps:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，先决条件可能很复杂，或者状态变化或副作用可能很复杂。它们可能复杂到需要分解成多个步骤。这个三部分模式的重要之处在于它如何将设置、执行和预期结果相互解开。这个模型适用于各种测试。如果我们想确保水足够热，可以再泡一杯茶，我们将遵循一系列类似的步骤：
- en: '`GIVEN` a kettle of water on the stove'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`给定`一个放在炉子上的水壶'
- en: '`AND` the burner is off'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AND` 燃烧器已关闭'
- en: '`WHEN` we flip open the lid on the kettle'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WHEN`我们打开壶盖'
- en: '`THEN` we see steam escaping'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`THEN` 我们看到蒸汽正在逸出'
- en: This pattern is quite handy for making sure we have a clear setup and an observable
    result.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式对于确保我们有清晰的设置和可观察的结果非常有用。
- en: 'Let''s say we need to write a function to compute an average of a list of numbers,
    excluding `None` values that might be in the sequence. We might start out like
    this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要编写一个函数来计算一个数字列表的平均值，同时排除序列中可能存在的`None`值。我们可能会这样开始：
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We've roughed out a definition of the function, with a summary of how we think
    it should behave. The GIVEN step defines some data for our test case. The WHEN
    step defines precisely what we're going to be doing. Finally, the THEN step describes
    the expected results. The automated test tool can compare actual results against
    the stated expectation and report back if the test fails. We can then refine this
    into a separate test class or function using our preferred test framework. The
    ways unittest and pytest implement the concept differ slightly, but the core concept
    remains in both frameworks. Once that's done, the test should fail and we can
    start implementing the real code, given this test as a clear goal line we want
    to cross.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经草拟了函数的定义，并总结了我们认为它应该如何表现。GIVEN步骤定义了测试用例的一些数据。WHEN步骤精确地定义了我们将要执行的操作。最后，THEN步骤描述了预期的结果。自动化测试工具可以将实际结果与声明的期望进行比较，并在测试失败时报告。然后，我们可以使用我们偏好的测试框架将此精炼为一个单独的测试类或函数。unittest和pytest实现这一概念的方式略有不同，但核心概念在两个框架中都保持一致。一旦完成，测试应该失败，然后我们可以开始实现真正的代码，因为这个测试作为一个清晰的终点线，是我们想要跨越的。
- en: Some techniques that can help design test cases are **equivalence partitioning**
    and **boundary value analysis**. These help us decompose the domain of all possible
    inputs to a method or function into partitions. A common example is locating two
    partitions, "valid data" and "invalid data." Given the partitions, the values
    at the boundaries of the partitions become interesting values to use in test cases.
    See [https://www.softwaretestinghelp.com/what-is-boundary-value-analysis-and-equivalence-partitioning/](https://www.softwaretestinghelp.com/what-is-boundary-value-analysis-and-equivalence-partitioning/)
    for more information.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一些有助于设计测试用例的技术包括**等价类划分**和**边界值分析**。这些技术帮助我们将一个方法或函数所有可能的输入域分解成多个部分。一个常见的例子是定位两个部分，“有效数据”和“无效数据”。给定这些部分，部分边界上的值成为在测试用例中使用的有兴趣的值。更多信息请参阅[https://www.softwaretestinghelp.com/what-is-boundary-value-analysis-and-equivalence-partitioning/](https://www.softwaretestinghelp.com/what-is-boundary-value-analysis-and-equivalence-partitioning/)。
- en: We'll start by looking at the built-in testing framework, `unittest`. It has
    a disadvantage of being a bit wordy and complicated looking. It has the advantage
    of being built-in and usable immediately; no further installs are required.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先了解内置的测试框架`unittest`。它有一个缺点，就是看起来有点冗长且复杂。但它也有一个优点，那就是它是内置的，可以立即使用；不需要进一步安装。
- en: Unit testing with unittest
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用unittest进行单元测试
- en: Let's start our exploration with Python's built-in test library. This library
    provides a common object-oriented interface for *unit tests*. The Python library
    for this is called, unsurprisingly, `unittest`. It provides several tools for
    creating and running unit tests, the most important being the `TestCase` class.
    (The names follow a Java naming style, so many of the method names don't look
    very Pythonic.) The `TestCase` class provides a set of methods that allow us to
    compare values, set up tests, and clean up when they have finished.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 Python 内置的测试库开始我们的探索。这个库提供了一个用于 *单元测试* 的通用面向对象接口。这个 Python 库被称为，不出所料，`unittest`。它提供了一些用于创建和运行单元测试的工具，其中最重要的是
    `TestCase` 类。（命名遵循 Java 命名风格，因此许多方法名看起来不太像 Python 风格。）`TestCase` 类提供了一组方法，允许我们比较值、设置测试，并在它们完成后进行清理。
- en: 'When we want to write a set of unit tests for a specific task, we create a
    subclass of `TestCase` and write individual methods to do the actual testing.
    These methods must all start with the name `test`. When this convention is followed,
    the tests automatically run as part of the test process. For simple examples,
    we can bundle the `GIVEN`, `WHEN`, and `THEN` concepts into the test method. Here''s
    a very simple example:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要为特定任务编写一组单元测试时，我们创建一个`TestCase`的子类，并编写单独的方法来进行实际测试。这些方法都必须以`test`开头命名。遵循此约定时，测试会自动作为测试过程的一部分运行。对于简单的例子，我们可以将`GIVEN`、`WHEN`和`THEN`概念打包到测试方法中。以下是一个非常简单的例子：
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This code subclasses the `TestCase` class and adds a method that calls the `TestCase.assertEqual()`
    method. The `GIVEN` step is a pair of values, 1 and 1.0\. The `WHEN` step is a
    kind of degenerate example because there's no new object created and no state
    change happening. The `THEN` step is the assertion that the two values will test
    as equal.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码继承自`TestCase`类并添加了一个调用`TestCase.assertEqual()`方法的方法。`GIVEN`步骤是一对值，1和1.0。`WHEN`步骤是一种退化示例，因为没有创建新对象且没有状态变化发生。`THEN`步骤是对两个值将测试为相等的断言。
- en: 'When we run the test case, this method will either succeed silently or it will
    raise an exception, depending on whether the two parameters are equal. If we run
    this code, the `main` function from `unittest` will give us the following output:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行测试用例时，这个方法要么会静默成功，要么会抛出一个异常，这取决于两个参数是否相等。如果我们运行这段代码，`unittest`模块中的`main`函数会给出以下输出：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Did you know that floats and integers can be compared as equal?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道浮点数和整数可以被视为相等进行比较吗？
- en: 'Let''s add a failing test, as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们添加一个失败的测试，如下所示：
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output of this code is more sinister, as integers and strings are not considered
    equal:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的输出更为险恶，因为整数和字符串不被视为相等：
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The dot on the first line indicates that the first test (the one we wrote before)
    passed successfully; the letter `F` after it shows that the second test failed.
    Then, at the end, it gives us some informative summary telling us how and where
    the test failed, along with a count of the number of failures.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行的点表示第一次测试（我们之前写的那个）成功通过；它后面的字母`F`表示第二次测试失败。然后，在最后，它给我们提供了一些信息性的总结，告诉我们测试失败的原因和位置，以及失败次数的统计。
- en: 'Even the OS-level return code provides a useful summary. The return code is
    zero if all tests pass and non-zero if any tests fail. This helps when building
    continuous integration tools: if the `unittest` run fails, the proposed change
    shouldn''t be permitted.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是操作系统级别的返回码也提供了一个有用的总结。如果所有测试都通过，返回码为零；如果有任何测试失败，返回码则不为零。这有助于构建持续集成工具：如果`unittest`运行失败，则不应允许提出的更改。
- en: We can have as many test methods on one `TestCase` class as we like. As long
    as the method name begins with `test`, the test runner will execute each one as
    a separate, isolated test.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在一个`TestCase`类中拥有尽可能多的测试方法。只要方法名以`test`开头，测试运行器就会将每个方法作为一个独立的、隔离的测试来执行。
- en: Each test should be completely independent of other tests.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 每个测试都应该完全独立于其他测试。
- en: Results or calculations from a test should have no impact on any other test.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 测试的结果或计算不应影响任何其他测试。
- en: In order to keep tests isolated from each other, we may have several tests with
    a common `GIVEN`, implemented by a common `setUp()` method. This suggests that
    we'll often have classes that are similar, and we'll need to use inheritance to
    design the tests so they can share features and still remain completely independent.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使测试彼此隔离，我们可能需要几个具有共同 `GIVEN` 的测试，这些测试通过一个共同的 `setUp()` 方法实现。这表明我们通常会拥有相似的课程，我们需要使用继承来设计测试，以便它们可以共享功能同时仍然保持完全独立。
- en: The key to writing good unit tests is keeping each test method as short as possible,
    testing a small unit of code with each test case. If our code does not seem to
    naturally break up into small, testable units, it's probably a sign that the code
    needs to be redesigned. The *Imitating objects using Mocks* section, later in
    this chapter, provides a way to isolate objects for testing purposes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 编写良好单元测试的关键是使每个测试方法尽可能简短，每个测试案例测试一小块代码。如果我们的代码看起来不能自然地分解成小块、可测试的单位，这可能是一个迹象，表明代码需要重新设计。本章后面的“使用模拟对象进行模仿”部分提供了一种用于测试目的隔离对象的方法。
- en: The `unittest` module imposes a requirement to structure tests as a class definition.
    This is – in some ways – a bit of overhead. The `pytest` package has slightly
    more clever test discovery and a slightly more flexible way to construct tests
    as functions instead of methods of a class. We'll look at `pytest` next.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`unittest` 模块要求将测试结构化为类定义。这在某种程度上——有点儿——增加了开销。`pytest` 包在测试发现方面稍微聪明一些，并且以函数而不是类的方法构建测试的方式更加灵活。我们将在下一节中探讨
    `pytest`。'
- en: Unit testing with pytest
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pytest进行单元测试
- en: We can create unit tests using a library that provides a common framework for
    the test scenarios, along with a test runner to execute the tests and log results.
    Unit tests focus on testing the least amount of code possible in any one test.
    The standard library includes the `unittest` package. While widely used, this
    package tends to force us to create a fair amount of boilerplate code for each
    test case.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用一个提供测试场景通用框架的库来创建单元测试，同时还包括一个测试运行器来执行测试并记录结果。单元测试专注于在任何一个测试中尽可能测试最少的代码。标准库中包含了`unittest`包。虽然这个包被广泛使用，但它往往迫使我们为每个测试案例编写相当多的样板代码。
- en: One of the more popular alternatives to the standard library `unittest` is `pytest`.
    This has the advantage of letting us write smaller, and more clear, test cases.
    The lack of overheads makes this a desirable alternative.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 标准库中的 `unittest` 之一更受欢迎的替代方案是 `pytest`。它具有让我们编写更小、更清晰的测试用例的优势。没有额外开销使得这成为一个理想的替代方案。
- en: Since `pytest` is not part of the standard library, you'll need to download
    and install it yourself. You can get it from the `pytest` home page at [https://docs.pytest.org/en/stable/](https://docs.pytest.org/en/stable/).
    You can install it with any of the installers.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `pytest` 不是标准库的一部分，您需要自行下载并安装它。您可以从 [https://docs.pytest.org/en/stable/](https://docs.pytest.org/en/stable/)
    的 `pytest` 主页获取它。您可以使用任何安装程序进行安装。
- en: 'In a Terminal window, activate the virtual environment you''re working in.
    (If you''re using venv, for example, you might use `python -m venv c:\path\to\myenv`.)
    Then, use an OS command like the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端窗口中，激活你正在工作的虚拟环境。（例如，如果你使用的是venv，你可能需要使用`python -m venv c:\path\to\myenv`。）然后，使用以下类似的操作系统命令：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The Windows command should be the same as the command on macOS and Linux.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Windows命令应与macOS和Linux上的命令相同。
- en: The `pytest` tool can use a substantially different test layout from the `unittest`
    module. It doesn't require test cases to be subclasses of `unittest.TestCase`.
    Instead, it takes advantage of the fact that Python functions are first-class
    objects and allows any properly named function to behave like a test. Rather than
    providing a bunch of custom methods for asserting equality, it uses the `assert` statement
    to verify results. This makes tests simpler, more readable, and, consequently,
    easier to maintain.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest` 工具可以使用与 `unittest` 模块显著不同的测试布局。它不需要测试用例是 `unittest.TestCase` 的子类。相反，它利用了
    Python 函数是一等对象的事实，并允许任何正确命名的函数表现得像测试。而不是提供大量用于断言相等的自定义方法，它使用 `assert` 语句来验证结果。这使得测试更加简单、易读，从而更容易维护。'
- en: When we run `pytest`, it starts in the current folder and searches for any modules
    or sub packages with names beginning with the characters `test_`. (Including the
    `_` character.) If any functions in this module also start with `test` (no `_`
    required), they will be executed as individual tests. Furthermore, if there are
    any classes in the module whose name starts with `Test`, any methods on that class
    that start with `test_` will also be executed in the test environment.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行`pytest`时，它将在当前文件夹中启动并搜索以字符`test_`开头的任何模块或子包。（包括`_`字符。）如果此模块中的任何函数也以`test`开头（不需要`_`），它们将被作为单独的测试执行。此外，如果模块中存在以`Test`开头的类，那么该类上以`test_`开头的任何方法也将被在测试环境中执行。
- en: 'It also searches in a folder named – unsurprisingly – `tests`. Because of this,
    it''s common to have code broken up into two folders: the `src/` directory contains
    the working module, library, or application, while the `tests/` directory contains
    all the test cases.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 它还会在名为 – 令人惊讶的是 – `tests` 的文件夹中进行搜索。正因为如此，常见的做法是将代码拆分到两个文件夹中：`src/` 目录包含工作模块、库或应用程序，而
    `tests/` 目录包含所有测试用例。
- en: 'Using the following code, let''s port the simple `unittest` example we wrote
    earlier to `pytest`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码，让我们将之前编写的简单 `unittest` 示例移植到 `pytest`：
- en: '[PRE7]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For the same test, we've written two lines of more readable code, in comparison
    to the six lines required in our first `unittest` example.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于相同的测试，我们编写了两行更易读的代码，相比之下，在我们的第一个`unittest`示例中需要六行代码。
- en: 'However, we are not forbidden from writing class-based tests. Classes can be
    useful for grouping related tests together or for tests that need to access related
    attributes or methods on the class. The following example shows an extended class
    with a passing and a failing test; we''ll see that the error output is more comprehensive
    than that provided by the `unittest` module:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们并没有被禁止编写基于类的测试。类可以用于将相关的测试分组在一起，或者用于需要访问类上相关属性或方法的测试。以下示例展示了一个包含通过和失败测试的扩展类；我们将看到错误输出比`unittest`模块提供的更为全面：
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Notice that the class doesn''t have to extend any special objects to be discovered
    as a test case (although `pytest` will run standard `unittest TestCases` just
    fine). If we run `python -m pytest tests/<filename>`, the output looks as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，类不需要扩展任何特殊对象就能被识别为测试用例（尽管`pytest`可以很好地运行标准的`unittest TestCases`）。如果我们运行`python
    -m pytest tests/<filename>`，输出将如下所示：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The output starts with some useful information about the platform and interpreter.
    This can be useful for sharing or discussing bugs across disparate systems. The
    third line tells us the name of the file being tested (if there are multiple test
    modules picked up, they will all be displayed), followed by the familiar `.F`
    we saw in the `unittest` module; the `.` character indicates a passing test, while
    the letter `F` demonstrates a failure.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 输出开始于一些关于平台和解释器的有用信息。这可以用于在不同系统间共享或讨论错误。第三行告诉我们正在测试的文件名称（如果有多个测试模块被选中，它们都将被显示），接着是我们在`unittest`模块中看到的熟悉的`.F`；`.`字符表示通过测试，而字母`F`表示失败。
- en: 'After all tests have run, the error output for each of them is displayed. It
    presents a summary of local variables (there is only one in this example: the `self` parameter
    passed into the function), the source code where the error occurred, and a summary
    of the error message. In addition, if an exception other than an `AssertionError` is
    raised, `pytest` will present us with a complete traceback, including source code
    references.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 所有测试运行完毕后，每个测试的错误输出都会显示出来。它展示了局部变量的摘要（在这个例子中只有一个：传递给函数的`self`参数），错误发生的位置的源代码，以及错误信息的摘要。此外，如果抛出的异常不是`AssertionError`，`pytest`将为我们提供一个完整的回溯信息，包括源代码引用。
- en: By default, `pytest` suppresses output from `print()` if the test is successful.
    This is useful for test debugging; when a test is failing, we can add `print()` statements
    to the test to check the values of specific variables and attributes as the test
    runs. If the test fails, these values are output to help with diagnosis. However,
    once the test is successful, the `print()` output is not displayed, and they are
    easily ignored. We don't have to clean up the test output by removing `print()`.
    If the tests ever fail again, due to future changes, the debugging output will
    be immediately available.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`pytest` 在测试成功时抑制 `print()` 输出。这对于测试调试很有用；当测试失败时，我们可以在测试中添加 `print()`
    语句来检查特定变量和属性在测试运行过程中的值。如果测试失败，这些值会被输出以帮助诊断。然而，一旦测试成功，`print()` 输出就不会显示，并且很容易被忽略。我们不需要通过移除
    `print()` 来清理测试输出。如果由于未来的更改，测试再次失败，调试输出将立即可用。
- en: Interestingly, this use of the `assert` statement exposes a potential problem
    to **mypy**. When we use the `assert` statement, **mypy** can examine the types,
    and will alert us to a potential problem with `assert 1 == "1"`. This code is
    unlikely to be right, and it will not only fail as a unit test, but will also
    fail a **mypy** inspection.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这种使用 `assert` 语句的方式向 **mypy** 暴露了一个潜在问题。当我们使用 `assert` 语句时，**mypy** 可以检查类型，并将提醒我们
    `assert 1 == "1"` 可能存在的问题。这段代码很可能是不正确的，它不仅会在单元测试中失败，而且还会在 **mypy** 检查中失败。
- en: We've looked at how `pytest` supports the `WHEN` and `THEN` steps of a test
    using a function and the `assert` statement. Now, we need to look more closely
    at how to handle `GIVEN` steps. There are two ways to establish the `GIVEN` precondition
    for a test; we'll start with one that works for simple cases.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探讨了`pytest`如何通过函数和`assert`语句支持测试的`WHEN`和`THEN`步骤。现在，我们需要更仔细地看看如何处理`GIVEN`步骤。为测试建立`GIVEN`前提条件有两种方法；我们将从适用于简单情况的一种开始。
- en: pytest's setup and teardown functions
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: pytest的设置和清理函数
- en: '`pytest` supports setup and teardown capabilities, similar to the methods used
    in `unittest`, but it provides even more flexibility. We''ll discuss these general
    functions briefly; `pytest` provides us with a powerful fixtures capability, which
    we''ll discuss in the next section.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest` 支持设置和清理功能，类似于 `unittest` 中使用的方法，但它提供了更大的灵活性。我们将简要讨论这些通用功能；`pytest`
    为我们提供了一种强大的固定功能，我们将在下一节中进行讨论。'
- en: If we are writing class-based tests, we can use two methods called `setup_method()`
    and `teardown_method()`. They are called before and after each test method in
    the class to perform setup and cleanup duties, respectively.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们正在编写基于类的测试，我们可以使用两种方法，称为 `setup_method()` 和 `teardown_method()`。它们分别在类中的每个测试方法之前和之后被调用，以执行设置和清理任务。
- en: In addition, `pytest` provides other setup and teardown functions to give us
    more control over when preparation and cleanup code is executed. The `setup_class()`
    and `teardown_class()` methods are expected to be class methods; they accept a
    single argument representing the class in question (there is no `self` argument
    because there's no instance; instead, the class is provided). These methods are
    run by `pytest` when the class is initiated rather than on each test run.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`pytest` 提供了其他设置和清理函数，以便我们能够更好地控制准备和清理代码的执行时机。`setup_class()` 和 `teardown_class()`
    方法预期是类方法；它们接受一个表示相关类的单个参数（因为没有 `self` 参数，因为没有实例；相反，提供了类）。这些方法是在类初始化时由 `pytest`
    运行的，而不是在每次测试运行时。
- en: Finally, we have the `setup_module()` and `teardown_module()` functions, which
    are run by `pytest` immediately before and after all tests (in functions or classes)
    in that module. These can be useful for *one-time* setup, such as creating a socket
    or database connection that will be used by all tests in the module. Be careful
    with this one, as it can accidentally introduce dependencies between tests if
    some object state isn't correctly cleaned up between tests.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有`setup_module()`和`teardown_module()`函数，这些函数会在`pytest`运行该模块中所有测试（在函数或类中）之前和之后立即执行。这些函数对于进行*一次性*设置很有用，例如创建一个将被模块中所有测试使用的套接字或数据库连接。在使用时请小心，因为如果某些对象状态在测试之间没有被正确清理，可能会意外地引入测试之间的依赖关系。
- en: 'That short description doesn''t do a great job of explaining exactly when these
    methods are called, so let''s look at an example that illustrates exactly when
    it happens:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 那个简短的描述并没有很好地解释这些方法究竟在何时被调用，所以让我们来看一个例子，以具体说明它发生的情况：
- en: '[PRE10]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The sole purpose of the `BaseTest` class is to extract four methods that are
    otherwise identical to the two test classes, and use inheritance to reduce the
    amount of duplicate code. So, from the point of view of `pytest`, the two subclasses
    have not only two test methods each, but also two setup and two teardown methods
    (one at the class level, one at the method level).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`BaseTest` 类的唯一目的是提取四个方法，这些方法在其他方面与两个测试类完全相同，并使用继承来减少重复代码的数量。因此，从 `pytest`
    的角度来看，这两个子类不仅各自有两个测试方法，还有两个设置方法和两个销毁方法（一个在类级别，一个在方法级别）。'
- en: 'If we run these tests using `pytest` with the `print()` function output suppression
    disabled (by passing the `-s` or `--capture=no` flag), they show us when the various
    functions are called in relation to the tests themselves:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用带有`print()`函数输出抑制（通过传递`-s`或`--capture=no`标志）的`pytest`运行这些测试，它们会显示各种函数在测试本身中的调用关系：
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The setup and teardown methods for the module as a whole are executed at the
    beginning and end of the session. Then, the lone module-level test function is
    run. Next, the setup method for the first class is executed, followed by the two
    tests for that class. These tests are each individually wrapped in separate `setup_method()`
    and `teardown_method()` calls. After the tests have executed, the teardown method
    on the class is called. The same sequence happens for the second class, before
    the `teardown_module()` method is finally called, exactly once.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 模块的整体设置和销毁方法在会话的开始和结束时执行。然后，单独的模块级测试函数被运行。接下来，执行第一个类的设置方法，然后是针对该类的两个测试。这些测试每个都分别被包裹在单独的
    `setup_method()` 和 `teardown_method()` 调用中。在测试执行完毕后，调用类上的销毁方法。对于第二个类，发生相同的序列，最后最终只调用一次
    `teardown_module()` 方法。
- en: While these function names provide a lot of options for testing, we'll often
    have setup conditions that are shared across multiple test scenarios. These can
    be reused via a composition-based design; `pytest` calls these designs "fixtures."
    We'll look at fixtures next.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些函数名提供了很多测试选项，但我们通常会面临多个测试场景中共享的设置条件。这些可以通过基于组合的设计进行复用；`pytest`将这些设计称为“固定装置”。我们将在下一节中探讨固定装置。
- en: pytest fixtures for setup and teardown
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: pytest 的设置和清理 fixtures
- en: One of the most common uses for the various setup functions is to ensure the
    GIVEN step of a test is prepared. This often involves creating objects and making
    sure certain class or module variables have known values before a test method
    is run.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 各种设置函数最常见的一个用途是确保测试的**给定步骤**已准备好。这通常涉及创建对象并确保在运行测试方法之前，某些类或模块变量具有已知的值。
- en: In addition to a set of special method names for a test class, `pytest` offers
    a completely different way of doing this, using what are known as **fixtures**.
    Fixtures are functions to build the `GIVEN` condition, prior to a test's `WHEN`
    step.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 除了为测试类提供一组特殊的方法名称外，`pytest` 还提供了一种完全不同的方法来实现这一点，即使用所谓的 ** fixtures**。Fixtures
    是用于构建测试的 `GIVEN` 条件的函数，在测试的 `WHEN` 步骤之前执行。
- en: The `pytest` tool has a number of built-in fixtures, we can define fixtures
    in a configuration file and reuse them, and we can define unique fixtures as part
    of our tests. This allows us to separate configuration from the execution of tests,
    allowing fixtures to be used across multiple classes and modules.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest` 工具提供了一系列内置的 fixtures，我们可以在配置文件中定义 fixtures 并重复使用它们，同时我们还可以将独特的 fixtures
    作为测试的一部分进行定义。这使我们能够将配置与测试执行分离，使得 fixtures 可以在多个类和模块之间使用。'
- en: 'Let''s look at a class that does a few computations that we need to test:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个执行了一些我们需要测试的计算的类：
- en: '[PRE12]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This class extends the built-in `list` class to add three statistical summary
    methods, `mean()`, `median()`, and `mode()`. For each method, we need to have
    some set of data we can use; this configuration of a `StatsList` with known data
    is the fixture we'll be testing.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类扩展了内置的 `list` 类，增加了三个统计摘要方法，`mean()`、`median()` 和 `mode()`。对于每个方法，我们需要有一组可以使用的数据；这种包含已知数据的
    `StatsList` 配置是我们将要测试的基准配置。
- en: To use a fixture to create the `GIVEN` precondition, we add the fixture name
    as a parameter to our test function. When a test runs, the names of a test function's
    parameters will be located in the collection of fixtures, and those fixture-creating
    functions will be executed for us automatically.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用夹具创建`GIVEN`预条件，我们将夹具名称作为参数添加到我们的测试函数中。当测试运行时，测试函数参数的名称将在夹具集合中定位，那些创建夹具的函数将自动为我们执行。
- en: 'For example, to test the `StatsList` class, we will want to repeatedly provide
    a list of valid integers. We can write our tests as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，为了测试`StatsList`类，我们希望反复提供一个有效的整数列表。我们可以这样编写我们的测试：
- en: '[PRE13]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Each of the three test functions accepts a parameter named `valid_stats`; this
    parameter is created by `pytest` automatically calling the `valid_stats` function
    for us. The function was decorated with `@pytest.fixture` so it could be used
    in this special way by `pytest`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 三个测试函数中的每一个都接受一个名为`valid_stats`的参数；这个参数是由`pytest`自动调用`valid_stats`函数为我们创建的。该函数被装饰为`@pytest.fixture`，因此可以通过`pytest`以这种方式使用。
- en: And yes, the names must match. The **pytest** runtime looks for functions with
    the `@fixture` decorator that match the parameter name.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 并且是的，名称必须匹配。**pytest** 运行时会寻找与参数名称匹配的带有 `@fixture` 装饰器的函数。
- en: Fixtures can do a lot more than return simple objects. A `request` object can
    be passed into the fixture factory to provide extremely useful methods and attributes
    to modify the fixture's behavior. The `module`, `cls`, and `function` attributes
    of the `request` object allow us to see exactly which test is requesting the fixture.
    The `config` attribute of the `request` object allows us to check command-line
    arguments and a great deal of other configuration data.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 固定装置的功能远不止返回简单的对象。可以将一个`request`对象传递给固定装置工厂，以提供修改固定装置行为的极其有用的方法和属性。`request`对象的`module`、`cls`和`function`属性使我们能够确切地看到哪个测试正在请求固定装置。`request`对象的`config`属性允许我们检查命令行参数以及大量的其他配置数据。
- en: If we implement the fixture as a generator, it can also run cleanup code after
    each test is run. This provides the equivalent of a teardown method on a per-fixture
    basis. We can use it to clean up files, close connections, empty lists, or reset
    queues. For unit tests, where items are isolated, a mock object is a better idea
    than performing a teardown on a stateful object. See the *Imitating objects using
    Mocks* section, later in this chapter, for a simpler approach that's ideal for
    unit testing.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将夹具实现为一个生成器，它也可以在每次测试运行后执行清理代码。这相当于在每个夹具级别上提供了一个拆卸方法。我们可以用它来清理文件、关闭连接、清空列表或重置队列。对于单元测试，其中项目是隔离的，使用模拟对象比在具有状态的对象上执行拆卸更好。请参阅本章后面的*使用模拟模仿对象*部分，了解适用于单元测试的更简单的方法。
- en: For integration tests, we might want to test some code that creates, deletes,
    or updates files. We'll often use the `pytest` `tmp_path` fixture to write these
    to directories that can be deleted later, saving us from having to do a teardown
    in a test. While rarely needed for unit testing, a teardown is helpful for stopping
    subprocesses or removing database changes that are part of an integration test.
    We'll see this a little later in this section. First, let's look at a small example
    of a fixture with setup and teardown capabilities.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对于集成测试，我们可能需要测试一些创建、删除或更新文件的代码。我们通常会使用`pytest`的`tmp_path`固定装置将这些代码写入可以稍后删除的目录中，这样我们就不需要在测试中进行拆卸操作了。虽然对于单元测试很少需要，但拆卸操作对于停止子进程或移除集成测试中的一部分数据库更改是有帮助的。我们将在本节稍后看到这一点。首先，让我们来看一个小型的具有设置和拆卸功能的固定装置的例子。
- en: 'To get started on the concept of a fixture that does both setup and teardown,
    here''s a little bit of code that makes a backup copy of a file and writes a new
    file with a checksum of an existing file:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始了解既包含设置又包含拆卸的夹具概念，这里有一小段代码，它会对文件创建备份副本，并写入一个包含现有文件校验和的新文件：
- en: '[PRE14]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There are two scenarios:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种情况：
- en: The source file exists; a new checksum is added to the directory
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源文件存在；已将新的校验和添加到目录中
- en: The source file and a checksum file both exist; in this case, the old checksum
    is copied to a backup location and a new checksum is written
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源文件和校验和文件都存在；在这种情况下，旧的校验和被复制到备份位置，并写入新的校验和
- en: 'We won''t test both scenarios, but we will show how a fixture can create –
    and then delete – the files required for a test sequence. We''ll focus on the
    second scenario because it''s more complex. We''ll break the testing into two
    parts, starting with the fixture:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会测试两种场景，但我们将展示一个夹具如何创建——然后删除——测试序列所需的文件。我们将重点关注第二种场景，因为它更复杂。我们将把测试分为两部分，从夹具开始：
- en: '[PRE15]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `yield` statement is the secret for making this work. Our fixture is really
    a generator that produces one result and then waits for the next request of a
    value. The first result that''s created follows a number of steps: a working directory
    is created, a source file is created in the working directory, and then an old
    checksum file is created. The `yield` statement provides two paths to the test
    and waits for the next request. This work completes the `GIVEN` condition setup
    for the test.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`yield`语句是使这工作起来的秘密。我们的工具实际上是生成器，它产生一个结果然后等待对值的下一个请求。第一个创建的结果遵循一系列步骤：创建一个工作目录，在工作目录中创建一个源文件，然后创建一个旧的校验和文件。`yield`语句为测试提供了两条路径并等待下一个请求。这项工作完成了测试的`GIVEN`条件设置。'
- en: When the test function finishes, `pytest` will try to get one final item from
    this fixture. This lets the function unlink the files, removing them. There's
    no return value, which signals the end of the iteration. In addition to leveraging
    the generator protocol, the `working_directory` fixture relies on the `tmp_path`
    fixture of `pytest` to create a temporary working location for this test.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当测试函数执行完毕时，`pytest` 将尝试从这个 fixture 中获取一个最后的项。这允许函数解除文件的链接，将其删除。没有返回值，这表示迭代的结束。除了利用生成器协议外，`working_directory`
    fixture 还依赖于 `pytest` 的 `tmp_path` fixture 来为这个测试创建一个临时的工作位置。
- en: 'Here''s the test that uses this `working_directory` fixture:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用这个`working_directory`测试用例的测试：
- en: '[PRE16]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The test is marked with a `skipif` condition because this test won't work in
    Python 3.8; the `with_stem()` method of a `Path` isn't part of the older `pathlib`
    implementation. This assures us that the test is counted but noted as inappropriate
    for a specific Python release. We'll return to this in the *Skipping tests with
    pytest* section, later in this chapter.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 测试被标记为`skipif`条件，因为在这个测试中Python 3.8将无法运行；`Path`对象的`with_stem()`方法不是旧版`pathlib`实现的一部分。这确保了测试会被计算，但会被标记为不适合特定Python版本。我们将在本章后面的*使用pytest跳过测试*部分回到这个问题。
- en: The reference to the `working_directory` fixture forces `pytest` to execute
    the fixture function, providing the test scenario with two paths to be used as
    part of the GIVEN condition prior to testing. The WHEN step evaluates the `checksum_writer.checksum()`
    function with these two paths. The THEN steps are a sequence of `assert` statements
    to make sure the files are created with the expected values. After the test is
    run, `pytest` will use `next()` to get another item from the fixture; this action
    executes the code after the `yield`, resulting in a teardown after the test.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对 `working_directory` 配置项的引用强制 `pytest` 执行配置项函数，在测试之前为测试场景提供两个路径作为 GIVEN 条件的一部分。WHEN
    步骤使用这两个路径评估 `checksum_writer.checksum()` 函数。THEN 步骤是一系列 `assert` 语句，以确保文件以预期的值创建。测试运行后，`pytest`
    将使用 `next()` 从配置项中获取另一个项目；这个动作执行 `yield` 之后的代码，导致测试之后进行清理。
- en: When testing components in isolation, we won't often need to use the teardown
    feature of a fixture. For integration tests, however, where a number of components
    are used in concert, it may be necessary to stop processes or remove files. In
    the next section, we'll look at a more sophisticated fixture. This kind of fixture
    can be used for more than a single test scenario.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当单独测试组件时，我们通常不需要使用夹具的拆卸功能。然而，对于集成测试，其中多个组件协同使用，可能需要停止进程或删除文件。在下一节中，我们将探讨一个更复杂的夹具。这种夹具可以用于多个测试场景。
- en: More sophisticated fixtures
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更复杂的夹具
- en: 'We can pass a `scope` parameter to create a fixture that lasts longer than
    one test. This is useful when setting up an expensive operation that can be reused
    by multiple tests, as long as the resource reuse doesn''t break the atomic or
    unit nature of the test: one unit test should not rely on, and should not be impacted
    by, any other unit test.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将一个`scope`参数传递给创建一个比单个测试更持久的夹具。这在设置一个可以被多个测试复用的昂贵操作时很有用，只要资源复用不会破坏测试的原子性或单元性质：一个单元测试不应该依赖于，也不应该受到任何其他单元测试的影响。
- en: As an example, we'll define a server that's part of a client-server application.
    We want multiple web servers to send their log messages to a single, centralized
    log. In addition to isolated unit tests, we need to have an integration test.
    This test makes sure the web server and the log collector properly integrate with
    each other. The integration test will need to start and stop this log collection
    server.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们将定义一个作为客户端-服务器应用程序一部分的服务器。我们希望多个网络服务器将它们的日志消息发送到单个集中式日志。除了独立的单元测试之外，我们还需要一个集成测试。这个测试确保网络服务器和日志收集器能够正确地相互集成。集成测试需要启动和停止这个日志收集服务器。
- en: There are at least three levels to the testing pyramid. Unit tests are the foundation,
    exercising each component in isolation. Integration tests are the middle of the
    pyramid, making sure the components integrate properly with each other. A system
    test or acceptance test is the top of the pyramid, making sure the entire suite
    of software does what it claims.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 测试金字塔至少有三个层级。单元测试是基础，它独立地锻炼每个组件。集成测试位于金字塔的中间，确保组件之间能够正确集成。系统测试或验收测试位于金字塔的顶端，确保整个软件套件能够实现其宣称的功能。
- en: We'll look at a log collection server that accepts messages and writes them
    to a single, central file. These messages are defined by the `logging` module's
    `SocketHandler`. We can depict each message as a block of bytes with a header
    and a payload. In the following table, we've shown the structure using slices
    of the block of bytes.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨一个日志收集服务器，它接受消息并将它们写入一个单一的、中央的文件。这些消息由`logging`模块的`SocketHandler`定义。我们可以将每个消息描绘为一个带有头部和有效负载的字节块。在下面的表格中，我们使用字节块的切片展示了其结构。
- en: 'Here''s how a message is defined:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是消息的定义方式：
- en: '| Slice start | Slice stop | Meaning | Python module and function for parsing
    |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 切片开始 | 切片结束 | 含义 | 解析的Python模块和函数 |'
- en: '| 0 | 4 | payload_size | `struct.unpack(">L", bytes)` |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 4 | 负载大小 | `struct.unpack(">L", bytes)` |'
- en: '| 4 | payload_size+4 | payload | `pickle.loads(bytes)` |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 负载大小+4 | 负载 | `pickle.loads(bytes)` |'
- en: The size of the header is shown as a four-byte slice, but the size shown here
    can be misleading. The header is formally and officially defined by a format string
    used by the `struct` module, `">L"`. The `struct` module has a function, `calcsize()`,
    to compute the actual length from the format string. Instead of using a literal
    4, which is derived from the size of the "`>L`" format, our code will derive the
    size, `size_bytes`, from the size format string, `size_format`. Using one proper
    source, `size_format`, for both pieces of information follows the design principle
    of Don't Repeat Yourself.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 标头的尺寸以四个字节的切片形式显示，但此处显示的尺寸可能会造成误导。标头正式且官方的定义是由`struct`模块使用的格式字符串，即`">L"`。`struct`模块有一个名为`calcsize()`的函数，用于从格式字符串计算实际长度。我们的代码不会直接使用从`">L"`格式派生出的字面量4，而是会从尺寸格式字符串`size_format`中派生出尺寸，即`size_bytes`。使用一个合适的来源`size_format`来为这两部分信息提供数据，遵循了“不要重复自己”（Don't
    Repeat Yourself）的设计原则。
- en: 'Here''s an example buffer with a message from the `logging` module embedded
    in it. The first line is the header with the payload size, a four-byte value.
    The next lines are the pickled data for a log message:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个包含`logging`模块消息的示例缓冲区。第一行是带有有效载荷大小的标题，一个四字节值。接下来的行是日志消息的序列化数据：
- en: '[PRE17]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To read these messages, we''ll need to collect the payload size bytes first.
    Then, we can consume the payload that follows. Here''s the socket server that
    reads the headers and the payloads and writes them to a file:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要读取这些消息，我们首先需要收集负载大小字节。然后，我们可以消费随后的负载。以下是读取头部和负载并将它们写入文件的套接字服务器：
- en: '[PRE18]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `socketserver.TCPServer` object will listen for connection requests from
    a client. When a client connects, it will create an instance of the `LogDataCatcher`
    class and evaluate the `handle()` method of that object to gather data from that
    client. The `handle()` method decodes the size and payload with a two-step dance.
    First, it reads a few bytes to find the size of the payload. It uses `struct.unpack()`
    to decode those bytes into a useful number, `payload_size`, and then reads the
    given number of bytes to get the payload. The `pickle.loads()` will load a Python
    object from the payload bytes. This is serialized into JSON notation using `json.dumps()`
    and written to the open file. Once a message has been handled, we can try to read
    the next few bytes to see if there's more data waiting. This server will absorb
    messages from the client until the connection is dropped, leading to an error
    in the read and an exit from the `while` statement.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`socketserver.TCPServer` 对象将监听来自客户端的连接请求。当客户端连接时，它将创建 `LogDataCatcher` 类的一个实例，并评估该对象的
    `handle()` 方法以从该客户端收集数据。`handle()` 方法通过两步舞来解码大小和有效载荷。首先，它读取几个字节以找到有效载荷的大小。它使用
    `struct.unpack()` 将这些字节解码成一个有用的数字，即 `payload_size`，然后读取指定数量的字节以获取有效载荷。`pickle.loads()`
    将从有效载荷字节中加载一个 Python 对象。这个对象被序列化为 JSON 表示法，使用 `json.dumps()` 并写入打开的文件。一旦处理了一条消息，我们就可以尝试读取下几个字节以查看是否有更多数据等待。这个服务器将吸收来自客户端的消息，直到连接断开，导致读取错误并退出
    `while` 语句。'
- en: This log collection server can absorb logging messages from an application anywhere
    in a network. This example implementation is single-threaded, meaning it only
    handles one client at a time. We can use additional mixins to create a multithreaded
    server that will accept messages from multiple sources. In this example, we want
    to focus on testing a single application that depends on this server.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 此日志收集服务器可以从网络中任何位置的应用程序吸收日志消息。此示例实现是单线程的，意味着它一次只能处理一个客户端。我们可以使用额外的混合器来创建一个多线程服务器，该服务器将接受来自多个来源的消息。在这个例子中，我们希望专注于测试一个依赖于此服务器的单个应用程序。
- en: 'For completeness, here''s the main script that starts the server running:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，以下是启动服务器运行的主要脚本：
- en: '[PRE19]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We provide a host IP address, a port number, and the file to which we want all
    the messages written. As a practical matter, we might consider using the `argparse`
    module and the `os.environ` dictionary to provide these values to the application.
    For now, we've hardcoded them.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供一个主机IP地址、端口号以及我们希望所有消息写入的文件。作为一个实际操作，我们可能会考虑使用`argparse`模块和`os.environ`字典来将这些值提供给应用程序。目前，我们已将它们硬编码。
- en: 'Here''s the `remote_logging_app.py` application, which transmits log records
    to the log-catching server:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`remote_logging_app.py`应用程序，它将日志记录传输到日志捕获服务器：
- en: '[PRE20]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This application creates two logging handlers. The `SocketHandler` instance
    will open a socket on the given server and port number, and start writing bytes.
    The bytes will include headers and payloads. The `StreamHandler` instance will
    write to the terminal window; this is the default log handler that we would get
    if we didn't create any special handlers. We configure our logger with both handlers
    so each log message goes both to our console and to the stream server collecting
    the messages. The actual work? A little bit of math to compute the factorial of
    a number. Each time we run this application, it should blast out 20 log messages.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 此应用程序创建了两个日志处理器。`SocketHandler` 实例将在指定的服务器和端口号上打开一个套接字，并开始写入字节。这些字节将包括头部和有效负载。`StreamHandler`
    实例将写入终端窗口；这是如果没有创建任何特殊处理器，我们会得到的默认日志处理器。我们使用这两个处理器配置我们的日志记录器，以便每个日志消息都发送到我们的控制台和收集消息的流服务器。实际的工作？一点数学计算，计算一个数的阶乘。每次运行此应用程序时，它应该发出
    20 条日志消息。
- en: 'To test the integrated client and server, we need to start the server in a
    separate process. We don''t want to start and stop it many times (that takes a
    while), so we will start it once and use it in multiple tests. We''ll break this
    into two sections, starting with the two fixtures:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试集成客户端和服务器，我们需要在一个单独的进程中启动服务器。我们不希望频繁地启动和停止它（这需要一些时间），因此我们将只启动一次并在多个测试中使用它。我们将将其分为两个部分，首先从以下两个固定装置开始：
- en: '[PRE21]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `log_catcher` fixture will start the `log_catcher.py` server as a subprocess.
    This has a scope set to `"session"` in the `@fixture` decorator, which means it's
    done once for the whole testing session. The scope can be one of the strings `"function"`,
    `"class"`, `"module"`, `"package"`, or `"session"`, providing distinct places
    where the fixture is created and reused. The startup involves a tiny pause (250
    ms) to make sure the other process has started properly. When this fixture reaches
    the `yield` statement, this part of the `GIVEN` test setup is done.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`log_catcher` 配置将启动 `log_catcher.py` 服务器作为一个子进程。在 `@fixture` 装饰器中，其作用域被设置为
    `"session"`，这意味着在整个测试会话中只执行一次。作用域可以是字符串 `"function"`、`"class"`、`"module"`、`"package"`
    或 `"session"` 之一，提供不同的位置来创建和重用配置。启动过程中会有一个短暂的暂停（250 毫秒），以确保其他进程已正确启动。当此配置达到 `yield`
    语句时，`GIVEN` 测试设置的这部分就完成了。'
- en: The `logging_config` fixture will tweak the log configuration for the `remote_logging_app`
    module that's being tested. When we look at the `work()` function in the `remote_logging_app.py`
    module, we can see that it expects a module-level `logger` object. This test fixture
    creates a `SocketHandler` object, adds this to the `logger`, and then executes
    the `yield` statement.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`logging_config` 配置项将调整正在测试的 `remote_logging_app` 模块的日志配置。当我们查看 `remote_logging_app.py`
    模块中的 `work()` 函数时，我们可以看到它期望一个模块级别的 `logger` 对象。这个测试配置项创建一个 `SocketHandler` 对象，将其添加到
    `logger` 中，然后执行 `yield` 语句。'
- en: 'Once both of these fixtures have contributed to the `GIVEN` condition, we can
    define test cases that contain the `WHEN` steps. Here are two examples for two
    similar scenarios:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这两个固定装置都对`给定`条件做出了贡献，我们就可以定义包含`当`步骤的测试用例。以下是两个类似场景的两个示例：
- en: '[PRE22]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: These two scenarios both require the two fixtures. The `log_catcher` fixture,
    with a session scope, is prepared once and used for both tests. The `logging_config`
    fixture, however, has default scope, which means it's prepared for each test function.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种场景都需要这两个固定装置。`log_catcher`装置具有会话作用域，只需准备一次，即可用于两个测试。然而，`logging_config`装置具有默认作用域，这意味着它为每个测试函数都进行了准备。
- en: The type hint of `None` follows the definition of the fixture as `Iterator[None]`.
    There's no value returned in the `yield` statement. For these tests, the setup
    operation is preparing the overall runtime environment by starting a process.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`None`的类型提示遵循了`Iterator[None]`的固定定义。在`yield`语句中不返回任何值。对于这些测试，设置操作通过启动一个进程来准备整体运行时环境。'
- en: When a test function finishes, the `logging_config` fixture resumes after the
    `yield` statement. (This fixture is an iterator, and the `next()` function is
    used to try to get a second value from it.) This closes and removes the handler,
    cleanly breaking the network connection with the log catcher process.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 当测试函数完成后，`logging_config` 配置项在 `yield` 语句之后恢复。（这个配置项是一个迭代器，使用 `next()` 函数尝试从中获取第二个值。）这会关闭并移除处理程序，干净利落地断开与日志捕获进程的网络连接。
- en: When testing finishes overall, the `log_catcher` fixture can then terminate
    the child process. To help with debugging, we print any output. To be sure the
    test worked, we check the OS return code. Because the process was terminated (via
    `p.terminate()`), the return code should be the `signal.SIGTERM` value. Other
    return code values, particularly a return code of one, mean the log catcher crashed
    and the test failed.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 当整体测试完成后，`log_catcher` 测试夹具可以终止子进程。为了帮助调试，我们打印任何输出。为了确保测试成功，我们检查操作系统的返回码。因为进程是被终止的（通过
    `p.terminate()`），返回码应该是 `signal.SIGTERM` 的值。其他返回码值，尤其是返回码为一，意味着日志捕获器崩溃，测试失败。
- en: We've omitted a detailed `THEN` check, but it would also be part of the `log_catcher`
    fixture. The existing `assert` statement makes sure the log catcher terminated
    with the expected return code. Once the catcher in the sky has finished absorbing
    log messages, this fixture should also read the log file to be sure it contains
    the expected entries for the two scenarios.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们省略了详细的`THEN`检查，但它也应该是`log_catcher`测试套件的一部分。现有的`assert`语句确保日志捕获器以预期的返回代码终止。一旦天上的捕获器完成吸收日志消息，这个测试套件也应该读取日志文件，以确保它包含两个场景预期的条目。
- en: Fixtures can also be parameterized. We can use a decorator like `@pytest.fixture(params=[some,
    list, of, values])` to create multiple copies of a fixture, which will lead to
    multiple tests with each of the parameter values.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 固件也可以进行参数化。我们可以使用一个装饰器如 `@pytest.fixture(params=[some, list, of, values])` 来创建固件的多个副本，这将导致每个参数值都有多个测试。
- en: The sophistication of `pytest` fixtures makes them very handy for a wide variety
    of test setup and teardown requirements. Earlier in this section, we hinted at
    ways to mark tests as inappropriate for a particular version of Python. In the
    next section, we'll look at how we can mark tests to be skipped.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest` 配置的复杂性使得它们在满足各种测试设置和清理需求时非常方便。在本节前面，我们提到了如何标记测试不适用于Python的特定版本。在下一节中，我们将探讨如何标记要跳过的测试。'
- en: Skipping tests with pytest
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跳过 pytest 中的测试
- en: 'It is sometimes necessary to skip tests in `pytest`, for a similar variety
    of reasons: the code being tested hasn''t been written yet, the test only runs
    on certain interpreters or operating systems, or the test is time-consuming and
    should only be run under certain circumstances. In the previous section, one of
    our tests would not work in Python 3.8, and needed to be skipped.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 有时在 `pytest` 中跳过测试是必要的，原因多种多样：被测试的代码尚未编写，测试仅在特定的解释器或操作系统上运行，或者测试耗时较长，只在特定情况下运行。在上一节中，我们的一些测试在
    Python 3.8 中无法运行，需要被跳过。
- en: 'One way to skip tests is by using the `pytest.skip()` function. It accepts
    a single argument: a string describing why it has been skipped. This function
    can be called anywhere. If we call it inside a test function, the test will be
    skipped. If we call it at the module level, all the tests in that module will
    be skipped. If we call it inside a fixture, all tests that reference the fixture
    will be skipped.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 跳过测试的一种方法是使用 `pytest.skip()` 函数。它接受一个参数：一个字符串，描述为什么它被跳过。这个函数可以在任何地方调用。如果我们在一个测试函数内部调用它，测试将被跳过。如果我们它在模块级别调用，该模块中的所有测试都将被跳过。如果我们它在
    fixture 内部调用，所有引用该 fixture 的测试都将被跳过。
- en: 'Of course, in all these locations, it is often only desirable to skip tests
    if certain conditions have or have not been met. Since we can execute the `skip()` function
    at any place in Python code, we can execute it inside an `if` statement. We may
    write a test that looks as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在这些所有位置，通常只有当满足或未满足某些条件时，才希望跳过测试。由于我们可以在Python代码的任何地方执行`skip()`函数，我们可以在`if`语句中执行它。我们可以编写一个看起来如下所示的测试：
- en: '[PRE23]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This test will skip on most operating systems. It should run on the Pythonista
    port of Python for iOS. It shows how we can skip a scenario conditionally, and
    since the `if` statement can check any valid conditional, we have a lot of power
    over when tests are skipped. Often, we check `sys.version_info` to check the Python
    interpreter version, `sys.platform` to check the operating system, or `some_library.__version__`
    to check whether we have a recent enough version of a given module.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这个测试在大多数操作系统上都会跳过。它应该在iOS的Pythonista端口上运行。它展示了我们如何有条件地跳过某个场景，并且由于`if`语句可以检查任何有效的条件，我们在决定测试是否跳过时拥有很大的权力。通常，我们会检查`sys.version_info`来确认Python解释器的版本，`sys.platform`来确认操作系统，或者`some_library.__version__`来检查我们是否有给定模块的最新版本。
- en: 'Since skipping an individual test method or function based on a condition is
    one of the most common uses of test skipping, `pytest` provides a convenient decorator
    that allows us to do this in one line. The decorator accepts a single string,
    which can contain any executable Python code that evaluates to a Boolean value.
    For example, the following test will only run on Python 3.9 or higher:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 由于基于条件跳过单个测试方法或函数是测试跳过的最常见用途之一，`pytest` 提供了一个方便的装饰器，允许我们一行内完成此操作。该装饰器接受一个字符串，该字符串可以包含任何评估为布尔值的可执行
    Python 代码。例如，以下测试仅在 Python 3.9 或更高版本上运行：
- en: '[PRE24]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `pytest.mark.xfail` decorator marks a test as expected to fail. If the test
    is successful, it will be recorded as a failure (it failed to fail!). If it fails,
    it will be reported as expected behavior. In the case of `xfail`, the conditional
    argument is optional. If it is not supplied, the test will be marked as expected
    to fail under all conditions.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest.mark.xfail` 装饰器将测试标记为预期会失败。如果测试成功，它将被记录为失败（它未能失败！）。如果测试失败，它将被报告为预期的行为。在`xfail`的情况下，条件参数是可选的。如果没有提供，测试将被标记为在所有条件下预期会失败。'
- en: The `pytest` framework has a ton of other features besides those described here,
    and the developers are constantly adding innovative new ways to make your testing
    experience more enjoyable. They have thorough documentation on their website at [https://docs.pytest.org/](https://docs.pytest.org/).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest` 框架除了这里描述的功能之外，还有许多其他特性，并且开发人员持续在添加创新的新方法来提升您的测试体验。他们在其网站上提供了详尽的文档，网址为
    [https://docs.pytest.org/](https://docs.pytest.org/)。'
- en: The `pytest` tool can find and run tests defined using the standard `unittest` library,
    in addition to its own testing infrastructure. This means that if you want to
    migrate from `unittest` to `pytest`, you don't have to rewrite all your old tests.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest` 工具可以找到并运行使用标准 `unittest` 库定义的测试，以及它自己的测试基础设施。这意味着，如果您想从 `unittest`
    迁移到 `pytest`，您不需要重写所有旧测试。'
- en: We've looked at using a fixture to set up and tear down a complex environment
    for testing. This is helpful for some integration tests, but a better approach
    may be to imitate an expensive object or a risky operation. Additionally, any
    kind of teardown operation is inappropriate for unit tests. A unit test isolates
    each software component as a separate unit to be tested. This means we'll often
    replace all of the interface objects with imitations, called "mocks," to isolate
    the unit being tested. Next, we'll turn to creating mock objects to isolate units
    and imitate expensive resources.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探讨了使用夹具来设置和拆除用于测试的复杂环境。这对某些集成测试很有帮助，但可能更好的方法是模拟一个昂贵的对象或一个有风险的操作。此外，任何拆除操作对于单元测试都是不合适的。单元测试将每个软件组件隔离成单独的单元进行测试。这意味着我们通常会替换所有接口对象为模拟对象，称为“模拟”，以隔离正在测试的单元。接下来，我们将转向创建模拟对象以隔离单元并模仿昂贵的资源。
- en: Imitating objects using Mocks
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Mocks 模拟对象
- en: 'Isolated problems are easier to diagnose and solve. Figuring out why a gasoline
    car won''t start can be tricky because there are so many interrelated parts. If
    a test fails, uncovering all the interrelationships makes diagnosis of the problem
    difficult. We often want to isolate items by providing simplified imitations.
    It turns out there are two reasons to replace perfectly good code with imitation
    (or "mock") objects:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 独立的问题更容易诊断和解决。弄清楚为什么汽油车无法启动可能很棘手，因为有很多相互关联的部件。如果测试失败，揭示所有这些相互关系会使问题诊断变得困难。我们通常希望通过提供简化的模拟来隔离项目。结果发现，用模拟（或“模拟”）对象替换完美的代码有两个原因：
- en: The most common case is to isolate a unit under test. We want to create collaborating
    classes and functions so we can test one unknown component in an environment of
    known, trusted test fixtures.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最常见的案例是隔离一个待测试的单元。我们希望创建协作的类和函数，这样我们就可以在已知、可信的测试固定装置环境中测试一个未知组件。
- en: Sometimes, we want to test code that requires an object that is either expensive
    or risky to use. Things like shared databases, filesystems, and cloud infrastructures
    can be very expensive to set up and tear down for testing.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时候，我们想要测试需要使用昂贵或存在风险的对象的代码。例如，共享数据库、文件系统和云基础设施的设置和拆除对于测试来说可能非常昂贵。
- en: In some cases, this may lead to designing an API to have a testable interface.
    Designing for testability often means designing a more usable interface, too.
    In particular, we have to expose assumptions about collaborating classes so we
    can inject a mock object instead of an instance of an actual application class.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，这可能会导致设计一个具有可测试接口的API。为了可测试性而进行设计通常也意味着设计一个更易用的接口。特别是，我们必须暴露关于协作类的假设，这样我们就可以注入一个模拟对象，而不是实际应用程序类的实例。
- en: 'For example, imagine we have some code that keeps track of flight statuses
    in an external key-value store (such as `redis` or `memcache`), such that we can
    store the timestamp and the most recent status. The implementation will require
    the `redis` client; it''s not needed to write unit tests. The client can be installed
    with the `python -m pip install redis` command like this:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有一些代码用于跟踪外部键值存储（例如`redis`或`memcache`）中的航班状态，以便我们可以存储时间戳和最新的状态。该实现将需要`redis`客户端；编写单元测试时不需要它。可以使用以下命令安装客户端：`python
    -m pip install redis`。
- en: '[PRE25]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'If you want to run this with a real `redis` server, you''ll also need to download
    and install `redis`. This can be done as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要使用真实的 `redis` 服务器运行此程序，你还需要下载并安装 `redis`。这可以通过以下步骤完成：
- en: Download the Docker desktop to help manage this application. See [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop).
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载 Docker 桌面版以帮助管理此应用程序。请参阅 [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)。
- en: Use the `docker pull redis` command from a Terminal window to download a `redis`
    server image. This image can be used to build a running Docker container.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用终端窗口中的 `docker pull redis` 命令下载一个 `redis` 服务器镜像。这个镜像可以用来构建一个正在运行的 Docker 容器。
- en: You can then start the server with `docker run -p 6379:6379 redis`. This will
    start a container running the `redis` image. Then you can use this for integration
    testing.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用 `docker run -p 6379:6379 redis` 命令启动服务器。这将启动一个运行 `redis` 镜像的容器。然后您可以用它来进行集成测试。
- en: An alternative that avoids **docker** involves a number of platform-specific
    steps. See [https://redislabs.com/ebook/appendix-a/](https://redislabs.com/ebook/appendix-a/)
    for a number of installation scenarios. The examples that follow will assume **docker**
    is being used; the minor changes that are required to switch to a native installation
    of `redis` are left as an exercise for the reader.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 避免使用**docker**的另一种方案涉及一系列平台特定的步骤。请参阅[https://redislabs.com/ebook/appendix-a/](https://redislabs.com/ebook/appendix-a/)以了解多种安装场景。以下示例将假设使用**docker**；将`redis`切换到原生安装所需的微小更改留作读者的练习。
- en: 'Here''s some code that saves status in a `redis` cache server:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些代码，用于在`redis`缓存服务器中保存状态：
- en: '[PRE26]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `Status` class defines an enumeration of four string values. We've provided
    symbolic names like `Status.CANCELLED` so that we can have a finite, bounded domain
    of valid status values. The actual values stored in the database will be strings like
    `"CANCELLED"` that – for now – happen to match the symbols we'll be using in the
    application. In the future, the domain of values may expand or change, but we'd
    like to keep our application's symbolic names separate from the strings that appear
    in the database. It's common to use numeric codes with `Enum`, but they can be difficult
    to remember.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '`Status` 类定义了一个包含四个字符串值的枚举。我们提供了如 `Status.CANCELLED` 这样的符号名称，以便我们能够拥有一个有限、有界的有效状态值域。实际存储在数据库中的值将是类似于
    `"CANCELLED"` 的字符串，目前它们恰好与我们将在应用程序中使用的符号相匹配。在未来，值域可能会扩展或改变，但我们希望将应用程序的符号名称与数据库中出现的字符串保持分离。使用
    `Enum` 与数字代码一起是很常见的，但它们可能难以记忆。'
- en: There are a lot of things we ought to test for in the `change_status()` method.
    We check to be sure the `status` argument value really is a valid instance of
    the `Status` enumeration, but we could do more. We should check that it raises
    the appropriate error if the `flight` argument value isn't sensible. More importantly,
    we need a test to prove that the key and value have the correct formatting when
    the `set()` method is called on the `redis` object.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在`change_status()`方法中，我们应该测试很多东西。我们检查以确保`status`参数的值确实是一个有效的`Status`枚举实例，但我们还可以做更多。我们应该检查如果`flight`参数的值不合理，它是否会引发适当的错误。更重要的是，我们需要一个测试来证明当在`redis`对象上调用`set()`方法时，键和值具有正确的格式。
- en: One thing we don't have to check in our unit tests, however, is that the `redis` object
    is storing the data properly. This is something that absolutely should be tested
    in integration or application testing, but at the unit test level, we can assume
    that the `py-redis` developers have tested their code and that this method does
    what we want it to. As a rule, unit tests should be self-contained; the unit under
    test should be isolated from outside resources, such as a running Redis instance.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们的单元测试中，我们不需要检查的是`redis`对象是否正确存储数据。这是在集成测试或应用测试中绝对应该测试的事情，但在单元测试层面，我们可以假设`py-redis`的开发者已经测试了他们的代码，并且这个方法会按照我们的期望执行。一般来说，单元测试应该是自包含的；被测试的单元应该与外部资源，例如正在运行的Redis实例，隔离。
- en: 'Instead of integrating with a Redis server, we only need to test that the `set()`
    method was called the appropriate number of times and with the appropriate arguments.
    We can use `Mock()` objects in our tests to replace the troublesome method with
    an object we can introspect. The following example illustrates the use of `Mock`:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要与 Redis 服务器集成，只需测试 `set()` 方法被正确次数和正确参数调用即可。我们可以在测试中使用 `Mock()` 对象来替换那个麻烦的方法，用一个我们可以内省的对象来代替。以下示例说明了
    `Mock` 的使用：
- en: '[PRE27]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This test uses the `raises()` context manager to make sure the correct exception
    is raised when an inappropriate argument is passed in. In addition, it creates
    a `Mock` object for the `redis` instance that the `FlightStatusTracker` will use.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 此测试使用`raises()`上下文管理器来确保在传入不适当的参数时，能够抛出正确的异常。此外，它为`FlightStatusTracker`将要使用的`redis`实例创建了一个`Mock`对象。
- en: The mock object contains an attribute, `set`, which is a mock method that will
    always return `True`. The test, however, makes sure the `redis.set()` method is
    never called. If it is, it means there is a bug in our exception handling code.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟对象包含一个属性，`set`，这是一个总是返回`True`的模拟方法。然而，测试确保`redis.set()`方法永远不会被调用。如果它被调用了，那就意味着我们的异常处理代码中存在一个bug。
- en: Note the navigation into the mock object. We use `mock_redis.set` to examine
    the mocked `set()` method of a `Mock` object created by the `mock_redis` fixture.
    The `call_count` is an attribute that all `Mock` objects maintain.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 注意对模拟对象的导航。我们使用`mock_redis.set`来检查由`mock_redis`测试用例创建的`Mock`对象的模拟`set()`方法。`call_count`是所有`Mock`对象都维护的一个属性。
- en: While we can use code like `flt.redis = mock_redis` to replace a real object
    with a `Mock` object during a test, there is potential for problems. Simply replacing
    a value or even replacing a class method can only work for objects that are destroyed
    and created for each test function. If we need to patch items at the module level,
    the module isn't going to be reimported. A much more general solution is to use
    a patcher to inject a `Mock` object temporarily. In this example, we used the
    `monkeypatch` fixture of `pytest` to make a temporary change to the `FlightStatusTracker`
    object. A `monkeypatch` has its own automatic teardown at the end of a test, allowing
    us to use monkeypatched modules and classes without breaking other tests.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: 'This test case will be flagged by **mypy**. The **mypy** tool will object to
    using a string argument value for the status parameter of the `change_status()`
    function; this clearly must be an instance of the `Status` enumeration. A special
    comment can be added to silence the **mypy** argument type check, `# type: ignore
    [arg-type]`.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Additional patching techniques
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外的打补丁技术
- en: In some cases, we only need to inject a special function or method for the duration
    of a single test. We may not really be creating a sophisticated `Mock` object
    that's used in multiple tests. We may only need a small `Mock` for a single test.
    In this case, we may not need to use all the features of the `monkeypatch` fixture,
    either. For example, if we want to test the timestamp formatting in the `Mock` method,
    we need to know exactly what `datetime.datetime.now()` is going to return. However,
    this value changes from run to run. We need some way to pin it to a specific datetime
    value so we can test it deterministically.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 'Temporarily setting a library function to a specific value is one place where
    patching is essential. In addition to the `monkeypatch` fixture, the `unittest.mock`
    library provides a `patch` context manager. This context manager allows us to
    replace attributes on existing libraries with mock objects. When the context manager
    exits, the original attribute is automatically restored so as not to impact other
    test cases. Here''s an example:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We don't want our test results to depend on the computer's clock, so we built
    the `fake_now` object with a specific date and time we can expect to see in our
    test results. This kind of replacement is very common in unit tests.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: The `patch()` context manager returns a `Mock` object that was used to replace
    some other object. In this case, the object being replaced is the entire `datetime`
    module inside the `flight_status_redis` module. When we assigned `mock_datetime.datetime`,
    we replaced the `datetime` class inside the mocked `datetime` module with our
    own `Mock` object; this new `Mock` defines one attribute, `now`. Because the `utcnow`
    attribute is a `Mock` that returns a value, it behaves like a method and returns
    a fixed, known value, `fake_now`. When the interpreter exits the `patch` context
    manager, the original `datetime` functionality is restored.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: After calling our `change_status()` method with known values, we use the `assert_called_once_with()`
    method of the `Mock` object to ensure that the `now()` function was indeed called
    exactly once with the expected arguments (no arguments, in this case). We also
    use the `assert_called_once_with()` method on the `Mock` `redis.set` method to
    make sure it called with arguments that were formatted as we expected them to
    be. In addition to the "called once with," we can also check the exact list of
    mock calls that were made. This sequence is available in the `mock_calls` attribute
    of a `Mock` object.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Mocking dates so you can have deterministic test results is a common patching
    scenario. The technique applies to any stateful object, but is particularly important
    for external resources (like the clock) that exist outside our application.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: For the special case of `datetime` and `time`, packages like `freezegun` can
    simplify the monkeypatching required so that a known, fixed date is available.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: The patches we made in this example are intentionally sweeping. We replaced
    the entire `datetime` module with a `Mock` object. This will tend to expose unexpected
    uses of datetime features; if any method not specifically mocked (like the `now()`
    method was mocked) gets used, it will return `Mock` objects that are likely to
    crash code under test.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous example also shows how testability needs to guide our API design.
    The `tracker` fixture has an interesting problem: it creates a `FlightStatusTracker`
    object, which constructs a Redis connection. After the Redis connection is built,
    we replace it. When we run tests for this code, however, we will discover that
    each test will create an unused Redis connection. Some tests may fail if there
    is no Redis server running. Because this test requires external resources, it''s
    not a proper unit test. There are two possible layers of failure: the code doesn''t
    work, or the unit tests don''t work because of some hidden external dependency.
    This can become a nightmare to sort out.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: 'We could solve this problem by mocking the `redis.Redis` class. A `Mock` for
    this class can return a mock instance in a `setUp` method. A better idea, however,
    might be to rethink our implementation more fundamentally. Instead of constructing
    the `redis` instance inside `__init__`, we should allow the user to pass one in,
    as in the following example:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This allows us to pass a connection in when we are testing so that the `Redis`
    method never gets constructed. Additionally, it allows any client code that talks
    to `FlightStatusTracker` to pass in their own `redis` instance. There are a variety
    of reasons they might want to do this: they may have already constructed one for
    other parts of their code; they may have created an optimized implementation of
    the `redis` API; perhaps they have one that logs metrics to their internal monitoring
    systems. By writing a unit test, we''ve uncovered a use case that makes our API
    more flexible from the start, rather than waiting for clients to demand we support
    their exotic needs.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: This has been a brief introduction to the wonders of mocking code. Mock objects
    have been part of the standard `unittest` library since Python 3.3\. As you see
    from these examples, they can also be used with `pytest` and other test frameworks.
    Mock objects have other, more advanced features that you may need to take advantage
    of as your code becomes more complicated. For example, you can use the `spec`
    argument to invite a mock to imitate an existing class, so that it raises an error
    if code tries to access an attribute that does not exist on the imitated class.
    You can also construct mock methods that return different arguments each time
    they are called by passing a list as the `side_effect` argument. The `side_effect` parameter
    is quite versatile; you can also use it to execute arbitrary functions when the
    mock is called or to raise an exception.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: The point of unit testing is to be sure that each "unit" works in isolation.
    Often, a unit is an individual class, and we'll need to mock the collaborators.
    In some cases, there's a composition of classes or a Façade for which a number
    of application classes can be tested together as a "unit." There's a clear boundary,
    however, when applying mocks inappropriately. If we need to look inside some external
    module or class (one we didn't write) to see how to mock its dependencies, we've
    taken a step too far.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Don't examine the implementation details of classes outside your application
    to see how to mock their collaborators; instead, mock the entire class you depend
    on.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: This generally leads to providing a mock for an entire database or external
    API.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: We can extend this idea of imitating objects one step further. There's a specialized
    fixture we use when we want to ensure data has been left untouched. We'll look
    at this next.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: The sentinel object
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many designs, we'll have a class with attribute values that can be provided
    as parameters to other objects, without really doing any processing on those objects.
    For example, we may provide a `Path` object to a class, and the class then provides
    this `Path` object to an OS function; the class we designed doesn't do anything
    more than save the object. From a unit testing perspective, the object is "opaque"
    to the class we're testing – the class we're writing doesn't look inside the object
    at state or methods.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: The `unittest.mock` module provides a handy object, the `sentinel`, that can
    be used to create opaque objects that we can use in test cases to be sure that
    the application stored and forwarded the object untouched.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a class, `FileChecksum`, that saves an object computed by the `sha256()`
    function of the `hashlib` module:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can isolate this code from the other modules for unit testing purposes.
    We''ll create a `Mock` for the `hashlib` module, and we''ll use a `sentinel` for
    the result:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Our `mocked_hashlib` object provides a method, `sha256`, that returns the unique
    `sentinel.checksum` object. This is an object, created by the `sentinel` object,
    with very few methods or attributes. Any attribute name can be created as a unique
    object; we've chosen "checksum" here. The resulting object is designed for equality
    checks and nothing else. A `sentinel` in a test case is a way to be sure the `FileChecksum`
    class doesn't do anything wrong or unexpected with the objects it was given.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: The test case creates a `FileChecksum` object. The test confirms that the file
    was the provided argument value, `source_file`. The test also confirms that the
    checksum matched the original `sentinel` object. This confirms that the `FileChecksum`
    instance stored the checksum results properly and presented the result as the
    value of the `checksum` attribute.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: If we change the implementation of the `FileChecksum` class to – for example
    – use properties instead of direct access to the attribute, the test will confirm
    the checksum was treated as an opaque object that came from the `hashlib.sha256()`
    function and was not processed in any other way.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve looked at two unit testing frameworks: the built-in `unittest` package
    and the external `pytest` package. They both provide ways for us to write clear,
    simple tests that can confirm that our application works. It''s important to have
    a clear objective defining the required amount of testing. Python has an easy-to-use
    coverage package that gives us one objective measure of test quality.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: How much testing is enough?
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've already established that untested code is broken code. But how can we
    tell how well our code is tested? How do we know how much of our code is actually
    being tested and how much is broken? The first question is the more important
    one, but it's hard to answer. Even if we know we have tested every line of code
    in our application, we do not know that we have tested it properly. For example,
    if we write a `stats` test that only checks what happens when we provide a list
    of integers, it may still fail spectacularly if used on a list of floats, strings,
    or self-made objects. The onus of designing complete test suites still lies with
    the programmer.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The second question – how much of our code is actually being tested – is easy
    to verify. **Code coverage** is a count of the number of lines of code that are
    executed by a program. From the number of lines that are in the program as a whole,
    we know what percentage of the code was really tested or covered. If we additionally
    have an indicator that tells us which lines were not tested, we can more easily
    write new tests to ensure those lines are less likely to harbor problems.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The most popular tool for testing code coverage is called, memorably enough, `coverage.py`.
    It can be installed like most other third-party libraries, using the `python -m
    pip install coverage` command.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'We don''t have space to cover all the details of the coverage API, so we''ll
    just look at a few typical examples. If we have a Python script that runs all
    our unit tests for us (this could be using `unittest.main`,  `unittest` `discover`,
    or `pytest`), we can use the following command to perform coverage analysis for
    a specific unit test file:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This command will create a file named `.coverage`, which holds the data from
    the run.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'Windows Powershell users can do the following:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can now use the `coverage report` command to get an analysis of the code
    coverage:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The resulting output should be as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This report lists the files that were executed (our unit test and the module
    it imported), the number of lines of code in each file, and the number of lines
    of code that were executed by the test. The two numbers are then combined to show
    the amount of code coverage. Not surprisingly, the entire test was executed, but
    only a fraction of the `stats` module was exercised.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'If we pass the `-m` option to the `report` command, it will add a column that
    identifies the lines that are missing from the test execution. The output looks
    as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The ranges of lines listed here identify the lines in the `stats` module that
    were not executed during the test run.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'The example code uses the same `stats` module we created earlier in this chapter.
    However, it deliberately uses a single test that fails to test a lot of code in
    the file. Here''s the test:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This test doesn't test the median or mode functions, which correspond to the
    line numbers that the coverage output told us were missing.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: The textual report provides sufficient information, but if we use the `coverage
    html` command, we can get an even more useful interactive HTML report, which we
    can view in a web browser. The interactive report has a number of useful filters
    we can enable. The web page even highlights which lines in the source code were
    and were not tested.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how it looks:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing graphical user interface  Description automatically
    generated](img/B17070_13_01.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.1: Interactive HTML coverage report'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: We created the HTML report using the `coverage` module with `pytest`. To do
    this, we previously installed the `pytest` plugin for code coverage, using `python
    -m pip install pytest-cov`. The plugin adds several command-line options to `pytest`,
    the most useful being `--cover-report`, which can be set to `html`, `report`,
    or `annotate` (the latter actually modifies the original source code to highlight
    any lines that were not covered).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: It can be helpful to include more than the `src` directory tree in coverage
    analysis. A large project may have a complex tests directory, including additional
    tools and supporting libraries. As the project evolves, there may be some test
    or support code that's obsolete, but hasn't been cleaned up yet.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, if we could somehow run a coverage report on this section of
    the chapter, we'd find that we have not covered most of what there is to know
    about code coverage! It is possible to use the coverage API to manage code coverage
    from within our own programs (or test suites), and `coverage.py` accepts numerous
    configuration options that we haven't touched on. We also haven't discussed the
    difference between statement coverage and branch coverage (the latter is much
    more useful and is the default in recent versions of `coverage.py`), or other
    styles of code coverage.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'Bear in mind that while 100 percent code coverage is a goal that we should
    all strive for, 100 percent coverage is not enough! Just because a statement was
    tested does not mean that it was tested properly for all possible inputs. The
    boundary value analysis technique includes looking at five values to bracket the
    edge cases: a value below the minimum, the minimum, in the middle somewhere, the
    maximum, and a value above the maximum. For non-numeric types, there may not be
    a tidy range, but the advice can be adapted to other data structures. For lists
    and mappings, for example, this advice often suggests testing with empty lists
    or mapping with unexpected keys. The Hypothesis package ([https://pypi.org/project/hypothesis/](https://pypi.org/project/hypothesis/))
    can help with more sophisticated test cases.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: It's difficult to emphasize how important testing is. The test-driven development
    approach encourages us to describe our software via visible, testable objectives.
    We have to decompose complex problems into discrete, testable solutions. It's
    not uncommon to have more lines of test code than actual application code. A short
    but confusing algorithm is sometimes best explained through examples, and each
    example should be a test case.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Testing and development
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the many ways these unit tests can help is when debugging application
    problems. When each unit seems to work in isolation, any remaining problems will
    often be the result of an improperly used interface between components. When searching
    for the root cause of a problem, a suite of passing tests acts as a set of signposts,
    directing the developer into the wilderness of untested features in the borderlands
    between components.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: 'When a problem is found, the cause is often one of the following:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Someone writing a new class failed to understand an interface with an existing
    class and used it incorrectly. This indicates a need for a new unit test to reflect
    the right way to use the interface. This new test should cause the new code to
    fail its expanded test suite. An integration test is also helpful, but not as
    important as the new unit test focused on interface details.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The interface was not spelled out in enough detail, and both parties using the
    interface need to reach an agreement on how the interface should be used. In this
    case, both sides of the interface will need additional unit tests to show what
    the interface should be. Both classes should fail these new unit tests; they can
    then be fixed. Additionally, an integration test can be used to confirm that the
    two classes agree.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The idea here is to use test cases to drive the development process. A "bug"
    or an "incident" needs to be translated into a test case that fails. Once we have
    a concrete expression of a problem in the form of a test case, we can create or
    revise software until all the tests pass.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: 'If bugs do occur, we''ll often follow a test-driven plan, as follows:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Write a test (or multiple tests) that duplicates or proves the bug in question
    is occurring. This test will, of course, fail. In more complex applications, it
    may be difficult to find the exact steps to recreate a bug in an isolated unit
    of code; finding this is valuable work, since it requires knowledge of the software,
    and captures the knowledge as a test scenario.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, write the code to make the tests stop failing. If the tests were comprehensive,
    the bug will be fixed, and we will know we didn't break something new while attempting
    to fix something.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Another benefit of test-driven development is the value of the test cases for
    further enhancement. Once the tests have been written, we can improve our code
    as much as we like and be confident that our changes didn''t break anything we
    have been testing for. Furthermore, we know exactly when our refactor is finished:
    when the tests all pass.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Of course, our tests may not comprehensively test everything we need them to;
    maintenance or code refactoring can still cause undiagnosed bugs that don't show
    up in testing. Automated tests are not foolproof. As E. W. Dijkstra said, "Program
    testing can be used to show the presence of bugs, but never to show their absence!"
    We need to have good reasons why our algorithm is correct, as well as test cases
    to show that it doesn't have any problems.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ll return to some material from an earlier chapter and apply some careful
    testing to be sure we''ve got a good, workable implementation. Back in *Chapter
    3*, *When Objects Are Alike*, we looked at the distance computations that are
    part of the *k*-nearest neighbors classifier. In that chapter, we looked at several
    computations that produced slightly different results:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '**Euclidean distance**: This is the direct line from one sample to another.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manhattan distance**: This follows streets-and-avenues around a grid (like
    the city of Manhattan), adding up the steps required along a series of straight-line
    paths.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chebyshev distance**: This is the largest of the streets-and-avenues distances.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sorensen distance**: This is a variation of the Manhattan distance that weights
    nearby steps more heavily than distant steps. It tends to magnify small distances,
    making more subtle discriminations.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These algorithms all produce distinct results from the same inputs; they all
    involve complex-looking math, and they all need to be tested in isolation to ensure
    we have implemented them correctly. We'll start with unit tests of the distances.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing the distance classes
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We need to create some test cases for each distance computation algorithm.
    When we look at the various equations, we can see that there are four pairs of
    relevant values from two samples: the sepal length and width, and the petal length
    and width. To be extremely thorough, we could create at least 16 distinct cases
    for each algorithm:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 0**: All four values are the same; the distance should be zero.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cases 1-4**: One of the four values is different between the two samples.
    For example, a test sample might have measurements of `("sepal_length": 5.1, "sepal_width":
    3.5, "petal_length": 1.4, "petal_width": 0.2`), where as a training sample might
    have measurements of (`"sepal_length": 5.2, "sepal_width": 3.5, "petal_length":
    1.4, "petal_width": 0.2`); only one of these values is distinct.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cases 5-10**: A pair of values is different.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cases 11-14**: Three values are different between the two samples.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Case 15**: All four values are different.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, the concepts of equivalence partitioning and boundary value analysis
    suggest that we also need to locate values where there is a profound state change.
    For example, invalid values will raise exceptions, something that should also
    be tested. This can create a number of sub-cases within each of the cases enumerated
    above.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: We won't create all 16 cases for each of the four algorithms in this part of
    the case study. Instead, we'll take a close look at whether or not all 16 cases
    are really required. To get started, we'll limit ourselves to one case for each
    distance algorithm. This will be an example of case 15, where all four values
    of the two samples are different.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: With mathematical results, we need to compute the expected answers outside the
    software we're building. We can, of course, try to compute the expected answers
    with pencil and paper or a spreadsheet.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: One trick that can be helpful when working with more advanced math is to use
    the `sympy` package as a way to check the math more carefully.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the Euclidean distance between a known sample, *k*, and an unknown
    sample, *u*, has the following formal definition:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17070_13_001.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
- en: This computes the distance among all four measurements. For example, the known
    sepal length is *k*[sl]. The other attributes have similar names.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: 'While `sympy` can do a great many things, we want to use it for two specific
    purposes:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: To confirm that our Python version of the formula really is correct
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To compute the expected results using specific variable substitutions
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We do this by using `sympy` to perform the operations symbolically. Instead
    of plugging in specific floating-point values, we want to transform the Python
    expression into conventional mathematical notation.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a test case that''s applied to the design, not the implementation.
    It confirms the code''s design is very likely to match the original intent. We''ve
    translated the nicely typeset names like *k*[sl] for "known sepal length" into
    a Pythonic (but not as easy to read) `k_sl`. Here''s our interaction with `sympy`:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We imported `sympy` and defined the batch of symbols that match the original
    formula. We need to define these objects so `sympy` will work with them as mathematical
    symbols, not ordinary Python objects. Then, we did our best to translate the Euclidean
    distance formula from math into Python. It seems right, but we'd like to be sure.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Note that when we asked for the value of `ED`, we didn't see the results of
    a Python computation. Because we've defined the variables as symbols, `sympy`
    builds a representation of the equation that we can work with.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: When we used the `pretty()` function from `sympy`, it displayed an ASCII art
    version of our expression, which looks a lot like the original. We used the `use_unicode=False`
    option because that looked the best in this book. When printed with an appropriate
    font, the `use_unicode=True` version may be easier to read.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula is something we can share with experts to be sure our test cases
    really do properly describe the behavior of this particular class. Because the
    formula looks right, we can evaluate it with concrete values:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The `subs()` method substitutes values for the symbols in the formula. We then
    use the `evalf()` method to evaluate the result as a floating-point number. We
    can use this to create a unit test case for the class.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we look at the test case, here''s an implementation of the Euclidean
    distance class. As an optimization, this uses `math.hypot()`:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'It seems like this implementation matches the math. The best way to check is
    to create an automated test. Recall that tests often have a `GIVEN`-`WHEN`-`THEN`
    outline. We can expand this to the following conceptual scenario:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We can provide the values used in the symbolic computation for `U`, `K`, and
    the expected distance. We''ll start with a test fixture that supports the `GIVEN`
    step:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We''ve created a `TrainingKnownSample` and an `UnknownSample` object that we
    can use in subsequent tests. This fixture definition depends on a number of important
    type hints and definitions:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We can provide the distance computation as a `WHEN` step, and a final `THEN`
    comparison in an `assert` statement. We need to use an `approx` object for comparison
    because we're working with floating-point values, and exact comparisons rarely
    work out well.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: 'For this application, the number of decimal places in the test case seems excessive.
    We''ve left all the digits so the values will fit with the defaults used by `approx`,
    which is a relative error of 1 x 10^(-6), or `1e-6` in Python notation. Here''s
    the rest of the test case:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This is pleasantly short and to the point. Given two samples, the distance result
    should match what we computed by hand, or computed using `sympy`.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of the distance classes needs a test case. Here are two other distance
    computations. The expected results come from validating the formula and providing
    concrete values, as we did previously:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: For the Chebyshev and Manhattan distances, we're adding the individual steps
    for each of the four attributes and computing the sum or finding the largest individual
    distance. We can work these out by hand and be confident that our expected answer
    is right.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: 'The Sorensen distance, however, is a little more complex and can benefit from
    a comparison with the symbolic results. Here''s the formal definition:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17070_13_002.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the symbolic definition that we can use to compare our implementation
    against the definition. The equation displayed looks a lot like the formal definition,
    giving us the confidence to use it to compute expected values. Here''s a definition
    extracted from the code that we''d like to check:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The ASCII-art version of the formula looks a lot like the formal definition,
    giving us a lot of confidence that we can use `sympy` to compute expected answers.
    We''ll substitute specific example values to see what the expected results should
    be:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Now that we''re sure we have valid expected results, we can plug this expectation
    into a unit test case. Here''s how the test case looks:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: We've used `sympy` as a design aid to help us create unit test cases. It's not
    run as a regular part of the testing process. We only want to use it for the obscure
    cases where we aren't sure we can trust ourselves to compute an expected answer
    with paper and pencil.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: As we noted at the beginning of this chapter's case study, there are 16 different
    combinations of values where the known and the unknown sample attributes are different.
    We've provided only one of the 16 combinations.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `coverage` tool, we can see that all of the relevant code is tested
    with this one case. Do we really need the other 15 cases? There are two viewpoints:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: From a "black box" point of view, we don't know what's in the code, and we need
    to test all the combinations. This kind of black box testing relies on the assumption
    that the values could have some complex interdependency that can only be found
    through patient examination of all cases.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From a "white box" point of view, we can look at the various distance function
    implementations and see that all four attributes are treated uniformly. An examination
    of the code tells us a single case is sufficient.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Python applications, we suggest following white box testing unless there's
    a compelling reason to avoid looking at the code. We can use the coverage report
    to confirm that one case really has tested the relevant code.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Instead of creating 16 different test cases for the various distance algorithms,
    we can focus our efforts on making sure the application is reliable and uses minimal
    computing resources. We can also focus on testing other parts of the application.
    We'll look at the `Hyperparameter` class next, because it depends on the `Distance`
    computation class hierarchy.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing the Hyperparameter class
  id: totrans-346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `Hyperparameter` class relies on a distance computation. We have two strategies
    for testing a complex class like this:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: An integration test that uses the distance computations already tested
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A unit test that isolates the `Hyperparameter` class from any of the distance
    computations to be sure the class works
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a general rule of thumb, every line of code needs to be exercised by at least
    one unit test. After that, integration tests can also be used to ensure that the
    interface definitions are honored by all of the modules, classes, and functions.
    The spirit of "test everything" is more important than "make the number come out
    right"; counting lines is one way to ensure that we've tested everything.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: We'll look at testing the `classify()` method of the `Hyperparameter` class
    using `Mock` objects to isolate the `Hyperparameter` class from any of the distance
    computations. We'll also mock the `TrainingData` object to further isolate an
    instance of this class.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the relevant code we''ll be testing:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The `algorithm` attribute of the `Hyperparameter` class is a reference to an
    instance of one of the distance computation objects. When we replace this, the
    `Mock` object must be callable and must return an appropriate sortable number.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: The `data` attribute is a reference to a `TrainingData` object. The `Mock` to
    replace the `data` object must provide a `training` attribute that is a list of
    mocked samples. Since these values are provided to another mock without any intermediate
    processing, we can use a `sentinel` object to confirm that the training data was
    provided to the mocked distance function.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: The idea can be summarized as watching the `classify()` method "go through the
    motions." We provide mocks and sentinels to confirm that requests are made and
    the results of those requests are captured.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: 'For the more complex test, we''ll need some mock sample data. This will rely
    on `sentinel` objects. The objects will be passed through to a mocked distance
    computation. Here''s the definition of some mocked sample objects we''ll use:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This fixture is a list of mocks for `KnownSamples`. We''ve provided a unique
    name for each sample to help with debugging. We''ve provided a `species` attribute,
    since that''s the attribute used by the `classify()` method. We didn''t provide
    any other attributes, because they aren''t used by the unit under test. We will
    use this `sample_data` fixture to create a `Hyperparameter` instance that will
    have a mock distance computation and this mock collection of data. Here''s the
    test fixture we''ll use:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The `mocked_distance` object will provide a sequence of results that look like
    the results of distance computations. The distance computations are tested separately,
    and we've isolated the `classify()` method from the specific distance computations
    with this `Mock`. We've provided the list of mocked `KnownSample` instances via
    a `Mock` object that will behave like a weak reference; the training attribute
    of this mock object will be the given sample data.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: 'To be sure the `Hyperparameter` instance makes the right requests, we evaluate
    the `classify()` method. Here''s the entire scenario, including these two final
    THEN steps:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: '`GIVEN` a sample data fixture with five instances reflecting two species'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WHEN` we apply the *k*-NN algorithm'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`THEN` the result is the species with the closest three distances'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AND` the mock distance computation was invoked with all of the training data'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s the final test, using the above fixtures:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This test case checks the distance algorithm to make sure the entire training
    set of data was used. It also confirms that the nearest neighbors were used to
    locate the resulting species for the unknown sample.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: Since we tested the distance computations separately, we have a great deal of
    confidence in running an integration test that combines these various classes
    into a single, working application. For debugging purposes, it is very helpful
    to isolate each component into a separately tested unit.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: Recall
  id: totrans-371
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we''ve looked at a number of topics related to testing applications
    written in Python. These topics include the following:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: We described the importance of unit testing and test-driven development as a
    way to be sure our software does what is expected.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We started by using the `unittest` module because it's part of the standard
    library and readily available. It seems a little wordy, but otherwise works well
    for confirming that our software works.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `pytest` tool requires a separate installation, but it seems to produce
    tests that are slightly simpler than those written with the `unittest` module.
    More importantly, the sophistication of the fixture concept lets us create tests
    for a wide variety of scenarios.
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `mock` module, part of the `unittest` package, lets us create mock objects
    to better isolate the unit of code being tested. By isolating each piece of code,
    we can narrow our focus on being sure it works and has the right interface. This
    makes it easier to combine components.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code coverage is a helpful metric to ensure that our testing is adequate. Simply
    adhering to a numeric goal is no substitute for thinking, but it can help to confirm
    that efforts were made to be thorough and careful when creating test scenarios.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We''ve been looking at several kinds of tests with a variety of tools:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests with the `unittest` package or the `pytest` package, often using
    `Mock` objects to isolate the fixture or unit being tested.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration tests, also with `unittest` and `pytest`, where more complete integrated
    collections of components are tested.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static analysis can use **mypy** to examine the data types to be sure they're
    used properly. This is a kind of test to ensure the software is acceptable. There
    are other kinds of static tests, and tools like `flake8`, `pylint`, and `pyflakes`
    can be used for these additional analyses.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some research will turn up scores of additional types of tests. Each distinct
    type of test has a distinct objective or approach to confirming the software works.
    A performance test, for example, seeks to establish the software is fast enough
    and uses an acceptable number of resources.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: 'We can''t emphasize enough how important testing is. Without automated tests,
    software can''t be considered complete, or even usable. Starting from test cases
    lets us define the expected behavior in a way that''s specific, measurable, achievable,
    results-based, and trackable: SMART.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Practice test-driven development. That is your first exercise. It's easier to
    do this if you're starting a new project, but if you have existing code you need
    to work on, you can start by writing tests for each new feature you implement.
    This can become frustrating as you become more enamored with automated tests.
    The old, untested code will start to feel rigid and tightly coupled, and will
    become uncomfortable to maintain; you'll start feeling like changes you make are
    breaking the code and you have no way of knowing, for lack of tests. But if you
    start small, adding tests to the code base improves it over time. It's not unusual
    for there to be more test code than application code!
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: So, to get your feet wet with test-driven development, start a fresh project.
    Once you've started to appreciate the benefits (you will) and realize that the
    time spent writing tests is quickly regained in terms of more maintainable code,
    you'll want to start writing tests for existing code. This is when you should
    start doing it, not before. Writing tests for code that we *know *works is boring.
    It is hard to get interested in the project until we realize just how broken the
    code we thought was working really is.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: Try writing the same set of tests using both the built-in `unittest` module
    and `pytest`. Which do you prefer? `unittest` is more similar to test frameworks
    in other languages, while `pytest` is arguably more Pythonic. Both allow us to
    write object-oriented tests and test object-oriented programs with ease.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: We used `pytest` in our case study, but we didn't touch on any features that
    wouldn't have been easily testable using `unittest`. Try adapting the tests to
    use test skipping or fixtures. Try the various setup and teardown methods. Which
    feels more natural to you?
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: Try running a coverage report on the tests you've written. Did you miss testing
    any lines of code? Even if you have 100 percent coverage, have you tested all
    the possible inputs? If you're doing test-driven development, 100 percent coverage
    should follow quite naturally, as you will write a test before the code that satisfies
    that test. However, if you're writing tests for existing code, it is more likely
    that there will be edge conditions that go untested.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: Getting the case study code to 100 percent coverage can be tricky, since we've
    been skipping around and implementing some aspects of the case study in several
    different ways. It may be necessary to write several similar tests for alternative
    implementations of case study classes. It can help to make reusable fixtures so
    that we can provide consistent testing among the alternative implementations.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: 'When creating test cases, it can help to think carefully about the values that
    are somehow different, such as the following, for example:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: Empty lists when you expect full ones
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Negative numbers, zero, one, or infinity compared to positive integers
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Floats that don't round to an exact decimal place
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strings when you expected numerals
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unicode strings when you expected ASCII
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ubiquitous `None` value when you expected something meaningful
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your tests cover such edge cases, your code will be in good shape.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: 'The numeric methods for distance computations are something that might be better
    tested using the Hypothesis project. Check out the documentation here: [https://hypothesis.readthedocs.io/en/latest/](https://hypothesis.readthedocs.io/en/latest/).
    We can use Hypothesis to easily confirm that the order of operands in a distance
    computation doesn''t matter; that is, `distance(s1, s2) == distance(s2, s1)`,
    given any two samples. It''s often helpful to include Hypothesis testing to confirm
    that the essential *k*-nearest neighbors classifier algorithm works for randomly
    shuffled data; this will ensure there''s no bias for the first or last item in
    the training set.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-400
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have finally covered the most important topic in Python programming: automated
    testing. Test-driven development is considered a best practice. The standard library `unittest` module
    provides a great out-of-the-box solution for testing, while the `pytest` framework
    has some more Pythonic syntaxes. Mocks can be used to emulate complex classes
    in our tests. Code coverage gives us an estimate of how much of our code is being
    run by our tests, but it does not tell us that we have tested the right things.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we''ll jump into a completely different topic: concurrency.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
