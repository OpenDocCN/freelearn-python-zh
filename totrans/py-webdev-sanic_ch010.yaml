- en: 9 Best Practices to Improve your Web Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From *Chapter 1* through *Chapter 8,* we learned how to build a web application
    from conception through deployment. Pat yourself on the back and give yourself
    a round of applause. Building and deploying a web application is not a simple
    feat. So, what have we learned? We, of course, spent time learning all of the
    fundamental tools that Sanic provides: route handlers, blueprints, middleware,
    signals, listeners, decorators, exception handlers, and so on. More importantly,
    however, we spent some time thinking about how HTTP works, and how we can use
    these tools to design and build applications that are secure, scalable, maintainable,
    and easily deployable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There have been a lot of specific patterns in this book for you to use, but
    also quite intentionally I have left a lot of ambiguity. You have continually
    read statements like: “*it depends upon your application’s need*.” Afterall, one
    of the goals of the Sanic project is to remain “*unopinionated*”.'
  prefs: []
  type: TYPE_NORMAL
- en: That’s all well and good, and flexibility is great. But what if you are a developer
    that has not yet determined what patterns work, and which do not? The difference
    between writing a “*Hello, world*” application and a production-ready, real-world
    application is huge. If you have only limited experience in writing applications,
    then you have also only had limited experience in making mistakes. It is through
    those mistakes (whether made by yourself, or from lessons learned by others who
    have made them) that I truly believe we become better developers. Like so many
    other things in life, failure leads to success.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of this chapter, therefore, is to include several examples and *preferences*
    that I have learned from my 20+ years of building web applications. That means
    for every best practice you will learn in this Chapter, there is probably some
    *mistake* that I made to go along with it. These are a set of base-level *best
    practices* that I think is critical for any professional-grade application to
    include from the beginning.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to look at:'
  prefs: []
  type: TYPE_NORMAL
- en: Practical real-world exception handlers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to setup a testable application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The benefit of real-world logging and tracing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing database connections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are no new technical requirements that you have not already seen. By
    this point, you should hopefully have a nice environment available for building
    Sanic, along with all the tools like Docker, Git, Kubernetes, and Curl that we
    have been using all along. You can follow along with the code examples on the
    GitHub repository: [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09).'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing practical real-world exception handlers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Exception handling is not a new concept at this point. We have explored the
    topic in the *Implementing proper exception handling* section in *Chapter 6*.
    I emphasized the importance of creating our own set of exceptions that include
    default status messages and response codes. This useful pattern was meant to get
    you up and running very quickly to be able to send *useful* messages to your users.
  prefs: []
  type: TYPE_NORMAL
- en: For example, imagine we are building an application for travel agents to book
    airline tickets for customers. You can imagine one of the steps of the operation
    might be to assist in matching flights through connecting airports.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, what if the customer selected two flights where the time between the
    flights was too short. You might do something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: I love this pattern because it makes it super easy for us to now repeatably
    raise an `InsufficientConnection` exception and have a known response for the
    user. But, responding properly to the user is only half of the battle. When something
    goes wrong in our applications in the *real world,* we want to know about it.
    Our applications need to be able to report back so that if there is indeed a problem,
    then we can fix it.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do we go about solving this problem? Logging is, of course, essential
    (we will look at that soon in the *Gaining insight from logging and tracing* section
    later). Having a reliable way to get to your system logs is an absolute must for
    a lot of reasons. But do you want to monitor your logs all day long every day
    looking for a traceback? Of course not!
  prefs: []
  type: TYPE_NORMAL
- en: Somehow, in some way you need to set up some alerts to notify you that an exception
    happened. You will learn that not all exceptions are created equal, and only sometimes
    will you actually want your attention called to the fact that there was an exception.
    If a customer forgets to input valid data, you do not need your mobile phone waking
    you up at 3 am. And while setting up system monitoring and alerting tools is outside
    the scope of this book, the point that I am trying to make is that your application
    should be proactive about warning you when certain things happen. Sometimes bad
    things will happen, and you want to make sure that you are able to sift through
    the noise and not miss out on the issues that really matter. A simple form of
    this might be to send an email when something particularly bad happens.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing what you do about Sanic so far, if I came to you and asked you to build
    a system that sent me an email whenever a `PinkElephantError` is raised, how would
    you do it?
  prefs: []
  type: TYPE_NORMAL
- en: 'I hope this is not your answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: “*Why?*”you might ask. For starters, what if this needs to be implemented in
    a few locations, and then we need to change the notification from `send_adam_an_email()`
    to `build_a_fire_and_send_a_smoke_signal()`? You now need to go searching through
    all of your code to make sure it is done consistently and hope you did not miss
    anything.
  prefs: []
  type: TYPE_NORMAL
- en: What else could you do? How can you simply write the following code in your
    application and have it know that it needs to send me an email?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Let’s learn that next.
  prefs: []
  type: TYPE_NORMAL
- en: Catching errors with middleware
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Adding the notification mechanism (in this case, `send_adam_an_email()`) right
    next to where we raise the exception is not the best solution. One solution would
    be to catch the exception with response middleware and send out the alert from
    there. The response is not likely to have an easily parseable exception for you.
    If `PinkElephantError` raises a 400 response, howe are you to be able to distinguish
    it from any other 400 response? You could, of course, have JSON formatting, and
    check the exception type. But that will only work in `DEBUG` mode because in `PRODUCITON`
    mode you do not have that information available.
  prefs: []
  type: TYPE_NORMAL
- en: 'One creative solution might be to attach an arbitrary exception code, and rewrite
    it in the middleware as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'For some very targeted use cases, I can see how this might be useful, and if
    it works for you, I will encourage you to do this. It does sort of remind me of
    the old-school style of error coding. You know the ones where you need a lookup
    table to translate a number to an error, which still has some incomprehensible
    meaning because there is no standardization or documentation? Just thinking about
    seeing *E19* on my coffee machine as I race around to find the owner’s manual
    to look up what that means is enough to raise my stress levels. What I am trying
    to say is: “*Save yourself the hassle and try to find a nicer solution to identifying
    exceptions than attaching some otherwise hard-to-understand error codes that you
    later need to translate to something else.*”'
  prefs: []
  type: TYPE_NORMAL
- en: Catching errors with signals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember our old friend signals from way back in *Leveraging signals for intra-worker
    communication* section in *Chapter 6*, *Outside the Response Cycle*? If you recall,
    Sanic can dispatch event signals when certain things occur. One of them is when
    an exception is raised. Better yet, the signal context includes the exception
    instance making it *MUCH* easier to identify which exception occurred.
  prefs: []
  type: TYPE_NORMAL
- en: 'A cleaner and more maintainable solution to the aforementioned code would look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: I think you can already see this is a much classier and fitting solution. For
    a lot of use cases, this might very well be the best solution for you. Therefore,
    I suggest you commit this simple 4-line pattern to memory. Now, when we need to
    change `send_adam_an_email()` to `build_a_fire_and_send_a_smoke_signal()` that
    will be a super simple change to our code.
  prefs: []
  type: TYPE_NORMAL
- en: Longtime builders of Sanic applications may be looking at this example of mine
    wondering if we can just use `app.exception`? This is certainly an acceptable
    pattern, but not without its potential pitfalls. Let’s look at that next.
  prefs: []
  type: TYPE_NORMAL
- en: Catching the error and responding manually
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When an exception is raised, Sanic stops the regular route handling process
    and moves it over to an `ErrorHandler` instance. This is a single object that
    exists throughout the lifespan of your application instance. Its purpose is to
    act as a sort of mini-router to take incoming exceptions and make sure they are
    passed off to the proper exception handler. If there is none, then it uses the
    default exception handler. As we have seen already, the default handler is what
    we can modify by using `error_format` argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a quick example of what an exception handler looks like in Sanic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The problem with this pattern is that because you took over the actual handling
    of the exception, it is now your job to respond with an appropriate response.
    If you build an application with 10, 20, or even more of these exception handlers,
    keeping their responses consistent becomes a chore.
  prefs: []
  type: TYPE_NORMAL
- en: It is for this reason that I genuinely try to avoid custom exception handling
    unless I need to. In my experience, I get much better results by controlling formatting
    as discussed in *Fallback handling* section in *Chapter 6*, *Operating outside
    the Request Handler*. However, there is one caveat to this which we will explore
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: I try to avoid one-off response customizations that only target a single use
    case. While building an application, we likely need to build error handlers for
    many types of exceptions, and not just the `PinkElephantError`. Therefore, I tend
    to disfavor using exception handlers when I need to do something with the error—like
    sending an email—and not just deal with how it is output for the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, okay, I give in. I will let you in on a secret: you can still use the
    `app.exception` pattern to intercept the error, do *something* with it, and then
    use the built-in error formatting. If you like the exception handler pattern better
    than the signal, then it is possible to use it without needing worry about my
    concern of formatting too many custom error responses. Let’s see how we can achieve
    this.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s make a simple endpoint to throw our error, and report back in
    text format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: I have added `quiet=True` to the exception because that will suppress the traceback
    from being logged. This is a helpful technique when the traceback is not important
    for you and it just gets in the way.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, create an exception handler to send the email, but still use the default
    error response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can access the default `ErrorHandler` instance using our application instance
    as shown in the preceding code.
  prefs: []
  type: TYPE_NORMAL
- en: I would like you to hit that endpoint using `curl` so you can see that this
    works as expected. You should get the default text response and see that a mock
    email was sent to me as faked in the logs.
  prefs: []
  type: TYPE_NORMAL
- en: As you can also see, we are using the `error_handler` object that exists application
    wide. In our next section, we will look at modifying that object.
  prefs: []
  type: TYPE_NORMAL
- en: Modifying the ErrorHandler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When Sanic starts up, one of the first things that it does is create an `ErrorHandler`
    instance. We saw in the previous example that we can access it from the application
    instance. Its purpose is to make sure that when you define an exception handler,
    the request is responded to from the proper location.
  prefs: []
  type: TYPE_NORMAL
- en: One of the other benefits of this object is that it is easily customizable and
    is triggered on every single exception. Therefore, in the days before Sanic introduced
    signals, it was the easiest way to get some arbitrary code to run on every exception,
    like our error reporting utility.
  prefs: []
  type: TYPE_NORMAL
- en: 'Modifying the default `ErrorHandler` instance might have looked something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: Create an `ErrorHandler` and inject the reporting code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Instantiate your application using your new handler.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: That’s it. Personally, I would almost *always* go for the signals solution when
    dealing with alerting or other error reporting. Signals have the benefit of being
    a much more succinct and targeted solution. It does not require me to subclass
    or monkey patch any objects. However, it is helpful to know how to create a custom
    `ErrorHandler` instance as you will see it out there in the wild.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you will see them in third-party error-reporting services. These
    services are platforms that you can subscribe to that will aggregate and track
    exceptions in your application. They can be incredibly helpful in identifying
    and debugging problems in production applications. Usually, they work by hooking
    into your normal exception handling process. Since overriding `ErrorHandler` used
    to be the best method for low-level access to all exceptions in Sanic, many of
    these providers will provide sample code or libraries to use that implement this
    strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Whether you use a custom `ErrorHandler` or signals is still a matter of personal
    taste. The biggest benefit, however, for signals is that they are run in a separate
    `asyncio` task. This means that Sanic will efficiently manage the *concurrent*
    response to the user with the reporting (provided you do not introduce other blocking
    code).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: With this in mind, you now have the ability to format all of your errors as
    needed. An alternative strategy to this would be to manage this with exception
    handlers. The problem with that method is that you potentially lose out on Sanic’s
    built-in auto-formatting logic. As a reminder, one of the great benefits of the
    default `ErrorHandler` is that it will attempt to respond with an appropriate
    format like HTML, JSON, or plain text depending upon the circumstance.
  prefs: []
  type: TYPE_NORMAL
- en: Exception handling may not be the most exciting thing to build. It is, nonetheless,
    an incredibly important fundamental component of any professional-grade web application.
    Make sure to put some thought into your application needs when designing a strategy.
    You very well may find that you need a mixture of signals, exception handlers,
    and a custom `ErrorHandler`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now turn our attention to another important aspect of professional-grade
    application development that may also not be exciting for some people to build:
    testing.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a testable application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Imagine this scenario: inspiration strikes you and you have a great application
    idea. Your excitement and creative juices are flowing as you start formulating
    ideas in your head about what to build. Of course, you do not rush straight into
    building it because you have read all the earlier chapters in this book. You take
    some time to plan it out, and in a caffeine-induced marathon, you start hacking
    away. Slowly you start to see the application take shape and it is working beautifully.
    Hours go by, maybe it''s days or weeks–you are not sure because you are in the
    zone. Finally, after all that work you have a **minimum viable product (MVP)**.
    You deploy it and go for some much-deserved sleep.'
  prefs: []
  type: TYPE_NORMAL
- en: The problem is that you never set up testing. Undoubtedly when you now come
    online and check out your error handling system that you set up with advice from
    the previous section, you notice that it is swamped with errors. Uh oh. Users
    are doing things in your application that you did not anticipate. Data is not
    behaving as you thought it might. Your application is broken.///
  prefs: []
  type: TYPE_NORMAL
- en: I would venture to guess that most people that have developed a web application
    or done any software development can sympathize with this story. We have all been
    there before. For many newcomers and experienced developers alike, testing is
    not fun. Maybe you are one of those rare breeds of engineers that completely love
    setting up a testing environment. If so, with all honesty, I tip my hat to you.
    For the rest of us, suffice it to say that if you want to build a professional
    application you need to find it in you to develop a test suite.
  prefs: []
  type: TYPE_NORMAL
- en: 'Testing is a *huge* field, and I will not cover it here. There are plenty of
    testing strategies out there, including the often-celebrated **test driven design**(**TDD**).
    If you know what it is and it works for you: great. If not: I will not judge you.
    If you are unfamiliar with it, I do suggest that you take some time and do some
    Internet research on the topic. It is a fundamental part of many professional
    development workflows and many companies have adopted it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, there are a lot of testing terms like **unit-testing** and **integration-testing**.
    Again, this book is not on test theory so we will use simplified definitions:
    unit testing is when you test a single component or endpoint, and integration-testing
    is when you test the component or endpoint interacting with another system (like
    a database). I know some people will not like my definitions, but the semantics
    of the terms is not important for our needs right now.'
  prefs: []
  type: TYPE_NORMAL
- en: What we care about in this book is how you can test your Sanic application in
    both unit and integration tests. Therefore, while I hope the general idea and
    approaches here are useful, to truly have a well-tested application you will need
    to go beyond the pages of this book.
  prefs: []
  type: TYPE_NORMAL
- en: The last ground rule that we need to get out of the way is that the tests here
    will all assume that you are using `pytest`. It is one of the most widely used
    testing frameworks with many plugins and resources.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with sanic-testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Sanic Community Organization (the community of developers that maintain
    the project) also maintains a testing library for Sanic. Although its primary
    utility is used by the Sanic project itself to achieve a high level of test coverage,
    it nonetheless has found a home and use case for developers working with Sanic.
    We will use it extensively because it provides a convenient interface for interacting
    with Sanic.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start we will need to install it into your virtual environment. While we
    are at it, we will install `pytest` too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: So, what does `sanic-testing` do? It provides an HTTP client that you can use
    to reach your endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical barebones implementation would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: First, you will have your application defined in some module or factory. For
    now, it will be a global scoped variable, but later in the chapter, we will start
    working with factory-pattern applications where the application instance is defined
    inside of a function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, in your testing environment, you initialize a test client. Since we are
    using `pytest`, let’s set that up in a `conftest.py` file as a fixture so we can
    easily access it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will now have access to the HTTP client in your unit tests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running your tests now is a matter of executing the pytest command. It should
    look something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, what just happened here? What happened is that the test client took your
    application instance and actually ran it locally on your operating system. It
    initiated the Sanic server binding it to a host and port address on your operating
    system and ran whatever event listeners were attached to your application. Then,
    once the server was running, it used `httpx` as an interface to send an actual
    HTTP request to the server. It then bundled up both the `Request` and the `HTTPResponse`
    objects and provided them as the return value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this example can be found in the GitHub repository: [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/testing0](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/testing0).'
  prefs: []
  type: TYPE_NORMAL
- en: This is something that I cannot stress enough. Just about every time that someone
    has come to me with a question about or problem using `sanic-testing` it is because
    the person failed to understand that the test client is *actually* running your
    application. This happens on every single call.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: When you run this, it will first start up the application and send a `GET` request
    to `/foo`. The server then goes through the full shutdown. Next, it stands up
    the application again and sends a `POST` request to `/bar`.
  prefs: []
  type: TYPE_NORMAL
- en: For most test cases, this starting and stopping of the server is preferred.
    It will make sure that your application runs in a clean environment every time.
    It happens very quickly and you can still whip through a bunch of unit tests without
    feeling this as a performance penalty.
  prefs: []
  type: TYPE_NORMAL
- en: There are some other options that we will explore later in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: A more practical test client implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that you have seen how the test client works, I am going to let you in
    on a little secret: you do not actually need to instantiate the test client. In
    fact, other than the previous example, I have *never* used `sanic-testing` like
    this in a real application.'
  prefs: []
  type: TYPE_NORMAL
- en: The Sanic application instance has a built-in property that can set up the test
    client for you if `sanic-testing` has been installed. Since we already installed
    the package, we can just go ahead and start using it. All that you need is access
    to your application instance.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an application fixture
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before going further, we will revisit the `pytest` fixtures. If you are unfamiliar
    with them, they might seem somewhat magical to you. In brief, they are a pattern
    in `pytest` to declare a function that will return a value. That value can then
    be used to inject an object into your individual tests.
  prefs: []
  type: TYPE_NORMAL
- en: So, for example in our last use case, we defined a fixture in a special file
    called `conftest.py`. Any fixtures that are defined there will be available anywhere
    in your testing environment. That is why we were able to inject `test_client`
    as an argument in our test case.
  prefs: []
  type: TYPE_NORMAL
- en: I find it almost always beneficial to do this with the application instance.
    Whether you are using a globally defined instance, or a factory pattern, you will
    make testing much easier with fixtures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, I will always do something like this in my `conftest.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'I now have access to my application instance everywhere in the test environment
    without importing it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '**TIP**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'There is one more quick trick you should know about fixtures. You can use the
    yield syntax here to help you inject code before and after your test. This is
    particularly helpful with an application if you need to do any sort of cleanup
    after the test runs. To achieve this, do the following:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'With access to our app instance using fixtures, we can now rewrite the previous
    unit test like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: To make our lives a little simpler, I added the type annotation for the fixture
    so that my **integrated development environment** (**IDE**) knows that it is a
    Sanic instance. Even though the main purpose of type hinting is to catch mistakes
    early, I also like to use it in cases like this to just make my IDE experience
    nicer.
  prefs: []
  type: TYPE_NORMAL
- en: This example shows that access to the test client is simply a matter of using
    the `app.test_client` property. By doing that, Sanic will automatically instantiate
    the client for you as long as the package is installed. This makes it super simple
    to write unit tests like this.
  prefs: []
  type: TYPE_NORMAL
- en: Testing blueprints
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Sometimes you may run across a scenario where you want to test some functionality
    that exists on a blueprint alone. In this case, we are assuming that any application-wide
    middleware or listeners that run before the blueprint are not relevant to our
    test. This means that we are testing some functionality that is entirely contained
    within the boundaries of the blueprint.
  prefs: []
  type: TYPE_NORMAL
- en: I love situations like this, and actively seek them out. The reason is that
    these are super easy to test as we will see in a minute. These types of testing
    patterns are probably best understood as they contrast to what we will do in the
    *Testing a full application section*. The main differentiator is that in these
    tests, our endpoints do not rely upon the existence of a third-party system like
    a database. Perhaps more accurately I should say that they do not rely upon the
    impacts that a third-party system might have. The functionality and business logic
    are self-contained, and therefore very conducive to unit testing.
  prefs: []
  type: TYPE_NORMAL
- en: When I find a situation like this, the first thing that I do is add a new fixture
    to my `conftest.py` file. It will act as a dummy application that I can use for
    testing. Each unit test I create can use this dummy application with my target
    blueprint attached and nothing else. This allows for my unit test to be more narrowly
    focused on my single example. Let’s see how that looks next.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will create a new fixture that creates a new application instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now stub out a test in our blueprint tests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this example, we see that I created a fixture that is localized to this one
    module. The point of this is to create a reusable application instance that has
    my target blueprint attached to it.
  prefs: []
  type: TYPE_NORMAL
- en: A simple use case for this kind of testing might be input validation. Let’s
    add a blueprint that does some input validation. The blueprint will have a simple
    `POST` handler that looks at the incoming JSON body and just checks that the key
    exists, and the type matches the expectation.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will create a schema that will be the keys and the value type that
    we expect our endpoint to be able to test.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Second, we will make a simple type checker that responds with one of three
    values depending upon whether the value exists, and is of the expected type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, we will create our endpoint that will take the request JSON and respond
    with a dictionary about whether the passed data was valid.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, we have now created a very simplistic data checker. We loop
    over the definitions in the schema, and check each to see whether it is as expected.
    All of the values should be `"OK"` and the request data should be the same length
    as the schema.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can now test this out in our test suite. The first thing that we could test
    is to make sure that all the required fields are present. There are three potential
    scenarios here: the input is missing fields, the input has only the correct fields,
    and the input has extra fields. Let’s take a look at these scenarios and create
    some tests for them:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we will create a test to check that there are no missing fields.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this test, we sent some bad data. Notice how the `an_int` value is actually
    a `str`. But we do not care about that right now. What this meant to test is that
    all the proper fields were sent.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next up is a test that should contain all of the inputs, of the correct types,
    but nothing more.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, all we need to assert is that the response is a 200 since we know that
    it will be a 400 if it is bad data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Lastly, we create a test that checks that we extraneous information is not sent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In this final test, we are sending known bad data since it contains the exact
    same payload as the previous test, except for the additional `"a_bool": True`.
    Therefore, we should assert that the response will be a 400.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Looking at these tests, it seems very repetitive. While the general rule of
    **Don’t Repeat Yourself** (aka **DRY**) is often cited as a reason to abstract
    logic, be careful with this in testing. I would prefer to see repetitive testing
    code over some highly abstracted, beautiful, shiny factory pattern. In my experience—and
    yes, I have been burned by this many times in the past—adding fancy abstraction
    layers into testing code is a recipe for disaster. Some abstraction might be helpful
    (creating the `dummy_app` fixture is an example of good abstraction), but too
    much could be disastrous. Unwinding them in the future when some functionality
    needs to change will become a nightmare. This is certainly one of those areas
    where development shades the line between science and art. Creating a powerful
    testing suite with a proper balance of repetition and abstraction will take some
    practice and is highly subjective.
  prefs: []
  type: TYPE_NORMAL
- en: With that warning out of the way, there is an abstraction layer that I do really
    like. It makes use of `pytest.parametrize`. This is a super helpful feature that
    allows you to create a test and run it against multiple inputs. We are not abstracting
    our tests, per se, but instead are testing the same code with a variety of inputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `pytest.parametrize`, we can actually condense those three tests into
    a single test:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a decorator that has two arguments: a string containing a comma-delimited
    list of argument names, and an iterable that contains values to be injected into
    the test.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We have three values that we are going to inject into our test: `input`, `has_missing`,
    and `expected_status`. The test is going to run multiple times, and each time
    it will pull one of the tuples of arguments to inject into the test function.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Our test function can now be abstracted to use these arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this way, it is much easier for us to write multiple unit tests across different
    use cases. You may have noticed that I actually just created a fourth test. Since
    it was so simple to add more tests using this method, I included one use case
    that we had not previously tested. I hope you see the huge benefit that this creates
    and come to learn to love testing with `@pytest.mark.parametrize`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this example, we are defining the inputs and what our expected outcome should
    be. By parametrizing the single test, it actually turns this into multiple tests
    inside `pytest`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for these examples can be found in the GitHub repository: [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/testing2](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/testing2).'
  prefs: []
  type: TYPE_NORMAL
- en: Mocking out services
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The sample blueprint that we were testing against is obviously not something
    we would ever use in real life. In that example, we were not actually doing anything
    with the data. The reason I oversimplified it was so that we did not need to worry
    about how you handle interactions with services like a database access layer.
    What about when we are testing a real endpoint? And, but a real endpoint I mean
    one that is meant to interface with a database. For example, how about a registration
    endpoint? How can we test that the registration endpoint actually does what it
    is supposed to do and injects data as expected?
  prefs: []
  type: TYPE_NORMAL
- en: 'I still like using the `dummy_app` pattern for testing even when I know that
    my endpoint needs to perform some database operation. We will look at how we can
    use Python’s mocking utilities to pretend like we have a real database layer:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will need to refactor our blueprint so that it looks like something
    you might actually encounter in the wild:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We are still doing the input validation. However, instead of simply storing
    the registration details to memory, we will send them off to a database for writing
    to disk. You can checkout the full code at [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/testing3](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/testing3)
    to see the input validation. The important things to note here are that we have
    a `RegistrationService`, and that is calling a `register_user` method.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Since we still have not looked at the usage of **object relationship mapping**
    (**ORM**), our database storage function will ultimately just call some raw SQL
    queries. We will look at ORMs in more detail in *Managing database connections*,
    but for now, let’s create the registration service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The registration service calls into our database to execute some SQL. We will
    also need a connection to our database. For the sake of the example, I am using
    a fake class, but this would (and should) be the actual object that your application
    uses to connect to the database. Therefore, imagine that this is a proper DB client:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With this in place, we can now create a new fixture that will take the places
    of our data access layer. Normally you would create something like this to instantiate
    the client:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use your imagination and imagine that the aforementioned piece of code exists
    on our *actual* application. It initiates the database connection and allows us
    to access the client within our endpoints as shown in the preceding code because
    our connection uses the applications `ctx` object. Since our unit tests will not
    have access to a database, we need to create a *mock* database instead and attach
    that to our dummy application.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To do that, we will create our `dummy_app` and then import the actual listener
    used by the real application to instantiate the fake client.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To force our client to use a mocked method instead of actually sending a network
    request to a database, we are going to monkeypatch the DB client using a feature
    of pytest. Setup a fixture like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We now have a mock object in place of the real `execute` method, and we can
    proceed to build out a test on our registration blueprint. One of the great benefits
    of using the `unittest.mock` library is that it allows us to create assertions
    that the database client would have been called. We will see what that looks like
    next.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here, we create a test with some assertions that help us to know that the correct
    data will make its way to the data access layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Just like before, we are using `parametrize` so that we could run multiple tests
    with different inputs. The key takeaway is that since we are using a mocked `execute`
    method, we can ask pytest to provide that to us so that our test can assert that
    it was called as we expected it to be.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is certainly helpful for testing isolated issues, but what about when there
    needs to be application-wide testing? We will look at that next.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a full application
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As an application progresses from its infancy, there is likely to begin a network
    of middleware, listeners, and signals that process requests that are not just
    limited to the route handler. In addition, there are likely to be connections
    to other services (like databases) that complicate the entire process. A typical
    web application cannot be run in a vacuum. When it starts up, it needs to connect
    to other services. These connections are critical to the proper performance of
    the application, and therefore if they do not exist, then the applications cannot
    start. Testing these can be very troublesome. Do not just throw your hands up
    and give up. Resist the temptation. In the previous tests, there was a glimpse
    of how this can be achieved quite simply. We did in fact successfully test against
    our database. But what about when that is not enough?
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes testing against a `dummy_app` is not sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: This is why I really like applications that are created by a factory pattern.
    The GitHub repository for this chapter is an example of a factory pattern that
    I use a lot. It has some very helpful features in it. Essentially, the end result
    is a function that returns a Sanic instance with everything attached to it. Through
    the implementation of the Sanic standard library, the function crawls through
    your source code looking for things to attach to it (routes, blueprints, middleware,
    signals, listeners, and much more), and is set up to avoid circular import issues.
    We talked about factory patterns and their benefits back in *Chapter 2*, *Organizing
    a project*.
  prefs: []
  type: TYPE_NORMAL
- en: What is particularly important right now is that the factory in the GitHub repository
    can selectively choose what to instantiate. This means we can use our actual application
    with targeted functionality. Let me provide an example.
  prefs: []
  type: TYPE_NORMAL
- en: Once I was building an application. It was critical to know exactly how it was
    performing in the real world. Therefore, I created a middleware that would calculate
    some performance metrics and then send them off to a vendor for analysis. Performance
    was critical—which was part of my decision to use Sanic to begin with. When I
    tried to do some testing, I realized that I could not run the application in my
    test suite if it did not connect to the vendor. Yes, I could have mocked it out.
    However, a better strategy was to just skip the operation altogether. Sometimes,
    there really is no need to test every bit of functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this concrete, here is a real quick explanation of what I am talking
    about. Here is a middleware code snippet that calculates runtime at the beginning
    and end of the request, and sends it off:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'One solution to my problem of contrasting testing versus production behavior
    could be to change the application code to only run in production:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'But in my opinion, a better solution was to skip this middleware altogether.
    Using the factory pattern shown in the repo, I could do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: In this factory, we are creating a new application instance and looping through
    a list of known modules to import them. In normal usage, we would create an application
    by calling `create_app()`, and the factory would import the `DEFAULT` known modules.
    By importing them, they will attach to our application instance. More importantly,
    however, this factory allows us to send an arbitrary list of modules to load.
    This allows us the flexibility to create a fixture in our tests that uses the
    actual factory pattern for our application, but has the control to pick and choose
    what to load.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our use case, we decided that we do not want to test the performance middleware.
    We can skip it by creating a test fixture that simply ignores that module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this opens up the ability for me to create tests that are specifically
    targeting parts of my actual application, and not just a dummy application. Using
    a factory through the use of inclusion and exclusion, I can create unit tests
    with only the functionality that I need, and avoid the unneeded functionality.
  prefs: []
  type: TYPE_NORMAL
- en: I hope your mind is now racing with possibilities that this opens up for you.
    Testing becomes so much easier when the application is itself composable. This
    awesome trick is one way you can really move your application development to the
    next level. An easily composable application becomes an easily testable application.
    This leads to the application being well-tested and now you are truly on your
    way to becoming a next-level developer.
  prefs: []
  type: TYPE_NORMAL
- en: If you have not already begun, I highly suggest that you use a factory like
    mine. Go ahead and copy it. Just promise me that you will use it to create some
    unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: Using the ReusableClient for testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Up until this point, we have been using a test client that starts and stops
    a service on every call to it. The `sanic-testing` package ships with it another
    test client that can be manually started and stopped. Therefore, it is possible
    to reuse it between calls, or even tests. In the next subsection, we will learn
    about this reusable test client.
  prefs: []
  type: TYPE_NORMAL
- en: Running a single test server per test
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You may sometimes need to have multiple calls to your API running on the same
    instance. For example, this could be useful if you were storing some temporary
    state in between calls in memory. This is obviously not a good solution in most
    use cases because storing the state in memory makes horizontal scaling difficult.
    Leaving that issue aside, let’s take a quick look at how you might implement this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first create an endpoint that just spits out a counter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this simplified example, every time that you hit the endpoint, it will increment
    a number.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can test this endpoint that maintains an internal state by using a `ReusableClient`
    instance as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As long as you are using the client inside that `with` context manager, then
    you will be hitting the exact same instance of your application in each call.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can simplify the preceding code by using fixtures:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, when you set up a unit test, it will keep the server running for as long
    as the test function is executing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The aforementioned unit test could be written as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As you can see, this is a potentially powerful strategy if you want to run
    only a single server for the duration of your test function.What if you want to
    keep the instance running for the entire duration of your testing? The simplest
    way would be to change the `scope` of the fixture to `session`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With this setup, no matter where you are running tests in `pytest`, it will
    be using the same application. While I personally have never felt the need for
    this pattern, I can definitely see its utility.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this example can be found in the GitHub repository: [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/testing4](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/testing4).'
  prefs: []
  type: TYPE_NORMAL
- en: With both proper exception management and testing out of the way, the next critical
    addition of any true professional application is logging.
  prefs: []
  type: TYPE_NORMAL
- en: Gaining insight from logging and tracing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When it comes to logging, I think that most Python developers fall into three
    main categories:'
  prefs: []
  type: TYPE_NORMAL
- en: People that always use `print` statements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: People that have extremely strong opinions and absurdly complex logging setups.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: People that know they should not use `print`, but do not have the time or energy
    to understand Python’s `logging` module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you fall into the second category, you might as well skip this section. There
    is nothing in it for you except if you want to criticize my solutions and tell
    me there is a better way.
  prefs: []
  type: TYPE_NORMAL
- en: If you fall into the first category, then you really need to learn to change
    your habits. Do not get me wrong, `print` is fantastic. However, it does not have
    a place in professional-grade web applications because it does not provide the
    flexibility that the logging module offers.
  prefs: []
  type: TYPE_NORMAL
- en: “*Wait a minute!*” I hear the first category people shouting already. “*If I
    deploy my application with containers and Kubernetes, it can pick up my output
    and redirect it from there.*”/// If you are deadset against using logging, then
    I suppose I might not be able to change your mind. However, leaving aside the
    configuration complexity, consider that the logging module provides a rich API
    to send messages at different levels and with meta context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the standard Sanic access logs. The message that the access logger sends
    out is actually blank. Take a look for yourself in the Sanic codebase if you want.
    The access log is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'What you actually see is something more like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Embedded in that line is a bunch of metadata that is both machine-friendly
    and human-readable, thanks to the `logging` module. In fact, you can store arbitrary
    data with logs that some logging configurations will store for you. Something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: If I have convinced you, and you want to learn more about how to use logging
    in Sanic, let’s continue.
  prefs: []
  type: TYPE_NORMAL
- en: Types of Sanic loggers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sanic itself ships with three loggers. You can access all of them in the `log`
    module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Feel free to use these in your own applications. Especially on smaller projects,
    I often will use the Sanic `logger` object for convenience. These are, of course,
    actually intended for use by Sanic itself, but nothing is stopping you from using
    them. In fact, it might be convenient as you know that all of your logs are formatted
    consistently. My only word of caution is that it’s best to leave the `access_logger`
    object alone since it has a highly specific job.
  prefs: []
  type: TYPE_NORMAL
- en: Why would you want to use both an `error_logger` and a regular logger? I think
    the answer depends upon what you want to happen to your logs. There are many options
    to choose from. The simplest form is obviously just to output to the console.
    This is not a great idea for error logs, however, since you have no way to persist
    the message and review them when something bad happens. Therefore, you might take
    the next step and output your `error_logger` to a file. This, of course, could
    become cumbersome, so you decide instead to use a third-party system to ship off
    your logs to another application to store and make them accessible. Whatever setup
    you desire, using multiple loggers may play a particular role in how the logging
    messages are handled and distributed.
  prefs: []
  type: TYPE_NORMAL
- en: Creating your own loggers, my first step in application development
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When I approach a new project, one of the things I ask myself is what will
    happen with my production logs? This is, of course, a question highly dependent
    upon your application, and you will need to decide this for yourself. Asking the
    question though highlights a very important point: there is a distinction between
    development logs and production logs. More often than not, I have no clue what
    I want to do with them in production yet. We can defer that question off for another
    day.'
  prefs: []
  type: TYPE_NORMAL
- en: Before I even begin writing my application, I will create a logging framework.
    I know that the goal is to have two sets of configurations, so I begin with my
    development logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'I want to emphasize this again: The *very first step* in building an application
    is to make a super simple framework for standing up an application with logging.
    So, let’s go through that setup process now:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing, we are going to do is make a super basic scaffold following
    the patterns that we established in *Chapter 2*, *Organizing a Project*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the application structure that I like to work with because it makes
    it very easy for me to develop on. Using this structure, we can easily create
    a development environment focused upon running the application locally, testing
    the application, logging, and building images. Here, we obviously are concerned
    with running the application locally with logging.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next thing I like to create is my application factory with a dummy route
    on it that I will remove later. Here is how we can begin `server.py`. We will
    continue to add to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'There is a very important reason that I call `setup_logging` after creating
    my app instance. I want to be able to use the configuration logic from Sanic to
    load environment variables that may be used in creating my logging setup.Here’s
    a quick aside that I want to point out before continuing. There are two different
    camps when it comes to creating a Python `logger` object. One side says that it
    is best practice to create a new `logger` in every module. In this scenario, you
    would put the following code at the top of *every single Python file*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The benefit of this approach is having the module name of where it was created
    closely related to the logger name. This is certainly helpful in tracking down
    where a log came from. The other camp, however, says that it should be a single
    global variable that is imported and reused since that may be easier to configure
    and control. Besides, we can get the specific targeting of file names and line
    numbers quickly with proper log formatting, so it is unnecessary to include the
    module name in the logger name. While I do not discredit the localized, per module
    approach, I too prefer the simplicity of importing a single instance like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you dive really deep into logging, this also provides you with a much greater
    ability to control how different logger instances operate. Similar to the conversation
    about exception handlers, I would rather limit the number of instances I need
    to control. In the example that I just showed for `server.py`, I chose the second
    option to use a single global `logging` instance. This is a personal choice and
    there is no wrong answer in my opinion. There are benefits and detriments of both
    strategies, so choose which makes sense to you.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is to create the basic `log.py`. For now, let’s keep it super
    simple, and we will build from there:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With this in place, we are ready to run the application and test it out. But
    wait?! Where is the app that we pass to our `sanic` command?We previously had
    used this to run our application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instead, we will tell the Sanic CLI the location of the `create_app` function,
    and let it run that for us. Change your startup to this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should now be able to hit your endpoint and see some basic messages output
    to your terminal. You likely will not have the `DEBUG` message since the logger
    is still probably set to only `INFO` and above. You should see something super
    basic like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Configuring logging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The preceding logging messages are exactly what using `print` could provide.
    The next thing that we need to add is some configuration that will output some
    metadata and format the messages. It is important to keep in mind that some logging
    details may need to be customized to suit the production environment:'
  prefs: []
  type: TYPE_NORMAL
- en: We, therefore, will start by creating a simple configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Make sure to note that we changed the signature function of `setup_logging`
    to now take the application instance as an argument. Make sure to go back to update
    your `server.py` file to reflect this change.As a side note, sometimes you might
    want to simplify your logging to force Sanic to use the same handlers. While you
    can certainly go through the process of updating the Sanic logger configuration
    (see [https://sanicframework.org/en/guide/best-practices/logging.html#changing-sanic-loggers](https://sanicframework.org/en/guide/best-practices/logging.html#changing-sanic-loggers)),
    I find that to be much too tedious. A simpler approach is to set up the logging
    handlers, and then simply apply them to the Sanic loggers as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It is good practice to always have a `StreamHandler`. This will be used to output
    your logs to the console. But what about when we want to add some additional logging
    utilities for production? Since we are not 100% sure yet what our production requirements
    will be, we will set up logging to a file for now. This can always be swapped
    out at another time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Change your `log.py` to look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can easily see how this could be configured with a different kind of logging
    handler or formatting that might more closely match your needs in different environments.
  prefs: []
  type: TYPE_NORMAL
- en: All of the configurations shown used programmatic controls of the logging instance.
    One of the great flexibilities of the `logging` library is that all of this can
    be controlled with a single `dict` configuration object. You, therefore, will
    find it a very common practice to keep YAML files containing logging configurations.
    These files are easy to update and swap in and out of build environments to control
    production settings.
  prefs: []
  type: TYPE_NORMAL
- en: Adding color context
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The preceding setup is entirely functional, and you could stop there. However,
    to me, this is not enough. When I am developing a web application, I always have
    my terminal open spitting out logs. In a sea of messages, it might be hard to
    sift through all of the text. How can we make this better? We will achieve this
    through the appropriate use of color.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because I generally do not need to add color to my production output, we will
    go through adding color formatting in my local environment only:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by setting up a custom logging formatter that will add colors
    based upon the logging level. Any debug messages are blue, warnings are yellow,
    errors are red, and a critical message will be red with a white background to
    help them stand out (in a dark colored terminal):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We are using the standard color escape codes that most terminals understand
    to apply the colors. This will color the entire message. You, of course, could
    get much fancier by coloring only parts of your messages, and if that interests
    you, I suggest you play around with this formatter to see what you can achieve.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After we create this, we will make a quick internal function to decide which
    formatter to use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If we are in a local environment that is a TTY terminal, then we use our color
    formatter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We need to change the start of our `setup_logging` function to account for
    these changes. We will also abstract some more details to our configuration for
    easy access to change them per environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Besides dynamically getting a formatter, this example adds one more new piece
    to the puzzle. It is using a configuration value to determine the logging level
    of your logger.
  prefs: []
  type: TYPE_NORMAL
- en: Adding some basic tracing with request IDs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A common problem with logs is that they can become noisy. It might be tough
    to correlate a specific log with a specific request. For example, you might be
    handling multiple requests at the same time. If there is an error, and you want
    to look back at earlier messages, how do you know which logs should be grouped
    together?
  prefs: []
  type: TYPE_NORMAL
- en: There are entire third-party applications that add what is known as **tracing**.
    This is particularly helpful if you are building out a system of inter-related
    microservices that work together to respond to incoming requests. While not necessarily
    diving into microservice architecture, it is worth mentioning here that tracing
    is an important concept that should be added to your application. This is true
    regardless if your application architecture uses microservices or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our purpose, what we want to achieve is to add a request identifier to
    every single request. Whenever that request attempts to log something, that identifier
    will automatically be injected into our request format. In order to accomplish
    this goal:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need a mechanism to inject the request object into every logging operation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, we need a way to show the identifier if it exists or ignore it if it
    does not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we get to the code implementation, I would like to point out that the
    second part could be handled in a couple of ways. The simplest might be to create
    a specific logger that will only be used inside of a request context. This means
    that you would have one logger that is used in startup and shutdown operations,
    and another that is used only for requests. I have seen this approach used well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is that we are again using multiple loggers. To be entirely honest,
    I really do prefer the simplicity of having just a single instance that works
    for all of my use cases. This way I do not need to bother thinking about which
    logger I should reach for. Therefore, I will show you here how to build option
    two: an omni logger that can be used anywhere in your application. If you instead
    prefer the more targeted types, then I challenge you to take my concepts here
    and build out two loggers instead of one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will get started by tackling the issue of passing the request context. Remember,
    because Sanic operates asynchronously, there is no way to guarantee which request
    will be handled in what order. Luckily the Python standard library has a utility
    that works great with `asyncio`. It is the `contextvars` module. What we will
    do to start is create a listener that setups up a context that we can use to share
    our request object and pass it to the logging framework:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file called `./middleware/request_context.py`. It should look like
    this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: What is happening here is that we are creating a context object that can be
    accessed from anywhere that has access to our app. Then, on every single request,
    we will attach the current request to the context variable to make it accessible
    from anywhere the application instance is accessible.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next thing that needs to happen is to create a logging filter that will
    grab the request (if it exists) and add it to our logging record. In order to
    do this, we will actually override Python’s function that creates logging records
    in our `log.py` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make sure you notice that we need to stash the default record factory because
    we want to make use of it. Then when this function is executed, it will check
    to see if there is a current request by looking inside that request context we
    just set up.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We also need to update our format to use this new bit of information. Make
    sure to update this value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can inject the new factory as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Feel free to check this book’s GitHub repository to make sure that your `log.py`
    looks like mine: [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/tracing](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/tracing).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With all of this in place, it is time to hit our endpoint. You should now see
    some nice pretty colors in your terminal, and some request information inserted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After running through these examples, one thing you might have noticed and not
    seen before is `request.id`. What is this, and where does it come from?
  prefs: []
  type: TYPE_NORMAL
- en: Using X-Request-ID
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is a common practice to use UUIDs to track requests. This makes it very easy
    for client applications to also track requests and *correlate* them to specific
    instances. This is why you will often hear them called correlation IDs. If you
    hear the term, they are the exact same thing.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a part of the practice of correlating requests, many client applications
    will send an X-Request-ID header. If Sanic sees that header in an incoming request,
    then it will grab that ID and use it to identify the request. If not, then it
    will automatically generate a UUID for you. Therefore, you should be able to send
    the following request to our logging application and see that ID populated in
    the logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: For the sake of simplicity, I am not using a UUID.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your logs should now reflect this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Logging is a critical component of professional-grade web applications. It really
    does not need to be that complicated. I have seen super lengthy and overly verbose
    configurations that quite honestly scared me away. With a little bit of attention
    to detail, however, you can make a truly fantastic logging experience without
    much effort. I encourage you to grab the source code for this and hack it until
    it meets your needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'We next turn our attention to another critical component of web applications:
    database management.'
  prefs: []
  type: TYPE_NORMAL
- en: Managing database connections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This book above all else is really hoping to provide you with confidence to
    build applications *your* way. This means we are actively looking to stomp out
    copy/paste development. You know what I mean. You go to **Stackoverflow** or some
    other website, copy code, paste it, and then move on with your day without thinking
    twice about it.
  prefs: []
  type: TYPE_NORMAL
- en: 'This sort of copy/paste mentality is perhaps most prevalent when it comes to
    database connections. Time for a challenge. Go startup a new Sanic app and connect
    it to a database. Some developers might approach this challenge by heading to
    some other codebase (from another project, an article, documentation, or a help
    website), copying some basic connection functions, changing the credentials, and
    calling it a day. They may never have put much thought into what it means to connect
    to a database: if it works, then it must be okay. I know I certainly did that
    for a long time.'
  prefs: []
  type: TYPE_NORMAL
- en: This is not what we are doing here. Instead, we will consider a couple of common
    scenarios, think through our concerns, and develop a solution around them.
  prefs: []
  type: TYPE_NORMAL
- en: To ORM or Not to ORM, that is the question
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the benefit of anyone that does not know what an ORM is, here is a quick
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ORM** is a framework used to build Python native objects. Those objects are
    related directly to a database schema and are also used to build queries to fetch
    data from the database to be used when building the Python objects. In other words,
    they are a data access layer that has the capability of two-way translation from
    Python and to the database. When people are talking about an ORM, they are typically
    referring to one that is intended to be used with an SQL-based database.'
  prefs: []
  type: TYPE_NORMAL
- en: The question about whether to use an ORM or not is one fraught with some strong
    opinions. In some contexts, people might think you are living in the stone age
    if instead of using one you are hand-writing your SQL queries. On the other hand,
    some people will think ORMs are a nuisance and lead to both overly simplistic,
    yet grotesquely complicated and inefficient queries. I suppose to an extent both
    groups are correct.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, I cannot tell you what you should or should not do. The implementation
    details and the use case are highly relevant to any decision. In my projects,
    I tend to shy away from them. I like to use the `databases` project ([https://github.com/encode/databases](https://github.com/encode/databases))
    to build custom SQL queries, and then map the results to `dataclass` objects.
    After handcrafting my SQL, I use some utilities to hydrate them from raw, unstructured
    values into schema-defined Python objects. I have also in the past made extensive
    use of ORMs like peewee ([https://github.com/coleifer/peewee](https://github.com/coleifer/peewee))
    and SQLAlchemy ([https://github.com/sqlalchemy/sqlalchemy](https://github.com/sqlalchemy/sqlalchemy)).
    And, of course, since I developed in Django for many years, I have done a lot
    of work in its internal ORM.
  prefs: []
  type: TYPE_NORMAL
- en: When should you use an ORM? First and foremost, for most projects using an ORM
    should probably be the default option. They are great at adding the required safety
    and security to make sure that you do not accidentally introduce a security bug.
    By enforcing types, they can be extremely beneficial in maintaining data integrity.
    And, of course, there is the benefit of abstracting away a lot of the database
    knowledge. Where they fall short, perhaps, is in their ability to handle complexity.
    As a project grows in the number of tables and interconnected relationships it
    may be more difficult to continue using ORMs. There also are a lot of more advanced
    options in SQL languages like Postgresql that you simply cannot accomplish with
    an ORM building your queries. I find them to really shine in more simplistic CRUD
    (create/read/update/delete) applications, but actually get in the way of more
    complex database schemas.
  prefs: []
  type: TYPE_NORMAL
- en: Another potential downside to ORMs is that they make it super easy to sabotage
    your own project. A little mistake in building an inefficient query could be the
    difference between absurdly long response times, and super-fast responses. Speaking
    from experience as someone who was bit by this bug, I find that applications that
    are built with ORMs tend to over fetch data and inefficiently, run more network
    calls than are needed. If you feel comfortable with SQL and know that your data
    will become fairly complicated, then perhaps you are better off writing your own
    SQL queries. The biggest benefit of using hand-crafted SQL is that it overcomes
    the complexity-scaling issue of ORMs.
  prefs: []
  type: TYPE_NORMAL
- en: Even though this book is not about SQL, after much consideration I think the
    best use of our time is to build a custom data layer and not use an off-the-shelf
    ORM. This option will force us into making good choices about maintaining our
    connection pools and developing secure and practical SQL queries. Moreover, anything
    that is discussed here in regards to implementation can easily be swapped out
    to a more fully featured ORM. If you are more familiar and comfortable with SQL
    Alchemy (which now has async support), then feel free to swap out my code accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a custom data access layer in Sanic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When deciding upon which strategy to use for this book I explored a lot of the
    options out there. I looked at all of the popular ORMs that I see people using
    with Sanic. Some options like SQLAlchemy have so much material out there that
    I could not possibly do it justice. Other options encouraged lesser quality patterns.
    Therefore, we turn to one of my favorites, the `databases` package using `asyncpg`
    to connect to Postgres (my relational DB of choice). The goal will be to implement
    good connection management,
  prefs: []
  type: TYPE_NORMAL
- en: 'I highly encourage you to look at the code in the repository at [https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/hikingapp](https://github.com/PacktPublishing/Web-Development-with-Sanic/tree/main/chapters/09/hikingapp).
    This is one of the first times that we have created a *complete* application.
    By that, I mean an example of an application that goes out to fetch some data.
    Going back to the discussion from *Chapter 2, Organizing a project* about project
    layout, you will see an example of how we might structure a real-world application.
    There also is a lot going on in there that is somewhat outside of the discussion
    here (which is much more narrowly focused on database connections), so we will
    not dive too deeply into it right now. But do not worry, we will come back to
    the application’s patterns again in *Chapter 11* when we build out a full application.
    In the meantime, it might be a good opportunity for you to review that source
    code now. Try to understand how the project is structured, run it, and then test
    out some of the endpoints. Instructions are in the repository: [https://github.com/PacktPublishing/Web-Development-with-Sanic/blob/main/chapters/09/hikingapp/README.md](https://github.com/PacktPublishing/Web-Development-with-Sanic/blob/main/chapters/09/hikingapp/README.md).'
  prefs: []
  type: TYPE_NORMAL
- en: I also would like to point out that since our applications are growing with
    the addition of another service, I am going to start running it using docker-compose
    and Docker containers locally. All the build materials are in the GitHub repository
    for you to copy for your own needs. But, of course, you would not dare just copy
    and paste the code without actually understanding it, so let’s make sure that
    you do.
  prefs: []
  type: TYPE_NORMAL
- en: The application we are talking about is a web API for storing details about
    hiking. It connects its database of known hiking trails to users who can keep
    track of the total distance they have hiked and when they hiked certain trails.
    When you spin up the database, there should be some information prepopulated for
    you.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing that we must do is make sure that our connection details are
    coming from environment variables. Never store them in the project files. Besides
    the security concerns associated with this, it is super helpful to make changes
    by redeploying your application with different values if you need to change the
    size of your connection pool or rotate your passwords. Let’s begin:'
  prefs: []
  type: TYPE_NORMAL
- en: Store your connection settings using docker-compose, kubernetes, or whatever
    other tool you are using to run your containers. If you are not running Sanic
    in a container (for example, you plan to deploy to a PAAS that offers environment
    variables for you thru a GUI), an option that I like to use for local development
    is `dotenv` ([https://github.com/theskumar/python-dotenv](https://github.com/theskumar/python-dotenv)).The
    config values that we care about right now are the **data source name** (**DSN**),
    and the pool settings. If you are not familiar with a DSN, it is a string that
    contains all of the information needed to connect to a database in a form that
    might look familiar to you as a URL.*What is a connection pool?* Imagine a scenario
    where a web request comes in, your application goes and opens a network socket
    to your database. It fetches information, serializes it and sends it back to the
    client. But, it also closes that connection. The next time that happens your application
    needs to reopen a connection to the database. This is hugely inefficient. Instead,
    your application can warm up several connections by opening them and holding them
    in reserve.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, when the application needs a connection, instead of opening a new connection
    it can simply connect to your database using a connection pool, and store that
    object on your application `ctx`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As you can see, three main things are happening:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The first is we are creating the Database object that stores our connection
    pool and acts as the interface for querying. We store it on the `app.ctx` object
    so that it will be easily accessible from anywhere in the application. This was
    placed inside of the `before_server_start` listener since it alters the state
    of our application.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The second is that the listener actually opens up the connections to the database
    and holds them at the ready until they are needed. We are warming up the connection
    pool prematurely so that we do not need to spend the overhead at query time.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: And of course, the important step we do is to make sure that our application
    properly shuts down its connections.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The next thing we need to do is create our endpoints. In this example, we will
    use class-based views:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here the `GET` endpoint on the root level of the `/trails` endpoint is meant
    to provide a list of all trails in the database (forgetting about pagination).
    The `TrailExecutor` is one of those objects that I do not want to dive too deeply
    into right now. But, as you can probably guess from this code, it takes the instance
    of our database (which we initiated in the last step) and provides methods to
    fetch data from the database.One of the reasons that I really like the databases
    package is that it makes it incredibly easy to handle connection pooling and session
    management. It basically does it all for you under the hood. But one thing that
    is a good habit to get into (regardless of what system you are using) is to wrap
    multiple consecutive writes to your database in a transaction.Imagine that you
    needed to do something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Often when you have multiple database writes in a single function you either
    want them all to succeed or them all to fail. Having a mixture of success and
    failures might, for example, leave your application in a bad state. When you identify
    situations like this it is almost always beneficial to nest your functions inside
    of a single transaction. To implement such a transaction within our sample, it
    would look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Now, if one of the queries fails for whatever reason, the database state will
    be rolled back to where it was before the change. I highly encourage you to adopt
    a similar practice no matter what framework you use for connecting to your database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, a discussion of databases is not necessarily limited to SQL databases.
    There are plenty of NoSQL options out there, and you, of course, should figure
    out what works for your needs. We will next take a look at connecting my personal
    favorite database option to Sanic: Redis.'
  prefs: []
  type: TYPE_NORMAL
- en: Connecting Sanic to Redis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Redis is a blazingly fast and simple database to work with. Many people think
    of it simply as a key/value store, which is something that it does extremely well.
    It also has a lot of other features that could be thought of as a sort of shared
    primitive data type. For example, Redis has hashes, lists, and sets. These correspond
    nicely to Python’s `dict`, `list`, and `set`. It is for this reason that I often
    recommend this as a solution to someone that needs to share data across a horizontal
    scale-out.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, we will use Redis as a caching layer. For this, we are relying
    upon its hashmap capability to store a `dict` like structure with details about
    a response. We have an endpoint that might take several seconds to generate a
    response. Let’s simulate that now:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First create a route that will take a while to generate a response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check to see that it works:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To fix this, we will create a decorator whose job is to look for precached
    responses and serve that if it exists:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will install `aioredis`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a database connection pool similar to what we did in the previous section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we will create a decorator to use with our endpoints.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: What is happening here is pretty simple. First, we generate some keys that will
    be used to look up and store values. Then we check to see if anything exists for
    that key. If yes, then use that to build a response. If no, then execute the actual
    route handler (which we know takes some time).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s see what we have accomplished in action. First, we will hit the endpoint
    again. To emphasize on my point, I will include some stats from `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will try it again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Wow! It returned almost instantly! In the first attempt, it took just under
    6 seconds to respond. In the second, because the information has been stored in
    Redis, we got an identical response in about 4/1000 of a second. And, don’t forget
    that in those 4/1000 of a second, Sanic went to fetch data from Redis. Amazing!
  prefs: []
  type: TYPE_NORMAL
- en: Using Redis as a caching layer is incredibly powerful as it can be used to significantly
    boost your performance. The flip side–as anyone that has worked with caching before
    knows–is that you need to have an appropriate use case and a mechanism for invalidating
    your cache. In the aforementioned example, this is accomplished in two ways. If
    you check the source code at GitHub ([https://github.com/PacktPublishing/Web-Development-with-Sanic/blob/main/chapters/09/hikingapp/application/hiking/common/cache.py#L43](https://github.com/PacktPublishing/Web-Development-with-Sanic/blob/main/chapters/09/hikingapp/application/hiking/common/cache.py#L43)),
    you will see that we are expiring the value automatically after 72 hours, or if
    someone sends a `?refresh=1` query argument to the endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we are past the point of talking about basic concepts in application development,
    we have graduated to the level of exploring some best practices that I have learned
    over the years of developing web applications. This is clearly just the tip of
    the iceberg, but they are some very important foundational practices that I encourage
    you to adopt. The examples from this chapter could become a great foundation for
    starting your next web application process.
  prefs: []
  type: TYPE_NORMAL
- en: First, we saw how you can use smart and repeatable exception handling to create
    a consistent and thoughtful experience for your users. Second, we explored the
    importance of creating a testable application, and some techniques to make it
    easily approachable. Third, we discussed implementing logging in both development
    and production environments, and how you could use those logs to easily debug
    and trace requests through your application. Finally, we spent time learning how
    databases could be integrated into your application.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will continue to expand upon the basic platform that
    we have built. You will continue to see a lot of the same patterns (like logging)
    continuing to reappear in our examples as we look at some common use cases of
    Sanic.
  prefs: []
  type: TYPE_NORMAL
