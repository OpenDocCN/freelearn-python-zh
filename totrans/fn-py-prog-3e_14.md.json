["```py\n99.49.32.197 - - [01/Jun/2012:22:17:54 -0400] \"GET /favicon.ico\\\\ \nHTTP/1.1\" 200 894 \"-\" \"Mozilla/5.0 (Windows NT 6.0)\\\\ \nAppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.52\\\\ \nSafari/536.5\"\n```", "```py\ndata = path_filter( \n    access_detail_iter( \n        access_iter( \n            local_gzip(filename))))\n```", "```py\n(local_gzip(filename) | access_iter \n    | access_detail_iter | path_filter) >data\n```", "```py\nfrom toolz.functoolz import pipe \n\ndata = pipe(filename, \n    local_gzip, \n    access_iter, \n    access_detail_iter, \n    path_filter \n)\n```", "```py\nfrom collections.abc import Iterator \nimport gzip \nfrom pathlib import Path \n\nimport sys \ndef local_gzip(zip_path: Path) -> Iterator[str]: \n    with gzip.open(zip_path, \"rb\") as log_file: \n        yield from ( \n            line.decode(’us-ascii’).rstrip() \n            for line in log_file \n        )\n```", "```py\nfrom typing import NamedTuple, Optional, cast \nimport re \n\nclass Access(NamedTuple): \n    host: str \n    identity: str \n    user: str \n    time: str \n    request: str \n    status: str \n    bytes: str \n    referer: str \n    user_agent: str \n\n    @classmethod \n    def create(cls: type, line: str) -> Optional[\"Access\"]: \n        format_pat = re.compile( \n            r\"(?P<host>[\\d\\.]+)\\s+\" \n            r\"(?P<identity>\\S+)\\s+\" \n            r\"(?P<user>\\S+)\\s+\" \n            r\"\\[(?P<time>.+?)\\]\\s+\" \n            r’\"(?P<request>.+?)\"\\s+’ \n            r\"(?P<status>\\d+)\\s+\" \n            r\"(?P<bytes>\\S+)\\s+\" \n            r’\"(?P<referer>.*?)\"\\s+’ \n            r’\"(?P<user_agent>.+?)\"\\s*’ \n            ) \n        if match := format_pat.match(line): \n            return cast(Access, cls(**match.groupdict())) \n        return None\n```", "```py\nfrom collections.abc import Iterator \n\ndef access_iter(source_iter: Iterator[str]) -> Iterator[Access]: \n    for line in source_iter: \n        if access := Access.create(line): \n            yield access\n```", "```py\ndef access_iter_2(source_iter: Iterator[str]) -> Iterator[Access]: \n    return filter( \n        None, \n        map( \n            Access.create, \n            source_iter \n        ) \n    )\n```", "```py\nfrom typing import NamedTuple, Optional \nimport datetime \nimport urllib.parse \n\nclass AccessDetails(NamedTuple): \n    access: Access \n    time: datetime.datetime \n    method: str \n    url: urllib.parse.ParseResult \n    protocol: str \n    referrer: urllib.parse.ParseResult \n    agent: dict[str, str] \n\n    @classmethod \n    def create(cls: type, access: Access) -> \"AccessDetails\": \n          meth, url, protocol = parse_request(access.request) \n          return AccessDetails( \n              access=access, \n              time=parse_time(access.time), \n              method=meth, \n              url=urllib.parse.urlparse(url), \n              protocol=protocol, \n              referrer=urllib.parse.urlparse(access.referer), \n              agent=parse_agent(access.user_agent) \n          )\n```", "```py\nfrom typing import Optional \nimport datetime \nimport re \n\ndef parse_request(request: str) -> tuple[str, str, str]: \n    words = request.split() \n    return words[0], ’ ’.join(words[1:-1]), words[-1] \n\ndef parse_time(ts: str) -> datetime.datetime: \n    return datetime.datetime.strptime( \n        ts, \"%d/%b/%Y:%H:%M:%S %z\" \n    ) \n\ndef parse_agent(user_agent: str) -> dict[str, str]: \n    agent_pat = re.compile( \n        r\"(?P<product>\\S*?)\\s+\" \n        r\"\\((?P<system>.*?)\\)\\s*\" \n        r\"(?P<platform_details_extensions>.*)\" \n    ) \n\n    if agent_match := agent_pat.match(user_agent): \n        return agent_match.groupdict() \n    return {}\n```", "```py\nfrom collections.abc import Iterable, Iterator \n\ndef access_detail_iter( \n    access_iter: Iterable[Access] \n) -> Iterator[AccessDetails]: \n    for access in access_iter: \n        yield AccessDetails.create(access)\n```", "```py\nfrom collections.abc import Iterable, Iterator \n\ndef access_detail_iter_2( \n    access_iter: Iterable[Access] \n) -> Iterator[AccessDetails]: \n    return map(AccessDetails.create, access_iter)\n```", "```py\ndef non_empty_path(detail: AccessDetails) -> bool: \n    path = detail.url.path.split(’/’) \n    return any(path)\n```", "```py\ndef path_filter( \n    access_details_iter: Iterable[AccessDetails] \n) -> Iterable[AccessDetails]: \n    non_empty = filter(non_empty_path, access_details_iter) \n    nx_name = filter(non_excluded_names, non_empty) \n    nx_ext = filter(non_excluded_ext, nx_name) \n    yield from nx_ext\n```", "```py\nfrom collections.abc import Iterable, Iterator \n\ndef book_filter( \n    access_details_iter: Iterable[AccessDetails] \n) -> Iterator[AccessDetails]: \n    def book_in_path(detail: AccessDetails) -> bool: \n        path = tuple( \n            item \n            for item in detail.url.path.split(’/’) \n            if item \n        ) \n        return path[0] == ’book’ and len(path) > 1 \n    return filter(book_in_path, access_details_iter)\n```", "```py\nfrom collections import Counter \n\ndef reduce_book_total( \n    access_details_iter: Iterable[AccessDetails] \n) -> dict[str, int]: \n    counts: Counter[str] = Counter( \n        detail.url.path for detail in access_details_iter \n    ) \n    return counts\n```", "```py\ndef analysis(log_path: Path) -> dict[str, int]: \n    \"\"\"Count book chapters in a given log\"\"\" \n    details = access_detail_iter( \n        access_iter( \n            local_gzip(log_path))) \n    books = book_filter(path_filter(details)) \n    totals = reduce_book_total(books) \n    return totals\n```", "```py\ndef demo_mp(root: Path = SAMPLE_DATA, pool_size: int | None = None) -> None: \n    pool_size = ( \n        multiprocessing.cpu_count() if pool_size is None \n        else pool_size \n    ) \n    combined: Counter[str] = Counter() \n    with multiprocessing.Pool(pool_size) as workers: \n        file_iter = list(root.glob(LOG_PATTERN)) \n        results_iter = workers.imap_unordered(analysis, file_iter) \n        for result in results_iter: \n            combined.update(result) \n    print(combined)\n```", "```py\ndef demo_mp_async(root: Path = SAMPLE_DATA, pool_size: int | None = None) -> None: \n    pool_size = ( \n        multiprocessing.cpu_count() if pool_size is None \n        else pool_size \n    ) \n    combined: Counter[str] = Counter() \n    with multiprocessing.Pool(pool_size) as workers: \n        file_iter = root.glob(LOG_PATTERN) \n        results = workers.map_async(analysis, file_iter) \n        for result in results.get(): \n            combined.update(result) \n    print(combined)\n```", "```py\nlist( \n    workers.apply(analysis, f) \n    for f in SAMPLE_DATA.glob(LOG_PATTERN) \n)\n```", "```py\ndef demo_cf_threads(root: Path = SAMPLE_DATA, pool_size: int = 4) -> None: \n    pattern = \"*itmaybeahack.com*.gz\" \n    combined: Counter[str] = Counter() \n    with futures.ProcessPoolExecutor(max_workers=pool_size) \n            as workers: \n        file_iter = root.glob(LOG_PATTERN) \n        for result in workers.map(analysis, file_iter): \n            combined.update(result) \n    print(combined)\n```"]