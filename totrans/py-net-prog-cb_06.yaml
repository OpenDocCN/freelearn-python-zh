- en: Chapter 6. Screen-scraping and Other Practical Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 屏幕抓取和其他实用应用
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Searching for business addresses using the Google Maps API
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Google Maps API搜索商业地址
- en: Searching for geographic coordinates using the Google Maps URL
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Google Maps URL搜索地理坐标
- en: Searching for an article in Wikipedia
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在维基百科中搜索文章
- en: Searching for Google stock quote
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索Google股票报价
- en: Searching for a source code repository at GitHub
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GitHub上搜索源代码仓库
- en: Reading news feed from BBC
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从BBC读取新闻源
- en: Crawling links present in a web page
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爬取网页中存在的链接
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: This chapter shows some of the interesting Python scripts that you can write
    to extract useful information from the web, for example, searching for a business
    address, stock quote for a particular company or the latest news from a news agency
    website. These scripts demonstrate how Python can extract simple information in
    simpler ways without communicating with complex APIs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了您可以编写的某些有趣的Python脚本，用于从网络中提取有用的信息，例如，搜索商业地址、特定公司的股票报价或新闻机构的最新新闻。这些脚本展示了Python如何在不与复杂的API通信的情况下以更简单的方式提取简单信息。
- en: Following these recipes, you should be able to write code for complex scenarios,
    for example, find the details about a business, including location, news, stock
    quote, and so on.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这些配方，您应该能够编写用于复杂场景的代码，例如，查找有关业务的信息，包括位置、新闻、股票报价等。
- en: Searching for business addresses using the Google Maps API
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Google Maps API搜索商业地址
- en: You would like to search for the address of a well-known business in your area.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您想搜索您所在地区一家知名企业的地址。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You can use the Python geocoding library `pygeocoder` to search for a local
    business. You need to install this library from **PyPI** with `pip` or `easy_install`,
    by entering `$ pip install pygeocoder` or `$ easy_install pygeocoder`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Python地理编码库`pygeocoder`来搜索本地商业。您需要使用`pip`或`easy_install`从**PyPI**安装此库，通过输入`$
    pip install pygeocoder`或`$ easy_install pygeocoder`。
- en: How to do it...
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: Let us find the address of Argos Ltd., a well-known UK retailer using a few
    lines of Python code.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用几行Python代码找到知名英国零售商Argos Ltd.的地址。
- en: 'Listing 6.1 gives a simple geocoding example to search for a business address,
    as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.1提供了一个简单的地理编码示例，用于搜索商业地址，如下所示：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This recipe will print the address of Argos Ltd., as shown. The output may
    vary slightly based on the output from your installed geocoding library:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方将打印出Argos Ltd.的地址，如所示。输出可能会根据您安装的地理编码库的输出略有不同：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How it works...
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This recipe relies on the Python third-party geocoder library.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方依赖于Python第三方地理编码库。
- en: This recipe defines a simple function `search_business()` that takes the business
    name as an input and passes that to the `geocode()` function. The `geocode()`
    function can return zero or more search results depending on your search term.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方定义了一个简单的函数`search_business()`，它接受业务名称作为输入并将其传递给`geocode()`函数。`geocode()`函数可以根据您的搜索词返回零个或多个搜索结果。
- en: In this recipe, the `geocode()` function has got the business name Argos Ltd.,
    London, as the search query. In return, it gives the address of Argos Ltd., which
    is 110-114 King Street, London, Greater London W6 0QP, UK.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在此配方中，`geocode()`函数将业务名称Argos Ltd.，伦敦作为搜索查询。作为回报，它给出了Argos Ltd.的地址，即110-114
    King Street，伦敦，大伦敦W6 0QP，英国。
- en: See also
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The `pygeocoder` library is powerful and has many interesting and useful features
    for geocoding. You may find more details on the developer's website at [https://bitbucket.org/xster/pygeocoder/wiki/Home](https://bitbucket.org/xster/pygeocoder/wiki/Home).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`pygeocoder`库功能强大，具有许多有趣和有用的地理编码功能。您可以在开发者的网站上找到更多详细信息，网址为[https://bitbucket.org/xster/pygeocoder/wiki/Home](https://bitbucket.org/xster/pygeocoder/wiki/Home)。'
- en: Searching for geographic coordinates using the Google Maps URL
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Google Maps URL搜索地理坐标
- en: Sometimes you'd like to have a simple function that gives the geographic coordinates
    of a city by giving it just the name of that city. You may not be interested in
    installing any third-party libraries for this simple task.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有时您可能需要一个简单的函数，通过仅提供该城市的名称即可给出该城市的地理坐标。您可能对安装任何第三方库来完成此简单任务不感兴趣。
- en: How to do it...
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: In this simple screen-scraping example, we use the Google Maps URL to query
    the latitude and longitude of a city. The URL used to query can be found after
    making a custom search on the Google Maps page. We can perform the following steps
    to extract some information from Google Maps.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的屏幕抓取示例中，我们使用谷歌地图URL查询城市的纬度和经度。用于查询的URL可以在对谷歌地图页面进行自定义搜索后找到。我们可以执行以下步骤从谷歌地图中提取一些信息。
- en: Let us take the name of a city from the command line using the `argparse` module.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`argparse`模块从命令行获取一个城市的名称。
- en: We can open the maps search URL using the `urlopen()` function of `urllib`.
    This will give an XML output if the URL is correct.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`urllib`模块的`urlopen()`函数打开地图搜索URL。如果URL正确，这将给出XML输出。
- en: Now, process the XML output in order to get the geographic coordinates of that
    city.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，处理XML输出以获取该城市的地理坐标。
- en: 'Listing 6.2 helps finding the geographic coordinates of a city using Google
    Maps, as shown:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.2帮助使用谷歌地图查找城市的地理坐标，如下所示：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you run this script, you should see something similar to the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行此脚本，您应该看到以下类似的内容：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works...
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This recipe takes a name of a city from the command line and passes that to
    the `find_lat_long()` function. This function queries the Google Maps service
    using the `urlopen()` function of `urllib` and gets the XML output. Then, the
    error string `'<error>'` is searched for. If that's not present, it means there
    are some good results.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方从命令行获取一个城市的名称并将其传递给`find_lat_long()`函数。此函数使用`urllib`模块的`urlopen()`函数查询谷歌地图服务并获取XML输出。然后，搜索错误字符串`'<error>'`。如果没有出现，这意味着有一些好的结果。
- en: If you print out the raw XML, it's a long stream of characters produced for
    the browser. In the browser, it would be interesting to display the layers in
    maps. But in our case, we just need the latitude and longitude.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您打印出原始XML，它是一长串为浏览器生成的字符流。在浏览器中，显示地图的层可能很有趣。但在我们的情况下，我们只需要纬度和经度。
- en: From the raw XML, the latitude and longitude is extracted using the string method
    `find()`. This searches for the keyword "center". This list key possesses the
    geographic coordinates information. But it also contains the additional characters
    which are removed using the string method `replace()`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从原始XML中，使用字符串方法`find()`提取纬度和经度。这是搜索关键字"center"。此列表键具有地理坐标信息。但它还包含额外的字符，这些字符使用字符串方法`replace()`被移除。
- en: You may try this recipe to find out the latitude/longitude of any known city
    of the world.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以尝试这个配方来找出世界上任何已知城市的纬度/经度。
- en: Searching for an article in Wikipedia
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在维基百科中搜索文章
- en: Wikipedia is a great site to gather information about virtually anything, for
    example, people, places, technology, and what not. If you like to search for something
    on Wikipedia from your Python script, this recipe is for you.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科是一个收集关于几乎任何事物的信息的绝佳网站，例如，人物、地点、技术等等。如果您想从Python脚本中在维基百科上搜索某些内容，这个配方就是为您准备的。
- en: 'Here is an example:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子：
- en: '![Searching for an article in Wikipedia](img/3463OS_06_01.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![在维基百科中搜索文章](img/3463OS_06_01.jpg)'
- en: Getting ready
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You need to install the `pyyaml` third-party library from PyPI using `pip` or
    `easy_install` by entering `$ pip install pyyaml` or `$ easy_install pyyaml`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要使用`pip`或`easy_install`通过输入`$ pip install pyyaml`或`$ easy_install pyyaml`从PyPI安装`pyyaml`第三方库。
- en: How to do it...
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: Let us search for the keyword `Islam` in Wikipedia and print each search result
    in one line.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在维基百科中搜索关键字`Islam`并按行打印每个搜索结果。
- en: 'Listing 6.3 explains how to search for an article in Wikipedia, as shown:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.3解释了如何在维基百科中搜索一篇文章，如下所示：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Running this recipe to query Wikipedia about Islam shows the following output:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此配方查询维基百科关于伊斯兰的结果如下：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How it works...
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'First, we collect the Wikipedia URL template for searching an article. We created
    a class called `Wikipedia`, which has two methods: `_get_content()` and `search_content()`.
    By default upon initialization, the class sets up its language attribute `lang`
    to `en` (English).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们收集搜索文章的维基百科URL模板。我们创建了一个名为`Wikipedia`的类，它有两个方法：`_get_content()`和`search_content()`。默认情况下，初始化时，该类将语言属性`lang`设置为`en`（英语）。
- en: The command-line query string is passed to the `search_content()` method. It
    then constructs the actual search URL by inserting variables such as language,
    query string, page offset, and number of results to return. The `search_content()`
    method can optionally take the parameters and the offset is determined by the
    `(page -1) * limit` expression.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 命令行查询字符串被传递给`search_content()`方法。然后它通过插入变量（如语言、查询字符串、页面偏移和要返回的结果数量）来构建实际的搜索URL。`search_content()`方法可以可选地接受参数，偏移量由`(page
    -1) * limit`表达式确定。
- en: The content of the search result is fetched via the `_get_content()` method
    which calls the `urlopen()` function of `urllib`. In the search URL, we set up
    the result format `yaml`, which is basically intended for plain text files. The
    `yaml` search result is then parsed with Python's `pyyaml` library.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索结果的内容是通过`_get_content()`方法获取的，该方法调用`urllib`的`urlopen()`函数。在搜索URL中，我们设置了结果格式`yaml`，这基本上是为了纯文本文件。然后使用Python的`pyyaml`库解析`yaml`搜索结果。
- en: The search result is processed by substituting the regular expressions found
    in each result item. For example, the `re.sub(r'(?m)<.*?>', '', snippet)` expression
    takes the snippet string and replaces a raw pattern `(?m)<.*?>)`. To learn more
    about regular expressions, visit the Python document page, available at [http://docs.python.org/2/howto/regex.html](http://docs.python.org/2/howto/regex.html).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索结果通过替换每个结果项中找到的正则表达式进行处理。例如，`re.sub(r'(?m)<.*?>', '', snippet)`表达式将替换片段字符串中的原始模式`(?m)<.*?>`。要了解更多关于正则表达式的信息，请访问Python文档页面，网址为[http://docs.python.org/2/howto/regex.html](http://docs.python.org/2/howto/regex.html)。
- en: In Wikipedia terminology, each article has a snippet or a short description.
    We create a list of dictionary items where each item contains the title and the
    snippet of each search result. The results are printed on the screen by looping
    through this list of dictionary items.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在维基百科术语中，每篇文章都有一个片段或简短描述。我们创建了一个字典项列表，其中每个项包含每个搜索结果的标题和片段。通过遍历这个字典项列表，结果被打印在屏幕上。
- en: Searching for Google stock quote
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 搜索谷歌股票报价
- en: If the stock quote of any company is of interest to you, this recipe can help
    you to find today's stock quote of that company.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对任何公司的股票报价感兴趣，此配方可以帮助您找到该公司的今日股票报价。
- en: Getting ready
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We assume that you already know the symbol used by your favorite company to
    enlist itself on any stock exchange. If you don't know, get the symbol from the
    company website or just search in Google.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您已经知道您喜欢的公司用于在任何证券交易所上市的符号。如果您不知道，可以从公司网站获取符号，或者直接在谷歌上搜索。
- en: How to do it...
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Here, we use Google Finance ([http://finance.google.com/](http://finance.google.com/))
    to search for the stock quote of a given company. You can input the symbol via
    the command line, as shown in the next code.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用谷歌财经([http://finance.google.com/](http://finance.google.com/))来搜索给定公司的股票报价。您可以通过命令行输入符号，如下所示。
- en: 'Listing 6.4 describes how to search for Google stock quote, as shown:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.4描述了如何搜索谷歌股票报价，如下所示：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If you run this script, you will see an output similar to the following. Here,
    the stock quote for Google is searched by inputting the symbol `goog`, as shown:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此脚本，你将看到类似以下输出。在此，通过输入符号`goog`来搜索谷歌的股票报价，如下所示：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How it works...
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This recipe uses the `urlopen()` function of `urllib` to get the stock data
    from the Google Finance website.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方使用`urllib`的`urlopen()`函数从谷歌财经网站获取股票数据。
- en: By using the regular expression library `re`, it locates the stock quote data
    in the first group of items. The `search()` function of `re` is powerful enough
    to search the content and filter the ID data of that particular company.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用正则表达式库`re`，它定位到第一个项目组中的股票报价数据。`re`的`search()`函数足够强大，可以搜索内容并过滤特定公司的ID数据。
- en: Using this recipe, we searched for the stock quote of Google, which was `868.86`
    on August 20, 2013.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此配方，我们搜索了谷歌的股票报价，该报价在2013年8月20日为`868.86`。
- en: Searching for a source code repository at GitHub
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在GitHub上搜索源代码仓库
- en: As a Python programmer, you may already be familiar with GitHub ([http://www.github.com](http://www.github.com)),
    a source code-sharing website, as shown in the following screenshot. You can share
    your source code privately to a team or publicly to the world using GitHub. It
    has a nice API interface to query about any source code repository. This recipe
    may give you a starting point to create your own source code search engine.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名Python程序员，您可能已经熟悉GitHub ([http://www.github.com](http://www.github.com))，一个源代码共享网站，如下面的截图所示。您可以使用GitHub将源代码私密地分享给团队或公开地分享给全世界。它有一个很好的API接口，可以查询任何源代码仓库。这个食谱可能为您创建自己的源代码搜索引擎提供了一个起点。
- en: '![Searching for a source code repository at GitHub](img/3463OS_06_02.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![在GitHub上搜索源代码仓库](img/3463OS_06_02.jpg)'
- en: Getting ready
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To run this recipe, you need to install the third-party Python library `requests`
    by entering `$ pip install requests` or `$ easy_install requests`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此食谱，您需要通过输入 `$ pip install requests` 或 `$ easy_install requests` 来安装第三方Python库
    `requests`。
- en: How to do it...
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We would like to define a `search_repository()` function that will take the
    name of author (also known as coder), repository, and search key. In return, it
    will give us back the available result against the search key. From the GitHub
    API, the following are the available search keys: `issues_url`, `has_wiki`, `forks_url`,
    `mirror_url`, `subscription_url`, `notifications_url`, `collaborators_url`, `updated_at`,
    `private`, `pulls_url`, `issue_comment_url`, `labels_url`, `full_name`, `owner`,
    `statuses_url`, `id`, `keys_url`, `description`, `tags_url`, `network_count`,
    `downloads_url`, `assignees_url`, `contents_url`, `git_refs_url`, `open_issues_count`,
    `clone_url`, `watchers_count`, `git_tags_url`, `milestones_url`, `languages_url`,
    `size`, `homepage`, `fork`, `commits_url`, `issue_events_url`, `archive_url`,
    `comments_url`, `events_url`, `contributors_url`, `html_url`, `forks`, `compare_url`,
    `open_issues`, `git_url`, `svn_url`, `merges_url`, `has_issues`, `ssh_url`, `blobs_url`,
    `master_branch`, `git_commits_url`, `hooks_url`, `has_downloads`, `watchers`,
    `name`, `language`, `url`, `created_at`, `pushed_at`, `forks_count`, `default_branch`,
    `teams_url`, `trees_url`, `organization`, `branches_url`, `subscribers_url`, and
    `stargazers_url`.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望定义一个 `search_repository()` 函数，它将接受作者名称（也称为程序员）、仓库和搜索键。作为回报，它将根据搜索键返回可用的结果。从GitHub
    API来看，以下是可以用的搜索键：`issues_url`、`has_wiki`、`forks_url`、`mirror_url`、`subscription_url`、`notifications_url`、`collaborators_url`、`updated_at`、`private`、`pulls_url`、`issue_comment_url`、`labels_url`、`full_name`、`owner`、`statuses_url`、`id`、`keys_url`、`description`、`tags_url`、`network_count`、`downloads_url`、`assignees_url`、`contents_url`、`git_refs_url`、`open_issues_count`、`clone_url`、`watchers_count`、`git_tags_url`、`milestones_url`、`languages_url`、`size`、`homepage`、`fork`、`commits_url`、`issue_events_url`、`archive_url`、`comments_url`、`events_url`、`contributors_url`、`html_url`、`forks`、`compare_url`、`open_issues`、`git_url`、`svn_url`、`merges_url`、`has_issues`、`ssh_url`、`blobs_url`、`master_branch`、`git_commits_url`、`hooks_url`、`has_downloads`、`watchers`、`name`、`language`、`url`、`created_at`、`pushed_at`、`forks_count`、`default_branch`、`teams_url`、`trees_url`、`organization`、`branches_url`、`subscribers_url`
    和 `stargazers_url`。
- en: 'Listing 6.5 gives the code to search for details of a source code repository
    at GitHub, as shown:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.5给出了在GitHub上搜索源代码仓库详细信息的代码，如下所示：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you run this script to search for the owner of the Python web framework
    Django, you can get the following result:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行此脚本以搜索Python网络框架Django的所有者，您可以得到以下结果：
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: How it works...
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'This script takes three command-line arguments: repository author (`--author`),
    repository name (`--repo`), and the item to search for (`--search_for`). The arguments
    are processed by the `argpase` module.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本接受三个命令行参数：仓库作者（`--author`）、仓库名称（`--repo`）和要搜索的项目（`--search_for`）。这些参数通过 `argpase`
    模块进行处理。
- en: Our `search_repository()` function appends the command-line arguments to a fixed
    search URL and receives the content by calling the `requests` module's `get()`
    function.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `search_repository()` 函数将命令行参数追加到固定的搜索URL，并通过调用 `requests` 模块的 `get()` 函数接收内容。
- en: The search results are, by default, returned in the JSON format. This content
    is then processed with the `json` module's `loads()` method. The search key is
    then looked for inside the result and the corresponding value of that key is returned
    back to the caller of the `search_repository()` function.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，搜索结果以JSON格式返回。然后使用 `json` 模块的 `loads()` 方法处理此内容。然后在结果中查找搜索键，并将该键的对应值返回给
    `search_repository()` 函数的调用者。
- en: In the main user code, we check whether the search result is an instance of
    the Python dictionary. If yes, then the key/values are printed iteratively. Otherwise,
    the value is printed.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在主用户代码中，我们检查搜索结果是否是Python字典的实例。如果是，则迭代打印键/值。否则，只打印值。
- en: Reading news feed from BBC
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从BBC读取新闻源
- en: If you are developing a social networking website with news and stories, you
    may be interested to present the news from various world news agencies, such as
    BBC and Reuters. Let us try to read news from BBC via a Python script.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在开发一个包含新闻和故事的社交网络网站，你可能对展示来自各种世界新闻机构（如BBC和路透社）的新闻感兴趣。让我们尝试通过Python脚本从BBC读取新闻。
- en: Getting ready
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: 'This recipe relies on Python''s third-party `feedparser` library. You can install
    this by running the following command:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此菜谱依赖于Python的第三方`feedparser`库。你可以通过运行以下命令来安装它：
- en: '[PRE10]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Or
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 或者
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: How to do it...
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: First, we collect the BBC's news feed URL from the BBC website. This URL can
    be used as a template to search news on various types, such as world, UK, health,
    business, and technology. So, we can take the type of news to display as user
    input. Then, we depend on the `read_news()` function, which will fetch the news
    from the BBC.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从BBC网站收集BBC的新闻源URL。这个URL可以用作模板来搜索各种类型的新闻，如世界、英国、健康、商业和技术。因此，我们可以将显示的新闻类型作为用户输入。然后，我们依赖于`read_news()`函数，它将从BBC获取新闻。
- en: 'Listing 6.6 explains how to read news feed from the BBC, as shown in the following
    code:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.6解释了如何从BBC读取新闻源，如下面的代码所示：
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Running this script will show you the available news categories. If we choose
    technology as the category, you can get the latest news on technology, as shown
    in the following command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此脚本将显示可用的新闻类别。如果我们选择技术作为类别，你可以获取最新的技术新闻，如下面的命令所示：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: How it works...
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, the `read_news()` function relies on Python's third-party module
    `feedparser`. The `feedparser` module's `parser()` method returns the feed data
    in a structured fashion.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，`read_news()`函数依赖于Python的第三方模块`feedparser`。`feedparser`模块的`parser()`方法以结构化的方式返回源数据。
- en: In this recipe, the `parser()` method parses the given feed URL. This URL is
    constructed from `BBC_FEED_URL` and user input.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，`parser()`方法解析给定的源URL。这个URL由`BBC_FEED_URL`和用户输入构成。
- en: After some valid feed data is obtained by calling `parse()`, the contents of
    the data is then printed, such as title, link, and description, of each feed entry.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用`parse()`获取一些有效的源数据后，然后打印数据的内容，例如每个源条目的标题、链接和描述。
- en: Crawling links present in a web page
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 爬取网页中存在的链接
- en: At times you would like to find a specific keyword present in a web page. In
    a web browser, you can use the browser's in-page search facility to locate the
    terms. Some browsers can highlight it. In a complex situation, you would like
    to dig deep and follow every URL present in a web page and find that specific
    term. This recipe will automate that task for you.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有时你希望在网页中找到特定的关键词。在网页浏览器中，你可以使用浏览器的页面搜索功能来定位术语。一些浏览器可以突出显示它。在复杂的情况下，你可能想深入挖掘并跟随网页中存在的每个URL，以找到那个特定的术语。这个菜谱将为你自动化这个任务。
- en: How to do it...
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let us write a `search_links()` function that will take three arguments: the
    search URL, the depth of the recursive search, and the search key/term, since
    every URL may have links present in the content and that content may have more
    URLs to crawl. To limit the recursive search, we define a depth. Upon reaching
    that depth, no more recursive search will be done.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个`search_links()`函数，它将接受三个参数：搜索URL、递归搜索的深度以及搜索关键词/术语，因为每个URL的内容中可能包含链接，而该内容可能包含更多要爬取的URL。为了限制递归搜索，我们定义了一个深度。达到那个深度后，将不再进行递归搜索。
- en: 'Listing 6.7 gives the code for crawling links present in a web page, as shown
    in the following code:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.7给出了爬取网页中存在的链接的代码，如下面的代码所示：
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you run this script to search [www.python.org](http://www.python.org) for
    `python`, you will see an output similar to the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此脚本来搜索[www.python.org](http://www.python.org)中的`python`，你将看到以下类似的输出：
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: How it works...
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'This recipe can take three command-line inputs: search URL (`--url`), the query
    string (`--query`), and the depth of recursion (`--depth`). These inputs are processed
    by the `argparse` module.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 此菜谱可以接受三个命令行输入：搜索URL（`--url`）、查询字符串（`--query`）和递归深度（`--depth`）。这些输入由`argparse`模块处理。
- en: When the `search_links()` function is called with the previous arguments, this
    will recursively iterate on all the links found on that given web page. If it
    takes too long to finish, you would like to exit prematurely. For this reason,
    the `search_links()` function is placed inside a try-catch block which can catch
    the user's keyboard interrupt action, such as *Ctrl* + *C*.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用之前的参数调用 `search_links()` 函数时，它将递归地遍历该给定网页上找到的所有链接。如果完成时间过长，你可能希望提前退出。因此，`search_links()`
    函数被放置在一个 try-catch 块中，该块可以捕获用户的键盘中断操作，例如 *Ctrl* + *C*。
- en: The `search_links()` function keeps track of visited links via a list called
    `processed`. This is made global to give access to all the recursive function
    calls.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`search_links()` 函数通过一个名为 `processed` 的列表来跟踪已访问的链接。这样做是为了使其全局可用，以便在所有递归函数调用中都能访问。'
- en: In a single instance of search, it is ensured that only HTTP URLs are processed
    in order to avoid the potential SSL certificate errors. The URL is split into
    a host and a path. The main crawling is initiated using the `HTTPConnection()`
    function of `httplib`. It gradually makes a `GET` request and a response is then
    processed using the regular expression module `re`. This collects all the links
    from the response. Each response is then examined for the search term. If the
    search term is found, it prints that incident.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个搜索实例中，确保只处理HTTP URL，以避免潜在的SSL证书错误。URL被拆分为主机和路径。主要的爬取操作使用 `httplib` 的 `HTTPConnection()`
    函数启动。它逐渐发起 `GET` 请求，然后使用正则表达式模块 `re` 处理响应。这收集了响应中的所有链接。然后检查每个响应以查找搜索词。如果找到搜索词，它将打印该事件。
- en: The collected links are visited recursively in the same way. If any relative
    URL is found, that instance is converted into a full URL by prefixing `http://`
    to the host and the path. If the depth of search is greater than 0, the recursion
    is activated. It reduces the depth by 1 and runs the search function again. When
    the search depth becomes 0, the recursion ends.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 收集到的链接以相同的方式递归访问。如果找到任何相对URL，该实例将通过在主机和路径前添加 `http://` 转换为完整URL。如果搜索深度大于0，则激活递归。它将深度减少1，并再次运行搜索函数。当搜索深度变为0时，递归结束。
