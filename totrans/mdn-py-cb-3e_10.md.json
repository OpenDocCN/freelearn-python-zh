["```py\n    from pathlib import Path \n\n    from dataclasses import dataclass \n\n    @dataclass \n\n    class Referenced: \n\n        \"\"\"Defines a data file and applications that reference it.\"\"\"\n    ```", "```py\n    datafile: Path \n\n        recipes: list[Path] \n    ```", "```py\n    from typing import TypeAlias \n\n    Unreferenced: TypeAlias = Path\n    ```", "```py\n    ContentType: TypeAlias = Unreferenced | Referenced\n    ```", "```py\ndef datafile_iter(base: Path) -> Iterator[ContentType]: \n\n    data = (base / \"data\") \n\n    code = (base / \"src\") \n\n    for path in sorted(data.glob(\"*.*\")): \n\n        if not path.is_file(): \n\n            continue \n\n        used_by = [ \n\n            chap_recipe.relative_to(code) \n\n            for chap_recipe in code.glob(\"**/*.py\") \n\n            if ( \n\n                chap_recipe.is_file() \n\n                and \"__pycache__\" not in chap_recipe.parts \n\n                and \".venv\" not in chap_recipe.parts \n\n                and \"ch10\" not in chap_recipe.parts \n\n                and path.name in chap_recipe.read_text() \n\n            ) \n\n        ] \n\n        if used_by: \n\n            yield Referenced(path.relative_to(data), used_by) \n\n        else: \n\n            yield path.relative_to(data)\n```", "```py\n    def datafile_iter(base): \n\n        data = (base / \"data\") \n\n        code = (base / \"src\")\n    ```", "```py\n        for path in sorted(data.glob(\"*.*\")): \n\n            if not path.is_file(): \n\n                continue \n\n            used_by = [ \n\n                chap_recipe.relative_to(code) \n\n                for chap_recipe in code.glob(\"**/*.py\") \n\n                if ( \n\n                        chap_recipe.is_file() \n\n                        and \"__pycache__\" not in chap_recipe.parts \n\n                        and \".venv\" not in chap_recipe.parts \n\n                        and \"ch10\" not in chap_recipe.parts \n\n                        and path.name in chap_recipe.read_text() \n\n                ) \n\n            ]\n    ```", "```py\n            if used_by: \n\n                yield (path.relative_to(data), used_by) \n\n            else: \n\n                yield path.relative_to(data)\n    ```", "```py\n    from typing import NamedTuple \n\n    class Referenced(NamedTuple): \n\n        datafile: Path \n\n        recipes: list[Path]\n    ```", "```py\n    yield Referenced(path.relative_to(data), used_by) \n    ```", "```py\n    def datafile_iter_2(base: Path) -> Iterator[Path | Referenced]:\n    ```", "```py\nfrom collections.abc import Iterator \n\nDataFileIter: TypeAlias = Iterator[Unreferenced | Referenced] \n\ndef datafile_iter(base: Path) -> DataFileIter:\n```", "```py\n    from collections.abc import Iterable \n\n    def analysis(source: Iterable[Unreferenced | Referenced]) -> None:\n    ```", "```py\n        good_files: list[Referenced] = [] \n\n        for file in source:\n    ```", "```py\n            if isinstance(file, Unreferenced): \n\n                print(f\"delete {file}\") \n\n            elif isinstance(file, Referenced): \n\n                good_files.append(file)\n    ```", "```py\n            else: \n\n                raise ValueError(f\"unexpected type {type(file)}\")\n    ```", "```py\n        print(f\"Keep {len(good_files)} files\")\n    ```", "```py\ntype Unreferenced = Path\n```", "```py\n    from collections.abc import Iterable \n\n    def analysis(source: Iterable[Unreferenced | Referenced]) -> None:\n    ```", "```py\n        good_files: list[Referenced] = [] \n\n        for file in source:\n    ```", "```py\n            match file:\n    ```", "```py\n    case Unreferenced() as unref: \n\n                    print(f\"delete {unref}\") \n\n                case Referenced() as ref: \n\n                    good_files.append(file) \n    ```", "```py\n                case _: \n\n                    raise ValueError(f\"unexpected type {type(file)}\")\n    ```", "```py\n        print(f\"Keep {len(good_files)} files\")\n    ```", "```py\nsingle use: Referenced(datafile=PosixPath(’race_result.json’), recipes=[PosixPath(’ch11/recipe_06.py’)])\n```", "```py\n case Referenced(_, [Path()]) as single: \n\n                print(f\"single use: {single}\") \n\n                good_files.append(single) \n\n            case Referenced() as multiple: \n\n                good_files.append(multiple)\n```", "```py\ndef haversine( \n\n    lat_1: float, lon_1: float, \n\n    lat_2: float, lon_2: float, *, R: float) -> float: \n\n    ...  # etc.\n```", "```py\ndef distance( \n\n    *args: str | float | tuple[float, float], \n\n    R: float = NM \n\n) -> float:\n```", "```py\n    from ast import literal_eval\n    ```", "```py\n    def distance( \n\n        *args: str | float | tuple[float, float], \n\n        R: float = NM \n\n    ) -> float:\n    ```", "```py\n        match args:\n    ```", "```py\n            case [float(lat_1), float(lon_1), float(lat_2), float(lon_2)]: \n\n                pass \n\n            case ( \n\n                [[float(lat_1), float(lon_1)], \n\n                 [float(lat_2), float(lon_2)]] \n\n            ): \n\n                pass\n    ```", "```py\n            case [str(s1), str(s2), str(s3), str(s4)]: \n\n                lat_1, lon_1, lat_2, lon_2 = ( \n\n                    float(s1), float(s2), float(s3), float(s4) \n\n                ) \n\n            case [str(ll1), str(ll2)]: \n\n                lat_1, lon_1 = literal_eval(ll1) \n\n                lat_2, lon_2 = literal_eval(ll2)\n    ```", "```py\n    case _: \n\n                raise ValueError(f\"unexpected types in {args!r}\") \n    ```", "```py\n        return haversine(lat_1, lon_1, lat_2, lon_2, R=R)\n    ```", "```py\n        case ( \n\n             {\"lat\": float(lat_1), \"lon\": float(lon_1)}, \n\n             {\"lat\": float(lat_2), \"lon\": float(lon_2)} \n\n        ): \n\n            pass\n```", "```py\n        case [p_1, p_2]: \n\n            lat_1, lon_1 = parse(p_1) \n\n            lat_2, lon_2 = parse(p_2)\n```", "```py\n    def parse(item: Point | float) -> tuple[float, float]: \n\n        match item: \n\n            case [float(lat), float(lon)]: \n\n                pass \n\n            case {\"lat\": float(lat), \"lon\": float(lon)}: \n\n                pass \n\n            case str(sll): \n\n                lat, lon = literal_eval(sll) \n\n            case _: \n\n                raise ValueError(f\"unexpected types in {item!r}\") \n\n        return lat, lon\n```", "```py\n    match args: \n\n        case [float(lat_1), float(lon_1), float(lat_2), float(lon_2)]: \n\n            pass \n\n        case [str(s1), str(s2), str(s3), str(s4)]: \n\n            lat_1, lon_1, lat_2, lon_2 = float(s1), float(s2), float(s3), float(s4) \n\n        case [p_1, p_2]: \n\n            lat_1, lon_1 = parse(p_1) \n\n            lat_2, lon_2 = parse(p_2) \n\n        case _: \n\n            raise ValueError(f\"unexpected types in {args!r}\")\n```", "```py\n(cookbook3) % python -m pip install pydantic\n```", "```py\n[2016-06-15 17:57:54,715] INFO in ch10_r10: Sample Message One \n\n[2016-06-15 17:57:54,716] DEBUG in ch10_r10: Debugging \n\n[2016-06-15 17:57:54,720] WARNING in ch10_r10: Something might have gone wrong\n```", "```py\n    import datetime \n\n    from enum import StrEnum \n\n    from typing import Annotated \n\n    from pydantic import BaseModel, Field\n    ```", "```py\n    class LevelClass(StrEnum): \n\n        DEBUG = \"DEBUG\" \n\n        INFO = \"INFO\" \n\n        WARNING = \"WARNING\" \n\n        ERROR = \"ERROR\"\n    ```", "```py\n    class LogData(BaseModel):\n    ```", "```py\n        date: datetime.datetime \n\n        level: LevelClass \n\n        module: Annotated[str, Field(pattern=r’^\\w+$’)] \n\n        message: str\n    ```", "```py\nfrom typing import Iterable, Iterator \n\ndef logdata_iter(source: Iterable[str]) -> Iterator[LogData]: \n\n    for row in source: \n\n        if match := pattern.match(row): \n\n            l = LogData.model_validate(match.groupdict()) \n\n            yield l\n```", "```py\n>>> from pprint import pprint \n\n>>> pprint(list(logdata_iter(data.splitlines()))) \n\n[LogData(date=datetime.datetime(2016, 6, 15, 17, 57, 54, 715000), level=<LevelClass.INFO: ’INFO’>, module=’ch10_r10’, message=’Sample Message One’), \n\n LogData(date=datetime.datetime(2016, 6, 15, 17, 57, 54, 716000), level=<LevelClass.DEBUG: ’DEBUG’>, module=’ch10_r10’, message=’Debugging’), \n\n LogData(date=datetime.datetime(2016, 6, 15, 17, 57, 54, 720000), level=<LevelClass.WARNING: ’WARNING’>, module=’ch10_r10’, message=’Something might have gone wrong’)]\n```", "```py\n>>> import json \n\n>>> print(json.dumps(LogData.model_json_schema(), indent=2))\n```", "```py\n>>> for record in logdata_iter(data.splitlines()): \n\n...     print(record.model_dump_json()) \n\n{\"date\":\"2016-06-15T17:57:54.715000\",\"level\":\"INFO\",\"module\":\"ch10_r10\",\"message\":\"Sample Message One\"} \n\n{\"date\":\"2016-06-15T17:57:54.716000\",\"level\":\"DEBUG\",\"module\":\"ch10_r10\",\"message\":\"Debugging\"} \n\n{\"date\":\"2016-06-15T17:57:54.720000\",\"level\":\"WARNING\",\"module\":\"ch10_r10\",\"message\":\"Something might have gone wrong\"}\n```", "```py\nNOAA/NOS/CO-OPS \n\nDisclaimer: These data are based upon the latest information available as of the date of your request, and may differ from the published tide tables. \n\nDaily Tide Predictions \n\nStationName: EL JOBEAN, MYAKKA RIVER \n\nState: FL \n\nStationid: 8725769 \n\n... \n\nDate           Day    Time    Pred    High/Low \n\n2024/04/01      Mon    04:30  -0.19  L \n\n2024/04/01      Mon    20:07  1.91    H \n\n...\n```", "```py\nimport csv \n\nfrom collections.abc import Iterator \n\nfrom typing import TextIO \n\ndef tide_table_reader(source: TextIO) -> Iterator[dict[str, str]]: \n\n    line_iter = iter(source) \n\n    for line in line_iter: \n\n        if len(line.rstrip()) == 0: \n\n            break \n\n    header = next(line_iter).rstrip().split(’\\t’) \n\n    del header[1]  # Extra tab in the header \n\n    reader = csv.DictReader(line_iter, fieldnames=header, delimiter=’\\t’) \n\n    yield from reader\n```", "```py\n ’Date \\t\\tDay\\tTime\\tPred\\tHigh/Low\\n’\n```", "```py\n    import datetime \n\n    from enum import StrEnum \n\n    from typing import Annotated \n\n    from pydantic import BaseModel, Field, PlainValidator\n    ```", "```py\n    class HighLow(StrEnum): \n\n        high = \"H\" \n\n        low = \"L\"\n    ```", "```py\n    def validate_date(v: str | datetime.date) -> datetime.date: \n\n        match v: \n\n            case datetime.date(): \n\n                return v \n\n            case str(): \n\n                return datetime.datetime.strptime(v, \"%Y/%m/%d\").date() \n\n            case _: \n\n                raise TypeError(\"can’t validate {v!r} of type {type(v)}\")\n    ```", "```py\n    class TideTable(BaseModel): \n\n        date: Annotated[ \n\n            datetime.date, \n\n            Field(validation_alias=’Date ’), \n\n            PlainValidator(validate_date)] \n\n        day: Annotated[ \n\n            str, Field(validation_alias=’Day’)] \n\n        time: Annotated[ \n\n            datetime.time, Field(validation_alias=’Time’)] \n\n        prediction: Annotated[ \n\n            float, Field(validation_alias=’Pred’)] \n\n        high_low: Annotated[ \n\n            HighLow, Field(validation_alias=’High/Low’)]\n    ```", "```py\n>>> tides = [TideTable.model_validate(row) for row in dict_rows] \n\n>>> tides[0] \n\nTideTable(date=datetime.date(2024, 4, 1), day=’Mon’, time=datetime.time(4, 30), prediction=-0.19, high_low=<HighLow.low: ’L’>) \n\n>>> tides[-1] \n\nTideTable(date=datetime.date(2024, 4, 30), day=’Tue’, time=datetime.time(19, 57), prediction=1.98, high_low=<HighLow.high: ’H’>)\n```", "```py\n    date: Annotated[ \n\n        datetime.date, \n\n        Field(validation_alias=’Date ’), \n\n        PlainValidator(validate_date)]\n```", "```py\n    BaseModel, Field, PlainValidator, AfterValidator, ValidationError \n\n) \n\ndef pass_high_tide(hl: HighLow) -> HighLow: \n\n    assert hl == HighLow.high, f\"rejected low tide\" \n\n    return hl\n```", "```py\ndef pass_daylight(time: datetime.time) -> datetime.time: \n\n    assert datetime.time(10, 0) <= time <= datetime.time(17, 0) \n\n    return time\n```", "```py\nclass HighTideTable(BaseModel): \n\n    date: Annotated[ \n\n        datetime.date, \n\n        Field(validation_alias=’Date ’), \n\n        PlainValidator(validate_date)] \n\n    time: Annotated[ \n\n        datetime.time, \n\n        Field(validation_alias=’Time’), \n\n        AfterValidator(pass_daylight)]  # Range check \n\n    prediction: Annotated[ \n\n        float, \n\n        Field(validation_alias=’Pred’, ge=1.5)]  # Minimum check \n\n    high_low: Annotated[ \n\n        HighLow, \n\n        Field(validation_alias=’High/Low’), \n\n        AfterValidator(pass_high_tide)]  # Required value check\n```", "```py\n>>> from pathlib import Path \n\n>>> data = Path(\"data\") / \"tide-table-2024.txt\" \n\n>>> with open(data) as tide_file: \n\n...     for ht in high_tide_iter(tide_table_reader(tide_file)): \n\n...         print(repr(ht)) \n\nHighTideTable(date=datetime.date(2024, 4, 7), time=datetime.time(15, 42), prediction=1.55, high_low=<HighLow.high: ’H’>) \n\n... \n\nHighTideTable(date=datetime.date(2024, 4, 10), time=datetime.time(16, 42), prediction=2.1, high_low=<HighLow.high: ’H’>) \n\n... \n\nHighTideTable(date=datetime.date(2024, 4, 26), time=datetime.time(16, 41), prediction=2.19, high_low=<HighLow.high: ’H’>)\n```"]