["```py\n$ export SCRIPT='\"\".join(str(i) for i in range(10000))'\n\n$ for p in pypy3 pyston python3.{8..10}; do echo -n \"$p: \"; $p -m timeit \"$SCRIPT\"; done\npypy3: ... 2000 loops, average of 7: 179 +- 6.05 usec per loop ...\npyston: 500 loops, best of 5: 817 usec per loop\npython3.8: 200 loops, best of 5: 1.21 msec per loop\npython3.9: 200 loops, best of 5: 1.64 msec per loop\npython3.10: 200 loops, best of 5: 1.14 msec per loop \n```", "```py\n$ python3 -m timeit 'x=[]; [x.insert(0, i) for i in range(10000)]'\n10 loops, best of 3: 30.2 msec per loop\n$ python3 -m timeit 'x=[]; [x.append(i) for i in range(10000)]'\n1000 loops, best of 3: 1.01 msec per loop\n$ python3 -m timeit 'x=[i for i in range(10000)]'\n1000 loops, best of 3: 381 usec per loop\n$ python3 -m timeit 'x=list(range(10000))'\n10000 loops, best of 3: 212 usec per loop \n```", "```py\nimport timeit\n\ndef test_list():\n    return list(range(10000))\n\ndef test_list_comprehension():\n    return [i for i in range(10000)]\n\ndef test_append():\n    x = []\n    for i in range(10000):\n        x.append(i)\n\n    return x\n\ndef test_insert():\n    x = []\n    for i in range(10000):\n        x.insert(0, i)\n\n    return x\n\ndef benchmark(function, number=100, repeat=10):\n    # Measure the execution times. Passing the globals() is an\n    # easy way to make the functions available.\n    times = timeit.repeat(function, number=number,\n                          globals=globals())\n    # The repeat function gives 'repeat' results so we take the\n    # min() and divide it by the number of runs\n    time = min(times) / number\n    print(f'{number} loops, best of {repeat}: {time:9.6f}s :: ',\n          function.__name__)\n\nif __name__ == '__main__':\n    benchmark(test_list)\n    benchmark(test_list_comprehension)\n    benchmark(test_append)\n    benchmark(test_insert) \n```", "```py\n$ python3 T_00_timeit.py\n100 loops, best of 10:  0.000168s ::  test_list\n100 loops, best of 10:  0.000322s ::  test_list_comprehension\n100 loops, best of 10:  0.000573s ::  test_append\n100 loops, best of 10:  0.027552s ::  test_insert \n```", "```py\ndef autorange_benchmark(function):\n    def print_result(number, time_taken):\n        # The autorange function keeps trying until the total\n        # runtime (time_taken) reaches 0.2 seconds. To get the\n        # time per run we need to divide it by the number of runs\n        time = time_taken / number\n        name = function.__name__\n        print(f'{number} loops, average: {time:9.6f}s :: {name}')\n\n    # Measure the execution times. Passing the globals() is an\n    # easy way to make the functions available.\n    timer = timeit.Timer(function, globals=globals())\n    timer.autorange(print_result) \n```", "```py\n$ ipython\nIn [1]: %timeit x=[]; [x.insert(0, i) for i in range(100000)]\n2.5 s ± 112 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\nIn [2]: %timeit x=[]; [x.append(i) for i in range(100000)]\n6.67 ms ± 252 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) \n```", "```py\nimport timeit\n\ntimeit.main(args=['[x for x in range(1000000)]']) \n```", "```py\n$ python3 -m timeit '[x for x in range(1000000)]' \n```", "```py\nimport gc\nimport time\nimport functools\n\nassert time\n\nTIMEIT_TEMPLATE = '''\ndef run(number):\n    {setup}\n    start = time.perf_counter()\n    for i in range(number):\n        {statement}\n    stop = time.perf_counter()\n    return stop - start\n'''\n\ndef timeit(statement, setup='', number=1000000, globals_=None):\n    # Get or create globals\n    globals_ = globals() if globals_ is None else globals_\n\n    # Create the test code so we can separate the namespace\n    src = TIMEIT_TEMPLATE.format(\n        statement=statement,\n        setup=setup,\n        number=number,\n    )\n    # Compile the source\n    code = compile(src, '<source>', 'exec')\n\n    # Define locals for the benchmarked code\n    locals_ = {}\n\n    # Execute the code so we can get the benchmark fuction\n    exec(code, globals_, locals_)\n\n    # Get the run function from locals() which was added by 'exec'\n    run = functools.partial(locals_['run'], number=number)\n\n    # Disable garbage collection to prevent skewing results\n    gc.disable()\n    try:\n        result = run()\n    finally:\n        gc.enable()\n\n    return result \n```", "```py\n>>> from T_02_custom_timeit import timeit\n\n>>> statement = '[x for x in range(100)]'\n\n>>> print('{:.7f}'.format(timeit(statement, number=1)))\n0.0000064\n>>> print('{:.7f}'.format(timeit(statement) / 1000000))\n0.0000029\n>>> print('{:.7f}'.format(timeit(statement, number=1)))\n0.0000287\n>>> print('{:.7f}'.format(timeit(statement) / 1000000))\n0.0000029 \n```", "```py\n[timeit(statement) for _ in range(repeat)] \n```", "```py\nprofile/cProfile modules are only useful for relative results because profiling increases the runtime. There are ways to make the results more accurate, but more about that later.\n```", "```py\nimport sys\nimport functools\n\n@functools.lru_cache()\ndef fibonacci_cached(n):\n    if n < 2:\n        return n\n    else:\n        return fibonacci_cached(n - 1) + fibonacci_cached(n - 2)\n\ndef fibonacci(n):\n    if n < 2:\n        return n\n    else:\n        return fibonacci(n - 1) + fibonacci(n - 2)\n\nif __name__ == '__main__':\n    n = 30\n    if sys.argv[-1] == 'cache':\n        fibonacci_cached(n)\n    else:\n        fibonacci(n) \n```", "```py\n$ python3 -m cProfile T_03_profile_fibonacci.py no_cache\n   2692557 function calls (21 primitive calls) in 0.596 seconds\n\n   Ordered by: standard name\n\n   ncalls tottime cumtime filename:lineno(function)\n        1   0.000   0.596 T_03_profile_fibonacci.py:1(<module>)\n2692537/1   0.596   0.596 T_03_profile_fibonacci.py:13(fibonacci)\n        1   0.000   0.000 functools.py:35(update_wrapper)\n        1   0.000   0.000 functools.py:479(lru_cache)\n        1   0.000   0.000 functools.py:518(decorating_function)\n        1   0.000   0.596 {built-in method builtins.exec}\n        7   0.000   0.000 {built-in method builtins.getattr}\n        1   0.000   0.000 {built-in method builtins.isinstance}\n        5   0.000   0.000 {built-in method builtins.setattr}\n        1   0.000   0.000 {method 'disable' of '_lsprof.Profile...\n        1   0.000   0.000 {method 'update' of 'dict' objects} \n```", "```py\n$ python3 -m cProfile T_03_profile_fibonacci.py cache\n         51 function calls (21 primitive calls) in 0.000 seconds\n\n   Ordered by: standard name\n\nncalls tottime cumtime filename:lineno(function)\n     1  0.000  0.000 T_03_profile_fibonacci.py:1(<module>)\n  31/1  0.000  0.000 T_03_profile_fibonacci.py:5(fibonacci_cached)\n     1  0.000  0.000 functools.py:35(update_wrapper)\n     1  0.000  0.000 functools.py:479(lru_cache)\n     1  0.000  0.000 functools.py:518(decorating_function)\n     1  0.000  0.000 {built-in method builtins.exec}\n     7  0.000  0.000 {built-in method builtins.getattr}\n     1  0.000  0.000 {built-in method builtins.isinstance}\n     5  0.000  0.000 {built-in method builtins.setattr}\n     1  0.000  0.000 {method 'disable' of '_lsprof.Profiler' ...}\n     1  0.000  0.000 {method 'update' of 'dict' objects} \n```", "```py\n$ python3 -m profile T_03_profile_fibonacci.py no_cache\n         2692558 function calls (22 primitive calls) in 4.541 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime cumtime filename:lineno(function)\n        1    0.000   4.530 :0(exec)\n        7    0.000   0.000 :0(getattr)\n        1    0.000   0.000 :0(isinstance)\n        5    0.000   0.000 :0(setattr)\n        1    0.010   0.010 :0(setprofile)\n        1    0.000   0.000 :0(update)\n        1    0.000   4.530 T_03_profile_fibonacci.py:1(<module>)\n2692537/1    4.530   4.530 T_03_profile_fibonacci.py:13(fibonacci)\n        1    0.000   0.000 functools.py:35(update_wrapper)\n        1    0.000   0.000 functools.py:479(lru_cache)\n        1    0.000   0.000 functools.py:518(decorating_function)\n        1    0.000   4.541 profile:0(<code object <module> at ...\n        0    0.000   0.000 profile:0(profiler) \n```", "```py\nimport profile\n\nif __name__ == '__main__':\n    profiler = profile.Profile()\n    for i in range(10):\n        print(profiler.calibrate(100000)) \n```", "```py\nimport profile\n\n# The number here is bias calculated earlier\nprofile.Profile.bias = 9.809351906482531e-07 \n```", "```py\nimport profile\n\nprofiler = profile.Profile(bias=9.809351906482531e-07) \n```", "```py\nimport sys\nimport pstats\nimport profile\n\n...\nif __name__ == '__main__':\n    profiler = profile.Profile(bias=9.809351906482531e-07)\n    n = 30\n\n    if sys.argv[-1] == 'cache':\n        profiler.runcall(fibonacci_cached, n)\n    else:\n        profiler.runcall(fibonacci, n)\n\n    stats = pstats.Stats(profiler).sort_stats('calls')\n    stats.print_stats() \n```", "```py\n$ python3 T_05_profiler_large_bias.py\n      2692539 function calls (3 primitive calls) in -0.746 seconds\n\n   Ordered by: call count\n\n   ncalls tottime cumtime filename:lineno(function)\n2692537/1  -0.747  -0.747 T_05_profiler..._bias.py:15(fibonacci)\n        1   0.000  -0.746 profile:0(<function fibonacci at ...>)\n        1   0.000   0.000 :0(setprofile)\n        0   0.000   0.000 profile:0(profiler) \n```", "```py\nimport profile\n\nif __name__ == '__main__':\n    profiler = profile.Profile()\n    profiler.bias = profiler.calibrate(100000) \n```", "```py\nprofile module. The only cost is the duration of the calibrate() run, and with a small number of trials (say, 10000), it only takes about 0.2 seconds on my current system while still greatly increasing the accuracy of the results. Because of this properly calculated bias, the results can actually be more accurate than the cProfile module.\n```", "```py\nimport cProfile\nimport datetime\nimport functools\n\ndef timer(function):\n    @functools.wraps(function)\n    def _timer(*args, **kwargs):\n        start = datetime.datetime.now()\n        try:\n            return function(*args, **kwargs)\n        finally:\n            end = datetime.datetime.now()\n            print(f'{function.__name__}: {end - start}')\n\n    return _timer\n\ndef profiler(function):\n    @functools.wraps(function)\n    def _profiler(*args, **kwargs):\n        profiler = cProfile.Profile()\n        try:\n            profiler.enable()\n            return function(*args, **kwargs)\n        finally:\n            profiler.disable()\n            profiler.print_stats()\n\n    return _profiler \n```", "```py\n@profiler\ndef profiled_fibonacci(n):\n    return fibonacci(n)\n\n@timer\ndef timed_fibonacci(n):\n    return fibonacci(n)\ndef fibonacci(n):\n    if n < 2:\n        return n\n    else:\n        return fibonacci(n - 1) + fibonacci(n - 2)\n\nif __name__ == '__main__':\n    timed_fibonacci(32)\n    profiled_fibonacci(32) \n```", "```py\n$ python3 T_06_selective_profiling.py\ntimed_fibonacci: 0:00:00.744912\n         7049157 function calls (3 primitive calls) in 1.675 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime cumtime filename:lineno(function)\n        1    0.000   1.675 T_06_select...py:31(profiled_fibonacci)\n7049155/1    1.675   1.675 T_06_selec...profiling.py:41(fibonacci)\n        1    0.000   0.000 {method 'disable' of '_lsprof.Profil... \n```", "```py\n$ pip3 install pyperformance \n```", "```py\nimport sys\nimport pathlib\nimport pstats\nimport cProfile\n\nimport pyperformance\n\n# pyperformance doesn't expose the benchmarks anymore so we need\n# to manually add the path\npyperformance_path = pathlib.Path(pyperformance.__file__).parent\nsys.path.append(str(pyperformance_path / 'data-files'))\n\n# Now we can import the benchmark\nfrom benchmarks.bm_float import run_benchmark as bm_float  # noqa\n\ndef benchmark():\n    for i in range(10):\n        bm_float.benchmark(bm_float.POINTS)\n\nif __name__ == '__main__':\n    profiler = cProfile.Profile()\n    profiler.runcall(benchmark)\n    profiler.dump_stats('bm_float.profile')\n    stats = pstats.Stats('bm_float.profile')\n    stats.strip_dirs()\n    stats.sort_stats('calls', 'cumtime')\n    stats.print_stats(10) \n```", "```py\n$ python3 T_07_profile_statistics.py\nSun May  1 06:14:26 2022    bm_float.profile\n\n         6000012 function calls in 2.501 seconds\n\n   Ordered by: call count, cumulative time\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n  1000000    0.446    0.000    0.682    0.000 run_benchmark.py:15(__init__)\n  1000000    0.525    0.000    0.599    0.000 run_benchmark.py:23(normalize)\n  1000000    0.120    0.000    0.120    0.000 {built-in method math.cos}\n  1000000    0.116    0.000    0.116    0.000 {built-in method math.sin}\n  1000000    0.073    0.000    0.073    0.000 {built-in method math.sqrt}\n   999990    0.375    0.000    0.375    0.000 run_benchmark.py:32(maximize)\n       10    0.625    0.063    2.446    0.245 run_benchmark.py:46(benchmark)\n       10    0.165    0.017    0.540    0.054 run_benchmark.py:39(maximize)\n        1    0.055    0.055    2.501    2.501 T_07_profile_statistics.py:17(benchmark)\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects} \n```", "```py\n$ pyprof2calltree -i bm_float.profile -o bm_float.callgrind\nwriting converted data to: bm_float.callgrind\n$ qcachegrind bm_float.callgrind \n```", "```py\n$ pip3 install line_profiler \n```", "```py\nimport itertools\n\n@profile\ndef primes():\n    n = 2\n    primes = set()\n    while True:\n        for p in primes:\n            if n % p == 0:\n                break\n        else:\n            primes.add(n)\n            yield n\n        n += 1\n\nif __name__ == '__main__':\n    total = 0\n    n = 2000\n    for prime in itertools.islice(primes(), n):\n        total += prime\n\n    print('The sum of the first %d primes is %d' % (n, total)) \n```", "```py\n$ kernprof --line-by-line T_08_line_profiler.py\nThe sum of the first 2000 primes is 16274627\nWrote profile results to T_08_line_profiler.py.lprof \n```", "```py\n$ python3 -m line_profiler T_08_line_profiler.py.lprof\nTimer unit: 1e-06 s\n\nTotal time: 1.34623 s\nFile: T_08_line_profiler.py\nFunction: primes at line 4\n   Hits         Time  Per Hit   % Time  Line Contents\n=====================================================\n                                        @profile\n                                        def primes():\n      1          3.0      3.0      0.0      n = 2\n      1          1.0      1.0      0.0      primes = set()\n                                            while True:\n2055131     625266.0      0.3     46.4          for p in primes:\n2053131     707403.0      0.3     52.5              if n % p == 0:\n  15388       4893.0      0.3      0.4                  break\n                                                else:\n   2000       1519.0      0.8      0.1              primes.add(n)\n   2000        636.0      0.3      0.0              yield n\n  17387       6510.0      0.4      0.5          n += 1 \n```", "```py\nIn [1]: a = list(range(1000000))\n\nIn [2]: b = dict.fromkeys(range(1000000))\n\nIn [3]: %timeit 'x' in a\n12.2 ms ± 245 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\nIn [4]: %timeit 'x' in b\n40.1 ns ± 0.446 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) \n```", "```py\nif some_key in some_dict:\n    process_value(some_dict[some_key]) \n```", "```py\ntry:\n    process_value(some_dict[some_key])\nexcept KeyError:\n    pass \n```", "```py\ntry:\n    value = some_dict[some_key]\nexcept KeyError:\n    pass\nelse:\n    process_value(value) \n```", "```py\n>>> import itertools\n\n# Without itertools.tee:\n>>> generator = itertools.count()\n>>> list(itertools.islice(generator, 5))\n[0, 1, 2, 3, 4]\n>>> list(itertools.islice(generator, 5))\n[5, 6, 7, 8, 9]\n\n>>> generator_a, generator_b = itertools.tee(itertools.count())\n>>> list(itertools.islice(generator_a, 5))\n[0, 1, 2, 3, 4]\n>>> list(itertools.islice(generator_b, 5))\n[0, 1, 2, 3, 4] \n```", "```py\nIn [1]: %%timeit\n   ...: s = ''\n   ...: for i in range(1000000):\n   ...:     s += str(i)\n   ...:\n1 loops, best of 3: 362 ms per loop\n\nIn [2]: %%timeit\n   ...: ss = []\n   ...: for i in range(1000000):\n   ...:     ss.append(str(i))\n   ...: s = ''.join(ss)\n   ...:\n1 loops, best of 3: 332 ms per loop\n\nIn [3]: %timeit ''.join(str(i) for i in range(1000000))\n1 loops, best of 3: 324 ms per loop\n\nIn [4]: %timeit ''.join([str(i) for i in range(1000000)])\n1 loops, best of 3: 294 ms per loop \n```", "```py\nIn [1]: %%timeit\n   ...: x = 0\n   ...: for i in range(1000000):\n   ...:     x += i\n   ...:\n10 loops, best of 3: 73.2 ms per loop\n\nIn [2]: %timeit x = sum(i for i in range(1000000))\n10 loops, best of 3: 75.3 ms per loop\n\nIn [3]: %timeit x = sum([i for i in range(1000000)])\n10 loops, best of 3: 71.2 ms per loop\n\nIn [4]: %timeit x = sum(range(1000000))\n10 loops, best of 3: 25.6 ms per loop \n```", "```py\nIn [1]: %timeit list(map(lambda x: x/2, range(1000000)))\n10 loops, best of 3: 182 ms per loop\n\nIn [2]: %timeit list(x/2 for x in range(1000000))\n10 loops, best of 3: 122 ms per loop\n\nIn [3]: %timeit [x/2 for x in range(1000000)]\n10 loops, best of 3: 84.7 ms per loop \n```", "```py\nimport timeit\nimport functools\n\nclass WithSlots:\n    __slots__ = 'eggs',\n\nclass WithoutSlots:\n    pass\n\nwith_slots = WithSlots()\nno_slots = WithoutSlots()\n\ndef test_set(obj):\n    obj.eggs = 5\n\ndef test_get(obj):\n    return obj.eggs\n\ntimer = functools.partial(\n    timeit.timeit,\n    number=20000000,\n    setup='\\n'.join((\n        f'from {__name__} import with_slots, no_slots',\n        f'from {__name__} import test_get, test_set',\n    )),\n)\nfor function in 'test_set', 'test_get':\n    print(function)\n    print('with slots', timer(f'{function}(with_slots)'))\n    print('with slots', timer(f'{function}(no_slots)')) \n```", "```py\n$ python3 T_10_slots_performance.py\ntest_set\nwith slots 1.748628467\nwith slots 2.0184642979999996\ntest_get\nwith slots 1.5832197570000002\nwith slots 1.6575410809999997 \n```", "```py\nIn [1]: import numpy\n\nIn [2]: a = list(range(1000000))\n\nIn [3]: b = numpy.arange(1000000)\n\nIn [4]: %timeit c = [x for x in a if x > 500000]\n10 loops, best of 3: 44 ms per loop\n\nIn [5]: %timeit d = b[b > 500000]\n1000 loops, best of 3: 1.61 ms per loop \n```", "```py\nimport numba\n\n@numba.jit\ndef sum(array):\n    total = 0.0\n    for value in array:\n        total += value\n    return value \n```", "```py\ncdef inline double recip_square(int i):\n    return 1./(i*i)\n\ndef approx_pi(int n=10000000):\n    cdef double val = 0.\n    cdef int k\n    for k in range(1,n+1):\n        val += recip_square(k)\n    return (6 * val)**.5 \n```", "```py\nimport tracemalloc\n\nif __name__ == '__main__':\n    tracemalloc.start()\n\n    # Reserve some memory\n    x = list(range(1000000))\n\n    # Import some modules\n    import os\n    import sys\n    import asyncio\n\n    # Take a snapshot to calculate the memory usage\n    snapshot = tracemalloc.take_snapshot()\n    for statistic in snapshot.statistics('lineno')[:10]:\n        print(statistic) \n```", "```py\n$ python3 T_11_tracemalloc.py\nT_11_tracemalloc.py:8: size=34.3 MiB, count=999746, average=36 B\n<frozen importlib._bootstrap_external>:587: size=1978 KiB, coun...\n<frozen importlib._bootstrap>:228: size=607 KiB, count=5433, av...\nabc.py:85: size=32.6 KiB, count=155, average=215 B\nenum.py:172: size=26.2 KiB, count=134, average=200 B\ncollections/__init__.py:496: size=24.1 KiB, count=117, average=...\nenum.py:225: size=23.3 KiB, count=451, average=53 B\nenum.py:391: size=15.0 KiB, count=21, average=729 B\n<frozen importlib._bootstrap_external>:64: size=14.3 KiB, count...\nenum.py:220: size=12.2 KiB, count=223, average=56 B \n```", "```py\nimport memory_profiler\n\n@memory_profiler.profile\ndef main():\n    n = 100000\n    a = [i for i in range(n)]\n    b = [i for i in range(n)]\n    c = list(range(n))\n    d = list(range(n))\n    e = dict.fromkeys(a, b)\n    f = dict.fromkeys(c, d)\n\nif __name__ == '__main__':\n    main() \n```", "```py\nFilename: CH_12_performance/T_12_memory_profiler.py\n\nMem usage  Increment  Occurrences  Line Contents\n===============================================\n 14.7 MiB   14.7 MiB           1  @memory_profiler.profile\n                                  def main():\n 14.7 MiB    0.0 MiB           1      n = 100000\n 18.5 MiB    3.8 MiB      100003      a = [i for i in range(n)]\n 22.4 MiB    3.9 MiB      100003      b = [i for i in range(n)]\n 26.3 MiB    3.9 MiB           1      c = list(range(n))\n 30.2 MiB    3.9 MiB           1      d = list(range(n))\n 39.9 MiB    9.8 MiB           1      e = dict.fromkeys(a, b)\n 44.9 MiB    5.0 MiB           1      f = dict.fromkeys(c, d)\n 44.9 MiB    0.0 MiB           1      assert e\n 44.9 MiB    0.0 MiB           1      assert f \n```", "```py\n 1 import tracemalloc\n  2\n  3\n  4 class SomeClass:\n  5     pass\n  6\n  7\n  8 if __name__ == '__main__':\n  9     # Initialize some variables to ignore them from the leak\n 10     # detection\n 11     n = 100000\n 12\n 13     tracemalloc.start()\n 14     # Your application should initialize here\n 15\n 16     snapshot_a = tracemalloc.take_snapshot()\n 17     instances = []\n 18\n 19     # This code should be the memory leaking part\n 20     for i in range(n):\n 21         a = SomeClass()\n 22         b = SomeClass()\n 23         # Circular reference. a references b, b references a\n 24         a.b = b\n 25         b.a = a\n 26         # Force Python to keep the object in memory for now\n 27         instances.append(a)\n 28\n 29     # Clear the list of items again. Now all memory should be\n 30     # released, right?\n 31     del instances\n 32     snapshot_b = tracemalloc.take_snapshot()\n 33\n 34     statistics = snapshot_b.compare_to(snapshot_a, 'lineno')\n 35     for statistic in statistics[:10]:\n 36         print(statistic) \n```", "```py\n$ python3 T_12_memory_leaks.py\nT_12_memory_leaks.py:25: size=22.1 MiB (+22.1 MiB), count=199992 (+199992), average=116 B\nT_12_memory_leaks.py:24: size=22.1 MiB (+22.1 MiB), count=199992 (+199992), average=116 B\nT_12_memory_leaks.py:22: size=4688 KiB (+4688 KiB), count=100000 (+100000), average=48 B\nT_12_memory_leaks.py:21: size=4688 KiB (+4688 KiB), count=100000 (+100000), average=48 B\ntracemalloc.py:423: size=88 B (+88 B), count=2 (+2), average=44 B\ntracemalloc.py:560: size=48 B (+48 B), count=1 (+1), average=48 B\ntracemalloc.py:315: size=40 B (+40 B), count=1 (+1), average=40 B\nT_12_memory_leaks.py:20: size=28 B (+28 B), count=1 (+1), average=28 B \n```", "```py\nimport gc\n\nclass SomeClass(object):\n    def __init__(self, name):\n        self.name = name\n\n    def __repr__(self):\n        return f'<{self.__class__.__name__}: {self.name}'\n\n# Create the objects\na = SomeClass('a')\nb = SomeClass('b')\n# Add some circular references\na.b = a\nb.a = b\n\n# Remove the objects\ndel a\ndel b\n\n# See if the objects are still there\nprint('Before manual collection:')\nfor object_ in gc.get_objects():\n    if isinstance(object_, SomeClass):\n        print('\\t', object_, gc.get_referents(object_))\n\nprint('After manual collection:')\ngc.collect()\nfor object_ in gc.get_objects():\n    if isinstance(object_, SomeClass):\n        print('\\t', object_, gc.get_referents(object_))\n\nprint('Thresholds:', gc.get_threshold()) \n```", "```py\n$ python3 T_14_garbage_collection.py\nBefore manual collection:\n         <SomeClass: a> [{'name': 'a', 'b': <SomeClass: a>}, <class '__main__.SomeClass'>]\n         <SomeClass: b> [{'name': 'b', 'a': <SomeClass: b>}, <class '__main__.SomeClass'>]\nAfter manual collection:\nThresholds: (700, 10, 10) \n```", "```py\nimport gc\nimport collections\nif __name__ == '__main__':\n    objects = collections.Counter()\n    for object_ in gc.get_objects():\n        objects[type(object_)] += 1\n\n    print(f'Different object count: {len(objects)}')\n    for object_, count in objects.most_common(10):\n        print(f'{count}: {object_}') \n```", "```py\n$ python3 T_15_garbage_collection_viewing.py\nDifferent object count: 42\n1058: <class 'wrapper_descriptor'>\n887: <class 'function'>\n677: <class 'method_descriptor'>\n652: <class 'builtin_function_or_method'>\n545: <class 'dict'>\n484: <class 'tuple'>\n431: <class 'weakref'>\n251: <class 'member_descriptor'>\n238: <class 'getset_descriptor'>\n76: <class 'type'> \n```", "```py\nimport gc\nimport weakref\nclass SomeClass(object):\n    def __init__(self, name):\n        self.name = name\n\n    def __repr__(self):\n        return '<%s: %s>' % (self.__class__.__name__, self.name)\n\ndef print_mem(message):\n    print(message)\n    for object_ in gc.get_objects():\n        if isinstance(object_, SomeClass):\n            print('\\t', object_, gc.get_referents(object_))\n\n# Create the objects\na = SomeClass('a')\nb = SomeClass('b')\n\n# Add some weak circular references\na.b = weakref.ref(a)\nb.a = weakref.ref(b)\n\nprint_mem('Objects in memory before del:')\n\n# Remove the objects\ndel a\ndel b\n\n# See if the objects are still there\nprint_mem('Objects in memory after del:') \n```", "```py\n$ python3 T_16_weak_references.py\nObjects in memory before del:\n         <SomeClass: a> [{'name': 'a', 'b': ...}, ...]\n         <SomeClass: b> [{'name': 'b', 'a': ...}, ...]\nObjects in memory after del: \n```", "```py\n>>> import weakref\n\n>>> weakref.ref(dict(a=123))\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: cannot create weak reference to 'dict' object\n\n>>> weakref.ref([1, 2, 3])\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: cannot create weak reference to 'list' object\n\n>>> weakref.ref('test')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: cannot create weak reference to 'str' object\n\n>>> weakref.ref(b'test')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: cannot create weak reference to 'bytes' object\n\n>>> a = weakref.WeakValueDictionary(a=123)\nTraceback (most recent call last):\n    ...\nTypeError: cannot create weak reference to 'int' object \n```", "```py\n>>> class CustomDict(dict):\n...     pass\n\n>>> weakref.ref(CustomDict())\n<weakref at 0x...; dead> \n```", "```py\n>>> class SomeClass:\n...     def __init__(self, name):\n...         self.name = name\n\n>>> a = SomeClass('a')\n>>> b = weakref.proxy(a)\n>>> b.name\n'a'\n>>> del a\n>>> b.name\nTraceback (most recent call last):\n    ...\nReferenceError: weakly-referenced object no longer exists \n```", "```py\nimport os\nimport psutil\n\ndef print_usage(message):\n    process = psutil.Process(os.getpid())\n    usage = process.memory_info().rss / (1 << 20)\n    print(f'Memory usage {message}: {usage:.1f} MiB')\n\ndef allocate_and_release():\n    # Allocate large block of memory\n    large_list = list(range(1000000))\n    print_usage('after allocation')\n\n    del large_list\n    print_usage('after releasing')\n\nprint_usage('initial')\nallocate_and_release()\nallocate_and_release() \n```", "```py\n$ python3 T_18_freeing_memory.py\nMemory usage initial: 9.4 MiB\nMemory usage after allocation: 48.1 MiB\nMemory usage after releasing: 17.3 MiB\nMemory usage after allocation: 55.7 MiB\nMemory usage after releasing: 25.0 MiB \n```", "```py\nLine #    Mem usage    Increment   Line Contents\n================================================\n     4     11.0 MiB      0.0 MiB   @memory_profiler.profile\n     5                             def main():\n     6     11.0 MiB      0.0 MiB    a = range(1000000)\n     7     49.7 MiB     38.6 MiB    b = list(range(1000000)) \n```", "```py\nMem usage    Increment   Line Contents\n======================================\n 11.5 MiB      0.0 MiB   @memory_profiler.profile\n                         def main():\n                         # Generate a huge dict\n 26.3 MiB     14.8 MiB   a = dict.fromkeys(range(100000))\n\n                         # Remove all items\n 26.3 MiB      0.0 MiB   for k in list(a.keys()):\n 26.3 MiB      0.0 MiB   del a[k]\n\n                         # Recreate the dict\n 23.6 MiB     -2.8 MiB   a = dict((k, v) for k, v in a.items()) \n```", "```py\nimport memory_profiler\n\nclass Slots(object):\n    __slots__ = 'index', 'name', 'description'\n\n    def __init__(self, index):\n        self.index = index\n        self.name = 'slot %d' % index\n        self.description = 'some slot with index %d' % index\n\nclass NoSlots(object):\n    def __init__(self, index):\n        self.index = index\n        self.name = 'slot %d' % index\n        self.description = 'some slot with index %d' % index\n\n@memory_profiler.profile\ndef main():\n    slots = [Slots(i) for i in range(25000)]\n    no_slots = [NoSlots(i) for i in range(25000)]\n    return slots, no_slots\n\nif __name__ == '__main__':\n    main() \n```", "```py\nMem usage Increment Occurrences Line Contents\n============================================\n38.4 MiB  38.4 MiB          1 @memory_profiler.profile\n                              def main():\n44.3 MiB   5.9 MiB      25003     slots = [Slots(i) for i in range(25000)]\n52.4 MiB   8.1 MiB      25003     no_slots = [NoSlots(i) for i in range(25000)]\n52.4 MiB   0.0 MiB          1     return slots, no_slots \n```"]