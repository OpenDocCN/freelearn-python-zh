<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch03"/>Chapter 3. C Performance with Cython</h1></div></div></div><p>Cython is a language that extends Python by adding static typing to functions, variables, and classes. Cython <a class="indexterm" id="id105"/>combines the simplicity of Python and the efficiency of C. After rewriting your scripts in Cython you can compile them to C or C++, generating efficient code in a straightforward way.</p><p>Cython also acts as a bridge between Python and C, as it can be used to create interfaces to external C code. By creating bindings, you can reuse fast C routines in your scripts, effectively using Python as a glue language.</p><p>In this chapter we will learn:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Cython syntax basics</li><li class="listitem" style="list-style-type: disc">How to compile Cython programs</li><li class="listitem" style="list-style-type: disc">How to use <strong>static typing</strong> to generate fast code</li><li class="listitem" style="list-style-type: disc">How to efficiently manipulate arrays by making use of typed <strong>memoryviews.</strong></li></ul></div><p>Finally, we will apply our new Cython skills to profile and optimize the particle simulator.</p><p>While a minimum knowledge of C is helpful, this chapter focuses only on Cython in the context of Python optimization. Therefore, it doesn't require any C background.</p><div><div><div><div><h1 class="title"><a id="ch03lvl1sec25"/>Compiling Cython extensions</h1></div></div></div><p>By design, the Cython syntax<a class="indexterm" id="id106"/> is a superset of Python. Cython can typically compile a Python module without requiring any change. Cython source files have<a class="indexterm" id="id107"/> the extension <code class="literal">.pyx</code> and they can be compiled to C using the <code class="literal">cython</code> command.</p><p>Our first Cython script will contain a simple function that prints <em>Hello, World!</em> to the output. Create a new file <code class="literal">hello.pyx</code> containing the following code:</p><div><pre class="programlisting">def hello():
  print('Hello, World!')</pre></div><p>The <code class="literal">cython</code> command<a class="indexterm" id="id108"/> will read <code class="literal">hello.pyx</code> and generate the <code class="literal">hello.c</code> file:</p><div><pre class="programlisting">
$ cython hello.pyx
</pre></div><p>To compile <code class="literal">hello.c</code> to a Python extension module we will use the gcc compiler. We need to add some Python-specific compilation options that depend on the operating system. On Ubuntu 13.10, <a class="indexterm" id="id109"/>with the default Python installation, you can <a class="indexterm" id="id110"/>use the following options to compile:</p><div><pre class="programlisting">
$ gcc -shared -pthread -fPIC -fwrapv -O2 -Wall -fno-strict-aliasing -lm -I/usr/include/python3.3/ -o hello.so hello.c
</pre></div><p>This will produce a file called <code class="literal">hello.so</code>: a C extension module importable from Python.</p><div><pre class="programlisting">&gt;&gt;&gt; import hello
&gt;&gt;&gt; hello.hello()
Hello, World!</pre></div><div><div><h3 class="title"><a id="note07"/>Note</h3><p>Cython accepts both Python 2 and Python 3 as input and output languages. In other words, you can compile a Python 3 <code class="literal">hello.pyx</code> file using the <code class="literal">-3</code> option:</p><div><pre class="programlisting">
<strong>$ cython -3 hello.pyx</strong>
</pre></div><p>The generated <code class="literal">hello.c</code> can be compiled without any changes to Python 2 and Python 3 by including the corresponding headers with the <code class="literal">-I</code> option in gcc as follows:</p><div><pre class="programlisting">
$ gcc -I/usr/include/python3.3 # ... other options
$ gcc -I/usr/include/python2.7 # ... other options
</pre></div></div></div><p>A Cython program can be compiled in a more straightforward way by using <code class="literal">distutils</code>—the standard Python packaging tool. By writing a <code class="literal">setup.py</code> script we can compile the <code class="literal">.pyx</code> file directly to an extension module. To compile our <code class="literal">hello.pyx</code> example we need to write a <code class="literal">setup.py</code> containing the following code:</p><div><pre class="programlisting">from distutils.core import setup
from Cython.Build import cythonize

setup(
  name='Hello',ext_modules = cythonize('hello.pyx'),)</pre></div><p>In the first two lines of the previous code, we import the <code class="literal">setup</code> function and the <code class="literal">cythonize</code> helper. The <code class="literal">setup</code> function contains a few key-value pairs that tell <code class="literal">distutils</code> the name of the application and which extensions need to be built.</p><p>The <code class="literal">cythonize</code> helper<a class="indexterm" id="id111"/> takes either a string or a list of strings containing the Cython modules we want to compile. You can also use glob patterns using the following code:</p><div><pre class="programlisting">cythonize(['hello.pyx', 'world.pyx', '*.pyx'])</pre></div><p>To compile our extension module using <code class="literal">distutils</code> you can execute the <code class="literal">setup.py</code> script using the following code:</p><div><pre class="programlisting">
$ python setup.py build_ext --inplace
</pre></div><p>The <code class="literal">build_ext</code> option tells the script to build the extension modules indicated in <code class="literal">ext_modules</code>, and the <code class="literal">--inplace</code> option places the output <code class="literal">hello.so</code> file in the same location as the source file (instead of a build directory).</p><p>Cython modules can automatically<a class="indexterm" id="id112"/> be compiled using <code class="literal">pyximport</code>. By adding <code class="literal">pyximport.install()</code> at the beginning of your script (or issuing the command in your interpreter) you can import <code class="literal">.pyx</code> files directly; <code class="literal">pyximport</code> will transparently compile the corresponding Cython modules.</p><div><pre class="programlisting">&gt;&gt;&gt; import pyximport
&gt;&gt;&gt; pyximport.install()
&gt;&gt;&gt; import hello # This will compile hello.pyx</pre></div><p>Unfortunately, <code class="literal">pyximport</code> will not work for all kinds of configurations (for example when they involve a combination of C and Cython files), but it comes in handy for testing simple scripts.</p><p>Since version 0.13, IPython includes the <code class="literal">cythonmagic</code> extension to interactively write and test a series of Cython statements. You can load the extensions in an IPython shell using <code class="literal">load_ext</code>:</p><div><pre class="programlisting">In [1]: %load_ext cythonmagic</pre></div><p>Once the extension is loaded you can use the <code class="literal">%%cython</code> <em>cell magic</em> to write a multi-line Cython snippet. In the following example, we define a <code class="literal">hello_snippet</code> function<a class="indexterm" id="id113"/> that will be compiled and added to the <code class="literal">session</code> namespace:</p><div><pre class="programlisting">In [2]: <strong>%%cython</strong>
  ....:  def hello_snippet():
   ....:    print("Hello, Cython!")
  ....:
In [3]:  hello_snippet()
Hello,  Cython!</pre></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec26"/>Adding static types</h1></div></div></div><p>In Python, variables have an associated type that can change during the execution. While this feature is desirable, as it makes the language more flexible, the interpreter needs to do type-checks and method look-ups to<a class="indexterm" id="id114"/> correctly handle operations between variables—an extra step that introduces a significant overhead. Cython extends the Python language with static type declarations; in this way it can generate efficient C code by avoiding the Python interpreter.</p><p>The main way to declare data types in Cython is by using <code class="literal">cdef</code> statements. The <a class="indexterm" id="id115"/>
<code class="literal">cdef</code> keyword can be used in multiple contexts: to declare variables, functions, and extension types (<code class="literal">cdef</code>
<em> </em>classes).</p><div><div><div><div><h2 class="title"><a id="ch03lvl2sec09"/>Variables</h2></div></div></div><p>In Cython you can declare the type<a class="indexterm" id="id116"/> of a variable by prepending the variable with <code class="literal">cdef</code> and its respective type. For example, we can declare the variable <code class="literal">i</code> as a 16 bit integer in the following way:</p><div><pre class="programlisting">cdef int i</pre></div><p>The <code class="literal">cdef</code> statement supports multiple<a class="indexterm" id="id117"/> variable names on the same line, along with optional initialization values, as seen in the following line of code:</p><div><pre class="programlisting">cdef double a, b = 2.0, c = 3.0</pre></div><p>Typed variables are treated differently in comparison to standard variables. In Python, variables are often regarded as <em>labels</em> referring to objects in memory. At any point in the program, we can assign a string to a variable as follows:</p><div><pre class="programlisting">a = 'hello'</pre></div><p>The string <em>hello</em> will be bound to the variable <code class="literal">a</code>. At a different place in the program, we can assign to the same variable another value, for example an integer:</p><div><pre class="programlisting">a = 1</pre></div><p>Python will assign the integer object <em>1</em> to the variable <code class="literal">a</code> without any problem.</p><p>Typed variables can be considered more like <em>data containers</em>; we <em>store</em> the value in the variable and only values of the same type are allowed to get in. For example, if we declare the variable <code class="literal">a</code> as an <code class="literal">int</code> type variable, and then we try to assign it to a <code class="literal">double</code>, Cython will trigger an error, as shown in the following code:</p><div><pre class="programlisting">In [4]: %%cython
  ....: cdef int i
  ....: i = 3.0
  ....:
# Output has been cut
...cf4b.pyx:2:4 <strong>Cannot assign type 'double' to 'int'</strong>
</pre></div><p>Static typing allows useful optimizations. If we declare indexes to be used in a loop as integers, Cython will rewrite the loops<a class="indexterm" id="id118"/> in pure C without stepping into the Python interpreter. In the following example, we do an iteration 100 times and each time<a class="indexterm" id="id119"/> we increment the <code class="literal">int</code> variable <code class="literal">j</code>:</p><div><pre class="programlisting">In [5]: %%cython
  ....: def example():
  ....:   cdef int i, j=0
  ....:   for i in range(100):....:      j += 1
  ....:   return j
  ....:
In [6]: example()
Out[6]: 100</pre></div><p>To understand how big the improvement is, we will compare the speed with an analogous, pure Python loop:</p><div><pre class="programlisting">In [7]: def example_python():
  ....:    j=0
  ....:    for i in range(100):....:      j += 1
  ....:    return j
  ....:
In [8]: %timeit example()
10000000 loops, best of 3: <strong>25 ns</strong> per loop
In [9]: %timeit example_python()
100000 loops, best of 3: <strong>2.74 us</strong> per loop</pre></div><p>The speedup obtained by writing the loop with typing information is a whopping 100x! This works because the Cython loop has first been converted to pure C and then to efficient machine code, while the Python loop still relies on the slow interpreter.</p><p>We can declare a variable of any available C type, and we can also define custom types by using C structs, enums, and typedefs. An interesting example is that if we declare a variable to be of <code class="literal">object</code> type, the variable will accept any kind of Python object:</p><div><pre class="programlisting">cdef object a_py
# both 'hello' and 1 are Python objects
a_py = 'hello'
a_py = 1</pre></div><p>Sometimes, certain types of variables are compatible (such as <code class="literal">float</code> and <code class="literal">int</code> numbers) but not exactly<a class="indexterm" id="id120"/> the same. In Cython<a class="indexterm" id="id121"/> it is possible to convert (<em>cast</em>) between types by surrounding the destination type with <code class="literal">&lt;</code> and <code class="literal">&gt;</code> pointy brackets, as shown in the following code snippet:</p><div><pre class="programlisting">cdef int a = 0
cdef double b
b = <strong>&lt;double&gt; a</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec10"/>Functions</h2></div></div></div><p>You can add type information to the arguments of a Python function by specifying the type in front of the argument name. Such<a class="indexterm" id="id122"/> functions will work and perform like a regular Python function but its arguments will be type-checked. We can write a <a class="indexterm" id="id123"/>
<code class="literal">max_python</code> function, which returns the greater value between two integers in the following way:</p><div><pre class="programlisting">def max_python(<strong>int a, int b</strong>):
  return a if a &gt; b else b</pre></div><p>That function doesn't <a class="indexterm" id="id124"/>provide much benefit except for type-checking. To take advantage of Cython optimizations we have to declare the function using a <code class="literal">cdef</code> statement and an optional return type, as in the following code:</p><div><pre class="programlisting">
<strong>cdef int</strong> max_cython(int a, int b):
  return a if a &gt; b else b</pre></div><p>Functions declared in this way are translated to native C functions, which are not callable from Python. They have much less overhead compared to Python functions, and using them results in a substantial increase in performance. Their scope is restricted to the same Cython file, unless they're exposed in a definition file (refer to the <em>Sharing Declarations</em> section).</p><p>Cython allows you to define functions that are both callable from Python and translatable to native C functions. If you declare a function with the keyword <code class="literal">cpdef</code>, Cython will generate two versions of the function—a Python version available to the interpreter, and a fast C function usable from Cython—achieving both convenience and speed. The <code class="literal">cpdef</code> syntax is equivalent to <code class="literal">cdef</code>, shown as follows:</p><div><pre class="programlisting">
<strong>cpdef int</strong> max_hybrid(int a, int b):
  return a if a &gt; b else b</pre></div><p>Sometimes, the call overhead can be a performance issue even with C functions, especially when the same function is called many times in a critical loop. When the function body is small, it<a class="indexterm" id="id125"/> is convenient to add the <code class="literal">inline</code> keyword in front of the function definition; the function<a class="indexterm" id="id126"/> call will be removed and replaced by the function body. For instance, our following <code class="literal">max</code> function is a good candidate for <em>inlining</em>:</p><div><pre class="programlisting">
<strong>cdef inline int</strong> max_inline(int a, int b):
  return a if a &gt; b else b</pre></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec11"/>Classes</h2></div></div></div><p>The<code class="literal"> </code><a class="indexterm" id="id127"/>
<code class="literal">cdef</code> keyword can also be put in front <a class="indexterm" id="id128"/>of a class definition to create an <em>extension type</em>. An extension type is similar to a Python class but its attributes must have a type and are stored in an efficient C <em>struct</em>.</p><p>We can define an extension type by using the <code class="literal">cdef class</code> statement and declaring its attributes in the class body. For example, <a class="indexterm" id="id129"/>we can create an extension type <code class="literal">Point</code>, as shown in the following code, which stores two coordinates (x, y) of type <code class="literal">double</code>:</p><div><pre class="programlisting">
<strong>cdef class Point:</strong>
<strong>  cdef double x</strong>
<strong>  cdef double y</strong>
  
  def __init__(self, double x,double y):
    self.x = x
    self.y = y</pre></div><p>Accessing the declared attributes in the class methods allows Cython to avoid the Python attribute look-up by replacing it with direct access to the <code class="literal">struct</code> fields. In this way, attribute access becomes an extremely fast operation.</p><p>To take advantage of the <code class="literal">struct</code> access, Cython needs to know that the variable is an extension type at the time of compilation. You can use the extension type name (such as <code class="literal">Point</code>) in any context where you would use a standard one (such as <code class="literal">double</code>, <code class="literal">float</code>, <code class="literal">int</code>). For example, if we want a Cython function that calculates the <code class="literal">norm</code> of a <code class="literal">Point</code>, we have to declare the input variable as <code class="literal">Point</code>, as shown in the following code:</p><div><pre class="programlisting">cdef double norm(<strong>Point p</strong>):
  return p.x**2 + p.y**2</pre></div><p>By default, access to the attributes is restricted to Cython code. If you try to access an extension type attribute from Python, you will get an <code class="literal">AttributeError</code> shown as follows:</p><div><pre class="programlisting">&gt;&gt;&gt; a = Point(0.0, 0.0)
&gt;&gt;&gt; a.x
<strong>AttributeError: 'Point' object has no attribute 'x'</strong>
</pre></div><p>In order to access attributes from <a class="indexterm" id="id130"/>Python code you have to use the <code class="literal">public</code> (for read-write access) or <code class="literal">readonly</code> specifiers in the attribute declaration, as shown in the following code:</p><div><pre class="programlisting">cdef class Point:
  cdef <strong>public</strong> double x</pre></div><p>Extension types do not support the addition <a class="indexterm" id="id131"/>of extra attributes. A workaround for this problem is subclassing the extension type, creating a derived Python class.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec27"/>Sharing declarations</h1></div></div></div><p>When writing your Cython modules, you may want to<a class="indexterm" id="id132"/> encapsulate generic functions and types in a separate file. Cython allows you to reuse those components with the <code class="literal">cimport</code> statement by writing a <em>definition file.</em>
</p><p>Let's say we have a module with the functions <code class="literal">max</code> and <code class="literal">min</code>, and we want to reuse those functions in multiple Cython programs. If we simply write a <code class="literal">.pyx</code> file—also called <em>implementation file</em>—the functions declared are confined in the same module.</p><div><div><h3 class="title"><a id="note09"/>Note</h3><p>Definition files are also used to interface Cython with an external C code. The idea is to copy the types and function prototypes in the definition file and leave the implementation to the external C code.</p></div></div><p>To share those functions we need to write a definition file, with a <code class="literal">.pxd</code> extension. Such a file only contains the types and function prototypes that we want share to other modules—a <em>public</em> interface. We can write the prototypes of our <code class="literal">max</code> and <code class="literal">min</code> functions in a file named <code class="literal">mathlib.pxd</code> as follows:</p><div><pre class="programlisting">cdef int max(int a, int b)
cdef int min(int a, int b)</pre></div><p>As you can see, we only write the function name and arguments, without implementing the function body.</p><p>The function implementation goes into the implementation file with the same base name but <code class="literal">.pyx</code> extension—<code class="literal">mathlib.pyx</code>:</p><div><pre class="programlisting">cdef int max(int a, int b):
  return a if a &gt; b else b

cdef int min(int a, int b):
  return a if a &lt; b else b</pre></div><p>The <code class="literal">mathlib</code> module<a class="indexterm" id="id133"/> is now importable from another Cython module.</p><p>To test our Cython module we<a class="indexterm" id="id134"/> will create a file named <code class="literal">distance.pyx</code> containing a function named <code class="literal">chebyshev</code>. The function will calculate the Chebyshev distance between two points, as shown in the following code. The Chebyshev distance between two coordinates (x1, y1) and (x2, y2) is defined as the maximum value of the difference between each coordinate.</p><div><pre class="programlisting">max(abs(x1 – x2), abs(y1 – y2))</pre></div><p>To implement the <code class="literal">chebyshev</code> function<a class="indexterm" id="id135"/> we will use the <code class="literal">max</code> function, declared in <code class="literal">mathlib.pxd</code> by importing it with the <code class="literal">cimport</code> statement, as shown in the following code snippet:</p><div><pre class="programlisting">
<strong>from mathlib cimport max</strong>

def chebyshev(int x1,int y1,int x2,int y2):
  return max(abs(x1 - x2), abs(y1 - y2))</pre></div><p>The <code class="literal">cimport</code> statement will read <code class="literal">hello.pxd</code> and the <code class="literal">max</code> definition will be used to generate the <code class="literal">distance.c</code> file.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec28"/>Working with arrays</h1></div></div></div><p>Numerical and high performance calculations<a class="indexterm" id="id136"/> often make use of arrays. Cython provides an easy way to interact with them, from the low-level approach of C arrays, to the more general <em>typed memoryviews</em>.</p><div><div><div><div><h2 class="title"><a id="ch03lvl2sec12"/>C arrays and pointers</h2></div></div></div><p>C arrays are a collection of<a class="indexterm" id="id137"/> items of the same size stored contiguously in memory. Before digging into the details, it is helpful to understand (or review) how memory is managed in C.</p><p>Variables in C are like containers. <a class="indexterm" id="id138"/>When creating a variable, a space in memory is reserved to store its value. For example, if we <a class="indexterm" id="id139"/>create a variable containing a 64 bit<a class="indexterm" id="id140"/> floating point number (<code class="literal">double</code>), the program will allocate 64 bit (16 bytes) of memory. This portion of memory can be accessed through an address to that memory location.</p><p>To obtain the address of a variable we can use the <em>address operator</em>, denoted with the <code class="literal">&amp;</code> symbol. We can also use the <a class="indexterm" id="id141"/>
<code class="literal">printf</code> function, as follows, available in the <code class="literal">libc.stdio</code> Cython module to print the address <a class="indexterm" id="id142"/>of this variable:</p><div><pre class="programlisting">In [1]: %%cython
  ...: cdef double a
  ...: from libc.stdio cimport printf
  ...: printf("%p", <strong>&amp;a</strong>)
  ...:
0x7fc8bb611210</pre></div><p>Memory addresses can be stored in special variables—<em>pointers</em>—declared by putting a <code class="literal">*</code> prefix on the variable name as follows:</p><div><pre class="programlisting">from libc.stdio cimport printf
cdef double a
<strong>cdef double *a_pointer</strong>
a_pointer = &amp;a # They are of the same data type</pre></div><p>If we have a pointer and we want to grab the value contained in the address it's pointing at, we can use the <em>dereference operator</em>, denoted with the <code class="literal">*</code> symbol, as<a class="indexterm" id="id143"/> shown in the following code. Be careful, the <code class="literal">*</code> used in<a class="indexterm" id="id144"/> this context has a different meaning from the <code class="literal">*</code> used in the variable declaration.</p><div><pre class="programlisting">cdef double a
cdef double *a_pointer
a_pointer = &amp;a
a = 3.0
<strong>print(*a_pointer) # prints 3.0</strong>
</pre></div><p>When declaring a C array, the program allocates enough space to contain several elements of the specified size. For instance, to create an array that has 10 <code class="literal">double</code> values (8 bytes each), the program will reserve <em>8 * 10 = 80</em> bytes of contiguous space in memory. In Cython we can declare such an array using the following syntax:</p><div><pre class="programlisting">cdef double arr[10]</pre></div><p>We can also declare a multidimensional array, like an array with 5 rows and 2 columns using the following syntax:</p><div><pre class="programlisting">cdef double arr[5][2]</pre></div><p>The memory will be allocated in a single block of memory, row after row. This order is commonly referred to as <a class="indexterm" id="id145"/>
<em>row-major</em> and is represented in the following figure. Arrays can also be ordered <a class="indexterm" id="id146"/>
<em>column-mayor</em>, as it happens in the FORTRAN programming language.</p><div><img alt="C arrays and pointers" src="img/8458_03_1.jpg"/></div><div><div><h3 class="title"><a id="tip09"/>Tip</h3><p>Array ordering has<a class="indexterm" id="id147"/> important consequences. When iterating a C array over the last dimension, we access contiguous memory blocks (in our example 0, 1, 2, 3 …)while when we iterate on the first dimension, we skip a few positions (0, 2, 4, 6, 8, 1 … ). You should <a class="indexterm" id="id148"/>always try to access memory contiguously as this optimizes cache usage.</p></div></div><p>We can store and retrieve elements from the array by using standard indexing, C arrays don't support fancy indexing or slices:</p><div><pre class="programlisting">arr[0] = 1.0</pre></div><p>C arrays can also be used as pointers. The <code class="literal">arr</code> variable, in fact, is a pointer to the first element of the array. We can <a class="indexterm" id="id149"/>verify that the address of the first element of the array is the <a class="indexterm" id="id150"/>same as the address contained in the variable <code class="literal">arr</code>:</p><div><pre class="programlisting">In [1]: %%cython
  ...: from libc.stdio cimport printf
  ...: cdef double arr[10]
  ...: printf("%p\n", arr)
  ...: printf("%p\n", &amp;arr[0])
  ...:
0x7ff6de204220
0x7ff6de204220</pre></div><p>You should use C arrays and pointers when interfacing with existing C libraries or when you need a fine control over the memory. For more common use-cases you can employ NumPy arrays or typed memoryviews.</p></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec13"/>NumPy arrays</h2></div></div></div><p>NumPy arrays can<a class="indexterm" id="id151"/> be used in Cython as normal Python objects, by using their already optimized broadcasted operations.</p><p>The problem<a class="indexterm" id="id152"/> comes when we want to efficiently iterate over the array. When we do an indexing operation on a NumPy array, a few other operations take place at the interpreter level causing a major overhead. Cython can optimize those indexing operations by acting directly on the underlying memory area used by NumPy arrays, allowing us to treat them just like C arrays.</p><p>NumPy array support comes in the form of a <code class="literal">ndarray</code> data type. We first have to <code class="literal">cimport</code> the <code class="literal">numpy</code> module. We assign it to the name <code class="literal">c_np</code> to differentiate it from the regular <code class="literal">numpy</code> Python module as follows:</p><div><pre class="programlisting">cimport numpy as c_np</pre></div><p>We can now declare a NumPy array by specifying the type of the array elements and the number of dimensions, with a special syntax called <em>buffer syntax</em>. To declare a two-dimensional array of type <code class="literal">double</code> we can use the following code:</p><div><pre class="programlisting">cdef c_np.ndarray[double, ndim=2] arr</pre></div><p>An array defined in this way will be indexed by acting directly on the underlying memory area; the operation will avoid the Python interpreter giving us a tremendous speed boost.</p><p>In the next example, we will show the usage of the buffer syntax and compare it with the normal Python version.</p><p>We first write the <code class="literal">numpy_bench_py</code> function<a class="indexterm" id="id153"/> that increments each element of <code class="literal">py_arr</code> by 1000. We declared the index <code class="literal">i</code> as integer so<a class="indexterm" id="id154"/> that we avoid the <code class="literal">for</code> loop overhead:</p><div><pre class="programlisting">In [1]:  %%cython
  ...:  import numpy as np
  ...:  def numpy_bench_py():...:    py_arr = np.random.rand(1000)
  ...:    cdef int i
  ...:    for i in range(1000):
  ...:       py_arr[i] += 1</pre></div><p>Then we write the same function using the buffer syntax. Notice that after we define the <code class="literal">c_arr</code> variable using <code class="literal">c_np.ndarray</code>, we can assign to it an array from the <code class="literal">numpy</code> Python module:</p><div><pre class="programlisting">In [2]:  %%cython
  ...:  import numpy as np
  ...:  cimport numpy as c_np
  ...:  def numpy_bench_c():
  ...:    <strong>cdef c_np.ndarray[double, ndim=1] c_arr</strong>
  ...:    <strong>c_arr = np.random.rand(1000)</strong>
  ...:    cdef int i
  ...:
  ...:    for i in range(1000):
  ...:       c_arr[i] += 1</pre></div><p>We can time<a class="indexterm" id="id155"/> the results using <code class="literal">timeit</code>, obtaining an impressive 50x speedup:</p><div><pre class="programlisting">In [10]: %timeit numpy_bench_c()
100000 loops, best of 3: 11.5 us per loop
In [11]: %timeit numpy_bench_py()
1000 loops, best of
 3: 603 us per loop</pre></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec14"/>Typed memoryviews</h2></div></div></div><p>C and NumPy arrays are both objects<a class="indexterm" id="id156"/> that act on a memory area. Cython provides a universal object—the <em>typed memoryview</em>—to access arrays and other data structures that expose the so called <em>buffer interface</em>, such as the built-ins <code class="literal">bytes</code>, <code class="literal">bytearray</code>, and <code class="literal">array.array</code>.</p><p>A <strong>memoryview</strong> is <a class="indexterm" id="id157"/>an object that maintains a reference on a certain memory area. It doesn't actually own the memory, but it can read and change its content (it is a <em>view</em>). By using typed memoryviews we can interact with both C and NumPy arrays in the same way.</p><p>Memoryviews can be defined using a<a class="indexterm" id="id158"/> special syntax. We can define a memoryview of <code class="literal">int</code> and a 2D memoryview of <code class="literal">double</code> in the following way:</p><div><pre class="programlisting">cdef int[:] a
cdef double[:, :] b</pre></div><p>The same syntax applies to function definitions, class attributes, and so on. Any object that exposes a buffer interface will automatically be bound to the memoryview. We can bind the memoryview to an array by the following simple assignment:</p><div><pre class="programlisting">import numpy as np

cdef int[:] arr
<strong>arr_np = np.zeros(10, dtype='int32')</strong>
<strong>arr = arr_np</strong> # We bind the array to the memoryview</pre></div><p>The new memoryview will share the data with the NumPy array. Changes in the array elements will be shared between the two data structures:</p><div><pre class="programlisting">arr[2] = 1 # Changing memoryview
print(arr_np)
# [0 0 1 0 0 0 0 0 0 0]</pre></div><p>In a certain sense, the memoryview is a generalization of a NumPy array. As we have seen in <a class="link" href="ch02.html" title="Chapter 2. Fast Array Operations with NumPy">Chapter 2</a>, <em>Fast Array Operations with Numpy</em>, slicing a NumPy array does not copy the data but returns a view on the same memory area.</p><p>Memoryviews also support array slicing with the following standard NumPy syntax:</p><div><pre class="programlisting">cdef int[:, :, :] a
arr[0, :, :] # Is a 2-dimensional memoryview
arr[0, 0, :] # Is a 1-dimensional memoryview
arr[0, 0, 0] # Is an int</pre></div><p>To copy data between a memoryview and another, you can use a syntax similar to the slice assignment, as shown in the following code:</p><div><pre class="programlisting">import numpy as np

cdef double[:, :] b
cdef double[:] r
b = np.random.rand(10, 3)
r = np.zeros(3, dtype='float64')

b[0, :] = r # Copy the value of r in the first row of b</pre></div><p>In the next section, we will use the<a class="indexterm" id="id159"/> typed memoryviews to handle the arrays in our particle simulator application.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec29"/>Particle simulator in Cython</h1></div></div></div><p>Now that we have a basic understanding <a class="indexterm" id="id160"/>on how Cython works we can rewrite the <code class="literal">ParticleSimulator.evolve</code> method. Thanks to Cython, we can convert our loops in C, thus removing the overhead introduced by the Python interpreter.</p><p>In <a class="link" href="ch02.html" title="Chapter 2. Fast Array Operations with NumPy">Chapter 2</a>, <em>Fast Array Operations with Numpy</em>, we wrote a fairly efficient version of the <code class="literal">evolve</code> method using NumPy. We can rename the old version as <code class="literal">evolve_numpy</code> to differentiate it from the new version:</p><div><pre class="programlisting">  def evolve_numpy(self, dt):
    timestep = 0.00001
    nsteps = int(dt/timestep)
    
    r_i = np.array([[p.x, p.y] for p in self.particles])    
    ang_speed_i = np.array([p.ang_speed for pin self.particles])
    v_i = np.empty_like(r_i)
    
    for i in range(nsteps):
      norm_i = np.sqrt((r_i ** 2).sum(axis=1))

      v_i = r_i[:, [1, 0]]
      v_i[:, 0] *= -1
      v_i /= norm_i[:, np.newaxis]        

      d_i = timestep * ang_speed_i[:, np.newaxis] * v_i

      r_i += d_i
    
    for i, p in enumerate(self.particles):
      p.x, p.y = r_i[i]</pre></div><p>We want to convert this code to Cython. Our strategy will be to take advantage of the fast indexing operations by removing the NumPy array broadcasting, thus reverting to an indexing-based algorithm. Since Cython generates efficient C code, we are free to use as many loops as we like without any performance penalty.</p><p>As a design choice, we can decide to encapsulate the loop in a function that we will rewrite in a Cython module called <code class="literal">cevolve.pyx.</code> The module will contain a single Python function <code class="literal">c_evolve</code> that will take the particle positions, the angular velocities, the timestep, and the number of steps as input.</p><p>At first, we are not adding typing information; we just want to isolate the function and make sure that we can compile our module without errors.</p><div><pre class="programlisting">
<strong># file: simul.py</strong>
# ... other code
  def evolve_cython(self, dt):
    timestep = 0.00001
    nsteps = int(dt/timestep)
    
    r_i = np.array([[p.x, p.y] for p in self.particles])    
    ang_speed_i = np.array([p.ang_speed forp in self.particles])

    <strong>c_evolve(r_i, ang_speed_i, timestep, nsteps)</strong>
    
    for i, p in enumerate(self.particles):
      p.x, p.y = r_i[i]

<strong># file: cevolve.pyx</strong>
import numpy as np

<strong>def c_evolve(r_i, ang_speed_i, timestep, nsteps)</strong>:
  v_i = np.empty_like(r_i)
    
  for i in range(nsteps):
    norm_i = np.sqrt((r_i ** 2).sum(axis=1))

    v_i = r_i[:, [1, 0]]
    v_i[:, 0] *= -1
    v_i /= norm_i[:, np.newaxis]        

    d_i = timestep * ang_speed_i[:, np.newaxis] * v_i

    r_i += d_i</pre></div><p>Notice that we don't need a return value for <code class="literal">c_evolve</code>, as values are updated in the <code class="literal">r_i</code> array in-place. We can benchmark the untyped Cython version against the old NumPy version by slightly changing our benchmark function, as follows:</p><div><pre class="programlisting">def benchmark(npart=100, method='python'):
  particles = [Particle(uniform(-1.0, 1.0),uniform(-1.0, 1.0),uniform(-1.0, 1.0))for i in range(npart)]

  simulator = ParticleSimulator(particles)
  if method=='python':
    simulator.evolve_python(0.1)

<strong>  if method == 'cython':</strong>
<strong>    simulator.evolve_cython(0.1)</strong>

  <strong>elif method == 'numpy':</strong>
<strong>    simulator.evolve_numpy(0.1)</strong>
</pre></div><p>We can time the different versions in an IPython shell:</p><div><pre class="programlisting">In [4]: %timeit benchmark(100, 'cython')
1 loops, best of 3: 401 ms per loop
In [5]: %timeit benchmark(100, 'numpy')
1 loops, best of 3: 413 ms per loop</pre></div><p>The two versions have the same speed. Compiling the Cython module without static typing doesn't have any advantage over pure Python. The next step, is to declare the type of all the important variables so that Cython can perform its optimizations.</p><p>We can start by adding types to the function arguments. We will declare the arrays as typed memoryviews containing <code class="literal">double</code> values. It is worth mentioning that if we pass an array of <code class="literal">int</code> or <code class="literal">float32</code> type, the casting won't happen automatically and we would get an error.</p><div><pre class="programlisting">def c_evolve(<strong>double[:, :]</strong> r_i, <strong>double[:]</strong> ang_speed_i,<strong>double</strong> timestep, <strong>int</strong> nsteps):</pre></div><p>At that point, we want to rewrite the loops over the particles and time steps. We can declare the iteration variables <code class="literal">i, j</code> and the particle number <code class="literal">nparticles</code> as <code class="literal">int</code>:</p><div><pre class="programlisting">  cdef int i, j
  cdef int nparticles = r_i.shape[0]</pre></div><p>At this point the algorithm is very similar to the pure Python version; we iterate over the particles and time steps and we compute the velocity and displacement vectors for each particle coordinate, using the following code:</p><div><pre class="programlisting">  for i in range(nsteps):
    for j in range(nparticles):
      x = r_i[j, 0]
      y = r_i[j, 1]
      ang_speed = ang_speed_i[j]
      
      norm = sqrt(x ** 2 + y ** 2)

      vx = (-y)/norm
      vy = x/norm

      dx = timestep * ang_speed * vx
      dy = timestep * ang_speed * vy

      r_i[j, 0] += dx
      r_i[j, 1] += dy</pre></div><p>In the previous code, we added the <code class="literal">x</code>, <code class="literal">y</code>, <code class="literal">ang_speed</code>, <code class="literal">norm</code>, <code class="literal">vx</code>, <code class="literal">vy</code>, <code class="literal">dx</code>, and <code class="literal">dy</code> variables. To avoid the Python interpreter overhead we have to declare them with their corresponding types at the beginning of the function as follows:</p><div><pre class="programlisting">cdef double norm, x, y, vx, vy, dx, dy, ang_speed</pre></div><p>We also used a function called <code class="literal">sqrt</code> to calculate the norm. If we use the <code class="literal">sqrt</code> present in the <code class="literal">math</code> module or the one in <code class="literal">numpy</code>, we would again include a slow Python function in our critical loop, thus killing our performance. A fast <code class="literal">sqrt</code> is available in the standard C library, already wrapped in the <code class="literal">libc.math</code> Cython module:</p><div><pre class="programlisting">from libc.math <strong>cimport</strong> sqrt</pre></div><p>After recompiling, we can re-run our benchmark to assess our improvements, as follows:</p><div><pre class="programlisting">In [4]: %timeit benchmark(100, 'cython')
100 loops, best of 3: <strong>13.4 ms</strong> per loop
In [5]: %timeit benchmark(100, 'numpy')
1 loops, best of 3: <strong>429 ms</strong> per loop</pre></div><p>For small particle numbers the speed-up is massive, we obtained a 40x performance improvement over the previous version. However, we should also try with a larger number of particles to test the performance scaling, as in the following code:</p><div><pre class="programlisting">In [2]: %timeit benchmark(1000, 'cython')
10 loops, best of 3: <strong>134 ms</strong> per loop
In [3]: %timeit benchmark(1000, 'numpy')
1 loops, best of 3: <strong>877 ms</strong> per loop</pre></div><p>As we increase the number of particles, the two versions get closer in speed. By increasing the particle size to 1000 we already decreased our speed-up to a more modest 6x. This is likely due to the fact that as we increase the number of particles the Python for-loop overhead gets less and less significant compared to the speed of the other operations.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec30"/>Profiling Cython</h1></div></div></div><p>Cython gives us a<a class="indexterm" id="id161"/> wonderful tool to quickly find the slow spots due to the Python interpreter—a feature called <em>annotated view</em>. We can turn on this feature by compiling a Cython file with the <code class="literal">-a</code> option, using the following command line. Cython will generate a HTML file containing our code annotated with some useful information:</p><div><pre class="programlisting">
$ cython -a cevolve.pyx
$ google-chrome cevolve.html
</pre></div><p>The HTML file displayed in the following screenshot shows our Cython file line-by-line:</p><div><img alt="Profiling Cython" src="img/8458_03_2.jpg"/></div><p>Each line has a background color in different shades of yellow; an intense color means that the code has a lot of interpreter-related calls, while white lines gets translated to pure C. Since interpreter calls are typically slow, the objective is to make the function body as white as possible. By clicking on any of the lines we can see the C code generated by the Cython compiler. For <a class="indexterm" id="id162"/>example, the line <code class="literal">v_y = x/norm</code> checks that the norm is not 0, raising a <code class="literal">ZeroDivisionError</code> otherwise. The line <code class="literal">x = r_i[j, 0]</code> shows that Cython checks that the indexes are within the bounds of the array. You may notice that the last line is of a very intense color, by inspecting the code we can see that this is actually a glitch; the code refers to a boilerplate related to the end of the function.</p><p>Cython can shut down those checks to improve speed using its compiler directives. There are three different ways to add compiler directives:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Using a decorator or a context manager</li><li class="listitem" style="list-style-type: disc">Using a comment at the beginning of the file</li><li class="listitem" style="list-style-type: disc">Using the Cython command line options<div><div><h3 class="title"><a id="note10"/>Note</h3><p>For a complete list of the Cython compiler directives you can refer to the official documentation at <a class="ulink" href="http://docs.cython.org/src/reference/compilation.html#compiler-directives">http://docs.cython.org/src/reference/compilation.html#compiler-directives</a>
</p></div></div></li></ul></div><p>For example, to disable the "bounds" checking of arrays, it is sufficient to decorate a function with <code class="literal">cython.boundscheck</code> in the following way:</p><div><pre class="programlisting">cimport cython

<strong>@cython.boundscheck(False)</strong>
def myfunction:
  # Code here</pre></div><p>We can use <code class="literal">cython.boundscheck</code> to wrap a block of code into a context manager, as follows:</p><div><pre class="programlisting">
<strong>with cython.boundscheck(False):</strong>
  # Code here</pre></div><p>If we want to disable bounds checking for a whole module we can add the following line of code at the beginning of the file:</p><div><pre class="programlisting"># cython: boundscheck=False</pre></div><p>To alter the directives with the command line options you can use <code class="literal">-X</code> as follows:</p><div><pre class="programlisting">
$ cython -X boundscheck=True
</pre></div><p>We can now try to avoid the extra checks in our function by disabling the <code class="literal">boundscheck</code> directive and<a class="indexterm" id="id163"/> enabling <code class="literal">cdivision</code> (this disables the checks for <code class="literal">ZeroDivisionError</code>) as in the following code:</p><div><pre class="programlisting">cimport cython

<strong>@cython.boundscheck(False)</strong>
<strong>@cython.cdivision(True)</strong>
def c_evolve(double[:, :] r_i,double[:] ang_speed_i,double timestep,int nsteps):</pre></div><p>If we look at the annotated view again, the loop body is completely white; we removed all traces of the interpreter from the loop. In the following case however, we didn't obtain a performance improvement:</p><div><pre class="programlisting">In [3]: %timeit benchmark(100, 'cython')
100 loops, best of 3: 13.4 ms per loop</pre></div><p>We can profile Cython code with <code class="literal">cProfile</code> by including the <code class="literal">profile=True</code> directive in our files. To show its usage we can write a function that calculates the Chebyshev distance between two arrays of coordinates. Create a file <code class="literal">cheb.py</code>:</p><div><pre class="programlisting">import numpy as np
from distance import chebyshev

def benchmark():
  a = np.random.rand(100, 2)
  b = np.random.rand(100, 2)
  for x1, y1 in a:
    for x2, y2 in b:
      chebyshev(x1, x2, y1, y2)</pre></div><p>If we try profiling this script as-is, we won't get any statistics regarding the functions that we implemented in Cython. If we want to know the profile metrics for the <code class="literal">max</code> and <code class="literal">min</code> functions we have to add the <code class="literal">profile=True</code> option to the <code class="literal">mathlib.pyx</code> file, as shown in the following code:</p><div><pre class="programlisting">
<strong># cython: profile=True</strong>

cdef int max(int a, int b):
  # Code here</pre></div><p>We can now profile our script with <code class="literal">%prun</code> using IPython, as follows:</p><div><pre class="programlisting">In [2]: import cheb
In [3]: %prun cheb.benchmark()
     2000005 function calls in 2.066 seconds

  Ordered by: internal time

  ncalls tottime percall cumtime percall filename:lineno(function)
    1  1.664  1.664  2.066  2.066 cheb.py:4(benchmark)
 1000000  0.351  0.000  0.401  0.000 {distance.chebyshev}
<strong> 1000000  0.050  0.000  0.050  0.000 mathlib.pyx:2(max)</strong>
    2  0.000  0.000  0.000  0.000 {method 'rand' of 'mtrand.RandomState' objects}
    1  0.000  0.000  2.066  2.066 &lt;string&gt;:1(&lt;module&gt;)
    1  0.000  0.000  0.000  0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre></div><p>From the output, we can <a class="indexterm" id="id164"/>see that the <code class="literal">max</code> function is present and is not a bottleneck. The problem seems to be lying in the <code class="literal">benchmark</code> function; the issue is likely to be the Python for-loop overhead. In this case, the best strategy would be rewriting the loop in NumPy or port the code to Cython.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec31"/>Summary</h1></div></div></div><p>Cython will bring the speed of your programs to another level. Cython programs are much easier to maintain in comparison to C, thanks to the tight integration with Python and the availability of profiling tools.</p><p>In this chapter, we introduced the basics of the Cython language and how to make our programs faster by adding static types. We also learned how to work with C arrays, NumPy arrays, and memoryviews.</p><p>We optimized our particle simulator by rewriting the critical <code class="literal">evolve</code> function, obtaining a tremendous speed gain. Finally, we learned how to use the annotated view to quickly spot interpreter related calls and how to enable <code class="literal">cProfile</code> for Cython scripts.</p><p>In the next chapter, we will learn the parallel processing basics and see how to write Python programs that take advantage of multiple processors so that you can write faster programs and solve larger problems.</p></div></body></html>