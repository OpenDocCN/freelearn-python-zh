- en: '*Chapter 3*: Fast Array Operations with NumPy, Pandas, and Xarray'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NumPy is the *de facto* standard for scientific computing in Python. It offers
    flexible multidimensional arrays that allow you to perform fast and concise mathematical
    calculations.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy provides common data structures and algorithms designed to express complex
    mathematical operations using a concise syntax. The multidimensional array, `numpy.ndarray`,
    is internally based on C arrays. Apart from the performance benefits, this choice
    allows NumPy code to easily interface with the existing C and FORTRAN routines;
    NumPy helps bridge the gap between Python and the legacy code written using those
    languages.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to create and manipulate NumPy arrays. We
    will also explore the NumPy broadcasting feature, which is used to rewrite complex
    mathematical expressions efficiently and succinctly.
  prefs: []
  type: TYPE_NORMAL
- en: '**pandas** is a tool that relies heavily on NumPy and provides additional data
    structures and algorithms targeted toward data analysis. We will introduce the
    main pandas features and their usage. We will also learn how to achieve high performance
    using pandas data structures and vectorized operations.'
  prefs: []
  type: TYPE_NORMAL
- en: Both NumPy and pandas are insufficient in many use cases concerning labeled,
    multidimensional data. The xarray library combines the best features from the
    other two tools and offers further optimized data processing functionalities.
    We will discuss the motivation for this tool and study the performance improvements
    it offers via explicit examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rewriting the particle simulator in NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reaching optimal performance with numexpr
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with database-style data with pandas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-performance labeled data with xarray
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code files for this chapter can be accessed by going to this book's GitHub
    repository at [https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/Chapter03](https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/Chapter03).
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The NumPy library revolves around its multidimensional array object, `numpy.ndarray`.
    NumPy arrays are collections of elements of the same data type; this fundamental
    restriction allows NumPy to pack the data in a way that allows for high-performance
    mathematical operations.
  prefs: []
  type: TYPE_NORMAL
- en: Creating arrays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s explore NumPy''s functionalities by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create NumPy arrays using the `numpy.array` function. It takes a list-like
    object (or another array) as input and, optionally, a string expressing its data
    type. You can interactively test array creation using an IPython shell, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Every NumPy array has an associated data type that can be accessed using the
    `dtype` attribute. If we inspect the `a` array, we will find that its `dtype`
    is `int64`, which stands for 64-bit integer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We may decide to convert those integer numbers into the `float` type. To do
    this, we can either pass the `dtype` argument at array initialization or cast
    the array to another data type using the `astype` method. These two ways to select
    a data type are shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To create an array with two dimensions (an array of arrays), we can perform
    the required initialization using a nested sequence, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'An array that''s created in this way has two dimensions, which are called `ndarray.shape`
    attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Arrays can also be reshaped, so long as the product of the shape dimensions
    is equal to the total number of elements in the array (that is, the total number
    of elements is conserved). For example, we can reshape an array containing 16
    elements in the following ways: `(2, 8)`, `(4, 4)`, or `(2, 2, 4)`. To reshape
    an array, we can either use the `ndarray.reshape` method or assign a new value
    to the `ndarray.shape` tuple. The following code illustrates the use of the `ndarray.reshape`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Thanks to this property, you can freely add dimensions of size `1`. You can
    reshape an array with 16 elements to `(16, 1)`, `(1, 16)`, `(16, 1, 1)`, and so
    on. In the next section, we will extensively use this feature to implement complex
    operations through *broadcasting*.
  prefs: []
  type: TYPE_NORMAL
- en: 'NumPy provides convenience functions, as shown in the following code, to create
    arrays filled with zeros, ones, or with no initial value (in this case, their
    actual value is meaningless and depends on the memory state). Those functions
    take the array shape as a tuple and, optionally, its `dtype`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In our examples, we will use the `numpy.random` module to generate random floating-point
    numbers in the `(0, 1)` interval. `numpy.random.rand` will take a shape and return
    an array of random numbers with that shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes, it is convenient to initialize arrays that have the same shape as
    that of some other array. For that purpose, NumPy provides some handy functions,
    such as `zeros_like`, `empty_like`, and `ones_like`. These functions can be used
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These functions will return arrays with the specified values, whose shapes match
    exactly with that of array `a`.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing arrays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The NumPy array interface is, at a shallow level, similar to that of Python
    lists. NumPy arrays can be indexed using integers and iterated using a `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: However, explicitly looping over an array is, most of the time, not the most
    efficient way to access its elements. In this section, we will learn how to take
    advantage of NumPy's API to fully utilize its efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Indexing and slicing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Indexing and slicing refer to the act of accessing elements within an array
    that are at certain locations or satisfy some condition that we are interested
    in. In NumPy, array elements and sub-arrays can be conveniently accessed by using
    multiple values separated by commas inside the subscript operator, `[]`. Let''s
    get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take a `(3,3)` array (an array containing three triplets) and we access
    the element with an index of `0`, we can obtain the first row, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can index the row again by adding another index separated by a comma. To
    get the second element of the first row, we can use the `(0, 1)` index. An important
    observation is that the `A[0, 1]` notation is shorthand for `A[(0, 1)]`; that
    is, we are indexing using a *tuple*! Both versions are shown in the following
    snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'NumPy allows you to slice arrays into multiple dimensions. If we slice on the
    first dimension, we can obtain a collection of triplets, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we slice the array again on the second dimension with `0:2`, we are extracting
    the first two elements from the collection of triplets shown earlier. This results
    in an array whose shape is `(2, 2)`, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Intuitively, you can update the values in the array using both *numerical indexes*
    and *slices*. An example of this is illustrated in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Indexing with the slicing syntax is very fast because, unlike lists, it doesn''t
    produce a copy of the array. In NumPy''s terminology, it returns a *view* of the
    same memory area. If we take a slice of the original array, and then we change
    one of its values, the original array will be updated as well. The following code
    illustrates an example of this feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It is important to be extra careful when mutating NumPy arrays. Since views
    share data, changing the values of a view can result in hard-to-find bugs. To
    prevent side effects, you can set the `a.flags.writeable = False` flag, which
    will prevent the array or any of its views from being accidentally mutated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at another example that shows how the slicing syntax can be used
    in a real-world setting. Let''s define an `r_i` array, as shown in the following
    line of code, which contains a set of 10 coordinates (*x*, *y*). Its shape will
    be `(10, 2)`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you have a hard time distinguishing arrays that differ in the axes order,
    for example, between an array of shape `(10, 2)` and shape `(2, 10)`, it is useful
    to think that every time you say the word *of*, you should introduce a new dimension.
    An array with 10 elements *of* size two will be `(10, 2)`. Conversely, an array
    with two elements *of* size 10 will be `(2, 10)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical operation we may be interested in is extracting the *x* component
    from each coordinate. In other words, you want to extract the `(0, 0)`, `(1, 0)`,
    and `(2, 0)`, items, resulting in an array with a shape of `(10,)`. It is helpful
    to think that the first index is *moving* while the second one is *fixed* (at
    `0`). With this in mind, we will slice every index on the first axis (the moving
    one) and take the first element (the fixed one) on the second axis, as shown in
    the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, the following expression will keep the first index fixed
    and the second index moving, returning the first (*x*, *y*) coordinate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Slicing all the indexes over the last axis is optional; using `r_i[0]` has the
    same effect as using `r_i[0, :]`.
  prefs: []
  type: TYPE_NORMAL
- en: Fancy indexing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'NumPy allows you to index an array using another NumPy array made up of either
    integer or Boolean values. This is a feature called **fancy indexing**:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you index an array (say, `a`) with another array of integers (say, `idx`),
    NumPy will interpret the integers as indexes and will return an array containing
    their corresponding values. If we index an array containing 10 elements with `np.array([0,
    2, 3])`, we obtain an array of shape `(3,)` containing the elements at positions
    `0`, `2`, and `3`. The following code illustrates this concept:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can use fancy indexing on multiple dimensions by passing an array for each
    dimension. If we want to extract the `(0, 2)` and `(1, 2)` elements, we have to
    pack all the indexes acting on the first axis in one array, and the ones acting
    on the second axis in another. This can be seen in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can also use normal lists as index arrays, but not tuples. For example,
    the following two statements are equivalent:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'However, if you use a tuple, NumPy will interpret the following statement as
    an index on multiple dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The index arrays are not required to be one-dimensional; we can extract elements
    from the original array in any shape. For example, we can select elements from
    the original array to form a `(2,2)` array, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The array slicing and fancy indexing features can be combined. This is useful,
    for instance, when we want to swap the *x* and *y* columns in a coordinate array.
    In the following code, the first index will be running over all the elements (a
    slice) and, for each of those, we extract the element in position `1` (the *y*)
    first and then the one in position `0` (the *x*):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When the index array is of the `bool` type, the rules are slightly different.
    The `bool` array will act as a *mask*; every element corresponding to `True` will
    be extracted and put in the output array. This is shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The same rules apply when dealing with multiple dimensions. Furthermore, if
    the index array has the same shape as the original array, the elements corresponding
    to `True` will be selected and put in the resulting array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Indexing in NumPy is a reasonably fast operation. When speed is critical, you
    can use the slightly faster `numpy.take` and `numpy.compress` functions to squeeze
    out a little more performance. The first argument of `numpy.take` is the array
    we want to operate on, while the second is the list of indexes we want to extract.
    The last argument is `axis`; if this is not provided, the indexes will act on
    the flattened array; otherwise, they will act along the specified axis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The similar but faster version for Boolean arrays is `numpy.compress`, which
    works in the same way. The use of `numpy.compress` is shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we can see, `compress` gives us a slight speed improvement, which will prove
    useful if you are dealing with large-sized arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Broadcasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The true power of NumPy lies in its fast mathematical operations. The approach
    that's used by NumPy is to avoid stepping into the Python interpreter by performing
    element-wise calculations using optimized C code. **Broadcasting** is a clever
    set of rules that enables fast array calculations for arrays of similar (but not
    equal!) shapes. Let's see how that goes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever you perform an arithmetic operation on two arrays (such as a product),
    if the two operands have the same shape, the operation will be applied in an element-wise
    fashion. For example, upon multiplying two `(2,2)` arrays, the operation will
    be done between pairs of corresponding elements, producing another `(2, 2)` array,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'If the shapes of the operands don''t match, NumPy will attempt to match them
    using broadcasting rules. If one of the operands is a *scalar* (for example, a
    number), it will be applied to every element of the array, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'If the operand is another array, NumPy will try to match the shapes starting
    from the last axis. For example, if we want to combine an array of shape `(3,
    2)` with one of shape `(2,)`, the second array will be repeated three times to
    generate a `(3, 2)` array. In other words, the array is *broadcasted* along a
    dimension to match the shape of the other operand, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – Illustration of array broadcasting ](img/Figure_3.1_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – Illustration of array broadcasting
  prefs: []
  type: TYPE_NORMAL
- en: If the shapes don't match – for example, when combining a `(3, 2)` array with
    a `(2, 2)` array – NumPy will throw an exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'If one of the axis''s sizes is 1, the array will be repeated over this axis
    until the shapes match. To illustrate this point, let''s consider that we have
    an array of the following shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s consider that we want to broadcast it with an array of shape `(5,
    1, 2)`; the array will be repeated on the second axis 10 times, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Earlier, we saw that it is possible to freely reshape arrays to add axes of
    size 1\. Using the `numpy.newaxis` constant while indexing will introduce an extra
    dimension. For instance, if we have a `(5, 2)` array and we want to combine it
    with one of shape `(5, 10, 2)`, we can add an extra axis in the middle, as shown
    in the following code, to obtain a compatible `(5, 1, 2)` array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This feature can be used, for example, to operate on all possible combinations
    of the two arrays. One of these applications is the *outer product*. Let''s consider
    that we have the following two arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The outer product is a matrix containing the product of all the possible combinations
    *(i, j)* of the two array elements, as shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To calculate this using NumPy, we will repeat the `[a1, a2, a3]` elements in
    one dimension, the `[b1, b2, b3]` elements in another dimension, and then take
    their element-wise product, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Illustration of an outer product ](img/Figure_3.2_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – Illustration of an outer product
  prefs: []
  type: TYPE_NORMAL
- en: 'Using code, our strategy will be to transform the `a` array from shape `(3,)`
    into shape `(3, 1)`, and the `b` array from shape `(3,)` into shape `(1, 3)`.
    These two arrays are broadcasted in the two dimensions and get multiplied together
    using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This operation is very fast and extremely effective as it avoids Python loops
    and can process a high number of elements at speeds comparable with pure C or
    FORTRAN code.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NumPy includes the most common mathematical operations available for broadcasting
    by default, ranging from simple algebra to trigonometry, rounding, and logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, to take the square root of every element in the array, we can
    use `numpy.sqrt`, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The comparison operators are useful when we''re trying to filter certain elements
    based on a condition. Imagine that we have an array of random numbers from `0`
    to `1`, and we want to extract all the numbers greater than `0.5`. We can use
    the `>` operator on the array to obtain a `bool` array, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting `bool` array can then be reused as an index to retrieve the elements
    that are greater than `0.5`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'NumPy also implements methods such as `ndarray.sum`, which takes the sum of
    all the elements on an axis. If we have an array of shape `(5, 3)`, we can use
    the `ndarray.sum` method to sum the elements on the first axis, the second axis,
    or over all the elements of the array, as illustrated in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Note that by summing the elements over an axis, we eliminate that axis. From
    the preceding example, the sum on axis `0` produces an array of shape `(3,)`,
    while the sum on axis `1` produces an array of shape `(5,)`.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the norm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can review the basic concepts illustrated in this section by calculating
    the *norm* of a set of coordinates. The norm of a pair of coordinates is an important
    concept in linear algebra and is often interpreted as the magnitude of the corresponding
    line segment. For a two-dimensional vector, the norm is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Given an array of 10 coordinates (*x*, *y*), we want to find the norm of each
    coordinate. We can calculate the norm by performing these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Square the coordinates, obtaining an array that contains `(x**2, y**2)` elements.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sum those with `numpy.sum` over the last axis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take the square root, element-wise, with `numpy.sqrt`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The final expression can be compressed into a single line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: We can verify that this method of calculating `norm` gives us the correct answer
    while having compact code.
  prefs: []
  type: TYPE_NORMAL
- en: Rewriting the particle simulator in NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will optimize our particle simulator by rewriting some
    parts of it in NumPy. From the profiling we did in [*Chapter 1*](B17499_01_Final_SS_ePub.xhtml#_idTextAnchor015),
    *Benchmarking and Profiling*, we found that the slowest part of our program is
    the following loop, which is contained in the `ParticleSimulator.evolve` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: You may have noticed that the body of the loop acts solely on the current particle.
    If we had an array containing the particle positions and angular speed, we could
    rewrite the loop using a broadcasted operation. In contrast, the loop's steps
    depend on the previous step and cannot be parallelized in this way.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, it is natural to store all the array coordinates in an array of shape `(nparticles,
    2)` and the angular speed in an array of shape `(nparticles,)`, where `nparticles`
    is the number of particles. We''ll call those arrays `r_i` and `ang_vel_i`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The velocity direction, which is perpendicular to the vector (*x*, *y*), was
    defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The norm can be calculated using the strategy illustrated in the *Calculating
    the norm* section under the *Getting started with NumPy* heading:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'For the (*-y*, *x*) components, we need to swap the *x* and *y* columns in
    `r_i` and then multiply the first column by `-1`, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'To calculate the displacement, we need to compute the product of `v_i`, `ang_vel_i`,
    and `timestep`. Since `ang_vel_i` is of shape `(nparticles,)`, it needs a new
    axis to operate with `v_i` of shape `(nparticles, 2)`. We will do that using `numpy.newaxis`,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Outside the loop, we have to update the particle instances with the new coordinates,
    *x* and *y*, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'To summarize, we will implement a method called `ParticleSimulator.evolve_numpy`
    and benchmark it against the pure Python version, renamed as `ParticleSimulator.evolve_python`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also update the benchmark to conveniently change the number of particles
    and the simulation method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s run the benchmark in an IPython session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We have made some improvements, but it doesn''t look like a huge speed boost.
    The power of NumPy is revealed when handling big arrays. If we increase the number
    of particles, we will note a more significant performance boost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot in the following diagram was produced by running the benchmark with
    different particle numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – The running time growth of pure Python versus NumPy ](img/Figure_3.3_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – The running time growth of pure Python versus NumPy
  prefs: []
  type: TYPE_NORMAL
- en: The plot shows that both implementations scale linearly with particle size,
    but the runtime in the pure Python version grows much faster than the NumPy version;
    at greater sizes, we have a greater NumPy advantage. In general, when using NumPy,
    you should try to pack things into large arrays and group the calculations using
    the broadcasting feature.
  prefs: []
  type: TYPE_NORMAL
- en: Reaching optimal performance with numexpr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When handling complex expressions, NumPy stores intermediate results in memory.
    David M. Cooke wrote a package called `numexpr`, which optimizes and compiles
    array expressions on the fly. It works by optimizing the usage of the CPU cache
    and by taking advantage of multiple processors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Its usage is generally straightforward and is based on a single function: `numexpr.evaluate`.
    The function takes a string containing an array expression as its first argument.
    The syntax is basically identical to that of NumPy. For example, we can calculate
    a simple `a + b * c` expression in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The `numexpr` package increases performance in almost all cases, but to get
    a substantial advantage, you should use it with large arrays. An application that
    involves a large array is the calculation of a *distance matrix*. In a particle
    system, a distance matrix contains all the possible distances between the particles.
    To calculate it, we should calculate all the vectors connecting any two particles,
    `(i,j)`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we must calculate the length of this vector by taking its norm, as shown
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We can write this in NumPy by employing the usual broadcasting rules (the operation
    is similar to the outer product):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we must calculate the norm over the last axis using the following
    line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Rewriting the same expression using the `numexpr` syntax is extremely easy.
    The `numexpr` package (aliased `ne` in our following code) doesn''t support slicing
    in its array expression; therefore, we first need to prepare the operands for
    broadcasting by adding an extra dimension, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we should try to pack as many operations as possible into a single
    expression to allow significant optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the NumPy mathematical functions are also available in `numexpr`. However,
    there is a limitation – the reduction operations (the ones that reduce an axis,
    such as `sum`) have to happen last. Therefore, we have to calculate the sum first,
    then step out of `numexpr`, and finally calculate the square root in another expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The `numexpr` compiler will avoid redundant memory allocation by not storing
    intermediate results. When possible, it will also distribute the operations over
    multiple processors. In the `distance_matrix.py` file, you will find two functions
    that implement the two versions – `distance_matrix_numpy` and `distance_matrix_numexpr`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: By simply converting the expressions to use `numexpr`, we were able to obtain
    a 4.5x increase in performance over standard NumPy. The `numexpr` package can
    be used every time you need to optimize a NumPy expression that involves large
    arrays and complex operations, and you can do so while making minimal changes
    to the code.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, we have seen that NumPy, in combination with numexpr, offers powerful
    APIs when it comes to working with multidimensional data. However, in many use
    cases, data is only two-dimensional but is *labeled* in the sense that the data
    axes include explicit information about the type of data they contain. This is
    the case for data extracted from database tables. In such situations, pandas is
    the most popular and one of the best libraries in Python for this, as we will
    see next.
  prefs: []
  type: TYPE_NORMAL
- en: Working with database-style data with pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: pandas is a library that was originally developed by Wes McKinney. It was designed
    to analyze datasets in a seamless and performant way. In recent years, this powerful
    library has seen incredible growth and a huge adoption by the Python community.
    In this section, we will introduce the main concepts and tools provided in this
    library, and we will use them to increase the performance of various use cases
    that can't otherwise be addressed with NumPy's vectorized operations and broadcasting.
  prefs: []
  type: TYPE_NORMAL
- en: pandas fundamentals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While NumPy deals mostly with arrays, pandas's main data structures are `pandas.Series`,
    `pandas.DataFrame`, and `pandas.Panel`. In the rest of this chapter, we will abbreviate
    `pandas` to `pd`.
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between a `pd.Series` object and an `np.array` is that a
    `pd.Series` object associates a specific *key* with each element of an array.
    Let's see how this works in practice with an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume that we are trying to test a new blood pressure drug and we want
    to store, for each patient, whether the patient''s blood pressure improved after
    administering the drug. We can encode this information by associating each subject
    ID (represented by an integer) with `True` if the drug was effective and `False`
    otherwise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a `pd.Series` object by associating an array of keys – the patients
    – to the array of values that represent the drug''s effectiveness. This array
    of keys can be passed to the `Series` constructor using the `index` argument,
    as shown in the following snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Associating a set of integers from *0* to *N* with a set of values can technically
    be implemented with `np.array` since, in this case, the key will simply be the
    position of the element in the array. In pandas, keys are not limited to integers;
    they can also be strings, floating-point numbers, and generic (hashable) Python
    objects. For example, we can easily turn our IDs into strings with little effort,
    as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: An interesting observation is that, while NumPy arrays can be thought of as
    a contiguous collection of values similar to Python lists, the pandas `pd.Series`
    object can be thought of as a structure that maps keys to values, similar to Python
    dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: What if you want to store the initial and final blood pressure for each patient?
    In pandas, you can use a `pd.DataFrame` object to associate multiple data with
    each key.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`pd.DataFrame` can be initialized, similarly to a `pd.Series` object, by passing
    a dictionary of columns and an index. In the following example, we will see how
    to create `pd.DataFrame` containing four columns that represent the initial and
    final measurements of systolic and diastolic blood pressure for our patients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Equivalently, you can think of `pd.DataFrame` as a collection of `pd.Series`.
    It is possible to directly initialize `pd.DataFrame` using a dictionary of `pd.Series`
    instances:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To inspect the content of a `pd.DataFrame` or `pd.Series` object, you can use
    the `pd.Series.head` and `pd.DataFrame.head` methods, which print the first few
    rows of the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Just like a `pd.DataFrame` can be used to store a collection of `pd.Series`,
    you can use a `pd.Panel` to store a collection of `pd.DataFrames`. We will not
    cover the usage of `pd.Panel` as it is not used as often as `pd.Series` and `pd.DataFrame`.
    To learn more about `pd.Panel`, make sure that you refer to the excellent documentation
    at [http://pandas.pydata.org/pandas-docs/stable/dsintro.html#panel](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#panel).
  prefs: []
  type: TYPE_NORMAL
- en: Indexing Series and DataFrame objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In many instances, we might want to access certain elements stored inside a
    `pd.Series` or a `pd.DataFrame` object. In the following steps, we will see how
    we can index these objects:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Retrieving data from a `pd.Series`, given its *key*, can be done intuitively
    by indexing the `pd.Series.loc` attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It is also possible to access the elements, given their *position* in the underlying
    array, using the `pd.Series.iloc` attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Indexing `pd.DataFrame` works similarly. For example, you can use `pd.DataFrame.loc`
    to extract a row by key, and you can use `pd.DataFrame.iloc` to extract a row
    by position:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'An important aspect is that the return type in this case is a `pd.Series`,
    where each column is a new key. To retrieve a specific row and column, you can
    use the following code. The `loc` attribute will index both the row and the column
    by key, while the `iloc` version will index the row and the column by an integer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Retrieving a column from a `pd.DataFrame` by name can be achieved by regular
    indexing or attribute access. To retrieve a column by position, you can either
    use `iloc` or use the `pd.DataFrame.column` attribute to retrieve the name of
    the column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These methods also support more advanced indexing, similar to those of NumPy,
    such as `bool`, lists, and `int` arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Now, it's time for some performance considerations. There are some differences
    between an index in pandas and a dictionary. For example, while the keys of a
    dictionary cannot contain duplicates, pandas indexes can contain repeated elements.
    This flexibility, however, comes at a cost – if we try to access an element in
    a non-unique index, we may incur substantial performance loss – the access will
    be *O*(*N*), like a linear search, rather than *O*(1), like a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: 'A way to mitigate this effect is to sort the index; this will allow pandas
    to use a binary search algorithm with a computational complexity of *O*(*log*(*N*)),
    which is much better. This can be accomplished using the `pd.Series.sort_index`
    function, as shown in the following code (the same applies for `pd.DataFrame`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The timings for the different versions are summarized in the following table.
    If you''d like to rerun this benchmarking yourself, please refer to `Chapter03/Pandas.ipynb`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 3.1 – Performance analysis for pandas indexing ](img/Table__3.1_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 3.1 – Performance analysis for pandas indexing
  prefs: []
  type: TYPE_NORMAL
- en: Database-style operations with pandas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may have noted that the *tabular* data is similar to what is usually stored
    in a database. A database is usually indexed using a primary key, and the various
    columns can have different data types, just like in a `pd.DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: The efficiency of the index operations in pandas makes it suitable for database-style
    manipulations, such as counting, joining, grouping, and aggregations.
  prefs: []
  type: TYPE_NORMAL
- en: Mapping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pandas supports element-wise operations, just like NumPy (after all, `pd.Series`
    stores their data using `np.array`).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, it is possible to apply transformation very easily to both `pd.Series`
    and `pd.DataFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also perform element-wise operations between two `pd.Series` objects
    in a way similar to NumPy. An important difference is that the operands will be
    matched by key, rather than by position; if there is a mismatch in the index,
    the resulting value will be set to `NaN`. Both scenarios are exemplified in the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: For added flexibility, pandas offers the `map`, `apply`, and `applymap` methods,
    which can be used to apply specific transformations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pd.Series.map` method can be used to execute a function for each value
    and return a `pd.Series` containing each result. In the following example, we
    can see how to apply the `superstar` function to each element of a `pd.Series`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The `pd.DataFrame.applymap` function is the equivalent of `pd.Series.map`,
    but for `DataFrames`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `pd.DataFrame.apply` function can apply the passed function to
    each column or each row, rather than element-wise. This selection can be performed
    with the argument axis, where a value of `0` (the default) corresponds to columns
    and `1` corresponds to rows. Also, note that the return value of `apply` is a
    `pd.Series`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'pandas also supports efficient `numexpr`-style expressions with the convenient
    `eval` method. For example, if we want to calculate the difference between the
    final and initial blood pressure, we can write the expression as a string, as
    shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to create new columns using the assignment operator in
    the `pd.DataFrame.eval` expression. Note that if the `inplace=True` argument is
    used, the operation will be applied directly to the original `pd.DataFrame`; otherwise,
    the function will return a new DataFrame. In the following example, we are computing
    the difference between `sys_final` and `sys_initial`, and we store it in the `sys_delta`
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Grouping, aggregations, and transforms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One of the most appreciated features of pandas is its simple and concise method
    of grouping, transforming, and aggregating data. To demonstrate this concept,
    let''s extend our dataset by adding two new patients that we didn''t administer
    the treatment to (this is usually called a *control group*). We will also include
    a column, `drug_admst`, which records whether the patient was administered the
    treatment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we may be interested to know how the blood pressure changed
    between the two groups. You can group the patients according to `drug_amst` using
    the `pd.DataFrame.groupby` function. The return value will be the `DataFrameGroupBy`
    object, which can be iterated to obtain a new `pd.DataFrame` for each value of
    the `drug_admst` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Iterating the `DataFrameGroupBy` object is rarely necessary because, thanks
    to method chaining, it is possible to calculate group-related properties directly.
    For example, we may want to calculate the mean, max, or standard deviation for
    each group. All those operations that summarize the data in some way are called
    aggregations and can be performed using the `agg` method. The result of `agg`
    is another `pd.DataFrame` that relates the grouping variables and the result of
    the aggregation, as illustrated in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible to perform processing on the DataFrame groups that do not
    represent a summarization. One common example of such an operation is filling
    in missing values. Those intermediate steps are called **transforms**.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can illustrate this concept with an example. Let''s assume that we have
    a few missing values in our dataset, and we want to replace those values with
    the average of the other values in the same group. This can be accomplished using
    a transform, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: Joining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`H1`, `H2`, and `H3` labels, and we can store the address and identifier of
    the hospital in a `hospital` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: Now, we want to find the city where the measure was taken for each patient.
    We need to *map* the keys from the `hospital_id` column to the city stored in
    the `hospitals` table.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be implemented in Python using dictionaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'This algorithm runs efficiently with an *O*(*N*) time complexity, where *N*
    is the size of `hospital_id`. pandas allows you to encode the same operation using
    simple indexing; the advantage is that the join will be performed in heavily optimized
    Cython and with efficient hashing algorithms. The preceding simple Python expression
    can easily be converted into pandas in this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'More advanced joins can also be performed with the `pd.DataFrame.join` method,
    which will produce a new `pd.DataFrame` that will attach the hospital information
    for each patient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: This concludes our discussion on pandas. In the next section, we will talk about
    xarray, the state-of-the-art tool for working with multidimensional labeled data
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: High-performance labeled data with xarray
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With NumPy, we can manipulate multidimensional numerical data and perform mathematical
    computations that are highly optimized by low-level C and FORTRAN code. On the
    other hand, we have seen that pandas allows us to work with labeled, categorical
    data that resembles data tables using database-like operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'These two tools complement each other: NumPy does not allow categorical data
    to be mixed in with numerical values, while pandas is mostly limited to two-dimensional,
    database-like datasets. Combining these tools can help address many data processing
    needs, but when we are faced with big, multidimensional data that is also labeled,
    many performance-related problems arise.'
  prefs: []
  type: TYPE_NORMAL
- en: In the last section of this chapter, we will discuss xarray, a library that
    combines the best of both the NumPy and the pandas worlds and offers one of the
    best tools for working with labeled multidimensional data. We will explore some
    of its most prominent features while noting the improvements we achieve with xarray
    over other Python libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing ![](img/Formula_3_B17499.png) concentration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To guide our discussion, we will be using the carbon dioxide concentration data,
    which was collected concerning the volcano Mauna Loa in Hawaii. The dataset is
    a time series of monthly measurements of the ![](img/Formula_3_B174991.png) level,
    starting from 1958 to this day. We have prepared a cleaned version of this dataset
    for you, which is included in the code repository for this book in the `monthly_co2.csv`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data has three simple columns:'
  prefs: []
  type: TYPE_NORMAL
- en: The year of measurement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The month of measurement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The measurement itself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our goal is to analyze this dataset and visualize any time-related trends.
    Since we are already familiar with using pandas to work with a `.csv` file, let''s
    proceed with the library to start:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure that the data file is in the same directory as this code. You may
    remember that this will read in the file and store the data in a `DataFrame` object.
    Here, we are using the first two columns (by using the `index_col=[0, 1]` argument)
    as the index of this `DataFrame` object. Finally, we print out the first five
    rows of this dataset, which look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that in March `1958`, the ![](img/Formula_3_B174992.png) level
    was `315.70`, and that the following month's measurement was `317.45`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we''d like to look at is a simple line graph corresponding
    to the `co2` column, which is simply the graph of the ![](img/Formula_3_B174992.png)
    level as a function of time (in `month`). With the help of Matplotlib, the go-to
    plotting tool in Python, we can do this very easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Monthly co2 level ](img/Figure_3.4_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – Monthly ![](img/Formula_3_B174993.png) level
  prefs: []
  type: TYPE_NORMAL
- en: 'We can notice two very distinct trends:'
  prefs: []
  type: TYPE_NORMAL
- en: The first is the *global* increasing trend, which roughly goes from 320 to 420
    during our timeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second looks like a *seasonal* zigzag trend, which is present locally and
    repeats itself every year.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To verify this intuition, we can inspect the average data across the years,
    which will tell us that the ![](img/Formula_3_B174993.png) level has been rising
    as a global trend. We can also compute the average measurement for each month
    and consider how the data changed from January to December. To accomplish this,
    we will utilize the `groupby` function by computing the yearly averages and plotting
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – Yearly co2 level, averaged across months ](img/Figure_3.5_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – Yearly ![](img/Formula_3_B174992.png) level, averaged across months
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as we expected, we can see the global rising trend of the ![](img/Formula_3_B174992.png)
    level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the preceding code generates the following average-by-month data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – Monthly co2 level, averaged across years ](img/Figure_3.6_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 – Monthly ![](img/Formula_3_B174992.png) level, averaged across years
  prefs: []
  type: TYPE_NORMAL
- en: 'The seasonal trend we suspected now becomes clear: the ![](img/Formula_3_B174992.png)
    level tends to rise during the summer and fall between fall and winter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we have been using pandas to manipulate our data. Even with this minimal
    example, we can notice a few things:'
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data, specifically the `co2` column, as a NumPy array would be inappropriate
    since we would lose information about the year and month each measurement was
    made. pandas is the better choice here.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the other hand, the `groupby` function can be unintuitive and costly to work
    with. Here, we simply want to compute the *average-by-month and average-by-year
    measurements*, but that requires us to group our data by the `month` column and
    then by `year`. Although pandas takes care of this grouping for us behind the
    scenes, it is an expensive operation, especially if we are working with a significantly
    large dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To bypass this inefficiency, we can think of representing the `co2` column as
    a two-dimensional NumPy array, where the rows represent years and the columns
    represent months, and each cell in the array holds the measurement. Now, to compute
    the averages we want, we could simply calculate the mean along each of the two
    axes, which we know NumPy can do efficiently. However, once again, we lose the
    expressiveness of the labeled `month` and `year` data we have under pandas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This dilemma we are currently facing is similar to the one that motivated the
    development of xarray, the premiere tool in Python for working with labeled, multidimensional
    data. The idea is to extend NumPy's support for fast, multidimensional array computations
    and allow dimensions (or axes) to have labels, which is one of the main selling
    points of pandas.
  prefs: []
  type: TYPE_NORMAL
- en: The xarray library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'xarray is developed and actively maintained by PyData and a part of the NumFOCUS
    project. To use the library, you must head to [http://xarray.pydata.org/en/stable/installing.html](http://xarray.pydata.org/en/stable/installing.html)
    for more details on how to install it. To continue with our example of the ![](img/Formula_3_B174992.png)
    concentration level, we will feed the data we have into a `Dataset` object in
    xarray using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'If we were to print this object out in a Jupyter notebook, the output would
    be formatted nicely:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – A Dataset instance of xarray, printed in Jupyter ](img/Figure_3.7_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 – A Dataset instance of xarray, printed in Jupyter
  prefs: []
  type: TYPE_NORMAL
- en: xarray was able to infer that `month` and `year` (the index columns in `DataFrame`)
    should be the dimension, as indicated by the `co2` data we care about, which is
    now a two-dimensional array indexed by `year` and `month`.
  prefs: []
  type: TYPE_NORMAL
- en: xarray makes interacting and inspecting its objects easy and interactive; you
    can inspect the values of the coordinates and data variables further by clicking
    on the icons highlighted in the preceding screenshot.
  prefs: []
  type: TYPE_NORMAL
- en: 'We mentioned earlier that xarray combines the best features of NumPy and pandas;
    this is best illustrated via the slicing/indexing interface it provides. For example,
    let''s say that we''d like to extract the measurements within the first 10 years
    of the dataset. For the first 5 months, we could apply NumPy-style slicing to
    the `''co2''` variable of the `ds` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us a `DataArray` object containing the requested values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 – A DataArray instance of xarray, printed in Jupyter ](img/Figure_3.8_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 – A DataArray instance of xarray, printed in Jupyter
  prefs: []
  type: TYPE_NORMAL
- en: 'While NumPy slicing can be flexible, it does not offer much expressiveness
    for labeled data: we would have to know that the first axis of the implied multidimensional
    array is `year`, that the second is `month`, and that `ds[''co2''][:10, :5]` doesn''t
    explicitly say which years we are selecting for.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As such, we could use the `sel` function, which roughly offers the same functionality
    as pandas filtering. To select the values within the example year of `1960`, we
    can simply use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: This explicitly tells us that we are selecting `1960` along the `year` axis.
    For more examples of the different APIs the library offers, you can check out
    the documentation at [http://xarray.pydata.org/en/stable/api.html](http://xarray.pydata.org/en/stable/api.html).
  prefs: []
  type: TYPE_NORMAL
- en: Improved performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we will consider the performance improvements that xarray offers. Recall
    that our goal is to compute the average measurement, first for each year to visualize
    the global trend, and then for each month for the seasonal trend. To do this,
    we can simply call the `mean` function while specifying the appropriate (labeled!)
    dimension.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, to obtain the average-by-year, we must compute the mean across the `month`
    dimension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns another `Dataset` object containing the computed values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.9 – Taking the average across a dimension in xarray ](img/Figure_3.9_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 – Taking the average across a dimension in xarray
  prefs: []
  type: TYPE_NORMAL
- en: From here, we can simply access the `co2` variable and pass the array to the
    `plot` function of Matplotlib to replicate *Figure 3.5*. For *Figure 3.6*, we
    can follow the same procedure using `ds.mean(dim='year')`.
  prefs: []
  type: TYPE_NORMAL
- en: The advantage we are gaining here is the expressiveness in our code. If we were
    using NumPy, we would need to specify the `'month'`, `'year'`). This might lead
    to hard-to-find bugs if you confuse which axis is which type of data in NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, the code is simpler and can take advantage of the optimized mean
    operation, which is managed under the hood by xarray, compared to the expensive
    `groupby` function from pandas. To see this, we can benchmark the two ways of
    computing the average-by-year that we have. First, we have the pandas way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we have the xarray way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see a clear performance improvement, achieved almost for free by
    passing our data to xarray!
  prefs: []
  type: TYPE_NORMAL
- en: Plotting with xarray
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Labeled multidimensional arrays are ubiquitous in time series (where one of
    the dimensions is time), geospatial data (where some dimensions represent the
    coordinates on a map), or data that is both geospatial and time-dependent. In
    these data analysis tasks, data visualization is crucial; as such, xarray makes
    it easy to implement and call complex plotting functions on its data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at this through a quick example. First, we will read in an example
    dataset we have prepared for you, saved in a file named `2d_measurement.npy`,
    which can be read into a Python program using NumPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it is a 100x100x3 array. Let's say that this dataset contains
    a specific type of measurement, taken over a 100x100 grid of a two-dimensional
    space (corresponding to the first two axes) at three specific timestamps (corresponding
    to the third axis).
  prefs: []
  type: TYPE_NORMAL
- en: We would like to visualize these measurements as three squares, where each square
    represents a specific time stamp, and each pixel in each square represents the
    intensity of the corresponding measurement.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this in Matplotlib, we could use the `imshow` function, which takes in
    a two-dimensional array and plots it as an image. So, we would iterate through
    the three timestamps that we have and plot the corresponding grids one by one,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The index, `i`, iterates through the three indices of the third axis in the
    `measures` array. Again, we can see that this indexing scheme is not very expressive
    and readable. Here, we are also using the `colorbar` function to add a color bar
    to each of the plots.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding code produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10 – Regular imshow from Matplotlib ](img/Figure_3.10_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 – Regular imshow from Matplotlib
  prefs: []
  type: TYPE_NORMAL
- en: Although there is noise in the measurements, we can observe some global trends;
    specifically, we seem to have low-intensity measurements in the lower-left corner
    in the first plot, in the center in the second, and in the top-right corner in
    the third. As the final note, something we might want to change about this plot
    is making the three color bars have the same range, which may be hard to do with
    Matplotlib.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see how we can produce this plot using xarray. First, we must convert
    the NumPy array into a `DataArray` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are also specifying the names for the three dimensions: `''x''`, `''y''`,
    and `''time''`. This will allow us to manipulate the data more expressively, as
    we saw previously. To plot out the 2D grids, we can use the similarly named `imshow`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11 – Specialized imshow from xarray ](img/Figure_3.11_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 – Specialized imshow from xarray
  prefs: []
  type: TYPE_NORMAL
- en: 'The plotting function is much simpler than the for loop we had earlier. Furthermore,
    with minimal code, xarray has taken care of many different aesthetics-related
    aspects of this plot:'
  prefs: []
  type: TYPE_NORMAL
- en: First, the plots have their titles and x- and y-axis labels automatically created.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, by using a common color range, the fact that the measurements at the
    second timestamp are lower than those in the other two is now more obvious. This
    demonstrates that functions and methods in xarray are optimized to make working
    with labeled multidimensional data more efficient.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On the topic of plotting, many data scientists work with map data. xarray nicely
    integrates with the popular Cartopy library for geospatial data processing and
    offers many plotting functionalities that incorporate world and country maps.
    More details can be found in their documentation: [http://xarray.pydata.org/en/stable/plotting.html](http://xarray.pydata.org/en/stable/plotting.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to manipulate NumPy arrays and how to write
    fast mathematical expressions using array broadcasting. This knowledge will help
    you write more concise, expressive code and, at the same time, obtain substantial
    performance gains. We also introduced the `numexpr` library to further speed up
    NumPy calculations with minimal effort.
  prefs: []
  type: TYPE_NORMAL
- en: pandas implements efficient data structures that are useful when analyzing large
    datasets. In particular, pandas shines when the data is indexed by non-integer
    keys and provides very fast hashing algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy and pandas work well when handling large, homogenous inputs, but they
    are not suitable when the expressions become complex and the operations cannot
    be expressed using the tools provided by these libraries. xarray comes in handy
    as an alternative option where we need to work with labeled, multidimensional
    data.
  prefs: []
  type: TYPE_NORMAL
- en: In combination, the three libraries offer Python users powerful APIs and flexible
    functionalities to work with a wide range of data. By keeping them in your toolbox,
    you are well situated to tackle most data processing and engineering tasks using
    Python.
  prefs: []
  type: TYPE_NORMAL
- en: In other cases, we can also leverage Python capabilities as a glue language
    by interfacing it with C using the Cython package, as we will see in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Name the advantages NumPy has over Python-native lists when working with multidimensional
    data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are some of the database-style operations that pandas offers in its API?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What problems does xarray address and why can they not be addressed by NumPy
    or pandas?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An overview tutorial on NumPy and pandas: [https://cloudxlab.com/blog/numpy-pandas-introduction/](https://cloudxlab.com/blog/numpy-pandas-introduction/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data structures in xarray: [https://towardsdatascience.com/basic-data-structures-of-xarray-80bab8094efa](https://towardsdatascience.com/basic-data-structures-of-xarray-80bab8094efa)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
