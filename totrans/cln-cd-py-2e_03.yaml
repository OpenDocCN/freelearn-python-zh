- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: General Traits of Good Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a book about software construction with Python. Good software is built
    from a good design. By saying things such as clean code, you may be thinking that
    we will explore good practices that relate only to the implementation details
    of the software, instead of its design. However, this assumption would be wrong
    since the code is not something different from the design—the code *is* the design.
  prefs: []
  type: TYPE_NORMAL
- en: The code is probably the most detailed representation of the design. In the
    first two chapters, we discussed why structuring the code in a consistent way
    was important, and we have seen idioms for writing more compact and idiomatic
    code. Now it's time to understand that clean code is that, and much more—the ultimate
    goal is to make the code as robust as possible, and to write it in a way that
    minimizes defects or makes them utterly evident, should they occur.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter, and the one following, is focused on design principles at a higher
    level of abstraction. I will present the general principles of software engineering
    that are applied in Python.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, for this chapter, we will review different principles that make
    for good software design. Good quality software should be built around these ideas,
    and they will serve as design tools. That does not mean that all of them should
    always be applied; in fact, some of them represent different points of view (such
    is the case with the **Design by Contract** (**DbC**) approach, as opposed to
    defensive programming). Some of them depend on the context and are not always
    applicable.
  prefs: []
  type: TYPE_NORMAL
- en: High-quality code is a concept that has multiple dimensions. We can think of
    this similarly to how we think about the quality attributes of a software architecture.
    For example, we want our software to be secure and to have good performance, reliability,
    and maintainability, to name just a few attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goals of this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To understand the concepts behind robust software
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To learn how to deal with erroneous data during the workflow of the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To design maintainable software that can easily be extended and adapted to new
    requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To design reusable software
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To write effective code that will keep the productivity of the development team
    high
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design by contract
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some parts of the software we are working on are not meant to be called directly
    by users, but instead by other parts of the code. Such is the case when we divide
    the responsibilities of the application into different components or layers, and
    we have to think about the interaction between them.
  prefs: []
  type: TYPE_NORMAL
- en: We have to encapsulate some functionality behind each component and expose an
    interface to clients who are going to use that functionality, namely, an **Application
    Programming Interface** (**API**). The functions, classes, or methods we write
    for that component have a particular way of working under certain considerations
    that, if they are not met, will make our code crash. Conversely, clients calling
    that code expect a particular response, and any failure of our function to provide
    this would represent a defect.
  prefs: []
  type: TYPE_NORMAL
- en: That is to say that if, for example, we have a function that is expected to
    work with a series of parameters of type integers, and some other function invokes
    ours by passing strings, it is clear that it should not work as expected, but
    in reality, the function should not run at all because it was called incorrectly
    (the client made a mistake). This error should not pass silently.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, when designing an API, the expected input, output, and side effects
    should be documented. But documentation cannot enforce the behavior of the software
    at runtime. These rules, what every part of the code expects in order to work
    properly and what the caller is expecting from them, should be part of the design,
    and here is where the concept of a **contract** comes into place.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind the DbC approach is that, instead of implicitly placing in the
    code what every party is expecting, both parties agree on a contract that, if
    violated, will raise an exception, clearly stating why it cannot continue.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our context, a contract is a construction that enforces some rules that
    must be honored during the communication of software components. A contract entails
    mainly preconditions and postconditions, but in some cases, invariants, and side
    effects are also described:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preconditions**: We can say that these are all the checks the code will perform
    before running. It will check for all the conditions that have to be made before
    the function can proceed. In general, it''s implemented by validating the dataset
    provided in the parameters passed, but nothing should stop us from running all
    sorts of validations (for example, validating a set in a database, a file, or
    another method that was called before) if we consider that their side effects
    are overshadowed by the importance of such validations. Note that this imposes
    a constraint on the caller.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Postconditions**: The opposite of preconditions, here, the validations are
    done after the function call is returned. Postcondition validations are run to validate
    what the caller is expecting from this component.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Invariants**: Optionally, it would be a good idea to document, in the docstring
    of a function, the invariants, the things that are kept constant while the code
    of the function is running, as an expression of the logic of the function to be
    correct.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Side effects**: Optionally, we can mention any side effects of our code in
    the docstring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While conceptually, all of these items form part of the contract for a software
    component, and this is what should go to the documentation of such a piece, only
    the first two (preconditions and postconditions) are to be enforced at a low level
    (code).
  prefs: []
  type: TYPE_NORMAL
- en: The reason why we would design by contract is that if errors occur, they must
    be easy to spot (and by noticing whether it was either the precondition or postcondition
    that failed, we will find the culprit much more easily) so that they can be quickly
    corrected. More importantly, we want critical parts of the code to avoid being
    executed under the wrong assumptions. This should help to clearly mark the limits
    for the responsibilities and errors if they occur, as opposed to something saying
    that this part of the application is failing. But the caller code provided the
    wrong arguments, so where should we apply the fix?
  prefs: []
  type: TYPE_NORMAL
- en: The idea is that preconditions bind the client (they have an obligation to meet
    them if they want to run some part of the code), whereas postconditions bind the
    component in relation to some guarantees that the client can verify and enforce.
  prefs: []
  type: TYPE_NORMAL
- en: This way, we can quickly identify responsibilities. If the precondition fails,
    we know it is due to a defect on the client. On the other hand, if the postcondition
    check fails, we know the problem is in the routine or class (supplier) itself.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, regarding preconditions, it is important to highlight that they
    can be checked at runtime, and if they occur, the code that is being called should
    not be run at all (it does not make sense to run it because its conditions do
    not hold, and doing so might end up making things worse).
  prefs: []
  type: TYPE_NORMAL
- en: Preconditions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Preconditions are all of the guarantees a function or method expects to receive
    in order to work correctly. In general programming terms, this usually means providing
    data that is properly formed, for example, objects that are initialized, non-null
    values, and many more. For Python, in particular, being dynamically typed, this
    also means that sometimes we need to check for the exact type of data that is
    provided. This is not exactly the same as type checking, the `mypy` kind would
    do this, but rather verify the exact values that are needed.
  prefs: []
  type: TYPE_NORMAL
- en: Part of these checks can be detected early on by using static analysis tools,
    such as `mypy`, which we already introduced in *Chapter 1*, *Introduction, Code
    Formatting, and Tools*, but these checks are not enough. A function should have
    proper validation for the information that it is going to handle.
  prefs: []
  type: TYPE_NORMAL
- en: Now, this poses the question of where to place the validation logic, depending
    on whether we let the clients validate all the data before calling the function,
    or allow this one to validate everything that it received prior to running its
    own logic. The former equates to a tolerant approach (because the function itself
    is still allowing any data, potentially malformed data as well), whereas the latter
    equates to a demanding approach.
  prefs: []
  type: TYPE_NORMAL
- en: For the purposes of this analysis, we prefer a demanding approach when it comes
    to DbC because it is usually the safest choice in terms of robustness, and usually
    the most common practice in the industry.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the approach we decide to take, we should always keep in mind
    the non-redundancy principle, which states that the enforcement of each precondition
    for a function should be done by only one of the two parts of the contract, but
    not both. This means that we put the validation logic on the client, or we leave
    it to the function itself, but in no case should we duplicate it (which also relates
    to the DRY principle, which we will discuss later on in this chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Postconditions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Postconditions are the part of the contract that is responsible for enforcing
    the state after the method or function has returned.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming that the function or method has been called with the correct properties
    (that is, with its preconditions met), then the postconditions will guarantee
    that certain properties are preserved.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is to use postconditions to check and validate everything that a client
    might need. If the method executed properly, and the postcondition validations
    pass, then any client calling that code should be able to work with the returned
    object without problems, as the contract has been fulfilled.
  prefs: []
  type: TYPE_NORMAL
- en: Pythonic contracts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the time of writing this book, a PEP-316, named *Programming by Contract
    for Python*, is deferred. That doesn't mean that we cannot implement it in Python
    because, as introduced at the beginning of the chapter, this is a general design
    principle.
  prefs: []
  type: TYPE_NORMAL
- en: Probably the best way to enforce this is by adding control mechanisms to our
    methods, functions, and classes, and if they fail, raise a `RuntimeError` exception
    or `ValueError`. It's hard to devise a general rule for the correct type of exception,
    as that would pretty much depend on the application in particular. These previously
    mentioned exceptions are the most common types of exception, but if they don't
    fit accurately with the problem, creating a custom exception would be the best
    choice.
  prefs: []
  type: TYPE_NORMAL
- en: We would also like to keep the code as isolated as possible. That is, the code
    for the preconditions in one part, the one for the postconditions in another,
    and the core of the function separated. We could achieve this separation by creating
    smaller functions, but in some cases implementing a decorator would be an interesting
    alternative.
  prefs: []
  type: TYPE_NORMAL
- en: Design by contract – conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main value of this design principle is to effectively identify where the
    problem is. By defining a contract, when something fails at runtime, it will be
    clear what part of the code is broken, and what broke the contract.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of following this principle, the code will be more robust. Each
    component is enforcing its own constraints and maintaining some invariants, and
    the program can be proven correct as long as these invariants are preserved.
  prefs: []
  type: TYPE_NORMAL
- en: It also serves the purpose of clarifying the structure of the program better.
    Instead of trying to run ad hoc validations, or trying to surmount all possible
    failure scenarios, the contracts explicitly specify what each function or method
    expects to work properly, and what is expected from them.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, following these principles also adds extra work, because we are not
    just programming the core logic of our main application, but also the contracts.
    In addition, we might want to consider adding unit tests for these contracts as
    well. However, the quality gained by this approach pays off in the long run; hence,
    it is a good idea to implement this principle for critical components of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, for this method to be effective, we should carefully think about
    what we are willing to validate, and this has to be a meaningful value. For example,
    it would not make much sense to define contracts that only check for the correct
    data types of the parameters provided to a function. Many programmers would argue
    that this would be like trying to make Python a statically typed language. Regardless
    of this, tools such as `mypy`, in combination with the use of annotations, would
    serve this purpose much better and with less effort. With that in mind, design
    contracts so that there is actually value in them, checking, for example, the
    properties of the objects being passed and returned, the conditions they have
    to abide by, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Defensive programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Defensive programming follows a somewhat different approach to DbC. Instead
    of stating all conditions that must be held in a contract, which, if unmet, will
    raise an exception and make the program fail, this is more about making all parts
    of the code (objects, functions, or methods) able to protect themselves against
    invalid inputs.
  prefs: []
  type: TYPE_NORMAL
- en: Defensive programming is a technique that has several aspects, and it is particularly
    useful if it is combined with other design principles (this means that the fact
    that it follows a different philosophy to DbC does not mean that it is a case
    of either one or the other—it could mean that they might complement one another).
  prefs: []
  type: TYPE_NORMAL
- en: The main ideas on the subject of defensive programming are how to handle errors
    for scenarios that we might expect to occur, and how to deal with errors that
    should never occur (when impossible conditions happen). The former will fall into
    error handling procedures, while the latter will be the case for assertions. Both
    topics are explored in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Error handling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our programs, we resort to error handling procedures for situations that
    we anticipate as prone to cause errors. This is usually the case for data input.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind error handling is to gracefully respond to these expected errors
    in an attempt to either continue our program execution or decide to fail if the
    error turns out to be insurmountable.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different approaches by which we can handle errors on our programs,
    but not all of them are always applicable. Some of these approaches are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Value substitution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Error logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exception handling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next two sections, we'll focus on value substitution and exception handling,
    because these forms of error handling provide more interesting analysis. Error
    logging is a complementary practice (and a good one; we should always log errors),
    but most of the time we only log when there's nothing else to be done, so the
    other methods provide more interesting alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: Value substitution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In some scenarios, when there is an error and there is a risk of the software
    producing an incorrect value or failing entirely, we might be able to replace
    the result with another, safer value. We call this value substitution, since we
    are, in fact, replacing the actual erroneous result for a value that is to be
    considered non-disruptive (it could be a default, a well-known constant, a sentinel
    value, or simply something that does not affect the result at all, such as returning
    zero in a case where the result is intended to be applied to a sum).
  prefs: []
  type: TYPE_NORMAL
- en: Value substitution is not always possible, however. This strategy has to be
    carefully chosen for cases where the substituted value is a safe option. Making
    this decision is a trade-off between robustness and correctness. A software program
    is robust when it does not fail, even in the presence of an erroneous scenario.
    But this is not correct either.
  prefs: []
  type: TYPE_NORMAL
- en: This might not be acceptable for some kinds of software. If the application
    is critical, or the data being handled is too sensitive, this is not an option,
    since we cannot afford to provide users (or other parts of the application) with
    erroneous results. In these cases, we opt for correctness, rather than let the
    program explode when yielding the wrong results.
  prefs: []
  type: TYPE_NORMAL
- en: A slightly different, and safer, version of this decision is to use default
    values for data that is not provided. This can be the case for parts of the code
    that can work with a default behavior, for example, default values for environment
    variables that are not set, for missing entries in configuration files, or for
    parameters of functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can find examples of Python supporting this throughout different methods
    of its API, for example, dictionaries have a `get` method, whose (optional) second
    parameter allows you to indicate a default value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Environment variables have a similar API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In both previous examples, if the second parameter is not provided, `None`
    will be returned because it''s the default value those functions are defined with.
    We can also define default values for the parameters of our own functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In general, replacing missing parameters with default values is acceptable,
    but substituting erroneous data with legal close values is more dangerous and
    can mask some errors. Take this criterion into consideration when deciding on
    this approach.
  prefs: []
  type: TYPE_NORMAL
- en: Exception handling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the presence of incorrect or missing input data, sometimes it is possible
    to correct the situation with some examples, such as the ones mentioned in the
    previous section. In other cases, however, it is better to stop the program from
    continuing to run with the wrong data than to leave it computing under erroneous
    assumptions. In those cases, failing and notifying the caller that something is
    wrong is a good approach, and this is the case for a precondition that was violated,
    as we saw in DbC.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, erroneous input data is not the only possible way in which a function
    can go wrong. After all, functions are not just about passing data around; they
    also have side effects and connect to external components.
  prefs: []
  type: TYPE_NORMAL
- en: It could be possible that a fault in a function call is due to a problem on
    one of these external components, and not in our function itself. If that is the
    case, our function should communicate this properly. This will make it easier
    to debug. The function should clearly, and unambiguously, notify the rest of the
    application regarding errors that cannot be ignored so that they can be addressed
    accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: The mechanism for accomplishing this is an exception. It is important to emphasize
    that this is what exceptions should be used for—clearly announcing an exceptional
    situation, and not altering the flow of the program according to business logic.
  prefs: []
  type: TYPE_NORMAL
- en: If the code tries to use exceptions to handle expected scenarios or business
    logic, the flow of the program will become harder to read. This will lead to a
    situation where exceptions are used as a sort of `go-to` statement, which (to
    make things worse) could span multiple levels on the call stack (up to caller
    functions), violating the encapsulation of the logic into its correct level of
    abstraction. The case could get even worse if these `except` blocks are mixing
    business logic with truly exceptional cases that the code is trying to defend
    against; in that case, it will be harder to distinguish between the core logic
    we have to maintain and the errors to be handled.
  prefs: []
  type: TYPE_NORMAL
- en: Do not use exceptions as a `go-to` mechanism for business logic. Raise exceptions
    when there is something wrong with the code that callers need to be aware of.
  prefs: []
  type: TYPE_NORMAL
- en: This last concept is an important one; exceptions are usually about notifying
    the caller about something amiss. This means that exceptions should be used carefully
    because they weaken encapsulation. The more exceptions a function has, the more
    the caller function will have to anticipate, therefore knowing about the function
    it is calling. And if a function raises too many exceptions, this means that it
    is not so context-free, because every time we want to invoke it, we will have
    to keep all of its possible side effects in mind.
  prefs: []
  type: TYPE_NORMAL
- en: This can be used as a heuristic to tell when a function is not sufficiently
    cohesive and has too many responsibilities. If it raises too many exceptions,
    it could be a sign that it has to be broken down into multiple, smaller ones.
  prefs: []
  type: TYPE_NORMAL
- en: Here are some recommendations that relate to exceptions in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Handling exceptions at the right level of abstraction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Exceptions are also part of the principal functions that do one thing, and one
    thing only. The exception the function is handling (or raising) has to be consistent
    with the logic encapsulated on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we can see what we mean by mixing different levels
    of abstractions. Imagine an object that acts as a transport for some data in our
    application. It connects to an external component where the data is going to be
    sent upon decoding. In the following listing, we will focus on the `deliver_event`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: For our analysis, let's zoom in and focus on how the `deliver_event()` method
    handles exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: What does `ValueError` have to do with `ConnectionError`? Not much. By looking
    at these two highly different types of error, we can get an idea of how responsibilities
    should be divided.
  prefs: []
  type: TYPE_NORMAL
- en: '`ConnectionError` should be handled inside the `connect` method. This allows
    a clear separation of behavior. For example, if this method needs to support retries,
    then handling said exception would be a way of doing it.'
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, `ValueError` belongs to the `decode` method of the event. With this
    new implementation (shown in the next example), this method does not need to catch
    any exception—the exceptions we were worrying about before are either handled
    by internal methods or deliberately left to be raised.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should separate these fragments into different methods or functions. For
    the connection management, a small function should be enough. This function will
    be in charge of trying to establish the connection, catching exceptions (should
    they occur), and logging them accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will call this function in our method. As for the `ValueError` exception
    on the event, we could separate it with a new object and do composition, but for
    this limited case it would be overkill, so just moving the logic to a separate
    method would be enough. With these two considerations in place, the new version
    of the method looks much more compact and easier to read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: See now how the separation of the exception classes also delimits a separation
    in responsibilities. In the first example shown, everything was mixed, and there
    wasn't a clear separation of concerns. Then we decided the connection as a concern
    on itself, so in the next example, the `connect_with_retry` function was created,
    and `ConnectionError` was being handled as part of this function, if we needed
    to modify that function (as we had). On the other hand, the `ValueError` wasn't
    part of that same logic, so it was left in the `send` method where it belongs.
  prefs: []
  type: TYPE_NORMAL
- en: Exceptions carry a meaning. For that reason, it's important to handle each type
    of exception at its right level of abstraction (that means, depending on the layer
    of our application they belong to). But they can also carry important information
    sometimes. And since this information might be sensitive, we don't want it to
    fall into the wrong hands, so in the next section we'll discuss the security implications
    of exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Do not expose tracebacks to end users
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This is a security consideration. When dealing with exceptions, it might be
    acceptable to let them propagate if the error is too important, and maybe even
    let the program fail if this is the decision for that particular scenario and
    correctness was favored over robustness.
  prefs: []
  type: TYPE_NORMAL
- en: When there is an exception that denotes a problem, it's important to log in
    with as much detail as possible (including the traceback information, message,
    and all we can gather) so that the issue can be corrected efficiently. At the
    same time, we want to include as much detail as possible for ourselves—we don't
    want any of this becoming visible to users.
  prefs: []
  type: TYPE_NORMAL
- en: In Python, tracebacks of exceptions contain very rich and useful debugging information.
    Unfortunately, this information is also very useful for attackers or malicious
    users who want to try and harm the application, not to mention that the leak would
    represent an important information disclosure, jeopardizing the intellectual property
    of your organization (as parts of the code will be exposed).
  prefs: []
  type: TYPE_NORMAL
- en: If you choose to let exceptions propagate, make sure not to disclose any sensitive
    information. Also, if you have to notify users about a problem, choose generic
    messages (such as `Something went wrong`, or `Page not found`). This is a common
    technique used in web applications that display generic informative messages when an
    HTTP error occurs.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid empty except blocks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This was even referred to as the most diabolical Python anti-pattern (REAL 01).
    While it is good to anticipate and defend our programs against some errors, being
    too defensive might lead to even worse problems. In particular, the only problem
    with being too defensive is that there is an empty `except` block that silently
    passes without doing anything.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python is so flexible that it allows us to write code that can be faulty and
    yet, will not raise an error, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The problem with this is that it will not fail, ever, even when it should. It
    is also non-Pythonic if you remember from the Zen of Python that errors should
    never pass silently.
  prefs: []
  type: TYPE_NORMAL
- en: Configure your continuous integration environment (by using tools such as those
    explored in *Chapter 1*, *Introduction, Code Formatting, and Tools*) to automatically
    report on empty exception blocks.
  prefs: []
  type: TYPE_NORMAL
- en: In the event of an exception, this block of code will not fail, which might
    be what we wanted in the first place. But what if there is a defect? There might
    occur an actual failure when the `process_data()` function runs, and we would
    like to know if there is an error in our logic in order to be able to correct
    it. Writing blocks such as this one will mask problems, making things harder to
    maintain.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two alternatives:'
  prefs: []
  type: TYPE_NORMAL
- en: Catch a more specific exception (not too broad, such as an `Exception`). In
    fact, some linting tools and IDEs will warn you in some cases when the code is
    handling too broad an exception.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform some actual error handling on the `except` block.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best thing to do would be to apply both recommendations. Handling a more
    specific exception (for example, `AttributeError` or `KeyError`) will make the
    program more maintainable because the reader will know what to expect and can
    get an idea of the *why* of it. It will also leave other exceptions free to be
    raised, and if that happens, this probably means a bug, only this time it can
    be discovered.
  prefs: []
  type: TYPE_NORMAL
- en: Handling the exception itself can mean multiple things. In its simplest form,
    it could be just about logging the exception (make sure to use `logger.exception`
    or `logger.error` to provide the full context of what happened). Other alternatives
    could be to return a default value (substitution, only that in this case after
    detecting an error, not prior to causing it), or raising a different exception.
  prefs: []
  type: TYPE_NORMAL
- en: If you choose to raise a different exception, include the original exception
    that caused the problem (see the next section).
  prefs: []
  type: TYPE_NORMAL
- en: 'Another reason to avoid having an empty `except` block (using `pass`) is the
    implicitness of it: it doesn''t tell readers of the code that we actually expect
    that exception to be ignored. A more explicit way of doing so would be to use
    the `contextlib.suppress` function, which can accept all exceptions as arguments
    that are to be ignored, and it can be used as a context manager.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, it might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Again, as with the previous case, try to avoid passing the general `Exception`
    to this context manager, because the effect will be the same.
  prefs: []
  type: TYPE_NORMAL
- en: Include the original exception
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As part of our error handling logic, we might decide to raise a different one,
    and maybe even change its message. If that is the case, it is recommended to include
    the original exception that led to that.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the `raise <e> from <original_exception>` syntax (PEP-3134). When
    using this construction, the original traceback will be embedded into the new
    exception, and the original exception will be set in the `__cause__` attribute
    of the resulting one.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we desire to wrap default exceptions with custom ones internally
    to our project, we could still do that while including information about the root
    exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Always use the `raise <e> from <o>` syntax when changing the type of the exception.
  prefs: []
  type: TYPE_NORMAL
- en: Using this syntax will make the tracebacks contain more information about the
    exception or the error that has just occurred, which will help significantly when
    debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Using assertions in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Assertions are to be used for situations that should never happen, so the expression
    on the `assert` statement has to mean an impossible condition. Should this condition
    happen, it means there is a defect in the software.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to the error handling approach, there are situations in which we
    don't want our program to continue its execution if a particular error occurred.
    This is because, in some cases, the error cannot be surmounted, and our program
    cannot correct its course of execution (or self-heal), so it's better to fail
    fast, and let the error be noticed, so it can be corrected with the next version
    upgrade.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of using assertions is to prevent the program from causing further
    damage if such an invalid scenario is presented. Sometimes, it is better to stop
    and let the program crash rather than let it continue processing under the wrong
    assumptions.
  prefs: []
  type: TYPE_NORMAL
- en: By definition, an assertion is a Boolean condition in the code that must hold
    true for the program to be correct. If the program fails because of an `AssertionError`,
    it means a defect has just been uncovered.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this reason, assertions should not be mixed with the business logic, or
    used as control flow mechanisms for the software. The following example is a bad
    idea:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Do not catch the `AssertionError` exception because it might be confusing for
    readers of the code. If you're expecting some part of your code to raise an exception,
    try to use a more specific one.
  prefs: []
  type: TYPE_NORMAL
- en: The previous advice of catching the `AssertionError` goes along the lines of
    not letting your program fail silently. But it could fail gracefully. So, instead
    of letting the application have a hard crash, you can catch the `AssertionError`
    and show a generic error message, while still logging all the internal error details
    to the logging platform of your company. The point is not exactly about whether
    or not to catch this exception, but that assertion errors are a valuable source
    of information that will help you improve the quality of your software.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that the program terminates when an assertion fails. This means that
    assertions are usually put in the code to identify erroneous parts of the program.
    There's a tendency in many programming languages to think that assertions can
    be suppressed when the program is running in production, but that defeats its
    purpose, because the point of them is to precisely let us know about those parts
    of the program that need to be fixed.
  prefs: []
  type: TYPE_NORMAL
- en: In Python, in particular, running with the `–O` flag will suppress the `assert`
    statements, but this is discouraged for the aforementioned reasons.
  prefs: []
  type: TYPE_NORMAL
- en: Do not run your production programs with `python –O` … as you'd like to take
    advantage of the assertions in the code to correct defects.
  prefs: []
  type: TYPE_NORMAL
- en: Include a descriptive error message in the assertion statement and log the errors
    to make sure that you can properly debug and correct the problem later on.
  prefs: []
  type: TYPE_NORMAL
- en: Another important reason why the previous code is a bad idea is that besides
    catching `AssertionError`, the statement in the assertion is a function call.
    Function calls can have side effects, and they aren't always repeatable (we don't
    know if calling `condition.holds()` again will yield the same result). Moreover,
    if we stop the debugger at that line, we might not be able to conveniently see
    the result that causes the error, and, again, even if we call that function again,
    we don't know if that was the offending value.
  prefs: []
  type: TYPE_NORMAL
- en: 'A better alternative requires a few more lines of code, but provides more useful
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: When using assertions, try to avoid using function calls directly, and write
    the expression in terms of local variables.
  prefs: []
  type: TYPE_NORMAL
- en: What's the relationship between assertions and exception handling? Some might
    ask if assertions are moot, in the light of exception handling. Why would you
    want to assert for a condition if we can check that with an `if` statement and
    raise an exception? There's a subtle difference, though. In general, exceptions
    are for handling unexpected situations in relation to the business logic that
    our program will want to consider, whereas assertions are like self-checking mechanisms
    put in the code, to validate (assert) its correctness.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this reason, exception raising will be much more common than having `assert`
    statements. Typical uses of `assert` are situations where an algorithm maintains
    an invariant logic that must be kept at all times: in that case, you might want
    to assert for the invariant. If this is broken at some point, it means either
    the algorithm is wrong or poorly implemented.'
  prefs: []
  type: TYPE_NORMAL
- en: We have explored defensive programming in Python, and some related topics regarding
    exception handling. Now, we move on to the next big topic, as the next section
    discusses the separation of concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Separation of concerns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a design principle that is applied at multiple levels. It is not just
    about the low-level design (code), but it is also relevant at a higher level of
    abstraction, so it will come up later when we talk about architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Different responsibilities should go into different components, layers, or modules
    of the application. Each part of the program should only be responsible for a
    part of the functionality (what we call its concerns) and should know nothing
    about the rest.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of separating concerns in software is to enhance maintainability by
    minimizing ripple effects. A **ripple** effect means the propagation of a change
    in the software from a starting point. This could be the case of an error or exception
    triggering a chain of other exceptions, causing failures that will result in a
    defect on a remote part of the application. It can also be that we have to change
    a lot of code scattered through multiple parts of the code base, as a result of
    a simple change in a function definition.
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, we do not want these scenarios to happen. The software has to be easy
    to change. If we have to modify or refactor some part of the code, this has to
    have a minimal impact on the rest of the application, and the way to achieve this
    is through proper encapsulation.
  prefs: []
  type: TYPE_NORMAL
- en: In a similar way, we want any potential errors to be contained so that they
    don't cause major damage.
  prefs: []
  type: TYPE_NORMAL
- en: This concept is related to the DbC principle in the sense that each concern
    can be enforced by a contract. When a contract is violated, and an exception is
    raised as a result of such a violation, we know what part of the program has the
    failure, and what responsibilities failed to be met.
  prefs: []
  type: TYPE_NORMAL
- en: Despite this similarity, separation of concerns goes further. We normally think
    of contracts between functions, methods, or classes, and while this also applies
    to responsibilities that have to be separated, the idea of the separation of concerns
    also applies to Python modules, packages, and basically any software component.
  prefs: []
  type: TYPE_NORMAL
- en: Cohesion and coupling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These are important concepts for good software design.
  prefs: []
  type: TYPE_NORMAL
- en: On the one hand, `cohesion` means that objects should have a small and well-defined
    purpose, and they should do as little as possible. It follows a similar philosophy
    as Unix commands that do only one thing and do it well. The more cohesive our
    objects are, the more useful and reusable they become, making our design better.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, `coupling` refers to the idea of how two or more objects
    depend on each other. This dependency poses a limitation. If two parts of the
    code (objects or methods) are too dependent on each other, they bring with them
    some undesired consequences:'
  prefs: []
  type: TYPE_NORMAL
- en: '**No code reuse**: If one function depends too much on a particular object,
    or takes too many parameters, it''s coupled with this object, which means that
    it will be really difficult to use that function in a different context (to do
    so, we will have to find a suitable parameter that complies with a very restrictive
    interface).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ripple effects**: Changes in one of the two parts will certainly impact the
    other, as they are too close.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low level of abstraction**: When two functions are so closely related, it
    is hard to see them as different concerns resolving problems at different levels
    of abstraction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rule of thumb: Well-defined software will achieve high cohesion and low coupling.'
  prefs: []
  type: TYPE_NORMAL
- en: Acronyms to live by
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will review some principles that yield some good design
    ideas. The point is to quickly relate to good software practices by acronyms that
    are easy to remember, working as a sort of mnemonic rule. If you keep these words
    in mind, you will be able to associate them with good practices more easily and
    finding the right idea behind a particular line of code that you are looking at
    will be faster.
  prefs: []
  type: TYPE_NORMAL
- en: These are by no means formal or academic definitions, but more like empirical
    ideas that emerged from years of working in the software industry. Some of them
    do appear in books, as they were coined by important authors (see the references
    to investigate them in more detail), and others have their roots probably in blog
    posts, papers, or conference talks.
  prefs: []
  type: TYPE_NORMAL
- en: DRY/OAOO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ideas of **Don't Repeat Yourself** (**DRY**) and **Once and Only Once**
    (**OAOO**) are closely related, so they were included together here. They are
    self-explanatory, and you should avoid duplication at all costs.
  prefs: []
  type: TYPE_NORMAL
- en: Things in the code, knowledge, have to be defined only once and in a single
    place. When you have to make a change to the code, there should be only one rightful
    location to modify. Failure to do so is a sign of a poorly designed system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code duplication is a problem that directly impacts maintainability. It is
    very undesirable to have code duplication because of its many negative consequences:'
  prefs: []
  type: TYPE_NORMAL
- en: '**It''s error prone**: When some logic is repeated multiple times throughout
    the code, and this needs to change, it means we depend on efficiently correcting
    all the instances with this logic, without forgetting any of them, because in
    that case there will be a bug.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**It''s expensive**: Linked to the previous point, making a change in multiple
    places takes much more time (development and testing effort) than if it was defined
    only once. This will slow the team down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**It''s unreliable**: Also linked to the first point, when multiple places
    need to be changed for a single change in the context, you rely on the person
    who wrote the code to remember all the instances where the modification has to
    be made. There is no single source of truth.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duplication is often caused by ignoring (or forgetting) that code represents
    knowledge. By giving meaning to certain parts of the code, we are identifying
    and labeling that knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what this means with an example. Imagine that, in a study center,
    students are ranked by the following criteria: 11 points per exam passed, minus
    five points per exam failed, and minus two per year in the institution. The following
    is not actual code, but just a representation of how this might be scattered in
    a real code base:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the lambda, which is in the key of the sorted function, represents
    some valid knowledge from the domain problem, yet it doesn't reflect it (it doesn't
    have a name, a proper and rightful location, there is no meaning assigned to that
    code, nothing). This lack of meaning in the code leads to the duplication we find
    when the score is printed out while listing the raking.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should reflect our knowledge of our domain problem in our code, and our
    code will then be less likely to suffer from duplication and will be easier to
    understand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'A fair disclaimer: This is just an analysis of one of the traits of code duplication.
    In reality, there are more cases, types, and taxonomies of code duplication. Entire
    chapters could be dedicated to this topic, but here we focus on one particular
    aspect to make the idea behind the acronym clear.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we have taken what is probably the simplest approach to eliminating
    duplication: creating a function. Depending on the case, the best solution would
    be different. In some cases, there might be an entirely new object that has to
    be created (maybe an entire abstraction was missing). In other cases, we can eliminate
    duplication with a context manager. Iterators or generators (described in *Chapter
    7*, *Generators, Iterators, and Asynchronous Programming*) could also help to
    avoid repetition in the code, and decorators (explained in *Chapter 5*, *Using
    Decorators to Improve Our Code*) will also help.'
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, there is no general rule or pattern to tell you which of the
    features of Python are the most suitable when it comes to addressing code duplication,
    but hopefully, after seeing the examples in this book, and how the elements of
    Python are used, the reader will be able to develop their own intuition.
  prefs: []
  type: TYPE_NORMAL
- en: YAGNI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**YAGNI** (short for **You Ain''t Gonna Need It**) is an idea you might want
    to keep in mind very often when writing a solution if you do not want to over-engineer
    it.'
  prefs: []
  type: TYPE_NORMAL
- en: We want to be able to easily modify our programs, so we want to make them future-proof.
    In line with that, many developers think that they have to anticipate all future
    requirements and create solutions that are very complex, and so create abstractions
    that are hard to read, maintain, and understand. Sometime later, it turns out
    that those anticipated requirements do not show up, or they do but in a different
    way (surprise!), and the original code that was supposed to handle precisely that
    does not work.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is that now it is even harder to refactor and extend our programs.
    What happened was that the original solution did not handle the original requirements
    correctly, and neither do the current ones, simply because it is the wrong abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: Having maintainable software is not about anticipating future requirements (do
    not do futurology!). It is about writing software that only addresses current
    requirements in such a way that it will be possible (and easy) to change later
    on. In other words, when designing, make sure that your decisions don't tie you
    down, and that you will be able to keep on building, but do not build more than
    what's necessary.
  prefs: []
  type: TYPE_NORMAL
- en: It's usually tempting to not follow this idea in some cases in which we're aware
    of principles that we think might apply or save time for us. For example, later
    in the book, we'll review design patterns, which are common solutions for typical
    situations of object-oriented design. While it's important to study design patterns,
    we must refuse the temptation to apply them prematurely as it might fall into
    a violation of the YAGNI principle.
  prefs: []
  type: TYPE_NORMAL
- en: For example, imagine you're creating a class to encapsulate the behavior of
    a component. You know it's needed, but then you think that more (and similar)
    requirements will come in the future, so it might be tempting to create a base
    class (as to define an interface with the methods that must be implemented), and
    then make the class you were just creating a subclass that implement that interface.
    This would be wrong for several reasons. First, all you need now is the class
    that was being created in the first place (investing more time in over-generalizing
    a solution that we don't know we'll need is not a good way of managing our resources).
    And then, that base class is being biased by the current requirements, so it'll
    likely not be the correct abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: 'The best approach would be to write only what''s needed now in a way that doesn''t
    hinder further improvements. If, later on, more requirements come in, we can think
    about creating a base class, abstract some methods, and perhaps we will discover
    a design pattern that emerged for our solution. This is also the way object-oriented
    design is supposed to work: bottom-up.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, I wanted to emphasize that YAGNI is an idea that also applies to software
    architecture (not just detailed code).
  prefs: []
  type: TYPE_NORMAL
- en: KIS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**KIS** (stands for **Keep It Simple**) relates very much to the previous point.
    When you are designing a software component, avoid over-engineering it. Ask yourself
    if your solution is the minimal one that fits the problem.'
  prefs: []
  type: TYPE_NORMAL
- en: Implement minimal functionality that correctly solves the problem and does not
    complicate your solution more than is necessary. Remember, the simpler the design,
    the more maintainable it will be.
  prefs: []
  type: TYPE_NORMAL
- en: This design principle is an idea we will want to keep in mind at all levels
    of abstraction, whether we are thinking of a high-level design, or addressing
    a particular line of code.
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, think about the components we are creating. Do we really need
    all of them? Does this module actually require being utterly extensible right
    now? Emphasize the last part—maybe we want to make that component extensible,
    but now is not the right time, or it is not appropriate to do so because we still
    do not have enough information to create the proper abstractions, and trying to
    come up with generic interfaces at this point will only lead to even worse problems.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of code, keeping it simple usually means using the smallest data structure
    that fits the problem. You will most likely find it in the standard library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, we might over-complicate code, creating more functions or methods
    than are necessary. The following class creates a namespace from a set of keyword
    arguments that have been provided, but it has a rather complicated code interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Having an extra class method for initializing the object doesn''t seem necessary.
    Then, the iteration and the call to `setattr` inside it make things even more
    strange, and the interface that is presented to the user is not very clear:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The user has to know of the existence of this other method, which is not convenient.
    It would be better to keep it simple, and just initialize the object as we initialize
    any other object in Python (after all, there is a method for that) with the `__init__`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember the Zen of Python: Simple is better than complex.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many scenarios in Python in which we would like to keep our code
    simple. One of them relates to something we''ve explored before: code duplication.
    A common way to abstract code in Python is by using decorators (which we''ll see
    later on, in *Chapter 5*, *Using Decorators to Improve Our Code*). But what if
    we''re trying to avoid duplication of a small section, let''s say three lines
    of code? In that case, writing the decorator would probably take more lines and
    be more trouble for the simple duplicated lines we''re trying to solve. In this
    case, apply common sense and be pragmatic. Accept that a small amount of duplication
    might be better than a complicated function (that is, of course, unless you find
    an even simpler way of removing the duplication and keeping the code simple!).'
  prefs: []
  type: TYPE_NORMAL
- en: As part of keeping the code simple, I would recommend avoiding advanced features
    of Python, like meta-classes (or anything related to meta-programming in general),
    because not only are these features hardly required (there are very special justifications
    for their use!), but also, they make the code much more complicated to read, and
    harder to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: EAFP/LBYL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**EAFP** stands for **Easier to Ask Forgiveness than Permission**, while **LBYL**
    stands for **Look Before You Leap**.'
  prefs: []
  type: TYPE_NORMAL
- en: The idea of EAFP is that we write our code so that it performs an action directly,
    and then we take care of the consequences later in case it doesn't work. Typically,
    this means try running some code, expecting it to work, but catching an exception
    if it doesn't, and then handling the corrective code on the `except` block.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the opposite of LBYL. As its name says, in the *look before you leap*
    approach, we first check what we are about to use. For example, we might want
    to check whether a file is available before trying to operate with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The EAFP version of the previous code would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If you are coming from other languages, such as C, which doesn't have exceptions,
    then it's logical that will find the LBYL approach of more use. And in other languages
    such as C++, there is some discouragement towards the use of exceptions due to
    performance considerations, but this doesn't generally hold true in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Particular cases might of course apply, but most of the time, you'll find the
    EAFP version to be more intention-revealing. The code written this way would be
    easier to read, because it goes directly to the task needed instead of preventively
    checking conditions. Put another way, in the last example, you'll see a part of
    the code that tries to open a file and then process it. If the file doesn't exist,
    then we handle that case. In the first example, we'll see a function checking
    whether a file exists, and then trying to do something. You might argue that this
    is also clear, but we don't know for sure. Maybe the file being asked about is
    a different one or is a function that belongs to a different layer of the program,
    or a leftover, and such like. The second approach is less error-prone when you
    look at the code at first glance.
  prefs: []
  type: TYPE_NORMAL
- en: You can apply both ideas as they make sense in your particular code, but in
    general, code written in an EAFP fashion would be easier to pick at first glance,
    so in case of doubt, I'd recommend you choose this variant.
  prefs: []
  type: TYPE_NORMAL
- en: Inheritance in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In object-oriented software design, there are often discussions as to how to
    address some problems by using the main ideas of the paradigm (polymorphism, inheritance,
    and encapsulation).
  prefs: []
  type: TYPE_NORMAL
- en: Probably the most commonly used of these ideas is inheritance—developers often
    start by creating a class hierarchy with the classes they are going to need and
    decide the methods each one should implement.
  prefs: []
  type: TYPE_NORMAL
- en: While inheritance is a powerful concept, it does come with its perils. The main
    one is that every time we extend a base class, we are creating a new one that
    is tightly coupled with the parent. As we have already discussed, coupling is
    one of the things we want to reduce to a minimum when designing software.
  prefs: []
  type: TYPE_NORMAL
- en: One of the main scenarios developers relate inheritance with is code reuse.
    While we should always embrace code reuse, it is not a good idea to force our
    design to use inheritance to reuse code just because we get the methods from the
    parent class for free. The proper way to reuse code is to have highly cohesive
    objects that can be easily composed and that could work on multiple contexts.
  prefs: []
  type: TYPE_NORMAL
- en: When inheritance is a good decision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have to be careful when creating a derived class because this is a double-edged
    sword—on the one hand, it has the advantage that we get all the code of the methods
    from the parent class for free, but on the other hand, we are carrying all of
    them to a new class, meaning that we might be placing too much functionality in
    a new definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'When creating a new subclass, we have to think if it is actually going to use
    all of the methods it has just inherited, as a heuristic to see whether the class
    is correctly defined. If instead, we find out that we do not need most of the
    methods, and have to override or replace them, this is a design mistake that could
    be caused by a number of reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: The superclass is vaguely defined and contains too much responsibility, instead
    of a well-defined interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The subclass is not a proper specialization of the superclass it is trying to
    extend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good case for using inheritance is the type of situation when you have a class
    that defines certain components with its behavior that are defined by the interface
    of this class (its `public` methods and attributes), and then you need to specialize
    this class in order to create objects that do the same but with something else
    added, or with some particular parts of its behavior changed.
  prefs: []
  type: TYPE_NORMAL
- en: You can find examples of good uses of inheritance in the Python standard library
    itself. For example, in the `http.server` package ([https://docs.python.org/3/library/http.server.html#http.server.BaseHTTPRequestHandler](https://docs.python.org/3/library/http.server.html#http.server.BaseHTTPRequestHandler)),
    we can find a base class such as `BaseHTTPRequestHandler`, and subclasses such
    as `SimpleHTTPRequestHandler`, that extend this one by adding or changing part
    of its base interface.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of interface definition, this is another good use of inheritance. When
    we want to enforce the interface of some objects, we can create an abstract base
    class that does not implement the behavior itself, but instead just defines the
    interface—every class that extends this one will have to implement these to be
    a proper subtype.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, another good case for inheritance is exceptions. We can see that the
    standard exception in Python derives from `Exception`. This is what allows you
    to have a generic clause such as `except Exception`, which will catch every possible
    error. The important point is the conceptual one; they are classes derived from
    `Exception` because they are more specific exceptions. This also works in well-known
    libraries such as `requests`, for instance, in which an `HTTPError` is a `RequestException`,
    which, in turn, is an `IOError`.
  prefs: []
  type: TYPE_NORMAL
- en: Anti-patterns for inheritance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the previous section had to be summarized in a single word, it would be *specialization*.
    The correct use of inheritance is to specialize objects and create more detailed
    abstractions starting from base ones.
  prefs: []
  type: TYPE_NORMAL
- en: The parent (or base) class is part of the `public` definition of the new derived
    class. This is because the methods that are inherited will be part of the interface
    of this new class. For this reason, when we read the `public` methods of a class,
    they have to be consistent with what the parent class defines.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we see that a class derived from `BaseHTTPRequestHandler` implements
    a method named `handle()`, it would make sense because it is overriding one of
    the parents. If it had any other method whose name relates to an action that has
    to do with an HTTP request, then we could also think that is correctly placed
    (but we would not think that if we found something called `process_purchase()`
    on that class).
  prefs: []
  type: TYPE_NORMAL
- en: The previous illustration might seem obvious, but it is something that happens
    very often, especially when developers try to use inheritance with the sole goal
    of reusing code. In the next example, we will see a typical situation that represents
    a common anti-pattern in Python—there is a domain problem that has to be represented,
    and a suitable data structure is devised for that problem, but instead of creating
    an object that uses such a data structure, the object becomes the data structure
    itself.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see these problems more concretely through an example. Imagine we have
    a system for managing insurance, with a module in charge of applying policies
    to different clients. We need to keep in memory a set of customers that are being
    processed at the time in order to apply those changes before further processing
    or persistence. The basic operations we need are to store a new customer with
    its records as satellite data, apply a change to a policy, or edit some of the
    data, to name but a few. We also need to support a batch operation. That is, when
    something on the policy itself changes (the one this module is currently processing),
    we have to apply these changes overall to customers on the current transaction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thinking in terms of the data structure we need, we realize that accessing
    the record for a particular customer in constant time is a nice trait. Therefore,
    something like `policy_transaction[customer_id]` looks like a nice interface.
    From this, we might think that a `subscriptable` object is a good idea, and further
    on, we might get carried away into thinking that the object we need is a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'With this code, we can get information about a policy for a customer by its
    identifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Sure, we achieved the interface we wanted in the first place, but at what cost?
    Now, this class has a lot of extra behavior from carrying out methods that weren''t
    necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: There are (at least) two major problems with this design. On the one hand, the
    hierarchy is wrong. Creating a new class from a base one conceptually means that
    it's a more specific version of the class it's extending (hence the name). How
    is it that a `TransactionalPolicy` is a dictionary? Does this make sense? Remember,
    this is part of the public interface of the object, so users will see this class
    and its hierarchy and will notice such an odd specialization as well as its public
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: This leads us to the second problem—coupling. The interface of the transactional
    policy now includes all methods from a dictionary. Does a transactional policy
    really need methods such as `pop()` or `items()`? However, there they are. They
    are also `public`, so any user of this interface is entitled to call them, with
    whatever undesired side effect they may carry. More on this point—we don't really
    gain much by extending a dictionary. The only method it actually needs to update
    for all customers affected by a change in the current policy (`change_in_policy()`)
    is not on the base class, so we will have to define it ourselves either way.
  prefs: []
  type: TYPE_NORMAL
- en: This is a problem of mixing implementation objects with domain objects. A dictionary
    is an implementation object, a data structure, suitable for certain kinds of operation,
    and with a trade-off like all data structures. A transactional policy should represent
    something in the domain problem, an entity that is part of the problem we are
    trying to solve.
  prefs: []
  type: TYPE_NORMAL
- en: Don't mix implementation data structures with business domain classes in the
    same hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchies like this one are incorrect, and just because we get a few magic
    methods from a base class (to make the object subscriptable by extending a dictionary)
    is not reason enough to create such an extension. Implementation classes should
    be extended solely when creating other, more specific, implementation classes.
    In other words, extend a dictionary if you want to create another (more specific,
    or slightly modified) dictionary. The same rule applies to classes of the domain
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'The correct solution here is to use composition. `TransactionalPolicy` is not
    a dictionary—it uses a dictionary. It should store a dictionary in a `private`
    attribute, and implement `__getitem__()` by proxying from that dictionary and
    then only implementing the rest of the `public` method it requires:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This way is not only conceptually correct, but also more extensible. If the
    underlying data structure (which, for now, is a dictionary) is changed in the
    future, callers of this object will not be affected, so long as the interface
    is maintained. This reduces coupling, minimizes ripple effects, allows for better
    refactoring (unit tests ought not to be changed), and makes the code more maintainable.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple inheritance in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python supports multiple inheritance. As inheritance, when improperly used,
    leads to design problems, you could also expect that multiple inheritance will
    also yield even bigger problems when it's not correctly implemented.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple inheritance is, therefore, a double-edged sword. It can also be very
    beneficial in some cases. Just to be clear, there is nothing wrong with multiple
    inheritance—the only problem it has is that when it's not implemented correctly,
    it will multiply the problems.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple inheritance is a perfectly valid solution when used correctly, and
    this opens up new patterns (such as the adapter pattern we discussed in *Chapter
    9*, *Common Design Patterns*) and mixins.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most powerful applications of multiple inheritance is perhaps that
    which enables the creation of mixins. Before exploring mixins, we need to understand
    how multiple inheritance works, and how methods are resolved in a complex hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: Method Resolution Order (MRO)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some people don''t like multiple inheritance because of the constraints it
    has in other programming languages, for instance, the so-called diamond problem.
    When a class extends from two or more classes, and all of those classes also extend
    from other base classes, the bottom ones will have multiple ways to resolve the
    methods coming from the top-level classes. The question is: Which of these implementations
    is used?'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following diagram, which has a structure with multiple inheritance.
    The top-level class has a class attribute and implements the `__str__` method.
    Think of any of the concrete classes, for example, `ConcreteModuleA12`—it extends
    from `BaseModule1` and `BaseModule2`, and each one of them will take the implementation
    of `__str__` from `BaseModule`. Which of these two methods is going to be the
    one for `ConcreteModuleA12`?
  prefs: []
  type: TYPE_NORMAL
- en: '![Picture 1](img/B16567_03_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: Method Resolution Order'
  prefs: []
  type: TYPE_NORMAL
- en: 'With the value of the class attribute, this will become evident:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s test this to see what method is being called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: There is no collision. Python resolves this by using an algorithm called C3
    linearization or MRO, which defines a deterministic way in which methods are going
    to be called.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, we can specifically ask the class for its resolution order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Knowing about how the method is going to be resolved in a hierarchy can be used
    to our advantage when designing classes because we can make use of mixins.
  prefs: []
  type: TYPE_NORMAL
- en: Mixins
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A mixin is a base class that encapsulates some common behavior with the goal
    of reusing code. Typically, a mixin class is not useful on its own, and extending
    this class alone will certainly not work, because most of the time it depends
    on methods and properties that are defined in other classes. The idea is to use
    mixin classes along with other ones, through multiple inheritance, so that the
    methods or properties used on the mixin will be available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine we have a simple parser that takes a `string` and provides iteration
    over it by its values separated by hyphens (`-`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This is quite straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'But now we want the values to be sent in uppercase, without altering the base
    class. For this simple example, we could just create a new class, but imagine
    that a lot of classes are already extending from `BaseTokenizer`, and we don''t
    want to replace all of them. We can mix a new class into the hierarchy that handles
    this transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The new `Tokenizer` class is really simple. It doesn't need any code because
    it takes advantage of the mixin. This type of mixin acts as a sort of decorator.
    Based on what we just saw, `Tokenizer` will take `__iter__` from the mixin, and
    this one, in turn, delegates to the next class on the line (by calling `super()`),
    which is `BaseTokenizer`, but it converts its values to uppercase, thereby creating
    the desired effect.
  prefs: []
  type: TYPE_NORMAL
- en: As we have discussed inheritance in Python, we've seen topics such as cohesion
    and coupling that are important to the design of our software. These concepts
    appear repeatedly in software design, and they can also be analyzed from the lens
    of functions and their arguments, which we explore in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Arguments in functions and methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Python, functions can be defined to receive arguments in several different
    ways, and these arguments can also be provided by callers in multiple ways.
  prefs: []
  type: TYPE_NORMAL
- en: There is also an industry-wide set of practices for defining interfaces in software
    engineering that closely relate to the definition of arguments in functions.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will first explore the mechanics of arguments in Python
    functions and then review the general principles of software engineering that
    relate to good practices regarding this subject to finally relate both concepts.
  prefs: []
  type: TYPE_NORMAL
- en: How function arguments work in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let's review the particularities of how arguments are passed to functions
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: By first understanding the possibilities that Python offers for handling parameters,
    we will be able to assimilate general rules more easily, and the idea is that
    after having done so, we can easily draw conclusions on what good patterns or
    idioms are when handling arguments. Then, we can identify in which scenarios the
    Pythonic approach is the correct one, and in which cases we might be abusing the features
    of the language.
  prefs: []
  type: TYPE_NORMAL
- en: How arguments are copied to functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first rule in Python is that all arguments are passed by a value. Always.
    This means that when passing values to functions, they are assigned to the variables
    on the signature definition of the function to be later used on it.
  prefs: []
  type: TYPE_NORMAL
- en: You will notice that a function may or may not mutate the parameters it receives,
    depending on their type. If we are passing `mutable` objects, and the body of
    the function modifies this, then of course, we have the side effect that they
    will have been changed by the time the function returns.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following, we can see the difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This might look like an inconsistency, but it's not. When we pass the first
    argument, a `string`, this is assigned to the argument on the `function`. Since
    `string` objects are immutable, a statement such as `argument += <expression>`
    will, in fact, create the new object, `argument + <expression>`, and assign that
    back to the argument. At that point, an argument is just a local variable inside
    the scope of the function and has nothing to do with the original one in the caller.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, when we pass `list`, which is a `mutable` object, then that
    statement has a different meaning (it is equivalent to `calling .extend()` on
    that `list`). This operator acts by modifying the `list` in place over a variable
    that holds a reference to the original `list` object, hence modifying it. What
    happened in this second case is that the `list`''s reference was passed by a value
    to the function. But since it''s a reference, it is mutating the original `list`
    object, so we see the mutation after the function has finished. It''s roughly
    equivalent to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We have to be careful when dealing with `mutable` objects because it can lead
    to unexpected side effects. Unless you are absolutely sure that it is correct
    to manipulate `mutable` arguments in this way, I would recommend avoiding it and
    going for alternatives without these problems.
  prefs: []
  type: TYPE_NORMAL
- en: Don't mutate function arguments. In general, try to avoid unnecessary side effects
    in functions as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Arguments in Python can be passed by position, as in many other programming
    languages, but also by keyword. This means that we can explicitly tell the function
    which values we want for which of its parameters. The only caveat is that after
    a parameter is passed by a keyword, the rest that follow must also be passed this
    way, otherwise, `SyntaxError` will be raised.
  prefs: []
  type: TYPE_NORMAL
- en: Variable number of arguments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Python, as well as other languages, has built-in functions and constructions
    that can take a variable number of arguments. Consider, for example, `string`
    interpolation functions (whether it be by using the `%` operator or the `format`
    method for strings), which follow a similar structure to the `printf` function
    in C, a first positional parameter with the `string` format, followed by any number
    of arguments that will be placed on the markers of that formatting string.
  prefs: []
  type: TYPE_NORMAL
- en: Besides taking advantage of these functions that are available in Python, we
    can also create our own, which will work in a similar fashion. In this section,
    we will cover the basic principles of functions with a variable number of arguments,
    along with some recommendations, so that in the next section, we can explore how
    to use these features to our advantage when dealing with common problems, issues,
    and constraints that functions might have if they have too many arguments.
  prefs: []
  type: TYPE_NORMAL
- en: For a variable number of `positional` arguments, the star symbol (`*`) is used,
    preceding the name of the variable that is packing those arguments. This works
    through the packing mechanism of Python.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say there is a function that takes three positional arguments. In one
    part of the code, we conveniently happen to have the arguments we want to pass
    to the function inside a `list`, in the same order as they are expected by the
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of passing them one by one by the position (that is, `list[0]` to the
    first element, `list[1]` to the second, and so on), which would be really un-Pythonic,
    we can use the packing mechanism and pass them all together in a single instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The nice thing about the packing mechanism is that it also works the other
    way around. If we want to extract the values of a `list` to variables, by their
    respective position, we can assign them like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Partial unpacking is also possible. Let''s say we are just interested in the
    first values of a sequence (this can be a `list`, `tuple`, or something else),
    and after some point we just want the rest to be kept together. We can assign
    the variables we need and leave the rest under a packaged `list`. The order in
    which we unpack is not limited. If there is nothing to place in one of the unpacked
    subsections, the result will be an empty `list`. Try the following examples on
    a Python terminal and also explore how unpacking works with generators as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'One of the best uses for unpacking variables can be found in iteration. When
    we have to iterate over a sequence of elements, and each element is, in turn,
    a sequence, it is a good idea to unpack at the same time each element is being
    iterated over. To see an example of this in action, we are going to pretend that
    we have a function that receives a `list` of database rows, and that it is in
    charge of creating users out of that data. The first implementation takes the
    values to construct the user with from the position of each column in the row,
    which is not idiomatic at all. The second implementation uses unpacking while
    iterating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the second version is much easier to read. In the first version
    of the function (`bad_users_from_rows`), we have data expressed in the form `row[0]`,
    `row[1]`, and `row[2]`, which doesn't tell us anything about what they are. On
    the other hand, variables such as `user_id`, `first_name`, and `last_name` speak
    for themselves.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could also use the star operator to pass all the `positional` parameters
    from the `tuple` when constructing the `User` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We can leverage this kind of functionality to our advantage when designing our
    own functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of this that we can find in the standard library lies in the `max`
    function, which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: There is a similar notation, with two stars (`**`) for keyword arguments. If
    we have a dictionary and we pass it with a double star to a function, what it
    will do is pick the keys as the name for the parameter, and pass the `value` for
    that `key` as the `value` for that `parameter` in that function.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, check this out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'It is the same as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Conversely, if we define a function with a parameter starting with two star
    symbols, the opposite will happen—keyword-provided parameters will be packed into
    a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This feature of Python is really powerful as it lets us choose dynamically the
    values we want to pass to a function. However, abusing this functionality, and
    making excessive use of it, will render the code harder to understand.
  prefs: []
  type: TYPE_NORMAL
- en: When we define a function as in the previous example, on which one of its parameters
    has a double star, meaning that arbitrary keyword arguments are allowed, Python
    will place them in a dictionary that we can access at our discretion. From the
    previously defined function, the `kwargs` argument is a dictionary. A good recommendation
    is to not use this dictionary to extract particular values from it.
  prefs: []
  type: TYPE_NORMAL
- en: Namely, don't look for particular keys of the dictionary. Instead, extract these
    arguments directly on the function definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, instead of doing something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Let Python do the unpacking and set the default argument at the signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: In this example, timeout is not strictly keyword-only. We'll see how to make
    keyword-only arguments in a few sections, but the idea that should prevail is
    to not manipulate the `kwargs` dictionary, and instead execute proper unpacking
    at the signature level.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving into keyword-only arguments, let's start with those that are positional-only
    first.
  prefs: []
  type: TYPE_NORMAL
- en: Positional-only parameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have seen already, positional arguments (variable or not) are those that
    are first provided to functions in Python. The values for these arguments are
    interpreted based on the position they're provided to the function, meaning they're
    assigned respectively to the parameters in the function's definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we don''t make use any special syntax when defining the function arguments,
    by default, they can be passed by position or keyword. For example, in the following
    function, all calls to the function are equivalent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: This means, in the first case, we pass the values `1` and `2`, and by their
    position, they're assigned to the parameters `x` and `y`, respectively. With this
    syntax, nothing stops us from passing the same arguments with their keyword (even
    in reverse order), should that be needed (for example, to be more explicit). The
    only constraint here is that if we pass one argument as a keyword, all the following
    ones must be provided as a keyword as well (the last example wouldn't work with
    the parameters reversed).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, starting from Python 3.8 (PEP-570), new syntax was introduced that
    allows parameters to be defined that are strictly positional (meaning we can''t
    provide their name when passing values by). To use this, a `/` must be added to
    the end of the last positional-only argument). For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Note how the first invocation of the function worked (just as before), but from
    now on, any attempt to pass a keyword argument will fail. The exception that is
    raised will tell us in its message the positional-only parameters that attempted
    to be passed as keyword-only. In general, using keyword arguments makes the code
    more readable because you'll know at all times which values are provided for which
    arguments, but there could be situations in which this syntax is useful, for example,
    in cases where the names of the arguments aren't meaningful (because they can't
    be, not because we did a poor job on naming them!), and attempting to use their
    name would be counterproductive.
  prefs: []
  type: TYPE_NORMAL
- en: To give a really simple example, imagine a function to check whether two words
    are anagrams. That function takes two strings and does some processing. It doesn't
    really matter how we name those two strings (and frankly their order doesn't matter,
    it would just be a first word and a second word). Trying to come up with good
    names for those arguments wouldn't make much sense, nor would assigning their
    keyword values when calling the function.
  prefs: []
  type: TYPE_NORMAL
- en: For the rest of the cases, this should be avoided.
  prefs: []
  type: TYPE_NORMAL
- en: Don't force meaningful arguments to be positional-only.
  prefs: []
  type: TYPE_NORMAL
- en: In very particular cases, positional-only parameters might be a good idea, but
    most of the time this shouldn't be required. But in general, this isn't a feature
    you'd want to use many times because we can take advantage of passing arguments
    as keywords, because that will make it easier to understand which values are being
    passed to which parameters. For that reason, the opposite case is something you'd
    want to do more often, making the arguments keyword-only, as we'll discuss in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Keyword-only arguments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Analogous to the previous feature is the possibility of making some arguments
    keyword-only. This probably makes more sense, because we can find meaning when
    assigning the keyword argument on a function call, and now we can enforce this
    explicitness.
  prefs: []
  type: TYPE_NORMAL
- en: In this case (and contrary to the previous one), we use the `*` symbol to signal
    when the keyword-only arguments start. In the function signature, everything that
    comes after the variable number of positional arguments (`*args`) will be keyword-only.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following definition takes two positional arguments, then
    any number of positional parameters, and then two final arguments, which are to
    be passed as keyword-only. The last one has a default value (although this is
    not mandatory, as in the third case):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The function calls make it clear how this behaves. If we didn't want any number
    of positional arguments after the first two, we can simply put `*` instead of
    `*args`.
  prefs: []
  type: TYPE_NORMAL
- en: This functionality is useful for extending functions or classes that are already
    defined (and being used) in a backward-compatible fashion. If, for example, you
    have a function that takes two arguments, and it's being called several times
    throughout the code (sometimes with the parameters by position, sometimes by keyword),
    and you'd want to add a third parameter, you'd have to set a default for it, if
    you want the current calls to keep working. But even better would be to make this
    last parameter keyword-only, so new calls have to make it explicit that they intend
    to use the new definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along the same lines, this functionality is also useful when refactoring and
    keeping compatibility. Imagine you have a function that you''re replacing with
    a new implementation, but you keep the original function as a wrapper, in order
    to preserve compatibility. Let''s analyze the difference between a function call
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'And another call as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: It's clear that the second example is much more explicit, and you get a clear
    idea of what's going on as soon as you glance at the function call. For that reason,
    it makes sense to make the new parameter (which determines which implementation
    to use) keyword-only.
  prefs: []
  type: TYPE_NORMAL
- en: In cases like this, where there's an argument that really needs context in order
    to be understood, making that parameter keyword-only is a good idea.
  prefs: []
  type: TYPE_NORMAL
- en: These are the basics in terms of how arguments and parameters work in Python
    functions. Now we can use that knowledge to discuss this in terms of good design
    ideas.
  prefs: []
  type: TYPE_NORMAL
- en: The number of arguments in functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we agree on the idea that having functions or methods that
    take too many arguments is a sign of bad design (a code smell). Then, we propose
    ways of dealing with this issue.
  prefs: []
  type: TYPE_NORMAL
- en: The first alternative is a more general principle of software design—reification
    (creating a new object for all of those arguments that we are passing, which is
    probably the abstraction we are missing). Compacting multiple arguments into a
    new object is not a solution specific to Python, but rather something that we
    can apply in any programming language.
  prefs: []
  type: TYPE_NORMAL
- en: Another option would be to use the Python-specific features we saw in the previous
    section, making use of variable positional and keyword arguments to create functions
    that have a dynamic signature. While this might be a Pythonic way of proceeding,
    we have to be careful not to abuse the feature, because we might be creating something
    that is so dynamic that it is hard to maintain. In this case, we should take a
    look at the body of the function. Regardless of the signature, and whether the
    parameters seem to be correct, if the function is doing too many different things
    responding to the values of the parameters, then it is a sign that it has to be
    broken down into multiple smaller functions (remember, functions should do one
    thing, and one thing only!).
  prefs: []
  type: TYPE_NORMAL
- en: Function arguments and coupling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The more arguments a function signature has, the more likely this one is going
    to be tightly coupled with the caller function.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say we have two functions, `f1`, and `f2`, and the latter takes five parameters.
    The more parameters `f2` takes, the more difficult it would be for anyone trying
    to call that function to gather all that information and pass it along so that
    it can work properly.
  prefs: []
  type: TYPE_NORMAL
- en: Now, `f1` seems to have all of this information because it can call it correctly.
    From this, we can derive two conclusions. First, `f2` is probably a leaky abstraction,
    which means that since `f1` knows everything that `f2` requires, it can pretty
    much figure out what it is doing internally and will be able to do it by itself.
  prefs: []
  type: TYPE_NORMAL
- en: So, all in all, `f2` is not abstracting that much. Second, it looks like `f2`
    is only useful to `f1`, and it is hard to imagine using this function in a different
    context, making it harder to reuse.
  prefs: []
  type: TYPE_NORMAL
- en: When functions have a more general interface and are able to work with higher-level
    abstractions, they become more reusable.
  prefs: []
  type: TYPE_NORMAL
- en: This applies to all sorts of functions and object methods, including the `__init__`
    method for classes. The presence of a method like this could generally (but not
    always) mean that a new higher-level abstraction should be passed instead, or
    that there is a missing object.
  prefs: []
  type: TYPE_NORMAL
- en: If a function needs too many parameters to work properly, consider it a code
    smell.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, this is such a design problem that static analysis tools such as `pylint`
    (discussed in *Chapter 1*, *Introduction, Code Formatting, and Tools*) will, by
    default, raise a warning when they encounter such a case. When this happens, don't
    suppress the warning—refactor it instead.
  prefs: []
  type: TYPE_NORMAL
- en: Compact function signatures that take too many arguments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose we find a function that requires too many parameters. We know that we
    cannot leave the code base like that, and a refactor process is imperative. But
    what are the options?
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the case, some of the following rules might apply. This is by no
    means extensive, but it does provide an idea of how to solve some scenarios that
    occur quite often.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, there is an easy way to change parameters if we can see that most
    of them belong to a common object. For example, consider a function call like
    this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the function might or might not take additional arguments, but something
    is really obvious here: All of the parameters depend upon `request`, so why not
    pass the `request` object instead? This is a simple change, but it significantly
    improves the code. The correct function call should be `track_request(request)`—not
    to mention that, semantically, it also makes much more sense.'
  prefs: []
  type: TYPE_NORMAL
- en: While passing around parameters like this is encouraged, in all cases where
    we pass `mutable` objects to functions, we must be really careful about side effects.
    The function we are calling should not make any modifications to the object we
    are passing because that will mutate the object, creating an undesired side effect.
    Unless this is actually the desired effect (in which case, it must be made explicit),
    this kind of behavior is discouraged. Even when we actually want to change something
    on the object we are dealing with, a better alternative would be to copy it and
    return a (new) modified version of it.
  prefs: []
  type: TYPE_NORMAL
- en: Work with immutable objects and avoid side effects as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: This brings us to a similar topic—grouping parameters. In the previous example,
    the parameters were already grouped, but the group (in this case, the `request`
    object) was not being used. But other cases are not as obvious as that one, and
    we might want to group all the data in the parameters in a single object that
    acts as a `container`. Needless to say, this grouping has to make sense. The idea
    here is to *reify*: Create the abstraction that was missing from our design.
  prefs: []
  type: TYPE_NORMAL
- en: If the previous strategies don't work, as a last resort we can change the signature
    of the function to accept a variable number of arguments. If the number of arguments
    is too big, using `*args` or `**kwargs` will make things harder to follow, so
    we have to make sure that the interface is properly documented and correctly used,
    but in some cases, this is worth doing.
  prefs: []
  type: TYPE_NORMAL
- en: It's true that a function defined with `*args` and `**kwargs` is really flexible
    and adaptable, but the disadvantage is that it loses its signature, and with that,
    part of its meaning, and almost all of its legibility. We have seen examples of
    how names for variables (including function arguments) make the code much easier
    to read. If a function will take any number of arguments (positional or keyword),
    we might find out that when we want to take a look at that function in the future,
    we probably won't know exactly what it was supposed to do with its parameters,
    unless it has a very good docstring.
  prefs: []
  type: TYPE_NORMAL
- en: Try to only define functions with the most generic arguments (`*args`, `**kwargs`)
    when you want a perfect wrapper over another function (for example, a method that
    will call `super()`, or a decorator).
  prefs: []
  type: TYPE_NORMAL
- en: Final remarks on good practices for software design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Good software design involves a combination of following good practices of software
    engineering and taking advantage of most of the features of the language. There
    is great value in using everything that Python has to offer, but there is also
    a great risk of abusing this and trying to fit complex features into simple designs.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to this general principle, it would be good to add some final recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Orthogonality in software
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This word is very general and can have multiple meanings or interpretations.
    In math, orthogonal means that two elements are independent. If two vectors are
    orthogonal, their scalar product is zero. It also means they are not related at
    all. A change in one of them doesn't affect the other one at all. That's the way
    we should think about our software.
  prefs: []
  type: TYPE_NORMAL
- en: Changing a module, class, or function should have no impact on the outside world
    to that component that is being modified. This is, of course, highly desirable,
    but not always possible. But even for cases where it's not possible, a good design
    will try to minimize the impact as much as possible. We have seen ideas such as
    separation of concerns, cohesion, and isolation of components.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of the runtime structure of software, orthogonality can be interpreted
    as the process of making changes (or side effects) local. This means, for instance,
    that calling a method on an object should not alter the internal state of other
    (unrelated) objects. We have already (and will continue to do so) emphasized in
    this book the importance of minimizing side effects in our code.
  prefs: []
  type: TYPE_NORMAL
- en: In the example with the mixin class, we created a tokenizer object that returned
    an `iterable`. The fact that the `__iter__` method returned a new generator increases
    the chances that all three classes (the base, the mixing, and the concrete class)
    are orthogonal. If this had returned something in concrete (a `list`, let's say),
    this would have created a dependency on the rest of the classes, because when
    we changed the `list` to something else, we might have needed to update other
    parts of the code, revealing that the classes were not as independent as they
    should be.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s show you a quick example. Python allows passing functions by parameter
    because they are just regular objects. We can use this feature to achieve some
    orthogonality. We have a function that calculates a price, including taxes and
    discounts, but afterward we want to format the final price that''s obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that the top-level function is composing two orthogonal functions. One
    thing to notice is how we calculate `price`, which is how the other one is going
    to be represented. Changing one does not change the other. If we don''t pass anything
    in particular, it will use `string` conversion as the default representation function,
    and if we choose to pass a custom function, the resulting `string` will change.
    However, changes in `show_price` do not affect `calculate_price`. We can make
    changes to either function, knowing that the other one will remain as it was:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: There is an interesting quality aspect that relates to orthogonality. If two
    parts of the code are orthogonal, it means one can change without affecting the
    other. This implies that the part that changed has unit tests that are also orthogonal
    to the unit tests of the rest of the application. Under this assumption, if those
    tests pass, we can assume (up to a certain degree) that the application is correct
    without needing full regression testing.
  prefs: []
  type: TYPE_NORMAL
- en: More broadly, orthogonality can be thought of in terms of features. Two functionalities
    of the application can be totally independent so that they can be tested and released
    without having to worry that one might break the other (or the rest of the code,
    for that matter). Imagine that the project requires a new authentication mechanism
    (`oauth2`, let's say, but just for the sake of the example), and at the same time
    another team is also working on a new report.
  prefs: []
  type: TYPE_NORMAL
- en: Unless there is something fundamentally wrong in that system, neither of those
    features should impact the other. Regardless of which one of those gets merged
    first, the other one should not be affected at all.
  prefs: []
  type: TYPE_NORMAL
- en: Structuring the code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The way code is organized also impacts the performance of the team and its maintainability.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, having large files with lots of definitions (classes, functions,
    constants, and so on) is a bad practice and should be discouraged. This doesn't
    mean going to the extreme of placing one definition per file, but a good code
    base will structure and arrange components by similarity.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, most of the time, changing a large file into smaller ones is not a
    hard task in Python. Even if other multiple parts of the code depend on definitions
    made on that file, this can be broken down into a package, and will maintain total
    compatibility. The idea would be to create a new directory with a `__init__.py`
    file on it (this will make it a Python package). Alongside this file, we will
    have multiple files with all the particular definitions each one requires (fewer
    functions and classes grouped by a certain criterion). Then, the `__init__.py`
    file will import from all the other files the definitions it previously had (which
    is what guarantees its compatibility). Additionally, these definitions can be
    mentioned in the `__all__` variable of the module to make them exportable.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many advantages to this. Other than the fact that each file will
    be easier to navigate, and things will be easier to find, we could argue that
    it will be more efficient for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: It contains fewer objects to parse and load into memory when the module is imported.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The module itself will probably be importing fewer modules because it needs fewer
    dependencies, like before.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It also helps to have a convention for the project. For example, instead of
    placing `constants` in all of the files, we can create a file specific to the
    constant values to be used in the project, and import it from there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Centralizing information in this way makes it easier to reuse code and helps
    to avoid inadvertent duplication.
  prefs: []
  type: TYPE_NORMAL
- en: More details about separating modules and creating Python packages will be discussed
    in *Chapter 10*, *Clean Architecture*, when we explore this in the context of
    software architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have explored several principles to achieve a clean design.
    Understanding that the code is part of the design is key to achieving high-quality
    software. This and the following chapter are focused precisely on that.
  prefs: []
  type: TYPE_NORMAL
- en: With these ideas, we can now construct more robust code. For example, by applying
    DbC, we can create components that are guaranteed to work within their constraints.
    More importantly, if errors occur, this will not happen out of the blue, but instead,
    we will have a clear idea of who the offender is and which part of the code broke
    the contract. This compartmentalization is key to effective debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Along similar lines, each component can be made more robust if it defends itself
    from malicious intent or incorrect input. Although this idea goes in a different
    direction from DbC, it might complement it very well. Defensive programming is
    a good idea, especially for critical parts of the application.
  prefs: []
  type: TYPE_NORMAL
- en: For both approaches (DbC and defensive programming), it's important to correctly
    handle assertions. Keep in mind how they should be used in Python, and don't use
    assertions as part of the control flow logic of the program. Don't catch this
    exception, either.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of exceptions, it's important to know how and when to use them, and
    the most important concept here is to avoid using exception as a control flow
    (`go-to`) kind of construction.
  prefs: []
  type: TYPE_NORMAL
- en: We have explored a recurrent topic in object-oriented design—deciding between
    using inheritance or composition. The main lesson here is not to use one over
    the other, but to use whichever option is better; we should also avoid some common
    anti-patterns, which we might often see in Python (especially given its highly
    dynamic nature).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discussed the number of arguments in functions, along with heuristics
    for a clean design, always with the particularities of Python in mind.
  prefs: []
  type: TYPE_NORMAL
- en: These concepts are fundamental design ideas that lay the foundations for what's
    coming in the next chapter. We need to first understand these ideas so that we
    can move on to more advanced topics, such as SOLID principles.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is a list of information you can refer to:'
  prefs: []
  type: TYPE_NORMAL
- en: '*PEP-570*: *Python Positional-Only Parameters* ([https://www.python.org/dev/peps/pep-0570/](https://www.python.org/dev/peps/pep-0570/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-3102*: *Keyword-Only Arguments* ([https://www.python.org/dev/peps/pep-3102/](https://www.python.org/dev/peps/pep-3102/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Object-Oriented Software Construction*, *Second Edition*, written by *Bertrand
    Meyer*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Pragmatic Programmer: From Journeyman to Master*, by *Andrew Hunt* and
    *David Thomas*, published by *Addison-Wesley*, 2000.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-316*: *Programming by Contract for Python* ([https://www.python.org/dev/peps/pep-0316/](https://www.python.org/dev/peps/pep-0316/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*REAL 01*: *The Most Diabolical Python Antipattern* ([https://realpython.com/blog/python/the-most-diabolical-python-antipattern/](https://realpython.com/blog/python/the-most-diabolical-python-antipattern/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-3134*: *Exception Chaining and Embedded Tracebacks*: ([https://www.python.org/dev/peps/pep-3134/](https://www.python.org/dev/peps/pep-3134/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Idiomatic Python: EAFP versus LBYL*: [https://blogs.msdn.microsoft.com/pythonengineering/2016/06/29/idiomatic-python-eafp-versus-lbyl/](https://blogs.msdn.microsoft.com/pythonengineering/2016/06/29/idiomatic-python-eafp-versus-lbyl/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Composition vs. Inheritance: How to Choose?* [https://www.thoughtworks.com/insights/blog/composition-vs-inheritance-how-choose](https://www.thoughtworks.com/insights/blog/composition-vs-inheritance-how-choose)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Python HTTP*: [https://docs.python.org/3/library/http.server.html#http.server.BaseHTTPRequestHandler](https://docs.python.org/3/library/http.server.html#http.server.BaseHTTPRequestHandler)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Source reference for exceptions in the requests library: [http://docs.python-requests.org/en/master/_modules/requests/exceptions/](http://docs.python-requests.org/en/master/_modules/requests/exceptions/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Code Complete: A Practical Handbook of Software Construction*, *Second Edition*,
    written by *Steve McConnell*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
