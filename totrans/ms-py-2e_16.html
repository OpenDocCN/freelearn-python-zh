<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer293" class="Basic-Text-Frame">&#13;
    <h1 class="chapterNumber">16</h1>&#13;
    <h1 id="_idParaDest-454" class="chapterTitle">Artificial Intelligence</h1>&#13;
    <p class="normal">In the last chapter, we saw a collection of scientific Python libraries that allow for really fast and easy processing of large data files. In this chapter, we will use some of these and a few others for machine learning.</p>&#13;
    <p class="normal">Machine learning is a complex subject, and many completely distinct subjects within it are entire branches of research by themselves. This should not discourage you from diving in, however; many of the libraries mentioned in this chapter are really powerful and allow you to get started with a very reasonable amount of effort.</p>&#13;
    <p class="normal">It should be noted that there is a huge difference between applying a pre-trained model and generating your own. Applying a model is usually possible in a few lines of code and barely requires any processing power; building your own model usually takes many lines of code and hours or more to process. This makes the training of models outside of the scope of this book in all but the most trivial cases. In these cases, you will get an overview of what the library can do with some explanation of where this would be useful, without explicit examples.</p>&#13;
    <p class="normal">Artificial intelligence is the branch of computer science relating to the study of all types of machine learning, which includes neural networks and deep learning, Bayesian networks, evolutionary algorithms, computer vision, <strong class="keyWord">natural language processing</strong> (<strong class="keyWord">NLP</strong>), and <strong class="keyWord">support-vector machines</strong> (<strong class="keyWord">SVM</strong>s), among others.</p>&#13;
    <p class="normal">In this chapter, we will cover the following topics:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Introduction to artificial intelligence</li>&#13;
      <li class="bulletList">Libraries for image processing</li>&#13;
      <li class="bulletList">Libraries for NLP</li>&#13;
      <li class="bulletList">Libraries for neural networks and deep learning</li>&#13;
      <li class="bulletList">Generic AI libraries and utilities</li>&#13;
    </ul>&#13;
    <h1 id="_idParaDest-455" class="heading-1">Introduction to artificial intelligence</h1>&#13;
    <p class="normal">Before we continue with this chapter, we need to establish a few definitions. Because <strong class="keyWord">artificial intelligence </strong>(<strong class="keyWord">AI</strong>) is<a id="_idIndexMarker1316"/> such a broad subject, the lines tend to blur a bit, so we need to make sure that we are all talking about the same thing.</p>&#13;
    <p class="normal">First of all, we define AI as <em class="italic">any algorithm with a human-like ability to solve problems</em>. While I admit that this statement is very broad, any narrower definition would exclude valid AI strategies. What is and is not AI is more a philosophical question than a technical one. While (almost) anyone would consider a neural network to be AI, once you get to algorithms such as (Bayesian) decision trees, not everyone agrees anymore.</p>&#13;
    <p class="normal">With that broad definition in mind, here is a list of technologies and terms we are going to cover, with a short explanation of what they are and what they can do.</p>&#13;
    <h2 id="_idParaDest-456" class="heading-2">Types of AI</h2>&#13;
    <p class="normal">Within the broad scope of AI, we have two major branches, <strong class="keyWord">machine learning </strong>(<strong class="keyWord">ML</strong>) and the rest. Machine learning <a id="_idIndexMarker1317"/>covers any method that can learn by itself. You might <a id="_idIndexMarker1318"/>wonder, is it even AI if it does not involve learning? This is a bit of a philosophical question, but I personally think that there are several non-learning algorithms that can still be considered AI because they can produce human-like decisions.</p>&#13;
    <p class="normal">Within self-learning systems, we have<a id="_idIndexMarker1319"/> further distinctions with their own goals and applications:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Supervised learning</li>&#13;
      <li class="bulletList">Reinforcement learning</li>&#13;
      <li class="bulletList">Unsupervised learning</li>&#13;
    </ul>&#13;
    <p class="normal">The use of one of these does not exclude the others from being used too, so many practical implementations use combinations of multiple methods.</p>&#13;
    <p class="normal">Non-machine learning systems<a id="_idIndexMarker1320"/> are quite a bit more diverse because they can mean just about anything, so here are a few examples of non-learning algorithms that can rival humans in some ways:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><strong class="keyWord">NLP</strong>: It should be noted that NLP<a id="_idIndexMarker1321"/> by itself does not use ML. Many NLP algorithms are still written by hand, because it is far easier for a human to explain to a machine how and why certain grammar and semantics work than to have a computer figure out the oddities and complexities of human languages. That field is changing very rapidly, however, and this might not be the case for much longer.</li>&#13;
      <li class="bulletList"><strong class="keyWord">Expert systems</strong>: This is the first type of AI that was actually successful in practice. The first expert systems<a id="_idIndexMarker1322"/> were created in 1970 and they have been used ever since. These systems work by asking you a string of questions and narrowing down a list of potential solutions/answers based on those. You have certainly encountered many of these when going through problem-solving wizards at some point, perhaps in the FAQ on websites or when calling a helpdesk. These systems allow the capturing of expert information and compress it down into a simple system that can make decisions. Many of these have been used (and are still used today) in diagnosing medical issues.</li>&#13;
    </ul>&#13;
    <p class="normal">Before we continue with actual AI implementations, it is a good idea to look at a few image processing libraries that are used as a basis in many of the AI examples.</p>&#13;
    <h1 id="_idParaDest-457" class="heading-1">Installing the packages</h1>&#13;
    <p class="normal">As was the case with installing the scientific <a id="_idIndexMarker1323"/>Python libraries in <em class="chapterRef">Chapter 15</em>, installing the packages in this chapter directly using <code class="inlineCode">pip</code> can be troublesome in some cases. Using one of the Jupyter Docker Stacks or <code class="inlineCode">conda</code> can be more convenient. Additionally, most of these projects have very well-documented installation instructions for many scenarios.</p>&#13;
    <div class="note">&#13;
      <p class="normal">For the neural networks portion of this chapter, it would be best to get a notebook stack that has most libraries available. I would recommend giving the <code class="inlineCode">jupyter/tensorflow-notebook</code> stack a test: <a href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-tensorflow-notebook"><span class="url">https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-tensorflow-notebook</span></a>.</p>&#13;
    </div>&#13;
    <h1 id="_idParaDest-458" class="heading-1">Image processing </h1>&#13;
    <p class="normal">Image processing<a id="_idIndexMarker1324"/> is an essential part of many types of machine learning, such<a id="_idIndexMarker1325"/> as <strong class="keyWord">computer vision </strong>(<strong class="keyWord">CV</strong>), so it is essential that we show you a few of the options and their possibilities here. These range from image-only libraries to libraries that have full machine learning capabilities while also supporting image inputs.</p>&#13;
    <h2 id="_idParaDest-459" class="heading-2">scikit-image</h2>&#13;
    <p class="normal">The scikit-image (<code class="inlineCode">skimage</code>) library<a id="_idIndexMarker1326"/> is part of the scikit project with the main project being scikit-learn (<code class="inlineCode">sklearn</code>), covered later in this chapter. It offers a range of functions for reading, processing, transforming, and generating images. The library builds on <code class="inlineCode">scipy.ndimage</code>, which provides several image processing options as well.</p>&#13;
    <p class="normal">We need to talk about what an image is in terms of these Python libraries first. In the case of <code class="inlineCode">scipy</code> (and consequently, <code class="inlineCode">skimage</code>), an <strong class="keyWord">image</strong> is a <code class="inlineCode">numpy.ndarray</code> object with 2 or more dimensions. The<a id="_idIndexMarker1327"/> conventions are:</p>&#13;
    <ul>&#13;
      <li class="bulletList">2D grayscale: Row, column</li>&#13;
      <li class="bulletList">2D color (for example, RGB): Row, column, color channel</li>&#13;
      <li class="bulletList">3D grayscale: Plane, row, column</li>&#13;
      <li class="bulletList">3D color: Plane, row, column, color channel</li>&#13;
    </ul>&#13;
    <p class="normal">All of these are just conventions, however; you can shape your arrays in other ways as well. A multichannel <a id="_idIndexMarker1328"/>image could also mean <strong class="keyWord">CMYK</strong> (<strong class="keyWord">cyan, magenta, yellow, and key/black</strong>) colors instead of <strong class="keyWord">RGB</strong> (<strong class="keyWord">red, green, and blue</strong>), or something <a id="_idIndexMarker1329"/>completely different.</p>&#13;
    <p class="normal">Naturally you could have more dimensions as well, such as a dimension for time (in other words, video). Since the arrays are regular <code class="inlineCode">numpy</code> arrays, you can manipulate them by slicing as usual.</p>&#13;
    <p class="normal">Often you will not use the scikit-image library for machine learning directly, but rather for <em class="italic">pre-processing</em> image data before you feed it to your machine learning algorithms. In many types of detections, for example, color is not that relevant, which means you can make your machine learning system three times as fast by going from RGB to grayscale. Additionally, there are often fast algorithms available to pre-process the data so your machine learning system only needs to look at the relevant sections of the image.</p>&#13;
    <h3 id="_idParaDest-460" class="heading-3">Installing scikit-image</h3>&#13;
    <p class="normal">The package<a id="_idIndexMarker1330"/> is easily installable through <code class="inlineCode">pip</code> for many platforms; I would suggest installing not just the base package but the <code class="inlineCode">optional</code> extras as well, which add extra capabilities to scikit-image, such as parallel processing:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$</span> pip3 install -U <span class="hljs-con-string">'scikit-image[optional]'</span>&#13;
</code></pre>&#13;
    <h3 id="_idParaDest-461" class="heading-3">Edge detection</h3>&#13;
    <p class="normal">Let’s look at how we <a id="_idIndexMarker1331"/>can display one of the built-in images and do some basic processing on it:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">%matplotlib inline&#13;
<span class="hljs-keyword">from</span> skimage <span class="hljs-keyword">import</span> io, data&#13;
&#13;
coins = data.coins()&#13;
io.imshow(coins)&#13;
</code></pre>&#13;
    <p class="normal">In this case, we are using the <code class="inlineCode">coins</code> dataset that is bundled with <code class="inlineCode">skimage</code>. It contains a few coins and we can use it to display some of the nice features of <code class="inlineCode">skimage</code>. First, let’s look at the results:</p>&#13;
    <figure class="mediaobject"><img src="Images/B15882_16_01.png" alt="/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/6A6F4AA2.tmp" width="541" height="430"/></figure>&#13;
    <p class="packt_figref">Figure 16.1: scikit-image coins</p>&#13;
    <p class="normal">As an example of what kind of processing we can do, let’s do some edge detection using the Canny edge detection algorithm. This is a prime example of a non-ML algorithm that can be really useful for pre-processing your data before you feed it to your ML system. To display the results a bit <a id="_idIndexMarker1332"/>better, first we will slice the image so only the top-right three coins are visible. In <em class="italic">Figure 16.1</em>, the numbers indicate the actual pixel indices for the <em class="italic">x</em> and <em class="italic">y</em> axes, which can be used to estimate where to slice. After that, we will apply the <code class="inlineCode">canny()</code> function to detect the edges:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">%matplotlib inline&#13;
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt&#13;
<span class="hljs-keyword">from</span> skimage <span class="hljs-keyword">import</span> feature&#13;
&#13;
<span class="hljs-comment"># Get pixels 180 to the end in the X direction</span>&#13;
x0, x1 = <span class="hljs-number">180</span>, -<span class="hljs-number">1</span>&#13;
<span class="hljs-comment"># Get pixels 0 to 90 in the Y direction </span>&#13;
y0, y1 = <span class="hljs-number">0</span>, <span class="hljs-number">90</span>&#13;
<span class="hljs-comment"># Slice the image so only the top-right three coins are visible</span>&#13;
three_coins = coins[y0:y1, x0:x1]&#13;
<span class="hljs-comment"># Apply the canny algorithm</span>&#13;
plt.imshow(feature.canny(three_coins), cmap=<span class="hljs-string">'gray'</span>)&#13;
</code></pre>&#13;
    <p class="normal">The results are shown in the following image, where you can see the auto-detected edges of coins we have selected:</p>&#13;
    <figure class="mediaobject"><img src="Images/B15882_16_02.png" alt="/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/748E410E.tmp" width="684" height="334"/></figure>&#13;
    <p class="packt_figref">Figure 16.2: Coins after edge detection</p>&#13;
    <p class="normal">scikit-image <a id="_idIndexMarker1333"/>can do much more, but this is a nice and basic example of how you can do edge detection in a single line of code, which can make your data much more useful for ML systems.</p>&#13;
    <h3 id="_idParaDest-462" class="heading-3">Face detection</h3>&#13;
    <p class="normal">We will now use one of the<a id="_idIndexMarker1334"/> examples from the fantastic scikit-image<a id="_idIndexMarker1335"/> documentation: <a href="https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html"><span class="url">https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html</span></a>.</p>&#13;
    <p class="normal">This is a machine learning example that uses a pre-trained model to automatically detect faces. The specific model uses a <a id="_idIndexMarker1336"/>multi-block <strong class="keyWord">local binary pattern </strong>(<strong class="keyWord">LBP</strong>). An LBP looks at points surrounding a center point and indicates whether these points are greater (lighter) or smaller (darker) than the center point. The multi-block part is an optional extension to this method and performs the LBP algorithm across multiple block sizes of 9 identically sized rectangles. The first iteration might look at a 3x3 pixel square; the second iteration could look at 6x6; the third 9x9; and so on.</p>&#13;
    <p class="normal">The model was trained using the OpenCV cascade classifier training, which can train your model, generate samples, and run the detection. A cascade classifier concatenates the results of multiple classifiers to reach a combined model that is expected to perform better than the separate classifiers by themselves.</p>&#13;
    <p class="normal">To test the face detection, we will apply it to a photo of the NASA astronaut Eileen Collins. First, we will import the libraries, load the image, and tell <code class="inlineCode">matplotlib</code> to draw it:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">%matplotlib inline&#13;
<span class="hljs-keyword">from</span> skimage <span class="hljs-keyword">import</span> data&#13;
<span class="hljs-keyword">from</span> skimage.feature <span class="hljs-keyword">import</span> Cascade&#13;
&#13;
<span class="hljs-comment"># We are using matplotlib directly so we can</span>&#13;
<span class="hljs-comment"># draw on the rendered output</span>&#13;
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt&#13;
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> patches&#13;
&#13;
dpi = <span class="hljs-number">300</span>&#13;
color = <span class="hljs-string">'white'</span>&#13;
thickness = <span class="hljs-number">1</span>&#13;
step_ratio = <span class="hljs-number">1</span>&#13;
scale_factor = <span class="hljs-number">1.2</span>&#13;
min_object_size = <span class="hljs-number">60</span>, <span class="hljs-number">60</span>&#13;
max_object_size = <span class="hljs-number">123</span>, <span class="hljs-number">123</span>&#13;
&#13;
<span class="hljs-comment"># A photo of Astronaut Eileen Collins</span>&#13;
img = data.astronaut()&#13;
&#13;
<span class="hljs-comment"># Plot the image as high resolution in grayscale</span>&#13;
plt.figure(dpi=dpi)&#13;
plt.imshow(img.mean(axis=<span class="hljs-number">2</span>), cmap=<span class="hljs-string">'gray'</span>)&#13;
</code></pre>&#13;
    <p class="normal">Looking at the code above, you might notice a few magic numbers such as the <code class="inlineCode">scale_factor</code>, <code class="inlineCode">step_ratio</code>, <code class="inlineCode">min_object_size</code>, and <code class="inlineCode">max_object_size</code>. These parameters are ones that you will have to tune to your input image. These specific numbers are straight from the OpenCV documentation, but depending on your input you will need to experiment with these values until they suit your scenario.</p>&#13;
    <p class="normal">Since these parameters <a id="_idIndexMarker1337"/>are somewhat arbitrary and dependent on your input, it can be a good idea to apply a bit of automation to find them. An evolutionary algorithm could be useful in helping you find effective parameters.</p>&#13;
    <p class="normal">Now we are ready to start the detection and illustrate what we found:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Load the trained file and initialize the detector cascade</span>&#13;
detector = Cascade(data.lbp_frontal_face_cascade_filename())&#13;
&#13;
<span class="hljs-comment"># Apply the detector to find faces of varying sizes</span>&#13;
out = detector.detect_multi_scale(&#13;
    img=img, step_ratio=step_ratio, scale_factor=scale_factor,&#13;
    min_size=min_object_size, max_size=max_object_size)&#13;
&#13;
img_desc = plt.gca()&#13;
<span class="hljs-keyword">for</span> box <span class="hljs-keyword">in</span> out:&#13;
    <span class="hljs-comment"># Draw a rectangle for every detected face</span>&#13;
    img_desc.add_patch(patches.Rectangle(&#13;
        <span class="hljs-comment"># Col and row as X and Y respectively</span>&#13;
        (box[<span class="hljs-string">'c'</span>], box[<span class="hljs-string">'</span><span class="hljs-string">r'</span>]), box[<span class="hljs-string">'width'</span>], box[<span class="hljs-string">'height'</span>],&#13;
        fill=<span class="hljs-literal">False</span>, color=color, linewidth=thickness))&#13;
</code></pre>&#13;
    <p class="normal">After loading the cascade, we run the model using the <code class="inlineCode">detect_multi_scale</code> method. This method searches for matching objects (faces) with sizes varying from <code class="inlineCode">min_size</code> to <code class="inlineCode">max_size</code>, which is needed because we don’t know how large the subject (face) is. Once we have the matches, we draw a rectangle around them to indicate where they are:</p>&#13;
    <figure class="mediaobject"> <img src="Images/B15882_16_03.png" alt="" width="395" height="379"/></figure>&#13;
    <p class="packt_figref">Figure 16.3: Face detected by scikit-image</p>&#13;
    <p class="normal">By itself, scikit-image does <a id="_idIndexMarker1338"/>not have many machine learning features available, but the coupling with other libraries is what makes this library very useful for machine learning. In addition to the frontal face dataset we loaded above, you can also use pre-trained cascades from OpenCV. </p>&#13;
    <div class="note">&#13;
      <p class="normal">Several pre-trained models <a id="_idIndexMarker1339"/>are available in the OpenCV Git repository: <a href="https://github.com/opencv/opencv/tree/master/data/lbpcascades"><span class="url">https://github.com/opencv/opencv/tree/master/data/lbpcascades</span></a>.</p>&#13;
    </div>&#13;
    <h3 id="_idParaDest-463" class="heading-3">scikit-image overview</h3>&#13;
    <p class="normal">The scikit-image library can do much more than we have covered. Here’s a quick overview of a few of the available submodules:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><code class="inlineCode">exposure</code>: Functions<a id="_idIndexMarker1340"/> for analyzing and fixing photo exposure levels, which can be essential for cleaning data before you feed it to your AI system.</li>&#13;
      <li class="bulletList"><code class="inlineCode">feature</code>: Feature detection<a id="_idIndexMarker1341"/> such as the <code class="inlineCode">canny()</code> edge detection function we used earlier. This allows for detecting objects, blobs of content, and more to pre-filter your input so you can reduce the processing time needed by your AI system.</li>&#13;
      <li class="bulletList"><code class="inlineCode">filters</code>: Image<a id="_idIndexMarker1342"/> filtering functions, such as thresholding to automatically filter noise, and many others. Similar to the <code class="inlineCode">exposure</code> functions, these can be very useful for cleanup.</li>&#13;
      <li class="bulletList"><code class="inlineCode">morphology</code>: Many functions<a id="_idIndexMarker1343"/> to sharpen edges, fill sections, find minima/maxima, and so on.</li>&#13;
      <li class="bulletList"><code class="inlineCode">registration</code>: Functions for calculating the optical flow in an image. With these functions, you can<a id="_idIndexMarker1344"/> estimate what part of the image is moving, and how fast objects are moving. Given two images, this can help to calculate the intermediate image.</li>&#13;
      <li class="bulletList"><code class="inlineCode">segmentation</code>: Functions for<a id="_idIndexMarker1345"/> segmenting images. In the case of the coins above, the separate coins can be extracted and/or labeled.</li>&#13;
    </ul>&#13;
    <p class="normal">As you can see, the scikit-image library offers an extensive list of image manipulation and processing functions. Additionally, it is well integrated into the scientific Python ecosystem.</p>&#13;
    <h2 id="_idParaDest-464" class="heading-2">OpenCV</h2>&#13;
    <p class="normal">The big “competitor” to scikit-image is <strong class="keyWord">OpenCV</strong> (<strong class="keyWord">Open Source Computer Vision library</strong>). The OpenCV library is <a id="_idIndexMarker1346"/>written in C/C++ but has bindings for several languages such as Python and Java. The reason I put “competitor” between quotes is that these libraries don’t have to compete; you can easily combine the strengths of both if you wish to do so, and it is something I have done myself in several projects.</p>&#13;
    <p class="normal">We will first look at installing the Python OpenCV package. </p>&#13;
    <h3 id="_idParaDest-465" class="heading-3">Installing OpenCV for Python</h3>&#13;
    <p class="normal">The <code class="inlineCode">opencv-python</code> package<a id="_idIndexMarker1347"/> comes <a id="_idIndexMarker1348"/>in several variants depending on your needs. Besides the main <a id="_idIndexMarker1349"/>OpenCV package, OpenCV also has many “contrib” and “extra” packages, which can be very useful. The contrib packages are mainly for following tutorials and trying examples, and the extra modules contain many useful additional algorithms.</p>&#13;
    <p class="normal">The list of extra modules<a id="_idIndexMarker1350"/> can be found in the documentation: <a href="https://docs.opencv.org/5.x/"><span class="url">https://docs.opencv.org/5.x/</span></a>.</p>&#13;
    <p class="normal">I strongly recommend installing the extra modules as well, since many very useful modules are part of the extra package.</p>&#13;
    <p class="normal">You have the following options if you are installing the package on a desktop machine where you will be using a GUI:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><code class="inlineCode">opencv-python</code>: The<a id="_idIndexMarker1351"/> main modules, the bare minimum</li>&#13;
      <li class="bulletList"><code class="inlineCode">opencv-contrib-python</code>: The <a id="_idIndexMarker1352"/>full package including the main modules from the <code class="inlineCode">opencv-python</code> package, but also the contrib and extra modules</li>&#13;
    </ul>&#13;
    <p class="normal">For servers that are not running a GUI, you have these options:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><code class="inlineCode">opencv-python-headless</code>: Beyond<a id="_idIndexMarker1353"/> not including any GUI output functions such as <code class="inlineCode">cv2.imshow()</code>, this is identical to <code class="inlineCode">opencv-python</code></li>&#13;
      <li class="bulletList"><code class="inlineCode">opencv-contrib-python-headless</code>: As above, this is <a id="_idIndexMarker1354"/>the headless version of <code class="inlineCode">opencv-contrib-python</code></li>&#13;
    </ul>&#13;
    <p class="normal">Now that we have OpenCV installed, let’s see if we can replicate the Canny edge detection from scikit-image using OpenCV. </p>&#13;
    <h3 id="_idParaDest-466" class="heading-3">Edge detection</h3>&#13;
    <p class="normal">Let’s look at how<a id="_idIndexMarker1355"/> we can perform the Canny algorithm using OpenCV, similar to what we did in the scikit-image example earlier. The Canny algorithm is not part of the OpenCV core, so you need to install the <code class="inlineCode">opencv-contrib-python</code> package for this:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$</span> pip3 install opencv-contrib-python&#13;
</code></pre>&#13;
    <p class="normal">We will use the same coins image as before:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">%matplotlib inline&#13;
<span class="hljs-keyword">import</span> cv2&#13;
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt&#13;
<span class="hljs-keyword">from</span> skimage <span class="hljs-keyword">import</span> data&#13;
&#13;
<span class="hljs-comment"># Use the coins image from scikit-image</span>&#13;
coins = data.coins()&#13;
&#13;
<span class="hljs-comment"># Get pixels 180 to the end in the X direction</span>&#13;
x0, x1 = <span class="hljs-number">180</span>, -<span class="hljs-number">1</span>&#13;
<span class="hljs-comment"># Get pixels 0 to 90 in the Y direction </span>&#13;
y0, y1 = <span class="hljs-number">0</span>, <span class="hljs-number">90</span>&#13;
<span class="hljs-comment"># Slice the image so only the top-right three coins are visible</span>&#13;
three_coins = coins[y0:y1, x0:x1]&#13;
<span class="hljs-comment"># scikit-image automatically guesses the thresholds, OpenCV does not</span>&#13;
threshold_1, threshold_2 = <span class="hljs-number">100</span>, <span class="hljs-number">200</span>&#13;
<span class="hljs-comment"># Apply the canny algorithm</span>&#13;
output = cv2.Canny(three_coins, threshold_1, threshold_2)&#13;
&#13;
<span class="hljs-comment"># OpenCV's imshow() function does not work well with Jupyter so</span>&#13;
<span class="hljs-comment"># we use matplotlib to render to grayscale</span>&#13;
plt.imshow(output, cmap=<span class="hljs-string">'gray'</span>)&#13;
</code></pre>&#13;
    <p class="normal">At a first glance the code looks quite similar, but there are a few differences.</p>&#13;
    <p class="normal">First, the <code class="inlineCode">cv2.Canny()</code> function requires two extra parameters: <code class="inlineCode">threshold_1</code> and <code class="inlineCode">threshold_2</code>, or the lower and upper bounds. These parameters decide what should be considered noise and<a id="_idIndexMarker1356"/> what parts are relevant for the edges. By increasing or decreasing these values, you can get finer details in the resulting edges, but doing so means the algorithm can also start wrongly detecting the background gradient as edges, which is already happening at the top right of the output image (<em class="italic">Figure 16.4</em>).</p>&#13;
    <p class="normal">While you can pass these along to scikit-image if you wish, by default scikit-image automatically guesses some suitable parameters for you. With OpenCV you could easily do the same, but this is not included by default. The algorithm that scikit-image uses for this estimation can be seen in the source: <a href="https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_canny.py"><span class="url">https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_canny.py</span></a><span class="url"> </span>Second, OpenCV has no native support for Jupyter, so we are using <code class="inlineCode">matplotlib</code> to render the output. Alternatively, we could also use the <code class="inlineCode">IPython.display</code> module to display the image.</p>&#13;
    <p class="normal">The generated output is similar, however:</p>&#13;
    <figure class="mediaobject"><img src="Images/B15882_16_04.png" alt="/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/9AF685DE.tmp" width="680" height="332"/></figure>&#13;
    <p class="packt_figref">Figure 16.4: OpenCV Canny</p>&#13;
    <p class="normal">For more similar <a id="_idIndexMarker1357"/>output, you could even use scikit-image to render the output from OpenCV. Since they both operate on <code class="inlineCode">numpy</code> arrays, you can easily mix and match the functions if needed.</p>&#13;
    <h3 id="_idParaDest-467" class="heading-3">Object detection</h3>&#13;
    <p class="normal">In the scikit-image <a id="_idIndexMarker1358"/>face detection example, we were actually using an OpenCV-generated model, so we could easily use that model with <code class="inlineCode">opencv-python</code> directly, with a few small changes:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Instead of <code class="inlineCode">skimage.feature.Cascade(filename)</code>, you need to use <code class="inlineCode">cv2.CascadeClassifier(filename)</code></li>&#13;
      <li class="bulletList">Instead of <code class="inlineCode">cascade.detect_multi_scale()</code> the function is called <code class="inlineCode">cascade.detectMultiScale()</code></li>&#13;
    </ul>&#13;
    <div class="note">&#13;
      <p class="normal">This immediately illustrates one of the differences between scikit-image and <code class="inlineCode">python-opencv</code>. Where scikit-image uses the Python convention of underscores between words in a function name, <code class="inlineCode">opencv-python</code> uses the camelCase function names directly from the OpenCV source. </p>&#13;
    </div>&#13;
    <p class="normal">With OpenCV we can easily go beyond the simple cascades we used for face detection; this time we will<a id="_idIndexMarker1359"/> use a <strong class="keyWord">DNN</strong> (<strong class="keyWord">deep neural network</strong>) instead.</p>&#13;
    <p class="normal">The network we will be using is <a id="_idIndexMarker1360"/>called <strong class="keyWord">YOLOv3 </strong>(<strong class="keyWord">You Only Look Once, version 3</strong>) and is able to detect many types of objects such as cars, animals, fruit, and many more. Naturally this model is far larger as well. The face detection model was only about 50 KiB, while the YOLOv3 network is nearly 5000 times larger, at 237 MiB.</p>&#13;
    <p class="normal">Before we can start, we <a id="_idIndexMarker1361"/>need to download a few files for the YOLO network to be fully functional:</p>&#13;
    <ul>&#13;
      <li class="bulletList">The model (237 MiB): <a href="https://pjreddie.com/media/files/yolov3.weights"><span class="url">https://pjreddie.com/media/files/yolov3.weights</span></a></li>&#13;
      <li class="bulletList">The YOLO configuration file: <a href="https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg"><span class="url">https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg</span></a></li>&#13;
      <li class="bulletList">The names for the objects: <a href="https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names"><span class="url">https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names</span></a></li>&#13;
    </ul>&#13;
    <p class="normal">Once you have those files, we can demonstrate the YOLO network. First, we set up a few imports and variables, and then load the image:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">%matplotlib inline&#13;
<span class="hljs-keyword">import</span> cv2 <span class="hljs-keyword">as</span> cv&#13;
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np&#13;
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt&#13;
<span class="hljs-keyword">from</span> skimage <span class="hljs-keyword">import</span> data&#13;
&#13;
color = <span class="hljs-number">0xFF</span>, <span class="hljs-number">0xFF</span>, <span class="hljs-number">0xFF</span>  <span class="hljs-comment"># White</span>&#13;
dpi = <span class="hljs-number">300</span>&#13;
font = cv.FONT_HERSHEY_SIMPLEX&#13;
font_size = <span class="hljs-number">3</span>&#13;
image_dims = <span class="hljs-number">320</span>, <span class="hljs-number">320</span>&#13;
label_offset = <span class="hljs-number">10</span>, <span class="hljs-number">70</span>&#13;
min_score = <span class="hljs-number">0.9</span>&#13;
thickness = <span class="hljs-number">2</span>&#13;
&#13;
<span class="hljs-comment"># Load the astronaut image from scikit-image as before</span>&#13;
img = data.astronaut()&#13;
<span class="hljs-comment"># Convert the image into a 4-dimensional blob</span>&#13;
<span class="hljs-comment"># by subtracting the mean and rescaling</span>&#13;
blob = cv.dnn.blobFromImage(img, <span class="hljs-number">1</span> / <span class="hljs-number">255</span>, size=image_dims)&#13;
</code></pre>&#13;
    <p class="normal">Now that we have the imports ready and the image converted to a blob that’s suitable for the model, we can load the model and show the results:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Load names of classes so we know what was detected</span>&#13;
classes = <span class="hljs-built_in">open</span>(<span class="hljs-string">'coco.names'</span>).read().splitlines()&#13;
<span class="hljs-comment"># Load the deep neural network model and configuration</span>&#13;
net = cv.dnn.readNetFromDarknet(<span class="hljs-string">'yolov3.cfg'</span>, <span class="hljs-string">'yolov3.weights'</span>)&#13;
<span class="hljs-comment"># Determine the output layer</span>&#13;
ln = net.getLayerNames()&#13;
ln = [ln[i - <span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> net.getUnconnectedOutLayers()]&#13;
&#13;
<span class="hljs-comment"># Pass the blob to the net and calculate the output blobs</span>&#13;
net.setInput(blob)&#13;
out = net.forward(ln)&#13;
<span class="hljs-comment"># Loop through all outputs after stacking because</span>&#13;
<span class="hljs-comment"># the net attempts to match multiple sizes</span>&#13;
<span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> np.vstack(out):&#13;
    <span class="hljs-comment"># x, y, w and h are numbers between 0 and 1 and need to be</span>&#13;
    <span class="hljs-comment"># scaled by the width and height</span>&#13;
    result[:<span class="hljs-number">4</span>] *= img.shape[<span class="hljs-number">1</span>::-<span class="hljs-number">1</span>] * <span class="hljs-number">2</span>&#13;
    x, y, w, h, *scores = result&#13;
    <span class="hljs-comment"># Search the net for the best match</span>&#13;
    match_index = np.argmax(scores)&#13;
    <span class="hljs-comment"># Skip questionable matches</span>&#13;
    <span class="hljs-keyword">if</span> scores[match_index] &lt; min_score:&#13;
        <span class="hljs-keyword">continue</span>&#13;
&#13;
    <span class="hljs-comment"># Calculate the top left and bottom right points</span>&#13;
    tl = np.array([x - w / <span class="hljs-number">2</span>, y - h / <span class="hljs-number">2</span>], dtype=<span class="hljs-built_in">int</span>)&#13;
    br = np.array([x + w / <span class="hljs-number">2</span>, y + h / <span class="hljs-number">2</span>], dtype=<span class="hljs-built_in">int</span>)&#13;
    cv.rectangle(img, tl, br, color, thickness)&#13;
    <span class="hljs-comment"># Calculate the point to place the text</span>&#13;
    cv.putText(img, classes[match_index], tl + label_offset,&#13;
               font, font_size, color, thickness)&#13;
    <span class="hljs-comment"># Stop after the first match to prevent overlapping results</span>&#13;
    <span class="hljs-keyword">break</span>&#13;
&#13;
plt.figure(dpi=dpi)&#13;
plt.imshow(img.mean(axis=<span class="hljs-number">2</span>), cmap=<span class="hljs-string">'gray'</span>)&#13;
</code></pre>&#13;
    <p class="normal">For brevity this example is very <a id="_idIndexMarker1362"/>condensed, but it shows you how you can do something as advanced as object detection in just a few lines. If we look at the output, the deep neural network has correctly identified the astronaut as being a person:</p>&#13;
    <figure class="mediaobject"><img src="Images/B15882_16_05.png" alt="/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/1F838D9C.tmp" width="377" height="362"/></figure>&#13;
    <p class="packt_figref">Figure 16.5: Object detection on astronaut</p>&#13;
    <p class="normal">I highly encourage you to try the <a id="_idIndexMarker1363"/>YOLOv3 network yourself with different images. For an old image of a street, I got the following results:</p>&#13;
    <figure class="mediaobject"><img src="Images/B15882_16_06.png" alt="" width="742" height="227"/></figure>&#13;
    <p class="packt_figref">Figure 16.6: Applying YOLOv3 on an image of a street with cars</p>&#13;
    <p class="normal">Isn’t it amazing how easy it is to do object detection these days and how well it works? If you take a good look at the image, you might notice that it’s even detecting cars and people that are partially obstructed. Training a new deep neural network and doing the research for it is a completely different question, of course, but at least applying these networks has become child’s play and they execute well within a second, including the loading of the network.</p>&#13;
    <p class="normal">The possibilities certainly don’t end here, and you could even use techniques like these to do real-time analysis of a video stream if you wanted. The OpenCV library really is an impressive bit of software.</p>&#13;
    <h2 id="_idParaDest-468" class="heading-2">OpenCV versus scikit-image</h2>&#13;
    <p class="normal">Both scikit-image and OpenCV have their own advantages over the other. This is one of the cases where you don’t really have to choose, however; you can easily use both simultaneously.</p>&#13;
    <p class="normal">In my opinion, OpenCV <a id="_idIndexMarker1364"/>has three <a id="_idIndexMarker1365"/>major advantages over scikit-image:</p>&#13;
    <ul>&#13;
      <li class="bulletList">OpenCV has native support for processing using your GPU</li>&#13;
      <li class="bulletList">Since it is implemented in C++, you can do parallel processing in threads without having to worry about the GIL</li>&#13;
      <li class="bulletList">OpenCV has even more features than scikit-image</li>&#13;
    </ul>&#13;
    <p class="normal">Naturally, scikit-image has a few advantages as well:</p>&#13;
    <ul>&#13;
      <li class="bulletList">scikit-image is written in Python so it is very easy to view (or modify) the algorithms right from your editor.</li>&#13;
      <li class="bulletList">scikit-image is focused toward Python, so the naming conventions feel more natural.</li>&#13;
      <li class="bulletList">As scikit-image is only for Python, all documentation is immediately relevant. With OpenCV, many<a id="_idIndexMarker1366"/> of the examples you will find on the <a id="_idIndexMarker1367"/>web (and in the documentation) are about the C++ interface, which is slightly different. </li>&#13;
    </ul>&#13;
    <p class="normal">If you need high performance for the live processing of video streams, then OpenCV would be my top recommendation because it has several methods built in to make that task a bit easier. If you simply need to read and modify some images and you can get away with scikit-image, then that would be my top recommendation.</p>&#13;
    <p class="normal">In either case, both libraries are great and I can confidently recommend both. If your needs span across both, use both. </p>&#13;
    <p class="normal">Now it is finally time to start discussing the artificial intelligence libraries themselves.</p>&#13;
    <h1 id="_idParaDest-469" class="heading-1"><span class="hljs-pattern-match">Natural language processing</span></h1>&#13;
    <p class="normal"><strong class="keyWord">NLP</strong> is the<a id="_idIndexMarker1368"/> process of parsing text and understanding its meaning. This can be used to extract knowledge from pieces of text, understand the differences between texts, and more.</p>&#13;
    <p class="normal">There are several well-developed libraries available for this purpose that work quite well. Additionally, there are also hosted pre-trained networks available such as the <strong class="keyWord">GPT-3</strong> network, which can be accessed through the OpenAI API. </p>&#13;
    <p class="normal">This network can generate text of such high quality that it is often indistinguishable from human-generated text.</p>&#13;
    <h2 id="_idParaDest-470" class="heading-2"><span class="hljs-pattern-match">NLTK – Natural Language Toolkit</span></h2>&#13;
    <p class="normal">NLTK is not <a id="_idIndexMarker1369"/>really a machine learning library by itself like most of the other libraries here, but it’s the basis for many natural language processing libraries. The NLTK project started in 2001 with the purpose of understanding natural languages, and definitely deserves a place in this list.</p>&#13;
    <p class="normal">The project comes bundled with a large collection of corpora and pre-trained models for many different languages.</p>&#13;
    <div class="note">&#13;
      <p class="normal">Corpora are large collections of structured texts that can be used for training and testing models.</p>&#13;
    </div>&#13;
    <p class="normal">Using these corpora and models, it can do sentiment analysis, tokenize the text to find the relevant keywords, and more.</p>&#13;
    <p class="normal">First, we need to install <code class="inlineCode">nltk</code>:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>pip3 install nltk&#13;
</code></pre>&#13;
    <p class="normal">As a basic example, let’s use the pre-trained sentiment analysis capability to see how positive or negative a sentence is:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">import</span> nltk&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span> nltk <span class="hljs-con-keyword">import</span> sentiment&#13;
&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> nltk.download(<span class="hljs-con-string">'vader_lexicon'</span>)&#13;
True&#13;
&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> sentences = [&#13;
<span class="hljs-con-meta">...</span>     <span class="hljs-con-string">'Python is a wonderful programming language'</span>,&#13;
<span class="hljs-con-meta">...</span>     <span class="hljs-con-string">'Weak-typed languages are prone to errors'</span>,&#13;
<span class="hljs-con-meta">...</span>     <span class="hljs-con-string">'I love programming in Python and I hate YAML'</span>,&#13;
<span class="hljs-con-meta">...</span> ]&#13;
&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> si = sentiment.SentimentIntensityAnalyzer()&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">for</span> sentence <span class="hljs-con-keyword">in</span> sentences:&#13;
<span class="hljs-con-meta">...</span>     scores = si.polarity_scores(sentence)&#13;
<span class="hljs-con-meta">...</span>     <span class="hljs-con-built_in">print</span>(sentence)&#13;
<span class="hljs-con-meta">...</span>     <span class="hljs-con-built_in">print</span>(<span class="hljs-con-string">'negative: {neg}, positive: {pos}'</span>.<span class="hljs-con-built_in">format</span>(**scores))&#13;
Python is a wonderful programming language&#13;
negative: 0.0, positive: 0.481&#13;
Weak-typed languages are prone to errors&#13;
negative: 0.324, positive: 0.0&#13;
I love programming in Python and I hate YAML&#13;
negative: 0.287, positive: 0.326&#13;
</code></pre>&#13;
    <p class="normal">We start by downloading the pre-trained model for sentiment analysis. After that, we can use the <code class="inlineCode">SentimentIntensityAnalyzer</code> to detect if a sentence is negative, neutral, positive, or a combination.</p>&#13;
    <p class="normal">The library can do much more, but this already gives you a nice indication of how easy it is to get started. If you need any basic human input parsing, make sure to give it a try as it offers very impressive results.</p>&#13;
    <h2 id="_idParaDest-471" class="heading-2">spaCy – Natural language processing with Cython</h2>&#13;
    <p class="normal">The spaCy<a id="_idIndexMarker1370"/> library is a very impressive and extremely fast NLP library. It comes with many pre-trained neural network models for over 60 languages and does a very good job at text classification and named entity recognition.</p>&#13;
    <p class="normal">The documentation is amazing and, while being fully open-source, it is developed by the company Explosion, which is doing a really good job of keeping up with the latest developments in NLP. If you want a high-level understanding of text, this library is one of your best options. If you only need basic text tokenization, then I would still recommend <code class="inlineCode">NLTK</code> because it is faster and more effective.</p>&#13;
    <p class="normal">Before we continue with the example, we need to install spaCy and download the models:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>pip3 install spacy&#13;
<span class="hljs-con-meta">$ </span>python3 -m spacy download en_core_web_sm&#13;
</code></pre>&#13;
    <p class="normal">The <code class="inlineCode">en_core_web_sm</code> dataset is a small and fast English dataset. If you need a more thorough dataset, you can download <code class="inlineCode">en_core_web_trf</code> instead.</p>&#13;
    <div class="note">&#13;
      <p class="normal">To install a different language, I recommend you visit the <a id="_idIndexMarker1371"/>spaCy website: <a href="https://spacy.io/usage#quickstart"><span class="url">https://spacy.io/usage#quickstart</span></a>. For example, the Dutch dataset is called <code class="inlineCode">nl_core_news_sm</code>, as opposed to <code class="inlineCode">nl_core_web_sm</code>, which you might have been expecting.</p>&#13;
    </div>&#13;
    <p class="normal">Now that we have <a id="_idIndexMarker1372"/>that taken care of, let’s try to extract some information from a sentence:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">import</span> spacy&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">import</span> en_core_web_sm&#13;
&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> nlp = en_core_web_sm.load()&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> _ = nlp.add_pipe(<span class="hljs-con-string">"merge_entities"</span>)&#13;
&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> sentence = (<span class="hljs-con-string">'Python was introduced in 1989 by Guido van '</span>&#13;
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">'Rossum at Stichting Mathematisch Centrum in Amsterdam.'</span>)&#13;
&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">for</span> token <span class="hljs-con-keyword">in</span> nlp(sentence):&#13;
<span class="hljs-con-meta">...</span>     <span class="hljs-con-keyword">if</span> token.ent_type_:&#13;
<span class="hljs-con-meta">...</span>         <span class="hljs-con-built_in">print</span>(<span class="hljs-con-string">f'</span><span class="hljs-con-subst">{token.ent_type_}</span><span class="hljs-con-string">: </span><span class="hljs-con-subst">{token.text}</span><span class="hljs-con-string">'</span>)&#13;
DATE: 1989&#13;
PERSON: Guido van Rossum&#13;
ORG: Stichting Mathematisch Centrum&#13;
GPE: Amsterdam&#13;
</code></pre>&#13;
    <p class="normal">After loading <code class="inlineCode">spacy</code> and the <code class="inlineCode">en_core_web_sm</code> model, we added the <code class="inlineCode">merge_entities</code> pipe. This pipe automatically merges the tokens together so we get <code class="inlineCode">"Guido van Rossum"</code> instead of <code class="inlineCode">"Guido"</code>, <code class="inlineCode">"van"</code>, and <code class="inlineCode">"Rossum"</code> as separate tokens.</p>&#13;
    <p class="normal">Isn’t this an amazing result? It automatically understands that <code class="inlineCode">"Guido van Rossum"</code> is a person, <code class="inlineCode">"Stichting Mathematisch Centrum"</code> is an organisation, and <code class="inlineCode">"Amsterdam"</code> is a geopolitical entity.</p>&#13;
    <h2 id="_idParaDest-472" class="heading-2">Gensim – Topic modeling for humans</h2>&#13;
    <p class="normal">The Gensim<a id="_idIndexMarker1373"/> library (<a href="https://radimrehurek.com/gensim/"><span class="url">https://radimrehurek.com/gensim/</span></a>) takes care of NLP for you. It is similar to NLTK but more focused on the modern machine learning libraries. It is well documented and easy to use and can be used to calculate similarities between texts, analyze the topic of a piece of text, and more. While there is a large overlap between NLTK and <a id="_idIndexMarker1374"/>Gensim, I would argue that Gensim is a bit of a higher-level library and slightly easier to get started with. NLTK, on the other hand, has existed for over 20 years and has a huge amount of documentation available in the wild because of that.</p>&#13;
    <h1 id="_idParaDest-473" class="heading-1">Machine learning</h1>&#13;
    <p class="normal">Machine learning<a id="_idIndexMarker1375"/> is the branch of artificial intelligence that can learn by itself. This can be fully autonomous learning, learning based on pre-labeled data, or a combination of these. </p>&#13;
    <p class="normal">We need a little bit of background information before we can dive into the libraries and the examples for this subject. Feel free to gloss over this section and jump straight to the libraries if you are already familiar with the types of machine learning.</p>&#13;
    <h2 id="_idParaDest-474" class="heading-2">Types of machine learning</h2>&#13;
    <p class="normal">As we have briefly covered in the <a id="_idIndexMarker1376"/>introduction, machine learning roughly splits up into three different methodologies, but often uses a combination of several. To recap, we have the following three major branches:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Supervised learning</li>&#13;
      <li class="bulletList">Reinforcement learning</li>&#13;
      <li class="bulletList">Unsupervised learning</li>&#13;
    </ul>&#13;
    <p class="normal">Naturally, there are many combinations of these, so we will discuss a few important distinct types of learning that are based on the branches above. The names themselves should already give you a hint about how they function, but we will dive deeper.</p>&#13;
    <h3 id="_idParaDest-475" class="heading-3">Supervised learning</h3>&#13;
    <p class="normal">In the case of <a id="_idIndexMarker1377"/>supervised learning, we provide the system with a lot of labeled data so the <a id="_idIndexMarker1378"/>machine can learn the relationship between the input data and the labels. Once it has been trained on that data, we can test using new data to see if it works. If the results are not as expected, parameters or intermediate training steps are tuned until the results improve.</p>&#13;
    <p class="normal">Examples of these are:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Classification models where the models are trained on a large number of photos to recognize the objects in the photo. Or to answer a question such as: “Are we looking at a bird?”</li>&#13;
      <li class="bulletList">Sentiment analysis of text. Is the person writing the message happy, sad, hostile, and so on?</li>&#13;
      <li class="bulletList">Weather prediction. Since we have a huge amount of historical weather data <a id="_idIndexMarker1379"/>available, this<a id="_idIndexMarker1380"/> is a perfect case for supervised learning.</li>&#13;
    </ul>&#13;
    <p class="normal">If you have the data available, this will probably be your best option. In many cases, however, you either don’t have the data or you have data without high-quality labels. That is where the other learning methods come in.</p>&#13;
    <h3 id="_idParaDest-476" class="heading-3">Reinforcement learning</h3>&#13;
    <p class="normal">Reinforcement learning <a id="_idIndexMarker1381"/>is similar to supervised learning, but instead of using<a id="_idIndexMarker1382"/> labeled input/output pairs it uses a <strong class="keyWord">scoring</strong> or <strong class="keyWord">reward function</strong> to provide feedback. The parameter that has to be <a id="_idIndexMarker1383"/>tuned with<a id="_idIndexMarker1384"/> reinforcement learning is whether to re-use existing knowledge or to investigate a new solution. Leaning too heavily toward re-use will result in a “local optimum,” where you will never get the best (or even a good) result because you get stuck on your previously found solution. Leaning too much toward investigation/exploration of new solutions, however, results in never reaching an optimal solution.</p>&#13;
    <p class="normal">Examples of these are:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Creating solvers/players for games. For a game such as Go or Chess, you could use win/lose as a scoring function. For a game such as Pong or Tetris, you could use the score as the reward.</li>&#13;
      <li class="bulletList">Robot navigation systems. As a scoring system, you could use “distance moved from origin” combined with “not hitting a wall.”</li>&#13;
      <li class="bulletList">Swarm intelligence. These are systems with many (a swarm) of independent, self-organizing systems that need to reach a common goal. As an example, some online supermarkets use swarms of robots to automatically fetch and package groceries with this method. The swarm intelligence takes care of collision avoidance and automatically replacing defective robots.</li>&#13;
    </ul>&#13;
    <p class="normal">Reinforcement<a id="_idIndexMarker1385"/> learning is the next best option after supervised learning, because it doesn’t require a large amount of high-quality data. You can combine these methods quite<a id="_idIndexMarker1386"/> well, though. Creating a good scoring function can be difficult, and you can easily verify your function by testing it on known good data.</p>&#13;
    <h3 id="_idParaDest-477" class="heading-3">Unsupervised learning</h3>&#13;
    <p class="normal">By the name alone, you <a id="_idIndexMarker1387"/>might be confused<a id="_idIndexMarker1388"/> by unsupervised learning. </p>&#13;
    <p class="normal">After all, how would an unsupervised system work if it has no idea when it has reached a useful solution? The point is that with unsupervised learning you don’t know what the solution will look like in the end, but you can declare how a solution <em class="italic">could</em> look.</p>&#13;
    <p class="normal">Since the explanation of unsupervised learning is a bit vague, I hope some examples help:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Clustering algorithms. With clustering, you feed the algorithm data with a lot of variables (for example, in the case of people, weight, height, gender, and so on) and tell the algorithm to find clusters.</li>&#13;
      <li class="bulletList">Anomaly detection. This is also an area where unsupervised learning can really shine. With anomaly detection, you never know what you are really looking for, but any patterns that are out of the ordinary could be important.</li>&#13;
    </ul>&#13;
    <p class="normal">Unsupervised learning is quite a different type of method from the other two machine learning methods we covered earlier because there is often no known target. However, that does not make it useless by any means. Finding patterns in seemingly random data can be really useful in uptime/stability monitoring or visitor analysis for e-commerce websites, among other things.</p>&#13;
    <p class="normal">Now it’s time to look at combinations of the previous methods.</p>&#13;
    <h3 id="_idParaDest-478" class="heading-3">Combinations of learning methods</h3>&#13;
    <p class="normal">AI development is as <a id="_idIndexMarker1389"/>active as it has ever been and I expect the field to keep growing in the foreseeable future. That is why more and more variants of algorithms are being used, which causes these clear-cut definitions to become more flexible all the time.</p>&#13;
    <p class="normal">In some cases, for example, you can get much better results by combining supervised and reinforcement learning together than you could by using either of these methods alone. That is why the lines between all of these methods can be extremely blurry, and if a method works for your <a id="_idIndexMarker1390"/>goal, it is not wrong to combine them.</p>&#13;
    <h3 id="_idParaDest-479" class="heading-3">Deep learning</h3>&#13;
    <p class="normal">One of the most effective<a id="_idIndexMarker1391"/> examples of machine learning is deep learning. This type of machine <a id="_idIndexMarker1392"/>learning has become extremely popular over the last few years because it has proven to be one of the most effective types of neural networks in practical applications, in some cases even outperforming human experts.</p>&#13;
    <p class="normal">This type of network is called <strong class="keyWord">deep</strong> because the neural network has multiple (often many) hidden internal layers, while traditional neural networks usually only have a single or a few hidden layers.</p>&#13;
    <p class="normal">Beyond that, it is just a regular neural network and can be supervised, unsupervised, reinforcement, or anything in between.</p>&#13;
    <h2 id="_idParaDest-480" class="heading-2">Artificial neural networks and deep learning</h2>&#13;
    <p class="normal">When thinking about AI, most people will immediately think of <strong class="keyWord">artificial neural networks</strong> (<strong class="keyWord">ANNs</strong>). These <a id="_idIndexMarker1393"/>networks are an attempt to mimic the workings of animal brains by having artificial neurons and connections between them similar to synapses.</p>&#13;
    <p class="normal">There are a few key differences, however. In an animal brain, a neuron can function both as input and output, whereas with an ANN there are usually a set of input neurons in an input layer, a set of neurons as an output layer, and the middle layer(s) that handles the processing.</p>&#13;
    <div class="note">&#13;
      <p class="normal">Currently (in 2021; it was launched in June 2020) by far the most impressive ANN is the GPT-3 network, which has been trained for NLP. It has an incredible 175 billion machine learning parameters and in some cases the text it generates is indistinguishable from human-written text.</p>&#13;
      <p class="normal">This text is likely to be outdated quite soon, however. The GPT-3 network is already 100 times bigger than GPT-2, which was released in 2019. GPT-4 has already been announced and is supposed to be about 500 times larger than GPT-3.</p>&#13;
    </div>&#13;
    <p class="normal">It should be noted that while <a id="_idIndexMarker1394"/>ANNs (and especially deep learning) networks are very powerful and can be self-learning, many of them are static. After they have been trained once, they do not improve or update anymore.</p>&#13;
    <p class="normal">The libraries in this section are made to build neural networks and to enable deep learning. Since this is an entirely distinct field in AI, it really deserves its own section. Note that you can still mix and match AI strategies if needed, of course.</p>&#13;
    <p class="normal">Within Python, there are multiple large libraries for creating neural networks, but the biggest ones by far are <strong class="keyWord">PyTorch</strong> and <strong class="keyWord">TensorFlow/Keras</strong>. Until a few years ago, there was another large library with<a id="_idIndexMarker1395"/> similar features called Theano. That library has since been discontinued and forked <a id="_idIndexMarker1396"/>under a new name, Aesara. Neither of these is used very often <a id="_idIndexMarker1397"/>these days, but Theano is considered to be the original Python neural network library. The TensorFlow library was actually created to replace Theano within Google.</p>&#13;
    <h3 id="_idParaDest-481" class="heading-3">Tensors</h3>&#13;
    <p class="normal">The basis of an ANN is the tensor. Tensors are a mathematical representation for your data with descriptions of valid<a id="_idIndexMarker1398"/> transformations that can be applied to this data. The actual story is much more complicated, of course, but for the purposes of the discussion here you can think of a tensor as a multi-dimensional array very similar to the <code class="inlineCode">numpy.ndarray</code> object we have seen in the previous chapter.</p>&#13;
    <p class="normal">When people talk about a 0-dimensional or 0D Tensor, they are effectively talking about a single number. Going up from that, a 1D tensor is an array or vector, and a 2D tensor is a matrix.</p>&#13;
    <p class="normal">The big takeaway for now is that the difference between a regular number/array/matrix and a tensor is that the tensors specify what transformations are valid on them as well. It is basically the difference between a <code class="inlineCode">list()</code> and a custom <code class="inlineCode">class</code> that contains the data for the <code class="inlineCode">list()</code> but has additional properties as well.</p>&#13;
    <h3 id="_idParaDest-482" class="heading-3">PyTorch – Fast (deep) neural networks</h3>&#13;
    <p class="normal">PyTorch<a id="_idIndexMarker1399"/> is a library developed by Facebook and focuses on building neural networks, such as deep learning networks, using tensors.</p>&#13;
    <p class="normal">The tensors in PyTorch use a custom data structure (instead of <code class="inlineCode">numpy.ndarray</code>) for performance reasons. The PyTorch library is heavily optimized for performance and it has built-in support for GPU acceleration for further speedups.</p>&#13;
    <div class="packt_tip">&#13;
      <p class="normal">In many cases you can use <code class="inlineCode">torch.Tensor</code> as a drop-in replacement for <code class="inlineCode">numpy.ndarray</code> to enable GPU acceleration. The <code class="inlineCode">torch.Tensor</code> API is largely identical to the <code class="inlineCode">numpy.ndarray</code> API.</p>&#13;
    </div>&#13;
    <p class="normal">The real strength of PyTorch (besides the performance) is the number of utility libraries included for different kinds of inputs. You can easily use it to process images, video, audio, and text using these APIs, and most processes can easily be run in parallel in a distributed fashion. </p>&#13;
    <p class="normal">Here is a little overview of the most useful modules:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><code class="inlineCode">torch.distributed</code>: For parallel training across multiple GPUs in a single system or across <a id="_idIndexMarker1400"/>multiple systems.</li>&#13;
      <li class="bulletList"><code class="inlineCode">torchaudio</code>: For <a id="_idIndexMarker1401"/>processing audio, either from pre-recorded files or straight from (multiple) microphones.</li>&#13;
      <li class="bulletList"><code class="inlineCode">torchtext</code>: For<a id="_idIndexMarker1402"/> processing text; you can also combine this with NLP libraries such as NLTK.</li>&#13;
      <li class="bulletList"><code class="inlineCode">torchvision</code>: For<a id="_idIndexMarker1403"/> processing images and sequences of images (videos).</li>&#13;
      <li class="bulletList"><code class="inlineCode">torchserve</code>: For<a id="_idIndexMarker1404"/> setting up a server that hosts your models so you can build a service that runs your calculations. This is useful because starting a process and loading the model can be a slow and heavy task.</li>&#13;
      <li class="bulletList"><code class="inlineCode">torch.utils</code>: Contains <a id="_idIndexMarker1405"/>many useful utility functions, but above all, TensorBoard. With TensorBoard, you can interactively (through a web interface) inspect your models and make changes to your model parameters.</li>&#13;
    </ul>&#13;
    <p class="normal">It’s time for a small example, but before we can get started we need to install both <code class="inlineCode">pytorch</code> and <code class="inlineCode">torchvision</code>:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>pip3 install torch torchvision&#13;
</code></pre>&#13;
    <p class="normal">We will use the pre-trained <strong class="keyWord">Mask R-CNN</strong> model to do<a id="_idIndexMarker1406"/> object <a id="_idIndexMarker1407"/>recognition. This is a <strong class="keyWord">region-based convolutional neural network</strong> (<strong class="keyWord">R-CNN</strong>) that has been trained using a combination of images and labeled image masks (object outlines).</p>&#13;
    <div class="note">&#13;
      <p class="normal">CNNs<a id="_idIndexMarker1408"/> are well suited for visual applications such as image classification and image segmentation. They can also be applied to other types of problems such as NLP as well.</p>&#13;
      <p class="normal">The R-CNN is <a id="_idIndexMarker1409"/>a specialized version of the CNN specifically for computer vision tasks such as object detection. R-CNN tasks are trained by specifying the <strong class="keyWord">region of interest</strong> (<strong class="keyWord">ROI</strong>) in a set of <a id="_idIndexMarker1410"/>images. The Mask R-CNN is a specialization that specifies the ROI not as a rectangle but as a mask that only highlights the specific object.</p>&#13;
    </div>&#13;
    <p class="normal">Now we’ll do some object recognition using <a id="_idIndexMarker1411"/>PyTorch. First, we load the photo and imports and convert the photo into a tensor:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">%matplotlib inline&#13;
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image&#13;
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt, patches&#13;
<span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms&#13;
<span class="hljs-keyword">from</span> torchvision.models <span class="hljs-keyword">import</span> detection&#13;
&#13;
dpi = <span class="hljs-number">300</span>&#13;
font_size = <span class="hljs-number">14</span>&#13;
color = <span class="hljs-string">'white'</span>&#13;
min_score = <span class="hljs-number">0.8</span>&#13;
min_size = <span class="hljs-number">100</span>&#13;
label_offset = <span class="hljs-number">25</span>, -<span class="hljs-number">25</span>&#13;
&#13;
<span class="hljs-comment"># Load the img and convert it to a PyTorch Tensor</span>&#13;
img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">'amsterdam-street.jpg'</span>)&#13;
img_t = transforms.ToTensor()(img)&#13;
</code></pre>&#13;
    <p class="normal">The conversion to a tensor can be done using the <code class="inlineCode">ToTensor</code> transform operation. The <code class="inlineCode">torchvision.transforms</code> module has many more operations available, such as resizing, cropping, and color normalization, to pre-filter the images before we send them to the model.</p>&#13;
    <p class="normal">Next up is the loading of the model and the labels: </p>&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Read the labels from coco_labels. The entire COCO</span>&#13;
<span class="hljs-comment"># (Common Objects in COntext) dataset is available at:</span>&#13;
<span class="hljs-comment"># https://cocodataset.org/#download</span>&#13;
labels = <span class="hljs-built_in">open</span>(<span class="hljs-string">'coco_labels.txt'</span>).read().splitlines()&#13;
&#13;
<span class="hljs-comment"># Load the R-CNN model and set it to eval mode for execution</span>&#13;
model = detection.fasterrcnn_resnet50_fpn(pretrained=<span class="hljs-literal">True</span>)&#13;
model.<span class="hljs-built_in">eval</span>()&#13;
<span class="hljs-comment"># Apply the model to the img as a list and unpack after applying</span>&#13;
out, = model([img_t])&#13;
</code></pre>&#13;
    <div class="note">&#13;
      <p class="normal">The label file is available on this book’s GitHub page. </p>&#13;
    </div>&#13;
    <p class="normal">As you can see, the model itself is bundled with<a id="_idIndexMarker1412"/> PyTorch. After loading the model and setting it to <code class="inlineCode">eval</code> mode (as opposed to training), we can quickly apply the model to our image. The labels are unfortunately not bundled, so we need to fetch those ourselves. Now we need to display the results:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">results = <span class="hljs-built_in">zip</span>(out[<span class="hljs-string">'boxes'</span>].detach(), out[<span class="hljs-string">'</span><span class="hljs-string">labels'</span>], out[<span class="hljs-string">'scores'</span>])&#13;
&#13;
<span class="hljs-comment"># Increase the DPI to get a larger output image</span>&#13;
plt.figure(dpi=dpi)&#13;
img_desc = plt.subplot()&#13;
<span class="hljs-comment"># Walk through the list of detections and print the results</span>&#13;
<span class="hljs-keyword">for</span> (t, l, b, r), label_idx, score <span class="hljs-keyword">in</span> results:&#13;
    <span class="hljs-comment"># Skip objects that are questionable matches</span>&#13;
    <span class="hljs-keyword">if</span> score &lt; min_score:&#13;
        <span class="hljs-keyword">continue</span>&#13;
&#13;
    <span class="hljs-comment"># Skip tiny matches</span>&#13;
    h, w = b - t, r - l,&#13;
    <span class="hljs-keyword">if</span> w &lt; min_size <span class="hljs-keyword">or</span> h &lt; min_size:&#13;
        <span class="hljs-keyword">continue</span>&#13;
&#13;
    <span class="hljs-comment"># Draw the bounding box and label</span>&#13;
    img_desc.add_patch(patches.Rectangle(&#13;
        (t, l), h, w, fill=<span class="hljs-literal">False</span>, color=color))&#13;
    label = <span class="hljs-string">f'</span><span class="hljs-subst">{labels[label_idx]}</span><span class="hljs-string"> </span><span class="hljs-subst">{score * </span><span class="hljs-number">100</span><span class="hljs-subst">:</span><span class="hljs-number">.0</span><span class="hljs-subst">f}</span><span class="hljs-string">%'</span>&#13;
    img_desc.text(&#13;
        t + label_offset[<span class="hljs-number">0</span>], r + label_offset[<span class="hljs-number">1</span>], label,&#13;
        fontsize=font_size, color=color)&#13;
&#13;
<span class="hljs-comment"># Output the img as grayscale for print purposes</span>&#13;
plt.imshow(img.convert(<span class="hljs-string">'L'</span>), cmap=<span class="hljs-string">'gray'</span>)&#13;
plt.show()&#13;
</code></pre>&#13;
    <p class="normal">We can display the matches and their bounding boxes to get the following result:</p>&#13;
    <figure class="mediaobject"><img src="Images/B15882_16_07.png" alt="/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/B561F30E.tmp" width="763" height="408"/></figure>&#13;
    <p class="packt_figref">Figure 16.7: Street in Amsterdam with objects labeled by PyTorch</p>&#13;
    <p class="normal">With just a few lines of code, we managed to create an object recognizer that correctly identified a few cars, bicycles, and a boat.</p>&#13;
    <p class="normal">In practice, the model actually recognized far more objects in the image, but we filtered out small matches so the image is not too busy. It actually recognized seven more cars, four people, and two boats.</p>&#13;
    <h3 id="_idParaDest-483" class="heading-3">PyTorch Lightning and PyTorch Ignite – High-level PyTorch APIs</h3>&#13;
    <p class="normal">The PyTorch Lightning<a id="_idIndexMarker1413"/> and PyTorch Ignite<a id="_idIndexMarker1414"/> libraries are convenient shortcuts for getting your network up and running with fewer steps and several useful features built in. You can do the same with PyTorch directly, but using the utility functions you can run several PyTorch steps at once, meaning less repetition while working.</p>&#13;
    <p class="normal">These libraries were created independently, but serve roughly the same goal and are comparable in features. It depends on your personal preference as to which is the best for you. I would initially recommend you start with <a id="_idIndexMarker1415"/>PyTorch directly, however. While these libraries are really great, it is important to understand the underlying principles before you start using shortcuts that you might not completely understand. The PyTorch documentation is quite easy to follow and largely identical in workings to PyTorch<a id="_idIndexMarker1416"/> Ignite and PyTorch Lightning, besides being a bit more verbose.</p>&#13;
    <h3 id="_idParaDest-484" class="heading-3">Skorch – Mixing PyTorch and scikit-learn</h3>&#13;
    <p class="normal">As was briefly mentioned, scikit-learn natively supports neural networks, but its performance is not good enough for large-scale networks. The Skorch library<a id="_idIndexMarker1417"/> takes care of that; you can still use the scikit-learn API if you are familiar with that, but it runs on PyTorch internally to achieve great performance.</p>&#13;
    <h3 id="_idParaDest-485" class="heading-3">TensorFlow/Keras – Fast (deep) neural networks</h3>&#13;
    <p class="normal">The TensorFlow library<a id="_idIndexMarker1418"/> is developed by Google and focuses on building deep neural networks very similar to PyTorch. The library is well documented and has a large number of pre-trained models available to use; you may never have to train your own models, which can be a big advantage.</p>&#13;
    <p class="normal">Similar to PyTorch, TensorFlow is also based on tensors for the actual calculations, and it is highly optimized for performance on many platforms, including mobile phones for deployment and<a id="_idIndexMarker1419"/> dedicated <strong class="keyWord">tensor processing units</strong> (<strong class="keyWord">TPU</strong>s) or GPU hardware for training the models.</p>&#13;
    <p class="normal">As an example, we will run the Mask R-CNN we used with PyTorch earlier again. Since this model is not bundled with <code class="inlineCode">tensorflow</code>, we need to install <code class="inlineCode">tensorflow-hub</code> in addition to <code class="inlineCode">tensorflow</code>:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$</span> pip3 install tensorflow tensorflow-hub&#13;
</code></pre>&#13;
    <p class="normal">This will automatically install <code class="inlineCode">tensorflow</code> with GPU support if available for your platform. Currently, that means either Windows or Ubuntu Linux. Now we can test some TensorFlow/Keras code. First, we import what we need, set some variables, and load the image:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">%matplotlib inline&#13;
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np&#13;
<span class="hljs-keyword">import</span> tensorflow_hub <span class="hljs-keyword">as</span> hub&#13;
<span class="hljs-keyword">from</span> keras.preprocessing <span class="hljs-keyword">import</span> image&#13;
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt, patches&#13;
&#13;
dpi = <span class="hljs-number">300</span>&#13;
font_size = <span class="hljs-number">14</span>&#13;
color = <span class="hljs-string">'white'</span>&#13;
min_score = <span class="hljs-number">0.8</span>&#13;
min_size = <span class="hljs-number">100</span>&#13;
label_offset = <span class="hljs-number">25</span>, -<span class="hljs-number">25</span>&#13;
&#13;
<span class="hljs-comment"># Load the img and convert it to a numpy array</span>&#13;
img = image.load_img(<span class="hljs-string">'amsterdam-street.jpg'</span>)&#13;
img_t = image.img_to_array(img)&#13;
img_w, img_h = img.size&#13;
</code></pre>&#13;
    <p class="normal">Now that the image is<a id="_idIndexMarker1420"/> loaded, let’s load the model using <code class="inlineCode">tensorflow_hub</code> and apply it on our image:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">labels = <span class="hljs-built_in">open</span>(<span class="hljs-string">'coco_labels.txt'</span>).read().splitlines()&#13;
model = hub.load(    <span class="hljs-string">'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'</span>)&#13;
out = model(np.array([img_t]))&#13;
&#13;
<span class="hljs-comment"># The box coordinates are normalized to [0, 1]</span>&#13;
img_dim = np.array([img.size[<span class="hljs-number">1</span>], img.size[<span class="hljs-number">0</span>]] * <span class="hljs-number">2</span>)&#13;
result = <span class="hljs-built_in">zip</span>(&#13;
    out[<span class="hljs-string">'detection_boxes'</span>][<span class="hljs-number">0</span>] * img_dim,&#13;
    out[<span class="hljs-string">'detection_classes'</span>][<span class="hljs-number">0</span>],&#13;
    out[<span class="hljs-string">'detection_scores'</span>][<span class="hljs-number">0</span>],&#13;
)&#13;
</code></pre>&#13;
    <p class="normal">Once again, we don’t have the labels available, so we read that from our <code class="inlineCode">coco_labels.txt</code> file. However, once we load the model we can easily apply it to our image. </p>&#13;
    <p class="normal">Now we need to prepare the results for easy processing and display them:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Increase the DPI to get a larger output image</span>&#13;
plt.figure(dpi=dpi)&#13;
img_desc = plt.subplot()&#13;
&#13;
<span class="hljs-comment"># Walk through the list of detections and print the results</span>&#13;
<span class="hljs-keyword">for</span> (l, t, r, b), label_idx, score <span class="hljs-keyword">in</span> result:&#13;
    label_idx = <span class="hljs-built_in">int</span>(label_idx)&#13;
    <span class="hljs-comment"># Skip objects that are questionable matches</span>&#13;
    <span class="hljs-keyword">if</span> score &lt; min_score:&#13;
        <span class="hljs-keyword">continue</span>&#13;
&#13;
    <span class="hljs-comment"># Skip tiny matches</span>&#13;
    h, w = b - t, r - l,&#13;
    <span class="hljs-keyword">if</span> w &lt; min_size <span class="hljs-keyword">or</span> h &lt; min_size:&#13;
        <span class="hljs-keyword">continue</span>&#13;
&#13;
    <span class="hljs-comment"># Draw the bounding box and label</span>&#13;
    img_desc.add_patch(patches.Rectangle(&#13;
        (t, l), h, w, fill=<span class="hljs-literal">False</span>, color=color))&#13;
    label = <span class="hljs-string">f'</span><span class="hljs-subst">{labels[label_idx]}</span><span class="hljs-string"> </span><span class="hljs-subst">{score * </span><span class="hljs-number">100</span><span class="hljs-subst">:</span><span class="hljs-number">.0</span><span class="hljs-subst">f}</span><span class="hljs-string">%'</span>&#13;
    img_desc.text(&#13;
        t + label_offset[<span class="hljs-number">0</span>], r + label_offset[<span class="hljs-number">1</span>], label,&#13;
        fontsize=font_size, color=color)&#13;
&#13;
<span class="hljs-comment"># Output the img as a large grayscale for print purposes</span>&#13;
plt.imshow(img.convert(<span class="hljs-string">'L'</span>), cmap=<span class="hljs-string">'gray'</span>)&#13;
</code></pre>&#13;
    <p class="normal">The code is largely<a id="_idIndexMarker1421"/> similar to the PyTorch code because it uses the same pre-trained model. The notable differences are:</p>&#13;
    <ul>&#13;
      <li class="bulletList">We loaded the model using <code class="inlineCode">tensorflow_hub</code>. This automatically downloads and executes pre-trained models from <a href="https://tfhub.dev/"><span class="url">https://tfhub.dev/</span></a>.</li>&#13;
      <li class="bulletList">The box points are from 0 to 1 instead of being relative to the image size. So, coordinate <code class="inlineCode">10x5</code> in a <code class="inlineCode">20x20</code> image results in <code class="inlineCode">0.5x0.25</code>.</li>&#13;
      <li class="bulletList">The output variable names are different. It should be noted that these are dependent on the model and can be found on TensorFlow Hub for this model: <a href="https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1"><span class="url">https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1</span></a>.</li>&#13;
      <li class="bulletList">The box points use the left, top, right, bottom order instead of top, left, bottom, right, as was the case with PyTorch.</li>&#13;
    </ul>&#13;
    <p class="normal">Beyond those small changes, the code is effectively identical.</p>&#13;
    <h4 class="heading-4">NumPy compatibility</h4>&#13;
    <p class="normal">The actual tensor objects in TensorFlow are slightly different from the PyTorch tensors. While the <code class="inlineCode">pytorch.Tensor</code> API <a id="_idIndexMarker1422"/>can be used as a <code class="inlineCode">numpy.ndarray</code> alternative, with <code class="inlineCode">tensorflow.Tensor</code> the API is a bit different.</p>&#13;
    <p class="normal">There is a <code class="inlineCode">tensorflow.Tensor.numpy()</code> method, which returns a <code class="inlineCode">numpy.ndarray</code> of the data. It is important to note that this is <em class="italic">not</em> a reference, however; modifying the <code class="inlineCode">numpy</code> array will <em class="italic">not</em> update the original tensor, so you will need to convert it back after your changes.</p>&#13;
    <p class="normal">As an alternative, TensorFlow does offer an experimental <code class="inlineCode">numpy</code> API if you prefer that API. It can be enabled like this:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">import</span> tensorflow.experimental.numpy <span class="hljs-con-keyword">as</span> tnp&#13;
&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> tnp.experimental_enable_numpy_behavior()&#13;
</code></pre>&#13;
    <p class="normal">Usage is fairly straightforward, but it is by no means fully <code class="inlineCode">numpy.ndarray</code>-compatible:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> x = tnp.random.random([<span class="hljs-con-number">5</span>])&#13;
<span class="hljs-con-meta">&gt;&gt;&gt;</span> x[:<span class="hljs-con-number">5</span>] += <span class="hljs-con-number">10</span>&#13;
Traceback (most recent call last):&#13;
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;&#13;
TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment&#13;
</code></pre>&#13;
    <h4 class="heading-4">Keras</h4>&#13;
    <p class="normal">The Keras <a id="_idIndexMarker1423"/>submodule of TensorFlow is similar to what PyTorch Lightning and PyTorch Ignite are for PyTorch. It offers a high-level interface for TensorFlow, making it easier to use and get started with. As opposed to the aforementioned PyTorch libraries, Keras is quite suitable as a starting point as well. Knowing the underlying TensorFlow functions can be useful, but it is not a requirement for being able to use Keras effectively.</p>&#13;
    <p class="normal">Keras might be for you if you are just getting started with TensorFlow and want to apply some machine learning to your project without going down the rabbit hole.</p>&#13;
    <h3 id="_idParaDest-486" class="heading-3">TensorFlow versus PyTorch</h3>&#13;
    <p class="normal">There are a few advantages and disadvantages to TensorFlow compared to PyTorch, so let’s list those before we continue.</p>&#13;
    <p class="normal">Here are some reasons you might choose TensorFlow over PyTorch:</p>&#13;
    <ul>&#13;
      <li class="bulletList">TensorFlow <a id="_idIndexMarker1424"/>supports the execution of the pre-trained <a id="_idIndexMarker1425"/>model in a web browser. While PyTorch does have a few libraries available to do this as well, they are either stale or far behind TensorFlow in terms of features and stability.</li>&#13;
      <li class="bulletList">TensorFlow is largely language-agnostic. This means that it has bindings for multiple languages, whereas PyTorch is largely Python-only.</li>&#13;
      <li class="bulletList">TensorFlow, or more specifically, Keras, is a very high-level API that allows you to get started quickly. When comparing Keras to PyTorch Lightning/PyTorch Ignite, I personally feel that you can get a working result more quickly with TensorFlow. Keras has many utility functions and classes bundled that can save you some work while creating a model. Another big help is TensorFlow Hub, which offers many pre-trained models with example code for your convenience.</li>&#13;
      <li class="bulletList">TensorFlow has a slightly bigger community and slightly more tutorials available.</li>&#13;
    </ul>&#13;
    <p class="normal">Conversely:</p>&#13;
    <ul>&#13;
      <li class="bulletList">PyTorch was written around Python and has a much more Pythonic API.</li>&#13;
      <li class="bulletList">PyTorch offers more fine-grained control and easily gives you many parameters to tune.</li>&#13;
      <li class="bulletList">While this is a personal opinion, I find that debugging PyTorch is much nicer (from Python, at least) than TensorFlow or Keras because the codebase has fewer layers and seems less complicated. Stepping through the execution of your model with a regular Python debugger works great and is easy to follow in the case of PyTorch. In my experience, regular Python debuggers do not work at all with TensorFlow.</li>&#13;
      <li class="bulletList">PyTorch is a <a id="_idIndexMarker1426"/>bit faster than TensorFlow. This can be a <a id="_idIndexMarker1427"/>huge help while developing and debugging. </li>&#13;
    </ul>&#13;
    <p class="normal">Which of the libraries you should use depends on personal preference and factors such as pre-existing experience for you and/or the rest of your team. I can certainly recommend both of them.</p>&#13;
    <h2 id="_idParaDest-487" class="heading-2">Evolutionary algorithms</h2>&#13;
    <p class="normal">Evolutionary algorithms <a id="_idIndexMarker1428"/>are a technique based on evolution in nature that improve by using a fitness function to determine quality, and by evolving the solution.</p>&#13;
    <p class="normal">The most common implementation<a id="_idIndexMarker1429"/> is the <strong class="keyWord">genetic algorithm</strong>, which commonly encodes the solution, or chromosome, into a string or an array that can be tested by the fitness function. This chromosome could be a list of functions to apply, a list of parameters to a function, or something else entirely. How you wish to encode the chromosome is up to you, as long as the fitness function can use it to calculate a fitness score.</p>&#13;
    <p class="normal">The genetic algorithm will employ one of the following operations to try and improve the fitness score:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><strong class="keyWord">Mutation</strong>: This could be a bit flip from 0 to 1, or a more complex mutation of replacing multiple bits. For example, if we have bit-string <code class="inlineCode">0101</code>, then a mutation could result in <code class="inlineCode">0111</code>.</li>&#13;
      <li class="bulletList"><strong class="keyWord">Selection</strong>: Given a set of different tested chromosomes using the fitness function, only keep the best few.</li>&#13;
      <li class="bulletList"><strong class="keyWord">Crossover</strong>: Given a few different chromosomes, combine parts of them to try new solutions. For example, if we have two strings, AABB and DEFG, the crossover can split them and combine them; for instance, you could get AAFG, which combines the first two characters from the first string and the last two from the second string.</li>&#13;
    </ul>&#13;
    <p class="normal">The genetic algorithm<a id="_idIndexMarker1430"/> takes a few parameters to control which strategy is employed at a given run. The <strong class="keyWord">mutation rate</strong> sets<a id="_idIndexMarker1431"/> the probability of a mutation occurring; the <strong class="keyWord">elitism parameter</strong> decides <a id="_idIndexMarker1432"/>how many results to keep in the selection process; and the <strong class="keyWord">crossover rate</strong> sets the probability of crossovers occurring. The difficult part<a id="_idIndexMarker1433"/> is tuning these parameters to return a good and stable solution (in other words, one that does not change too much between runs), but not getting stuck in a local optimum where your solution appears the best but could be far better by attempting more genetic diversity.</p>&#13;
    <p class="normal">There are many applications where genetic algorithms (or more generally, genetic programming) are the most feasible option to get a good solution to your problem. One of the prime examples of where genetic algorithms<a id="_idIndexMarker1434"/> shine is the <strong class="keyWord">traveling salesman problem</strong> (<strong class="keyWord">TSP</strong>). With the TSP, you have a list of cities that you want to visit, and you want to find the shortest route that covers all of them. The standard brute-force solution has a time complexity of <code class="inlineCode">O(n!)</code>, which means that for 10 cities you need about 3,628,800 steps to calculate. That is a lot, but still easily manageable. For 20 cities, however, the number grows to 2,432,902,008,176,640,000, or, 2 quintillion (2 billion billion), and that growth continues very rapidly. With genetic programming, the fitness problem will almost immediately eliminate parts of the solution space that are completely infeasible and gives you a good (but possibly not the best) solution relatively fast.</p>&#13;
    <p class="normal">Even though <a id="_idIndexMarker1435"/>evolutionary algorithms offer a lot of power, implementing them is relatively easy to do and often highly specific to your specific use case. This makes it a scenario where applications and libraries usually opt for writing their own implementation instead of using a library for this goal.</p>&#13;
    <p class="normal">There is at least one notable Python library for genetic algorithms however. The PyGAD library can make it <a id="_idIndexMarker1436"/>easily possible for you to use genetic algorithms in your project. It also comes with built-in support for Keras and PyTorch to save you some work.</p>&#13;
    <p class="normal">Let’s start by installing PyGAD:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>pip3 install pygad&#13;
</code></pre>&#13;
    <p class="normal">Now we will attempt to solve a problem you might encounter in the real world. Let’s say that you need a new floor and you want wooden floorboards. Due to bulk discounts, it can be cheaper to buy a large stack of boards instead of just a few separate boards, so let’s assume we have a few different bulk quantities and make our algorithm optimize for cost. First, we need to define our list of bulk sizes with the prices. We will also define the number of boards we are looking for. Lastly, we will define the fitness function to tell PyGAD how good (or bad) the solution is:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np&#13;
<span class="hljs-keyword">import</span> pygad&#13;
<span class="hljs-comment"># Combination of number of boards with the prices per board</span>&#13;
stack_prices = np.array(&#13;
    [&#13;
        [<span class="hljs-number">1</span>, <span class="hljs-number">10</span>],  <span class="hljs-comment"># $10 per board</span>&#13;
        [<span class="hljs-number">5</span>, <span class="hljs-number">5</span> * <span class="hljs-number">9</span>],  <span class="hljs-comment"># $9 per board</span>&#13;
        [<span class="hljs-number">10</span>, <span class="hljs-number">10</span> * <span class="hljs-number">8</span>],  <span class="hljs-comment"># $8 per board</span>&#13;
        [<span class="hljs-number">25</span>, <span class="hljs-number">25</span> * <span class="hljs-number">7</span>],  <span class="hljs-comment"># $7 per board</span>&#13;
    ]&#13;
)&#13;
&#13;
<span class="hljs-comment"># The minimum number of boards to buy</span>&#13;
desired_boards = <span class="hljs-number">67</span>&#13;
&#13;
<span class="hljs-keyword">def</span> <span class="hljs-title">fitness_function</span>(<span class="hljs-params">solution: numpy.ndarray, solution_index</span>):&#13;
    <span class="hljs-comment"># We can't have a negative number of boards</span>&#13;
    <span class="hljs-keyword">if</span> (solution &lt; <span class="hljs-number">0</span>).<span class="hljs-built_in">any</span>():&#13;
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(<span class="hljs-string">'-inf'</span>)&#13;
&#13;
    <span class="hljs-comment"># Make sure we have the minimum number of boards required</span>&#13;
    total_area = stack_prices[:, <span class="hljs-number">0</span>] * solution&#13;
    <span class="hljs-keyword">if</span> total_area.<span class="hljs-built_in">sum</span>() &lt; desired_boards:&#13;
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(<span class="hljs-string">'-inf'</span>)&#13;
&#13;
    <span class="hljs-comment"># Calculate the price of the solution</span>&#13;
    price = stack_prices[:, <span class="hljs-number">1</span>] * solution&#13;
    <span class="hljs-comment"># The fitness function maximizes so invert the price</span>&#13;
    <span class="hljs-keyword">return</span> - price.<span class="hljs-built_in">sum</span>()&#13;
</code></pre>&#13;
    <p class="normal">The fitness functions for <a id="_idIndexMarker1437"/>PyGAD optimize for the highest number; since we are looking for the lowest price, we can simply invert the price. Additionally, we can return minus infinity when we want to rule out “bad” solutions.</p>&#13;
    <p class="normal">To get some intermediate results, we can optionally add a function that will show us the state at every generation:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">print_status</span>(<span class="hljs-params">instance</span>):&#13;
    <span class="hljs-comment"># Only print the status every 100 iterations</span>&#13;
    <span class="hljs-keyword">if</span> instance.generations_completed % <span class="hljs-number">100</span>:&#13;
        <span class="hljs-keyword">return</span>&#13;
&#13;
    total = <span class="hljs-number">0</span>&#13;
    solution = instance.best_solution()[<span class="hljs-number">0</span>]&#13;
    <span class="hljs-comment"># Print the generation, bulk size, and the total price</span>&#13;
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'Generation </span><span class="hljs-subst">{instance.generations_completed}</span><span class="hljs-string">'</span>, end=<span class="hljs-string">' '</span>)&#13;
    <span class="hljs-keyword">for</span> mp, (boards, price) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(solution, stack_prices):&#13;
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f'</span><span class="hljs-subst">{mp:2d}</span><span class="hljs-string">x</span><span class="hljs-subst">{boards}</span><span class="hljs-string">,'</span>, end=<span class="hljs-string">''</span>)&#13;
        total += mp * price&#13;
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f' price: $</span><span class="hljs-subst">{total}</span><span class="hljs-string">'</span>)&#13;
</code></pre>&#13;
    <p class="normal">Now it’s time to run the algorithm and show the output while doing so:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">ga_instance = pygad.GA(&#13;
    num_generations=<span class="hljs-number">1000</span>,&#13;
    num_parents_mating=<span class="hljs-number">10</span>,&#13;
    <span class="hljs-comment"># Every generation will have 100 solutions</span>&#13;
    sol_per_pop=<span class="hljs-number">100</span>,&#13;
    <span class="hljs-comment"># We use 1 gene per stack size</span>&#13;
    num_genes=stack_prices.shape[<span class="hljs-number">0</span>],&#13;
    fitness_func=fitness_function,&#13;
    on_generation=print_status,&#13;
    <span class="hljs-comment"># We can't buy half a board, so use integers</span>&#13;
    gene_type=<span class="hljs-built_in">int</span>,&#13;
    <span class="hljs-comment"># Limit the solution space to our maximum number of boards</span>&#13;
    gene_space=numpy.arange(desired_boards),&#13;
    <span class="hljs-comment"># Limit how large the change in a mutation can be</span>&#13;
    random_mutation_min_val=-<span class="hljs-number">2</span>,&#13;
    random_mutation_max_val=<span class="hljs-number">2</span>,&#13;
    <span class="hljs-comment"># Disable crossover since it does not make sense in this case</span>&#13;
    crossover_probability=<span class="hljs-number">0</span>,&#13;
    <span class="hljs-comment"># Set the number of genes that are allowed to mutate at once</span>&#13;
    mutation_num_genes=stack_prices.shape[<span class="hljs-number">0</span>] // <span class="hljs-number">2</span>,&#13;
)&#13;
&#13;
ga_instance.run()&#13;
ga_instance.plot_fitness()&#13;
</code></pre>&#13;
    <p class="normal">This will run 1,000 generations <a id="_idIndexMarker1438"/>for us with 100 solutions per generation. A single solution contains the number of stacks of wood to buy for each stack size. When we run this code, we should get something similar to this:</p>&#13;
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>python3 T_02_pygad.py&#13;
Generation 100  3x1, 1x5, 6x10, 0x25, price: $555&#13;
Generation 200  3x1, 0x5, 4x10, 1x25, price: $525&#13;
...&#13;
Generation 900  2x1, 1x5, 1x10, 2x25, price: $495&#13;
Generation 1000  2x1, 1x5, 1x10, 2x25, price: $495&#13;
</code></pre>&#13;
    <p class="normal">The plot of our results:</p>&#13;
    <figure class="mediaobject"><img src="Images/B15882_16_08.png" alt="" width="620" height="491"/></figure>&#13;
    <p class="packt_figref">Figure 16.8: Genetic algorithm fitness result plot</p>&#13;
    <p class="normal">In this case, 495 is <a id="_idIndexMarker1439"/>actually the optimal result; in most cases, though, you don’t know if you have reached the optimal result. This essentially means that you could keep your code running forever, which is why you should either configure a fixed number of generations, or tell PyGAD to stop once it has reached a steady state for a certain number of generations.</p>&#13;
    <p class="normal">More importantly, however, after about 50 generations we already had a great and very usable solution for our problem, whereas the optimal solution took roughly 700 generations this run. In many of the other runs I did, it never even found the optimal solution. This shows you how quickly the genetic algorithm can give you a useful result.</p>&#13;
    <h2 id="_idParaDest-488" class="heading-2">Support-vector machines</h2>&#13;
    <p class="normal"><strong class="keyWord">Support-vector machines</strong> (<strong class="keyWord">SVMs</strong>) or support-vector networks are common models for supervised learning. Since it<a id="_idIndexMarker1440"/> is a supervised learning method, it expects a dataset that is already labeled (for example, a list of photos with correct labels) to train on. Once the model has been trained, it can be used for classification and regression analysis.</p>&#13;
    <p class="normal">In statistics, <strong class="keyWord">regression analysis</strong> is a <a id="_idIndexMarker1441"/>way to show the relationship between variables. These can be used to fit lines, create predictors, detect outliers, and more. We have seen several examples of regression analysis in <em class="chapterRef">Chapter 15</em>, <em class="italic">Scientific Python and Plotting</em>, as well.</p>&#13;
    <p class="normal"><strong class="keyWord">Classification</strong> refers to<a id="_idIndexMarker1442"/> statistical classification and is a method of splitting data. For example, the question as to whether an email is spam or not is a form of binary classification.</p>&#13;
    <h2 id="_idParaDest-489" class="heading-2">Bayesian networks</h2>&#13;
    <p class="normal">Bayesian networks<a id="_idIndexMarker1443"/> are based on the idea that we have probabilities of an event occurring. This is usually expressed as <code class="inlineCode">P(event)</code>, where <code class="inlineCode">P(event)=1</code> is 100% probability of <code class="inlineCode">event</code> occurring and <code class="inlineCode">P(event)=0</code> is no probability at all.</p>&#13;
    <p class="normal">These can be used for all sorts of applications and are particularly useful for expert systems, which can make recommendations based on your given data. For example, given that there is a thunderstorm outside, we know that there is a larger probability of rain than if it is sunny outside. In Bayesian terms, we would describe it like this:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">P(rain) = The probability of rain&#13;
P(thunderstorm) = The probability of a thunderstorm&#13;
P(rain | thunderstorm) = The probability of rain given that there is a thunderstorm&#13;
</code></pre>&#13;
    <p class="normal">Bayesian networks are often used for spam filters that look for certain keywords and calculate the odds of an email being spam. Another possible use case for Bayesian networks is text prediction when typing. If you train your network with many sentences, you can calculate the next most likely word to occur given the previous word or words.</p>&#13;
    <p class="normal">As you have seen, there are many types of different machine learning models, and many more submodels that all have their own strengths and weaknesses. This list of examples is an extremely condensed and simplified list of available models, but it should give you at least some idea of the scenarios in which these different algorithms can do their magic.</p>&#13;
    <h1 id="_idParaDest-490" class="heading-1">Versatile AI libraries and utilities</h1>&#13;
    <p class="normal">Python is by far the most<a id="_idIndexMarker1444"/> popular language when it comes to developing AI systems. The <a id="_idIndexMarker1445"/>result of this popularity is that there are a huge number of libraries available for every branch of AI you can think of. There is at least a single good library for nearly every AI technique, and often dozens. </p>&#13;
    <p class="normal">In this section of this chapter, you will find a curated (and incomplete) list of useful AI libraries split into segments. There are many more that are not mentioned due to being too specific, too new, or simply because I have omitted them owing to the great number of libraries that are out there.</p>&#13;
    <h2 id="_idParaDest-491" class="heading-2">scikit-learn – Machine learning in Python</h2>&#13;
    <p class="normal">The scikit-learn<a id="_idIndexMarker1446"/> library is an extremely versatile machine learning library that covers many AI topics; for many of them, this should be your starting point. We have already seen the scikit-image library earlier, which is a part of the scikit-learn project, but there are many more options.</p>&#13;
    <p class="normal">The complete list of possibilities is huge, so I will try to give you a very small list based on the scikit-learn modules that I have personally found useful. Many more methods are available, so make sure to read through the scikit-learn documentation if you are interested in anything specific.</p>&#13;
    <p class="normal">This section is split between supervised and unsupervised options, since your dataset is the most important factor in deciding on an algorithm for your use case. </p>&#13;
    <h3 id="_idParaDest-492" class="heading-3">Supervised learning</h3>&#13;
    <p class="normal">Starting with supervised<a id="_idIndexMarker1447"/> learning, scikit-learn offers a host of different options in many different categories.</p>&#13;
    <h4 class="heading-4">Linear models</h4>&#13;
    <p class="normal">First of all, scikit-learn offers dozens of different linear models for performing many types of regressions. It has functions <a id="_idIndexMarker1448"/>for many specific use<a id="_idIndexMarker1449"/> cases, such as:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><strong class="keyWord">Ordinary least squares</strong> regression, as we<a id="_idIndexMarker1450"/> have seen several times in the previous chapter as well.</li>&#13;
      <li class="bulletList"><strong class="keyWord">Ridge regression and classifier</strong>, a function similar to the ordinary least squares <a id="_idIndexMarker1451"/>method but more<a id="_idIndexMarker1452"/> resistant to collinearity.</li>&#13;
      <li class="bulletList">The <strong class="keyWord">LASSO</strong> (<strong class="keyWord">least absolute shrinkage and selection operator</strong>) <strong class="keyWord">model</strong>, which can be seen as the successor<a id="_idIndexMarker1453"/> to the Ridge model for specific use cases. One of the advantages of the lasso model is that, in the case of machine learning, it can help filter out (usually irrelevant) features with very little data.</li>&#13;
      <li class="bulletList"><strong class="keyWord">Polynomial regression</strong>: Methods <a id="_idIndexMarker1454"/>such as the ordinary least squares method perform regression by creating a single straight line. In some cases, however, a straight line will never properly fit your data. In <a id="_idIndexMarker1455"/>these cases, polynomial regression can help a lot since it can generate <a id="_idIndexMarker1456"/>curved lines.</li>&#13;
    </ul>&#13;
    <div class="note">&#13;
      <p class="normal">There are many more methods in this module, so make sure to take a look at the documentation: <a href="https://scikit-learn.org/stable/modules/linear_model.html"><span class="url">https://scikit-learn.org/stable/modules/linear_model.html</span></a>.</p>&#13;
    </div>&#13;
    <h4 class="heading-4">Support-vector machines</h4>&#13;
    <p class="normal">Next up are <a id="_idIndexMarker1457"/>support-vector machines. We already discussed <a id="_idIndexMarker1458"/>SVMs briefly, but in short these can be used for classification, regression, and outlier detection. As opposed to the linear (2D) models above, these methods also function for higher-dimensional data.</p>&#13;
    <p class="normal">Currently, scikit-learn supports these types of SVMs:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><code class="inlineCode">SVC</code>/<code class="inlineCode">SVR</code>: Support-vector <a id="_idIndexMarker1459"/>classification and regression based on the C <code class="inlineCode">libsvm</code> library. For smaller datasets (a few thousand samples), this is the most useful and flexible <a id="_idIndexMarker1460"/>SVM implementation in scikit-learn. This method can also handle support vectors, which can increase the precision of classifiers.</li>&#13;
      <li class="bulletList"><code class="inlineCode">NuSVC</code>/<code class="inlineCode">NuSVR</code>: A <a id="_idIndexMarker1461"/>modified version of SVC/SVR that introduces a parameter <em class="italic">v</em> (the Greek letter Nu) to approximate the fraction of training errors and support <a id="_idIndexMarker1462"/>vectors.</li>&#13;
      <li class="bulletList"><code class="inlineCode">LinearSVC</code>/<code class="inlineCode">LinearSVR</code>: A fast (faster than <code class="inlineCode">SVC</code>/<code class="inlineCode">SVR</code>) linear support vector classification and <a id="_idIndexMarker1463"/>regression system. For large datasets (over 10,000 samples) this<a id="_idIndexMarker1464"/> is the better alternative to <code class="inlineCode">SVC</code>/<code class="inlineCode">SVR</code>, but it does not handle separate support vectors.</li>&#13;
    </ul>&#13;
    <p class="normal">SVMs are very robust prediction methods for higher-dimensional data while still maintaining decent execution speeds.</p>&#13;
    <h4 class="heading-4">Decision trees</h4>&#13;
    <p class="normal"><strong class="keyWord">Decision trees </strong>(<strong class="keyWord">DTs</strong>) also <a id="_idIndexMarker1465"/>deserve special attention. While most of the machine learning <a id="_idIndexMarker1466"/>models are still relatively expensive to use after training, with DTs you build a tree based on the training data to use in your classification or regression. If you are familiar with tree structures, you know that many lookups only take <code class="inlineCode">O(log(n))</code> time to do. In addition to being really fast to calculate, it can also make it much easier to visualize your data, because <code class="inlineCode">scikit-learn</code> can export the evaluated results to Graphviz, a tool for rendering graph structures.</p>&#13;
    <p class="normal">To supercharge the DTs, you can also combine a collection of them into a forest using a <code class="inlineCode">RandomForestClassifier</code> or <code class="inlineCode">RandomForestRegressor</code>, which results in reduced variance. To take this a step further, you can also use the <strong class="keyWord">extremely randomized trees</strong> methods <code class="inlineCode">ExtraTreesClassifier</code> or <code class="inlineCode">ExtraTreesRegressor</code>, which also randomize the specific thresholds between the trees, for further reduced variance over the normal forest methods.</p>&#13;
    <h4 class="heading-4">Feature selection</h4>&#13;
    <p class="normal">Using<a id="_idIndexMarker1467"/> feature selection, you can input a<a id="_idIndexMarker1468"/> large number of input parameters without specifying what they are for, and let the model figure out the most important features.</p>&#13;
    <p class="normal">For example, let’s say that you have collected a large set of weather and geographical data, such as temperature, humidity, air pressure, altitude, and coordinates, and you want to know which of these play a role in answering the question of whether it will snow. The coordinates and air pressure are probably less important factors than temperature is in this case.</p>&#13;
    <p class="normal">The scikit-learn library has several different options available for feature selection:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><code class="inlineCode">sklearn.feature_selection.VarianceThreshold</code>: Excludes items with a small variance by satisfying the <a id="_idIndexMarker1469"/>equation Var[X]=p(1-p)</li>&#13;
      <li class="bulletList"><code class="inlineCode">sklearn.feature_selection.SelectKBest</code>: Selects the k highest scoring features</li>&#13;
      <li class="bulletList"><code class="inlineCode">sklearn.feature_selection.SelectPercentile</code>: Selects the top nth percentile scoring features</li>&#13;
      <li class="bulletList"><code class="inlineCode">sklearn.feature_selection.SelectFromModel</code>: A special and very useful feature selector that<a id="_idIndexMarker1470"/> can use previously generated models (such as an SVM) to filter features</li>&#13;
    </ul>&#13;
    <p class="normal">There are several other feature selection and feature filtering methods available, so make sure to check the documentation to see if there is a better method available for your specific use case.</p>&#13;
    <h4 class="heading-4">Other models</h4>&#13;
    <p class="normal">In addition to these methods, there are many other methods supported by scikit-learn, such as:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><strong class="keyWord">Bayesian networks</strong>: Gaussian, multinomial, complement, Bernoulli, <a id="_idIndexMarker1471"/>categorical, and <a id="_idIndexMarker1472"/>out-of-core.</li>&#13;
      <li class="bulletList"><strong class="keyWord">Linear and quadratic discriminant analysis</strong>: These are<a id="_idIndexMarker1473"/> similar to the linear models <a id="_idIndexMarker1474"/>but also offer <a id="_idIndexMarker1475"/>quadratic <a id="_idIndexMarker1476"/>solutions.</li>&#13;
      <li class="bulletList"><strong class="keyWord">Kernel ridge regression</strong>: A <a id="_idIndexMarker1477"/>combination of ridge <a id="_idIndexMarker1478"/>regression and classification. This can be a faster alternative to SVR.</li>&#13;
      <li class="bulletList"><strong class="keyWord">Stochastic gradient descent</strong>: A very <a id="_idIndexMarker1479"/>fast regression/classifier <a id="_idIndexMarker1480"/>alternative to SVM for specific use cases.</li>&#13;
      <li class="bulletList"><strong class="keyWord">Nearest neighbor</strong>: These <a id="_idIndexMarker1481"/>methods are useful for a <a id="_idIndexMarker1482"/>range of different purposes and are at the core of many of the other functions in this library. At the very least, take a look at this section, because structures such as KD-trees have many applications outside of machine learning as well.</li>&#13;
    </ul>&#13;
    <p class="normal">While there are several other options as well, these are probably the ones that are most useful to you. Note that even though scikit-learn does support neural networks such as multi-layer perceptrons, I would not recommend you use scikit-learn for this purpose. While the implementation works well, it does not have support for GPU (video card) acceleration, which makes a huge performance difference. For neural networks I recommend using TensorFlow, as discussed earlier in this chapter.</p>&#13;
    <h3 id="_idParaDest-493" class="heading-3">Unsupervised learning</h3>&#13;
    <p class="normal">Due to the nature of <a id="_idIndexMarker1483"/>unsupervised learning, it is a lot less versatile than supervised learning, but there are a few scenarios where unsupervised learning absolutely makes sense and is an easy solution. While the unsupervised learning portion of scikit-learn is smaller than the supervised portion, there are still several really useful functions available.</p>&#13;
    <p class="normal">Clustering is the prime example of where unsupervised learning shines. This comes down to giving the algorithm a whole bunch of data and telling it to cluster (split) it into useful sections wherever it can find a pattern. To facilitate this, scikit-learn has a range of different algorithms. The documentation explains this very well: <a href="https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods"><span class="url">https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods</span></a>.</p>&#13;
    <p class="normal">A subsection of this documentation is given below:</p>&#13;
    <table id="table001-2" class="table-container">&#13;
      <tbody>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal"><strong class="keyWord">Method name</strong></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal"><strong class="keyWord">Scalability</strong></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal"><strong class="keyWord">Use case</strong></p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">K-Means</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Very large <code class="inlineCode">n_samples</code>, medium <code class="inlineCode">n_clusters</code> with MiniBatch code</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">General-purpose, even cluster size, flat geometry, not too many clusters, inductive</p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Affinity propagation</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Not scalable with <code class="inlineCode">n_samples</code></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Many clusters, uneven cluster size, non-flat geometry, inductive</p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Mean-shift</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Not scalable with <code class="inlineCode">n_samples</code></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Many clusters, uneven cluster size, non-flat geometry, inductive</p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Spectral clustering</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Medium <code class="inlineCode">n_samples</code>, small <code class="inlineCode">n_clusters</code></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Few clusters, even cluster size, non-flat geometry, transductive</p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Ward hierarchical clustering</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Large <code class="inlineCode">n_samples</code> and <code class="inlineCode">n_clusters</code></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Many clusters, possibly connectivity constraints, transductive</p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Agglomerative clustering</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Large <code class="inlineCode">n_samples</code> and <code class="inlineCode">n_clusters</code></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Many clusters, possibly connectivity constraints, non-Euclidean distances, transductive</p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">DBSCAN</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Very large <code class="inlineCode">n_samples</code>, medium <code class="inlineCode">n_clusters</code></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Non-flat geometry, uneven cluster sizes, transductive</p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">OPTICS</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Very large <code class="inlineCode">n_samples</code>, large <code class="inlineCode">n_clusters</code></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Non-flat geometry, uneven cluster sizes, variable cluster density, transductive</p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Gaussian mixtures</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Not scalable</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Flat geometry, good for density estimation, inductive</p>&#13;
          </td>&#13;
        </tr>&#13;
        <tr>&#13;
          <td class="table-cell">&#13;
            <p class="normal">BIRCH</p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Large <code class="inlineCode">n_clusters</code> and <code class="inlineCode">n_samples</code></p>&#13;
          </td>&#13;
          <td class="table-cell">&#13;
            <p class="normal">Large dataset, outlier removal, data reduction, inductive</p>&#13;
          </td>&#13;
        </tr>&#13;
      </tbody>&#13;
    </table>&#13;
    <p class="normal">All of these methods have their own use cases and the scikit-learn documentation explains this much better than I could. In general, however, the K-Means algorithm, which we have also used in the previous chapter, is a very good starting point.</p>&#13;
    <p class="normal">Note that the clusters can also be used for learning features and the relationship between them. Once you have learned the features, you could use the feature selection in supervised learning to filter them for subselections.</p>&#13;
    <p class="normal">To summarize, for the<a id="_idIndexMarker1484"/> general machine learning cases, scikit-learn is probably your best bet. For special cases, there are often better libraries available; many of these are built on top of scikit-learn, however, so it is recommended that you familiarize yourself with the library if you plan to employ machine learning.</p>&#13;
    <h2 id="_idParaDest-494" class="heading-2">auto-sklearn – Automatic scikit-learn</h2>&#13;
    <p class="normal">The scikit-learn library <a id="_idIndexMarker1485"/>can do so many things that it is often overwhelming to use. At the time of writing, there are 34 distinct regression functions and 25 different classifiers, which can make it quite a challenge to select the right one for you.</p>&#13;
    <p class="normal">This is where <code class="inlineCode">auto-sklearn</code> can help. It can automatically select a classification function for you and fill in the parameters needed for it to work. If you’re just looking for something that just works, this is your best bet.</p>&#13;
    <h2 id="_idParaDest-495" class="heading-2">mlxtend – Machine learning extensions</h2>&#13;
    <p class="normal"><code class="inlineCode">mlxtend</code> is a <a id="_idIndexMarker1486"/>library with a range of relatively easy and well-documented machine learning examples.</p>&#13;
    <p class="normal">It uses <code class="inlineCode">scikit-learn</code>, pandas, and <code class="inlineCode">matplotlib</code> internally to provide a more user-friendly interface for machine learning compared to scikit-learn. If you are starting out with machine learning (or scikit-learn), this can be a nice introduction, since it’s a bit less complicated than using scikit-learn directly.</p>&#13;
    <h2 id="_idParaDest-496" class="heading-2">scikit-lego – scikit-learn utilities</h2>&#13;
    <p class="normal">Even though scikit-learn already <a id="_idIndexMarker1487"/>has a huge catalog of functions and features built in, there are still many things that it does not provide an easy interface for. This is where the scikit-lego library can help, it has many convenient functions for scikit-learn and pandas so you don’t need to repeat yourself too often.</p>&#13;
    <p class="normal">In the previous chapter, we used the Penguins dataset a few times. Loading that dataset and plotting the distribution can be done in just a few lines:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> collections&#13;
&#13;
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt&#13;
<span class="hljs-keyword">from</span> sklego <span class="hljs-keyword">import</span> datasets&#13;
&#13;
X, y = datasets.load_penguins(return_X_y=<span class="hljs-literal">True</span>)&#13;
counter = collections.Counter(y)&#13;
plt.bar(counter.keys(), counter.values())&#13;
plt.show()&#13;
</code></pre>&#13;
    <p class="normal">This results in:</p>&#13;
    <figure class="mediaobject"><img src="Images/B15882_16_09.png" alt="/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/195F70F3.tmp" width="618" height="410"/></figure>&#13;
    <p class="packt_figref">Figure 16.9: Penguin distribution</p>&#13;
    <p class="normal">scikit-lego can <a id="_idIndexMarker1488"/>automatically perform some conversions for us (the <code class="inlineCode">return_X_y</code> parameter here) so we can easily plot the results. There are many more of these functions available, which make it really easy to play around with Scikit-learn.</p>&#13;
    <h2 id="_idParaDest-497" class="heading-2">XGBoost – eXtreme Gradient Boosting</h2>&#13;
    <p class="normal">XGBoost <a id="_idIndexMarker1489"/>is a fast and efficient library for gradient boosting, a regression/classification technique that produces forests of decision trees. The main advantage of this technique compared to many other regression/classification algorithms is the <strong class="keyWord">scalability</strong>. With XGBoost, you can easily spread your workload along clusters of many computers, and it happily scales to billions of data points.</p>&#13;
    <p class="normal">If you have very large datasets, XGBoost <a id="_idIndexMarker1490"/>might be one of your best options.</p>&#13;
    <h2 id="_idParaDest-498" class="heading-2">Featuretools – Feature detection and prediction</h2>&#13;
    <p class="normal">The Featuretools<a id="_idIndexMarker1491"/> library makes it really easy to transform your datasets into aggregated feature matrices based on either time-based datasets or relational ones. Once the feature matrix is constructed, the library can be used for predictions about these features.</p>&#13;
    <p class="normal">You could, for example, predict trip durations based on a collection of multiple trips, or predict when a customer will purchase from you again.</p>&#13;
    <h2 id="_idParaDest-499" class="heading-2">Snorkel – Improving your ML data automatically</h2>&#13;
    <p class="normal">Snorkel <a id="_idIndexMarker1492"/>is a library that attempts to make the training of your ML models much easier. Getting enough training data to properly train your models can be really difficult, and this library has several clever methods to make this easier.</p>&#13;
    <p class="normal">The library has three core operations to help you build your datasets:</p>&#13;
    <ul>&#13;
      <li class="bulletList">First, to help with labeling, the Snorkel library features several heuristic methods. While these labels will not be perfect, manually labeling all data can be a prohibitive task.</li>&#13;
      <li class="bulletList">The second core operation is the transforming and augmenting of datasets. Once again, these use heuristic methods to (hopefully) improve your data quality.</li>&#13;
      <li class="bulletList">The last core operation is the slicing of data so you only get data that is relevant for your use case. This operation is also heuristics-based.</li>&#13;
    </ul>&#13;
    <p class="normal">You will not need this if you already have good-quality data available, but it is certainly worth looking at if your data could use some improvement. As is always the case with machine learning, care must be taken to avoid overfitting or underfitting data. Applying the Snorkel methods can quickly exacerbate problems in your dataset, since it uses the dataset as a source.</p>&#13;
    <h2 id="_idParaDest-500" class="heading-2">TPOT – Optimizing ML models using genetic programming</h2>&#13;
    <p class="normal">TPOT (tea-pot) is a <a id="_idIndexMarker1493"/>library that optimizes your learning pipelines through genetic programming. We already covered evolutionary algorithms earlier, but to remind you, they are algorithms that improve by changing themselves or their parameters through evolution.</p>&#13;
    <p class="normal">While genetic algorithms are relatively easy to implement by themselves, the complexity comes from the encoding of the solution so it is compatible with the genetic algorithm. This is what is very nice about the TPOT library; it makes it really easy to encode your features, cache parts of the pipeline, and even run the attempts in parallel using Dask.</p>&#13;
    <p class="normal">To illustrate, here is the code needed to tell TPOT to automatically optimize a scikit-learn classifier with its parameters:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> tpot&#13;
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split&#13;
&#13;
X_train, X_test, y_train, y_test = train_test_split(&#13;
    some_data, some_target, train_size=<span class="hljs-number">0.75</span>, test_size=<span class="hljs-number">0.25</span>)&#13;
&#13;
tpot = tpot.TPOTClassifier(verbosity=<span class="hljs-number">2</span>, max_time_mins=<span class="hljs-number">10</span>)&#13;
tpot.fit(X_train, y_train)&#13;
tpot.export(<span class="hljs-string">'optimized_classifier.py'</span>)&#13;
</code></pre>&#13;
    <p class="normal">Once it is done trying multiple classifiers, it will write the optimized function calls to <code class="inlineCode">optimized_classifier.py</code>. It is important to note that the classifier returned is also dependent on the optimizer results; it could be <code class="inlineCode">sklearn.neighbors.KNeighborsClassifier</code>, but you could also get <code class="inlineCode">sklearn.ensemble.RandomForestClassifier</code> or something else.</p>&#13;
    <p class="normal">Do not assume that <code class="inlineCode">TPOT</code> is a fast solution for finding your parameters, though; getting a good solution using genetic algorithms can take a long time, and it can be beneficial to reduce your test set before you apply this algorithm.</p>&#13;
    <p class="normal">That was the last library, and it’s time to try things out for yourself in the <em class="chapterRef">Exercises</em> section.</p>&#13;
    <h1 id="_idParaDest-501" class="heading-1">Exercises</h1>&#13;
    <p class="normal">Due to the nature of this chapter, all topics only cover the absolute basics of the mentioned libraries and they really do deserve much more. In this case, as an exercise, I recommend that you try and use some (or all) of the mentioned libraries and see if you can do something useful with them.</p>&#13;
    <p class="normal">Some suggestions:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Browse through TensorFlow Hub and apply some models to your own data. Perhaps you can apply object detection to your holiday photos.</li>&#13;
      <li class="bulletList">After applying a model to your photos, try and improve the model by adding some new objects and finetuning it.</li>&#13;
      <li class="bulletList">Try to extract some data or information from this chapter’s summary by applying one of the NLP algorithms.</li>&#13;
    </ul>&#13;
    <p class="normal">AI is a complicated subject, and even simple example guides are often quite elaborate. Luckily, these days we can often immediately try examples online through Google Colab or by running a Jupyter Notebook. Dive in and don’t get discouraged; there is an incredible amount of high-quality information available online from field experts.</p>&#13;
    <div class="note">&#13;
      <p class="normal">Example answers for these exercises can be found on GitHub: <a href="Chapter_16.xhtml"><span class="url">https://github.com/mastering-python/exercises</span></a>. You are encouraged to submit your own solutions and learn about alternative solutions from others.</p>&#13;
    </div>&#13;
    <h1 id="_idParaDest-502" class="heading-1">Summary</h1>&#13;
    <p class="normal">This chapter gave you a sample of some of the largest and most popular Python AI libraries, but there are many more (large) libraries around that could be useful for your particular use case. There are, for example, also many libraries available for specific topics such as astronomy, geographical information systems (GISes), protein folding, and neurological imaging.</p>&#13;
    <p class="normal">After this chapter, you should have some idea of where to start searching for particular types of AI libraries. Additionally, you should know a little bit about when to apply a particular type of AI. For many use cases, you will need a combination of these methods to solve the problem in an efficient manner. A supervised ML system, for example, is a fantastic option if you have a vast amount of good-quality, labeled data. Often this is not the case, which is where the other algorithms come in.</p>&#13;
    <p class="normal">Surprisingly enough, many of the current “AI” start-up companies don’t actually use AI for their recommendation systems but humans instead, hoping to upgrade to an effective AI somewhere in the future when they have gathered enough training data. Effectively, they are trying to solve the data requirement for supervised ML systems with brute force. Similarly, algorithms are only part of the reason that voice recognition systems such as Alexa, Google Assistant, or Siri have become possible. Another large part is the availability of training data over the last several years. Naturally, these systems are not built on one algorithm specifically but use a combination of multiple algorithms; the system not only tries to convert your voice to words, but also attempts to understand what you are likely to say by constantly cross-validating those results with what would be a logical sentence structure.</p>&#13;
    <p class="normal">The field of AI is improving and changing more rapidly with each year. With the increased processing power we have now, there are many more options than we had in the past. The currently used deep learning AI models were completely infeasible to build only 20 years ago, and in 10 years’ time the models will have far surpassed what is possible now. If there is no solution available for the issue you are facing today, the situation might be completely different a year from now.</p>&#13;
    <p class="normal">It is also perfectly reasonable to skip this part of Python entirely. While AI is becoming a larger and larger portion of what is being done with Python, a big part of that is in academic settings and might not be interesting for your field of work. AI can be a great help, but it is often a much more complicated solution than is actually needed.</p>&#13;
    <p class="normal">In the next chapter, we will learn about creating extensions in C/C++ to increase performance and allow low-level access to memory and other hardware resources. While this can greatly help with performance, performance rarely comes free, as we will see. </p>&#13;
    <h1 class="heading-1">Join our community on Discord</h1>&#13;
    <p class="normal">Join our community’s Discord space for discussions with the author and other readers: <a href="https://discord.gg/QMzJenHuJf"><span class="url">https://discord.gg/QMzJenHuJf</span></a></p>&#13;
    <p class="normal"><img src="Images/QR_Code156081100001293319171.png" alt="" width="177" height="177"/></p>&#13;
  </div>&#13;
</div></body></html>