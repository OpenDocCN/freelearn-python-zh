<html><head></head><body>
		<div id="_idContainer053">
			<h1 id="_idParaDest-169"><em class="italic"><a id="_idTextAnchor207"/>Chapter 7</em>: Multiprocessing, Multithreading, and Asynchronous Programming</h1>
			<p>We can write efficient and optimized code for faster execution time, but there is always a limit to the amount of resources available for the processes running our programs. However, we can still improve application execution time by executing certain tasks in parallel on the same machine or across different machines. This chapter will cover parallel processing or concurrency in Python for the applications running on a single machine. We will cover parallel processing using multiple machines in the next chapter. In this chapter, we focus on the built-in support available in Python for the implementation of parallel processing. We will start with the multithreading in Python followed by discussing the multiprocessing. After that, we will discuss how we can design responsive systems using asynchronous programming. For each of the approaches, we will design and discuss a case study of implementing a concurrent application to download files from a Google Drive directory.</p>
			<p>We will cover the following topics in this chapter:</p>
			<ul>
				<li>Understanding multithreading in Python and its limitations</li>
				<li>Going beyond a single CPU – implementing multiprocessing</li>
				<li>Using asynchronous programming for responsive systems</li>
			</ul>
			<p>After completing this chapter, you will be aware of the different options for building multithreaded or multiprocessing applications using built-in Python libraries. These skills will help you to build not only more efficient applications but also build applications for large-scale users.</p>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor208"/>Technical requirements</h1>
			<p>The following are the technical requirements for this chapter:</p>
			<ul>
				<li>Python 3 (3.7 or later)</li>
				<li>A Google Drive account</li>
				<li>API key enabled for your Google Drive account</li>
			</ul>
			<p>Sample code for this chapter can be found at <a href="https://github.com/PacktPublishing/Python-for-Geeks/tree/master/Chapter07">https://github.com/PacktPublishing/Python-for-Geeks/tree/master/Chapter07</a>.</p>
			<p>We will start our discussion with multithreading concepts in Python.</p>
			<h1 id="_idParaDest-171"><a id="_idTextAnchor209"/>Understanding multithreading in Python and its limitations</h1>
			<p>A thread is a basic unit of <a id="_idIndexMarker736"/>execution within an operating system process, and it consists of its own program counter, a stack, and a set of registers. An application process can be built using multiple threads that can run simultaneously and share the same memory.</p>
			<p>For multithreading in a program, all the threads of a process share common code and other resources, such as data and system files. For each thread, all its related information is stored as a data structure inside the operating system kernel, and this data structure<a id="_idIndexMarker737"/> is called the <strong class="bold">Thread Control Block</strong> (<strong class="bold">TCB</strong>). The TCB has the following main components:</p>
			<ul>
				<li><strong class="bold">Program Counter (PC)</strong>: This is used to <a id="_idIndexMarker738"/>track the execution flow of the program.</li>
				<li><strong class="bold">System Registers (REG)</strong>: These<a id="_idIndexMarker739"/> registers are used to hold variable data.</li>
				<li><strong class="bold">Stack</strong>: The stack is an <a id="_idIndexMarker740"/>array of registers that manages the execution history.</li>
			</ul>
			<p>The anatomy of a thread is exhibited in <em class="italic">Figure 7.1</em>, with three threads. Each thread has its own PC, a stack, and REG, but shares code and other resources with other threads:</p>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="image/B17189_07_01.jpg" alt="Figure 7.1 – Multiple threads in a process&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1 – Multiple threads in a process</p>
			<p>The TCB also contains a thread identifier, the state of the thread (such as running, waiting, or stopped), and a pointer to the process it belongs to. Multithreading is an operating system concept. It is a feature offered through the system kernel. The operating system facilitates the execution of multiple threads concurrently in the same process context, allowing them to share the process memory. This means the operating system has full control of which thread will be activated, rather than the application. We need to underline this point for a later discussion comparing different concurrency options.</p>
			<p>When threads are run on <a id="_idIndexMarker741"/>a single-CPU machine, the operating system actually switches the CPU from one thread to the other such that the threads appear to be running concurrently. Is there any advantage to running multiple threads on a single-CPU machine? The answer is yes and no, and it depends on the nature of the application. For applications running using only the local memory, there may not be any advantage; in fact, it is likely to exhibit lower performance due to the overhead of switching threads on a single CPU. But for applications that depend on other resources, the execution can be faster because of the better utilization of the CPU: when one thread is waiting for another resource, another thread can utilize the CPU.</p>
			<p>When executing multiple threads on multiprocessors or multiple CPU cores, it is possible to execute them concurrently. Next, we will discuss the limitations of multithreaded programming in Python.</p>
			<h2 id="_idParaDest-172"><a id="_idTextAnchor210"/>What is a Python blind spot?</h2>
			<p>From a programming <a id="_idIndexMarker742"/>perspective, multithreading is an approach to running different parts of an application concurrently. Python uses multiple kernel threads that can run the Python user threads. But the Python implementation (<em class="italic">CPython</em>) allows threads to access the Python objects through one global lock, which is called the <strong class="bold">Global Interpreter Lock (GIL)</strong>. In simple words, the GIL is a mutex that allows only one thread to use the Python<a id="_idIndexMarker743"/> interpreter at a time and blocks all other threads. This is necessary to protect the reference count that is managed for each object in Python from garbage collection. Without such protection, the reference count can get corrupted if it's updated by multiple threads at the same time. The reason for this limitation is to protect the internal interpreter data structures and third-party <em class="italic">C</em> code that is not thread safe.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">This GIL limitation does not exist in Jython and IronPython, which are other implementations of Python.</p>
			<p>This Python limitation may give us the impression that there is no advantage to writing multithreaded programs in Python. This is not true. We still can write code in Python that runs concurrently or in parallel, and we will see it in our case study. Multithreading can be beneficial in the following cases:</p>
			<ul>
				<li><strong class="bold">I/O bound tasks</strong>: When <a id="_idIndexMarker744"/>working with multiple I/O operations, there is always room to improve performance by running tasks using more than one thread. When one thread is waiting for a response from an I/O resource, it will release the GIL and let the other threads work. The original thread will wake up as soon as the response arrives from the I/O resource.</li>
				<li><strong class="bold">Responsive GUI application</strong>: For <a id="_idIndexMarker745"/>interactive GUI applications, it is necessary to have a design pattern to display the progress of tasks running in the background (for example, downloading a file) and also to allow a user to work on other GUI features while one or more tasks are running in the background. This is all possible by using separate threads for the actions initiated by a user through the GUI.</li>
				<li><strong class="bold">Multiuser applications</strong>: Threads are also a prerequisite for building multiuser applications. A web server and a<a id="_idIndexMarker746"/> file server are examples of such applications. As soon as a new request arrives in the main thread of such an application, a new thread is created to serve the request while the main thread at the back listens for a new request.</li>
			</ul>
			<p>Before discussing a case study of a multithreaded application, it is important to introduce the key components of multithreaded programming in Python.</p>
			<h2 id="_idParaDest-173"><a id="_idTextAnchor211"/>Learning the key components of multithreaded programming in Python</h2>
			<p>Multithreading in<a id="_idIndexMarker747"/> Python allows us to run different components of a program concurrently. To create multiple threads of an application, we will use the Python <strong class="source-inline">threading</strong> module, and the main components of this module are described next.   </p>
			<p>We will start by discussing the <strong class="source-inline">threading</strong> module in Python first.</p>
			<h3>The threading module</h3>
			<p>The <strong class="source-inline">threading</strong> module comes as a <a id="_idIndexMarker748"/>standard module and provides simple and easy-to-use methods for building multiple threads of a program. Under the hood, this module uses the lower level <strong class="source-inline">_thread</strong> module, which was a popular choice of multithreading in the early version of Python.</p>
			<p>To create a new thread, we will create an object of the <strong class="source-inline">Thread</strong> class that can take a function (to be executed) name as the <strong class="source-inline">target</strong> attribute and arguments to be passed to the function as the <strong class="source-inline">args</strong> attribute. A thread can be given a name that can be set at the time it is created using the <strong class="source-inline">name</strong> argument with the constructor.</p>
			<p>After creating an object of the <strong class="source-inline">Thread</strong> class, we need to start the thread by using the <strong class="source-inline">start</strong> method. To make the main program or thread wait until the newly created thread object(s) finishes, we<a id="_idIndexMarker749"/> need to use the <strong class="source-inline">join</strong> method. The <strong class="source-inline">join</strong> method makes sure that the main thread (a calling thread) waits until the thread on which the <strong class="source-inline">join</strong> method is called completes its execution.</p>
			<p>To explain the process of creating, starting, and waiting to finish the execution of a thread, we will create a simple program with three threads. A complete code example of such a program is shown next:</p>
			<p class="source-code"># <strong class="bold">thread1</strong>.py to create simple threads with function</p>
			<p class="source-code">from threading import current_thread, Thread as Thread</p>
			<p class="source-code">from time import sleep</p>
			<p class="source-code">def <strong class="bold">print_hello</strong>():</p>
			<p class="source-code">    sleep(2)</p>
			<p class="source-code">    print("{}: Hello".format(current_thread().name))</p>
			<p class="source-code">def <strong class="bold">print_message</strong>(msg):</p>
			<p class="source-code">    sleep(1)</p>
			<p class="source-code">    print("{}: {}".format(current_thread().name, msg))</p>
			<p class="source-code"># create threads</p>
			<p class="source-code">t1 = <strong class="bold">Thread(target=print_hello, name="Th 1")</strong></p>
			<p class="source-code">t2 = Thread(target=print_hello, name="Th 2")</p>
			<p class="source-code">t3 = <strong class="bold">Thread(target=print_message, args=["Good morning"], </strong></p>
			<p class="source-code"><strong class="bold">        name="Th 3")</strong></p>
			<p class="source-code"># start the threads</p>
			<p class="source-code"><strong class="bold">t1.start</strong>()</p>
			<p class="source-code">t2.start()</p>
			<p class="source-code">t3.start()</p>
			<p class="source-code"># wait till all are done</p>
			<p class="source-code"><strong class="bold">t1.join</strong>()</p>
			<p class="source-code">t2.join()</p>
			<p class="source-code">t3.join()</p>
			<p>In this program, we implemented the following:</p>
			<ul>
				<li>We created two simple functions, <strong class="source-inline">print_hello</strong> and <strong class="source-inline">print_message</strong>, that are to be used by the<a id="_idIndexMarker750"/> threads. We used the <strong class="source-inline">sleep</strong> function from the <strong class="source-inline">time</strong> module in both functions to make sure that the two functions finish their execution time at different times.</li>
				<li>We created three <strong class="source-inline">Thread</strong> objects. Two of the three objects will execute one function (<strong class="source-inline">print_hello</strong>) to illustrate the code sharing by the threads, and the third thread object will use the second function (<strong class="source-inline">print_message</strong>), which takes one argument as well.</li>
				<li>We started all three threads one by one using the <strong class="source-inline">start</strong> method.</li>
				<li>We waited for each thread to finish by using the <strong class="source-inline">join</strong> method.</li>
			</ul>
			<p>The <strong class="source-inline">Thread</strong> objects can be stored in a list to simplify the <strong class="source-inline">start</strong> and <strong class="source-inline">join</strong> operations using a <strong class="source-inline">for</strong> loop. The console output of this program will look like this:</p>
			<p class="source-code">Th 3: Good morning</p>
			<p class="source-code">Th 2: Hello</p>
			<p class="source-code">Th 1: Hello</p>
			<p>Thread 1 and thread 2 have more sleep time than thread 3, so thread 3 will always finish first. Thread 1 and thread 2 can finish in any order depending on who gets hold of the processor first.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">By default, the <strong class="source-inline">join</strong> method blocks the caller thread indefinitely. But we can use a timeout (in seconds) as an argument to the <strong class="source-inline">join</strong> method. This will make the caller thread block only for the timeout period.</p>
			<p>We will review a<a id="_idIndexMarker751"/> few more concepts before discussing a more complex case study.</p>
			<h3>Daemon threads</h3>
			<p>In a normal application, our<a id="_idIndexMarker752"/> main program implicitly waits until all other threads finish their execution. However, sometimes we need to run some threads in the background so that they run without blocking the main program from terminating itself. These threads are known as <strong class="bold">daemon threads</strong>. These<a id="_idIndexMarker753"/> threads stay active as long as the main program (with non-daemon threads) is running, and it is fine to terminate the daemon threads once the non-daemon threads exit. The use of daemon threads is popular in situations where it is not an issue if a thread dies in the middle of its execution without losing or corrupting any data.</p>
			<p>A thread can be declared a daemon thread by using one of the following two approaches:</p>
			<ul>
				<li>Pass the <strong class="source-inline">daemon</strong> attribute set to <strong class="source-inline">True</strong> with the constructor (<strong class="source-inline">daemon = True</strong>).</li>
				<li>Set the <strong class="source-inline">daemon</strong> attribute to <strong class="source-inline">True</strong> on the thread instance (<strong class="source-inline">thread.daemon = True</strong>).</li>
			</ul>
			<p>If a thread is set as a daemon thread, we start the thread and forget about it. The thread will be automatically killed when the program that called it quits.</p>
			<p>The next code shows the use of both <a id="_idIndexMarker754"/>daemon and non-daemon threads:</p>
			<p class="source-code">#<strong class="bold">thread2</strong>.py to create daemon and non-daemon threads</p>
			<p class="source-code">from threading import current_thread, Thread as Thread</p>
			<p class="source-code">from time import sleep</p>
			<p class="source-code">def <strong class="bold">daeom_func</strong>():</p>
			<p class="source-code">    #print(threading.current_thread().isDaemon())</p>
			<p class="source-code">    sleep(3)</p>
			<p class="source-code">    print("{}: Hello from daemon".format           (current_thread().name))</p>
			<p class="source-code">def <strong class="bold">nondaeom_func</strong>():</p>
			<p class="source-code">    #print(threading.current_thread().isDaemon())</p>
			<p class="source-code">    sleep(1)</p>
			<p class="source-code">    print("{}: Hello from non-daemon".format(        current_thread().name))</p>
			<p class="source-code">#creating threads</p>
			<p class="source-code">t1 = Thread(target=daeom_func, name="Daemon Thread",     <strong class="bold">daemon=True</strong>)</p>
			<p class="source-code">t2 = Thread(target=nondaeom_func, name="Non-Daemon Thread")</p>
			<p class="source-code"># start the threads</p>
			<p class="source-code">t1.start()</p>
			<p class="source-code">t2.start()</p>
			<p class="source-code">print("Exiting the main program")</p>
			<p>In this code example, we created one daemon and one non-daemon thread. The daemon thread (<strong class="source-inline">daeom_func</strong>) is executing a function that has a sleep time of <strong class="source-inline">3</strong> seconds, whereas the non-daemon thread is executing a function (<strong class="source-inline">nondaeom_func</strong>) that has a sleep time of 1 second. The sleep<a id="_idIndexMarker755"/> time of the two functions is set to make sure the non-daemon thread finishes its execution first. The console output of this program is as follows:</p>
			<p class="source-code">Exiting the main program</p>
			<p class="source-code">Non-Daemon Thread: Hello from non-daemon </p>
			<p>Since we did not use a <strong class="source-inline">join</strong> method in any thread, the main thread exits first, and then the non-daemon thread finishes a bit later with a print message. But there is no print message from the daemon thread. This is because the daemon thread is terminated as soon as the non-daemon thread finishes its execution. If we change the sleep time in the <strong class="source-inline">nondaeom_func</strong> function to <strong class="source-inline">5</strong>, the console output will be as follows:</p>
			<p class="source-code">Exiting the main program</p>
			<p class="source-code">Daemon Thread: Hello from daemon</p>
			<p class="source-code">Non-Daemon Thread: Hello from non-daemon</p>
			<p>By delaying the execution of the non-daemon thread, we make sure the daemon thread finished its execution and does not get terminated abruptly.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">If we use a <strong class="source-inline">join</strong> on the daemon thread, the main thread will be forced to wait for the daemon thread to finish its execution.</p>
			<p>Next, we will investigate how to synchronize the threads in Python.</p>
			<h3>Synchronizing threads</h3>
			<p><strong class="bold">Thread synchronization</strong> is a mechanism to ensure that the two or more threads do not execute a shared block<a id="_idIndexMarker756"/> of code at the same time. The block of code that is typically accessing shared data or shared<a id="_idIndexMarker757"/> resources is also known as the <strong class="bold">critical section</strong>. This concept can be made clearer through the following figure:</p>
			<p class="figure-caption">   </p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/B17189_07_02.jpg" alt="Figure 7.2 – Two threads accessing a critical section of a program&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.2 – Two threads accessing a critical section of a program</p>
			<p>Multiple threads accessing the critical section at the same time may try to access or change the data at the same <a id="_idIndexMarker758"/>time, which may result in unpredictable results on the data. This situation is called a <strong class="bold">race condition</strong>.</p>
			<p>To illustrate the concept of the race condition, we will implement a simple program with two threads, and each thread increments a shared variable 1 million times. We chose a high number for the increment to make sure that we can observe the outcome of the race condition. The race condition may also be observed by using a lower value for the increment cycle on a slower CPU. In this program, we will create two threads that are using the same function (<strong class="source-inline">inc</strong> in this case) as the target. The code for accessing the shared variable and incrementing it by 1 occurs in the critical section, and the two threads are accessing it without any protection. The complete code example is as follows:</p>
			<p class="source-code"># <strong class="bold">thread3a</strong>.py when no thread synchronization used</p>
			<p class="source-code">from threading import Thread as Thread</p>
			<p class="source-code">def inc():</p>
			<p class="source-code">    global x</p>
			<p class="source-code">    for _ in range(<strong class="bold">1000000</strong>):</p>
			<p class="source-code">        <strong class="bold">x+=1</strong></p>
			<p class="source-code">#global variabale</p>
			<p class="source-code">x = 0</p>
			<p class="source-code"># creating threads</p>
			<p class="source-code">t1 = Thread(target=inc, name="Th 1")</p>
			<p class="source-code">t2 = Thread(target=inc, name="Th 2")</p>
			<p class="source-code"># start the threads</p>
			<p class="source-code">t1.start()</p>
			<p class="source-code">t2.start()</p>
			<p class="source-code">#wait for the threads</p>
			<p class="source-code">t1.join()</p>
			<p class="source-code">t2.join()</p>
			<p class="source-code">print("final value of x :", x)</p>
			<p>The expected value of <strong class="source-inline">x</strong> at the end <a id="_idIndexMarker759"/>of the execution is <em class="italic">2,000,000</em>, which will not be observed in the console output. Every time we execute this program, we will get a different value of <strong class="source-inline">x</strong> that's a lot lower than 2,000,000. This is because of the race condition between the two threads. Let's look at a scenario where threads <strong class="source-inline">Th 1</strong> and <strong class="source-inline">Th 2</strong> are running the critical section (<strong class="source-inline">x+=1</strong>) at the same time. Both threads will ask for the current value of <strong class="source-inline">x</strong>. If we assume the current value of <strong class="source-inline">x</strong> is <strong class="source-inline">100</strong>, both threads will read it as <strong class="source-inline">100</strong> and increment it to a new value of <strong class="source-inline">101</strong>. The two threads will write back to the memory the new value of <strong class="source-inline">101</strong>. This is a one-time increment and, in reality, the two threads should increment the variable independently of each other and the final value of <strong class="source-inline">x</strong> should be <strong class="source-inline">102</strong>. How can we achieve this? This is where thread synchronization comes to the rescue.</p>
			<p>Thread synchronization can be achieved by using a <strong class="source-inline">Lock</strong> class from the <strong class="source-inline">threading</strong> module. The lock is<a id="_idIndexMarker760"/> implemented using a <strong class="bold">semaphore</strong> object provided by the operating system. A semaphore is a synchronization object at the operating system level to control access to the resources<a id="_idIndexMarker761"/> and data for multiple processors and threads. The <strong class="source-inline">Lock</strong> class provides two methods, <strong class="source-inline">acquire</strong> and <strong class="source-inline">release</strong>, which are described next:</p>
			<ul>
				<li>The <strong class="source-inline">acquire</strong> method is used to<a id="_idIndexMarker762"/> acquire a lock. A lock can be <strong class="bold">blocking</strong> (default) or <strong class="bold">non-blocking</strong>. In the case of a blocking lock, the requesting thread's execution is blocked <a id="_idIndexMarker763"/>until the lock is released by the current acquiring thread. Once the lock is released by the current acquiring thread (<strong class="source-inline">unlocked</strong>), then the lock is provided to the requesting thread to proceed. In the case of a non-blocking acquire request, the thread execution is not blocked. If the lock is available (<strong class="source-inline">unlocked</strong>), then the lock is provided (and <strong class="source-inline">locked</strong>) to the requesting thread to proceed, otherwise the requesting thread gets <strong class="source-inline">False</strong> as a response.</li>
				<li>The <strong class="source-inline">release</strong> method is used to release a lock, which means it resets the lock to an <strong class="source-inline">unlocked</strong> state. If there is any thread blocking and waiting for the lock, it will allow one of the threads to proceed.</li>
			</ul>
			<p>The <strong class="source-inline">thread3a.py</strong> code example is revised with the use of a lock around the increment statement on the shared variable <strong class="source-inline">x</strong>. In this revised example, we created a lock at the main thread level and then passed it to the <strong class="source-inline">inc</strong> function to acquire and release a lock around the shared variable. The complete revised code example is as follows:</p>
			<p class="source-code"># <strong class="bold">thread3b</strong>.py when thread synchronization is used</p>
			<p class="source-code">from threading import Lock, Thread as Thread</p>
			<p class="source-code">def inc_with_lock (lock):</p>
			<p class="source-code">    global x</p>
			<p class="source-code">    for _ in range(1000000):</p>
			<p class="source-code">        <strong class="bold">lock.acquire()</strong></p>
			<p class="source-code">        x+=1</p>
			<p class="source-code">        <strong class="bold">lock.release()</strong></p>
			<p class="source-code">x = 0</p>
			<p class="source-code"><strong class="bold">mylock = Lock()</strong></p>
			<p class="source-code"># creating threads</p>
			<p class="source-code">t1 = Thread(target= inc_with_lock, args=(<strong class="bold">mylock</strong>,), name="Th     1")</p>
			<p class="source-code">t2 = Thread(target= inc_with_lock, args=(<strong class="bold">mylock</strong>,), name="Th     2")</p>
			<p class="source-code"># start the threads</p>
			<p class="source-code">t1.start()</p>
			<p class="source-code">t2.start()</p>
			<p class="source-code">#wait for the threads</p>
			<p class="source-code">t1.join()</p>
			<p class="source-code">t2.join()</p>
			<p class="source-code">print("final value of x :", x)</p>
			<p>After using the <strong class="source-inline">Lock</strong> object, the value of <strong class="source-inline">x</strong> is always <strong class="source-inline">2000000</strong>. The <strong class="source-inline">Lock</strong> object made sure that only one<a id="_idIndexMarker764"/> thread increments the shared variable at a time. The advantage of thread synchronization is that you can use system resources with enhanced performance and predictable results.</p>
			<p>However, locks have to be used carefully because improper use of locks can result in a deadlock situation. Suppose a thread acquires a lock on resource A and is waiting to acquire a lock on resource B. But another thread already holds a lock on resource B and is looking to acquire a lock resource A. The two threads will wait for each other to release the locks, but it will never happen. To avoid deadlock situations, the multithreading and multiprocessing libraries come with mechanisms such as adding a timeout for a resource to hold a lock, or using a context manager to acquire locks. </p>
			<h3>Using a synchronized queue</h3>
			<p>The <strong class="source-inline">Queue</strong> module in <a id="_idIndexMarker765"/>Python implements multi-producer and multi-consumer queues. Queues are very useful in multithread applications when the information has to be exchanged between different threads safely. The beauty of the synchronized queue is that they come with all the required locking mechanisms, and there is no need to use additional locking semantics.</p>
			<p>There are three types of queues in the <strong class="source-inline">Queue</strong> module:</p>
			<ul>
				<li><strong class="bold">FIFO</strong>: In the FIFO queue, the task <a id="_idIndexMarker766"/>added first is retrieved first.</li>
				<li><strong class="bold">LIFO</strong>: In the LIFO queue, the<a id="_idIndexMarker767"/> last task added is retrieved first.</li>
				<li><strong class="bold">Priority queue</strong>: In this queue, the entries are <a id="_idIndexMarker768"/>sorted and the entry with the lowest value is retrieved first.</li>
			</ul>
			<p>These queues use locks to protect access to the queue entries from competing threads. The use of a queue with a multithreaded program is best illustrated with a code example. In the next example, we will create a FIFO queue with dummy tasks in it. To process the tasks from the queue, we will implement a custom thread class by inheriting the <strong class="source-inline">Thread</strong> class. This is another way of implementing a thread.</p>
			<p>To implement a custom thread class, we need to override the <strong class="source-inline">init</strong> and <strong class="source-inline">run</strong> methods. In the <strong class="source-inline">init</strong> method, it is required to call the <strong class="source-inline">init</strong> method of the superclass (the <strong class="source-inline">Thread</strong> class). The <strong class="source-inline">run</strong> method is the execution part of the thread class. The complete code example is as follows:</p>
			<p class="source-code"># <strong class="bold">thread5</strong>.py with queue and custom Thread class</p>
			<p class="source-code">from queue import Queue</p>
			<p class="source-code">from threading import Thread as Thread</p>
			<p class="source-code">from time import sleep</p>
			<p class="source-code">class <strong class="bold">MyWorker (Thread)</strong>:</p>
			<p class="source-code">   def __init__(self, name, q):</p>
			<p class="source-code">      <strong class="bold">threading.Thread.__init__(self)</strong></p>
			<p class="source-code">      self.name = name</p>
			<p class="source-code">      self.queue = q</p>
			<p class="source-code">   def <strong class="bold">run</strong>(self):</p>
			<p class="source-code">      while True:</p>
			<p class="source-code">          item = self.queue.get()</p>
			<p class="source-code">          sleep(1)</p>
			<p class="source-code">          try:</p>
			<p class="source-code">              print ("{}: {}".format(self.name, item))</p>
			<p class="source-code">          finally:</p>
			<p class="source-code">            self.queue.task_done()</p>
			<p class="source-code">#filling the queue</p>
			<p class="source-code"><strong class="bold">myqueue = Queue()</strong></p>
			<p class="source-code">for i in range (10):</p>
			<p class="source-code">    <strong class="bold">myqueue.put</strong>("Task {}".format(i+1))</p>
			<p class="source-code"># creating threads</p>
			<p class="source-code">for i in range (5):</p>
			<p class="source-code">    worker = MyWorker("Th {}".format(i+1), myqueue)</p>
			<p class="source-code">    worker.daemon = True</p>
			<p class="source-code">    worker.start()</p>
			<p class="source-code">myqueue.join()</p>
			<p>In this code example, we <a id="_idIndexMarker769"/>created five worker threads using the custom thread class (<strong class="source-inline">MyThread</strong>). These five worker threads access the queue to get the task item from it. After getting the task item, the threads sleep for 1 second and then print the thread name and the task name. For each <strong class="source-inline">get</strong> call for an item of a queue, a subsequent call of <strong class="source-inline">task_done()</strong> indicates that the processing of the task has been completed.</p>
			<p>It is important to note that we used the <strong class="source-inline">join</strong> method on the <strong class="source-inline">myqueue</strong> object and not on the threads. The <strong class="source-inline">join</strong> method on the queue blocks the main thread until all items in the queue have been processed and completed (<strong class="source-inline">task_done</strong> is called for them). This is a recommended way to block the main thread when a queue object is used to hold the tasks' data for threads.</p>
			<p>Next, we will implement an application to download files from Google Drive using the <strong class="source-inline">Thread</strong> class, the <strong class="source-inline">Queue</strong> class, and a couple of third-party libraries.</p>
			<h2 id="_idParaDest-174"><a id="_idTextAnchor212"/>Case study – a multithreaded application to download files from Google Drive</h2>
			<p>We have discussed in the previous<a id="_idIndexMarker770"/> section that multithreaded applications in Python stand out well when different threads are working on input and output tasks. That is why we selected to implement an application that downloads files from a shared directory of Google Drive. To implement this application, we will need the following:</p>
			<ul>
				<li><strong class="bold">Google Drive</strong>: A Google Drive account (a free basic account is fine) with one directory marked as shared.</li>
				<li><strong class="bold">API key</strong>: An API key to access Google APIs is required. The API key needs to be enabled to use the Google APIs for Google Drive. The API can be enabled by following the guidelines on the Google Developers site (<a href="https://developers.google.com/drive/api/v3/enable-drive-api">https://developers.google.com/drive/api/v3/enable-drive-api</a>).</li>
				<li><strong class="bold">getfilelistpy</strong>: This is a third-party library that gets a list of files from a Google Drive shared directory. This library can be installed using the <strong class="source-inline">pip</strong> tool.</li>
				<li><strong class="bold">gdown</strong>: This is a third-party library that downloads a file from Google Drive. This library can also be installed through the <strong class="source-inline">pip</strong> tool as well. There are other libraries available that offer the same functionality. We selected the <strong class="source-inline">gdown</strong> library for its ease of use.</li>
			</ul>
			<p>To use the <strong class="source-inline">getfilelistpy</strong> module, we need to create a resource data structure. This data structure will include a folder identifier as <strong class="source-inline">id</strong> (this will be Google Drive folder ID in our case), the API security key (<strong class="source-inline">api_key</strong>) for accessing the Google Drive folder, and a list of file attributes (<strong class="source-inline">fields</strong>) to be fetched when we get a list of files. We build the resource data structure as follows:</p>
			<p class="source-code">resource = {</p>
			<p class="source-code">    "api_key": "AIzaSyDYKmm85kebxddKrGns4z0",</p>
			<p class="source-code">    "id": "0B8TxHW2Ci6dbckVwTRtTl3RUU",</p>
			<p class="source-code">    "fields": "files(name, id, webContentLink)",</p>
			<p class="source-code">}</p>
			<p class="source-code">'''API key and id used in the examples are not original, so should be replaced as per your account and shared directory id''' </p>
			<p>We limit the file attributes to the <strong class="source-inline">file id</strong>, <strong class="source-inline">name</strong>, and its <strong class="source-inline">web link</strong> (URL) only. Next, we need to add each file item into a queue as a task for threads. The queue will be used by multiple worker threads to download the files in parallel.</p>
			<p>To make the application more flexible in terms of the number of workers we can use, we build a pool of worker threads. The size of the pool is controlled by a global variable that is set at the beginning of the program. We created worker threads as per the size of the thread pool. Each worker thread in the pool has access to the queue, which has a list of files. Like the previous code<a id="_idIndexMarker771"/> example, each worker thread will take one file item from the queue at a time, download the file, and mark the file item as complete using the <strong class="source-inline">task_done</strong> method. An example code for defining a resource data structure and for defining a class for the worker thread is as follows:</p>
			<p class="source-code">#threads_casestudy.py</p>
			<p class="source-code">from queue import Queue</p>
			<p class="source-code">from threading import Thread</p>
			<p class="source-code">import time</p>
			<p class="source-code">from getfilelistpy import getfilelist</p>
			<p class="source-code">import gdown</p>
			<p class="source-code">THREAD_POOL_SIZE = 1</p>
			<p class="source-code">resource = {</p>
			<p class="source-code">    "api_key": "AIzaSyDYKmm85kea2bxddKrGns4z0",</p>
			<p class="source-code">    "id": "0B8TxHW2Ci6dbckVweTRtTl3RUU ",</p>
			<p class="source-code">    "fields": "files(name,id,webContentLink)",</p>
			<p class="source-code">}</p>
			<p class="source-code">class DownlaodWorker(Thread):</p>
			<p class="source-code">    def __init__(self, name, queue):</p>
			<p class="source-code">        Thread.__init__(self)</p>
			<p class="source-code">        self.name = name</p>
			<p class="source-code">        self.queue = queue</p>
			<p class="source-code">    def run(self):</p>
			<p class="source-code">        while True:</p>
			<p class="source-code">            # Get the file id and name from the queue</p>
			<p class="source-code">            item1 = self.queue.get()</p>
			<p class="source-code">            try:</p>
			<p class="source-code">                <strong class="bold">gdown.download</strong>( item1['webContentLink'], </p>
			<p class="source-code">                    './files/{}'.format(item1['name']), </p>
			<p class="source-code">                    quiet=False)</p>
			<p class="source-code">            finally:</p>
			<p class="source-code">                self.queue.task_done()</p>
			<p>We get the files' metadata from a Google Drive directory using the resource data structure as follows:</p>
			<p class="source-code">def get_files(resource):</p>
			<p class="source-code">        #global files_list</p>
			<p class="source-code">        res = getfilelist.GetFileList(resource)</p>
			<p class="source-code">        files_list = res['fileList'][0]</p>
			<p class="source-code">        return files_list</p>
			<p>In the <strong class="source-inline">main</strong> function, we create a <strong class="source-inline">Queue</strong> object to insert file metadata into the queue. The <strong class="source-inline">Queue</strong> object is handed <a id="_idIndexMarker772"/>over to a pool of worker threads for downloading the files. The worker threads will download the files, as discussed earlier. We use the <strong class="source-inline">time</strong> class to measure the time it takes to complete the download of all the files from the Google Drive directory. The code for the <strong class="source-inline">main</strong> function is as follows:</p>
			<p class="source-code">def main():</p>
			<p class="source-code">    start_time = time.monotonic()</p>
			<p class="source-code">    files = <strong class="bold">get_files(resource)</strong></p>
			<p class="source-code">    #add files info into the queue</p>
			<p class="source-code">    queue = Queue()</p>
			<p class="source-code">    for item in files['files']:</p>
			<p class="source-code">        queue.put(item)</p>
			<p class="source-code">    for i in range (THREAD_POOL_SIZE):</p>
			<p class="source-code">        worker = DownlaodWorker("Thread {}".format(i+1), </p>
			<p class="source-code">                queue)</p>
			<p class="source-code">        worker.daemon = True</p>
			<p class="source-code">        worker.start()</p>
			<p class="source-code">    queue.join()</p>
			<p class="source-code">    end_time = time.monotonic()</p>
			<p class="source-code">    print('Time taken to download: {} seconds'.</p>
			<p class="source-code">          format( end_time - start_time))</p>
			<p class="source-code">main()</p>
			<p>For this application, we have 10 files in the Google Drive directory, varying in size from 500 KB to 3 MB. We ran the application with 1, 5, and 10 worker threads. The total time taken to download the 10 files with 1 thread was approximately 20 seconds. This is almost equivalent to <a id="_idIndexMarker773"/>writing a code without any threads. In fact, we have written a code to download the same files without any threads and made it available with this book's source code as an example. The time it took to download 10 files with a non-threaded application was approximately 19 seconds.</p>
			<p>When we changed the number of worker threads to 5, the time taken to download the 10 files reduced significantly to approximately 6 seconds on our MacBook machine (Intel Core i5 with 16 GB RAM). If you run the same program on your computer, the time may be different, but there will definitely be an improvement if we increase the number of worker threads. With 10 threads, we observed the execution time to be around 4 seconds. This observation shows that there is an improvement in the execution time for I/O bound tasks by using multithreading regardless of the GIL limitation it has.</p>
			<p>This concludes our <a id="_idIndexMarker774"/>discussion of how to implement threads in Python and how to benefit from different locking mechanisms using the <strong class="source-inline">Lock</strong> class and the <strong class="source-inline">Queue</strong> class. Next, we will discuss multiprocessing programming in Python.</p>
			<h1 id="_idParaDest-175"><a id="_idTextAnchor213"/>Going beyond a single CPU – implementing multiprocessing</h1>
			<p>We have seen the complexity of multithreaded programming and its limitations. The question is whether the complexity of multithreading is worth the effort. It may be worth it for I/O-related tasks but not for general application use cases, especially when an alternative approach exists. The alternative approach is to use multiprocessing because separate Python processes are not constrained by the GIL and execution can happen in parallel. This is especially beneficial when applications run on multicore processors and involve intensive CPU-demanding tasks. In reality, the use of multiprocessing is the only option in Python's built-in libraries to utilize multiple processor cores.</p>
			<p><strong class="bold">Graphics Processing Units</strong> (<strong class="bold">GPUs</strong>) provide a <a id="_idIndexMarker775"/>greater number of cores than regular CPUs and are considered more suitable for data processing tasks, especially when executing them in parallel. The only caveat is that in order to execute a data processing program on a GPU, we have to transfer the data from the main memory to the GPU's memory. This additional step of data transfer will be compensated when we are processing a large dataset. But there will be little or no benefit if our dataset is small. Using GPUs for big data processing, especially for training machine learning models, is becoming a popular option. NVIDIA has introduced a GPU for parallel processing called CUDA, which is well supported through external libraries in Python.</p>
			<p>Each process has a data <a id="_idIndexMarker776"/>structure called the <strong class="bold">Process Control Block</strong> (<strong class="bold">PCB</strong>) at the operating system level. Like the TCB, the PCB has a <strong class="bold">Process ID</strong> (<strong class="bold">PID</strong>) for process<a id="_idIndexMarker777"/> identification, stores the state of the process (such as running or waiting), and has a program counter, CPU registers, CPU scheduling information, and many more attributes.</p>
			<p>In the case of multiple processes for CPUs, there is no sharing of memory natively. This means there is a lower chance of data corruption. If the two processes have to share the data, they need to use some interprocess communication mechanism. Python supports interprocess communication through its primitives. In the next subsections, we will first discuss the fundamentals of creating processes in Python and then discuss how to achieve interprocess communication.</p>
			<h2 id="_idParaDest-176"><a id="_idTextAnchor214"/>Creating multiple processes </h2>
			<p>For multiprocessing programming, Python provides a <strong class="source-inline">multiprocessing</strong> package that is very similar to the <a id="_idIndexMarker778"/>multithreading package. The <strong class="source-inline">multiprocessing</strong> package includes two approaches to implement multiprocessing, which are using the <strong class="source-inline">Process</strong> object and the <strong class="source-inline">Pool</strong> object. We will discuss each of these approaches one by one.</p>
			<h3>Using the Process object</h3>
			<p>The processes <a id="_idIndexMarker779"/>can be spawned by creating a <strong class="source-inline">Process</strong> object and then using its <strong class="source-inline">start</strong> method similar to the <strong class="source-inline">start</strong> method for starting a <strong class="source-inline">Thread</strong> object. In fact, the <strong class="source-inline">Process</strong> object offers the same API as the <strong class="source-inline">Thread</strong> object. A simple code example for creating multiple child processes is as follows:</p>
			<p class="source-code"># <strong class="bold">process1</strong>.py to create simple processes with function</p>
			<p class="source-code">import os</p>
			<p class="source-code">from multiprocessing import Process, current_process as cp</p>
			<p class="source-code">from time import sleep</p>
			<p class="source-code">def <strong class="bold">print_hello</strong>():</p>
			<p class="source-code">    sleep(2)</p>
			<p class="source-code">    print("{}-{}: Hello".format(os.getpid(), cp().name))</p>
			<p class="source-code">def <strong class="bold">print_message</strong>(msg):</p>
			<p class="source-code">    sleep(1)</p>
			<p class="source-code">    print("{}-{}: {}".format(os.getpid(), cp().name, msg))</p>
			<p class="source-code">def main():</p>
			<p class="source-code">    processes = []</p>
			<p class="source-code">    # creating process</p>
			<p class="source-code">    processes.append(<strong class="bold">Process</strong>(target=print_hello, name="Process       1"))</p>
			<p class="source-code">    processes.append(<strong class="bold">Process</strong>(target=print_hello, name="Process       2"))</p>
			<p class="source-code">    processes.append(<strong class="bold">Process</strong>(target=print_message,      args=["Good morning"], name="Process 3"))</p>
			<p class="source-code">    # start the process</p>
			<p class="source-code">    for p in processes:</p>
			<p class="source-code">        <strong class="bold">p.start</strong>()</p>
			<p class="source-code">    # wait till all are done</p>
			<p class="source-code">    for p in processes:</p>
			<p class="source-code">        <strong class="bold">p.join()</strong></p>
			<p class="source-code">    print("Exiting the main process")</p>
			<p class="source-code">if __name__ == '__main__':</p>
			<p class="source-code">    main()</p>
			<p>As already mentioned, the methods used for the <strong class="source-inline">Process</strong> object are pretty much the same as those used for the <strong class="source-inline">Thread</strong> object. The explanation of this example is the same as for the example code in the <a id="_idIndexMarker780"/>multithreading code examples.</p>
			<h3>Using the Pool object</h3>
			<p>The <strong class="source-inline">Pool</strong> object offers a <a id="_idIndexMarker781"/>convenient way (using its <strong class="source-inline">map</strong> method) of creating processes, assigning functions to each new process, and distributing input parameters across the processes. We selected the code example with a pool size of <strong class="source-inline">3</strong> but provided input parameters for five processes. The reason for setting the pool size to <strong class="source-inline">3</strong> is to make sure a maximum of three child processes are active at a time, regardless of how many parameters we pass with the <strong class="source-inline">map</strong> method of the <strong class="source-inline">Pool</strong> object. The additional parameters will be handed over to the same child processes as soon they finish their current execution. Here is a code example with a pool size of <strong class="source-inline">3</strong>:</p>
			<p class="source-code"># <strong class="bold">process2</strong>.py to create processes using a pool</p>
			<p class="source-code">import os</p>
			<p class="source-code">from multiprocessing import Process, Pool, current_process     as cp</p>
			<p class="source-code">from time import sleep</p>
			<p class="source-code">def <strong class="bold">print_message</strong>(msg):</p>
			<p class="source-code">    sleep(1)</p>
			<p class="source-code">    print("{}-{}: {}".format(os.getpid(), cp().name, msg))</p>
			<p class="source-code">def main():</p>
			<p class="source-code">    # creating process from a pool</p>
			<p class="source-code">    with <strong class="bold">Pool</strong>(3) as proc:</p>
			<p class="source-code">        <strong class="bold">proc.map</strong>(print_message, ["Orange", "Apple", "Banana",</p>
			<p class="source-code">                                 "Grapes","Pears"])</p>
			<p class="source-code">    print("Exiting the main process")</p>
			<p class="source-code">if __name__ == '__main__':</p>
			<p class="source-code">    main()</p>
			<p>The magic of distributing input parameters to a function that is tied to a set of pool processes is done by the <strong class="source-inline">map</strong> method. The <strong class="source-inline">map</strong> method waits until all functions complete their execution, and that is why there is no need to use a <strong class="source-inline">join</strong> method if the processes are created using the <strong class="source-inline">Pool</strong> object.</p>
			<p>A few differences between using the <strong class="source-inline">Process</strong> object versus the <strong class="source-inline">Pool</strong> object are shown in the following table:</p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B17189_07_Table_1.jpg" alt="Table 7.1 – Comparison of using the Pool object and the Process object&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Table 7.1 – Comparison of using the Pool object and the Process object</p>
			<p>Next, we will discuss how to<a id="_idIndexMarker782"/> exchange data between processes. </p>
			<h2 id="_idParaDest-177"><a id="_idTextAnchor215"/>Sharing data between processes</h2>
			<p>There are two<a id="_idIndexMarker783"/> approaches in the multiprocessing package to share data between processes. These are <strong class="bold">shared memory</strong> and <strong class="bold">server process</strong>. They are described next. </p>
			<h3>Using shared ctype objects (shared memory)</h3>
			<p>In this case, a <em class="italic">shared memory</em> block is<a id="_idIndexMarker784"/> created, and the processes have access to this shared memory block. The shared memory is created as soon we initiate one of the <strong class="source-inline">ctype</strong> datatypes available in the <strong class="source-inline">multiprocessing</strong> package. The datatypes are <strong class="source-inline">Array</strong> and <strong class="source-inline">Value</strong>. The <strong class="source-inline">Array</strong> datatype is a <strong class="source-inline">ctype</strong> array and the <strong class="source-inline">Value</strong> datatype is a generic <strong class="source-inline">ctype</strong> object, both of which are allocated from the shared memory. To create a <strong class="source-inline">ctype</strong> array, we will use a statement like the following:</p>
			<p class="source-code">mylist = multiprocessing.Array('i', 5)</p>
			<p>This will create an array of the <strong class="source-inline">integer</strong> datatype with a size of <strong class="source-inline">5</strong>. <strong class="source-inline">i</strong> is one of the typecodes, and it stands for integer. We can use the <strong class="source-inline">d</strong> typecode for float datatypes. We can also initialize the array by providing the sequence as a second argument (instead of the size) as follows:</p>
			<p class="source-code">mylist = multiprocessing.Array('i', [1,2,3,4,5])</p>
			<p>To create a <strong class="source-inline">Value</strong> <strong class="source-inline">ctype</strong> object, we will use a statement similar to the following:</p>
			<p class="source-code">obj = multiprocessing.Value('i')</p>
			<p>This will create an object of the <strong class="source-inline">integer</strong> datatype because the typecode is set to <strong class="source-inline">i</strong>. The value of this object can <a id="_idIndexMarker785"/>be accessed or set by using the <strong class="source-inline">value</strong> attribute.</p>
			<p>Both these <strong class="source-inline">ctype</strong> objects have <strong class="source-inline">Lock</strong> as an optional argument, which is set to <strong class="source-inline">True</strong> by default. This argument when set to <strong class="source-inline">True</strong> is used to create a new recursive lock object that provides synchronized access to the value of the objects. If it is set to <strong class="source-inline">False</strong>, there will be no protection and it will not be a safe process. If your process is only accessing the shared memory for reading purposes, it is fine to set the <strong class="source-inline">Lock</strong> to <strong class="source-inline">False</strong>. We leave this <strong class="source-inline">Lock</strong> argument as the default (<strong class="source-inline">True</strong>) in our next code examples.</p>
			<p>To illustrate the use of these <strong class="source-inline">ctype</strong> objects from the shared memory, we will create a default list with three numeric values, a <strong class="source-inline">ctype</strong> array of size <strong class="source-inline">3</strong> to hold the incremented values of the original array, and a <strong class="source-inline">ctype</strong> object to hold the sum of the incremented array. These objects will be created by a parent process in shared memory and will be accessed and updated by a child process from the shared memory. This interaction of the parent and the child processes with the shared memory is shown in the following figure:</p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/B17189_07_03.jpg" alt="Figure 7.3 – Use of shared memory by a parent and a child process&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.3 – Use of shared memory by a parent and a child process</p>
			<p>A complete code<a id="_idIndexMarker786"/> example of using the shared memory is shown next:</p>
			<p class="source-code"># <strong class="bold">process3</strong>.py to use shared memory ctype objects</p>
			<p class="source-code">import multiprocessing</p>
			<p class="source-code">from multiprocessing import Process, Pool, current_process   as cp</p>
			<p class="source-code">def <strong class="bold">inc_sum_list(list, inc_list, sum):</strong></p>
			<p class="source-code">    sum.value = 0</p>
			<p class="source-code">    for index, num in enumerate(list):</p>
			<p class="source-code">        inc_list[index] = num + 1</p>
			<p class="source-code">        sum.value = sum.value + inc_list[index]</p>
			<p class="source-code">def main():</p>
			<p class="source-code">    mylist = [2, 5, 7]</p>
			<p class="source-code">    inc_list = <strong class="bold">multiprocessing.Array('i', 3)</strong></p>
			<p class="source-code">    sum = <strong class="bold">multiprocessing.Value('i')</strong></p>
			<p class="source-code">    p = Process(target=inc_sum_list,                args=(mylist, inc_list, sum))</p>
			<p class="source-code">    p.start()</p>
			<p class="source-code">    p.join()</p>
			<p class="source-code">    print("incremented list: ", list(inc_list))</p>
			<p class="source-code">    print("sum of inc list: ", sum.value)</p>
			<p class="source-code">    print("Exiting the main process")</p>
			<p class="source-code">if __name__ == '__main__':</p>
			<p class="source-code">    main()</p>
			<p>The shared datatypes (<strong class="source-inline">inc_list</strong> and <strong class="source-inline">sum</strong> in this case) are accessed by both the parent process and the child process. It is important to mention that using the shared memory is not a recommended option because it requires synchronization and locking mechanisms (similar to what we did for multithreading) when the same shared memory objects are accessed by<a id="_idIndexMarker787"/> multiple processes and the <strong class="source-inline">Lock</strong> argument is set to <strong class="source-inline">False</strong>. </p>
			<p>The next approach of sharing data between processes is using the server process. </p>
			<h3>Using the server process</h3>
			<p>In this case, a server process<a id="_idIndexMarker788"/> is started as soon as a Python program starts. This new process is used to create and manage the new child processes requested by a parent process. This server process can hold Python objects that other processes can access using proxies.</p>
			<p>To implement the server process and share the objects between the processes, the <strong class="source-inline">multiprocessing</strong> package provides a <strong class="source-inline">Manager</strong> object. The <strong class="source-inline">Manager</strong> object supports different data types such as the following:</p>
			<ul>
				<li>Lists</li>
				<li>Dictionaries</li>
				<li>Locks</li>
				<li>Rlocks</li>
				<li>Queues</li>
				<li>Values</li>
				<li>Arrays</li>
			</ul>
			<p>The code example we selected for illustrating the server process creates a <strong class="source-inline">dictionary</strong> object using the <strong class="source-inline">Manager</strong> object, then passes the dictionary object to different child processes to insert more data and to print out the dictionary contents. We will create three child processes for our example: two for inserting data into the dictionary object and one for getting the dictionary contents as the console output. The interaction between<a id="_idIndexMarker789"/> the parent process, the server process, and the three child processes is shown in <em class="italic">Figure 7.4</em>. The parent process creates the server process as soon as a new process request is executed using the <em class="italic">Manager</em> context. The child processes are created and managed by the server process. The shared data is available within the server process and is accessible by all processes, including the parent process:</p>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/B17189_07_04.jpg" alt="Figure 7.4 – Use of server process for sharing data between processes&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.4 – Use of server process for sharing data between processes</p>
			<p>The complete code example is shown next:</p>
			<p class="source-code"># <strong class="bold">process4</strong>.py to use shared memory using the server process</p>
			<p class="source-code">import multiprocessing</p>
			<p class="source-code">from multiprocessing import Process, Manager</p>
			<p class="source-code">def <strong class="bold">insert_data</strong> (dict1, code, subject):</p>
			<p class="source-code">    dict1[code] =  subject</p>
			<p class="source-code">def <strong class="bold">output</strong>(dict1):</p>
			<p class="source-code">    print("Dictionary data: ", dict1)</p>
			<p class="source-code">def main():</p>
			<p class="source-code">    with multiprocessing.<strong class="bold">Manager</strong>() as mgr:</p>
			<p class="source-code">        # create a dictionary in the server process</p>
			<p class="source-code">        mydict = <strong class="bold">mgr.dict</strong>({100: "Maths", 200: "Science"})</p>
			<p class="source-code">        p1 = Process(target=<strong class="bold">insert_data</strong>, args=(mydict, 300,           "English"))</p>
			<p class="source-code">        p2 = Process(target=<strong class="bold">insert_data</strong>, args=(mydict, 400,           "French"))</p>
			<p class="source-code">        p3 = Process(target=<strong class="bold">output</strong>, args=(mydict,))</p>
			<p class="source-code">        p1.start()</p>
			<p class="source-code">        p2.start()</p>
			<p class="source-code">        p1.join()</p>
			<p class="source-code">        p2.join()</p>
			<p class="source-code">        p3.start()</p>
			<p class="source-code">        p3.join()</p>
			<p class="source-code">    print("Exiting the main process")</p>
			<p class="source-code">if __name__ == '__main__':</p>
			<p class="source-code">    main()</p>
			<p>The server process approach offers more flexibility than the shared memory approach because it supports a large variety of object types. However, this comes at the cost of slower performance <a id="_idIndexMarker790"/>compared to the shared memory approach. </p>
			<p>In the next section, we will explore the options of direct communication between the processes.</p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor216"/>Exchanging objects between processes</h2>
			<p>In the previous section, we <a id="_idIndexMarker791"/>studied how to share data between the processes through an external memory block or a new process. In this section, we will investigate exchanging of data between processes using Python objects. The <strong class="source-inline">multiprocessing</strong> module provides two options for this purpose. These are using the <strong class="source-inline">Queue</strong> object and the <strong class="source-inline">Pipe</strong> object.</p>
			<h3>Using the Queue object</h3>
			<p>The <strong class="source-inline">Queue</strong> object is <a id="_idIndexMarker792"/>available from the <strong class="source-inline">multiprocessing</strong> package and is nearly the same as the synchronized queue object (<strong class="source-inline">queue.Queue</strong>) that we used for multithreading. This <strong class="source-inline">Queue</strong> object is process-safe and does not require any additional protection. A code example to illustrate the use of the multiprocessing <strong class="source-inline">Queue</strong> object for data exchange is shown next:</p>
			<p class="source-code"># <strong class="bold">process5</strong>.py to use queue to exchange data</p>
			<p class="source-code">import multiprocessing</p>
			<p class="source-code">from multiprocessing import Process, Queue</p>
			<p class="source-code">def <strong class="bold">copy_data</strong> (list, myqueue):</p>
			<p class="source-code">    for num in list:</p>
			<p class="source-code">        myqueue.put(num)</p>
			<p class="source-code">def <strong class="bold">output</strong>(myqueue):</p>
			<p class="source-code">    while not myqueue.empty():</p>
			<p class="source-code">        print(myqueue.get())</p>
			<p class="source-code">def main():</p>
			<p class="source-code">    mylist = [2, 5, 7]</p>
			<p class="source-code">    myqueue = Queue()</p>
			<p class="source-code">    p1 = Process(target=copy_data, args=(mylist, myqueue))</p>
			<p class="source-code">    p2 = Process(target=output, args=(myqueue,))</p>
			<p class="source-code">    p1.start()</p>
			<p class="source-code">    p1.join()</p>
			<p class="source-code">    p2.start()</p>
			<p class="source-code">    p2.join()</p>
			<p class="source-code">    print("Queue is empty: ",myqueue.empty())</p>
			<p class="source-code">    print("Exiting the main process")</p>
			<p class="source-code">if __name__ == '__main__':</p>
			<p class="source-code">    main()</p>
			<p>In this code example, we created a <a id="_idIndexMarker793"/>standard <strong class="source-inline">list</strong> object and a multiprocessing <strong class="source-inline">Queue</strong> object. The <strong class="source-inline">list</strong> and <strong class="source-inline">Queue</strong> objects are passed to a new process, which is attached to a function called <strong class="source-inline">copy_data</strong>. This function will copy the data from the <strong class="source-inline">list</strong> object to the <strong class="source-inline">Queue</strong> object. A new process is initiated to print the contents of the <strong class="source-inline">Queue</strong> object. Note that the data in the <strong class="source-inline">Queue</strong> object is set by the previous process and the data will be available to the new process. This is a convenient way to exchange data without adding the complexity of shared memory or the server process.</p>
			<h3>Using the Pipe object</h3>
			<p>The <strong class="source-inline">Pipe</strong> object is like a pipe <a id="_idIndexMarker794"/>between two processes for exchanging data. This is why this object is especially useful when two-way communication is required. When we create a <strong class="source-inline">Pipe</strong> object, it provides two connection objects, which are the two ends of the <strong class="source-inline">Pipe</strong> object. Each connection object provides a <strong class="source-inline">send</strong> and a <strong class="source-inline">recv</strong> method to send and receive data.</p>
			<p>To illustrate the concept and use of the <strong class="source-inline">Pipe</strong> object, we will create two functions that will be attached to two separate processes:</p>
			<ul>
				<li>The first function is for sending the message through a <strong class="source-inline">Pipe</strong> object connection. We will send a few data messages and finish the communication with a <strong class="source-inline">BYE</strong> message.</li>
				<li>The second function is to receive the message using the other connection object of the <strong class="source-inline">Pipe</strong> object. This <a id="_idIndexMarker795"/>function will run in an infinite loop until it receives a <strong class="source-inline">BYE</strong> message.</li>
			</ul>
			<p>The two functions (or processes) are provided with the two connection objects of a pipe. The complete code is as follows:</p>
			<p class="source-code"># <strong class="bold">process6</strong>.py to use Pipe to exchange data</p>
			<p class="source-code">from multiprocessing import Process, Pipe</p>
			<p class="source-code">def <strong class="bold">mysender</strong> (s_conn):</p>
			<p class="source-code">    <strong class="bold">s_conn.send</strong>({100, "Maths"})</p>
			<p class="source-code">    s_conn.send({200, "Science"})</p>
			<p class="source-code">    s_conn.send("BYE")</p>
			<p class="source-code">def <strong class="bold">myreceiver</strong>(r_conn):</p>
			<p class="source-code">    while True:</p>
			<p class="source-code">        msg = <strong class="bold">r_conn.recv</strong>()</p>
			<p class="source-code">        if msg == "BYE":</p>
			<p class="source-code">            break</p>
			<p class="source-code">        print("Received message : ", msg)</p>
			<p class="source-code">def main():</p>
			<p class="source-code">    sender_conn, receiver_conn= Pipe()</p>
			<p class="source-code">    p1 = Process(target=mysender, args=(sender_conn, ))</p>
			<p class="source-code">    p2 = Process(target=myreceiver, args=(receiver_conn,))</p>
			<p class="source-code">    p1.start()</p>
			<p class="source-code">    p2.start()</p>
			<p class="source-code">    p1.join()</p>
			<p class="source-code">    p2.join()</p>
			<p class="source-code">    print("Exiting the main process")</p>
			<p class="source-code">if __name__ == '__main__':</p>
			<p class="source-code">    main()</p>
			<p>It is important to mention<a id="_idIndexMarker796"/> that the data in a <strong class="source-inline">Pipe</strong> object can easily be corrupted if the two processes try to read from or write to it using the same connection object at the same time. That is why multiprocessing queues are the preferred option: because they provide proper synchronization between the processes.</p>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor217"/>Synchronization between processes</h2>
			<p>Synchronization between processes <a id="_idIndexMarker797"/>makes sure that two or more processes do not access the same resources or program code at the same time, which is also called the <strong class="bold">critical section</strong>. Such a situation can lead to a race condition, which can corrupt the data. The chance of a<a id="_idIndexMarker798"/> race condition occurring among different processes is not very high, but it is still possible if they are using shared memory or accessing the same resources. These situations can be avoided either by using the appropriate objects with built-in synchronization or by using the <strong class="source-inline">Lock</strong> object, similar to what we used in the case of multithreading.</p>
			<p>We illustrated the use of <strong class="source-inline">queues</strong> and <strong class="source-inline">ctype</strong> datatypes with <strong class="source-inline">Lock</strong> set to <strong class="source-inline">True</strong>, which is process safe. In the next code example, we will illustrate the use of the <strong class="source-inline">Lock</strong> object to make sure one process gets access to<a id="_idIndexMarker799"/> the console output at a time. We created the processes using the <strong class="source-inline">Pool</strong> object and to pass the same <strong class="source-inline">Lock</strong> object to all processes, we used the <strong class="source-inline">Lock</strong> from the <strong class="source-inline">Manager</strong> object and not the one from the multiprocessing package. We also used the <strong class="source-inline">partial</strong> function to tie the <strong class="source-inline">Lock</strong> object to each process, along with a list to be distributed to each process function. Here is the complete code example:</p>
			<p class="source-code"># <strong class="bold">process7</strong>.py to show synchronization and locking</p>
			<p class="source-code">from functools import partial</p>
			<p class="source-code">from multiprocessing import Pool, Manager</p>
			<p class="source-code">def printme (lock, msg):</p>
			<p class="source-code">    lock.acquire()</p>
			<p class="source-code">    try:</p>
			<p class="source-code">        print(msg)</p>
			<p class="source-code">    finally:</p>
			<p class="source-code">        lock.release()</p>
			<p class="source-code">def main():</p>
			<p class="source-code">    with Pool(3) as proc:</p>
			<p class="source-code">        lock = Manager().Lock()</p>
			<p class="source-code">        func = partial(printme,lock)</p>
			<p class="source-code">        proc.map(func, ["Orange", "Apple", "Banana",</p>
			<p class="source-code">                                 "Grapes","Pears"])</p>
			<p class="source-code">    print("Exiting the main process")</p>
			<p class="source-code">if __name__ == '__main__':</p>
			<p class="source-code">    main()</p>
			<p>If we do not use the <strong class="source-inline">Lock</strong> object, the output from the different processes can be mixed up.</p>
			<h2 id="_idParaDest-180"><a id="_idTextAnchor218"/>Case study – a multiprocessor application to download files from Google Drive</h2>
			<p>In this section, we will implement the<a id="_idIndexMarker800"/> same case study as we did in the <em class="italic">Case study – a multithreaded application to download files from Google Drive</em> section, but using processors instead. The prerequisites and goals are the same as described for the case study of the multithreaded application.</p>
			<p>For this application, we used the same code that we built for the multithreaded application except that we used processes instead of threads. Another difference is that we used the <strong class="source-inline">JoinableQueue</strong> object from the <strong class="source-inline">multiprocessing</strong> module to achieve the same functionality as we were getting from the regular <strong class="source-inline">Queue</strong> object. Code for defining a resource data structure and for a function to download files from Google Drive is as follows:</p>
			<p class="source-code">#<strong class="bold">processes_casestudy</strong>.py</p>
			<p class="source-code">import time</p>
			<p class="source-code">from multiprocessing import Process, JoinableQueue</p>
			<p class="source-code">from getfilelistpy import getfilelist</p>
			<p class="source-code">import gdown</p>
			<p class="source-code">PROCESSES_POOL_SIZE = 5</p>
			<p class="source-code">resource = {</p>
			<p class="source-code">    "api_key": "AIzaSyDYKmm85keqnk4bF1Da2bxddKrGns4z0",</p>
			<p class="source-code">    "id": "0B8TxHW2Ci6dbckVwetTlV3RUU",</p>
			<p class="source-code">    "fields": "files(name,id,webContentLink)",</p>
			<p class="source-code">}</p>
			<p class="source-code">def <strong class="bold">mydownloader</strong>( queue):</p>
			<p class="source-code">    while True:</p>
			<p class="source-code">        # Get the file id and name from the queue</p>
			<p class="source-code">        item1 =  queue.get()</p>
			<p class="source-code">        try:</p>
			<p class="source-code">            <strong class="bold">gdown.download</strong>(item1['webContentLink'],</p>
			<p class="source-code">                           './files/{}'.format(item1['name']),</p>
			<p class="source-code">                           quiet=False)</p>
			<p class="source-code">        finally:</p>
			<p class="source-code">            queue.task_done()</p>
			<p>We get the files' metadata, such as the name and HTTP link, from a Google Drive directory using the resource<a id="_idIndexMarker801"/> data structure as follows:</p>
			<p class="source-code">def get_files(resource):</p>
			<p class="source-code">    res = getfilelist.GetFileList(resource)</p>
			<p class="source-code">    files_list = res['fileList'][0]</p>
			<p class="source-code">    return files_list</p>
			<p>In our <strong class="source-inline">main</strong> function, we create a <strong class="source-inline">JoinableQueue</strong> object and insert the files' metadata into the queue. The queue will be handed over to a pool of processes to download the files. The processes will download the files. We used the <strong class="source-inline">time</strong> class to measure the time it takes to download all the files from the Google Drive directory. The code for the <strong class="source-inline">main</strong> function is as follows:</p>
			<p class="source-code">def main ():</p>
			<p class="source-code">    files = get_files(resource)</p>
			<p class="source-code">    #add files info into the queue</p>
			<p class="source-code">    <strong class="bold">myqueue = JoinableQueue()</strong></p>
			<p class="source-code">    for item in files['files']:</p>
			<p class="source-code">        myqueue.put(item)</p>
			<p class="source-code">    processes = []</p>
			<p class="source-code">    for id in range(PROCESSES_POOL_SIZE):</p>
			<p class="source-code">        p = <strong class="bold">Process</strong>(target=<strong class="bold">mydownloader</strong>, args=(myqueue,))</p>
			<p class="source-code">        p.daemon = True</p>
			<p class="source-code">        p.start()</p>
			<p class="source-code">    start_time = time.monotonic()</p>
			<p class="source-code">    <strong class="bold">myqueue.join()</strong></p>
			<p class="source-code">    total_exec_time = time.monotonic() - start_time</p>
			<p class="source-code">    print(f'Time taken to download: {total_exec_time:.2f}         seconds')</p>
			<p class="source-code">if __name__ == '__main__':</p>
			<p class="source-code">    main()</p>
			<p>We ran this application by varying the different number of processes, such as <strong class="source-inline">3</strong>, <strong class="source-inline">5</strong>, <strong class="source-inline">7</strong>, and <strong class="source-inline">10</strong>. We found that the time it took to download the same files (as for the case study of multithreading) is slightly <a id="_idIndexMarker802"/>better than with the multithreaded application. The execution time will vary from machine to machine, but on our machine (MacBook Pro: Intel Core i5 with 16 GB RAM), it took around 5 seconds with 5 processes and 3 seconds with 10 processes running in parallel. This improvement of 1 second over the multithreaded application is in line with the expected results as multiprocessing provides true concurrency.</p>
			<h1 id="_idParaDest-181"><a id="_idTextAnchor219"/>Using asynchronous programming for responsive systems</h1>
			<p>With multiprocessing <a id="_idIndexMarker803"/>and multithreaded programming, we were mostly dealing with synchronous programming, where we request something and wait for the response to be received before we move to the next block <a id="_idIndexMarker804"/>of code. If any context switching is applied, it is provided by the operating system. Asynchronous programming in Python is different mainly in the following two aspects:</p>
			<ul>
				<li>The tasks are to be created for asynchronous execution. This means the parent caller does not have to wait for the response from another process. The process will respond to the caller once it finishes the execution.</li>
				<li>The operating system is no longer managing the context switching between the processes and the threads. The asynchronous program will be given only a single thread in a process, but we can do multiple things with it. In this style of execution, every process or task voluntarily releases control whenever it is idle or waiting for another resource<a id="_idIndexMarker805"/> to make sure that the other tasks get a turn. This concept is called <strong class="bold">cooperative multitasking</strong>.</li>
			</ul>
			<p>Cooperative multitasking is an effective tool for achieving concurrency at the application level. In cooperative multitasking, we do not build processes or threads, but tasks, which comprises <strong class="bold">tasklets</strong>, or <strong class="bold">coroutines</strong>, and or <strong class="bold">green threads</strong>. These<a id="_idIndexMarker806"/> tasks are coordinated<a id="_idIndexMarker807"/> by a single function known as an <strong class="bold">event loop</strong>. The event loop registers the tasks and handles the flow of control<a id="_idIndexMarker808"/> between the tasks. The beauty of the event loop in <a id="_idIndexMarker809"/>Python is that it is implemented using generators, and these generators can execute a function and pause it at a specific point (using <strong class="source-inline">yield</strong>) while keeping the stack of objects under control before it is resumed.</p>
			<p>For a system based on cooperative multitasking, there is always a question of when to release the control back to a scheduler or to an event loop. The most commonly used logic is to use the I/O operation as the event to release the control because there is always a waiting time involved whenever we are doing an I/O operation.</p>
			<p>But hold on, is it not the same logic we used for multithreading? We found that multithreading improves application performance when dealing with I/O operations. But there is a difference here. In the case of multithreading, the operating system is managing the context switching between the threads, and it can preempt any running thread for any reason and<a id="_idIndexMarker810"/> give control to another thread. But in asynchronous programming or cooperative multitasking, the tasks or coroutines are not visible to the operating systems and cannot be preempted. The coroutines in fact cannot be preempted by the main event loop. But this does not mean that the operating system cannot preempt the whole Python process. The main Python process is still competing for resources with other applications and processes at the operating system level.</p>
			<p>In the next section, we will discuss a few building blocks of asynchronous programming in Python, which is <a id="_idIndexMarker811"/>provided by the <strong class="source-inline">asyncio</strong> module, and we will conclude with a comprehensive case study.</p>
			<h2 id="_idParaDest-182"><a id="_idTextAnchor220"/>Understanding the asyncio module</h2>
			<p>The <strong class="source-inline">asyncio</strong> module is available in <a id="_idIndexMarker812"/>Python 3.5 or later to write concurrent programs using the <strong class="source-inline">async/await</strong> syntax. But it is recommended to use Python 3.7 or later to build any serious <strong class="source-inline">asyncio</strong> application. The library is<a id="_idIndexMarker813"/> rich with features and supports creating and running Python coroutines, performing network I/O operations, distributing tasks to queues, and synchronizing concurrent code.</p>
			<p>We will start with how to write and execute coroutines and tasks.</p>
			<h3>Coroutines and tasks</h3>
			<p>Coroutines are the functions that <a id="_idIndexMarker814"/>are to be executed asynchronously. A simple<a id="_idIndexMarker815"/> example of sending a string to the console output using a coroutine is as follows:</p>
			<p class="source-code">#<strong class="bold">asyncio1</strong>.py to build a basic coroutine</p>
			<p class="source-code">import asyncio</p>
			<p class="source-code">import time</p>
			<p class="source-code">async def <strong class="bold">say</strong>(delay, msg):</p>
			<p class="source-code">    <strong class="bold">await</strong> asyncio.sleep(delay)</p>
			<p class="source-code">    print(msg)</p>
			<p class="source-code">print("Started at ", time.strftime("%X"))</p>
			<p class="source-code">asyncio.<strong class="bold">run</strong>(say(1,"Good"))</p>
			<p class="source-code">asyncio.run(say(2, "Morning"))</p>
			<p class="source-code">print("Stopped at ", time.strftime("%X"))</p>
			<p>In this code example, it is important <a id="_idIndexMarker816"/>to note the following:</p>
			<ul>
				<li>The coroutine takes <strong class="source-inline">delay</strong> and <strong class="source-inline">msg</strong> arguments. The <strong class="source-inline">delay</strong> argument is used to add a delay<a id="_idIndexMarker817"/> before sending the <strong class="source-inline">msg</strong> string to the console output.</li>
				<li>We used the <strong class="source-inline">asyncio.sleep</strong> function instead of the traditional <strong class="source-inline">time.sleep</strong> function. If the <strong class="source-inline">time.sleep</strong> function is used, control will not be given back to the event loop. That is why it is important to use the compatible <strong class="source-inline">asyncio.sleep</strong> function.</li>
				<li>The coroutine is executed twice with two different values of the <strong class="source-inline">delay</strong> argument by using the <strong class="source-inline">run</strong> method. The <strong class="source-inline">run</strong> method will not execute the coroutines concurrently.</li>
			</ul>
			<p>The console output of this program will be as follows. This shows that the coroutines are executed one after the other as the total delay added is 3 seconds:</p>
			<p class="source-code">Started at 15:59:55</p>
			<p class="source-code">Good</p>
			<p class="source-code">Morning</p>
			<p class="source-code">Stopped at 15:59:58</p>
			<p>To run the coroutines in parallel, we need to use the <strong class="source-inline">create_task</strong> function from the <strong class="source-inline">asyncio</strong> module. This function creates a task that can be used to schedule coroutines to run concurrently.</p>
			<p>The next code example is a revised version of <strong class="source-inline">asyncio1.py</strong>, in which we wrapped the coroutine (<strong class="source-inline">say</strong> in our case) into a task using the <strong class="source-inline">create_task</strong> function. In this revised version, we created<a id="_idIndexMarker818"/> two tasks that are wrapping the <strong class="source-inline">say</strong> coroutine. We <a id="_idIndexMarker819"/>waited for the two tasks to be completed using the <strong class="source-inline">await</strong> keyword:</p>
			<p class="source-code">#<strong class="bold">asyncio2</strong>.py to build and run coroutines in parallel</p>
			<p class="source-code">import asyncio</p>
			<p class="source-code">import time</p>
			<p class="source-code">async def <strong class="bold">say</strong>(delay, msg):</p>
			<p class="source-code">    await asyncio.sleep(delay)</p>
			<p class="source-code">    print(msg)</p>
			<p class="source-code">async def main ():</p>
			<p class="source-code">    task1 = <strong class="bold">asyncio.create_task</strong>( say(1, 'Good'))</p>
			<p class="source-code">    task2 = asyncio.create_task( say(1, 'Morning'))</p>
			<p class="source-code">    print("Started at ", time.strftime("%X"))</p>
			<p class="source-code">    <strong class="bold">await task1</strong></p>
			<p class="source-code">    await task2</p>
			<p class="source-code">    print("Stopped at ", time.strftime("%X"))</p>
			<p class="source-code">asyncio.run(main())</p>
			<p>The console output of this program is as follows:</p>
			<p class="source-code">Started at 16:04:40</p>
			<p class="source-code">Good</p>
			<p class="source-code">Morning</p>
			<p class="source-code">Stopped at  16:04:41</p>
			<p>This console output <a id="_idIndexMarker820"/>shows that the two tasks were completed in 1 second, which <a id="_idIndexMarker821"/>is proof that the tasks are executed in parallel.</p>
			<h3>Using awaitable objects</h3>
			<p>An object is<a id="_idIndexMarker822"/> awaitable if we can apply the <strong class="source-inline">await</strong> statement to it. The majority of <strong class="source-inline">asyncio</strong> functions and modules inside it are designed to work with awaitable objects. But most Python objects and third-party libraries are not built for asynchronous programming. It is important to select compatible libraries that provide awaitable objects to use when building asynchronous applications.</p>
			<p>Awaitable objects are split<a id="_idIndexMarker823"/> mainly into three types: coroutines, tasks, and <strong class="bold">Futures</strong>. We already discussed coroutines and tasks. A <strong class="source-inline">Future</strong> is a low-level object that is like a callback mechanism used to process the result coming from the <strong class="source-inline">async</strong>/<strong class="source-inline">await</strong>. The <strong class="source-inline">Future</strong> objects are typically not exposed for user-level programming.</p>
			<h3>Running tasks concurrently</h3>
			<p>If we have to run<a id="_idIndexMarker824"/> multiple tasks in parallel, we can use the <strong class="source-inline">await</strong> keyword as we did in the previous example. But there is a better way of doing this by using the <strong class="source-inline">gather</strong> function. This function will run the awaitable objects in the sequence provided. If any of the awaitable objects is a coroutine, it will be scheduled as a task. We will see the use of the <strong class="source-inline">gather</strong> function in the next section with a code example.</p>
			<h2 id="_idParaDest-183"><a id="_idTextAnchor221"/>Distributing tasks using queues</h2>
			<p>The <strong class="source-inline">Queue</strong> object in the <strong class="source-inline">asyncio</strong> package is similar to the <strong class="source-inline">Queue</strong> module but it is not thread safe. The <strong class="source-inline">aysncio</strong> module provides a variety of queue implementations, such as FIFO queues, priority queues, and LIFO queues. The queues in the <strong class="source-inline">asyncio</strong> module can be used to distribute the <a id="_idIndexMarker825"/>workloads to the tasks.</p>
			<p>To illustrate the use of a queue with tasks, we will write a small program that will simulate the execution time of a real function by sleeping for a random amount of time. The random sleeping time is calculated for 10 such executions and added to a <strong class="source-inline">Queue</strong> object as working items by the main process. The <strong class="source-inline">Queue</strong> object is passed to a pool of three tasks. Each task in the pool<a id="_idIndexMarker826"/> executes the assigned coroutine, which consumes the execution time as per the queue entry available to it. The complete code is shown next:</p>
			<p class="source-code">#<strong class="bold">asyncio3</strong>.py to distribute work via queue</p>
			<p class="source-code">import asyncio</p>
			<p class="source-code">import random</p>
			<p class="source-code">import time</p>
			<p class="source-code">async def <strong class="bold">executer</strong>(name, queue):</p>
			<p class="source-code">    while True:</p>
			<p class="source-code">        exec_time = await queue.get()</p>
			<p class="source-code">        await asyncio.sleep(exec_time)</p>
			<p class="source-code">        queue.task_done()</p>
			<p class="source-code">        #print(f'{name} has taken  {exec_time:.2f} seconds')</p>
			<p class="source-code">async def main ():</p>
			<p class="source-code">    <strong class="bold">myqueue = asyncio.Queue()</strong></p>
			<p class="source-code">    calc_exuection_time = 0</p>
			<p class="source-code">    for _ in range(10):</p>
			<p class="source-code">        sleep_for = random.uniform(0.4, 0.8)</p>
			<p class="source-code">        calc_exuection_time += sleep_for</p>
			<p class="source-code">        <strong class="bold">myqueue.put_nowait</strong>(sleep_for)</p>
			<p class="source-code">    tasks = []</p>
			<p class="source-code">    for id in range(3):</p>
			<p class="source-code">        task = <strong class="bold">asyncio.create_task</strong>(<strong class="bold">executer</strong>(f'Task-{id+1}',                 myqueue))</p>
			<p class="source-code">        tasks.append(task)</p>
			<p class="source-code">    start_time = time.monotonic()</p>
			<p class="source-code">    await myqueue.join()</p>
			<p class="source-code">    total_exec_time = time.monotonic() - start_time</p>
			<p class="source-code">    for task in tasks:</p>
			<p class="source-code">        task.cancel()</p>
			<p class="source-code">    await asyncio.gather(*tasks, return_exceptions=True)</p>
			<p class="source-code">    print(f"Calculated execution time         {calc_exuection_time:0.2f}")</p>
			<p class="source-code">    print(f"Actual execution time {total_exec_time:0.2f}")</p>
			<p class="source-code">asyncio.run(main())</p>
			<p>We used the <strong class="source-inline">put_no_wait</strong> function of the <strong class="source-inline">Queue</strong> object because it is a non-blocking operation. The console output of this <a id="_idIndexMarker827"/>program is as follows:</p>
			<p class="source-code">Calculated execution time 5.58</p>
			<p class="source-code">Actual execution time 2.05</p>
			<p>This clearly shows that<a id="_idIndexMarker828"/> the tasks are executed in parallel, and the execution is three times better than if tasks are run sequentially.</p>
			<p>So far, we have covered the fundamental concepts of the <strong class="source-inline">asyncio</strong> package in Python. Before concluding this topic, we will revisit the case study we did for the multithreading section by implementing it using the <strong class="source-inline">asyncio</strong> tasks.</p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor222"/>Case study – asyncio application to download files from Google Drive</h2>
			<p>We will implement the <a id="_idIndexMarker829"/>same case study as we did in the <em class="italic">Case study – a multithreaded application to download files from Google Drive</em> section, but using the <strong class="source-inline">asyncio</strong> module with <strong class="source-inline">async</strong>, <strong class="source-inline">await</strong>, and <strong class="source-inline">async queue</strong>. The prerequisites for this case study are the same except that we use the <strong class="source-inline">aiohttp</strong> and <strong class="source-inline">aiofiles</strong> library instead of the <strong class="source-inline">gdown</strong> library. The reason is simple: the <strong class="source-inline">gdown</strong> library is not built as an async module. There is no benefit of using it with async programming. This is an important point to consider whenever selecting libraries to be used with async applications.</p>
			<p>For this application, we built a coroutine, <strong class="source-inline">mydownloader</strong>, to download a file from Google Drive using the <strong class="source-inline">aiohttp</strong> and <strong class="source-inline">aiofiles</strong> modules. This is shown in the following code, and the code that is different from the previous case studies is highlighted:</p>
			<p class="source-code">#<strong class="bold">asyncio_casestudy</strong>.py</p>
			<p class="source-code">import asyncio</p>
			<p class="source-code">import time</p>
			<p class="source-code">import aiofiles, aiohttp</p>
			<p class="source-code">from getfilelistpy import getfilelist</p>
			<p class="source-code">TASK_POOL_SIZE = 5</p>
			<p class="source-code">resource = {</p>
			<p class="source-code">    "api_key": "AIzaSyDYKmm85keqnk4bF1DpYa2dKrGns4z0",</p>
			<p class="source-code">    "id": "0B8TxHW2Ci6dbckVwetTlV3RUU",</p>
			<p class="source-code">    "fields": "files(name, id, webContentLink)",</p>
			<p class="source-code">}</p>
			<p class="source-code">async def <strong class="bold">mydownloader</strong>(name, queue):</p>
			<p class="source-code">    while True:</p>
			<p class="source-code">        # Get the file id and name from the queue</p>
			<p class="source-code">        item = await queue.get()</p>
			<p class="source-code">        try:</p>
			<p class="source-code">            <strong class="bold">async with aiohttp.ClientSession()</strong> as sess:</p>
			<p class="source-code">                <strong class="bold">async with sess.get</strong>(item['webContentLink']) </p>
			<p class="source-code">                    as resp:</p>
			<p class="source-code">                    if resp.status == 200:</p>
			<p class="source-code">                       f = <strong class="bold">await aiofiles.open</strong>('./files/{}'                         .format(</p>
			<p class="source-code">                            item['name']), mode='wb')</p>
			<p class="source-code">                        <strong class="bold">await f.write</strong>(await resp.read())</p>
			<p class="source-code">                        <strong class="bold">await f.close()</strong></p>
			<p class="source-code">        finally:</p>
			<p class="source-code">            print(f"{name}: Download completed for </p>
			<p class="source-code">                        ",item['name'])</p>
			<p class="source-code">            queue.task_done()</p>
			<p>The process to get the list of files from a shared Google Drive folder is the same as we used in the previous case<a id="_idIndexMarker830"/> study for multithreading and multiprocessing. In this case study, we created a pool of tasks (configurable) based on the <strong class="source-inline">mydownloader</strong> coroutine. These tasks are then scheduled to run together, and our parent process waits for all tasks to complete their execution. A code to get a list of files from Google Drive and then download the files using <strong class="source-inline">asyncio</strong> tasks is as follows:</p>
			<p class="source-code">def get_files(resource):</p>
			<p class="source-code">    res = getfilelist.GetFileList(resource)</p>
			<p class="source-code">    files_list = res['fileList'][0]</p>
			<p class="source-code">    return files_list</p>
			<p class="source-code">async def main ():</p>
			<p class="source-code">    files = get_files(resource)</p>
			<p class="source-code">    #add files info into the queue</p>
			<p class="source-code">    myqueue = asyncio.Queue()</p>
			<p class="source-code">    for item in files['files']:</p>
			<p class="source-code">        myqueue.put_nowait(item)</p>
			<p class="source-code">    tasks = []</p>
			<p class="source-code">    for id in range(TASK_POOL_SIZE):</p>
			<p class="source-code">        task = <strong class="bold">asyncio.create_task</strong>(</p>
			<p class="source-code">            <strong class="bold">mydownloade</strong>r(f'Task-{id+1}', myqueue))</p>
			<p class="source-code">        tasks.append(task)</p>
			<p class="source-code">    start_time = time.monotonic()</p>
			<p class="source-code">    <strong class="bold">await myqueue.join()</strong></p>
			<p class="source-code">    total_exec_time = time.monotonic() - start_time</p>
			<p class="source-code">    for task in tasks:</p>
			<p class="source-code">        task.cancel()</p>
			<p class="source-code">    <strong class="bold">await asyncio.gather</strong>(*tasks, return_exceptions=True)</p>
			<p class="source-code">    print(f'Time taken to download: {total_exec_time:.2f}         seconds')</p>
			<p class="source-code">asyncio.run(main())</p>
			<p>We ran this application by<a id="_idIndexMarker831"/> varying the number of tasks, such as 3, 5, 7, and 10. We found that the time it took to download the files with the <strong class="source-inline">asyncio</strong> tasks is lower than when we downloaded the same files using the multithreading approach or the multiprocessing approach. The exact details of the time taken with the multithreading approach and the multiprocessing approach are available in the <em class="italic">Case study – a multithreaded application to download files from Google Drive</em> and <em class="italic">Case study – a multiprocessor application to download files from Google Drive</em> sections.</p>
			<p>The execution time can vary from machine to machine, but on our machine (MacBook Pro: Intel Core i5 with 16 GB RAM), it took around 4 seconds with 5 tasks and 2 seconds with 10 tasks running in parallel. This is a significant improvement compared to the numbers we observed for the multithreading and multiprocessing case studies. This is in line with expected results, as <strong class="source-inline">asyncio</strong> provides a better concurrency framework when it comes to I/O-related tasks, but it has to be implemented using the right set of programming objects.</p>
			<p>This concludes our discussion of asynchronous programming. This section provided all the core ingredients to build an asynchronous application using the <strong class="source-inline">asyncio</strong> package.</p>
			<h1 id="_idParaDest-185"><a id="_idTextAnchor223"/>Summary</h1>
			<p>In this chapter, we discussed different options of concurrent programming in Python using the standard libraries. We started with multithreading with an introduction to the core concepts of concurrent programming. We introduced the challenges with multithreading, such as the GIL, which allows only one thread at a time to access Python objects. The concepts of locking and synchronization were explored with practical examples of Python code. We also discussed the types of task that multithreaded programming is more effective for using a case study.</p>
			<p>We studied how to achieve concurrency using multiple processes in Python. With multiprocessing programming, we learned how to share data between processes using shared memory and the server process, and also how to exchange objects safely between processes using the <strong class="source-inline">Queue</strong> object and the <strong class="source-inline">Pipe</strong> object. In the end, we built the same case study as we did for the multithreading example, but using processes instead. Then, we introduced a completely different approach to achieving concurrency by using asynchronous programming. This was a complete shift in concept, and we started it by looking at the high-level concepts of the <strong class="source-inline">async</strong> and <strong class="source-inline">await</strong> keywords and how to build tasks, or coroutines, using the <strong class="source-inline">asyncio</strong> package. We concluded the chapter with the same case study we examined for multiprocessing and multithreading but using asynchronous programming.</p>
			<p>This chapter has provided a lot of hands-on examples of how to implement concurrent applications in Python. This knowledge is important for anyone who wants to build multithreaded or asynchronous applications using the standard libraries available in Python.</p>
			<p>In the next chapter, we will explore using third-party libraries to build concurrent applications in Python.</p>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor224"/>Questions</h1>
			<ol>
				<li>What coordinates Python threads? Is it a Python interpreter?</li>
				<li>What is the GIL in Python?</li>
				<li>When should you use daemon threads?</li>
				<li>For a system with limited memory, should we use a <strong class="source-inline">Process</strong> object or <strong class="source-inline">Pool</strong> object to create processes?</li>
				<li>What are Futures in the <strong class="source-inline">asyncio</strong> package?</li>
				<li>What is an event loop in asynchronous programming?</li>
				<li>How do you write an asynchronous coroutine or function in Python?</li>
			</ol>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor225"/>Further reading</h1>
			<ul>
				<li><em class="italic">Learning Concurrency in Python</em> by Elliot Forbes</li>
				<li><em class="italic">Expert Python Programming</em> by Michal Jaworski and Tarek Ziade</li>
				<li><em class="italic">Python 3 Object-Oriented Programming,</em> <em class="italic">Second Edition</em> by Dusty Phillips</li>
				<li><em class="italic">Mastering Concurrency</em> <em class="italic">in Python</em> by Quan Nguyen</li>
				<li><em class="italic">Python Concurrency with asyncio</em> by Mathew Fowler</li>
			</ul>
			<h1 id="_idParaDest-188"><a id="_idTextAnchor226"/>Answers</h1>
			<ol>
				<li value="1">The threads and processes are coordinated by the operating system kernel.</li>
				<li>Python's GIL is a locking mechanism used by Python to allow only one thread to execute at a time.</li>
				<li>Daemon threads are used when it is not an issue for a thread to be terminated once its main thread terminates.</li>
				<li>The <strong class="source-inline">Pool</strong> object keeps only the active processes in memory, so it is a better choice.</li>
				<li>Futures are like a callback mechanism that is used to process the result coming from async/await calls.</li>
				<li>An event loop object keeps track of tasks and handles the flow of control between them.</li>
				<li>We can write an asynchronous coroutine by starting with <strong class="source-inline">async def</strong>.</li>
			</ol>
		</div>
	</body></html>