<html><head></head><body>
  <div><div><div><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Working with Audios</h1></div></div></div><div><blockquote class="blockquote"><p>Decades ago, silent movies lit up the screen but later, it was audio effect that brought life into them. We deal with digital audio processing quite frequently when just playing a CD track, recording your own voice or converting songs into a different audio format. There are many libraries or multimedia frameworks available for audio processing. This chapter teaches some common digital audio processing techniques using Python bindings of a popular multimedia framework called GStreamer.</p></blockquote></div><p>In this chapter, we shall:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Learn basic concepts behind GStreamer multimedia framework</li><li class="listitem" style="list-style-type: disc">Use GStreamer API for audio processing</li><li class="listitem" style="list-style-type: disc">Develop some simple audio processing tools for 'everyday use'. We will develop tools that will batch convert audio file formats, record an audio, and play audio files</li></ul></div><p>So let's get on with it!</p><div><div><div><div><h1 class="title"><a id="ch05lvl1sec01"/>Installation prerequisites</h1></div></div></div><p>Since we are going to use an external multimedia framework, it is necessary to install the packages mentioned in this section.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec01"/>GStreamer</h2></div></div></div><p>GStreamer is a popular open source multimedia framework that supports audio/video manipulation of a wide range of multimedia formats. It is written in the C programming language and provides bindings for other programming languages including Python. Several open source projects use GStreamer framework to develop their own multimedia application. Throughout this chapter, we will make use of the GStreamer framework for audio handling. In order to get this working with Python, we need to install both GStreamer and the Python bindings for GStreamer.<a id="id186" class="indexterm"/>
</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec01"/>Windows platform</h3></div></div></div><p>The binary distribution of GStreamer is not provided on the project website<a class="ulink" href="http://www.gstreamer.net/"> http://www.gstreamer.net/</a>. Installing it from the source may require considerable effort on the part of Windows users. Fortunately,<em> GStreamer WinBuilds</em> project provides pre-compiled binary distributions. Here is the URL to the project website:<a class="ulink" href="http://www.gstreamer-winbuild.ylatuya.es"> http://www.gstreamer-winbuild.ylatuya.es</a>
<a id="id187" class="indexterm"/>
</p><p>The binary distribution for GStreamer as well as its Python bindings (Python 2.6) are available in the<strong> Download</strong> area of the website:<a class="ulink" href="http://www.gstreamer-winbuild.ylatuya.es/doku.php?id=download"> http://www.gstreamer-winbuild.ylatuya.es/doku.php?id=download</a>
</p><p>You need to install two packages. First, the GStreamer and then the Python bindings to the GStreamer. Download and install the GPL distribution of GStreamer available on the GStreamer WinBuilds project website. The name of the GStreamer executable is<code class="literal"> GStreamerWinBuild-0.10.5.1.exe</code>. The version should be 0.10.5 or higher. By default, this installation will create a folder<a class="ulink" href="http://C:%5Cgstreamer"> C:\gstreamer</a> on your machine. The<code class="literal"> bin</code> directory within this folder contains runtime libraries needed while using GStreamer.</p><p>Next, install the Python bindings for GStreamer. The binary distribution is available on the same website. Use the executable<code class="literal"> Pygst-0.10.15.1-Python2.6.exe</code> pertaining to Python 2.6. The version should be 0.10.15 or higher.</p><div><div><h3 class="title"><a id="note04"/>Note</h3><p>GStreamer WinBuilds appears to be an independent project. It is based on the OSSBuild developing suite. Visit<a class="ulink" href="http://code.google.com/p/ossbuild/"> http://code.google.com/p/ossbuild/</a> for more information. It could happen that the GStreamer binary built with Python 2.6 is no longer available on the mentioned website at the time you are reading this book. Therefore, it is advised that you should contact the developer community of OSSBuild. Perhaps they might help you out!</p></div></div><p>Alternatively, you can build GStreamer from source on the Windows platform, using a Linux-like environment for Windows, such as Cygwin (http://www.cygwin.com/). Under this environment, you can first install dependent software packages such as Python 2.6, gcc compiler, and others. Download the<code class="literal"> gst-python-0.10.17.2.tar.gz</code> package from the GStreamer website<a class="ulink" href="http://www.gstreamer.net/"> http://www.gstreamer.net/</a>. Then extract this package and install it from sources using the Cygwin environment. The<code class="literal"> INSTALL</code> file within this package will have installation instructions.</p></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec02"/>Other platforms</h3></div></div></div><p>Many of the Linux distributions provide GStreamer package. You can search for the appropriate<code class="literal"> gst-python</code> distribution (for Python 2.6) in the package repository. If such a package is not available, install<code class="literal"> gst-python</code> from the source as discussed in the earlier the<em> Windows platform</em> section.<a id="id188" class="indexterm"/>
</p><p>If you are a Mac OS X user, visit<a class="ulink" href="http://py26-gst-python.darwinports.com/"> http://py26-gst-python.darwinports.com/</a>. It has detailed instructions on how to download and install the package<code class="literal"> Py26-gst-python version 0.10.17</code> (or higher).<a id="id189" class="indexterm"/>
</p><div><div><h3 class="title"><a id="note05"/>Note</h3><p>Mac OS X 10.5.x (Leopard) comes with the Python 2.5 distribution. If you are using packages using this default version of Python, GStreamer Python bindings using Python 2.5 are available on the darwinports website:<a class="ulink" href="http://gst-python.darwinports.com/"> http://gst-python.darwinports.com/</a>
</p></div></div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec02"/>PyGobject</h2></div></div></div><p>There is a free multiplatform software utility library called 'GLib'. It provides data structures such as hash maps, linked lists, and so on. It also supports the creation of threads. The 'object system' of GLib is called<strong> GObject</strong>. Here, we need to install the Python bindings for GObject. The Python bindings are available on the PyGTK website at:<a class="ulink" href="http://www.pygtk.org/downloads.html"> http://www.pygtk.org/downloads.html</a>.<a id="id190" class="indexterm"/>
</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec03"/>Windows platform</h3></div></div></div><p>The binary installer is available on the PyGTK website. The complete URL is:<a class="ulink" href="http://ftp.acc.umu.se/pub/GNOME/binaries/win32/pygobject/2.20/"> http://ftp.acc.umu.se/pub/GNOME/binaries/win32/pygobject/2.20/</a>. Download and install version 2.20 for Python 2.6.<a id="id191" class="indexterm"/>
</p></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec04"/>Other platforms</h3></div></div></div><p>For Linux, the source tarball is available on the PyGTK website. There could even be binary distribution in the package repository of your Linux operating system. The direct link to the Version 2.21 of PyGObject (source tarball) is:<a class="ulink" href="http://ftp.gnome.org/pub/GNOME/sources/pygobject/2.21/"> http://ftp.gnome.org/pub/GNOME/sources/pygobject/2.21/</a>.<a id="id192" class="indexterm"/>
</p><p>If you are a Mac user and you have Python 2.6 installed, a distribution of PyGObject is available at<a class="ulink" href="http://py26-gobject.darwinports.com/"> http://py26-gobject.darwinports.com/</a>. Install version 2.14 or later.</p></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec03"/>Summary of installation prerequisites</h2></div></div></div><p>The following table summarizes the packages needed for this chapter.</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Package</p>
</th><th style="text-align: left" valign="bottom">
<p>Download location</p>
</th><th style="text-align: left" valign="bottom">
<p>Version</p>
</th><th style="text-align: left" valign="bottom">
<p>Windows platform</p>
</th><th style="text-align: left" valign="bottom">
<p>Linux/Unix/OS X platforms</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>GStreamer</p>
</td><td style="text-align: left" valign="top">
<p>
<a class="ulink" href="http://www.gstreamer.net/">http://www.gstreamer.net/</a>
</p>
</td><td style="text-align: left" valign="top">
<p>0.10.5 or later</p>
</td><td style="text-align: left" valign="top">
<p>Install using binary distribution available on the Gstreamer WinBuild website:</p>
<p>
<a class="ulink" href="http://www.gstreamer-winbuild.ylatuya.es/doku.php?id=download">http://www.gstreamer-winbuild.ylatuya.es/doku.php?id=download</a>
</p>
<p>Use<code class="literal"> GStreamerWinBuild-0.10.5.1.exe</code> (or later version if available).</p>
</td><td style="text-align: left" valign="top">
<p>Linux: Use GStreamer distribution in package repository.</p>
<p>Mac OS X: Download and install by following instructions on the website:<a class="ulink" href="http://gstreamer.darwinports.com/"> http://gstreamer.darwinports.com/</a>.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Python Bindings for GStreamer</p>
</td><td style="text-align: left" valign="top">
<p>
<a class="ulink" href="http://www.gstreamer.net/">http://www.gstreamer.net/</a>
</p>
</td><td style="text-align: left" valign="top">
<p>0.10.15 or later for Python 2.6</p>
</td><td style="text-align: left" valign="top">
<p>Use binary provided by GStreamer WinBuild project. See<a class="ulink" href="http://www.gstreamer-winbuild.ylatuya.es"> http://www.gstreamer-winbuild.ylatuya.es</a> for details pertaining to Python 2.6.</p>
</td><td style="text-align: left" valign="top">
<p>Linux: Use gst-python distribution in the package repository.</p>
<p>Mac OS X: Use this package (if you are using Python2.6):<a class="ulink" href="http://py26-gst-python.darwinports.com/"> http://py26-gst-python.darwinports.com/</a>.</p>
<p>Linux/Mac: Build and install from the source tarball.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Python bindings for GObject "PyGObject"</p>
</td><td style="text-align: left" valign="top">
<p>Source distribution:</p>
<p>
<a class="ulink" href="http://www.pygtk.org/downloads.html">http://www.pygtk.org/downloads.html</a>
</p>
</td><td style="text-align: left" valign="top">
<p>2.14 or later for Python 2.6</p>
</td><td style="text-align: left" valign="top">
<p>Use binary package from</p>
<p>
<code class="literal">pygobject-2.20.0.win32-py2.6.exe</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Linux: Install from source if pygobject is not available in the package repository.</p>
<p>Mac: Use this package on darwinports (if you are using Python2.6) See<a class="ulink" href="http://py26-gobject.darwinports.com/"> http://py26-gobject.darwinports.com/</a> for details.</p>
</td></tr></tbody></table></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec04"/>Testing the installation</h2></div></div></div><p>Ensure that the GStreamer and its Python bindings are properly installed. It is simple to test this. Just start Python from the command line and type the following:<a id="id193" class="indexterm"/>
</p><div><pre class="programlisting">&gt;&gt;&gt;import pygst
</pre></div><p>If there is no error, it means the Python bindings are installed properly.</p><p>Next, type the following:</p><div><pre class="programlisting">&gt;&gt;&gt;pygst.require("0.10")
&gt;&gt;&gt;import gst
</pre></div><p>If this import is successful, we are all set to use GStreamer for processing audios and videos!</p><p>If<code class="literal"> import gst</code> fails, it will probably complain that it is unable to work some required DLL/shared object. In this case, check your environment variables and make sure that the PATH variable has the correct path to the<code class="literal"> gstreamer/bin</code> directory. The following lines of code in a Python interpreter show the typical location of the<code class="literal"> pygst</code> and<code class="literal"> gst</code> modules on the Windows platform.</p><div><pre class="programlisting">&gt;&gt;&gt; import pygst
&gt;&gt;&gt; pygst
&lt;module 'pygst' from 'C:\Python26\lib\site-packages\pygst.pyc'&gt;
&gt;&gt;&gt; pygst.require('0.10')
&gt;&gt;&gt; import gst
&gt;&gt;&gt; gst
&lt;module 'gst' from 'C:\Python26\lib\site-packages\gst-0.10\gst\__init__.pyc'&gt;
</pre></div><p>Next, test if PyGObject is successfully installed. Start the Python interpreter and try importing the<code class="literal"> gobject</code> module.</p><div><pre class="programlisting">&gt;&gt;import gobject
</pre></div><p>If this works, we are all set to proceed!</p></div></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec02"/>A primer on GStreamer</h1></div></div></div><p>In this chapter, we will be using GStreamer multimedia framework extensively. Before we move on to the topics that teach us various audio processing techniques, a primer on GStreamer is necessary.</p><p>So what is GStreamer? It is a framework on top of which one can develop multimedia applications. The rich set of libraries it provides makes it easier to develop applications with complex audio/video processing capabilities. Fundamental components of GStreamer are briefly explained in the coming sub-sections.</p><p>Comprehensive documentation is available on the GStreamer project website. GStreamer Application Development Manual is a very good starting point. In this section, we will briefly cover some of the important aspects of GStreamer. For further reading, you are recommended to visit the GStreamer project website:<a class="ulink" href="http://www.gstreamer.net/documentation/"> http://www.gstreamer.net/documentation/</a>
</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec05"/>gst-inspect and gst-launch</h2></div></div></div><p>We will start by learning the two important GStreamer commands. GStreamer can be run from the command line, by calling<code class="literal"> gst-launch-0.10.exe</code> (on Windows) or<code class="literal"> gst-launch-0.10</code> (on other platforms). The following command shows a typical execution of GStreamer on Linux. We will see what a<code class="literal"> pipeline</code> means in the next sub-section.<a id="id194" class="indexterm"/>
</p><div><pre class="programlisting">$gst-launch-0.10 pipeline_description
</pre></div><p>GStreamer has a plugin architecture. It supports a huge number of plugins. To see more details about any plugin in your GStreamer installation, use the command<code class="literal"> gst-inspect-0.10</code> (gst-inspect-0.10.exe on Windows). We will use this command quite often. Use of this command is illustrated here.</p><div><pre class="programlisting">$gst-inspect-0.10 decodebin
</pre></div><p>Here,<code class="literal"> decodebin</code> is a plugin. Upon execution of the preceding command, it prints detailed information about the plugin<code class="literal"> decodebin</code>.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec06"/>Elements and pipeline</h2></div></div></div><p>In GStreamer, the data flows in a pipeline. Various elements are connected together forming a pipeline, such that the output of the previous element is the input to the next one.<a id="id195" class="indexterm"/>
</p><p>A pipeline can be logically represented as follows:<a id="id196" class="indexterm"/>
</p><div><pre class="programlisting">Element1 ! Element2 ! Element3 ! Element4 ! Element5
</pre></div><p>Here,<code class="literal"> Element1</code> through to<code class="literal"> Element5</code> are the element objects chained together by the symbol<code class="literal"> !</code>. Each of the elements performs a specific task. One of the element objects performs the task of reading input data such as an audio or a video. Another element decodes the file read by the first element, whereas another element performs the job of converting this data into some other format and saving the output. As stated earlier, linking these element objects in a proper manner creates a pipeline.<a id="id197" class="indexterm"/>
</p><p>The concept of a pipeline is similar to the one used in Unix. Following is a Unix example of a pipeline. Here, the vertical separator<code class="literal"> |</code> defines the pipe.<a id="id198" class="indexterm"/>
</p><div><pre class="programlisting">$ls -la | more
</pre></div><p>Here, the<code class="literal"> ls -la</code> lists all the files in a directory. However, sometimes, this list is too long to be displayed in the shell window. So, adding<code class="literal"> | more</code> allows a user to navigate the data.</p><p>Now let's see a realistic example of running GStreamer from the command prompt.</p><div><pre class="programlisting">$ gst-launch-0.10 -v filesrc location=path/to/file.ogg ! decodebin ! audioconvert ! fakesink
</pre></div><p>For a Windows user, the<code class="literal"> gst</code> command name would be<code class="literal"> gst-launch-0.10.exe</code>. The pipeline is constructed by specifying different elements. The<code class="literal"> !symbol</code> links the adjacent elements, thereby forming the whole pipeline for the data to flow. For Python bindings of GStreamer, the abstract base class for pipeline elements is<code class="literal"> gst.Element</code>, whereas<code class="literal"> gst.Pipeline</code> class can be used to created pipeline instance. In a pipeline, the data is sent to a separate thread where it is processed until it reaches the end or a termination signal is sent.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec07"/>Plugins</h2></div></div></div><p>GStreamer is a plugin-based framework. There are several plugins available. A plugin is used to encapsulate the functionality of one or more GStreamer elements. Thus we can have a plugin where multiple elements work together to create the desired output. The plugin itself can then be used as an abstract element in the GStreamer pipeline. An example is<code class="literal"> decodebin</code>. We will learn about it in the upcoming sections. A comprehensive list of available plugins is available at the GStreamer website<a class="ulink" href="http://gstreamer.freedesktop.org"> http://gstreamer.freedesktop.org</a>. In this book, we will be using several of them to develop audio/video processing applications. For example, a plugin<code class="literal"> Playbin</code> will be used for audio playback. In almost all applications to be developed,<code class="literal"> decodebin</code> plugin will be used. For audio processing, the functionality provided by plugins such as<code class="literal"> gnonlin, audioecho, monoscope, interleave</code>, and so on will be used.<a id="id199" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec08"/>Bins</h2></div></div></div><p>In GStreamer, a bin is a container that manages the element objects added to it. A bin instance can be created using gst.Bin class. It is inherited from<code class="literal"> gst.Element</code> and can act as an abstract element representing a bunch of elements within it. A GStreamer plugin decodebin is a good example representing a bin. The decodebin contains decoder elements. It auto-plugs the decoder to create the decoding pipeline.<a id="id200" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec09"/>Pads</h2></div></div></div><p>Each element has some sort of<em> connection points</em> to handle data input and output. GStreamer refers to them as<em> pads</em>. Thus an element object can have one or more "receiver pads" termed as<strong> sink pads</strong> that accept data from the previous element in the pipeline. Similarly, there are 'source pads' that take the data out of the element as an input to the next element (if any) in the pipeline. The following is a very simple example that shows how source and sink pads are specified.<a id="id201" class="indexterm"/>
</p><div><pre class="programlisting">&gt;gst-launch-0.10.exe fakesrc num-bufferes=1 ! fakesink
</pre></div><p>The<code class="literal"> fakesrc</code> is the first element in the pipeline. Therefore, it only has a source pad. It transmits the data to the next<code class="literal"> linkedelement</code>, that is<code class="literal"> fakesink</code> which only has a sink pad to accept elements. Note that, in this case, since these are<code class="literal"> fakesrc</code> and<code class="literal"> fakesink</code>, just empty buffers are exchanged. A pad is defined by the class<code class="literal"> gst.Pad</code>. A pad can be attached to an element object using the<code class="literal"> gst.Element.add_pad()</code> method.<a id="id202" class="indexterm"/>
</p><p>The following is a diagrammatic representation of a GStreamer element with a pad. It illustrates two GStreamer elements within a pipeline, having a single source and sink pad.</p><div><img src="img/0165_05_01.jpg" alt="Pads"/></div><p>Now that we know how the pads operate, let's discuss some of special types of pads. In the example, we assumed that the pads for the element are always 'out there'. However, there are some situations where the element doesn't have the pads available all the time. Such elements request the pads they need at runtime. Such a pad is called a dynamic pad. Another type of pad is called ghost pad. These types are discussed in this section.</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec05"/>Dynamic pads</h3></div></div></div><p>Some objects such as<code class="literal"> decodebin</code> do not have pads defined when they are created. Such elements determine the type of pad to be used at the runtime. For example, depending on the media file input being processed, the<code class="literal"> decodebin</code> will create a pad. This is often referred to as<strong> dynamic pad</strong> or sometimes the<strong> available pad</strong> as it is not always available in elements such as<code class="literal"> decodebin</code>.<a id="id203" class="indexterm"/>
</p></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec06"/>Ghost pads</h3></div></div></div><p>As stated in the<em> Bins</em> section a<strong> bin</strong> object can act as an abstract element. How is it achieved? For that, the bin uses 'ghost pads' or 'pseudo link pads'. The ghost pads of a bin are used to connect an appropriate element inside it. A ghost pad can be created using<code class="literal"> gst.GhostPad</code> class.<a id="id204" class="indexterm"/>
</p></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec10"/>Caps</h2></div></div></div><p>The element objects send and receive the data by using the pads. The type of media data that the element objects will handle is determined by the<strong> caps</strong> (a short form for<strong> capabilities)</strong>. It is a structure that describes the media formats supported by the element. The caps are defined by the class<code class="literal"> gst.Caps</code>.<a id="id205" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec11"/>Bus</h2></div></div></div><p>A<code class="literal"> bus</code> refers to the object that delivers the message generated by GStreamer. A message is a<code class="literal"> gst.Message</code> object that informs the application about an event within the pipeline. A message is put on the bus using the<code class="literal"> gst.Bus.gst_bus_post()</code> method. The following code shows an example usage of the<code class="literal"> bus</code>.<a id="id206" class="indexterm"/>
</p><div><pre class="programlisting">1 bus = pipeline.get_bus()
2 bus.add_signal_watch()
3 bus.connect("message", message_handler)
</pre></div><p>The first line in the code creates a<code class="literal"> gst.Bus</code> instance. Here the pipeline is an instance of<code class="literal"> gst.PipeLine</code>. On the next line, we add a signal watch so that the bus gives out all the messages posted on that bus. Line 3 connects the signal with a Python method. In this example, the message is the signal string and the method it calls is<code class="literal"> message_handler</code>.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec12"/>Playbin/Playbin2</h2></div></div></div><p>Playbin is a GStreamer plugin that provides a high-level audio/video player. It can handle a number of things such as automatic detection of the input media file format, auto-determination of decoders, audio visualization and volume control, and so on. The following line of code creates a<code class="literal"> playbin</code> element.<a id="id207" class="indexterm"/>
</p><div><pre class="programlisting">playbin = gst.element_factory_make("playbin")
</pre></div><p>It defines a property called<code class="literal"> uri</code>. The<strong> URI</strong> (Uniform<strong> Resource Identifier)</strong> should be an absolute path to a file on your computer or on the Web. According to the GStreamer documentation, Playbin2 is just the latest unstable version but once stable, it will replace the Playbin.</p><p>A Playbin2 instance can be created the same way as a Playbin instance.</p><div><pre class="programlisting">gst-inspect-0.10 playbin2
</pre></div><p>With this basic understanding, let us learn about various audio processing techniques using GStreamer and Python.<a id="id208" class="indexterm"/>
</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec03"/>Playing music</h1></div></div></div><p>Given an audio file, one the first things you will do is to play that audio file, isn't it? In GStreamer, what basic elements do we need to play an audio? The essential elements are listed as follows.<a id="id209" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The first thing we need is to open an audio file for reading</li><li class="listitem" style="list-style-type: disc">Next, we need a decoder to transform the encoded information</li><li class="listitem" style="list-style-type: disc">Then, there needs to be an element to convert the audio format so that it is in a 'playable' format required by an audio device such as speakers</li><li class="listitem" style="list-style-type: disc">Finally, an element that will enable the actual playback of the audio file</li></ul></div><p>How will you play an audio file using the command-line version of GStreamer? One way to execute it using command line is as follows:</p><div><pre class="programlisting">$gstlaunch-0.10 filesrc location=/path/to/audio.mp3 ! decodebin ! audioconvert ! autoaudiosink
</pre></div><div><div><h3 class="title"><a id="note06"/>Note</h3><p>The<code class="literal"> autoaudiosink</code> automatically detects the correct audio device on your computer to play the audio. This was tested on a machine with Windows XP and it worked fine. If there is any error playing an audio, check if the audio device on your computer is working properly. You can also try using element<code class="literal"> sdlaudiosink</code> that outputs to the sound card via<code class="literal"> SDLAUDIO</code> . If this doesn't work, and you want to install a plugin for<code class="literal"> audiosink</code> here is a partial list of GStreamer plugins:<a class="ulink" href="http://www.gstreamer.net/data/doc/gstreamer/head/gst-plugins-good-plugins/html/"> http://www.gstreamer.net/data/doc/gstreamer/head/gst-plugins-good-plugins/html/</a>
</p><p>Mac OS X users can try installing<code class="literal"> osxaudiosink</code> if the default<code class="literal"> autoaudiosink</code> doesn't work.</p></div></div><p>The audio file should start playing with this command unless there are any missing plugins.</p></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec04"/>Time for action -  playing an audio: method 1</h1></div></div></div><p>There are a number of ways to play an audio using Python and GStreamer. Let's start with a simple one. In this section, we will use a command string, similar to what you would specify using the command-line version of GStreamer. This string will be used to construct a<code class="literal"> gst.Pipeline</code> instance in a Python program.<a id="id210" class="indexterm"/>
</p><p>So, here we go!<a id="id211" class="indexterm"/>
</p><div><ol class="orderedlist arabic"><li class="listitem">Start by creating an<code class="literal"> AudioPlayer</code> class in a Python source file. Just define the empty methods illustrated in the following code snippet. We will expand those in the later steps.<div><pre class="programlisting">1 import thread
2 import gobject
3 import pygst
4 pygst.require("0.10")
5 import gst
6
7 class AudioPlayer:
8 def __init__(self):
9 pass
10 def constructPipeline(self):
11 pass
12 def connectSignals(self):
13 pass
14 def play(self):
15 pass
16 def message_handler(self):
17 pass
18
19 # Now run the program
20 player = AudioPlayer()
21 thread.start_new_thread(player.play, ())
22 gobject.threads_init()
23 evt_loop = gobject.MainLoop()
24 evt_loop.run()
</pre></div></li><li class="listitem">Lines 1 to 5 in the code import the necessary modules. As discussed in the Installation prerequisites section, the package pygst is imported first. Then we call pygst.require to enable the import of gst module.</li><li class="listitem">Now focus on the code block between lines 19 to 24. It is the main execution code. It enables running the program until the music is played. We will use this or similar code throughout this book to run our audio application.<p>On line 21, the thread module is used to create a new thread for playing the audio. The method AudioPlayer.play is sent on this thread. The second argument of thread.start_new_thread is the list of arguments to be passed to the method play. In this example, we do not support any command-line arguments. Therefore, an empty tuple is passed. Python adds its own thread management functionality on top of the operating system threads. When such a thread makes calls to external functions (such as C functions), it puts the 'Global Interpreter Lock' on other threads until, for instance, the C function returns a value.
</p><p>The gobject.threads_init() is an initialization function for facilitating the use of Python threading within the gobject modules. It can enable or disable threading while calling the C functions. We call this before running the main event loop. The main event loop for executing this program is created using gobject on line 23 and this loop is started by the call evt_loop.run().
<a id="id212" class="indexterm"/>
</p></li><li class="listitem">Next, fill the<code class="literal"> AudioPlayer</code> class methods with the code. First, write the constructor of the class.<div><pre class="programlisting">1 def __init__(self):
2 self.constructPipeline()
3 self.is_playing = False
4 self.connectSignals()
</pre></div></li><li class="listitem">The pipeline is constructed by the method call on line 2. The flag self.is_playing is initialized to False. It will be used to determine whether the audio being played has reached the end of the stream. On line 4, a method self.connectSignals is called, to capture the messages posted on a bus. We will discuss both these methods next.</li><li class="listitem">The main driver for playing the sound is the following<code class="literal"> gst</code> command:<div><pre class="programlisting">"filesrc location=C:/AudioFiles/my_music.mp3 "\
"! decodebin ! audioconvert ! autoaudiosink"
</pre></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: none">The preceding string has four elements separated by the symbol !. These elements represent the components we briefly discussed earlier.</li></ul></div></li><li class="listitem">The first element<code class="literal"> filesrc location=C:/AudioFiles/my_music.mp3</code> defines the source element that loads the audio file from a given location. In this string, just replace the audio file path represented by<code class="literal"> location</code> with an appropriate file path on your computer. You can also specify a file on a disk drive.<div><div><h3 class="title"><a id="note07"/>Note</h3><p>If the filename contains namespaces, make sure you specify the path within quotes. For example, if the filename is my sound.mp3, specify it as follows:<code class="literal"> filesrc location =\"C:/AudioFiles/my sound.mp3\</code>"</p></div></div></li><li class="listitem">The next element loads the file. This element is connected to a<code class="literal"> decodebin</code>. As discussed earlier, the<code class="literal"> decodebin</code> is a plugin to GStreamer and it inherits<code class="literal"> gst.Bin</code>. Based on the input audio format, it determines the right type of decoder element to use.<a id="id213" class="indexterm"/><p>The third element is audioconvert. It translates the decoded audio data into a format playable by the audio device.
</p><p>The final element, autoaudiosink, is a plugin; it automatically detects the audio sink for the audio output.
</p><p>We have sufficient information now to create an instance of gst.Pipeline. Write the following method.
</p><div><pre class="programlisting">1 def constructPipeline(self):
2 myPipelineString = \
3 "filesrc location=C:/AudioFiles/my_music.mp3 "\
4 "! decodebin ! audioconvert ! autoaudiosink"
5 self.player = gst.parse_launch(myPipelineString)
</pre></div><p>An instance of gst.Pipeline is created on line 5, using the gst.parse_launch method.
</p></li><li class="listitem">Now write the following method of class<code class="literal"> AudioPlayer</code>.<div><pre class="programlisting">1 def connectSignals(self):
2 # In this case, we only capture the messages
3 # put on the bus.
4 bus = self.player.get_bus()
5 bus.add_signal_watch()
6 bus.connect("message", self.message_handler)
</pre></div><p>On line 4, an instance of gst.Bus is created. In the introductory section on GStreamer, we already learned what the code between lines 4 to 6 does. This bus has the job of delivering the messages posted on it from the streaming threads. The add_signal_watch call makes the bus emit the message signal for each message posted. This signal is used by the method message_handler to take appropriate action.
</p><p>Write the following method:
</p><div><pre class="programlisting">1 def play(self):
2 self.is_playing = True
3 self.player.set_state(gst.STATE_PLAYING)
4 while self.is_playing:
5 time.sleep(1)
6 evt_loop.quit()
</pre></div><p>On line 2, we set the state of the gst pipeline to gst.STATE_PLAYING to start the audio streaming. The flag self.is_playing controls the while loop on line 4. This loop ensures that the main event loop is not terminated before the end of the audio stream is reached. Within the loop the call to time.sleep just buys some time for the audio streaming to finish. The value of flag is changed in the method message_handler that watches for the messages from the bus. On line 6, the main event loop is terminated. This gets called when the end of stream message is emitted or when some error occurs while playing the audio.
</p></li><li class="listitem">Next, develop method<code class="literal"> AudioPlayer.message_handler</code>. This method sets the appropriate flag to terminate the main loop and is also responsible for changing the playing state of the pipeline.<a id="id214" class="indexterm"/><div><pre class="programlisting">1 def message_handler(self, bus, message):
2 # Capture the messages on the bus and
3 # set the appropriate flag.
4 msgType = message.type
5 if msgType == gst.MESSAGE_ERROR:
6 self.player.set_state(gst.STATE_NULL)
7 self.is_playing = False
8 print "\n Unable to play audio. Error: ", \
9 message.parse_error()
10 elif msgType == gst.MESSAGE_EOS:
11 self.player.set_state(gst.STATE_NULL)
12 self.is_playing = False
</pre></div></li><li class="listitem">In this method, we only check two things: whether the message on the bus says the streaming audio has reached its end (gst.MESSAGE_EOS ) or if any error occurred while playing the audio stream (gst.MESSAGE_ERROR ). For both these messages, the state of the gst pipeline is changed from gst.STATE_PLAYING to gst.STATE_NULL. The self.is_playing flag is updated to instruct the program to terminate the main event loop.<p>We have defined all the necessary code to play the audio. Save the file as PlayingAudio.py and run the application from the command line as follows:
</p><div><pre class="programlisting">$python PlayingAudio.py
</pre></div></li></ol></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: none">This will begin playback of the input audio file. Once it is done playing, the program will be terminated. You can press Ctrl + C on Windows or Linux to interrupt the playing of the audio file. It will terminate the program.</li></ul></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec13"/>What just happened?</h2></div></div></div><p>We developed a very simple audio player, which can play an input audio file. The code we wrote covered some of the most important components of GStreamer. These components will be useful throughout this chapter. The core component of the program was a GStreamer pipeline that had instructions to play the given audio file. Additionally, we learned how to create a thread and then start a<code class="literal"> gobject</code> event loop to ensure that the audio file is played until the end.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec14"/>Have a go hero play audios from a playlist</h2></div></div></div><p>The simple audio player we developed can only play a single audio file, whose path is hardcoded in the constructed GStreamer pipeline. Modify this program so it can play audios in a "playlist". In this case, play list should define full paths of the audio files you would like to play, one after the other. For example, you can specify the file paths as arguments to this application or load the paths defined in a text file or load all audio files from a directory. Hint: In a later section, we will develop an audio file converter utility. See if you can use some of that code here.<a id="id215" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec15"/>Building a pipeline from elements</h2></div></div></div><p>In the last section, a gst.Pipeline was automatically constructed for us by the gst.parse_launch method. All it required was an appropriate command string, similar to the one specified while running the command-line version of GStreamer. The creation and linking of elements was handled internally by this method. In this section, we will see how to construct a pipeline by adding and linking individual element objects. 'GStreamer Pipeline' construction is a fundamental technique that we will use throughout this chapter and also in other chapters related to audio and video processing.<a id="id216" class="indexterm"/>
</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec05"/>Time for action -  playing an audio: method 2</h1></div></div></div><p>We have already developed code for playing an audio. Let's now tweak the method<code class="literal"> AudioPlayer.constructPipeline</code> to build the<code class="literal"> gst.Pipeline</code> using different element objects.</p><div><ol class="orderedlist arabic"><li class="listitem">Rewrite the<code class="literal"> constructPipeline</code> method as follows. You can also download the file<code class="literal"> PlayingAudio.py</code> from the Packt website for reference. This file has all the code we discussed in this and previous sections.<div><pre class="programlisting">1 def constructPipeline(self):
2 self.player = gst.Pipeline()
3 self.filesrc = gst.element_factory_make("filesrc")
4 self.filesrc.set_property("location",
5 "C:/AudioFiles/my_music.mp3")
6
7 self.decodebin = gst.element_factory_make("decodebin",
8 "decodebin")
9 # Connect decodebin signal with a method.
10 # You can move this call to self.connectSignals)
11 self.decodebin.connect("pad_added",
12 self.decodebin_pad_added)
13
14 self.audioconvert = \
15 gst.element_factory_make("audioconvert",
16 "audioconvert")
17
18 self.audiosink = \
19 gst.element_factory_make("autoaudiosink",
20 "a_a_sink")
21
22 # Construct the pipeline
23 self.player.add(self.filesrc, self.decodebin,
24 self.audioconvert, self.audiosink)
25 # Link elements in the pipeline.
26 gst.element_link_many(self.filesrc, self.decodebin)
27 gst.element_link_many(self.audioconvert,self.audiosink)
</pre></div></li><li class="listitem">We begin by creating an instance of class<code class="literal"> gst.Pipeline</code>.</li><li class="listitem">Next, on line 2, we create the element for loading the audio file. Any new<code class="literal"> gst</code> element can be created using the API method,<code class="literal"> gst.element_factory_make</code>. The method takes the element name (string) as an argument. For example, on line 3, this argument is specified as<code class="literal"> "filesrc</code>" in order to create an instance of element<code class="literal"> GstFileSrc</code>. Each element will have a set of properties. The path of the input audio file is stored in a property<code class="literal"> location</code> of<code class="literal"> self.filesrc</code> element. This property is set on line 4. Replace the file path string with an appropriate audio file path.<a id="id217" class="indexterm"/><div><div><h3 class="title"><a id="tip13"/>Tip</h3><p>You can get a list of all properties by running the<code class="literal">'gst-inspect-0.10</code>' command from a console window. See the introductory section on<strong> GSreamer</strong> for more details.</p></div></div></li><li class="listitem">The second optional argument serves as a custom name for the created object. For example, on line 20, the name for the<code class="literal"> autoaudiosink</code> object is specified as<code class="literal"> a_a_sink</code>. Like this, we create all the essential elements necessary to build the pipeline.</li><li class="listitem">On line 23 in the code, all the elements are put in the pipeline by calling the<code class="literal"> gst.Pipeline.add</code> method.</li><li class="listitem">The method<code class="literal"> gst.element_link_many</code> establishes connection between two or more elements for the audio data to flow between them. The elements are linked together by the code on lines 26 and 27. However, notice that we haven't linked together the elements<code class="literal"> self.decodebin</code> and<code class="literal"> self.audioconvert</code>. Why? That's up next.</li><li class="listitem">We cannot link the<code class="literal"> decodebin</code> element with the<code class="literal"> audioconvert</code> element at the time the pipeline is created. This is because<code class="literal"> decodebin</code> uses dynamic pads. These pads are not available for connection with the<code class="literal"> audioconvert</code> element when the pipeline is created. Depending upon the input data , it will create a pad. Thus, we need to watch out for a signal that is emitted when the<code class="literal"> decodebin</code> adds a pad! How do we do that? It is done by the code on line 11 in the code snippet above. The "pad-added" signal is connected with a method,<code class="literal"> decodebin_pad_added</code>. Whenever<code class="literal"> decodebin</code> adds a dynamic pad, this method will get called.<a id="id218" class="indexterm"/></li><li class="listitem">Thus, all we need to do is to manually establish a connection between<code class="literal"> decodebin</code> and<code class="literal"> audioconvert</code> elements in the method<code class="literal"> decodebin_pad_added</code>. Write the following method.<div><pre class="programlisting">1 def decodebin_pad_added(self, decodebin, pad ):
2 caps = pad.get_caps()
3 compatible_pad = \
4 self.audioconvert.get_compatible_pad(pad, caps)
5
6 pad.link(compatible_pad)
</pre></div></li><li class="listitem">The method takes the element (in this case it is self.decodebin ) and pad as arguments. The pad is the new pad for the decodebin element. We need to link this pad with the appropriate one on self.audioconvert.</li><li class="listitem">On line 2 in this code snippet, we find out what type of media data the pad handles. Once the capabilities (caps) are known, we pass this information to the method<code class="literal"> get_compatible_pad</code> of object<code class="literal"> self.audioconvert</code>. This method returns a compatible pad which is then linked with<code class="literal"> pad</code> on line 6.</li><li class="listitem">The rest of the code is identical with the one illustrated in the earlier section. You can run this program the same way described earlier.</li></ol></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec16"/>What just happened?</h2></div></div></div><p>We learned some very crucial components of GStreamer framework. With the simple audio player as an example, we created a GStreamer pipeline 'from scratch' by creating various element objects and linking them together. We also learned how to connect two elements by 'manually' linking their pads and why that was required for the element<code class="literal"> self.decodebin</code>.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec17"/>Pop Quiz  - element linking</h2></div></div></div><p>In the earlier example, most of the elements in the pipeline linked using<code class="literal"> gst.element_link_many</code> in method<code class="literal"> AudioPlayer.constructPipeline</code>. However, we did not link the elements<code class="literal"> self.decodebin</code> and<code class="literal"> self.audioconvert</code> at the time when the pipeline was constructed. Why? Choose the correct answer from the following.</p><div><ol class="orderedlist arabic"><li class="listitem">We were just trying out a different technique of manually linking these elements together.</li><li class="listitem"><code class="literal"> Decodebin</code> uses a dynamic pad that is created at the runtime. This pad is not available when the pipeline is created.</li><li class="listitem">We don't need to link these elements in the pipeline. The media data will just find its way somehow.</li><li class="listitem">What are you talking about? It is impossible to connect<code class="literal"> decodebin</code> and<code class="literal"> audioconvert</code> elements no matter what you try.</li></ol></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec18"/>Playing an audio from a website</h2></div></div></div><p>If there is an audio somewhere on a website that you would like to play, we can pretty much use the same AudioPlayer class developed earlier. In this section, we will illustrate the use of gst.Playbin2 to play an audio by specifying a URL. The code snippet below shows the revised AudioPlayer.constructPipeline method. The name of this method should be changed as it is playbin object that it creates.<a id="id219" class="indexterm"/>
</p><div><pre class="programlisting">1 def constructPipeline(self):
2 file_url = "http://path/to/audiofile.wav"
3 buf_size = 1024000
4 self.player = gst.element_factory_make("playbin2")
5 self.player.set_property("uri", file_url)
6 self.player.set_property("buffer-size", buf_size)
7 self.is_playing = False
8 self.connectSignals()
</pre></div><p>On line 4, the gst.Playbin2 element is created using<code class="literal"> gst.element_factory_make</code> method. The argument to this method is a string that describes the element to be created. In this case it is "playbin2" . You can also define a custom name for this object by supplying an optional second argument to this method. Next, on line 5 and 6, we assign values to the properties uri and buffer-size. Set the uri property to an appropriate URL , the full path to the audio file you would like to play.</p><div><div><h3 class="title"><a id="tip14"/>Tip</h3><p>Note: When you execute this program, Python application tries to access the Internet. The anti-virus installed on your computer may block the program execution. In this case, you will need to allow this program to access the Internet. Also, you need to be careful of hackers. If you get the<code class="literal"> fil_url</code> from an untrusted source, perform a safety check such as<code class="literal"> assert not re.match("file://", file_url)</code>.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec19"/>Have a go hero use 'playbin' to play local audios</h2></div></div></div><p>In the last few sections, we learned different ways to play an audio file using Python and GStreamer. In the previous section, you must have noticed another simple way to achieve this, using a playbin or playbin2 object to play an audio. In the previous section, we learned how to play an audio file from a URL. Modify this code so that this program can now play audio files located in a drive on your computer. Hint: You will need to use the correct "uri" path. Convert the file path using Python's module<code class="literal"> urllib.pathname2url</code> and then append it to the string:<code class="literal"> "file://</code>".<a id="id220" class="indexterm"/>
</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec06"/>Converting audio file format</h1></div></div></div><p>Suppose you have a big collection of songs in wav file format that you would like to load on a cell phone. But you find out that the cell phone memory card doesn't have enough space to hold all these. What will you do? You will probably try to reduce the size of the song files right? Converting the files into mp3 format will reduce the size. Of course you can do it using some media player. Let's learn how to perform this conversion operation using Python and GStreamer. Later we will develop a simple command-line utility that can be used to perform a batch conversion for all the files you need.<a id="id221" class="indexterm"/>
</p><div><ol class="orderedlist arabic"><li class="listitem">Like in the earlier examples, let's first list the important building blocks we need to accomplish file conversion. The first three elements remain the same.</li><li class="listitem">As before, the first thing we need is to load an audio file for reading.</li><li class="listitem">Next, we need a decoder to transform the encoded information.</li><li class="listitem">Then, there needs to be an element to convert the raw audio buffers into an appropriate format.</li><li class="listitem">An encoder is needed that takes the raw audio data and encodes it to an appropriate file format to be written.</li><li class="listitem">An element where the encoded data will be streamed to is needed. In this case it is our output audio file.</li></ol></div><p>Okay, what's next? Before jumping into the code, first check if you can achieve what you want using the command-line version of GStreamer.</p><div><pre class="programlisting">$gstlaunch-0.10.exe filesrc location=/path/to/input.wav ! decodebin ! audioconvert ! lame ! Filesink location=/path/to/output.mp3
</pre></div><p>Specify the correct input and output file paths and run this command to convert a wave file to an mp3. If it works, we are all set to proceed. Otherwise check for missing plugins.</p><p>You should refer to the GStreamer API documentation to know more about the properties of various elements illustrated above. Trust me, the<code class="literal"> gst-inspect-0.10</code> (or<code class="literal"> gst-inspect-0.10.exe</code> for Windows users) command is a very handy tool that will help you understand the components of a GStreamer plugin. The instructions on running this tool are already discussed earlier in this chapter.<a id="id222" class="indexterm"/>
</p></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec07"/>Time for action -  audio file format converter</h1></div></div></div><p>Let's write a simple audio file converter. This utility will batch process input audio files and save them in a user-specified file format. To get started, download the file AudioConverter.py from the Packt website. This file can be run from the command line as:<a id="id223" class="indexterm"/>
</p><div><pre class="programlisting">python AudioConverter.py [options]
</pre></div><p>Where, the<code class="literal"> [options]</code> are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">--input_dir</code> : The directory from which to read the input audio file(s) to be converted.</li><li class="listitem" style="list-style-type: disc"><code class="literal">--input_format:</code> The audio format of the input files. The format should be in a supported list of formats. The supported formats are "mp3", "ogg", and "wav". If no format is specified, it will use the default format as ".wav".</li><li class="listitem" style="list-style-type: disc"><code class="literal">--output_dir</code> : The output directory where the converted files will be saved. If no output directory is specified, it will create a folder<code class="literal"> OUTPUT_AUDIOS</code> within the input directory.</li><li class="listitem" style="list-style-type: disc"><code class="literal">--output_format:</code> The audio format of the output file. Supported output formats are "wav" and "mp3".<p>Let's write this code now.
</p></li></ul></div><div><ol class="orderedlist arabic"><li class="listitem">Start by importing necessary modules.<div><pre class="programlisting">import os, sys, time
import thread
import getopt, glob
import gobject
import pygst
pygst.require("0.10")
import gst
</pre></div></li><li class="listitem">Now declare the following class and the utility function. As you will notice, several of the methods have the same names as before. The underlying functionality of these methods will be similar to what we already discussed. In this section we will review only the most important methods in this class. You can refer to file<code class="literal"> AudioConverter.py</code> for other methods or develop those on your own.<a id="id224" class="indexterm"/><div><pre class="programlisting">def audioFileExists(fil):
return os.path.isfile(fil)
class AudioConverter:
def __init__(self):
pass
def constructPipeline(self):
pass
def connectSignals(self):
pass
def decodebin_pad_added(self, decodebin, pad):
pass
def processArgs(self):
pass
def convert(self):
pass
def convert_single_audio(self, inPath, outPath):
pass
def message_handler(self, bus, message):
pass
def printUsage(self):
pass
def printFinalStatus(self, inputFileList,
starttime, endtime):
pass
# Run the converter
converter = AudioConverter()
thread.start_new_thread(converter.convert, ())
gobject.threads_init()
evt_loop = gobject.MainLoop()
evt_loop.run()
</pre></div></li><li class="listitem">Look at the last few lines of code above. This is exactly the same code we used in the Playing Music section. The only difference is the name of the class and its method that is put on the thread in the call<code class="literal"> thread.start_new_thread</code>. At the beginning, the function<code class="literal"> audioFileExists()</code> is declared. It will be used to check if the specified path is a valid file path.</li><li class="listitem">Now write the constructor of the class. Here we do initialization of various variables.<a id="id225" class="indexterm"/><div><pre class="programlisting">def __init__(self):
# Initialize various attrs
self.inputDir = os.getcwd()
self.inputFormat = "wav"
self.outputDir = ""
self.outputFormat = ""
self.error_message = ""
self.encoders = {"mp3":"lame",
"wav": "wavenc"}
self.supportedOutputFormats = self.encoders.keys()
self.supportedInputFormats = ("ogg", "mp3", "wav")
self.pipeline = None
self.is_playing = False
self.processArgs()
self.constructPipeline()
self.connectSignals()
</pre></div></li><li class="listitem">The self.supportedOutputFormats is a tuple that stores the supported output formats.<code class="literal"> self.supportedInputFormats</code> is a list obtained from the keys of<code class="literal"> self.encoders</code> and stores the supported input formats. These objects are used in<code class="literal"> self.processArguments</code> to do necessary checks. The dictionary<code class="literal"> self.encoders</code> provides the correct type of encoder string to be used to create an encoder element object for the GStreamer pipeline. As the name suggests, the call to<code class="literal"> self.constructPipeline()</code> builds a<code class="literal"> gst.Pipeline</code> instance and various signals are connected using<code class="literal"> self.connectSignals()</code>.</li><li class="listitem">Next, prepare a GStreamer pipeline.<div><pre class="programlisting">def constructPipeline(self):
self.pipeline = gst.Pipeline("pipeline")
self.filesrc = gst.element_factory_make("filesrc")
self.decodebin = gst.element_factory_make("decodebin")
self.audioconvert = gst.element_factory_make(
"audioconvert")
self.filesink = gst.element_factory_make("filesink")
encoder_str = self.encoders[self.outputFormat]
self.encoder= gst.element_factory_make(encoder_str)
self.pipeline.add( self.filesrc, self.decodebin,
self.audioconvert, self.encoder,
self.filesink)
gst.element_link_many(self.filesrc, self.decodebin)
gst.element_link_many(self.audioconvert, self.encoder,
self.filesink)
</pre></div></li><li class="listitem">This code is similar to the one we developed in the<em> Playing Music</em> sub-section. However there are some noticeable differences. In the Audio Player example, we used the<code class="literal"> autoaudiosink</code> plugin as the last element. In the Audio Converter, we have replaced it with elements<code class="literal"> self.encoder</code> and<code class="literal"> self.filesink</code>. The former encodes the audio data coming out of the<code class="literal"> self.audioconvert</code>. The encoder will be linked to the sink element. In this case, it is a<code class="literal"> filesink</code>. The<code class="literal"> self.filesink</code> is where the audio data is written to a file given by the<code class="literal"> location</code> property.<a id="id226" class="indexterm"/></li><li class="listitem">The encoder string,<code class="literal"> encoder_str</code> determines the type of encoder element to create. For example, if the output format is specified as "mp3" the corresponding encoder to use is "lame" mp3 encoder. You can run the gst-inspect-0.10 command to know more about the<code class="literal"> lame</code> mp3 encoder. The following command can be run from shell on Linux.<div><pre class="programlisting">$gst-inspect-0.10 lame
</pre></div></li><li class="listitem">The elements are added to the pipeline and then linked together. As before, the<code class="literal"> self.decodebin</code> and<code class="literal"> self.audioconvert</code> are not linked in this method as the<code class="literal"> decodebin</code> plugin uses dynamic pads. The<code class="literal"> pad_added</code> signal from the<code class="literal"> self.decodebin</code> is connected in the<code class="literal"> self.connectSignals()</code> method.</li><li class="listitem">Another noticeable change is that we have not set the<code class="literal"> location</code> property for both,<code class="literal"> self.filesrc</code> and<code class="literal"> self.filesink</code>. These properties will be set at the runtime. The input and output file locations keep on changing as the tool is a batch processing utility.</li><li class="listitem">Let's write the main method that controls the conversion process.<div><pre class="programlisting">1 def convert(self):
2 pattern = "*." + self.inputFormat
3 filetype = os.path.join(self.inputDir, pattern)
4 fileList = glob.glob(filetype)
5 inputFileList = filter(audioFileExists, fileList)
6
7 if not inputFileList:
8 print "\n No audio files with extension %s "\
9 "located in dir %s"%(
10 self.outputFormat, self.inputDir)
11 return
12 else:
13 # Record time before beginning audio conversion
14 starttime = time.clock()
15 print "\n Converting Audio files.."
16
17 # Save the audio into specified file format.
18 # Do it in a for loop If the audio by that name already
19 # exists, do not overwrite it
20 for inPath in inputFileList:
21 dir, fil = os.path.split(inPath)
22 fil, ext = os.path.splitext(fil)
23 outPath = os.path.join(
24 self.outputDir,
25 fil + "." + self.outputFormat)
26
27
28 print "\n Input File: %s%s, Conversion STARTED..."\
29 % (fil, ext)
30 self.convert_single_audio(inPath, outPath)
31 if self.error_message:
32 print "\n Input File: %s%s, ERROR OCCURED" \
33 % (fil, ext)
34 print self.error_message
35 else:
36 print "\nInput File: %s%s,Conversion COMPLETE"\
37 % (fil, ext)
38
39 endtime = time.clock()
40
41 self.printFinalStatus(inputFileList, starttime,
42 endtime)
43 evt_loop.quit()
</pre></div></li><li class="listitem">The code between lines 2 to 26 is similar to the one developed in the Image File conversion utility in this book. Refer to the Reading and Writing Images section of<a class="link" href="ch02.html" title="Chapter 2. Working with Images"> Chapter 2</a> to know what that code does. All the input audio files are collected in the list<code class="literal"> inputFileList</code> by the code between lines 2 to 6 . Then, we loop over each of these files. First, the output file path is derived based on user inputs and then the input file path.<a id="id227" class="indexterm"/></li><li class="listitem">The highlighted line of code is the workhorse method,<code class="literal"> AudioConverter.convert_single_audio</code>, that actually does the job of converting the input audio. We will discuss that method next. On line 43, the main event loop is terminated. The rest of the code in method convert is self-explanatory.</li><li class="listitem">The code in method<code class="literal"> convert_single_audio</code> is illustrated below.<a id="id228" class="indexterm"/><div><pre class="programlisting">1 def convert_single_audio(self, inPath, outPath):
2 inPth = repr(inPath)
3 outPth = repr(outPath)
4
5 # Set the location property for file source and sink
6 self.filesrc.set_property("location", inPth[1:-1])
7 self.filesink.set_property("location", outPth[1:-1])
8
9 self.is_playing = True
10 self.pipeline.set_state(gst.STATE_PLAYING)
11 while self.is_playing:
12 time.sleep(1)
</pre></div></li><li class="listitem">As mentioned in the last step,<code class="literal"> convert_single_audio</code> method is called within a for loop in the<code class="literal"> self.convert()</code> . The for loop iterates over a list containing input audio file paths. The input and output file paths are given as arguments to this method. The code between lines 8-12 looks more or less similar to<code class="literal"> AudioPlayer.play()</code> method illustrated in the<em> Play audio section</em>. The only difference is the main event loop is not terminated in this method. Earlier we did not set the location property for the file source and sink. These properties are set on lines 6 and 7 respectively.</li><li class="listitem">Now what's up with the code on lines 2 and 3? The call<code class="literal"> repr(inPath)</code> returns a printable representation of the string<code class="literal"> inPath</code>. The<code class="literal"> inPath</code> is obtained from the 'for loop'. The<code class="literal"> os.path.normpath</code> doesn't work on this string. In Windows, if you directly use<code class="literal"> inPath</code>, GStreamer will throw an error while processing such a path string. One way to handle this is to use<code class="literal"> repr(string)</code> , which will return the whole string including the quotes . For example: if<code class="literal"> inPath</code> be "C:/AudioFiles/my_music.mp3" , then<code class="literal"> repr(inPath)</code> will return<code class="literal"> "'C:\\\\AudioFiles\\\\my_music.mp3'</code>". Notice that it has two single quotes. We need to get rid of the extra single quotes at the beginning and end by slicing the string as<code class="literal"> inPth[1:-1]</code>. There could be some other better ways. You can come up with one and then just use that code as a path string!</li><li class="listitem">Let's quickly skim through a few more methods. Write these down:<div><pre class="programlisting">def connectSignals(self):
# Connect the signals.
# Catch the messages on the bus
bus = self.pipeline.get_bus()
bus.add_signal_watch()
bus.connect("message", self.message_handler)
# Connect the decodebin "pad_added" signal.
self.decodebin.connect("pad_added",
self.decodebin_pad_added)
def decodebin_pad_added(self, decodebin, pad):
caps = pad.get_caps()
compatible_pad=\
self.audioconvert.get_compatible_pad(pad, caps)
pad.link(compatible_pad)
</pre></div></li><li class="listitem">The<code class="literal"> connectSignal</code> method is identical to the one discussed in the<em> Playing music</em> section, except that we are also connecting the<code class="literal"> decodebin</code> signal with a method<code class="literal"> decodebin_pad_added</code>. Add a print statement to<code class="literal"> decodebin_pad_added</code> to check when it gets called. It will help you understand how the dynamic pad works! The program starts by processing the first audio file. The method<code class="literal"> convert_single_audio</code> gets called. Here, we set the necessary file paths. After that, it begins playing the audio file. At this time, the<code class="literal"> pad_added</code> signal is generated. Thus based on the input file data,<code class="literal"> decodebin</code> will create the pad.<a id="id229" class="indexterm"/></li><li class="listitem">The rest of the methods such as<code class="literal"> processArgs, printUsage</code>, and<code class="literal"> message_handler</code> are self-explanatory. You can review these methods from the file<code class="literal"> AudioConverter.py</code>.</li><li class="listitem">The audio converter should be ready for action now! Make sure that all methods are properly defined and then run the code by specifying appropriate input arguments. The following screenshot shows a sample run of audio conversion utility on Windows XP. Here, it will batch process all audio files in directory<code class="literal"> C:\AudioFiles</code> with extension<code class="literal"> .ogg</code> and convert them into mp3 file format . The resultant mp3 files will be created in directory<code class="literal"> C:\AudioFiles\OUTPUT_AUDIOS</code>.<div><img src="img/0165_5_2.jpg" alt="Time for action - audio file format converter"/></div></li></ol></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec20"/>What just happened?</h2></div></div></div><p>A basic audio conversion utility was developed in the previous section. This utility can batch-convert audio files with ogg or mp3 or wav format into user-specified output format (where supported formats are wav and mp3). We learned how to specify encoder and filesink elements and link them in the GStreamer pipeline. To accomplish this task, we also applied knowledge gained in earlier sections such as creation of GStreamer pipeline, capturing bus messages, running the main event loop, and so on.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec21"/>Have a go hero do more with audio converter</h2></div></div></div><p>The audio converter we wrote is fairly simple. It deserves an upgrade.<a id="id230" class="indexterm"/>
</p><p>Extend this application to support more audio output formats such as<code class="literal"> ogg, flac</code>, and so on. The following pipeline illustrated one way of converting an input audio file into ogg file format.</p><div><pre class="programlisting">filesrc location=input.mp3 ! decodebin ! audioconvert ! vorbisenc ! oggmux ! filesink location=output.ogg
</pre></div><p>Notice that we have an audio muxer, oggmux, that needs to be linked with encoder vorbisenc. Similarly, to create an MP4 audio file, it will need { faac ! mp4mux} as encoder and audio muxer. One of the simplest things to do is to define proper elements (such as encoder and muxer) and instead of constructing a pipeline from individual elements, use the<code class="literal"> gst.parse_launch</code> method we studied earlier and let it automatically create and link elements using the command string. You can create a pipeline instance each time the audio conversion is called for. But in this case you would also need to connect signals each time the pipeline is created. Another better and simpler way is to link the audio muxer in the<code class="literal"> AudioConverter.constructPipeline</code> method. You just need to check if it is needed based on the type of plugin you are using for encoding. In this case the code will be:</p><div><pre class="programlisting">gst.element_link_many(self.audioconvert, self.encoder,
self.audiomuxer, self.filesink)
</pre></div><p>The audio converter illustrated in this example takes input files of only a single audio file format. This can easily be extended to accept input audio files in all supported file formats (except for the type specified by the<code class="literal"> --output_format</code> option). The<code class="literal"> decodebin</code> should take care of decoding the given input data. Extend Audio Converter to support this feature. You will need to modify the code in the<code class="literal"> AudioConverter.convert()</code> method where the input file list is determined.<a id="id231" class="indexterm"/>
</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec08"/>Extracting part of an audio</h1></div></div></div><p>Suppose you have recorded a live concert of your favorite musician or a singer. You have saved all this into a single file with MP3 format but you would like to break this file into small pieces. There is more than one way to achieve this using Python and GStreamer. We will use the simplest and perhaps the most efficient way of cutting a small piece from an audio track. It makes use of an excellent GStreamer plugin, called Gnonlin.<a id="id232" class="indexterm"/>
</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec22"/>The Gnonlin plugin</h2></div></div></div><p>The multimedia editing can be classified as linear or non-linear. Non-linear multimedia editing enables control over the media progress in an interactive way. For example, it allows you to control the order in which the sources should be executed. At the same time it allows modifications to the position in a media track. While doing all this, note that the original source (such as an audio file) remains unchanged. Thus the editing is non-destructive. The Gnonlin or (G-Non-Linear) provides essential elements for non-linear editing of a multimedia. It has five major elements, namely,<code class="literal"> gnlfilesource, gnlurisource, gnlcomposition, gnloperation</code>, and<code class="literal"> gnlsource</code>. To know more about their properties, run gst-inspect-0.10 command on each of these elements.<a id="id233" class="indexterm"/>
</p><p>Here, we will only focus on the element gnlfilesource and a few of its properties. This is really a GStreamer bin element. Like decodebin, it determines which pads to use at the runtime. As the name suggests, it deals with the input media file. All you need to specify is the input media source it needs to handle. The media file format can be any of the supported media formats. The gnlfilesource defines a number of properties. To extract a chunk of an audio, we just need to consider three of them:<a id="id234" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">media-start:</code> The position in the input media file, which will become the start position of the extracted media. This is specified in nanoseconds.<a id="id235" class="indexterm"/></li><li class="listitem" style="list-style-type: disc"><code class="literal">media-duration:</code> Total duration of the extracted media file (beginning from<code class="literal"> media-start)</code>. This is specified in nanoseconds as well.<a id="id236" class="indexterm"/></li><li class="listitem" style="list-style-type: disc"><code class="literal">uri:</code> The full path of the input media file. For example, if it is a file on your local hard drive, the<code class="literal"> uri</code> will be something like<code class="literal"> file:///C:/AudioFiles/my_music.mp3</code>. If the file is located on a website, then the<code class="literal"> uri</code> will something of this sort:<code class="literal"> http://path/to/file.mp3</code>.<a id="id237" class="indexterm"/></li></ul></div><p>The gnlfilesource internally does operations like loading and decoding the file, seeking the track to the specified position, and so on. This makes our job easier. We just need to create basic elements that will process the information furnished by gnlfilesource, to create an output audio file. Now that we know the basics of gnlfilesource, let's try to come up with a GStreamer pipeline that will cut a portion of an input audio file.</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">First the<code class="literal"> gnlfilesource</code> element that does the crucial job of loading, decoding the file, seeking the correct start position, and finally presenting us with an audio data that represents the portion of track to be extracted.</li><li class="listitem" style="list-style-type: disc">An<code class="literal"> audioconvert</code> element that will convert this data into an appropriate audio format.</li><li class="listitem" style="list-style-type: disc">An encoder that encodes this data further into the final audio format we want.</li><li class="listitem" style="list-style-type: disc">A sink where the output data is dumped. This specifies the output audio file.</li></ul></div><p>Try running the following from the command prompt by replacing the uri and location paths with appropriate file paths on your computer.</p><div><pre class="programlisting">$gst-launch-0.10.exe gnlfilesource uri=file:///C:/my_music.mp3
media-start=0 media-duration=15000000000 !
audioconvert !
lame !
filesink location=C:/my_chunk.mp3
</pre></div><p>This should create an extracted audio file of duration 15 seconds, starting at the initial position on the original file. Note that the media-start and media-duration properties take the input in nanoseconds. This is really the essence of what we will do next.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec09"/>Time for action -  MP3 cutter!</h1></div></div></div><p>In this section we will develop a utility that will cut out a portion of an MP3 formatted audio and save it as a separate file.<a id="id238" class="indexterm"/>
</p><div><ol class="orderedlist arabic"><li class="listitem">Keep the file<code class="literal"> AudioCutter.py</code> handy. You can download it from the Packt website. Here we will only discuss important methods. The methods not discussed here are similar to the ones from earlier examples. Review the file<code class="literal"> AudioCutter.py</code> which has all the necessary source code to run this application.</li><li class="listitem">Start the usual way. Do the necessary imports and write the following skeleton code.<a id="id239" class="indexterm"/><div><pre class="programlisting">import os, sys, time
import thread
import gobject
import pygst
pygst.require("0.10")
import gst
class AudioCutter:
def __init__(self):
pass
def constructPipeline(self):
pass
def gnonlin_pad_added(self, gnonlin_elem, pad):
pass
def connectSignals(self):
pass
def run(self):
pass
def printFinalStatus(self):
pass
def message_handler(self, bus, message):
pass
#Run the program
audioCutter = AudioCutter()
thread.start_new_thread(audioCutter.run, ())
gobject.threads_init()
evt_loop = gobject.MainLoop()
evt_loop.run()
</pre></div></li><li class="listitem">The overall code layout looks familiar doesn't it? The code is very similar to the code we developed earlier in this chapter. The key here is the appropriate choice of the file source element and linking it with the rest of the pipeline! The last few lines of code create a thread with method AudioCutter.run and run the main event loop as seen before.</li><li class="listitem">Now fill in the constructor of the class. We will keep it simple this time. The things we need will be hardcoded within the constructor of the<code class="literal"> class AudioCutter</code>. It is very easy to implement a<code class="literal"> processArgs()</code> method as done on many occasions before. Replace the input and output file locations in the code snippet with a proper audio file path on your computer.<div><pre class="programlisting">def __init__(self):
self.is_playing = False
# Flag used for printing purpose only.
self.error_msg = ''
self.media_start_time = 100
self.media_duration = 30
self.inFileLocation = "C:\AudioFiles\my_music.mp3"
self.outFileLocation = "C:\AudioFiles\my_music_chunk.mp3"
self.constructPipeline()
self.connectSignals()
</pre></div></li><li class="listitem">the<code class="literal"> self.media_start_time</code> is the new starting position of the mp3 file in seconds. This is the new start position for the extracted output audio. The<code class="literal"> self.duration</code> variable stores the total duration extracted track. Thus, if you have an audio file with a total duration of 5 minutes, the extracted audio will have a starting position corresponding to 1 min, 40 seconds on the original track. The total duration of this output file will be 30 seconds, that is, the end time will correspond to 2 minutes, 10 seconds on the original track. The last two lines of this method build a pipeline and connect signals with class methods.</li><li class="listitem">Next, build the GStreamer pipeline.<div><pre class="programlisting">1 def constructPipeline(self):
2 self.pipeline = gst.Pipeline()
3 self.filesrc = gst.element_factory_make(
4 "gnlfilesource")
5
6 # Set properties of filesrc element
7 # Note: the gnlfilesource signal will be connected
8 # in self.connectSignals()
9 self.filesrc.set_property("uri",
10 "file:///" + self.inFileLocation)
11 self.filesrc.set_property("media-start",
12 self.media_start_time*gst.SECOND)
13 self.filesrc.set_property("media-duration",
14 self.media_duration*gst.SECOND)
15
16 self.audioconvert = \
17 gst.element_factory_make("audioconvert")
18
19 self.encoder = \
20 gst.element_factory_make("lame", "mp3_encoder")
21
22 self.filesink = \
23 gst.element_factory_make("filesink")
24
25 self.filesink.set_property("location",
26 self.outFileLocation)
27
28 #Add elements to the pipeline
29 self.pipeline.add(self.filesrc, self.audioconvert,
30 self.encoder, self.filesink)
31 # Link elements
32 gst.element_link_many(self.audioconvert,self.encoder,
33 self.filesink)
</pre></div></li><li class="listitem">The highlighted line of code (line 3) creates the gnlfilesource. We call this as self.filesrc. As discussed earlier, this is responsible for loading and decoding audio data and presenting only the required portion of audio data that we need. It enables a higher level of abstraction in the main pipeline.</li><li class="listitem">The code between lines 9 to 13 sets three properties of<code class="literal"> gnlfilesource, uri, media-start</code> and<code class="literal"> media-duration</code> . The<code class="literal"> media-start</code> and<code class="literal"> media-duration</code> are specified in nanoseconds. Therefore, we multiply the parameter value (which is in seconds) by<code class="literal"> gst.SECOND</code> which takes care of the units.</li><li class="listitem">The rest of the code looks very much similar to the Audio Converter example. In this case, we only support saving the file in mp3 audio format. The encoder element is defined on line 19.<code class="literal"> self.filesink</code> determines where the output file will be saved. Elements are added to the pipeline by self.pipeline.add call and are linked together on line 32. Note that the<code class="literal"> gnlfilesource</code> element,<code class="literal"> self.filesrc</code>, is not linked with<code class="literal"> self.audioconvert</code> while constructing the pipeline. Like the<code class="literal"> decodebin</code>, the<code class="literal"> gnlfilesource</code> implements dynamic pads. Thus, the pad is not available when the pipeline is constructed. It is created at the runtime depending on the specified input audio format. The "pad_added" signal of<code class="literal"> gnlfilesource</code> is connected with a method<code class="literal"> self.gnonlin_pad_added</code>.</li><li class="listitem">Now write the<code class="literal"> connectSignals</code> and<code class="literal"> gnonlin_pad_added</code> methods.<div><pre class="programlisting">def connectSignals(self):
# capture the messages put on the bus.
bus = self.pipeline.get_bus()
bus.add_signal_watch()
bus.connect("message", self.message_handler)
# gnlsource plugin uses dynamic pads.
# Capture the pad_added signal.
self.filesrc.connect("pad-added",self.gnonlin_pad_added)
def gnonlin_pad_added(self, gnonlin_elem, pad):
pad.get_caps()
compatible_pad = \
self.audioconvert.get_compatible_pad(pad, caps)
pad.link(compatible_pad)
</pre></div></li><li class="listitem">The highlighted line of code in method connectSignals connects the pad_added signal of gnlfilesource with a method gnonlin_pad_added. The gnonlin_pad_added method is identical to the decodebin_pad_added method of class AudioConverter developed earlier. Whenever gnlfilesource creates a pad at the runtime, this method gets called and here, we manually link the pads of gnlfilesource with the compatible pad on self.audioconvert.</li><li class="listitem">The rest of the code is very much similar to the code developed in the<em> Playing an audio</em> section. For example,<code class="literal"> AudioCutter.run</code> method is equivalent to<code class="literal"> AudioPlayer.play</code> and so on. You can review the code for remaining methods from the file<code class="literal"> AudioCutter.py</code>.</li><li class="listitem">Once everything is in place, run the program from the command line as:</li><li class="listitem">This should create a new MP3 file which is just a specific portion of the original audio file.<div><pre class="programlisting">$python AudioCutter.py
</pre></div></li></ol></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec23"/>What just happened?</h2></div></div></div><p>We accomplished creation of a utility that can cut a piece out of an MP3 audio file (yet keep the original file unchanged). This audio piece was saved as a separate MP3 file. We learned about a very useful plugin, called Gnonlin, intended for non-linear multimedia editing. A few fundamental properties of gnlfilesource element in this plugin to extract an audio file.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec24"/>Have a go hero extend MP3 cutter</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Modify this program so that the parameters such as<code class="literal"> media_start_time</code> can be passed as an argument to the program. You will need a method like<code class="literal"> processArguments()</code>. You can use either<code class="literal"> getopt</code> or<code class="literal"> OptionParser</code> module to parse the arguments.<a id="id240" class="indexterm"/></li><li class="listitem" style="list-style-type: disc">Add support for other file formats. For example, extend this code so that it can extract a piece from a wav formatted audio and save it as an MP3 audio file. The input part will be handled by<code class="literal"> gnlfilesource</code>. Depending upon the type of output file format, you will need a specific encoder and possibly an audio muxer element. Then add and link these elements in the main GStreamer pipeline.<a id="id241" class="indexterm"/></li></ul></div></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec10"/>Recording</h1></div></div></div><p>After learning how to cut out a piece from our favorite music tracks, the next exciting thing we will have is a 'home grown' audio recorder. Then use it the way you like to record music, mimicry or just a simple speech!<a id="id242" class="indexterm"/>
</p><p>Remember what pipeline we used to play an audio? The elements in the pipeline to play an audio were<code class="literal"> filesrc ! decodebin ! audioconvert ! autoaudiosink</code> . The autoaudiosink did the job of automatically detecting the output audio device on your computer.</p><p>For recording purposes, the audio source is going to be from the microphone connected to your computer. Thus, there won't be any<code class="literal"> filesrc</code> element. We will instead replace with a GStreamer plugin that automatically detects the input audio device. On similar lines, you probably want to save the recording to a file. So, the<code class="literal"> autoaudiosink</code> element gets replaced with a<code class="literal"> filesink</code> element.</p><p>autoaudiosrc is an element we can possibly use for detecting input audio source. However, while testing this program on Windows XP, the autoaudiosrc was unable to detect the audio source for unknown reasons. So, we will use the<code class="literal"> Directshow</code> audio capture source plugin called dshowaudiosrc, to accomplish the recording task. Run the<code class="literal"> gst-inspect-0.10 dshowaudiosrc</code> command to make sure it is installed and to learn various properties of this element. Putting this plugin in the pipeline worked fine on Windows XP. The<code class="literal"> dshowaudiosrc</code> is linked to the audioconvert.</p><p>With this information, let's give it a try using the command-line version of GStreamer. Make sure you have a microphone connected or built into your computer. For a change, we will save the output file in<code class="literal"> ogg</code> format.</p><div><pre class="programlisting">gst-launch-0.10.exe dshowaudiosrc num-buffers=1000 !
audioconvert ! audioresample !
vorbisenc ! oggmux !
filesink location=C:/my_voice.ogg
</pre></div><p>The audioresample re-samples the raw audio data with different sample rates. Then the encoder element encodes it. The multiplexer or mux, if present, takes the encoded data and puts it into a single channel. The recorded audio file is written to the location specified by the filesink element.</p></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec11"/>Time for action -  recording</h1></div></div></div><p>Okay, time to write some code that does audio recording for us.<a id="id243" class="indexterm"/>
</p><div><ol class="orderedlist arabic"><li class="listitem">Download the file<code class="literal"> RecordingAudio.py</code> and review the code. You will notice that the only important task is to set up a proper pipeline for audio recording. Content-wise, the other code is very much similar to what we learned earlier in the chapter. It will have some minor differences such as method names and print statements. In this section we will discuss only the important methods in the<code class="literal"> class AudioRecorder</code>.</li><li class="listitem">Write the constructor.<div><pre class="programlisting">def __init__(self):
self.is_playing = False
self.num_buffers = -1
self.error_message = ""
self.processArgs()
self.constructPipeline()
self.connectSignals()
</pre></div></li><li class="listitem">This is similar to the<code class="literal"> AudioPlayer.__init__()</code> except that we have added a call to<code class="literal"> processArgs()</code> and initialized the error reporting variable<code class="literal"> self.error_message</code> and the variable that indicates the total duration of the recording.</li><li class="listitem">Build the GStreamer pipeline by writing<code class="literal"> constructPipeline</code> method.<div><pre class="programlisting">1 def constructPipeline(self):
2 # Create the pipeline instance
3 self.recorder = gst.Pipeline()
4
5 # Define pipeline elements
6 self.audiosrc = \
7 gst.element_factory_make("dshowaudiosrc")
8
9 self.audiosrc.set_property("num-buffers",
10 self.num_buffers)
11
12 self.audioconvert = \
13 gst.element_factory_make("audioconvert")
14
15 self.audioresample = \
16 gst.element_factory_make("audioresample")
17
18 self.encoder = \
19 gst.element_factory_make("lame")
20
21 self.filesink = \
22 gst.element_factory_make("filesink")
23
24 self.filesink.set_property("location",
25 self.outFileLocation)
26
27 # Add elements to the pipeline
28 self.recorder.add(self.audiosrc, self.audioconvert,
29 self.audioresample,
30 self.encoder, self.filesink)
31
32 # Link elements in the pipeline.
33 gst.element_link_many(self.audiosrc,self.audioconvert,
34 self.audioresample,
35 self.encoder,self.filesink)
</pre></div></li><li class="listitem">We use the<code class="literal"> dshowaudiosrc</code> (Directshow audiosrc) plugin as an audio source element. It finds out the input audio source which will be, for instance, the audio input from a microphone.<a id="id244" class="indexterm"/></li><li class="listitem">On line 9, we set the number of buffers property to the one specified by<code class="literal"> self.num_buffers</code>. This has a default value as<code class="literal"> -1</code> , indicating that there is no limit on the number of buffers. If you specify this value as<code class="literal"> 500</code> for instance, it will output<code class="literal"> 500</code> buffers (5 second duration) before sending a<strong> End of Stream</strong> message to end the run of the program.</li><li class="listitem">On line 15, an instance of element 'audioresample' is created. This element is takes the raw audio buffer from the<code class="literal"> self.audioconvert</code> and re-samples it to different sample rates. The encoder element then encodes the audio data into a suitable format and the recorder file is written to the location specified by<code class="literal"> self.filesink</code>.</li><li class="listitem">The code between lines 28 to 35 adds various elements to the pipeline and links them together.</li><li class="listitem">Review the code in file<code class="literal"> RecordingAudio.py</code> to add rest of the code. Then run the program to record your voice or anything that you want to record that makes an audible sound! Following are sample command-line arguments. This program will record an audio for 5 seconds.<div><pre class="programlisting">$python RecordingAudio.py -num_buffers=500
- out_file=C:/my_voice.mp3
</pre></div></li></ol></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec25"/>What just happened?</h2></div></div></div><p>We learned how to record an audio using Python and GStreamer. We developed a simple audio recording utility to accomplish this task. The GStreamer plugin, dshowaudiosrc, captured the audio input for us. We created the main GStreamer Pipeline by adding this and other elements and used it for the Audio Recorder program.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec12"/>Summary</h1></div></div></div><p>This chapter gave us deeper insight into the fundamentals of audio processing using Python and the GStreamer multimedia framework. We used several important components of GStreamer to develop some frequently needed audio processing utilities. The main learning points of the chapter can be summarized as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">GStreamer installation: We learned how to install GStreamer and the dependent packages on various platforms. This set up a stage for learning audio processing techniques and will also be useful for the next chapters on audio/video processing.</li><li class="listitem" style="list-style-type: disc">A primer on GStreamer: A quick primer on GStreamer helped us understand important elements required for media processing.</li><li class="listitem" style="list-style-type: disc">Use of GStreamer API to develop audio tools: We learned how to use GStremer API for general audio processing. This helped us develop tools such as an Audio player, a file format converter, an MP3 cutter, and audio recorder.</li></ul></div><p>Now that we've learned about basic audio processing using GStreamer, we're ready to add some 'spice' to the audio. In the next chapter we will learn techniques that will help us add special effects to an audio.</p></div></div>
</body></html>