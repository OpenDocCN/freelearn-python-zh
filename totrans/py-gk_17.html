<html><head></head><body>
		<div><h1 id="_idParaDest-276"><em class="italic"><a id="_idTextAnchor314"/>Chapter 13</em>: Python and Machine Learning </h1>
			<p><strong class="bold">Machine learning</strong> (<strong class="bold">ML</strong>) is a branch of <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) that is based on building models by learning patterns from data and then using those models to make predictions. It is one of the most popular AI techniques for helping humans as well as businesses in many ways. For example, it is being used for medical diagnosis, image processing, speech recognition, predicting threats, data mining, classification, and many more scenarios. We all understand the importance and usefulness of machine learning in our lives. Python, being a concise but powerful language, is being used extensively to implement machine learning models. Python's ability to process and prepare data using libraries such as NumPy, pandas, and PySpark makes it a preferred choice for developers for building and training ML models. </p>
			<p>In this chapter, we will discuss using Python for machine learning tasks in an optimized way. This is especially important because training an ML model is a compute-intensive task and optimizing the code is fundamental when using Python for machine learning. </p>
			<p>We will cover the following topics in this chapter:</p>
			<ul>
				<li>Introducing machine learning</li>
				<li>Using Python for machine learning</li>
				<li>Testing and evaluating machine learning models</li>
				<li>Deploying machine learning models in the cloud </li>
			</ul>
			<p>After completing this chapter, you will understand how to use Python to build, train, and evaluate machine learning models and how to deploy them in the cloud and use them to make predictions. </p>
			<h1 id="_idParaDest-277"><a id="_idTextAnchor315"/>Technical requirements</h1>
			<p>The following are the technical requirements for this chapter:</p>
			<ul>
				<li>You need to have Python 3.7 or later installed on your computer.</li>
				<li>You need to install additional libraries for machine learning such as SciPy, NumPy, pandas, and scikit-learn.</li>
				<li>To deploy an ML model on GCP's AI Platform, you will need a GCP account (a free trial will work fine).</li>
			</ul>
			<p>The sample code for this chapter can be found at <a href="https://github.com/PacktPublishing/Python-for-Geeks/tree/master/Chapter13">https://github.com/PacktPublishing/Python-for-Geeks/tree/master/Chapter13</a>. </p>
			<p>We will start our discussion with an introduction to machine learning.</p>
			<h1 id="_idParaDest-278"><a id="_idTextAnchor316"/>Introducing machine learning </h1>
			<p>In traditional programming, we provide data and some rules as input to our program to get the desired output. Machine learning is a fundamentally different programming approach, in which <a id="_idIndexMarker1394"/>the data and the expected output are provided as input to produce a set of rules. This is called a <strong class="bold">model</strong> in machine learning nomenclature. This concept is illustrated in the following diagram: </p>
			<div><div><img src="img/B17189_13_01.jpg" alt="Figure 13.1 – Traditional programming versus machine learning programming&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.1 – Traditional programming versus machine learning programming</p>
			<p>To understand how machine learning works, we need to familiarize ourselves with its core components or elements:</p>
			<ul>
				<li><strong class="bold">Dataset</strong>: Without a good set of data, machine learning is nothing. Good data is the <a id="_idIndexMarker1395"/>real power of machine learning. It has to be collected from different environments and cover various situations to represent a model close to a real-world process or system. Another requirement for data is that it has to be large, and by large we mean thousands of records. Moreover, the data should be as accurate as possible and have meaningful information in it. Data is used to train the system and also to evaluate <a id="_idIndexMarker1396"/>its accuracy. We can collect data from many sources but most of the time, it is in a raw format. We can use data processing techniques by utilizing libraries such as pandas, as we discussed in the previous chapters. </li>
				<li><strong class="bold">Feature extraction</strong>: Before using any data to build a model, we need to understand <a id="_idIndexMarker1397"/>what type of data we have and how it is structured. Once we have understood that, we can select what features of the data can be used by an ML algorithm to build a model. We can also compute additional features based on the original feature set. For example, if we have raw image data in the form of pixels, which itself may not be useful for training a model, we can use the length or breadth of the shape inside an image as features to build rules for our model.</li>
				<li><strong class="bold">Algorithm</strong>: This is a program that is used to build an ML model from the available <a id="_idIndexMarker1398"/>data. In mathematical terms, a machine learning algorithm tries to learn a target function <em class="italic">f(X)</em> that can map the input data, <em class="italic">X</em>, to an output, <em class="italic">y</em>, like so: <p><img src="img/B17189_13_001.png" alt=""/></p><p>There are several algorithms available for different types of problems and situations because there is not a single algorithm that can solve every problem. A few popular <a id="_idIndexMarker1399"/>algorithms are <strong class="bold">linear regression</strong>, <strong class="bold">classification and regression trees</strong>, and <strong class="bold">support vector classifier</strong> (<strong class="bold">SVC</strong>). The <a id="_idIndexMarker1400"/>mathematical details of how <a id="_idIndexMarker1401"/>these algorithms work are beyond the scope of this book. We recommend checking the additional links provided in the <em class="italic">Further reading</em> section for details regarding these algorithms.</p></li>
				<li><strong class="bold">Models</strong>: Often, we <a id="_idIndexMarker1402"/>hear the term model in machine learning. A model is a mathematical or computational representation of a process that is happening in our day-to-day life. From a machine learning perspective, it is the output of a machine learning algorithm <a id="_idIndexMarker1403"/>when we apply it to our dataset. This output (model) can be a set of rules or some specific data structure that can be used to make predictions when used for any real-world data.</li>
				<li><strong class="bold">Training</strong>: This is not a new component or step in machine learning. When we say <a id="_idIndexMarker1404"/>training a model, this means applying an ML algorithm to a dataset to produce an ML model. The model we get as output is said to be trained on a certain dataset. There are three different ways to train a model:<p>a) <strong class="bold">Supervised learning</strong>: This includes providing the desired output, along with our <a id="_idIndexMarker1405"/>data records. The goal here is to learn how the input (X) can be mapped to the output (Y) using the available data. This approach of learning is used for classification and regression problems. Image classification and predicting house prices (regression) are a couple of real-world examples of supervised learning. In the case of image processing, we can train a model to identify the type of animal in an image, such as a cat or a dog, based on the shape, length, and breadth of the image. To train our image classification model, we will label each image in the training dataset with the animal's name. To predict house pricing, we must provide data about the houses in the location we are looking at, such as the area they're in, the number of rooms and bathrooms, and so on.</p><p>b) <strong class="bold">Unsupervised learning</strong>: In this case, we train a model without knowing the desired <a id="_idIndexMarker1406"/>output. Unsupervised learning is typically applied to clustering and association use cases. This type of learning is mainly based on observations and finding groups or clusters of data points so that the data points in a group or cluster have similar characteristics. This type of learning approach is extensively used by online retail stores such as Amazon to find different groups of customers (clustering) based on their shopping behavior and offer them items they're interested in. Online stores also try to find an association between different purchases, such as how likely that a person buying item A will want to buy item B as well.</p><p>c) <strong class="bold">Reinforcement learning</strong>: In the case of reinforcement learning, the model is rewarded <a id="_idIndexMarker1407"/>for making an appropriate decision in a particular situation. In this case, no training data is available at all, but the model has to learn from experience. Autonomous cars are a popular example of reinforcement learning. </p></li>
				<li><strong class="bold">Testing</strong>: We need <a id="_idIndexMarker1408"/>to test our model on a dataset that is not used to train the model. A traditional approach is to train our model using two-thirds of the dataset and test the model using the remaining one-third. </li>
			</ul>
			<p>In addition to the three learning approaches we discussed, we also have deep learning. This is an advanced <a id="_idIndexMarker1409"/>type of machine learning based on the approach of how the human brain achieves a certain type of knowledge using neural network algorithms. In this chapter, we will use supervised learning to build our sample models. </p>
			<p>In the next section, we will explore the options that are available in Python for machine learning.</p>
			<h1 id="_idParaDest-279"><a id="_idTextAnchor317"/>Using Python for machine learning</h1>
			<p>Python is a popular language in the data scientist community because of its simplicity, cross-platform <a id="_idIndexMarker1410"/>compatibilities, and rich support <a id="_idIndexMarker1411"/>for data analysis and data processing through its libraries. One of the key steps in machine learning is preparing data for building the ML models, and Python is a natural winner in doing this. The only challenge in using Python is that it is an interpreted language, so the speed of executing code is <a id="_idIndexMarker1412"/>slow in comparison to languages such as C. But this is <a id="_idIndexMarker1413"/>not a major issue as there are libraries available to maximize Python's speed by using multiple cores of <strong class="bold">central processing units</strong> (<strong class="bold">CPUs</strong>) or <strong class="bold">graphics processing units</strong> (<strong class="bold">GPUs</strong>) in parallel.  </p>
			<p>In the next subsection, we will introduce a few Python libraries for machine learning.</p>
			<h2 id="_idParaDest-280"><a id="_idTextAnchor318"/>Introducing machine learning libraries in Python </h2>
			<p>Python comes with several machine learning libraries. We already mentioned supporting <a id="_idIndexMarker1414"/>libraries such as NumPy, SciPy, and pandas, which are fundamental for data refinement, data analysis, and data manipulation. In this section, we will briefly discuss the most popular Python libraries for building machine learning models. </p>
			<h3>scikit-learn</h3>
			<p>This library is a popular choice because it has a large variety of built-in ML algorithms and tools to evaluate the performance of those ML algorithms. These algorithms include classification <a id="_idIndexMarker1415"/>and regression algorithms for supervised learning and clustering and association algorithms for unsupervised <a id="_idIndexMarker1416"/>learning. scikit-learn is mostly written in Python and relies on the NumPy library for many operations. For beginners, we recommend starting with the scikit-learn library and then moving to the next level of libraries, such as TensorFlow. We will use scikit-learn to <a id="_idIndexMarker1417"/>illustrate the concepts of building, training, and evaluating the ML models.</p>
			<p>scikit-learn also offers <strong class="bold">gradient boost algorithms</strong>. These algorithms are based on the mathematical <a id="_idIndexMarker1418"/>concept of <strong class="bold">Gradient</strong>, which is a slope of a function. It measures the change in an error in the ML context. The idea of gradient-based algorithms is to fine-tune the parameters iteratively to find the local minimum of a function (minimizing errors for the ML models). Gradient boost algorithms use the same strategy to improve a model iteratively by taking into account the performance of the previous model, by fine-tuning the parameters for the new model, and by setting the target to accept the new model if it minimizes the errors more than the previous model. </p>
			<h3>XGBoost</h3>
			<p>XGBoost, or <strong class="bold">eXtreme Gradient Boosting</strong>, is a library of algorithms that relies on gradient <a id="_idIndexMarker1419"/>boosted decision trees. This library <a id="_idIndexMarker1420"/>is popular as it is extremely fast and offers the best performance compared to other implementations of gradient boosting algorithms, as well as traditional machine learning algorithms. scikit-learn also offers gradient boost algorithms, which are fundamentally the same as XGBoost, though XGBoost is significantly fast. The main reason is the maximal utilization of parallelism across <a id="_idIndexMarker1421"/>different cores of a single machine or in a distributed cluster of nodes. XGBoost can also regularize the decision trees to avoid <a id="_idIndexMarker1422"/>overfitting the model to the data. XGBoost is not a full framework for machine learning but offers mainly algorithms (models). To use XGBoost, we must use scikit-learn for the rest of the utility functions and tools, such as data analysis and data preparation. </p>
			<h3>TensorFlow</h3>
			<p>TensorFlow is <a id="_idIndexMarker1423"/>another very popular open source library for machine learning, developed by <a id="_idIndexMarker1424"/>the Google Brain team for high-performance computation. TensorFlow is particularly useful for training and running deep neural networks and is a popular choice in the area of deep learning. </p>
			<h3>Keras</h3>
			<p>This is an <a id="_idIndexMarker1425"/>open source API for deep learning for <a id="_idIndexMarker1426"/>neural networks in Python. Keras is more of a high-level API on top of TensorFlow. For developers, using Keras is more convenient than using TensorFlow directly, so it is recommended to use Keras if you are starting to develop deep learning models with Python. Keras can work with both CPUs and GPUs.</p>
			<h3>PyTorch</h3>
			<p>PyTorch is <a id="_idIndexMarker1427"/>another open source machine <a id="_idIndexMarker1428"/>learning library that is a Python implementation of the popular <strong class="bold">Torch</strong> library in C. </p>
			<p>In the next section, we will briefly discuss the best practices for using Python for machine learning. </p>
			<h2 id="_idParaDest-281"><a id="_idTextAnchor319"/>Best practices of training data with Python</h2>
			<p>We have <a id="_idIndexMarker1429"/>already highlighted how important the data is when training a machine learning model. In this section, we will highlight a few best practices and recommendations when preparing and using data to train your ML model. These are as follows:</p>
			<ul>
				<li>As we mentioned previously, collecting a large set of data is of key importance (a few thousand data records or at least many hundreds). The bigger the size of the data, the more accurate the ML model will be. </li>
				<li>Clean and refine your data before starting any training. This means that there should not be any missing fields or misleading fields in the data. Python libraries such as pandas are very handy for such tasks.</li>
				<li>Using a dataset without compromising the privacy and security of data is important. You need to make sure you are not using the data of some other organization without the appropriate approval.</li>
				<li>GPUs work <a id="_idIndexMarker1430"/>well with data-intensive applications. We encourage you to use GPUs to train your algorithms for faster results. Libraries such as XGBoost, TensorFlow, and Keras are well known for using GPUs for training purposes. </li>
				<li>When dealing with a large set of data for training, it is important to utilize the system memory efficiently. We should be loading the data in memory in chunks, or utilizing distributed clusters to process the data. We encourage you to use the generator function as much as you can.</li>
				<li>It is also a good practice to watch your memory usage during data-intensive tasks (for example, while training a model) and free up memory periodically by forcing garbage collection to release unreferenced objects.</li>
			</ul>
			<p>Now that we've covered the available Python libraries and the best practices of using Python for machine learning, it is time to start working with real code examples. </p>
			<h1 id="_idParaDest-282"><a id="_idTextAnchor320"/>Building and evaluating a machine learning model</h1>
			<p>Before we <a id="_idIndexMarker1431"/>start writing a Python program, we will <a id="_idIndexMarker1432"/>evaluate the process of building a machine learning model. </p>
			<h2 id="_idParaDest-283"><a id="_idTextAnchor321"/>Learning about an ML model building process</h2>
			<p>We discussed <a id="_idIndexMarker1433"/>the different components of machine learning in the <em class="italic">Introducing machine learning</em> section. The machine learning process uses those elements as input to train a model. This process follows a procedure with three main phases, and each phase has several steps in it. These phases are shown here: </p>
			<div><div><img src="img/B17189_13_02.jpg" alt="Figure 13.2 – Steps of building an ML model using a classic learning approach&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.2 – Steps of building an ML model using a classic learning approach</p>
			<p>Each phase, along with detailed steps of it, is described here: </p>
			<ul>
				<li><strong class="bold">Data analysis</strong>: In this phase, we collect raw data and transform it into a form that <a id="_idIndexMarker1434"/>can be analyzed and then used to train and test a model. We may discard some data, such as records with empty values. Through data analysis, we try to select the features (attributes) that can be used to identify patterns in our data. Extracting features is a very important step, and a lot depends on these features when building a successful model. In many cases, we have to fine-tune features after the testing phase to make sure we have the right set of features for the data. Typically, we partition the data into two sets; one part is used to train the model in the modeling phase, while the other part is used to test the trained model for accuracy in the testing phase. We can skip the testing phase if we are evaluating the model using other approaches, such as <strong class="bold">cross-validation</strong>. We recommend having a <a id="_idIndexMarker1435"/>testing phase in your ML building process and keeping some data (unseen to the model) aside for the testing phase, as shown in the preceding diagram. </li>
				<li><strong class="bold">Modeling</strong>: This phase is about training our model based on the training data and features we extracted in the previous phase. In a traditional ML approach, we can <a id="_idIndexMarker1436"/>use the training data as-is to train our model. But to ensure our model has better accuracy, we can use the following additional techniques: <p>a) We can partition our training data into slices and use one slice for evaluating of our model and use the remaining slices for training the model. We repeat this for a different combination of training slices and the evaluation slice. This evaluation approach is called cross-validation.</p><p>b) ML algorithms come with several parameters that can be used to fine-tune the model to best fit the data. Fine-tuning these parameters, also known as <strong class="bold">hyperparameters</strong>, is typically <a id="_idIndexMarker1437"/>done along with cross-validation during the modeling phase.</p><p>The feature values in data may use different scales of measurement, which makes it difficult to build rules with a combination of such features. In such cases, we can transform the data (feature values) into a common scale or into a normalized scale (say 0 to 1). This step is called scaling the data, or normalization. All these scaling and evaluation steps (or some of them) can be added to a pipeline (such as an Apache Beam pipeline) and can be executed together to evaluate different combinations for selecting the best model. The output of this phase is a candidate ML model, as shown in the preceding diagram.</p></li>
				<li><strong class="bold">Testing</strong>: In the <a id="_idIndexMarker1438"/>testing phase, we use the data we set aside to test the accuracy of the candidate ML model we built in the previous phase. The output of this phase can be used to add or remove some features and fine-tune the model until we get one with acceptable accuracy.</li>
			</ul>
			<p>Once we are satisfied with the accuracy of our model, we can implement it to predict based on the data from the real world. </p>
			<h2 id="_idParaDest-284"><a id="_idTextAnchor322"/>Building a sample ML model</h2>
			<p>In this section, we will build a sample ML model using Python, which will identify three types <a id="_idIndexMarker1439"/>of Iris plants. To build this model, we will use a commonly available dataset containing four features (length and width of sepals and petals) and three types of Iris plants.</p>
			<p>For this code exercise, we will use the following components: </p>
			<ul>
				<li>We will use the Iris dataset provided by <em class="italic">UC Irvine Machine Learning Repository</em> (http://archive.ics.uci.edu/ml/). This dataset contains 150 records and three expected patterns to identify. This is a refined dataset that comes with the necessary features already identified.</li>
				<li>We will use various Python libraries, as follows:<p>a) The pandas and the matplotlib libraries, for data analysis</p><p>b) The scikit-learn library, for training and testing our ML model</p></li>
			</ul>
			<p>First, we will write a Python program for analyzing the Iris dataset. </p>
			<h3>Analyzing the Iris dataset </h3>
			<p>For ease of programming, we downloaded the two files for the Iris dataset (<code>iris.data</code> and <code>iris.names</code>) from <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/iris/">https://archive.ics.uci.edu/ml/machine-learning-databases/iris/</a>.</p>
			<p>We can <a id="_idIndexMarker1440"/>directly access the data file from this repository through Python. But in our sample program, we will use a local copy of the files. The scikit-learn library also provides several datasets as part of the library and can be used directly for evaluation purposes. We decided to use the actual files as this will be close to real-world scenarios, where you collect data yourself and then use it in your program. </p>
			<p>The Iris data file contains 150 records that are sorted based on the expected output. In the data file, the values of four different features are provided. These four features are described in the <code>iris.names</code> file as <code>sepal-length</code>, <code>sepal-width</code>, <code>petal-length</code>, and <code>petal-width</code>. The expected output types of Iris plant, as per the data file, are <code>Iris-setosa</code>, <code>Iris-versicolor</code>, and <code>Iris-virginica</code>. We will load the data <a id="_idIndexMarker1441"/>into a pandas DataFrame and then analyze it for different attributes of interest. Some sample code for analyzing the Iris data is as follows:</p>
			<pre>#<strong class="bold">iris_data_analysis.py</strong>
from pandas import read_csv
from matplotlib import pyplot
data_file = "iris/iris.data"
iris_names = ['sepal-length', 'sepal-width', 'petal-  length', 'petal-width', 'class']
df = <code>read_csv</code>(data_file, names=iris_names)
print(df.shape)
print(df.head(20))
print(df.describe())
print(df.groupby('class').size())
# box and whisker plots
df.plot(kind='box', subplots=True, layout=(3,3),   sharex=False, sharey=False)
pyplot.show()
# check the histograms
df.hist()
pyplot.show()</pre>
			<p>In the <a id="_idIndexMarker1442"/>first part of the data analysis, we checked a few metrics about the data using the pandas library functions, as follows: </p>
			<ul>
				<li>We used the <code>shape</code> method to get the dimension of the DataFrame. This should be [150, 5] for the Iris dataset as we have 150 records and five columns (four for features and one for the expected output). This step ensures that all the data is loaded into our DataFrame correctly.</li>
				<li>We checked the actual data using the <code>head</code> or <code>tail</code> method. This is only to see the data visually, especially if we have not seen what is inside the data file. </li>
				<li>The <code>describe</code> method gave us the different statistical KPIs available for the data. The outcome of this method is as follows:</li>
			</ul>
			<pre>       sepal-length  sepal-width  petal-length  petal-width
count    150.000000   150.000000    150.000000   150.000000
mean       5.843333     3.054000      3.758667     1.198667
std        0.828066     0.433594      1.764420     0.763161
min        4.300000     2.000000      1.000000     0.100000
25%        5.100000     2.800000      1.600000     0.300000
50%        5.800000     3.000000      4.350000     1.300000
75%        6.400000     3.300000      5.100000     1.800000
max        7.900000     4.400000      6.900000     2.500000</pre>
			<p>These KPIs can help us select the right algorithm for the dataset. </p>
			<ul>
				<li>The <code>groupby</code> method was used to identify the number of records for each <code>class</code> (name of the column for the expected output). The output will indicate that there are 50 records for each type of Iris plant:</li>
			</ul>
			<pre>Iris-setosa        50
Iris-versicolor    50
Iris-virginica     50</pre>
			<p>In the second part <a id="_idIndexMarker1443"/>of the analysis, we tried to use a <code>describe</code> method (minimum value, first quartile, second quartile (median), third quartile, and the maximum value). This plot will tell you if your data is symmetrically distributed or grouped in a certain range, or how much of your data is skewed <a id="_idIndexMarker1446"/>toward one side of the distribution. For our Iris dataset, we will get the box plots for our four features as follows: </p>
			<div><div><img src="img/B17189_13_03.jpg" alt="Figure 13.3 – Box and whisker plots of Iris dataset features&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.3 – Box and whisker plots of Iris dataset features</p>
			<p>From these plots, we can see that the <strong class="bold">petal-length</strong> and the <strong class="bold">petal-width</strong> data has the most grouping between the first quartile and the third quartile. We can confirm this by analyzing the data distribution by using the histogram plots, as follows: </p>
			<div><div><img src="img/B17189_13_04.jpg" alt="Figure 13.4 – Histogram of Iris dataset features&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.4 – Histogram of Iris dataset features</p>
			<p>After <a id="_idIndexMarker1447"/>analyzing the data and selecting the right type of algorithm (model) to use, we will move on to the next step, which is training our model. </p>
			<h3>Training and testing a sample ML model</h3>
			<p>To train <a id="_idIndexMarker1448"/>and test an ML algorithm (model), we <a id="_idIndexMarker1449"/>must follow these steps: </p>
			<ol>
				<li>As a first step, we will split our original dataset into two groups: training data and testing data. This <a id="_idIndexMarker1450"/>approach of splitting the data is called the <code>train_test_split</code> function to make this split convenient: <pre>#<code>train_test_split</code> function, we split the full dataset into a features dataset (typically called <code>X</code>, which should be uppercase in machine learning nomenclature) and the expected output dataset (called <code>y</code>, which should be lowercase <a id="_idIndexMarker1451"/>in machine <a id="_idIndexMarker1452"/>learning nomenclature). These two datasets (<code>X</code> and <code>y</code>) are split by the <code>train_test_split</code> function as per our <code>test_size</code> (20%, in our case). We also allow the data to be shuffled before splitting it. The output of this operation will give us four datasets (<code>X_train</code>, <code>y_train</code>, <code>X_test</code>, and <code>y_test</code>) for training and testing purposes. </p></li>
				<li>In the next step, we will create a model and provide the training data (<code>X_train</code> and <code>y_train</code>) to train this model. The choice of ML algorithm is not that important for this exercise. For the Iris dataset, we will use the SVC algorithm with default parameters. Some sample Python code is as follows: <pre><code>fit</code> method. In the next statement, we made predictions based on the testing data (<code>X_test</code>). These predictions will be used to evaluate the performance of our trained model. </p></li>
				<li>Finally, the predictions will be evaluated with the expected results, as per the test data (<code>y_test</code>), using the <code>accuracy_score</code> and <code>classification_report</code> functions of the scikit-learn library, as follows: <pre>#<strong class="bold">iris_build_svm_model.py (#3)</strong>
# predictions evaluation
print(accuracy_score(y_test, predictions))
print(classification_report(y_test, predictions))</pre></li>
			</ol>
			<p>The console output of this program is as follows:</p>
			<pre>0.9666666
    Iris-setosa       1.00      1.00      1.00        11
Iris-versicolor       1.00      0.92      0.96        13
 Iris-virginica       0.86      1.00      0.92         6
       accuracy                           0.97        30
      macro avg       0.95      0.97      0.96        30
   weighted avg       0.97      0.97      0.97        30</pre>
			<p>The accuracy <a id="_idIndexMarker1453"/>scope is very high (<em class="italic">0.966</em>), which indicates that the model can predict the Iris plant with nearly 96% accuracy <a id="_idIndexMarker1454"/>for the testing data. The model is doing an excellent job for <strong class="bold">Iris-setosa</strong> and <strong class="bold">Iris-versicolor</strong> but only a decent job (86% precise) in the case of <strong class="bold">Iris-virginica</strong>. There are several ways to improve the performance of our model, all of which we will discuss in the next section. </p>
			<h2 id="_idParaDest-285"><a id="_idTextAnchor323"/>Evaluating a model using cross-validation and fine tuning hyperparameters </h2>
			<p>For the <a id="_idIndexMarker1455"/>previous sample <a id="_idIndexMarker1456"/>model, we kept the training process simple for the sake of learning the core steps of building an ML model. For production deployments, we cannot rely on a dataset that only contains 150 records. Additionally, we must evaluate the model for the best predictions using techniques such as the following: </p>
			<ul>
				<li><strong class="bold">k-fold cross validation</strong>: In the previous model, we shuffled the data before splitting it <a id="_idIndexMarker1457"/>into training and testing datasets using the Holdout method. Due to this, the model can give us different results every time we train it, thus resulting in an unstable model. It is not trivial to select training data from a small dataset that contains 150 records since in our case, that can truly represent the data of a real-world system or environment. To make our previous model more stable with a small dataset, k-fold cross-validation is the recommended approach. This approach is based on dividing our dataset into <em class="italic">k</em> folds or slices. The idea is to use <em class="italic">k-1</em> slices for training and to use the <em class="italic">kth</em> slice for evaluating or testing. This process is repeated until we use every slice of data for testing purposes. This is equivalent to repeating the holdout method <em class="italic">k</em> times using the different slices of data for testing. <p>To elaborate further, we must split our whole dataset or training data set into five slices, say <em class="italic">k=5</em>, for 5-fold cross-validation. In the first iteration, we can use the first slice (20%) for testing and the remaining four slices (80%) for training. In the second iteration, we can use the second slice for testing and the remaining four slices for training, and so on. We can evaluate the model for all five possible training datasets and select the best model in the end. The selection scheme of data for training and testing is shown here: </p></li>
			</ul>
			<div><div><img src="img/B17189_13_05.jpg" alt="Figure 13.5 – Cross-validation scheme for five slices of data&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.5 – Cross-validation scheme for five slices of data</p>
			<p>The cross-validation accuracy is calculated by taking the average accuracy of each model we build in each iteration, as per the value of <em class="italic">k</em>. </p>
			<ul>
				<li><strong class="bold">Optimizing hyperparameters</strong>: In the previous code example, we used the machine learning algorithm with default parameters. Each machine learning algorithm <a id="_idIndexMarker1458"/>comes with many hyperparameters that can be fine-tuned to customize the model, as per the dataset. It may be possible for statisticians to set a few parameters manually by analyzing the data distribution, but it is tedious to analyze the impact of a combination of these parameters. There is a need to evaluate our model by using different values of these hyperparameters, which can assist us in selecting the best hyperparameter combination in the end. This technique is called fine-tuning or optimizing the hyperparameters. </li>
			</ul>
			<p>Cross-validation and fine-tuning hyperparameters are tedious to implement, even through programming. The good news is that the scikit-learn library comes with tools to achieve these evaluations in a couple of lines of Python code. The scikit-learn library offers two types of tools for this evaluation: <code>GridSearchCV</code> and <code>RandomizedSearchCV</code>. We will discuss each of these tools next. </p>
			<h3>GridSearchCV</h3>
			<p>The <code>GridSearchCV</code> tool evaluates any given model by using the cross-validation approach <a id="_idIndexMarker1459"/>for all possible combinations of values provided for the hyperparameters. Each combination of values of hyperparameters will be evaluated <a id="_idIndexMarker1460"/>by using cross-validation on dataset slices.</p>
			<p>In the following code example, we will use the <code>GridSearchCV</code> class from the scikit-learn library to evaluate the SVC model for a combination of <code>C</code> and <code>gamma</code> parameters. The <code>C</code> parameter is a regularization parameter that manages the tradeoff between having a low training error versus having a low testing error. A higher value of <code>C</code> means we can accept a higher number of errors. We will use 0.001, 0.01, 1, 5, 10, and 100 as values for <code>C</code>. The <code>gamma</code> parameter is used to define the non-linear hyperplanes or non-linear lines for the classification. The higher the value of <code>gamma</code>, the model can try to fit more data by adding more curvature or curve to the hyperplane or the line. We will use values such as 0.001, 0.01, 1, 5, 10, and 100 for <code>gamma</code> as well. The complete code for <code>GridSearchCV</code> is as follows:</p>
			<pre>#<strong class="bold">iris_eval_svc_model.py (part 1 of 2)</strong>
from sklearn.model_selection import train_test_split
from sklearn.model_selection import   GridSearchCV,RandomizedSearchCV
from sklearn.datasets import load_iris
from sklearn.svm import SVC
iris= load_iris()
X = iris.data
y = iris.target
X_train, X_test, y_train, y_test=train_test_split   (X,y,test_size=0.2)
<strong class="bold">params</strong> = {"C":[0.001, 0.01, 1, 5, 10, 100],              "gamma": [0.001, 0.01, 0.1, 1, 10, 100]}
model=SVC()
grid_cv=<strong class="bold">GridSearchCV</strong>(model, params,  cv=5)
grid_cv.<strong class="bold">fit</strong>(X_train,y_train)
print(f"<strong class="bold">GridSearch</strong>- best parameter:{grid_cv.best_params_}")
print(f"<strong class="bold">GridSearch</strong>- accuracy: {grid_cv.best_score_}")
print(classification_report(y_test,   grid_cv.best_estimator_.predict( X_test)))</pre>
			<p>In this <a id="_idIndexMarker1461"/>code example, the following points need to be <a id="_idIndexMarker1462"/>highlighted:</p>
			<ul>
				<li>We loaded the data directly from the scikit-learn library for illustration purposes. You can use the previous code to load the data from a local file as well. </li>
				<li>It is important to define the <code>params</code> dictionary for fine-tuning hyperparameters as a first step. We set the values for the <code>C</code> and <code>gamma</code> parameters in this dictionary.</li>
				<li>We set <code>cv=5</code>. This will evaluate each parameter combination by using cross-validation across the five slices.  </li>
			</ul>
			<p>The output of this program will give us the best combination of <code>C</code> and <code>gamma</code> and the accuracy of the model with cross-validation. The console output for the best parameters and the accuracy of the best model is as follows: </p>
			<pre>GridSearch- best parameter: {'C': 5, 'gamma': 0.1}
GridSearch- accuracy: 0.9833333333333334</pre>
			<p>By evaluating <a id="_idIndexMarker1463"/>different combinations of parameters <a id="_idIndexMarker1464"/>and using cross-validation with <code>GridSearchCV</code>, the overall accuracy of the model is improved to 98% from 96%, compared to the results we observed without cross-validation and hyperparameter fine-tuning. The classification report (not shown in the program output) shows that the precision for the three plant types is 100% for our test data. However, this tool is not feasible to use when we have a large number of parameter values with a large dataset. </p>
			<h3>RandomizedSearchCV</h3>
			<p>In the case of the <code>RandomizedSearchCV</code> tool, we only evaluate a model for randomly <a id="_idIndexMarker1465"/>selected hyperparameter values instead of all the different combinations. We can provide the parameter values and the number of random <a id="_idIndexMarker1466"/>iterations to perform as input. The <code>RandomizedSearchCV</code> tool will randomly select the parameter combination as per the number of iterations provided. This tool is useful when we are dealing with a large dataset and when many combinations of parameters/values are possible. Evaluating all the possible combinations for a large dataset can be a very long process that requires a lot of computing resources.</p>
			<p>The Python code for using <code>RandomizedSearchCV</code> is the same as for the <code>GridSearchCV</code> tool, except for the following additional lines of codes:</p>
			<pre>#<strong class="bold">iris_eval_svc_model.py (part 2 of 2)</strong>
rand_cv=<strong class="bold">RandomizedSearchCV</strong>(model, params, n_iter = 5, cv=5)
rand_cv.<strong class="bold">fit</strong>(x_train,y_train)
print(f" RandomizedSearch - best parameter:   {rand_cv.best_params_}")
print(f" RandomizedSearch - accuracy:   {rand_cv.best_score_}")</pre>
			<p>Since we defined <code>n_iter=5</code>, <code>RandomizedSearchCV</code> will select only five combinations of the <code>C</code> and <code>gamma</code> parameters and evaluate the model accordingly. </p>
			<p>When this part of the program is executed, we will get an output similar to the following: </p>
			<pre>RandomizedSearch- best parameter: {'gamma': 10, 'C': 5}
RandomizedSearch- accuracy: 0.9333333333333333</pre>
			<p>Note that you may get a different output because this tool may select different parameter values for the evaluation. If we increase the number of iterations (<code>n_iter</code>) for the <code>RandomizedSearchCV</code> object, we will observe more accuracy in the output. If we do not set <code>n_iter</code>, we will run the evaluation for all combinations, which means we'll get the same output that <code>GridSearchCV</code> provides. </p>
			<p>As we can see, the best parameter combination that's selected by the <code>GridSearchCV</code> tool is <a id="_idIndexMarker1467"/>different than the one selected by the <code>RandomizedSearchCV</code> tool. This is expected because we ran the two tools for a different number of iterations. </p>
			<p>This concludes <a id="_idIndexMarker1468"/>our discussion on building a sample ML model using the scikit-learn library. We covered the core steps and concepts that are required in building and evaluating such models. In practice, we also scale the data for normalization. This scaling can be achieved either by using built-in scaler classes in the scikit-learn library, such as <code>StandardScaler</code>, or by building our own scaler class. The scaling operation is a data transformation operation and can be combined with the model training task under a single pipeline. scikit-learn supports combining multiple operations or tasks as a pipeline using the <code>Pipeline</code> class. The <code>Pipeline</code> class can also be used directly with the <code>RandomizedSearchCV</code> or <code>GridSearchCV</code> tools. You can find out more about how to use scalers and pipelines with the scikit-learn library by reading the <a id="_idIndexMarker1469"/>online documentation for the scikit-learn library (<a href="https://scikit-learn.org/stable/user_guide.html">https://scikit-learn.org/stable/user_guide.html</a>).</p>
			<p>In the next section, we will discuss how to save a model to a file and restore a model from a file. </p>
			<h2 id="_idParaDest-286"><a id="_idTextAnchor324"/>Saving an ML model to a file</h2>
			<p>When we have evaluated a model and selected the best one as per our dataset, the next step is to implement this model for future predictions. This model can be implemented as part <a id="_idIndexMarker1470"/>of any Python application, such as web applications, Flask, or Django, or it can be used as a microservice or even a cloud function. The real question is how to transfer the model object from one program to the other. There are a couple of libraries such as <code>pickle</code> and <code>joblib</code> that can be used to serialize a model into a file. The file can then be used in any application to load the model again in Python and make predictions using the <code>predict</code> method of the model object. </p>
			<p>To illustrate this concept, we will save the ML model we created in one of the previous code examples (for example, the <code>model</code> object in the <code>iris_build_svm_model.py</code> program) to a file called <code>model.pkl</code>. In the next step, we will load the model from this file using the pickle library and make a prediction using new data to emulate the use of a model in any application. The complete sample code is as follows:</p>
			<pre>#iris_save_load_predict_model.py 
#model is creating using the code in #iris_build_svm_model.py
#saving the model to a file
with <strong class="bold">open</strong>("model.pkl", 'wb') as file:
   <strong class="bold">pickle.dump</strong>(model, file)
#loading the model from a file (in another application
with open("model.pkl", 'rb') as file:
   loaded_model = <strong class="bold">pickle.load</strong>(file)
   x_new = [[5.6, 2.6, 3.9, 1.2]]
   y_new = <strong class="bold">loaded_model.predict</strong>(x_new)
   print("X=%s, Predicted=%s" % (x_new[0], y_new[0]))</pre>
			<p>The use of the joblib library is simpler than the pickle library but it may require you to install this library if it has not been installed as a dependency of scikit-learn. The following sample code shows the use of the joblib library to save our best model, as per the evaluation of the <code>GridSearchCV</code> tool we did in the previous section, and then load the model from the file:</p>
			<pre>#iris_save_load_predict_gridmodel.py 
#grid_cv is created and trained using the code in the 
  #iris_eval_svm_model.py
joblib.dump(grid_cv.best_estimator_, "model.joblib")
loaded_model = joblib.load("model.joblib")
x_new = [[5.6, 2.5, 3.9, 1.1]]
y_new = loaded_model.predict(x_new)
print("X=%s, Predicted=%s" % (x_new[0], y_new[0]))</pre>
			<p>The code <a id="_idIndexMarker1471"/>for the joblib library is concise and simple. The prediction part of the sample code is the same as in the previous code sample for the pickle library.</p>
			<p>Now that we've learned how the model can be saved in a file, we can take the model to any application for deployment and even to a cloud platform, such as GCP AI Platform. We will discuss how to deploy our ML model on a GCP platform in the next section.</p>
			<h1 id="_idParaDest-287"><a id="_idTextAnchor325"/>Deploying and predicting an ML model on GCP Cloud</h1>
			<p>Public <a id="_idIndexMarker1472"/>cloud providers are offering several AI <a id="_idIndexMarker1473"/>platforms for training built-in models, as well as <a id="_idIndexMarker1474"/>your custom models, for <a id="_idIndexMarker1475"/>deploying the models for predictions. Google <a id="_idIndexMarker1476"/>offers the <strong class="bold">Vertex AI</strong> platform for ML use cases, whereas <a id="_idIndexMarker1477"/>Amazon and Azure <a id="_idIndexMarker1478"/>offer the <strong class="bold">Amazon SageMaker</strong> and <strong class="bold">Azure ML</strong> services, respectively. We selected Google because we assume you have set up an account with GCP and that you are already familiar with the core concepts of GCP. GCP offers its AI Platform, which is part of the Vertex AI Platform, for training and deploying your ML models at scale. The GCP AI Platform supports libraries such as scikit-learn, TensorFlow, and XGBoost. In this section, we will explore how to deploy our already trained model on GCP and then predict the outcome based on that model.</p>
			<p>Google AI Platform offers its prediction server (compute node) either through a global endpoint (<code>ml.googleapis.com</code>) or through a regional endpoint (<code>&lt;region&gt;-ml.googleapis.com</code>). The global API endpoint is recommended for batch predictions, which are available for TensorFlow on Google AI Platform. The regional endpoint offers additional protection against outages in other regions. We will use a regional endpoint to deploy our sample ML model.</p>
			<p>Before <a id="_idIndexMarker1479"/>we start deploying a model in GCP, we <a id="_idIndexMarker1480"/>will need to have a GCP project. We can create a new GCP project or use an existing GCP project that we've created <a id="_idIndexMarker1481"/>for previous exercises. The <a id="_idIndexMarker1482"/>steps of creating a GCP project and associating a billing account with it were discussed in <a href="B17189_09_Final_PG_ePub.xhtml#_idTextAnchor247"><em class="italic">Chapter 9</em></a>, <em class="italic">Python Programming for the Cloud</em>. Once we have a GCP project ready, we can deploy the <code>model.joblib</code> model, which we created in the previous section. The steps for deploying our model are as follows: </p>
			<ol>
				<li value="1">As a first step, we will create a storage bucket where we will store our model file. We can use the following Cloud SDK command to create a new bucket:<pre>gsutil mb gs://&lt;bucket name&gt;
gsutil mb gs://muasif-svc-model #Example bucket created</pre></li>
				<li>Once our bucket is ready, we can upload our model file (<code>model.joblib</code>) to this storage bucket using the following Cloud SDK command:<pre>gsutil <code>model</code> with an extension such as <code>pkl</code>, <code>joblib</code>, or <code>bst</code>, depending on the library we used to package the model.</p><p>We can now initiate a workflow to create a model object on the AI Platform by using <a id="_idIndexMarker1483"/>the following command. Note <a id="_idIndexMarker1484"/>that the name of the model must include only alphanumeric and underscore characters:</p><pre>gcloud ai-platform <strong class="bold">models</strong> <strong class="bold">create</strong> my_iris_model –  region=us-central1</pre></li>
				<li>Now, we <a id="_idIndexMarker1485"/>can create a version <a id="_idIndexMarker1486"/>for our model by using the following command:<pre>gcloud ai-platform versions <code>model</code> attribute will point to the name of the model we created in the previous step. </p><p>b) The <code>origin</code> attribute will point to the storage bucket location where the model file is residing. We will only provide the directory's location, not the path to the file.</p><p>c) The <code>framework</code> attribute is used to select which ML library to use. GCP offers scikit-learn, TensorFlow, and XGBoost.</p><p>d) <code>runtime-version</code> is for the scikit-learn library in our case.</p><p>e) <code>python-version</code> is selected as 3.7, which is the highest version offered that's by GCP AI Platform at the time of writing this book.</p><p>f) The <code>region</code> attribute is set as per the region that was selected for the model.</p><p>g) The <code>machine-type</code> attribute is optional and is used to indicate what type of compute <a id="_idIndexMarker1487"/>node to use for <a id="_idIndexMarker1488"/>model deployment. If not provided, the <code>n1-standard-2</code> machine type is used.</p><p>The <code>versions create</code> command may take a few minutes to deploy a new version. Once it is done, we will get an output similar to the following:</p><pre><strong class="bold">Using endpoint [https://us-central1-  ml.googleapis.com/]</strong>
<strong class="bold">Creating version (this might take a few   minutes)......done.   </strong></pre></li>
				<li>To check <a id="_idIndexMarker1489"/>if our model and <a id="_idIndexMarker1490"/>version have been deployed correctly, we can use the <code>describe</code> command under the <code>versions</code> context, as shown here:<pre>gcloud ai-platform <strong class="bold">versions</strong> <strong class="bold">describe</strong> v1 –  model=my_iris_model</pre></li>
				<li>Once our model has been deployed with its version, we can use new data to predict the outcome using the model we deployed on Google AI Platform. For testing, we added a couple of data records, different from the original dataset, in a JSON file (<code>input.json</code>), as follows:<pre>[5.6, 2.5, 3.9, 1.1]
[3.2, 1.4, 3.0, 1.8]</pre><p>We can use the following Cloud SDK command to predict the outcome based on the records inside the <code>input.json</code> file, as follows:</p><pre>gcloud ai-platform <strong class="bold">predict</strong> --model my_iris_model --version v1 --json-instances input.json</pre><p>The console output will show the predicted class for each record, as well as the following:</p><pre><strong class="bold">Using endpoint [https://us-central1-ml.googleapis.com/]</strong>
<strong class="bold">['Iris-versicolor', 'Iris-virginica']</strong></pre></li>
			</ol>
			<p>To use <a id="_idIndexMarker1491"/>the deployed model in our <a id="_idIndexMarker1492"/>application (local or cloud), we can use <em class="italic">Cloud SDK</em> or <em class="italic">Cloud Shell</em>, but the recommended approach is to use the Google AI API to make any predictions.</p>
			<p>With that, we have covered cloud deployment and the prediction options for our ML model <a id="_idIndexMarker1493"/>using Google AI Platform. However, you can also take your ML model to other platforms, such as Amazon SageMaker <a id="_idIndexMarker1494"/>and Azure ML for deployment <a id="_idIndexMarker1495"/>and prediction. You can find more <a id="_idIndexMarker1496"/>details about the Amazon SageMaker platform at https://docs.aws.amazon.com/sagemaker/ and more details about Azure ML at <a href="https://docs.microsoft.com/en-us/azure/machine-learning/">https://docs.microsoft.com/en-us/azure/machine-learning/</a>.</p>
			<h1 id="_idParaDest-288"><a id="_idTextAnchor326"/>Summary</h1>
			<p>In this chapter, we introduced machine learning and its main components, such as datasets, algorithms, and models, as well as training and testing a model. This introduction was followed by a discussion of popular machine learning frameworks and libraries available for Python. These include scikit-learn, TensorFlow, PyTorch, and BGBoost. We also discussed the best practices of refining and managing the data for training ML models. To get familiar with the scikit-learn library, we built a sample ML model using the SVC algorithm. We trained the model and evaluated it using techniques such as k-fold cross-validation and fine-tuning hyperparameters. We also learned how to store a trained model in a file and then load that model into any program for prediction purposes. In the end, we demonstrated how we can deploy our ML model and predict results using the Google AI Platform with a few GCP Cloud SDK commands. </p>
			<p>The concepts and the hands-on exercises included in this chapter are adequate to help build the foundation for using Python for machine learning projects. This theoretical and hands-on knowledge is beneficial for those who are looking to start using Python for machine learning.</p>
			<p>In the next chapter, we will explore how to use Python for network automation. </p>
			<h1 id="_idParaDest-289"><a id="_idTextAnchor327"/>Questions</h1>
			<ol>
				<li value="1">What are supervised learning and unsupervised learning?</li>
				<li>What is k-fold cross-validation and how it is used to evaluate a model?</li>
				<li>What is <code>RandomizedSearchCV</code> and how it is different from <code>GridSearchCV</code>?</li>
				<li>What libraries can we use to save a model in a file?</li>
				<li>Why are regional endpoints preferred option over global endpoints for Google AI Platform?</li>
			</ol>
			<h1 id="_idParaDest-290"><a id="_idTextAnchor328"/>Further reading</h1>
			<ul>
				<li><em class="italic">Machine Learning Algorithms</em>, by Giuseppe Bonaccorso</li>
				<li><em class="italic">40 Algorithms Every Programmer Should Know</em>, by Imran Ahmad</li>
				<li><em class="italic">Mastering Machine Learning with scikit-learn</em>, by Gavin Hackeling</li>
				<li><em class="italic">Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow 2</em>, by Sebastian Raschka and Vahid Mirjalili</li>
				<li><em class="italic">scikit-learn User Guide</em>, available at <a href="https://scikit-learn.org/stable/user_guide.html">https://scikit-learn.org/stable/user_guide.html</a></li>
				<li><em class="italic">Google AI Platform Guides</em> for training and deploying ML models are available at <a href="https://cloud.google.com/ai-platform/docs">https://cloud.google.com/ai-platform/docs</a> </li>
			</ul>
			<h1 id="_idParaDest-291"><a id="_idTextAnchor329"/>Answers</h1>
			<ol>
				<li value="1">In supervised learning, we provide the desired output with the training data. The desired output is not included as part of the training data for unsupervised learning.</li>
				<li>Cross-validation is a statistical technique that's used to measure the performance of an ML model. In k-fold cross-validation, we divide the data into <em class="italic">k</em> folds or slices. We train our model using the <em class="italic">k-1</em> slices of the dataset and test the accuracy of the model using the <em class="italic">kth</em> slice. We repeat this process until each <em class="italic">kth</em> slice is used as testing data. The cross-validation accuracy of the model is computed by taking the average of the accuracy of all the models we built through <em class="italic">k</em> iterations. </li>
				<li><code>RandomizedSearchCV</code> is a tool that's available with scikit-learn for applying cross-validation functionality to an ML model for randomly selected hyperparameters. <code>GridSearchCV</code> provides similar functionality to <code>RandomizedSearchCV</code>, except that it validates the model for all the combinations of hyperparameter values provided to it as an input. </li>
				<li>Pickle and Joblib.</li>
				<li>Regional endpoints offer additional protection against any outages in other regions, and the availability of computing resources is more for regional endpoints than global endpoints. </li>
			</ol>
		</div>
	</body></html>