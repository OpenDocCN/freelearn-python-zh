<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Lightning Fast Number Crunching with Numba, Parakeet, and pandas</h1></div></div></div><p>Number crunching is a topic specific to the programming world. However, given that Python is so often used for scientific research and data science problems, number crunching ends up being a very common topic in the Python world.</p><p>That being said, we could just as easily implement our algorithms using the information from the earlier six chapters, and we would most likely end up with pretty fast and performant code. Again, that information is meant to be for generic use cases. There will always be something to say about optimizing for a particular case.</p><p>In this chapter, we'll cover three options that will help us write faster and more optimized code focused on scientific problems. For each one, we'll go over the basic installation instructions. We will also look at some code samples showing the benefits of each option.</p><p>The tools we'll review in this chapter are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Numba</strong>: This is <a id="id385" class="indexterm"/>a module that allows you to write high-performance functions in pure Python by generating optimized machine code.</li><li class="listitem" style="list-style-type: disc"><strong>Parakeet</strong>: This is a <a id="id386" class="indexterm"/>runtime compiler for scientific operations written in a subset of Python. It is ideal for expressing numerical computations.</li><li class="listitem" style="list-style-type: disc"><strong>pandas</strong>: This is a<a id="id387" class="indexterm"/> library that provides a set of high-performance data structures and analysis tools.</li></ul></div><div><div><div><div><h1 class="title"><a id="ch07lvl1sec35"/>Numba</h1></div></div></div><p>Numba (<a class="ulink" href="http://numba.pydata.org/">http://numba.pydata.org/</a>) is a module that allows you to indicate (via decorators) to the <a id="id388" class="indexterm"/>Python interpreter which functions should be translated into machine code. Numba thus <a id="id389" class="indexterm"/>provides equivalent performance to C or Cython without the need to either use a different interpreter or actually code in C.</p><p>The module will generate optimized machine code just by requiring it. It can even be compiled to run on either CPU or GPU hardware.</p><p>Here is a very basic example taken from their official site, showing how to use it. We'll go into more detail in a bit:</p><div><pre class="programlisting">from numba import jit
from numpy import arange

# jit decorator tells Numba to compile this function.
# The argument types will be inferred by Numba when function is called.
@jit
def sum2d(arr):
    M, N = arr.shape
    result = 0.0
    for i in range(M):
        for j in range(N):
            result += arr[i,j]
    return result

a = arange(9).reshape(3,3)
print(sum2d(a))</pre></div><p>Note that even though the promise of Numba sounds impressive, the library is meant to optimize operations on arrays. It is considerably tied to NumPy (which we'll review shortly). So, not every function will be optimizable by it, and using it might even hurt performance.</p><p>For instance, let's take a look at a similar example, one that doesn't use NumPy and accomplishes a similar task:</p><div><pre class="programlisting">from numba import jit
from numpy import arange

# jit decorator tells Numba to compile this function.
# The argument types will be inferred by Numba when function is called.
@jit
def sum2d(arr):
    M, N = arr.shape
    result = 0.0
    for i in range(M):
        for j in range(N):
            result += arr[i,j]
    return result

a = arange(9).reshape(3,3)
print(sum2d(a))</pre></div><p>The preceding <a id="id390" class="indexterm"/>code has the following execution times, depending on whether we keep the <code class="literal">@jit</code> line or not:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">With the <code class="literal">@jit</code> line on: 0.3 seconds</li><li class="listitem" style="list-style-type: disc">Without the <code class="literal">@jit</code> line: 0.1 seconds</li></ul></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec63"/>Installation</h2></div></div></div><p>There are actually two <a id="id391" class="indexterm"/>ways to install Numba: you can either use the <code class="literal">conda</code> package manager from Anaconda, or you can just clone the GitHub repo and compile it.</p><p>If you're going for the <code class="literal">conda</code> approach, you can install the command-line tool called <code class="literal">miniconda</code> (which can be downloaded from <a class="ulink" href="http://conda.pydata.org/miniconda.html">http://conda.pydata.org/miniconda.html</a>). After<a id="id392" class="indexterm"/> installing <a id="id393" class="indexterm"/>it, you can just use the following command:</p><div><pre class="programlisting">
<strong>$ conda install numba</strong>
</pre></div><p>The following screenshot shows the output from this command. The command lists all packages that will be installed or updated, specifically <code class="literal">numpy</code> and <code class="literal">llvmlite</code>, which are <a id="id394" class="indexterm"/>direct dependencies from Numba:</p><div><img src="img/B02088_07_01.jpg" alt="Installation"/></div><p>If, on the other hand, you want to use the source code, you could clone the repo by using this command:</p><div><pre class="programlisting">
<strong>$ git clone git://github.com/numba/numba.git</strong>
</pre></div><p>You'll need to have <code class="literal">numpy</code> and <code class="literal">llvmlite</code> installed as well. After that, you can use the following command:</p><div><pre class="programlisting">
<strong>$ python setup.py build_ext –inplace</strong>
</pre></div><div><div><h3 class="title"><a id="note26"/>Note</h3><p>Note that the preceding command will succeed even if you don't have the requirements installed. However, you won't be able to use Numba unless you install them.</p></div></div><p>In order to <a id="id395" class="indexterm"/>check whether your installation was successful, you can do a simple check from the Python REPL:</p><div><pre class="programlisting">&gt;&gt;&gt; import numba
&gt;&gt;&gt; numba.__version__
'0.18.2'</pre></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec64"/>Using Numba</h2></div></div></div><p>Now that you have managed to install Numba, let's take a look at what we can do with it. The<a id="id396" class="indexterm"/> main features provided by this module are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">On-the-fly code generation</li><li class="listitem" style="list-style-type: disc">Native code generation for both CPU and GPU hardware</li><li class="listitem" style="list-style-type: disc">Integration with Python's scientific software, thanks to the Numpy dependency</li></ul></div><div><div><div><div><h3 class="title"><a id="ch07lvl3sec15"/>Numba's code generation</h3></div></div></div><p>When it comes to <a id="id397" class="indexterm"/>code generation, the main feature of Numba is its <code class="literal">@jit</code> decorator. Using it, you can mark a function for optimization under Numba's JIT compiler.</p><p>We already talked about the benefits of having a JIT compiler in the previous chapter, so we won't go into the details here. Instead, let's see how to use the decorator for our benefit.</p><p>There are several ways to use this decorator. The default one, which is also the recommended way, is the one we already showed earlier:</p><div><pre class="programlisting">Lazy compilation</pre></div><p>The following code will cause Numba to generate the optimized code once the function is called. It'll try to infer the types of its attributes and the return type of the function:</p><div><pre class="programlisting">from numba import jit

@jit
def sum2(a,b):
  return a + b</pre></div><p>If you call the <a id="id398" class="indexterm"/>same function with different types, then different code paths will be generated and optimized.</p><div><div><div><div><h4 class="title"><a id="ch07lvl4sec17"/>Eager compilation</h4></div></div></div><p>On the other<a id="id399" class="indexterm"/> hand, if you happen to know the types that your function will receive (and optionally, return), you could pass those to the <code class="literal">@jit</code> decorator. Then, only that specific case would be optimized.</p><p>The following code shows the added code needed to pass in the function signature:</p><div><pre class="programlisting">from numba import jit, <strong>int32</strong>

@jit<strong>(int32(int32, int32))</strong>
def sum2(a,b):
  return a + b</pre></div><p>Here are the most common types that are used to specify function signatures:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">void</code>: These are used as the return type for functions not returning anything</li><li class="listitem" style="list-style-type: disc"><code class="literal">intp</code> and <code class="literal">uintp</code>: These are pointer-sized integers, signed and unsigned respectively</li><li class="listitem" style="list-style-type: disc"><code class="literal">intc</code> and <code class="literal">uintc</code>: These are the C equivalent to the int and unsigned int types</li><li class="listitem" style="list-style-type: disc"><code class="literal">int8</code>, <code class="literal">int16</code>, <code class="literal">int32</code>, and <code class="literal">int64</code>: These are the fix-width integers of the corresponding bit width (for the unsigned version, just add <code class="literal">u</code> as a prefix, for instance, <code class="literal">uint8</code>)</li><li class="listitem" style="list-style-type: disc"><code class="literal">float32</code> and <code class="literal">float64</code>: These are single and double-precision floating-point numbers</li><li class="listitem" style="list-style-type: disc"><code class="literal">complex64</code> and <code class="literal">complex128</code>: These represent single and double-precision complex numbers</li><li class="listitem" style="list-style-type: disc">Arrays can also be declared by indexing any of the numeric types, for example, <code class="literal">float32[:]</code> for a one-dimensional floating-point number array and <code class="literal">int32[:,:]</code> for a two-dimensional integer array</li></ul></div></div><div><div><div><div><h4 class="title"><a id="ch07lvl4sec18"/>Other configuration settings</h4></div></div></div><p>Apart from eager compilation, there are two more options we can pass onto the <code class="literal">@jit</code> decorator. These <a id="id400" class="indexterm"/>options will help us force Numba's optimization. They are described here.</p><div><div><div><div><h5 class="title"><a id="ch07lvl5sec03"/>No GIL</h5></div></div></div><p>Whenever our <a id="id401" class="indexterm"/>code is optimized using native types (rather than using Python types), the GIL (which we discussed in <a class="link" href="ch06.html" title="Chapter 6. Generic Optimization Options">Chapter 6</a>, <em>Generic Optimization Options</em>) is no longer necessary.</p><p>We have a way of disabling the GIL in such cases. We can pass the <code class="literal">nogil=True</code> attribute to the decorator. This way, we can run Python code (or Numba code) concurrently with other threads.</p><p>That being said, remember that if you don't have the GIL limitation, then you will have to deal with the common problems of multithreaded systems (consistency, synchronization, race conditions, and so on).</p></div><div><div><div><div><h5 class="title"><a id="ch07lvl5sec04"/>NoPython mode</h5></div></div></div><p>This option <a id="id402" class="indexterm"/>will let us set the compilation mode of Numba. By default, it will try to jump between modes. It will try to decide the best mode possible depending on the code of the optimized function.</p><p>There are two modes that are available. On one hand, there is <code class="literal">object</code> mode. It generates code capable of handling all Python objects and uses the C API to perform operations on those objects. On the other hand, the <code class="literal">nopython</code> mode generates much faster code by avoiding the calls to the C API. The only problem with it is that only a subset of functions and methods are available to be used.</p><p>The <code class="literal">object</code> mode will not generate faster code unless Numba can take advantage of loop-jitting (which means that a loop can be extracted and compiled in <code class="literal">nopython</code> mode).</p><p>What we can do is force Numba to go into <code class="literal">nopython</code> mode and raise an error if such a thing is not possible. This can be done using these lines of code:</p><div><pre class="programlisting">@jit(nopython=True)
def add2(a, b):
  return a + b</pre></div><p>The issue with the <code class="literal">nopython</code> mode is that it has certain restrictions, apart from the limited subset of Python it supports:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The native types used for all values inside the function have to be capable of being inferred</li><li class="listitem" style="list-style-type: disc">No new memory can be allocated inside the function</li></ul></div><p>As an added <a id="id403" class="indexterm"/>extra, for loop-jitting to take place, the to-be-optimized loops can't have a return statement inside. Otherwise, they won't be eligible for optimization.</p><p>So, let's now look at an example of how this will look for our code:</p><div><pre class="programlisting">def sum(x, y):
    array = np.arange(x * y).reshape(x, y)
    sum = 0
    for i in range(x):
        for j in range(y):
            sum += array[i, j]
    return sum</pre></div><p>The preceding example is taken from the Numba site. It shows a function that is eligible for loop-jitting, also called loop-lifting. To make sure it works as expected, we can use the Python REPL as follows:</p><div><img src="img/B02088_07_02.jpg" alt="NoPython mode"/></div><p>Alternatively, we can also call the <code class="literal">inspect_types</code> method directly from our code. The benefit of the latter is that we'll also have access to the source code of our functions. This is a great advantage when trying to match Numba-generated instructions to lines of code.</p><p>The preceding output is useful to understand the behind-the-scenes action that goes on when we optimize our code with Numba. More specifically, we can understand how it infers the types, whether there is any automatic optimization going on, and basically, how many instructions each Python line is translated into.</p><p>Let's take a look <a id="id404" class="indexterm"/>at the output we would get from calling the <code class="literal">inspect_types</code> method from within our code (which is considerably more detailed than using the REPL):</p><div><div><h3 class="title"><a id="note27"/>Note</h3><p>Note that the following code is a reduced version of the entire output. If you want to study it completely, you need to run the command on your computer.</p></div></div><div><pre class="programlisting">sum_auto_jitting (int64, int64)
--------------------------------------------------------------------------------
# File: auto-jitting.py
# --- LINE 6 --- 

@jit

# --- LINE 7 --- 

def sum_auto_jitting(x, y):

    # --- LINE 8 --- 
    # label 0
    #   x = arg(0, name=x)  :: pyobject
    #   y = arg(1, name=y)  :: pyobject
    #   $0.1 = global(np: &lt;module 'numpy' from '/home/fernando/miniconda/lib/python2.7/site-packages/numpy/__init__.pyc'&gt;)  :: pyobject
    #   $0.2 = getattr(attr=arange, value=$0.1)  :: pyobject
    #   del $0.1
    #   $0.5 = x * y  :: pyobject
    #   $0.6 = call $0.2($0.5, )  :: pyobject
    #   del $0.5
    #   del $0.2
    #   $0.7 = getattr(attr=reshape, value=$0.6)  :: pyobject
    #   del $0.6
    #   $0.10 = call $0.7(x, y, )  :: pyobject
    #   del $0.7
    #   array = $0.10  :: pyobject
    #   del $0.10

    array = np.arange(x * y).reshape(x, y)

    # --- LINE 9 --- 
    #   $const0.11 = const(int, 0)  :: pyobject
    #   sum = $const0.11  :: pyobject
    #   del $const0.11

    sum = 0

    # --- LINE 10 --- 
    #   jump 40.1
    # label 40.1
    #   $const40.1.1 = const(LiftedLoop, LiftedLoop(&lt;function sum_auto_jitting at 0x7ff5f94756e0&gt;))  :: XXX Lifted Loop XXX
    #   $40.1.6 = call $const40.1.1(y, x, sum, array, )  :: XXX Lifted Loop XXX
    #   del y
...
 
    #   jump 103
    for i in range(x):
        # --- LINE 11 --- 
        for j in range(y):
            # --- LINE 12 --- 
            sum += array[i, j]
    # --- LINE 13 --- 
    # label 103
    #   $103.2 = cast(value=sum.1)  :: pyobject
    #   del sum.1
    #   return $103.2
    return sum
# The function contains lifted loops
# Loop at line 10
# Has 1 overloads
# File: auto-jitting.py
# --- LINE 6 --- 

@jit
# --- LINE 7 --- 
def sum_auto_jitting(x, y):
    # --- LINE 8 --- 
    array = np.arange(x * y).reshape(x, y)
    # --- LINE 9 --- 
    sum = 0
    # --- LINE 10 --- 
    # label 37
    #   y = arg(0, name=y)  :: int64
    #   x = arg(1, name=x)  :: int64
    #   sum = arg(2, name=sum)  :: int64
    #   array = arg(3, name=array)  :: array(int64, 2d, C)
    #   $37.1 = global(range: &lt;built-in function range&gt;)  :: range
    #   $37.3 = call $37.1(x, )  :: (int64,) -&gt; range_state64
    #   del x
    #   del $37.1
    #   $37.4 = getiter(value=$37.3)  :: range_iter64
    #   del $37.3
    #   $phi50.1 = $37.4  :: range_iter64
    #   del $37.4
    #   jump 50
    # label 50
    #   $50.2 = iternext(value=$phi50.1)  :: pair&lt;int64, bool&gt;
    #   $50.3 = pair_first(value=$50.2)  :: int64
    #   $50.4 = pair_second(value=$50.2)  :: bool
    #   del $50.2
    #   $phi53.1 = $50.3  :: int64
    #   del $50.3
    #   branch $50.4, 53, 102
    # label 53
    #   i = $phi53.1  :: int64
    #   del $phi53.1

    for i in range(x):

        # --- LINE 11 --- 
        #   jump 56
        # label 56
 
...
        #   j = $phi72.1  :: int64
        #   del $phi72.1

        for j in range(y):

            # --- LINE 12 --- 
            #   $72.6 = build_tuple(items=[Var(i, auto-jitting.py (10)), Var(j, auto-jitting.py (11))])  :: (int64 x 2)
            #   del j
            #   $72.7 = getitem(index=$72.6, value=array)  :: int64
         
...
            #   return $103.3

            sum += array[i, j]

    # --- LINE 13 --- 

    return sum</pre></div><p>In order to <a id="id405" class="indexterm"/>understand the preceding output, notice how every commented block starts with the line number of the original source code. It then follows with the instructions generated by that line, and finally, you'll see the uncommented Python line you wrote.</p><p>Notice the <code class="literal">LiftedLoop</code> line. In this line, you can see the automatic optimization done by Numba. Also, notice the type inferred by Numba at the end of most lines. Whenever you see a <code class="literal">pyobject</code> property, it means that it is not using a native type. Instead, it is using a generic object that wraps all Python types.</p></div></div></div><div><div><div><div><h3 class="title"><a id="ch07lvl3sec16"/>Running your code on the GPU</h3></div></div></div><p>As it's been already<a id="id406" class="indexterm"/> mentioned, Numba provides support to run our code on both CPU and GPU hardware. This, in practice, would allow us to improve the performance of <a id="id407" class="indexterm"/>certain computations by running them in an environment better suited for parallel computation than the CPU.</p><p>More specifically, Numba supports <a id="id408" class="indexterm"/>CUDA programming (<a class="ulink" href="http://www.nvidia.com/object/cuda_home_new.html">http://www.nvidia.com/object/cuda_home_new.html</a>) by translating a subset of Python functions into CUDA kernels and devices following the CUDA execution model.</p><p>CUDA is a<a id="id409" class="indexterm"/> parallel computing platform and programming model invented by Nvidia. It enables considerable speed boosts by harnessing the power of GPUs.</p><p>GPU programming is a topic that could most likely fill an entire book, so we won't go into details here. Instead, we'll just mention that Numba possesses this capability and that it can be achieved using the <code class="literal">@cuda.jit</code> decorator. For full documentation on this subject, refer to the <a id="id410" class="indexterm"/>official documents at<a class="ulink" href="http://numba.pydata.org/numba-doc/0.18.2/cuda/index.html"> http://numba.pydata.org/numba-doc/0.18.2/cuda/index.html</a>.</p></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec36"/>The pandas tool</h1></div></div></div><p>The second tool that <a id="id411" class="indexterm"/>we'll discuss in this chapter is called pandas (<a class="ulink" href="http://pandas.pydata.org/">http://pandas.pydata.org/</a>). It is an open source library that provides high-performance, easy-to-use data <a id="id412" class="indexterm"/>structures, and data-analysis tools for Python.</p><p>This tool was invented back in 2008 by developer Wes McKinney while needing a performant solution to perform quantitative analysis on financial data. The library has become one of the most popular and active projects in the Python community.</p><p>One thing to note regarding the performance of code written using pandas is that parts of its critical code paths were written using Cython (we covered Cython in <a class="link" href="ch06.html" title="Chapter 6. Generic Optimization Options">Chapter 6</a>, <em>Generic Optimization Options</em>).</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec65"/>Installing pandas</h2></div></div></div><p>Given the popularity of pandas, there are many ways to install it onto your system. It all depends on the <a id="id413" class="indexterm"/>type of setup you have.</p><p>The recommended way is to directly install the <a id="id414" class="indexterm"/>Anaconda Python distribution (<a class="ulink" href="http://docs.continuum.io/anaconda/">docs.continuum.io/anaconda/</a>), which comes packed with pandas and the rest of the SciPy stack (such as NumPy, Matplotlib, and so on). This way, by the time you're done, you'd have installed over 100 packages and downloaded several 100 megabytes of data during the process.</p><p>If, on the other hand, you don't want to deal with the full Anaconda distribution, you could use <code class="literal">miniconda</code> (which we already covered earlier when discussing Numba's installation). With this approach, you can use the <code class="literal">conda</code> package manager by following these steps:</p><div><ol class="orderedlist arabic"><li class="listitem">Create a new environment in which you can install a new version of Python using this line of code:<div><pre class="programlisting">
<strong>$ conda create -n my_new_environment python </strong>
</pre></div></li><li class="listitem">Enable that environment:<div><pre class="programlisting">
<strong>$ source activate my_new_environment</strong>
</pre></div></li><li class="listitem">Finally, install pandas:<div><pre class="programlisting">
<strong>$ conda install  pandas</strong>
</pre></div></li></ol></div><p>Additionally, pandas can be installed using the <code class="literal">pip</code> command-line tool (probably, the easiest and most compatible way of doing it) using this line of code:</p><div><pre class="programlisting">
<strong>$ pip install pandas</strong>
</pre></div><p>Finally, one more option could be installing it using your OS's package manager, given that the<a id="id415" class="indexterm"/> package is available:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Distribution</p>
</th><th style="text-align: left" valign="bottom">
<p>Repo link</p>
</th><th style="text-align: left" valign="bottom">
<p>Installation method</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Debian</p>
</td><td style="text-align: left" valign="top">
<p>
<a class="ulink" href="http://packages.debian.org/search?keywords=pandas&amp;searchon=names&amp;suite=all&amp;section=all">packages.debian.org/search?keywords=pandas&amp;searchon=names&amp;suite=all&amp;section=all</a>
</p>
</td><td style="text-align: left" valign="top">
<p>
</p><div><pre class="programlisting">
<strong>$ sudo apt-get install python-pandas</strong>
</pre></div>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Ubuntu</p>
</td><td style="text-align: left" valign="top">
<p>
<a class="ulink" href="http://packages.ubuntu.com/search?keywords=pandas&amp;searchon=names&amp;suite=all&amp;section=all">http://packages.ubuntu.com/search?keywords=pandas&amp;searchon=names&amp;suite=all&amp;section=all</a>
</p>
</td><td style="text-align: left" valign="top">
<p>
</p><div><pre class="programlisting">
<strong>$ sudo apt-get install python-pandas</strong>
</pre></div>
</td></tr><tr><td style="text-align: left" valign="top">
<p>OpenSUSE and Fedora</p>
</td><td style="text-align: left" valign="top">
<p>
<a class="ulink" href="http://software.opensuse.org/package/python-pandas?search_term=pandas">http://software.opensuse.org/package/python-pandas?search_term=pandas</a>
</p>
</td><td style="text-align: left" valign="top">
<p>
</p><div><pre class="programlisting">
<strong>$ zypper in python-pandas</strong>
</pre></div>
</td></tr></tbody></table></div><p>If the preceding options fail and you choose to install pandas from source, you can get the instructions from their website at <a class="ulink" href="http://pandas.pydata.org/pandas-docs/stable/install.html">http://pandas.pydata.org/pandas-docs/stable/install.html</a>.</p></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec66"/>Using pandas for data analysis</h2></div></div></div><p>In the world of big <a id="id416" class="indexterm"/>data and data analytics, having the right tools for the job means having the upper hand (of course, this is just one side of the story; the other one is knowing how to use them). For data analysis and, more specifically, for ad hoc tasks and data<a id="id417" class="indexterm"/> cleanup processes, one would normally use a programming language. A programming language would provide considerably more flexibility than a standard tool.</p><p>That being said, there are two languages that lead this particular performance race: R and Python. In the case of Python, this might come as a bit of a shock for some, since we've been showing nothing but evidence that Python by itself is not fast enough when it comes to number crunching. This is why libraries such as pandas are created.</p><p>It provides tools designed to ease and simplify the task commonly known as "data wrangling", such as:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The ability to load big data files into memory and stream out</li><li class="listitem" style="list-style-type: disc">Simple integration with <a id="id418" class="indexterm"/><code class="literal">matplotlib</code> (<a class="ulink" href="http://matplotlib.org/">http://matplotlib.org/</a>), which enables it to create interactive plots with very few lines of code</li><li class="listitem" style="list-style-type: disc">Simple syntax to deal with missing data, dropping fields, and so on</li></ul></div><p>Let's now look at a very simple and quick example of how using pandas can benefit the performance of your code as well as improve the syntax of your programs. The following code grabs a CSV file, with a portion of the export (a 500 MB file) from the <strong>311 service requests from 2010 to present</strong> taken from the NYC OpenData site (<a class="ulink" href="https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9">https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9</a>).</p><p>It then tries to <a id="id419" class="indexterm"/>simply <a id="id420" class="indexterm"/>calculate the number of records per zip code using both plain Python and pandas code:</p><div><pre class="programlisting">import pandas as pd 
import time
import csv
import collections

SOURCE_FILE = './311.csv'

def readCSV(fname):
  with open(fname, 'rb') as csvfile:
    reader = csv.DictReader(csvfile)
    lines = [line for line in reader]
    return lines

def process(fname):
  content = readCSV(fname)
  incidents_by_zipcode = collections.defaultdict(int)
  for record in content:
    incidents_by_zipcode[toFloat(record['Incident Zip'])] += 1
  return sorted(incidents_by_zipcode.items(), reverse=True, key=lambda a: int(a[1]))[:10]

def toFloat(number):
  try:
    return int(float(number))
  except:
    return 0

def process_pandas(fname):
  df = pd.read_csv(fname, dtype={'Incident Zip': str, 'Landmark': str, 'Vehicle Type': str, 'Ferry Direction': str})

  df['Incident Zip'] = df['Incident Zip'].apply(toFloat)
  column_names =  list(df.columns.values)
  column_names.remove("Incident Zip")
  column_names.remove("Unique Key")
  return df.drop(column_names, axis=1).groupby(['Incident Zip'], sort=False).count().sort('Unique Key', ascending=False).head(10)

init = time.clock()
total = process(SOURCE_FILE)
endtime = time.clock() - init
for item in total:
  print "%s\t%s" % (item[0], item[1])

print "(Pure Python) time: %s" % (endtime)

init = time.clock()
total = process_pandas(SOURCE_FILE)
endtime = time.clock() - init
print total
print "(Pandas) time: %s" % (endtime)</pre></div><p>The <code class="literal">process</code> function is <a id="id421" class="indexterm"/>very <a id="id422" class="indexterm"/>simple. It has only five lines of code. It loads the file, does a bit of processing (mainly manual grouping and counting), and finally, it sorts the results and returns the first 10 of them. As an added bonus, we use the <code class="literal">defaultdict</code> data type, which we mentioned a few chapters ago as a possible performance improvement in these cases.</p><p>On the other side, the <code class="literal">process_pandas</code> function does essentially the same thing, only with pandas. We have some more lines of code, but they are quite simple to understand. They're clearly "data-wrangling oriented", as you can see that there are no loops declared. We can even access the columns by name automatically and apply functions over those groups of records without having to manually iterate over them.</p><p>The following screenshot shows the output of the preceding code:</p><div><img src="img/B02088_07_04.jpg" alt="Using pandas for data analysis"/></div><p>As you can <a id="id423" class="indexterm"/>see, there is <a id="id424" class="indexterm"/>a 3-second improvement on the performance of our algorithm when we simply reimplement it in pandas. Let's now dig a bit deeper into the API of pandas in order to get even better numbers. There are two major improvements we can make to our code, and they're both related to the <code class="literal">read_csv</code> method, which uses a lot of parameters. Two of these parameters are of real interest to us:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">usecols</code>: This will only return the columns we want, effectively helping us deal with only 2 columns out of the 40+ our dataset has. This will also help us get rid of the logic that we have to drop the columns before returning the results.</li><li class="listitem" style="list-style-type: disc"><code class="literal">converters</code>: This allows us to auto-convert data with a function, instead of calling the apply method, as we will do now.</li></ul></div><p>Our new function looks like this:</p><div><pre class="programlisting">def process_pandas(fname):
  df = pd.read_csv(fname, usecols=['Incident Zip', 'Unique Key'], converters={'Incident Zip': toFloat}, dtype={'Incident Zip': str})
  return df.groupby(['Incident Zip'], sort=False).count().sort('Unique Key', ascending=False).head(10)</pre></div><p>That's right. Only two lines of code! The reader will do all the work for us. Then, we need to simply group, count, and sort. Now, check out how this looks compared to our previous results:</p><div><img src="img/B02088_07_05.jpg" alt="Using pandas for data analysis"/></div><p>That's a 10-second <a id="id425" class="indexterm"/>improvement on the performance of our algorithm and considerably less code to<a id="id426" class="indexterm"/> deal with, otherwise known as a "win-win" situation.</p><p>An added bonus to our code is that it scales. The pandas-based function can deal with a 5.9 GB file in just 30 seconds with no changes. On the other hand, our pure Python code won't even load that file in that time, let alone process it if we don't have enough resources.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec37"/>Parakeet</h1></div></div></div><p>This one is the most <a id="id427" class="indexterm"/>specific tool yet to deal with numbers in Python. It is very specific because it only supports a very narrow subset of the resulting combination of Python and NumPy. So, if you're dealing with anything outside that universe, this might not be an option for you, but if you can fit your solution into it, then keep on reading.</p><p>To be more specific about the limited universe that Parakeet supports (normally useful only to express numerical computations), here is a short list:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Types <a id="id428" class="indexterm"/>supported by Python are numbers, tuples, slices, and NumPy's arrays</li><li class="listitem" style="list-style-type: disc">Parakeet follows the upcasting rule, that is, whenever two values of different types try to reach the same variable, they'll be upcast into a unifying one. For instance, the Python expression <code class="literal">1.0 if b else false</code> would translate to <code class="literal">1.0 if b else 0.0</code>, but when automatic casting isn't possible, such as <code class="literal">1.0 if b else (1,2)</code>, then an uncatchable exception (see next point) will be raised during compilation time.</li><li class="listitem" style="list-style-type: disc">Catching or even raising exceptions isn't possible in Parakeet; neither are break and continue statements. This is because Parakeet represents programs using structured SSA (<a class="ulink" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.4503">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.4503</a>).</li><li class="listitem" style="list-style-type: disc">Array broadcasting (a feature of NumPy) is partially implemented by inserting explicit map operators based on the types of array arguments. This is a limited implementation because it can't really handle an expansion of dimensions (such as broadcasting 8 x 2 x 3 and 7 x 2 arrays).</li><li class="listitem" style="list-style-type: disc">There is only a small subset of the built-in functions of Python and NumPy that have been implemented. The complete list can be seen at <a class="ulink" href="https://github.com/iskandr/parakeet/blob/master/parakeet/mappings.py">https://github.com/iskandr/parakeet/blob/master/parakeet/mappings.py</a>.</li><li class="listitem" style="list-style-type: disc">List comprehension expressions are treated as array comprehensions.</li></ul></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec67"/>Installing Parakeet</h2></div></div></div><p>The installation <a id="id429" class="indexterm"/>of Parakeet is simple enough. There are no hard-to-get requirements if you want to go with the <code class="literal">pip</code> route. Simply type the following command:</p><div><pre class="programlisting">
<strong>$ pip install parakeet</strong>
</pre></div><p>And you're done!</p><p>If, on the other hand, you want to directly try the source code approach, you would need some other packages installed beforehand. Here is a list of these packages:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Python 2.7</strong></li><li class="listitem" style="list-style-type: disc"><strong>dsltools</strong> (<a class="ulink" href="https://github.com/iskandr/dsltools">https://github.com/iskandr/dsltools</a>)</li><li class="listitem" style="list-style-type: disc"><strong>nose</strong> for<a id="id430" class="indexterm"/> running<a id="id431" class="indexterm"/> the tests (<a class="ulink" href="https://nose.readthedocs.org/en/latest/">https://nose.readthedocs.org/en/latest/</a>)</li><li class="listitem" style="list-style-type: disc"><strong>NumPy</strong> (<a class="ulink" href="http://www.scipy.org/install.html">http://www.scipy.org/install.html</a>)</li><li class="listitem" style="list-style-type: disc"><strong>appDirs</strong> (<a class="ulink" href="https://pypi.python.org/pypi/appdirs/">https://pypi.python.org/pypi/appdirs/</a>)</li><li class="listitem" style="list-style-type: disc"><strong>gcc 4.4+</strong> for the<a id="id432" class="indexterm"/> OpenMP back-end, which is the default one</li></ul></div><div><div><h3 class="title"><a id="note28"/>Note</h3><p>If you're on a Windows box, you would have better luck if it's a 32-bit machine. Otherwise, you might be out of luck since there is no official documentation on the subject.</p><p>If you are a OS X user you'll probably want to install a more up-to-date version of the C compiler using HomeBrew, since either clang or the installed version of <code class="literal">gcc</code> might not be updated enough.</p></div></div><p>After the prerequisites <a id="id433" class="indexterm"/>are met, simply download the code from: <a class="ulink" href="https://github.com/iskandr/parakeet">https://github.com/iskandr/parakeet</a> and run<a id="id434" class="indexterm"/> the following command (from within the code's folder):</p><div><pre class="programlisting">
<strong>$ python setup.py install</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec68"/>How does Parakeet work?</h2></div></div></div><p>Instead of going deep into the details about the theory behind Parakeet, let's simply see how to use it to <a id="id435" class="indexterm"/>optimize our code. This will help you get a feel of the module without having to chew through all the documentation.</p><p>The main construct of this library is a decorator that you can apply to your functions, so Parakeet can take control and optimize your code if possible.</p><p>For our simple test, let's take one of the example functions presented on Parakeet's website and run a simple test against a <code class="literal">4000</code> * <code class="literal">4000</code> random floating-point list. The code will run the same function in both an optimized way using Parakeet, and in an unoptimized way. Then, it will measure the time each one takes to process the exact same input:</p><div><pre class="programlisting">from parakeet import jit
import random
import numpy as np
import time

@jit 
def allpairs_dist_prkt(X,Y):
  def dist(x,y):
    return np.sum( (x-y)**2 )
  return np.array([[dist(x,y) for y in Y] for x in X])

def allpairs_dist_py(X,Y):
  def dist(x,y):
    return np.sum( (x-y)**2 )
  return np.array([[dist(x,y) for y in Y] for x in X])

input_a =  [ random.random()  for x in range(0, 4000)] 
input_b =  [ random.random()  for x in range(0, 4000)] 

print "----------------------------------------------"
init = time.clock()
allpairs_dist_py(input_a, input_b)
end = time.clock()
print "Total time pure python: %s" % (end - init)
print 
init = time.clock()
allpairs_dist_prkt(input_a, input_b)
end = time.clock()
print "Total time parakeet: %s" % (end – init)
print "----------------------------------------------"</pre></div><p>In an i7 processor, with 8 GB of RAM, this is the performance we get:</p><div><img src="img/B02088_07_06.jpg" alt="How does Parakeet work?"/></div><p>The preceding<a id="id436" class="indexterm"/> screenshot shows the amazing performance boost we get in this particular function (which complies with the required subset of Python supported by Parakeet).</p><p>Simply put, the decorated function is being used as a template from which several type-specialized functions are created, one for each input type (in our case, we only need one). It is these new functions that get optimized in several different ways by Parakeet before getting translated into native code.</p><div><div><h3 class="title"><a id="note29"/>Note</h3><p>Note that even though the performance gain is amazing, Parakeet only supports a very limited version of Python, so it is not really meant to be a general purpose optimizer (quite the opposite actually).</p></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec38"/>Summary</h1></div></div></div><p>In this chapter, we covered three alternatives to data processing with Python. We covered specific use cases (but with amazing benefits), such as Parakeet, and others more generic ones, such as pandas and Numba. For all three of them, we covered the basics: description, installation, and an example. There is a lot more to discover for each one, depending on your specific needs. However, the information provided here should be enough to start you in the right direction.</p><p>For the next and final chapter, we'll cover a practical example of a script in need of optimization. We'll try to apply everything (or as much as makes sense) that we've covered so far in the book.</p></div></body></html>