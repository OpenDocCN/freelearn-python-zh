["```py\n pip install flask[async]\n```", "```py\n @current_app.route('/ch05/web/index') <st c=\"3063\">async</st> def welcome():\n    return render_template('index.html'), 200\n```", "```py\n @current_app.post('/ch05/login/add') <st c=\"3334\">async</st> def add_login():\n   async with db_session() as sess:\n            repo = LoginRepository(sess)\n            login_json = request.get_json()\n            login = Login(**login_json)\n            result = await repo.insert(login)\n            if result:\n                content = jsonify(login_json)\n                return make_response(content, 201)\n            else:\n                raise DuplicateRecordException(\"add login credential has failed\")\n```", "```py\n<st c=\"4932\">@app.before_request</st>\n<st c=\"4952\">async</st> def init_request():\n    app.logger.info('executing ' + request.endpoint + ' starts') <st c=\"5040\">@app.after_request</st>\n<st c=\"5058\">async</st> def return_response(response):\n    app.logger.info('executing ' + request.endpoint + ' stops')\n    return response\n```", "```py\n<st c=\"5630\">@app.errorhandler(404)</st>\n<st c=\"5652\">async</st> def not_found(e):\n    return jsonify(error=str(e)), 404 <st c=\"5711\">@app.errorhandler(400)</st>\n<st c=\"5733\">async</st> def bad_request(e):\n    return jsonify(error=str(e)), 400 <st c=\"5794\">@app.errorhandler(DuplicateRecordException)</st>\n<st c=\"5837\">async</st> def insert_record_exception(e):\n    return jsonify(e.to_dict()), e.code <st c=\"5912\">async</st> def server_error(e):\n    return jsonify(error=str(e)), 500\napp.register_error_handler(500, server_error)\n```", "```py\n pip install asyncpg\n```", "```py\n pip install greenlet\n```", "```py\n<st c=\"9371\">from sqlalchemy.ext.asyncio</st> import <st c=\"9407\">create_async_engine</st>, <st c=\"9428\">AsyncSession, async_scoped_session</st>\n<st c=\"9462\">from sqlalchemy.orm</st> import declarative_base, <st c=\"9508\">sessionmaker</st>\n<st c=\"9520\">from sqlalchemy.pool import NullPool</st>\n<st c=\"9557\">from asyncio import current_task</st> DB_URL = \"postgresql+<st c=\"9612\">asyncpg</st>:// postgres:admin2255@localhost:5433/ovs\"\nengine = <st c=\"9673\">create_async_engine</st>(DB_URL, <st c=\"9702\">future=True</st>, echo=True, <st c=\"9726\">pool_pre_ping=True</st>, <st c=\"9746\">poolclass=NullPool</st>)\ndb_session = <st c=\"9780\">async_scoped_session</st>(<st c=\"9802\">sessionmaker</st>(engine, expire_on_commit=False, class_=AsyncSession), <st c=\"9870\">scopefunc=current_task</st>)\nBase = declarative_base() <st c=\"9921\">def init_db():</st> import app.model.db\n```", "```py\n<st c=\"10778\">from sqlalchemy import update, delete, insert</st>\n<st c=\"10824\">from sqlalchemy.future import select</st>\n<st c=\"10861\">from sqlalchemy.orm import Session</st>\n<st c=\"10896\">from app.model.db import Voter</st> from datetime import datetime\nclass <st c=\"10964\">VoterRepository</st>: <st c=\"11128\">Session</st> object is always part of the constructor parameters of the repository class, like in the preceding <st c=\"11235\">VoterRepository</st>.\n\t\t\t<st c=\"11251\">Every operation under the</st> `<st c=\"11278\">AsyncSession</st>` <st c=\"11290\">scope requires an</st> `<st c=\"11309\">await</st>` <st c=\"11314\">process to finish its execution, which means every repository transaction must be</st> *<st c=\"11397\">coroutines</st>*<st c=\"11407\">. Every repository transaction requires an event loop to pursue its execution because of the</st> `<st c=\"11500\">async</st>`<st c=\"11505\">/</st>`<st c=\"11507\">await</st>` <st c=\"11512\">design pattern delegated</st> <st c=\"11538\">by</st> `<st c=\"11541\">AsyncSession</st>`<st c=\"11553\">.</st>\n\t\t\t<st c=\"11554\">The best-fit approach to applying the asynchronous</st> *<st c=\"11606\">INSERT</st>* <st c=\"11612\">operation is to utilize the</st> `<st c=\"11641\">insert()</st>` <st c=\"11649\">method from SQLAlchemy utilities.</st> <st c=\"11684\">The</st> `<st c=\"11688\">insert()</st>` <st c=\"11696\">method will establish the</st> *<st c=\"11723\">INSERT</st>* <st c=\"11729\">command, which</st> `<st c=\"11745\">AsyncSession</st>` <st c=\"11757\">will</st> *<st c=\"11763\">execute</st>*<st c=\"11770\">,</st> *<st c=\"11772\">commit</st>*<st c=\"11778\">, or</st> *<st c=\"11783\">roll back</st>* <st c=\"11792\">asynchronously.</st> <st c=\"11809\">The following is</st> `<st c=\"11826\">VoterRepository</st>`<st c=\"11841\">’s</st> <st c=\"11845\">INSERT transaction:</st>\n\n```", "```py\n\n\t\t\t<st c=\"12224\">As depicted in the preceding snippet, the transaction awaits the</st> `<st c=\"12290\">execute()</st>`<st c=\"12299\">,</st> `<st c=\"12301\">commit()</st>`<st c=\"12309\">, and</st> `<st c=\"12315\">close()</st>` <st c=\"12322\">methods to finish their respective tasks, which is a clear indicator that a repository operation needs to be a coroutine before executing these</st> `<st c=\"12467\">AsyncSession</st>` <st c=\"12479\">member methods.</st> <st c=\"12496\">The same applies to the following UPDATE transaction of</st> <st c=\"12552\">the</st> <st c=\"12555\">repository:</st>\n\n```", "```py\n\n\t\t\t<st c=\"12837\">The preceding</st> `<st c=\"12852\">update_voter()</st>` <st c=\"12866\">also uses the same asynchronous approach as</st> `<st c=\"12911\">insert_voter()</st>` <st c=\"12925\">using the</st> `<st c=\"12936\">AsyncSession</st>` <st c=\"12948\">methods.</st> `<st c=\"12958\">update_voter()</st>` <st c=\"12972\">also needs an event loop from</st> <st c=\"13003\">Flask to run successfully as an</st> <st c=\"13035\">asynchronous task:</st>\n\n```", "```py\n\n\t\t\t<st c=\"13281\">For the query transactions, the following are the repository’s coroutines that implement its SELECT</st> <st c=\"13382\">operations:</st>\n\n```", "```py\n\n\t\t\t<st c=\"13547\">Both</st> `<st c=\"13553\">select_all_voter()</st>` <st c=\"13571\">and</st> `<st c=\"13576\">select_voter()</st>` <st c=\"13590\">use the</st> `<st c=\"13599\">select()</st>` <st c=\"13607\">method from the</st> `<st c=\"13624\">sqlalchemy</st>` <st c=\"13634\">or</st> `<st c=\"13638\">sqlalchemy.future</st>` <st c=\"13655\">module.</st> <st c=\"13664\">With the same objective as the</st> `<st c=\"13695\">insert()</st>`<st c=\"13703\">,</st> `<st c=\"13705\">update()</st>`<st c=\"13713\">, and</st> `<st c=\"13719\">delete()</st>` <st c=\"13727\">utilities, the</st> `<st c=\"13743\">select()</st>` <st c=\"13751\">method establishes a</st> *<st c=\"13773\">SELECT</st>* <st c=\"13779\">command object, which requires the asynchronous</st> `<st c=\"13828\">execute()</st>` <st c=\"13837\">utility for its execution.</st> <st c=\"13865\">Thus, both query implementations are</st> <st c=\"13902\">also coroutines:</st>\n\n```", "```py\n\n\t\t\t<st c=\"14096\">In SQLAlchemy, the</st> *<st c=\"14116\">INSERT</st>*<st c=\"14122\">,</st> *<st c=\"14124\">UPDATE</st>*<st c=\"14130\">, and</st> *<st c=\"14136\">DELETE</st>* <st c=\"14142\">transactions technically utilize the model attributes that refer to the primary keys of the models’ corresponding DB tables, such as</st> `<st c=\"14276\">id</st>`<st c=\"14278\">. Conventionally, SQLAlchemy recommends updating and removing retrieved records based on</st> <st c=\"14366\">their</st> `<st c=\"14546\">update_precinct()</st>` <st c=\"14563\">and</st> `<st c=\"14568\">delete_voter_by_precinct()</st>` <st c=\"14594\">of</st> <st c=\"14598\">the repository:</st>\n\n```", "```py\n\n\t\t\t`<st c=\"14954\">update_precinct()</st>` <st c=\"14972\">searches a</st> `<st c=\"14984\">Voter</st>` <st c=\"14989\">record with an existing</st> `<st c=\"15014\">old_prec</st>` <st c=\"15022\">(old precinct) and replaces it with</st> `<st c=\"15059\">new_prec</st>` <st c=\"15067\">(new precinct).</st> <st c=\"15084\">There is no</st> `<st c=\"15096\">id</st>` <st c=\"15098\">primary key used to search the records for updating.</st> <st c=\"15152\">The same scenario is also depicted in</st> `<st c=\"15190\">delete_voter_by_precinct()</st>`<st c=\"15216\">, which uses the</st> `<st c=\"15233\">precinct</st>` <st c=\"15241\">non-primary key value for record removal.</st> <st c=\"15284\">Both</st> <st c=\"15288\">transactions do not conform with the</st> <st c=\"15326\">ideal</st> **<st c=\"15332\">object-relational</st>** **<st c=\"15350\">mapper</st>** <st c=\"15356\">persistence:</st>\n\n```", "```py\n\n\t\t\t<st c=\"15678\">In this regard, it is mandatory to perform</st> `<st c=\"15722\">execution_options()</st>` <st c=\"15741\">to apply the necessary synchronization strategy, preferably the</st> `<st c=\"15806\">fetch</st>` <st c=\"15811\">strategy, before executing the</st> *<st c=\"15843\">UPDATE</st>* <st c=\"15849\">and</st> *<st c=\"15854\">DELETE</st>* <st c=\"15861\">operations that do not conform with the ORM persistence.</st> <st c=\"15918\">This mechanism provides the session with the resolution to manage the changes reflected by these two operations.</st> <st c=\"16031\">For instance, the</st> `<st c=\"16049\">fetch</st>` <st c=\"16054\">strategy will let the session retrieve the primary keys of those records retrieved through the arbitrary values and will eventually update the in-memory objects or records affected by the operations and merge them into the actual table records.</st> <st c=\"16300\">This setup is essential for the asynchronous</st> <st c=\"16345\">SQLAlchemy operations.</st>\n\t\t\t<st c=\"16367\">After</st> <st c=\"16374\">building the repository layer, let us call these CRUD transactions in our view or</st> <st c=\"16456\">API functions.</st>\n\t\t\t<st c=\"16470\">Utilizing the asynchronous DB transactions</st>\n\t\t\t<st c=\"16513\">To call the</st> <st c=\"16526\">repository transactions, the asynchronous view and endpoint functions require an asynchronous context manager to create and manage</st> `<st c=\"16657\">AsyncSession</st>` <st c=\"16669\">for the repository class.</st> <st c=\"16696\">The following is an</st> `<st c=\"16716\">add_login()</st>` <st c=\"16727\">API function that adds a new</st> `<st c=\"16757\">Login</st>` <st c=\"16762\">credential to</st> <st c=\"16777\">the DB:</st>\n\n```", "```py\n\n\t\t\t<st c=\"17244\">The view function uses the</st> `<st c=\"17272\">async with</st>` <st c=\"17282\">context manager to localize the session for the coroutine or task execution.</st> <st c=\"17360\">It opens the session for that specific task that will run the</st> `<st c=\"17422\">insert_login()</st>` <st c=\"17436\">transaction of</st> `<st c=\"17452\">LoginRepository</st>`<st c=\"17467\">. Then, eventually, the session will be closed by</st> <st c=\"17516\">the repository or the context</st> <st c=\"17547\">manager itself.</st>\n\t\t\t<st c=\"17562\">Now, let us focus on another way of running asynchronous transactions using the</st> `<st c=\"17643\">asyncio</st>` <st c=\"17650\">library.</st>\n\t\t\t<st c=\"17659\">Implementing async transactions with asyncio</st>\n\t\t\t<st c=\"17704\">The</st> `<st c=\"17709\">asyncio</st>` <st c=\"17716\">module</st> <st c=\"17723\">is an easy-to-use library for implementing asynchronous tasks.</st> <st c=\"17787\">Compared to the</st> `<st c=\"17803\">threading</st>` <st c=\"17812\">module, the</st> `<st c=\"17825\">asyncio</st>` <st c=\"17832\">utilities use an event loop to execute each task, which is lightweight and easier to control.</st> <st c=\"17927\">Threading uses one whole thread to run one specific operation, while</st> `<st c=\"17996\">asyncio</st>` <st c=\"18003\">utilizes only a single event loop to run all registered tasks concurrently.</st> <st c=\"18080\">Thus, constructing an event loop is more resource friendly than running multiple threads to build</st> <st c=\"18178\">concurrent transactions.</st>\n\t\t\t`<st c=\"18202\">asyncio</st>` <st c=\"18210\">is seamlessly compatible with</st> `<st c=\"18241\">flask[async]</st>`<st c=\"18253\">, and the clear proof is the following API function that adds a new voter to the DB using the task created by the</st> `<st c=\"18367\">create_task()</st>` <st c=\"18380\">method:</st>\n\n```", "```py\n\n\t\t\t<st c=\"19128\">The</st> `<st c=\"19133\">create_task()</st>` <st c=\"19146\">method</st> <st c=\"19153\">requires a coroutine to create a task and schedule its execution in an event loop.</st> <st c=\"19237\">So, coroutines are not tasks at all, but they are the core inputs for generating these tasks.</st> <st c=\"19331\">Running the scheduled task requires the</st> `<st c=\"19371\">await</st>` <st c=\"19376\">keyword.</st> <st c=\"19386\">After its execution, the task returns a</st> `<st c=\"19426\">Future</st>` <st c=\"19432\">object that requires the task’s</st> `<st c=\"19465\">result()</st>` <st c=\"19473\">built-in method to retrieve its actual returned value.</st> <st c=\"19529\">The given API transaction creates an</st> *<st c=\"19566\">INSERT</st>* <st c=\"19572\">task from the</st> `<st c=\"19587\">insert_login()</st>` <st c=\"19601\">coroutine and retrieves a</st> `<st c=\"19628\">bool</st>` <st c=\"19632\">result</st> <st c=\"19640\">after execution.</st>\n\t\t\t<st c=\"19656\">Now,</st> `<st c=\"19662\">create_task()</st>` <st c=\"19675\">automatically utilizes Flask’s internal event loop in running its tasks.</st> <st c=\"19749\">However, for complex cases such as executing scheduled tasks,</st> `<st c=\"19811\">get_event_loop()</st>` <st c=\"19827\">or</st> `<st c=\"19831\">get_running_loop()</st>` <st c=\"19849\">are more applicable to utilize than</st> `<st c=\"19886\">create_task()</st>` <st c=\"19899\">due to their flexible settings.</st> `<st c=\"19932\">get_event_loop()</st>` <st c=\"19948\">gets the current running event loop, while</st> `<st c=\"19992\">get_running_loop()</st>` <st c=\"20010\">uses the running event in the current</st> <st c=\"20049\">system’s thread.</st>\n\t\t\t<st c=\"20065\">Another way of creating tasks from the coroutine is through</st> `<st c=\"20126\">asyncio</st>`<st c=\"20133\">’s</st> `<st c=\"20137\">ensure_future()</st>`<st c=\"20152\">. The following API uses this utility to spawn a task that lists all</st> <st c=\"20221\">user accounts:</st>\n\n```", "```py\n\n\t\t\t<st c=\"20598\">The only difference</st> <st c=\"20618\">between</st> `<st c=\"20627\">create_task()</st>` <st c=\"20640\">and</st> `<st c=\"20645\">ensure_future()</st>` <st c=\"20660\">is that the former strictly requires coroutines, while the latter can accept coroutines,</st> `<st c=\"20750\">Future</st>`<st c=\"20756\">, or any awaitable objects.</st> `<st c=\"20784\">ensure_future()</st>` <st c=\"20799\">also invokes</st> `<st c=\"20813\">create_task()</st>` <st c=\"20826\">to wrap a</st> `<st c=\"20837\">coroutine()</st>` <st c=\"20848\">argument or directly return a</st> `<st c=\"20879\">Future</st>` <st c=\"20885\">result from a</st> `<st c=\"20900\">Future</st>` <st c=\"20906\">parameter object.</st>\n\t\t\t<st c=\"20924\">On the other hand,</st> `<st c=\"20944\">flask[async]</st>` <st c=\"20956\">supports creating and running multiple tasks concurrently using</st> `<st c=\"21021\">asyncio</st>`<st c=\"21028\">. Its</st> `<st c=\"21034\">gather()</st>` <st c=\"21042\">method has</st> <st c=\"21054\">two parameters:</st>\n\n\t\t\t\t*   <st c=\"21069\">The first parameter is the sequence of coroutines,</st> `<st c=\"21121\">Future</st>`<st c=\"21127\">, or any</st> <st c=\"21136\">awaitable objects.</st>\n\t\t\t\t*   <st c=\"21154\">The second parameter is</st> `<st c=\"21179\">return_exceptions</st>`<st c=\"21196\">, which is set to</st> `<st c=\"21214\">False</st>` <st c=\"21219\">by default.</st>\n\n\t\t\t<st c=\"21231\">The following is an endpoint function that inserts multiple profiles of candidates using</st> <st c=\"21321\">concurrent tasks:</st>\n\n```", "```py\n\n\t\t\t<st c=\"21703\">The given API</st> <st c=\"21717\">expects a list of candidate profile details from</st> `<st c=\"21767\">request</st>`<st c=\"21774\">. A service named</st> `<st c=\"21792\">insert_candidate_task()</st>` <st c=\"21815\">will create a task that will convert the dictionary of objects to a</st> `<st c=\"21884\">Candidate</st>` <st c=\"21893\">instance and add the model instance to the DB through the</st> `<st c=\"21952\">insert_candidate()</st>` <st c=\"21970\">transaction of</st> `<st c=\"21986\">CandidateRepository</st>`<st c=\"22005\">. The following code showcases the complete implementation of this</st> <st c=\"22072\">service task:</st>\n\n```", "```py\n\n\t\t\t<st c=\"22389\">Since our SQLAlchemy connection pooling is</st> `<st c=\"22433\">NullPool</st>`<st c=\"22441\">, which means connection pooling is disabled, we cannot utilize the same</st> `<st c=\"22514\">AsyncSession</st>` <st c=\"22526\">for all the</st> `<st c=\"22539\">insert_candidate()</st>` <st c=\"22557\">transactions.</st> <st c=\"22572\">Otherwise,</st> `<st c=\"22583\">gather()</st>` <st c=\"22591\">will throw</st> `<st c=\"22603\">RuntimeError</st>` <st c=\"22615\">object.</st> <st c=\"22624\">Thus, each</st> `<st c=\"22635\">insert_candidate_task()</st>` <st c=\"22658\">will open a new localized session for every</st> `<st c=\"22703\">insert_candidate()</st>` <st c=\"22721\">task execution.</st> <st c=\"22738\">To add connection pooling, replace</st> `<st c=\"22773\">NullPool</st>` <st c=\"22781\">with</st> `<st c=\"22787\">QueuePool</st>`<st c=\"22796\">,</st> `<st c=\"22798\">AsyncAdaptedQueuePool</st>`<st c=\"22819\">,</st> <st c=\"22821\">or</st> `<st c=\"22824\">SingletonThreadPool</st>`<st c=\"22843\">.</st>\n\t\t\t<st c=\"22844\">Now, the</st> `<st c=\"22854\">await</st>` <st c=\"22859\">keyword will concurrently run the sequence of tasks registered in</st> `<st c=\"22926\">gather()</st>` <st c=\"22934\">and propagate all results in the resulting</st> `<st c=\"22978\">tuple</st>` <st c=\"22983\">of</st> `<st c=\"22987\">Future</st>` <st c=\"22993\">once these tasks have finished their execution successfully.</st> <st c=\"23055\">The order of these</st> `<st c=\"23074\">Future</st>` <st c=\"23080\">objects is the same as the sequence of the awaitable objects provided in</st> `<st c=\"23154\">gather()</st>`<st c=\"23162\">. If a task has encountered failure or exception, it will not throw any exception and pre-empt the other task execution because</st> `<st c=\"23290\">return_exceptions</st>` <st c=\"23307\">of</st> `<st c=\"23311\">gather()</st>` <st c=\"23319\">is</st> `<st c=\"23323\">False</st>`<st c=\"23328\">. Instead, the failed task will join as a typical awaitable object in the</st> <st c=\"23402\">resulting</st> `<st c=\"23412\">tuple</st>`<st c=\"23417\">.</st>\n\t\t\t<st c=\"23418\">By the way, the</st> <st c=\"23434\">given</st> `<st c=\"23441\">add_list_candidates()</st>` <st c=\"23462\">API function will return the number of successful INSERT tasks that persisted in the</st> <st c=\"23548\">candidate profiles.</st>\n\t\t\t<st c=\"23567\">The next section will discuss how to de-couple Flask components using the event-driven behavior of</st> <st c=\"23667\">Flask</st> **<st c=\"23673\">signals</st>**<st c=\"23680\">.</st>\n\t\t\t<st c=\"23681\">Utilizing asynchronous signal notifications</st>\n\t\t\t<st c=\"23725\">Flask has a</st> <st c=\"23737\">built-in lightweight event-driven mechanism called signals that can establish a loosely coupled software architecture using subscription-based event handling.</st> <st c=\"23897\">It can trigger single or multiple transactions depending on the purpose.</st> <st c=\"23970\">The</st> `<st c=\"23974\">blinker</st>` <st c=\"23981\">module provides the building blocks for Flask signal utilities, so install</st> `<st c=\"24057\">blinker</st>` <st c=\"24064\">using the</st> `<st c=\"24075\">pip</st>` <st c=\"24078\">command if it is not yet in the</st> <st c=\"24111\">virtual environment.</st>\n\t\t\t<st c=\"24131\">Flask has built-in signals and listens to many Flask events and callbacks such as</st> `<st c=\"24214\">render_template()</st>`<st c=\"24231\">,</st> `<st c=\"24233\">before_request()</st>`<st c=\"24249\">, and</st> `<st c=\"24255\">after_request()</st>`<st c=\"24270\">. These signals, such as</st> `<st c=\"24295\">request_started</st>`<st c=\"24310\">,</st> `<st c=\"24312\">request_finished</st>`<st c=\"24328\">,</st> `<st c=\"24330\">message_flashed</st>`<st c=\"24345\">, and</st> `<st c=\"24351\">template_rendered</st>`<st c=\"24368\">, are found in the</st> `<st c=\"24387\">flask</st>` <st c=\"24392\">module.</st> <st c=\"24401\">For instance, once a component connects to</st> `<st c=\"24444\">template_rendered</st>`<st c=\"24461\">, it will run its callback method after</st> `<st c=\"24501\">render_template()</st>` <st c=\"24518\">finishes posting a Jinja template.</st> <st c=\"24554\">However, our target is to create custom</st> *<st c=\"24594\">asynchronous signals</st>*<st c=\"24614\">.</st>\n\t\t\t<st c=\"24615\">To create custom signals, import the</st> `<st c=\"24653\">Namespace</st>` <st c=\"24662\">class from the</st> `<st c=\"24678\">flask.signals</st>` <st c=\"24691\">module and instantiate it.</st> <st c=\"24719\">Use its instance to define and instantiate specific custom signals, each having a unique name.</st> <st c=\"24814\">The following is a snippet from our applications that creates an event signal for election date verification and another for retrieving all the</st> <st c=\"24958\">election details:</st>\n\n```", "```py\n<st c=\"25411\">@check_election.connect</st>\n<st c=\"25435\">async</st> def check_election_event(<st c=\"25467\">app</st>, election_date):\n    async with db_session() as sess:\n        async with sess.begin():\n            repo = ElectionRepository(sess)\n            records = await repo.select_all_election()\n            election_rec = [rec.to_json() for rec in records if rec.election_date == datetime.strptime(election_date, '%Y-%m-%d').date()]\n            if len(election_rec) > 0:\n                return True\n            return False\n```", "```py\n<st c=\"25934\">@list_elections.connect</st>\n<st c=\"25958\">async</st> def list_elections_event(app):\n    async with db_session() as sess:\n        async with sess.begin():\n            repo = ElectionRepository(sess)\n            records = await repo.select_all_election()\n            election_rec = [rec.to_json() for rec in records]\n            return election_rec\n```", "```py\n<st c=\"27031\">@current_app.post('/ch05/election/verify')</st>\n<st c=\"27074\">async</st> def verify_election():\n    election_json = request.get_json()\n    election_date = election_json['election_date'] <st c=\"27186\">result_tuple = await</st> <st c=\"27206\">check_election.send_async(current_app,</st> <st c=\"27245\">election_date=election_date)</st> isApproved = result_tuple[0][1]\n    if isApproved:\n        return jsonify(message=f'election for {election_date} is approved'), 201\n    else:\n        return jsonify(message=f'election for {election_date} is disabled'), 201\n```", "```py\n pip install celery\n```", "```py\n CELERY_BROKER_URL = \"redis://127.0.0.1:6379/0\"\nCELERY_RESULT_BACKEND = \"redis://127.0.0.1:6379/0 <st c=\"30982\">[CELERY]</st> celery_store_errors_even_if_ignored = true\ntask_create_missing_queues = true\ntask_store_errors_even_if_ignored = true\ntask_ignore_result = false\nbroker_connection_retry_on_startup = true\ncelery_task_serializer = \"pickle\"\ncelery_result_serializer = \"pickle\"\ncelery_event_serializer = \"json\"\ncelery_accept_content = [\"pickle\", \"application/json\", \"application/x-python-serialize\"]\ncelery_result_accept_content = [\"pickle\", \"application/json\", \"application/x-python-serialize\"]\n```", "```py\n<st c=\"33632\">from celery import Celery, Task</st> from flask import Flask\ndef <st c=\"33692\">celery_init_app</st>(app: Flask) -> Celery:\n    class FlaskTask(Task):\n        def __call__(self, *args: object, **kwargs: object) -> object: <st c=\"33818\">with app.app_context():</st> return self.run(*args, **kwargs)\n    celery_app = <st c=\"33888\">Celery(app.name, task_cls=FlaskTask,</st> <st c=\"33924\">broker=app.config[\"CELERY_BROKER_URL\"],</st> <st c=\"33964\">backend=app.config[\"CELERY_RESULT_BACKEND\"])</st><st c=\"34009\">celery_app.config_from_object(app.config[\"CELERY\"])</st><st c=\"34061\">celery_app.set_default()</st> return celery_app\n```", "```py\n<st c=\"35243\">from celery import shared_task</st>\n<st c=\"35274\">from asyncio import run</st>\n<st c=\"35298\">@shared_task</st> def add_vote_task_wrapper(details): <st c=\"35348\">async</st> def add_vote_task(details):\n        try: <st c=\"35387\">async</st> with db_session() as sess: <st c=\"35420\">async</st> with sess.begin():\n                repo = VoteRepository(sess)\n                details_dict = loads(details)\n                print(details_dict)\n                election = Vote(**details_dict)\n                result = await repo.insert(election)\n                if result: <st c=\"35603\">return str(True)</st> else: <st c=\"35626\">return str(False)</st> except Exception as e:\n            print(e) <st c=\"35676\">return str(False)</st> return <st c=\"35776\">add_vote_task_wrapper()</st>, must not be a coroutine. A Celery task is a class generated by any callable decorated by <st c=\"35890\">@shared_task</st>, which means it cannot propagate the <st c=\"35940\">await</st> keyword outwards with the <st c=\"35972\">async</st> function call. However, it can enclose an asynchronous local method to handle all the operations asynchronously, such as <st c=\"36099\">add_vote_task()</st>, which wraps and executes the INSERT transactions for new vote details. The Celery task can apply the <st c=\"36217\">asyncio</st>’s <st c=\"36228\">run()</st> utility method to run its async local function.\n\t\t\t<st c=\"36281\">Since our Celery app does not ignore the result, our task returns a Boolean value converted into a string, a safe object type that a task can return to the caller.</st> <st c=\"36446\">Although it is feasible to use pickling, through the</st> `<st c=\"36499\">pickle</st>` <st c=\"36505\">module, to pass an argument to or transport return values from Celery tasks to the callers, it might open vulnerabilities that can pose security risks to the application, such as accidentally exposing confidential information stored in the pickled object or unpickling/de-serializing</st> <st c=\"36790\">malicious objects.</st>\n\t\t\t<st c=\"36808\">Another approach to manage the Celery task’s input arguments and returned values, especially if they are collection types, is through the</st> `<st c=\"36947\">loads()</st>` <st c=\"36954\">and</st> `<st c=\"36959\">dumps()</st>` <st c=\"36966\">utilities of the</st> `<st c=\"36984\">json</st>` <st c=\"36988\">module.</st> <st c=\"36997\">This</st> `<st c=\"37002\">loads()</st>` <st c=\"37009\">function deserializes a JSON string into a Python object while</st> `<st c=\"37073\">dumps()</st>` <st c=\"37080\">serializes Python objects (e.g., dictionaries, lists, etc.) into a JSON formatted string.</st> <st c=\"37171\">However, sometimes, using</st> `<st c=\"37197\">dumps()</st>` <st c=\"37204\">to convert these objects to strings is not certain.</st> <st c=\"37257\">There are data in the string payload that can cause serialization error, because Celery does not support their default format, such as</st> `<st c=\"37392\">time</st>`<st c=\"37396\">,</st> `<st c=\"37398\">date</st>`<st c=\"37402\">, and</st> `<st c=\"37408\">datetime</st>`<st c=\"37416\">. In this</st> <st c=\"37425\">scenario, the</st> `<st c=\"37440\">dumps()</st>` <st c=\"37447\">method needs a custom serializer to convert these temporal data types to their equivalent</st> *<st c=\"37538\">ISO 8601</st>* <st c=\"37546\">formats.</st> <st c=\"37556\">The following Celery task has the same problem, thus the presence of a</st> <st c=\"37627\">custom</st> `<st c=\"37634\">json_date_serializer()</st>`<st c=\"37656\">:</st>\n\n```", "```py\n\n\t\t\t<st c=\"38122\">Among the many</st> <st c=\"38137\">ways to implement a date serializer,</st> `<st c=\"38175\">json_date_serializer()</st>` <st c=\"38197\">uses the</st> `<st c=\"38207\">time</st>`<st c=\"38211\">’s</st> `<st c=\"38215\">isoformat()</st>` <st c=\"38226\">method to convert the time object to an</st> *<st c=\"38267\">ISO 8601</st>* <st c=\"38275\">or</st> *<st c=\"38279\">HH:MM:SS:ssssss</st>* <st c=\"38294\">formatted string value so that the task can return the list of vote records without conflicts on the</st> `<st c=\"38396\">date</st>` <st c=\"38400\">types.</st>\n\t\t\t<st c=\"38407\">Running the Celery worker server</st>\n\t\t\t<st c=\"38440\">After creating the</st> <st c=\"38460\">Celery tasks, the next step is to run the built-in Celery server through the following command to check whether the server can</st> <st c=\"38587\">recognize them:</st>\n\n```", "```py\n\n\t\t\t`<st c=\"38659\">main</st>` <st c=\"38664\">in the command is the</st> `<st c=\"38687\">main.py</st>` <st c=\"38694\">module, and</st> `<st c=\"38707\">celery_app</st>` <st c=\"38717\">is the Celery instance found in the</st> `<st c=\"38754\">main.py</st>` <st c=\"38761\">module.</st> <st c=\"38770\">The</st> `<st c=\"38774\">loglevel</st>` <st c=\"38782\">option creates a console logger for the server, and the</st> `<st c=\"38839\">P</st>` <st c=\"38840\">option indicates the</st> *<st c=\"38862\">concurrency pool</st>*<st c=\"38878\">, which is</st> `<st c=\"38889\">solo</st>` <st c=\"38893\">in the given command.</st> *<st c=\"38916\">Figure 5</st>**<st c=\"38924\">.1</st>* <st c=\"38926\">shows the screen details after the</st> <st c=\"38962\">server started.</st>\n\t\t\t![Figure 5.1 – Server details after Celery server startup](img/B19383_05_001.jpg)\n\n\t\t\t<st c=\"39751\">Figure 5.1 – Server details after Celery server startup</st>\n\t\t\t<st c=\"39806\">Celery server fetched the</st> `<st c=\"39833\">add_vote_task_wrapper()</st>` <st c=\"39856\">and</st> `<st c=\"39861\">list_all_votes_task_wrapper()</st>` <st c=\"39890\">tasks, as indicated in</st> *<st c=\"39914\">Figure 5</st>**<st c=\"39922\">.1</st>*<st c=\"39924\">. Thus, Flask views and endpoints can now use these tasks to cast and view the votes from users.</st> <st c=\"40021\">Aside from the list of ready-to-use tasks, the server logs also show details of the default task queue,</st> `<st c=\"40125\">celery</st>`<st c=\"40131\">. Also, it indicates the concurrency pool type, which is</st> `<st c=\"40188\">solo</st>`<st c=\"40192\">, and has a concurrency worker limit of</st> `<st c=\"40232\">8</st>`<st c=\"40233\">. Among the</st> `<st c=\"40245\">prefork</st>`<st c=\"40252\">,</st> `<st c=\"40254\">eventlet</st>`<st c=\"40262\">,</st> `<st c=\"40264\">gevent</st>`<st c=\"40270\">, and</st> `<st c=\"40276\">solo</st>` <st c=\"40280\">concurrency options, our applications use</st> `<st c=\"40323\">solo</st>` <st c=\"40327\">and</st> `<st c=\"40332\">eventlet</st>`<st c=\"40340\">. However, to use</st> `<st c=\"40358\">eventlet</st>`<st c=\"40366\">, install the</st> `<st c=\"40380\">eventlet</st>` <st c=\"40388\">module using the</st> `<st c=\"40406\">pip</st>` <st c=\"40409\">command:</st>\n\n```", "```py\n\n\t\t\t<st c=\"40439\">Our application uses the solo Celery execution pool because it runs within the worker process, which makes a task’s performance fast.</st> <st c=\"40574\">This pool is fit for running resource-intensive tasks.</st> <st c=\"40629\">Other better options are</st> `<st c=\"40654\">eventlet</st>` <st c=\"40662\">and</st> `<st c=\"40667\">gevent</st>`<st c=\"40673\">, which spawn greenlets, sometimes called green threads, cooperative threads, or coroutines.</st> <st c=\"40766\">Most Input/Output-bound tasks run better with</st> `<st c=\"40812\">eventlet</st>` <st c=\"40820\">or</st> `<st c=\"40824\">gevent</st>` <st c=\"40830\">because they generate more threads and emulate a multi-threading environment</st> <st c=\"40908\">for efficiency.</st>\n\t\t\t<st c=\"40923\">Once the Celery</st> <st c=\"40940\">server loads and recognizes the tasks with a worker managing the message queues, Flask view and endpoint functions can invoke the tasks now using Celery</st> <st c=\"41093\">utility methods.</st>\n\t\t\t<st c=\"41109\">Utilizing the Celery tasks</st>\n\t\t\t<st c=\"41136\">Once the</st> <st c=\"41146\">Celery worker server runs with the list of tasks, Flask’s</st> `<st c=\"41204\">async</st>` <st c=\"41209\">views and endpoints can now access and run these tasks like signals.</st> <st c=\"41279\">These tasks will execute only when the caller invokes their built-in</st> `<st c=\"41348\">delay()</st>` <st c=\"41355\">or</st> `<st c=\"41359\">apply_async()</st>` <st c=\"41372\">methods.</st> <st c=\"41382\">The following endpoint function runs</st> `<st c=\"41419\">add_vote_task_wrapper()</st>` <st c=\"41442\">to cast a vote for</st> <st c=\"41462\">a user:</st>\n\n```", "```py\n\n\t\t\t<st c=\"41700\">The given</st> `<st c=\"41711\">add_vote()</st>` <st c=\"41721\">endpoint retrieves the request JSON data and converts it to a string before passing it as an argument to</st> `<st c=\"41827\">add_vote_task_wrapper()</st>`<st c=\"41850\">. Without using the</st> `<st c=\"41870\">await</st>` <st c=\"41875\">keyword, the Celery task has</st> `<st c=\"41905\">apply_async()</st>`<st c=\"41918\">, which the invoker can use to trigger its execution with the argument.</st> `<st c=\"41990\">apply_async()</st>` <st c=\"42003\">returns an</st> `<st c=\"42015\">AsyncResult</st>` <st c=\"42026\">object with a</st> `<st c=\"42041\">get()</st>` <st c=\"42046\">method that returns the returned value, if any.</st> <st c=\"42095\">It also has a</st> `<st c=\"42109\">traceback</st>` <st c=\"42118\">variable</st> <st c=\"42127\">that retrieves an exception stack trace when the execution raises</st> <st c=\"42194\">an exception.</st>\n\t\t\t<st c=\"42207\">From creating asynchronous background tasks, let us move on to WebSocket implementation with</st> <st c=\"42301\">asynchronous transactions.</st>\n\t\t\t<st c=\"42327\">Building WebSockets with asynchronous transactions</st>\n\t\t\t<st c=\"42378\">WebSocket is</st> <st c=\"42391\">a well-known bi-directional communication between a server and browser-based clients.</st> <st c=\"42478\">Many popular frameworks such as Spring, JSF, Jakarta EE, Django, FastAPI, Angular, and React support this technology, and Flask is one of them.</st> <st c=\"42622\">However, this chapter will focus on implementing WebSocket and its client applications using the</st> <st c=\"42719\">asynchronous paradigm.</st>\n\t\t\t<st c=\"42741\">Creating the client-side application</st>\n\t\t\t<st c=\"42778\">Our WebSocket implementation with the</st> <st c=\"42817\">client-side application is in the</st> `<st c=\"42851\">ch05-web</st>` <st c=\"42859\">project.</st> <st c=\"42869\">Calling</st> `<st c=\"42877\">/ch05/votecount/add</st>` <st c=\"42896\">from the</st> `<st c=\"42906\">vote_count.py</st>` <st c=\"42919\">view module will give us the following HTML form in</st> *<st c=\"42972\">Figure 5</st>**<st c=\"42980\">.2</st>*<st c=\"42982\">, which handles the data entry for the final vote tally per precinct or</st> <st c=\"43054\">election district:</st>\n\t\t\t![Figure 5.2 – Client-side application for adding final vote counts](img/B19383_05_002.jpg)\n\n\t\t\t<st c=\"43230\">Figure 5.2 – Client-side application for adding final vote counts</st>\n\t\t\t<st c=\"43295\">Our</st> <st c=\"43299\">WebSocket captures election data from officers and then updates DB records in real time.</st> <st c=\"43389\">It retrieves a string message from the server as a response.</st> <st c=\"43450\">The HTML form and the</st> `<st c=\"43507\">WebSocket</st>` <st c=\"43516\">are in</st> `<st c=\"43524\">pages/vote_count_add.html</st>` <st c=\"43549\">of</st> `<st c=\"43553\">ch05-web</st>`<st c=\"43561\">. The following snippet is the JS code that communicates with our</st> <st c=\"43627\">server-side</st> `<st c=\"43639\">WebSocket</st>`<st c=\"43648\">:</st>\n\n```", "```py\n\n\t\t\t<st c=\"44681\">The preceding JS script will connect to the Flask server through</st> `<st c=\"44747\">ws://localhost:5001/ch05/vote/save/ws</st>` <st c=\"44784\">by instantiating the</st> `<st c=\"44806\">WebSocket</st>` <st c=\"44815\">API.</st> <st c=\"44821\">When the connection is ready, the client can ask for vote details from the client through the form components.</st> <st c=\"44932\">Submitting the data will create a JSON object out of the form data before sending the JSON formatted details to the server through the</st> `<st c=\"45067\">WebSocket</st>` <st c=\"45076\">connection.</st>\n\t\t\t<st c=\"45088\">On the other</st> <st c=\"45102\">hand, to capture the message from the server, the client must create a listener to the message emitter by calling the WebSocket’s</st> `<st c=\"45232\">addEventListener()</st>`<st c=\"45250\">, which will watch and retrieve any JSON message from the Flask server.</st> <st c=\"45322\">The custom</st> `<st c=\"45333\">add_log()</st>` <st c=\"45342\">function will render the message to the front end using the</st> `<st c=\"45403\"><</st>``<st c=\"45404\">span></st>` <st c=\"45409\">tag.</st>\n\t\t\t<st c=\"45414\">Next, let us focus on the WebSocket implementation per se using the</st> `<st c=\"45483\">flask-sock</st>` <st c=\"45493\">module.</st>\n\t\t\t<st c=\"45501\">Creating server-side transactions</st>\n\t\t\t<st c=\"45535\">There are many ways to implement a</st> <st c=\"45571\">server-side message emitter, such as</st> `<st c=\"45608\">WebSocket</st>`<st c=\"45617\">, in Flask, and many Flask extensions can provide support for it, such as</st> `<st c=\"45691\">flask-socketio</st>`<st c=\"45705\">,</st> `<st c=\"45707\">flask-sockets</st>`<st c=\"45720\">, and</st> `<st c=\"45726\">flask-sock</st>`<st c=\"45736\">. This chapter will use the</st> `<st c=\"45764\">flask-sock</st>` <st c=\"45774\">module to create WebSocket routes because it can implement WebSocket communication with minimal configuration and setup.</st> <st c=\"45896\">So, to start, install the</st> `<st c=\"45922\">flask-sock</st>` <st c=\"45932\">extension using the</st> `<st c=\"45953\">pip</st>` <st c=\"45956\">command:</st>\n\n```", "```py\n\n\t\t\t<st c=\"45988\">Then, integrate the extension to Flask by instantiating the</st> `<st c=\"46049\">Sock</st>` <st c=\"46053\">class with the</st> `<st c=\"46069\">app</st>` <st c=\"46072\">instance as its required argument.</st> <st c=\"46108\">The following</st> `<st c=\"46122\">app/__init__.py</st>` <st c=\"46137\">snippet shows the</st> `<st c=\"46156\">flask-sock</st>` <st c=\"46166\">setup:</st>\n\n```", "```py\n from app import sock <st c=\"46680\">@sock.route('/ch05/vote/save/ws')</st> def add_vote_count_server(<st c=\"46740\">ws</st>):\n    async def add_vote_count():\n        while True:\n            vote_count_json = ws.receive()\n            vote_count_dict = loads(vote_count_json)\n            async with db_session() as sess:\n                repo = VoteCountRepository(sess)\n                vote_count = VoteCount(**vote_count_dict)\n                result = await repo.insert(vote_count)\n                if result:\n                    ws.send(\"data added\")\n                else:\n                    ws.send(\"data not added\")\n    run(add_vote_count())\n```", "```py\n [\n    {\n        \"election_id\": 1,\n        \"cand_id\": \"PHL-101\"\n    },\n    {\n        \"election_id\": 1,\n        \"cand_id\": \"PHL-111\"\n    },\n    {\n        \"election_id\": 1,\n        \"cand_id\": \"PHL-005\"\n    }\n]\n```", "```py\n<st c=\"49690\">from simple_websocket import Client</st>\n<st c=\"49726\">from json import dumps</st>\n<st c=\"49749\">@current_app.post(\"/ch05/check/vote/counts/client\")</st> def bulk_check_vote_count(): <st c=\"49831\">ws =</st> <st c=\"49835\">Client('ws://127.0.0.1:5000/ch05/check/vote/counts/ws',</st><st c=\"49891\">headers={\"Access-Control-Allow-Origin\": \"*\"})</st><st c=\"49937\">candidates = request.get_json()</st> for candidate in candidates:\n            try:\n                print(f'client sent: {candidate}') <st c=\"50039\">ws.send(dumps(candidate))</st><st c=\"50064\">vote_count = ws.receive()</st> print(f'client recieved: {vote_count}')\n            except Exception as e:\n                print(e)\n    return jsonify(message=\"done client transaction\"), 201\n```", "```py\n pip install simple-websocket\n```", "```py\n<st c=\"50823\">@sock.route(\"/ch05/check/vote/counts/ws\")</st> def bulk_check_vote_count_ws(<st c=\"50895\">websocket</st>): <st c=\"50909\">async</st> def vote_count():\n      While True:\n        try: <st c=\"50950\">candidate = websocket.receive()</st> candidate_map = loads(candidate)\n          print(f'server received: {candidate_map}')\n          async with db_session() as sess:\n            async with sess.begin():\n               repo = VoteRepository(sess) <st c=\"51144\">count = await repo.count_votes_by_candidate(</st> <st c=\"51188\">candidate_map[\"cand_id\"],</st> <st c=\"51214\">int(candidate_map[\"election_id\"]))</st> vote_count_data = {\"cand_id\": candidate_map[\"cand_id\"], \"vote_count\": count} <st c=\"51327\">websocket.send(dumps(vote_count_data))</st> print(f'server sent: {candidate_map}')\n        except  Exception as e:\n          print(e)\n          break <st c=\"51527\">run()</st> from <st c=\"51538\">asyncio</st> to execute asynchronous query transactions from <st c=\"51594\">VoteRepository</st> and extract the total number of votes for each candidate sent by the API client. The emitter will send a newly formed dictionary containing the candidate’s ID and counted votes back to the client API in string format. So, the handshake in this setup is between two Flask components, the WebSocket route and an async Flask API.\n\t\t\t<st c=\"51935\">There are other client-server interactions that</st> `<st c=\"51984\">flask[async]</st>` <st c=\"51996\">can build, and one of these is</st> <st c=\"52028\">the SSE.</st>\n\t\t\t<st c=\"52036\">Implementing asynchronous SSE</st>\n\t\t\t<st c=\"52066\">Like the</st> <st c=\"52075\">WebSocket, the SSE is a real-time mechanism for sending messages from the server to client applications.</st> <st c=\"52181\">However, unlike the WebSocket, it establishes unidirectional communication between the server and</st> <st c=\"52279\">client applications.</st>\n\t\t\t<st c=\"52299\">There are many ways to build server push solutions in Flask, but our applications prefer using the built-in</st> <st c=\"52408\">response’s</st> `<st c=\"52419\">text/event-stream</st>`<st c=\"52436\">.</st>\n\t\t\t<st c=\"52437\">Implementing the message publisher</st>\n\t\t\t<st c=\"52472\">SSE is a</st> *<st c=\"52482\">server push</st>* <st c=\"52493\">solution</st> <st c=\"52503\">that requires an input source where it can listen for incoming data or messages in real time and push that data to its client applications.</st> <st c=\"52643\">One of the reliable sources that will work with SSE is</st> <st c=\"52698\">a</st> **<st c=\"52700\">message broker</st>**<st c=\"52714\">, which can store messages from various resources.</st> <st c=\"52765\">It can also help the SSE generator function to listen for incoming messages before yielding them to</st> <st c=\"52865\">the clients.</st>\n\t\t\t<st c=\"52877\">In this chapter, our</st> `<st c=\"52899\">ch05-web</st>` <st c=\"52907\">application utilizes Redis as the broker, which our</st> `<st c=\"52960\">ch05-api</st>` <st c=\"52968\">project used for invoking the Celery background tasks.</st> <st c=\"53024\">However, in this scenario, there is a need to create a Redis client application that will implement its publisher-subscribe pattern.</st> <st c=\"53157\">So, install the</st> *<st c=\"53173\">redis-py</st>* <st c=\"53181\">extension by using the</st> `<st c=\"53205\">pip</st>` <st c=\"53208\">command:</st>\n\n```", "```py\n\n\t\t\t<st c=\"53235\">This extension will provide us with the</st> `<st c=\"53276\">Redis</st>` <st c=\"53281\">client that will connect to the Redis server once instantiated in the</st> `<st c=\"53352\">main</st>` <st c=\"53356\">module.</st> <st c=\"53365\">The following</st> `<st c=\"53379\">main.py</st>` <st c=\"53386\">snippet shows the setup of the Redis</st> <st c=\"53424\">client application:</st>\n\n```", "```py\n\n\t\t\t<st c=\"53614\">The Redis callable requires details about the DB (</st>`<st c=\"53664\">db</st>`<st c=\"53667\">), port, and host address of the installed Redis server as its parameters for setup.</st> <st c=\"53753\">Since Celery tasks can return bytes, the</st> `<st c=\"53794\">Redis</st>` <st c=\"53799\">constructor should set its</st> `<st c=\"53827\">decode_response</st>` <st c=\"53842\">parameter to</st> `<st c=\"53856\">True</st>` <st c=\"53860\">to enable binary message data decoding mechanism and receive decoded strings.</st> <st c=\"53939\">The instance,</st> `<st c=\"53953\">redis_conn</st>`<st c=\"53963\">, will be the key to the message publisher implementation needed by the SSE.</st> <st c=\"54040\">In the complaint module of the application, our input source is a form view function that requests the user its statement and voter’s ID before pushing these details to the Redis</st> <st c=\"54219\">broker.</st> <st c=\"54227\">The following is the view that publishes data to the</st> <st c=\"54280\">Redis server:</st>\n\n```", "```py\n\n\t\t\t<st c=\"54763\">The</st> `<st c=\"54768\">Redis</st>` <st c=\"54773\">client</st> <st c=\"54780\">instance,</st> `<st c=\"54791\">redis_conn</st>`<st c=\"54801\">, has a</st> `<st c=\"54809\">publish()</st>` <st c=\"54818\">method that stores a message to Redis under a specific topic or channel, a point where a subscriber will fetch the message from the broker.</st> <st c=\"54959\">The name of our Redis channel</st> <st c=\"54989\">is</st> `<st c=\"54992\">complaint_channel</st>`<st c=\"55009\">.</st>\n\t\t\t<st c=\"55010\">Building the server push</st>\n\t\t\t<st c=\"55035\">Our SSE will be</st> <st c=\"55051\">the subscriber to</st> `<st c=\"55070\">complaint_channel</st>`<st c=\"55087\">. It will create a subscriber object first, through</st> `<st c=\"55139\">redis_conn</st>`<st c=\"55149\">’s</st> `<st c=\"55153\">pubsub()</st>` <st c=\"55161\">method, to connect to Redis and eventually use the broker to listen for any published message from the form view.</st> <st c=\"55276\">The following is our SSE implementation using the</st> `<st c=\"55326\">async</st>` <st c=\"55331\">Flask route:</st>\n\n```", "```py\n pip install reactivex\n```", "```py\n<st c=\"58442\">from reactivex import Observable, Observer, create</st>\n<st c=\"58493\">from reactivex.disposable import Disposable</st>\n<st c=\"58537\">from asyncio import ensure_future</st>\n<st c=\"58571\">async</st> def extract_precinct_tally(rec_dict):\n    del rec_dict['id']\n    del rec_dict['election_id']\n    del rec_dict['approved_date']\n    return str(rec_dict) <st c=\"58714\">async</st> def create_tally_data(<st c=\"58742\">observer</st>):\n    async with db_session() as sess:\n          async with sess.begin():\n            repo = VoteCountRepository(sess)\n            records = await repo.select_all_votecount()\n            votecount_rec = [rec.to_json() for rec in records]\n            print(votecount_rec)\n            for vc in votecount_rec:\n                rec_str = await extract_precinct_tally(vc) <st c=\"59030\">observer.on_next(rec_str)</st><st c=\"59055\">observer.on_completed()</st>\n<st c=\"59388\">create_tally_data()</st> and <st c=\"59412\">extract_precinct_tally()</st> service operations that utilize these <st c=\"59475\">async</st> queries also asynchronous. The objective is not to call these <st c=\"59543\">async</st> services directly from the API layer but to wrap these service transactions in one <st c=\"59632\">Observable</st> object through <st c=\"59658\">create_observable()</st> and let the API functions subscribe to it. However, the problem is that <st c=\"59750\">create_observable()</st> can’t be <st c=\"59779\">async</st> because <st c=\"59793\">reactivex</st> does not allow <st c=\"59818\">async</st> to deal with its operators such as <st c=\"59859\">create()</st>, <st c=\"59869\">from_iterable()</st>, and <st c=\"59890\">from_list()</st>.\n\t\t\t<st c=\"59902\">With that, the</st> `<st c=\"59918\">create_observable()</st>` <st c=\"59937\">custom function needs a local-scoped subscriber function,</st> `<st c=\"59996\">on_subscribe()</st>`<st c=\"60010\">, that will invoke</st> `<st c=\"60029\">create_task()</st>` <st c=\"60042\">or</st> `<st c=\"60046\">ensure_future()</st>` <st c=\"60061\">with an event loop to create a task for the</st> `<st c=\"60106\">create_tally_data()</st>` <st c=\"60125\">coroutine and return it as a</st> `<st c=\"60155\">Disposable</st>` <st c=\"60165\">resource object.</st> <st c=\"60183\">A disposable resource link allows for the cleaning up of the resources used by the observable operators during the subscription.</st> <st c=\"60312\">Creating the</st> `<st c=\"60325\">async</st>` <st c=\"60330\">subscriber disposable will help manage the</st> <st c=\"60374\">Flask resources.</st>\n\t\t\t<st c=\"60390\">In connection with this setup,</st> `<st c=\"60422\">create_tally_data()</st>` <st c=\"60441\">will now emit the vote counts from the repository to the observer or subscriber.</st> <st c=\"60523\">The only goal now of</st> `<st c=\"60544\">create_observable()</st>` <st c=\"60563\">is to return its created</st> `<st c=\"60589\">Observable</st>` <st c=\"60599\">based on the</st> `<st c=\"60613\">on_subscribe()</st>` <st c=\"60627\">emissions.</st>\n\t\t\t<st c=\"60638\">The API transaction needs</st> <st c=\"60665\">to run the</st> `<st c=\"60676\">create_tally_date()</st>` <st c=\"60695\">service and extract all the emitted vote counts by invoking</st> `<st c=\"60756\">create_observable()</st>` <st c=\"60775\">and subscribing to its returned</st> `<st c=\"60808\">Observable</st>` <st c=\"60818\">through the</st> `<st c=\"60831\">subscribe()</st>` <st c=\"60842\">method.</st> <st c=\"60851\">The following is the</st> `<st c=\"60872\">list_votecount_tally()</st>` <st c=\"60894\">endpoint function that creates a subscription to the</st> <st c=\"60948\">returned</st> `<st c=\"60957\">Observable</st>`<st c=\"60967\">:</st>\n\n```", "```py\n\n\t\t\t`<st c=\"61484\">subscribe()</st>` <st c=\"61496\">has three</st> <st c=\"61506\">callback methods that are all active and ready to run anytime</st> <st c=\"61569\">when triggered:</st>\n\n\t\t\t\t*   `<st c=\"61584\">on_next()</st>`<st c=\"61594\">: This executes when</st> `<st c=\"61616\">Observer</st>` <st c=\"61624\">receives</st> <st c=\"61634\">emitted data.</st>\n\t\t\t\t*   `<st c=\"61647\">on_error()</st>`<st c=\"61658\">: This executes when</st> `<st c=\"61680\">Observable</st>` <st c=\"61690\">encounters an exception along</st> <st c=\"61721\">its operators.</st>\n\t\t\t\t*   `<st c=\"61735\">on_completed()</st>`<st c=\"61750\">: This runs when</st> `<st c=\"61768\">Observable</st>` <st c=\"61778\">completes</st> <st c=\"61789\">its task.</st>\n\n\t\t\t<st c=\"61798\">Our</st> `<st c=\"61803\">on_next()</st>` <st c=\"61812\">callback adds all the emitted data to the</st> <st c=\"61855\">tally list.</st>\n\t\t\t<st c=\"61866\">Now, the execution of the</st> `<st c=\"61893\">Observable</st>` <st c=\"61903\">operations will not be possible without the event loop.</st> <st c=\"61960\">The API function needs the currently running event loop for the</st> `<st c=\"62024\">create_tally_data()</st>` <st c=\"62043\">coroutine execution, and thus its</st> `<st c=\"62078\">get_event_loop()</st>` <st c=\"62094\">invocation.</st> <st c=\"62107\">The API will return the tally list once it disposes of the task running</st> <st c=\"62179\">in</st> `<st c=\"62182\">Observable</st>`<st c=\"62192\">.</st>\n\t\t\t<st c=\"62193\">Even though our framework is asynchronous Flask or the solutions applied to our applications are reactive and asynchronous, Flask will remain a WSGI-based framework, unlike FastAPI.</st> <st c=\"62376\">The platform is still not 100% asynchronous friendly.</st> <st c=\"62430\">However, if the application requires a 100% Flask environment, replace Flask with one of its variations called the</st> *<st c=\"62545\">Quart</st>* <st c=\"62550\">framework.</st>\n\t\t\t<st c=\"62561\">Choosing Quart over Flask 2.x</st>\n\t\t\t<st c=\"62591\">Quart</st> <st c=\"62597\">is a Flask framework in and out but with a platform that runs entirely on</st> `<st c=\"62672\">asyncio</st>`<st c=\"62679\">. Many of the core features from Flask are part of the Quart framework, except for the main application class.</st> <st c=\"62790\">The framework has its</st> `<st c=\"62812\">Quart</st>` <st c=\"62817\">class to set up</st> <st c=\"62834\">an application.</st>\n\t\t\t<st c=\"62849\">Moreover, Quart supports the</st> `<st c=\"63016\">hypercorn</st>` <st c=\"63025\">server, which supports HTTP/2</st> <st c=\"63056\">request-response transactions.</st>\n\t\t\t<st c=\"63086\">Since Quart and</st> <st c=\"63102\">Flask are almost the same, migration of Flask applications to Quart is seamless and straightforward.</st> `<st c=\"63204\">ch05-quart</st>` <st c=\"63214\">is a product of migrating our</st> `<st c=\"63245\">ch05-web</st>` <st c=\"63253\">and</st> `<st c=\"63258\">ch05-api</st>` <st c=\"63266\">projects into using the Quart platform.</st> <st c=\"63307\">The following is the</st> `<st c=\"63328\">app/__init__.py</st>` <st c=\"63343\">configuration of</st> <st c=\"63361\">that project:</st>\n\n```", "```py\n\n\t\t\t<st c=\"64039\">The</st> <st c=\"64044\">Quart framework has a</st> `<st c=\"64066\">Quart</st>` <st c=\"64071\">class to build the application.</st> <st c=\"64104\">Its constructor parameters, such as</st> `<st c=\"64140\">template_folder</st>` <st c=\"64155\">and</st> `<st c=\"64160\">static_folder</st>`<st c=\"64173\">, are the same as those of Flask.</st> <st c=\"64207\">The framework can also recognize TOML</st> <st c=\"64245\">configuration files.</st>\n\t\t\t<st c=\"64265\">On the repository layer, the framework has a</st> `<st c=\"64311\">quart-sqlalchemy</st>` <st c=\"64327\">extension module that supports asynchronous ORM operations for Quart applications.</st> <st c=\"64411\">There is no need to rewrite the model and repository classes during the migration because all the helper classes and utilities are the same as the</st> `<st c=\"64558\">flask-sqlalchemy</st>` <st c=\"64574\">extension.</st> <st c=\"64586\">The same</st> `<st c=\"64595\">init_db()</st>` <st c=\"64604\">from the project’s application factory will set up and load the helper functions, methods, and model classes of the</st> `<st c=\"64721\">quart-sqlalchemy</st>` <st c=\"64737\">ORM.</st>\n\t\t\t<st c=\"64742\">Quart also supports blueprint, application factory design, or even the hybrid approach in building the application.</st> <st c=\"64859\">However, the current version,</st> *<st c=\"64889\">Quart 0.18.4</st>*<st c=\"64901\">, does not have an easy way to manage the asynchronous request context so that modules inside the application can access the</st> `<st c=\"65026\">current_app</st>` <st c=\"65037\">proxy for view or API implementation.</st> <st c=\"65076\">That’s why, from the given configuration, the views and endpoints can be defined inside</st> `<st c=\"65164\">create_app()</st>` <st c=\"65176\">using</st> `<st c=\"65183\">add_url_rule()</st>`<st c=\"65197\">. Decorating them with</st> `<st c=\"65220\">route()</st>` <st c=\"65227\">in their respective module script using the</st> `<st c=\"65272\">app</st>` <st c=\"65275\">object or</st> `<st c=\"65286\">current_app</st>` <st c=\"65297\">raises an exception.</st> <st c=\"65319\">Now, the following are the view and endpoint implementations in the</st> <st c=\"65387\">Quart platform:</st>\n\n```", "```py\n pip install hypercorn\n```", "```py\n\n```", "```py\n\n```", "```py\n\n```", "```py\n\n```"]