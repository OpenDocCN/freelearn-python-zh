["```py\n    import multiprocessing \n    import time \n    class Process(multiprocessing.Process): \n        def __init__(self, id): \n            super(Process, self).__init__() \n            self.id = id \n        def run(self): \n            time.sleep(1) \n            print(\"I'm the process with id: \n              {}\".format(self.id))\n```", "```py\n    if __name__ == '__main__': \n        p = Process(0) \n        p.start()\n```", "```py\n    if __name__ == '__main__': \n       p = Process(0) \n       p.start() \n       p.join()\n```", "```py\n    if __name__ == '__main__': \n        processes = Process(1), Process(2), Process(3), \n          Process(4) \n        [p.start() for p in processes]\n```", "```py\n    pool = multiprocessing.Pool() \n    pool = multiprocessing.Pool(processes=4)\n```", "```py\n    def square(x): \n        return x * x \n    inputs = [0, 1, 2, 3, 4] \n    outputs = pool.map(square, inputs)\n```", "```py\n    outputs_async = pool.map_async(square, inputs) \n    outputs = outputs_async.get()\n```", "```py\n    results_async = [pool.apply_async(square, i) for i in \\\n      range(100))] \n    results = [r.get() for r in results_async]\n```", "```py\n    from concurrent.futures import ProcessPoolExecutor\n    executor = ProcessPoolExecutor(max_workers=4)\n    fut = executor.submit(square, 2)\n    # Result:\n    # <Future at 0x7f5b5c030940 state=running>\n    result = executor.map(square, [0, 1, 2, 3, 4])\n    list(result)\n    # Result:\n    # [0, 1, 4, 9, 16]\n```", "```py\n    from concurrent.futures import wait, as_completed\n    fut1 = executor.submit(square, 2)\n    fut2 = executor.submit(square, 3)\n    wait([fut1, fut2])\n    # Then you can extract the results using fut1.result() \n      and fut2.result()\n    results = as_completed([fut1, fut2])\n    list(results)\n    # Result:\n    # [4, 9]\n```", "```py\n    hits/total = area_circle/area_square = pi/4 \n    pi = 4 * hits/total\n```", "```py\n    import random \n    samples = 1000000 \n    hits = 0 \n    for i in range(samples): \n        x = random.uniform(-1.0, 1.0) \n        y = random.uniform(-1.0, 1.0) \n        if x**2 + y**2 <= 1: \n            hits += 1 \n\n    pi = 4.0 * hits/samples\n```", "```py\n    def sample(): \n        x = random.uniform(-1.0, 1.0) \n        y = random.uniform(-1.0, 1.0) \n        if x**2 + y**2 <= 1: \n            return 1 \n        else: \n            return 0 \n    pool = multiprocessing.Pool() \n    results_async = [pool.apply_async(sample) for i in \\\n      range(samples)] \n    hits = sum(r.get() for r in results_async)\n```", "```py\n$ time python -c 'import pi; pi.pi_serial()'\nreal    0m0.734s\nuser    0m0.731s\nsys     0m0.004s\n$ time python -c 'import pi; pi.pi_apply_async()'\nreal    1m36.989s\nuser    1m55.984s\nsys     0m50.386\n```", "```py\n    def sample_multiple(samples_partial): \n        return sum(sample() for i inrange(samples_partial)) \n    n_tasks = 10 \n    chunk_size = samples/n_tasks \n    pool = multiprocessing.Pool() \n    results_async = [pool.apply_async(sample_multiple, \\\n      chunk_size) for i in range(n_tasks)] \n    hits = sum(r.get() for r in results_async)\n```", "```py\n$ time python -c 'import pi; pi.pi_apply_async_chunked()'\nreal    0m0.325s\nuser    0m0.816s\nsys     0m0.008s\n```", "```py\n    shared_variable = multiprocessing.Value('f') \n    shared_variable.value = 0\n```", "```py\n    class Process(multiprocessing.Process): \n        def __init__(self, counter): \n            super(Process, self).__init__() \n            self.counter = counter \n        def run(self): \n            for i in range(1000): \n                self.counter.value += 1\n```", "```py\n    def main(): \n        counter = multiprocessing.Value('i', lock=True) \n        counter.value = 0 \n        processes = [Process(counter) for i in range(4)] \n        [p.start() for p in processes] \n        [p.join() for p in processes] # processes are done \n        print(counter.value)\n```", "```py\n    class Process(multiprocessing.Process): \n        def __init__(self, counter): \n            super(Process, self).__init__() \n            self.counter = counter \n        def run(self): \n            for i in range(1000): \n                with lock: # acquire the lock \n                    self.counter.value += 1 \n                # release the lock\n```", "```py\n    import numpy as np \n    def square_serial(double[:] inp): \n        cdef int i, size \n        cdef double[:] out \n        size = inp.shape[0] \n        out_np = np.empty(size, 'double') \n        out = out_np \n        for i in range(size): \n            out[i] = inp[i]*inp[i] \n        return out_np\n```", "```py\n    with nogil: \n        for i in prange(size): \n            out[i] = inp[i]*inp[i]\n```", "```py\n    for i in prange(size, nogil=True): \n        out[i] = inp[i]*inp[i]\n```", "```py\n    for i in prange(size, nogil=True): \n        out[i] = inp[i]*inp[i] \n        with gil:   \n            x = 0 # Python assignment\n```", "```py\n    from distutils.core import setup \n    from distutils.extension import Extension \n    from Cython.Build import cythonize \n    hello_parallel = Extension(\n        'hello_parallel', \n        ['hello_parallel.pyx'], \n        extra_compile_args=['-fopenmp'], \n        extra_link_args=['-fopenmp']) \n    setup( \n       name='Hello', \n       ext_modules = cythonize(['cevolve.pyx', \n         hello_parallel]), \n    )\n```", "```py\n    def c_evolve(double[:, :] r_i,double[:] ang_speed_i, \\\n                 double timestep,int nsteps): \n        # cdef declarations \n        for i in range(nsteps): \n            for j in range(nparticles): \n                # loop body\n```", "```py\n        for j in range(nparticles): \n            for i in range(nsteps): \n                # loop body\n```", "```py\n    for j in prange(nparticles, nogil=True)\n```", "```py\n    In [3]: %timeit benchmark(10000, 'openmp') # Running on \n      4 processors\n    1 loops, best of 3: 599 ms per loop \n    In [4]: %timeit benchmark(10000, 'cython') \n    1 loops, best of 3: 1.35 s per loop\n```", "```py\n$pip install Theano\n```", "```py\n    import theano.tensor as T\n    import theano as th\n    a = T.scalar('a')\n    a_sq = a ** 2\n    print(a_sq)\n    # Output:\n    # Elemwise{pow,no_inplace}.0\n```", "```py\n    compute_square = th.function([a], a_sq)\n```", "```py\n    compute_square(2)\n    4.0\n```", "```py\n    a.dtype\n    # Result: \n    # float64\n```", "```py\n    a = T.vector('a')\n    b = T.vector('b')\n    ab_sq = a**2 + b**2\n    compute_square = th.function([a, b], ab_sq)\n    compute_square([0, 1, 2], [3, 4, 5])\n    # Result:\n    # array([  9.,  17.,  29.])\n```", "```py\n    x = T.vector('x')\n    y = T.vector('y')\n    hit_test = x ** 2 + y ** 2 < 1\n```", "```py\n    hits = hit_test.sum()\n    total = x.shape[0]\n    pi_est = 4 * hits/total\n```", "```py\n    calculate_pi = th.function([x, y], pi_est)\n    x_val = np.random.uniform(-1, 1, 30000)\n    y_val = np.random.uniform(-1, 1, 30000)\n    import timeit\n    res = timeit.timeit(\"calculate_pi(x_val, y_val)\", \\\n    \"from __main__ import x_val, y_val, calculate_pi\", \\\n      number=100000)\n    print(res)\n    # Output:\n    # 10.905971487998613\n```", "```py\nimport theano\ntheano.config.openmp = True\ntheano.config.openmp_elemwise_minsize = 10\n```", "```py\n    # File: test_theano.py\n    import numpy as np\n    import theano.tensor as T\n    import theano as th\n    th.config.openmp_elemwise_minsize = 1000\n    th.config.openmp = True\n    x = T.vector('x')\n    y = T.vector('y')\n    hit_test = x ** 2 + y ** 2 <= 1\n    hits = hit_test.sum()\n    misses = x.shape[0]\n    pi_est = 4 * hits/misses\n    calculate_pi = th.function([x, y], pi_est)\n    x_val = np.random.uniform(-1, 1, 30000)\n    y_val = np.random.uniform(-1, 1, 30000)\n    import timeit\n    res = timeit.timeit(\"calculate_pi(x_val, y_val)\", \n                        \"from __main__ import x_val, y_val, \n                        calculate_pi\", number=100000)\n    print(res)\n```", "```py\n    $ OMP_NUM_THREADS=1 python test_theano.py\n    10.905971487998613\n    $ OMP_NUM_THREADS=2 python test_theano.py\n    7.538279129999864\n    $ OMP_NUM_THREADS=3 python test_theano.py\n    9.405846934998408\n    $ OMP_NUM_THREADS=4 python test_theano.py\n    14.634153957000308\n```", "```py\n    # Older version\n    # hits = hit_test.sum()\n    hits = hit_test.astype('int32').sum()\n```", "```py\n    $ OMP_NUM_THREADS=1 python test_theano.py\n    5.822126664999814\n    $ OMP_NUM_THREADS=2 python test_theano.py\n    5.697357518001809\n    $ OMP_NUM_THREADS=3 python test_theano.py \n    5.636914656002773\n    $ OMP_NUM_THREADS=4 python test_theano.py\n    5.764030176000233\n```", "```py\n    calculate_pi = th.function([x, y], pi_est, \n      profile=True)\n```", "```py\n    calculate_pi.profile.summary()\n```", "```py\nFunction profiling\n==================\n  Message: test_theano.py:15\n... other output\n   Time in 100000 calls to Function.__call__: 1.015549e+01s\n... other output\nClass\n---\n<% time> <sum %> <apply time> <time per call> <type> \n<#call> <#apply> <Class name>\n.... timing info by class\nOps\n---\n<% time> <sum %> <apply time> <time per call> <type> <#call> \n<#apply> <Op name>\n  80.0%    80.0%       6.722s       6.72e-\n05s     C     100000        1   Elemwise{Composite{LT((sqr(\ni0) + sqr(i1)), i2)}}\n  19.4%    99.4%       1.634s       1.63e-\n05s     C     100000        1   Sum{acc_dtype=int64}\n   0.3%    99.8%       0.027s       2.66e-\n07s     C     100000        1   Elemwise{Composite{((i0 * \ni1) / i2)}}\n   0.2%   100.0%       0.020s       2.03e-\n07s     C     100000        1   Shape_i{0}\n   ... (remaining 0 Ops account for   0.00%(0.00s) of the \n     runtime)\nApply\n------\n<% time> <sum %> <apply time> <time per call> <#call> <id> \n<Apply name>\n... timing info by apply\n```", "```py\n$pip install tensorflow\n```", "```py\n    import tensorflow.compat.v1 as tf\n    tf.disable_v2_behavior()\n    a = tf.placeholder('float64')\n```", "```py\n    a = tf.placeholder('float64')\n    b = tf.placeholder('float64')\n    ab_sq = a**2 + b**2\n    with tf.Session() as session:\n        result = session.run(ab_sq, feed_dict={a: [0, 1, \\\n          2], b: [3, 4, 5]})\n        print(result)\n    # Output:\n    # array([  9.,  17.,  29.])\n```", "```py\n    import tensorflow.compat.v1 as tf\n    tf.disable_v2_behavior()\n    import numpy as np\n    import time\n    import sys\n    NUM_THREADS = int(sys.argv[1])\n    samples = 30000\n    print('Num threads', NUM_THREADS)\n    x_data = np.random.uniform(-1, 1, samples)\n    y_data = np.random.uniform(-1, 1, samples)\n    x = tf.placeholder('float64', name='x')\n    y = tf.placeholder('float64', name='y')\n    hit_tests = x ** 2 + y ** 2 <= 1.0\n    hits = tf.reduce_sum(tf.cast(hit_tests, 'int32'))\n    with tf.Session\n        (config=tf.ConfigProto\n            (inter_op_parallelism_threads=NUM_THREADS,\n             intra_op_parallelism_threads=NUM_THREADS)) as \\\n               sess:\n        start = time.time()\n        for i in range(10000):\n            sess.run(hits, {x: x_data, y: y_data})\n        print(time.time() - start)\n```", "```py\n    $ python test_tensorflow.py 1\n    13.059704780578613\n    $ python test_tensorflow.py 2\n    11.938535928726196\n    $ python test_tensorflow.py 3\n    12.783955574035645\n    $ python test_tensorflow.py 4\n    12.158143043518066\n```", "```py\n    from theano import function, config\n    import theano.tensor as T\n    import numpy as np\n    import time\n    N = 5000\n    A_data = np.random.rand(N, N).astype('float32')\n    B_data = np.random.rand(N, N).astype('float32')\n    A = T.matrix('A')\n    B = T.matrix('B')\n    f = function([A, B], T.dot(A, B))\n    start = time.time()\n    f(A_data, B_data)\n    print(\"Matrix multiply ({}) took {} seconds\".format(N, \\\n      time.time() - start))\n    print('Device used:', config.device)\n```", "```py\n    $ THEANO_FLAGS=device=gpu python test_theano_gpu.py \n    Matrix multiply (5000) took 0.4182612895965576 seconds\n    Device used: gpu\n```", "```py\n    $ THEANO_FLAGS=device=cpu python test_theano.py \n    Matrix multiply (5000) took 2.9623231887817383 seconds\n    Device used: cpu\n```", "```py\n    import tensorflow as tf\n    import time\n    import numpy as np\n    N = 5000\n    A_data = np.random.rand(N, N)\n    B_data = np.random.rand(N, N)\n    # Creates a graph.\n    with tf.device('/gpu:0'):\n        A = tf.placeholder('float32')\n        B = tf.placeholder('float32')\n        C = tf.matmul(A, B)\n    with tf.Session() as sess:\n        start = time.time()\n        sess.run(C, {A: A_data, B: B_data})\n        print('Matrix multiply ({}) took: {}'.format(N, \\\n          time.time() - start))\n```", "```py\n    # Ran with tf.device('/gpu:0')\n    Matrix multiply (5000) took: 1.417285680770874\n    # Ran with tf.device('/cpu:0')\n    Matrix multiply (5000) took: 2.9646761417388916 \n```", "```py\n    import numba as nb\n    import math\n    @nb.vectorize(target='cpu')\n    def expon_cpu(x, y):\n        return math.exp(x) + math.exp(y)\n```", "```py\n    @nb.vectorize(['float32(float32, float32)'], \n      target='cuda')\n    def expon_gpu(x, y):\n        return math.exp(x) + math.exp(y)\n```", "```py\n    import numpy as np\n    import time\n    N = 1000000\n    niter = 100\n    a = np.random.rand(N).astype('float32')\n    b = np.random.rand(N).astype('float32')\n    # Trigger compilation\n    expon_cpu(a, b)\n    expon_gpu(a, b)\n    # Timing\n    start = time.time()\n    for i in range(niter):\n       expon_cpu(a, b)\n    print(\"CPU:\", time.time() - start)\n    start = time.time()\n    for i in range(niter): \n        expon_gpu(a, b) \n    print(\"GPU:\", time.time() - start) \n    # Output:\n    # CPU: 2.4762887954711914\n    # GPU: 0.8668839931488037\n```"]