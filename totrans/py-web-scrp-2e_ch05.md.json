["```py\n>>> from lxml.html import fromstring\n>>> from downloader import Downloader \n>>> D = Downloader() \n>>> html = D('http://example.webscraping.com/search') \n>>> tree = fromstring(html) \n>>> tree.cssselect('div#results a') \n[] \n\n```", "```py\n<div id=\"results\"> \n</div> \n\n```", "```py\n>>> import requests\n>>> resp = requests.get('http://example.webscraping.com/ajax/search.json?page=0&page_size=10&search_term=a') \n>>> resp.json()\n{'error': '', \n 'num_pages': 22, \n 'records': [{'country': 'Afghanistan', \n 'id': 1261, \n 'pretty_link': '<div><a href=\"/view/Afghanistan-1\"><img        src=\"img/af.png\" />Afghanistan</a></div>'}, \n ...] \n} \n\n```", "```py\nimport requests\nimport string\n\nPAGE_SIZE = 10\n\ntemplate_url = 'http://example.webscraping.com/ajax/' + \n    'search.json?page={}&page_size={}&search_term={}'\n\ncountries = set()\n\nfor letter in string.ascii_lowercase:\n    print('Searching with %s' % letter)\n    page = 0\n    while True:\n        resp = requests.get(template_url.format(page, PAGE_SIZE, letter))\n        data = resp.json()\n        print('adding %d more records from page %d' %\n              (len(data.get('records')), page))\n        for record in data.get('records'):\n            countries.add(record['country'])\n        page += 1\n        if page >= data['num_pages']:\n            break\n\nwith open('../data/countries.txt', 'w') as countries_file:\n    countries_file.write('n'.join(sorted(countries)))\n\n```", "```py\n$ python chp5/json_scraper.py\nSearching with a\nadding 10 more records from page 0\nadding 10 more records from page 1\n...\n\n```", "```py\n>>> url = 'http://example.webscraping.com/ajax/search.json?page=0&page_size=10&search_term=' \n>>> requests.get(url).json()['num_pages'] \n0 \n\n```", "```py\n>>> requests.get(url + '*').json()['num_pages'] \n0 \n\n```", "```py\n>>> requests.get(url + '.').json()['num_pages'] \n26\n\n```", "```py\n>>> url = 'http://example.webscraping.com/ajax/search.json?page=0&page_size=20&search_term=.' \n>>> requests.get(url).json()['num_pages'] \n13 \n\n```", "```py\n>>> url = 'http://example.webscraping.com/ajax/search.json?page=0&page_size=1000&search_term=.' \n>>> requests.get(url).json()['num_pages'] \n1 \n\n```", "```py\nfrom csv import DictWriter\nimport requests\n\nPAGE_SIZE = 1000\n\ntemplate_url = 'http://example.webscraping.com/ajax/' + \n 'search.json?page=0&page_size={}&search_term=.'\n\nresp = requests.get(template_url.format(PAGE_SIZE))\ndata = resp.json()\nrecords = data.get('records')\n\nwith open('../data/countries.csv', 'w') as countries_file:\n   wrtr = DictWriter(countries_file, fieldnames=records[0].keys())\n   wrtr.writeheader()\n   wrtr.writerows(records)\n\n```", "```py\ntry: \n    from PySide.QtGui import * \n    from PySide.QtCore import * \n    from PySide.QtWebKit import * \nexcept ImportError: \n    from PyQt4.QtGui import * \n    from PyQt4.QtCore import * \n    from PyQt4.QtWebKit import * \n\n```", "```py\n<html> \n    <body> \n        <div id=\"result\"></div> \n        <script> \n        document.getElementById(\"result\").innerText = 'Hello World'; \n        </script> \n    </body> \n</html> \n\n```", "```py\n>>> import lxml.html\n>>> from chp3.downloader import Downloader\n>>> D = Downloader()\n>>> url = 'http://example.webscraping.com/dynamic' \n>>> html = D(url) \n>>> tree = lxml.html.fromstring(html) \n>>> tree.cssselect('#result')[0].text_content() \n'' \n\n```", "```py\n>>> app = QApplication([]) \n>>> webview = QWebView() \n>>> loop = QEventLoop() \n>>> webview.loadFinished.connect(loop.quit) \n>>> webview.load(QUrl(url)) \n>>> loop.exec_() \n>>> html = webview.page().mainFrame().toHtml() \n>>> tree = lxml.html.fromstring(html) \n>>> tree.cssselect('#result')[0].text_content() \n'Hello World' \n\n```", "```py\napp = QApplication([]) \nwebview = QWebView() \nloop = QEventLoop() \nwebview.loadFinished.connect(loop.quit) \nwebview.load(QUrl('http://example.webscraping.com/search')) \nloop.exec_() \nwebview.show() \nframe = webview.page().mainFrame() \nframe.findFirstElement('#search_term'). \n       setAttribute('value', '.') \nframe.findFirstElement('#page_size option:checked'). \n       setPlainText('1000') \nframe.findFirstElement('#search'). \n       evaluateJavaScript('this.click()') \napp.exec_() \n\n```", "```py\n>>> elements = None \n>>> while not elements: \n...     app.processEvents() \n...     elements = frame.findAllElements('#results a') \n... \n>>> countries = [e.toPlainText().strip() for e in elements] \n>>> print(countries)\n['Afghanistan', 'Aland Islands', ... , 'Zambia', 'Zimbabwe'] \n\n```", "```py\nimport time \n\nclass BrowserRender(QWebView): \n    def __init__(self, show=True): \n        self.app = QApplication(sys.argv) \n        QWebView.__init__(self) \n        if show: \n            self.show() # show the browser \n\n    def download(self, url, timeout=60): \n        \"\"\"Wait for download to complete and return result\"\"\" \n        loop = QEventLoop() \n        timer = QTimer() \n        timer.setSingleShot(True) \n        timer.timeout.connect(loop.quit) \n        self.loadFinished.connect(loop.quit) \n        self.load(QUrl(url)) \n        timer.start(timeout * 1000) \n        loop.exec_() # delay here until download finished \n        if timer.isActive(): \n            # downloaded successfully \n            timer.stop() \n            return self.html() \n        else: \n            # timed out \n            print 'Request timed out: ' + url \n\n    def html(self): \n        \"\"\"Shortcut to return the current HTML\"\"\" \n        return self.page().mainFrame().toHtml() \n\n    def find(self, pattern): \n        \"\"\"Find all elements that match the pattern\"\"\" \n        return self.page().mainFrame().findAllElements(pattern) \n\n    def attr(self, pattern, name, value): \n        \"\"\"Set attribute for matching elements\"\"\" \n        for e in self.find(pattern): \n            e.setAttribute(name, value) \n\n    def text(self, pattern, value): \n        \"\"\"Set attribute for matching elements\"\"\" \n        for e in self.find(pattern): \n            e.setPlainText(value) \n\n    def click(self, pattern): \n        \"\"\"Click matching elements\"\"\" \n        for e in self.find(pattern): \n            e.evaluateJavaScript(\"this.click()\") \n\n    def wait_load(self, pattern, timeout=60): \n        \"\"\"Wait until pattern is found and return matches\"\"\" \n        deadline = time.time() + timeout \n        while time.time() < deadline: \n            self.app.processEvents() \n            matches = self.find(pattern) \n            if matches: \n                return matches \n        print('Wait load timed out') \n\n```", "```py\n>>> br = BrowserRender() \n>>> br.download('http://example.webscraping.com/search') \n>>> br.attr('#search_term', 'value', '.') \n>>> br.text('#page_size option:checked', '1000') \n>>> br.click('#search') \n>>> elements = br.wait_load('#results a') \n>>> countries = [e.toPlainText().strip() for e in elements] \n>>> print countries\n['Afghanistan', 'Aland Islands', ... , 'Zambia', 'Zimbabwe'] \n\n```", "```py\npip install selenium\n\n```", "```py\n>>> from selenium import webdriver \n>>> driver = webdriver.Firefox() \n\n```", "```py\n>>> driver.get('http://example.webscraping.com/search') \n\n```", "```py\n>>> driver.find_element_by_id('search_term').send_keys('.') \n\n```", "```py\n>>> js = \"document.getElementById('page_size').options[1].text = '1000';\" \n>>> driver.execute_script(js)\n\n```", "```py\n>>> driver.find_element_by_id('search').click() \n\n```", "```py\n>>> driver.implicitly_wait(30) \n\n```", "```py\n>>> links = driver.find_elements_by_css_selector('#results a') \n\n```", "```py\n>>> countries = [link.text for link in links] \n>>> print(countries)\n['Afghanistan', 'Aland Islands', ... , 'Zambia', 'Zimbabwe'] \n\n```", "```py\n>>> driver.close() \n\n```", "```py\n>>> from selenium import webdriver\n>>> driver = webdriver.PhantomJS()  # note: you should use the phantomjs executable path here \n # if you see an error (e.g. PhantomJS('/Downloads/pjs'))\n\n```", "```py\n>>> driver.get('http://python.org')\n>>> driver.save_screenshot('../data/python_website.png')\nTrue\n\n```"]