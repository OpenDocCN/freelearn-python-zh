- en: Chapter 9. Improving Performance – Part Two, NumPy and Parallelization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is the final chapter in the series of the three chapters on performance
    improvement. It will introduce you to two important libraries, **NumPy**, a third-party
    package, and the built-in **multiprocessing** module. In this chapter, we will
    cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: A brief introduction to the NumPy package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using NumPy to speed up the *Gold Hunt* application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to parallel processing using the `multiprocessing` module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the `multiprocessing` module to further improve the application runtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prerequisites for this chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should read the last two chapters, [Chapter 7](ch07.html "Chapter 7. Performance
    – Identifying Bottlenecks"), *Performance – Identifying Bottlenecks*, and [Chapter
    8](ch08.html "Chapter 8. Improving Performance – Part One"), *Improving Performance
    – Part one*, on performance that teaches you how to identify the performance bottlenecks
    and improve the runtime using built-in functionality. This chapter takes the application
    to the next level by drastically improving performance.
  prefs: []
  type: TYPE_NORMAL
- en: This is how the chapter is organized
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will be the *Part two* of performance improvement. Just like the
    previous chapter, the performance of the *Gold Hunt* program will be improved
    in steps. We will start with a quick introduction to NumPy, just enough to use
    its functionality for *optimization passes four* and *five*, which follow next.
    Moving ahead, there will be a superficial introduction to the `multiprocessing`
    module. In *optimization pass six*, we will use this module to parallelize a portion
    of the application code. Let's pull up the same bar chart from the previous chapter.
    The last two bars indicate the speedup accomplished by the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '![This is how the chapter is organized](img/B05034_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: But the chart does not tell the full story. The *optimization pass four*, will
    significantly speedup the `generate_random_points` function of the *Gold Hunt*
    program. This speedup is not reflected in the chart as the function does not significantly
    contribute to the runtime in this scenario. Towards the end, the chapter will
    provide preliminary information on **PyPy** for further reading. PyPy is a Python
    interpreter that provides a **Just In Time** (**JIT**) compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Running Gold Hunt optimization examples**'
  prefs: []
  type: TYPE_NORMAL
- en: If you look closely at the profiling output shown in the upcoming discussion,
    you will notice a filename, `goldhunt_run_master.py`. Using this file is optional
    but it provides a convenient way to run any of the optimization passes. You can
    find this file in this chapter's supporting code bundle.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NumPy is a powerful Python package for scientific computing. It provides a multidimensional
    `array` object that enables efficient implementation of numerical computations
    in Python. It also has a relatively smaller memory footprint when compared to
    a list. An `array` object is just one of the many important features of NumPy.
    Among other things, it offers linear algebra and random number generation capabilities.
    It also provides tools to access codes written in other languages, such as C/C++
    and Fortran. Let's start with a short introduction that gives a flavor of its
    capabilities. What we will discuss in this book is more like scratching the surface
    of NumPy! This chapter covers some features to be used later to speed up the *Gold
    Hunt* application.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Review the official NumPy documentation ([http://docs.scipy.org](http://docs.scipy.org))
    to learn about several other features that are not covered here.
  prefs: []
  type: TYPE_NORMAL
- en: If you are already familiar with NumPy, you can optionally skip this introduction
    and directly move on to the *Optimizing Gold Hunt – Part two* section.
  prefs: []
  type: TYPE_NORMAL
- en: Installing NumPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some Python distributions, such as Anaconda ([https://www.continuum.io/downloads](https://www.continuum.io/downloads)),
    provide NumPy by default. If unavailable, use `pip` to install it. Here is how
    to do it on Linux, assuming `pip` is available as a command in the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This should install NumPy. If you encounter problems, refer to the platform
    specific installation instructions at [http://www.scipy.org/install.html](http://www.scipy.org/install.html).
    Alternatively, you can use the earlier mentioned Anaconda Python distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once installed, open the Python interpreter and type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Assuming the installation is successful, it should import NumPy. For the rest
    of the discussion, we will use the notation `np` as the alias for `numpy`. Keep
    the interpreter window open. For the rest of the introduction, we will run some
    simple NumPy operations.
  prefs: []
  type: TYPE_NORMAL
- en: Creating array objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As noted before, a multidimensional (**N-dimensional**) array object is one
    of the core NumPy capabilities. This array is provided by a built-in class, `numpy.ndarray`.
    It represents a collection of elements of the same type. In other words, it is
    a homogeneous array. There are several ways to create a Numpy array. Type the
    following code in your Python interpreter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates an array instance denoted by the `x` variable with two elements.
    This is of the `numpy.ndarray` type. It is a single dimensional array. You can
    access any element or change its value, just like a Python `list`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In this simple example, the size of the array is `2`. This is also called the
    *shape* of an array. NumPy represents the array shape as a tuple of integers.
    It gives the size of the array along each dimension. This is shown in the following
    line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Continuing further, here is another example that creates a two-dimensional
    array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, `ndim` represents the number of dimensions of an array. The array shape
    indicates the size of two in each dimension.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review the `numpy.arange` function. This is similar to the Python `range`
    function. But, `arange` returns an `array` object instead of a `list`. The following
    is another way to create an array using `numpy.arange`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: There are many other ways to create arrays in NumPy. Refer to the documentation,
    ([http://docs.scipy.org/doc/numpy/reference/](http://docs.scipy.org/doc/numpy/reference/))
    for more details. Specifically, look for array creation routines.
  prefs: []
  type: TYPE_NORMAL
- en: Simple array operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will review some basic mathematical operations that can be performed on
    NumPy arrays. Let''s create two arrays, `x` and `y` (these are one-dimensional
    arrays or vectors):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Using these arrays, you can perform mathematical operations, such as addition,
    subtraction, multiplication, and so on. NumPy performs all these operations element
    by element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'It is important to note here that `x*y` is not the inner product. It is just
    a multiplication of the corresponding elements in the `x` and `y` arrays. The
    inner product of these vectors can be accomplished using the `dot` function, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code illustrates the concept using a two-dimensional array. Here,
    `x2.dot(y2)` is a matrix multiplication operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Array slicing and indexing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For single dimensional arrays, the **indexing** and **slicing** operations are
    similar to a Python `list`. If you are unfamiliar with the `list` slicing operation,
    refer to [https://docs.python.org/3/tutorial/introduction.html#lists](https://docs.python.org/3/tutorial/introduction.html#lists).
    This is an important concept. In this chapter, we will only need to perform a
    few basic indexing operations.
  prefs: []
  type: TYPE_NORMAL
- en: Indexing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Array indexing is essentially an operation that enables us to access a particular
    element in an array. Here is a simple one-dimensional array with a size of five:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The simplest indexing operation is shown below, which accesses an element of
    this array. This operation is similar to how it is done for a Python `list`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is how you can retrieve elements from a two-dimensional array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Once complete, it returns an array with only the first row.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is important to note that the basic array indexing does not return a copy
    of the original array. It just points to the same memory location as the original
    array. Refer to the following link where the basic and advanced indexing has been
    comprehensively documented: [http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html](http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code will retrieve a single value from a two-dimensional array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: With this basic introduction to array indexing, let's learn about some common
    slicing operations.
  prefs: []
  type: TYPE_NORMAL
- en: Slicing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Suppose you want to get an array with only the first two elements. Just like
    a `list`, you will need to specify a start and an end. For example, `b[start:stop]`
    means the resulting (sliced) array will begin at the `start` index and end at
    the `stop-1` index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, to get any array with only the elements at the positions `1` and
    `2`, you can do as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'For the N-dimensional arrays, you have to give the slicing instructions in
    each direction. Consider the following array with four rows and columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s slice this array so that it returns only the first row. Here is the
    syntax to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to get only the first column of `z2` instead, then specify the
    slicing as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following slicing operation will create a new array using elements of the
    first two rows and columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: To gain a better understanding of array slicing operations, try more examples
    in a Python interpreter. See the documentation for details (search the Web for
    NumPy array slicing).
  prefs: []
  type: TYPE_NORMAL
- en: Broadcasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Broadcasting is another important NumPy feature. Let''s understand this concept
    with a simple example. We have two arrays, `p0` and `p1`, as shown in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The shapes of these arrays are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Although the arrays have different shapes, NumPy can perform arithmetic operations
    on these arrays. A basic multiplication operation is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This is referred to as broadcasting. The `p0` array has a smaller shape relative
    to `p1`. The broadcasting enables this array to work with `p1`. In this example,
    it enables the multiplication operation. Of course, the two arrays need to meet
    certain requirements to take advantage of this feature. Refer to the NumPy documentation
    to learn more about broadcasting.
  prefs: []
  type: TYPE_NORMAL
- en: Miscellaneous functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's look at some advanced mathematical operations that you can perform using
    the NumPy arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most of the operations illustrated here will be used in the upcoming discussion
    on performance improvement using NumPy. So, pay close attention to this section.
  prefs: []
  type: TYPE_NORMAL
- en: numpy.ndarray.tolist
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is a handy function that returns the NumPy array as a Python `list` object.
    Depending on the array dimension, it can be a nested list. Here is an example
    that shows this function in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: numpy.reshape
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As the name suggests, it changes the shape of an array without actually changing
    its data. Look at the following code; the `x` array is one dimensional and has
    a size (shape) of `9`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see how to reshape this into a matrix that has three rows and columns.
    In other words, the following code returns an array with a new shape of `(3,3)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The new shape selected should be compatible with the original shape of the array;
    otherwise, it will throw an error. For the preceding example, if you reshape it
    as `np.reshape(x, (3,2))`, it will throw a value error complaining about changed
    size.
  prefs: []
  type: TYPE_NORMAL
- en: numpy.random
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This module provides several functions for random sampling. For a detailed list,
    refer to [http://docs.scipy.org/doc/numpy/reference/routines.random.html](http://docs.scipy.org/doc/numpy/reference/routines.random.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review `np.random.uniform` that draws samples from a uniform distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The first two arguments of this function represent the lower (`0.0`) and upper
    (`2.0`) boundaries of the output interval. You can specify any float value as
    the limit. All the random values or samples generated by the function lie within
    these two limits. The default lower and upper limits are `0.0` and `1.0`, respectively.
    The `size` argument represents the shape of the output array. In the preceding
    example, it is specified as a single integer value. If you do not specify the
    `size` argument, it defaults to `None`. In that case, the function will simply
    return a single floating point number. The following is a slightly complicated
    example of when the `size` (or shape) argument is a tuple `(2,2)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Have you already noticed a difference between Python's built-in `random.uniform`
    function and NumPy equivalent's `np.random.uniform`? The Numpy `np.random.uniform`
    function, can optionally give us an `array` object with samples drawn from uniform
    distribution, whereas the built-in `random.uniform` can only give us a single
    number. We will use this NumPy function in *optimization pass four*.
  prefs: []
  type: TYPE_NORMAL
- en: numpy.dstack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This provides a simple way to stack or concatenate a sequence of arrays along
    a third axis. Consider two NumPy arrays, `x` and `y`, representing the x and y
    coordinates of some points in space. These arrays are shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Thus, `x[0]=1` and `y[0]=10` represent a point `(1, 10)`. Likewise, we can
    represent other points for the remaining elements. Sometimes, it is convenient
    to use a single array to express the coordinates of several such points, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'How do we create such an array using the `x` and `y` arrays shown earlier?
    There are multiple ways to do this. One option is to use `numpy.dstack`. This
    function enables stacking arrays along a third axis to create a single array.
    The following code shows how to create a `points` array discussed earlier using
    the input `x` and `y` arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that the resultant array is three-dimensional:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The size of the array along each axis (or dimension) is given by its shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We will use this function in *optimization pass five*. Similarly, there are
    other ways of stacking arrays, for example, `numpy.hstack` or `numpy.vstack`.
    These are not discussed in this book. Refer to the NumPy documentation for further
    details.
  prefs: []
  type: TYPE_NORMAL
- en: numpy.einsum
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This function provides a way to compute the **Einstein notation** (or **Einstein
    summation convention**) on the input arrays for the operations (called **operands**).
    In terms of performance, this function offers great efficiency. Later in the chapter,
    we will exploit it to find the square of the distance between two points.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Understanding the mathematical concept behind `einsum` can be a bit challenging,
    especially if you do not have a math background. In that case, just remember one
    key thing about `numpy.einsum`—It is a function that allows you to perform some
    highly efficient operations involving arrays. For example, a matrix multiplication
    operation between two NumPy arrays or a dot product can be done more efficiently
    using `numpy.einsum`.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to the NumPy documentation for more information on this function. Also,
    see [https://en.wikipedia.org/wiki/Einstein_notation](https://en.wikipedia.org/wiki/Einstein_notation)
    for information on Einstein notation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be better explained with an example. Consider the following equations
    that represent two vectors, *A* and *B*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![numpy.einsum](img/B05034_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'These are two points in space with some *x*, *y*, and *z* coordinates. The
    dot product of these vectors is represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![numpy.einsum](img/B05034_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To learn more about a dot product, see [https://en.wikipedia.org/wiki/Dot_product](https://en.wikipedia.org/wiki/Dot_product).
  prefs: []
  type: TYPE_NORMAL
- en: 'It is a scalar product and can be represented as a summation, as shown in the
    following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![numpy.einsum](img/B05034_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The Einstein summation convention for the preceding equation is written as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![numpy.einsum](img/B05034_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, it is implied that *AiBi* is a summation over *i* with a lower bound of
    *1* and upper bound of *3*. This is the Einstein summation convention in a nutshell.
  prefs: []
  type: TYPE_NORMAL
- en: '`numpy.einsum` evaluates the Einstein summation convention on the given input
    arrays. The basic syntax is shown below—there are other optional arguments as
    well, but those are not shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The first argument, `subscripts`, is a string that represents a list of subscript
    labels. These are separated by a comma and each label represents a dimension of
    a particular operand. In the example we just saw, there was only one subscript
    label, *i*. The second argument, `operands`, represents the input arrays (*A*
    and *B* in the example).
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose the *A* and *B* vectors are one dimensional. Their inner product can
    be represented with the subscript string `''i,i''`. This can be better explained
    with the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The arrays `a` and `b` are one dimensional. You can also cross-check the answer
    using the `numpy.inner` function, which returns the same answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The `numpy.einsum` function is faster and also memory efficient. Now, take
    a look at the following code—it represents a dot product (or matrix multiplication)
    of two vectors, `a2` and `b2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The subscript string for `numpy.einsum` is `''ij,jk''`, where `ij` is the subscript
    for two dimensions of array `a2`, and `jk` is the one for array `b2`. The dot
    product can also be obtained by following this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Computing distance square with einsum
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The examples shown so far should just give you a flavor of the `einsum` function.
    Let's only discuss how to use this function to calculate the square of the distance
    between two points. Again, for a comprehensive reference, refer to the NumPy documentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider any point `p1` with coordinates (`0, 2`). Furthermore, assume that
    the center is located at (`0,` `0`). As the x coordinate of the `p1` point is
    `0`, you can easily determine the distance between `p1` and center as 2 units.
    The square of the distance can be found using the `einsum` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, imagine that there are multiple such points and you want to find the square
    of the distance of each point from the center. Here is one way to compute this
    using `einsum`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The `points` array represents a list of points. For each of these points, we
    will find a vector, with `center` as its starting point and the given point (from
    the `points` array) as its end. Let''s represent the array of such vectors as
    `diff`, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'As the center is (`0,0`), the `diff` array is essentially the same as the `points`
    array. The following line of code shows the `einsum` syntax—it uses the ellipsis
    notation (`…`), to the left of each term in the subscripts argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: It returns an array that contains a square of the distances for each point in
    the `points` array. That's all we need!
  prefs: []
  type: TYPE_NORMAL
- en: What does this ellipsis notation do? Why didn't we use the earlier syntax?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The earlier syntax involved single dimensional arrays (`d`) that had only one
    subscript label. We cannot use it here as the operand (or the `diffs` array) for
    the Einstein sum is a two-dimensional array. To understand this, let''s look at
    the `diffs` array one more time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider any row of this array. It is essentially a vector between a point
    and the center. For example, `[0, 2]` represents a vector between a center `[0,0]`
    and a point `[0,2]`. The other dimension of the array is to hold many such vectors.
    The ellipsis symbol, "`…`", is a convenient way to broadcast the second dimension.
    The alternative syntax to get the same result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'However, if the array shapes change further, you will need to work on constructing
    a proper subscript string for the `einsum` function again. The NumPy documentation
    has several examples that show how to use `einsum`. Here is a NumPy version 1.10
    documentation: [http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.einsum.html](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.einsum.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Where to get more information on NumPy?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the NumPy introduction, you were presented with several links to the documentation.
    Just for the completeness, let's summarize where to find more information on NumPy.
    You can start by visiting their website ([http://www.numpy.org/](http://www.numpy.org/))
    or just do a web search on NumPy to get to its homepage.
  prefs: []
  type: TYPE_NORMAL
- en: '**SciPy** is another project worth mentioning. It is a library that integrates
    several open source tools for mathematics, science, and engineering disciplines.
    NumPy, matplotlib, and pandas are some of its core packages. See the project website
    ([https://www.scipy.org/](https://www.scipy.org/)) for more information.'
  prefs: []
  type: TYPE_NORMAL
- en: In an earlier discussion, several links were provided to the NumPy documentation.
    Looking at those links, you must have already noticed that they all point to the
    SciPy website. The documentation for both NumPy and SciPy is located at [http://docs.scipy.org/doc/](http://docs.scipy.org/doc/).
  prefs: []
  type: TYPE_NORMAL
- en: The open source pandas library is used for data analysis using Python. It provides
    high performance data structures and tools to analyze data. Refer to [http://pandas.pydata.org/](http://pandas.pydata.org/)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing Gold Hunt – Part two
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous section served as a short introduction to NumPy. Recall that, in
    earlier chapters, we gradually improved the runtime performance of the game. The
    last recorded timing was the one obtained with *optimization pass three*. We successfully
    reduced the total runtime down to nearly 44 seconds from the original time of
    about 106 seconds. NumPy supports vectorized calculation routines such as element-wise
    multiplication. It internally uses efficient C loops that help run such operations
    faster. Let's leverage NumPy capabilities to speed up the *Gold Hunt* game even
    further.
  prefs: []
  type: TYPE_NORMAL
- en: Gold Hunt optimization – pass four
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is now time to resume the optimization operation for the *Gold Hunt* problem.
    Let's start with *optimization pass four*. We will focus our attention once again
    on the function, `generate_random_numbers`. As a refresher, the `cProfiler` output
    of the last optimization run reported the total time as ~ 2.6 seconds and a cumulative
    time, which includes the time spent by sub-functions, was ~ 5.2 seconds*.*
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – pass four](img/B05034_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *You are right. For this example, it is not worth optimizing this piece of
    code. The 5.2 seconds time doesn''t look that bad. At this time, the function
    is called only once, as indicated by the* `ncalls` *column of the* `cProfile`
    *output. But any future requirements can potentially make this function a new
    bottleneck. As an example, imagine a new game scenario where there are hundreds
    of such gold fields or places full of abandoned weapons. We might need to call
    such a function many times. This will increase the total time spent in generating
    points. Keeping this in mind, let''s work on improving its performance.* |'
  prefs: []
  type: TYPE_TB
- en: 'We will revamp the code from the previous optimization run (`goldhunt_pass3.py`).
    The supporting source code is in the `goldhunt_pass4.py` file. The first thing
    we will add is the NumPy `import` statement at the beginning of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The reworked `generate_random_points` function is illustrated in the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – pass four](img/B05034_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'It is optional to use local variables such as `l_uniform`. Those are used here
    to skip the function reevaluation. This was already discussed in the *Skipping
    the dots* section from the previous chapter. Let''s review this function next:'
  prefs: []
  type: TYPE_NORMAL
- en: Compare the new function with the previous implementation. The key thing to
    note here is the use of the NumPy functions, such as `np.random.uniform`, `np.sqrt`,
    and others in place of the built-in functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another major difference is that we no longer need a `for` loop. The `np.random.uniform`
    function returns a NumPy array. The last argument specifies its size. Refer to
    the earlier introductory section on NumPy for more information on the `random.uniform`
    functionality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `x` and `y` coordinates are computed using the `radius` and `theta` arrays.
    Note that the variables, `x` and `y`, are created as NumPy arrays. For efficiency
    reasons, we will return these as Python lists. This is accomplished by using `numpy.ndarray.tolist()`,
    a method accessible to NumPy `array` objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s profile this code and compare the performance with the previous optimization
    pass. Here is the command to execute this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The profiler output is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – pass four](img/B05034_09_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Observe the cumulative time column for the `generate_random_points` function.
    The cumulative time for the original function was ~ 5.2 seconds, that is now reduced
    to `0.346` seconds. This is already a significant improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is possible to further improve the performance of the `generate_random_points`
    function. For example, at the beginning of the function, you can compute the product
    `2*l_pi`, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Then use this variable in the computation of `theta`. However, this will only
    result in a marginal improvement in the runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Gold Hunt optimization – pass five
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this optimization pass, we will further improve the runtime performance of
    the `GoldHunt.find_coins` method. The original method is shown in the following
    code snippet for convenience. You can also find it in an earlier `goldhunt_pass4.py`
    file. For more details, see the previous chapter's, *Gold Hunt Optimization –
    Pass two* section.
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – pass five](img/B05034_09_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Recall that the last recorded runtime for this method was about 38 seconds.
    Our task is to improve it further. We will start the optimization work by making
    a small change to the `generate_random_points` function. Recall that this function
    returns the `x` and `y` coordinates of the *gold coins* on the field as Python
    lists. Instead, let's return these as NumPy arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you have skipped reading the earlier introductory section on NumPy, now would
    be the time to go back and read it! The *optimization pass five* uses the NumPy
    functions discussed in that section. More specifically, the code presented next
    uses the `einsum` and `dpstack` functions. You may find the `einsum` syntax confusing.
    Therefore, it is recommended that you read the introduction first before diving
    into the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `find_coins` method, we will use the NumPy functions that work efficiently
    with these NumPy arrays. The following code fragment shows the updated function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – pass five](img/B05034_09_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'With this change, let''s quickly review the reworked `find_coins` method next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – pass five](img/B05034_09_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s review the preceding code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: Recall that our task is to find the square of the distance between any gold
    coin on the field and the center of the search circle, and then use this value
    to check if the gold coin lies inside the search circle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The input argument, `x_list` and `y_list`, are the NumPy arrays representing
    the x and y positions of the gold coins on the field.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using these coordinates, we will create a single `points` array that contains
    (x, y) coordinate pairs as its elements. This is accomplished using `numpy.dstack`.
    See the earlier introductory section on NumPy for an example usage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will find the vector between each point in the `points` array and the
    `center` array for the search circle. These vectors are stored as the elements
    of the `diff` array.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using this `diff` array, we will find the square of the distances between all
    the gold coins from the center using `einsum`. See an earlier, *Computing distance
    square with einsum* section, where this was discussed in detail.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we will check if the gold coin lies inside the circle by comparing
    the distance squares. The `enumerate()` function is a built-in function that presents
    a cleaner way to get the current index (`i`) of the loop and the corresponding
    value (`d`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code is ready. Now, it is time to profile it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The profiler output is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – pass five](img/B05034_09_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Observe that the cumulative time taken by the `find_coins` function has gone
    down to ~19.5 seconds from the earlier ~ 38 seconds. It is nearly a 50% improvement
    for this function alone. Also, the total runtime is now ~ 21.5 seconds compared
    to the previous timing of ~38 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is possible to improve the performance of `find_coins` by using list comprehension
    instead of the `for` loop. However, the improvement will be marginal. You can
    try it as an exercise (no solution is provided). Here is a sample code that uses
    list comprehension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Parallelization with the multiprocessing module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before jumping onto the discussion of the `multiprocessing` module, let's first
    understand what we mean by parallelization. This will be a very short introduction
    to parallelization, just enough to understand how to use some features of the
    `multiprocessing` module.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to parallelization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine you are standing in a long queue at a checkout counter in a grocery
    store, waiting for your turn. Now, three more counters are opened to serve the
    customers and the existing queue is split. As a result, you can pay and get out
    of the store quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelization, in some sense, accomplishes similar results. In this example,
    each counter can be imagined as a separate process, carrying out independent tasks
    of accepting payments. The initial queue of the customers can be imagined as your
    program. This long queue is then divided into independent queues (or tasks), processing
    them parallely on separate counters (processes).
  prefs: []
  type: TYPE_NORMAL
- en: The *Gold Hunt* program we have written so far runs serially. The program executes
    a set of tasks one after another on a single processor. This is analogous to the
    single counter in the previously mentioned grocery store example. Many times,
    it is possible to split the program into smaller tasks and run them independently
    using multiple processes or threads.
  prefs: []
  type: TYPE_NORMAL
- en: Let's quickly review two broad programming models that handle parallel process
    communications. These are **shared memory** and **distributed memory** parallelization.
  prefs: []
  type: TYPE_NORMAL
- en: Shared memory parallelization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the shared memory programming model, the parallel processes access the same
    memory segment. Thus, the exchange of data and the communication between processes
    happens through this common memory. This programming model is often referred to
    as *threaded programming*. The disadvantage of the shared memory model is something
    known as a **race condition**. Here, multiple threads compete to access or modify,
    for instance, data at a memory location. The race condition can be avoided by
    controlling access to that critical information using *locks*. However, this adds
    to the programming overhead. Refer to [https://en.wikipedia.org/wiki/Shared_memory](https://en.wikipedia.org/wiki/Shared_memory)
    for further information.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed memory parallelization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here, each process gets its own memory space. The processes do not share any
    memory resources, and they run independent of each other. The communication between
    the processes happens over inter-process communication channels. This is referred
    to as **message passing**. To learn more about message passing, see [https://en.wikipedia.org/wiki/Message_passing](https://en.wikipedia.org/wiki/Message_passing).
    Since the processes do not share the same memory space, there is an additional
    communication overhead associated with the distributed memory mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Global interpreter lock
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Python, the `threading` module provides a high-level interface for thread
    based parallelization. To avoid the race condition discussed earlier, Python employs
    a mechanism called **global interpreter lock** (**GIL**). When a thread is executing
    a block of code, a global lock is acquired. This lock makes sure that only one
    thread is executed at a time in the Python interpreter environment. The disadvantage
    of GIL is that you cannot take full advantage of a multiprocessor machine.
  prefs: []
  type: TYPE_NORMAL
- en: The multiprocessing module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `multiprocessing` module addresses the GIL problem and provides a simple
    way to parallelize Python programs. Instead of using threads, it uses sub-processes
    and avoids GIL. In this module, the exchange of data between processes is supported
    using two communication channels, a `Queue` class and a `Pipe` function. This
    module also provides several other useful features, such as *managers* and *proxy
    objects*. The `Manager` object is created using `multiprocessing.Manager()`. It
    controls a server process that manages the Python objects. The manager also enables
    other processes to manipulate these Python objects using proxies. Discussing these
    features is beyond the scope of this book. Python documentation has great examples
    of how these features work. Refer to [https://docs.python.org/3/library/multiprocessing.html](https://docs.python.org/3/library/multiprocessing.html)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will cover only a few features of the `Pool` class.
  prefs: []
  type: TYPE_NORMAL
- en: The Pool class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `multiprocessing.Pool` class provides a simple approach to parallelize the
    program. It is used to manage a pool of worker processes and defines methods that
    enable various ways to run the given tasks parallely.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The other basic approach is to use the `Process` class, which is not discussed
    in this book. See the previous documentation link for details.
  prefs: []
  type: TYPE_NORMAL
- en: The `Pool.map` and `Pool.apply` methods are among the ones frequently used.
    These are the parallel equivalents of the Python built-in `map` and `apply` functions.
    Both these methods block the main program until a worker process is finished and
    the results are ready. The blocking nature is useful if you are interested in
    getting a sequential output from the parallel processes. They also have their
    asynchronous variants, namely `map_async` and `apply_async`. The asynchronous
    variants are better suited to run parallel jobs where you don't care about the
    order in which results are returned by the processes.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `apply` function is no longer a built-in function in Python 3\. However,
    it was supported in Python 2.7\. You can refer to Python 2 documentation to learn
    what this function does.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s work on a simple example that shows how to use the `Pool` class and
    its methods, `map` and `apply`. Observe the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Pool class](img/B05034_09_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s review the preceding code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: We start by importing the `multiprocessing` module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `pool` instance is created with two worker processes. You can specify the
    number of worker processes as an optional input argument.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After creating a pool of workers, the `pool.map` method is called. As previously
    stated, this is a parallel equivalent of the built-in `map` function. The first
    argument is a trivial function called `get_result`. This function is applied to
    the `iterable` specified as the second argument.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this case, the `get_result` function is applied on each element of the `numbers`
    list. Inside this function, we also print the name of the current worker process
    doing the job.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `pool.close()` method stops the worker processes after execution, whereas
    the `pool.join()` method blocks until the worker process terminates. This mimics
    the API provided by the `threading` module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The preceding code can also be found in `pool_example.py`. In this file, you
    just need to enable the relevant code and disable the other function calls. The
    file can be run from the Command Prompt, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a sample command-line output after this execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the elements of the output list (`mylist`) are arranged in the same
    order as the input list (`numbers`). In other words, we have the input as `[2,
    4, 6, 8]` and the output is 10 times each element, given as `[20, 40, 60, 80]`.
    This may or may not be the case for asynchronous variants. It will depend on which
    order the processes finish and return the results for.
  prefs: []
  type: TYPE_NORMAL
- en: 'With just a single line change, we can run the same example using `Pool.apply`.
    The following code snippet shows how to do this. The `get_result` function is
    not shown as it remains the same as before, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Pool class](img/B05034_09_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we created `mylist` using list comprehension. For each element of the
    `numbers` list, it calls the `Pool.apply` method. The first argument to the method
    is the name of the function whereas the second argument, `args`,is used to specify
    the other arguments to this function. This method offers convenient syntax to
    specify any number of arguments to the function being sent to the worker processes.
    The rest of the code and programming output remains the same, as shown in the
    `Pool.map` method example. Let''s review one of the asynchronous variants, `Pool.apply_async`.
    The code is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Pool class](img/B05034_09_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s talk through this code:'
  prefs: []
  type: TYPE_NORMAL
- en: This involves two changes. The first one is a trivial one. The `apply` method
    is simply replaced with `apply_async` (shown highlighted). There is no change
    in the method syntax.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, the output of the `apply_async` call does not directly give us the
    final values we need. Instead, it returns the object of a `Pool.ApplyResult` class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this example, `apply_async` is used inside a list comprehension. So, the
    elements of the `results` list are objects of the `ApplyResult` class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final value can be obtained using the `ApplyResult.get()` method. We do
    this using a list comprehension, as shown in the preceding image. Alternatively,
    you can also use the generator expression syntax discussed in the previous chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this short introduction on parallelization, let's see how to parallelize
    some functionality from the *Gold Hunt* application.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelizing the Gold Hunt program
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Looking at the previous profiler output, the `find_coins` function is still
    the main bottleneck with ~19.5 seconds of cumulative time. Let's see how parallelization
    can help speed it up further.
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting the gold field
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is the *gold field* image from [Chapter 7](ch07.html "Chapter 7. Performance
    – Identifying Bottlenecks"), *Performance – Identifying Bottlenecks*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Revisiting the gold field](img/B05034_09_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s quickly summarize what we already saw in [Chapter 7](ch07.html "Chapter 7. Performance
    – Identifying Bottlenecks"), *Performance – Identifying Bottlenecks*:'
  prefs: []
  type: TYPE_NORMAL
- en: The `find_coins` method is called for each of the small search circles shown
    in the figure. So, if there are 10 search circles, `find_coins` will be called
    10 times, one after the other.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `find_coins` method returns the coordinates of the gold coins lying inside
    the given search circle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The information about all such collected coins is maintained in a list object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is one important thing to note here. It is a serial execution. You start
    with the first circle, collect the coins and move on to the next one, and repeat
    the procedure until you hit the other end of the field.
  prefs: []
  type: TYPE_NORMAL
- en: '| *So how can we further enhance the search operation? Any thoughts, Mr. Great
    Dwarf?* |'
  prefs: []
  type: TYPE_TB
- en: '![Revisiting the gold field](img/B05034_09_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *Perfect! The search* *operation inside each circle is independent of the
    others. Therefore, the* `find_coins` *function can be independently executed for
    each search circle. This is an ideal candidate for parallelization.* |'
  prefs: []
  type: TYPE_TB
- en: '![Revisiting the gold field](img/B05034_09_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *That is even better!**Since the order in which the results are returned
    (by the worker processes) is not important, we can use* `Pool.apply_async` *to
    parallelize this task.* |'
  prefs: []
  type: TYPE_TB
- en: Gold Hunt optimization – Pass six, parallelization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a first step, you should skim through the `play` method of the last *optimization
    pass five*. Most of the changes we are about to make will be in this method. Additionally,
    we will pass some more arguments to the `find_coins` method.
  prefs: []
  type: TYPE_NORMAL
- en: So, we decided to use a pool of worker processes represented by a `Pool` object.
    The *work queue* of this `Pool` object consists of all the search circles inside
    the gold field shown earlier. Each worker process will parallely run the search
    operation (`find_coins`), and it doesn't depend on other search circles. Generally,
    the worker processes within a `Pool` object are not terminated until the complete
    work queue is processed. When a worker process is done finding the coins in a
    particular search circle, it may get assigned to perform this operation for another
    search circle.
  prefs: []
  type: TYPE_NORMAL
- en: '| *So what changes are required to be done to the play method? The code will
    be very similar to the basic example of* `apply_async`*, as seen earlier. Does
    anything else need to be changed in the existing method? Our friend Elf has a
    question...* |'
  prefs: []
  type: TYPE_TB
- en: '![Gold Hunt optimization – Pass six, parallelization](img/B05034_09_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '| *You are spot on! The existing* `play` *method serially runs the search operation.
    It starts with the leftmost circle, finds the coins, and moves on to the next
    circle by updating* `x_ref`. *Note that we have chosen* `y_ref` *as* `0.0` *in
    this example.**When we run this search* *operation on parallel processes, each
    circle will have its unique center coordinates. We need to provide appropriate
    values of these coordinates to each parallel process. To do this, let''s remove
    the dependence on* `x_ref` *and* `y_ref`*. The center coordinates of all the circles
    will be determined and stored in a list before parallelizing the search operation.*
    |'
  prefs: []
  type: TYPE_TB
- en: 'The `play` method with the preceding changes is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – Pass six, parallelization](img/B05034_09_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s talk through the important changes in this method:'
  prefs: []
  type: TYPE_NORMAL
- en: In a `while` loop, we will first determine the centers of all the search circles
    and store the coordinates in a list called `x_centers`. The y coordinate (`y_ref`)
    is not updated because we have chosen it as constant `(0.0)` for all the circles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the same `while` loop, another `circle_number` list is populated to represent
    the circle id. This is just for printing purposes so that we will know which search
    operation is being performed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After preparing the list, a pool of worker threads is created and then `apply_async`
    is called in a list comprehension.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recall that the first argument to the `Pool.apply_async` method is the name
    of the function (`self.find_coins)`, whereas the second argument, `args`, is used
    to specify all the arguments to this function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rest of the code is similar to what we saw in the introduction of the `multiprocessing`
    module. The `apply_async` call returns a list containing objects of the `ApplyResult`
    class. Then, the `get()` method of this class is used to obtain the final values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you are using Python 2.7.9, you may have to create and use a global function
    as the first argument to `apply_async`. This global function can then return the
    `GoldHunt.find_coins` method. This is a workaround to avoid a `PicklingError`
    exception noticed while testing the code. For Python 3.x, there is no problem.
    This code is provided in the supplementary code bundle. See the Python 2 equivalent
    of the `goldhunt_pass6_parallel.py` file for details.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, there are some changes to the `GoldHunt.find_coins` method. It now
    takes the `process_x_ref` and `circle_number` functions as two new arguments.
    The `process_x_ref` function represents the x coordinate of a given search circle.
    The `process_` prefix is added just to distinguish it from `self.x_ref`, and indicate
    that its value will be different for each worker process.
  prefs: []
  type: TYPE_NORMAL
- en: Using `apply_async`, we will run this method on separate parallel processes.
    Each process gets its own circle center and number to be given as an input for
    the `find_coins` method. The method is shown in the following code snippet. The
    highlighted code indicates the changes in comparison with the previous optimization
    pass.
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – Pass six, parallelization](img/B05034_09_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The rest of the code remains the same as the previous optimization pass. The
    source code is provided in the `goldhunt_pass6_parallel.py` file. Let''s run this
    code and see the profiler output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This will print information on the search circles as it did earlier. Here is
    the profiler output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gold Hunt optimization – Pass six, parallelization](img/B05034_09_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that the `find_coins` call is not shown in the profiler output. It is hidden
    inside the reported timing of the `play` method. Comparing the cumulative time
    (`cumtime`) of the `play` method should give a reasonable estimate on the performance
    gain with parallelization.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, the parallelization has helped improve the total timing from earlier,
    ~21.5 seconds to ~13.5 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Depending on your machine specifications, you can try increasing the number
    of worker processes by updating the argument to the `Pool` class. For example,
    instead of three processes you can run the program with four processes. However,
    this is a simple case and the runtime is so short that you will hardly see any
    further improvement. In fact, the overhead of the sub-processes may even result
    in a slightly degraded performance. Also, depending on the problem, beyond a certain
    number of processes, the performance gain due to parallelization can fade away.
  prefs: []
  type: TYPE_NORMAL
- en: Other methods for parallelization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Is the `apply_async` method the only way to parallelize this problem? Certainly
    not. There are other methods in the `multiprocessing` module that can do this
    efficiently. `Pool.starmap_async` is one such method available in Python 3.3 and
    beyond. We are not going to discuss this here, but the following code shows how
    to invoke it along with the `itertools.repeat` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: For more information on such methods, refer to the `multiprocessing` module
    documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the series of the three chapters on performance, we covered several important
    aspects. The things learned here will help you with the majority of common application
    performance enhancement tasks. Where do we go from here? There are some other
    important topics that you can explore, among those are JIT compilers and **Graphics
    Processing Unit** (**GPU**) programming. This section aims at providing some basic
    information on these two topics. You can follow the links provided here for further
    understanding.
  prefs: []
  type: TYPE_NORMAL
- en: JIT compilers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python is an interpreted language. In simple terms, it means that the code is
    parsed and executed directly without involving any code compilation. Although
    this offers a great deal of flexibility, the program typically runs slower.
  prefs: []
  type: TYPE_NORMAL
- en: In high-level programming languages such as C++, the code is compiled ahead
    of time or before the execution. Generally speaking, a compiled program (C++)
    runs faster compared to the equivalent interpreted program (Python).
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we have an interpreted code on one side which offers flexibility and a
    compiled code on the other that runs faster. The JIT compiler gets the best of
    both worlds. It compiles the code, but instead of compiling it ahead of execution,
    it does this just-in-time or during the program execution.
  prefs: []
  type: TYPE_NORMAL
- en: PyPy is one such project that provides an alternative implementation of the
    Python language that comes with a JIT compiler. Python programs often run faster
    with PyPy. It is also memory efficient and offers high compatibility with the
    existing Python code. To learn more about PyPy, check out [http://pypy.org](http://pypy.org).
  prefs: []
  type: TYPE_NORMAL
- en: '**Numba** is another project aimed at speeding up the application. It provides
    a JIT compiler and a very simple syntax to mark a function for optimization using
    a JIT compiler. You just need to use the `numba.git()` decorator. In other words,
    add `@jit` above the function name to mark the function for optimization. If you
    are using the Anaconda Python distribution discussed in [Chapter 1](ch01.html
    "Chapter 1. Developing Simple Applications"), *Developing Simple Applications*,
    it already provides the `numba` module by default. To learn more, visit the project
    home page ([http://numba.pydata.org](http://numba.pydata.org)).'
  prefs: []
  type: TYPE_NORMAL
- en: GPU accelerated computing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GPU is traditionally used for applications involving heavy rendering, such as
    game applications. It is now widely used for applications involving scientific
    simulations, neural networks, financial modeling, and so on. The massively parallel
    architecture of a GPU offers tremendous performance improvement (of the order
    of 100x or more) over the CPU-based parallelization. A typical strategy is to
    identify the most compute intensive part of your application, and then send it
    to a GPU. The rest of the code can continue to use CPU. However, it is not as
    simple as it sounds, especially if you are working on a legacy code. In such cases,
    the challenge can be to make it compatible to fully utilize the GPU acceleration.
  prefs: []
  type: TYPE_NORMAL
- en: '**PyCUDA** ([https://pypi.python.org/pypi/pycuda](https://pypi.python.org/pypi/pycuda))
    is a popular Python package that provides a wrapper to access Nvidia''s CUDA parallel
    API. CUDA is a parallel computing platform by NVIDIA. More information can be
    found at [http://www.nvidia.com/object/cuda_home_new.html](http://www.nvidia.com/object/cuda_home_new.html).'
  prefs: []
  type: TYPE_NORMAL
- en: '**PyOpenCL** ([https://pypi.python.org/pypi/pyopencl](https://pypi.python.org/pypi/pyopencl))
    is another Python package. It provides an easy access to the **Open Computing
    Language** (**OpenCL**) API. OpenCL is a framework for parallel computation. Refer
    to [https://en.wikipedia.org/wiki/OpenCL](https://en.wikipedia.org/wiki/OpenCL)
    for further information.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With this chapter, we end the series of chapters focused on performance improvements.
    Let's first summarize what you learned in this chapter. We started with a basic
    introduction to the NumPy library and saw how to leverage it to further speed
    up the *Gold Hunt* application. In particular, we used the array (`numpy.ndarray`)
    data structure and other functionalities, such as `numpy.random.uniform` and `numpy.einsum`
    to achieve the speedup. The final optimization pass involved parallelizing the
    code. The chapter briefly introduced you to the basics of parallel processing.
    We used functionality from Python's `multiprocessing.Pool` class to further trim
    down the application runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's summarize the three performance chapters together. We started
    by profiling the code to identify the performance bottlenecks and learned about
    the big O notation. We gradually addressed these bottlenecks to improve the application
    performance. This was accomplished by several means, ranging from changing the
    algorithm and implementing efficient data structures to using the functionality
    from a Python standard library. We further improved the runtime by using NumPy
    and also by parallelizing the code.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The timings reported by the profiler will vary widely. It depends on your machine
    specifications, and also on the current running tasks. So, the timings observed
    in your case will likely be different than the numbers reported in this book.
  prefs: []
  type: TYPE_NORMAL
- en: For the *Gold Hunt* example discussed in these chapters, the total runtime was
    reduced almost by an order of magnitude, from an initial value of about 106 seconds
    to a final runtime of nearly 13.5 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: So far, in this book, you learned several key aspects of application development
    using command-line programs. In the final chapter, we'll see how to develop simple
    GUI applications in Python.
  prefs: []
  type: TYPE_NORMAL
