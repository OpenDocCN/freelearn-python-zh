- en: '10'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Functools Module
  prefs: []
  type: TYPE_NORMAL
- en: Functional programming considers functions to be first-class objects. We’ve
    seen several higher-order functions that accept functions as arguments or return
    functions as results. In this chapter, we’ll look at the `functools` library,
    which contains some tools to help us implement some common functional design patterns.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll look at some higher-order functions. This extends the material from [Chapter 5](Chapter_05.xhtml#x1-1000005),
    [Higher-Order Functions](Chapter_05.xhtml#x1-1000005). We’ll continue looking
    at higher-order function techniques in [Chapter 12](Chapter_12.xhtml#x1-25000012),
    [Decorator Design Techniques](Chapter_12.xhtml#x1-25000012), as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll look at the following functions in this module:'
  prefs: []
  type: TYPE_NORMAL
- en: '`@cache` and `@lru_cache`: These decorators can be a huge performance boost
    for certain types of applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`@total_ordering`: This decorator can help create rich comparison operators.
    Additionally, it lets us look at the more general question of object-oriented
    design mixed with functional programming.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`partial()`: This function creates a new function from a function and some
    parameter value bindings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reduce()`: This is a higher-order function that generalizes reductions such
    as `sum()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`singledispatch()`: This function allows us to assemble alternative implementations
    based on the argument type. It saves us from writing the `match` statement to
    choose the implementation, keeping the implementations cleanly separated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We’ll defer two additional members of this library to [Chapter 12](Chapter_12.xhtml#x1-25000012),
    [Decorator Design Techniques](Chapter_12.xhtml#x1-25000012): the `update_wrapper()`
    and `wraps()` functions. We’ll also look more closely at writing our own decorators
    in the next chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll ignore the `cmp_to_key()` function entirely. Its purpose is to help with
    converting Python 2 code to run under Python 3\. Since Python 2 is no longer being
    actively maintained, we can safely ignore this function.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1 Function tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We looked at a number of higher-order functions in [Chapter 5](Chapter_05.xhtml#x1-1000005),
    [Higher-Order Functions](Chapter_05.xhtml#x1-1000005). Those functions either
    accept a function as an argument or return a function (or generator expression)
    as a result. All those higher-order functions have an essential algorithm that
    is customized by injecting another function. Functions such as `max()`, `min()`,
    and `sorted()` accept a `key=` function to customize their behavior. Functions
    such as `map()` and `filter()` accept a function and an iterable and apply the
    given function to the argument iterable. In the case of the `map()` function,
    the results of the function are simply yielded. In the case of the `filter()`
    function, the Boolean result of the function is used to yield or reject values
    from an iterable source.
  prefs: []
  type: TYPE_NORMAL
- en: All the functions in [Chapter 5](Chapter_05.xhtml#x1-1000005), [Higher-Order
    Functions](Chapter_05.xhtml#x1-1000005), are part of the Python `__builtins__`
    package, meaning these functions are available without the need to use the `import`
    statement. They were made ubiquitous because they seem universally useful. The
    functions in this chapter must be introduced with an `import` statement because
    they’re not quite so universally helpful.
  prefs: []
  type: TYPE_NORMAL
- en: The `reduce()` function straddles this fence. It was originally built in. After
    some discussion, it was moved from the `__builtins__` package to the `functools`
    module because of the possibility of really poor performance. Later in this chapter,
    we’ll see how seemingly simple operations can perform remarkably poorly.
  prefs: []
  type: TYPE_NORMAL
- en: 10.2 Memoizing previous results with cache
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `@cache` and `@lru_cache` decorators transform a given function into a function
    that might perform more quickly. LRU means Least Recently Used—a finite pool of
    recently used items is retained. Items not recently used are discarded to keep
    the pool to a bounded size. The `@cache` has no storage management and requires
    a little bit of consideration to be sure it won’t consume all available memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since these are decorators, we can apply one of them to any function that might
    benefit from caching previous results. We can use it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This is an example based on [Chapter 6](Chapter_06.xhtml#x1-1260006), [Recursions
    and Reductions](Chapter_06.xhtml#x1-1260006). We’ve applied the `@lru_cache` decorator
    to the naive Fibonacci number calculation. Because of this decoration, each evaluation
    of the `fibc(n)` function will now be checked against a cache maintained by the
    decorator. If the argument value, `n`, is in the cache, the previously computed
    result is used instead of doing a potentially expensive re-calculation. Each new
    collection of argument values and return value updates the cache.
  prefs: []
  type: TYPE_NORMAL
- en: We highlight this example because the naive recursion is quite expensive in
    this case. The complexity of computing any given Fibonacci number, F[n] = F[n−1]
    + F[n−2], involves not merely computing F[n−1] but also F[n−2]. This tree of values
    leads to a complexity in the order of O(2^n).
  prefs: []
  type: TYPE_NORMAL
- en: The argument value of `128` is the size of the cache. This is used to limit
    the amount of memory used for the cache. When the cache is full, the LRU item
    is replaced.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can try to confirm the benefits empirically using the `timeit` module. We
    can execute the two implementations 1,000 times each to see how the timing compares.
    Using the `fib(20)` and `fibc(20)` methods shows just how costly this calculation
    is without the benefit of caching. Because the naive version is so slow, the `timeit`
    number of repetitions was reduced to only 1,000\. Here are the results (in seconds):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Naive: 3.23'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cached: 0.0779'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that we can’t trivially use the `timeit` module on the `fibc()` function.
    The cached values will remain in place; we’ll only evaluate the complete `fibc(20)`
    calculation once, which populates values in the cache. Each of the remaining 999
    iterations will simply fetch the value from the cache. We need to actually clear
    the cache between uses of the `fibc()` function or the time drops to almost zero.
    This is done with a `fibc.cache_clear()` method built by the decorator.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of memoization is powerful. There are many algorithms that can benefit
    from memoization of results. Because the `@cache` decorator applies to a function,
    it means using a functional programming approach can also lead to high-performance
    software. Functions with side effects are rarely good candidates for memoization;
    pure functions will work out best.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll look at one more example of the benefits of caching. This will involve
    a small computation that also has repeated values. The number of combinations
    of p things taken in groups of r is often stated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![( ) p = ----p!--- r r!(p− r!) ](img/file97.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This binomial function involves computing three factorial values. It might make
    sense to use the `@cache` decorator on a factorial function. A program that calculates
    a number of binomial values will not need to re-compute all of those factorials.
    For cases where similar values are computed repeatedly, the speedup can be impressive.
    For situations where the cached values are rarely reused, the overheads of maintaining
    the cached values may outweigh any speedups.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve omitted the details of the actual binomial function. It’s only one line
    of code. Caching a built-in function is done like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This applies the decorator to an existing function. For more information on
    this approach to decoration, see [Chapter 12](Chapter_12.xhtml#x1-25000012), [Decorator
    Design Techniques](Chapter_12.xhtml#x1-25000012).
  prefs: []
  type: TYPE_NORMAL
- en: 'When evaluating a binomial function repeatedly, we see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Naive factorial: 0.174'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cached factorial: 0.046'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to recognize that the cache is a stateful object. This design
    pushes the edge of the envelope on purely functional programming. One functional
    ideal is to avoid changes of state. This concept of avoiding stateful variables
    is exemplified by a recursive function; the current state is contained in the
    argument values, and not in the changing values of variables. We’ve seen how tail-call
    optimization is an essential performance improvement to ensure that this idealized
    recursion actually works nicely with the available processor hardware and limited
    memory budgets. In Python, we can do this tail-call optimization manually by replacing
    the tail recursions with a `for` loop. Caching is a similar kind of optimization;
    we must implement it manually as needed, knowing that it isn’t purely functional
    programming.
  prefs: []
  type: TYPE_NORMAL
- en: 'Further, if our design is centered on pure functions—free of side effects—then
    there are no problems with introducing caching. Applying an `@cache` decorator
    to a function that has side effects, for example, the `print()` function, will
    create confusion: we’ll note that evaluations of `print()` with the same argument
    values won’t produce any output because the result value, `None`, will be fetched
    from cache.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In principle, each call to a function with a cache has two results: the expected
    result and a new `cache` object available for future evaluations of the function.
    Pragmatically, in our example, the `cache` object is encapsulated inside the decorated
    version of the `fibc()` function, and it isn’t available for inspection or manipulation.'
  prefs: []
  type: TYPE_NORMAL
- en: Caching is not a panacea. Applications that work with float values might not
    benefit much from memoization because float values are often approximations. The
    least-significant bits of a float value should be seen as random noise that can
    prevent the exact equality test in the `@lru_cache` or `@cache` decorator from
    working.
  prefs: []
  type: TYPE_NORMAL
- en: 10.3 Defining classes with total ordering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `@total_ordering` decorator is helpful for creating new class definitions
    that implement a rich set of comparison operators. This might apply to numeric
    classes that subclass `numbers.Number`. It may also apply to semi-numeric classes.
  prefs: []
  type: TYPE_NORMAL
- en: As an example of a semi-numeric class, consider a playing card. It has a numeric
    rank and a symbolic suit. The suit, for example, may not matter for some games.
    Like ordinary integers, cards have an ordering. We often sum the point values
    of each card, making them number-like. However, multiplication of cards, card
    × card, doesn’t really make any sense; a card isn’t quite like a number.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can almost emulate a playing card with a `NamedTuple` base class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This model suffers from a profound limitation: all comparisons between cards
    will include both the rank and the suit. This leads to the following awkward behavior
    when we compare the two of spades against the two of clubs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The default comparison rule is fine for some games. It does not work well for
    those games in which comparisons focus on rank and ignore suit.
  prefs: []
  type: TYPE_NORMAL
- en: For some games, it can be better for the default comparisons between cards to
    be based on only their rank.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following class definition is appropriate for games where the suit isn’t
    a primary concern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This class extends the `NamedTuple` class. We’ve provided a `__str__()` method
    to print a string representation of a `Card2` object.
  prefs: []
  type: TYPE_NORMAL
- en: There are two comparisons defined—one for equality and one for ordering. A wide
    variety of comparisons can be defined, and the `@total_ordering` decorator handles
    the construction of the remaining comparisons. In this case, the decorator creates
    `__le__()`, `__gt__()`, and `__ge__()` from these two definitions. The default
    implementation of `__ne__()` uses `__eq__()`; this works without using a decorator.
  prefs: []
  type: TYPE_NORMAL
- en: Both the methods provided in this class allow two kinds of comparisons—between
    `Card2` objects, and also between a `Card2` object and an integer. The type hint
    must be `Any` to remain compatible with the superclass definition of `__eq__()`
    and `__lt__()`. It’s clear that it could be narrowed to `Union[Card2,`` int]`,
    but this conflicts with the definition inherited from the superclass.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, this class offers proper comparison of only the ranks, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use this class for a number of simulations with simplified syntax to
    compare ranks of cards. Furthermore, the decorator builds a rich set of comparison
    operators as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We didn’t need to write all of the comparison method functions; they were generated
    by the decorator. The decorator’s creation of operators isn’t perfect. In our
    case, we’ve asked for comparisons with integers as well as between `Card` instances.
    This reveals some problems.
  prefs: []
  type: TYPE_NORMAL
- en: Operations such as the `c4c`` >`` 3` and `3`` <`` c4c` comparisons would raise
    `TypeError` exceptions because of the way the operators are resolved to find a
    class that implements the comparison. This exposes a limitation of the methods
    created by the `@total_ordering` decorator. Specifically, the generated methods
    won’t have clever type matching rules. If we need type matching in all of the
    comparisons, we’ll need to write all of the methods.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4 Applying partial arguments with partial()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `partial()` function leads to something called a partial application. A
    partially applied function is a new function built from an old function and a
    subset of the required argument values. It is closely related to the concept of
    currying. Much of the theoretical background is not relevant here, since currying
    doesn’t apply directly to the way Python functions are implemented. The concept,
    however, can lead us to some handy simplifications.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can look at trivial examples as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We’ve created the function `exp2(y)`, which is the `pow(2,`` y)` function. The
    `partial()` function binds the first positional parameter to the `pow()` function.
    When we evaluate the newly created `exp2()` function, we get values computed from
    the argument bound by the `partial()` function, plus the additional argument provided
    to the `exp2()` function.
  prefs: []
  type: TYPE_NORMAL
- en: The bindings of positional parameters are handled in a strict left-to-right
    order. Functions that accept keyword parameters can also be provided when building
    the partially applied function.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also create this kind of partially applied function with a lambda form
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Neither is clearly superior. The use of `partial()` can help a reader understand
    the design intent. The use of a lambda may not have the same explanatory power.
  prefs: []
  type: TYPE_NORMAL
- en: Partial functions can be very handy in a context where we want to avoid repeating
    argument values to a function. We may, for example, be normalizing data after
    computing the mean and standard deviation. These normalized values are sometimes
    called Z-scores. While we can define a function `z(mean:`` float,`` stdev:`` float,`` score:`` float)`` ->`` float:`,
    this has the clutter of many argument values that don’t change once the mean and
    standard deviation are known.
  prefs: []
  type: TYPE_NORMAL
- en: 'We prefer something like the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The creation of the `z_value()` partial function is not – strictly speaking
    – needed. Having this function can clarify the expression that creates the `normalized_some_data`
    object. Using `z_value(x)` seems slightly more readable than `z_value(m,`` std,`` x)`.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll return to the `partial()` function in [Chapter 13](Chapter_13.xhtml#x1-26600013),
    [The PyMonad Library](Chapter_13.xhtml#x1-26600013), and look at how we can accomplish
    this same kind of function definition using currying.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5 Reducing sets of data with the reduce() function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `sum()`, `len()`, `max()`, and `min()` functions are, in a way, all specializations
    of a more general algorithm expressed by the `reduce()` function. See [Chapter 5](Chapter_05.xhtml#x1-1000005),
    [Higher-Order Functions](Chapter_05.xhtml#x1-1000005) for more on these functions.
    The `reduce()` function is a higher-order function that folds a binary operation
    into each pair of items in an iterable.
  prefs: []
  type: TYPE_NORMAL
- en: 'A sequence object is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The expression `reduce(lambda`` x,`` y:`` x+y,`` d)` will fold in `+` operators
    to the list as if we were evaluating the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'It can help to include `()` to show the effective left-to-right grouping as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Python’s standard interpretation of expressions involves a left-to-right evaluation
    of operators. Consequently, a fold left doesn’t involve a change in meaning. Many
    functional programming languages including Haskell and OCaml (among many others)
    offer a fold-right alternative. When used in conjunction with recursion, a compiler
    can do a number of clever optimizations. This isn’t available in Python; a reduction
    is always left to right.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also provide an initial value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If we don’t supply an initial value, the initial value from the sequence is
    used as the initialization. Providing an initial value is essential when there’s
    a `map()` function as well as a `reduce()` function. The following is how the
    right answer is computed with an explicit `0` initializer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'If we omit the initialization of `0`, the `reduce()` function uses the first
    item as an initial value. This value does not have the transformation function
    applied, which leads to the wrong answer. In effect, the `reduce()` without a
    proper initial value is computing this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This kind of mistake is part of the reason why `reduce()` must be used carefully.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can define a number of common and built-in reductions using the `reduce()`
    higher-order function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `sum2()` reduction function is the sum of squares, useful for computing
    the standard deviation of a set of samples. This `sum()` reduction function mimics
    the built-in `sum()` function. The `count()` reduction function is similar to
    the `len()` function, but it can work on an iterable, whereas the `len()` function
    can only work on a materialized collection object.
  prefs: []
  type: TYPE_NORMAL
- en: The `cast()` functions notify mypy of the intended types for the lambda objects.
    Without this, the default type hint for a lambda object is `Any`, which isn’t
    the intent for these functions. The type hint `FloatFT` describes a float function
    that accepts two float argument values and returns a float object as a result.
  prefs: []
  type: TYPE_NORMAL
- en: The `min()` and `max()` functions mimic the built-in reductions. Because the
    first item of the iterable is used for initialization, these two functions will
    work properly. If we provided an initial value to these `reduce()` functions,
    we might incorrectly use a value that never occurred in the original iterable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The complexity of the type hints is a suggestion that lambda objects don’t
    convey enough information to tools like mypy. While a lambda is valid Python,
    it can be difficult to examine in detail. This leads to the following tip:'
  prefs: []
  type: TYPE_NORMAL
- en: A good design uses small function definitions.
  prefs: []
  type: TYPE_NORMAL
- en: A complete function definition lets us provide default values, documentation,
    and `doctest` test cases.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.1 Combining map() and reduce()
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We can see how to build higher-order functions around these foundational definitions.
    We can define a map-reduce function that combines the `map()` and `reduce()` functions
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This definition has a few formal type constraints. First, the `source` iterator
    produces some consistently typed data. We’ll bind the source type to the `ST`
    type variable to show where consistent types are required. Second, the provided
    `map_fun()` function accepts one argument of whatever type could be bound to `ST`
    and produces a float object. Third, the provided `reduce_fun()` function will
    reduce float objects to return a result of the same type. Because mypy is aware
    of the way Python operators work with integers as well as float values, this works
    in an integer context as well as a float context.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can build a sum-of-squares reduction using the `map_fun()` and `reduce_fun()`
    functions separately as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we’ve used a `lambda`` y:`` y**2` argument value as a mapping
    to square each value. The reduction is the `lambda`` x,`` y:`` x+y` argument value.
    We don’t need to explicitly provide an initial value because the initial value
    will be the first item in the iterable after the provided `map_fun()` lambda has
    squared it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `lambda`` x,`` y:`` x+y` argument value is the `+` operator. Python offers
    all of the arithmetic operators as short functions in the `operator` module. (We’ll
    look at this in [Chapter 11](Chapter_11.xhtml#x1-23500011), [The Toolz Package](Chapter_11.xhtml#x1-23500011).)
    The following is how we can slightly simplify our map-reduce operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We’ve used the `operator.add` function to sum our values instead of the longer
    lambda form.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is how we can count values in an iterable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We’ve used the `lambda`` y:`` 1` parameter to map each value to the value `1`.
    The count is then reduced using a lambda or the `operator.add` function.
  prefs: []
  type: TYPE_NORMAL
- en: The general-purpose `reduce()` function allows us to create any species of reduction
    from a large dataset to a single value. There are some limitations, however, on
    what we should do with the `reduce()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.2 Using the reduce() and partial() functions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As we saw earlier, the `reduce()` function has a provision for an initial value.
    The default initial value is zero. This initial value seeds the reduction and
    will be the default value if the source iterable is empty.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we’ve provided an absurd initial value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The initial value provided to the `reduce()` function is a string. Because the
    iterable source of data, `d` is empty, no operations were performed and the initial
    value is the final result, even though it’s absurdly invalid.
  prefs: []
  type: TYPE_NORMAL
- en: 'We note a complication here when we try to create a partial function using
    `reduce()`: there’s no sensible way to provide an initial value. This stems from
    the following root cause: the `reduce()` function has no keyword parameters. For
    some reductions, we need to provide values for the first and third positional
    parameters to the `reduce()` function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the result of attempting to combine `partial()` and `reduce()`. The
    following example definitions of partial functions do not work correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The `psum2()` function should compute a sum of squares of a source of values.
    As we’ll see, this does not work as hoped. Here’s an example of trying to use
    these functions based on the `partial()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The sum-of-squares defined as a partial does not use a proper initialization
    for the sequence of values.
  prefs: []
  type: TYPE_NORMAL
- en: The reduction should start with 0\. It will apply the lambda to each value,
    and sum `0`` +`` 2**2`, `0`` +`` 2**2`` +`` 4**2`, etc. In actual fact, it starts
    with the first of the values, `2`. Then it applies the lambda to the remaining
    values, computing `2`` +`` 4**2`, `2`` +`` 4**2`` +`` 4**2`, etc.
  prefs: []
  type: TYPE_NORMAL
- en: There’s no work-around using `partial()`. A lambda must be used in these cases
    where we’d like to apply a transformation while using `reduce()`.
  prefs: []
  type: TYPE_NORMAL
- en: A partial function is an important technique for simplifying a particularly
    complicated calculation. When there are numerous parameters, few of which change,
    then a partial function can be helpful. A partial function can make it easier
    to refactor a complex computation to use alternative implementations of discrete
    parts. Since each discrete part is a separately defined function, unit testing
    can confirm that the results are as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'The limitation around the `reduce()` function is a result of a function with
    two properties:'
  prefs: []
  type: TYPE_NORMAL
- en: Only positional parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The parameters being provided in an awkward order
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of `reduce()`, the initial value comes after the source of values,
    making it difficult to provide via `partial()`.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.3 Using the map() and reduce() functions to sanitize raw data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When doing data cleansing, we’ll often introduce filters of various degrees
    of complexity to exclude invalid values. We may also include a mapping to sanitize
    values in the cases where a valid but improperly formatted value can be replaced
    with a valid and proper value.
  prefs: []
  type: TYPE_NORMAL
- en: 'We might produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We’ve defined a mapping, the `comma_fix()` function, that will convert data
    from a nearly correct string format into a usable floating-point value. This will
    remove the comma character. Another common variation could remove dollar signs
    and convert to `decimal.Decimal`. We’ve left this as an exercise for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve also defined a map-reduce operation that applies a given cleaner function,
    the `comma_fix()` function in this case, to the data before doing a `reduce()`
    function, using the `operator.add` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can apply the previously described function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We’ve cleaned the data by fixing the commas, as well as computing a sum. The
    syntax is very convenient for combining these two operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have to be careful, however, of using the cleaning function more than once.
    If we’re also going to compute a sum of squares, we really should not execute
    the following kinds of processing steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Using `clean_sum()` expressions more than once means we’ll do the comma-fixing
    operation more than once on the source data. This is a poor design. It would be
    better to cache the intermediate numeric results of the `comma_fix()` function.
    Using a `@cache` decorator can help. Materializing the sanitized intermediate
    values as a temporary sequence object is better. Comparing the performance of
    different caching options is left as an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.4 Using the groupby() and reduce() functions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A common requirement is to summarize data after partitioning it into groups.
    We can use a `defaultdict(list)` method to partition data. We can then analyze
    each partition separately. In [Chapter 4](Chapter_04.xhtml#x1-740004), [Working
    with Collections](Chapter_04.xhtml#x1-740004), we looked at some ways to group
    and partition. In [Chapter 8](Chapter_08.xhtml#x1-1700008), [The Itertools Module](Chapter_08.xhtml#x1-1700008),
    we looked at others.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is some sample data that we need to analyze:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We’ve got a sequence of raw data values with a key (a short string) and a measurement
    for each key (a float value).
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to produce usable groups from this data is to build a dictionary that
    maps a key to a list of members in this groups, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This will separate each item in the iterable into a group based on the key.
    The iterable source of data is described using a type variable of `DT`, representing
    the type of each data item. The `key()` function is used to extract a key value
    from each item. This function produces an object of some key type, `KT`, that
    is generally distinct from the original data item type, `DT`. When looking at
    the sample data, the type of each data item is a tuple. The keys are of type `str`.
    The callable function for extracting a key transforms a tuple into a string.
  prefs: []
  type: TYPE_NORMAL
- en: This key value extracted from each data item is used to append each item to
    a list in the `pd` dictionary. The `defaultdict` object is defined as mapping
    each key, `KT`, to a list of the data items, `list[DT]`.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting value of this function matches the results of the `itertools.groupby()`
    function. It’s an iterable sequence of the `(group`` key,`` iterator)` tuples.
    The group key value will be of the type produced by the key function. The iterator
    will provide a sequence of the original data items.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the same feature defined with the `itertools.groupby()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The important difference in the inputs to each function is that the `groupby()`
    function version requires data to be sorted by the key, whereas the
  prefs: []
  type: TYPE_NORMAL
- en: '`defaultdict` version doesn’t require sorting. For very large sets of data,
    the sort can be expensive, measured in both time and storage.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the core partitioning operation. This might be used prior to filtering
    out a group, or it might be used prior to computing statistics for each group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We can summarize this grouped data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The results of the `partition()` functions will be a sequence of (key, iterator)
    two-tuples. The `summarize()` function accepts the two-tuple and decomposes it
    into the key and the iterator over the original data items. In this function,
    the data items are defined as `tuple[KT,`` float]`, a key of some type, `KT`,
    and a numeric value. From each two-tuple in the `item_iter` iterator we want the
    value portion, and we use a generator expression to create a tuple of only the
    values.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use the expression `map(snd,`` item_iter)` to pick the second item
    from each of the two-tuples. This requires a definition of `snd`` =`` lambda`` x:`` x[1]`
    or perhaps `snd`` =`` operator.itemgetter(1)`. The name `snd` is a short form
    of second.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the following command to apply the `summarize()` function to each
    partition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This uses the `starmap()` function from the `itertools` module. See [Chapter 8](Chapter_08.xhtml#x1-1700008),
    [The Itertools Module](Chapter_08.xhtml#x1-1700008). An alternative definition
    using the `partition_s()` function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Both will provide us with summary values for each group. The resulting group
    statistics look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The variance can be used as part of a χ² (chi-squared) test to determine if
    the null hypothesis holds for this data. The null hypothesis asserts that there’s
    nothing to see: the variance in the data is essentially random. We can also compare
    the data between the four groups to see if the various means are consistent with
    the null hypothesis or if there is some statistically significant variation.'
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.5 Avoiding problems with reduce()
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There is a dark side to the `reduce()` function. We must avoid expressions
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This does work, because Python will apply the generic `add` operator between
    two operands, which are strings. However, it will compute a large number of intermediate
    string objects, a relatively costly operation. An alternative is the `"".join(list_of_strings)`
    expression. A little study with `timeit` reveals that the `string.join()` approach
    is more efficient than the generic `reduce()` version. We’ll leave the data collection
    and analysis as an exercise for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: In general, it’s best to scrutinize `reduce()` operations where the function
    provided creates or modifies a collection of some kind. It’s possible to have
    a superficially simple-looking expression that creates very large intermediate
    results. For example, we might write `reduce(accumulate_details,`` some_source,`` {})`
    without thinking of the way the `accumulate_details()` function updates a dictionary.
    We might be better off looking at ways to rewrite the underlying `accumulate_details()`
    function to accept a sequence instead of a single item.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6 Handling multiple types with singledispatch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ll often have functions which have similar semantics but distinct implementations
    based on the type of data presented. We might have a function that works for either
    a subclass of `NamedTuple`, or `TypedDict`. The syntax for working with these
    objects is distinct, and we can’t use a single, generic Python function.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the following choices for working with data of distinct types:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the `match` statement with a `case` clause for each distinct type.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `@singledispatch` decorator to define a number of closely-related functions.
    This will create the necessary type-matching `match` statement for us.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A small example arises when working with US postal data and spreadsheets. It’s
    common for a US postal ZIP code to be misinterpreted as an integer (or float)
    value. The town of Andover, MA, for example, has a postal code of 01810\. A spreadsheet
    might misinterpret this as an integer, 1810, dropping the leading zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'When working with US postal data, we often need a function to normalize ZIP
    codes as string values, restoring any dropped leading zero values. This function
    will have at least the following three cases:'
  prefs: []
  type: TYPE_NORMAL
- en: An integer value needs to be converted to a string and have leading zeroes restored.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A float value, similarly, needs to be converted to a string and have the leading
    zeroes restored.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string value may be a five-digit ZIP code or a nine-digit ZIP code. Depending
    on the application, we might want to truncate the ZIP codes to ensure they are
    uniform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While we can use a `match` statement to handle these three cases, we can also
    define several closely-related functions. The `@singledispatch` decorator lets
    us define a ”default” function, used when no type matching is possible. We can
    then overload this function with additional definitions for each of the data types
    we want to process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the suite of definitions for a single `zip_format()` function. We’ll
    start with the base definition, used when no other definition will work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The `@singledispatch` decorator will create a new decorator, using the name
    of the function, `zip_format`. This new `@zip_format` decorator can then use be
    used to create alternative, overloaded definitions. These definitions imply a
    `match` statement to distinguish among the alternatives based on type matching
    rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the alternative definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Note that each alternative function uses a name, `_`, that will be ignored.
    The functions will all be combined into a single `zip_format()` function that
    will dispatch an appropriate implementation based on the type of the argument
    value.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important to note that these functions do not all need to be defined
    in the same module. We can provide a module with foundational definitions. Additional
    modules can then import the base definitions and register their unique implementation
    functions. This permits expansion by adding alternative implementations at the
    module level.
  prefs: []
  type: TYPE_NORMAL
- en: 10.7 Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we’ve looked at a number of functions in the `functools` module.
    This library module provides a number of functions that help us create sophisticated
    functions and classes.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve looked at the `@cache` and `@lru_cache` decorators as ways to boost certain
    types of applications with frequent re-calculations of the same values. These
    two decorators are of tremendous value for certain kinds of functions that take
    integer or string argument values. They can reduce processing by simply implementing
    memoization. The `@lru_cache` has an upper bound on the memory it will use; this
    is good for a domain with an unknown size.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at the `@total_ordering` function as a decorator to help us build
    objects that support rich ordering comparisons. This is at the fringe of functional
    programming, but is very helpful when creating new kinds of numbers.
  prefs: []
  type: TYPE_NORMAL
- en: The `partial()` function creates a new function with the partial application
    of argument values. As an alternative, we can build a lambda with similar features.
    The use case for this is ambiguous.
  prefs: []
  type: TYPE_NORMAL
- en: We also looked at the `reduce()` function as a higher-order function. This generalizes
    reductions like the `sum()` function. We’ll use this function in several examples
    in later chapters. This fits logically with the `filter()` and `map()` functions
    as an important higher-order function.
  prefs: []
  type: TYPE_NORMAL
- en: The `@singledispatch` decorator can help us to create a number of functions
    with similar semantics, but distinct data types for the argument values. This
    prevents the overhead of an explicit `match` statement. As the software evolves,
    we can add definitions to the collection of alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll look at a collection of small topics. We’ll examine
    the `toolz` package, which provides some alternatives to the built-in `itertools`
    and `functools` modules. This alternative has a number of new features. It also
    has some overlapping features that are considered from a different perspective,
    making them more useful for some applications.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll also see some additional use of the `operator` module. This module makes
    some Python operators available as functions, letting us simplify our own function
    definitions.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll also look at some techniques to design flexible decision-making and to
    allow expressions to be evaluated in a non-strict order.
  prefs: []
  type: TYPE_NORMAL
- en: 10.8 Exercises
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter’s exercises are based on code available from Packt Publishing on
    GitHub. See [https://github.com/PacktPublishing/Functional-Python-Programming-3rd-Edition](https://github.com/PacktPublishing/Functional-Python-Programming-3rd-Edition).
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, the reader will notice that the code provided on GitHub includes
    partial solutions to some of the exercises. These serve as hints, allowing the
    reader to explore alternative solutions.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, exercises will need unit test cases to confirm they actually
    solve the problem. These are often identical to the unit test cases already provided
    in the GitHub repository. The reader should replace the book’s example function
    name with their own solution to confirm that it works.
  prefs: []
  type: TYPE_NORMAL
- en: 10.8.1 Compare string.join() and reduce()
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the [Avoiding problems with reduce()](#x1-2270005) section of this chapter,
    we noted that we can combine a list of string values into a single string in the
    following two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '`reduce(operator.add,`` list_of_strings,`` "")`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"".join(list_of_strings)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of these is considerably more efficient than the other. Use the `timeit`
    module to find out which is more efficient. The efficiency gain is dramatic, and
    it can be helpful to know what the ratio of time between these two approaches
    is.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important to know how the two approaches scale with larger and larger
    collections of strings. To this end, build a small module that exercises the above
    two expressions with collections of strings. Use collections with sizes 100, 200,
    300, ..., 900 as a way to see how the work scales with the number of strings being
    concatenated.
  prefs: []
  type: TYPE_NORMAL
- en: 10.8.2 Extend the comma_fix() function
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the [Using the map() and reduce() functions to sanitize raw data](#x1-2250003)
    section, we defined a mapping, the `comma_fix()` function, that will convert data
    from a nearly correct string format into a usable floating-point value. This will
    remove the comma character.
  prefs: []
  type: TYPE_NORMAL
- en: This function has a misleading name. It’s really a string-to-float conversion
    that tolerates some punctuation. A better name might be `tolerant_str_to_float()`.
  prefs: []
  type: TYPE_NORMAL
- en: Define and test a tolerant string-to-decimal conversion function. This should
    remove dollar signs, as well as commas, and convert the remaining string to `decimal.Decimal`.
  prefs: []
  type: TYPE_NORMAL
- en: Define and test a tolerant string-to-int conversion function. This should parallel
    the `tolerant_str_to_float()` by removing only comma characters.
  prefs: []
  type: TYPE_NORMAL
- en: 10.8.3 Revise the clean_sum() function
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the [Using the map() and reduce() functions to sanitize raw data](#x1-2250003)
    section, we defined a `clean_sum()` function to cleanse and sum a collection of
    raw string values. For a simple case like computing a mean, this involves a single
    pass over the data doing conversion and computation.
  prefs: []
  type: TYPE_NORMAL
- en: For a more complex operation, like variance or standard deviation, multiple
    passes can be burdensome because the string conversion is done repeatedly. This
    suggests the `clean_sum()` function is a poor design.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first requirement is a function to compute the mean, variance, and standard
    deviation of string data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ ∑ --x∈D-x- mean (D ) = len(D ) ](img/file102.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '![ ∑ (x-−-mean-(D-))2 var(D ) = len(D )− 1 x∈D ](img/file103.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '![stdev(D ) = ∘var-(D-) ](img/file104.jpg)'
  prefs: []
  type: TYPE_IMG
- en: One design alternative is to cache the intermediate numeric results of the `comma_fix()`
    function. Use the `@cache` decorator to define a `comma_fix()` function. (This
    function should be renamed to something a little more explicit, like `str_to_float()`.)
  prefs: []
  type: TYPE_NORMAL
- en: Create a very large collection of randomized numeric strings and see which alternative
    is faster.
  prefs: []
  type: TYPE_NORMAL
- en: Another design alternative is to materialize the sanitized intermediate values.
    Create a temporary sequence object with the purely numeric values, and then compute
    the various statistical measures on these purely numeric lists.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 7](Chapter_07.xhtml#x1-1530007), [Complex Stateless Objects](Chapter_07.xhtml#x1-1530007),
    we presented a way to use `sys.getallocatedblocks()` to understand how much memory
    was being used by Python. This procedure can be applied here to see which caching
    alternative uses the least memory.
  prefs: []
  type: TYPE_NORMAL
- en: Present the results to show which design alternative is best for performance
    and memory use.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community Discord space
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Join our Python Discord workspace to discuss and know more about the book:
    [https://packt.link/dHrHU](https://packt.link/dHrHU)'
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file1.png)'
  prefs: []
  type: TYPE_IMG
