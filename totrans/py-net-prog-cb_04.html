<html><head></head><body>
  <div><div><div><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Programming with HTTP for the Internet</h1></div></div></div><p>In this chapter, we will cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Downloading data from an HTTP server</li><li class="listitem" style="list-style-type: disc">Serving HTTP requests from your machine</li><li class="listitem" style="list-style-type: disc">Extracting cookie information after visiting a website</li><li class="listitem" style="list-style-type: disc">Submitting web forms</li><li class="listitem" style="list-style-type: disc">Sending web requests through a proxy server</li><li class="listitem" style="list-style-type: disc">Checking whether a web page exists with the HEAD request</li><li class="listitem" style="list-style-type: disc">Spoofing Mozilla Firefox in your client code</li><li class="listitem" style="list-style-type: disc">Saving bandwidth in web requests with the HTTP compression</li><li class="listitem" style="list-style-type: disc">Writing an HTTP fail-over client with resume and partial downloading</li><li class="listitem" style="list-style-type: disc">Writing a simple HTTPS server code with Python and OpenSSL</li></ul></div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec41"/>Introduction</h1></div></div></div><p>This chapter explains Python HTTP networking library functions with a few third-party libraries. For example, the <code class="literal">requests</code> library deals with the HTTP requests in a nicer and cleaner way. The <code class="literal">OpenSSL</code> library is used in one of the recipes to create a SSL-enabled web server.</p><p>Many common HTTP protocol features have been illustrated in a few recipes, for example, the web form submission with <code class="literal">POST</code>, manipulating header information, use of compression, and so on.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec42"/>Downloading data from an HTTP server</h1></div></div></div><p>You would like to write <a id="id233" class="indexterm"/>a simple HTTP client to fetch some data<a id="id234" class="indexterm"/> from any web server using the native HTTP protocol. This can be the very first steps towards creating your own HTTP browser.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec79"/>How to do it...</h2></div></div></div><p>Let us access <a class="ulink" href="http://www.python.org">www.python.org</a> with our Pythonic minimal browser that uses Python's <code class="literal">httplib</code>.</p><p>Listing 4.1 explains the following code for a simple HTTP client:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter - 4
# This program is optimized for Python 2.7.
# It may run on any other version with/without modifications.


import argparse
import httplib

REMOTE_SERVER_HOST = 'www.python.org'
REMOTE_SERVER_PATH = '/'

class HTTPClient:

  def __init__(self, host):
    self.host = host

  def fetch(self, path):
    http = httplib.HTTP(self.host)

    # Prepare header
    http.putrequest("GET", path)
    http.putheader("User-Agent", __file__)
    http.putheader("Host", self.host)
    http.putheader("Accept", "*/*")
    http.endheaders()

    try:
      errcode, errmsg, headers = http.getreply()

    except Exception, e:
      print "Client failed error code: %s message:%s headers:%s" 
%(errcode, errmsg, headers)
    else: 
      print "Got homepage from %s" %self.host 

    file = http.getfile()
    return file.read()

if __name__ == "__main__":
  parser = argparse.ArgumentParser(description='HTTP Client 
Example')
  parser.add_argument('--host', action="store", dest="host",  
default=REMOTE_SERVER_HOST)
  parser.add_argument('--path', action="store", dest="path",  
default=REMOTE_SERVER_PATH)
  given_args = parser.parse_args() 
  host, path = given_args.host, given_args.path
  client = HTTPClient(host)
  print client.fetch(path)</pre></div><p>This recipe will by default fetch a page from <a class="ulink" href="http://www.python.org">www.python.org</a>. You can run this recipe with or without the host and<a id="id235" class="indexterm"/> path arguments. If this script is <a id="id236" class="indexterm"/>run, it will show the following output:</p><div><pre class="programlisting">
<strong>$  python 4_1_download_data.py --host=www.python.org </strong>
<strong>Got homepage from www.python.org</strong>
<strong>&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;</strong>
<strong>&lt;html  xml:lang="en" lang="en"&gt;</strong>

<strong>&lt;head&gt;</strong>
<strong>  &lt;meta http-equiv="content-type" content="text/html; charset=utf-8" /&gt;</strong>
<strong>  &lt;title&gt;Python Programming Language &amp;ndash; Official Website&lt;/title&gt;</strong>
<strong>....</strong>
</pre></div><p>If you run this recipe with an invalid path, it will show the following server response:</p><div><pre class="programlisting">
<strong>$ python 4_1_download_data.py --host='www.python.org' --path='/not-</strong>
<strong>exist'</strong>
<strong>Got homepage from www.python.org</strong>
<strong>&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;</strong>
<strong>&lt;html  xml:lang="en" lang="en"&gt;</strong>
<strong>&lt;head&gt;</strong>
<strong>  &lt;meta http-equiv="content-type" content="text/html; charset=utf-8" /&gt;</strong>
<strong>  &lt;title&gt;Page Not Found&lt;/title&gt;</strong>
<strong>  &lt;meta name="keywords" content="Page Not Found" /&gt;</strong>
<strong>  &lt;meta name="description" content="Page Not Found" /&gt;</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec80"/>How it works...</h2></div></div></div><p>This recipe defines an <code class="literal">HTTPClient</code> class<a id="id237" class="indexterm"/> that fetches data from the remote host. It is built using Python's native <code class="literal">httplib</code> library. In the <code class="literal">fetch()</code> method<a id="id238" class="indexterm"/>, it uses the <code class="literal">HTTP()</code> function<a id="id239" class="indexterm"/> and other auxiliary functions to create a dummy HTTP client, such as <code class="literal">putrequest()</code> or <code class="literal">putheader()</code>. It first puts the <code class="literal">GET/path</code> string that is followed by setting up a user agent, which is the <a id="id240" class="indexterm"/>name of the current script (<code class="literal">__file__</code>).</p><p>The main request <code class="literal">getreply()</code>method<a id="id241" class="indexterm"/> is <a id="id242" class="indexterm"/>put inside a try-except block. The response is retrieved from the <code class="literal">getfile()</code> method<a id="id243" class="indexterm"/> and the stream's content is read.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec43"/>Serving HTTP requests from your machine</h1></div></div></div><p>You would like to create <a id="id244" class="indexterm"/>your own web server. Your web server <a id="id245" class="indexterm"/>should handle client requests and send a simple <code class="literal">hello</code> message.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec81"/>How to do it...</h2></div></div></div><p>Python ships with a very simple web server that can be launched from the command line as follows:</p><div><pre class="programlisting">
<strong>$ python -m SimpleHTTPServer 8080</strong>
</pre></div><p>This will launch an HTTP web server on port <code class="literal">8080</code>. You can access this web server from your browser by typing <code class="literal">http://localhost:8080</code>. This will show the contents of the current directory from where you run the preceding command. If there is any web server index file, for example, <code class="literal">index.html</code>, inside that directory, your browser will show the contents of <code class="literal">index.html</code>. However, if you like to have full control over your web server, you need to launch your customized HTTP server..</p><p>Listing 4.2 gives the following code for the custom HTTP web server:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter - 4
# This program is optimized for Python 2.7.
# It may run on any other version with/without modifications.

import argparse
import sys
from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer

DEFAULT_HOST = '127.0.0.1'
DEFAULT_PORT = 8800

class RequestHandler(BaseHTTPRequestHandler):
  """ Custom request handler"""
  
  def do_GET(self):
    """ Handler for the GET requests """
    self.send_response(200)
    self.send_header('Content-type','text/html')
    self.end_headers()
    # Send the message to browser
    self.wfile.write("Hello from server!")
  

class CustomHTTPServer(HTTPServer):
  "A custom HTTP server"
  def __init__(self, host, port):
    server_address = (host, port)
    HTTPServer.__init__(self, server_address, RequestHandler)
  

def run_server(port):
  try:
    server= CustomHTTPServer(DEFAULT_HOST, port)
    print "Custom HTTP server started on port: %s" % port
    server.serve_forever()
  except Exception, err:
    print "Error:%s" %err
  except KeyboardInterrupt:
    print "Server interrupted and is shutting down..."
    server.socket.close()

if __name__ == "__main__":
  parser = argparse.ArgumentParser(description='Simple HTTP Server 
Example')
  parser.add_argument('--port', action="store", dest="port", 
type=int, default=DEFAULT_PORT)
  given_args = parser.parse_args() 
  port = given_args.port
  run_server(port)</pre></div><p>The following screenshot shows a simple HTTP server:</p><div><img src="img/3463OS_04_01.jpg" alt="How to do it..."/></div><p>If you run this web server and<a id="id246" class="indexterm"/> access the URL from a browser, this <a id="id247" class="indexterm"/>will send the one line text <code class="literal">Hello from server!</code> to the browser, as follows:</p><div><pre class="programlisting">
<strong>$ python 4_2_simple_http_server.py --port=8800</strong>
<strong>Custom HTTP server started on port: 8800</strong>
<strong>localhost - - [18/Apr/2013 13:39:33] "GET / HTTP/1.1" 200 -</strong>
<strong>localhost - - [18/Apr/2013 13:39:33] "GET /favicon.ico HTTP/1.1" 200 </strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec82"/>How it works...</h2></div></div></div><p>In this recipe, we created the <code class="literal">CustomHTTPServer</code> class<a id="id248" class="indexterm"/> inherited from the <code class="literal">HTTPServer</code> class. In the constructor method, the <code class="literal">CustomHTTPServer</code> class sets up the server address and port received as a user input. In the constructor, our web server's <code class="literal">RequestHandler</code> class<a id="id249" class="indexterm"/> has been set up. Every time a client is connected, the server handles the request according to this class.</p><p>The <code class="literal">RequestHandler</code> defines the action to handle the client's <code class="literal">GET</code> request. It sends an HTTP header (code 200) with a<a id="id250" class="indexterm"/> success message<a id="id251" class="indexterm"/> <strong>Hello from server!</strong> using the <code class="literal">write()</code> method.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec44"/>Extracting cookie information after visiting a website</h1></div></div></div><p>Many websites use cookies to<a id="id252" class="indexterm"/> store their various information on to your local disk. You would like to see this cookie information and perhaps log in to that website automatically using cookies.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec83"/>How to do it...</h2></div></div></div><p>Let us try to pretend to log in to a popular code-sharing website, <a class="ulink" href="http://www.bitbucket.org">www.bitbucket.org</a>. We would like to submit the login information on the login page, <a class="ulink" href="https://bitbucket.org/account/signin/?next=/">https://bitbucket.org/account/signin/?next=/</a>. The following screenshot shows the login page:</p><div><img src="img/3463OS_04_02.jpg" alt="How to do it..."/></div><p>So, we note down the form element IDs and decide which fake values should be submitted. We access this page the first time, and the next time, we access the home page to observe what cookies have been set up.</p><p>Listing 4.3 explains extracting cookie information as follows:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter - 4
# This program is optimized for Python 2.7.
# It may run on any other version with/without modifications.

import cookielib 
import urllib
import urllib2

ID_USERNAME = 'id_username'
ID_PASSWORD = 'id_password'
USERNAME = 'you@email.com'
PASSWORD = 'mypassword'
LOGIN_URL = 'https://bitbucket.org/account/signin/?next=/'
NORMAL_URL = 'https://bitbucket.org/'

def extract_cookie_info():
  """ Fake login to a site with cookie"""
  # setup cookie jar
  cj = cookielib.CookieJar()
  login_data = urllib.urlencode({ID_USERNAME : USERNAME, 
  ID_PASSWORD : PASSWORD})
  # create url opener
  opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))
  resp = opener.open(LOGIN_URL, login_data)

  # send login info 
  for cookie in cj:
    print "----First time cookie: %s --&gt; %s" %(cookie.name, 
cookie.value)
    print "Headers: %s" %resp.headers

  # now access without any login info
  resp = opener.open(NORMAL_URL)
  for cookie in cj:
    print "++++Second time cookie: %s --&gt; %s" %(cookie.name, 
cookie.value)
  
  print "Headers: %s" %resp.headers

if __name__ == '__main__':
  extract_cookie_info()</pre></div><p>Running this <a id="id253" class="indexterm"/>recipe results in the following output:</p><div><pre class="programlisting">
<strong>$ python 4_3_extract_cookie_information.py </strong>
<strong>----First time cookie: bb_session --&gt; aed58dde1228571bf60466581790566d</strong>
<strong>Headers: Server: nginx/1.2.4</strong>
<strong>Date: Sun, 05 May 2013 15:13:56 GMT</strong>
<strong>Content-Type: text/html; charset=utf-8</strong>
<strong>Content-Length: 21167</strong>
<strong>Connection: close</strong>
<strong>X-Served-By: bitbucket04</strong>
<strong>Content-Language: en</strong>
<strong>X-Static-Version: c67fb01467cf</strong>
<strong>Expires: Sun, 05 May 2013 15:13:56 GMT</strong>
<strong>Vary: Accept-Language, Cookie</strong>
<strong>Last-Modified: Sun, 05 May 2013 15:13:56 GMT</strong>
<strong>X-Version: 14f9c66ad9db</strong>
<strong>ETag: "3ba81d9eb350c295a453b5ab6e88935e"</strong>
<strong>X-Request-Count: 310</strong>
<strong>Cache-Control: max-age=0</strong>
<strong>Set-Cookie: bb_session=aed58dde1228571bf60466581790566d; expires=Sun, 19-May-2013 15:13:56 GMT; httponly; Max-Age=1209600; Path=/; secure</strong>

<strong>Strict-Transport-Security: max-age=2592000</strong>
<strong>X-Content-Type-Options: nosniff</strong>

<strong>++++Second time cookie: bb_session --&gt; aed58dde1228571bf60466581790566d</strong>
<strong>Headers: Server: nginx/1.2.4</strong>
<strong>Date: Sun, 05 May 2013 15:13:57 GMT</strong>
<strong>Content-Type: text/html; charset=utf-8</strong>
<strong>Content-Length: 36787</strong>
<strong>Connection: close</strong>
<strong>X-Served-By: bitbucket02</strong>
<strong>Content-Language: en</strong>
<strong>X-Static-Version: c67fb01467cf</strong>
<strong>Vary: Accept-Language, Cookie</strong>
<strong>X-Version: 14f9c66ad9db</strong>
<strong>X-Request-Count: 97</strong>
<strong>Strict-Transport-Security: max-age=2592000</strong>
<strong>X-Content-Type-Options: nosniff</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec84"/>How it works...</h2></div></div></div><p>We have <a id="id254" class="indexterm"/>used Python's <code class="literal">cookielib</code> and set up a cookie jar, <code class="literal">cj</code>. The login data has been encoded using <code class="literal">urllib.urlencode</code>. <code class="literal">urllib2</code> has a <code class="literal">build_opener()</code> method<a id="id255" class="indexterm"/>, which takes the predefined cookie jar with an instance of <code class="literal">HTTPCookieProcessor()</code> and returns a URL opener. We call this opener twice: once for the login page and once for the home page of the website. It seems that only one cookie, <code class="literal">bb_session</code>, was set with the set-cookie directive present in the page<a id="id256" class="indexterm"/> header. More information about <code class="literal">cookielib</code> can be found on the official Python documentation site at <a class="ulink" href="http://docs.python.org/2/library/cookielib.html">http://docs.python.org/2/library/cookielib.html</a>.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec45"/>Submitting web forms</h1></div></div></div><p>During web browsing, we<a id="id257" class="indexterm"/> submit web forms many times in a day. Now, you would like do that using the Python code.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec85"/>Getting ready</h2></div></div></div><p>This recipe uses a third-party Python module called <code class="literal">requests</code>. You can install the compatible version of this module by following the instructions from <a class="ulink" href="http://docs.python-requests.org/en/latest/user/install/">http://docs.python-requests.org/en/latest/user/install/</a>. For example, you can use <code class="literal">pip</code> to install <code class="literal">requests</code> from the command line as follows:</p><div><pre class="programlisting">
<strong>$ pip install requests</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec86"/>How to do it...</h2></div></div></div><p>Let us submit some fake data to register with <a class="ulink" href="http://www.twitter.com">www.twitter.com</a>. Each form submission has two methods: <code class="literal">GET</code> and <code class="literal">POST</code>. The less sensitive data, for example, search queries, are usually submitted by <code class="literal">GET</code> and the more sensitive data is sent via the <code class="literal">POST</code> method. Let us try submitting data with both of them.</p><p>Listing 4.4 explains the submit web forms, as follows:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter – 4
# This program is optimized for Python 2.7.
# It may run on any other version with/without modifications.

import requests
import urllib
import urllib2

ID_USERNAME = 'signup-user-name'
ID_EMAIL = 'signup-user-email'
ID_PASSWORD = 'signup-user-password'
USERNAME = 'username'
EMAIL = 'you@email.com'
PASSWORD = 'yourpassword'
SIGNUP_URL = 'https://twitter.com/account/create'


def submit_form():
    """Submit a form"""
    payload = {ID_USERNAME : USERNAME,
               ID_EMAIL    :  EMAIL,
               ID_PASSWORD : PASSWORD,}
    
    # make a get request
    resp = requests.get(SIGNUP_URL)
    print "Response to GET request: %s" %resp.content
    
    # send POST request
    resp = requests.post(SIGNUP_URL, payload)
    print "Headers from a POST request response: %s" %resp.headers
    #print "HTML Response: %s" %resp.read()

if __name__ == '__main__':
    submit_form()</pre></div><p>If you run this script, you<a id="id258" class="indexterm"/> will see the following output:</p><div><pre class="programlisting">
<strong>$ python 4_4_submit_web_form.py </strong>
<strong>Response to GET request: &lt;?xml version="1.0" encoding="UTF-8"?&gt;</strong>
<strong>&lt;hash&gt;</strong>
<strong>  &lt;error&gt;This method requires a POST.&lt;/error&gt;</strong>
<strong>  &lt;request&gt;/account/create&lt;/request&gt;</strong>
<strong>&lt;/hash&gt;</strong>

<strong>Headers from a POST request response: {'status': '200 OK', 'content-</strong>
<strong>length': '21064', 'set-cookie': '_twitter_sess=BAh7CD--</strong>
<strong>d2865d40d1365eeb2175559dc5e6b99f64ea39ff; domain=.twitter.com; </strong>
<strong>path=/; HttpOnly', 'expires': 'Tue, 31 Mar 1981 05:00:00 GMT', </strong>
<strong>'vary': 'Accept-Encoding', 'last-modified': 'Sun, 05 May 2013 </strong>
<strong>15:59:27 GMT', 'pragma': 'no-cache', 'date': 'Sun, 05 May 2013 </strong>
<strong>15:59:27 GMT', 'x-xss-protection': '1; mode=block', 'x-transaction': </strong>
<strong>'a4b425eda23b5312', 'content-encoding': 'gzip', 'strict-transport-</strong>
<strong>security': 'max-age=631138519', 'server': 'tfe', 'x-mid': </strong>
<strong>'f7cde9a3f3d111310427116adc90bf3e8c95e868', 'x-runtime': '0.09969', </strong>
<strong>'etag': '"7af6f92a7f7b4d37a6454caa6094071d"', 'cache-control': 'no-</strong>
<strong>cache, no-store, must-revalidate, pre-check=0, post-check=0', 'x-</strong>
<strong>frame-options': 'SAMEORIGIN', 'content-type': 'text/html; </strong>
<strong>charset=utf-8'}</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec87"/>How it works...</h2></div></div></div><p>This recipe uses a third-party module, <code class="literal">requests</code>. It has convenient wrapper methods, <code class="literal">get()</code> and <code class="literal">post()</code>, that do the URL encoding of data and submit forms properly.</p><p>In this recipe, we created a data payload with a username, password, and e-mail for creating the Twitter account. <a id="id259" class="indexterm"/>When we first submit the form with the <code class="literal">GET</code> method, the Twitter website returns an error saying that the page only supports <code class="literal">POST</code>. After we submit the data with <code class="literal">POST</code>, the page processes it. We can confirm this from the header data.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec46"/>Sending web requests through a proxy server</h1></div></div></div><p>You would like to browse web pages through a proxy. If you have configured your browser with a proxy server<a id="id260" class="indexterm"/> and that works, you can try this recipe. <a id="id261" class="indexterm"/>Otherwise, you can use any of the public proxy servers available on the Internet.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec88"/>Getting ready</h2></div></div></div><p>You need to have access to a proxy server. You can find a free proxy server by searching on Google or on any other search engine. Here, for the sake of demonstration, we have used <code class="literal">165.24.10.8</code>.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec89"/>How to do it...</h2></div></div></div><p>Let us send our HTTP request through a public domain proxy server.</p><p>Listing 4.5 explains proxying web requests across a proxy server as follows:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter - 4
# This program is optimized for Python 2.7.
# It may run on any other version with/without modifications.

import urllib

URL = 'https://www.github.com'
PROXY_ADDRESS = "165.24.10.8:8080" 

if __name__ == '__main__':
  resp = urllib.urlopen(URL, proxies = {"http" : PROXY_ADDRESS})
  print "Proxy server returns response headers: %s " 
%resp.headers</pre></div><p>If you run this script, it will show the following output:</p><div><pre class="programlisting">
<strong>$ python 4_5_proxy_web_request.py </strong>
<strong>Proxy server returns response headers: Server: GitHub.com</strong>
<strong>Date: Sun, 05 May 2013 16:16:04 GMT</strong>
<strong>Content-Type: text/html; charset=utf-8</strong>
<strong>Connection: close</strong>
<strong>Status: 200 OK</strong>
<strong>Cache-Control: private, max-age=0, must-revalidate</strong>
<strong>Strict-Transport-Security: max-age=2592000</strong>
<strong>X-Frame-Options: deny</strong>
<strong>Set-Cookie: logged_in=no; domain=.github.com; path=/; expires=Thu, 05-May-2033 16:16:04 GMT; HttpOnly</strong>
<strong>Set-Cookie: _gh_sess=BAh7...; path=/; expires=Sun, 01-Jan-2023 00:00:00 GMT; secure; HttpOnly</strong>
<strong>X-Runtime: 8</strong>
<strong>ETag: "66fcc37865eb05c19b2d15fbb44cd7a9"</strong>
<strong>Content-Length: 10643</strong>
<strong>Vary: Accept-Encoding</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec90"/>How it works...</h2></div></div></div><p>This is a short recipe where we access the social code-sharing site, <a class="ulink" href="http://www.github.com">www.github.com</a>, with a public proxy server<a id="id262" class="indexterm"/> found on Google search. The <a id="id263" class="indexterm"/>proxy address argument has been passed to the <code class="literal">urlopen()</code> method of <code class="literal">urllib</code>. We print the HTTP header of response to show that the proxy settings work here.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec47"/>Checking whether a web page exists with the HEAD request</h1></div></div></div><p>You would like to check the<a id="id264" class="indexterm"/> existence of a web page without downloading the HTML content. This means that we need to send a <code class="literal">get HEAD</code> request with<a id="id265" class="indexterm"/> a browser client. According to Wikipedia, the <code class="literal">HEAD</code> request asks for the response identical to the one that would correspond to a <code class="literal">GET</code> request, but without the response body. This is useful for retrieving meta-information written in response headers, without having to transport the entire content.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec91"/>How to do it...</h2></div></div></div><p>We would like to send a <code class="literal">HEAD</code> request to <a class="ulink" href="http://www.python.org">www.python.org</a>. This will not download the content of the homepage, rather it checks whether the server returns one of the valid responses, for example, <code class="literal">OK</code>, <code class="literal">FOUND</code>, <code class="literal">MOVED PERMANENTLY</code>, and so on.</p><p>Listing 4.6 explains<a id="id266" class="indexterm"/> checking a web page<a id="id267" class="indexterm"/> with the <code class="literal">HEAD</code> request as follows:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter - 4
# This program is optimized for Python 2.7.
# It may run on any other version with/without modifications.
import argparse
import httplib
import urlparse
import re
import urllib

DEFAULT_URL = 'http://www.python.org'
HTTP_GOOD_CODES =  [httplib.OK, httplib.FOUND, httplib.MOVED_PERMANENTLY]

def get_server_status_code(url):
  """
  Download just the header of a URL and
  return the server's status code.
  """
  host, path = urlparse.urlparse(url)[1:3] 
  try:
    conn = httplib.HTTPConnection(host)
    conn.request('HEAD', path)
    return conn.getresponse().status
    except StandardError:
  return None

if __name__ == '__main__':
  parser = argparse.ArgumentParser(description='Example HEAD 
Request')
  parser.add_argument('--url', action="store", dest="url", 
default=DEFAULT_URL)
  given_args = parser.parse_args() 
  url = given_args.url
  if get_server_status_code(url) in HTTP_GOOD_CODES:
    print "Server: %s status is OK: " %url
  else:
    print "Server: %s status is NOT OK!" %url</pre></div><p>Running this script shows the success or error if the page is found by the <code class="literal">HEAD</code> request as follows:</p><div><pre class="programlisting">
<strong>$ python 4_6_checking_webpage_with_HEAD_request.py </strong>
<strong>Server: http://www.python.org status is OK!</strong>
<strong>$ python 4_6_checking_webpage_with_HEAD_request.py --url=http://www.zytho.org</strong>
<strong>Server: http://www.zytho.org status is NOT OK!</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec92"/>How it works...</h2></div></div></div><p>We used the <code class="literal">HTTPConnection()</code> method<a id="id268" class="indexterm"/> of <code class="literal">httplib</code>, which can make a <code class="literal">HEAD</code> request to a server. We can specify the path if necessary. Here, the <code class="literal">HTTPConnection()</code> method checks the home <a id="id269" class="indexterm"/>page or path of <a class="ulink" href="http://www.python.org">www.python.org</a>. However, if the URL is not correct, it can't find the return<a id="id270" class="indexterm"/> response inside the accepted list of return codes.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec48"/>Spoofing Mozilla Firefox in your client code</h1></div></div></div><p>From your Python code, you<a id="id271" class="indexterm"/> would like to pretend to the web server that you are browsing from Mozilla Firefox.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec93"/>How to do it...</h2></div></div></div><p>You can send the<a id="id272" class="indexterm"/> custom user-agent values in the HTTP request header.</p><p>Listing 4.7 explains spoofing Mozilla Firefox in your client code as follows:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter – 4
# This program is optimized for Python 2.7.
# It may run on any other version with/without modifications.

import urllib2

BROWSER = 'Mozilla/5.0 (Windows NT 5.1; rv:20.0) Gecko/20100101 
Firefox/20.0'
URL = 'http://www.python.org'

def spoof_firefox():
  opener = urllib2.build_opener()
  opener.addheaders = [('User-agent', BROWSER)]
  result = opener.open(URL)
  print "Response headers:"
  for header in  result.headers.headers:
    print "\t",header

if __name__ == '__main__':
  spoof_firefox()</pre></div><p>If you run this script, you will see the following output:</p><div><pre class="programlisting">
<strong>$ python 4_7_spoof_mozilla_firefox_in_client_code.py </strong>
<strong>Response headers:</strong>
<strong>    Date: Sun, 05 May 2013 16:56:36 GMT</strong>
<strong>    Server: Apache/2.2.16 (Debian)</strong>
<strong>    Last-Modified: Sun, 05 May 2013 00:51:40 GMT</strong>
<strong>    ETag: "105800d-5280-4dbedfcb07f00"</strong>
<strong>    Accept-Ranges: bytes</strong>
<strong>    Content-Length: 21120</strong>
<strong>    Vary: Accept-Encoding</strong>
<strong>    Connection: close</strong>
<strong>    Content-Type: text/html</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec94"/>How it works...</h2></div></div></div><p>We used the <code class="literal">build_opener()</code> method<a id="id273" class="indexterm"/> of <code class="literal">urllib2</code> to create<a id="id274" class="indexterm"/> our custom browser whose user-agent string<a id="id275" class="indexterm"/> has been set up as <code class="literal">Mozilla/5.0 (Windows NT 5.1; rv:20.0) Gecko/20100101 Firefox/20.0</code>.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec49"/>Saving bandwidth in web requests with the HTTP compression</h1></div></div></div><p>You would like to give your <a id="id276" class="indexterm"/>web server users<a id="id277" class="indexterm"/> better performance <a id="id278" class="indexterm"/>in downloading web pages. By compressing HTTP data, you can speed up the serving of web contents.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec95"/>How to do it...</h2></div></div></div><p>Let us create a web server that serves contents after compressing it to the <code class="literal">gzip</code> format.</p><p>Listing 4.8 explains the HTTP compression as follows:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter - 4
# This program is optimized for Python 2.7.
# It may run on any other version with/without modifications.
import argparse
import string
import os
import sys
import gzip
import cStringIO
from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer

DEFAULT_HOST = '127.0.0.1'
DEFAULT_PORT = 8800
HTML_CONTENT = """&lt;html&gt;&lt;body&gt;&lt;h1&gt;Compressed Hello  World!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;"""

class RequestHandler(BaseHTTPRequestHandler):
  """ Custom request handler"""
  
  def do_GET(self):
    """ Handler for the GET requests """
    self.send_response(200)
    self.send_header('Content-type','text/html')
    self.send_header('Content-Encoding','gzip')
 
    zbuf = self.compress_buffer(HTML_CONTENT)
    sys.stdout.write("Content-Encoding: gzip\r\n")
    self.send_header('Content-Length',len(zbuf))
    self.end_headers()
    
  # Send the message to browser
    zbuf = self.compress_buffer(HTML_CONTENT)
    sys.stdout.write("Content-Encoding: gzip\r\n")
    sys.stdout.write("Content-Length: %d\r\n" % (len(zbuf)))
    sys.stdout.write("\r\n")
    self.wfile.write(zbuf)
  return
 
  def compress_buffer(self, buf):
    zbuf = cStringIO.StringIO()
    zfile = gzip.GzipFile(mode = 'wb',  fileobj = zbuf, 
compresslevel = 6)
    zfile.write(buf)
    zfile.close()
    return zbuf.getvalue()
  

if __name__ == '__main__':
  parser = argparse.ArgumentParser(description='Simple HTTP Server 
Example')
  parser.add_argument('--port', action="store", dest="port", 
type=int, default=DEFAULT_PORT)
  given_args = parser.parse_args() 
  port = given_args.port
  server_address =  (DEFAULT_HOST, port)
  server = HTTPServer(server_address, RequestHandler)
  server.serve_forever()</pre></div><p>You can run this <a id="id279" class="indexterm"/>script and see<a id="id280" class="indexterm"/> the <code class="literal">Compressed Hello World!</code> text (as a result of the HTTP compression) on your browser screen<a id="id281" class="indexterm"/> when accessing <code class="literal">http://localhost:8800</code> as follows:</p><div><pre class="programlisting">
<strong>$ python 4_8_http_compression.py </strong>
<strong>localhost - - [22/Feb/2014 12:01:26] "GET / HTTP/1.1" 200 -</strong>
<strong>Content-Encoding: gzip</strong>
<strong>Content-Encoding: gzip</strong>
<strong>Content-Length: 71</strong>
<strong>localhost - - [22/Feb/2014 12:01:26] "GET /favicon.ico HTTP/1.1" 200 -</strong>
<strong>Content-Encoding: gzip</strong>
<strong>Content-Encoding: gzip</strong>
<strong>Content-Length: 71</strong>
</pre></div><p>The following screenshot illustrates serving compressed content by a web server:</p><div><img src="img/3463OS_04_03.jpg" alt="How to do it..."/></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec96"/>How it works...</h2></div></div></div><p>We created a web server by<a id="id282" class="indexterm"/> instantiating the <code class="literal">HTTPServer</code> class from the <code class="literal">BaseHTTPServer</code> module. We attached a<a id="id283" class="indexterm"/> custom request handler to this server instance, which compresses every client response using a <code class="literal">compress_buffer()</code> method<a id="id284" class="indexterm"/>. A predefined HTML content has been<a id="id285" class="indexterm"/> supplied to the clients.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec50"/>Writing an HTTP fail-over client with resume and partial downloading</h1></div></div></div><p>You would like to create<a id="id286" class="indexterm"/> a fail-over client that<a id="id287" class="indexterm"/> will resume downloading a file if it fails for any reason in the first instance.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec97"/>How to do it...</h2></div></div></div><p>Let us download the Python 2.7 code from <a class="ulink" href="http://www.python.org">www.python.org</a>. A <code class="literal">resume_download()</code> file will resume any unfinished download of that file.</p><p>Listing 4.9 explains<a id="id288" class="indexterm"/> resume downloading <a id="id289" class="indexterm"/>as follows:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter - 4
# This program is optimized for Python 2.7.# It may run on any other version with/without modifications.

import urllib, os
TARGET_URL = 'http://python.org/ftp/python/2.7.4/'
TARGET_FILE = 'Python-2.7.4.tgz'

class CustomURLOpener(urllib.FancyURLopener):
  """Override FancyURLopener to skip error 206 (when a
    partial file is being sent)
  """
  def http_error_206(self, url, fp, errcode, errmsg, headers, 
data=None):
    pass

  def resume_download():
    file_exists = False
    CustomURLClass = CustomURLOpener()
  if os.path.exists(TARGET_FILE):
    out_file = open(TARGET_FILE,"ab")
    file_exists = os.path.getsize(TARGET_FILE)
    #If the file exists, then only download the unfinished part
    CustomURLClass.addheader("Download range","bytes=%s-" % 
(file_exists))
  else:
    out_file = open(TARGET_FILE,"wb")

  web_page = CustomURLClass.open(TARGET_URL + TARGET_FILE)

  #If the file exists, but we already have the whole thing, don't 
download again
  if int(web_page.headers['Content-Length']) == file_exists:
    loop = 0
    print "File already downloaded!"

  byte_count = 0
  while True:
    data = web_page.read(8192)
    if not data:
      break
    out_file.write(data)
    byte_count = byte_count + len(data)

  web_page.close()
  out_file.close()

  for k,v in web_page.headers.items():
    print k, "=",v
  print "File copied", byte_count, "bytes from", web_page.url

if __name__ == '__main__':
  resume_download()</pre></div><p>Running this<a id="id290" class="indexterm"/> script will result in the following output:</p><div><pre class="programlisting">
<strong>$   python 4_9_http_fail_over_client.py</strong>
<strong>content-length = 14489063</strong>
<strong>content-encoding = x-gzip</strong>
<strong>accept-ranges = bytes</strong>
<strong>connection = close</strong>
<strong>server = Apache/2.2.16 (Debian)</strong>
<strong>last-modified = Sat, 06 Apr 2013 14:16:10 GMT</strong>
<strong>content-range = bytes 0-14489062/14489063</strong>
<strong>etag = "1748016-dd15e7-4d9b1d8685e80"</strong>
<strong>date = Tue, 07 May 2013 12:51:31 GMT</strong>
<strong>content-type = application/x-tar</strong>
<strong>File copied 14489063 bytes from http://python.org/ftp/python/2.7.4/Python-2.7.4.tgz</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec98"/>How it works...</h2></div></div></div><p>In this recipe, we <a id="id291" class="indexterm"/>created a custom URL opener class inheriting from the <code class="literal">FancyURLopener</code> method<a id="id292" class="indexterm"/> of <code class="literal">urllib</code>, but <code class="literal">http_error_206()</code> is overridden where partial content is downloaded. So, our method checks the existence of the target file and if it is not present, it tries to download with the custom URL opener class.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec51"/>Writing a simple HTTPS server code with Python and OpenSSL</h1></div></div></div><p>You need a secure web <a id="id293" class="indexterm"/>server code written in Python.<a id="id294" class="indexterm"/> You already have your SSL keys and certificate files ready with you.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec99"/>Getting ready</h2></div></div></div><p>You need to install the third-party Python module, <code class="literal">pyOpenSSL</code>. This can be grabbed from PyPI (<a class="ulink" href="https://pypi.python.org/pypi/pyOpenSSL">https://pypi.python.org/pypi/pyOpenSSL</a>). Both on Windows and Linux hosts, you may need to install some additional packages, which are documented at <a class="ulink" href="http://pythonhosted.org//pyOpenSSL/">http://pythonhosted.org//pyOpenSSL/</a>.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec100"/>How to do it...</h2></div></div></div><p>After placing a certificate file on the current working folder, we can create a web server that makes use of this certificate to serve encrypted content to the clients.</p><p>Listing 4.10 explains the code for a secure HTTP server as follows:</p><div><pre class="programlisting">#!/usr/bin/env python
# Python Network Programming Cookbook -- Chapter - 4
# This program is optimized for Python 2.7.
# It may run on any other version with/without modifications.
# Requires pyOpenSSL and SSL packages installed

import socket, os
from SocketServer import BaseServer
from BaseHTTPServer import HTTPServer
from SimpleHTTPServer import SimpleHTTPRequestHandler
from OpenSSL import SSL

class SecureHTTPServer(HTTPServer):
  def __init__(self, server_address, HandlerClass):
    BaseServer.__init__(self, server_address, HandlerClass)
    ctx = SSL.Context(SSL.SSLv23_METHOD)
    fpem = 'server.pem' # location of the server private key and 
the server certificate
    ctx.use_privatekey_file (fpem)
    ctx.use_certificate_file(fpem)
    self.socket = SSL.Connection(ctx, 
socket.socket(self.address_family, self.socket_type))
    self.server_bind()
    self.server_activate()

class SecureHTTPRequestHandler(SimpleHTTPRequestHandler):
  def setup(self):
    self.connection = self.request
    self.rfile = socket._fileobject(self.request, "rb", 
self.rbufsize)
    self.wfile = socket._fileobject(self.request, "wb", 
self.wbufsize)


  def run_server(HandlerClass = SecureHTTPRequestHandler,
    ServerClass = SecureHTTPServer):
    server_address = ('', 4443) # port needs to be accessible by 
user
    server = ServerClass(server_address, HandlerClass)
    running_address = server.socket.getsockname()
    print "Serving HTTPS Server on %s:%s ..." 
%(running_address[0], running_address[1])
    server.serve_forever()

if __name__ == '__main__':
  run_server()</pre></div><p>If you run this script, it will result in the following output:</p><div><pre class="programlisting">
<strong>$ python 4_10_https_server.py </strong>
<strong>Serving HTTPS Server on 0.0.0.0:4443 ...</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec101"/>How it works...</h2></div></div></div><p>If you notice the<a id="id295" class="indexterm"/> previous recipes that create the web server,<a id="id296" class="indexterm"/> there is not much difference in terms of the basic procedure. The main difference is in applying the SSL <code class="literal">Context()</code> method<a id="id297" class="indexterm"/> with the <code class="literal">SSLv23_METHOD</code> argument. We have created the SSL socket with the Python OpenSSL third-party module's <code class="literal">Connection()</code> class<a id="id298" class="indexterm"/>. This class takes this context object along with the address family and socket type.</p><p>The server's certificate file is kept in the current directory, and this has been applied with the context object. Finally, the server has been activated with<a id="id299" class="indexterm"/> the <code class="literal">server_activate()</code> method.</p></div></div></div>
</body></html>