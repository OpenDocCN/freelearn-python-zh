- en: Chapter 8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章
- en: 'Project 2.5: Schema and Metadata'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 项目 2.5：模式和元数据
- en: It helps to keep the data schema separate from the various applications that
    share the schema. One way to do this is to have a separate module with class definitions
    that all of the applications in a suite can share. While this is helpful for a
    simple project, it can be awkward when sharing data schema more widely. A Python
    language module is particularly difficult for sharing data outside the Python
    environment.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据模式与共享该模式的各个应用程序保持分离是有帮助的。实现这一目标的一种方法是为套件中的所有应用程序创建一个具有类定义的单独模块。虽然这对简单项目有帮助，但在更广泛地共享数据模式时可能会有些尴尬。Python
    语言模块在共享 Python 环境之外的数据时尤其困难。
- en: This project will define a schema in JSON Schema Notation, first by building
    `pydantic` class definitions, then by extracting the JSON from the class definition.
    This will allow you to publish a formal definition of the data being created.
    The schema can be used by a variety of tools to validate data files and assure
    that the data is suitable for further analytical use.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目将使用 JSON Schema 语法定义一个模式，首先通过构建 `pydantic` 类定义，然后从类定义中提取 JSON。这将允许您发布正在创建的数据的正式定义。该模式可以被各种工具用于验证数据文件，并确保数据适合进一步的分析使用。
- en: The schema is also useful for diagnosing problems with data sources. Validator
    tools like `jsonschema` can provide detailed error reports that can help identify
    changes in source data from bug fixes or software updates.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 模式对于诊断数据源的问题也很有用。像 `jsonschema` 这样的验证工具可以提供详细的错误报告，有助于识别源数据中的更改，这些更改可能是由于错误修复或软件更新。
- en: 'This chapter will cover a number of skills related to data inspection techniques:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖与数据检查技术相关的多个技能：
- en: Using the **Pydantic** module for crisp, complete definitions
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 **Pydantic** 模块进行清晰、完整的定义
- en: Using JSON Schema to create an exportable language-independent definition that
    anyone can use
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 JSON Schema 创建一个可导出且语言无关的定义，任何人都可以使用
- en: Creating test scenarios to use the formal schema definition
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建用于使用正式模式定义的测试场景
- en: We’ll start by looking at the reasons why a formal schema is helpful.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先探讨正式模式为什么有帮助的原因。
- en: 8.1 Description
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 描述
- en: Data validation is a common requirement when moving data between applications.
    It is extremely helpful to have a clear definition of what constitutes valid data.
    It helps even more when the definition exists outside a particular programming
    language or platform.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序之间移动数据时，数据验证是一个常见的要求。拥有一个明确的数据有效性的定义非常有帮助。当这个定义存在于特定的编程语言或平台之外时，帮助就更大了。
- en: We can use the JSON Schema ([https://json-schema.org](https://json-schema.org))
    to define a schema that applies to the intermediate documents created by the acquisition
    process. Using JSON Schema enables the confident and reliable use of the JSON
    data format.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 JSON Schema ([https://json-schema.org](https://json-schema.org)) 来定义一个适用于由获取过程创建的中间文档的模式。使用
    JSON Schema 可以使 JSON 数据格式的使用更加自信和可靠。
- en: The JSON Schema definition can be shared and reused within separate Python projects
    and with non-Python environments, as well. It allows us to build data quality
    checks into the acquisition pipeline to positively affirm the data really fit
    the requirements for analysis and processing.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: JSON Schema 定义可以在不同的 Python 项目和非 Python 环境中共享和重用。它允许我们将数据质量检查集成到获取管道中，以积极确认数据确实符合分析和处理的要求。
- en: Additional metadata provided with a schema often includes the provenance of
    the data and details on how attribute values are derived. This isn’t a formal
    part of a JSON Schema, but we can add some details to the JSON Schema document
    that includes provenance and processing descriptions.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模式提供的附加元数据通常包括数据的来源和属性值是如何导出的详细信息。这不是 JSON 模式的一部分，但我们可以向 JSON 模式文档中添加一些包含来源和处理描述的详细信息。
- en: 'The subsequent data cleaning projects should validate the input documents using
    a source schema. Starting with [*Chapter** 9*](ch013.xhtml#x1-2080009), [*Project
    3.1: Data Cleaning Base* *Application*](ch013.xhtml#x1-2080009), the applications
    should validate their output using the target analytic schema. It can seem silly
    to have an application both create sample records and also validate those records
    against a schema. What’s important is the schema will be shared, and evolve with
    the needs of consumers of the data. The data acquisition and cleaning operations,
    on the other hand, evolve with the data sources. It is all too common for an ad
    hoc solution to a data problem to seem good but create invalid data.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随后的数据清洗项目应使用源架构验证输入文档。从第9章[*项目3.1：数据清洗基础应用*](ch013.xhtml#x1-2080009)开始，应用应使用目标分析架构验证其输出。一个应用既创建样本记录又验证这些记录是否符合架构可能看起来有些荒谬。重要的是架构将是共享的，并随着数据消费者的需求而发展。另一方面，数据采集和清洗操作随着数据源的发展而发展。一个临时的数据问题解决方案看起来很好，但可能创建无效数据的情况非常普遍。
- en: It rarely creates new problems to validate inputs as well as outputs against
    a visible, agreed-upon schema. There will be some overhead to the validation operation,
    but much of the processing cost is dominated by the time to perform input and
    output, not data validation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 验证输入和输出是否符合可见的、达成一致的架构很少会创建新的问题。验证操作会有一些开销，但大部分处理成本是由输入和输出的时间决定的，而不是数据验证。
- en: 'Looking forward to [*Chapter** 12*](ch016.xhtml#x1-27600012), [*Project 3.8:
    Integrated Data Acquisition Web* *Service*](ch016.xhtml#x1-27600012), we’ll see
    additional uses for a formally-defined schema. We’ll also uncover a small problem
    with using JSON Schema to describe ND JSON documents. For now, we’ll focus on
    the need to use JSON Schema to describe data.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 展望第12章[*项目3.8：集成数据采集Web服务*](ch016.xhtml#x1-27600012)，我们将看到正式定义的架构的更多用途。我们还将揭示使用JSON
    Schema描述ND JSON文档时存在的一个小问题。目前，我们将专注于使用JSON Schema描述数据的需求。
- en: We’ll start by adding some modules to make it easier to create JSON Schema documents.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先添加一些模块，以便更容易创建JSON Schema文档。
- en: 8.2 Approach
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 方法
- en: First, we’ll need some additional modules. The `jsonschema` module defines a
    validator that can be used to confirm a document matches the defined schema.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一些额外的模块。`jsonschema`模块定义了一个验证器，可以用来确认文档是否符合定义的架构。
- en: Additionally, the **Pydantic** module provides a way to create class definitions
    that can emit JSON Schema definitions, saving us from having to create the schema
    manually. In most cases, manual schema creation is not terribly difficult. For
    some cases, though, the schema and the validation rules might be challenging to
    write directly, and having Python class definitions available can simplify the
    process.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，**Pydantic**模块提供了一种创建可以发出JSON Schema定义的类定义的方法，这样我们就不必手动创建架构。在大多数情况下，手动创建架构并不特别困难。然而，在某些情况下，架构和验证规则可能难以直接编写，并且有Python类定义可用可以简化这个过程。
- en: This needs to be added to the `requirements-dev.txt` file so other developers
    know to install it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要添加到`requirements-dev.txt`文件中，以便其他开发者知道安装它。
- en: 'When using **conda** to manage virtual environments, the command might look
    like the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用**conda**管理虚拟环境时，命令可能如下所示：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When using other tools to manage virtual environments, the command might look
    like the following:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用其他工具管理虚拟环境时，命令可能如下所示：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The JSON Schema package requires some supplemental type stubs. These are used
    by the **mypy** tool to confirm the application is using types consistently. Use
    the following command to add stubs:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: JSON Schema包需要一些补充的类型存根。这些由**mypy**工具使用，以确认应用程序正在一致地使用类型。使用以下命令添加存根：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Additionally, the `pydantic` package includes a **mypy** plug-in that will extend
    the type-checking capabilities of **mypy**. This will spot more nuanced potential
    problems with classes defined using `pydantic`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`pydantic`包包括一个**mypy**插件，它将扩展**mypy**的类型检查功能。这将发现使用`pydantic`定义的类中更多细微的潜在问题。
- en: 'To enable the plugin, add `pydantic.mypy` to the list of plugins in the **mypy**
    configuration file, `mypy.ini`. The `mypy.ini` file should look like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用插件，将`pydantic.mypy`添加到**mypy**配置文件`mypy.ini`中插件列表。`mypy.ini`文件应如下所示：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: (This file goes in the root of the project directory.)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: （此文件应放在项目目录的根目录下。）
- en: This plugin is part of the **pydantic** download, and is compatible with **mypy**
    versions starting with 0.910.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此插件是 **pydantic** 下载的一部分，并且与从 0.910 版本开始的 **mypy** 兼容。
- en: With these two packages, we can define classes with details that can be used
    to create JSON Schema files. Once we have a JSON Schema file, we can use the schema
    definition to confirm that sample data is valid.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两个包，我们可以定义具有详细信息的类，这些信息可用于创建 JSON Schema 文件。一旦我们有了 JSON Schema 文件，我们就可以使用该模式定义来确认样本数据的有效性。
- en: For more information on **Pydantic**, see [https://docs.pydantic.dev](https://docs.pydantic.dev).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 **Pydantic** 的更多信息，请参阅 [https://docs.pydantic.dev](https://docs.pydantic.dev)。
- en: The core concept is to use **Pydantic** to define dataclasses with detailed
    field definitions. These definitions can be used for data validation in Python.
    The definition can also be used to emit a JSON Schema document to share with other
    projects.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 核心概念是使用 **Pydantic** 来定义具有详细字段定义的数据类。这些定义可以用于 Python 中的数据验证。定义也可以用来生成一个 JSON
    Schema 文档，以便与其他项目共享。
- en: 'The schema definitions are also useful for defining an OpenAPI specification.
    In [*Chapter** 12*](ch016.xhtml#x1-27600012), [*Project 3.8: Integrated Data Acquisition
    Web Service*](ch016.xhtml#x1-27600012), we’ll turn to creating a web service that
    provides data. The OpenAPI specification for this service will include the schema
    definitions from this project.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 模式定义对于定义 OpenAPI 规范也很有用。在 [*第 12 章*](ch016.xhtml#x1-27600012)，[*项目 3.8：集成数据采集网络服务*](ch016.xhtml#x1-27600012)
    中，我们将转向创建提供数据的网络服务。此服务的 OpenAPI 规范将包括来自此项目的模式定义。
- en: The use of **Pydantic** isn’t required. It is, however, very convenient for
    creating a schema that can be described via JSON Schema. It saves a great deal
    of fussing with details in JSON syntax.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 **Pydantic** 不是必需的。然而，它对于创建可以通过 JSON Schema 描述的模式来说非常方便。它节省了大量与 JSON 语法细节的纠缠。
- en: We’ll start with using **Pydantic** to create a useful data model module. This
    will extend the data models built for projects in earlier chapters.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开始使用 **Pydantic** 创建一个有用的数据模型模块。这将扩展早期章节中为项目构建的数据模型。
- en: 8.2.1 Define Pydantic classes and emit the JSON Schema
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 定义 Pydantic 类并生成 JSON Schema
- en: We’ll start with two profound modifications to the data model definitions used
    in earlier chapters. One change is to switch from the `dataclasses` module to
    the `pydantic.dataclasses` module. Doing this creates the need to explicitly use
    `dataclasses.field` for individual field definitions. This is generally a small
    change to an `import` statement to use `from`` pydantic.dataclasses`` import`` dataclass`.
    The dataclasses `field()` function will need some changes, also, to add additional
    details used by **pydantic**. The changes should be completely transparent to
    the existing application; all tests will pass after these changes.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从对早期章节中使用的数据模型定义进行两个深刻的修改开始。一个变化是将从 `dataclasses` 模块切换到 `pydantic.dataclasses`
    模块。这样做需要显式使用 `dataclasses.field` 进行单个字段定义。这通常是对 `import` 语句的一个小改动，使用 `from pydantic.dataclasses
    import dataclass`。数据类的 `field()` 函数也需要一些更改，以添加 **pydantic** 所使用的额外细节。这些更改对现有应用程序应该是完全透明的；所有测试在更改后都将通过。
- en: The second change is to add some important metadata to the classes. Where the
    `dataclasses.field(...)` definition is used, the `metadata={}` attribute can be
    added to include a dictionary with JSON Schema attributes like the description,
    title, examples, valid ranges of values, etc. For other fields, the `pydantic.Field()`
    function must be used to provide a title, description, and other constraints on
    the field. This will generate a great deal of metadata for us.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个变化是为类添加一些重要的元数据。在 `dataclasses.field(...)` 定义中使用的地方，可以添加 `metadata={}` 属性，以包含一个包含
    JSON Schema 属性的字典，如描述、标题、示例、值的有效范围等。对于其他字段，必须使用 `pydantic.Field()` 函数来提供标题、描述和其他字段约束。这将为我们生成大量的元数据。
- en: See [https://docs.pydantic.dev/usage/schema/#field-customization](https://docs.pydantic.dev/usage/schema/#field-customization)
    for the wide variety of field definition details available.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有关可用的各种字段定义细节，请参阅 [https://docs.pydantic.dev/usage/schema/#field-customization](https://docs.pydantic.dev/usage/schema/#field-customization)。
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We’ve provided several additional details in this model definition module.
    The details include:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个模型定义模块中提供了几个额外的细节。这些细节包括：
- en: Docstrings on each class. These will become descriptions in the JSON Schema.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个类的文档字符串。这些将成为 JSON Schema 中的描述。
- en: Fields for each attribute. These, too, become descriptions in the JSON Schema.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个属性的字段。这些字段也成为了 JSON Schema 中的描述。
- en: For the `x` and `y` attributes of the `SeriesSample` class definition, we added
    a `ge` value. This is a range specification, requiring the values to be greater
    than or equal to zero.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`SeriesSample`类定义的`x`和`y`属性，我们添加了一个`ge`值。这是一个范围规范，要求值大于或等于零。
- en: 'We’ve also made extremely profound changes to the model: we’ve moved from the
    source data description — which was a number of `str` values — to the target data
    description, using `float` values.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还对模型进行了极其深刻的变化：我们从源数据描述——即多个`str`值——转变为目标数据描述，使用`float`值。
- en: 'What’s central here is that we have two variations on each model:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里的核心是，我们对每个模型有两种变体：
- en: '**Acquisition**: This is the data as we find it ”in the wild.” In the examples
    in this book, some variations of source data are text-only, forcing us to use
    `str` as a common type. Some data sources will have data in more useful Python
    objects, permitting types other than `str`.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**获取**：这是我们在“野外”找到的数据。在本书的例子中，一些源数据变体是纯文本，迫使我们使用`str`作为通用类型。一些数据源将包含更有用的Python对象，允许使用除`str`之外的其他类型。'
- en: '**Analysis**: This is the data used for further analysis. These data sets can
    use native Python objects. For the most part, we’ll focus on objects that are
    easily serialized to JSON. The exception will be date-time values, which don’t
    readily serialize to JSON, but require some additional conversion from a standard
    ISO text format.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析**：这是用于进一步分析的数据。这些数据集可以使用原生Python对象。大部分时间，我们将关注那些容易序列化为JSON的对象。例外的是日期时间值，它们不能直接序列化为JSON，但需要从标准的ISO文本格式进行一些额外的转换。'
- en: The class examples shown above do not *replace* the `model` module in our applications.
    They form a second model of more useful data. The recommended approach is to change
    the initial acquisition model’s module name from `model` to `acquisition_model`
    (or perhaps the shorter `source_model`). This property describes the model with
    mostly string values as the source. This second model is the `analysis_model`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的类示例并不*替换*我们应用程序中的`model`模块。它们形成了一个更有用数据的第二个模型。建议的方法是将初始获取模型的模块名称从`model`更改为`acquisition_model`（或者可能是更短的`source_model`）。这个属性主要用字符串值描述模型。这个第二个模型是`analysis_model`。
- en: The results of the initial investigation into the data can provide narrower
    and more strict constraints for the analysis model class definitions. See [*Chapter** 7*](ch011.xhtml#x1-1610007),
    [*Data Inspection Features*](ch011.xhtml#x1-1610007) for a number of inspections
    that can help to reveal expected minima and maxima for attribute values.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据的初步调查结果可以为分析模型类定义提供更窄和更严格的约束。参见[*第7章*](ch011.xhtml#x1-1610007)，[*数据检查功能*](ch011.xhtml#x1-1610007)中的一些检查，这些检查有助于揭示属性值的预期最小值和最大值。
- en: The **Pydantic** library comes with a large number of customized data types
    that can be used to describe data values. See [https://docs.pydantic.dev/usage/types/](https://docs.pydantic.dev/usage/types/)
    for documentation. Using the `pydantic` types can be simpler than defining an
    attribute as a string, and trying to create a regular expression for valid values.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pydantic**库附带了许多自定义数据类型，可以用来描述数据值。请参阅[https://docs.pydantic.dev/usage/types/](https://docs.pydantic.dev/usage/types/)以获取文档。使用`pydantic`类型可能比将属性定义为字符串并尝试创建有效值的正则表达式要简单。'
- en: Note that validation of source values isn’t central to **Pydantic**. When Python
    objects are provided, it’s entirely possible for the **Pydantic** module to perform
    a successful data conversion where we might have hoped for an exception to be
    raised. A concrete example is providing a Python `float` object to a field that
    requires an `int` value. The `float` object will be converted; an exception will
    *not* be raised. If this kind of very strict validation of Python objects is required,
    some additional programming is needed.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，源值验证不是**Pydantic**的核心。当提供Python对象时，**Pydantic**模块完全有可能执行成功的数据转换，而我们在希望抛出异常的地方可能没有。一个具体的例子是将Python
    `float`对象提供给需要`int`值的字段。`float`对象将被转换；不会抛出异常。如果需要这种非常严格的Python对象验证，则需要一些额外的编程。
- en: In the next section, we’ll create a JSON Schema definition of our model. We
    can either export the definition from the class definition, or we can craft the
    JSON manually.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将创建我们模型的JSON Schema定义。我们可以从类定义中导出定义，或者我们可以手动构建JSON。
- en: 8.2.2 Define expected data domains in JSON Schema notation
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 使用JSON Schema表示法定义预期数据域
- en: Once we have the class definition, we can then export a schema that describes
    the class. Note that the **Pydantic** dataclass is a wrapper around an underlying
    `pydantic.BaseModel` subclass definition.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了类定义，我们就可以导出一个描述类的模式。请注意，**Pydantic**数据类是一个围绕底层`pydantic.BaseModel`子类定义的包装器。
- en: 'We can create a JSON Schema document by adding the following lines to the bottom
    of the module:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在模块底部添加以下行来创建一个JSON Schema文档：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: These lines turn the data definition module into a script that writes the JSON
    Schema definition to the standard output file.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这些行将数据定义模块转换为一个脚本，该脚本将JSON Schema定义写入标准输出文件。
- en: The `schema_of()` function will extract a schema from the dataclass created
    in the previous section. (See [*Define Pydantic classes and emit the JSON Schema*](#x1-1980001).)
    The underlying `pydantic.BaseModel` subclass also has a `schema()` method that
    will transform the class definition into a richly-detailed JSON Schema definition.
    When working with **pydantic** dataclasses, the `pydantic.BaseModel` isn’t directly
    available, and the `schema_of()` function must be used.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`schema_of()`函数将从上一节创建的数据类中提取一个模式。（参见[*定义Pydantic类并生成JSON Schema*](#x1-1980001)。）底层的`pydantic.BaseModel`子类还有一个`schema()`方法，它将类定义转换为一个详细丰富的JSON
    Schema定义。当与**pydantic**数据类一起工作时，`pydantic.BaseModel`不可直接使用，必须使用`schema_of()`函数。'
- en: When executing the terminal command `python`` src/analysis_model.py`, the schema
    is displayed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行终端命令`python src/analysis_model.py`时，将显示模式。
- en: 'The output begins as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 输出开始如下：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can see that the title matches the class name. The description matches the
    docstring. The collection of properties matches the attributes’ names in the class.
    Each of the property definitions provides the type information from the dataclass.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到标题与类名匹配。描述与文档字符串匹配。属性集合与类中的属性名称匹配。每个属性定义都提供了数据类中的类型信息。
- en: The `$ref` item is a reference to another definition provided later in the JSON
    Schema. This use of references makes sure the other class definition is separately
    visible, and is available to support this schema definition.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ref`项是对JSON Schema中稍后提供的另一个定义的引用。这种引用的使用确保其他类定义是单独可见的，并且可用于支持此模式定义。'
- en: A very complex model may have a number of definitions that are shared in multiple
    places. This `$ref` technique normalizes the structure so only a single definition
    is provided. Multiple references to the single definition assure proper reuse
    of the class definition.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常复杂的模型可能有多个定义，这些定义在多个地方共享。这种`$ref`技术使结构标准化，因此只提供一个定义。对单个定义的多次引用确保了类定义的正确重用。
- en: The JSON structure may look unusual at first glance, but it’s not frighteningly
    complex. Reviewing [https://json-schema.org](https://json-schema.org) will provide
    information on how best to create JSON Schema definitions without using the **Pydantic**
    module.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: JSON结构乍一看可能看起来不寻常，但它并不令人畏惧地复杂。查看[https://json-schema.org](https://json-schema.org)将提供有关如何在不使用**Pydantic**模块的情况下最佳创建JSON
    Schema定义的信息。
- en: 8.2.3 Use JSON Schema to validate intermediate files
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.3 使用JSON Schema验证中间文件
- en: Once we have a JSON Schema definition, we can provide it to other stakeholders
    to be sure they understand the data required or the data provided. We can also
    use the JSON Schema to create a validator that can examine a JSON document and
    determine if the document really does match the schema.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了JSON Schema定义，我们可以将其提供给其他利益相关者，以确保他们理解所需或提供的数据。我们还可以使用JSON Schema创建一个验证器，该验证器可以检查JSON文档，并确定该文档是否真的符合模式。
- en: We can do this with a `pydantic` class definition. There’s a `parse_obj()` method
    that will examine a dictionary to create an instance of the given `pydantic` class
    could be built. The `parse_raw()` method can parse a string or bytes object to
    create an instance of the given class.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`pydantic`类定义来做这件事。有一个`parse_obj()`方法，它将检查字典以创建给定`pydantic`类的实例。`parse_raw()`方法可以将字符串或字节对象解析为给定类的实例。
- en: We can also do this with the `jsonschema` module. We’ll look at this as an alternative
    to `pydantic` to show how sharing the JSON Schema allows other applications to
    work with a formal definition of the analysis model.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用`jsonschema`模块来做这件事。我们将将其视为`pydantic`的替代方案，以展示共享JSON Schema如何允许其他应用程序与分析模型的正式定义一起工作。
- en: 'First, we need to create a validator from the schema. We can dump the JSON
    into a file and then load the JSON back from the file. We can also save a step
    by creating a validator directly from the **Pydantic**-created JSON Schema. Here’s
    the short version:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要从模式中创建一个验证器。我们可以将 JSON 数据导出到一个文件中，然后从文件中重新加载 JSON 数据。我们还可以通过直接从由 **Pydantic**
    创建的 JSON 模式创建验证器来省略一个步骤。以下是简短版本：
- en: '[PRE7]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This creates a validator using the latest version of JSON Schema, the 2020 draft.
    (The project is on track to become a standard, and has gone through a number of
    drafts as it matures.)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使用最新的 JSON 模式版本，即 2020 草案。 (该项目正在成为标准，并且随着其成熟已经通过了多个草案。)
- en: 'Here’s how we might write a function to scan a file to be sure the NDJSON documents
    all properly fit the defined schema:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们可能编写一个函数来扫描文件以确保 NDJSON 文档都正确符合定义的模式的示例：
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This function will read each NDJSON document from the given source file. It
    will use the given validator to see if the document has problems or is otherwise
    valid. For faulty documents, it will print the document and the entire list of
    validation errors.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将读取给定源文件中的每个 NDJSON 文档。它将使用给定的验证器来检查文档是否存在问题或是否有效。对于有问题的文档，它将打印文档和整个验证错误列表。
- en: This kind of function can be embedded into a separate script to check files.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的函数可以嵌入到单独的脚本中以检查文件。
- en: We can, similarly, create the schema for the source model, and use JSON Schema
    (or **Pydantic**) to validate source files before attempting to process them.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以为源模型创建模式，并使用 JSON 模式（或 **Pydantic**）在尝试处理源文件之前对其进行验证。
- en: 'We’ll turn to the more complete validation and cleaning solution in [*Chapter** 9*](ch013.xhtml#x1-2080009),
    [*Project 3.1: Data Cleaning Base Application*](ch013.xhtml#x1-2080009). This
    project is one of the foundational components of the more complete solution.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将转向更完整的验证和清理解决方案，见 [*第 9 章*](ch013.xhtml#x1-2080009)，[*项目 3.1：数据清理基础应用*](ch013.xhtml#x1-2080009)。该项目是更完整解决方案的基础组件之一。
- en: We’ll look at the deliverables for this project in the next section.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中查看这个项目的交付成果。
- en: 8.3 Deliverables
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 交付成果
- en: 'This project has the following deliverables:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目有以下交付成果：
- en: A `requirements.txt` file that identifies the tools used, usually `pydantic==1.10.2`
    and `jsonschema==4.16.0`.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 `requirements.txt` 文件，用于标识使用的工具，通常是 `pydantic==1.10.2` 和 `jsonschema==4.16.0`。
- en: Documentation in the `docs` folder.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docs` 文件夹中的文档。'
- en: The JSON-format files with the source and analysis schemas. A separate `schema`
    directory is the suggested location for these files.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含源和分析模式的 JSON 格式文件。建议将这些文件放在单独的 `schema` 目录中。
- en: An acceptance test for the schemas.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式的接受测试。
- en: We’ll look at the schema acceptance test in some detail. Then we’ll look at
    using schema to extend other acceptance tests.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将详细查看模式接受测试。然后我们将查看如何使用模式扩展其他接受测试。
- en: 8.3.1 Schema acceptance tests
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.1 模式接受测试
- en: To know if the schema is useful, it is essential to have acceptance test cases.
    As new sources of data are integrated into an application, and old sources of
    data mutate through ordinary bug fixes and upgrades, files will change. The new
    files will often cause problems, and the root cause of the problem will be the
    unexpected file format change.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要知道模式是否有用，必须要有接受测试用例。随着新的数据源集成到应用程序中，以及旧的数据源通过常规的错误修复和升级而发生变化，文件将发生变化。新文件通常会引发问题，问题的根本原因将是意外的文件格式变化。
- en: Once a file format change is identified, the smallest relevant example needs
    to be transformed into an acceptance test. The test will — of course — fail. Now,
    the data acquisition pipeline can be fixed knowing there is a precise definition
    of done.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定文件格式发生变化，最小的相关示例需要转换为接受测试。当然，测试将失败。现在，数据获取管道可以修复，因为有一个精确的完成定义。
- en: To start with, the acceptance test suite should have an example file that’s
    valid and an example file that’s invalid.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，接受测试套件应该有一个有效的示例文件和一个无效的示例文件。
- en: 'As we noted in [*Chapter** 4*](ch008.xhtml#x1-780004), [*Data Acquisition Features:
    Web APIs and Scraping*](ch008.xhtml#x1-780004), we can provide a large block of
    text as part of a Gherkin scenario. We can consider something like the following
    scenario:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 [*第 4 章*](ch008.xhtml#x1-780004)，[*数据获取功能：Web API 和抓取*](ch008.xhtml#x1-780004)
    中所提到的，我们可以将一大块文本作为 Gherkin 场景的一部分提供。我们可以考虑以下场景：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This allows us to provide the contents for an NDJSON file. The HTML extract
    command is quite long. The content is available as the `context.text` parameter
    of the step definition function. See [*Acceptance tests*](ch008.xhtml#x1-1050004)
    for more examples of how to write the step definitions to create a temporary file
    to be used for this test case.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够提供 NDJSON 文件的内容。HTML 提取命令相当长。内容作为步骤定义函数的 `context.text` 参数提供。参见[*验收测试*](ch008.xhtml#x1-1050004)以获取更多如何编写步骤定义以创建用于此测试用例的临时文件的示例。
- en: Scenarios for faulty records are also essential, of course. It’s important to
    be sure the schema definition will reject invalid data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，故障记录的场景也是必不可少的。确保模式定义能够拒绝无效数据是很重要的。
- en: 8.3.2 Extended acceptance testing
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.2 扩展验收测试
- en: In *Chapters 3*, *4*, and *5*, we wrote acceptance tests that — generally —
    looked at log summaries of the application’s activity to be sure it properly acquired
    source data. We did not write acceptance tests that specifically looked at the
    data.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 3 章、第 4 章和第 5 章中，我们编写了验收测试，通常查看应用程序活动的日志摘要，以确保它正确获取了源数据。我们没有编写专门查看数据的验收测试。
- en: Testing with a schema definition permits a complete analysis of each and every
    field and record in a file. The completeness of this check is of tremendous value.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模式定义进行测试允许对文件中的每个字段和记录进行完整分析。这种检查的完整性具有极大的价值。
- en: 'This means that we can add some additional Then steps to existing scenarios.
    They might look like the following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以为现有场景添加一些额外的“然后”步骤。它们可能看起来像以下这样：
- en: '[PRE10]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The additional ”Then the output directory files are valid...” line requires
    a step definition that must do the following things:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的“然后输出目录文件有效...”行需要一个步骤定义，该定义必须执行以下操作：
- en: Load the named JSON Schema file and build a `Validator`.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载命名的 JSON 模式文件并构建一个 `Validator`。
- en: Use the `Validator` object to examine each line of the ND JSON file to be sure
    they’re valid.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `Validator` 对象检查 ND JSON 文件的每一行，以确保它们是有效的。
- en: This use of the schema as part of the acceptance test suite will parallel the
    way data suppliers and data consumers can use the schema to assure the data files
    are valid.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 将模式作为验收测试套件的一部分使用，将并行于数据供应商和数据消费者如何使用模式来确保数据文件有效的方式。
- en: It’s important to note the schema definition given earlier in this chapter (in
    [*Define Pydantic classes and emit the JSON Schema*](#x1-1980001)) was the output
    from a future project’s data cleaning step. The schema shown in that example is
    not the output from the previous data acquisition applications.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，本章前面给出的模式定义（在[*定义 Pydantic 类并生成 JSON 模式*](#x1-1980001)中）是从未来项目的数据清理步骤中输出的。该示例中显示的模式不是之前数据获取应用的输出。
- en: 'To validate the output from data acquisition, you will need to use the model
    for the various data acquisition projects in *Chapters 3*, *4*, and *5*. This
    will be **very** similar to the example shown earlier in this chapter. While similar,
    it will differ in a profound way: it will use `str` instead of `float` for the
    series sample attribute values.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证数据获取的输出，您需要使用第 3 章、第 4 章和第 5 章中各种数据获取项目的模型。这将与本章前面显示的示例非常相似。虽然相似，但它将在本质上有所不同：它将使用
    `str` 而不是 `float` 作为序列样本属性值。
- en: 8.4 Summary
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 概述
- en: 'This chapter’s projects have shown examples of the following features of a
    data acquisition application:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的项目展示了数据获取应用以下功能的一些示例：
- en: Using the Pydantic module for crisp, complete definitions
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pydantic 模块进行清晰、完整的定义
- en: Using JSON Schema to create an exportable language-independent definition that
    anyone can use
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 JSON 模式创建一个可导出且语言无关的定义，任何人都可以使用
- en: Creating test scenarios to use the formal schema definition
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建测试场景以使用正式的模式定义
- en: Having formalized schema definitions permits recording additional details about
    the data processing applications and the transformations applied to the data.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通过正式化模式定义，可以记录有关数据处理应用程序以及应用于数据的转换的更多详细信息。
- en: The docstrings for the class definitions become the descriptions in the schema.
    This permits writing details on data provenance and transformation that are exposed
    to all users of the data.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 类定义的文档字符串成为模式中的描述。这允许记录有关数据来源和转换的详细信息，这些信息对所有数据用户都是可见的。
- en: The JSON Schema standard permits recording examples of values. The **Pydantic**
    package has ways to include this metadata in field definitions, and class configuration
    objects. This can be helpful when explaining odd or unusual data encodings.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: JSON Schema标准允许记录值示例。**Pydantic**包有方法在字段定义和类配置对象中包含此元数据，这有助于解释奇怪或不寻常的数据编码。
- en: Further, for text fields, JSONSchema permits including a format attribute that
    can provide a regular expression used to validate the text. The **Pydantic** package
    has first-class support for this additional validation of text fields.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于文本字段，JSONSchema允许包含一个格式属性，该属性可以提供用于验证文本的正则表达式。**Pydantic**包对文本字段的这种额外验证提供了第一级支持。
- en: 'We’ll return to the details of data validation in [*Chapter** 9*](ch013.xhtml#x1-2080009),
    [*Project 3.1: Data* *Cleaning Base Application*](ch013.xhtml#x1-2080009) and
    [*Chapter** 10*](ch014.xhtml#x1-22900010), [*Data Cleaning Features*](ch014.xhtml#x1-22900010).
    In those chapters, we’ll delve more deeply into the various **Pydantic** validation
    features.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第9章*](ch013.xhtml#x1-2080009)、[*项目3.1：数据清洗基础应用*](ch013.xhtml#x1-2080009)和[*第10章*](ch014.xhtml#x1-22900010)、[*数据清洗功能*](ch014.xhtml#x1-22900010)的细节中返回数据验证的细节。在这些章节中，我们将更深入地探讨**Pydantic**的各种验证功能。
- en: 8.5 Extras
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 额外内容
- en: Here are some ideas for you to add to this project.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些想法供您添加到这个项目中。
- en: 8.5.1 Revise all previous chapter models to use Pydantic
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5.1 修订所有之前的章节模型以使用Pydantic
- en: The previous chapters used `dataclass` definitions from the `dataclasses` module.
    These can be shifted to use the `pydantic.dataclasses` module. This should have
    minimal impact on the previous projects.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 前几章使用了`dataclasses`模块中的`dataclass`定义。这些可以转换为使用`pydantic.dataclasses`模块。这应该对之前的项目影响最小。
- en: We can also shift all of the previous acceptance test suites to use a formal
    schema definition for the source data.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将所有之前的验收测试套件转换为使用正式的源数据模式定义。
- en: 8.5.2 Use the ORM layer
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5.2 使用ORM层
- en: For SQL extracts, an ORM can be helpful. The `pydantic` module lets an application
    create Python objects from intermediate ORM objects. This two-layer processing
    seems complex but permits detailed validation in the **Pydantic** objects that
    aren’t handled by the database.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SQL提取，ORM非常有用。`pydantic`模块允许应用程序从中间ORM对象创建Python对象。这种双层处理似乎很复杂，但允许在**Pydantic**对象中进行详细的验证，这些对象不受数据库处理。
- en: For example, a database may have a numeric column without any range provided.
    A **Pydantic** class definition can provide a field definition with `ge` and `le`
    attributes to define a range. Further, **Pydantic** permits the definition of
    a unique data type with unique validation rules that can be applied to database
    extract values.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个数据库可能有一个没有提供任何范围的数值列。**Pydantic**类定义可以提供一个带有`ge`和`le`属性的字段定义来定义一个范围。此外，**Pydantic**允许定义具有独特验证规则的唯一数据类型，这些规则可以应用于数据库提取值。
- en: First, see [https://docs.sqlalchemy.org/en/20/orm/](https://docs.sqlalchemy.org/en/20/orm/)
    for information on the SQLAlchemy ORM layer. This provides a class definition
    from which SQL statements like `CREATE`` TABLE`, `SELECT`, and `INSERT` can be
    derived.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，查看[https://docs.sqlalchemy.org/en/20/orm/](https://docs.sqlalchemy.org/en/20/orm/)以获取关于SQLAlchemy
    ORM层的详细信息。这提供了一个类定义，从中可以派生出SQL语句，如`CREATE TABLE`、`SELECT`和`INSERT`。
- en: Then, see the [https://docs.pydantic.dev/usage/models/#orm-mode-aka-arbitrary-class-instances](https://docs.pydantic.dev/usage/models/#orm-mode-aka-arbitrary-class-instances)
    ”ORM Mode (aka Arbitrary Class Instances)” section of the **Pydantic** documentation
    for ways to map a more useful class to the intermediate ORM class.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，查看**Pydantic**文档中的[https://docs.pydantic.dev/usage/models/#orm-mode-aka-arbitrary-class-instances](https://docs.pydantic.dev/usage/models/#orm-mode-aka-arbitrary-class-instances)
    “ORM模式（也称为任意类实例）”部分，了解如何将更有用的类映射到中间ORM类。
- en: For legacy data in a quirky, poorly-designed database, this can become a problem.
    For databases designed from the beginning with an ORM layer, on the other hand,
    this can be a simplification to the SQL.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个古怪、设计不佳的数据库中的旧数据，这可能会成为一个问题。另一方面，对于从一开始就设计有ORM层的数据库，这可以简化SQL。
