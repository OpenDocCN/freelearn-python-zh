- en: '15'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Scientific Python and Plotting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Python programming language is quite suited for scientific work. This is
    due to it being really easy to program for while being powerful enough to do almost
    anything you need. This combination has spawned a whole bunch of (very large)
    Python projects, such as `numpy`, `scipy`, `matplotlib`, `pandas`, and so on,
    over the years. While these libraries are all large enough to warrant entire books
    for themselves, we can offer a little insight into where and when they can be
    useful so you have an idea of where to start.
  prefs: []
  type: TYPE_NORMAL
- en: 'The major topics and libraries covered in this chapter are split into three
    sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Arrays and matrices**: NumPy, Numba, SciPy, Pandas, statsmodels, and xarray'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mathematics and precise calculations**: gmpy2, Sage, mpmath, SymPy, and Patsy'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Plotting, graphing, and charting**: Matplotlib, Seaborn, Yellowbrick, Plotly,
    Bokeh, and Datashader'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is very likely that not all libraries in this chapter are relevant to you,
    so don’t feel bad for not reading through all of it. However, I would recommend
    you at least look at the NumPy and Pandas sections briefly, as they are used heavily
    in the next chapter on machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, I would also recommend taking a look at the Matplotlib and Plotly
    sections, since those could be very useful in a wide range of scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the packages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As is always the case with Python libraries that are built on C and other non-Python
    code, installing is very platform-dependent. On most platforms, thanks to binary
    wheels, we can simply do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For this and the next chapter, however, I would recommend an alternative solution
    instead. While some of the libraries, such as `numpy`, are easy to install on
    most platforms, some of the other libraries are more challenging. For this reason,
    I would recommend the use of either the **Anaconda** distribution or one of the
    **Jupyter Docker Stacks**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Jupyter Docker Stacks require you to have Docker working on your system,
    but if you do, it can be extremely easy to launch very complicated systems that
    would be near impossible to set up otherwise. The list of available stacks can
    be found here: [https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#core-stacks](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#core-stacks).'
  prefs: []
  type: TYPE_NORMAL
- en: 'A good starting point for this chapter is the `jupyter/scipy-notebook` stack,
    which includes a huge list of packages such as `numpy`, `scipy`, `numba`, `matplotlib`,
    `cython`, and many more. Running this image (assuming you have Docker running)
    is as easy as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: After running the command, it will give you some information on how to open
    Jupyter in your browser.
  prefs: []
  type: TYPE_NORMAL
- en: Arrays and matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Matrices are at the heart of most scientific Python and artificial intelligence
    libraries because they are very convenient for storing a lot of related data.
    They are also suitable for really fast bulk processing, and calculations on them
    can be performed much faster than you could achieve with many separate variables.
    In some cases, these calculations can even be offloaded to the GPU for even faster
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: Note that a 0D matrix is effectively a single number, a 1D matrix is a regular
    array, and there is no real limit to the number of dimensions you can use. It
    should be noted that both size and processing time quickly increase with multiple
    dimensions, of course.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy – Fast arrays and matrices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `numpy` package spawned most of the scientific Python development and is
    still used at the core of many of the libraries covered in this chapter and the
    next. The library is largely (where it matters, at least) written in C, which
    makes it extremely fast; we will see a few benchmarks later, but depending on
    the operation, it can easily be 100 times faster than pure Python for the CPython
    interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: Since `numpy` has numerous features, we can only cover a few of the basics.
    But these already demonstrate how incredibly powerful (and fast) it is and why
    it is the basis for many of the other scientific Python packages in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The core feature of the `numpy` library is the `numpy.ndarray` object. The `numpy.ndarray`
    object is implemented in C and offers a very fast and memory-efficient array.
    It can be represented as a single-dimension array or a multi-dimensional matrix
    with very powerful slicing features. You can store any Python object in one of
    these arrays, but to take full benefit of the power of `numpy`, you will need
    to use numbers such as integers or floating point numbers.
  prefs: []
  type: TYPE_NORMAL
- en: One important thing to note about `numpy` arrays is that they have a **fixed**
    size and cannot be resized because they reserve a contiguous block of memory.
    If you need to make them smaller or larger, you will need to create a new array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a few basic examples of how this array can be used and why it
    is very convenient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the slicing options of `numpy` are very powerful, but what is
    even more useful about these slices is that they are all references/views instead
    of copies.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that if you modify the data in a slice, the original array will
    be modified as well. To illustrate using the array we created in the earlier examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, after modifying the first row and the first column for each
    row, we now see that `a`, `b`, and consequently all slices of `a` and `b` have
    been modified; and all of that in a single operation instead of having to loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to run a simple benchmark to see how fast `numpy` can be at certain
    operations. If you are familiar with linear algebra, you undoubtedly know what
    a dot product is. If not, the dot product is an algebraic operation on two equal-length
    arrays of numbers, which are multiplied pair-wise and summed after. In mathematical
    terms, it looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_001.png)'
  prefs: []
  type: TYPE_IMG
- en: It is a rather simple procedure and not that computationally heavy, but still
    something that is much faster when executed through `numpy`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of the dot product is to apply the growth of the second vector (array)
    onto the first vector. When applied to matrices, this can be used to move/rotate/scale
    a point or even an *n*-dimensional object. Simply put, if you have a 3D model
    stored in `numpy`, you can run a full transform on it using `numpy.dot`. Some
    examples of these operations can be found in my `numpy-stl` package: [https://pypi.org/project/numpy-stl/.](https://pypi.org/project/numpy-stl/.)'
  prefs: []
  type: TYPE_NORMAL
- en: Within this example, we will keep to the standard dot product of two 1-dimensional
    arrays, however.
  prefs: []
  type: TYPE_NORMAL
- en: 'To easily time the results, we will execute this from an IPython shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In this basic example, we can see that the pure Python version takes 78.7 ms
    and the `numpy` version takes 518 µs. That means that the `numpy` version is 150
    times faster. Depending on what you are trying to do and on the size of the array,
    the advantage can be far greater.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create an array, there are several options available, but the following
    are the most useful in my experience:'
  prefs: []
  type: TYPE_NORMAL
- en: '`numpy.array(source_array)` creates an array from a different array (as we
    saw in the previous example).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy.arange(n)` creates an array with the given range. Effectively identical
    to `numpy.array(range(n))`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy.zeros(n)` creates an array of size `n`, filled with zeros. It also supports
    tuples to create matrices: `numpy.zeros((x, y, z))`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy.fromfunction(function, (x, y, z))` creates an array with the given shape
    using the given function. It should be noted that this function will be passed
    the index/indices of the current item, so the `x`, `y`, and `z` indices in this
    case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `numpy` library has many more useful functions, but at the very least it
    offers an array with nearly unbeatable performance and a very easy-to-use interface.
  prefs: []
  type: TYPE_NORMAL
- en: Numba – Faster Python on CPU or GPU
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We already covered the basics of `numba` in *Chapter 12*, *Performance – Tracking
    and Reducing Your Memory and CPU Usage*. Combined with `numpy`, `numba` gets even
    more powerful because it natively supports functions that broadcast over `numpy`
    arrays (`numpy` calls these `ufuncs` or **universal functions**), similar to how
    the built-in `numpy` functions work. The only important difference between a regular
    `numba` function and one that supports `numpy` per-element processing is which
    decorator function you use. Normally you would use `numba.jit()`; for `numpy`
    per-element processing you need to use the `numba.vectorize(...)` decorator with
    the input and output types as parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Adding 1 is a useless example of course, but you can do anything you want here,
    which makes it very useful. The real point is how easy it is; as long as your
    function is purely functional (in other words, does not mutate external variables),
    it can be made extremely fast with very little effort. That is also the reason
    why several of the other libraries in this chapter heavily depend on `numba` for
    their performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we specified `numba.vectorize([numba.int64(numba.int64)])`, our function
    will only accept a 64-bit integer and will return a 64-bit integer. To create
    a function that takes two 32- or 64-bit floats and returns a 64-bit integer, we
    would use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In addition to the `numba.vectorize()` decorator, we have several other options
    available, such as the `numba.jitclass()` decorator for JIT-compiling an entire
    class, or the `numba.jit_module()` function to enhance an entire module.
  prefs: []
  type: TYPE_NORMAL
- en: SciPy – Mathematical algorithms and NumPy utilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `scipy` (Scientific Python) package contains a collection of mathematical
    algorithms for many different problems. The functions vary from signal processing
    to spatial algorithms to statistical functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a list of some of the current sub-packages available in the `scipy`
    library (according to the `scipy` manual):'
  prefs: []
  type: TYPE_NORMAL
- en: '`cluster`: Clustering algorithms such as *k*-means'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fftpack`: Fast Fourier Transform routines'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`integrate`: Integration and ordinary differential equation solvers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`interpolate`: Interpolation and spline smoothing functions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`linalg`: Linear algebra functions such as linear equation solving'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ndimage`: *N*-dimensional image processing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`odr`: Orthogonal distance regression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`optimize`: Optimization and root-finding routines'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`signal`: Signal processing functions such as peak finding and spectral analysis'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sparse`: Sparse matrices and associated routines to save memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spatial`: Spatial data structures and algorithms for triangulation and plotting'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stats`: Statistical distributions and functions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, `scipy` features algorithms for a large range of topics and
    many of the functions are really fast, so it is definitely worth taking a look
    at.
  prefs: []
  type: TYPE_NORMAL
- en: With most of these topics, you can already guess by their names whether or not
    they apply to your use case, but there are a few that warrant a small example.
    So, let’s look at one.
  prefs: []
  type: TYPE_NORMAL
- en: Sparse matrices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the most useful features of `scipy` (in my opinion, at least) is `scipy.sparse`.
    This module allows you to create sparse arrays, which can save you a huge amount
    of memory. While a `numpy` array takes roughly the amount of memory you are reserving,
    the `sparse` arrays only store the non-zero values or the non-zero blocks/rows/columns,
    depending on the type you choose. In the case of `numpy`, storing 1 million 64-bit
    integers takes 64 million bits or 8 megabytes.
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, the advantage of a sparse array comes with a bunch of downsides,
    such as slower processing for certain operations or directions. The `scipy.sparse.csc_matrix`
    method, for example, produces sparse matrices that are really fast to slice in
    the column direction, but slow when slicing rows. Meanwhile, `scipy.sparse.csr_matrix`
    is the opposite.
  prefs: []
  type: TYPE_NORMAL
- en: 'Usage of sparse arrays is roughly as straightforward as a `numpy` array, but
    care has to be taken when selecting the specific sparse matrix type. The options
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`bsr_matrix(arg1[, shape, dtype, copy, blocksize])`: Block Sparse Row matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`coo_matrix(arg1[, shape, dtype, copy])`: A sparse matrix in COOrdinate format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`csc_matrix(arg1[, shape, dtype, copy])`: Compressed Sparse Column matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`csr_matrix(arg1[, shape, dtype, copy])`: Compressed Sparse Row matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dia_matrix(arg1[, shape, dtype, copy])`: Sparse matrix with DIAgonal storage'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dok_matrix(arg1[, shape, dtype, copy])`: Dictionary Of Keys-based sparse matrix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lil_matrix(arg1[, shape, dtype, copy])`: Row-based List-Of-Lists sparse matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you only need something like a large identity matrix, this can be extremely
    useful. It is easy to construct and takes very little memory. The following two
    matrices are identical in contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As you can see here, the non-sparse version of the identity matrix (`x`) took
    10,000 times more memory. In this case, it is 800 megabytes versus 80 kilobytes,
    but if you have a much larger matrix this quickly becomes impossible. Since the
    matrix grows in size quadratically (`n^2`; the matrix above has size 10,000x10,000=100,000,000)
    this can make a very dramatic difference. The sparse matrix (in this case, at
    least) grows linearly (`n`).
  prefs: []
  type: TYPE_NORMAL
- en: For smaller non-sparse arrays (up to a billion numbers) the memory usage is
    still workable and it would take about 8 gigabytes of memory for a billion 64-bit
    numbers, but when you go beyond that, most systems will quickly run out of memory.
    As is often the case, these memory savings do come at the cost of increased CPU
    time for many operations, so I would not recommend replacing all of your `numpy`
    arrays with sparse arrays.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, `scipy` is a versatile and very useful module that supports a
    wide variety of calculations and algorithms. If `scipy` has an algorithm available
    for your goal, it is likely one of the fastest options you are going to find within
    the Python ecosystem. Many of the functions are very domain-specific, however,
    so you can probably guess which are (and are not) useful for you.
  prefs: []
  type: TYPE_NORMAL
- en: Pandas – Real-world data analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the focus of `numpy`, `scipy`, and `sympy` is mostly mathematical, Pandas
    is focused more on real-world data analysis. With Pandas, you are generally expected
    to load data from some external source such as databases or CSV files. Once you
    have the data loaded, you can easily calculate statistics, visualize the data,
    or combine the data with other datasets.
  prefs: []
  type: TYPE_NORMAL
- en: To store data, Pandas offers two different data structures. The `pandas.Series`
    is a 1-dimensional array and the `pandas.DataFrame` is a 2-dimensional matrix
    where the columns can be labeled if needed. Internally these objects wrap a `numpy.ndarray`,
    so all `numpy` operations are still possible on these objects as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Why do we need Pandas on top of `numpy`? It all comes down to convenience,
    and Pandas offers several features on top of `numpy` that are beneficial for doing
    real-world data analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: It can gracefully handle missing data. Within a `numpy` floating point number,
    you can store `NaN` (not a number), but not all `numpy` methods will handle that
    nicely without custom filtering.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As opposed to the fixed-size `numpy.ndarray`, columns can be added and removed
    to a `numpy.DataFrame` as desired.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides bundled data management functions to easily group, aggregate, or
    transform data. While you can easily modify `numpy` data, grouping data is a lot
    harder out of the box.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also provides utility functions for data containing time series, allowing
    you to easily apply moving window statistics and compare newer to older data with
    very little effort.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s create a simple example that stores the release dates of major Python
    releases with their versions. The data is sourced from Wikipedia, which has a
    nice table that we can quickly use and copy: [https://en.wikipedia.org/wiki/History_of_Python#Table_of_versions](https://en.wikipedia.org/wiki/History_of_Python#Table_of_versions).'
  prefs: []
  type: TYPE_NORMAL
- en: For brevity, we are showing a shortened version of the code here, but you can
    copy/paste the full table from Wikipedia or look in the GitHub project for this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s read the data into a dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we have the entire table stored in `data` as a tab-separated string.
    Since that includes the references that Wikipedia uses, we use a regular expression
    to clean up everything that looks like `[...]`. Lastly, we read the data into
    a `pandas.DataFrame` object using `pandas.read_table()`. The `read_table()` function
    supports either a filename or a file handle and, since we have the data as a string,
    we’re using `io.StringIO()` to convert the string to a file handle.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have the data, let’s see what we can do with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we know how to read the data from the table, let’s see how we can
    do something more useful with it. This time we are going to convert it into a
    time series so we can do analysis based on dates/times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: While you could do all of this with plain `numpy`, it is certainly much more
    convenient with `pandas`.
  prefs: []
  type: TYPE_NORMAL
- en: Input and output options
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One huge advantage of Pandas is the huge amount of readily available input and
    output options. Let’s start by saying that this list will never be complete because
    you can easily implement your own method, or install a library to handle other
    types for you. We will see an example of this later in this chapter when we cover
    `xarray`.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the time of writing, the `pandas` library natively supports a huge list
    of input and/or output formats:'
  prefs: []
  type: TYPE_NORMAL
- en: Common formats such as Pickle, CSV, JSON, HTML, and XML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spreadsheets such as Excel files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data formats used by other statistical systems such as HDF5, Feather, Parquet,
    ORC, SAS, SPSS, and Stata
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many types of databases using SQLAlchemy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your preferred format is not on the list, the odds are that you can easily
    find a converter for it. Alternatively, it is fairly easy to write a converter
    yourself as you can implement them in plain Python.
  prefs: []
  type: TYPE_NORMAL
- en: Pivoting and grouping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One very useful feature of Pandas is the ability to **pivot** and **unpivot**
    a DataFrame. When pivoting, we can convert rows to columns based on their values,
    effectively grouping them. The `pandas` library has several options to pivot/unpivot
    your data:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pivot`: Returns a reshaped pivot table without aggregation (e.g. sum/count/etc.)
    support'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pivot_table`: Returns a pivot table with aggregation support'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`melt`: Reverses the operation of `pivot`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`wide_to_long`: A simpler version of `melt` that can be more convenient to
    use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What can we achieve by pivoting? Let’s create a very simple example of some
    temperature measurements in a long list, and pivot them so we get the days as
    columns instead of rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The way this data is set up is similar to how a data logging tool would usually
    return it, with a single row for a single measurement. However, this is often
    not the most convenient way to read or analyze the data, and that is where pivoting
    can really help.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the mean room temperature per hour:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: That shows a row for each room and a column for each hour, with the values generated
    through `numpy.mean()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also get the mean room temperature per building, per room, per hour:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `pandas` handles missing values by showing `NaN` for the missing
    data and gives us a very nice aggregate result.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to these pivoting features, Pandas provides a huge list of grouping
    functions that also allow you to aggregate results. The big advantage of the grouping
    feature over pivoting is that you can group over arbitrary ranges and functions.
    For time-based results, for example, you could choose to group per second, minute,
    hour, 5 minutes, or any other interval that might be useful to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a basic example with the data above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This example already shows how the `groupby` feature can be used, but the real
    power comes when combining it with timestamps. For instance, you could do `pd.Grouper(freq='5min')`.
  prefs: []
  type: TYPE_NORMAL
- en: Merging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another extremely useful feature of Pandas is that you can merge data, similar
    to how you would join tables in a database. As is the case with pivoting, the
    `pandas` library has several join methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pandas.merge`: The `merge` function is pretty much the straight equivalent
    of a database join. It can do inner, outer, left, right, and cross joins, similar
    to many databases. Additionally, it can validate if the relations between the
    columns are correct (i.e. one-to-one, one-to-many, many-to-one, and many-to-many),
    in a similar way to how referential integrity in a database functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas.merge_ordered`: Similar to `merge` but allows for optional filling/interpolation
    using a function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas.merge_asof`: This function does a left join on the nearest key instead
    of requiring an exact match.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to easily merge multiple `DataFrame` objects is a really powerful
    feature that is invaluable when processing real-world data.
  prefs: []
  type: TYPE_NORMAL
- en: Rolling or expanding windows
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Pandas, windows can help you to efficiently run calculations on rolling subsets
    of (expanding) data. Naively calculating is of course possible, but that can be
    highly inefficient and infeasible for larger datasets. With a **rolling window**,
    you can have a running mean, sum, or other function on a fixed window size in
    an efficient manner.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate, let’s assume you have an array with 100 items and you want to
    get the mean value using a window size of 10\. The naïve solution would be to
    sum the first 10 items and divide them by 10, then repeat that for items 1 to
    11, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: For each of these, you would have to walk through all 10 items in the window.
    If we take `n` as the length of the array and `w` as the size of the window, this
    takes `O(n*w)` time. We can do much better if we keep track of the intermediate
    sum, however; if we simply add the next number and simultaneously remove the first
    number from our running sum, we can do the same in `O(n)` instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s illustrate how `pandas` can take care of this for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The rolling window as we have seen above supports functions for count, sum,
    mean, median, variance, standard deviation, quantiles, and several more. If you
    need something special, you can also provide your own function.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few extra features to these windows. Instead of having all items
    calculated with the same weight, you can also use **weighted windows** to vary
    the weight of the items so recent data becomes more relevant than older data.
    In addition to regular weighted windows, you can also opt for **exponentially
    weighted windows** to increase the effect even further.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we also have **expanding windows**. With these, you get the result from
    the beginning of the dataset up to your current point. If you were to sum a series
    with values `1, 2, 3, 4, 5`, it would return `1, 3, 6, 10, 15`, with each item
    being the total sum from the beginning of the series up to that point.
  prefs: []
  type: TYPE_NORMAL
- en: To conclude, the `pandas` library is extremely useful for analyzing data from
    varying sources. Since it was built on top of `numpy` it is also extremely fast,
    which makes it very convenient for in-depth analysis.
  prefs: []
  type: TYPE_NORMAL
- en: If you ever have a large amount of data to process, or data from several different
    sources, give `pandas` a try and see if it can help you to sort it out.
  prefs: []
  type: TYPE_NORMAL
- en: Statsmodels – Statistical models on top of Pandas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to how `scipy` builds on top of `numpy`, we have `statsmodels` that
    builds on top of `pandas`. Initially, it was part of the `scipy` package, but
    later split off and greatly improved.
  prefs: []
  type: TYPE_NORMAL
- en: The `statsmodels` library offers a host of statistical methods and plotting
    tools and can be used to create regression models, choice models, analysis of
    variance (ANOVA), forecasting, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'A quick example of a weighted least squares regression, which attempts to fit
    a line to a set of data points, can be applied like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: While it still requires some background knowledge about statistics to be able
    to apply this properly, it does show how easily you can do a regression with `statsmodels`.
  prefs: []
  type: TYPE_NORMAL
- en: An abbreviated list of the models and analysis types that are currently supported
    by `statmodels` from the `statsmodels` manual follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regression and linear models:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalized linear models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalized estimating equations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalized additive models (GAMs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robust linear models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear mixed effects models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression with discrete dependent variable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalized linear mixed effects models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ANOVA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Time series analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: Generic time series analysis such as univariate and vector autoregressive models
    (ARs/VARs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series analysis by state space methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector autoregressions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other models:'
  prefs: []
  type: TYPE_NORMAL
- en: Methods for survival and duration analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nonparametric methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalized method of moments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multivariate statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The actual list of supported features is quite a bit longer, but this should
    give you a good indication as to whether it is a useful library for you. If you
    are familiar with statistical models, you should be able to get started with `statsmodels`
    rather quickly and the package is well documented with great examples.
  prefs: []
  type: TYPE_NORMAL
- en: xarray – Labeled arrays and datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `xarray` library is very similar to `pandas` and is also built on top of
    `numpy`. The main differences are that `xarray` is multi-dimensional, whereas
    `pandas` supports one-dimensional and two-dimensional data only, and it was created
    with the **netCDF** (**Network Common Data Form**) formats in mind. The netCDF
    formats are commonly used for scientific research data, which (as opposed to CSV
    files, for example) contain both the data and metadata such as variable labels,
    data descriptions, and documentation, allowing for easy use in a multitude of
    software.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `xarray` library can easily work together with `pandas`, so for this example,
    we will re-use the data from our earlier `pandas` example. The other way around
    is also easily possible using the `to_dataframe()` method on an `xarray.DataArray`
    object (the standard `xarray` matrix object). In this example, we will assume
    that you still have the `df` variable available from the `pandas` example earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The syntax for the `groupby()` is slightly different from `pandas`, and less
    Pythonic (if you ask me) due to the use of strings over variables, but it essentially
    comes down to the same operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `pandas` version, the order of the `count()` and the `[''Version'']`
    can be swapped to be even more similar. That is, the following is also valid and
    returns the same results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Additionally, for this use case, I would argue that the output of `xarray` is
    not all that readable, but it certainly isn’t bad either. Often, you will have
    so many data points that you won’t be too interested in the raw data anyway.
  prefs: []
  type: TYPE_NORMAL
- en: 'The real advantage to `xarray` over `pandas` (in my opinion, at least) is the
    support for multi-dimensional data. You can add as much as you want to the `Dataset`
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we only added the `triangles` and the `points`, but you can add
    as much as you want and you can use `xarray` to combine these so you can reference
    multi-dimensional objects easily. Data combination can be achieved through several
    methods such as concatenation, merging to combine multiple datasets into one,
    combining based on field values, through per-row updates, and others.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes down to `pandas` versus `xarray`, I would recommend simply giving
    them both a try and seeing which is more convenient for your use case. The libraries
    are very similar in features and usability and both have their own advantages.
    The multi-dimensionality of `xarray` is a huge advantage over `pandas` if you
    need it, however.
  prefs: []
  type: TYPE_NORMAL
- en: If it’s all the same to you then I would currently recommend `pandas` over `xarray`,
    simply because it is currently the most used of the two, which results in more
    documentation/blog posts/books being available.
  prefs: []
  type: TYPE_NORMAL
- en: STUMPY – Finding patterns in time series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `stumpy` library offers several tools to automatically detect patterns and
    anomalies in your time series matrices. It is built upon `numpy`, `scipy`, and
    `numba` to provide great performance and gives you the possibility of employing
    GPU (video card) power as well, to process the data even faster.
  prefs: []
  type: TYPE_NORMAL
- en: Using `stumpy` you could, for example, automatically detect if a website is
    getting an abnormal number of visitors. One of the nice features of `stumpy` in
    this scenario is that, in addition to static matrices, you can also add more data
    in a streaming way, which allows you to do real-time analysis without too much
    overhead.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let’s assume we have a list of temperatures for a living room
    thermostat and see if we can find any repeating patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The observant among you may have noticed that this distance matrix only has
    `4` rows for `6` values instead of the traditional `n*n` (`6*6` in this case)
    distance matrix. This is in part because we use a window size of `3` and we only
    look at the number of windows (which is `n-window_size+1=4`). A larger part is
    due to `stumpy` storing only the closest pairs, resulting in only requiring `O(n)`
    space instead of the normal `O(n*n)`.
  prefs: []
  type: TYPE_NORMAL
- en: While you can do these types of analysis with plain `numpy` as well, `stumpy`
    uses a very smart algorithm and relies heavily on `numba` for faster processing,
    so if you can use the library, I would recommend it.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematics and precise calculations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python has a decent number of mathematical functions and features built in,
    but there are cases where you need more advanced features or something faster.
    In this section, we will discuss a few libraries that help by introducing many
    extra mathematical functions and/or increase mathematical precision and/or performance
    quite a bit.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s discuss the options in the Python core libraries to store numbers
    and perform calculations with varying precision:'
  prefs: []
  type: TYPE_NORMAL
- en: '`int`: To store whole numbers (e.g. `1, 2, 3`), we have the `int` object in
    Python. The `int` is directly translated into a C `int64` on most systems as long
    as it can fit within 64-bit. Outside of that, it is internally cast to a Python
    `long` type (not to be confused with a C `long`), which can be arbitrarily large.
    This allows for infinite accuracy but only works as long as you use whole numbers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fractions.Fraction`: The `Fraction` object makes it possible to store fractional
    numbers (for example, `1/2`, `1/3`, `2/3`) and they are infinitely precise since
    they rely on two `int` (or `long`) objects internally as the denominator and the
    numerator. However, these only work if the number you are trying to store can
    be represented as a fraction. Irrational numbers such as Pi cannot be represented
    this way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`float`: Floating point numbers make it really easy to store numbers that include
    decimals (for example `1.23`, `4.56`). These numbers are generally stored as a
    64-bit floating point, which is a combination of a sign (1 bit positive or negative),
    exponent (11 bits), and a fraction (52 bits), resulting in the following equation:![](img/B15882_15_002.png)
    . This means that a number such as 0.5 is stored using fraction 0 and exponent
    -1, resulting in: ![](img/B15882_15_003.png) . In the case of 0.5, this can be
    stored perfectly; in many other cases, this is problematic because not every number
    can be accurately described like this, which causes floating point inaccuracies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decimal.Decimal`: The `Decimal` object allows for calculations with an arbitrary
    but specified precision. You can choose how many decimals you want, but it is
    not all that fast.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Several of the following libraries offer solutions to enhance the precision
    of your calculations.
  prefs: []
  type: TYPE_NORMAL
- en: gmpy2 – Fast and precise calculations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `gmpy2` library uses libraries that are written in C for really fast high-precision
    calculations. On Linux/Unix systems it will rely on GMP (hence the name); on Windows
    it will use MPIR, which is based on GMP. Additionally, the MPFR and MPC libraries
    are used for correctly rounding floating point real and complex numbers respectively.
    Lastly, it uses `mpz_lucas` and `mpz_prp` for really fast primality testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a tiny example on how to get Pi to 1000 places, which you can’t easily
    do with the Python core library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This library is invaluable if you need fast and high-precision calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'For my personal use case, the `gmpy` library (`gmpy2` didn’t exist yet at that
    time) has been extremely helpful when competing in the fun online math challenge
    project called Project Euler: [https://projecteuler.net/](https://projecteuler.net/).'
  prefs: []
  type: TYPE_NORMAL
- en: Sage – An alternative to Mathematica/Maple/MATLAB
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have ever taken an advanced math class in college or university, chances
    are that you have encountered software such as Mathematica, Maple, MATLAB, or
    Magma. Or perhaps you have used WolframAlpha, which is built on Mathematica. The
    Sage project is meant as a free and open source alternative to those really expensive
    software packages.
  prefs: []
  type: TYPE_NORMAL
- en: For reference, at the time of writing, the basic Mathematica Home edition, which
    can only run at 4 CPU cores at the same time, costs 413 euros (487 US dollars).
  prefs: []
  type: TYPE_NORMAL
- en: The Sage package can be used to solve equations both numerically and exactly,
    plot charts, and perform many other tasks from the Sage interpreter. Similar to
    IPython and Jupyter, Sage offers its own interpreter with a custom language so
    it feels closer to mathematical packages such as Mathematica. Naturally, you could
    import the Sage code from regular Python as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'A small example of solving for a variable using Sage with the Sage interpreter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, we asked Sage to solve an equation with three variables for us
    given the following constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_004.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/B15882_15_005.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/B15882_15_006.png)'
  prefs: []
  type: TYPE_IMG
- en: 'According to Sage (correctly), this results in:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_007.png)'
  prefs: []
  type: TYPE_IMG
- en: If you are looking for a full-fledged mathematical software system (or some
    features of one), Sage is a good option.
  prefs: []
  type: TYPE_NORMAL
- en: mpmath – Convenient, precise calculations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `mpmath` library is an all-round mathematical library offering functions
    for trigonometry, calculus, matrices, and many others while still maintaining
    a configurable precision.
  prefs: []
  type: TYPE_NORMAL
- en: Installing `mpmath` is really easy since it is pure Python and has no required
    dependencies, but it does offer speedups using Sage and `gmpy2` if they are available.
    This combines the benefits of the Sage and `gmpy2` libraries for speed with the
    convenience of a pure Python installation if those are not available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s illustrate the advantages of configurable precision versus regular floating
    point numbers in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, both regular addition and `sum()` are both inaccurate. Python
    does have a better method available for this specific problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'When it comes to the general case, however, floating point math will always
    be inaccurate and at times that can be problematic. So, if your calculations do
    require floating point math but you want more accuracy, `mpmath` can help you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: While these results are obviously still not perfect (you would assume the result
    to be 1.0, like what `math.fsum()` produced), it can help to reduce floating point
    errors a lot more. Make sure to feed `mpmath` strings or integers, otherwise your
    variable can already introduce floating point errors. If we had used `x` in the
    sum instead of `y`, it would have resulted in floating point inaccuracy similar
    to regular Python math.
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, `fpmath` can do a lot more than simply reduce your floating point
    errors, such as plotting and calculus, but I will leave that for you to explore.
    If you are looking for solutions to mathematical problems, this library should
    be on your list.
  prefs: []
  type: TYPE_NORMAL
- en: SymPy – Symbolic mathematics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `sympy` module is a library that you might never need, but it is such a
    great library that it should be covered. The goal of `sympy` is to be a fully
    featured **Computer Algebra System** (**CAS**) so you can manipulate mathematical
    expressions similar to how you would do so on paper.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with a little demo on how we can express and solve an integral
    using `sympy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Apologies if this gave you horrible flashbacks to some calculus exam, but I
    think it is amazing to be able to do this. This code first imports `sympy` using
    a wildcard because the equations would quickly become unreadable if all functions
    needed to be prefixed by `sympy`.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we use the `init_printing()` function with the Unicode flag enabled
    to tell `sympy` that our shell supports Unicode characters. This allows for pretty
    rendering of many mathematical formulas, but certainly not all of them. The alternatives
    to this are basic ASCII rendering (as you can imagine, this does not look too
    pretty for an integral), and LaTeX output, which can render as images (for example,
    when using Jupyter). There are actually several other rendering modes available,
    but they greatly depend on your environment so we will not be getting into those.
  prefs: []
  type: TYPE_NORMAL
- en: Because you can use any variable name in an equation, we need to specifically
    declare `x`, `y`, and `z` as variables. Even though we only use `x` in this case,
    you will often need the others as well, so why not declare them in advance?
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we use the `Integral` function to declare the integral. Due to font limitations,
    the example above is not perfect, but the rendered integral should look like this
    in your shell or browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_008.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Lastly, we tell `sympy` to solve the integral using the `doit()` method. This
    correctly results in the equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_009.png)'
  prefs: []
  type: TYPE_IMG
- en: The only nitpick I have here is that `sympy` omits the integration constant
    by default. Ideally, it would include the `+ C`.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re looking to represent (and solve) an equation, `sympy` can certainly
    help. I personally think it is a really great library even though I have very
    little use for it.
  prefs: []
  type: TYPE_NORMAL
- en: Patsy – Describing statistical models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Similar to how `sympy` can describe mathematical formulas in Python, `patsy`
    can describe statistical models, which makes it go hand in hand with the `statsmodels`
    package. It can also use regular Python functions or directly apply `numpy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we created a `numpy` array with a range from 2 to 6 and passed
    this to the `patsy.dmatrix()` function under the names `a`, `b`, and `c`, since
    duplicate names will be ignored. After that, we created the matrix using `patsy`;
    as you can see, the `+` in the `patsy` language tells it to add a new column.
    Those columns can be plain columns such as `a`, but they can also call functions
    such as `np.square(b)`.
  prefs: []
  type: TYPE_NORMAL
- en: If you are familiar with the mathematics behind vectors and matrices, this library
    might feel very natural to you. At the very least, it can be a slightly more obvious
    way to declare how your data interacts.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting, graphing, and charting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Being able to read, process, and write data is important, of course, but to
    understand the meaning of data it is often far more convenient to create a plot,
    graph, or chart. As the old adage goes: “A picture is worth a thousand words.”'
  prefs: []
  type: TYPE_NORMAL
- en: If you have experience with any of the libraries mentioned earlier in this chapter,
    you may know that many of them have options for graphical output. In (almost?)
    all cases, however, this is not really a built-in feature but a convenient shortcut
    to an external library such as `matplotlib`.
  prefs: []
  type: TYPE_NORMAL
- en: As is the case with several of the libraries mentioned in this chapter, there
    are multiple libraries with similar features and possibilities, so this is certainly
    not an exhaustive list. To make visual plotting easier, for these examples we
    will mostly rely on `jupyter-notebook` with the use of the `ipywidgets` to create
    interactive samples. As always, the code (in these cases, the `jupyter-notebooks`)
    can be found on GitHub at [https://github.com/mastering-python/code_2](https://github.com/mastering-python/code_2).
  prefs: []
  type: TYPE_NORMAL
- en: Matplotlib
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `matplotlib` library is the reliable standard for plotting and is supported
    by many of the scientific libraries in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the libraries mentioned earlier in this chapter either explain how `matplotlib`
    can be used with the library, or even have utility functions to facilitate plotting
    with `matplotlib`.
  prefs: []
  type: TYPE_NORMAL
- en: Does this mean that the `matplotlib` library is the gold standard for plotting?
    As usual, it depends. While `matplotlib` is certainly the most used scientific
    plotting Python library with a huge array of features, it is not always the most
    beautiful option. That doesn’t mean you cannot configure it to be pretty, but
    out of the box, the library focuses on easy-to-read, consistent results and works
    for everyone and all scenarios. Some of the prettier libraries might look fantastic
    on a web page and have very useful interactive features but are not that suited
    for publishing and printing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic example is trivially easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Effectively, we only need `plt.plot()` to plot a basic chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.1: Matplotlib plot'
  prefs: []
  type: TYPE_NORMAL
- en: 'This simple example was very easy to plot, but `matplotlib` can do so much
    more. Let’s take a look at how we can combine a few graphs and make the plot interactive
    using `ipywidgets`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This function generates the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.2: Matplotlib in Jupyter Notebook with adjustable sliders'
  prefs: []
  type: TYPE_NORMAL
- en: With a combination of `jupyter-notebook` and `matplotlib`, we can create interactive
    plots. If you run this in your own browser, not only can you drag the 3D plot
    around and view it from all sides, but you can also modify the `size` and `step`
    parameters by dragging the sliders.
  prefs: []
  type: TYPE_NORMAL
- en: With regard to actual plot types supported by `matplotlib`, there are really
    too many options and variations to list here, but if you are looking for any type
    of chart, graph, or plot, you are likely to find a solution using `matplotlib`.
    Additionally, many of the scientific Python libraries natively support it, which
    makes it an easy choice. This short section really does not do justice to the
    depth and features of `matplotlib`, but fear not – we are far from done with it
    as it, is the basis of a few other plotting libraries in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Seaborn
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `seaborn` library is related to `matplotlib` in a similar way to how `statsmodels`
    works on top of `pandas`. It provides an interface for `matplotlib` with a strong
    focus on statistical data. The major feature of `seaborn` is that it makes it
    really easy to automatically generate an entire grid of plots.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, which is very convenient for our examples, `seaborn` comes with
    some test data so we can show fully fledged demonstrations based on real data.
    To illustrate, let’s look at how easily we can create a very elaborate set of
    plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following set of plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.3: Seaborn pairplot render'
  prefs: []
  type: TYPE_NORMAL
- en: While this still seems like a very elaborate call, you could actually get away
    with just using `sns.pairplot(df)` to get great results. Without the `hue=...`
    parameter, the results will not be split by species, however.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `seaborn` library has support for many types of plots:'
  prefs: []
  type: TYPE_NORMAL
- en: Relational plots such as line plots and scatter plots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distribution plots such as histograms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Categorical plots such as box plots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix plots such as heatmaps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `seaborn` library also has many shortcuts for creating sets of plots or
    automatically processing the data using algorithms such as kernel density estimation.
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking for a nice-looking plotting library, `seaborn` is a very
    good option, especially due to the multi-plot grid features. The list of plots
    above are all specific plots, but as we saw with `pairplot`, `seaborn` can generate
    an entire grid of plots in just a single line of code, which is extremely useful.
    You could do the same with `matplotlib` directly, but it would probably take you
    a few dozen lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: Yellowbrick
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As is the case with `seaborn`, `yellowbrick` is also built on top of `matplotlib`.
    The difference is that `yellowbrick` is focused on visualizing machine learning
    results and depends on the scikit-learn (`sklearn`) machine learning library.
    The scikit-learn integration is also what makes this library very powerful in
    those scenarios; it natively understands the scikit-learn data structures so it
    can easily plot them for you with almost no configuration. In the next chapter,
    we will see more on scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: 'This example, straight from the `yellowbrick` manual, shows how you can visualize
    a regression in effectively a single line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This generates the following scatter plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.4: Yellowbrick regression plot'
  prefs: []
  type: TYPE_NORMAL
- en: These kinds of shortcut functions make it really easy to generate usable output
    and work on your regression instead of having to worry about how to properly plot
    the data. In addition to plotting regressions, `yellowbrick` has many more visualizers
    organized by analysis type. Similar to `seaborn`, `yellowbrick` can take care
    of not only the plotting but also the calculations and analysis for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `yellowbrick` library has functions for many types of analysis such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature visualization**: Displaying features as scatter plots, detecting
    relationships and ranking them, creating a circular plot of related features,
    and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classification visualization**: Displaying the thresholds, precision, and
    the error prediction for classifications as line, area, or matrix plots'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression visualization**: Displaying a scatter or a combination of scatter
    plots and histograms'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster visualization**: Displaying maps to visualize the distance between
    the clusters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model selection visualization**: Displaying the learning curve through a
    combination of lines and area or showing the feature importance as a bar chart'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `yellowbrick` library is currently the most convenient option for visualizing
    scikit-learn output, but most of the charting options also apply to other data
    types such as `pandas.DataFrame` objects, so it’s worth taking a look if `seaborn`
    does not suit your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Plotly
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `plotly` library supports a lot of different types of plots and even has
    native support for controls such as sliders, so you can change parameters when
    viewing from a web browser. Additionally, similar to how `seaborn` makes usage
    of `matplotlib` much easier in some cases, `plotly` also includes Plotly Express
    (often denoted as `px`), which makes usage trivially easy.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate how easy Plotly Express can be, let’s try to replicate the plots
    we made with `seaborn`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.5: Plotly Express example output'
  prefs: []
  type: TYPE_NORMAL
- en: While I would argue that the `seaborn` output is slightly prettier in this specific
    case, it does show just how easy it is to create useful plots using Plotly Express.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might be wondering how easy or difficult it is to use the regular `plotly`
    API, as opposed to Plotly Express. For that, let’s see if we can replicate the
    3D `matplotlib` render:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the final result with the two cosines plotted in 3D:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.6: 3D plot using plotly'
  prefs: []
  type: TYPE_NORMAL
- en: This is pretty much identical to `matplotlib`, and I would argue that it’s even
    slightly better due to being even more interactive (which the book cannot effectively
    show, unfortunately). By default, `plotly` features a very useful display of the
    values when you hover with the mouse and allows for really easy zooming and filtering
    interactively.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to the choice between `matplotlib` and `plotly`, I would recommend
    looking at your specific use case. I think `plotly` is slightly easier and more
    convenient to use, but `matplotlib` is deeply integrated with many scientific
    Python libraries, which makes it a very convenient option. As always, opinions
    vary, so make sure to take a look at both.
  prefs: []
  type: TYPE_NORMAL
- en: Bokeh
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `bokeh` library is a beautiful and powerful visualization library with a
    strong focus on interactive visualizations in web browsers. Being able to make
    plots interactive can be extremely useful for analyzing the results. Instead of
    having to create multiple plots in a grid as we saw with `seaborn`, you can use
    a single grid and filter interactively. As this is a book, however, we cannot
    really demonstrate the full power of `bokeh`.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get started with some examples, we need to talk about the two ways
    you can use `bokeh`. Effectively it comes down to **static** versus **dynamic**,
    where the static version uses a static snapshot of all data shown and the dynamic
    version loads data on demand.
  prefs: []
  type: TYPE_NORMAL
- en: 'The static version is similar to how `matplotlib` and most plotting libraries
    work: all data is contained in a single image or on a single web page without
    loading external resources. This works great for many cases, but not all.'
  prefs: []
  type: TYPE_NORMAL
- en: What if you have a *lot* of data? A nice example of a visualization like this
    is Google Earth. You could never realistically download all of the data from Google
    Earth onto your computer (according to some estimates, currently over 100 petabytes
    of data), so you need to load it as you move around the map. For this purpose,
    `bokeh` has a server built in so the visualization can dynamically load the results
    as you filter. For the purpose of this book that makes little sense because it
    will be static in all cases, but we can show examples of both.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s create a very basic plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'From this, we get the sine and cosine rendered as lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.7: Bokeh basic render'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, rendering basic *x*/*y* data as a line is really easy and does
    not look too different from the `matplotlib` output. If you look carefully, however,
    you might also notice the buttons on the right. These are what `bokeh` calls **tools**,
    and they can be used for zooming by either scrolling or by drawing a rectangle
    around what you wish to see. Panning can be done by dragging the image. It is
    also possible to save the render as an image file. If desired, you can create
    tooltips that respond to mouse clicks or mouse hovers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s see if we can recreate a more advanced plot like the one we made
    with `seaborn`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in a collection of scatter plots and histograms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_15_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.8: Seaborn-like plots using Bokeh'
  prefs: []
  type: TYPE_NORMAL
- en: This somewhat resembles what we created with `seaborn`, but it still took quite
    a bit of effort to do. It does show how we can fairly easily combine several plots
    (and types of plots) together even when using a `pandas.DataFrame` as a source.
  prefs: []
  type: TYPE_NORMAL
- en: Should you use `bokeh`? I think `bokeh` is a nicely documented plotting library
    with a lot of merits, but so are many of the others. In my opinion, the main feature
    of `bokeh` is the support for dynamic data loading through the `bokeh` server,
    which can be a really useful feature in some cases. As opposed to `plotly`, the
    `bokeh` server has more features for maintaining its own state, so chart changes
    can be made easily without recalculation.
  prefs: []
  type: TYPE_NORMAL
- en: Datashader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `datashader` library is a special case but I believe it deserves a mention.
    The `datashader` plotting library can be used for regular plotting, but it is
    specially optimized for high performance and large datasets. As a little example,
    this plot with 10 million data points only takes about a second to render:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the plot generated by calculating the 10 million points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/EC6EBE9A.tmp](img/B15882_15_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.9: Datashader attractor render'
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Due to the nature of this chapter, we have only covered the absolute basics
    of the mentioned libraries and they really do deserve much more. In this case,
    as an exercise, I recommend that you try and use some (or all) of the mentioned
    libraries and see if you can do something useful with them, using the variety
    of examples we have introduced already as inspiration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some suggestions:'
  prefs: []
  type: TYPE_NORMAL
- en: Create your own beautiful datashader plots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Render the lines of code per project of your personal workspace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuing from the lines of code per project, see if you can cluster the projects
    by programming language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example answers for these exercises can be found on GitHub: [https://github.com/mastering-python/exercises](Chapter_15.xhtml).
    You are encouraged to submit your own solutions and learn about alternative solutions
    from others.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has shown us a sample of the most commonly used and generic scientific
    Python libraries. While it covered a lot of libraries, there are many more available,
    especially when you start looking for domain-specific libraries. With regard to
    plotting alone, there are at least several other very big libraries that could
    be useful for your use cases but would be superfluous for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: To recap, we have covered the basics of working with NumPy matrices and Pandas
    data objects, both of which are important for the next chapter. We have also seen
    a few libraries that focus on mathematics and really precise calculations. Lastly,
    we have covered several plotting libraries, some of which will be used in the
    next chapter as well.
  prefs: []
  type: TYPE_NORMAL
- en: Next up is the chapter about artificial intelligence and machine learning in
    Python. As is the case with this chapter, we cannot go into too much depth, but
    we can cover the most important technologies and libraries so you know where to
    look.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers: [https://discord.gg/QMzJenHuJf](https://discord.gg/QMzJenHuJf)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code156081100001293319171.png)'
  prefs: []
  type: TYPE_IMG
