["```py\n$ pip3 install -U 'scikit-image[optional]' \n```", "```py\n%matplotlib inline\nfrom skimage import io, data\n\ncoins = data.coins()\nio.imshow(coins) \n```", "```py\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom skimage import feature\n\n# Get pixels 180 to the end in the X direction\nx0, x1 = 180, -1\n# Get pixels 0 to 90 in the Y direction \ny0, y1 = 0, 90\n# Slice the image so only the top-right three coins are visible\nthree_coins = coins[y0:y1, x0:x1]\n# Apply the canny algorithm\nplt.imshow(feature.canny(three_coins), cmap='gray') \n```", "```py\n%matplotlib inline\nfrom skimage import data\nfrom skimage.feature import Cascade\n\n# We are using matplotlib directly so we can\n# draw on the rendered output\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\n\ndpi = 300\ncolor = 'white'\nthickness = 1\nstep_ratio = 1\nscale_factor = 1.2\nmin_object_size = 60, 60\nmax_object_size = 123, 123\n\n# A photo of Astronaut Eileen Collins\nimg = data.astronaut()\n\n# Plot the image as high resolution in grayscale\nplt.figure(dpi=dpi)\nplt.imshow(img.mean(axis=2), cmap='gray') \n```", "```py\n# Load the trained file and initialize the detector cascade\ndetector = Cascade(data.lbp_frontal_face_cascade_filename())\n\n# Apply the detector to find faces of varying sizes\nout = detector.detect_multi_scale(\n    img=img, step_ratio=step_ratio, scale_factor=scale_factor,\n    min_size=min_object_size, max_size=max_object_size)\n\nimg_desc = plt.gca()\nfor box in out:\n    # Draw a rectangle for every detected face\n    img_desc.add_patch(patches.Rectangle(\n        # Col and row as X and Y respectively\n        (box['c'], box['r']), box['width'], box['height'],\n        fill=False, color=color, linewidth=thickness)) \n```", "```py\n$ pip3 install opencv-contrib-python \n```", "```py\n%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom skimage import data\n\n# Use the coins image from scikit-image\ncoins = data.coins()\n\n# Get pixels 180 to the end in the X direction\nx0, x1 = 180, -1\n# Get pixels 0 to 90 in the Y direction \ny0, y1 = 0, 90\n# Slice the image so only the top-right three coins are visible\nthree_coins = coins[y0:y1, x0:x1]\n# scikit-image automatically guesses the thresholds, OpenCV does not\nthreshold_1, threshold_2 = 100, 200\n# Apply the canny algorithm\noutput = cv2.Canny(three_coins, threshold_1, threshold_2)\n\n# OpenCV's imshow() function does not work well with Jupyter so\n# we use matplotlib to render to grayscale\nplt.imshow(output, cmap='gray') \n```", "```py\n%matplotlib inline\nimport cv2 as cv\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom skimage import data\n\ncolor = 0xFF, 0xFF, 0xFF  # White\ndpi = 300\nfont = cv.FONT_HERSHEY_SIMPLEX\nfont_size = 3\nimage_dims = 320, 320\nlabel_offset = 10, 70\nmin_score = 0.9\nthickness = 2\n\n# Load the astronaut image from scikit-image as before\nimg = data.astronaut()\n# Convert the image into a 4-dimensional blob\n# by subtracting the mean and rescaling\nblob = cv.dnn.blobFromImage(img, 1 / 255, size=image_dims) \n```", "```py\n# Load names of classes so we know what was detected\nclasses = open('coco.names').read().splitlines()\n# Load the deep neural network model and configuration\nnet = cv.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n# Determine the output layer\nln = net.getLayerNames()\nln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n\n# Pass the blob to the net and calculate the output blobs\nnet.setInput(blob)\nout = net.forward(ln)\n# Loop through all outputs after stacking because\n# the net attempts to match multiple sizes\nfor result in np.vstack(out):\n    # x, y, w and h are numbers between 0 and 1 and need to be\n    # scaled by the width and height\n    result[:4] *= img.shape[1::-1] * 2\n    x, y, w, h, *scores = result\n    # Search the net for the best match\n    match_index = np.argmax(scores)\n    # Skip questionable matches\n    if scores[match_index] < min_score:\n        continue\n\n    # Calculate the top left and bottom right points\n    tl = np.array([x - w / 2, y - h / 2], dtype=int)\n    br = np.array([x + w / 2, y + h / 2], dtype=int)\n    cv.rectangle(img, tl, br, color, thickness)\n    # Calculate the point to place the text\n    cv.putText(img, classes[match_index], tl + label_offset,\n               font, font_size, color, thickness)\n    # Stop after the first match to prevent overlapping results\n    break\n\nplt.figure(dpi=dpi)\nplt.imshow(img.mean(axis=2), cmap='gray') \n```", "```py\n$ pip3 install nltk \n```", "```py\n>>> import nltk\n>>> from nltk import sentiment\n\n>>> nltk.download('vader_lexicon')\nTrue\n\n>>> sentences = [\n...     'Python is a wonderful programming language',\n...     'Weak-typed languages are prone to errors',\n...     'I love programming in Python and I hate YAML',\n... ]\n\n>>> si = sentiment.SentimentIntensityAnalyzer()\n>>> for sentence in sentences:\n...     scores = si.polarity_scores(sentence)\n...     print(sentence)\n...     print('negative: {neg}, positive: {pos}'.format(**scores))\nPython is a wonderful programming language\nnegative: 0.0, positive: 0.481\nWeak-typed languages are prone to errors\nnegative: 0.324, positive: 0.0\nI love programming in Python and I hate YAML\nnegative: 0.287, positive: 0.326 \n```", "```py\n$ pip3 install spacy\n$ python3 -m spacy download en_core_web_sm \n```", "```py\n>>> import spacy\n>>> import en_core_web_sm\n\n>>> nlp = en_core_web_sm.load()\n>>> _ = nlp.add_pipe(\"merge_entities\")\n\n>>> sentence = ('Python was introduced in 1989 by Guido van '\n... 'Rossum at Stichting Mathematisch Centrum in Amsterdam.')\n\n>>> for token in nlp(sentence):\n...     if token.ent_type_:\n...         print(f'{token.ent_type_}: {token.text}')\nDATE: 1989\nPERSON: Guido van Rossum\nORG: Stichting Mathematisch Centrum\nGPE: Amsterdam \n```", "```py\n$ pip3 install torch torchvision \n```", "```py\n%matplotlib inline\nfrom PIL import Image\nfrom matplotlib import pyplot as plt, patches\nfrom torchvision import transforms\nfrom torchvision.models import detection\n\ndpi = 300\nfont_size = 14\ncolor = 'white'\nmin_score = 0.8\nmin_size = 100\nlabel_offset = 25, -25\n\n# Load the img and convert it to a PyTorch Tensor\nimg = Image.open('amsterdam-street.jpg')\nimg_t = transforms.ToTensor()(img) \n```", "```py\n# Read the labels from coco_labels. The entire COCO\n# (Common Objects in COntext) dataset is available at:\n# https://cocodataset.org/#download\nlabels = open('coco_labels.txt').read().splitlines()\n\n# Load the R-CNN model and set it to eval mode for execution\nmodel = detection.fasterrcnn_resnet50_fpn(pretrained=True)\nmodel.eval()\n# Apply the model to the img as a list and unpack after applying\nout, = model([img_t]) \n```", "```py\nresults = zip(out['boxes'].detach(), out['labels'], out['scores'])\n\n# Increase the DPI to get a larger output image\nplt.figure(dpi=dpi)\nimg_desc = plt.subplot()\n# Walk through the list of detections and print the results\nfor (t, l, b, r), label_idx, score in results:\n    # Skip objects that are questionable matches\n    if score < min_score:\n        continue\n\n    # Skip tiny matches\n    h, w = b - t, r - l,\n    if w < min_size or h < min_size:\n        continue\n\n    # Draw the bounding box and label\n    img_desc.add_patch(patches.Rectangle(\n        (t, l), h, w, fill=False, color=color))\n    label = f'{labels[label_idx]} {score * 100:.0f}%'\n    img_desc.text(\n        t + label_offset[0], r + label_offset[1], label,\n        fontsize=font_size, color=color)\n\n# Output the img as grayscale for print purposes\nplt.imshow(img.convert('L'), cmap='gray')\nplt.show() \n```", "```py\n$ pip3 install tensorflow tensorflow-hub \n```", "```py\n%matplotlib inline\nimport numpy as np\nimport tensorflow_hub as hub\nfrom keras.preprocessing import image\nfrom matplotlib import pyplot as plt, patches\n\ndpi = 300\nfont_size = 14\ncolor = 'white'\nmin_score = 0.8\nmin_size = 100\nlabel_offset = 25, -25\n\n# Load the img and convert it to a numpy array\nimg = image.load_img('amsterdam-street.jpg')\nimg_t = image.img_to_array(img)\nimg_w, img_h = img.size \n```", "```py\nlabels = open('coco_labels.txt').read().splitlines()\nmodel = hub.load(    'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1')\nout = model(np.array([img_t]))\n\n# The box coordinates are normalized to [0, 1]\nimg_dim = np.array([img.size[1], img.size[0]] * 2)\nresult = zip(\n    out['detection_boxes'][0] * img_dim,\n    out['detection_classes'][0],\n    out['detection_scores'][0],\n) \n```", "```py\n# Increase the DPI to get a larger output image\nplt.figure(dpi=dpi)\nimg_desc = plt.subplot()\n\n# Walk through the list of detections and print the results\nfor (l, t, r, b), label_idx, score in result:\n    label_idx = int(label_idx)\n    # Skip objects that are questionable matches\n    if score < min_score:\n        continue\n\n    # Skip tiny matches\n    h, w = b - t, r - l,\n    if w < min_size or h < min_size:\n        continue\n\n    # Draw the bounding box and label\n    img_desc.add_patch(patches.Rectangle(\n        (t, l), h, w, fill=False, color=color))\n    label = f'{labels[label_idx]} {score * 100:.0f}%'\n    img_desc.text(\n        t + label_offset[0], r + label_offset[1], label,\n        fontsize=font_size, color=color)\n\n# Output the img as a large grayscale for print purposes\nplt.imshow(img.convert('L'), cmap='gray') \n```", "```py\n>>> import tensorflow.experimental.numpy as tnp\n\n>>> tnp.experimental_enable_numpy_behavior() \n```", "```py\n>>> x = tnp.random.random([5])\n>>> x[:5] += 10\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment \n```", "```py\n$ pip3 install pygad \n```", "```py\nimport numpy as np\nimport pygad\n# Combination of number of boards with the prices per board\nstack_prices = np.array(\n    [\n        [1, 10],  # $10 per board\n        [5, 5 * 9],  # $9 per board\n        [10, 10 * 8],  # $8 per board\n        [25, 25 * 7],  # $7 per board\n    ]\n)\n\n# The minimum number of boards to buy\ndesired_boards = 67\n\ndef fitness_function(solution: numpy.ndarray, solution_index):\n    # We can't have a negative number of boards\n    if (solution < 0).any():\n        return float('-inf')\n\n    # Make sure we have the minimum number of boards required\n    total_area = stack_prices[:, 0] * solution\n    if total_area.sum() < desired_boards:\n        return float('-inf')\n\n    # Calculate the price of the solution\n    price = stack_prices[:, 1] * solution\n    # The fitness function maximizes so invert the price\n    return - price.sum() \n```", "```py\ndef print_status(instance):\n    # Only print the status every 100 iterations\n    if instance.generations_completed % 100:\n        return\n\n    total = 0\n    solution = instance.best_solution()[0]\n    # Print the generation, bulk size, and the total price\n    print(f'Generation {instance.generations_completed}', end=' ')\n    for mp, (boards, price) in zip(solution, stack_prices):\n        print(f'{mp:2d}x{boards},', end='')\n        total += mp * price\n    print(f' price: ${total}') \n```", "```py\nga_instance = pygad.GA(\n    num_generations=1000,\n    num_parents_mating=10,\n    # Every generation will have 100 solutions\n    sol_per_pop=100,\n    # We use 1 gene per stack size\n    num_genes=stack_prices.shape[0],\n    fitness_func=fitness_function,\n    on_generation=print_status,\n    # We can't buy half a board, so use integers\n    gene_type=int,\n    # Limit the solution space to our maximum number of boards\n    gene_space=numpy.arange(desired_boards),\n    # Limit how large the change in a mutation can be\n    random_mutation_min_val=-2,\n    random_mutation_max_val=2,\n    # Disable crossover since it does not make sense in this case\n    crossover_probability=0,\n    # Set the number of genes that are allowed to mutate at once\n    mutation_num_genes=stack_prices.shape[0] // 2,\n)\n\nga_instance.run()\nga_instance.plot_fitness() \n```", "```py\n$ python3 T_02_pygad.py\nGeneration 100  3x1, 1x5, 6x10, 0x25, price: $555\nGeneration 200  3x1, 0x5, 4x10, 1x25, price: $525\n...\nGeneration 900  2x1, 1x5, 1x10, 2x25, price: $495\nGeneration 1000  2x1, 1x5, 1x10, 2x25, price: $495 \n```", "```py\nP(rain) = The probability of rain\nP(thunderstorm) = The probability of a thunderstorm\nP(rain | thunderstorm) = The probability of rain given that there is a thunderstorm \n```", "```py\nimport collections\n\nfrom matplotlib import pyplot as plt\nfrom sklego import datasets\n\nX, y = datasets.load_penguins(return_X_y=True)\ncounter = collections.Counter(y)\nplt.bar(counter.keys(), counter.values())\nplt.show() \n```", "```py\nimport tpot\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    some_data, some_target, train_size=0.75, test_size=0.25)\n\ntpot = tpot.TPOTClassifier(verbosity=2, max_time_mins=10)\ntpot.fit(X_train, y_train)\ntpot.export('optimized_classifier.py') \n```"]