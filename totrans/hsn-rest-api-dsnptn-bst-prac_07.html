<html><head></head><body>
        

                            
                    <h1 class="header-title">RESTful Service Composition for Smart Applications</h1>
                
            
            
                
<p>Through the leverage of edge and digitization technologies and tools, all kinds of tangible elements in our personal, social, and professional environments are digitized. That is, these are becoming computational, communicative, sensitive, perceptive, responsive, and active. Digitized elements are also called smart objects or sentient materials. Further on, all sorts of embedded systems in everyday places (such as homes, hotels, and hospitals) are getting networked through a variety of communication and data-transmission protocols. Hence, the combination of digitized entities and networked embedded systems make our environments intelligent, which are typically self-, surrounding-, and situation-aware. Another noteworthy trend is that all of these empowered artifacts are increasingly integrated with remotely-held (cloud) applications, services, and data sources in order to be appropriately strengthened in their operations, output, and offerings. There are a number of integration and brokerage platforms, adapters, connectors, drivers, and plug-ins that enable <strong>device-to-device</strong> (<strong>D2D</strong>) and <strong>device-to-cloud </strong>(<strong>D2C</strong>) integration. This strategically-sound transition ultimately enables them to be innately smart in their actions and reactions. And this grandiose and technology-inspired transformation of everyday elements and entities in our daily environments leads to the timely formulation and delivery of service-oriented, event-driven, insight-filled, cloud-enabled, fault-tolerant, mission-critical, multifaceted, and people-centric services. The role of the powerful RESTful paradigm in building and providing these kinds of advanced and next-generation services is steadily growing.</p>
<p>This chapter is specially crafted to tell you all about the contributions of the RESTful services paradigm toward designing, developing, and deploying next-generation microservices-centric and enterprise-scale applications. It looks at how RESTful services that are capable of finding and binding with one another result in process-aware, business-critical, and people-centric composite services.</p>
<p class="mce-root"/>
<p>This chapter will cover the following topics:</p>
<ul>
<li>The need for service composition</li>
<li>The various compositions methods (orchestration and choreography)</li>
<li>The orchestration method</li>
<li>The choreography method</li>
<li>The hybrid version of orchestration and choreography towards smarter applications</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<ul>
<li>This chapter is primarily a chapter with a lot of theoretical information</li>
<li>Readers have to be familiar with the Java language and platform</li>
<li>A simple service-composition example is fully developed and deployed in this book's GitHub repository</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Briefing RESTful microservices</h1>
                
            
            
                
<p>Without an iota of doubt, we're heading toward the promised knowledge era. Every common and casual thing in our everyday environment is being meticulously stuffed with the right and relevant intelligence in order to be adaptive, assistive, and adroit in its operations, output, and offerings. That is, all kinds of physical, mechanical, and electrical systems in our personal, professional, and social environments are systematically tuned to be digitized entities and elements. They gain the required knowledge through a host of noteworthy technological advancements, which are being brought in through the application of proven and potential digitization and edge technologies. The faster maturity and stability of information, communication, sensing, perception, vision, analytics, decision-enabling, and actuation technologies contribute immensely to the realization of intelligent solutions, systems, and services.</p>
<p>Fast-evolving digital technologies include state-of-the-art IT infrastructures, such as software-defined clouds, integrated platforms for big and fast data, streaming and IoT data analytics, the mobile-enablement of every enterprise system, the futuristic <strong>Internet of Things</strong> (<strong>IoT</strong>), the mesmerizing blockchain technology, and the pervasive <strong>software as a service</strong> (<strong>Saa</strong><strong>S</strong>) phenomenon. The well-known edge technologies include disappearing sensors, actuators, multifaceted micro- and nano-scale electronics, miniaturized stickers, pads, tags, barcodes, chips, controllers, specks, beacons, and LEDs.</p>
<p class="mce-root"/>
<p>The seamless combination of digital and edge technologies enables the mandated disruption, innovation, and transformation to dynamically and dexterously tend toward the IT vision, which is all about creating smarter homes, hotels, and hospitals.</p>
<p>The emergence of the <strong>microservices architecture</strong> (<strong>MSA</strong>) is being touted as the most interesting and inspiring thing for business and IT organizations across the globe. Currently-running web, cloud, and enterprise applications are being redesigned, refactored, and remedied using microservices in order to be flexible and futuristic. Further on, all kinds of devices, such as mobile devices (cellphones, smartphones, digital assistants, and tablets), handhelds, wearables, implantables (such as sensors and actuators), portables (laptops), fixed, nomadic, and edge/fog devices are also being empowered through microservices. That is, every digitized and connected device is being presented as microservices to the outside world. All of the device deficiencies and differences are being taken care of by this sort of service-enablement. As usual, every microservice is being stuffed with well-intended RESTful APIs. Hence, there's a separation between interfacing and implementation, which is technology-agnostic.</p>
<p>This chapter will look at how microservices enabled with RESTful interfaces are to be orchestrated and choreographed to formulate high-end and process-centric services.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Demystifying the MSA style</h1>
                
            
            
                
<p>There are some crucial requirements to ensure business agility and automation through the smart leverage of the distinct advancements in the <strong>Information and communication technologies</strong> (<strong>ICT</strong>) space. The necessary IT requirements include maximizing team autonomy, optimizing development speed, providing flexibility without compromising on consistency, fulfilling resiliency, and easing up on maintenance. There are agile programming models and techniques to speed up the process of writing code for software applications, but designing and delineating application components in an elegant and extensible manner is vital to the intended success of software applications in the long run. There shouldn't be any vendor lock-in. Any technology and tool can be leveraged to produce and sustain application modules. Also, application components have to be modular in order to be right and relevant for enterprises, which are increasingly service-oriented, customer-centric, adaptive, and productive. Also, application components have to be publicly-discoverable, network-accessible, interoperable, and composable. Hence, the concept of MSA has started to flourish with the proper nourishment from worldwide IT experts. Microservices are fine-grained, horizontally-scalable, independently-deployable, API-driven, usable and reusable, portable, and technology-agnostic.</p>
<p class="mce-root"/>
<p>With the containerization movement picking up steadily, it's easy to have containerized microservices, the images of which can be downloaded and committed to be executable insight containers, which emerge as the most optimal runtime platform. As indicated earlier, microservices can be composed (orchestrated and choreographed) to create composite, process-aware, and business-critical applications. Container orchestration links multiple containerized microservices to create better and bigger containerized applications. Now, in order to manage containers—which are typically large in number in a typical IT environment—containerization orchestration platforms, such as Kubernetes, Swarm, and Mesos, are gaining popularity. With the availability of competent technologies and tools, containerized cloud environments are being set up by enterprises and cloud service providers to host, run, and manage microservices-centric containerized applications. Hence, legacy applications are being partitioned to be a collection of microservices, and there are platforms and infrastructures in order to run them. That is, large, monolithic applications are being cloud-enabled in order to reap the strategically-sound benefits of cloud environments and the powerful microservices architecture pattern.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The advantages of microservices</h1>
                
            
            
                
<p>The surging popularity of microservices is due to multiple reasons. First of all, microservices strictly follow the single responsibility principle. That is, microservices do things one at a time but do it well. The MSA pattern mandates that different responsibilities need to be placed in different services. These fine-grained and self-contained microservices offer a number of unique benefits. The cost of developing, changing, and advancing is cheap, and the time to market is minimal. Each service runs in its own process space and is being stuffed with its own data store. Every service has to be bestowed with an easy-to-understand and should use APIs. RESTful APIs are the most popular for API-enabled microservices. The services talk to one another through API calls. To craft and sustain business-critical and enterprise-grade applications, multiple microservices have to be blended together. Microservices are modular (loosely coupled and highly cohesive). The lightly- or loosely-coupled microservices do away the dependency-associated risks and drawbacks. On the other hand, the closely-related responsibilities of a software module are kept together.</p>
<p>Each microservice implements a distinct business functionality and hence has a small code base. Therefore, it's easy and quick for service developers to bring in any desired changes. Also, microservices facilitate simplified and streamlined software design. Microservices can also be given to testers and users for initial verification and validation.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Microservices fulfill the varied goals of the agile design and development of software applications. Further on, as we've discussed legacy modernization in another chapter of this book, microservices emerge as the best fit for modernizing and migrating large, monolithic applications. Microservices easily leverage all of the innate competencies of cloud environments to produce and sustain next-generation applications, which are mandated to be agile, adaptive, and adroit.</p>
<p>Furthermore, the nimbleness, simplicity, and astuteness of microservices elevates them to be the most competent unit to build and deploy business-critical workloads. Also, because of its small size, there's a lower likelihood of introducing errors into the source code and it's easy to troubleshoot microservices and their combinations. Hence, there are a number of businesses, technical and user advantages of microservices architecture. Experts continuously publish a variety of best practices to leverage the unique capabilities of MSA in a highly beneficial manner. As software applications are becoming more integrated and hence complicated, the soothing experience of MSA is helpful in delegating the development, deployment, and operational complexities. MSA, if used intelligently, offers a litany of strategic advantages; the noteworthy ones include the agile design of applications, the support for both cloud-enabled and native software applications, and the enabling of the separation of concerns.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The emergence of cloud-native applications</h1>
                
            
            
                
<p>The MSA pattern emerges as the most efficient tool for creating and sustaining software applications. In order to benefit in the long run, enterprises are strategizing on two things—empowering currently-running applications to be microservices-centric, and migrating those remedied applications to be hosted in cloud environments (private, public, and hybrid). That is, applications are becoming cloud-enabled through the leverage of MSA.</p>
<p>With the pervasiveness of cloud centers, software engineers and architects are designing, developing, and deploying microservices-centric applications in cloud environments. This scenario is being touted as cloud-native applications. Precisely speaking, in order to decisively reap all of the originally envisioned benefits (business, technical, and user), applications are being designed through microservices, developed using one of the integrated development platforms and frameworks, and deployed in cloud environments. The microservices-based software design is faster than the traditional, agile programming models, and methods are made available in plenty to speed up the process of software construction.</p>
<p class="mce-root"/>
<p>The continued adoption of enterprise DevOps tools and processes accelerates the continuous integration, delivery, and deployment of software applications, and the emergence of <strong>site-reliability engineering</strong> (<strong>SRE</strong>) concepts bring forth additional automation and acceleration for software engineering. Hence, the future belongs to cloud-native applications. That is, all kinds of enterprise, mobile, social, embedded, transactional, operational, and analytical applications are being built as cloud-native applications.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The growing ecosystem of IoT device services</h1>
                
            
            
                
<p>We talked about business-specific and agnostic microservices, which are increasingly containerized. The container images of any software can be uniformly packaged, quickly shipped, and easily deployed across any software platforms to run and deliver their functionalities without any hitch or hurdle. With the rapid growth of a variety of purpose-specific and agnostic devices, there's a continued rise of device services, which are MSA-compliant. We have a variety of devices, such as medical instruments, robots, drones, wares, utensils, appliances, consumer electronics, and machines, which are gradually being connected in order to join in the mainstream computing arena. Leading market analysis and research reports forecast that there will be billions of connected devices in another one to two years.</p>
<p>The various functionalities of connected devices are being exposed via service interfaces. The service paradigm could fulfil the much-needed interoperability among different and distributed devices. That is, every device is being projected as a findable, flexible, and usable service. The robustness, versatility, and resiliency of microservices come in handy when presenting devices as services to the outside world, which eliminates all kinds of dependency-induced challenges.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The changing application ecosystem</h1>
                
            
            
                
<p>Mainframe-era applications are typically monolithic and massive. They are centralized, inflexible, closed, and expensive to maintain. Then, we came across client-server and multi-tier distributed applications. There are business-domain-specific applications that solve specific problems. There are web, cloud, social, enterprise, mobile, wearable, and IoT applications. Then, there are operational, transactional, and analytical applications. With the solidity of microservices, all kinds of software applications get disintegrated into a number of microservices, which are very famous for facilitating easy integration, deployment, management, and manoeuvrability. Microservices are self-defined and hence autonomous.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>They can be developed and deployed independently. Microservices are being stuffed with their own data stores. Microservices are decoupled, so dependency issues don't crop up. However, to create and sustain bigger and better applications, different and geographically-distributed microservices need to be found and fused systematically. That is, services should be matched and composed to realize composite applications, which are right and relevant for enterprise and cloud IT. Not only for enterprise applications but also for creating integrated and insightful applications, the act of composition acquires special significance.</p>
<p>Composition is being accomplished in two prominent ways—orchestration and choreography. As mentioned in the <em>The emergence of cloud-native applications</em> section, there are domain-specific and neutral applications that innately need the blending of multiple microservices to fulfil varying business requirements, market sentiments, and user expectations. In short, the composition of microservices deserves the highest recognition for producing smarter applications towards user-empowerment. Hence, to realize all kinds of smart applications, API-stuffed, extensible, configurable, interoperable, and composable microservices are the need of the hour. Composition tools and techniques are flourishing, and hence service composites are the best fit for constructing insight-driven, highly sophisticated, and integrated applications that can run on any runtime (bare-metal servers, virtual machines, containers, and functions). In addition, the future calls for device-centric cloud environments, which are aptly termed fog or device clouds. Microservice composites can run not only on resource-intensive servers but also on resource-constrained and networked devices, which is the real beauty of microservices.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Tending toward the API-driven world</h1>
                
            
            
                
<p>Integration and collaboration are important needs for software to achieve business processes. Old and modern software applications run on multiple kinds of IT platforms and infrastructures. Software solutions automate most business processes. However, business applications have to spontaneously synchronize with other software packages in order to bear fruit. Processes, applications, and data have to be integrated to guarantee a comprehensive yet compact view for executives and end users. Communication is the key. APIs are the widely-recognized mechanism for software components to find one another to interact with in a systematic manner. APIs are being created and supplied with any kind of software, including web and cloud applications, databases, middleware, and platforms. The current internet paradigm is steadily expanding. Once upon a time, the internet was the network of networked computers. That is, all kinds of computers (both clients and servers) were networked to share their unique capabilities.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>These days, not only computers but also our communicators and consumer electronics, such as smartphones, <strong>personal digital assistants</strong> (<strong>PDAs</strong>), tablets, laptops, handhelds, and communication gateways, are also joining the internet. Precisely speaking, the <strong>internet of devices</strong> (<strong>IoD</strong>) paradigm is fast emerging and evolving.</p>
<p>All kinds of personal and professional devices, instruments, appliances, and machines are getting connected to the internet; all kinds of common and cheap things in our everyday environments are getting digitized with the help of scores of digitization and edge technologies and tools in order to be sufficiently empowered to join mainstream computing. Everyday items are becoming computational, communicative, sensitive, responsive, and active with the appropriate enablement of powerful and pioneering technologies. Now, with the faster stability of service-engineering techniques, we see the world as the <strong>Internet of Services</strong> (<strong>IoS</strong>). That is, everything is expressed and exposed as a service for the outside world. All kinds of software and hardware systems, including embedded systems, are being presented as a collection of publicly-addressable and-available services. This is ultimately helping to hide systems' complexities and deficiencies.</p>
<p>At one end, we see an increased number of hardware systems (IT infrastructures), software applications and services, data sources, and scores of platforms in the internet space. However, creating and sustaining APIs for these kinds of internet-attached systems, applications, and services isn't an easy task. At the other end, we have a variety of digitized, embedded, networked, handy, trendy, slim, and sleek I/O devices. Hence, in order to establish a beneficial link between the ground-level systems and the faraway internet-hosted systems, APIs are the way forward. In short, the RESTful service paradigm comes as a solace by simplifying and streamlining API creation and usage for systems integration and collaboration.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Representational State Transfer service paradigm</h1>
                
            
            
                
<p>RESTful services assist in establishing a beneficial relationship between computers and other I/O devices with internet-based systems, applications, and data sources. The RESTful API uses the pervasive HTTP methods to perform the most common actions (<kbd>GET</kbd>, <kbd>PUT</kbd>, <kbd>POST</kbd>, and <kbd>DELETE</kbd>). <strong>Representation State Transfer</strong> (<strong>REST</strong>) is a promising and potential architectural style for designing loosely-coupled applications over HTTP. RESTful services are the simplest and most sought-after services that blend well to result in web, mobile, cloud, and IoT applications.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">API design best practices</h1>
                
            
            
                
<p>When creating APIs, the following <strong>non-functional requirements</strong> (<strong>NFRs</strong>) and the <strong>quality of service</strong> (<strong>QoS</strong>) attributes need to be given utmost importance in order to develop flexible APIs. The most popular ones include performance/throughput, scalability, simplicity, modifiability, portability, and reliability. These qualities can be achieved if APIs are being prepared based on the constraints. Here is a list of the most crucial constraints:</p>
<ul>
<li><strong>Client-server architecture</strong>: This essentially prescribes that the client and server applications should be able to evolve independently. A client has to know only resource URIs. There shouldn't be any other dependency between the client and the server systems. Therefore, the design of the client and server interfaces can be done separately. This constraint gives developers much-needed flexibility as the same API can be leveraged across multiple backend server and database systems. The APIs can be easily changed to accommodate special requirements without making any destructive impact on others.</li>
<li><strong>Cache-ability</strong>: As we all know, caching is the age-old practice of storing copies of frequently-accessed data in multiple locations along the request-response path. When a client asks for a resource representation, the request typically goes first to the nearest cache to get the data. If the desired data is not found in the local cache, the next destination for the client request is the proxy cache or the reverse cache of the requested resource. If none of the caches have the latest data/fresh copy, there's no other option but to knock the resource itself. Optimizing the network using caching reduces latency, optimizes bandwidth usage, reduces the load on servers, and hides any network failure.</li>
</ul>
<p>There are other constraints, which are explained in other chapters in detail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Learning about service-composition methods</h1>
                
            
            
                
<p>Orchestration and choreography are the well-known and widely-used ways of accomplishing composite services. With the containerization movement picking up, microservices are being containerized and run in cloud environments. With the adoption of container-orchestration platforms, multi-container applications are being easily and quickly realized. Hence, composite applications are being realized at the service level and at the container level. Microservices are, for getting composed, having to find and bind with other microservices in order to accomplish greater goals and reach bigger targets. A simple example is that, when a new service gets registered in the service registry, it has to call a couple of other services, such as authentication and authorization services. Depending on use cases, services may need to interact with more services in order to be relevant to their stakeholders and subscribers.</p>
<p class="mce-root"/>
<p>As indicated elsewhere, every microservice is stuffed with its own data source. Every microservice is enabled with its own one or many interfaces. Due to the surging popularity and simplicity exhibited by the RESTful service paradigm, the majority of APIs are RESTful APIs. The following diagram vividly illustrates the following. There are several microservices in the server side and a client is accessing one or more services. For the idea of microservices to flourish, services need to be dynamically integrated in order to facilitate service interactions purposefully:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/4696c58c-ef87-4f82-9578-44ff53fe1f40.png"/></p>
<p>There are a few important challenges here. The calling service doesn't know whether the serving services are doing well. The services being requested can be overburdened due to an unprecedented number of service requests. The service performance, health condition, and security information are not known to calling services. Also, there are no failure-handling and compensation mechanisms here. When multiple services are being involved for business processes and transactions, it's important to know which part of the data and control flow faces the problem. The root of the problem has to be identified in order to streamline troubleshooting.</p>
<p>Further on, these kinds of interactions happen through tight coupling, but tight coupling can lead to dependency issues. This is why lightly- and loosely-coupled services are preferred: so that the development and deployment can be done independently. Also, service interactions don't produce any issues. RESTful APIs are the method for service collaboration.</p>
<p>Any change being made on one service has cascading implications; the operational complexities of service environments are bound to escalate as more services join. Hence, experts have come out with competent alternatives that solve these bad implications by invoking tightly-coupled services.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Service orchestration and choreography</h1>
                
            
            
                
<p>Orchestration microservices have to be composed through an orchestration engine. The composition has to happen through predefined patterns, which are typically described using an orchestration language. Orchestration is more suitable and relevant for implementing business process flows. A competent and standards-compliant orchestration engine immensely contributes as a central brain to guide and guarantee the control flows and their execution. The policies/business rules are being managed and manipulated through the orchestration engine in a centralized manner. The 360-degree view of an application flow is delivered through the orchestration engine. The service and operational-level agreements (SLAs/OLA) are estimated and codified through the centralized engine. Simplistically speaking, all of the centrally-managed and commonly-used functionalities are being abstracted out of participating services and are being incorporated in the orchestration engine, which also has a business process flow and management engine.</p>
<p>Service chaining and workflows, widely termed as service orchestration, are helping out in legacy and enterprise application integrations:</p>
<ul>
<li><strong>Short-running orchestrations</strong>: These are stateless and synchronous besides dealing with momentary data and sessions. They are a kind of request and response type. They talk to multiple services in a sequenced manner. Based on the output of the first service, the orchestrator forms an appropriate message for the second service, and so on.</li>
<li><strong>Long-running orchestrations</strong>: These are typically stateful and asynchronous. These involve human involvement, interpretation, and instruction and are made to run for longer by leveraging persistent data storage.</li>
</ul>
<p>There are a few drawbacks too. There's a kind of tight coupling being established between the orchestrator and all of the associated application components/services. Adding new services and states mandates for an update in the central business logic. The central coordinator sometimes emerges as a single point of failure.</p>
<p>Choreography, on the other hand, implements a data flow between multiple decoupled services. Each service knows what sort of data it can expect and provide. There is no need for a centralized conductor to run the flows. This is all about peer-to-peer service composition. Each service is stuffed with the required intelligence to act and react. Each microservice is a self-defined and contained service, and each microservice communicates and completes the assignment via messages and events. <strong>Event-driven architecture</strong> (<strong>EDA</strong>) is emerging as the core architectural style and pattern for the increasingly event-driven world. Choreography is more suitable for implementing event-driven applications. Due to their decoupled nature, microservices can be replaced and substituted with better service implementations.</p>
<p class="mce-root"/>
<p>Additional services and their instances can be incorporated without affecting the system. New technologies and algorithms can be leveraged easily. All kinds of service dependencies and their negative implications are getting eliminated. The single point of failure is not there in the choreography-based service composition. However, there are a few drawbacks. Without a central conductor or coordinator, the monitoring, measuring, and management of service interactions and collaborations remain a challenge. That is, looking at a sequenced view of services that talk to one another is problematic. Empowering every microservice to be self-reliant and intelligent in their actions and reactions is tough, and bringing forth business-mandated and technology-enabled advancements across the participating services is a bit difficult. Choreography facilitates scalability and a shared-nothing architecture. Hence, experts and exponents are of the view that, by combining these two architectural styles, most of the emerging application scenarios can be elegantly tackled.</p>
<p>As we all know, business processes are becoming complex due to various reasons as days go by. Though a process consolidation toward optimization happens on one side, business processes continuously grow to become complicated and long-running. Processes also have to involve geographically-distributed and different microservices. Hence, process governance and management become painful. As the number of contributing microservices is growing rapidly, the number of fine-grained interactions among microservices is bound to increase exponentially. Hence, there are technology-sponsored solutions and best practices that surmount the lingering issues of microservices and their interactions. The main methods are orchestration and choreography. The subsequent sections describe their needs, key drivers, capabilities, and how to use them.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Beginning with service orchestration</h1>
                
            
            
                
<p>Business processes are being accomplished through a variety of service implementations. However, there's a sequence for involving services. Typically, a business process indicates the sequence of services to be leveraged. Orchestration is a way for service composition through a centralized coordinator. This coordinator/brain guides and fulfils the business process requirements, just like a conductor in an orchestra—he/she leads the team as the central authority. By employing such an intermediary among different microservices, the issues that come from tight coupling go off once for all. That is, we get loosely-coupled microservices and they don't need to know each other. They also don't need to know whether other services are running. The communication can be mainly synchronous. That is, the requesting services should wait until they get the response from the requested services. </p>
<p class="mce-root"/>
<p>There is one controller or coordinator that acts as the service orchestrator. That is, all of the service interactions happen via the orchestrator. This follows the well-known interaction:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/bac759af-ebef-4080-b0ea-2f11fdb15019.png" style="width:24.25em;height:13.33em;"/></p>
<p>For example, we need two or more services to be involved and invoked to accomplish a business process. The sequence of calling is also important here. The orchestrator makes a call to each one and waits for a response from the requested service. Once the response reaches the orchestrator, the next service in the sequence has to be called out, and so on. Check out <a href="https://medium.com/capital-one-developers/microservices-when-to-react-vs-orchestrate-c6b18308a14c">https://medium.com/capital-one-developers/microservices-when-to-react-vs-orchestrate-c6b18308a14c</a> for more information.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The shortcomings of service orchestration</h1>
                
            
            
                
<p>This is a good way to have tighter flow control when there's a need for synchronous communication and processing. There are a few drawbacks with this—if the first service isn't responding, the other services can't be called. That is, it creates a kind of coupling that results in unwanted dependency issues. The orchestrator becomes the single point of failure, and hence the recommendation is to go for clustered orchestration. Synchronous communication blocks other service requests.</p>
<p class="mce-root"/>
<p>The following diagram illustrates how the orchestration process gets accomplished through the participation of disparate and geographically-distributed microservices:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/ae5ed59e-bc88-473a-a31d-434c7e9e8693.png" style="width:41.75em;height:23.67em;"/></p>
<p>This composition model typically doesn't address failure cases. Most of the time, the service request is being attended. The failure rate is mostly one percent. The best practice is that if there is a failure, one or other viable counter measures, such as compensation, has to be initiated immediately in order to wriggle out of the chaos. The retry and repair activities are the other mechanisms to ensure business continuity. Data and disaster-recovery capabilities have to be in place to reduce the data loss in order to maximize business profits. Considering the drawbacks of service orchestration, the service choreography (this is explained in detail in the subsequent sections) is gaining a lot of attention.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Applying orchestration-based composition</h1>
                
            
            
                
<p>If most of the works have to be done in a sequential manner (if there is zero possibility for parallel execution), orchestration is the way to go. If there's a need to keep the control flow logic centralized, orchestration is the way forward. If there are hundreds of microservices participating with different control flows, centralization is preferred. The mantra of distributed deployment and centralized management is getting fulfilled through orchestration. If the decoupling is not a strict mandate, the orchestration method is the widely-used one.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Beginning with service choreography</h1>
                
            
            
                
<p>When building a microservices-centric applications, the service dependencies have to be nipped in the budding stage itself. Orchestration leads to dependencies, which are bad in the long run. Hence, all kinds of dependencies have to be avoided to fulfil the strategic vision of self-defined and autonomous microservices. Experts contend that EDA is the way forward for solving some of the challenges previously quoted. That is, the controlling logic is being stuffed in the orchestrator module, whereas in this case, the logic is inscribed in each of the participating services; the logic is distributed and these empowered services (smart services) know beforehand how to react to various events. The communication is asynchronous and an event bus (dumb pipe) is being leveraged to route events. This means multiple services can consume the same events and then initiate their ordained tasks. The results are then packaged and transmitted as events back to the event bus at the same time. As previously noted, these microservices are called <strong>smart entities</strong> and the event bus is just a dumb pipe. No intelligence is embedded in the event bus, which is the primary communication infrastructure for event-driven microservices.</p>
<p>The asynchronous nature removes the blocking or waiting, which is the main drawback of orchestration. Services, on receiving events, can produce other events, which are looped back to the event bus to be consumed by other services to do their assigned works. This sort of decoupling is demanded in the microservices world.</p>
<p>The following diagram shows how the event-driven architecture pattern functions:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/d7f4bde3-2a8a-4606-83e1-c136ce097717.png" style="width:28.17em;height:25.00em;"/></p>
<p>Hence, event producers and consumers, without knowing anything about others, collaborate in a purpose-driven manner. Due to parallel processing (many services receive the event and go ahead with their processing), faster processing by services is ensured. Newer services can easily join and contribute without impacting others. The existing services can be easily manipulated to accommodate business, technology, and user changes, which are, without an ounce of doubt, the new normal. Microservices can be independently developed and deployed, and this empowers different and distributed development teams to focus on their core activities toward the faster realization and deployment of microservice-centric applications. An event stream stores all of the events. Suppose a service goes down while events are still being produced; after some time, the service comes back to life, gets back all of the missed events, and acts upon them. Also, this EDA, a kind of reactive architecture, enables us to separate out the read and write activities. That is, both of these activities can be independently accomplished. The advantage of this segregation is that they can be independently scaled based on the evolving requirements. The application is read-heavy, then that part can be scaled alone without any impact on the write part.</p>
<p>With choreography, the services are accordingly empowered to act and react as per the evolving situation. Services behave like dancers—performing their assigned movements to appropriately react to other dancers, so as to finish the process in an organized way.</p>
<p>Primarily, the choreography concept depends on the popular EDA. The choreographed services typically react to events and put their output onto the queue of the event bus, and from there, other authorized services pick up and start to showcase their unique capabilities. <strong>Event Bus</strong> is the primary intermediary and communication infrastructure. This is illustrated in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/e6d40e80-595b-439f-b961-f83482896a63.png" style="width:52.00em;height:29.42em;"/></p>
<p>Services don't need to talk to other services in order to initiate and implement an action. Services are waiting for some events to get initiated somewhere and get forwarded to them through the event bus, which is the primary messaging middleware/broker/bus.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">The shortcomings of service choreography</h1>
                
            
            
                
<p>Systems that are choreographed are loosely coupled, highly flexible, and easily amenable to changes (internal as well as external). As an example, let's consider an order application. Using the reactive architecture (event-driven choreography), the flow can be represented as follows (this is taken from <a href="https://blog.bernd-ruecker.com/why-service-collaboration-needs-choreography-and-orchestration-239c4f9700fa">https://blog.bernd-ruecker.com/why-service-collaboration-needs-choreography-and-orchestration-239c4f9700fa</a>):</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/657b2837-a326-4f08-81e5-687d9898a1d8.png" style="width:48.92em;height:35.50em;"/></p>
<p>The payment service is destined to react to the order-placed event. The issue here is that the payment service has to know its consumer. If any other service needs the payment service, we need to make the changes in the payment service. Now, there's a new addition in the business requirement. The addition is that VIP customers can pay later by invoice. This change is to affect multiple components. The payment service has to execute payments for non-VIP customers only.</p>
<p>The inventory service also has to react on the order-placed event, but only for VIP customers. The following diagram explains this process:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/452b9ebe-df47-4669-8963-95e9d04f5fb3.png" style="width:40.08em;height:16.00em;"/></p>
<p class="CDPAlignCenter CDPAlign">This requires the introduction of an additional component that brings in a clear separation between <strong>Service A</strong> and its users. This is called the <strong>event-command-transformation pattern</strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/62dd6aff-3c9f-4d30-ac17-a51a50e0fe6b.png" style="width:41.25em;height:11.92em;"/></p>
<p>The event-command-transformation pattern is ultimately helping to realize decoupled event-based systems.</p>
<p>The second hurdle is that the payment service might take longer to complete. Customers have to clear their payments and this may take days or weeks. This is a long-running process flow and it's mandatory to track the state. It clearly bats for an orchestrated style of collaboration. Hence, the blending of orchestration and choreography is the best way for pitching in highly flexible architecture for composite applications.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Applying choreography-based composition</h1>
                
            
            
                
<p>Choreography helps to accomplish business processes in a parallel manner. It's possible to change the process by adding, relegating, replacing, substituting, and decommissioning process components. If all or most of our processing can be performed in an asynchronous manner, this composition method is the best fit. Parallel execution is the main motivation of the reactive architecture. As previously indicated, the flow logic is typically distributed in this method. And if this decentralization is manageable, the choreography method is good. To create a centralized and consolidated view for monitoring, measurement, and management, the best option is to use correlation IDs.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The hybridization of orchestration and choreography</h1>
                
            
            
                
<p>We've seen that both of the composition methods have pros and cons. That is, with software platforms and packages becoming more distributed, integrated, and complicated, there's no one architectural style that is a perfect fit in all situations. Therefore, IT professionals have come out with the hybrid versions of orchestration and choreography to overcome these limitations.</p>
<p>The first hybrid pattern uses reactive (event-driven) between services (choreography for inter-service communication) and orchestration within a service (intra-service communication). In the following diagram, we have three services: A, B, and C. These are event-driven and reactive to one another via the event bus. <strong>Service A</strong> consumes an event and gets triggered to orchestrate calls to the services D, E, and F. These calls can be synchronous or asynchronous. Then, on getting the result from the services, <strong>Service A</strong> produces an event:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b0d30881-5f3a-403f-8bf8-a0aec2ae6bf3.png" style="width:29.00em;height:32.92em;"/></p>
<p>The A, B, and C services are decoupled. However, the D, E, and F services within <strong>Service A</strong> are coupled. This means if these services are doing synchronous processing, the blocking surfaces here. The event bus facilitates asynchronous processing among the A, B, and C services. Each service (A, B, and C) is stuffed with the control logic to exhibit an independent behavior. That is, the logic is typically distributed across multiple services, whereas the control, flow, and other horizontal capabilities are being centralized in the case of the orchestrator.</p>
<p><em>The second hybrid pattern</em> uses reactive (event-driven) between services and a coordinator (reactive orchestrator) to assist the flow. In this example, it leverages the concepts of commands and events. As shown in the following diagram, the coordinator produces commands to the event stream, and the microservices that are empowered to act for the particular commands receive the command, do the desired processing, and then create and pass on the events to the event stream.</p>
<p class="mce-root"/>
<p>In this example, services A and C start at the same time, and the coordinator consumes the generated events from the event stream and reacts to the events accordingly:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/15617688-400a-489f-858a-ed0703a6992d.png" style="width:32.00em;height:25.67em;"/></p>
<p>The services are generally decoupled, yet still there's a kind of coupling between the services and the coordinator. That is, the coordinator has to know what commands a service needs to get in order to react correctly. Events between services lead to asynchronous processing. The overall flow logic is stuffed in the reactive coordinator. The coordinator, as usual, is a single point of failure.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Another example of the hybridization of orchestration and choreography</h1>
                
            
            
                
<p>Here is another interesting example, taken from <a href="https://dzone.com/articles/event-driven-orchestration-an-effective-microservi">https://dzone.com/articles/event-driven-orchestration-an-effective-microservi</a>.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Choreography</h1>
                
            
            
                
<p>As shown in the following diagram, a process is getting initiated by an event from a user. The process is then accomplished by the respective microservices collectively in a choreography mode. This method ensures light coupling and high cohesiveness:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/71fd7a90-bede-4e05-99f8-398bc0597564.png"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Service choreography using the message broker</h1>
                
            
            
                
<p>There are a few important drawbacks with this approach. Choreography typically enables a decentralized approach and hence all the participating services need to be embedded with the relevant business-processing logic. Any business- and communication-logic changes have to be shared across all the microservices, and the state information of the process has to be stored separately. There is no centralized service to take care of all of the services. Finally, the strict implementation of the ACID properties isn't possible because of multiple distributed services participate towards the process fulfillment.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Service orchestration</h1>
                
            
            
                
<p>There is another approach found in the web. This is to implement a centralized service orchestration through by integrating the <strong>business process model and notation</strong> (<strong>BPMN</strong>) workflow and REST. The following diagram clearly depicts how a complex <strong>Shopping Cart Microservice</strong> is realized:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/c13b5a6b-5971-45ea-a03a-ff6c6def36ce.png"/></p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Service orchestration using BPMN and REST</h1>
                
            
            
                
<p>As you can see, there are three primitive resource types. The corresponding path details for those resources are also etched in the preceding image. For a monolithic application, the central server would have handled requests for all the resource destinations. Further on, there is a shared datastore that stocks the resources as distinct tables. For complex queries, the much-discussed concept of complex joins comes to the rescue.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">The hybridization – event-driven service orchestration</h1>
                
            
            
                
<p>As shown in the following diagram , the shopping cart service is implemented as an orchestration service using the BPMN workflow. However, all of the various service adapters are being replaced through an out-of-the-box AMQP, but the service adapters are eliminated through a common out-of-the-box AMQP adapter, which is one of the prime components of the AMQP event bus, which is the message broker to decouple the services:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/39e6c39c-5c23-4c98-ab74-02aefd482f1f.png"/></p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Data management </h1>
                
            
            
                
<p class="graf graf--p graf-after--h3">The core philosophy of MSA is the decentralization of software design and development. The decentralization not only guides the organization of business logic but also how data has to be persisted.</p>
<p class="mce-root"/>
<p class="graf graf--p graf-after--p">In a monolithic architecture, application components and data are traditionally centralized. One of the SQL databases, such as SQL server, is used as a single database with multiple tables. This is the way data gets persisted in the previous era. Some portions of the application logic even get delegated to the SQL server database in the form of stored procedures, complex joins, and so on.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Thinking in REST</h1>
                
            
            
                
<p class="graf graf--p graf-after--h3">To correctly and concisely organize data in a decentralized fashion, the RESTful service paradigm comes in handy. That is, the REST concept introduces a new way to model data. There are multiple resources in any application. REST gives each participating resource a URL. Then, the recommendation is to use the standard HTTP verbs to interact with the resource. The author of the article at <a href="https://medium.com/@nathankpeck/microservice-principles-decentralized-data-management-4adaceea173f">https://medium.com/@nathankpeck/microservice-principles-decentralized-data-management-4adaceea173f</a> has come out with a sample API for a small social-messaging application:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/819c5fd3-a0d7-43f7-a017-a3fbadab2d80.png" style="width:57.92em;height:37.33em;"/></p>
<p class="mce-root"/>
<p class="graf graf--p graf-after--figure">There are three primitive resource types—user, message, and friend. There is a set of paths for the resource types, as illustrated in the following diagram. In the case of a monolith application, the central server would handle requests for all of the resource paths and there is a single database that stores all of the resource types as tables:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/5075d9aa-253e-45bb-b6b6-c93b849ba0c3.png" style="width:33.67em;height:17.67em;"/></p>
<p class="graf graf--p graf-after--figure">However, for a microservices-centric application, every microservice has its own database.</p>
<p class="graf graf--p graf-after--figure">This arrangement ensures tighter security for data. That is, every data request, access, and manipulation has to be accomplished through microservice APIs. The philosophy here is that there's a one-to-one mapping between microservices and resource types:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/8980456f-7550-4d13-82f0-6c95569a40fe.png" style="width:34.75em;height:14.33em;"/></p>
<p>Having a unique database/database instance for each microservice brings forth a number of advantages.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Discarding SQL join</h1>
                
            
            
                
<p>A noteworthy tip for better data management is to avoid the SQL join operation. As every database is logically separated in the MSA world, doing SQL join function is very tedious and time-consuming. It's going to be a technical and security nightmare. However, there can be different application requirements. For example, suppose the messaging application mandates for timeline view. That is, the timeline view has to show the most recent message from each friend of the authenticated user. Also, this new view has to show the friend's name and other details along with the message sent.</p>
<p class="mce-root">It's still possible to implement this complicated view using the basic REST API. That is, the client has to employ several API calls to different resources to fulfill this specialized view requirement:</p>
<div><div><img class="progressiveMedia-image js-progressiveMedia-image" src="img/0d747727-c501-4d9f-b43c-1189a5be71ea.png" style="width:28.25em;height:10.25em;"/></div>
</div>
<p class="graf graf--p graf-after--figure">That means there is a total of five requests. This is to degrade the performance. A workaround is to bring forth a new route to the API:</p>
<div><img class="graf-image" src="img/7d93efc3-a4ce-4d15-acd6-0834548ec8e3.png" style="width:43.50em;height:4.50em;"/></div>
<p class="graf graf--p graf-after--figure">The <strong>Client</strong> can then fetch this single timeline resource to get all the data it requires to render the timeline view. That is, it creates an additional timeline microservice that lives on top of the three data microservices. This new microservice treats each underlying microservice as a resource. This top-level microservice joins the data from the underlying microservices and exposes the joined result to the client.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="graf graf--p graf-after--figure">In the microservice era, the localized database operations are being accomplished through a composite microservice: </p>
<p class="CDPAlignCenter CDPAlign"><img src="img/174054f8-77ea-433e-8134-6f51863596d5.png" style="width:52.08em;height:21.42em;"/></p>
<p class="mce-root"/>
<p class="graf graf--p graf-after--figure">The much-discussed performance issue does not creep in here as the timeline service is predominantly hosted in containers along with the other three services. All of these are in the same physical machine or within nearby machines. To further reduce round-trip network penalties, the timeline service could leverage the advantages of <em>bulk fetch</em> endpoints. The user microservice could have an endpoint that accepts a list of user IDs and returns all of the matching user objects. The advantage here is that the newly-carved-out timeline service only has to make one request to the friends service, one request to the user service, and one request to the message service. The timeline service functions as a centralized place to define the logic and this separation facilitates to accommodate any business, technology, and user-inspired changes at later point in time. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Eventual consistency</h1>
                
            
            
                
<p class="graf graf--p graf-after--h3">This is a well-known characteristic of NoSQL databases. This isn't an issue for transactional databases, which are the primary data-persistence mechanism for the centralized architecture. However, when data gets separated into many logical or physical databases, the consistency feature can't be attained easily. </p>
<p class="mce-root"/>
<p class="graf graf--p graf-after--p">For example, consider what would happen if a user fetched their timeline at the same time that one of their friends deleted their account:</p>
<ol class="postList">
<li class="graf graf--li graf-after--p">The timeline service fetches the list of friends from the friend service and sees a friend ID that it needs to resolve</li>
<li class="graf graf--li graf-after--li">Friend deletes the account, which deletes the user object from the user service, as well as all of the friend references in the friend service</li>
<li class="graf graf--li graf-after--li">Timeline service attempts to turn the friend ID into user details by making a request to the user service, but receives a <kbd>404 Not Found</kbd> response instead</li>
</ol>
<p class="graf graf--p graf-after--li">It's clear that decentralized data modeling requires extra conditional handling to detect and handle race conditions where underlying data has changed between requests. For complex applications, it becomes necessary to have some tables together in the same database to fulfill the database transaction. The idea is that these linked tables have to be handled by a single microservice. If related data needs strong consistency, the option is to use the proven <em>two-phase commit</em> mechanism. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Polyglot persistence</h1>
                
            
            
                
<p class="graf graf--p graf-after--h3">Decentralized data management helps to take advantage of polyglot persistence. Different types of data have different storage requirements. We have multi-structured and massive amount that needs batch and real-time processing. For streaming data, there are the following streaming-analytics platforms:</p>
<ul class="postList">
<li class="graf graf--li graf-after--p"><strong>Read/write balance</strong>: Some types of data have a very high write volume. This needs a different type of data store.</li>
<li class="graf graf--li graf-after--li"><strong>Data structure</strong>: Some types of highly-structured data, such as JSON documents, may be better stored and served via a document-oriented NoSQL database. </li>
<li class="graf graf--li graf-after--li"><strong>Data querying</strong>: Some data may be easily accessible using a simple key-value database, whereas other types of data mandate for advanced querying based on the values of multiple columns.</li>
<li class="graf graf--li graf-after--li"><strong>Data life cycle</strong>: Some data is needed for a short time and can be stored in a fast and in-memory database, such as Redis or Memcached, while other data has to be retained for all time and hence stored using durable disk storage. </li>
<li class="graf graf--li graf-after--li"><strong>Data size</strong>: Data size is varies considerably these days. There are object-storage options that accommodate staggering amounts of data. </li>
</ul>
<p class="graf graf--p graf-after--h3 graf--trailing">Hence, data management in the ensuring microservices era is quite different and challenging too. However, data professionals have come out with competent data persistence, representation, interchange, masking, wrangling, management, analytics, and security solutions. </p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>Microservices have to be composed through the orchestration engine. The composition has to happen through predefined patterns, which are typically described using an orchestration language. Orchestration is relevant for implementing business-process flows. A competent and standards-compliant orchestration engine acts as a central brain to guide and guarantee the control flows and their execution. The policies/business rules are being managed and manipulated through the orchestration engine in a centralized manner. The 360-degree view of an application flow is delivered through the orchestration engine. The service and operational-level agreements (SLAs/OLA) are estimated and codified through the centralized engine. Simplistically speaking, all of the centrally-managed and commonly-used functionalities are being abstracted out of participating services and are being incorporated into the orchestration engine, which also has a business-process flow and management engine.</p>
<p>Service chaining and workflows, widely termed as service orchestration, are helping out in legacy and enterprise application integrations.</p>
<p><em>Divide and conquer</em> has been the mantra for moderating the design, development, deployment, and operational complexities of complicated systems. MSA is being positioned as the most efficient and agile design technique. Then there are agile development processes to speed up the realization of microservices. With the faster stability of DevOps concepts and the scores of automated tools accelerate the integration, delivery, and deployment of microservices in cloud environments.</p>
<p>To craft process-centric, business-aware, production-ready, and enterprise-grade applications, microservices should be identified, matched for their competencies and capacities, and composed. There are two composition methods—orchestration and choreography. In the next chapter, we'll explain the best practices for producing effective and extensible RESTful service APIs. </p>


            

            
        
    </body></html>