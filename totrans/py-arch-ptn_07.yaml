- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Twelve-Factor App Methodology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When designing a software system, it's not a good idea to reinvent the wheel
    each time for each new project. Certain parts of software are common to most web
    service projects. Learning some of the known practices that have proven successful
    over time is important to avoid making easily fixed mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will focus on the Twelve-Factor App methodology. This methodology
    is a series of recommendations that are well proven for web services that are
    deployed on the web.
  prefs: []
  type: TYPE_NORMAL
- en: The Twelve-Factor App has its origins in Heroku, a company that provides easy
    access to deployments. Some of the factors are more general than others, and everything
    should be considered general advice and not necessarily an imposition. The methodology
    is less applicable outside of web cloud services, but it's still a good idea to
    review it and try to extract useful information.
  prefs: []
  type: TYPE_NORMAL
- en: We will present the base details for this methodology during the chapter and
    will spend some time describing in more detail some of the most important factors
    that this methodology covers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Intro to the Twelve-Factor App
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous Integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Twelve factors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containerized Twelve-Factor Apps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start by introducing the basic concepts of the Twelve-Factor App.
  prefs: []
  type: TYPE_NORMAL
- en: Intro to the Twelve-Factor App
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Twelve-Factor App is a methodology with 12 different aspects or factors
    that cover good practices to follow while designing a web system. They aim to
    provide clarity and simplify some of the possibilities, detailing patterns that
    are known to work.
  prefs: []
  type: TYPE_NORMAL
- en: The factors are generic enough to not be prescriptive in how to implement them
    or force the use of specific tools, and at the same time, give clear direction.
    The Twelve-Factor App Methodology is opinionated in the sense that it aims to
    cover cloud services in a scalable way, and also promotes the idea of **Continuous
    Integration** (**CI**) as a critical aspect of these kinds of operations. This
    also leads to a reduction in the differences between a local, development environment
    and a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: These two aspects, consistency between local and production deployments, and
    CI, interact, as it allows the system to be tested in a consistent way, both in
    a development environment and while running the tests in a CI system.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability is another key element. As cloud services require working with a
    variable workload, we need to allow our service to be capable of growing and be
    able to process more requests coming into the system without any issues.
  prefs: []
  type: TYPE_NORMAL
- en: A third general problem that we will cover, and which is also central to the
    Twelve-Factor App, is the challenge of configuration. Configuration allows the
    same code to be set up in different environments, while also tweaking some features
    to adjust them in certain situations.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuous Integration, or CI, is the practice of automating the running of
    tests when new code is submitted to a central repository. Whereas, when originally
    introduced back in 1991, it could be understood as running a "nightly build",
    as running the tests took time and was expensive, these days, it is commonly understood
    as running a set of tests with each new code submission.
  prefs: []
  type: TYPE_NORMAL
- en: The objective is to produce code that always works. After all, if it's not,
    it is detected quickly by the failing tests. This fast feedback loop helps developers
    to increase their speed and create a safety net that allows them to focus on whatever
    feature they are implementing and leave it to the CI system to run the totality
    of tests. The discipline of running the tests automatically and on every single
    test greatly helps to ensure high-quality code, as any error is detected quickly.
  prefs: []
  type: TYPE_NORMAL
- en: This is also dependent on the quality of the tests that are run, so in order
    to have a good CI system, it is important to understand the importance of good
    tests and to refine the testing procedure regularly, both to ensure that it gives
    us an adequate level of confidence and that it runs fast enough not to cause a
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: Fast enough, when dealing with a CI system can vary. Keep in mind that the tests
    will run in the background, automatically, without the involvement of a developer,
    so they may take a while to return a result, compared with the quick feedback
    that a developer will expect when debugging a problem. As a very general approximation,
    aim to have your test pipeline finished in around 20 minutes or less, if that
    is possible.
  prefs: []
  type: TYPE_NORMAL
- en: CI is based on the capacity of automating whatever system is used as a central
    repository for code, so tests are launched as soon as new changes are forthcoming
    from a developer. It is very common to use a source control system like `git`,
    and add a hook that automatically runs the tests.
  prefs: []
  type: TYPE_NORMAL
- en: In a more practical approach, `git` is normally used under a cloud system like
    GitHub ([https://github.com/](https://github.com/)) or GitLab ([https://about.gitlab.com/](https://about.gitlab.com/)).
    Both of them have other services that integrate with them and allow operations
    to be run automatically through some configuration. Examples include TravisCI
    ([https://www.travis-ci.com/](https://www.travis-ci.com/)) and CircleCI ([https://circleci.com/](https://circleci.com/)).
    In the case of GitHub, they have their own native system called GitHub Actions.
    All of these are based on the idea of adding a special file to configure the service,
    thereby simplifying the setup and run of a pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: A CI pipeline is a succession of steps that are run in order. If there's an
    error, it will stop the execution of the pipeline and report whatever problem
    has been detected, allowing for early detection and feedback for developers. Typically,
    we build the software into a testable state and then run the tests. If there are
    different kinds of tests, such as unit and integration tests, run them both, either
    one after the other or in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical pipeline to run tests could do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: As it starts in a new, empty environment, install the required dependency tools
    to run the tests; for example, a particular version of Python and a compiler,
    or a static analysis tool that will be used in *step 3*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform any build command to prepare the code, such as compiling or packetizing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run static analysis tools like `flake8` to detect style problems. If the results
    reveal problems, stop here and report.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the unit tests. If the results are incorrect, stop here and show the errors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prepare and run other tests, such as integration or system tests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These stages may be run, in certain cases, in parallel. For example, *steps
    3* and *4* may run at the same time as there is no dependency between the cases,
    whereas *step 2* needs to be completed before moving on to *step 3*. These steps
    can be described in some CI systems to allow for faster execution.
  prefs: []
  type: TYPE_NORMAL
- en: The keyword in a CI pipeline is **automation**. To allow the pipeline to be
    executed, all the steps need to be able to be run automatically, without any manual
    intervention. This requires that any dependency is also able to be set up automatically.
    For example, elements like databases or other dependencies, if required for tests,
    need to be allocated.
  prefs: []
  type: TYPE_NORMAL
- en: A common pattern is that CI tools allocate a virtual machine that allows a database
    to start up so that it's available in the environment, including the usual suspects
    such as MySQL, PostgreSQL, and MongoDB. Keep in mind that the database will start
    empty, and if test data needs to be seeded, it will need to be done during the
    setting up of the environment. Check the documentation for your specific tool
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: One possibility is to use Docker to build one or more containers that will standardize
    the process and make all dependencies explicit in the building process. This is
    becoming an increasingly common option.
  prefs: []
  type: TYPE_NORMAL
- en: We will talk more about Docker in *Chapter 8*, *Advanced Event-Driven Structures*.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the factors of the Twelve-Factor App play a part in the setup of a CI
    pipeline, as they aim to have code that is easy to build, to be deployed either
    for testing or operating and configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud systems are expected to behave correctly under high loads, or at least
    to adjust between different loads. This requires the software to be **scalable**.
    Scalability is the ability of the software to be allowed to grow and accept more
    requests, mostly by increasing resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two types of scalability:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Vertical scalability: Increasing resources to each node, making them more powerful.
    This is the equivalent of buying a more powerful computer; adding more RAM, more
    hard drive space, a faster CPU…'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Horizontal scalability: Adding more nodes to the system, without them being
    necessarily more powerful. For example, instead of having two web servers, increase
    them to five.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, horizontal scalability is considered more desirable. In a cloud
    system, the capacity of adding and removing nodes can be automated, allowing for
    deployments to adjust automatically based on the number of current requests flowing
    into the system. Compared with the traditional way of operating, where the system
    had to be dimensioned for the moment of maximum system load, this can greatly
    reduce costs since, most of the time, the system will be underutilized.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's compare a situation where, at noon, the system requires 11
    servers, when most customers are connected. At midnight, the system is at its
    lowest utilization point, and only 2 servers are required.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows a typical situation when the number of servers
    grows based on the load:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, histogram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_05_01.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.1: Service scaling up and down over time'
  prefs: []
  type: TYPE_NORMAL
- en: The traditional situation will make use of 264 cost units (11 servers * 24 hours),
    while automatically scaling uses approximately 166 cost units, saving a considerable
    number of resources.
  prefs: []
  type: TYPE_NORMAL
- en: Even more so, a traditional system requires extra headroom to allow for unexpected
    spikes that could occur. Normally, a system will be set up to allow at least a
    30% extra load, maybe even more. In that case, the cost is permanently added.
  prefs: []
  type: TYPE_NORMAL
- en: To allow a system to be horizontally scalable, it needs to be stateless. This
    means that each node is indistinguishable. Each request will be allocated to a
    node in some sort of rotation, distributing the load across all nodes. All state
    from each request needs to come either from the request itself (input parameters)
    or from an external storage source. From the point of view of the application,
    each request comes in an empty space and cannot be carried over in any event.
    That means not storing anything in the local hard drive or local memory between
    requests.
  prefs: []
  type: TYPE_NORMAL
- en: Storing information intra-request, for example, composing a file with information
    from the database to return it in the request is OK, although keeping it in memory,
    if possible, will likely be faster than using the hard drive.
  prefs: []
  type: TYPE_NORMAL
- en: The external storage source will typically be a database, but it's also common
    to use storage services more oriented to store files or other big blobs of binary
    data, for example, AWS S3\.
  prefs: []
  type: TYPE_NORMAL
- en: AWS S3 is a web service that allows a file to be stored and retrieved from a
    URL. It allows the creation of a *bucket*, which will contain a number of *keys*
    or paths; for example, accessing a URL similar to `https://s3.amazonaws.com/mybucket/path/to/file`
    so it can upload and download file-like objects. There are also plenty of libraries
    to help deal with the service, such as `boto3` for Python.
  prefs: []
  type: TYPE_NORMAL
- en: This service is very useful for working with files in a scalable way, and it
    allows configuration in such a way that access for reading can be done publicly,
    enabling the pattern of storing the data through your system, and then allowing
    the user to read it from the public URL, thereby simplifying the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to the AWS documentation for more information: [https://aws.amazon.com/s3/](https://aws.amazon.com/s3/)'
  prefs: []
  type: TYPE_NORMAL
- en: A cache should also be kept outside of each individual node, using tools such
    as Riak or memcached. Internal caches, using local memory, have the problem that
    they likely won't be used, as the next relevant request will likely be served
    by another node in the system. Using an external service allows all nodes to access
    the cache and improves the general performance of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the whole system cannot be stateless. In particular, the storage
    elements, such as databases and caches, require a different way of operating,
    as they are the ones storing the data. We discussed how to scale storage systems
    in *Chapter 3*, *Data Modeling*.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the basic ideas of the Twelve-Factor App is that the code is unique,
    but it can be adjusted through configuration. This enables the same code to be
    used and deployed in different environments.
  prefs: []
  type: TYPE_NORMAL
- en: The use of different environments allows testing environments to be set up,
    where tests can be run without affecting production data. They are a more controlled
    place for experimenting or trying to replicate real problems in a sandbox. There's
    also another environment that is not typically thought of as such, which is the
    local development environment, where developers are able to check that the system
    works.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a comprehensive and easy-to-use local environment is a critical aspect
    of developer productivity. When working with a single service or process, such
    as a web server, it is relatively easy to set up, as most projects will allow
    starting in a dev mode, but once there are more elements, it becomes more difficult
    to set up.
  prefs: []
  type: TYPE_NORMAL
- en: Complex settings have been quite common for years. There has been a relatively
    recent push to use virtual machines that could be set up from scratch, and more
    recently, containerization to ensure that it's easy to start it from a known point.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the system is more difficult than it appears at first sight. There's
    always a growing number of parameters to take care of. In complex systems, it
    is important to structure parameters in certain ways to allow them to be divided
    into more manageable parts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configuration parameters can be divided into two main categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Operational configuration**: These are parameters that connect different
    parts of the system or that are related to monitoring; for example, the address
    and credentials for the database, the URL to use to access an external API, or
    setting the level of logging to `INFO`. These config parameters are only changed
    when there''s a change in the cluster, but the external behavior of the application
    doesn''t change; for example, a change to log only `WARNING` logs or higher, or
    the credentials are replaced to rotate them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These parameters are under the control of operations and are normally changed
    transparently or during maintenance. A misconfiguration in these parameters is
    normally a serious problem as it can affect the functionality of the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature configuration**: These parameters change external behavior, enabling
    or disabling features or changing aspects of the software; for example, theming
    parameters to set the color and header images; or enabling the premium feature
    to allow a charge for premium access, or updating the parameters of a mathematical
    model that changes how the internal calculation of orbits are performed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These parameters are irrelevant as regards the operation of the software. A
    misconfiguration here will likely not cause problems, as it will continue to operate
    normally. Changes here are more under the control of developers or even business
    managers to enable a feature at a particular point in time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Configuration parameters that aim to activate or deactivate a full feature are
    known as *feature flags*. They are used to produce a "business release" at a particular
    time, deploying new code into a production environment without the feature, while
    the feature is being worked on internally.
  prefs: []
  type: TYPE_NORMAL
- en: Once the feature is ready for release, after thoroughly testing it, the code
    can be deployed beforehand in production, and the full feature can be activated
    just by changing the proper config parameter.
  prefs: []
  type: TYPE_NORMAL
- en: This allows us to keep working in small increases toward a big feature, such
    as a revamp of the user interface, while at the same time building and releasing
    small increments frequently. Once the feature is released, the code can be refactored
    to remove the parameter.
  prefs: []
  type: TYPE_NORMAL
- en: These two categories have different aims and, normally, are maintained by different
    people. While the operational configuration parameters are tightly related to
    a single environment and require parameters that are correct for the environment,
    the feature configuration normally moves between the local development to test
    it until it is changed in the production one with the same value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditionally, the configuration has been stored in one or more files, typically
    grouped by environment. This creates a file called `production.cnf` and another
    one called `staging.cnf` that are attached to the code base, and depending on
    the environment, one or the other is used. This entails certain problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Making a configuration change is, de facto, a code change. This limits the speed
    of changes that can be performed and cause problems with scope.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the number of environments grows, the number of files grows at the same
    time. This can cause errors as a result of duplication; for example, a mistake
    that changes the wrong file is not reverted and is unexpectedly deployed later.
    Old files may also not be removed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Centralizing control among developers. As we've seen, some of these parameters
    are not necessarily under the control of developers, but ops teams. Storing all
    the data in the code base makes it more difficult to create a division between
    jobs, requiring both teams to access the same files. While this is fine for small
    teams, over time, it makes sense to try to reduce the need to have big groups
    of people accessing the same file to only care about half of it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing sensitive parameters such as passwords in files and storing them in
    the code repo is an obvious security risk, as anyone with access to the repo can
    use these credentials to access all environments, including production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These problems render it unadvisable to store the configuration directly as
    files inside the code base. We will see how the Twelve-Factor App deals with it
    specifically in the *Configuration* factor.
  prefs: []
  type: TYPE_NORMAL
- en: The Twelve Factors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The factors for Twelve-Factor Apps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code base**. Store the code in a single repo and differentiate only by configuration.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Dependencies**. Declare them explicitly and clearly.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Config**. Config through the environment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Backing** **services**. Any backing service should be treated as an attached
    resource.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Build, release, run**. Differentiate between build and run states.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Processes**. Execute the app as a stateless process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Port binding**. Expose services through ports.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Concurrency**. Set up the services as processes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Disposability**. Fast start and graceful shutdown.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Dev/prod parity**. All environments should be as similar as possible.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Logs**. Send logs to event streams.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Admin processes**. Run one-off admin processes independently.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The factors can be grouped around different concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Code base*, *Build, release, run*,and *Dev/prod parity* work around the idea
    of generating a single application that runs in different environments, differentiating
    only through configuration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Config*, *Dependencies*, *Port binding*, and *Backing services* work around
    the configuration and connectivity of different services'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Processes*, *Disposability*, and *Concurrency* are related to the scalability
    concept'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Logs* and *Admin processes* are practical ideas involved with monitoring and
    one-off processes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a look at all four of these groups.
  prefs: []
  type: TYPE_NORMAL
- en: Build once, run multiple times
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the key concepts around the Twelve-Factor App is that it's easy to build
    and manage, but at the same time, it's a unified system. This means that there's
    no ad hoc code that's changed from one version to another, just configurable options.
  prefs: []
  type: TYPE_NORMAL
- en: The aim of the *Code base* factor is that all the software for an app is a single
    repo, with a single state, without special branches for each customer, or a special
    functionality that's only available in a particular environment.
  prefs: []
  type: TYPE_NORMAL
- en: Very specific environments are typically called *snowflake environments*. Anyone
    that has dealt with them knows how painfully difficult they are to maintain, and
    that's why the objective for the Twelve-Factor App is to remove them, or at least
    make them change based just on the configuration.
  prefs: []
  type: TYPE_NORMAL
- en: This means that the code to deploy is always the same, and only the configuration
    changes. This allows easy testing of all the configuration changes and does not
    introduce blind spots.
  prefs: []
  type: TYPE_NORMAL
- en: Note that a single system may have multiple projects, living in multiple repos,
    that individually fulfill the Twelve-Factor App and work together. Other factors
    talk about interoperation on applications.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping multiple applications working together, through coordinated APIs, is
    always a challenge and requires good coordination across teams. Some companies
    adopt the monorepo approach, where there's a single repository with all the company
    projects living in multiple subdirectories, to be sure that there's a complete
    view of the whole system and a single state across the whole organization.
  prefs: []
  type: TYPE_NORMAL
- en: This also has its own challenges, and requires greater coordination across teams
    and can present big challenges for big repos.
  prefs: []
  type: TYPE_NORMAL
- en: 'A single code base allows a strict differentiation of the stages in the *Build,
    release, run* factor. This factor ensures that there are three distinct stages:'
  prefs: []
  type: TYPE_NORMAL
- en: The build stage transforms the content of the code repo into a package or executable
    that will be run later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The release stage uses this built package, combines it with the proper configuration
    for the selected environment, and sets it ready for execution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The run stage finally executes the package in the selected environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we discussed previously, the configuration lives in a different place to
    the code base. This separation makes sense, and it could be also under source
    control. It may be stored as files, but the access can then be separated by environment,
    something that makes sense, as some environments, like production, are more critical
    than others. Storing the configuration as part of the code base makes it difficult
    to perform that separation.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that more than one file can be combined, allowing the parameters
    to be separated into feature and operational configurations.
  prefs: []
  type: TYPE_NORMAL
- en: Because stages are strictly divided, it's not possible to change the configuration
    or the code after the code is deployed. This requires a new release in any case.
    This makes the releases very explicit, and each one should be executed independently.
    Note that the run stage may need to be executed again in case there's a new server
    or the server crashes, so the aim should be for this to be as easy to do as possible.
    As we are seeing, a common thread through the Twelve-Factor App is strict separation,
    so that each element is easy to recognize and to operate. We will check how to
    define the configuration in other factors.
  prefs: []
  type: TYPE_NORMAL
- en: Performing tests after the build stage also ensures that the code remains without
    changes between the tests and the release and operation.
  prefs: []
  type: TYPE_NORMAL
- en: Because of this strict separation, in particular, in the build stage, it's easy
    to follow the *Dev/prod parity*. In essence, a development environment is the
    same as a production one, as they use the same building stage, but with proper
    configuration to run locally. This factor also makes it possible to use the same
    (or as close as possible) backing services, like databases or queues, to ensure
    that local development is as representative as a production environment. Container
    tools such as Docker, or provisioning tools such as Chef or Puppet, can also help
    in automatically setting up environments that contain all the required dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining a fast and easy process to develop, build, and deploy is critical
    for speeding up the cycle and adjusting quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies and configurations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Twelve-Factor App advocates the explicit definition of dependencies and
    configuration and, at the same time, is opinionated in terms of how to do them
    and provides solid standards that are proven.
  prefs: []
  type: TYPE_NORMAL
- en: That is why, in the *Config* factor, it talks about storing all the configuration
    for the system in **environment** **variables**. Environment variables are independent
    from code, which allows retention of the strict differentiation that we talked
    about in the *Build, release, run factor* and avoidance of the problems that we
    described previously in storing them in files inside the code base. They are also
    language- and OS-independent, and easy to work with. Injecting environment variables
    into a new environment is also easy.
  prefs: []
  type: TYPE_NORMAL
- en: This is preferred to other alternatives, such as setting different files into
    the code base describing environments like `staging` or `production`, because
    they allow more granularity, and because this kind of handling ends up creating
    too many files and changing the code for environments that are not affected; for
    example, having to update the code base for a `demo` environment that is short-lived.
  prefs: []
  type: TYPE_NORMAL
- en: Although the Twelve-Factor App encourages dealing with configurations in a variable-independent
    way, the reality of the work means that there are a limited number of environments
    and their configuration should be stored somewhere. The key element is storing
    it in a different place to the code base, managed only on the *release* stage.
    This allows plenty of flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that for local development, these environment variables may need
    to be changed independently to test or debug different features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configuration can be obtained in configuration files directly from the environment
    using standard libraries; for example, in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This code will store in the constant `PARAMETER` the value of the `PATH` environment
    variable. Be careful as the lack of a `PATH` environment variable will generate
    a `KeyError` as it won't be present in the `environ` dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: For the following examples, keep in mind that the defined environment variables
    need to be defined in your environment. These definitions are not included, to
    simplify the explanation. You can run Python, adding a local environment, by running
    `$ MYENVVAR=VALUE python3`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To allow for optional environment variables, and protect against them going
    missing, use `.get` to set up a default value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As a general recommendation, it's better to raise an exception because there's
    a missing configuration variable than to continue with a default parameter. This
    makes configuration problems easier to spot, as it will stop when the process
    starts, failing loudly. Remember, following the Twelve-Factor App ideas, you want
    to describe things explicitly and any problem should fail as early as possible
    in order to be able to fix it correctly instead of passing without detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that environment variables are always defined as text. If the value needs
    to be in a different format, it needs to be converted, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This presents a common problem when defining a `Boolean` value. Defining this
    translation code as follows is incorrect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If the value of `ENVPARAMETER` is `"TRUE"`, the value of `BOOL_PARAMETER` is
    `True` (Boolean). But if the value of `ENVPARAMETER` is `"FALSE"`, the value of
    `BOOL_PARAMETER` is also `True`.This is because the string `"FALSE"` is a non-empty
    string and gets converted into `True`. Instead, the standard library package,
    `distutils`, can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`strtobool` returns not `True` or `False` as `Booleans`, but `0` or `1` as
    integers. This normally works correctly, but if you need strict `Boolean` values,
    add `bool` like this: `bool(strtobool(os.environ[''ENVPARAMETER'']))`'
  prefs: []
  type: TYPE_NORMAL
- en: Environment variables also allow the injection of sensitive values such as secrets
    without storing them in the code base. Keep in mind that the secret will be available
    to inspect in the environment of the execution, but typically that's protected
    so only authorized team members can access it through `ssh` or similar in the
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: As part of this configuration, any *backing services* should be defined as well
    as environment variables. Backing services are external services that the app
    uses over the network. They could be databases, queues, caching systems, or suchlike.
    They can be local to the same network or external services, such as APIs handled
    by an external company or AWS services.
  prefs: []
  type: TYPE_NORMAL
- en: From the point of view of the app, this differentiation should be irrelevant.
    The resources should be accessed by a URI and credentials, and, as part of the
    configuration, can be changed based on the environment. This makes the resources
    loosely coupled, and means they can be replaced easily. If there is a migration
    and the database needs to be moved between two networks, we can start the new
    database, perform a new release with a configuration change, and the app will
    point to the new database. This can be done with no code changes.
  prefs: []
  type: TYPE_NORMAL
- en: To allow the concatenation of multiple applications, the *Port binding* factor
    ensures that any service exposed is a port, which may be different depending on
    the service. This makes it easy to consider each app a backing service. Preferably,
    it should be exposed in HTTP as this makes it very standard to connect to.
  prefs: []
  type: TYPE_NORMAL
- en: For applications, use HTTP over port `80` when possible. This makes all connections
    easy with URLs such as `http://service-a.local/`.
  prefs: []
  type: TYPE_NORMAL
- en: Some applications require the combination of several processes working in conjunction.
    For example, it is typical for a web server for a Python application, such as
    Django, to use an application server like uWSGI to run it, and then a web server
    like nginx or Apache to serve it and the static files.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_05_02.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.2: Connecting a web server and application server'
  prefs: []
  type: TYPE_NORMAL
- en: They all connect by exposing a known port and protocol, which makes the setup
    easy.
  prefs: []
  type: TYPE_NORMAL
- en: On the same note, for clarity, all library *dependencies* should be explicitly
    set up and not rely on the pre-installation of certain packages in the existing
    operating system. The dependencies should be described through a dependency declaration,
    like a `requisites.txt` pip file for Python.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies should then be installed as part of the build stage, with commands
    such as `pip install -r requirements.txt`.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the specific Python version is also a dependency that should
    be controlled tightly. The same is true of other required OS dependencies. Ideally,
    the OS environment should be created from scratch with the dependencies specified.
  prefs: []
  type: TYPE_NORMAL
- en: Even more so, dependencies should be isolated to ensure that there are no implicit
    dependencies that are not tightly controlled. Dependencies should also be defined
    as tightly as possible, to avoid the problem of different versions of dependencies
    being installed if new versions are released upstream.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in a pip file, a dependency can be described in different ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The first way accepts any version, so it will typically use the latest. The
    second describes a minimum (and optionally maximum) version. The third version
    pins a specific version.
  prefs: []
  type: TYPE_NORMAL
- en: This is equivalent to other package management systems in operative systems,
    like `apt` in Ubuntu. You can install a specific version with `apt-get install
    dependency=version`.
  prefs: []
  type: TYPE_NORMAL
- en: Using very explicit dependencies makes the builds repeatable and deterministic.
    It ensures a lack of unknown changes during the build stage because a new version
    has been released. While most new packages will be compatible, it may also *sometimes*
    introduce changes that affect the behavior of the system. Even worse, those changes
    will be introduced **inadvertently**, causing severe problems.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We talked earlier in the chapter about the why's of scalability. The Twelve-Factor
    App also talks about how to successfully grow or reduce the system.
  prefs: []
  type: TYPE_NORMAL
- en: The *Processes* factor talks about making sure that the run stage consists of
    starting one or more processes. These processes should be stateless and share
    nothing, meaning that all the data needs to be retrieved from an external backing
    service like a database. A temporal local disk can be used for temporal data within
    the same request, although their use should be kept to a minimum.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a file upload may use the local hard drive to store a temporal
    copy and then process the data. After the data is processed, the file should be
    deleted from the disk.
  prefs: []
  type: TYPE_NORMAL
- en: If possible, try to use memory for this temporal storage as it will make this
    distinction more strict.
  prefs: []
  type: TYPE_NORMAL
- en: The next property that processes need to fulfill is their *disposability*. The
    processes need to be able to be started and stopped quickly, and at any time.
  prefs: []
  type: TYPE_NORMAL
- en: Starting quickly allows the system to react quickly to releases or restarts.
    The aim should be to take not more than a few seconds to have the process up and
    running. Quick turnaround is also important to allow rapid growth of the system
    in case more processes are being added for scale purposes.
  prefs: []
  type: TYPE_NORMAL
- en: The opposite is to allow the graceful shutdown of the process. This can be required
    for scale-down situations, to be sure that any request is not interrupted in this
    case. By convention, processes should be stopped by sending the `SIGTERM` signal.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Docker containers automatically uses this convection by sending
    a `SIGTERM` signal to the main process whenever the container needs to be stopped.
    If the process doesn't stop itself after a grace period, it will be killed instead.
    The grace period can be configured if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Be sure that the main process for the container can receive `SIGTERM` and deal
    with it properly to ensure a graceful stopping of the container.
  prefs: []
  type: TYPE_NORMAL
- en: For example, for a web request, a graceful shutdown first will curtail the acceptance
    of any new requests, will finish any requests in the queue, and finally, will
    shut down the process. Web requests are typically quick to answer, but for other
    processes, such as long asynchronous tasks, it may take a long time to stop if
    they need to finish the current task.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, long task workers should return the job to the queue and cancel the
    execution. This way, the task will be performed again, and to ensure that this
    doesn't duplicate actions, we need to ensure that all tasks can be canceled by
    waiting until the end of it to save its results and wrapping them into a transaction
    or similar.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, it may be necessary to distinguish between the bulk of the preparation
    job and the saving of results part. We either want to wait, if the job is saving
    the results at the time of shut down, or stop execution and return the task to
    the queue. Some save operations may require calling systems that don't accept
    transactions. The acceptable time for shutting down long-running processes may
    be longer than for web servers.
  prefs: []
  type: TYPE_NORMAL
- en: Processes should also be robust against unexpected stoppages. These stoppages
    could be caused by bugs, hardware errors, or, in general, unexpected surprises
    that always appear in software. Creating a resilient queue system that can retry
    in case a task is interrupted will help greatly in these instances.
  prefs: []
  type: TYPE_NORMAL
- en: Because the system is created through processes, based on that, we can scale
    out by creating more of them. Processes are independent and can be run at the
    same time on the same server or others. This is the basis of the *Concurrency*
    factor.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the same application can use multiple processes that coordinate
    among them to handle different tasks and each process may have a different number
    of copies. In our previous example above, with an nginx server and uWSGI one,
    the optimal number may be to have a single nginx process for many more times the
    number of uWSGI workers.
  prefs: []
  type: TYPE_NORMAL
- en: The traditional deployment process was to set up a physical server (or virtual
    machine) for a node and fit a number of elements, which normally included tailoring
    the number of workers until finding the optimal figure to make proper use of the
    hardware.
  prefs: []
  type: TYPE_NORMAL
- en: With containers, this process is somehow reversed. Containers tend to be more
    lightweight and more can be created. While the optimization process is still required,
    with containers, it's more about creating a unit and then checking how many of
    them a single node can fit, as containers can be moved around nodes more easily,
    and the resulting apps tend to be smaller. Instead of finding out what is the
    proper size of the application for a given server, we figure out how many copies
    of a small application fit in a server, knowing that we can use different server
    sizes or add more servers with ease.
  prefs: []
  type: TYPE_NORMAL
- en: Adding more nodes, as they are independent and stateless, becomes an easy operation
    under a Twelve-Factor App. That allows the size of the entire operation to be
    adjusted to the load of the system. This can be a manual operation, to slowly
    add new nodes as the system grows in load and requests, or it can be done automatically,
    as we described earlier in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The Twelve-Factor App doesn't demand that this scale is done automatically,
    but definitively enables it. Automating the adjustment should be treated with
    care, as it requires careful metrics on the load of the system. Allow time to
    perform tests to make the proper adjustments.
  prefs: []
  type: TYPE_NORMAL
- en: The Twelve-factor App processes should also be run by some sort of operating
    system process manager, like `upstart` or `systemd`. These systems ensure that
    the processes remain running, even in the event of a crash, handle graceful manual
    restarts, and also manage output streams gracefully. We will talk more about output
    streams as part of logs.
  prefs: []
  type: TYPE_NORMAL
- en: When working with containers, this changes a bit, as the equivalent is mostly
    handling containers more than processes. Instead of an operating system process
    manager, the work is performed by a container orchestrator that ensures that the
    containers are running properly and capturing any output stream. Inside the container,
    the processes can start without being under the control of a manager. The container
    will stop if the process is stopped.
  prefs: []
  type: TYPE_NORMAL
- en: Restarting the processes automatically, combined with a quick start up time
    and resilience in shutdown situations, makes the app dynamic and capable of self-repairing
    in case there is an unexpected problem that causes a process to crash. It also
    allows controlled shutdowns to be used as part of a general operation to avoid
    long-running processes and act as a contingency plan for memory leaks or other
    kinds of long-running problems.
  prefs: []
  type: TYPE_NORMAL
- en: This is equivalent to the old trick of turning it off and then turning it back
    on! If it can be done very quickly, it can save a lot of situations!
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and admin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A comprehensive monitoring system is important for detecting problems and analyzing
    the operation of the system. While it's not the only monitoring tool, logs are
    a critical part of any monitoring system.
  prefs: []
  type: TYPE_NORMAL
- en: Logs are text strings that provide visibility of the behavior of a running app.
    They should always include a timestamp on when they were generated. They are generated
    as the code is being executed, giving information on the different actions as
    they happen. The specifics about what to log can vary significantly by application,
    but typically frameworks will automatically create logs based on common practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, any web-related software will log requests received, something
    like this, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that it includes:'
  prefs: []
  type: TYPE_NORMAL
- en: A timestamp for when it was generated `[16/May/2021 13:32:16]`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HTTP `GET` method and the `HTTP/1.1` protocol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The accessed path – `/path`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The returned status code – `200`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The size of the request – `10697`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This kind of log is called an access log and will be generated in different
    formats. At the very least, it should always include the timestamp, HTTP method,
    path, and status code, but it can be configured to return extra information, such
    as the IP of the client making the request, or the time that it took to process
    the request.
  prefs: []
  type: TYPE_NORMAL
- en: Access logs are also generated by web servers including nginx and Apache. Configuring
    them properly to adjust the information produced is important for operational
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Access logs are not the only useful ones. Application logs are also very useful.
    Application logs are generated inside the code and can be used to communicate
    significant milestones or errors. Web frameworks prepare the logs, so it''s easy
    to generate new ones. For example, in Django, you can create logs this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate logs like these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We will get into more details about logs in *Chapter 11*, *Package Management*.
  prefs: []
  type: TYPE_NORMAL
- en: The *Logs* factor suggests that logs shouldn't be managed by the process itself.
    Instead, logs should be printed in their own standard output without any intermediate
    step. The environment surrounding the process, like the operating system process
    manager described in the *Concurrency* factor, should be charged with receiving
    the logs, combining them, and routing them properly to a long-term archival and
    monitoring system. Note that this configuration is totally out of the application's
    control.
  prefs: []
  type: TYPE_NORMAL
- en: For local development, just showing the logs in a terminal may be enough for
    development purposes.
  prefs: []
  type: TYPE_NORMAL
- en: This is in contrast to storing the logs as log files in the hard drive. This
    has the problem of requiring the logs to be rotated and ensure that there's enough
    space. This also requires the different processes to coordinate in terms of having
    a similar policy for log rotation and storage. Instead, standard outputs can be
    combined and aggregated together for a whole image of the system, and not a single
    process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logs can also be directed toward an external log indexing system, such
    as the ELK Stack (Elasticsearch, Kibana, and Logstash: [https://www.elastic.co/products/](https://www.elastic.co/products/)),
    which will capture logs and provide analytic tools to search through them. External
    tools are also available, including Loggly ([https://www.loggly.com/](https://www.loggly.com/))
    or Splunk ([https://www.splunk.com/](https://www.splunk.com/)) to avoid maintenance.
    All these tools allow standard output logs to be captured and redirected to their
    solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: In the container world, this recommendation makes even more sense. Docker orchestration
    tools can easily capture the standard output from the containers and then redirect
    them to somewhere else.
  prefs: []
  type: TYPE_NORMAL
- en: These other tools can provide capabilities like searching and finding specific
    events in a particular time window, observing trends such as changes in the number
    of requests per hour, and even creating automatic alerts based on certain rules,
    such as an increase in the number of `ERROR` logs over a period of time over and
    above a certain value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *Admin processes* factor covers some processes that sometimes need to be
    run for specific operations, but are not part of the app''s normal operation.
    Examples include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Database migrations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The production of ad hoc reports, such as generating a one-off report for certain
    sales or detecting how many records are affected by a bug
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a console for debugging purposes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing commands in a console in a production environment should be used only
    when no other alternative is available, and not as a way of removing the need
    to create specific scripts for recurring operations. Extreme caution should apply.
    Keep in mind that an error in a production environment can create a serious problem.
    Treat your production environment with the proper respect.
  prefs: []
  type: TYPE_NORMAL
- en: These operations are not part of the day-to-day operation, but may need to be
    run. The interface is clearly different. To execute them, they should run in the
    same environment as the regular processes, using the same code base and configuration.
    These admin operations should be included as part of the code base to avoid problems
    with mismatched code.
  prefs: []
  type: TYPE_NORMAL
- en: In traditional environments, it may be necessary to log in to a server through
    `ssh` to allow the execution of this process. In container environments, a full
    container can be started exclusively to execute the process.
  prefs: []
  type: TYPE_NORMAL
- en: This is very common in cases of migrations, for example. A preparation command
    may consist of running the build to execute migrations.
  prefs: []
  type: TYPE_NORMAL
- en: This should be done before the actual release, to ensure that the database is
    migrated. Refer to *Chapter 4* for more details on migrations.
  prefs: []
  type: TYPE_NORMAL
- en: To run these admin commands in containers, the container image should be the
    same one that runs the application, but called with a different command, so the
    code and environment are the same as in the running application.
  prefs: []
  type: TYPE_NORMAL
- en: Containerized Twelve-Factor Apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the Twelve-Factor App methodology is older than the current trend toward
    containerization using Docker and related tools, it's very aligned. Both tools
    are oriented toward scalable services in the cloud, and containers help to create
    patterns that match the ones described in the Twelve-Factor methodology.
  prefs: []
  type: TYPE_NORMAL
- en: We will talk more about Docker containers in *Chapter 8*, *Advanced Event-Driven
    Structures*.
  prefs: []
  type: TYPE_NORMAL
- en: The most important, arguably, is the fact that the creation of an invariant
    container image that then gets run works very well with the *Build, release, run*
    factor and with being very explicit with *Dependencies*, as the whole image will
    include details such as the specific OS to use and any library. Including the
    build process as part of the repository also helps in the implementation of the
    *Code base* factor.
  prefs: []
  type: TYPE_NORMAL
- en: Each container also works as a *Process*, which allows scaling by creating multiple
    copies of the same container, using the *Concurrency* model.
  prefs: []
  type: TYPE_NORMAL
- en: While containers are usually thought of conceptually as lightweight virtual
    machines, it's better to think of them as a process wrapped in its own filesystem.
    This is closer to the way they operate.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of containers makes them easy to start and stop, leaning into the
    *Disposability* factor, and connecting one to another through an orchestration
    tool such as Kubernetes makes it easy to also set up the *Backing services* factor,
    and it's also easy to share services between specific ports in containers following
    the *Port binding* factor. In most cases, however, they'll be shared as web interfaces
    on the standard port `80`.
  prefs: []
  type: TYPE_NORMAL
- en: In Docker and orchestrator tools like Kubernetes, it is very easy to set up
    different environments injecting environment variables, thereby fulfilling the
    *Configuration* factor. This environment configuration, as well as a description
    of the cluster, can be stored in files, which allow multiple environments to be
    created easily. It also includes tools for handling properly secrets, so they
    are properly encrypted and are not stored in the configuration files to avoid
    leaking secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Another critical advantage of containers is the fact that a cluster can be replicated
    easily locally, as the same image that runs in production can run in a local environment,
    with only small changes in its configuration. This helps greatly in ensuring that
    the different environments are kept up to date, as demanded by the *Dev/Prod parity*
    factor.
  prefs: []
  type: TYPE_NORMAL
- en: In general, the container approach works toward defining a cluster and instigating
    a clear separation between different services and containers in a consistent manner.
    This brings together different environments, as the development environment can
    replicate the production setup on a small scale.
  prefs: []
  type: TYPE_NORMAL
- en: Sending information to standard output as per the *Logs* factor is also a great
    way to store logs as container tools will receive and deal with or redirect those
    logs adequately.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the *Admin processes* can be handled by launching the same container
    image with a different command that runs the specific admin command. This can
    be handled by the orchestrator if it needs to happen regularly, such as running
    the migrations prior to a deployment, or if it's a periodic task.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, working with containers is a great way of following the recommendations
    for the Twelve-Factor App, as the tools work in the same direction. This doesn't
    mean that they are done for free, but that there's a significant degree of alignment
    between the methodology and the ideas behind containers.
  prefs: []
  type: TYPE_NORMAL
- en: This is not surprising as both come from a similar background, dealing with
    web services that need to be run in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw that it's good to have solid and reliable patterns to
    build software to be sure that we stand over the shoulder of tested decisions
    that we can use to shape new designs. For web services living in the cloud, we
    can use the Twelve-Factor App methodology as a guideline for a lot of useful advice.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed how the Twelve-Factor App is aligned with two main ideas – CI and
    scalability.
  prefs: []
  type: TYPE_NORMAL
- en: CI is the practice of constantly validating any new code by running tests automatically
    after the code is shared. This creates a safety net that enables developers to
    move quickly, although it requires discipline to properly add automated tests
    as new features are being developed.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed the concept of scalability, or the capacity for software to
    allow more load by adding more resources. We talked about why it is important
    to allow the software to grow and reduce based on the load, even to the point
    to be able to adjust dynamically. We also saw how making the system stateless
    is key to achieving scalable software.
  prefs: []
  type: TYPE_NORMAL
- en: We saw the challenges for configuration, something that the Twelve-Factor App
    also deals with, and how not every configuration parameter is equal. We described
    how configuration can be divided into Operational configuration and Feature configuration,
    which can help divide and give the proper context to each parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We went through each of the factors for the Twelve-Factor App, and divided
    them into four different groups, relating them, and explaining how the different
    factors support each other. We divided the factors into groups:'
  prefs: []
  type: TYPE_NORMAL
- en: Build once, run multiple times, based on the idea of generating a single package
    that runs in a different environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dependencies and configuration, around the configuration and software and service
    dependencies of the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability, to achieve the scalability that we talked about before
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and admin with other elements to deal with the operation of the software
    while in operation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we spent some time talking about how the Twelve-Factor App ideas are
    very much in line with what containerization is about, and how different Docker
    features and concepts allow us to easily create Twelve-Factor Apps.
  prefs: []
  type: TYPE_NORMAL
