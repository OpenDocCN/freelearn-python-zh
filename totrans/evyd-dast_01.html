<html><head></head><body>
<div class="book" title="Chapter&#xA0;1.&#xA0;Data Types: Foundational Structures"><div class="book" id="E9OE2-77f2b5b248f04368a6f723b0e9357ef3"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch01" class="calibre1"/>Chapter 1. Data Types: Foundational Structures</h1></div></div></div><p class="calibre7">Calling data types <span class="strong"><em class="calibre20">foundational structures</em></span> may seem like a bit of a misnomer, but not when you consider that developers use data types to build their classes and collections. So, before we examine proper data structures, it's a good idea to quickly review data types, as these are the foundation of what comes next. This chapter is meant to review the most common and most important fundamental data types from the 10,000-foot view. If you already have a strong grasp of these basic concepts, feel free to skim through this chapter or even skip it entirely as you see fit.</p><p class="calibre7">In this chapter, we will cover the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Numeric data types</li><li class="listitem">Casting, Narrowing, and Widening</li><li class="listitem">32-bit and 64-bit architecture concerns</li><li class="listitem">Boolean data types</li><li class="listitem">Logic operations</li><li class="listitem">Order of operations</li><li class="listitem">Nesting operations</li><li class="listitem">Short-circuiting</li><li class="listitem">String data types</li><li class="listitem">Mutability of strings</li></ul></div></div>

<div class="book" title="Chapter&#xA0;1.&#xA0;Data Types: Foundational Structures">
<div class="book" title="Numeric data types"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch01lvl1sec7" class="calibre1"/>Numeric data types</h1></div></div></div><p class="calibre7">A detailed description of all the numeric data types in each of the following four languages, C#, Java, Objective-C, and Swift, could easily encompass a book of its own. Here, we will review only the most common numeric type identifiers for each language. The simplest way to evaluate these types is based on the underlying size of the data, using examples from each language as a framework for the discussion.</p><div class="informaltable" title="Note"><h3 class="title1"><a id="tip3" class="calibre1"/>Tip</h3><p class="calibre7"><span class="strong"><strong class="calibre16">Compare apples to apples!</strong></span></p><p class="calibre7">When you are developing applications for multiple mobile platforms, you should be aware that the languages you use could share a data type identifier or keyword, but under the hood, those identifiers may not be equal in value. Likewise, the same data type in one language may have a different identifier in another. For example, examine the case of the 16-bit unsigned integer, sometimes referred to as an <code class="literal">unsigned short</code>. Well, it's called an <code class="literal">unsigned short</code> in Objective-C. In C#, we talk about a <code class="literal">ushort</code>, while Swift calls it a <code class="literal">UInt16</code>. Java's only provision for the 16-bit unsigned integer, on the other hand, is <code class="literal">char</code> although this object would typically not be used for numeric values. Each of these data types represents a 16-bit unsigned integer; they just use different names. This may seem like a small point, but if you are developing apps for multiple devices using each platform's native language, for the sake of consistency, you will need to be aware of these differences. Otherwise, you may risk introducing platform-specific bugs that are extremely difficult to detect and diagnose.</p></div></div></div>

<div class="book" title="Chapter&#xA0;1.&#xA0;Data Types: Foundational Structures">
<div class="book" title="Numeric data types">
<div class="book" title="Integer types"><div class="book"><div class="book"><div class="book"><h2 class="title2" id="calibre_pb_2"><a id="ch01lvl2sec5" class="calibre1"/>Integer types</h2></div></div></div><p class="calibre7">Integer data types are defined as representing whole numbers and can be either <span class="strong"><strong class="calibre16">signed</strong></span> (negative, zero, or positive values) or <span class="strong"><strong class="calibre16">unsigned</strong></span> (zero or positive values). Each language uses its own identifiers and keywords for integer types, so it is easiest to think in terms of memory length. For our purpose, we will only discuss the integer types representing 8-, 16-, 32-, and 64-bit memory objects.</p><p class="calibre7">8-bit data types, or <span class="strong"><strong class="calibre16">bytes</strong></span> as they are more commonly referred to, are the smallest data types that we will examine. If you have brushed up on your binary math, you will know that an 8-bit memory block can represent 2<sup class="calibre21">8</sup>, or 256 values. Signed bytes can range in value from -128 to 127, or -(2<sup class="calibre21">7</sup>) to (2<sup class="calibre21">7</sup>) - 1. Unsigned bytes can range in value from 0 to 255, or 0 to (2<sup class="calibre21">8</sup>) -1.</p><p class="calibre7">A 16-bit data type is often referred to as a <span class="strong"><strong class="calibre16">short</strong></span>, although that is not always the case. These types can represent 2<sup class="calibre21">16</sup> values. Signed shorts can range in value from -(2<sup class="calibre21">15</sup>) to (2<sup class="calibre21">15</sup>) - 1. Unsigned shorts can range in value from 0 to (2<sup class="calibre21">16</sup>) - 1.</p><p class="calibre7">A 32-bit data type is most commonly identified as an integer, although it is sometimes identified as a <span class="strong"><strong class="calibre16">long</strong></span>. Int types can represent 2<sup class="calibre21">32 </sup>values. Signed integers can range in values from -2<sup class="calibre21">31</sup> to 2<sup class="calibre21">31</sup> - 1. Unsigned integers can range in values from 0 to (2<sup class="calibre21">32</sup>) - 1.</p><p class="calibre7">Finally, a 64-bit data type is most commonly identified as a long, although Objective-C identifies it as a <span class="strong"><strong class="calibre16">long</strong></span> <span class="strong"><strong class="calibre16">long</strong></span>. Long types can represent 2<sup class="calibre21">64</sup> values. Signed long types can range in values from -(2<sup class="calibre21">63</sup>) to (2<sup class="calibre21">63</sup>) - 1. Unsigned long types can range in values from 0 to (2<sup class="calibre21">63</sup>) - 1.</p><div class="informaltable" title="Note"><h3 class="title1"><a id="note4" class="calibre1"/>Note</h3><p class="calibre7">Note that these values happen to be consistent across the four languages we will work with, but some languages will introduce slight variations. It is always a good idea to become familiar with the details of a language's numeric identifiers. This is especially true if you expect to be working with cases that involve the identifier's extreme values.</p></div><p class="calibre7"><span class="strong"><strong class="calibre16">C#</strong></span></p><p class="calibre7">C# refers to integer types as <span class="strong"><strong class="calibre16">integral types</strong></span>. The language provides two mechanisms for creating 8-bit types, <code class="literal">byte</code> and <code class="literal">sbyte</code>. Both containers hold up to 256 values, and the unsigned byte ranges from 0 to 255. The signed byte provides support for negative values and, therefore, ranges from -128 to 127:</p><pre class="programlisting">    // C# 
    sbyte minSbyte = -128; 
    byte maxByte = 255; 
    Console.WriteLine("minSbyte: {0}", minSbyte); 
    Console.WriteLine("maxByte: {0}", maxByte); 
 
    /* 
      Output 
      minSbyte: -128 
      maxByte: 255 
    */ 
</pre><p class="calibre7">Interestingly, C# reverses its pattern for longer bit identifiers. Instead of prefixing signed identifiers with <code class="literal">s</code>, as in the case of <code class="literal">sbyte</code>, it prefixes unsigned identifiers with <code class="literal">u</code>. So, for 16-, 32-, and 64-bit identifiers, we have <code class="literal">short</code>, <code class="literal">ushort</code>; <code class="literal">int</code>, <code class="literal">uint</code>; <code class="literal">long</code>, and <code class="literal">ulong</code> respectively:</p><pre class="programlisting">    short minShort = -32768; 
    ushort maxUShort = 65535; 
    Console.WriteLine("minShort: {0}", minShort); 
    Console.WriteLine("maxUShort: {0}", maxUShort); 
 
    int minInt = -2147483648; 
    uint maxUint = 4294967295; 
    Console.WriteLine("minInt: {0}", minInt); 
    Console.WriteLine("maxUint: {0}", maxUint); 
 
    long minLong = -9223372036854775808; 
    ulong maxUlong = 18446744073709551615;  
    Console.WriteLine("minLong: {0}", minLong); 
    Console.WriteLine("maxUlong: {0}", maxUlong); 
 
    /* 
      Output 
      minShort: -32768 
      maxUShort: 65535 
      minInt: -2147483648 
      maxUint: 4294967295 
      minLong: -9223372036854775808 
      maxUlong: 18446744073709551615 
    */ 
</pre><p class="calibre7"><span class="strong"><strong class="calibre16">Java</strong></span></p><p class="calibre7">Java includes integer types as a part of its primitive data types. The Java language only provides one construct for 8-bit storage, also identified as a <code class="literal">byte</code>. It is a signed data type, so it will represent values from -127 to 128. Java also provides a wrapper class called <code class="literal">Byte</code>, which wraps the primitive value and provides additional constructor support for parsable strings, or text, which can be converted to a numeric value such as the text 42. This pattern is repeated in the 16-, 32-, and 64-bit data types:</p><pre class="programlisting">    //Java 
    byte myByte = -128; 
    byte bigByte = 127; 
 
    Byte minByte = new Byte(myByte); 
    Byte maxByte = new Byte("128"); 
    System.out.println(minByte);  
    System.out.println(bigByte); 
    System.out.println(maxByte); 
 
    /* 
      Output 
      -128 
      127 
      127 
    */ 
</pre><p class="calibre7">Java shares identifiers with C# for all of integer data type, which means it also provides the <code class="literal">byte</code>, <code class="literal">short</code>, <code class="literal">int</code>, and <code class="literal">long</code> identifiers for 8-, 16-, 32-, and 64-bit types. One exception to the pattern in Java is the <code class="literal">char</code> identifier, which is provided for unsigned 16-bit data types. It should be noted, however, that the <code class="literal">char</code> data type is typically only used for ASCII character assignment and not for actual integer values:</p><pre class="programlisting">    //Short class 
    Short minShort = new Short(myShort); 
    Short maxShort = new Short("32767"); 
    System.out.println(minShort);  
    System.out.println(bigShort); 
    System.out.println(maxShort); 
         
    int myInt = -2147483648; 
    int bigInt = 2147483647; 
 
    //Integer class 
    Integer minInt = new Integer(myInt); 
    Integer maxInt = new Integer("2147483647"); 
    System.out.println(minInt);  
    System.out.println(bigInt); 
    System.out.println(maxInt); 
         
    long myLong = -9223372036854775808L; 
    long bigLong = 9223372036854775807L; 
 
    //Long class 
    Long minLong = new Long(myLong); 
    Long maxLong = new Long("9223372036854775807"); 
    System.out.println(minLong);  
    System.out.println(bigLong); 
    System.out.println(maxLong); 
 
    /* 
      Output 
      -32768 
      32767 
      32767 
      -2147483648 
      2147483647 
      2147483647 
      -9223372036854775808 
      9223372036854775807 
      9223372036854775807 
   */ 
</pre><p class="calibre7">In the preceding code, take note of the <code class="literal">int</code> type and <code class="literal">Integer</code> class. Unlike the other primitive wrapper classes, <code class="literal">Integer</code> does not share the same name as the identifier it is supporting.</p><p class="calibre7">Also, note the <code class="literal">long</code> type and its assigned values. In each case, the values have the suffix <code class="literal">L</code>. This is a requirement for <code class="literal">long</code> literals in Java because the compiler interprets all numeral literals as 32-bit integers. If you want to explicitly specify that your literal is larger than 32-bit, you must append the suffix <code class="literal">L</code>. Otherwise, the compiler will honk at you. This is not a requirement, however, when passing a string value into the <code class="literal">Long</code> class constructor:</p><pre class="programlisting">    Long maxLong = new Long("9223372036854775807"); 
</pre><p class="calibre7"><span class="strong"><strong class="calibre16">Objective-C</strong></span></p><p class="calibre7">For 8-bit data, Objective-C provides the <code class="literal">char</code> data type in both signed and unsigned formats. As with other languages, the signed data type ranges from -127 to 128, while the unsigned data type ranges from 0 to 255. Developers also have the option to use Objective-C's fixed-width counterparts named <code class="literal">int8_t</code> and <code class="literal">uint8_t</code>. This pattern is repeated in the 16-, 32-, and 64-bit data types. Finally, Objective-C also provides an object-oriented wrapper class for each of the integer types in the form of the <code class="literal">NSNumber</code> class:</p><div class="informaltable" title="Note"><h3 class="title1"><a id="note5" class="calibre1"/>Note</h3><p class="calibre7">The difference between the <code class="literal">char</code> or the other integer data type identifiers and their fixed-width counterparts is an important distinction. With the exception of char, which is always precisely 1 byte in length, every other integer data type in Objective-C will vary in size, depending on the implementation and underlying architecture. This is because Objective-C is based on C, which was designed to work at peak efficiency with various types of underlying architectures. Although it is possible to determine the exact length of an integer type at runtime, at compile, you can only be certain that <code class="literal">short &lt;= int &lt;= long &lt;= long long</code>.</p><p class="calibre7">This is where <span class="strong"><strong class="calibre16">fixed-width integers</strong></span> come in handy. If more rigid control over the number of bytes is required, the <code class="literal">(u)int&lt;n&gt;_t</code> data types allow you to denote integers that are precisely 8-, 16-, 32-, or 64-bit in length.</p></div><pre class="programlisting">    //Objective-C 
    char number = -127; 
    unsigned char uNumber = 255; 
    NSLog(@"Signed char number: %hhd", number); 
    NSLog(@"Unsigned char uNumber: %hhu", uNumber); 
     
    //fixed width 
    int8_t fixedNumber = -127; 
    uint8_t fixedUNumber = 255; 
    NSLog(@"fixedNumber8: %hhd", fixedNumber8); 
    NSLog(@"fixedUNumber8: %hhu", fixedUNumber8); 
 
    NSNumber *charNumber = [NSNumber numberWithChar:number]; 
    NSLog(@"Char charNumber: %@", [charNumber stringValue]); 
 
    /*  
      Output 
      Signed char number: -127 
      Unsigned char uNumber: 255 
      fixedNumber8: -127 
      fixedUNumber8: 255 
      Char charNumber: -127 
    */ 
</pre><p class="calibre7">In the preceding example, you can see that, when using the <code class="literal">char</code> data types in code, you must specify the <code class="literal">unsigned</code> identifier, such as <code class="literal">unsigned char</code>. However, <code class="literal">signed</code> is the default and may be omitted, which means the <code class="literal">char</code> type is equivalent to <code class="literal">signed char</code>. This pattern applies to each of the integer data types in Objective-C.</p><p class="calibre7">Larger integer types in Objective-C include <code class="literal">short</code> for 16-bit, <code class="literal">int</code> for 32-bit, and <code class="literal">long long</code> for 64-bit. Each of these has a fixed-width counterpart following the <code class="literal">(u)int&lt;n&gt;_t</code> pattern. Supporting methods are also available for each type within the <code class="literal">NSNumber</code> class:</p><pre class="programlisting">    //Larger Objective-C types 
    short aShort = -32768; 
    unsigned short anUnsignedShort = 65535; 
    NSLog(@"Signed short aShort: %hd", aShort); 
    NSLog(@"Unsigned short anUnsignedShort: %hu", anUnsignedShort); 
 
    int16_t fixedNumber16 = -32768; 
    uint16_t fixedUNumber16 = 65535; 
    NSLog(@"fixedNumber16: %hd", fixedNumber16); 
    NSLog(@"fixedUNumber16: %hu", fixedUNumber16); 
 
    NSNumber *shortNumber = [NSNumber numberWithShort:aShort]; 
    NSLog(@"Short shortNumber: %@", [shortNumber stringValue]); 
 
    int anInt = -2147483648; 
    unsigned int anUnsignedInt = 4294967295; 
    NSLog(@"Signed Int anInt: %d", anInt); 
    NSLog(@"Unsigned Int anUnsignedInt: %u", anUnsignedInt); 
 
    int32_t fixedNumber32 = -2147483648; 
    uint32_t fixedUNumber32 = 4294967295; 
    NSLog(@"fixedNumber32: %d", fixedNumber32); 
    NSLog(@"fixedUNumber32: %u", fixedUNumber32); 
 
    NSNumber *intNumber = [NSNumber numberWithInt:anInt]; 
    NSLog(@"Int intNumber: %@", [intNumber stringValue]); 
 
    long long aLongLong = -9223372036854775808; 
    unsigned long long anUnsignedLongLong = 18446744073709551615; 
    NSLog(@"Signed long long aLongLong: %lld", aLongLong); 
    NSLog(@"Unsigned long long anUnsignedLongLong: %llu", anUnsignedLongLong); 
 
    int64_t fixedNumber64 = -9223372036854775808; 
    uint64_t fixedUNumber64 = 18446744073709551615; 
    NSLog(@"fixedNumber64: %lld", fixedNumber64); 
    NSLog(@"fixedUNumber64: %llu", fixedUNumber64); 
 
    NSNumber *longlongNumber = [NSNumber numberWithLongLong:aLongLong]; 
    NSLog(@"Long long longlongNumber: %@", [longlongNumber stringValue]); 
 
    /*  
      Output 
      Signed short aShort: -32768 
      Unsigned short anUnsignedShort: 65535 
      fixedNumber16: -32768 
      fixedUNumber16: 65535 
      Short shortNumber: -32768 
      Signed Int anInt: -2147483648 
      Unsigned Int anUnsignedInt: 4294967295 
      fixedNumber32: -2147483648 
      fixedUNumber32: 4294967295 
      Int intNumber: -2147483648 
      Signed long long aLongLong: -9223372036854775808 
      Unsigned long long anUnsignedLongLong: 18446744073709551615 
      fixedNumber64: -9223372036854775808 
      fixedUNumber64: 18446744073709551615 
      Long long longlongNumber: -9223372036854775808 
    */ 
</pre><span class="strong"><strong class="calibre16">Swift</strong></span><p class="calibre7">The Swift language is similar to others, in that, it provides separate identifiers for signed and unsigned integers, for example <code class="literal">Int8</code> and <code class="literal">UInt8</code>. This pattern applies to each of the integer data types in Swift, making it possibly the simplest language in terms of remembering which identifier applies to which type:</p><pre class="programlisting">    //Swift 
    var int8 : Int8 = -127 
    var uint8 : UInt8 = 255 
    print("int8: \(int8)") 
    print("uint8: \(uint8)") 
 
    /*  
      Output 
      int8: -127  
      uint8: 255 
    */ 
</pre><p class="calibre7">In the preceding example, I have explicitly declared the data type using the <code class="literal">:Int8</code> and <code class="literal">: UInt8</code> identifiers to demonstrate explicit declaration. In Swift, it is also acceptable to leave these identifiers out and allow Swift to infer the types dynamically at runtime:</p><pre class="programlisting">    //Larger Swift types 
    var int16 : Int16 = -32768 
    var uint16 : UInt16 = 65535 
    print("int16: \(int16)") 
    print("uint16: \(uint16)") 
 
    var int32 : Int32 = -2147483648 
    var uint32 : UInt32 = 4294967295 
    print("int32: \(int32)") 
    print("uint32: \(uint32)") 
 
    var int64 : Int64 = -9223372036854775808 
    var uint64 : UInt64 = 18446744073709551615 
    print("int64: \(int64)") 
    print("uint64: \(uint64)") 
 
    /*  
      Output 
      int16: -32768 
      uint16: 65535 
      int32: -2147483648 
      uint32: 4294967295 
      int64: -9223372036854775808 
      uint64: 18446744073709551615 
    */ 
</pre><p class="calibre7">Why do I need to know this?</p><p class="calibre7">You may ask, Why do I need to know the ins and outs of these data types? Can't I just declare an <code class="literal">int</code> object or some similar identifier and move on to writing the interesting code? Modern computers and even mobile devices provide nearly unlimited resources, so it's not a big deal, right?</p><p class="calibre7">Well, not exactly. It is true that, in many circumstances in your daily programming experience, any integer type will do. For example, looping through a list of license plates issued at <span class="strong"><strong class="calibre16">Department of Motor Vehicles</strong></span> (<span class="strong"><strong class="calibre16">DMV</strong></span>) offices across the state of West Virginia on any given day may yield anything from a few dozen to perhaps a few hundred results. You could control the <code class="literal">for</code> loop's iterations using a <code class="literal">short</code> or you could use <code class="literal">long long</code>. Either way, the loop will have very little impact on the performance of your system.</p><p class="calibre7">However, what if you're dealing with a set of data where each discrete result in that set can fit in a 16-bit type, but you choose a 32-bit identifier just because that's what you're used to? You've just doubled the amount of memory required to manage that collection. This decision wouldn't matter with 100 or maybe even 100,000 results. However, when you start working with very large sets of data, with hundreds of thousands or even millions of discrete results, such design decisions can have a huge impact on system performance.</p></div></div></div>

<div class="book" title="Chapter&#xA0;1.&#xA0;Data Types: Foundational Structures">
<div class="book" title="Numeric data types">
<div class="book" title="Single precision float"><div class="book"><div class="book"><div class="book"><h2 class="title2" id="calibre_pb_3"><a id="ch01lvl2sec6" class="calibre1"/>Single precision float</h2></div></div></div><p class="calibre7"><span class="strong"><strong class="calibre16">Single precision floating point</strong></span> numbers, or <span class="strong"><strong class="calibre16">floats</strong></span> as they are more commonly referred to, are 32-bit floating point containers that allow storing values with much greater precision than integer types, typically to six or seven significant digits. Many languages use the <code class="literal">float</code> keyword or identifier for single-precision float values, and that is the case for each of the four languages we are discussing.</p><p class="calibre7">You should be aware that floating point values are subject to rounding errors because they cannot represent base-10 numbers exactly. The arithmetic of floating point types is a fairly complex topic, the details of which will not be pertinent to the majority of developers on any given day. However, it is still a good practice to familiarize yourself with the particulars of the underlying science as well as the implementation in each language.</p><div class="informaltable" title="Note"><h3 class="title1"><a id="note6" class="calibre1"/>Note</h3><p class="calibre7">As I am by no means an expert on the subject, this discussion will only scratch the surface of the science behind these types, and we will not even begin to cover the arithmetic. There are others who truly are experts in this area, however, and I highly recommend you review some of their work listed in the <span class="strong"><em class="calibre20">Additional resources</em></span> section at the end of this chapter.</p></div><span class="strong"><strong class="calibre16">C#</strong></span><p class="calibre7">In C#, the <code class="literal">float</code> keyword identifies 32-bit floating point values. The C# <code class="literal">float</code> data type has an approximate range of -3.4 × 10<sup class="calibre21">38 </sup>to +3.4 × 10<sup class="calibre21">38</sup> and a precision of six significant digits:</p><pre class="programlisting">    //C# 
    float piFloat = 3.14159265358979323846264338327f; 
    Console.WriteLine("piFloat: {0}", piFloat); 
 
    /*  
      Output 
      piFloat: 3.141593 
    */ 
</pre><p class="calibre7">When you examine the preceding code, you will notice that the <code class="literal">float</code> value assignment has the <code class="literal">f</code> suffix. This is because, like other C-based languages, C# treats real numeric literals on the right-hand side of assignments as a <span class="strong"><strong class="calibre16">double</strong></span> (discussed later) by default. If you leave the <code class="literal">f</code> or <code class="literal">F</code> suffix off the assignment, you will receive a compilation error, because you are trying to assign a double point precision value to a single point precision type.</p><p class="calibre7">Also, note the rounding error in the last digit. We populated the <code class="literal">piFloat</code> object with pi presented out to 30 significant digits. However, <code class="literal">float</code> can only retain six significant digits, so the software rounded off everything after that. When pi is calculated out to six significant digits, we get 3.141592, but our <code class="literal">float</code> value is now 3.141593 due to this limitation.</p><p class="calibre7"><span class="strong"><strong class="calibre16">Java</strong></span></p><p class="calibre7">As with C#, Java uses the <span class="strong"><strong class="calibre16">float</strong></span> identifier for floating point values. In Java, a <code class="literal">float</code> has an approximate range of -3.4 × 10<sup class="calibre21">38</sup> to +3.4 × 10<sup class="calibre21">38</sup> and a precision of six or seven significant digits:</p><pre class="programlisting">    //Java 
    float piFloat = 3.141592653589793238462643383279f; 
    System.out.println(piFloat);  
 
    /*  
      Output 
      3.1415927 
    */ 
</pre><p class="calibre7">When you examine the preceding code, you will notice that the float value assignment has the <code class="literal">f</code> suffix. This is because, like other C based languages, Java treats real numeric literals on the right side of assignments as a double by default. If you leave the <code class="literal">f</code> or <code class="literal">F</code> suffix off the assignment, you will receive a compilation error because you are trying to assign a double-point precision value to a single-point precision type.</p><p class="calibre7"><span class="strong"><strong class="calibre16">Objective-C</strong></span></p><p class="calibre7">Objective-C uses the <code class="literal">float</code> identifier for floating point values. In Objective-C, a <code class="literal">float</code> has an approximate range of -3.4 × 10<sup class="calibre21">38 </sup>to +3.4 × 10<sup class="calibre21">38</sup> and a precision of 6 significant digits:</p><pre class="programlisting">    //Objective-C 
    float piFloat = 3.14159265358979323846264338327f; 
    NSLog(@"piFloat: %f", piFloat); 
 
    NSNumber *floatNumber = [NSNumber numberWithFloat:piFloat]; 
    NSLog(@"floatNumber: %@", [floatNumber stringValue]); 
 
    /*  
      Output 
      piFloat: 3.141593 
      floatNumber: 3.141593 
    */ 
</pre><p class="calibre7">When you examine the preceding code, you will notice that the float value assignment has the <code class="literal">f</code> suffix. This is because, like other C-based languages, Objective-C treats real numeric literals on the right-hand side of assignments as a double by default. If you leave the <code class="literal">f</code> or <code class="literal">F</code> suffix off of the assignment, you will receive a compilation error because you are trying to assign a double-point precision value to a single-point precision type.</p><p class="calibre7">Also, note the rounding error in the last digit. We populated the <code class="literal">piFloat</code> object with pi presented out to 30 significant digits, but float can only retain six significant digits, so the software rounded off everything after that. When pi is calculated out to six significant digits, we get 3.141592, but our float value is now 3.141593 due to this limitation.</p><p class="calibre7"><span class="strong"><strong class="calibre16">Swift</strong></span></p><p class="calibre7">Swift uses the <code class="literal">float</code> identifier for floating point values. In Swift, a <code class="literal">float</code> has an approximate range of -3.4 × 10<sup class="calibre21">38 </sup>to +3.4 × 10<sup class="calibre21">38</sup> and a precision of six significant digits:</p><pre class="programlisting">    //Swift 
    var floatValue : Float = 3.141592653589793238462643383279 
    print("floatValue: \(floatValue)") 
 
    /* 
      Output 
      floatValue: 3.141593 
    */ 
</pre><p class="calibre7">When you examine the preceding code, you will notice that the float value assignment has the <code class="literal">f</code> suffix. This is because, like other C-based languages, Swift treats real numeric literals on the right-hand side of assignments as a double by default. If you leave the <code class="literal">f</code> or <code class="literal">F</code> suffix off of the assignment, you will receive a compilation error because you are trying to assign a double-point precision value to a single-point precision type.</p><p class="calibre7">Also, note the rounding error in the last digit. We populated the <code class="literal">floatValue</code> object with pi presented out to 30 significant digits, but float can only retain six significant digits, so the software rounded off everything after that. When pi is calculated out to six significant digits, we get 3.141592, but our float value is now 3.141593 due to this limitation.</p></div></div></div>

<div class="book" title="Chapter&#xA0;1.&#xA0;Data Types: Foundational Structures">
<div class="book" title="Numeric data types">
<div class="book" title="Double precision float"><div class="book"><div class="book"><div class="book"><h2 class="title2" id="calibre_pb_4"><a id="ch01lvl2sec7" class="calibre1"/>Double precision float</h2></div></div></div><p class="calibre7"><span class="strong"><strong class="calibre16">Double precision floating point</strong></span> numbers, or <span class="strong"><strong class="calibre16">doubles</strong></span> as they are more commonly referred to, are 64-bit floating point values that allow storing values with much greater precision than the integer types, typically to 15 significant digits. Many languages use the double identifier for double precision float values and that is also the case for each of the four languages we are discussing.</p><div class="informaltable" title="Note"><h3 class="title1"><a id="note7" class="calibre1"/>Note</h3><p class="calibre7">In most circumstances, it will not matter whether you choose <code class="literal">float</code> over <code class="literal">double</code> unless memory space is a concern, in which case you will want to choose <code class="literal">float</code> whenever possible. Many argue that <code class="literal">float</code> is more performant than double under most conditions, and generally speaking, this is the case. However, there are other conditions where <code class="literal">double</code> will be more performant than <code class="literal">float</code>. The reality is that the efficiency of each type is going to vary from case to case, based on criteria that are too numerous to detail in the context of this discussion. Therefore, if your particular application requires truly peak efficiency, you should research the requirements and environmental factors carefully and decide what is best for your situation. Otherwise, just use whichever container will get the job done and move on.</p></div><span class="strong"><strong class="calibre16">C#</strong></span><p class="calibre7">In C#, the <code class="literal">double</code> keyword identifies 64-bit floating point values. The C# <code class="literal">double</code> has an approximate range of ±5.0 × 10<sup class="calibre21">−324</sup> to ±1.7 × 10<sup class="calibre21">308</sup> and a precision of 14 or 15 significant digits:</p><pre class="programlisting">    //C# 
    double piDouble = 3.14159265358979323846264338327; 
    double wholeDouble = 3d; 
    Console.WriteLine("piDouble: {0}", piDouble); 
    Console.WriteLine("wholeDouble: {0}", wholeDouble); 
 
    /*  
      Output 
      piDouble: 3.14159265358979 
      wholeDouble: 3 
    */ 
</pre><p class="calibre7">When you examine the preceding code, you will notice that the <code class="literal">wholeDouble</code> value assignment has the <code class="literal">d</code> suffix. This is because, like other C-based languages, C# treats real numeric literals on the right-hand side of assignments as integers by default. If you were to leave the <code class="literal">d</code> or <code class="literal">D</code> suffix off the assignment, you will receive a compilation error because you are trying to assign an integer value to a double-point precision type.</p><p class="calibre7">Also, note the rounding error in the last digit. We populated the <code class="literal">piDouble</code> object using pi out to 30 significant digits, but double can only retain 14 significant digits, so the software rounded off everything after that. When pi is calculated out to 15 significant digits, we get 3.141592653589793, but our float value is now 3.14159265358979 due to this limitation.</p><p class="calibre7"><span class="strong"><strong class="calibre16">Java</strong></span></p><p class="calibre7">In Java, the <code class="literal">double</code> keyword identifies 64-bit floating-point values. The Java <code class="literal">double</code> has an approximate range of ±4.9 × 10<sup class="calibre21">−324</sup> to ±1.8 × 10<sup class="calibre21">308</sup> and a precision of 15 or 16 significant digits:</p><pre class="programlisting">    double piDouble = 3.141592653589793238462643383279; 
    System.out.println(piDouble); 
 
    /*  
      Output 
      3.141592653589793 
    */ 
</pre><p class="calibre7">When you examine the preceding code, note the rounding error in the last digit. We populated the <code class="literal">piDouble</code> object using pi out to 30 significant digits, but double can only retain 15 significant digits, so the software rounded off everything after that. When pi is calculated out to 15 significant digits, we get 3.1415926535897932, but our float value is now 3.141592653589793 due to this limitation.</p><p class="calibre7"><span class="strong"><strong class="calibre16">Objective-C</strong></span></p><p class="calibre7">Objective-C also uses the <code class="literal">double</code> identifier for 64-bit floating point values. The Objective-C double has an approximate range of 2.3E<sup class="calibre21">-308</sup> to 1.7E<sup class="calibre21">308</sup> and a precision of 15 significant digits. Objective-C takes accuracy a step further by providing an even more precise version of double called the <span class="strong"><strong class="calibre16">long double</strong></span>. The long double identifier is used for an 80 bit storage container with a range of 3.4E<sup class="calibre21">-4932</sup> to 1.1E<sup class="calibre21">4932</sup> and a precision of 19 significant digits:</p><pre class="programlisting">    //Objective-C 
    double piDouble = 3.14159265358979323846264338327; 
    NSLog(@"piDouble: %.15f", piDouble); 
 
    NSNumber *doubleNumber = [NSNumber numberWithDouble:piDouble]; 
    NSLog(@"doubleNumber: %@", [doubleNumber stringValue]); 
 
    /* 
      Output 
      piDouble: 3.141592653589793 
      doubleNumber: 3.141592653589793 
    */ 
</pre><p class="calibre7">In our preceding example, note the rounding error in the last digit. We populated the <code class="literal">piDouble</code> object using pi out to 30 significant digits, but double can only retain 15 significant digits, so the software rounded off everything after that. When pi is calculated out to 15 significant digits, we get 3.1415926535897932, but our float value is now 3.141592653589793 due to this limitation.</p><p class="calibre7"><span class="strong"><strong class="calibre16">Swift</strong></span></p><p class="calibre7">Swift uses the <code class="literal">double</code> identifier for 64-bit floating-point values. In Swift, a double has an approximate range of 2.3E<sup class="calibre21">-308</sup> to 1.7E<sup class="calibre21">308</sup> and a precision of 15 significant digits. Note that, according to Apple's documentation for Swift, when either <code class="literal">float</code> or <code class="literal">double</code> types will suffice, double is recommended:</p><pre class="programlisting">    //Swift 
    var doubleValue : Double = 3.141592653589793238462643383279 
    print("doubleValue: \(doubleValue)") 
 
    /* 
      Output 
      doubleValue: 3.14159265358979 
    */ 
</pre><p class="calibre7">In our preceding example, note the rounding error in the last digit. We populated the <code class="literal">doubleValue</code> object using pi out to 30 significant digits, but double can only retain 15 significant digits, so the software rounded off everything after that. When pi is calculated out to 15 significant digits, we get 3.141592653589793, but our <code class="literal">float</code> value is now 3.14159265358979 due to this limitation.</p></div></div></div>

<div class="book" title="Chapter&#xA0;1.&#xA0;Data Types: Foundational Structures">
<div class="book" title="Numeric data types">
<div class="book" title="Currency"><div class="book"><div class="book"><div class="book"><h2 class="title2" id="calibre_pb_5"><a id="ch01lvl2sec8" class="calibre1"/>Currency</h2></div></div></div><p class="calibre7">Due to the inherent inaccuracy found in floating point arithmetic, grounded in the fact that they are based on binary arithmetic, floats, and doubles cannot accurately represent the base-10 multiples we use for currency. Representing currency as a <code class="literal">float</code> or <code class="literal">double</code> may seem like a good idea at first as the software will round off the tiny errors in your arithmetic. However, as you begin to perform more and complex arithmetic operations on these inexact results, your precision errors will begin to add up and result in serious inaccuracies and bugs that can be very difficult to track down. This makes float and double data types insufficient for working with currency where perfect accuracy for multiples of 10 is essential. Luckily, each of the languages we are discussing provides a mechanism to work with currency, and other arithmetic problems require high precision in based-10 values and calculations.</p><p class="calibre7"><span class="strong"><strong class="calibre16">C#</strong></span></p><p class="calibre7">C# uses the <code class="literal">decimal</code> keyword for precise floating-point values. In C#, <code class="literal">decimal</code> has a range of ±1.0 x 10<sup class="calibre21">-28</sup> to ±7.9 x 10<sup class="calibre21">28</sup> with a precision of 28 or 29 significant digits:</p><pre class="programlisting">    var decimalValue = NSDecimalNumber.init(string:"3.141592653589793238462643383279") 
    print("decimalValue \(decimalValue)") 
 
    /* 
      Output 
      piDecimal: 3.1415926535897932384626433833 
    */ 
</pre><p class="calibre7">In the preceding example, note that we populated the <code class="literal">decimalValue</code> object with pi out to 30 significant digits, but the framework rounded this off to 28 significant digits.</p><p class="calibre7"><span class="strong"><strong class="calibre16">Java</strong></span></p><p class="calibre7">Java provides an object-oriented solution to the currency problem in the form of the <code class="literal">BigDecimal</code> class:</p><pre class="programlisting">    BigDecimal piDecimal = new BigDecimal("3.141592653589793238462643383279"); 
    System.out.println(piDecimal); 
 
    /* 
      Output 
      3.141592653589793238462643383279 
    */ 
</pre><p class="calibre7">In the preceding example, we are initializing the <code class="literal">BigDecimal</code> class using a constructor that takes a string representation of our decimal value as a parameter. When the program runs, the output proves that the <code class="literal">BigDecimal</code> class did not lose any of our intended precision, returning pi to 30 significant digits.</p><p class="calibre7"><span class="strong"><strong class="calibre16">Objective-C </strong></span></p><p class="calibre7">Objective-C also provides an object-oriented solution to the currency problem in the form of the <code class="literal">NSDecimalNumber</code> class:</p><pre class="programlisting">    //Objective-C 
    NSDecimalNumber *piDecimalNumber = [[NSDecimalNumber alloc] initWithDouble:3.14159265358979323846264338327]; 
    NSLog(@"piDecimalNumber: %@", [piDecimalNumber stringValue]); 
 
    /* 
      Output 
      piDecimalNumber: 3.141592653589793792 
    */ 
</pre><p class="calibre7"><span class="strong"><strong class="calibre16">Swift</strong></span></p><p class="calibre7">Swift also provides an object-oriented solution to the currency problem, and it is the same class used in Objective-C, the <code class="literal">NSDecimalNumber</code> class. The Swift version is initialized slightly differently, but it retains the same functionality as its Objective-C counterpart:</p><pre class="programlisting">    var decimalValue = NSDecimalNumber.init(string:"3.141592653589793238462643383279") 
    print("decimalValue \(decimalValue)") 
 
    /* 
      Output 
      decimalValue 3.141592653589793238462643383279 
    */ 
</pre><p class="calibre7">Note that precision, in both the Objective-C and Swift examples, is retained out to 30 significant digits, proving that the <code class="literal">NSDecimalNumber</code> class is superior for working with currency and other base-10 values.</p><div class="informaltable" title="Note"><h3 class="title1"><a id="tip8" class="calibre1"/>Tip</h3><p class="calibre7">In the spirit of full disclosure, there is a simple and arguably more elegant alternative to using these custom types. You could just use <code class="literal">int</code> or <code class="literal">long</code> for your currency calculations and count in cents rather than dollars:</p><p class="calibre7">    //C# long total = 316;</p><p class="calibre7">    //$3.16</p></div></div></div></div>

<div class="book" title="Chapter&#xA0;1.&#xA0;Data Types: Foundational Structures">
<div class="book" title="Numeric data types">
<div class="book" title="Typecasting"><div class="book"><div class="book"><div class="book"><h2 class="title2" id="calibre_pb_6"><a id="ch01lvl2sec9" class="calibre1"/>Typecasting</h2></div></div></div><p class="calibre7">In the realm of computer science, <span class="strong"><strong class="calibre16">type conversion</strong></span> or <span class="strong"><strong class="calibre16">typecasting</strong></span> means to converting an instance of one object or data type into another. For example, let's say you make a call to a method that returns an integer value but you need to use that value in another method that requires a long value as the input parameter. Since an integer value by definition exists within the realm of allowable <code class="literal">long</code> values, the <code class="literal">int</code> value can be redefined as a long.</p><p class="calibre7">Such conversions can be done through either implicit conversion, sometimes called <span class="strong"><strong class="calibre16">coercion</strong></span>, or explicit conversion, otherwise known as <span class="strong"><strong class="calibre16">casting</strong></span>. To fully appreciate casting, we also need to understand the difference between <span class="strong"><strong class="calibre16">static</strong></span> and <span class="strong"><strong class="calibre16">dynamic</strong></span> languages.</p><div class="book" title="Statically versus dynamically typed languages"><div class="book"><div class="book"><div class="book"><h3 class="title1"><a id="ch01lvl3sec0" class="calibre1"/>Statically versus dynamically typed languages</h3></div></div></div><p class="calibre7">A statically typed language will perform its <span class="strong"><strong class="calibre16">type checking</strong></span> at compile time. This means that, when you try to build your solution, the compiler will verify and enforce each of the constraints that apply to the types in your application. If they are not enforced, you will receive an error and the application will not build. C#, Java, and Swift are all statically typed languages.</p><p class="calibre7">Dynamically typed languages, on the other hand, do most or all of their type checking at run time. This means that the application might build just fine, but could experience a problem while it is actually running if the developer wasn't careful in how he wrote the code. Objective-C is a dynamically typed language because it uses a mixture of statically typed objects and dynamically typed objects. The plain C objects used for numeric values discussed earlier in this chapter are all examples of statically typed objects, while the Objective-C classes <code class="literal">NSNumber</code> and <code class="literal">NSDecimalNumber</code> are both examples of dynamically typed objects. Consider the following code example in Objective-C:</p><pre class="programlisting">    double myDouble = @"chicken"; 
    NSNumber *myNumber = @"salad"; 
</pre><p class="calibre7">The compiler will throw an error on the first line, stating <code class="literal">Initializing 'double' with an expression of incompatible type 'NSString *'</code>. That's because <code class="literal">double</code> is a plain C object, and it is statically typed. The compiler knows what to do with this statically typed object before we even get to the build, so your build will fail.</p><p class="calibre7">However, the compiler will only throw a warning on the second line, stating <code class="literal">Incompatible pointer types initializing 'NSNumber *' with an expression of type 'NSString *'</code>. That's because <code class="literal">NSNumber</code> is an Objective-C class, and it is dynamically typed. The compiler is smart enough to catch your mistake, but it will allow the build to succeed (unless you have instructed the compiler to treat warnings as errors in your build settings).</p><div class="informaltable" title="Note"><h3 class="title1"><a id="tip9" class="calibre1"/>Tip</h3><p class="calibre7">Although the forthcoming crash at runtime is obvious in the previous example, there are cases where your app will function perfectly fine despite the warnings. However, no matter what type of language you are working with, it is always a good idea to consistently clean up your code warnings before moving on to new code. This helps keep your code clean and avoids any runtime errors which can be difficult to diagnose.</p><p class="calibre7">On those rare occasions where it is not prudent to address the warning immediately, you should clearly document your code and explain the source of the warning so that other developers will understand your reasoning. As a last resort, you can take advantage of macros or pre-processor (pre-compiler) directives that can suppress warnings on a line-by-line basis.</p></div></div><div class="book" title="Implicit and explicit casting"><div class="book"><div class="book"><div class="book"><h3 class="title1"><a id="ch01lvl3sec1" class="calibre1"/>Implicit and explicit casting</h3></div></div></div><p class="calibre7"><span class="strong"><strong class="calibre16">Implicit casting</strong></span> does not require any special syntax in your source code. This makes implicit casting somewhat convenient. Consider the following code example in C#:</p><pre class="programlisting">    int a = 10; 
    double b = a++; 
</pre><p class="calibre7">In this scenario, since <code class="literal">a</code> can be defined as both an <code class="literal">int</code> and a <code class="literal">double</code>, the cast to type <code class="literal">double</code> is perfectly acceptable because we have defined both types manually. However, since implicit casts do not necessarily define their types manually, the compiler cannot always determine which constraints apply to the conversion and therefore will not be able to check these constraints until runtime. This makes the implicit cast also somewhat dangerous. Consider the following code example also in C#:</p><pre class="programlisting">    double x = "54"; 
</pre><p class="calibre7">This is an implicit conversion because you have not told the compiler how to treat the string value. In this case, the conversion will fail when you try to build the application, and the compiler will throw an error for this line, stating <code class="literal">Cannot implicitly convert type 'string' to 'double'</code>. Now, consider the explicitly cast version of this example:</p><pre class="programlisting">    double x = double.Parse("42"); 
    Console.WriteLine("40 + 2 = {0}", x); 
 
    /* 
      Output 
      40 + 2 = 42 
    */ 
</pre><p class="calibre7">This conversion is explicit and therefore type-safe, assuming that the string value is <span class="strong"><em class="calibre20">parsable</em></span>.</p></div><div class="book" title="Widening and narrowing"><div class="book"><div class="book"><div class="book"><h3 class="title1"><a id="ch01lvl3sec2" class="calibre1"/>Widening and narrowing</h3></div></div></div><p class="calibre7">When casting between two types, an important consideration is whether the result of the change is within the range of the target data type. If your source data type supports more bytes than your target data type, the cast is considered to be a <span class="strong"><strong class="calibre16">narrowing conversion</strong></span>.</p><p class="calibre7">Narrowing conversions are either casts that cannot be proven to always succeed or casts that are known to possibly lose information. For example, casting from a float to an integer will result in loss of information (precision in this case), as the result will be rounded off to the nearest whole number. In most statically typed languages, narrowing casts cannot be performed implicitly. Here is an example by borrowing from the C# single-precision and double-precision examples earlier in this chapter:</p><pre class="programlisting">    //C# 
    piFloat = piDouble; 
</pre><p class="calibre7">In this example, the compiler will throw an error, stating <code class="literal">Cannot implicitly convert type 'double' to 'float'. And explicit conversion exists (Are you missing a cast?)</code>. The compiler sees this as a narrowing conversion and treats the loss of precision as an error. The error message itself is helpful and suggests an explicit cast as a potential solution for our problem:</p><pre class="programlisting">    //C# 
    piFloat = (float)piDouble;   
</pre><p class="calibre7">We have now explicitly cast the double value <code class="literal">piDouble</code> to a <code class="literal">float</code>, and the compiler no longer concerns itself with loss of precision.</p><p class="calibre7">If your source data type supports fewer bytes than your target data type, the cast is considered to be a <span class="strong"><strong class="calibre16">widening conversion</strong></span>. Widening conversions will preserve the source object's value, but may change its representation in some way. Most statically typed languages will permit implicit widening casts. Let's borrow again from our previous C# example:</p><pre class="programlisting">    //C# 
    piDouble = piFloat; 
</pre><p class="calibre7">In this example, the compiler is completely satisfied with the implicit conversion and the app will build. Let's expand the example further:</p><pre class="programlisting">    //C# 
    piDouble = (double)piFloat; 
</pre><p class="calibre7">This explicit cast improves readability, but does not change the nature of the statement in any way. The compiler also finds this format to be completely acceptable, even if it is somewhat more verbose. Beyond improved readability, explicit casting when widening adds nothing to your application. Therefore, it is your preference if you want to use explicit casting when widening is a matter of personal preference.</p></div></div></div></div>

<div class="book" title="Boolean data type"><div class="book" id="F8902-77f2b5b248f04368a6f723b0e9357ef3"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec8" class="calibre1"/>Boolean data type</h1></div></div></div><p class="calibre7">Boolean data types are intended to symbolize binary values, usually denoted by <code class="literal">1</code> and <code class="literal">0</code>, <code class="literal">true</code> and <code class="literal">false</code>, or even <code class="literal">YES</code> and <code class="literal">NO</code>. Boolean types are used to represent truth logic, which is based on Boolean algebra. This is just a way of saying that Boolean values are used in conditional statements, such as <code class="literal">if</code> or <code class="literal">while</code>, to evaluate logic or repeat an execution conditionally.</p><p class="calibre7">Equality operations include any operations that compare the value of any two entities. The equality operators are:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="literal">==</code> implies equal to</li><li class="listitem"><code class="literal">!=</code> implies not equal to</li></ul></div><p class="calibre7">Relational operations include any operations that test a relation between two entities. The relational operators are:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="literal">&gt;</code> implies greater than</li><li class="listitem"><code class="literal">&gt;=</code> implies greater than or equal to</li><li class="listitem"><code class="literal">&lt;</code> implies less than</li><li class="listitem"><code class="literal">&lt;=</code> implies less than or equal to</li></ul></div><p class="calibre7">Logic operations include any operations in your program that evaluate and manipulate Boolean values. There are three primary logic operators, namely <code class="literal">AND</code>, <code class="literal">OR</code>, and <code class="literal">NOT</code>. Another, slightly less commonly used operator, is the <span class="strong"><strong class="calibre16">exclusive or</strong></span>, or XOR operator. All Boolean functions and statements can be built with these four basic operators.</p><p class="calibre7">The AND operator is the most exclusive comparator. Given two Boolean variables A and B, AND will return <code class="literal">true</code> if, and only if, both A and B is <code class="literal">true</code>. Boolean variables are often visualized using tools called <span class="strong"><strong class="calibre16">truth tables</strong></span>. Consider the following truth table for the AND operator:</p><div class="informaltable"><table border="1" class="calibre8"><colgroup class="calibre9"><col class="calibre10"/><col class="calibre10"/><col class="calibre10"/></colgroup><tbody class="calibre11"><tr class="calibre12"><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">A</strong></span></p>
</td><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">B</strong></span></p>
</td><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">A ^ B</strong></span></p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td></tr></tbody></table></div><p class="calibre7">This table demonstrates the AND operator. When evaluating a conditional statement, 0 is considered to be <code class="literal">false</code>, while any other value is considered to be <code class="literal">true</code>. Only when the value of both A and B is <code class="literal">true</code>, is the resulting comparison of A ^ B also <code class="literal">true</code>.</p><p class="calibre7">The OR operator is the inclusive operator. Given two Boolean variables A and B, OR will return <code class="literal">true</code> if either A or B is <code class="literal">true</code>, including the case when both A and B are <code class="literal">true</code>. Consider the following truth table for the OR operator:</p><div class="informaltable"><table border="1" class="calibre8"><colgroup class="calibre9"><col class="calibre10"/><col class="calibre10"/><col class="calibre10"/></colgroup><tbody class="calibre11"><tr class="calibre12"><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">A</strong></span></p>
</td><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">B</strong></span></p>
</td><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">A v B</strong></span></p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td></tr></tbody></table></div><p class="calibre7">Next, the NOT A operator is <code class="literal">true</code> when A is <code class="literal">false</code>, and <code class="literal">false</code> when A is <code class="literal">true</code>. Consider the following truth table for the NOT operator:</p><div class="informaltable"><table border="1" class="calibre8"><colgroup class="calibre9"><col class="calibre10"/><col class="calibre10"/></colgroup><tbody class="calibre11"><tr class="calibre12"><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">A</strong></span></p>
</td><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">!A</strong></span></p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td></tr></tbody></table></div><p class="calibre7">Finally, the XOR operator is <code class="literal">true</code> when either A or B is <code class="literal">true</code>, but not both. Another way to say it is, XOR is <code class="literal">true</code> when A and B are different. There are many occasions where it is useful to evaluate an expression in this manner, so most computer architectures include it. Consider the following truth table for XOR:</p><div class="informaltable"><table border="1" class="calibre8"><colgroup class="calibre9"><col class="calibre10"/><col class="calibre10"/><col class="calibre10"/></colgroup><tbody class="calibre11"><tr class="calibre12"><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">A</strong></span></p>
</td><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">B</strong></span></p>
</td><td class="calibre13">
<p class="calibre14"><span><strong class="calibre15">A XOR B</strong></span></p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td></tr><tr class="calibre12"><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">1</p>
</td><td class="calibre13">
<p class="calibre14">0</p>
</td></tr></tbody></table></div></div>

<div class="book" title="Boolean data type">
<div class="book" title="Operator precedence"><div class="book"><div class="book"><div class="book"><h2 class="title2" id="calibre_pb_1"><a id="ch01lvl2sec10" class="calibre1"/>Operator precedence</h2></div></div></div><p class="calibre7">Just as with arithmetic, comparison and Boolean operations have <span class="strong"><strong class="calibre16">operator precedence</strong></span>. This means the architecture will give a higher precedence to one operator over another. Generally speaking, the Boolean order of operations for all languages is as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Parentheses</li><li class="listitem">Relational operators</li><li class="listitem">Equality operators</li><li class="listitem">Bitwise operators (not discussed)</li><li class="listitem">NOT</li><li class="listitem">AND</li><li class="listitem">OR</li><li class="listitem">XOR</li><li class="listitem">Ternary operator</li><li class="listitem">Assignment operators</li></ul></div><p class="calibre7">It is extremely important to understand operator precedence when working with Boolean values, because mistaking how the architecture will evaluate complex logical operations will introduce bugs in your code that you will not understand how to sort out. When in doubt, remember that, as in arithmetic parentheses, take the highest precedence and anything defined within them will be evaluated first.</p></div></div>

<div class="book" title="Boolean data type">
<div class="book" title="Short-circuiting"><div class="book"><div class="book"><div class="book"><h2 class="title2" id="calibre_pb_2"><a id="ch01lvl2sec11" class="calibre1"/>Short-circuiting</h2></div></div></div><p class="calibre7">As you recall, AND only returns <code class="literal">true</code> when both of the operands are <code class="literal">true</code>, and OR returns <code class="literal">true</code> as soon as one operand is <code class="literal">true</code>. These characteristics sometimes make it possible to determine the outcome of an expression by evaluating only one of the operands. When your applications stops evaluation immediately upon determining the overall outcome of an expression, it is called <span class="strong"><strong class="calibre16">short-circuiting</strong></span>. There are three main reasons why you would want to use short-circuiting in your code.</p><p class="calibre7">First, short-circuiting can improve your application's performance by limiting the number of operations your code must perform. Second, when later operands could potentially generate errors based on the value of a previous operand, short-circuiting can halt execution before the higher risk operand is reached. Finally, short-circuiting can improve the readability and complexity of your code by eliminating the need for nested logical statements.</p><p class="calibre7"><span class="strong"><strong class="calibre16">C#</strong></span></p><p class="calibre7">C# uses the <code class="literal">bool</code> keyword as an alias of <code class="literal">System.Boolean</code> and stores the values <code class="literal">true</code> and <code class="literal">false</code>:</p><pre class="programlisting">    //C# 
    bool a = true; 
    bool b = false; 
    bool c = a; 
 
    Console.WriteLine("a: {0}", a); 
    Console.WriteLine("b: {0}", b); 
    Console.WriteLine("c: {0}", c); 
    Console.WriteLine("a AND b: {0}", a &amp;&amp; b); 
    Console.WriteLine("a OR b: {0}", a || b); 
    Console.WriteLine("NOT a: {0}", !a); 
    Console.WriteLine("NOT b: {0}", !b); 
    Console.WriteLine("a XOR b: {0}", a ^ b); 
    Console.WriteLine("(c OR b) AND a: {0}", (c || b) &amp;&amp; a); 
 
    /* 
      Output 
      a: True 
      b: False 
      c: True 
      a AND b: False 
      a OR b: True 
      NOT a: False 
      NOT b: True 
      a XOR b: True 
      (c OR b) AND a: True 
    */ 
</pre><p class="calibre7"><span class="strong"><strong class="calibre16">Java</strong></span></p><p class="calibre7">Java uses the <code class="literal">boolean</code> keyword for the primitive Boolean data type. Java also provides a <code class="literal">Boolean</code> wrapper class for the same primitive type:</p><pre class="programlisting">    //Java 
    boolean a = true; 
    boolean b = false; 
    boolean c = a; 
 
    System.out.println("a: " + a); 
    System.out.println("b: " + b); 
    System.out.println("c: " + c); 
    System.out.println("a AND b: " + (a &amp;&amp; b)); 
    System.out.println("a OR b: " + (a || b)); 
    System.out.println("NOT a: " + !a); 
    System.out.println("NOT b: " + !b); 
    System.out.println("a XOR b: " + (a ^ b)); 
    System.out.println("(c OR b) AND a: " + ((c || b) &amp;&amp; a)); 
 
    /* 
      Output 
      a: true 
      b: false 
      c: true 
      a AND b: false 
      a OR b: true 
      NOT a: false 
      NOT b: true 
      a XOR b: true 
     (c OR b) AND a: true 
    */ 
</pre><p class="calibre7"><span class="strong"><strong class="calibre16">Objective-C</strong></span></p><p class="calibre7">Objective-C uses the <code class="literal">BOOL</code> identifier to represent Boolean values:</p><pre class="programlisting">    //Objective-C 
    BOOL a = YES; 
    BOOL b = NO; 
    BOOL c = a; 
 
    NSLog(@"a: %hhd", a); 
    NSLog(@"b: %hhd", b); 
    NSLog(@"c: %hhd", c); 
    NSLog(@"a AND b: %d", a &amp;&amp; b); 
    NSLog(@"a OR b: %d", a || b); 
    NSLog(@"NOT a: %d", !a); 
    NSLog(@"NOT b: %d", !b); 
    NSLog(@"a XOR b: %d", a ^ b); 
    NSLog(@"(c OR b) AND a: %d", (c || b) &amp;&amp; a); 
 
    /* 
      Output 
      a: 1 
      b: 0 
      c: 1 
      a AND b: 0 
      a OR b: 1 
      NOT a: 0 
      NOT b: 1 
      a XOR b: 1 
      (c OR b) AND a: 1 
    */ 
</pre><div class="informaltable" title="Note"><h3 class="title1"><a id="note10" class="calibre1"/>Note</h3><p class="calibre7">As it happens, Boolean data types give Objective-C yet another opportunity to prove it is more complex than its counterparts. The language does not provide one identifier or class to represent logic values. It provides five. For the sake of simplicity (and because my editor won't give me the extra pages), we're only going to use <code class="literal">BOOL</code> in this text. If you want to know more, I encourage you to check out the <span class="strong"><em class="calibre20">Additional resources</em></span> section at the end of this chapter.</p></div><p class="calibre7"><span class="strong"><strong class="calibre16">Swift</strong></span></p><p class="calibre7">Swift uses the <code class="literal">Bool</code> keyword for the primitive Boolean data type:</p><pre class="programlisting">    //Swift 
    var a : Bool = true 
    var b : Bool = false 
    var c = a 
 
    print("a: \(a)") 
    print("b: \(b)") 
    print("c: \(c)") 
    print("a AND b: \(a &amp;&amp; b)") 
    print("a OR b: \(a || b)") 
    print("NOT a: \(!a)") 
    print("NOT b: \(!b)") 
    print("a XOR b: \(a != b)") 
    print("(c OR b) AND a: \((c || b) &amp;&amp; a)") 
 
    /* 
      Output 
      a: true 
      b: false 
      c: true 
      a AND b: false 
      a OR b: true 
      NOT a: false 
      NOT b: true 
      a XOR b: true 
      (c OR b) AND a: true 
    */ 
</pre><p class="calibre7">In the preceding example, the Boolean object <code class="literal">c</code> is not explicitly declared as <code class="literal">Bool</code>, but it is implicitly typed as a <code class="literal">Bool</code>. In Swift terms, the data type has been <span class="strong"><em class="calibre20">inferred</em></span> in this case. Also, note that Swift does not provide a specific XOR operator, so if you need that comparison, you should use the <code class="literal">(a != b)</code> pattern.</p><div class="informaltable" title="Note"><h3 class="title1"><a id="tip11" class="calibre1"/>Tip</h3><p class="calibre7">Objective-C nil values</p><p class="calibre7">In Objective-C, the value <code class="literal">nil</code> also evaluates to <code class="literal">false</code>. Although other languages must handle NULL objects with care, Objective-C will not crash when it attempts to perform an operation on a nil object. Speaking from personal experience, this can be somewhat confusing for developers who learned C# or Java before learning Objective-C, and thus expect an unhandled NULL object to crash their app. However, it is common for Objective-C developers to use this behavior to their advantage. Many times, simply checking whether an object is <code class="literal">nil</code> logically confirms whether an operation was successful, saving you from writing tedious logical comparisons.</p></div></div></div>
<div class="book" title="Strings" id="G6PI1-77f2b5b248f04368a6f723b0e9357ef3"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec9" class="calibre1"/>Strings</h1></div></div></div><p class="calibre7">Strings are not precisely data types, although as developers we very often treat them as such. In actuality, strings are simply objects whose value is text; under the hood, strings contain a sequential collection of read-only <code class="literal">char</code> objects. This read-only nature of a string object makes strings <span class="strong"><strong class="calibre16">immutable</strong></span>, which means the objects cannot be changed once they have been created in memory.</p><p class="calibre7">It is important to understand that changing any immutable object, not just a string, means your program is actually creating a new object in memory and discarding the old one. This is a more intensive operation than simply changing the value of an address in memory and requires more processing. Merging two strings together is called <span class="strong"><strong class="calibre16">concatenation</strong></span>, and this is an even more costly procedure as you are disposing of two objects before creating a new one. If you find that you are editing your string values frequently, or frequently concatenating strings together, be aware that your program is not as efficient as it could be.</p><p class="calibre7">Strings are strictly immutable in C#, Java, and Objective-C. It is interesting to note that the Swift documentation refers to strings as mutable. However, the behavior is similar to Java, in that, when a string is modified, it gets copied on assignment to another object. Therefore, although the documentation says otherwise, strings are effectively immutable in Swift as well.</p><p class="calibre7"><span class="strong"><strong class="calibre16">C#</strong></span></p><p class="calibre7">C# uses the string keyword to declare string types:</p><pre class="programlisting">    //C# 
    string one = "One String"; 
    Console.WriteLine("One: {0}", one); 
 
    String two = "Two String"; 
    Console.WriteLine("Two: {0}", two); 
 
    String red = "Red String"; 
    Console.WriteLine("Red: {0}", red); 
 
    String blue = "Blue String"; 
    Console.WriteLine("Blue: {0}", blue); 
 
    String purple = red + blue; 
    Console.WriteLine("Concatenation: {0}", purple); 
 
    purple = "Purple String"; 
    Console.WriteLine("Whoops! Mutation: {0}", purple); 
</pre><p class="calibre7"><span class="strong"><strong class="calibre16">Java</strong></span></p><p class="calibre7">Java uses the system class <code class="literal">String</code> to declare string types:</p><pre class="programlisting">    //Java 
    String one = "One String"; 
    System.out.println("One: " + one); 
 
    String two = "Two String"; 
    System.out.println("Two: " + two); 
 
    String red = "Red String"; 
    System.out.println("Red: " + red); 
 
    String blue = "Blue String"; 
    System.out.println("Blue: " + blue); 
 
    String purple = red + blue; 
    System.out.println("Concatenation: " + purple); 
 
    purple = "Purple String"; 
    System.out.println("Whoops! Mutation: " + purple); 
</pre><span class="strong"><strong class="calibre16">Objective-C</strong></span><p class="calibre7">Objective-C provides the <code class="literal">NSString</code> class to create string objects:</p><pre class="programlisting">    //Objective-C 
    NSString *one = @"One String"; 
    NSLog(@"One: %@", one); 
 
    NSString *two = @"Two String"; 
    NSLog(@"Two: %@", two); 
 
    NSString *red = @"Red String"; 
    NSLog(@"Red: %@", red); 
 
    NSString *blue = @"Blue String"; 
    NSLog(@"Blue: %@", blue); 
 
    NSString *purple = [[NSArray arrayWithObjects:red, blue, nil] componentsJoinedByString:@""]; 
    NSLog(@"Concatenation: %@", purple); 
 
    purple = @"Purple String"; 
    NSLog(@"Whoops! Mutation: %@", purple); 
</pre><p class="calibre7">When you examine the Objective-C example, you might wonder why we have all that extra code for creating the purple object. That code is necessary because Objective-C does not provide a shortcut mechanism for concatenating strings like the other three languages we're using. So, in this scenario, I have chosen to place the two strings into an array and then call the <code class="literal">NSArray</code> method <code class="literal">componentsJoinedByString:</code>. I could have also chosen to use the <code class="literal">NSMutableString</code> class, which provides a method for concatenating strings. However, since we're not discussing mutable string classes in any of our selected languages, I have opted not to use that approach.</p><p class="calibre7"><span class="strong"><strong class="calibre16">Swift</strong></span></p><p class="calibre7">Swift provides the <code class="literal">String</code> class to create string objects:</p><pre class="programlisting">    //Swift 
    var one : String = "One String" 
    print("One: \(one)") 
 
    var two : String = "Two String" 
    print("Two: \(two)") 
 
    var red : String = "Red String" 
    print("Red: \(red)") 
 
    var blue : String = "Blue String" 
    print("Blue: \(blue)") 
 
    var purple : String = red + blue 
    print("Concatenation: \(purple)") 
 
    purple = "Purple String"; 
    print("Whoops! Mutation: \(purple)") 

    /* 
      Output from each string example: 
      One: One String 
      Two: Two String 
      Red: Red String 
      Blue: Blue String 
      Concatenation: Red StringBlue String 
      Whoops! Mutation: Purple String 
    */ 
</pre></div>
<div class="book" title="Summary" id="H5A41-77f2b5b248f04368a6f723b0e9357ef3"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec10" class="calibre1"/>Summary</h1></div></div></div><p class="calibre7">In this chapter, you learned about the basic data types available to a programmer in each of the four most common mobile development languages. Numeric and floating point data type characteristics and operations are as dependent on the underlying architecture as on the specifications of the language. You also learned about casting objects from one type to another and how the type of cast is defined as either a widening cast or a narrowing cast depending on the size of the source and target data types in the conversion. Next, we discussed Boolean type and how it is used in comparators to affect program flow and execution. In this, we discussed operator order of precedence and nested operations. You also learned how to use short-circuiting to improve your code's performance. Finally, we examined the <code class="literal">String</code> data type and what it means to work with mutable objects.</p></div></body></html>