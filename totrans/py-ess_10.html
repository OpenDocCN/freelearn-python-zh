<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch10"/>Chapter 10. Files, Databases, Networks, and Contexts</h1></div></div></div><p>Files<a class="indexterm" id="id523"/> and the filesystem<a class="indexterm" id="id524"/> are central to the way modern OSs work. Many OS resources are visible as part of the filesystem. For example, the Linux <code class="literal">/dev/mem</code> is a view into the processor's memory, implemented as a device visible in the filesystem. Python provides file objects that map to these OS features.</p><p>At a fundamental level, OS files are simply collections of bytes. In practice, we often work with files that are collections of Unicode characters. Python offers both views of files. With some file formats, we need to process the bytes. With text files, we expect Python to properly decode Unicode characters from the bytes.</p><p>A Python file object will generally be entangled with an OS resource. In order to be sure that an application doesn't leak OS resources, we often use a context manager. This allows us to be sure that OS resources are released when Python files are closed. The <code class="literal">with</code> statement provides a tidy way to work with a context manager to allocate and de-allocate resources.</p><p>In addition to ordinary files, we'll look at TCP/IP sockets. The <code class="literal">urllib</code> module<a class="indexterm" id="id525"/> allows us to open a socket to a remote host. The socket is used like a file to read the data from the remote host.</p><p>A file has a physical format; all but the simplest formats require a <code class="literal">library</code> module<a class="indexterm" id="id526"/> to read and write the content properly. Additionally, within the constraints of a physical format, there may be variations in the logical layout of the data. A<a class="indexterm" id="id527"/> <strong>comma-separated values</strong> (<strong>CSV</strong>) file, for example, may use field names in the first line of the file to describe the logical layout of the columns.</p><p>A SQLite database or a <code class="literal">shelve</code> database relies on one (or more) file to make the data persistent. We'll look briefly at higher-level constructs which rely on files.</p><div><div><div><div><h1 class="title"><a id="ch10lvl1sec89"/>The essential file concept</h1></div></div></div><p>Modern OSs rely on files and <a class="indexterm" id="id528"/>device drivers for a variety of services and features. Bytes on a disk drive are only one type of file.</p><div><div><h3 class="title"><a id="note07"/>Note</h3><p>Since many storage devices use or include<a class="indexterm" id="id529"/> <strong>Solid State Drives</strong> (<strong>SSD</strong>) the term "disk" is technically a misnomer; we'll use the outdated term.</p></div></div><p>A network adapter<a class="indexterm" id="id530"/> is another kind of file; one in which bytes are available continuously, instead of appearing at rest. In addition to disk and network files, the Linux filesystem includes the <code class="literal">/dev</code> directory, which describes all of the devices on a given computer. These devices include serial ports, references to memory, and even a device which accumulates an entropy pool to provide random bytes.</p><p>The Python file object wraps an OS file. The <code class="literal">open()</code> function<a class="indexterm" id="id531"/> binds a Python file object to an OS file. In addition to a name, the function expects a mode string for access. The mode string combines two features:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Characters versus bytes</strong>: By default, a file is<a class="indexterm" id="id532"/> opened in text mode; we <a class="indexterm" id="id533"/>can make this explicit by using <code class="literal">t</code>. When<a class="indexterm" id="id534"/> reading, the OS bytes are decoded to create Unicode characters. When writing, the Unicode characters are encoded into bytes. To use bytes instead of text, we include <code class="literal">b</code> in the mode; no encoding or decoding will be done.</li><li class="listitem" style="list-style-type: disc"><strong>Allowed operations</strong>: By <a class="indexterm" id="id535"/>default, a file is opened in <code class="literal">r</code> mode which allows reading only. We can open a file in <code class="literal">w</code> mode which will remove any previous content and allow writing only. We can open a file in <code class="literal">a</code> mode which will search to the end of the previous content so that new content can be appended. The <code class="literal">+</code> modifier allows both reading and writing; this means that <code class="literal">w+</code> removes any previous content and allows reading and writing; <code class="literal">r+</code> leaves the previous content in place and allows reading and writing.</li></ul></div><p>When we open a text file, we provide explicit encoding. In some cases, explicit encoding is required because the encoding expected by the OS isn't in the file.</p><p>In some cases, we may also need to specify how newline characters should be handled. On input, we rarely need to specify line endings: Python handles them gracefully by translating Windows <code class="literal">\r\n</code> to <code class="literal">\n</code>. On output, however, we might need to explicitly provide the line ending. If we set <code class="literal">newline=""</code>, then no translation is performed; we'll need this so that we can create CSV files with <code class="literal">\r\n</code> line endings. If we set <code class="literal">newline=None</code> when opening a file, then <code class="literal">\n</code> from our program's output translates the platform-specific value in the <code class="literal">os.linesep</code> variable. This is the default behavior. Any other values for <code class="literal">newline</code> replace the <code class="literal">\n</code> characters in our output.</p><p>We can specify buffering. We can also specify how Unicode decoding errors are handled. There are seven choices for Unicode errors, including <code class="literal">strict</code>, <code class="literal">ignore</code>, <code class="literal">replace</code>, <code class="literal">xmlcharrefreplace</code>, <code class="literal">backslashreplace</code>, and <code class="literal">surrogateescape</code>. The <code class="literal">strict</code> error handling raises an exception. The <code class="literal">ignore</code> error handling quietly drops the illegal character. The other choices offer different kinds of replacement strategies.</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec83"/>Opening text files</h2></div></div></div><p>For processing<a class="indexterm" id="id536"/> text files, here's how to <a class="indexterm" id="id537"/>create the file object using the <code class="literal">open()</code> function:</p><div><pre class="programlisting">&gt;&gt;&gt; my_file = open("Chapter_10/10letterwords.txt")
&gt;&gt;&gt; text= my_file.read().splitlines()
&gt;&gt;&gt; text[:5]
['consultive', 'syncopated', 'forestland', 'postmarked', 'configures']</pre></div><p>We've opened a file using all of the default settings. The mode will be read-only. The file must use the system's default encoding (Mac-Roman, for example). We'll rely on the default buffering and the default Unicode error handling, which is <code class="literal">strict</code>.</p><p>In this example, we read the entire file into a giant string and then split that single string into a sequence of individual lines. We assigned the list of strings to the <code class="literal">text</code> variable. We only displayed the first five items from this list. By default, the string <code class="literal">split()</code> method does not preserve the split character.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec84"/>Filtering text lines</h2></div></div></div><p>We'll look at two key concepts in the<a class="indexterm" id="id538"/> following examples. We'll start by opening a <a class="indexterm" id="id539"/>file that's encoded using <code class="literal">"utf-8"</code>:</p><div><pre class="programlisting">&gt;&gt;&gt; code_file = open("Chapter_1/ch01_ex1.py", "rt", encoding="utf-8", errors="replace")
&gt;&gt;&gt; code_lines = list(code_file)
&gt;&gt;&gt; code_lines[:5]
['#!/usr/bin/env python3\n', '"""Python Essentials\n', '\n',
'Chapter 1, Example Set 1\n', '\n']</pre></div><p>We've opened a file with the mode <code class="literal">"rt",</code> which means read-only and text. This is the default, so it could have been omitted. We've explicitly provided <code class="literal">"utf-8"</code> encoding, which is not the OS default.</p><p>We used the <code class="literal">list()</code> function to convert the file object into a sequence of lines. When we use a file object as if it is an iterable, we'll see that the file iterates over lines. If we don't change the newline setting for the file, then the "universal newlines" rules are used: <code class="literal">\n</code>, <code class="literal">\r</code>, or <code class="literal">\r\n</code> will end a line; they're normalized to <code class="literal">\n</code>. When we process a file as lines, the line ending characters are preserved.</p><p>We often want to remove newline<a class="indexterm" id="id540"/> characters from the end of each line. This is a kind of mapping<a class="indexterm" id="id541"/> from raw lines to lines with trailing whitespace stripped. We can use a generator expression or the <code class="literal">map()</code> function and the <code class="literal">str.rstrip()</code> method.</p><p>In some cases, an empty line has no meaning and can be removed. This, too, can be done with a generator expression that has an <code class="literal">if</code> clause to reject empty lines. We can also do it with a <code class="literal">filter()</code> function. It's easier if we write these map and filter operations in two lines, like this:</p><div><pre class="programlisting">&gt;&gt;&gt; txt_stripped = (line.rstrip() for line in code_file)
&gt;&gt;&gt; txt_non_empty= (line for line in txt_stripped if line)
&gt;&gt;&gt; code_lines= list(txt_non_empty)</pre></div><p>We've broken down the input cleanup into two generator expressions. The first generator expression, <code class="literal">txt_stripped</code>, maps raw lines to lines with trailing whitespace stripped. The second generator expression, <code class="literal">txt_non_empty</code>, is a filter which rejects lines that are empty. We could easily add other filter conditions to the <code class="literal">if</code> clause. Since generator expressions are lazy, nothing is really done until the final <code class="literal">list()</code> function consumes all of the lines from the generators.</p><p>In this way, we can design fairly sophisticated file parsing as a collection of generator expressions. We can apply a number of mapping and filtering operations so that the main suite of statements has only clean data.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec85"/>Working with raw bytes</h2></div></div></div><p>Here's how we<a class="indexterm" id="id542"/> open a<a class="indexterm" id="id543"/> file and see the raw bytes:</p><div><pre class="programlisting">&gt;&gt;&gt; raw_bytes = open("Chapter_10/favicon.ico", "rb" )
&gt;&gt;&gt; data = raw_bytes.read()
&gt;&gt;&gt; len(data)
894
&gt;&gt;&gt; data[:22]
b'\x00\x00\x01\x00\x01\x00\x10\x10\x00\x00\x00\x00\x18\x00h\x03\x00\x00\x16\x00\x00\x00'</pre></div><p>We've opened this file in binary mode. The input we get will be <code class="literal">bytes</code> instead of <code class="literal">str</code>. Since a <code class="literal">bytes</code> object has many similar features to a <code class="literal">str</code> object, we can do a great deal of string-like processing on these bytes. We've dumped the first 22 bytes from the file. Bytes are shown as a mixture of hex values and ASCII characters.</p><p>We'll need to look at the description of the ICO file format<a class="indexterm" id="id544"/> to see what the bytes mean. Here's some background at <a class="ulink" href="http://en.wikipedia.org/wiki/ICO_(file_format)">http://en.wikipedia.org/wiki/ICO_(file_format)</a>.</p><p>The easiest way to decode this block of bytes is by using the <code class="literal">struct</code> module. We can do the following to pick apart the header on the file and the header on the first image of the file.</p><div><pre class="programlisting">&gt;&gt;&gt; import struct
&gt;&gt;&gt; struct.unpack( "&lt;hhhbbbbhhii", data[:22] )
(0, 1, 1, 16, 16, 0, 0, 0, 24, 872, 22)</pre></div><p>The<a class="indexterm" id="id545"/> <code class="literal">unpack()</code> function<a class="indexterm" id="id546"/> requires a format that specifies different kinds <a class="indexterm" id="id547"/>of conversions to perform on the stream of bytes. In this case, the format contains three codes for groups of bytes: <code class="literal">h</code> means two-byte half worlds, <code class="literal">b</code> means single bytes, and <code class="literal">i</code> means four-byte integers. The bytes are assembled into numeric values and the resulting structure is a tuple of proper Python <code class="literal">int</code> values. The leading <code class="literal">&lt;</code> in the format specifies that the conversion to integers uses <a class="indexterm" id="id548"/>
<strong>little-endian</strong> byte ordering.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec86"/>Using file-like objects</h2></div></div></div><p>Because of the way <a class="indexterm" id="id549"/>objects work in Python, any object that offers an interface similar to <a class="indexterm" id="id550"/>the <code class="literal">file</code> class can be used in place of a file. This leads to the term "file-like object". We can use a file object, or any other object which is designed to behave like a file. For example, the <code class="literal">io</code> module has the <code class="literal">StringIO</code> class, which allows us to work with a string as if it were the contents of a file.</p><p>We often use this for creating test data. Note that an <code class="literal">io.StringIO</code> object is a lot like an open file. When we think about designing for testability—the subject of <a class="link" href="ch14.html" title="Chapter 14. Fit and Finish – Unit Testing, Packaging, and Documentation">Chapter 14</a>, <em>Fit and Finish – Unit Testing, Packaging, and Documentation</em>—we need to design functions to work with file objects, not filenames.</p><p>Here's a function that applies simple pattern matching to lines of a file to yield numeric values extracted from complex lines of text. For more information on regular expressions, see <a class="link" href="ch03.html" title="Chapter 3. Expressions and Output">Chapter 3</a>, <em>Expressions and Output</em>.</p><p>This function uses a pattern to filter the lines of a file or file-like object:</p><div><pre class="programlisting">import re
def tests_run(log_file):
    data_pat = re.compile(r"\s*([\w ]+):\s+(\d+\.?\d*)\s*")
    for line in log_file:
        match= <strong>data_pat.findall(line)</strong>
        if match:
            yield match</pre></div><p>We've defined a generator function, which will reduce a log file to the few lines that match the given pattern. We've used the <code class="literal">re</code> module to define a pattern, <code class="literal">data_pat</code>, that looks for a string of words (<code class="literal">[\w ]+</code>), a <code class="literal">:</code> character, and a number that could be an integer or floating-point (<code class="literal">\d+\.?\d*</code>). The <code class="literal">data_pat.findall(line)</code> expression will locate all of these <em>words: number</em> pairs in a given line. A resulting list of match results is produced for each matching line.</p><p>The matches are strings. We'll need to apply additional functions to the results to convert the numeric group from a string to a proper number.</p><p>It is important when defining<a class="indexterm" id="id551"/> our function to use a filename; the function doesn't <a class="indexterm" id="id552"/>open the file. A function that opens a file is slightly more difficult to test. Instead, we defined our <code class="literal">tests_run()</code> function to use any file-like object. This allows us to write unit tests like the following:</p><div><pre class="programlisting">&gt;&gt;&gt; import io
&gt;&gt;&gt; data = io.StringIO(
... '''
... Tests run: 1, Failures: 2, Errors: 0, Skipped: 1, Time elapsed: 0.547 sec
... Other data
... Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.018 sec
... ''')
&gt;&gt;&gt; list( tests_run(data) )
[[('Tests run', '1'), ('Failures', '2'), ('Errors', '0'), ('Skipped', '1'), ('Time elapsed', '0.547')],
[('Tests run', '1'), ('Failures', '0'), ('Errors', '0'), ('Skipped', '0'), ('Time elapsed', '0.018')]]</pre></div><p>We've imported the <code class="literal">io</code> module so that we can create an <code class="literal">io.StringIO</code> object that contains simulated input. We can provide this file-like object to the <code class="literal">tests_run()</code> function. Since <code class="literal">StringIO</code> behaves like a file, we can use it in place of an actual file to test our function to be sure that it properly locates the <code class="literal">Tests run</code> lines and ignores other lines. We'll look at unit testing in <a class="link" href="ch14.html" title="Chapter 14. Fit and Finish – Unit Testing, Packaging, and Documentation">Chapter 14</a>, <em>Fit and Finish – Unit Testing, Packaging, and Documentation</em>.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec90"/>Using a context manager via the with statement</h1></div></div></div><p>A Python file<a class="indexterm" id="id553"/> object is generally entangled with <a class="indexterm" id="id554"/>OS resources. When we're done using the file, we need to be sure that the file is properly closed so that the OS resources can be released. For small command-line applications, this consideration is not that important: when we exit from Python, and the reference counts for all objects are decreased to zero, the files will be closed during object delete processing.</p><p>For a large, long-running server, however, files that are not properly closed will accumulate OS resources. Since pools of OS resources are finite, a file handle leak will, eventually, cause problems.</p><p>As a general practice, we can use a context manager to be sure that files are closed when we're done using them. The idea is to constrain an open file to the suite of statements within the context manager. Once that suite of statements is finished, the context manager will ensure that the file is closed.</p><p>We specify the context using the <code class="literal">with</code> statement. A file object is a context manager; the <code class="literal">with</code> statement uses the file as a manager. At the end of the <code class="literal">with</code> statement, the context manager will exit and the file will be closed. Some more complex file structures are also context managers. For example, a <code class="literal">ZipFile</code> object, defined in the <code class="literal">zipfile</code> module, is a proper context manager; when used in a <code class="literal">with</code> statement, the file will be neatly closed.</p><p>It should be considered a <a class="indexterm" id="id555"/>best practice to wrap all file input-output<a class="indexterm" id="id556"/> processing in a <code class="literal">with</code> statement to be absolutely sure that the file is properly closed. Here's an example of how we can use the <code class="literal">tests_run()</code> function (shown earlier) using a context manager:</p><div><pre class="programlisting">file_in= "Chapter_10/log_example.txt"
file_out= "Chapter_10/summary.txt"
with open(file_in) as source, open(file_out, "w") as target:
    for stats in tests_run(source):
        print(stats, file=target)</pre></div><p>We've opened two files to serve as context managers. The file which is opened for reading, <code class="literal">"Chapter_10/log_example.txt"</code>, is assigned to the <code class="literal">source</code> variable. The file opened for writing, <code class="literal">"Chapter_10/summary.txt"</code>, is assigned to the <code class="literal">target</code> variable. We can then process these files knowing that they will close properly.</p><p>If an exception is raised, the files will be closed. This is very important. Each of these context managers is notified if an exception occurs in the suite of statements inside the <code class="literal">with</code> statement. In this case, both of the managers are file objects. Each will see the exception and close the file—releasing all OS resources—and allow the exception handling to continue. Our application will crash with an exception, but the files will also close properly.</p><div><div><h3 class="title"><a id="tip20"/>Tip</h3><p>Always wrap file processing in a <code class="literal">with</code> statement.</p></div></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec87"/>Closing file-like objects with contextlib</h2></div></div></div><p>In some cases, we want to be<a class="indexterm" id="id557"/> sure that our application closes a file-like <a class="indexterm" id="id558"/>object that does not implement the context manager methods. Modules such as <code class="literal">http.client</code> will create an <code class="literal">HTTPConnection</code> object that may be entangled with network resources. We'd like to ensure that any network resources are released when we're done using the connection object. However, since this object is not a proper context manager, it won't be closed automatically when used in a <code class="literal">with</code> statement.</p><p>Indeed, trying to use an <code class="literal">HTTPConnection</code> object as context manager in a <code class="literal">with</code> statement will raise an <code class="literal">AttributeError</code> exception. This error will show that the <code class="literal">HTTPConnection</code> object does not implement the correct methods to behave as a context manager.</p><p>We can leverage a generic context manager in the <code class="literal">contextlib</code> module. The <code class="literal">contextlib.closing()</code> function will wrap any object that has a <code class="literal">close()</code> method with the required special methods to make the wrapped object into a context manager.</p><p>A RESTful web services request might look like this:</p><div><pre class="programlisting">import contextlib
import http.client
with contextlib.closing(
  http.client.HTTPConnection("www.example.com")) as host:
    host.request("GET", "/path/to/resources/12345/")
    response= host.getresponse()
    print(response.read())</pre></div><p>We're interested in making a GET request to a web service. The <code class="literal">http.client.HTTPConnection</code> object isn't a context manager; there's no guarantee that it will be closed if an exception occurs. By wrapping it with the <code class="literal">contextlib.closing()</code> function, we've made it into a proper context manager. We can make requests and process responses, in the knowledge that the <code class="literal">HTTPConnection</code> object will have its <code class="literal">close()</code> method called properly.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec91"/>Using the shelve module as a database</h1></div></div></div><p>Files offer us persistent<a class="indexterm" id="id559"/> storage. The simple use of files is limited by <a class="indexterm" id="id560"/>the fact that the data must be accessed sequentially. How can we access items in an arbitrary order?</p><p>We'll use the term "database" for a file (a set of files) on which we're going to perform <strong>Create, Retrieve, Update, and Delete</strong> (<strong>CRUD</strong>)<a class="indexterm" id="id561"/> operations on data elements in an arbitrary order. If we create objects of a consistent size, we can open an ordinary text file in <code class="literal">r+</code> mode and use the <code class="literal">seek()</code> method to position at the start of any particular record. This is rather complex, however, and we can do better.</p><p>The core database concept of readable and writable storage can be extended with a seemingly endless list of ancillary features. We'll ignore locking, logging, auditing, journaling, distributed transaction management, and many other features, for now to focus on the core feature of persistence.</p><p>The <code class="literal">shelve</code> module provides us with a very flexible database. A shelf object behaves like an ordinary Python mapping with the bonus feature that the content is persistent. One additional constraint is that keys used for a shelf must be strings.</p><p>Generally, we use multi-part strings as shelf keys so that we can include some class information along with a unique identifier for the instance of the class. We can use a simple <code class="literal">class:id</code> format to include both the class name and an object's identifier value as the composite key for the shelf.</p><p>Here's an example of <a class="indexterm" id="id562"/>creating a shelf that maps a key to a list of values. In <a class="indexterm" id="id563"/>this example, the input file has a sequence of words, plus some blank lines and a trailer line that we want to ignore. The shelf has keys which are the initial letters of words. The value associated with each key is a list of words that share that common first letter.</p><p>Here's the entire function:</p><div><pre class="programlisting">import contextlib
import shelve
def populate():
    with contextlib.closing(
      shelve.open("Chapter_10/shelf","n")) as shelf:
        with open("Chapter_10/10letterwords.txt") as source:
            txt_stripped= (l.strip() for l in source)
            txt_non_empty= (l for l in txt_stripped
                            if l and not l.startswith("Tool") )
            for word in txt_non_empty:
                key = "word_list:{0}".format(word[0])
                try:
                    word_list= shelf[key]
                except KeyError:
                    word_list= []
                word_list.append(word)
                shelf[key]= word_list</pre></div><p>We've opened the shelf object using <code class="literal">shelve.open()</code>. The <code class="literal">"n"</code> mode creates a new, empty shelf file each time the application runs. Since a shelf is not a proper context manager, we need to wrap it with the <code class="literal">contextlib.closing()</code> function.</p><p>The <code class="literal">shelve</code> module relies on a platform-specific database module. This may necessitate one or more underlying files to support the shelf. We've provided a base filename of <code class="literal">"Chapter_10/shelf"</code>. We may see a <code class="literal">.dat</code> or <code class="literal">.db</code> file get created, depending on the OS we're using.</p><p>The <code class="literal">for</code> loop traverses the input sequence of words generated by the <code class="literal">txt_non_empty</code> expression. The suite starts by building a two-part key. The first part is the string <code class="literal">word_list</code>; this is clearly not the Python data class, but it serves as a summary of what the data means. After the colon, we've put the first character of the word.</p><p>We fetch the current list <a class="indexterm" id="id564"/>of words associated with this key. If there is no<a class="indexterm" id="id565"/> such key in the shelf, we handle the <code class="literal">KeyError</code> exception by creating a fresh, empty list. Once we have a list—either new or fetched from the shelf—we can update the list by appending our new word. We then save the word list in the shelf.</p><p>To query words with a certain first letter, we can use <code class="literal">shelf["word_list:"+letter]</code>. We need to create a complete key string that includes a classifier so that we have a shelf with multiple collections.</p><p>To retrieve and summarize the data, we use a simple loop based on this generator expression:</p><div><pre class="programlisting">sorted(k for k in shelf.keys() if k.startswith("word_list:"))</pre></div><p>This will select only the keys from our <code class="literal">word_list</code> collection in the shelf database. In a more sophisticated database, there may be other collections with other key prefixes.</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec88"/>Using the sqlite database</h2></div></div></div><p>The <code class="literal">sqlite</code> module <a class="indexterm" id="id566"/>provides us with a SQL-based database. An application that leverages SQL is—in principle—portable. We should be able to use MySQL or PostgreSQL as our database instead of SQLite without making dramatic changes to our Python application.</p><p>While there are several applicable standards for SQL, each implementation seems to suffer from its own particular problems. SQL-based applications are therefore rarely perfectly portable between database platforms.</p><p>SQL databases require a formal schema definition. This means that SQL applications must always include some provision for creating or confirming the schema. As in the previous example, we'll work with a database that has a single table with two columns: a non-unique key which is the initial letter of a word, and the word which has that initial letter.</p><p>Here's the table definition in SQL:</p><div><pre class="programlisting">CREATE TABLE IF NOT EXISTS word(
    letter VARCHAR(1),
    word VARCHAR(10),
    PRIMARY KEY (letter))</pre></div><p>This defines a table that has two columns, <code class="literal">letter</code> and <code class="literal">word</code>. To find all of the words which have a common first letter, we'll need to retrieve multiple rows from this table. This is a common type of SQL design. It doesn't fit neatly with Python's object-oriented design, a common limitation when using SQL.</p><p>We need to execute the SQL <code class="literal">CREATE TABLE</code> statement to create (or confirm the existence of) the table in a SQLite database. Here's a function that will establish (or confirm) the schema:</p><div><pre class="programlisting">def schema():
    with SQL.connect("Chapter_10/sqlite.sdb") as db:
        db.execute( """CREATE TABLE IF NOT EXISTS word(
                   letter VARCHAR(1),
                   word VARCHAR(10),
                   PRIMARY KEY (letter))
                   """)</pre></div><p>The essential statement is the <code class="literal">execute()</code> method of the SQLite connection object. We've provided the SQL with a triple-quoted string. If there's a problem, an exception will be raised.</p><p>Here's a function that will load this table with data from a text file:</p><div><pre class="programlisting">def populate():
    with SQL.connect("Chapter_10/sqlite.sdb") as db:
        db.execute( """DELETE FROM word""" )
        with open("Chapter_10/10letterwords.txt") as source:
            txt_stripped= (l.strip() for l in source)
            txt_non_empty= (l for l in txt_stripped
                            if l and not l.startswith("Tool") )
            for word in txt_non_empty:
                db.execute( """INSERT INTO WORD(letter, word)
                           VALUES (:1, :2)""", (word[0], word) )</pre></div><p>Note that we begin by<a class="indexterm" id="id567"/> deleting all the rows from the <code class="literal">word</code> table. This parallels the way that our previous example worked by creating a fresh, empty <code class="literal">shelve</code> database. There may be high overheads in creating an empty SQL database; this example expects an established database with a table already defined, and deletes rows from the defined table.</p><p>As with the previous example, we've used two generator expressions to filter out these lines of junk from the input file. The loop traverses the words generated by the <code class="literal">no_summary</code> expression. The suite executes a SQL <code class="literal">INSERT</code> statement binding two values for the <code class="literal">letter</code> and <code class="literal">word</code> columns of the table. This statement creates a new row in the word table in our database.</p><p>To see counts of words which begin with a given letter, we can use SQL aggregation. We would execute the following <code class="literal">SELECT</code> statement.</p><div><pre class="programlisting">SELECT letter, COUNT(*) FROM word GROUP BY letter</pre></div><p>When we execute this, we <a class="indexterm" id="id568"/>get a SQL iterator (called a "cursor") that yields a sequence of two-tuples based on the <code class="literal">SELECT</code> clause. Each tuple will have the letter and the number of words that share that letter. We can use this to display a summary of counts of words with a given initial letter.</p></div><div><div><div><div><h2 class="title"><a id="ch10lvl2sec89"/>Using object-relational mapping</h2></div></div></div><p>Many popular SQL <a class="indexterm" id="id569"/>databases offer Python drivers. Some have better levels of support than others. When working with SQL databases, it's sometimes difficult to locate SQL syntax that is effective and portable. A feature on one database may be a problem on another.</p><p>More importantly, however, there's a mismatch between the completely flat column-and-row structure of a SQL table and the requirements of more complex class definitions in an object-oriented language like Python. This impedance mismatch is often addressed with an <strong>object-relational mapping</strong> (<strong>ORM</strong>) package. Two popular packages are SQLAlchemy<a class="indexterm" id="id570"/> or <a class="indexterm" id="id571"/>SQLObject.</p><p>These packages help with the mapping of complex objects to simple SQL tables. It also helps by divorcing the application programming for the details of a particular SQL database.</p><p>Databases which don't use SQL, such as <code class="literal">shelve</code>, MongoDB, CouchDB, and other NoSQL databases, don't have the same object-relational impedance mismatch problem that SQL databases have. We have many choices for persistence technology; Python can be used with a wide variety of databases.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec92"/>Web services and Internet protocols</h1></div></div></div><p>As we noted earlier, many <a class="indexterm" id="id572"/>TCP/IP protocols, like HTTP, depend on the socket abstraction. Sockets are designed to be file-like: we can use ordinary file operations to read or write a socket. At a very low level, we can use the Python <code class="literal">socket</code> module. We can create, read, and write sockets to connect client and server programs.</p><p>Rather than work directly with <a class="indexterm" id="id573"/>sockets, however, we'll make use of higher-level modules, such as <code class="literal">urllib</code> and <code class="literal">http.client</code>. These give us the client-side operations of the HTTP protocol, allowing us to connect to a web server, make requests, and get replies. We looked briefly at the <code class="literal">http.client</code> module in the previous <em>Closing file-like objects with contextlib</em> section.</p><p>To implement a server, we can use <code class="literal">http.server</code>. In practice, though, we'll often leverage a frontend application, such as Apache HTTPD or NGINX, to provide the static content of a website. For the dynamic content, we'll often use a WSGI gateway to pass web requests from the <a class="indexterm" id="id574"/>frontend to a Python framework. There are several Python <a class="indexterm" id="id575"/>web server frameworks, each with a variety of features, strengths, and weaknesses.</p></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec93"/>Physical format considerations</h1></div></div></div><p>The Python library <a class="indexterm" id="id576"/>offers us a number of modules to help process common physical file formats. <em>Chapter 13</em>, <em>File Formats</em>, of the <em>Python Standard Library</em> describes file compression and archiving; this includes modules to handle files compressed using zip or BZip2. <em>Chapter 14</em>, <em>Cryptographic Services</em> describes modules which handle file formats such as CSV, configuration files, and PLIST files. <em>Chapter 19</em>, <em>Structured Markup Processing Tools</em> describes Internet data handling, which includes the JSON file format. <em>Chapter 20</em>, <em>Internet Protocols and Support</em> describes modules to handle markup languages such as HTML and XML. For modules that are not part of the standard library, the <a class="indexterm" id="id577"/>
<strong>Python Package Index</strong> (<strong>PyPI</strong>) may have <a class="indexterm" id="id578"/>a package that handles the file format. See <a class="ulink" href="http://pypi.python.org">http://pypi.python.org</a>.</p><p>We'll look quickly at the CSV module because it is often used when working on "big data" problems. For example, the Apache Hadoop software library—a framework that allows for the distributed processing of large datasets—leverages simple programming models. We can use Python with Hadoop streaming.</p><p>A Hadoop file is often a CSV-formatted file. In some instances, it will have "<code class="literal">|</code>" instead of a comma, and quoting or escapes won't be used. In other cases, an <code class="literal">\x01</code> (ASCII SOH) character could be used as a separator. This is relatively simple to handle with the Python CSV module.</p><p>When we create a CSV file from a spreadsheet, the first row may have header information. This can be very helpful. The <code class="literal">csv.DictReader()</code> class uses the first line of a CSV file as the header. Each remaining line is transformed into a <code class="literal">dict</code>. The keys in this <code class="literal">dict</code> will be the column names from the first line.</p><p>When working with other CSV files, a header line may not be present. This means that we'll need a separate schema definition to determine the meaning of each column. In most cases, we can simply represent the schema as a list or tuple of column names.</p><p>We might have a line like this to provide the missing column names:</p><div><pre class="programlisting">TEST_LOG_SUMMARY = (
    "module", "datetime", "tests_run", "failures",
    "errors", "skipped", "time_elapsed",
)</pre></div><p>This gives us pleasant Python-friendly column names in a simple tuple. We've included a gratuitous comma at the end of the items in the tuple to make it easier to add new columns without getting a syntax error. In general, we can simply put this into a file and import this schema definition.</p><p>Let's assume that we have a function named <code class="literal">log_parser()</code> that can parse a complex log file to extract the fields shown earlier. This function will use regular expressions to locate lines with the test results, the module name, and the time stamp in the log. The data from a log will be used to build a simple dictionary with the keys defined by the <code class="literal">TEST_LOG_SUMMARY</code> global variable. The parser will return a sequence of <code class="literal">dict</code> objects which looks like this:</p><div><pre class="programlisting">{'module': 'com.mycompany.app.AppTest', 'errors': '0', 'time_elapsed': '0', 'failures': '0', 'datetime': 'Thu Oct 06 08:12:17 MDT 2005', 'tests_run': '1'}</pre></div><p>We can use this <code class="literal">log_parser()</code> function to <a class="indexterm" id="id579"/>write a CSV summary file from a log. We'll call this function <code class="literal">mapper()</code> because it maps a sequence of filenames to file to a sequence of data rows, preserving the relevant details:</p><div><pre class="programlisting">def mapper(name_iter, result):
    writer= csv.DictWriter(result, fieldnames=TEST_LOG_SUMMARY, delimiter='|')
    for name in name_iter:
        with open(name) as source:
            writer.writerow( log_parser(source) )</pre></div><p>This function expects two parameters: an iterator which yields log file names, and an open file into which the results are written. This function will create a CSV <code class="literal">DictWriter</code> object using the output file, the set of field names that will be part of each dictionary to be written, and finally, a delimiter.</p><p>For each name, the log is opened and parsed. The results of the parse, <code class="literal">dict</code>, are written to the CSV file to summarize the processing. We might use this function in a script that looks like this:</p><div><pre class="programlisting">mapper(glob.glob("Chapter_10/log_*.txt"), sys.stdout)</pre></div><p>We've written the output to the OS standard out. This allows us to pipe these results into a separate program which computes statistics on the log summaries. We might call the statistical summary a reducer, since it reduces a large number of values to single results. The reducer would share the <code class="literal">TEST_LOG_SUMMARY</code> variable to assure that both programs agree on the content of the file that passes between them.</p></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec94"/>Summary</h1></div></div></div><p>In this chapter, we've seen how we can use Python exceptions to write programs which work with files of various kinds. We've focused on text files, since they are easy to work with. We've also looked at parsing binary files, which often require support from the <code class="literal">struct</code> module.</p><p>A file is also a context manager. The best practice is to use files in a <code class="literal">with</code> statement so that the file is closed properly and all OS resources are released. In a command-line program, this may not be that important; in long-running servers, it's absolutely essential to be sure that resources don't leak from improperly closed files.</p><p>We've also looked at more complex persistence mechanisms, including the <code class="literal">shelve</code> module and the SQLite database. These provide us with ways to perform CRUD operations on data objects in a file. The SQLite database requires us to use the SQL language to describe data access: this can make our programs more portable to other databases. It can also be confusing to leverage SQL in addition to Python. We can overcome that small problem by using a library such as SQLAlchemy so that we can work entirely in Python, and leave it to SQLAlchemy to create the SQL appropriate for our database.</p><p>The standard library has numerous packages to handle different physical file formats. One of these can help to create and retrieve data in the CSV format. The role of the comma delimiter can be any sequence of characters, extending the concept so that many kinds of delimited files can be read or written by this module.</p><p>In <a class="link" href="ch11.html" title="Chapter 11. Class Definitions">Chapter 11</a>, <em>Class Definitions</em>, we'll look at how we can define our own customized classes in Python. Class definitions are the heart of object-oriented programming. We'll touch on several of the class design patterns that are common in Python programming.</p></div></body></html>