- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adding Other Microservice Features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our long journey of exploring FastAPI’s extensibility in building microservice
    applications will end with this chapter, which covers standard recommendations
    on project setup, maintenance, and deployment using some microservice-related
    tools based on design patterns. This chapter will discuss the *OpenTracing* mechanism
    and its use in a distributed FastAPI architecture setup using tools such as *Jaeger*
    and `StarletteTracingMiddleWare`. The *service registry* and *client-side discovery*
    design patterns are included likewise in the detailed discussions on how to manage
    access to the API endpoints of the microservices. A microservice component that
    checks for the *health* of the API endpoints will also be part of the discussion.
    Moreover, the chapter will not end without recommendations on the FastAPI application’s
    *deployment*, which might lead to other design strategies and network setups.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main goal of this chapter is to complete the design architecture of a FastAPI
    application before its sign-off. Here are the topics that will complete our FastAPI
    application development venture:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the virtual environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking the API properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing open tracing mechanisms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up service registry and client-side service discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying and running applications using Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Docker Compose for deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing NGINX as an API gateway
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating Django and Flask sub-applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our last software prototype will be an `ch11` and other [*Chapter 11*](B17975_11.xhtml#_idTextAnchor321)-related
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the virtual environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let us start with the proper way of setting up the development environment
    of our FastAPI application. In Python development, it is common to manage the
    libraries and extension modules that are needed using a virtual environment. A
    virtual environment is a way of creating multiple different and parallel installations
    of Python interpreters and their dependencies where each has the application(s)
    to be compiled and run. Each instance has its own set of libraries depending on
    the requirements of its application(s). But first, we need to install the `virtualenv`
    module to pursue the creation of these instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following list describes the benefits of having a virtual environment:'
  prefs: []
  type: TYPE_NORMAL
- en: To avoid the overlapping of the library version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To avoid broken installed module files due to namespace collisions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To localize the libraries to avoid conflicts with the globally installed modules
    on which some applications are very dependent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To create a template or baseline copy of the set of modules to be replicated
    on some related projects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To maintain operating system performance and setup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After the installation, we need to run the `python -m virtualenv` command to
    create an instance. *Figure 11.1* shows how the `ch01-env` virtual environment
    for the `ch01` project is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Creating a Python virtual environment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.01_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.1 – Creating a Python virtual environment
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the virtual environment, we need to configure our *VS Code editor* to
    utilize the Python interpreter of the virtual environment instead of the global
    interpreter to install modules, compile, and run the application. Pressing *Ctrl*
    + *Shift* + *P* will open the *Command Palette* showing the Python command to
    *select the interpreter*. *Figure 11.2* shows the process of choosing the Python
    interpreter for the `ch01` project:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Choosing the Python interpreter'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.02_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.2 – Choosing the Python interpreter
  prefs: []
  type: TYPE_NORMAL
- en: 'The select command will open a pop-up Windows *File Explorer* window to search
    for the appropriate virtual environment with the Python interpreter, as shown
    in *Figure 11.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – Searching for the virtual environment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.03_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.3 – Searching for the virtual environment
  prefs: []
  type: TYPE_NORMAL
- en: 'Opening a *Terminal console* for the project will automatically activate the
    virtual environment by running the `/Scripts/activate.bat` command for the Windows
    operating system. Additionally, this `activate.bat` script can be manually run
    if the automated activation was not successful. By the way, the activation will
    not be feasible with the Powershell terminal, but only with the command console,
    as shown in *Figure 11.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – Activating the virtual environment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.04_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.4 – Activating the virtual environment
  prefs: []
  type: TYPE_NORMAL
- en: After activation, we can determine the name of the activated virtual environment
    from the leftmost part of the command line. *Figure 11.4* shows that the Python
    interpreter of `ch11-env` is the chosen interpreter for the project. Anything
    installed by its `pip` command will only be available within that instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of our projects has a virtual environment, thus having multiple virtual
    environments containing different set of installed module dependencies, as shown
    in *Figure 11.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Creating multiple virtual environments'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.05_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.5 – Creating multiple virtual environments
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the virtual environment is only one of the best practices when it
    comes to initiating a Python microservice application. Aside from localizing the
    module installation, it helps prepare the deployment of the application in terms
    of identifying what modules to install in the cloud servers. However, before we
    discuss FastAPI deployment approaches, first, let us discuss what microservice
    utilities to include before deploying a project, such as **Prometheus**.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the API properties
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Prometheus** is a popular monitoring total that can monitor and check API
    services in any microservice application. It can check the number of concurrent
    request transactions, the number of responses at a certain period, and the total
    incoming requests of an endpoint. To apply Prometheus to FastAPI applications,
    first, we need to install the following module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we add `PrometheusMiddleware` to the application and enable its endpoint
    to observe the API’s properties at runtime. The following script shows the application
    setup with the Prometheus monitoring module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we add `PrometheusMiddleware` using the `add_middleware()` method of
    FastAPI. Then, we add an arbitrary URI pattern to the `handle_metrics()` utility
    to expose all of the API health details. Accessing `http://localhost:8000/metrics`
    will provide us with something as shown in *Figure 11.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – Monitoring the endpoints'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.06_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.6 – Monitoring the endpoints
  prefs: []
  type: TYPE_NORMAL
- en: The data in *Figure 11.6* displays the time duration, in seconds, used by each
    API in processing requests, providing response to clients, and emitting the status
    code of each API transaction. Additionally, it includes some buckets that are
    built-in values used by the tool to create histograms. Aside from the histogram,
    Prometheus also allows the customization of some metrics inherent to a particular
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Another way of monitoring a FastAPI microservice application is by adding an
    open tracing tool.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing open tracing mechanisms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When monitoring multiple, independent, and distributed microservices, the *OpenTracing*
    mechanism is preferred when managing API logs and traces. Tools such as *Zipkin*,
    *Jaeger*, and *Skywalking* are popular distributed tracing systems that can provide
    the setup for trace and log collections. In this prototype, we will be using the
    Jaeger tool to manage the application’s API traces and logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The current way to integrate an OpenTracing tool into FastAPI microservices
    is through the *OpenTelemetry* modules since the *Opentracing for Python* extension
    is already a deprecated module. To use Jaeger as the tracing service, OpenTelemetry
    has an *OpenTelemetry Jaeger Thrift Exporter* utility, which allows you to export
    traces to the Jaeger client applications. This exporter utility sends these traces
    to the configured agent using the Thrift compact protocol over UDP. But first,
    we need to install the following extension to utilize this exporter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Afterward, add the following configuration to the `main.py` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first step in the preceding setup is to create a tracing service with a
    name using OpenTelemetry’s `Resource` class. Then, we instantiate a tracer from
    the service resource. To complete the setup, we need to provide the tracer with
    `BatchSpanProcessor` instantiated through the `JaegerExporter` details to manage
    all of the traces and logs using a Jaeger client. A *trace* includes full-detailed
    information about the exchange of requests and responses among all API services
    and other components across the distributed setup. This is unlike a *log*, which
    only contains the details regarding a transaction within an application.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the completed Jaeger tracer setup, we integrate the `tracer` client with
    FastAPI through `FastAPIInstrumentor`. To utilize this class, first, we need to
    install the following extension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Before we can run our application, first, we need to download a Jaeger client
    from `https://www.jaegertracing.io/download/`, unzip the `jaeger-xxxx-windows-amd64.tar.gz`
    file, and run `jaeger-all-in-one.exe`. Installers for Linux and macOS are also
    available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, open a browser and access the Jaeger client through the default `http://localhost:16686`.
    *Figure 11.7* shows a snapshot of the tracer client:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Monitoring microservices through a Jaeger client'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.07_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.7 – Monitoring microservices through a Jaeger client
  prefs: []
  type: TYPE_NORMAL
- en: 'After some browser reloads, the Jaeger app will detect our tracer through its
    service name, `online-sports-tracer`, after running our microservice application.
    All accessed API endpoints are detected and monitored, thus creating traces and
    visual analyses regarding all requests and response transactions incurred by these
    endpoints. *Figure 11.8* shows the traces and graphical plots generated by Jaeger:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Searching the traces of every API transaction'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.08_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.8 – Searching the traces of every API transaction
  prefs: []
  type: TYPE_NORMAL
- en: 'A span in OpenTelemetry is equivalent to a trace with a unique *ID*, and we
    can scrutinize each span to view all the details by clicking on the search traces
    for every endpoint. Clicking on the searched trace for the `/ch11/login/list/all`
    endpoint, as shown in *Figure 11.8*, can provide us with the following trace details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Scrutinizing the trace details of an endpoint'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.09_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.9 – Scrutinizing the trace details of an endpoint
  prefs: []
  type: TYPE_NORMAL
- en: Aside from the traces shown in *Figure 11.9*, the Jaeger client can also collect
    the *uvicorn logs* through an OpenTelemetry module called `opentelemetry-instrumentation-logging`.
    After installing the module, we can enable the integration by instantiating `LoggingInstrumentor`
    in the `main.py` file, as shown in the previous code snippet.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us add the *service registry* and *client-side service discovery* mechanisms
    to our application.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up service registry and client-side service discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A service registry tool such as *Netflix Eureka* enables the registration of
    microservice applications without knowing the exact DNS locations of their servers.
    It manages all access to these registered services using a load-balancing algorithm
    and dynamically assigns these service instances with network locations. This service
    registration is helpful to microservice applications deployed to servers with
    changing DNS names due to failures, upgrades, and enhancements.
  prefs: []
  type: TYPE_NORMAL
- en: For the service registry to work, the service instances should have a mechanism
    to discover the registry server before the server registration. For FastAPI, we
    need to utilize the `py_eureka_client` module to implement the service discovery
    design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing client-side service discovery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creating a FastAPI microservice application to discover and register to a service
    registry server such as *Netflix Eureka* is straightforward. First, we need to
    install `py_eureka_client` through `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we instantiate its `EurekaClient` component class with the correct `eureka_server`,
    `app_name`, `instance_port`, and `instance_host` parameter details. The `eureka_server`
    parameter must be the exact machine address of the Eureka server and not `localhost`.
    Additionally, the client instance must have the appropriate `app_name` parameter
    for the FastAPI microservice application (or client app), with the `instance_port`
    parameter set to `8000` and the `instance_host` to `192.XXX.XXX.XXX` (not `localhost`
    or `127.0.0.1`). The following snippet depicts the location in `main.py` in which
    to instantiate the `EurekaClient` component class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The client discovery happens in the `startup` event of the application. It starts
    with the instantiation of the `EurekaClient` component class and invoking its
    `start()` method either asynchronously or not. The `EurekaClient` component class
    can handle asynchronous or synchronous FastAPI startup events. To close the server
    discovery process, always invoke `Eurek` `a` `Client`’s `stop()` method in the
    `shutdown` event. Now, let us build our Netflix Eureka server registry before
    running and performing the client-side service discovery.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the Netflix Eureka service registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us utilize the Spring Boot platform to create our Eureka server. We can
    create an application through `https://start.spring.io/` or the *Spring STS IDE*,
    using either a Maven- or Gradle-driven application. Ours is a Maven application
    with `pom.xml` that has the following dependency for the Eureka Server setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In this case, `application.properties` must have `server.port` set to `8761`,
    `server.shutdown` enabled for a `graceful` server shutdown, and a `spring.cloud.inetutils.timeout-seconds`
    property set to `10` for its hostname calculation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, run the Eureka Server application before the FastAPI client application.
    The Eureka server’s logs will show us the automatic detection and registration
    of FastAPI’s `EurekaClient`, as shown in *Figure 11.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Discovering the FastAPI microservice application'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.10_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.10 – Discovering the FastAPI microservice application
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of the client-side service discovery is also evident on the Eureka
    server’s dashboard at `http://localhost:8761`. The page will show us all the services
    that consist of the registry and through which we can access and test each service.
    *Figure 11.11* shows a sample snapshot of the dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – Creating the service registry'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.11_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.11 – Creating the service registry
  prefs: []
  type: TYPE_NORMAL
- en: Our **SPORTS_SERVICE** being part of the Eureka server registry, as depicted
    in *Figure 11.11*, means we successfully implemented the *client-side service
    discovery design pattern*, and it is time to deploy our application to a Docker
    container.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and running applications using Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Dockerization* is a process of packaging, deploying, and running applications
    using Docker containers. Containerizing FastAPI microservices saves installation
    and setup time, space, and resources. And containerized apps are replaceable,
    replicable, efficient, and scalable compared to the usual deployment packaging.'
  prefs: []
  type: TYPE_NORMAL
- en: To pursue Dockerization, we need to install *Docker Hub* and/or *Docker Engine*
    for the CLI commands. But be aware of the new Docker Desktop License Agreement
    ([https://www.docker.com/legal/docker-software-end-user-license-agreement/](https://www.docker.com/legal/docker-software-end-user-license-agreement/))
    regarding its new subscription model. This chapter mainly focuses on how to run
    CLI commands rather than the Docker Hub GUI tool. Now, let us generate the list
    of modules to be installed in the docker image.
  prefs: []
  type: TYPE_NORMAL
- en: Generating the requirements.txt file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since we are using a virtual environment instance for module management, it
    is easy to identify what extension modules to install in the Docker image. We
    can run the following command to generate a complete list of modules and their
    versions to the `requirements.txt` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Then, we can create a command to copy this file to the image through the `Dockerfile`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Docker image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next step is to build a container image from any available Linux-based
    container images in *Docker Hub*. But we need a `Dockerfile` containing all the
    commands associated with pulling an available Python image from Docker Hub, creating
    a working directory, and copying project files from the local directory. The following
    is a `Dockerfile` set of instructions we use to deploy our prototype to a Python
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The first line is an instruction that will derive a Python image, usually Linux-based,
    with an installed Python 3.9 interpreter. The command after that creates an arbitrary
    folder, `/code`, which will become the application’s main folder. The `COPY` command
    copies our `requirements.txt` file to the `/code` folder, and then the `RUN` instruction
    installs the updated modules from the `requirements.txt` list using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Afterward, the second `COPY` command copies our `ch11` application to the working
    directory. The `EXPOSE` command binds port `8000` to the local machine’s port
    `8000` to run the `CMD` command, which is the last instruction of the `Dockerfile`.
    The `CMD` instruction uses *uvicorn* to run the application at port `8000` using
    host `0.0.0.0` and not `localhost` to automatically map and utilize the IP address
    assigned to the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Dockerfile` must be in the same folder as the `requirements.txt` file
    and the `ch11` application. *Figure 11.12* shows the organization of the files
    and folders that needed to be Dockerized to a Python container image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12 – Setting up the Docker folder structure'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.12_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.12 – Setting up the Docker folder structure
  prefs: []
  type: TYPE_NORMAL
- en: 'Once all the files and folders are complete, we run the following CLI command
    within the folder using the terminal console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: To check the image, run the `docker image ls` CLI command.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Mongo Docker image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The backend of our application is MongoDB, so we need to pull the latest `mongo`
    image from Docker Hub using the following CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'And before we run both the `ch11-app` application and the `mongo:latest` images,
    first, we need to create a `ch11-network` by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This network becomes a bridge between `mongo` and `ch11-app` once they are deployed
    as containers. It will establish the connectivity between the two containers to
    pursue the *Motor-ODM* transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A `docker run` command to start and run a pulled or created image. So, running
    the Mongo image using the `ch11-network` routes requires the execution of the
    following CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Inspect the `mongo:latest` container using the `docker inspect` command to derive
    and use its IP address for Motor-ODM’s connectivity. Replace the `localhost` used
    in `AsyncIOMotorClient`, which is found in the `config/db.py` module of `ch11-app`
    with the “inspected” IP address. Be sure to re-build the `ch11-app` Docker image
    after the update.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, run the `ch11-app` image with `ch11-network` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Access the application through `http://localhost:8000/docs` to check all the
    API endpoints from the OpenAPI documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Now, another approach to simplifying containerization is to use the *Docker
    Compose* tool.
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker Compose for deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'However, you need to install the Docker Compose utility in your operating system,
    which requires Docker Engine as the pre-installation requirement. After the installation,
    the next step is to create the `docker-decompose.yaml` file containing all the
    services needed to build the images, process the Dockerfile, build the Docker
    network, and create and run the containers. The following snippet shows the content
    of our configuration file that sets up the `mongo` and `ch11-app` containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Instead of running separate Docker CLI commands, Docker Compose creates services,
    such as `ch11-mongo` and `ch11-app`, to manage the containerization and only uses
    one CLI command to execute these services, `docker-compose up`. The command not
    only creates the network of images but also runs all the containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'One advantage of using Docker Compose is the ease of ORM and ODM configuration.
    Instead of performing a container inspection to understand which IP address to
    use, we can use the *service name of the database setup* as the hostname to establish
    database connectivity. It is convenient since the IP address of the `mongo` container
    varies for every instance created. The following is the new `AsyncIOMotorClient`
    with the `ch11-mongo` service as the hostname:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now, let us implement an API Gateway design pattern for the containerized applications
    using the *NGINX* utility.
  prefs: []
  type: TYPE_NORMAL
- en: Using NGINX as an API Gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 4*](B17975_04.xhtml#_idTextAnchor080)*, Building the Microservice
    Application*, we implemented the API Gateway design pattern using only some FastAPI
    components. In this last chapter, we will build a *reverse proxy server* through
    NGINX that will assign a proxy IP address to each containerized microservice application.
    These proxy IPs will redirect client requests to the actual microservices running
    on their respective containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of building an actual NGINX environment, we will be pulling an available
    NGINX image from Docker Hub to implement the reverse proxy server. This image
    creation requires a new Docker app folder with a different `Dockerfile` containing
    the following instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Dockerfile` instructs the creation of the latest *NGINX* image and a copy
    of a `nginx_config.conf` file to that image. The file is an *NGINX configuration
    file* that contains the mapping of a proxy IP address to the actual container
    address of each microservice application. It also exposes `8080` as its official
    port. The following is the content of our `nginx_config.conf` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The application’s OpenAPI documentation can now be accessed through `http://localhost:8080/docs`.
  prefs: []
  type: TYPE_NORMAL
- en: The Dockerization of NGINX must come after deploying applications to the containers.
    But another approach is to include NGINX’s `Dockerfile` instructions in the application’s
    `Dockerfile` to save time and effort. Or we can create another service in the
    `docker-decompose.yaml` file to build and run the NGINX image.
  prefs: []
  type: TYPE_NORMAL
- en: And for the last time, let us explore the power of FastAPI in its integration
    with other popular Python frameworks such as *Flask* and *Django*.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating Flask and Django sub-applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Flask* is a lightweight framework that is popular for its *Jinja2* templates
    and *WSGI* server. On the other hand, *Django* is a Python framework that promotes
    rapid development using CLI commands and applies the scaffolding of files and
    folders to build projects and applications. Django applications can run on either
    WSGI- or ASGI-based servers.'
  prefs: []
  type: TYPE_NORMAL
- en: We can create, deploy, and run Flask and Django projects inside a FastAPI microservice
    application. The framework has `WSGIMiddleware` to wrap both Flask and Django
    applications and integrate them into the FastAPI platform. Running the FastAPI
    application through *uvicorn* will also run both applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of the two, it is easier to integrate the Flask application with a project
    than Django. We only need to import the Flask `app` object into the `main.py`
    file, wrap it with `WSGIMiddleware`, and mount it into the FastAPI `app` object.
    The following script shows the part of `main.py` that integrates our `ch11_flask`
    project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'All API endpoints implemented in `ch11_flask` will be accessed using the URL
    prefix, `/ch11/flask`, as indicated in the `mount()` method. *Figure 11.13* shows
    the location of `ch11_flask` inside the `ch11` project:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.13 – Creating a Flask application inside the FastAPI project'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.13_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.13 – Creating a Flask application inside the FastAPI project
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the following `main.py` script integrates our `ch11_django`
    application into the `ch11` project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The Django framework has a `get_wsgi_application()` method that is uses to retrieve
    its `app` instance. This instance needs to be wrapped by `WSGIMiddleware` and
    mounted into the FastAPI `app` object. Moreover, we need to load the `settings.py`
    module of the `ch11_django` project into the FastAPI platform for global access.
    Also, we need to mount all the static files of the `django.contrib.main` module,
    which includes some HTML templates of the Django *security module*.
  prefs: []
  type: TYPE_NORMAL
- en: 'All views and endpoints created by the `sports` application of the `ch11_django`
    project must be accessed using the `/ch11/django` URL prefix. *Figure 11.14* shows
    the placement of the `ch11_django` project within the ch11 app:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.14 – Creating a Django project and application inside a FastAPI
    object'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_11.14_B17975.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.14 – Creating a Django project and application inside a FastAPI object
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last chapter has given us the avenue on how to start, deploy, and run a
    FastAPI microservice application that follows the standards and best practices.
    It introduces the use of a virtual environment instance to control and manage
    the installation of modules from the start of the development until the deployment
    of our applications to Docker containers. The chapter has extensively explained
    the approaches on how to package, deploy, and run containerized applications.
    And lastly, the chapter has implemented an NGINX reverse proxy server for the
    application to build the API Gateway for our specimen.
  prefs: []
  type: TYPE_NORMAL
- en: Right from the start, we have witnessed the simplicity, power, adaptability,
    and scalability of the FastAPI framework, from creating background processes to
    rendering data using HTML templates. Its fast execution of API endpoints through
    its coroutines gives the framework the edge to become one of the most popular
    Python frameworks in the future. As the community of FastAPI continues to grow,
    we hope for more promising features in its future updates, such as support for
    reactive programming, circuit breakers, and a signature security module. We're
    hoping for the best for the FastAPI framework!
  prefs: []
  type: TYPE_NORMAL
