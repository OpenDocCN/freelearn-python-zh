- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Adding Computer Vision to A.R.E.S.
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将计算机视觉添加到A.R.E.S.
- en: In this final chapter, we will be adding computer vision to A.R.E.S. This will
    give A.R.E.S. the ability to recognize objects as well as alert us via text message
    to the presence of these objects. For our example, we will be recognizing dogs,
    although we could just as easily set up our object recognition code to recognize
    other objects.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后，我们将向A.R.E.S.添加计算机视觉功能。这将使A.R.E.S.能够识别物体，并通过短信通知我们这些物体的存在。在我们的例子中，我们将识别狗，尽管我们同样可以设置我们的目标识别代码来识别其他物体。
- en: We will start our journey by exploring **computer vision** and what it is before
    downloading and installing the **Open Source Computer Vision** (**OpenCV**) library
    and the **You Only Look Once** (**YOLO**) object detection system. After setting
    up these tools, we will explore hands-on examples.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过探索**计算机视觉**及其定义来开始我们的旅程，然后再下载和安装**开源计算机视觉**（**OpenCV**）库和**你只看一次**（**YOLO**）目标检测系统。在设置好这些工具之后，我们将探索一些实际操作示例。
- en: By the end of this chapter, you will have built a smart video streaming application
    that utilizes the video stream from the camera on A.R.E.S.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将构建一个智能视频流应用程序，该程序利用A.R.E.S.摄像头的视频流。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: Exploring computer vision
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索计算机视觉
- en: Adding computer vision to A.R.E.S.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将计算机视觉添加到A.R.E.S.
- en: Sending out a text alert
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发送文本警报
- en: Let’s begin!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You will need the following to complete this chapter:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章内容你需要以下条件：
- en: Intermediate knowledge of Python programming
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python编程的中级知识
- en: The A.R.E.S. robot from [*Chapter 13*](B21282_13.xhtml#_idTextAnchor209)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A.R.E.S.机器人来自[*第13章*](B21282_13.xhtml#_idTextAnchor209)
- en: A computer with a GUI-style operating system, such as the Raspberry Pi 5, macOS,
    or Windows
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台具有GUI风格的操作系统计算机，例如Raspberry Pi 5、macOS或Windows
- en: 'The code for this chapter can be found here: [https://github.com/PacktPublishing/-Internet-of-Things-Programming-Projects-2nd-Edition/tree/main/Chapter14](https://github.com/PacktPublishing/-Internet-of-Things-Programming-Projects-2nd-Edition/tree/main/Chapter14).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下位置找到：[https://github.com/PacktPublishing/-Internet-of-Things-Programming-Projects-2nd-Edition/tree/main/Chapter14](https://github.com/PacktPublishing/-Internet-of-Things-Programming-Projects-2nd-Edition/tree/main/Chapter14)。
- en: Exploring computer vision
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索计算机视觉
- en: 'Computer vision began in the 1950s, evolving significantly with key milestones
    such as image processing algorithms in the 1960s and the introduction of GPUs
    in the 1990s. These advancements improved processing speeds and complex computations
    and enabled real-time image analysis and sophisticated models. Modern computer
    vision technology is a result of these developments. The following diagram shows
    where computer vision sits in terms of artificial intelligence:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉始于20世纪50年代，随着20世纪60年代图像处理算法的关键里程碑和20世纪90年代GPU的引入而显著发展。这些进步提高了处理速度和复杂计算，并实现了实时图像分析和复杂模型。现代计算机视觉技术是这些发展的结果。以下图表显示了计算机视觉在人工智能中的位置：
- en: '![Figure 14.1 – Artificial intelligence](img/B21282_14_1.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图14.1 – 人工智能](img/B21282_14_1.jpg)'
- en: Figure 14.1 – Artificial intelligence
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1 – 人工智能
- en: '*Figure 14**.1* shows a set of concentric circles representing the relationship
    between different fields of artificial intelligence. At the core is computer vision,
    surrounded by **object detection**, which is a subset of deep learning, something
    that’s nested within machine learning. All are encompassed by the broader field
    of artificial intelligence.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.1* 展示了一系列同心圆，代表人工智能不同领域之间的关系。核心是计算机视觉，周围是**目标检测**，它是深度学习的一个子集，嵌套在机器学习之中。所有这些都包含在更广泛的人工智能领域内。'
- en: Not all computer vision techniques involve machine learning or deep learning,
    but object detection, a part of computer vision, often does.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有计算机视觉技术都涉及机器学习或深度学习，但计算机视觉的一部分——目标检测，通常是这样。
- en: What is the difference between image recognition, object recognition, object
    detection, and image classification?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图像识别、目标识别、目标检测和图像分类之间的区别是什么？
- en: In computer vision, terms such as **image recognition**, **object recognition**,
    **object detection**, and **image classification** describe specific processes.
    Image recognition detects features or patterns within an image. Object recognition
    moves beyond this to identify distinct objects within an image or video, although
    it does not specify their precise locations, concentrating on identifying *what*
    objects are present rather than *where* they are. Object detection, conversely,
    not only identifies objects but also locates them spatially, often using bounding
    boxes. Meanwhile, image classification involves analyzing an entire image to assign
    it to a specific category, such as determining whether an image shows a dog, cat,
    or car. For A.R.E.S., we want a video feed that creates a bounding box around
    an object that’s been detected. So, we will use object detection in our application.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉中，诸如 **图像识别**、**目标识别**、**目标检测** 和 **图像分类** 等术语描述了特定的过程。图像识别检测图像内的特征或模式。目标识别超越了这一点，以识别图像或视频中的特定对象，尽管它不指定它们的精确位置，而是专注于识别
    *存在什么* 对象，而不是 *它们在哪里*。相反，目标检测不仅识别对象，还从空间上定位它们，通常使用边界框。同时，图像分类涉及分析整个图像，将其分配到特定的类别，例如确定图像是否显示狗、猫或汽车。对于
    A.R.E.S.，我们希望有一个视频流，它会在检测到的对象周围创建一个边界框。因此，我们将在应用程序中使用目标检测。
- en: In this chapter, we will integrate OpenCV and the YOLO deep learning algorithm
    into A.R.E.S. so that we can use object detection to detect the presence of a
    dog.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将 OpenCV 和 YOLO 深度学习算法集成到 A.R.E.S. 中，以便我们可以使用目标检测来检测狗的存在。
- en: We will start our foray into computer vision by familiarizing ourselves with
    the OpenCV library.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过熟悉 OpenCV 库来开始我们对计算机视觉的探索。
- en: Introducing OpenCV
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍 OpenCV
- en: OpenCV is a foundational tool in the field of computer vision that offers a
    vast range of capabilities for real-time image processing. OpenCV supports a multitude
    of applications, from simple image transformations to complex machine learning
    algorithms.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 是计算机视觉领域的基础工具，提供了实时图像处理的大量功能。OpenCV 支持多种应用，从简单的图像变换到复杂的机器学习算法。
- en: OpenCV not only allows for rapid prototyping but also supports full-scale application
    development across various operating systems, making it an excellent choice for
    hobbyists, educators, and commercial developers alike.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 不仅允许快速原型设计，还支持跨各种操作系统的全面应用开发，使其成为爱好者和教育工作者以及商业开发者的绝佳选择。
- en: In this section, we will explore the core functionalities of OpenCV. We will
    start by creating a Python virtual environment and a project folder.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探索 OpenCV 的核心功能。我们将从创建一个 Python 虚拟环境和项目文件夹开始。
- en: Viewing an image using OpenCV
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 OpenCV 查看图像
- en: 'Getting started with OpenCV can be as simple as displaying an image in a window.
    This basic exercise introduces us to key functions for image loading, handling,
    and window operations in OpenCV. Follow these steps:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用 OpenCV 可以简单到在窗口中显示一个图像。这个基本练习介绍了 OpenCV 中用于图像加载、处理和窗口操作的关键函数。按照以下步骤操作：
- en: Start by opening a terminal window. We can use the Raspberry Pi operating system
    on our Raspberry Pi 5 or another operating system of our choice.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先打开一个终端窗口。我们可以在 Raspberry Pi 5 上使用 Raspberry Pi 操作系统，或者使用我们选择的另一个操作系统。
- en: 'To store our project files, we must create a new directory and subdirectory
    (for images) with the following command (Linux commands are being used here):'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了存储我们的项目文件，我们必须创建一个新的目录和子目录（用于图像），可以使用以下命令（这里使用的是 Linux 命令）：
- en: '[PRE0]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we navigate to the new directory:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们导航到新目录：
- en: '[PRE1]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'venv library if it is not already installed):'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果尚未安装 venv 库）：
- en: '[PRE2]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'With our new Python virtual environment created, we can source into it with
    the following command:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建我们的新 Python 虚拟环境后，我们可以使用以下命令将其激活：
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: pip install opencv-python
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pip install opencv-python
- en: '[PRE5]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We close the terminal by running the following command:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过运行以下命令来关闭终端：
- en: '[PRE6]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we launch Thonny and source our newly created Python virtual environment:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们启动 Thonny 并激活我们新创建的 Python 虚拟环境：
- en: '![Figure 14.2 – Sourcing our Python virtual environment](img/B21282_14_2.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.2 – 激活我们的 Python 虚拟环境](img/B21282_14_2.jpg)'
- en: Figure 14.2 – Sourcing our Python virtual environment
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2 – 激活我们的 Python 虚拟环境
- en: Next, we’ll create a new tab. We can do this by selecting **File** and then
    **New** or by hitting *Ctrl* + *N* on our keyboard.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个新标签页。我们可以通过选择 **文件** 然后选择 **新建** 或者通过在键盘上按 *Ctrl* + *N* 来实现。
- en: 'Enter the following code in the editor:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在编辑器中输入以下代码：
- en: '[PRE7]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let’s take a closer look at this code:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看这段代码：
- en: First, we import the `OpenCV` library and give it an alias of `cv` for easier
    reference in the code.
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入`OpenCV`库，并给它一个别名`cv`，以便在代码中更容易引用。
- en: Our code then reads the `Toronto.png` image file into the `img` variable from
    the `images` folder.
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的代码接着将`Toronto.png`图像文件从`images`文件夹读取到`img`变量中。
- en: Next, we create a window named `Downtown Toronto` and display `img` within this
    window.
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个名为`Downtown Toronto`的窗口，并在其中显示`img`。
- en: Then, our code waits indefinitely for a key event before moving on to the next
    line of code. The `0` value means it will wait until a key is pressed.
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们的代码在继续执行下一行代码之前无限期地等待一个按键事件。`0`值表示它将等待直到按键被按下。
- en: Finally, we destroy all the windows that have been created during the session
    and ensure no window from the OpenCV UI remains open after the script is run.
    This could potentially cause a memory leak.
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们销毁在会话期间创建的所有窗口，并确保在脚本运行后没有OpenCV UI窗口保持打开。这可能会引起内存泄漏。
- en: We save the code with a descriptive name such as `Toronto.py` in our `Chapter14`
    project folder.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将代码保存为具有描述性名称的文件，例如在`Chapter14`项目文件夹中保存为`Toronto.py`。
- en: We run the code by clicking on the green run button, hitting *F5* on our keyboard,
    or clicking on the **Run** menu option at the top and then **Run** **current script**.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过点击绿色运行按钮，按键盘上的*F5*，或在顶部菜单中选择**运行**然后**运行当前脚本**来运行代码。
- en: 'We should see a window appear that contains an image of Toronto:'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们应该看到一个包含多伦多市图像的窗口出现：
- en: '![Figure 14.3 – OpenCV window popup showing downtown Toronto (image: Maximillian
    Dow)](img/B21282_14_3.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图14.3 – 显示多伦多市区的OpenCV窗口弹出窗口（图片：Maximillian Dow）](img/B21282_14_3.jpg)'
- en: 'Figure 14.3 – OpenCV window popup showing downtown Toronto (image: Maximillian
    Dow)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3 – 显示多伦多市区的OpenCV窗口弹出窗口（图片：Maximillian Dow）
- en: To close the pop-up window, we hit any key on our keyboard.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要关闭弹出窗口，我们按键盘上的任意键。
- en: Although very simple, this exercise lays the groundwork for more complex computer
    vision projects. Before we move on to using artificial intelligence, we will investigate
    using OpenCV to view the camera feed coming from A.R.E.S.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个练习非常简单，但它为更复杂的计算机视觉项目奠定了基础。在我们转向使用人工智能之前，我们将研究使用OpenCV来查看来自A.R.E.S.的摄像头视频流。
- en: Streaming video using OpenCV
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用OpenCV进行视频流处理
- en: In [*Chapter 13*](B21282_13.xhtml#_idTextAnchor209), we streamed a video from
    A.R.E.S. using the VLC media player. To utilize the video coming from A.R.E.S.,
    we can use OpenCV for real-time image and video analysis.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第13章*](B21282_13.xhtml#_idTextAnchor209)中，我们使用VLC媒体播放器从A.R.E.S.流式传输视频。为了利用来自A.R.E.S.的视频，我们可以使用OpenCV进行实时图像和视频分析。
- en: 'To view our video feed using OpenCV, we must do the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用OpenCV查看我们的视频流，我们必须执行以下操作：
- en: We launch Thonny and source the `ch14-env` Python virtual environment.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们启动Thonny并源码`ch14-env` Python虚拟环境。
- en: We create a new tab by selecting **File** and then **New** or by hitting *Ctrl*
    + *N* on our keyboard.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过选择**文件**然后**新建**或在键盘上按*Ctrl* + *N*来创建一个新的标签页。
- en: 'We enter the following code in the editor:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在编辑器中输入以下代码：
- en: '[PRE8]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s take a closer look at this code:'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看这段代码：
- en: We start by importing the OpenCV library.
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先导入OpenCV库。
- en: Then, we define the RTSP URL as a string for the video stream source.
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将RTSP URL定义为字符串，作为视频流源。
- en: Our code creates a `VideoCapture` object that attempts to open the video stream
    from the specified RTSP URL. If the stream can’t be opened, an error message is
    printed.
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的代码创建了一个`VideoCapture`对象，尝试从指定的RTSP URL打开视频流。如果无法打开流，将打印错误信息。
- en: Then, we start an infinite loop to continuously fetch frames from the stream.
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们启动一个无限循环，以连续从流中获取帧。
- en: After, we attempt to read the next frame from the stream.
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们尝试从流中读取下一帧。
- en: We print an error message if a frame can’t be received and exit the loop.
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果无法接收到帧，我们打印错误信息并退出循环。
- en: We display the current frame in a window titled `A.R.E.S. Stream`.
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在标题为`A.R.E.S. Stream`的窗口中显示当前帧。
- en: Then, we allow the user to close the stream window manually if they press `q`
    on their keyboard.
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，如果用户在键盘上按`q`，我们允许用户手动关闭流窗口。
- en: Next, release the video capture object, freeing up resources and closing the
    video file or capturing device.
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，释放视频捕获对象，释放资源并关闭视频文件或捕获设备。
- en: Finally, we close all OpenCV windows, cleaning up any remaining resources associated
    with the window displays.
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们关闭所有OpenCV窗口，清理与窗口显示相关的任何剩余资源。
- en: We save the code with a descriptive name such as `video-feed.py` in our `Chapter14`
    project folder.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将代码保存为具有描述性的名称，例如`video-feed.py`，在我们的`Chapter14`项目文件夹中。
- en: We run the code by clicking on the green run button, hitting *F5* on our keyboard,
    or clicking on the **Run** menu option at the top and then **Run** **current script**.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过点击绿色运行按钮，在键盘上按*F5*，或者在顶部菜单中选择**运行**，然后选择**运行****当前脚本**来运行代码。
- en: 'We should see a window appear, displaying the feed from the camera on A.R.E.S:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该会看到一个窗口出现，显示A.R.E.S的摄像头视频流：
- en: '![Figure 14.4 – Video feed from the camera on A.R.E.S.](img/B21282_14_4.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图14.4 – A.R.E.S摄像头视频流](img/B21282_14_4.jpg)'
- en: Figure 14.4 – Video feed from the camera on A.R.E.S.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4 – A.R.E.S摄像头视频流
- en: To close the pop-up window, we hit `q` on our keyboard.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要关闭弹出窗口，我们在键盘上按`q`键。
- en: Now that we have some experience using OpenCV to view images and videos, let’s
    take this a step further and have it identify objects, specifically dogs, as we
    continue our computer vision journey.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使用OpenCV查看图像和视频积累了一些经验，让我们更进一步，让它识别物体，特别是狗，在我们继续计算机视觉之旅的过程中。
- en: We will start by looking at neural networks and how they are used to identify
    objects.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先探讨神经网络及其在识别物体中的应用。
- en: Understanding YOLO and neural networks
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解YOLO和神经网络
- en: In this section, we’ll focus on YOLO and the various layers of neural networks
    so that we can construct object detection code that can identify dogs. Turning
    our attention to *Figure 14**.1*, we can see that object detection is a part of
    computer vision, where both deep learning and machine learning techniques are
    used.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将重点关注YOLO和神经网络的不同层次，以便我们可以构建能够识别狗的物体检测代码。将注意力转向*图14**.1*，我们可以看到物体检测是计算机视觉的一部分，其中使用了深度学习和机器学习技术。
- en: Machine learning versus deep learning
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习与深度学习
- en: Machine learning is a subset of artificial intelligence where algorithms use
    statistical methods to enable machines to improve with experience, typically requiring
    manual feature selection. In contrast, deep learning, a specialized subset of
    machine learning, operates with neural networks, which automatically extract and
    learn features from large volumes of data. This is ideal for complex tasks such
    as image and speech recognition. While machine learning works with less data and
    provides more model transparency, deep learning requires substantial data and
    computational power, often acting as a *black box* with less interpretability.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能的一个子集，其中算法使用统计方法使机器能够通过经验改进，通常需要手动选择特征。相比之下，深度学习是机器学习的一个专门子集，它使用神经网络，这些神经网络可以从大量数据中自动提取和学习特征。这对于图像和语音识别等复杂任务来说非常理想。虽然机器学习使用较少的数据并提供更多的模型透明度，但深度学习需要大量的数据和计算能力，通常作为一个*黑盒*运行，可解释性较低。
- en: To represent deep learning, YOLO uses a sophisticated neural network that assesses
    images in a single sweep.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了表示深度学习，YOLO使用一个复杂的神经网络，它可以在一次扫描中评估图像。
- en: Exploring object detection
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索物体检测
- en: 'As mentioned previously, object detection is the process of finding objects
    in an image or video feed. The following figure illustrates the sequential stages
    of an object detection algorithm, using the example of an image of a dog:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，物体检测是在图像或视频流中寻找物体的过程。以下图示展示了物体检测算法的连续阶段，以狗的图像为例：
- en: '![](img/B21282_14_5.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21282_14_5.jpg)'
- en: Figure 14.5 – Stages of object detection in computer vision
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.5 – 计算机视觉中物体检测的阶段
- en: First, we have the original image as the input. We proceed by decomposing it
    into input pixels and then identify the edges, corners, and contours for structural
    interpretation. Our algorithm proceeds to recognize individual object parts and
    places bounding boxes around these components. This leads to the final output,
    which highlights the detected object within the image.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们有原始图像作为输入。我们通过将其分解为输入像素，然后识别边缘、角和轮廓来进行结构解释。我们的算法接着识别单个物体部分，并在这些组件周围放置边界框。这导致了最终的输出，它突出了图像中检测到的物体。
- en: Now that we understand how object detection works when used with neural networks,
    let’s consider an example. In the next subsection, we will use YOLO to identify
    a dog in a picture.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了使用神经网络进行物体检测的工作原理，让我们考虑一个例子。在下一小节中，我们将使用YOLO在图片中识别一只狗。
- en: Using YOLO to identify a dog in a picture
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用YOLO在图片中识别狗
- en: In this section, we will write a program using OpenCV and the YOLO deep learning
    algorithm to detect a dog in a picture.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 OpenCV 和 YOLO 深度学习算法编写一个程序，用于在图片中检测狗。
- en: To get started, we need to download the YOLO configuration files, the pre-trained
    weights, and the `coco.names` file, which contains the list of classes recognized
    by the model. These files are typically available on the official YOLO website
    or reputable GitHub repositories dedicated to YOLO. The configuration file (`yolov4.cfg`)
    outlines the network architecture, the weights file (`yolov4.weights`) contains
    the trained model parameters, and the class names file lists the object categories
    the YOLO model can detect, all of which are crucial for the object detection task
    at hand.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，我们需要下载 YOLO 配置文件、预训练权重和 `coco.names` 文件，该文件包含模型识别的类别列表。这些文件通常可在官方 YOLO 网站或专注于
    YOLO 的信誉良好的 GitHub 仓库中找到。配置文件（`yolov4.cfg`）概述了网络架构，权重文件（`yolov4.weights`）包含训练好的模型参数，类别名称文件列出了
    YOLO 模型可以检测的对象类别，所有这些对于当前的目标检测任务至关重要。
- en: To make this easier, we have included all the files you’ll need for this exercise
    in this chapter’s GitHub repository.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个过程更简单，我们已经在本章的 GitHub 仓库中包含了您进行此练习所需的所有文件。
- en: What is the yolo4.weights file?
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`yolo4.weights` 文件是什么？'
- en: The `yolov4.weights` file contains pre-trained weights for the YOLOv4 object
    detection model, enabling it to accurately detect and locate objects in images
    and videos. Since this file is too large to be included in this chapter’s GitHub
    repository, you’ll need to download it from the official YOLO website or GitHub
    repository ([https://github.com/AlexeyAB/darknet/releases](https://github.com/AlexeyAB/darknet/releases)).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`yolov4.weights` 文件包含 YOLOv4 目标检测模型的预训练权重，使其能够准确地在图像和视频中检测和定位对象。由于此文件太大，无法包含在本章的
    GitHub 仓库中，您需要从官方 YOLO 网站或 GitHub 仓库（[https://github.com/AlexeyAB/darknet/releases](https://github.com/AlexeyAB/darknet/releases)）下载。'
- en: 'To create our object detection code, follow these steps:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建我们的目标检测代码，请按照以下步骤操作：
- en: We start by opening a terminal window. We can use the Raspberry Pi operating
    system on our Raspberry Pi 5 or another operating system of our choice.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先打开一个终端窗口。我们可以在 Raspberry Pi 5 上使用 Raspberry Pi 操作系统，或者使用我们选择的另一个操作系统。
- en: 'We navigate to our `Chapter14` project directory with the following command:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用以下命令导航到 `Chapter14` 项目目录：
- en: '[PRE9]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To store our YOLO files, create a new directory with the following command:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要存储我们的 YOLO 文件，使用以下命令创建一个新的目录：
- en: '[PRE10]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For our test image, we copy the `dog.png` file from the images directory of
    this chapter’s GitHub repository to our project folder’s images directory.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们的测试图像，我们将 `dog.png` 文件从本章 GitHub 仓库的图像目录复制到我们的项目文件夹的图像目录。
- en: We launch Thonny and source the `ch14-env` Python virtual environment.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们启动 Thonny 并源码导入 `ch14-env` Python 虚拟环境。
- en: We create a new tab by selecting **File** and then **New** or by hitting *Ctrl*
    + *N* on our keyboard.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过选择 **文件** 然后选择 **新建** 或者在键盘上按 *Ctrl* + *N* 来创建一个新的标签页。
- en: 'In the editor, we add the necessary imports for our code. Here, we’ll need
    OpenCV as our library and NumPy for its mathematical functions:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在编辑器中，我们添加代码所需的必要导入。在这里，我们需要 OpenCV 作为我们的库，以及 NumPy 用于其数学函数：
- en: '[PRE11]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, we load the YOLO algorithm by running the following lines of code:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们通过运行以下代码行来加载 YOLO 算法：
- en: '[PRE12]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let’s take a closer look at this code:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们仔细看看这段代码：
- en: First, we initialize the YOLO network by loading the pre-trained weights (`yolov4.weights`)
    and configuration (`yolov4.cfg`). This creates a neural network ready for object
    detection.
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们通过加载预训练权重（`yolov4.weights`）和配置（`yolov4.cfg`）来初始化 YOLO 网络。这创建了一个准备进行目标检测的神经网络。
- en: Then, we create an empty list intended to store the class names (for example,
    dog and cat) that YOLO can detect, once they are read from a file.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建一个空列表，用于存储 YOLO 可以检测的类别名称（例如，狗和猫），一旦从文件中读取，它们就会被存储在这个列表中。
- en: Our code then retrieves the names of all the layers in the YOLO network. These
    layer names are used to identify output layers. This is crucial for obtaining
    detection results.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们的代码检索 YOLO 网络中所有层的名称。这些层名称用于识别输出层。这对于获取检测结果至关重要。
- en: 'We enter the following code to fetch the indices of the final layers in the
    YOLO neural network. These directly output detection results using the OpenCV
    `getUnconnectedOutLayers()` method:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们输入以下代码来获取 YOLO 神经网络中最终层的索引。这些层直接使用 OpenCV 的 `getUnconnectedOutLayers()` 方法输出检测结果：
- en: '[PRE13]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, create a list of the names of the output layers of the YOLO neural network
    by indexing into the list of all layer names using the indices provided by `output_layer_indices`,
    adjusted for zero-based indexing. This corresponds to the *Bounding Boxes* stage
    of the algorithm, as outlined in *Figure 14**.5*:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过使用`output_layer_indices`提供的索引并调整为零基索引，从所有层名称列表中索引以创建YOLO神经网络的输出层名称列表。这对应于算法中的*边界框*阶段，如*图14*5*所示：
- en: '[PRE14]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we read the `coco.names` file, which contains the list of object classes
    that the YOLO model can identify, and creates a list of class names by removing
    any leading or trailing whitespace from each line. The following code finds and
    stores the index of the `"dog"` class within that list, effectively preparing
    the program to specifically recognize and identify dogs in the images processed
    by the YOLO model:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们读取`coco.names`文件，该文件包含YOLO模型可以识别的对象类别列表，并创建一个类别名称列表，通过从每一行中删除任何前导或尾随空白来创建。以下代码找到并存储`"dog"`类别在该列表中的索引，有效地使程序准备好在YOLO模型处理的图像中特定识别和识别狗：
- en: '[PRE15]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The following code reads the `dog.png` image from the `images` directory, scales
    it down to 40% of its original size to reduce computational load, and extracts
    its dimensions and color channel count. The resizing step is crucial because YOLO
    models typically expect a fixed input size, and resizing helps to match that requirement
    while also accelerating the detection process due to the smaller image size:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码从`images`目录中读取`dog.png`图像，将其缩小到原始大小的40%以减少计算负载，并提取其尺寸和颜色通道数。调整大小步骤至关重要，因为YOLO模型通常期望固定大小的输入，而调整大小有助于满足这一要求，同时由于图像尺寸较小，还可以加速检测过程：
- en: '[PRE16]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, we must convert the resized image into a **blob** – a preprocessed image
    that’s compatible with the neural network – by normalizing pixel values and setting
    the size to 416x416 pixels, a standard input size for YOLO models. Then, we must
    set this blob as the input to the neural network. Finally, we must perform a forward
    pass through the network using the specified output layers to obtain the detection
    predictions. This includes class labels, confidences, and bounding box coordinates.
    The following snippet corresponds to the action that takes place between the *Input
    Pixels* and the *Bounding Boxes* stages shown in *Figure 14**.5*. It processes
    the image through various layers to detect objects, with the final line in the
    snippet producing the detections that lead to the *Output* stage:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须将调整大小的图像转换为**blob**——一个与神经网络兼容的预处理图像——通过归一化像素值并将大小设置为416x416像素，这是YOLO模型的标准输入大小。然后，我们必须将此blob设置为神经网络的输入。最后，我们必须使用指定的输出层通过网络执行正向传递以获得检测预测。这包括类别标签、置信度和边界框坐标。以下代码片段对应于*图14*5*中显示的*输入像素*和*边界框*阶段之间的动作。它通过各种层处理图像以检测对象，代码片段中的最后一行产生导致*输出*阶段的检测：
- en: '[PRE17]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following code analyzes the results from the neural network’s forward pass,
    filtering and processing detected objects for the `dog` class with a confidence
    level above 50%. It calculates the bounding box coordinates based on the object’s
    center, width, and height, then stores these coordinates along with the detection
    confidence and class ID in corresponding lists. This aligns with the *Bounding
    Boxes* stage shown in *Figure 14**.5*, where the processed outputs are used to
    specifically locate and classify the detected objects within the image. This sets
    the stage for the final visual representation in the *Output* phase, where these
    bounding boxes are drawn to indicate where dogs are located within the image:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码分析神经网络正向传递的结果，对检测到的`dog`类对象进行过滤和处理，置信度高于50%。它根据对象的中心、宽度和高度计算边界框坐标，然后将这些坐标以及检测置信度和类别ID存储在相应的列表中。这与*图14*5*中显示的*边界框*阶段相一致，其中处理后的输出用于在图像中特定定位和分类检测到的对象。这为*输出*阶段的最终视觉表示奠定了基础，在该阶段，这些边界框被绘制出来以指示图像中狗的位置：
- en: '[PRE18]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following code uses `NMSBoxes` function from OpenCV to refine the detection
    results by reducing overlap among bounding boxes, ensuring that each detected
    object is represented only once. After determining the best bounding boxes based
    on their confidence and overlap, it iterates through these optimized boxes to
    visually annotate the image. It does this by drawing a rectangle for each box
    and labeling it with the corresponding class name. This final step marks and identifies
    the detected objects (`dogs`) in the image, aligning with the *Output* stage shown
    in *Figure 14**.5*:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码使用OpenCV的`NMSBoxes`函数通过减少边界框之间的重叠来细化检测结果，确保每个检测到的对象只被表示一次。在根据它们的置信度和重叠情况确定最佳边界框之后，它遍历这些优化后的边界框以可视标注图像。这是通过为每个边界框绘制一个矩形并标注相应的类别名称来实现的。这一步标记并识别图像中检测到的对象（狗），与图14**.5**中所示的*输出*阶段相一致：
- en: '[PRE19]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the final section of our code, we display the processed image with detected
    objects marked by bounding boxes. The `cv2.imshow("Image", img)` function displays
    the image in a window titled `"Image"`. The `cv2.waitKey(0)` function pauses the
    execution of the script, waiting indefinitely for a key press to proceed, allowing
    the user to view the image for as long as needed. Finally, `cv2.destroyAllWindows()`
    closes all OpenCV windows opened by the script, ensuring a clean exit without
    leaving any GUI windows open:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们代码的最后一部分，我们显示带有边界框标记的已处理图像。`cv2.imshow("Image", img)`函数在标题为`"Image"`的窗口中显示图像。`cv2.waitKey(0)`函数暂停脚本的执行，无限期地等待按键以继续，使用户能够查看图像所需的时间。最后，`cv2.destroyAllWindows()`关闭由脚本打开的所有OpenCV窗口，确保干净退出，不留下任何GUI窗口打开：
- en: '[PRE20]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We save the code with a descriptive name, such as `recognize-dog.py`, in our
    `Chapter14` project folder.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将代码保存为具有描述性的名称，例如`recognize-dog.py`，在我们的`Chapter14`项目文件夹中。
- en: We run the code by clicking on the green run button, hitting *F5* on our keyboard,
    or clicking on the **Run** menu option at the top and then **Run** **current script**.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过点击绿色运行按钮，按键盘上的*F5*，或者在顶部菜单中选择**运行**，然后选择**运行** **当前脚本**来运行代码。
- en: 'We should observe a pop-up window appear with a bounding box around the face
    of the dog:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该会看到一个弹出窗口出现，窗口中有一个围绕狗脸的边界框：
- en: '![Figure 14.6 – YOLO library used to recognize a dog](img/B21282_14_6.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图14.6 – 用于识别狗的YOLO库](img/B21282_14_6.jpg)'
- en: Figure 14.6 – YOLO library used to recognize a dog
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.6 – 用于识别狗的YOLO库
- en: We press any key on our keyboard to close the pop-up window.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们按键盘上的任意键来关闭弹出窗口。
- en: As we can see, our program can identify a dog from a picture. If we were to
    provide a picture of any object identified in the `coco.names` file (a person,
    for example), our program should be able to identify that.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们的程序可以从图片中识别出狗。如果我们提供`coco.names`文件中识别到的任何对象的图片（例如，一个人），我们的程序应该能够识别出那个对象。
- en: Now that we have a little exposure to YOLO, neural networks, and object detection,
    let’s add this functionality to A.R.E.S. We will program our application to send
    a text message whenever A.R.E.S. detects a dog.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对YOLO、神经网络和目标检测有了一定的了解，让我们将这个功能添加到A.R.E.S中。我们将编程我们的应用程序，以便每当A.R.E.S检测到狗时发送一条文本消息。
- en: Adding computer vision to A.R.E.S.
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将计算机视觉添加到A.R.E.S中。
- en: In the previous section, we explored OpenCV and YOLO, using OpenCV to view images
    and video feeds, and YOLO to identify a dog in a picture. In this section, we’ll
    apply what we’ve learned to create a smart video streaming application that represents
    the eyes of A.R.E.S. We’ll only use dogs as an example, but we could easily adapt
    this application for tracking other objects.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们探讨了OpenCV和YOLO，使用OpenCV查看图像和视频流，使用YOLO在图片中识别狗。在本节中，我们将应用我们所学到的知识来创建一个智能视频流应用程序，代表A.R.E.S的眼睛。我们将仅以狗为例，但我们可以轻松地将此应用程序改编为跟踪其他对象。
- en: We will start by encapsulating our YOLO code into a class called `DogTracker`
    before creating a video streaming application using this class with OpenCV.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建视频流应用程序之前，我们将首先将我们的YOLO代码封装到一个名为`DogTracker`的类中。
- en: Creating the DogTracker class
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建DogTracker类
- en: The `DogTracker` class embodies the artificial intelligence component of A.R.E.S.
    Although it could be installed directly on the Raspberry Pi 3B+ within A.R.E.S.
    and accessed remotely via the streaming window application, we will install it
    on a computer alongside our streaming application for simplicity and improved
    performance. In our example, we will utilize a Windows PC.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`DogTracker`类体现了A.R.E.S的人工智能组件。尽管它可以直接安装在A.R.E.S的Raspberry Pi 3B+上并通过流窗口应用程序远程访问，但为了简单和性能提升，我们将将其安装在包含流式应用程序的计算机上。在我们的示例中，我们将使用Windows
    PC。'
- en: 'To create the `DogTracker` class, we must do the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建`DogTracker`类，我们必须执行以下步骤：
- en: We launch Thonny and source our `ch14-env` Python virtual environment.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们启动Thonny并激活我们的`ch14-env` Python虚拟环境。
- en: We create a new tab by selecting **File** and then **New** or by hitting *Ctrl*
    + *N* on our keyboard.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过选择**文件**然后**新建**或在键盘上按*Ctrl* + *N*创建一个新标签页。
- en: 'Next, we add the necessary imports:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们添加必要的导入：
- en: '[PRE21]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then, we define our class and initialization method:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义我们的类和初始化方法：
- en: '[PRE22]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, we must define our only method: `detect_dogs()`. This method processes
    video frames to detect dogs using a YOLO neural network model. It begins by resizing
    the input frame for optimal processing and creates a blob from the resized image,
    which is then fed into the neural network. The network outputs detection results,
    which include bounding boxes, confidences, and class IDs for detected objects.
    The method checks each detection to see if it meets the confidence threshold and
    corresponds to the class ID for dogs. If such detections are found, it calculates
    and stores their bounding box coordinates. NMS is then applied to refine these
    bounding boxes by reducing overlaps. If any boxes remain after this process, it
    confirms the presence of dogs, draws these boxes on the frame, and labels them.
    Finally, the method returns the processed frame, along with a Boolean indicating
    whether any dogs were detected:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须定义我们的唯一方法：`detect_dogs()`。此方法通过YOLO神经网络模型处理视频帧以检测狗。它首先将输入帧调整大小以进行最佳处理，然后从调整大小的图像中创建一个blob，该blob随后被输入到神经网络中。网络输出检测结果，包括检测对象的边界框、置信度和类别ID。该方法检查每个检测是否满足置信度阈值并对应于狗的类别ID。如果找到此类检测，它将计算并存储它们的边界框坐标。然后应用NMS以通过减少重叠来细化这些边界框。如果在此过程之后仍有任何框，它将确认狗的存在，在帧上绘制这些框，并对其进行标记。最后，该方法返回处理后的帧，以及一个布尔值，指示是否检测到狗：
- en: '[PRE23]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We save the code with a descriptive name, such as `DogDetector.py`, in our `Chapter14`
    project folder.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将代码保存为具有描述性的名称，例如`DogDetector.py`，在我们的`Chapter14`项目文件夹中。
- en: Here, we reorganized the `recognize-dog.py` code from the previous section into
    a class that we will use for our smart video streamer. With this class in place,
    it’s time to create our streaming application. We will use OpenCV for this.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将上一节中的`recognize-dog.py`代码重新组织成一个类，我们将使用该类来创建我们的智能视频流器。有了这个类，现在是时候创建我们的流式应用程序了。我们将使用OpenCV来完成这项工作。
- en: Building a smart video streamer
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建智能视频流器
- en: We will use the `detect_dogs()` method inside the `DogDetector` class to identify
    dogs from the video stream coming from A.R.E.S. As mentioned previously, we could
    easily change our code so that we can use YOLO to identify other objects. Recognizing
    dogs presents a fun way for those of us with dogs to program A.R.E.S. as a sort
    of pet detection robot. We will install our smart video streamer onto the same
    computer as our `DogDetector` class.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在`DogDetector`类内部使用`detect_dogs()`方法来从来自A.R.E.S的视频流中识别狗。如前所述，我们可以轻松地更改我们的代码，以便可以使用YOLO来识别其他对象。识别狗为我们有狗的朋友们提供了一个有趣的方式来编程A.R.E.S作为一个宠物检测机器人。我们将把我们的智能视频流器安装在与`DogDetector`类相同的计算机上。
- en: 'To create the smart video streamer, follow these steps:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建智能视频流器，请按照以下步骤操作：
- en: We launch Thonny and source our `ch14-env` Python virtual environment.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们启动Thonny并激活我们的`ch14-env` Python虚拟环境。
- en: We create a new tab by selecting **File** and then **New** or by hitting *Ctrl*
    + *N* on our keyboard.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过选择**文件**然后**新建**或在键盘上按*Ctrl* + *N*创建一个新标签页。
- en: 'We start by adding our imports:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先添加我们的导入：
- en: '[PRE24]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then, we define our variable declarations:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义我们的变量声明：
- en: '[PRE25]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The bulk of our code sits inside an infinite loop. This code continuously captures
    frames from a video source, checking if each frame is successfully retrieved.
    If a second passes since the last processed frame, it detects dogs in the current
    frame using the `detect_dogs()` method, updates the time marker, and displays
    the result; if the `q` key is pressed, the loop breaks, and the video capture
    and any OpenCV windows are cleanly released and closed:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的大部分代码都位于一个无限循环中。此代码持续从视频源捕获帧，检查是否成功检索到每一帧。如果自上次处理的帧以来已过去一秒钟，它将使用 `detect_dogs()`
    方法在当前帧中检测到狗，更新时间标记，并显示结果；如果按下 `q` 键，循环中断，视频捕获以及任何 OpenCV 窗口将被干净地释放和关闭：
- en: '[PRE26]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We save the code with a descriptive name, such as `smart-video-feed.py`, in
    our `Chapter14` project folder.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将代码保存为具有描述性的名称，例如 `smart-video-feed.py`，在我们的 `Chapter14` 项目文件夹中。
- en: We run the code by clicking on the green run button, hitting *F5* on our keyboard,
    or clicking on the **Run** menu option at the top and then **Run** **current script**.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过点击绿色运行按钮，在键盘上按 *F5*，或者在顶部菜单中选择 **运行** 选项，然后选择 **运行** **当前脚本** 来运行代码。
- en: 'We should observe a pop-up window appear with a video feed from A.R.E.S. Our
    application should detect the presence of a dog:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们应该会看到一个弹出窗口出现，显示来自 A.R.E.S. 的视频流。我们的应用程序应该能够检测到狗的存在：
- en: '![Figure 14.7 – Detecting a dog using our smart video streamer](img/B21282_14_7.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.7 – 使用我们的智能视频流器检测狗](img/B21282_14_7.jpg)'
- en: Figure 14.7 – Detecting a dog using our smart video streamer
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.7 – 使用我们的智能视频流器检测狗
- en: With this, we have successfully added artificial intelligence in the form of
    object detection to A.R.E.S. We may adjust the size, font, and color of the frame
    in our `DogDetector` class. As impressive as getting object detection to work
    with A.R.E.S. is, we will take this a step further and introduce text notification,
    turning the smart video streaming functionality into a true IoT application.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们已经成功地将人工智能以对象检测的形式添加到 A.R.E.S.。我们可以在 `DogDetector` 类中调整帧的大小、字体和颜色。尽管让对象检测在
    A.R.E.S. 上工作令人印象深刻，但我们将进一步推进，引入文本通知，将智能视频流功能转变为真正的物联网应用程序。
- en: Sending out a text alert
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送文本警报
- en: To make A.R.E.S. a true IoT device, we will add text functionality. This will
    give A.R.E.S. the ability to send out text alerts when an object of interest –
    in our case, a dog – is detected. We will use the Twilio service for this.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 A.R.E.S. 成为一个真正的物联网设备，我们将添加文本功能。这将使 A.R.E.S. 能够在检测到感兴趣的对象时（在我们的案例中是狗）发送文本警报。我们将使用
    Twilio 服务来完成这项工作。
- en: We will start by setting up our Twilio account and testing the number we are
    assigned before we integrate text messaging functionality into A.R.E.S. We must
    ensure that we follow the upcoming steps carefully so that we can set up our Twilio
    account successfully.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将文本消息功能集成到 A.R.E.S. 之前，我们将首先设置我们的 Twilio 账户并测试分配给我们的号码。我们必须确保我们仔细遵循即将到来的步骤，以便我们能够成功设置我们的
    Twilio 账户。
- en: Setting up our Twilio account
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置我们的 Twilio 账户
- en: Setting up a Twilio account involves registering on their website, where we’ll
    be provided with an account SID and an auth token to authenticate API requests.
    Once registered, we can also obtain a Twilio phone number, which is necessary
    for sending SMS messages and making calls through their service. In this section,
    we will set up our Twilio account and send a test SMS message.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 Twilio 账户涉及在他们网站上注册，在那里我们将获得一个账户 SID 和一个认证令牌，用于验证 API 请求。一旦注册，我们还可以获取一个 Twilio
    电话号码，这对于通过他们的服务发送短信和打电话是必要的。在本节中，我们将设置我们的 Twilio 账户并发送一条测试短信。
- en: 'To set up our Twilio account, follow these steps:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置我们的 Twilio 账户，请按照以下步骤操作：
- en: 'Using a web browser, we navigate to [www.twilio.com](https://www.twilio.com)
    and click the blue **Start for** **free** button:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网络浏览器，我们导航到 [www.twilio.com](https://www.twilio.com) 并点击蓝色 **免费开始** 按钮：
- en: '![Figure 14.8 – The Twilio website](img/B21282_14_8.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.8 – Twilio 网站](img/B21282_14_8.jpg)'
- en: Figure 14.8 – The Twilio website
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.8 – Twilio 网站
- en: 'This will take us to the **Sign up** page. Here, we can create a Twilio account
    or use a Google account:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将带我们到 **注册** 页面。在这里，我们可以创建一个 Twilio 账户或使用 Google 账户：
- en: '![Figure 14.9 – Twilio’s Sign up page](img/B21282_14_9.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.9 – Twilio 的注册页面](img/B21282_14_9.jpg)'
- en: Figure 14.9 – Twilio’s Sign up page
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.9 – Twilio 的注册页面
- en: 'To verify our new account, we type in a phone number and click on the blue
    **Send code via** **SMS** button:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了验证我们的新账户，我们输入一个电话号码并点击蓝色 **通过 SMS 发送代码** 按钮：
- en: '![Figure 14.10 – Verify page](img/B21282_14_10.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.10 – 验证页面](img/B21282_14_10.jpg)'
- en: Figure 14.10 – Verify page
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.10 – 验证页面
- en: 'We should receive a text message containing a verification code. We enter the
    number and click on the blue **Verify** button:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该收到包含验证码的短信。我们输入号码并点击蓝色 **验证** 按钮：
- en: '![Figure 14.11 – Verification code step](img/B21282_14_11.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.11 – 验证码步骤](img/B21282_14_11.jpg)'
- en: Figure 14.11 – Verification code step
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.11 – 验证码步骤
- en: 'This will take us to the **You’re all verified!** page, which will provide
    us with a **Recovery code** value. We click on the blue **Continue** button to
    go to the next page:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将带我们到 **您已全部验证！** 页面，该页面将为我们提供 **恢复码** 值。我们点击蓝色 **继续** 按钮进入下一页：
- en: '![Figure 14.12 – Recovery code](img/B21282_14_12.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.12 – 恢复码](img/B21282_14_12.jpg)'
- en: Figure 14.12 – Recovery code
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.12 – 恢复码
- en: 'The next page allows us to customize our Twilio experience:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一页允许我们自定义 Twilio 体验：
- en: '![Figure 14.13 – Customizing Twilio](img/B21282_14_13.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.13 – 自定义 Twilio](img/B21282_14_13.jpg)'
- en: Figure 14.13 – Customizing Twilio
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.13 – 自定义 Twilio
- en: The dashboard screen allows us to get a Twilio phone number. We click on the
    blue **Get phone number** button to continue.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仪表板屏幕允许我们获取 Twilio 电话号码。我们点击蓝色 **获取电话号码** 按钮继续。
- en: The next page provides us with a Twilio phone number we can use. We click on
    the blue **Next** button to proceed.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一页提供了我们可以使用的 Twilio 电话号码。我们点击蓝色 **下一步** 按钮继续。
- en: 'On the next screen, we can test out our new Twilio number. The `IoT test`,
    and click on the blue **Send test** **SMS** button:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一屏幕上，我们可以测试我们的新 Twilio 号码。点击蓝色 **发送测试** **短信** 按钮：
- en: '![Figure 14.14 – Testing our new Twilio phone number](img/B21282_14_14.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.14 – 测试我们的新 Twilio 电话号码](img/B21282_14_14.jpg)'
- en: Figure 14.14 – Testing our new Twilio phone number
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.14 – 测试我们的新 Twilio 电话号码
- en: 'We should receive a text message with our test message, **IoT test**, on the
    phone we provided the number to Twilio on:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该在提供给 Twilio 的手机上收到包含测试消息 **IoT 测试** 的短信：
- en: '![Figure 14.15 – Test message successfully received, as seen on a cell phone](img/B21282_14_15.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.15 – 测试消息成功接收，如手机上所见](img/B21282_14_15.jpg)'
- en: Figure 14.15 – Test message successfully received, as seen on a cell phone
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.15 – 测试消息成功接收，如手机上所见
- en: With our Twilio account set up and our phone number tested, we are ready to
    incorporate text messaging into A.R.E.S.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好 Twilio 账户并测试了电话号码后，我们就可以将短信功能集成到 A.R.E.S. 中了。
- en: Adding text message functionality to A.R.E.S.
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将文本消息功能添加到 A.R.E.S.
- en: 'To integrate text messaging functionality into A.R.E.S., we will develop a
    new class named `TwilioMessage` and a new version of the `smart-video-feed.py`
    script:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 要将文本消息功能集成到 A.R.E.S. 中，我们将开发一个名为 `TwilioMessage` 的新类和一个新的 `smart-video-feed.py`
    脚本版本：
- en: '![Figure 14.16 – Adding text functionality to A.R.E.S.](img/B21282_14_16.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.16 – 将文本功能添加到 A.R.E.S.](img/B21282_14_16.jpg)'
- en: Figure 14.16 – Adding text functionality to A.R.E.S.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.16 – 将文本功能添加到 A.R.E.S.
- en: The `TwilioMessage` class will encapsulate communication to the Twilio server.
    As shown in *Figure 14**.16*, our new `TwilioMessage` class is called from our
    smart video streamer and sends out text messages.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`TwilioMessage` 类将封装与 Twilio 服务器的通信。如图 *图 14**.16* 所示，我们的新 `TwilioMessage`
    类从我们的智能视频流器调用并发送文本消息。'
- en: We will start by creating this class.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建这个类。
- en: Creating the TwilioMessage class
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 TwilioMessage 类
- en: 'To create the `TwilioMessage` class, we must do the following:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建 `TwilioMessage` 类，我们必须执行以下操作：
- en: We launch Thonny and source our `ch14-env` Python virtual environment.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们启动 Thonny 并源我们的 `ch14-env` Python 虚拟环境。
- en: 'As we require a library from Twilio to make our code work, we will install
    it in our Python virtual environment. To do so, open the system shell by clicking
    on **Tools** | **Open system shell…** in Thonny:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们需要从 Twilio 获取库以使我们的代码工作，我们将在 Python 虚拟环境中安装它。为此，在 Thonny 中通过点击 **工具** |
    **打开系统 shell…** 来打开系统壳：
- en: '![Figure 14.17 – Open system shell…](img/B21282_14_17.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.17 – 打开系统壳…](img/B21282_14_17.jpg)'
- en: Figure 14.17 – Open system shell…
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.17 – 打开系统壳…
- en: 'At the command prompt, we execute the following command:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在命令提示符下，我们执行以下命令：
- en: '[PRE27]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Once the library has been installed, we close the terminal.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦安装了库，我们就关闭终端。
- en: We create a new tab by selecting **File** and then **New** or by hitting *Ctrl*
    + *N* on our keyboard.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过选择 **文件** 然后选择 **新建** 或按键盘上的 *Ctrl* + *N* 创建一个新标签页。
- en: 'We add the following code to the editor:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将以下代码添加到编辑器中：
- en: '[PRE28]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let’s take a closer look at our code:'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们仔细看看我们的代码：
- en: First, we import the Twilio client and define the `TwilioMessage` class.
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入 Twilio 客户端并定义 `TwilioMessage` 类。
- en: Then, we initialize our class with Twilio credentials (account SID, auth token,
    and Twilio phone number).
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用Twilio凭证（账户SID、认证令牌和Twilio电话号码）初始化我们的类。
- en: The `send_sms()` method sends an SMS to a specified number and prints the message
    SID after sending.
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`send_sms()`方法向指定的号码发送短信，并在发送后打印消息SID。'
- en: In the main execution block, an instance of `TwilioMessage` is created with
    Twilio credentials, and a test SMS is sent to our number.
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主执行块中，创建了一个带有Twilio凭证的`TwilioMessage`实例，并发送了一条测试短信到我们的号码。
- en: We save the code with a descriptive name, such as `TwilioMessage.py`, in our
    `Chapter14` project folder.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将代码保存为具有描述性的名称，例如`TwilioMessage.py`，在我们的`Chapter14`项目文件夹中。
- en: We run the code by clicking on the green run button, hitting *F5* on our keyboard,
    or clicking on the **Run** menu option at the top and then **Run** **current script**.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过点击绿色运行按钮、在键盘上按*F5*键或点击顶部的**运行**菜单选项然后**运行****当前脚本**来运行代码。
- en: We should receive a text message saying, `Hello from A.R.E.S.` on our cell phone.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该在手机上收到一条短信，内容为`Hello from A.R.E.S.`。
- en: With the `TwilioMessage` class created, it is time to modify the smart video
    streamer code so that text messages will be sent when a dog or dogs are detected.
    We will do that in the next section.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建了`TwilioMessage`类之后，是时候修改智能视频流代码，以便在检测到狗或狗时发送短信。我们将在下一节中这样做。
- en: Modifying the smart video streamer
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修改智能视频流
- en: The final step in providing text message functionality in A.R.E.S. is to create
    a new smart video streamer script to send a text message when a dog is detected.
    To limit the number of messages sent, we will increase the time between frames
    to 5 seconds.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在A.R.E.S.中提供短信功能的最后一步是创建一个新的智能视频流脚本，当检测到狗时发送短信。为了限制发送的消息数量，我们将帧之间的时间间隔增加到5秒。
- en: 'To modify our smart video streamer, follow these steps:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要修改我们的智能视频流，请按照以下步骤操作：
- en: In Thonny, we create a new tab by selecting **File** and then **New** or by
    hitting *Ctrl* + *N* on our keyboard.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Thonny中，我们通过选择**文件**然后**新建**或按键盘上的*Ctrl* + *N*键来创建一个新的标签页。
- en: 'We add the following code to the editor:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将以下代码添加到编辑器中：
- en: '[PRE29]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We save the code with a descriptive name, such as `smart-video-sms.py`, in our
    `Chapter14` project folder.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将代码保存为具有描述性的名称，例如`smart-video-sms.py`，在我们的`Chapter14`项目文件夹中。
- en: We run the code by clicking on the green run button, hitting *F5* on n our keyboard,
    or clicking on the **Run** menu option at the top and then **Run** **current script**.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过点击绿色运行按钮、在键盘上按*F5*键或点击顶部的**运行**菜单选项然后**运行****当前脚本**来运行代码。
- en: We should observe a window appear with a video feed coming from A.R.E.S. that
    provides object detection functionality when a dog is present.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该看到一个窗口出现，其中包含来自A.R.E.S.的视频流，当有狗在场时提供对象检测功能。
- en: 'We should receive a text message once a dog has been detected:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当检测到狗时，我们应该收到一条短信：
- en: '![Figure 14.18 – A text message indicating that a dog or dogs were detected](img/B21282_14_18.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![图14.18 – 表示检测到狗或狗的消息的文本消息](img/B21282_14_18.jpg)'
- en: Figure 14.18 – A text message indicating that a dog or dogs were detected
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.18 – 表示检测到狗或狗的消息的文本消息
- en: With that, we have successfully added text message functionality to A.R.E.S.
    to alert us when an object we are interested in – in this case, a dog – is detected.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经成功地为A.R.E.S.添加了短信功能，以便在检测到我们感兴趣的对象时（在这种情况下，是一只狗）发出警报。
- en: Summary
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored the field of computer vision and successfully integrated
    it into our A.R.E.S. robot car. By incorporating this technology, A.R.E.S. can
    now process and interpret visual data. We also added text messaging functionality
    to A.R.E.S., turning our robot car into a true IoT device.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了计算机视觉领域，并将其成功集成到我们的A.R.E.S.机器人汽车中。通过采用这项技术，A.R.E.S.现在可以处理和解释视觉数据。我们还为A.R.E.S.添加了短信功能，使我们的机器人汽车成为真正的物联网设备。
- en: Although not implemented, we could easily imagine how we would take A.R.E.S.
    to the next level by incorporating obstacle avoidance based on the data we get
    back from YOLO. We may also imagine how we could make A.R.E.S. follow a certain
    object if desired.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然尚未实现，但我们可以很容易地想象如何通过结合YOLO返回的数据将A.R.E.S.提升到下一个水平，基于障碍物避免。我们也可以想象如果需要，A.R.E.S.如何跟随某个特定对象。
- en: This chapter marks the end of our IoT journey together. Throughout, we have
    explored the world of IoT while utilizing and building our programming skills
    – from using the Sense HAT to serve up web services data to utilizing LoRa for
    long-range communication to implementing advanced features such as computer vision
    in a robot car we control using the internet. This adventure has not only taught
    us technical know-how but also showed us the potential of IoT to innovate and
    solve any real-world challenges in the future.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 本章标志着我们共同物联网旅程的结束。在此过程中，我们探索了物联网的世界，同时利用并提升了我们的编程技能——从使用Sense HAT提供网络服务数据，到利用LoRa进行长距离通信，再到在我们的互联网控制下实现机器人汽车中的高级功能，如计算机视觉。这次冒险不仅教会了我们技术知识，还展示了物联网在创新和解决未来任何现实世界挑战中的潜力。
- en: It’s been a pleasure.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 很高兴。
