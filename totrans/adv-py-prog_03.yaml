- en: '*Chapter 2*: Pure Python Optimizations'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*: 纯Python优化'
- en: As mentioned in the previous chapter, one of the most effective ways of improving
    the performance of applications is through the use of better algorithms and data
    structures. The Python standard library provides a large variety of ready-to-use
    algorithms and data structures that can be directly incorporated into your applications.
    With the tools learned from this chapter, you will be able to use the right algorithm
    for the task and achieve massive speed gains.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，提高应用程序性能的最有效方法之一是通过使用更好的算法和数据结构。Python标准库提供了一系列现成的算法和数据结构，可以直接集成到您的应用程序中。通过本章学到的工具，您将能够为任务选择合适的算法，并实现巨大的速度提升。
- en: Even though many algorithms have been around for quite a while, they are especially
    relevant in today's world as we continuously produce, consume, and analyze ever-increasing
    amounts of data. Buying a larger server or micro-optimizing can work for some
    time, but achieving better scaling through algorithmic improvement can solve the
    problem once and for all.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多算法已经存在了很长时间，但它们在当今世界尤其相关，因为我们不断地生产、消费和分析越来越多的数据。购买更大的服务器或进行微优化可能暂时有效，但通过算法改进实现更好的扩展性可以一劳永逸地解决问题。
- en: In this chapter, we will learn how to achieve better scaling using standard
    algorithms and data structures. More advanced use cases where we take advantage
    of third-party libraries will also be covered. We will also learn about tools
    to implement caching, a technique used to achieve faster response times by sacrificing
    some space in memory or on disk.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何通过标准算法和数据结构实现更好的扩展性。同时，我们还将涵盖利用第三方库的更高级用法。我们还将了解用于实现缓存的工具，这是一种通过牺牲一些内存或磁盘空间来换取更快响应时间的技巧。
- en: 'The list of topics to be covered in this chapter is as follows:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题列表：
- en: Using the right algorithms and data structures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用合适的算法和数据结构
- en: Improved efficiency with caching and memoization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过缓存和记忆化提高效率
- en: Efficient iteration with comprehensions and generators
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用列表推导和生成器进行高效迭代
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You will find the code files for this chapter here: [https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter02](https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter02).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处找到本章的代码文件：[https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter02](https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter02)。
- en: Using the right algorithms and data structures
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用合适的算法和数据结构
- en: Algorithmic improvements are especially effective in increasing performance
    because they typically allow the application to scale better with increasingly
    large inputs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 算法改进在提高性能方面特别有效，因为它们通常允许应用程序在输入越来越大时更好地扩展。
- en: Algorithm running times can be classified according to their computational complexity,
    a characterization of the resources required to perform a task.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 算法运行时间可以根据其计算复杂度进行分类，这是对执行任务所需资源的一种描述。
- en: Such classification is expressed through the *Big O notation*, an upper bound
    on the operations required to execute the task, which usually depends on the input
    size. Specifically, Big O notation describes how the runtime or memory requirement
    of an algorithm grows in terms of the input size. For this reason, a lower Big
    O denotes a more efficient algorithm, which is what we aim for.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分类通过 *大O表示法* 来表达，它是执行任务所需操作的上限，通常取决于输入大小。具体来说，大O表示法描述了算法的运行时间或内存需求如何随着输入大小的增长而增长。因此，较低的Big
    O表示一个更有效的算法，这是我们追求的目标。
- en: 'For example, incrementing each element of a list can be implemented using a
    `for` loop, as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，可以使用 `for` 循环实现列表中每个元素的递增，如下所示：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If the operation does not depend on the size of the input (for example, accessing
    the first element of a list), the algorithm is said to take constant, or *O*(1),
    time. This means that, no matter how much data we have, the time to run the algorithm
    will always be the same.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果操作不依赖于输入的大小（例如，访问列表的第一个元素），则该算法被称为常数时间，或 *O*(1) 时间。这意味着，无论我们有多少数据，算法的运行时间都将保持不变。
- en: In this simple algorithm, the `input[i] += 1` operation will be repeated `10`
    times, which is the size of the input. If we double the size of the input array,
    the number of operations will increase proportionally. Since the number of operations
    is proportional to the input size, this algorithm is said to take *O*(*N*) time,
    where *N* is the size of the input array.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的算法中，`input[i] += 1` 操作将会重复执行 `10` 次，这是输入的大小。如果我们加倍输入数组的大小，操作的数量将成比例增加。由于操作的数量与输入大小成正比，因此这个算法被称为
    *O*(*N*) 时间复杂度，其中 *N* 是输入数组的大小。
- en: In some instances, the running time may depend on the structure of the input
    (for example, if the collection is sorted or contains many duplicates). In these
    cases, an algorithm may have different best-case, average-case, and worst-case
    running times. Unless stated otherwise, the running times presented in this chapter
    are considered to be average running times.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，运行时间可能取决于输入的结构（例如，如果集合是有序的或包含许多重复项）。在这些情况下，一个算法可能具有不同的最佳情况、平均情况和最坏情况运行时间。除非另有说明，本章中展示的运行时间被认为是平均运行时间。
- en: In this section, we will examine the running times of algorithms and data structures
    that are implemented in the Python standard library and understand how improving
    running times results in massive gains and allows us to solve large-scale problems
    with elegance.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将检查 Python 标准库中实现算法和数据结构的运行时间，并了解提高运行时间如何带来巨大的收益，并使我们能够以优雅的方式解决大规模问题。
- en: You can find the code used to run the benchmarks in this chapter in the `Algorithms.ipynb`
    notebook, which can be opened using *Jupyter*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章节的 `Algorithms.ipynb` 笔记本中找到用于运行基准测试的代码，该笔记本可以使用 *Jupyter* 打开。
- en: First, we will examine **lists** and **deques**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将检查 **列表** 和 **双端队列**。
- en: Lists and deques
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列表和双端队列
- en: Python lists are ordered collections of elements and, in Python, are implemented
    as resizable arrays. An **array** is a basic data structure that consists of a
    series of contiguous memory locations, and each location contains a reference
    to a Python object.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Python 列表是有序元素集合，在 Python 中实现为可调整大小的数组。**数组**是一种基本数据结构，由一系列连续的内存位置组成，每个位置包含对
    Python 对象的引用。
- en: Lists shine in accessing, modifying, and appending elements. Accessing or modifying
    an element involves fetching the object reference from the appropriate position
    of the underlying array and has *O*(1) complexity. Appending an element is also
    very fast. When an empty list is created, an array of fixed size is allocated
    and, as we insert elements, the slots in the array are gradually filled up. Once
    all the slots are occupied, the list needs to increase the size of its underlying
    array, thus triggering a memory reallocation that can take *O*(*N*) time. Nevertheless,
    those memory allocations are infrequent, and the time complexity for the append
    operation is referred to as amortized *O*(1) time.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列表在访问、修改和追加元素方面表现突出。访问或修改一个元素涉及到从底层数组的适当位置获取对象引用，具有 *O*(1) 的复杂度。追加一个元素也非常快。当创建一个空列表时，会分配一个固定大小的数组，并且随着我们插入元素，数组中的槽位逐渐被填满。一旦所有槽位都被占用，列表需要增加其底层数组的大小，从而触发可能需要
    *O*(*N*) 时间的内存重新分配。尽管如此，这些内存分配并不频繁，追加操作的复杂度被称为摊销的 *O*(1) 时间。
- en: The list operations that may have efficiency problems are those that add or
    remove elements at the beginning (or somewhere in the middle) of the list. When
    an item is inserted or removed from the beginning of a list, all the subsequent
    elements of the array need to be shifted by a position, thus taking *O*(*N*) time.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 可能存在效率问题的列表操作是那些在列表开头（或中间某处）添加或删除元素的操作。当从列表开头插入或删除一个项目时，数组中所有后续元素都需要移动一个位置，因此需要
    *O*(*N*) 的时间。
- en: 'In the following table, the timings for different operations on a list of 10,000
    size are shown; you can see how insertion and removal performances vary quite
    dramatically if performed at the beginning or the end of the list:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表中，展示了大小为 10,000 的列表上不同操作的计时；你可以看到，如果是在列表开头或结尾执行插入和删除操作，性能会有相当大的差异：
- en: '![Table 1.1 – The speed of different list operations ](img/B17499_Table_2.1.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![表 1.1 – 不同列表操作的速率](img/B17499_Table_2.1.jpg)'
- en: Table 1.1 – The speed of different list operations
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.1 – 不同列表操作的速率
- en: In some cases, it is necessary to efficiently perform the insertion or removal
    of elements both at the beginning and the end of the collection. Python provides
    a data structure with those properties in the `collections.deque` class. The word
    *deque* stands for **double-ended queue** because this data structure is designed
    to efficiently put and remove elements at the beginning and the end of the collection,
    as it is in the case of queues. In Python, deques are implemented as doubly linked
    lists.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，需要在集合的开始和末尾有效地执行元素的插入或删除。Python 在 `collections.deque` 类中提供了一个具有这些属性的数据结构。单词
    *deque* 代表 **双端队列**，因为这种数据结构被设计成在集合的开始和末尾有效地放置和删除元素，就像队列一样。在 Python 中，双端队列被实现为双链表。
- en: 'Deques, in addition to `pop` and `append`, expose the `popleft` and `appendleft`
    methods that have *O*(1) running time:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `pop` 和 `append`，双端队列还公开了具有 *O*(1) 运行时间的 `popleft` 和 `appendleft` 方法：
- en: '![Table 1.2 – The speed of different deque operations ](img/B17499_Table_2.2.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![表 1.2 – 不同双端队列操作的速度](img/B17499_Table_2.2.jpg)'
- en: Table 1.2 – The speed of different deque operations
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.2 – 不同双端队列操作的速度
- en: 'Despite these advantages, deques should not be used to replace regular lists
    in most cases. The efficiency gained by the `appendleft` and `popleft` operations
    comes at a cost – accessing an element in the middle of a deque is an *O*(N) operation,
    as shown in the following table:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这些优点，但在大多数情况下不应使用双端队列来替换常规列表。`appendleft` 和 `popleft` 操作获得的效率是以代价为代价的——在双端队列的中间访问一个元素是一个
    *O*(N) 操作，如下表所示：
- en: '![Table 1.3 – The inefficiency of deques in accessing the middle element ](img/B17499_Table_2.3.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![表 1.3 – 双端队列在访问中间元素时的低效性](img/B17499_Table_2.3.jpg)'
- en: Table 1.3 – The inefficiency of deques in accessing the middle element
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.3 – 双端队列在访问中间元素时的低效性
- en: Searching for an item in a list is generally an *O*(*N*) operation and is performed
    using the `list.index` method. A simple way to speed up searches in lists is to
    keep the array sorted and perform a binary search using the `bisect` module.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表中搜索一个项目通常是一个 *O*(*N*) 操作，并使用 `list.index` 方法执行。加快列表中搜索的一种简单方法是将数组排序，并使用 `bisect`
    模块执行二分搜索。
- en: 'The `bisect` module allows fast searches on sorted arrays. The `bisect.bisect`
    function can be used on a sorted list to find the index to place an element while
    maintaining the array in sorted order. In the following example, we can see that
    if we want to insert the `3` element in the array while keeping `collection` in
    sorted order, we should put `3` in the third position (which corresponds to index
    `2`):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`bisect` 模块允许在排序数组上进行快速搜索。`bisect.bisect` 函数可以用于排序列表，以找到放置元素的位置，同时保持数组排序。在下面的示例中，如果我们想在保持
    `collection` 排序顺序的情况下将 `3` 元素插入数组，我们应该将 `3` 放在第三个位置（对应索引 `2`）：'
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This function uses the binary search algorithm that has *O*(*log*(*N*)) running
    time. Such a running time is exceptionally fast and, basically, means that your
    running time will increase by a constant amount every time you *double* your input
    size. This means that if, for example, your program takes `1` second to run on
    an input of `1000` size, it will take `2` seconds to process an input of `2000`
    size, `3` seconds to process an input of `4000` size, and so on. If you had `100`
    seconds, you could theoretically process an input of `10^33` size, which is larger
    than the number of atoms in your body!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数使用具有 *O*(*log*(*N*)) 运行时间的二分搜索算法。这样的运行时间非常快，基本上意味着每次你 *加倍* 输入大小时，你的运行时间将增加一个常数。这意味着，例如，如果你的程序在
    `1000` 大小的输入上运行需要 `1` 秒，那么处理 `2000` 大小的输入将需要 `2` 秒，处理 `4000` 大小的输入将需要 `3` 秒，依此类推。如果你有
    `100` 秒，理论上可以处理 `10^33` 大小的输入，这比你体内的原子数量还要多！
- en: 'If the value we are trying to insert is already present in the list, the `bisect.bisect`
    function will return the location *after* the already present value. Therefore,
    we can use the `bisect.bisect_left` variant, which returns the correct index in
    the following way (taken from the module documentation at [https://docs.python.org/3.5/library/bisect.html](https://docs.python.org/3.5/library/bisect.html)):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们试图插入的值已经在列表中存在，`bisect.bisect` 函数将返回已存在值之后的定位。因此，我们可以使用 `bisect.bisect_left`
    变体，它以以下方式返回正确的索引（摘自模块文档[https://docs.python.org/3.5/library/bisect.html](https://docs.python.org/3.5/library/bisect.html)）：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the following table, you can see how the running time of the `bisect` solution
    is barely affected by these input sizes, making it a suitable solution when searching
    through very large collections:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下表格中，您可以看到`bisect`解决方案的运行时间几乎不受这些输入大小的影响，这使得它在搜索非常大的集合时成为一个合适的解决方案：
- en: '![](img/B17499_Table_2.4.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17499_Table_2.4.jpg)'
- en: Table 1.4 – The efficiency of the bisect function
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.4 – bisect函数的效率
- en: Dictionaries
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 字典
- en: '**Dictionaries** are extremely versatile and extensively used in the Python
    language, for example, in package-, module-, and class-level namespaces, as well
    as object and class annotations. Dictionaries are implemented as hash maps and
    are very good at element insertion, deletion, and access; all these operations
    have an average *O*(1) time complexity.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**字典**在Python语言中极其灵活且广泛使用，例如在包、模块和类级别的命名空间中，以及对象和类注解中。字典作为哈希表实现，非常擅长元素插入、删除和访问；所有这些操作的平均时间复杂度都是*O*(1)。'
- en: Important Note
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In Python versions up to 3.5, dictionaries are *unordered collections*. Since
    Python 3.6, dictionaries are capable of maintaining their elements by order of
    insertion.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python 3.5之前的版本中，字典是*无序集合*。从Python 3.6开始，字典能够根据插入顺序维护其元素。
- en: Hash map
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 哈希表
- en: 'A `hash` function; Python implements `hash` functions for several data types.
    As a demonstration, the generic function to obtain hash codes is `hash`. In the
    following example, we show you how to obtain the hash code when given the `"hello"`
    string:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`hash`函数；Python为几种数据类型实现了`hash`函数。作为一个演示，获取哈希码的通用函数是`hash`。在以下示例中，我们将向您展示如何获取给定`"hello"`字符串时的哈希码：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Hash maps can be tricky to implement because they need to handle collisions
    that happen when two different objects have the same hash code. However, all the
    complexity is elegantly hidden behind the implementation and the default collision
    resolution works well in most real-world scenarios.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希表实现起来可能有些棘手，因为它们需要处理当两个不同的对象具有相同的哈希码时发生的冲突。然而，所有这些复杂性都被巧妙地隐藏在实现和默认的冲突解决策略之后，在大多数实际场景中默认的冲突解决策略都运行良好。
- en: The access to, insertion, and removal of an item in a dictionary scales as *O*(1)
    with the size of the dictionary. However, note that the computation of the `hash`
    function still needs to happen and, for strings, the computation scales with the
    length of the string. As string keys are usually relatively small, this doesn't
    constitute a problem in practice.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在字典中访问、插入和删除一个项的操作与字典的大小成*O*(1)的比例。然而，请注意，`hash`函数的计算仍然需要发生，对于字符串，计算与字符串的长度成比例。由于字符串键通常相对较小，这在实践中并不构成问题。
- en: 'A dictionary can be used to efficiently count unique elements in a list. In
    this example, we define the `counter_dict` function that takes a list and returns
    a dictionary containing the number of occurrences of each value in the list:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 字典可以用来高效地计算列表中的唯一元素的数量。在这个例子中，我们定义了`counter_dict`函数，它接受一个列表并返回一个包含列表中每个值出现次数的字典：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The code can be somewhat simplified using `collections.defaultdict`, which
    can be used to produce dictionaries where each new key is automatically assigned
    a default value. In the following code, the `defaultdict(int)` call produces a
    dictionary where every new element is automatically assigned a zero value and
    can be used to streamline the counting:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`collections.defaultdict`来简化代码，它可以用来生成每个新键自动分配默认值的字典。在以下代码中，`defaultdict(int)`调用生成一个每个新元素自动分配零值的字典，并可用于简化计数：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `collections` module also includes a `Counter` class that can be used for
    the same purpose with a single line of code:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`collections`模块还包括一个`Counter`类，它可以使用一行代码达到相同的目的：'
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Speed-wise, all these ways of counting have the same time complexity, but the
    `Counter` implementation is the most efficient, as shown in the following table:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在速度方面，所有这些计数方式都具有相同的时间复杂度，但`Counter`实现是最有效的，如下表所示：
- en: '![Table 1.5 – The different methods of computing counters ](img/B17499_Table_2.5.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![表1.5 – 计算计数器的不同方法](img/B17499_Table_2.5.jpg)'
- en: Table 1.5 – The different methods of computing counters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.5 – 计算计数器的不同方法
- en: Building an in-memory search index using a hash map
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用哈希表构建内存搜索索引
- en: 'Dictionaries can be used to quickly search for a word in a list of documents,
    similar to a search engine. In this subsection, we will learn how to build an
    inverted index based on a dictionary of lists. Let''s say we have a collection
    of four documents:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 字典可以用来快速在文档列表中搜索单词，类似于搜索引擎。在本小节中，我们将学习如何基于列表字典构建倒排索引。假设我们有一个包含四个文档的集合：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'A simple way to retrieve all the documents that match a query is to scan each
    document and test for the presence of a word. For example, if we want to look
    up the documents where the word `table` appears, we can employ the following filtering
    operation:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 获取与查询匹配的所有文档的一个简单方法是扫描每个文档并测试单词的存在。例如，如果我们想查找包含单词`table`的文档，我们可以采用以下过滤操作：
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This approach is simple and works well when we have one-off queries; however,
    if we need to query the collection very often, it can be beneficial to optimize
    querying time. Since the per-query cost of the linear scan is *O*(*N*), you can
    imagine that better scaling will allow us to handle much larger document collections.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法简单且在处理一次性查询时效果良好；然而，如果我们需要经常查询集合，优化查询时间可能是有益的。由于线性扫描的每次查询成本为*O*(*N*)，你可以想象更好的扩展性将使我们能够处理更大的文档集合。
- en: A better strategy is to spend some time preprocessing the documents so that
    they are easier to find at query time. We can build a structure, called the `"table"`
    will be associated with the `"the cat is under the table"` and `"the dog is under
    the table"` documents; they correspond to `0` and `1` indices.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的策略是花些时间预处理文档，以便在查询时更容易找到。我们可以构建一个结构，称为`"table"`，将与`"the cat is under the
    table"`和`"the dog is under the table"`文档相关联；它们对应于`0`和`1`索引。
- en: 'Such a mapping can be implemented by going over our collection of documents
    and storing in a dictionary the index of the documents where that term appears.
    The implementation is similar to the `counter_dict` function, except that, instead
    of incrementing a counter, we are growing the list of documents that match the
    current term:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这种映射可以通过遍历我们的文档集合，并在字典中存储该术语出现的文档索引来实现。实现方式与`counter_dict`函数类似，只不过，我们不是增加计数器，而是在匹配当前术语的文档列表中增长：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once we have built our index, doing a query involves a simple dictionary lookup.
    For example, if we want to return all the documents containing the `table` term,
    we can simply query the index and retrieve the corresponding documents:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们构建了索引，进行查询就涉及简单的字典查找。例如，如果我们想返回包含`table`这个术语的所有文档，我们只需查询索引并检索相应的文档：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Since all it takes to query our collection is dictionary access, the index can
    handle queries with *O*(1) time complexity! Thanks to the inverted index, we are
    now able to query any number of documents (as long as they fit in memory) in constant
    time. Needless to say, indexing is a technique widely used to quickly retrieve
    data, not only in search engines but also in databases and any system that requires
    fast searches.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 由于查询我们的集合只需要字典访问，索引可以处理具有*O*(1)时间复杂度的查询！多亏了倒排索引，我们现在能够在常数时间内查询任意数量的文档（只要它们适合内存）。不用说，索引是一种广泛用于快速检索数据的技术，不仅用于搜索引擎，也用于数据库和任何需要快速搜索的系统。
- en: Important Note
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Building an inverted index is an expensive operation and requires you to encode
    every possible query. This is a substantial drawback, but the benefits are great,
    and it may be worthwhile to pay the price in terms of decreased flexibility.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 构建倒排索引是一个昂贵的操作，需要你编码每个可能的查询。这是一个重大的缺点，但好处很大，可能值得为了降低灵活性而付出代价。
- en: Sets
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集合
- en: '**Sets** are unordered collections of elements, with the additional restriction
    that the elements must be unique. The main use cases where sets are a good choice
    are membership tests (testing whether an element is present in the collection)
    and, unsurprisingly, set operations such as union, difference, and intersection.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**集合**是无序的元素集合，额外的限制是元素必须是唯一的。集合是一个很好的选择的主要用例包括成员资格测试（测试元素是否存在于集合中）以及，不出所料，集合操作，如并集、差集和交集。'
- en: In Python, sets are implemented using a hash-based algorithm, just like dictionaries;
    therefore, the time complexities for addition, deletion, and testing for membership
    scale as *O*(1) with the size of the collection.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，集合是通过哈希算法实现的，就像字典一样；因此，添加、删除和测试成员资格的时间复杂度随着集合大小的增长而以*O*(1)的比例缩放。
- en: 'Sets contain only *unique elements*. An immediate use case of sets is the removal
    of duplicates from a collection, which can be accomplished by simply passing the
    collection through the `set` constructor, as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 集合只包含*唯一元素*。集合的一个直接用途是从集合中删除重复项，这可以通过简单地通过`set`构造函数传递集合来完成，如下所示：
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The time complexity for removing duplicates is *O*(N), as it requires reading
    the input and putting each element in the set.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 删除重复项的时间复杂度是*O*(N)，因为它需要读取输入并将每个元素放入集合中。
- en: 'Sets offer a number of operations, such as union, intersection, and difference.
    The union of two sets is a new set containing all the elements of both the sets;
    the intersection is a new set that contains only the elements in common between
    the two sets, and the difference is a new set containing the elements of the first
    set that are not contained in the second set. The time complexities for these
    operations are shown in the following table. Note that since we have two different
    input sizes, we will use the letter `S` to indicate the size of the first set
    (called `s`), and `T` to indicate the size of the second set (called `t`):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 集合提供了一些操作，如并集、交集和差集。两个集合的并集是一个包含两个集合所有元素的新集合；交集是一个只包含两个集合共有元素的新集合，差集是一个包含第一个集合中不包含在第二个集合中的元素的新集合。这些操作的时间复杂度如下表所示。请注意，由于我们有两个不同的输入大小，我们将使用字母`S`来表示第一个集合的大小（称为`s`），使用`T`来表示第二个集合的大小（称为`t`）：
- en: '![Table 1.6 – The running time of set operations ](img/B17499_Table_2.6.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![表1.6 – 集合操作运行时间](img/B17499_Table_2.6.png)'
- en: Table 1.6 – The running time of set operations
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.6 – 集合操作运行时间
- en: An application of set operations is, for example, Boolean queries. Going back
    to the inverted index example of the previous subsection, we may want to support
    queries that include multiple terms. For example, we may want to search for all
    the documents that contain the words `cat` and `table`. This kind of query can
    be efficiently computed by taking the intersection between the set of documents
    containing `cat` and the set of documents containing `table`.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 集合操作的示例应用是布尔查询。回到前一小节中提到的倒排索引示例，我们可能希望支持包含多个术语的查询。例如，我们可能想要搜索包含单词`cat`和`table`的所有文档。这种查询可以通过取包含`cat`的文档集合和包含`table`的文档集合的交集来有效地计算。
- en: 'In order to efficiently support those operations, we can change our indexing
    code so that each term is associated with a set of documents (rather than a list).
    After applying this change, calculating more advanced queries is a matter of applying
    the right set operation. In the following code, we show the inverted index based
    on sets and the query using set operations:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地支持这些操作，我们可以修改我们的索引代码，使得每个术语都与一组文档（而不是列表）相关联。应用这个更改后，计算更高级的查询就变成了应用正确的集合操作。在下面的代码中，我们展示了基于集合的倒排索引和基于集合操作的查询：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Heaps
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 堆
- en: '**Heaps** are data structures designed to quickly find and extract the maximum
    (or minimum) value in a collection. A typical use case for heaps is to process
    a series of incoming tasks in order of maximum priority.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**堆**是一种设计用来快速查找和提取集合中最大（或最小）值的数据结构。堆的一个典型用途是按照最大优先级顺序处理一系列传入的任务。'
- en: You can theoretically use a sorted list using the tools in the `bisect` module;
    however, while extracting the maximum value will take *O*(1) time (using `list.pop`),
    insertion will still take *O*(N) time (remember that, even if finding the insertion
    point takes *O*(*log*(*N*)) time, inserting an element in the middle of a list
    is still an *O*(*N*) operation). A heap is a more efficient data structure that
    allows for the insertion and extraction of maximum values with *O*(*log*(*N*))
    time complexity.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，你可以使用`bisect`模块中的工具来使用排序列表；然而，虽然提取最大值将花费*O*(1)时间（使用`list.pop`），插入仍然需要*O*(N)时间（记住，即使找到插入点需要*O*(*log*(*N*))时间，在列表中间插入一个元素仍然是一个*O*(*N*)操作）。堆是一个更有效的数据结构，它允许以*O*(*log*(*N*))时间复杂度插入和提取最大值。
- en: 'In Python, heaps are built using the procedures contained in the `heapq` module
    on an underlying list. For example, if we have a list of 10 elements, we can reorganize
    it into a heap with the `heapq.heapify` function:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，堆是通过`heapq`模块中的过程在底层列表上构建的。例如，如果我们有一个包含10个元素的列表，我们可以使用`heapq.heapify`函数将其重新组织成一个堆：
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To perform the insertion and extraction operations on the heap, we can use
    the `heapq.heappush` and `heapq.heappop` functions. The `heapq.heappop` function
    will extract the minimum value in the collection in *O*(*log*(*N*)) time and can
    be used in the following way:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要在堆上执行插入和提取操作，我们可以使用 `heapq.heappush` 和 `heapq.heappop` 函数。`heapq.heappop` 函数将以
    *O*(*log*(*N*)) 的时间复杂度从集合中提取最小值，并且可以按以下方式使用：
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Similarly, you can push the `1` integer with the `heapq.heappush` function,
    as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你可以使用 `heapq.heappush` 函数将 `1` 整数推入堆中，如下所示：
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Another easy-to-use option is the `queue.PriorityQueue` class, which as a bonus,
    is thread- and process-safe. The `PriorityQueue` class can be filled up with elements
    using the `PriorityQueue.put` method, while `PriorityQueue.get` can be used to
    extract the minimum value in the collection:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个易于使用的选项是 `queue.PriorityQueue` 类，它还有一个额外的好处，即线程和进程安全。可以使用 `PriorityQueue.put`
    方法向 `PriorityQueue` 类中填充元素，而 `PriorityQueue.get` 可以用来提取集合中的最小值：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If the maximum element is required, a simple trick is to multiply each element
    of the list by `-1`. In this way, the order of the elements will be inverted.
    Also, if you want to associate an object (for example, a task to run) with each
    number (which can represent the priority), you can insert tuples of the `(number,
    object)` form; the comparison operator for the tuple will be ordered with respect
    to its first element, as shown in the following example:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要最大元素，一个简单的技巧是将列表中的每个元素乘以 `-1`。这样，元素的顺序将会反转。此外，如果你想将一个对象（例如，要运行的任务）与每个数字（它可以表示优先级）关联起来，你可以插入
    `(number, object)` 形式的元组；元组的比较操作将根据其第一个元素进行排序，如下面的示例所示：
- en: '[PRE17]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Tries
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Tries
- en: A perhaps less popular data structure, but very useful in practice, is the **trie**
    (sometimes called **prefix tree**). Tries are extremely fast at matching a list
    of strings against a prefix. This is especially useful when implementing features
    such as *search as you type* and *autocompletion*, where the list of available
    completions is very large and short response times are required.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能不太受欢迎但非常实用的数据结构是 **trie**（有时称为 **前缀树**）。Trie 在匹配字符串列表与前缀方面非常快速。这在实现如 *搜索即输入*
    和 *自动完成* 等功能时特别有用，在这些功能中，可用的完成列表非常大，并且需要短响应时间。
- en: Unfortunately, Python does not include a trie implementation in its standard
    library; however, many efficient implementations are readily available through
    *PyPI*. The one we will use in this subsection is `patricia-trie`, a single-file,
    pure Python implementation of trie. As an example, we will use `patricia-trie`
    to perform the task of finding the longest prefix in a set of strings (just like
    autocompletion).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Python 并没有在其标准库中包含 trie 实现；然而，通过 *PyPI* 可以轻松获得许多高效的实现。在本小节中，我们将使用 `patricia-trie`，这是一个单文件、纯
    Python 实现的 trie。作为一个例子，我们将使用 `patricia-trie` 来执行在字符串集合中查找最长前缀的任务（就像自动完成一样）。
- en: 'Here, we can demonstrate how fast a trie is able to search through a list of
    strings. In order to generate a large amount of unique random strings, we can
    define a function, `random_string`. The `random_string` function will return a
    string composed of random uppercase characters and, while there is a chance to
    get duplicates, we can greatly reduce the probability of duplicates to the point
    of being negligible if we make the string long enough. The implementation of the
    `random_string` function is shown as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以展示 trie 如何快速搜索字符串列表。为了生成大量唯一的随机字符串，我们可以定义一个函数，`random_string`。`random_string`
    函数将返回由随机大写字母组成的字符串，虽然有可能得到重复的字符串，但如果我们使字符串足够长，我们可以将重复的概率大大降低到可以忽略不计的程度。`random_string`
    函数的实现如下所示：
- en: '[PRE18]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can build a list of random strings and time how fast it searches for a prefix
    (in our case, the `"AA"` string) using the `str.startswith` function:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以构建一个随机字符串列表，并使用 `str.startswith` 函数来测量它搜索前缀（在我们的例子中，是 `"AA"` 字符串）的速度：
- en: '[PRE19]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'List comprehension and `str.startwith` are already very optimized operations
    and, on this small dataset, the search takes only a millisecond or so:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 列表推导和 `str.startswith` 已经是非常优化的操作，在这个小数据集中，搜索只需要一毫秒左右：
- en: '[PRE20]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, let''s try using a trie for the same operation. In this example, we will
    use the `patricia-trie` library that is installable through `pip`. The `patricia.trie`
    class implements a variant of the trie data structure with an interface similar
    to a dictionary. We can initialize our trie by creating a dictionary from our
    list of strings, as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试使用trie进行相同的操作。在这个例子中，我们将使用可以通过`pip`安装的`patricia-trie`库。`patricia.trie`类实现了一种类似字典的接口的trie数据结构变体。我们可以通过从我们的字符串列表创建一个字典来初始化我们的trie，如下所示：
- en: '[PRE21]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'To query `patricia-trie` for a matching prefix, we can use the `trie.iter`
    method, which returns an iterator over the matching strings:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 要查询`patricia-trie`以匹配前缀，我们可以使用`trie.iter`方法，它返回一个匹配字符串的迭代器：
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now that we know how to initialize and query a trie, we can time the operation:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何初始化和查询trie，我们可以计时操作：
- en: '[PRE23]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The timing for this input size is **60.1 µs**, which is about 30 times faster
    (1.76 ms = 1760 µs) than linear search! This impressive speedup is because of
    the better computational complexity of the trie prefix search. Querying a trie
    has an *O*(*S*) time complexity, where *S* is the length of the longest string
    in the collection, while the time complexity of a simple linear scan is *O*(*N*),
    where *N* is the size of the collection.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个输入大小的计时为**60.1 µs**，这比线性搜索快约30倍（1.76 ms = 1760 µs）！这种令人印象深刻的加速是由于trie前缀搜索更好的计算复杂度。查询trie的时间复杂度为*O*(*S*)，其中*S*是集合中最长字符串的长度，而简单线性扫描的时间复杂度为*O*(*N*)，其中*N*是集合的大小。
- en: Note that if we want to return all the prefixes that match, the running time
    will be proportional to the number of results that match the prefix. Therefore,
    when designing timing benchmarks, care must be taken to ensure that we are always
    returning the same number of results.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果我们想返回所有匹配的前缀，运行时间将与匹配前缀的结果数量成比例。因此，在设计计时基准时，我们必须确保我们总是返回相同数量的结果。
- en: 'The scaling properties of a trie versus a linear scan for datasets of different
    sizes that contains 10 prefix matches are shown in the following table:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了包含10个前缀匹配的不同大小数据集的trie与线性扫描的缩放特性：
- en: '![Table 1.7 – The running time of a trie versus a linear scan ](img/B17499_Table_2.7.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![表1.7 – trie与线性扫描的运行时间](img/B17499_Table_2.7.jpg)'
- en: Table 1.7 – The running time of a trie versus a linear scan
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.7 – trie与线性扫描的运行时间
- en: An interesting fact is that the implementation of `patricia-trie` is actually
    a single Python file; this clearly shows how simple and powerful a clever algorithm
    can be. For extra features and performance, other C-optimized trie libraries are
    also available, such as `datrie` and `marisa-trie`.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的事实是，`patricia-trie`的实现实际上是一个单一的Python文件；这清楚地展示了巧妙算法的简单和强大。为了额外的功能和性能，还有其他C优化的trie库可供选择，例如`datrie`和`marisa-trie`。
- en: At this point, we have considered most of the important data structures that
    are native to Python. Appropriate use of these data structures will speed up your
    application by a significant degree. In addition to data structures, there are
    other computing techniques and concepts that we could utilize in order to make
    our programs even faster. In the next section, we will take a look at caching
    and memoization, which are common practices when you expect the same computations
    to be repeated multiple times.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经考虑了Python中大多数重要的原生数据结构。适当使用这些数据结构将显著加快您的应用程序。除了数据结构之外，还有其他计算技术和概念我们可以利用，以使我们的程序运行得更快。在下一节中，我们将探讨缓存和记忆化，这是在预期相同的计算会被多次重复时常见的做法。
- en: Improved efficiency with caching and memoization
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存和记忆化带来的效率提升
- en: '**Caching** is a great technique used to improve the performance of a wide
    range of applications. The idea behind caching is to store expensive results in
    a temporary location, called a **cache**, that can be located in memory, on disk,
    or in a remote location.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**缓存**是一种用于提高各种应用程序性能的出色技术。缓存背后的理念是将昂贵的计算结果存储在一个临时位置，称为**缓存**，它可以位于内存中、磁盘上或远程位置。'
- en: Web applications make extensive use of caching. In a web application, it is
    often the case that multiple users request a certain page at the same time. In
    this case, instead of recomputing the page for each user, the web application
    can compute it once and serve the user the already rendered page. Ideally, caching
    also needs a mechanism for invalidation so that if the page needs to be updated,
    we can recompute it before serving it again. Intelligent caching allows web applications
    to handle the increasing number of users with fewer resources. Caching can also
    be done preemptively, such as the later sections of a video getting buffered when
    watching a video online.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 网络应用程序广泛使用缓存。在Web应用程序中，通常会有多个用户同时请求同一页面。在这种情况下，而不是为每个用户重新计算页面，Web应用程序可以计算一次，然后为用户提供已经渲染的页面。理想情况下，缓存还需要一个失效机制，以便如果页面需要更新，我们可以在再次提供服务之前重新计算它。智能缓存允许Web应用程序以更少的资源处理越来越多的用户。缓存也可以预先执行，例如在在线观看视频时，视频的后续部分被缓冲。
- en: Caching is also used to improve the performance of certain algorithms. A great
    example is computing the Fibonacci sequence. Since computing the next number in
    the Fibonacci sequence requires the previous number in the sequence, you can store
    and reuse previous results, dramatically improving the running time. Storing and
    reusing the results of the previous function calls in an application is usually
    termed **memoization** and is one of the forms of caching. Several other algorithms
    can take advantage of memoization to gain impressive performance improvements,
    and this programming technique is commonly referred to as **dynamic programming**,
    where you aim to solve a large problem by breaking it into smaller ones.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存也被用来提高某些算法的性能。一个很好的例子是计算斐波那契数列。由于计算斐波那契数列中的下一个数字需要序列中的前一个数字，您可以存储并重用之前的结果，从而显著提高运行时间。在应用程序中存储和重用之前函数调用的结果通常被称为
    **记忆化**，它是缓存的一种形式。其他几种算法可以利用记忆化来获得令人印象深刻的性能提升，这种编程技术通常被称为 **动态规划**，其目的是通过将大问题分解为更小的问题来解决。
- en: The benefits of caching, however, do not come for free. What we are actually
    doing is sacrificing some space to improve the speed of the application. Additionally,
    if the cache is stored in a location on the network, we may incur transfer costs
    and the general time needed for communication. You should evaluate when it is
    convenient to use a cache and how much space you are willing to trade for an increase
    in speed.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，缓存的益处并非免费得来。我们实际上是在牺牲一些空间来提高应用程序的速度。此外，如果缓存存储在网络上的某个位置，我们可能会产生传输成本和通信所需的一般时间。您应该评估何时使用缓存方便，以及您愿意为速度的提升牺牲多少空间。
- en: Given the usefulness of this technique, the Python standard library includes
    a simple in-memory cache out of the box in the `functools` module. The `functools.lru_cache`
    decorator can be used to easily cache the results of a function.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这种技术的有用性，Python标准库在 `functools` 模块中提供了一个简单的内存缓存。`functools.lru_cache` 装饰器可以用来轻松缓存函数的结果。
- en: 'In the following example, we create a function, `sum2`, that prints a statement
    and returns the sum of two numbers. By running the function twice, you can see
    that the first time the `sum2` function is executed, the `"Calculating ..."` string
    is produced, while the second time, the result is returned without running the
    function:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们创建了一个函数 `sum2`，该函数打印一条语句并返回两个数字的和。通过运行该函数两次，您可以看到，第一次执行 `sum2` 函数时，会输出
    `"Calculating ..."` 字符串，而第二次，结果会被返回，而无需再次运行函数：
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `lru_cache` decorator also provides other basic features. To restrict the
    size of the cache, you can set the number of elements that we intend to maintain
    through the `max_size` argument. If we want our cache size to be unbounded, we
    can specify a value of `None`. An example of `max_size` usage is shown here:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`lru_cache` 装饰器还提供了其他基本功能。为了限制缓存的大小，您可以通过 `max_size` 参数设置我们打算维护的元素数量。如果我们希望缓存大小无限制，我们可以指定一个
    `None` 值。下面是一个 `max_size` 用法的示例：'
- en: '[PRE25]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In this way, as we execute `sum2` with different arguments, the cache will reach
    a maximum size of `16` and, as we keep requesting more calculations, new values
    will replace older values in the cache. The `lru` prefix originates from this
    strategy, which means *least recently used*.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，当我们用不同的参数执行 `sum2` 时，缓存将达到最大大小 `16`，并且随着我们不断请求更多计算，新的值将替换缓存中的旧值。`lru` 前缀来源于这种策略，意味着
    *最近最少使用*。
- en: 'The `lru_cache` decorator also adds extra functionalities to the decorated
    function. For example, it is possible to examine the cache performance using the
    `cache_info` method, and it is possible to reset the cache using the `cache_clear`
    method, as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`lru_cache` 装饰器还为装饰的函数添加了额外的功能。例如，可以使用 `cache_info` 方法检查缓存性能，并使用 `cache_clear`
    方法重置缓存，如下所示：'
- en: '[PRE26]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As an example, we can see how a problem, such as computing the Fibonacci series,
    may benefit from caching. We can define a `fibonacci` function and time its execution:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以看到缓存如何使计算斐波那契数列等问题受益。我们可以定义一个 `fibonacci` 函数并测量其执行时间：
- en: '[PRE27]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The execution takes 5.57 milliseconds, which is very long. The scaling of the
    function written in this way has poor performance; the previously computed Fibonacci
    sequences are not reused, causing this algorithm to have an exponential scaling
    of roughly *O*(*2N*).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 执行时间需要 5.57 毫秒，这非常长。以这种方式编写的函数的扩展性能很差；之前计算的斐波那契序列没有被重用，导致这个算法具有大约 *O*(2N) 的指数级扩展。
- en: 'Caching can improve this algorithm by storing and reusing the already-computed
    Fibonacci numbers. To implement the cached version, it is sufficient to apply
    the `lru_cache` decorator to the original `fibonacci` function. Also, to design
    a proper benchmark, we need to ensure that a new cache is instantiated for every
    run; to do this, we can use the `timeit.repeat` function, as shown in the following
    example:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 通过存储和重用已经计算过的斐波那契数，缓存可以提高这个算法的性能。要实现缓存的版本，只需将 `lru_cache` 装饰器应用到原始的 `fibonacci`
    函数上即可。此外，为了设计一个合适的基准测试，我们需要确保每次运行都实例化一个新的缓存；为此，我们可以使用 `timeit.repeat` 函数，如下例所示：
- en: '[PRE28]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Even though we changed the algorithm by adding a simple decorator, the running
    time now is much less than a microsecond. The reason is, thanks to caching, we
    now have a linear time algorithm instead of an exponential one.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们通过添加简单的装饰器改变了算法，但现在的运行时间现在比微秒还少。原因是，多亏了缓存，我们现在有一个线性时间算法，而不是指数级算法。
- en: The `lru_cache` decorator can be used to implement simple in-memory caching
    in your application. For more advanced use cases, third-party modules can be used
    for more powerful implementation and on-disk caching.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`lru_cache` 装饰器可用于在您的应用程序中实现简单的内存缓存。对于更高级的使用场景，可以使用第三方模块来实现更强大的实现和磁盘缓存。'
- en: Joblib
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Joblib
- en: A simple library that, among other things, provides a simple on-disk cache is
    `joblib`. The package can be used in a similar way as `lru_cache`, except that
    the results will be stored on disk and will persist between runs.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的库，除了其他功能外，还提供了一个简单的磁盘缓存，是 `joblib`。该包可以像 `lru_cache` 一样使用，但结果将存储在磁盘上，并在运行之间持续存在。
- en: The `joblib` module can be installed from PyPI using the `pip install joblib`
    command.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `pip install joblib` 命令从 PyPI 安装 `joblib` 模块。
- en: 'The `joblib` module provides the `Memory` class, which can be used to memoize
    functions using the `Memory.cache` decorator:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`joblib` 模块提供了 `Memory` 类，可以使用 `Memory.cache` 装饰器来缓存函数：'
- en: '[PRE29]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The function will behave similarly to `lru_cache`, with the exception that the
    results will be stored on disk in the directory specified by the `cachedir` argument
    during `Memory` initialization. Additionally, the cached results will persist
    over subsequent runs!
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数的行为将与 `lru_cache` 类似，但结果将存储在 `Memory` 初始化时由 `cachedir` 参数指定的目录中。此外，缓存的成果将在后续运行中持续存在！
- en: The `Memory.cache` method also allows limiting recomputation to only when certain
    arguments change, and the resulting decorated function supports basic functionalities
    to clear and analyze the cache.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`Memory.cache` 方法还允许限制重新计算仅在某些参数改变时发生，并且结果装饰的函数支持基本的清除和分析缓存的功能。'
- en: Perhaps the best `joblib` feature is, thanks to intelligent hashing algorithms,
    providing efficient memoization of functions that operate on `numpy` arrays, which
    is particularly useful in scientific and engineering applications.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 也许 `joblib` 最好的特性是，由于智能哈希算法，它能够高效地缓存操作 `numpy` 数组的函数，这在科学和工程应用中尤其有用。
- en: At this point, we have seen that by using caching and memoization, our program
    can reuse computations in an efficient way. Another common strategy to improve
    running time is to utilize specifically designed techniques as appropriate. In
    the next section, we will see how we can take advantage of comprehensions and
    generators when working with Python loops.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到，通过使用缓存和记忆化，我们的程序可以以高效的方式重用计算。另一种常见的提高运行时间的策略是利用适当设计的特定技术。在下一节中，我们将看到如何利用推导和生成器在处理Python循环时获得优势。
- en: Efficient iteration with comprehensions and generators
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用推导和生成器进行高效迭代
- en: In this section, we will explore a few simple strategies to speed up Python
    loops using `for` loops, as they are designed to avoid many unnecessary computational
    overheads during their construction. Another reason to use this construct is readability;
    even if the speedup over a standard loop is modest, the comprehension and generator
    syntax is more compact and (most of the time) more intuitive.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一些简单的策略，使用`for`循环来加快Python循环的速度，因为它们在设计时旨在避免在构建过程中产生许多不必要的计算开销。使用这种结构的另一个原因是可读性；即使与标准循环相比，速度提升不大，推导和生成器语法更紧凑，并且（大多数时候）更直观。
- en: 'In the following example, we can see that both the list comprehension and generator
    expressions are faster than an explicit loop when combined with the `sum` function:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们可以看到，当与`sum`函数结合使用时，列表推导和生成器表达式都比显式循环更快：
- en: '[PRE30]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Just like lists, it is possible to use `dict` comprehension to build dictionaries
    slightly more efficiently and compactly, as shown in the following code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 就像列表一样，我们可以使用`dict`推导来更高效、更紧凑地构建字典，如下面的代码所示：
- en: '[PRE31]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Efficient looping (especially in terms of memory) can be implemented using
    iterators and functions such as `filter` and `map`. As an example, consider the
    problem of applying a series of operations to a list using list comprehension
    and then taking the maximum value:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 使用迭代器和如`filter`和`map`之类的函数可以实现高效的循环（特别是在内存方面）。例如，考虑使用列表推导对列表应用一系列操作，然后取最大值的问题：
- en: '[PRE32]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The problem with this approach is that for every list comprehension, we are
    allocating a new list, increasing memory usage. Instead of using list comprehension,
    we can employ generators. Generators are objects that, when iterated upon, compute
    a value on the fly and return the result.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的缺点是，对于每个列表推导，我们都在分配一个新的列表，这增加了内存使用。而不是使用列表推导，我们可以使用生成器。生成器是当迭代时，即时计算值并返回结果的对象。
- en: For example, the `map` function takes two arguments – a function and an iterator
    – and returns a generator that applies the function to every element of the collection.
    The important point is that the operation happens only *while we are iterating*,
    and not when `map` is invoked!
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`map`函数接受两个参数——一个函数和一个迭代器——并返回一个生成器，该生成器将函数应用于集合中的每个元素。重要的是，操作仅在*我们迭代时发生*，而不是在调用`map`时发生！
- en: 'We can rewrite the previous function using `map` and by creating intermediate
    generators, rather than lists, thus saving memory by computing the values on the
    fly:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`map`和创建中间生成器（而不是列表）来重写前面的函数，从而通过即时计算值来节省内存：
- en: '[PRE33]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can profile the memory of the two solutions using the `memory_profiler`
    extension from an IPython session. The extension provides a small utility, `%memit`,
    that will help us evaluate the memory usage of a Python statement in a way similar
    to `%timeit`, as illustrated in the following details:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用来自IPython会话的`memory_profiler`扩展来分析这两个解决方案的内存。该扩展提供了一个小的实用工具`%memit`，它将帮助我们以类似于`%timeit`的方式评估Python语句的内存使用情况，如下面的详细说明所示：
- en: '[PRE34]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As you can see, the memory used by the first version is `102.54 MiB`, while
    the second version consumes `0.00 MiB`! For those who are interested, more functions
    that return generators can be found in the `itertools` module, which provides
    a set of utilities designed to handle common iteration patterns.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，第一个版本使用的内存为`102.54 MiB`，而第二个版本消耗的内存为`0.00 MiB`！对于那些感兴趣的人来说，可以在`itertools`模块中找到更多返回生成器的函数，该模块提供了一套旨在处理常见迭代模式的实用工具。
- en: Summary
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Algorithmic optimization can improve how your application scales as we process
    increasingly large data. In this chapter, we demonstrated use cases and running
    times of the most common data structures available in Python, such as lists, deques,
    dictionaries, heaps, and tries. We also covered caching, a technique that can
    be used to trade some space, in memory or on disk, in exchange for the increased
    responsiveness of an application. We also demonstrated how to get modest speed
    gains by replacing `for` loops with fast constructs, such as list comprehensions
    and generator expressions.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 算法优化可以提高我们处理越来越大的数据时应用程序的扩展性。在本章中，我们展示了 Python 中最常见的数据结构（如列表、双端队列、字典、堆和 trie）的使用案例和运行时间。我们还介绍了缓存技术，这是一种可以在内存或磁盘上交换一些空间以换取应用程序响应性提高的技术。我们还演示了如何通过用快速结构（如列表解析和生成器表达式）替换
    `for` 循环来获得适度的速度提升。
- en: Overall, we have seen that by utilizing a specifically designed data structure
    or technique that is appropriate in certain situations, the efficiency of our
    program can be greatly improved. The topics covered in this chapter offer us the
    ability to do just that across a wide range of use cases.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，我们已经看到，通过利用特定情况下合适的数据结构或技术，我们可以大大提高程序的效率。本章涵盖的主题为我们提供了在广泛用例中做到这一点的能力。
- en: In the subsequent chapters, we will learn how to improve performance further
    using numerical libraries such as `numpy` and how to write extension modules in
    a lower-level language with the help of *Cython*.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在随后的章节中，我们将学习如何使用数值库（如 `numpy`）进一步提高性能，以及如何在 *Cython* 的帮助下用低级语言编写扩展模块。
- en: Questions
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Identify the best/most appropriate from the data structures covered in this
    chapter concerning the following use cases:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据以下用例，从本章介绍的数据结构中识别最佳/最合适的数据结构：
- en: Mapping items to another *set* of items (*set* being used in the most general
    sense)
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将项目映射到另一个 *集合* 中的项目（*集合* 在最一般的意义上使用）
- en: Accessing, modifying, and appending elements
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问、修改和添加元素
- en: Maintaining a collection of unique elements
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 维护一组唯一元素
- en: Keeping track of the minimum/maximum of a *set* (in the most general sense)
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪一个 *集合*（在最一般的意义上）的最小/最大值
- en: Appending and removing elements at the endpoints of a *sequence* (in the most
    general sense).
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *序列*（在最一般的意义上）的端点添加和删除元素。
- en: Fast searching according to some similarity criterion (for example, being used
    by autocompletion engines).
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据某些相似性标准进行快速搜索（例如，被自动完成引擎使用）。
- en: What is the difference between caching and memoization?
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 缓存和记忆化之间的区别是什么？
- en: Why are comprehensions and generators (in most situations) more preferred than
    explicit `for` loops?
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在大多数情况下，列表解析和生成器（相对于显式的 `for` 循环）更受欢迎？
- en: Consider the problem of representing a pairwise association between a set of
    letters and a set of numbers (for example, a  2, b  1, c  3, and so on), where
    we need to look at what number a given letter is associated with in our application.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑这样一个问题：表示一组字母和一组数字之间的成对关联（例如，a  2，b  1，c  3，等等），在我们应用中需要查看给定字母关联的数字是什么。
- en: Is a list an appropriate data structure for this task, and if not, what is?
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列表是否是完成这个任务的合适数据结构，如果不是，那又是什么？
- en: What if each number represented the number of instances of a given letter in
    a text document? What would the best data structure for this task be?
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果每个数字代表一个文本文档中给定字母的实例数量呢？这个任务的最佳数据结构会是什么？
- en: Further reading
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Lazy evaluation in Python: [https://towardsdatascience.com/what-is-lazy-evaluation-in-python-9efb1d3bfed0](https://towardsdatascience.com/what-is-lazy-evaluation-in-python-9efb1d3bfed0)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 中的延迟评估：[https://towardsdatascience.com/what-is-lazy-evaluation-in-python-9efb1d3bfed0](https://towardsdatascience.com/what-is-lazy-evaluation-in-python-9efb1d3bfed0)
- en: 'The `yield` statement in Python: [https://realpython.com/introduction-to-python-generators/](https://realpython.com/introduction-to-python-generators/)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 中的 `yield` 语句：[https://realpython.com/introduction-to-python-generators/](https://realpython.com/introduction-to-python-generators/)
