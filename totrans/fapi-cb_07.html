<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-224"><a id="_idTextAnchor227"/>7</h1>
<h1 id="_idParaDest-225"><a id="_idTextAnchor228"/>Integrating FastAPI with NoSQL Databases</h1>
<p>In this chapter, we will explore the integration of <strong class="bold">FastAPI</strong> with <strong class="bold">NoSQL</strong> databases. By crafting the backend of a music streaming platform application, you will learn how to set up and use <strong class="bold">MongoDB</strong>, a popular NoSQL database, with FastAPI.</p>
<p>You will also learn how to perform <strong class="bold">create, read, update and delete </strong>(<strong class="bold">CRUD</strong>) operations, work with indexes for performance optimization, and handle relationships in NoSQL databases. Additionally, you will learn how to integrate FastAPI with <strong class="bold">Elasticsearch</strong> for powerful search capabilities, secure sensitive data, and implement caching using <strong class="bold">Redis</strong>.</p>
<p>By the end of this chapter, you will have a solid understanding of how to effectively use NoSQL databases with FastAPI to improve the performance and functionality of your applications.</p>
<p>In this chapter, we’re going to cover the following recipes:</p>
<ul>
<li>Setting up MongoDB with FastAPI</li>
<li>CRUD operations in MongoDB</li>
<li>Handling relationships in NoSQL databases</li>
<li>Working with indexes in MongoDB</li>
<li>Exposing sensitive data from NoSQL databases</li>
<li>Integrating FastAPI with Elasticsearch</li>
<li>Using Redis for caching in FastAPI</li>
</ul>
<h1 id="_idParaDest-226"><a id="_idTextAnchor229"/>Technical requirements</h1>
<p>To follow along with the recipes of the chapter, ensure your setup includes the following essentials:</p>
<ul>
<li><strong class="bold">Python</strong>: A version 3.7 or higher should be installed on your computer</li>
<li><code>fastapi</code> package in your working environment</li>
<li><code>asyncio</code>: Be familiar with the <code>asyncio</code> framework and <code>async</code>/<code>await</code> syntax since we will use it all along the recipes</li>
</ul>
<p>The code used in the chapter is hosted on GitHub at this address: <a href="https://github.com/PacktPublishing/FastAPI-Cookbook/tree/main/Chapter07">https://github.com/PacktPublishing/FastAPI-Cookbook/tree/main/Chapter07</a>.</p>
<p>You can create a virtual environment for the project within the project root folder to manage dependencies efficiently and maintain project isolation.</p>
<p>Within your virtual environment, you can install all the dependencies at once by using <code>requirements.txt</code>, which is provided on the GitHub repository in the project folder:</p>
<pre class="console">
$ pip install –r requirements.txt</pre> <p>General knowledge of the external tools we are going to use for each recipe can be beneficial, although not mandatory. Each recipe will provide you with a minimal explanation of the used tool.</p>
<h1 id="_idParaDest-227"><a id="_idTextAnchor230"/>Setting up MongoDB with FastAPI</h1>
<p>In this recipe, you <a id="_idIndexMarker418"/>will learn how to set up MongoDB, a <a id="_idIndexMarker419"/>popular document-oriented NoSQL database, with FastAPI. You will learn how to manage Python packages to interact with MongoDB, create a database, and connect it to a FastAPI application. By the end of this recipe, you will have a solid understanding of how to integrate MongoDB with FastAPI to store and retrieve data for your applications.</p>
<h2 id="_idParaDest-228"><a id="_idTextAnchor231"/>Getting ready</h2>
<p>To follow along with this recipe, you need Python and <code>fastapi package</code> installed in your environment.</p>
<p>Also, for this recipe, make sure you have a MongoDB instance running and reachable, and if not, set up a local one. Depending on your operating system and your personal preference, you can set up a local MongoDB instance in several ways. Feel free to consult the official documentation on how to install the community edition of MongoDB on your local machine at the following link: <a href="https://www.mongodb.com/try/download/community">https://www.mongodb.com/try/download/community</a>.</p>
<p>For the recipe and throughout the chapter, we will consider a local instance of MongoDB running on http://localhost:27017. If you run the MongoDB instance on a remote machine, or simply use a different port, adjust the URL reference accordingly.</p>
<p>You also need the <code>motor</code> package installed in your environment. If you haven’t installed the packages with <code>requirements.txt</code>, you can install <code>motor</code> in your environment from the command line:</p>
<pre class="console">
$ pip install motor</pre> <p><code>asyncio</code> library.</p>
<p>Once we have the MongoDB instance running and reachable and the <code>motor</code> package installed in your environment, we can proceed with the recipe.</p>
<h2 id="_idParaDest-229"><a id="_idTextAnchor232"/>How to do it…</h2>
<p>Let’s start by creating a project root folder called <code>streaming_platform</code> with an <code>app</code> subfolder. In <code>app</code>, we create a module called <code>db_connection.py</code>, which will contain the information on the connection with MongoDB.</p>
<p>Now, we will set up the connection through the following steps:</p>
<ol>
<li>In the <code>db_connecion.py</code> module, let’s define the MongoDB client:<pre class="source-code">
from motor.motor_asyncio import AsyncIOMotorClient
mongo_client = AsyncIOMotorClient(
    "mongodb://localhost:27017"
)</pre><p class="list-inset">We will use the <code>mongo_client</code> object each time we need to interact with the MongoDB instance that is running at http://localhost:27017.</p></li> <li>In the <code>db_connection.py</code> module, we will create a function to ping the MongoDB instance to ensure it is running. But first, we retrieve the <code>uvicorn</code> logger, used by the FastAPI server, to print messages to the terminal:<pre class="source-code">
import logging
logger = logging.getLogger("uvicorn.error")</pre></li> <li>Then, let’s create<a id="_idIndexMarker424"/> the <a id="_idIndexMarker425"/>function to ping the MongoDB as follows:<pre class="source-code">
async def ping_mongo_db_server():
    try:
        await mongo_client.admin.command("ping")
        logger.info("Connected to MongoDB")
    except Exception as e:
        logger.error(
            f"Error connecting to MongoDB: {e}"
        )
        raise e</pre><p class="list-inset">The function will ping the server, and if it doesn’t receive any response, it will propagate an error that will stop the code from running.</p></li> <li>Finally, we need to run the <code>ping_mongo_db_server</code> function when starting the FastAPI server. In the <code>app</code> folder, let’s create a <code>main.py</code> module with a context manager that will be used for the startup and shutdown of our FastAPI server:<pre class="source-code">
from contextlib import asynccontextmanager
from app.db_connection import (
    ping_mongo_db_server,
)
@asynccontextmanager
async def lifespan(app: FastAPI):
    await ping_mongo_db_server(),
    yield</pre><p class="list-inset">The <code>lifespan</code> context<a id="_idIndexMarker426"/> manager <a id="_idIndexMarker427"/>has to be passed as an argument to the <code>FastAPI</code> object:</p><pre class="source-code">from fastapi import FastAPI
app = FastAPI(lifespan=lifespan)</pre><p class="list-inset">The server is wrapped in the <code>lifespan</code> context manager to execute the database check at startup.</p></li> </ol>
<p>To test it, make sure your MongoDB instance is already running and as usual, let’s spin up the server from the command line:</p>
<pre class="console">
<strong class="bold">$ uvicorn app.main:app</strong></pre> <p>You will see the following log messages on the output:</p>
<pre class="source-code">
INFO:    Started server process [1364]
INFO:    Waiting for application startup.
<strong class="bold">INFO:    </strong><strong class="bold">Connected to MongoDB</strong>
INFO:    Application startup complete.</pre> <p>This message confirms that our application correctly communicates with the MongoDB instance.</p>
<p>You’ve just set up<a id="_idIndexMarker428"/> the <a id="_idIndexMarker429"/>connection between a FastAPI application and a MongoDB instance.</p>
<h2 id="_idParaDest-230"><a id="_idTextAnchor233"/>See also</h2>
<p>You can see more on the Motor asynchronous driver on the MongoDB official documentation <a id="_idIndexMarker430"/>page:</p>
<ul>
<li><em class="italic">Motor Async Driver </em><em class="italic">Setup</em>: https://www.mongodb.com/docs/drivers/motor/</li>
</ul>
<p>For startups and shutdown events of the FastAPI server, you can find more on this page:</p>
<ul>
<li><em class="italic">FastAPI Lifespan </em><em class="italic">Events</em>: <a href="https://fastapi.tiangolo.com/advanced/events/">https://fastapi.tiangolo.com/advanced/events/</a><a href="https://fastapi.tiangolo.com/advanced/events/%20"/></li>
</ul>
<h1 id="_idParaDest-231"><a id="_idTextAnchor234"/>CRUD operations in MongoDB</h1>
<p>CRUD operations <a id="_idIndexMarker431"/>form the cornerstone of data manipulation in<a id="_idIndexMarker432"/> databases, enabling users to create, read, update, and delete data entities with efficiency, flexibility, and scalability.</p>
<p>This recipe will demonstrate how to create endpoints in FastAPI for creating, reading, updating, and deleting a document from a MongoDB database for the backbone of our streaming platform.</p>
<h2 id="_idParaDest-232"><a id="_idTextAnchor235"/>Getting ready</h2>
<p>To follow along with the recipe, you need a database connection with MongoDB already in place with your application, otherwise, go to the previous recipe, <em class="italic">Setting up MongoDB with FastAPI</em>, which will show you in detail how to do it.</p>
<h2 id="_idParaDest-233"><a id="_idTextAnchor236"/>How to do it…</h2>
<p>Before creating the endpoints for the CRUD operations, we have to initialize a database on the MongoDB instance for our streaming application.</p>
<p>Let’s do it in a dedicated module in the <code>app</code> directory called <code>database.py</code> as follows:</p>
<pre class="source-code">
from app.db_connection import mongo_client
database = mongo_client.beat_streaming</pre> <p>We’ve defined a database called <code>beat_streaming</code>, which will contain all the collections of our application.</p>
<p>On the MongoDB server side, we don’t need any action to do since the <code>motor</code> library will automatically check for the existence of a database named <code>beat_streaming</code> and the eventual collections, and it will create them if they don’t exist.</p>
<p>In the same<a id="_idIndexMarker433"/> module, we <a id="_idIndexMarker434"/>can create the function to return the database that will be used as a dependency in the endpoints for code maintainability:</p>
<pre class="source-code">
def mongo_database():
    return database</pre> <p>Now, we can define our endpoints in <code>main.py</code> for each of the CRUD operations through the following steps.</p>
<ol>
<li>Let’s start by creating the endpoint to add a song to the <code>songs</code> collection:<pre class="source-code">
from bson import ObjectId
from fastapi import Body, Depends
from app.database import mongo_database
from fastapi.encoders import ENCODERS_BY_TYPE
ENCODERS_BY_TYPE[ObjectId] = str
@app.post("/song")
async def add_song(
    song: dict = Body(
        example={
            "title": "My Song",
            "artist": "My Artist",
            "genre": "My Genre",
        },
    ),
    mongo_db=Depends(mongo_database),
):
    await mongo_db.songs.insert_one(song)
    return {
        "message": "Song added successfully",
        "id": song["_id"],
    }</pre><p class="list-inset">The endpoint takes<a id="_idIndexMarker435"/> a <a id="_idIndexMarker436"/>general JSON in the body and returns the ID affected from the database. The <code>ENCONDERS_BY_TYPE[ObjectID] = str</code> line specifies to the FastAPI server that the <code>song["_id"]</code> document ID has to be decoded as a <code>string</code>.</p><p class="list-inset">One of the reasons to choose a NoSQL database is the freedom from SQL schema, which allows for more flexibility in managing data. However, it can be helpful to provide an example to follow in the documentation. This is achieved by using the <code>Body</code> object class with the example parameter.</p></li> <li>The endpoint<a id="_idIndexMarker437"/> to<a id="_idIndexMarker438"/> retrieve a song will be quite straightforward:<pre class="source-code">
@app.get("/song/{song_id}")
async def get_song(
    song_id: str,
    db=Depends(mongo_database),
):
    song = await db.songs.find_one(
        {
            "_id": ObjectId(song_id)
            if ObjectId.is_valid(song_id)
            else None
        }
    )
    if not song:
        raise HTTPException(
            status_code=404,
            detail="Song not found"
        )
    return song</pre><p class="list-inset">The application will search for a song with the specified ID and return a <code>404</code> error if none is found.</p></li> <li>To update a song, the endpoint will look like this:<pre class="source-code">
@app.put("/song/{song_id}")
async def update_song(
    song_id: str,
    updated_song: dict,
    db=Depends(mongo_database),
):
    result = await db.songs.update_one(
        {
            "_id": ObjectId(song_id)
            if ObjectId.is_valid(song_id)
            else None
        },
        {"$set": updated_song},
    )
    if result.modified_count == 1:
      return {
          "message": "Song updated successfully"
      }
    raise HTTPException(
        status_code=404, detail="Song not found"
    )</pre><p class="list-inset">The endpoint<a id="_idIndexMarker439"/> will <a id="_idIndexMarker440"/>return a <code>404</code> error if the song id does not exist, otherwise it will update only the fields specified in the body request.</p></li> <li>Finally, the <code>delete</code> operation endpoint can be done as follows:<pre class="source-code">
@app.delete("/song/{song_id}")
async def delete_song(
    song_id: str,
    db=Depends(mongo_database),
):
    result = await db.songs.delete_one(
        {
            "_id": ObjectId(song_id)
            if ObjectId.is_valid(song_id)
            else None
        }
    )
    if result.deleted_count == 1:
        return {
            "message": "Song deleted successfully"
        }
    raise HTTPException(
        status_code=404, detail="Song not found"
    )</pre><p class="list-inset">You have just created the endpoints to interact with a MongoDB database.</p></li> </ol>
<p>Now, spin up the<a id="_idIndexMarker441"/> server <a id="_idIndexMarker442"/>from the command line and test the endpoints you just created from the interactive documentation at http://localhost:8000/docs.</p>
<p>If you follow along with the GitHub repository, you can also prefill the database with the script <code>fill_mongo_db_database.py</code> at the link: <a href="https://github.com/PacktPublishing/FastAPI-Cookbook/blob/main/Chapter07/streaming_platform/fill_mongo_db_database.py">https://github.com/PacktPublishing/FastAPI-Cookbook/blob/main/Chapter07/streaming_platform/fill_mongo_db_database.py</a></p>
<p>Make sure you download also the <code>songs_info.py</code> in the same folder.</p>
<p>You can then run the script from the terminal as follows:</p>
<pre class="console">
$ python fill_mongo_db_database.py</pre> <p>If you call<a id="_idIndexMarker443"/> the<a id="_idIndexMarker444"/> endpoint <code>GET /songs</code> you will have a long list of songs pre filled to test your API.</p>
<h2 id="_idParaDest-234"><a id="_idTextAnchor237"/>See also</h2>
<p>You can investigate the operations provided by <code>motor</code> to interact with a MongoDB instance further at the official documentation link:</p>
<ul>
<li><em class="italic">Motor MongoDB Aynscio </em><em class="italic">Tutorial</em>: <a href="https://motor.readthedocs.io/en/stable/tutorial-asyncio.xhtml">https://motor.readthedocs.io/en/stable/tutorial-asyncio.xhtml</a></li>
</ul>
<h1 id="_idParaDest-235"><a id="_idTextAnchor238"/>Handling relationships in NoSQL databases</h1>
<p>Unlike relational<a id="_idIndexMarker445"/> databases, NoSQL databases do not support joins or foreign keys for defining relationships between collections.</p>
<p>Schema-less databases, such as MongoDB, do not enforce relationships like traditional relational databases. Instead, two primary approaches can be used for handling relationships: <strong class="bold">embedding</strong> and <strong class="bold">referencing</strong>.</p>
<p>Embedding involves storing related data within a single document. This approach is suitable for all types of relationships, provided that the embedded data is closely tied to the parent document. This technique is good for read performance for frequently accessed data and atomic updates with a single document. However, it can easily lead to size limitation problems with data duplication and potential inconsistencies if the embedded data changes frequently.</p>
<p>Referencing involves storing references to related documents using their object ID or other unique identifiers. This approach is suitable for many-to-one and many-to-many relationships where the related data is huge and is shared across multiple documents.</p>
<p>This technique reduces data duplication and improves flexibility to update related data independently, but, on the other hand, increases the complexity of reading operations due to multiple queries leading to slower performances when fetching related data.</p>
<p>In this recipe, we’ll explore both techniques for handling relationships between data entities in MongoDB by adding new collections to our streaming platform and making them interact.</p>
<h2 id="_idParaDest-236"><a id="_idTextAnchor239"/>Getting ready</h2>
<p>We will continue building our streaming platform. Make sure you have followed all the previous recipes in this chapter, or you can apply the steps to an existing application that interacts with a NoSQL database.</p>
<h2 id="_idParaDest-237"><a id="_idTextAnchor240"/>How to do it…</h2>
<p>Let’s see how to<a id="_idIndexMarker446"/> implement relationships for both embedding and referencing techniques.</p>
<h3>Embedding</h3>
<p>A suitable candidate<a id="_idIndexMarker447"/> to showcase embedded relationships for songs is a collection of albums. Album information does not change often, if not never, once it is published.</p>
<p>The <code>album</code> document will embedded into the <code>song</code> document with a nested field:</p>
<pre class="source-code">
{
    "title": "Title of the Song",
    "artist": "Singer Name",
    "genre": "Music genre",
    "album": {
        "title": "Album Title",
        "release_year": 2017,
    },
}</pre> <p>When using MongoDB, we can retrieve information about an album and a song using the same endpoint. This means that when we create a new song, we can directly add information about the album it belongs to. We specify the way we want the document song to be stored, and MongoDB takes care of the rest.</p>
<p>Spin up the server and test the <code>POST /song</code> endpoint. In the JSON body, include information about the album. Take note of the ID retrieved and use it to call the <code>GET /song</code> endpoint. Since we haven’t defined any response schema restriction in the response model, the endpoint will return all the document information retrieved from the database including the album.</p>
<p>For this use case example, there is nothing to worry about, but for some applications, you might not want to disclose a field to the end user. You can either define a response model (see <a href="B21025_01.xhtml#_idTextAnchor020"><em class="italic">Chapter 1</em></a>, <em class="italic">First Steps with FastAPI</em>, in the <em class="italic">Defining and using request and response models</em> recipe) or drop the field from the <code>dict</code> object before it is returned.</p>
<p>You have just defined <a id="_idIndexMarker448"/>a many-to-one relationship with the embedding strategy that relates songs to albums.</p>
<h3>Referencing</h3>
<p>A typical use case for <a id="_idIndexMarker449"/>referencing relationships can be the creation of a playlist. A playlist contains multiple songs, and each song can appear in different playlists. Furthermore, playlists are often changed or updated, so it respond to the need for a referencing strategy to manage relationships.</p>
<p>On the database side, we don’t need any action so we will directly proceed to create the endpoint to create the playlist and the one to retrieve the playlist with all song information.</p>
<ol>
<li>You can define the endpoint to create a playlist in the <code>main.py</code> module:<pre class="source-code">
class Playlist(BaseModel):
    name: str
    songs: list[str] = []
@app.post("/playlist")
async def create_playlist(
    playlist: Playlist = Body(
        example={
            "name": "My Playlist",
            "songs": ["song_id"],
        }
    ),
    db=Depends(mongo_database),
):
    result = await db.playlists.insert_one(
        playlist.model_dump()
    )
    return {
        "message": "Playlist created successfully",
        "id": str(result.inserted_id),
    }</pre><p class="list-inset">The endpoint <a id="_idIndexMarker450"/>requires a JSON body specifying the playlist name and the list of song IDs to include, and it returns the playlist ID.</p></li> <li>The endpoint to retrieve the playlist will take as an argument the playlist ID. You can code it as follows:<pre class="source-code">
@app.get("/playlist/{playlist_id}")
async def get_playlist(
    playlist_id: str,
    db=Depends(mongo_database),
):
    playlist = await db.playlists.find_one(
        {
            "_id": ObjectId(playlist_id)
            if ObjectId.is_valid(playlist_id)
            else None
        }
    )
    if not playlist:
        raise HTTPException(
            status_code=404,
            detail="Playlist not found"
        )
    songs = await db.songs.find(
        {
            "_id": {
                "$in": [
                    ObjectId(song_id)
                    for song_id in playlist["songs"]
                ]
            }
        }
    ).to_list(None)
    return {
        "name": playlist["name"],
        "songs": songs
    }</pre><p class="list-inset">Notice that the song IDs in the playlist collection are stored as strings, not <code>ObjectId</code>, which means that they have to be converted when queried.</p><p class="list-inset">Also, to receive the list of songs for the playlist, we had to make two queries: one for the playlist and one to retrieve the songs based on their IDs.</p></li> </ol>
<p>Now that you build the endpoints to create and retrieve playlists, spin up the server:</p>
<pre class="console">
<code>http://localhost:8000/docs</code> and you will see the new endpoints: <code>POST /playlist</code> and <code>GET /playlist</code>.</p>
<p>To test the endpoints, create some songs and note their IDs. Then, create a playlist and retrieve the playlist with the <code>GET /playlist</code> endpoint. You will see that the response will contain<a id="_idIndexMarker451"/> the songs with all the information including the album.</p>
<p>At this point, you have all the tools to manage relationships between collections in MongoDB.</p>
<h2 id="_idParaDest-238"><a id="_idTextAnchor241"/>See also</h2>
<p>We just saw how to manage relationships with MongoDB and create relative endpoints. Feel free to check the official <a id="_idIndexMarker452"/>MongoDB guidelines at this link:</p>
<ul>
<li><em class="italic">MongoDB Model </em><em class="italic">Relationships</em>: <a href="https://www.mongodb.com/docs/manual/applications/data-models-relationships/">https://www.mongodb.com/docs/manual/applications/data-models-relationships/</a></li>
</ul>
<h1 id="_idParaDest-239"><a id="_idTextAnchor242"/>Working with indexes in MongoDB</h1>
<p>An <strong class="bold">index</strong> is a data <a id="_idIndexMarker453"/>structure that provides a quick lookup <a id="_idIndexMarker454"/>mechanism for locating specific pieces of data within a vast dataset. Indexes are crucial for enhancing query performance by enabling the database to quickly locate documents based on specific fields.</p>
<p>By creating appropriate indexes, you can significantly reduce the time taken to execute queries, especially for large collections. Indexes also facilitate the enforcement of uniqueness constraints and support the execution of sorted queries and text search queries.</p>
<p>In this recipe, we’ll explore the concept of indexes in MongoDB and we will create indexes to improve search performances for songs in our streaming platform.</p>
<h2 id="_idParaDest-240"><a id="_idTextAnchor243"/>Getting ready</h2>
<p>To follow along with the recipe, you need to have a MongoDB instance already set up with at least a collection to apply indexes. If you are following along with the cookbook, make sure you went through the <em class="italic">Setting up MongoDB with FastAPI</em> and <em class="italic">CRUD operations in </em><em class="italic">MongoDB</em> recipes.</p>
<h2 id="_idParaDest-241"><a id="_idTextAnchor244"/>How to do it…</h2>
<p>Let’s imagine we need to search for songs released in a certain year. We can create a dedicated endpoint directly in the <code>main.py</code> module as follows:</p>
<pre class="source-code">
@app.get("/songs/year")
async def get_songs_by_released_year(
    year: int,
    db=Depends(mongo_database),
):
    query = db.songs.find({"album.release_year": year})
    songs = await query.to_list(None)
    return songs</pre> <p>The query will fetch all documents and filter the one with a certain <code>release_year</code>. To speed up the query, we can create a dedicated index on the release year. We can do it at the server startup in the <code>lifespan</code> context manager in <code>main.py</code>. A text search in MongoDB won’t be possible without a text index.</p>
<p>First, at the startup server, let’s create a text index based on the <code>artist</code> field of the collection document. To do this, let’s modify the <code>lifespan</code> context manager in the <code>main.py</code> module:</p>
<pre class="source-code">
@asynccontextmanager
async def lifespan(app: FastAPI):
    await ping_mongo_db_server(),
<strong class="bold">    db = mongo_database()</strong>
<strong class="bold">    await db.songs.create_index({"album.release_year": -1})</strong>
    yield</pre> <p>The <code>create_index</code> method will create an index based on the <code>release_year</code> field sorted in<a id="_idIndexMarker455"/> descending <a id="_idIndexMarker456"/>mode because of the <code>-</code><code>1</code> value.</p>
<p>You’ve just created an index based on the <code>release_year</code> field.</p>
<h2 id="_idParaDest-242"><a id="_idTextAnchor245"/>How it works…</h2>
<p>The index just created is automatically used by MongoDB when running the query.</p>
<p>Let’s check it by leveraging the explain query method. Let’s add the following log message to the endpoint to retrieve songs released in a certain year:</p>
<pre class="source-code">
@app.get("/songs/year")
async def get_songs_by_released_year(
    year: int,
    db=Depends(mongo_database),
):
    query = db.songs.find({"album.release_year": year})
    explained_query = await query.explain()
<strong class="bold">    logger.info(</strong>
<strong class="bold">        "Index used: %s",</strong>
<strong class="bold">        explained_query.get("queryPlanner", {})</strong>
<strong class="bold">        .get("winningPlan", {})</strong>
<strong class="bold">        .get("inputStage", {})</strong>
<strong class="bold">        .get("indexName", "No index used"),</strong>
<strong class="bold">    )</strong>
    songs = await query.to_list(None)
    return songs</pre> <p>The <code>explained_query</code> variable holds information about the query such as the query execution or index used for the search.</p>
<p>If you run the<a id="_idIndexMarker457"/> server <a id="_idIndexMarker458"/>and call the <code>GET /songs/year</code> endpoint, you will see the following message log on the terminal output:</p>
<pre class="console">
INFO:    Index used: album.release_year_-1</pre> <p>This confirms that the query has correctly used the index we created to run.</p>
<h2 id="_idParaDest-243"><a id="_idTextAnchor246"/>There’s more…</h2>
<p>Database indexes become necessary to run text search queries. Imagine we need to retrieve the songs of a certain artist.</p>
<p>To query and create the endpoint, we need to make a text index on the <code>artist</code> field. We can do it at the server startup like the previous index on <code>album.release_year</code>.</p>
<p>In the <code>lifespan</code> context manager, you can add the index creation:</p>
<pre class="source-code">
@asynccontextmanager
async def lifespan(app: FastAPI):
    await ping_mongodb_server(),
    db = mongo_database()
    await db.songs.drop_indexes()
    await db.songs.create_index({"release_year": -1})
<strong class="bold">    await db.songs.create_index({"artist": "text"})</strong>
    yield</pre> <p>Once we have created the index, we can proceed to create the endpoint to retrieve the song based on the <a id="_idIndexMarker459"/>artist’s <a id="_idIndexMarker460"/>name.</p>
<p>In the same <code>main.py</code> module, create the endpoint as follows:</p>
<pre class="source-code">
@app.get("/songs/artist")
async def get_songs_by_artist(
    artist: str,
    db=Depends(mongo_database),
):
    query = db.songs.find(
        {"$text": {"$search": artist}}
    )
    explained_query = await query.explain()
    logger.info(
        "Index used: %s",
        explained_query.get("queryPlanner", {})
        .get("winningPlan", {})
        .get("indexName", "No index used"),
    )
    songs = await query.to_list(None)
    return songs</pre> <p>Spin up the server from the command line with the following:</p>
<pre class="console">
$ uvicorn app.main:app</pre> <p>Go to the interactive documentation at <code>http:/localhost:8000/docs</code> and try to run the new <code>GET /</code><code>songs/artist</code> endpoint.</p>
<p>Text searching allow you to fetch records based on text matching. If you have filled the database with the <code>fill_mongo_db_database.py</code> script you can try searching for Bruno Mars’s songs by specifying the family name <code>"mars"</code>. The query will be:</p>
<pre class="source-code">
http://localhost:8000/songs/artist?artist=mars</pre> <p>This will return at<a id="_idIndexMarker461"/> the <a id="_idIndexMarker462"/>least the song:</p>
<pre class="source-code">
[
  {
    "_id": "667038acde3a00e55e764cf7",
    "title": "Uptown Funk",
    "artist": "Mark Ronson ft. Bruno Mars",
    "genre": "Funk/pop",
    "album": {
      "title": "Uptown Special",
      "release_year": 2014
    }
  }
]</pre> <p>Also, you will see a message on the terminal output like:</p>
<pre class="console">
INFO:    Index used: artist_text</pre> <p>That means that the database has used the correct index to fetch the data.</p>
<p class="callout-heading">Important note</p>
<p class="callout">By using the <code>explanation_query</code> variable, you can also check the difference in the execution time. However, you<a id="_idIndexMarker463"/> need a huge number of documents in <a id="_idIndexMarker464"/>your collection to appreciate the improvement.</p>
<h2 id="_idParaDest-244"><a id="_idTextAnchor247"/>See also</h2>
<p>We saw how to build a text index for the search over the artist and a numbered index for the year of release. MongoDB allows you to do more, such as defining 2D sphere index types or<a id="_idIndexMarker465"/> compound<a id="_idIndexMarker466"/> indexes. Have a look at the documentation to discover the potential of indexing your MongoDB database:</p>
<ul>
<li><em class="italic">Mongo </em><em class="italic">Indexes</em>: https://www.mongodb.com/docs/v5.3/indexes/</li>
<li><em class="italic">MongoDB Text </em><em class="italic">Search</em>: <a href="https://www.mongodb.com/docs/manual/core/link-text-indexes/">https://www.mongodb.com/docs/manual/core/link-text-indexes/</a></li>
</ul>
<h1 id="_idParaDest-245"><a id="_idTextAnchor248"/>Exposing sensitive data from NoSQL databases</h1>
<p>The way to<a id="_idIndexMarker467"/> expose sensitive data in NoSQL<a id="_idIndexMarker468"/> databases is pivotal to protecting sensitive information and maintaining the integrity of your application.</p>
<p>In this recipe, we will demonstrate how to securely view our data through database aggregations with the intent to expose it to a third-party consumer of our API. This technique is known<a id="_idIndexMarker469"/> as <strong class="bold">data masking</strong>. Then, we will explore some strategies and best practices for securing sensitive data in MongoDB and NoSQL databases in general.</p>
<p>By following best practices and staying informed about the latest security updates, you can effectively safeguard your MongoDB databases against potential security threats.</p>
<h2 id="_idParaDest-246"><a id="_idTextAnchor249"/>Getting ready</h2>
<p>To follow the recipe, you need to have a running FastAPI application with a MongoDB connection already set up. If don’t have it yet, have a look at the <em class="italic">Setting up MongoDB with FastAPI</em> recipe. In addition, you need a collection of sensitive data such as <strong class="bold">Personal Identifiable Information</strong> (<strong class="bold">PII</strong>) or <a id="_idIndexMarker470"/>other restricted information.</p>
<p>Alternatively, we can build a collection of users into our MongoDB database, <code>beat_streaming</code>. The document contains PIIs such as names and emails, as well as users actions on<a id="_idIndexMarker471"/> the <a id="_idIndexMarker472"/>platform. The document will look like this:</p>
<pre class="source-code">
{
    "name": "John Doe",
    "email": "johndoe@email.com",
    "year_of_birth": 1990,
    "country": "USA",
<strong class="bold">    "consent_to_share_data": True,</strong>
    "actions": [
        {
            "action": "basic subscription",
            "date": "2021-01-01",
            "amount": 10,
        },
        {
            "action": "unscription",
            "date": "2021-05-01",
        },
    ],
}</pre> <p>The <code>consent_to_share_data</code> field stores the consent of the user to share behavioral data with third-party partners.</p>
<p>Let’s first fill the collection users in our database. You can do this with a user’s sample by running the script provided in the GitHub repository:</p>
<pre class="console">
$ python fill_users_in_mongo.py</pre> <p>If everything runs smoothly, you should have the collection users in your MongoDB instance.</p>
<h2 id="_idParaDest-247"><a id="_idTextAnchor250"/>How to do it…</h2>
<p>Imagine we need to expose users data for marketing research to a third-party API consumer for commercial purposes. The third-party consumer does not need PII information such as names or emails, and they are also not allowed to have data from users who<a id="_idIndexMarker473"/> didn’t give <a id="_idIndexMarker474"/>their consent. This is a perfect use case to apply data masking.</p>
<p>In MongoDB, you can build aggregation pipelines in stages. We will do it step by step.</p>
<ol>
<li>Since the database scaffolding is an infrastructure operation rather than an application, let’s create the pipeline with the view in a separate script that we will run separately from the server.<p class="list-inset">In a new file called <code>create_aggregation_and_user_data_view.py</code>, let’s start by defining the client:</p><pre class="source-code">
from pymongo import MongoClient
client = MongoClient("mongodb://localhost:27017/")</pre><p class="list-inset">Since we don’t have any need to manage high traffic, we will use the simple <code>pymongo</code> client instead of the asynchronous one. We will reserve the asynchronous to the sole use of the application interactions.</p></li> <li>The pipeline stage follows a specific aggregations framework. The first step of the pipeline will be to filter out the users who didn’t approve the consent. This can be done with a <code>$</code><code>redact</code> stage:<pre class="source-code">
pipeline_redact = {
    "$redact": {
        "$cond": {
            "if": {
                "$eq": [
                    "$consent_to_share_data", True
                ]
            },
            "then": "$$KEEP",
            "else": "$$PRUNE",
        }
    }
}</pre></li> <li>Then, we filter out<a id="_idIndexMarker475"/> the<a id="_idIndexMarker476"/> emails that shouldn’t be shared with a <code>$</code><code>unset</code> stage:<pre class="source-code">
pipeline_remove_email_and_name = {
    "$unset": ["email", "name"]
}</pre></li> <li>This part of the pipeline will prevent emails and names from appearing in the pipeline’s output. We will split stage definition into three dictionaries for a better understanding.<p class="list-inset">First, we define the action to obfuscate the day for each date:</p><pre class="source-code">
obfuscate_day_of_date = {
    "$concat": [
        {
            "$substrCP": [
                "$$action.date",
                0,
                7,
            ]
        },
        "-XX",
    ]
}</pre></li> <li>Then, we map <a id="_idIndexMarker477"/>the <a id="_idIndexMarker478"/>new <code>date</code> field for each element of the actions list:<pre class="source-code">
rebuild_actions_elements = {
    "input": "$actions",
    "as": "action",
    "in": {
        "$mergeObjects": [
            "$$action",
            {"date": obfuscate_day_of_date},
        ]
    },
}</pre></li> <li>Then, we use a <code>$set</code> operation to apply the <code>rebuild_actions_element</code> operation to every record like that:<pre class="source-code">
pipeline_set_actions = {
    "$set": {
        "actions": {"$map": rebuild_actions_elements},
    }
}</pre></li> <li>Then, we gather the pipelines just created to define the entire pipeline stage:<pre class="source-code">
pipeline = [
    pipeline_redact,
    pipeline_remove_email_and_name,
    pipeline_set_actions,
]</pre></li> <li>We can use the<a id="_idIndexMarker479"/> list <a id="_idIndexMarker480"/>of aggregation stages to retrieve results and create the view in the <code>__main__</code> section of the script:<pre class="source-code">
if __name__ == "__main__":
    client["beat_streaming"].drop_collection(
        "users_data_view"
    )
    client["beat_streaming"].create_collection(
        "users_data_view",
        viewOn="users",
        pipeline=pipeline,
    )
<code>users_data_view</code> view will be created in our <code>beat_streaming</code> database.</pre></li> <li>Once we have the view, we can create a dedicated endpoint to expose this view to a third-party customer without exposing any sensible data. We can create our endpoint in a separate module for clarity. In the <code>app</code> folder, let’s create the <code>third_party_endpoint.py</code> module. In the module, let’s create the module router <a id="_idIndexMarker481"/>as <a id="_idIndexMarker482"/>follows:<pre class="source-code">
from fastapi import APIRouter, Depends
from app.database import mongo_database
router = APIRouter(
    prefix="/thirdparty",
    tags=["third party"],
)</pre></li> <li>Then, we can define the endpoint:<pre class="source-code">
@router.get("/users/actions")
async def get_users_with_actions(
    db=Depends(mongo_database),
):
    users = [
        user
        async for user in db.users_data_view.find(
            {}, {"_id": 0}
        )
    ]
    return users</pre></li> <li>Once the endpoint function has been created, let’s include the new router in the <code>FastAPI</code> object in the <code>main.py</code> module:<pre class="source-code">
<strong class="bold">from app import third_party_endpoint</strong>
## rest of the main.py code
app = FastAPI(lifespan=lifespan)
<strong class="bold">app.include_router(third_party_endpoint.router)</strong>
## rest of the main.py code</pre></li> </ol>
<p>The endpoint is <a id="_idIndexMarker483"/>now<a id="_idIndexMarker484"/> implemented in our API. Let’s start the server by running the following command:</p>
<pre class="console">
<code>http://localhost:8000/docs</code>, you can check that the newly created endpoint is present and call it to retrieve all the users from the created view without any sensible information.</p>
<p>You have just created an endpoint that securely exposes users data. An additional layer of security can be added by<a id="_idIndexMarker485"/> implementing <strong class="bold">role-based access control</strong> (<strong class="bold">RBAC</strong>) on the endpoint as we have done, for example, in <a href="B21025_04.xhtml#_idTextAnchor122"><em class="italic">Chapter 4</em></a>, <em class="italic">Authentication and Authorization</em>, in the recipe <em class="italic">Setting </em><em class="italic">up RBAC</em>.</p>
<h2 id="_idParaDest-248"><a id="_idTextAnchor251"/>There’s more…</h2>
<p>Additional layers are often added to secure your data’s application, besides data masking. The most important ones are as follows:</p>
<ul>
<li><strong class="bold">Encryption </strong><strong class="bold">at rest</strong></li>
<li><strong class="bold">Encryption </strong><strong class="bold">in transit</strong></li>
<li><strong class="bold">RBAC</strong></li>
</ul>
<p>The three services are provided as ready-to-use solutions in enterprise versions of MongoDB. The choice of using it or not is at the discretion of software architects.</p>
<p><strong class="bold">Encryption at rest</strong> involves <a id="_idIndexMarker486"/>encrypting the data stored in<a id="_idIndexMarker487"/> your MongoDB database to prevent unauthorized access to sensitive information. The enterprise version of MongoDB provides built-in encryption capabilities through the use of a dedicated storage engine. By enabling encryption at rest, you can ensure that your data is encrypted on disk, making it unreadable to anyone without the proper encryption keys.</p>
<p><strong class="bold">Encryption in transit</strong> ensures<a id="_idIndexMarker488"/> that data transmitted between<a id="_idIndexMarker489"/> your application and the MongoDB server is encrypted to prevent eavesdropping and tampering. MongoDB supports encryption in transit using <strong class="bold">Transport Layer Security</strong> (<strong class="bold">TLS</strong>), which<a id="_idIndexMarker490"/> encrypts data sent over the network between your application and the MongoDB server.</p>
<p><strong class="bold">RBAC</strong> is essential for <a id="_idIndexMarker491"/>restricting access to sensitive data in<a id="_idIndexMarker492"/> MongoDB databases. MongoDB provides robust authentication and authorization mechanisms to control access to databases, collections, and documents. You can create user accounts with different roles and privileges to ensure that only authorized users can access and manipulate sensitive data.</p>
<p>MongoDB supports RBAC, allowing you to assign specific roles to users based on their responsibilities <a id="_idIndexMarker493"/>and<a id="_idIndexMarker494"/> restrict access to sensitive data accordingly.</p>
<h2 id="_idParaDest-249"><a id="_idTextAnchor252"/>See also</h2>
<p>In the recipe, we had a quick look at how to create aggregations and views in MongoDB. Feel free to look into this more on the official documentation pages:</p>
<ul>
<li><em class="italic">MongoDB Aggregations </em><em class="italic">Quickstart</em>: <a href="https://www.mongodb.com/developer/languages/python/python-quickstart-aggregation/">https://www.mongodb.com/developer/languages/python/python-quickstart-aggregation/</a></li>
<li><em class="italic">MongoDB Views </em><em class="italic">Documentation</em>: <a href="https://www.mongodb.com/docs/manual/core/views/">https://www.mongodb.com/docs/manual/core/views/</a></li>
</ul>
<p>A good example of pushing data masking forward through database aggregations in MongoDB can be found at this link:</p>
<ul>
<li><em class="italic">MongoDB Data Masking </em><em class="italic">Example</em>: <a href="https://github.com/pkdone/mongo-data-masking?tab=readme-ov-file">https://github.com/pkdone/mongo-data-masking?tab=readme-ov-file</a></li>
</ul>
<p>You can see more about the commands of the aggregation framework on the official documentation page:</p>
<ul>
<li><em class="italic">Aggregation </em><em class="italic">Stage</em>: <a href="https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/">https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/</a></li>
</ul>
<p>Also, a comprehensive book on MongoDB aggregations, free to consult, is available at this link:</p>
<ul>
<li><em class="italic">Practical MongoDB Aggregation </em><em class="italic">Book</em>: <a href="https://www.practical-mongodb-aggregations.com">https://www.practical-mongodb-aggregations.com</a></li>
</ul>
<h1 id="_idParaDest-250"><a id="_idTextAnchor253"/>Integrating FastAPI with Elasticsearch</h1>
<p><strong class="bold">Elasticsearch</strong> is a <a id="_idIndexMarker495"/>powerful <a id="_idIndexMarker496"/>search engine that provides fast and efficient full-text search, real-time analytics, and more. By integrating Elasticsearch with FastAPI, you can enable advanced search functionality, including keyword search, filtering, and aggregation. We’ll walk through the process of integrating Elasticsearch, indexing data, executing search queries, and handling search results within a FastAPI application.</p>
<p>In this recipe, we will create a specific endpoint for our streaming platform to enable analytics and enhance search capabilities in your web applications. Specifically, we will retrieve the top ten artists based on views from a specified country.</p>
<p>By the end of this recipe, you’ll be equipped with the knowledge and tools to leverage Elasticsearch for robust search functionality in your FastAPI projects.</p>
<h2 id="_idParaDest-251"><a id="_idTextAnchor254"/>Getting ready</h2>
<p>To follow along <a id="_idIndexMarker497"/>with the recipe, you need a running application <a id="_idIndexMarker498"/>or to keep on working on our streaming platform.</p>
<p>Furthermore, you need an Elasticsearch instance running and reachable at this address: <code>http://localhost:9200</code>.</p>
<p>You can also install Elasticsearch on your machine by following the official guide: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.xhtml">https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.xhtml</a>.</p>
<p>Then, if you haven’t installed the packages with <code>requirements.txt</code>, you need to install the Elasticsearch Python client with the <code>aiohttp</code> package in your environment. You can do this with <code>pip</code> from the command line:</p>
<pre class="console">
$ pip install "elasticsearch&gt;=8,&lt;9" aiohttp</pre> <p>A basic knowledge of <strong class="bold">Domain Specific Language</strong> (<strong class="bold">DSL</strong>) in Elasticsearch can be beneficial to get a deeper understanding of the queries we are going to implement.</p>
<p>Have a look at the official documentation at this link: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.xhtml">https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.xhtml</a>.</p>
<p>Once you have Elasticsearch installed and running, we can proceed to integrate it into our application.</p>
<h2 id="_idParaDest-252"><a id="_idTextAnchor255"/>How to do it…</h2>
<p>We break down the process into the following steps:</p>
<ol>
<li>Set up Elasticsearch in our FastAPI application to allow our API to communicate with the Elasticsearch instance.</li>
<li>Create an Elasticsearch index so that our songs can be indexed and queried by Elasticsearch.</li>
<li>Build the query to query our songs index.</li>
<li>Create the FastAPI endpoint to expose our analytics endpoint to the API users.</li>
</ol>
<p>Let’s look at each <a id="_idIndexMarker499"/>of<a id="_idIndexMarker500"/> these steps in detail.</p>
<h3>Set up Elasticsearch in our FastAPI application</h3>
<p>To interact<a id="_idIndexMarker501"/> with the Elasticsearch server, we <a id="_idIndexMarker502"/>need to define the client in our Python code. In the <code>db_connection.py</code> module, where we already define parameters for MongoDB, let’s define the Elasticsearch asynchronous client:</p>
<pre class="source-code">
from elasticsearch import AsyncElasticsearch,
es_client = AsyncElasticsearch(
    "localhost:27017"
)</pre> <p>We can create a function to check the connection with Elasticsearch in the same module:</p>
<pre class="source-code">
from elasticsearch import (
    TransportError,
)
async def ping_elasticsearch_server():
    try:
        await es_client.info()
        logger.info(
            "Elasticsearch connection successful"
        )
    except TransportError as e:
        logger.error(
            f"Elasticsearch connection failed: {e}"
        )
        raise e</pre> <p>The function will ping the Elasticsearch server and propagate an error if the ping fails.</p>
<p>Then, we can call the function at the FastAPI server startup in the <code>lifetime</code> context manager in the <code>main.py</code> module:</p>
<pre class="source-code">
@asynccontextmanager
async def lifespan(app: FastAPI):
    await ping_mongo_db_server(),
<strong class="bold">    await ping_elasticsearch_server()</strong>
# rest of the code</pre> <p>This will ensure<a id="_idIndexMarker503"/> that<a id="_idIndexMarker504"/> the application checks the connection with the Elasticsearch server at the startup, and it will propagate an error if the Elasticsearch server does not respond.</p>
<h3>Create an Elasticsearch index</h3>
<p>First of all, we should <a id="_idIndexMarker505"/>start by filling our Elasticsearch instance with a collection of song documents. In Elasticsearch, a collection is referred to as an <em class="italic">index</em>.</p>
<p>The song document should contain an additional field that tracks information about the views per country. For example, a new document song will look like the following:</p>
<pre class="source-code">
{
    "title": "Song Title",
    "artist": "Singer Name",
    "album": {
    "title": "Album Title",
    "release_year": 2012,
    },
    "genre": "rock pop",
<strong class="bold">    "views_per_country": {</strong>
<strong class="bold">    "India": 50_000_000,</strong>
<strong class="bold">    "UK": 35_000_150_000,</strong>
<strong class="bold">    "Mexico": 60_000_000,</strong>
<strong class="bold">    "Spain": 40_000_000,</strong>
<strong class="bold">    },</strong>
}</pre> <p>You can find a list of<a id="_idIndexMarker506"/> sampling songs in the file <code>songs_info.py</code> in the project GitHub repository. If you use the file, you can also define a function to fill in the index as:</p>
<pre class="source-code">
from app.db_connection import es_client
async def fill_elastichsearch():
    for song in songs_info:
        await es_client.index(
            index="songs_index", body=song
        )
    await es_client.close()</pre> <p>To group our songs based on the country’s views, we will need to fetch data based on the <code>views_per_country</code> field, and for the top ten artists, we will group based on the <code>artist</code> field.</p>
<p>This information should be provided to the indexing process so that Elasticsearch understands how to index documents within the index for running queries.</p>
<p>In a new module <a id="_idIndexMarker507"/>called <code>fill_elasticsearch_index.py</code>, we can store this information in a <code>python</code> dictionary:</p>
<pre class="source-code">
mapping = {
    "mappings": {
        "properties": {
            "artist": {"type": "keyword"},
            "views_per_country": {
                "type": "object",
                "dynamic": True,
            },
        }
    }
}</pre> <p>The <code>mapping</code> object will be passed as an argument to the Elasticsearch client when creating the index. We can define a function to create our <code>songs_index</code>:</p>
<pre class="source-code">
from app.db_connection import es_client
async def create_index():
    await es_client.options(
        ignore_status=[400, 404]
    ).indices.create(
        index="songs_index",
        body=mapping,
    )
    await es_client.close()</pre> <p>You can run the function in into a grouping <code>main()</code> one, and use the <code>__main__</code> section of the module to run as follows:</p>
<pre class="source-code">
async def main():
    await create_index()
    await fill_elastichsearch() # only if you use it
if __name__ == "__main__":
    import asyncio
    asyncio.run(create_index())</pre> <p>You can then run<a id="_idIndexMarker508"/> the script from the terminal:</p>
<pre class="console">
$ python fill_elasticsearch_index.py</pre> <p>Now that the index is created, we just have to add the songs to the index. You can do this by creating a separate script or by running <code>fill_elasticsearch_index.py</code>, which is provided in the GitHub repository.</p>
<p>We have just set up our index filled with documents on our Elasticsearch index. Let’s see how to build the query.</p>
<h3>Build the query</h3>
<p>We will build a <a id="_idIndexMarker509"/>function to return the query based on the specified country.</p>
<p>We can do it in a separate module in the <code>app</code> folder called <code>es_queries.py</code>. The query should fetch all the documents containing the <code>views_per_country</code> map index for the <a id="_idIndexMarker510"/>country and sort the results in descending order:</p>
<pre class="source-code">
def top_ten_songs_query(country) -&gt; dict:
    views_field = f"views_per_country.{country}"
    query = {
        "bool": {
            "must": {"match_all": {}},
            "filter": [
                {"exists": {"field": views_field}}
            ],
        }
    }
    sort = {views_field: {"order": "desc"}}</pre> <p>Then, we filter the fields that we want in the response as follows:</p>
<pre class="source-code">
    source = [
        "title",
        views_field,
        "album.title",
        "artist",
    ]</pre> <p>Finally, we return the query in the form of a dictionary by specifying the size of the list we will expect:</p>
<pre class="source-code">
      return {
        "index": "songs_index",
        "query": query,
        "size": 10,
        "sort": sort,
        "source": source,
    }</pre> <p>We now have the function that will construct the query to retrieve the top ten artists for a specified country, and<a id="_idIndexMarker511"/> we will utilize it in our endpoint.</p>
<h3>Create the FastAPI endpoint</h3>
<p>Once we have set <a id="_idIndexMarker512"/>up the Elasticsearch connection and formulated the query, creating the endpoint is a straightforward process. Let’s define it in a new module called <code>main_search.py</code> under the <code>app</code> folder. Let’s start by defining the router:</p>
<pre class="source-code">
from fastapi import APIRouter
router = APIRouter(prefix="/search", tags=["search"])</pre> <p>Then, the endpoint will be:</p>
<pre class="source-code">
from fastapi import Depends, HTTPException
from app.db_connection import es_client
def get_elasticsearch_client():
    return es_client
@router.get("/top/ten/artists/{country}")
async def top_ten_artist_by_country(
    country: str,
    es_client=Depends(get_elasticsearch_client),
):
    try:
        response = await es_client.search(
         *top_ten_artists_query(country)
    )
    except BadRequestError as e:
        logger.error(e)
        raise HTTPException(
            status_code=400,
            detail="Invalid country",
        )
    return [
        {
            "artist": record.get("key"),
            "views": record.get("views", {}).get(
                "value"
            ),
        }
        for record in response["aggregations"][
            "top_ten_artists"
        ]["buckets"]
    ]</pre> <p>The result of the query is further adjusted before being returned to extract only the values we are interested in, namely the artist and views.</p>
<p>The last step is to include the router in our <code>FastAPI</code> object to include the endpoint.</p>
<p>In the <code>main.py</code> module, we can add the router as follows:</p>
<pre class="source-code">
<strong class="bold">import main_search</strong>
## existing code in main.py
app = FastAPI(lifespan=lifespan)
app.include_router(third_party_endpoint.router)
<strong class="bold">app.include_router(main_search.router)</strong>
## rest of the code</pre> <p>Now, if you spin up the server with the <code>uvicorn app.main:app</code> command and go to the interactive documentation at <code>http://localhost:8000/docs</code>, you will see the newly created endpoint to retrieve the top ten artists in a country based on the views of the songs.</p>
<p>You have just created a FastAPI endpoint that interacts with an Elasticsearch instance. Feel free to create new <a id="_idIndexMarker513"/>endpoints on your own. For example, you can create an endpoint to return the top ten songs for a country.</p>
<h2 id="_idParaDest-253"><a id="_idTextAnchor256"/>See also</h2>
<p>Since we have used the<a id="_idIndexMarker514"/> Elasticsearch Python client, feel free to <a id="_idIndexMarker515"/>dig more into the official documentation pages:</p>
<ul>
<li><em class="italic">Elasticsearch Python </em><em class="italic">Client</em>: <a href="https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.xhtml">https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.xhtml</a></li>
<li><em class="italic">Using Asyncio with </em><em class="italic">Elasticsearch</em>: <a href="https://elasticsearch-py.readthedocs.io/en/7.x/async.xhtml">https://elasticsearch-py.readthedocs.io/en/7.x/async.xhtml</a></li>
</ul>
<p>To learn more about <a id="_idIndexMarker516"/>Elasticsearch indexes, have a look at the Elasticsearch documentation:</p>
<ul>
<li><em class="italic">Index </em><em class="italic">API</em>: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.xhtml">https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.xhtml</a></li>
</ul>
<p>You can find a guide to mapping at this link:</p>
<ul>
<li><em class="italic">Mapping</em>: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.xhtml">https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.xhtml</a></li>
</ul>
<p>Finally, you can dig into the search query language at the following link:</p>
<ul>
<li><em class="italic">Query </em><em class="italic">DSL</em>: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.xhtml">https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.xhtml</a></li>
</ul>
<h1 id="_idParaDest-254"><a id="_idTextAnchor257"/>Using Redis for caching in FastAPI</h1>
<p>Redis is an in-memory <a id="_idIndexMarker517"/>data store that can be used as a cache<a id="_idIndexMarker518"/> to improve the performance and scalability of FastAPI applications. By caching frequently accessed data in Redis, you can reduce the load on your database and speed up response times for your API endpoints.</p>
<p>In this recipe, we’ll explore how to integrate Redis caching into our streaming platform application and we will cache an endpoint as an example.</p>
<h2 id="_idParaDest-255"><a id="_idTextAnchor258"/>Getting ready</h2>
<p>To follow along with the recipe you need a running Redis instance reachable at the http://localhost:6379 address.</p>
<p>Depending on your machine and your preference, you have several ways to install it and run it. Have a look at the Redis documentation to see how to do it for your operating system: <a href="https://redis.io/docs/install/install-redis/">https://redis.io/docs/install/install-redis/</a>.</p>
<p>In addition, you need a FastAPI application with an endpoint that is time consuming.</p>
<p>Alternatively, if you follow the streaming platform, make sure that you have created the top ten artists endpoint from the previous recipe, <em class="italic">Integrating FastAPI </em><em class="italic">with Elasticsearch</em>.</p>
<p>You will also need the Redis client for Python in your environment. If you haven’t installed the packages with <code>requirements.txt</code>, you do it by running the following command:</p>
<pre class="console">
$ pip install redis</pre> <p>Once the installation is complete, we can proceed with the recipe.</p>
<h2 id="_idParaDest-256"><a id="_idTextAnchor259"/>How to do it…</h2>
<p>Once Redis is running <a id="_idIndexMarker519"/>and<a id="_idIndexMarker520"/> reachable at <code>localhost:6379</code>, we can integrate the Redis client into our code:</p>
<ol>
<li>In the <code>db_connection.py</code> module, where we already defined the clients for Mongo and Elasticsearch, let’s add the client for Redis:<pre class="source-code">
from redis import asyncio as aioredis
redis_client = aioredis.from_url("redis://localhost")</pre></li> <li>Similarly to the other databases, we can create a function that pings the Redis server at the application’s startup. The function can be defined as follows:<pre class="source-code">
async def ping_redis_server():
    try:
        await redis_client.ping()
        logger.info("Connected to Redis")
    except Exception as e:
        logger.error(
            f"Error connecting to Redis: {e}"
        )
        raise e</pre></li> <li>Then, include it in the <code>lifespan</code> context manager in <code>main.py</code>:<pre class="source-code">
@asynccontextmanager
async def lifespan(app: FastAPI):
    await ping_mongo_db_server(),
    await ping_elasticsearch_server(),
<strong class="bold">    await ping_redis_server(),</strong>
    yield</pre><p class="list-inset">Now, we can<a id="_idIndexMarker521"/> use <a id="_idIndexMarker522"/>the <code>redis_client</code> object to cache our endpoints. We will cache the <code>GET /search/top/ten/artists</code> endpoint used to query Elasticsearch.</p></li> <li>In <code>main_search.py</code>, we can define a function to retrieve the Redis client as a dependency:<pre class="source-code">
def get_redis_client():
    return redis_client</pre></li> <li>Then, you can modify the endpoint as follows:<pre class="source-code">
@router.get("/top/ten/artists/{country}")
async def top_ten_artist_by_country(
    country: str,
    es_client=Depends(get_elasticsearch_client),
<strong class="bold">    redis_client=Depends(get_redis_client),</strong>
):</pre></li> <li>At the beginning of the function, we retrieve the key to store the value and check whether the value is already stored in Redis:<pre class="source-code">
<strong class="bold">    cache_key = f"top_ten_artists_{country}"</strong>
<strong class="bold">    cached_data = await redis_client.get(cache_key)</strong>
<strong class="bold">    if cached_data:</strong>
<strong class="bold">        logger.info(</strong>
<strong class="bold">            f"Returning cached data for {country}"</strong>
<strong class="bold">        )</strong>
<strong class="bold">        return json.loads(cached_data)</strong></pre></li> <li>Then, when we <a id="_idIndexMarker523"/>see<a id="_idIndexMarker524"/> that the data is not present, we continue by getting the data from Elasticsearch:<pre class="source-code">
    try:
        response = await es_client.search(
             *top_ten_artists_query(country)
        )
    except BadRequestError as e:
        logger.error(e)
        raise HTTPException(
            status_code=400,
            detail="Invalid country",
        )
    artists = [
        {
            "artist": record.get("key"),
            "views": record.get("views", {}).get(
                "value"
            ),
        }
        for record in response["aggregations"][
            "top_ten_artists"
        ]["buckets"]
    ]</pre></li> <li>Once we retrieve the <a id="_idIndexMarker525"/>list, we<a id="_idIndexMarker526"/> store it in Redis so we can retrieve it at the following call:<pre class="source-code">
<strong class="bold">    await redis_client.set(</strong>
<strong class="bold">        cache_key, json.dumps(artists), ex=3600</strong>
<strong class="bold">    )</strong>
    return artists</pre></li> <li>We specified an expiring time, which is the time the record will stay in Redis in seconds. After that time, the record won’t be available anymore and the artists list will be recalled from Elasticsearch.</li>
</ol>
<p>Now, if you run the server with the <code>uvicorn app.main:app</code> command and try to call the endpoint for Italy, you will notice that the response time for the second call will be much less.</p>
<p>You have just implemented a cache for one of the endpoints of our application with Redis. With the same<a id="_idIndexMarker527"/> strategy, feel<a id="_idIndexMarker528"/> free to cache all the other endpoints.</p>
<h2 id="_idParaDest-257"><a id="_idTextAnchor260"/>There’s more…</h2>
<p>At the time of writing, there is a promising library, <code>fastapi-cache</code>, which makes caching in FastAPI very easy. Check the GitHub repository: <a href="https://github.com/long2ice/fastapi-cache">https://github.com/long2ice/fastapi-cache</a>.</p>
<p>The library supports several caching databases, including Redis and in-memory caching. With simple endpoint decorators, you can specify caching parameters such as time to live, encoder, and cache response header.</p>
<h2 id="_idParaDest-258"><a id="_idTextAnchor261"/>See also</h2>
<p>Redis client for Python supports more advanced functionalities. Feel free to explore its potential in the official documentation:</p>
<ul>
<li><em class="italic">Redis Python </em><em class="italic">Client</em>: <a href="https://redis.io/docs/connect/clients/python/">https://redis.io/docs/connect/clients/python/</a></li>
<li><em class="italic">Redis Python Asynchronous </em><em class="italic">Client</em>: <a href="https://redis-py.readthedocs.io/en/stable/examples/asyncio_examples.xhtml">https://redis-py.readthedocs.io/en/stable/examples/asyncio_examples.xhtml</a></li>
</ul>
</div>
</div></body></html>