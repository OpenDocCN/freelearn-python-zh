<html><head></head><body>
        

            
                <h1 class="header-title">Graphs and Other Algorithms</h1>
            

            
                
<p>In this chapter, we are going to talk about graphs. This is a concept that comes from the branch of mathematics called graph theory.</p>
<p>Graphs are used to solve a number of computing problems. They also have much less structure than other data structures we have looked at and things like traversal can be much more unconventional, as we shall see.</p>
<p>By the end of this chapter, you should be able to do the following:</p>
<ul>
<li>Understand what graphs are</li>
<li>Know the types of graphs and their constituents</li>
<li>Know how to represent a graph and traverse it</li>
<li>Get a fundamental idea of what priority queues are</li>
<li>Be able to implement a priority queue</li>
<li>Be able to determine the ith smallest element in a list</li>
</ul>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Graphs</h1>
            

            
                
<p>A graph is a set of vertices and edges that form connections between the vertices. In a more formal approach, a graph G is an ordered pair of a set V of vertices and a set E of edges given as <kbd>G = (V, E)</kbd> in formal mathematical notation.</p>
<p>An example of a graph is given here:</p>
<div><img class="aligncenter size-full wp-image-962 image-border" height="182" src="img/CH_08_01.png" width="263"/></div>
<p>Let's now go through some definitions of a graph:</p>
<ul>
<li><strong>Node or vertex</strong>: A point, usually represented by a dot in a graph. The vertices or nodes are A, B, C, D, and E.</li>
<li><strong>Edge</strong>: This is a connection between two vertices. The line connecting A and B is an example of an edge.</li>
<li><strong>Loop</strong>: When an edge from a node is incident on itself, that edge forms a loop.</li>
<li><strong>Degree of a vertex</strong>: This is the number of vertices that are incident on a given vertex. The degree of vertex B is <kbd>4</kbd>.</li>
<li><strong>Adjacency</strong>: This refers to the connection(s) between a node and its neighbor. The node C is adjacent to node A because there is an edge between them.</li>
<li><strong>Path</strong>: A sequence of vertices where each adjacent pair is connected by an edge.</li>
</ul>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Directed and undirected graphs</h1>
            

            
                
<p>Graphs can be classified based on whether they are undirected or directed. An undirected graph simply represents edges as lines between the nodes. There is no additional information about the relationship between the nodes than the fact that they are connected:</p>
<div><img class="image-border aligncenter" height="135" src="img/image_08_001.jpg" width="142"/></div>
<p>In a directed graph, the edges provide orientation in addition to connecting nodes. That is, the edges, which will be drawn as lines with an arrow, will point in which direction the edge connects the two nodes:</p>
<div><img class="aligncenter size-full wp-image-963 image-border" height="223" src="img/CH_08_06.png" width="330"/></div>
<p>The arrow of an edge determines the flow of direction. One can only move from <strong>A</strong> to <strong>B</strong> in the preceding diagram. Not <strong>B</strong> to <strong>A</strong>.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Weighted graphs</h1>
            

            
                
<p>A weighted graph adds a bit of extra information to the edges. This can be a numerical value that indicates something. Let's say, for example, that the following graph indicates different ways to get from point <strong>A</strong> to point <strong>D</strong>. You can either go straight from <strong>A</strong> to <strong>D</strong>, or choose to pass through <strong>B</strong> and <strong>C</strong>. Associated with each edge is the amount of time in minutes the journey to the next node will take:</p>
<div><img class="image-border aligncenter" height="181" src="img/image_08_002.jpg" width="202"/></div>
<p>Perhaps the journey <strong>AD</strong> would require you to ride a bike (or walk). <strong>B</strong> and <strong>C</strong> might represent bus stops. At <strong>B</strong> you would have to change to a different bus. Finally, <strong>CD</strong> may be a short walk to reach <strong>D</strong>.</p>
<p>In this example, <strong>AD</strong> and <strong>ABCD</strong> represent two different paths. <strong>A</strong> path is simply a sequence of edges that you <em>pass through</em> between two nodes. Following these paths, you see that the total journey <strong>AD</strong> takes <strong>40</strong> minutes, whereas the journey <strong>ABCD</strong> takes <strong>25</strong> minutes. If your only concern is time, you would be better off traveling along <strong>ABCD</strong>, even with the added inconvenience of changing buses.</p>
<p>The fact that edges can be directed and may hold other information, such as time taken or whatever other value the move along a path is associated with, indicates something interesting. In previous data structures that we have worked with, the <em>lines</em> we have drawn between nodes have simply been connectors. Even when they had arrows pointing from a node to another, that was easy to represent in the node class by using <kbd>next</kbd> or <kbd>previous</kbd>, <kbd>parent</kbd> or <kbd>child</kbd>.</p>
<p>With graphs, it makes sense to see edges as objects just as much as nodes. Just like nodes, edges can contain extra information that is necessary to follow a particular path.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Graph representation</h1>
            

            
                
<p>Graphs can be represented in two main forms. One way is to use an adjacency matrix and the other is to use an adjacency list.</p>
<p>We shall be working with the following figure to develop both types of representation for graphs:</p>
<div><img class="aligncenter size-full wp-image-964 image-border" height="207" src="img/CH_08_02.png" width="206"/></div>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Adjacency list</h1>
            

            
                
<p>A simple list can be used to present a graph. The indices of the list will represent the nodes or vertices in the graph. At each index, the adjacent nodes to that vertex can be stored:</p>
<div><img class="aligncenter size-full wp-image-965 image-border" height="185" src="img/CH_08_03.png" width="203"/></div>
<p>The numbers in the box represent the vertices. Index <strong>0</strong> represents vertex <strong>A</strong>, with its adjacent nodes being <strong>B</strong> and <strong>C</strong>.</p>
<p>Using a list for the representation is quite restrictive because we lack the ability to directly use the vertex labels. A dictionary is therefore more suited. To represent the graph in the diagram, we can use the following statements:</p>
<pre>
    graph = dict() <br/>    graph['A'] = ['B', 'C'] <br/>    graph['B'] = ['E','A'] <br/>    graph['C'] = ['A', 'B', 'E','F'] <br/>    graph['E'] = ['B', 'C'] <br/>    graph['F'] = ['C'] 
</pre>
<p>Now we easy establish that vertex <strong>A</strong> has the adjacent vertices <strong>B</strong> and <strong>C</strong>. Vertex F has vertex <strong>C</strong> as its only neighbor.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Adjacency matrix</h1>
            

            
                
<p>Another approach by which a graph can be represented is by using an adjacency matrix. A matrix is a two-dimensional array. The idea here is to represent the cells with a 1 or 0 depending on whether two vertices are connected by an edge.</p>
<p>Given an adjacency list, it should be possible to create an adjacency matrix. A sorted list of keys of graph is required:</p>
<pre>
    matrix_elements = sorted(graph.keys()) <br/>    cols = rows = len(matrix_elements) 
</pre>
<p>The length of the keys is used to provide the dimensions of the matrix which are stored in <kbd>cols</kbd> and <kbd>rows</kbd>. These values in <kbd>cols</kbd> and <kbd>rows</kbd> are equal:</p>
<pre>
    adjacency_matrix = [[0 for x in range(rows)] for y in range(cols)] <br/>    edges_list = [] 
</pre>
<p>We then set up a <kbd>cols</kbd> by <kbd>rows</kbd> array, filling it with zeros. The <kbd>edges_list</kbd> variable will store the tuples that form the edges of in the graph. For example, an edge between node A and B will be stored as (A, B).</p>
<p>The multidimensional array is filled using a nested for loop:</p>
<pre>
    for key in matrix_elements: <br/>        for neighbor in graph[key]: <br/>            edges_list.append((key,neighbor)) 
</pre>
<p>The neighbors of a vertex are obtained by <kbd>graph[key]</kbd>. The key in combination with the <kbd>neighbor</kbd> is then used to create the tuple stored in <kbd>edges_list</kbd>.</p>
<p>The output of the iteration is as follows:</p>
<pre>
<strong>&gt;&gt;&gt; [('A', 'B'), ('A', 'C'), ('B', 'E'), ('B', 'A'), ('C', 'A'), <br/>     ('C', 'B'), ('C', 'E'), ('C', 'F'), ('E', 'B'), ('E', 'C'), <br/>     ('F', 'C')]</strong>
</pre>
<p>What needs to be done now is to fill the our multidimensional array by using 1 to mark the presence of an edge with the line <kbd>adjacency_matrix[index_of_first_vertex][index_of_second_vertex] = 1</kbd>:</p>
<pre>
    for edge in edges_list: <br/>        index_of_first_vertex = matrix_elements.index(edge[0]) <br/>        index_of_second_vertex = matrix_elements.index(edge[1]) <br/>        adjacecy_matrix[index_of_first_vertex][index_of_second_vertex] = 1 
</pre>
<p>The <kbd>matrix_elements</kbd> array has its <kbd>rows</kbd> and <kbd>cols</kbd> starting from A through to E with the indices 0 through to 5. The <kbd>for</kbd> loop iterates through our list of tuples and uses the <kbd>index</kbd> method to get the corresponding index where an edge is to be stored.</p>
<p>The adjacency matrix produced looks like so:</p>
<pre>
<strong>&gt;&gt;&gt;</strong><br/><strong>[0, 1, 1, 0, 0]</strong><br/><strong>[1, 0, 0, 1, 0]</strong><br/><strong>[1, 1, 0, 1, 1]</strong><br/><strong>[0, 1, 1, 0, 0]</strong><br/><strong>[0, 0, 1, 0, 0]</strong>
</pre>
<p>At column 1 and row 1, the 0 there represents the absence of an edge between A and A. On column 2 and row 3, there is an edge between C and B.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Graph traversal</h1>
            

            
                
<p>Since graphs don't necessarily have an ordered structure, traversing a graph can be more involving. Traversal normally involves keeping track of which nodes or vertices have already been visited and which ones have not. A common strategy is to follow a path until a dead end is reached, then walking back up until there is a point where there is an alternative path. We can also iteratively move from one node to another in order to traverse the full graph or part of it. In the next section, we will discuss breadth and depth-first search algorithms for graph traversal.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Breadth-first search</h1>
            

            
                
<p>The breadth-first search algorithm starts at a node, chooses that node or vertex as its root node, and visits the neighboring nodes, after which it explores neighbors on the next level of the graph.</p>
<p>Consider the following diagram as a graph:</p>
<div><img class="aligncenter size-full wp-image-966 image-border" height="194" src="img/CH_08_05.png" width="213"/></div>
<p>The diagram is an example of an undirected graph. We continue to use this type of graph to help make explanation easy without being too verbose.</p>
<p>The adjacency list for the graph is as follows:</p>
<pre>
    graph = dict() <br/>    graph['A'] = ['B', 'G', 'D'] <br/>    graph['B'] = ['A', 'F', 'E'] <br/>    graph['C'] = ['F', 'H'] <br/>    graph['D'] = ['F', 'A'] <br/>    graph['E'] = ['B', 'G'] <br/>    graph['F'] = ['B', 'D', 'C'] <br/>    graph['G'] = ['A', 'E'] <br/>    graph['H'] = ['C'] 
</pre>
<p>In trying to traverse this graph breadth first, we will employ the use of a queue. The algorithm creates a list to store the nodes that have been visited as the traversal process proceeds. We shall start our traversal from node A.</p>
<p>Node A is queued and added to the list of visited nodes. Afterward, we use a <kbd>while</kbd> loop to effect traversal of the graph. In the <kbd>while</kbd> loop, node A is dequeued. Its unvisited adjacent nodes B, G, and D are sorted in alphabetical order and queued up. The queue will now contain the nodes B, D, and G. These nodes are also added to the list of visited nodes. At this point, we start another iteration of the <kbd>while</kbd> loop because the queue is not empty, which also means we are not really done with the traversal.</p>
<p>Node B is dequeued. Out of its adjacent nodes A, F, and E, node A has already been visited. Therefore, we only enqueue the nodes E and F in alphabetical order. Nodes E and F are then added to the list of visited nodes.</p>
<p>Our queue now holds the following nodes at this point: D, G, E, and F. The list of visited nodes contains A, B, D, G, E, F.</p>
<p>Node D is dequeued but all of its adjacent nodes have been visited so we simply dequeue it. The next node at the front of the queue is G. We dequeue node G but we also find out that all its adjacent nodes have been visited because they are in the list of visited nodes. Node G is also dequeued. We dequeue node E too because all of its nodes have been visited. The only node in the queue now is node F.</p>
<p>Node F is dequeued and we realize that out of its adjacent nodes B, D, and C, only node C has not been visited. We then enqueue node C and add it to the list of visited nodes. Node C is dequeued. Node C has the adjacent nodes F and H but F has already been visited, leaving node H. Node H is enqueued and added to the list of visited nodes.</p>
<p>Finally, the last iteration of the <kbd>while</kbd> loop will lead to node H being dequeued. Its only adjacent node C has already been visited. Once the queue is completely empty, the loop breaks.</p>
<p>The output of the traversing the graph in the diagram is A, B, D, G, E, F, C, H.</p>
<p>The code for a breadth-first search is given as follows:</p>
<pre>
    from collections import deque <br/><br/>    def breadth_first_search(graph, root): <br/>        visited_vertices = list() <br/>        graph_queue = deque([root]) <br/>        visited_vertices.append(root) <br/>        node = root <br/><br/>        while len(graph_queue) &gt; 0: <br/>            node = graph_queue.popleft() <br/>            adj_nodes = graph[node] <br/><br/>            remaining_elements = <br/>                set(adj_nodes).difference(set(visited_vertices)) <br/>            if len(remaining_elements) &gt; 0: <br/>                for elem in sorted(remaining_elements): <br/>                    visited_vertices.append(elem) <br/>                    graph_queue.append(elem) <br/><br/>        return visited_vertices 
</pre>
<p>When we want to find out whether a set of nodes are in the list of visited nodes, we use the statement <kbd>remaining_elements = set(adj_nodes).difference(set(visited_vertices))</kbd>. This uses the set object's difference method to find the nodes that are in <kbd>adj_nodes</kbd> but not in <kbd>visited_vertices</kbd>.</p>
<p>In the worst-case scenario, each vertex or node and edge will be traversed, thus the time complexity of the algorithm is <kbd>O(|V| + |E|)</kbd>, where <kbd>|V|</kbd> is the number of vertices or nodes while <kbd>|E|</kbd> is the number of edges in the graph.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Depth-first search</h1>
            

            
                
<p>As the name suggests, this algorithm traverses the depth of any particular path in the graph before traversing its breadth. As such, child nodes are visited first before sibling nodes. It works on finite graphs and requires the use of a stack to maintain the state of the algorithm:</p>
<pre>
    def depth_first_search(graph, root): <br/>        visited_vertices = list() <br/>        graph_stack = list() <br/><br/>        graph_stack.append(root) <br/>        node = root 
</pre>
<p>The algorithm begins by creating a list to store the visited nodes. The <kbd>graph_stack</kbd> stack variable is used to aid the traversal process. For continuity's sake, we are using a regular Python list as a stack.</p>
<p>The starting node, called <kbd>root</kbd>, is passed with the graph's adjacency matrix, graph. <kbd>root</kbd> is pushed onto the stack. <kbd>node = root</kbd> holds the first node in the stack:</p>
<pre>
        while len(graph_stack) &gt; 0: <br/><br/>            if node not in visited_vertices: <br/>                visited_vertices.append(node) <br/><br/>            adj_nodes = graph[node] <br/><br/><br/>            if set(adj_nodes).issubset(set(visited_vertices)): <br/>                graph_stack.pop() <br/>            if len(graph_stack) &gt; 0: <br/>                node = graph_stack[-1] <br/>                continue <br/>            else: <br/>                remaining_elements = <br/>                set(adj_nodes).difference(set(visited_vertices)) <br/><br/><br/>            first_adj_node = sorted(remaining_elements)[0] <br/>            graph_stack.append(first_adj_node) <br/>            node = first_adj_node <br/>                return visited_vertices 
</pre>
<p>The body of the <kbd>while</kbd> loop will be executed provided the stack is not empty. If <kbd>node</kbd> is not in the list of visited nodes, we add it. All adjacent nodes to <kbd>node</kbd> are collected by <kbd>adj_nodes = graph[node]</kbd>. If all the adjacent nodes have been visited, we pop that node from the stack and set <kbd>node</kbd> to <kbd>graph_stack[-1]</kbd>. <kbd>graph_stack[-1]</kbd> is the top node on the stack. The <kbd>continue</kbd> statement jumps back to the beginning of the while loop's test condition.</p>
<p>If, on the other hand, not all the adjacent nodes have been visited, the nodes that are yet to be visited are obtained by finding the difference between the <kbd>adj_nodes</kbd> and <kbd>visited_vertices</kbd> with the statement <kbd>remaining_elements = set(adj_nodes).difference(set(visited_vertices))</kbd>.</p>
<p>The first item within <kbd>sorted(remaining_elements)</kbd> is assigned to <kbd>first_adj_node</kbd>, and pushed onto the stack. We then point the top of the stack to this node.</p>
<p>When the <kbd>while</kbd> loop exists, we will return the <kbd>visited_vertices</kbd>.</p>
<p>Dry running the algorithm will prove useful. Consider the following graph:</p>
<div><img class="aligncenter size-full wp-image-967 image-border" height="191" src="img/CH_08_04.png" width="242"/></div>
<p>The adjacency list of such a graph is given as follows:</p>
<pre>
    graph = dict() <br/>    graph['A'] = ['B', 'S'] <br/>    graph['B'] = ['A'] <br/>    graph['S'] = ['A','G','C'] <br/>    graph['D'] = ['C'] <br/>    graph['G'] = ['S','F','H'] <br/>    graph['H'] = ['G','E'] <br/>    graph['E'] = ['C','H'] <br/>    graph['F'] = ['C','G'] <br/>    graph['C'] = ['D','S','E','F'] 
</pre>
<p>Node A is chosen as our beginning node. Node A is pushed onto the stack and added to the <kbd>visisted_vertices</kbd> list. In doing so, we mark it as having been visited. The stack <kbd>graph_stack</kbd> is implemented with a simple Python list. Our stack now has A as its only element. We examine node A's adjacent nodes B and S. To test whether all the adjacent nodes of A have been visited, we use the if statement:</p>
<pre>
    if set(adj_nodes).issubset(set(visited_vertices)): <br/>        graph_stack.pop() <br/>        if len(graph_stack) &gt; 0: <br/>            node = graph_stack[-1] <br/>        continue 
</pre>
<p>If all the nodes have been visited, we pop the top of the stack. If the stack <kbd>graph_stack</kbd> is not empty, we assign the node on top of the stack to <kbd>node</kbd> and start the beginning of another execution of the body of the <kbd>while</kbd> loop. The statement <kbd>set(adj_nodes).issubset(set(visited_vertices))</kbd> will evaluate to <kbd>True</kbd> if all the nodes in <kbd>adj_nodes</kbd> are a subset of <kbd>visited_vertices</kbd>. If the if statement fails, it means that some nodes remain to be visited. We obtain that list of nodes with <kbd>remaining_elements = set(adj_nodes).difference(set(visited_vertices))</kbd>.</p>
<p>From the diagram, nodes <strong>B</strong> and <strong>S</strong> will be stored in <kbd>remaining_elements</kbd>. We will access the list in alphabetical order:</p>
<pre>
    first_adj_node = sorted(remaining_elements)[0] <br/>    graph_stack.append(first_adj_node) <br/>    node = first_adj_node 
</pre>
<p>We sort <kbd>remaining_elements</kbd> and return the first node to <kbd>first_adj_node</kbd>. This will return B. We push node B onto the stack by appending it to the <kbd>graph_stack</kbd>. We prepare node B for access by assigning it to <kbd>node</kbd>.</p>
<p>On the next iteration of the <kbd>while</kbd> loop, we add node B to the list of <kbd>visited nodes</kbd>. We discover that the only adjacent node to B, which is A, has already been visited. Because all the adjacent nodes of B have been visited, we pop it off the stack, leaving node A as the only element on the stack. We return to node A and examine whether all of its adjacent nodes have been visited. The node A now has S as the only unvisited node. We push S to the stack and begin the whole process again.</p>
<p>The output of the traversal is A-B-S-C-D-E-H-G-F.</p>
<p>Depth-first searches find application in solving maze problems, finding connected components, and finding the bridges of a graph, among others.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Other useful graph methods</h1>
            

            
                
<p>Very often, you are concerned with finding a path between two nodes. You may also want to find all the paths between nodes. Another useful method would be to find the shortest path between nodes. In an unweighted graph, this would simply be the path with the lowest number of edges between them. In a weighted graph, as you have seen, this could involve calculating the total weight of passing through a set of edges.</p>
<p>Of course, in a different situation, you may want to find the longest or shortest path.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Priority queues and heaps</h1>
            

            
                
<p>A priority queue is basically a type of queue that will always return items in order of priority. This priority could be, for example, that the lowest item is always popped off first. Although it is called a queue, priority queues are often implemented using a heap, since it is very efficient for this purpose.</p>
<p>Consider that, in a store, customers queue in a line where service is only rendered at the front of the queue. Each customer will spend some time in the queue to get served. If the waiting times for the customers in the queue are 4, 30, 2, and 1, then the average time spent in the queue becomes <kbd>(4 + 34 + 36 + 37)/4</kbd>, which is <kbd>27.75</kbd>. However, if we change the order of service such that customers with the least amount of waiting time are served first, then we obtain a different average waiting time. In doing so, we calculate our new average waiting time by <kbd>(1 + 3 + 7 + 37)/4</kbd>, which now equals <kbd>12</kbd>, a better average waiting time. Clearly, there is merit to serving the customers from the least waiting time upward. This method of selecting the next item by priority or some other criterion is the basis for creating priority queues.</p>
<p>A heap is a data structure that satisfies the heap property. The heap property states that there must be a certain relationship between a parent node and its child nodes. This property must apply through the entire heap.</p>
<p>In a min heap, the relationship between parent and children is that the parent must always be less than or equal to its children. As a consequence of this, the lowest element in the heap must be the root node.</p>
<p>In a max heap, on the other hand, the parent is greater than or equal to its child or its children. It follows from this that the largest value makes up the root node.</p>
<p>As you can see from what we just mentioned, heaps are trees and, to be more specific, binary trees.</p>
<p>Although we are going to use a binary tree, we will actually use a list to represent it. This is possible because the heap will store a complete binary tree. A complete binary tree is one in which each row must be fully filled before starting to fill the next row:</p>
<div><img class="image-border aligncenter" height="212" src="img/image_08_003.jpg" width="293"/></div>
<p>To make the math with indexes easier, we are going to leave the first item in the list (index 0) empty. After that, we place the tree nodes into the list, from top to bottom, left to right:</p>
<div><img class="image-border" height="273" src="img/image_08_004.jpg" width="289"/></div>
<p>If you observe carefully, you will notice that you can retrieve the children of any node n very easily. The left child is located at <kbd>2n</kbd> and the right child is located at <kbd>2n + 1</kbd>. This will always hold true.</p>
<p>We are going to look at a min heap implementation. It shouldn't be difficult to reverse the logic in order to get a max heap:</p>
<pre>
     class Heap: <br/>        def __init__(self): <br/>            self.heap = [0] <br/>            self.size = 0 
</pre>
<p>We initialize our heap list with a zero to represent the dummy first element (remember that we are only doing this to make the math simpler). We also create a variable to hold the size of the heap. This would not be necessary as such, since we could check the size of the list, but we would always have to remember to reduce it by one. So we chose to keep a separate variable instead.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Inserting</h1>
            

            
                
<p>Inserting an item is very simple in itself. We add the new element to the end of the list (which we understand to be the bottom of the tree). Then we increment the size of the heap by one.</p>
<p>But after each insert, we need to float the new element up if needed. Bear in mind that the lowest element in the min heap needs to be the root element. We first create a helper method called <kbd>float</kbd> that takes care of this. Let us look at how it is meant to behave. Imagine that we have the following heap and want to insert the value <kbd>2</kbd>:</p>
<div><img class="image-border aligncenter" height="152" src="img/image_08_005.jpg" width="268"/></div>
<p>The new element has occupied the last slot in the third row or level. Its index value is <strong>7</strong>. Now we compare that value with its parent. The parent is at index <kbd>7/2 = 3</kbd> (integer division). That element holds <strong>6</strong> so we swap the <strong>2</strong>:</p>
<div><img class="image-border centeralign" height="147" src="img/image_08_006.jpg" width="252"/></div>
<p>Our new element has been swapped and moved up to index <strong>3</strong>. We have not reached the top of the heap yet (<kbd>3 / 2 &gt; 0</kbd>), so we continue. The new parent of our element is at index <kbd>3/2 = 1</kbd>. So we compare and, if necessary, swap again:</p>
<div><img class="image-border centeralign" height="155" src="img/image_08_007.jpg" width="239"/></div>
<p>After the final swap, we are left with the heap looking as follows. Notice how it adheres to the definition of a heap:</p>
<div><img class="image-border aligncenter" height="162" src="img/image_08_008.jpg" width="261"/></div>
<p>Here follows an implementation of what we have just described:</p>
<pre>
    def float(self, k): 
</pre>
<p>We are going to loop until we have reached the root node so that we can keep floating the element up as high as it needs to go. Since we are using integer division, as soon as we get below 2, the loop will break out:</p>
<pre>
        while k // 2 &gt; 0: 
</pre>
<p>Compare parent and child. If the parent is greater than the child, swap the two values:</p>
<pre>
        if self.heap[k] &lt; self.heap[k//2]: <br/>            self.heap[k], self.heap[k//2] = self.heap[k//2], <br/>            self.heap[k] 
</pre>
<p>Finally, let's not forget to move up the tree:</p>
<pre>
        k //= 2 
</pre>
<p>This method ensures that the elements are ordered properly. Now we just need to call this from our <kbd>insert</kbd> method:</p>
<pre>
    def insert(self, item): <br/>        self.heap.append(item) <br/>        self.size += 1 <br/>        self.float(self.size) 
</pre>
<p>Notice the last line in insert calls the <kbd>float()</kbd> method to reorganize the heap as necessary.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Pop</h1>
            

            
                
<p>Just like insert, <kbd>pop()</kbd> is by itself a simple operation. We remove the root node and decrement the size of the heap by one. However, once the root has been popped off, we need a new root node.</p>
<p>To make this as simple as possible, we just take the last item in the list and make it the new root. That is, we move it to the beginning of the list. But now we might not have the lowest element at the top of the heap, so we perform the opposite of the float operation: we let the new root node sink down as required.</p>
<p>As we did with insert, let us have a look at how the whole operation is meant to work on an existing heap. Imagine the following heap. We pop off the <kbd>root</kbd> element, leaving the heap temporarily rootless:</p>
<div><img class="image-border centeralign" height="135" src="img/image_08_009.jpg" width="217"/></div>
<p>Since we cannot have a rootless heap, we need to fill this slot with something. If we choose to move up one of the children, we will have to figure out how to rebalance the entire tree structure. So instead, we do something really interesting. We move up the very last element in the list to fill the position of the <kbd>root</kbd> element:</p>
<div><img class="image-border" height="146" src="img/image_08_010.jpg" width="226"/></div>
<p>Now this element clearly is not the lowest in the heap. This is where we begin to sink it down. First we need to determine where to sink it down. We compare the two children, so that the lowest element will be the one to float up as the root sinks down:</p>
<div><img class="image-border centeralign" height="75" src="img/image_08_011.jpg" width="207"/></div>
<p>The right child is clearly less. Its index is <strong>3</strong>, which represents the root index <kbd>* 2 + 1</kbd>. We go ahead and compare our new root node with the value at this index:</p>
<div><img class="image-border aligncenter" height="169" src="img/image_08_012.jpg" width="246"/></div>
<p>Now our node has jumped down to index <strong>3</strong>. We need to compare it to the lesser of its children. However, now we only have one child, so we don't need to worry about which child to compare against (for a min heap, it is always the lesser child):</p>
<div><img class="image-border centeralign" height="155" src="img/image_08_013.jpg" width="253"/></div>
<p>There is no need to swap here. Since there are no more rows either, we are done. Notice again how, after the <kbd>sink()</kbd> operation is completed, our heap adheres to the definition of a heap.</p>
<p>Now we can begin implementing this. Before we do the <kbd>sink()</kbd> method itself, notice how we need to determine which of the children to compare our parent node against. Well, let us put that selection in its own little method, just to make the code look a little simpler:</p>
<pre>
    def minindex(self, k): 
</pre>
<p>We may get beyond the end of the list, in which case we return the index of the left child:</p>
<pre>
        if k * 2 + 1 &gt; self.size: <br/>            return k * 2 
</pre>
<p>Otherwise, we simply return the index of the lesser of the two children:</p>
<pre>
        elif self.heap[k*2] &lt; self.heap[k*2+1]: <br/>            return k * 2 <br/>        else: <br/>            return k * 2 + 1 
</pre>
<p>Now we can create the <kbd>sink</kbd> function:</p>
<pre>
    def sink(self, k): 
</pre>
<p>As before, we are going to loop so that we can sink our element down as far as is needed:</p>
<pre>
        while k * 2 &lt;= self.size: 
</pre>
<p>Next we need to know which of the left or the right child to compare against. This is where we make use of the <kbd>minindex()</kbd> function:</p>
<pre>
            mi = self.minindex(k) 
</pre>
<p>As we did in the <kbd>float()</kbd> method, we compare parent and child to see whether we need to swap:</p>
<pre>
            if self.heap[k] &gt; self.heap[mi]: <br/>                self.heap[k], self.heap[mi] = self.heap[mi], <br/>                self.heap[k] 
</pre>
<p>And we need to make sure that we move down the tree so that we don't get stuck in a loop:</p>
<pre>
            k = mi 
</pre>
<p>The only thing remaining now is to implement <kbd>pop()</kbd> itself. This is very straightforward as the grunt work is performed by the <kbd>sink()</kbd> method:</p>
<pre>
    def pop(self): <br/>        item = self.heap[1] <br/>        self.heap[1] = self.heap[self.size] <br/>        self.size -= 1 <br/>        self.heap.pop() <br/>        self.sink(1) <br/>        return item 
</pre>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Testing the heap</h1>
            

            
                
<p>Now we just need some code to test the heap. We begin by creating our heap and inserting some data:</p>
<pre>
    h = Heap() <br/>    for i in (4, 8, 7, 2, 9, 10, 5, 1, 3, 6): <br/>        h.insert(i) 
</pre>
<p>We can print the heap list, just to inspect how the elements are ordered. If you redraw this as a tree structure, you should notice that it meets the required properties of a heap:</p>
<pre>
    print(h.heap) 
</pre>
<p>Now we will pop off the items, one at a time. Notice how the items come out in a sorted order, from lowest to highest. Also notice how the heap list changes after each pop. It is a good idea to take out a pen and paper and to redraw this list as a tree after each pop, to fully understand how the <kbd>sink()</kbd> method works:</p>
<pre>
    for i in range(10): <br/>        n = h.pop() <br/>        print(n) <br/>        print(h.heap) 
</pre>
<p>In the chapter on sorting algorithms, we will reorganize the code for the heap sort algorithm.</p>
<p>Once you have the min heap working properly and understand how it works, it should be a simple task to implement a max heap. All you have to do is to reverse the logic.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Selection algorithms</h1>
            

            
                
<p>Selection algorithms fall under a class of algorithms that seek to answer the problem of finding the ith-smallest element in a list. When a list is sorted in ascending order, the first element in the list will be the smallest item in the list. The second element in the list will be the second-smallest element in the list. The last element in the list will be the last-smallest element in the list but that will also qualify as the largest element in the list.</p>
<p>In creating the heap data structure, we have come to the understanding that a call to the <kbd>pop</kbd> method will return the smallest element in the heap. The first element to pop off a min heap is the first-smallest element in the list. Similarly, the seventh element to be popped off the min heap will be the seventh-smallest element in the list. Therefore, to find the ith-smallest element in a list will require us to pop the heap <em>i</em> number of times. That is a very simple and efficient way of finding the ith-smallest element in a list.</p>
<p>But in <a href="8523afdb-a3e7-4ab8-b8a7-be7278a1c735.xhtml" target="_blank">Chapter 11</a>, <em>Selection Algorithms</em>, we will study another approach by which we can find the ith-smallest element in a list.</p>
<p>Selection algorithms have applications in filtering out noisy data, finding the median, smallest, and largest elements in a list, and can even be applied in computer chess programs.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Summary</h1>
            

            
                
<p>Graphs and heaps have been treated in this chapter. We looked at ways to represent a graph in Python using lists and dictionaries. In order to traverse the graph, we looked at breadth-first searches and depth-first searches.</p>
<p>We then switched our attention to heaps and priority queues to understand their implementation. The chapter ended with using the concept of a heap to find the ith-smallest element in a list.</p>
<p>The subject of graphs is very complicated and just one chapter will not do justice to it. The journey with nodes will end with this chapter. The next chapter will usher us into the arena of searching and the various means by which we can efficiently search for items in lists.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    </body></html>