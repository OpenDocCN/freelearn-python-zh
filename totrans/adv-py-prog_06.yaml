- en: '*Chapter 5*: Exploring Compilers'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is a mature and widely used language, and there is great interest in
    improving its performance by compiling functions and methods directly to machine
    code rather than executing instructions in the interpreter. We have already seen
    a compiler example in [*Chapter 4*](B17499_04_Final_SS_ePub.xhtml#_idTextAnchor068),
    *C Performance with Cython*, where Python code is enhanced with types, compiled
    to efficient C code, and the interpreter calls are sidestepped.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore two projects, Numba and PyPy, that approach
    compilation in a slightly different way. **Numba** is a library designed to compile
    small functions on the fly. Instead of transforming Python code to C, Numba analyzes
    and compiles Python functions directly to machine code. **PyPy** is a replacement
    interpreter that works by analyzing the code at runtime and optimizing the slow
    loops automatically.
  prefs: []
  type: TYPE_NORMAL
- en: These tools are called **Just-In-Time** (**JIT**) compilers because the compilation
    is performed at runtime rather than before running the code (in other cases, the
    compiler is called **Ahead-Of-Time** or **AOT**).
  prefs: []
  type: TYPE_NORMAL
- en: 'The list of topics to be covered in this chapter is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Numba
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The PyPy project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other interesting projects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, Numba and PyPy offer us flexibility in leveraging JIT compilation to
    accelerate our programs. This chapter adds another instrument to our toolbox for
    improving the speed of Python applications.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code files for this chapter can be accessed through this link: [https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter05](https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter05).'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Numba
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Numba was started in 2012 by Travis Oliphant, the original author of NumPy,
    as a library for compiling individual Python functions at runtime using the **Low-Level
    Virtual Machine** (**LLVM**) toolchain.
  prefs: []
  type: TYPE_NORMAL
- en: LLVM is a set of tools designed to write compilers. LLVM is language-agnostic
    and is used to write compilers for a wide range of languages (an important example
    is the Clang compiler). One of the core aspects of LLVM is the intermediate representation
    (the LLVM IR), a very low-level, platform-agnostic language-like assembly, that
    can be compiled to machine code for the specific target platform.
  prefs: []
  type: TYPE_NORMAL
- en: Numba works by inspecting Python functions and compiling them, using LLVM, to
    the IR. As we saw in the last chapter, speed gains can be obtained when we introduce
    types for variables and functions. Numba implements clever algorithms to guess
    the types (this is called **type inference**) and compiles type-aware versions
    of the functions for fast execution.
  prefs: []
  type: TYPE_NORMAL
- en: Note that Numba was developed to improve the performance of numerical code.
    The development efforts often prioritize the optimization of applications that
    intensively use NumPy arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Numba is evolving fast and can have substantial improvements between releases
    and, sometimes, backward-incompatible changes. To keep up, ensure that you refer
    to the release notes for each version. In the rest of this chapter, we will use
    Numba version 0.53.1; ensure that you install the correct version to avoid any
    error by using `pip install numba==0.53.1`. The complete code examples in this
    chapter can be found in the `Numba.ipynb` notebook.
  prefs: []
  type: TYPE_NORMAL
- en: For the rest of this section, we will explore different aspects of Numba usage
    such as type specializations and JIT classes, as well as its limitations. First,
    we will discuss how to integrate Numba into a Python program via decorators.
  prefs: []
  type: TYPE_NORMAL
- en: Using Numba decorators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In most cases, the way we point Numba to specific Python functions is via decorators.
    Let''s see how to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first example, we will implement a function that calculates the sum of
    the squares of an array. The function definition is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To set up this function with Numba, it is sufficient to apply the `nb.jit`
    decorator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `nb.jit` decorator won't do much when applied. However, when the function
    is invoked for the first time, Numba will detect the type of the input argument,
    `a`, and compile a specialized, performant version of the original function.
  prefs: []
  type: TYPE_NORMAL
- en: 'To measure the performance gain obtained by the Numba compiler, we can compare
    the timings of the original and the specialized functions. The original, undecorated
    function can be easily accessed through the `py_func` attribute. The timings for
    the two functions are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: From the previous code, you can see how the Numba version (12.8 µs) is one order
    of magnitude faster than the Python version (4.3 ms).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also compare how this implementation stacks up against NumPy standard
    operators:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this case, the Numba compiled function is marginally slower than NumPy vectorized
    operations, although this difference might change across different runs.
  prefs: []
  type: TYPE_NORMAL
- en: Considering that all we needed to do was apply a simple decorator to obtain
    an incredible speed up over different data types, it's no wonder that what Numba
    does looks like magic. In the following sections, we will dig deeper to understand
    how Numba works and evaluate the benefits and limitations of the Numba compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Type specializations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As shown earlier, the `nb.jit` decorator works by compiling a specialized version
    of the function once it encounters a new argument type. To better understand how
    this works, we can inspect the decorated function in the `sum_sq` example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Numba exposes the specialized types using the `signatures` attribute. Right
    after the `sum_sq` definition, we can inspect the available specialization by
    accessing `sum_sq.signatures`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we call this function with a specific argument, for instance, an array of
    `float64` numbers, we can see how Numba compiles a specialized version on the
    fly. If we also apply the function on an array of `float32`, we can see how a
    new entry is added to the `sum_sq.signatures` list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It is possible to explicitly compile the function for certain types by passing
    a signature to the `nb.jit` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'An individual signature can be passed as a tuple that contains the type we
    would like to accept. Numba provides a great variety of types that can be found
    in the `nb.types` module, and they are also available in the top-level `nb` namespace.
    If we want to specify an array of a specific type, we can use the slicing operator,
    `[:]`, on the type itself. In the following example, we demonstrate how to declare
    a function that takes an array of `float64` as its only argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Note that when we explicitly declare a signature, we are prevented from using
    other types, as demonstrated in the following example. If we try to pass an array,
    `x`, as `float32`, Numba will raise a `TypeError` exception:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Another way to declare signatures is through type strings. For example, a function
    that takes `float64` as input and returns `float64` as output can be declared
    with the `float64(float64)` string. Array types can be declared using a `[:]`
    suffix. To put this together, we can declare a signature for our `sum_sq` function,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can also pass multiple signatures by passing a list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These APIs ensure that Numba has the correct information about what data type
    a function works with.
  prefs: []
  type: TYPE_NORMAL
- en: Object mode versus native mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have shown how Numba behaves when handling a simple function. In
    this case, Numba worked exceptionally well, and we obtained great performance
    on arrays and lists.
  prefs: []
  type: TYPE_NORMAL
- en: The degree of optimization obtainable from Numba depends on how well Numba can
    infer the variable types and how well it can translate those standard Python operations
    to fast type-specific versions. If this happens, the interpreter is sidestepped,
    and we can get performance gains such as those of Cython.
  prefs: []
  type: TYPE_NORMAL
- en: When Numba cannot infer variable types, it will still try and compile the code,
    reverting to the interpreter when the types can't be determined or when certain
    operations are unsupported. In Numba, this is called **object mode** and contrasts
    with the interpreter-free scenario called **native mode**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Numba provides a function called `inspect_types` that helps understand how
    effective the type inference was and which operations were optimized. Let''s see
    how to use the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, we can look at the types inferred for our `sum_sq` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When this function is called, Numba will print the type inferred for each specialized
    version of the function. The output consists of blocks that contain information
    about variables and types associated with them. For example, we can examine the
    `N = len(a)` line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For each line, Numba prints a thorough description of variables, functions,
    and intermediate results. In the preceding example, you can see (on the second
    line) that the `a` argument is correctly identified as an array of `float64` numbers.
    At `LINE 4`, the input and return type of the `len` function is also correctly
    identified (and likely optimized) as taking an array of `float64` numbers and
    returning `int64`.
  prefs: []
  type: TYPE_NORMAL
- en: If you scroll through the output, you can see how all the variables have a well-defined
    type. Therefore, we can be certain that Numba is able to compile the code quite
    efficiently. This form of compilation is called **native mode**.
  prefs: []
  type: TYPE_NORMAL
- en: As a counterexample, we can see what happens if we write a function with unsupported
    operations. For example, as of version 0.53.1, Numba has limited support for string
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can implement a function that concatenates a series of strings and compiles
    it as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can invoke this function with a list of strings and inspect the types:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Numba will return the output of the function for the `reflected list (unicode
    type)` type. We can, for instance, examine how the third line gets inferred. The
    output of `concatenate.inspect_types()` is reproduced here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can see that this time, each variable, or function is of the `unicode`
    or `str` type. Once again by timing the original and compiled function, we can
    note a significant improvement in performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This is because the Numba compiler is not able to optimize the code and adds
    some extra overhead to the function call.
  prefs: []
  type: TYPE_NORMAL
- en: An Equivalent Decorator
  prefs: []
  type: TYPE_NORMAL
- en: Note that from version 0.12, the more concise `@nb.njit` decorator could be
    used instead.
  prefs: []
  type: TYPE_NORMAL
- en: Numba and NumPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Numba was originally developed to easily increase the performance of code that
    uses NumPy arrays. Currently, many NumPy features are implemented efficiently
    by the compiler. Here, we will see how to combine the two tools to achieve even
    better performance for universal functions.
  prefs: []
  type: TYPE_NORMAL
- en: Universal functions with Numba
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Universal functions are special functions defined in NumPy that can operate
    on arrays of different sizes and shapes according to the broadcasting rules. One
    of the best features of Numba is the implementation of fast `ufunc` instances.
  prefs: []
  type: TYPE_NORMAL
- en: We have already seen some `ufunc` examples in [*Chapter 3*](B17499_03_Final_SS_ePub.xhtml#_idTextAnchor047),
    *Fast Array Operations with NumPy, Pandas, and Xarray*. For instance, the `np.log`
    function is a `ufunc` instance because it can accept scalars and arrays of different
    sizes and shapes. Also, universal functions that take multiple arguments still
    work according to the broadcasting rules. Examples of universal functions that
    take multiple arguments are `np.sum` and `np.difference`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Universal functions can be defined in standard NumPy by implementing the scalar
    version and using the `np.vectorize` function to enhance the function with the
    broadcasting feature. As an example, let''s see how to write the *Cantor pairing
    function*:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A pairing function is a function that encodes two natural numbers into a single
    natural number so that you can easily interconvert between the two representations.
    The Cantor pairing function can be written as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As already mentioned, it is possible to create a `ufunc` instance in pure Python
    using the `np.vectorized` decorator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Except for the convenience, defining universal functions in pure Python is not
    very useful, as it requires a lot of function calls affected by interpreter overhead.
    For this reason, `ufunc` implementation is usually done in C or Cython, but Numba
    beats all these methods with its convenience.
  prefs: []
  type: TYPE_NORMAL
- en: All that is needed in order to perform the conversion is to use the equivalent
    decorator, `nb.vectorize`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can compare the speed of the standard `np.vectorized` version, which, in
    the following code, is called `cantor_py`, and the same function is implemented
    using standard NumPy operations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can see how the Numba version beats all the other options by a large margin!
    Numba works extremely well because the function is simple and type inference is
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: An additional advantage of universal functions is that, since they depend on
    individual values, their evaluation can also be executed in parallel. Numba provides
    an easy way to parallelize such functions by passing the `target="cpu"` or `target="gpu"`
    keyword argument to the `nb.vectorize` decorator.
  prefs: []
  type: TYPE_NORMAL
- en: Generalized universal functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One of the main limitations of universal functions is that they must be defined
    on scalar values. A `gufunc`, is an extension of universal functions to procedures
    that take arrays. Let''s see how we can apply Numba to these functions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A classic example is matrix multiplication. In NumPy, matrix multiplication
    can be applied using the `np.matmul` function, which takes two 2D arrays and returns
    another 2D array. An example of the usage of `np.matmul` is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we saw in the previous subsection, a `ufunc` instance broadcasts the operation
    over arrays of *scalars*; its natural generalization will be to broadcast over
    an array of *arrays*. If, for instance, we take two arrays of 3 by 3 matrices,
    we will expect `np.matmul` to match the matrices and take their product.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we take two arrays containing 10 matrices of the
    `(3, 3)` shape. If we apply `np.matmul`, the product will be applied *matrix-wise*
    to obtain a new array containing the 10 results (which are, again, `(3, 3)` matrices):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The usual rules for broadcasting will work in a similar way. For example, if
    we have an array of `(3, 3)` matrices, which will have a shape of `(10, 3, 3)`,
    we can use `np.matmul` to calculate the matrix multiplication of each element
    with a single `(3, 3)` matrix. According to the broadcasting rules, we find that
    the single matrix will be repeated to obtain a size of `(10, 3, 3)`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Numba supports the implementation of efficient generalized universal functions
    through the `nb.guvectorize` decorator. As an example, we will implement a function
    that computes the Euclidean distance between two arrays as a `gufunc` instance.
    To create a `gufunc` instance, we must define a function that takes the input
    arrays, plus an output array where we will store the result of our calculation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `nb.guvectorize` decorator requires two arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: The types of input and output – two 1D arrays as input and a scalar as output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The so-called layout string, which is a representation of the input and output
    sizes; in our case, we take two arrays of the same size (denoted arbitrarily by
    `n`) and output a scalar.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following example, we can see the implementation of the `euclidean`
    function using the `nb.guvectorize` decorator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There are a few very important points to be made. Predictably, we declared the
    `a` and `b` input types as `float64[:]` because they are 1D arrays. However, what
    about the output argument? Wasn't it supposed to be a scalar? Yes, but *Numba
    treats a scalar argument as arrays of size 1*. That's why it was declared as `float64[:]`.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the layout string indicates that we have two arrays of size `(n)`
    and the output is a scalar, denoted by empty brackets – `()`. However, the array
    out will be passed as an array of size 1\. Also, note that we don't return anything
    from the function; all the output must be written in the `out` array.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: The letter `n` in the layout string is completely arbitrary; you may choose
    to use `k` or other letters of your liking. Also, if you want to combine arrays
    of uneven sizes, you can use layout strings, such as `(n, m)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our brand-new `euclidean` function can be conveniently used on arrays of different
    shapes, as shown in the following example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'How does the speed of `euclidean` compare to standard NumPy? In the following
    code, we will benchmark a NumPy vectorized version with our previously defined
    `euclidean` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The Numba version, again, beats the NumPy version by a large margin!
  prefs: []
  type: TYPE_NORMAL
- en: JIT classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As of today, Numba doesn't support the optimization of generic Python objects.
    This limitation, however, doesn't have a huge impact on numerical codes, as they
    usually involve arrays and math operations exclusively.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, certain data structures are much more naturally implemented using
    objects; therefore, Numba provides support for defining classes that can be used
    and compiled to fast native code. Bear in mind that this is one of the newest
    (and almost experimental) features, and it is extremely useful, as it allows us
    to extend Numba to support fast data structures that are not easily implemented
    with arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, we will show how to implement a simple linked list using *JIT
    classes*. A linked list can be implemented by defining a `Node` class that contains
    two fields – a value and the next item in the list. As you can see in the following
    figure, each **Node** connects to the next and holds a value, and the last **Node**
    contains a broken link, to which we assign a value of **None**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – An illustration of a linked list ](img/Figure_5.1_B17499.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – An illustration of a linked list
  prefs: []
  type: TYPE_NORMAL
- en: 'We will explore various JIT-related features in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, we can define the `Node` class as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can manage the collection of `Node` instances by creating another class,
    called `LinkedList`. This class will keep track of the head of the list (in the
    preceding figure, this corresponds to the `Node` instance and link it to the current
    head.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the following code, we develop the initialization function for `LinkedList`
    and the `LinkedList.push_back` method that inserts an element in the front of
    the list using the strategy outlined earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'For debugging purposes, we can also implement the `LinkedList.show` method
    that traverses and prints each element in the list. The method is shown in the
    following snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'At this point, we can test our `LinkedList` and see whether it behaves correctly.
    We can create an empty list, add a few elements, and print its content. Note that
    since we are pushing elements to the front of the list, the last elements inserted
    will be the first to be printed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can implement a function, `sum_list`, that returns the sum of the
    elements in the linked list. We will use this method to time differences between
    the Numba and pure Python versions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we measure the execution time of the original `sum_list` version and the
    `nb.jit` version, we see that there is not much difference. The reason is that
    Numba cannot infer the type of classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can improve the performance of `sum_list` by compiling the `Node` and `LinkedList`
    classes using the `nb.jitclass` decorator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `nb.jitclass` decorator takes a single argument that contains the attribute
    types. In the `Node` class, the attribute types are `int64` for `value` and `Node`
    for `next`. The `nb.jitclass` decorator will also compile all the methods defined
    for the class. Before delving into the code, we need to make two observations.
  prefs: []
  type: TYPE_NORMAL
- en: First, the attribute declaration must be done before the class is defined, but
    how do we declare a type that we haven't defined yet? Numba provides the `nb.deferred_type()`
    function that can be used for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Second, the `next` attribute can be either `None` or a `Node` instance. This
    is what is called an optional type, and Numba provides a utility called `nb.optional`
    that lets you declare variables that can be (optionally) `None`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This `Node` class is illustrated in the following code sample. As you can see,
    `node_type` is predeclared using `nb.deferred_type()`. The attributes are declared
    as a list of pairs containing the attribute name and the type (also note the use
    of `nb.optional`). After the class declaration, we are required to declare the
    deferred type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The `LinkedList` class can be easily compiled, as follows. All that''s needed
    is to define the `head` attribute and to apply the `nb.jitclass` decorator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now measure the execution time of the `sum_list` function when we pass
    a JIT `LinkedList`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Interestingly, when using a JIT class from a compiled function, we obtain a
    substantial performance improvement against the pure Python version. However,
    using the JIT class from the original `sum_list.py_func` actually results in a
    worse performance. Ensure that you use JIT classes only inside compiled functions!
  prefs: []
  type: TYPE_NORMAL
- en: Limitations in Numba
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are some instances where Numba cannot properly infer the variable types.
    In the following example, we define a function that takes a nested list of integers
    and returns the sum of the element in every sublist. In this case, Numba will
    raise a warning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The problem with this code is that Numba is not able to determine the list
    type and fails. A way to fix this problem is to help the compiler determine the
    right type by initializing the list with a sample element and removing it at the
    end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Among other features that are not yet implemented in the Numba compiler are
    function and class definitions, `list`, `set`, and `dict` comprehensions, generators,
    the `with` statement, and `try` and `except` blocks. Note, however, that many
    of these features may become supported in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, we have seen multiple approaches of working with Numba to speed up
    our applications, such as type specializations, NumPy's universal functions, and
    JIT classes. We will now move on to our second main topic in this chapter – PyPy.
  prefs: []
  type: TYPE_NORMAL
- en: The PyPy project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyPy is a very ambitious project at improving the performance of the Python
    interpreter. The way PyPy improves performance is by automatically compiling slow
    sections of the code at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: PyPy is written in a special language called **RPython** (rather than C) that
    allows developers to implement advanced features and improvements quickly and
    reliably. RPython means **Restricted Python** because it implements a restricted
    subset of the Python language targeted to the compiler development.
  prefs: []
  type: TYPE_NORMAL
- en: As of today, PyPy version 7.3.5 supports a lot of Python features and is a possible
    choice for a large variety of applications, such as game and web development.
    PyPy compiles code using a very clever strategy called **tracing JIT compilation**.
    At first, the code is executed normally using interpreter calls. PyPy then starts
    to profile the code and identifies the most intensive loops. After the identification
    takes place, the compiler then observes (*traces*) the operations and can compile
    its optimized, interpreter-free version.
  prefs: []
  type: TYPE_NORMAL
- en: Once an optimized version of the code is present, PyPy can run the slow loop
    much faster than the interpreted version.
  prefs: []
  type: TYPE_NORMAL
- en: This strategy can be contrasted with what Numba does. In Numba, the units of
    compilation are methods and functions, while the PyPy focus is just slow loops.
    Overall, the focus of the projects is also very different, as Numba has limited
    scope for numerical code and requires a lot of instrumentation, while PyPy aims
    at replacing the CPython interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will demonstrate and benchmark PyPy on our particle simulator
    application. We will begin by setting up Python and then look at running a particle
    simulator in PyPy.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up PyPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PyPy is distributed as a precompiled binary that can be downloaded from [http://pypy.org/download.html](http://pypy.org/download.html),
    and it currently supports Python versions 2.7 and 3.7\. In this chapter, we will
    demonstrate the usage of the 3.7 version.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once PyPy is downloaded and unpacked, you can locate the interpreter in the
    `bin/pypy` directory relative to the unpacked archive. You can initialize a new
    virtual environment, where we can install additional packages using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'To activate the environment, we will use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, you can verify that the binary Python is linked to the PyPy
    executable by typing `python -V`. At this point, we can go ahead and install some
    packages we may need. Note that PyPy may have limited support for software that
    uses the Python C API (most notably, packages such as `numpy` and `matplotlib`).
    We can go ahead and install them in the usual way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: On certain platforms, the installation of `numpy` and `matplotlib` can be tricky.
    You can skip the installation step and remove any imports on these two packages
    from the scripts we will run.
  prefs: []
  type: TYPE_NORMAL
- en: Running a particle simulator in PyPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have successfully set up the PyPy installation, we can go ahead
    and run our particle simulator. As a first step, we will time the particle simulator
    from [*Chapter 1*](B17499_01_Final_SS_ePub.xhtml#_idTextAnchor015), *Benchmarking
    and Profiling*, on the standard Python interpreter. If the virtual environment
    is still active, you can issue the `deactivate` command to exit the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we can time our code using the `timeit` command-line interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We can reactivate the environment and run the exact same code from PyPy. On
    Ubuntu, you may have problems importing the `matplotlib.pyplot` module. You can
    try issuing the following `export` command to fix the issue or removing the `matplotlib`
    imports from `simul.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can go ahead and time the code using PyPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we obtained a large (more than eight times) speed-up! PyPy, however,
    warns us that the `timeit` module can be unreliable. We can confirm our timings
    using the `perf` module, as suggested by PyPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This gives us a more reliable assurance that our speed-up is consistent. Overall,
    we can see that with a simple reinstallation of Python, we are able to achieve
    significant speed-up via PyPy.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced PyPy
  prefs: []
  type: TYPE_NORMAL
- en: Although not within the scope of this chapter, for more advanced usage of PyPy,
    one could integrate it with Pyglet for game development and PyLongs and Django
    for web development.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, Numba and PyPy together offer us many options regarding how we might
    want to go about leveraging JIT compilers to supercharge our Python programs.
    In the next section, we examine several other options that may be of interest.
  prefs: []
  type: TYPE_NORMAL
- en: Other interesting projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the years, many projects attempted to improve Python performance through
    several strategies, and, sadly, many of them failed. As of today, there are a
    few projects that survive and hold the promise for a faster Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Numba and PyPy are mature projects that are steadily improving over the years.
    Features are continuously being added, and they hold great promise for the future
    of Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Nuitka** is a program developed by Kay Hayen that compiles Python code to
    C. At the time of writing (version 0.6.15), it provides extreme compatibility
    with the Python language and produces efficient code that results in moderate
    performance improvements over CPython.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nuitka is quite different than Cython in the sense that it focuses on extreme
    compatibility with the Python language, and it doesn't extend the language with
    additional constructs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pyston** is a new interpreter developed by Dropbox that powers JIT compilers.
    It differs substantially from PyPy as it doesn''t employ a tracing JIT but rather
    a method-at-a-time JIT (similar to what Numba does). Pyston, like Numba, is also
    built on top of the LLVM compiler infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pyston is in active development and supports both **Python 2.7** and **3.8**.
    Benchmarks show that it is faster than CPython but slower than PyPy; that said,
    it is still an interesting project to follow as new features are added and compatibility
    is increased.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have been introduced to four different JIT compilers. You
    may find in your own experience that, when developing an application, different
    situations and use cases may call for different compilers. It is, therefore, important
    to explore our options when it comes to using a JIT compiler to speed up our Python
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Numba is a tool that compiles fast, specialized versions of Python functions
    at runtime. In this chapter, we learned how to compile, inspect, and analyze functions
    compiled by Numba. We also learned how to implement fast NumPy universal functions
    that are useful in a wide array of numerical applications. Finally, we implemented
    more complex data structures using the `nb.jitclass` decorator. Overall, Numba
    is built to accelerate numeric loops that are common in scientific computing.
    As we have seen, Numba works seamlessly with the popular NumPy library.
  prefs: []
  type: TYPE_NORMAL
- en: Tools such as PyPy allow us to run Python programs unchanged to obtain significant
    speed improvements. We demonstrated how to set up PyPy, and we assessed the performance
    improvements on our particle simulator application. We have also seen that, unlike
    Numba, PyPy doesn't operate on a function level but instead seeks to implement
    a more efficient interpreter for a whole Python program.
  prefs: []
  type: TYPE_NORMAL
- en: We also, briefly, described the current ecosystem of the Python compilers and
    compared them with each other. These discussions will give you the confidence
    to explore and work with different JIT compilers and select the most appropriate
    for your applications. In the next chapter, we will see a specialized version
    of a JIT compiler that is optimized for machine learning operations and tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are JIT compilers and why are they useful?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does Numba determine the types of variables in a Python program? What happens
    when these variables are not of the type that Numba works well with?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the high-level idea of tracing a JIT compilation of PyPy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'More on JIT compilers: [https://www.freecodecamp.org/news/just-in-time-compilation-explained/](https://www.freecodecamp.org/news/just-in-time-compilation-explained/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
