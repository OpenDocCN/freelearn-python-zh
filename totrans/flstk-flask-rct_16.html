<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-288"><a id="_idTextAnchor328"/>16</h1>
<h1 id="_idParaDest-289"><a id="_idTextAnchor329"/>Containerization and Flask Application Deployment</h1>
<p>After a long journey, we’ve reached the last chapter! We’re thrilled beyond words! Right now, we are about to embark on the last lap of showcasing our full stack web application to the world. In today’s modern software development sphere, the pace of containerization adoption is rapidly increasing.</p>
<p>According to Gartner’s predictions, the adoption of containerized applications in production will increase significantly, with more than 75% of global organizations expected to utilize them by 2022, a notable increase from the less than 30% reported in 2020 (<a href="https://www.gartner.com/en/documents/3985796">https://www.gartner.com/en/documents/3985796</a>).</p>
<p>Containerization and the deployment of software applications have become essential skills needed for developers to stay modern and in demand. Developers who have the skills and knowledge to containerize and deploy software applications are better equipped to meet the demands of modern software development practices, stay up to date with industry trends, and remain competitive in the job market.</p>
<p>Containerization <a id="_idIndexMarker1122"/>allows developers to package applications and required dependencies into a standardized and portable container that can run consistently across different computing environments. And, of course, deployment ensures <a id="_idIndexMarker1123"/>that your application gets to the production environment, where it can be used by end users.</p>
<p>In this chapter, we will discuss containerization as a revolution changing the information technology industry. We will touch on the significance and benefits of containerization in software development, as well as exploring the issues it tackles.</p>
<p>Furthermore, we will delve into one of the containerization platforms in the software development<a id="_idIndexMarker1124"/> industry, called <strong class="bold">Docker</strong>. We will introduce Docker and use it to containerize both the React frontend and the Flask backend. We will discuss Docker’s benefits and why it is popular among developers.</p>
<p>By the end of the chapter, you will understand the importance of containerization in modern software development, and you will be able to package React and Flask applications into containers ready to be shipped and shared.</p>
<p>Finally, you will learn how to use <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) Elastic Beanstalk to deploy React-Flask applications leveraging the AWS fully managed cloud platform, which allows developers to deploy, manage, and scale their web applications and services with ease.</p>
<p>In this chapter, we’ll cover the following topics:</p>
<ul>
<li>What is containerization?</li>
<li>Introducing Docker</li>
<li>Dockerizing React and Flask applications</li>
<li>Understanding AWS Elastic Container Registry</li>
<li>Using <code>docker-compose</code></li>
<li>Deploying React and Flask applications to AWS Elastic Beanstalk</li>
</ul>
<h1 id="_idParaDest-290"><a id="_idTextAnchor330"/>Technical requirements</h1>
<p>The complete code for this chapter is available on GitHub at: <a href="https://github.com/PacktPublishing/Full-Stack-Flask-and-React/tree/main/Chapter16">https://github.com/PacktPublishing/Full-Stack-Flask-and-React/tree/main/Chapter16</a>.</p>
<p>Due to page count constraints, some of the long code blocks have been shortened. Please refer to GitHub for the complete code.</p>
<h1 id="_idParaDest-291"><a id="_idTextAnchor331"/>What is containerization?</h1>
<p><strong class="bold">Containerization</strong> is a <a id="_idIndexMarker1125"/>software development practice that involves packaging an application and required dependencies into a self-contained unit called a <strong class="bold">container</strong>. A container <a id="_idIndexMarker1126"/>is an isolated and lightweight runtime environment that provides a consistent and reproducible way to run an application across different computing environments.</p>
<p>Let’s say you have developed a web application using the Flask framework on your local machine running on MacOS. You want to deploy this application to a server running Ubuntu Linux in a production environment. However, there may be differences in the versions of the operating system, dependencies, or other system configurations that could affect the behavior of your application.</p>
<p>By packaging your Flask application and all the required dependencies into a container, you can ensure that the application runs consistently and reliably across different computing environments. The container will provide an isolated and lightweight runtime environment that encapsulates the application and related dependencies, ensuring that it runs consistently regardless of the underlying system configurations.</p>
<p>Containers <a id="_idIndexMarker1127"/>are like <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>) in that they provide a way to isolate applications from the underlying host operating system. However, while VMs require a complete copy of the host operating system to run, containers only require the minimal runtime components needed to run the application.</p>
<p>Containers <a id="_idIndexMarker1128"/>utilize a technique called containerization, which employs virtualization at the operating system level. Containerization allows multiple containers to run on the same host operating system, each with its own isolated filesystem, networking, and process space. With containerization, developers can lower the deployment time and cost.</p>
<p>Let’s check out a few <a id="_idIndexMarker1129"/>other benefits of containerization:</p>
<ul>
<li>Containers provide a standardized way of packaging applications and required dependencies, which reduces the time and effort required for configuration and setup.</li>
<li>Containers are portable across different computing environments, allowing for deployment on any system with the same container runtime. This portability approach eliminates the need to create and maintain separate deployment configurations for different environments.</li>
<li>Containers share the same operating system kernel, enabling more efficient use of system resources compared to traditional virtualization.</li>
<li>Containers provide isolation between applications and accompanying dependencies, making the conflicts and errors that can arise when running applications on a <a id="_idIndexMarker1130"/>shared infrastructure obsolete.</li>
</ul>
<p>In a nutshell, containers are lightweight, self-containing to run applications, portable, and efficient, and can be easily replicated and scaled as needed.</p>
<p>Although there are several containerization technologies to choose from, we will specifically discuss Docker in the next section. Before exploring Docker in depth, let’s take a brief look at some of <a id="_idIndexMarker1131"/>the other containerization tools and platforms<a id="_idIndexMarker1132"/> available in the software industry:</p>
<ul>
<li><strong class="bold">Kubernetes</strong>: An <a id="_idIndexMarker1133"/>open source container orchestration system that automates deploying, scaling, and managing containerized applications</li>
<li><strong class="bold">Apache Mesos</strong>: An <a id="_idIndexMarker1134"/>open source platform for managing and deploying containerized applications and big data services</li>
<li><strong class="bold">LXC/LXD</strong>: A <a id="_idIndexMarker1135"/>containerization solution that uses lightweight VMs to provide isolation and resource management</li>
<li><strong class="bold">CoreOS rkt</strong>: A <a id="_idIndexMarker1136"/>container runtime that provides security, simplicity, and speed to the container environment</li>
<li><strong class="bold">OpenVZ</strong>: An<a id="_idIndexMarker1137"/> open source containerization platform that provides container-based virtualization for Linux</li>
<li><strong class="bold">AWS Elastic Container Service (ECS)</strong>: A<a id="_idIndexMarker1138"/> fully managed container orchestration service provided by AWS</li>
<li><strong class="bold">Google Kubernetes Engine (GKE)</strong>: A<a id="_idIndexMarker1139"/> fully managed Kubernetes service provided by Google Cloud Platform</li>
</ul>
<p>As the demand for scalable and efficient software deployment grows, more and more developers are going to turn to Docker as a solution. In the next section, we’ll explore the basics of Docker and how it can help you streamline your development workflow.</p>
<h1 id="_idParaDest-292"><a id="_idTextAnchor332"/>Introducing Docker</h1>
<p><strong class="bold">Docker</strong> is a <a id="_idIndexMarker1140"/>popular platform for developing, packaging, and deploying applications in containers. Before Docker’s invention, software developers had to deal with the problem of software dependencies, which meant that the software would work well on one computer but fail to work on another system.</p>
<p>Software developers would create programs on their computers, but when they tried to share them with other people, things often went wrong. Programs that worked perfectly on one computer might not have worked on another because of differences in the operating system, software versions, configuration files, or other system-related factors.</p>
<p>To solve this problem, a group of developers in 2013 released a tool called Docker. Docker lets developers package programs and all the necessary dependencies into something called a <strong class="bold">Docker image</strong>. A <a id="_idIndexMarker1141"/>Docker image is a read-only template that contains the instructions for creating a Docker container. A Docker image includes the application code, runtime, libraries, dependencies, and configurations needed to run the application.</p>
<p>With Docker, developers can create a Docker image for their programs and share it with others. A Docker container is a runnable instance of a Docker image. A Docker container is a lightweight, isolated, and portable environment that can run on any system that supports Docker. This means that the program will run the same way on every computer, which makes it much easier to share and deploy.</p>
<p>Developers can create a Docker image <a id="_idIndexMarker1142"/>by writing a <strong class="bold">Dockerfile</strong>, which is a text file that contains the instructions for building a Docker image. The Dockerfile specifies the base image, adds the necessary packages and files, and sets the configuration options for the application.</p>
<p>Once you have built your application Docker image, you might want to ship to production or send it to other developers. To achieve this, you can use a Docker registry, which is a central repository for storing and distributing Docker images. Docker Hub is the most popular public registry, but you can also set up your own private registry for your organization. In the course of this chapter, we will store the book project Docker images in<a id="_idIndexMarker1143"/> AWS <strong class="bold">Elastic Container </strong><strong class="bold">Registry</strong> (<strong class="bold">ECR</strong>).</p>
<p>Docker Compose is <a id="_idIndexMarker1144"/>another tool of interest in the Docker ecosystem. Docker Compose is a tool for defining and running multi-container Docker applications. Docker Compose uses a YAML file to define the services, networks, and volumes needed to run the application. In the subsequent section, we will discuss Docker Compose in great detail. Next, we will explore how we can containerize a simple Flask application.</p>
<h2 id="_idParaDest-293"><a id="_idTextAnchor333"/>Creating a Flask application</h2>
<p>Now, let’s <a id="_idIndexMarker1145"/>demonstrate with a simple Flask application the process of containerization using Docker:</p>
<ol>
<li>Download Docker<a id="_idIndexMarker1146"/> from <a href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a> and install Docker on your system.</li>
</ol>
<div><div><img alt="Figure 16.1 – The download page of Docker" src="img/Figure_16.01_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.1 – The download page of Docker</p>
<ol>
<li value="2">Select the appropriate computer OS for your Docker platform.</li>
<li>Once the Docker installation is complete, test it in your Terminal with the following command:<pre class="source-code"><code>Docker version</code> and you will get the following output:</p></li>
</ol>
<div><div><img alt="Figure 16.2 – The command to verify the Docker installation" src="img/Figure_16.02_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.2 – The command to verify the Docker installation</p>
<ol>
<li value="4">Now that <a id="_idIndexMarker1147"/>Docker is installed on your computer, run the <code>mkdir bizza-docker</code> command to create a new working directory for deploying a Flask application using a Docker container. Then, enter <code>cd bizza-docker</code>:</li>
</ol>
<div><div><img alt="Figure 16.3 – The creation of a Docker working directory" src="img/Figure_16.03_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.3 – The creation of a Docker working directory</p>
<p class="list-inset">Let’s create a virtual environment for the new Flask Docker application.</p>
<ol>
<li value="5">Run <code>python –m venv venv</code> in the Terminal to install a virtual environment.</li>
<li>Activate the virtual environment with these commands:<ul><li><code>venv\Scripts\activate</code></li>
<li><code>source venv/bin/activate</code></li>
</ul></li>
<li>Inside the Docker project directory, <code>bizza-docker/</code>, create an <code>app.py</code> file and add the following code snippet to run a simple Flask application:<pre class="source-code">from flask import Flaskapp = Flask(__name__)@app.route('/')def index():    return "Bizza Web App Dockerization!"if __name__ == "__main__":    app.run(host='0.0.0.0', port=5001, debug=True)</pre><p class="list-inset">The <a id="_idIndexMarker1148"/>preceding code runs a simple Flask app showing <strong class="bold">Bizza Web App Dockerization!</strong> in the browser.</p></li>
<li>Create a <code>.flaskenv</code> file inside <code>bizza-docker/</code> and add the following code snippet:<pre class="source-code">FLASK_APP = app.pyFLASK_DEBUG = True</pre></li>
<li>Now, run the Flask app with <code>flask run</code> in the Terminal and you will get the following output:</li>
</ol>
<div><div><img alt="Figure 16.4 – Testing the Flask application" src="img/Figure_16.04_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.4 – Testing the Flask application</p>
<p class="list-inset">Now that the Flask app is working, let’s create a Flask application <code>requirements.txt</code> file to be able to reproduce the dependencies for this simple application.</p>
<ol>
<li value="10">Run the <code>pip freeze &gt; requirements.txt</code> command and you will get the following output:</li>
</ol>
<div><div><img alt="Figure 16.5 – The requirements.txt file for the Flask dependencies" src="img/Figure_16.05_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.5 – The requirements.txt file for the Flask dependencies</p>
<p>The following <a id="_idIndexMarker1149"/>block displays the content of the <code>requirements.txt</code> file:</p>
<pre class="source-code">blinker==1.6.2click==8.1.3
colorama==0.4.6
Flask==2.3.2
itsdangerous==2.1.2
Jinja2==3.1.2
MarkupSafe==2.1.2
python-dotenv==1.0.0
Werkzeug==2.3.3</pre>
<p>We now have all the resources to build the Docker image.</p>
<h2 id="_idParaDest-294"><a id="_idTextAnchor334"/>Creating a Dockerfile</h2>
<p>A Dockerfile <a id="_idIndexMarker1150"/>defines the container image for a Flask application. We are going to create a Dockerfile that uses the official Python 3.8 image as the base image, installs Flask and its dependencies, and copies the Flask application code into the container.</p>
<p>In the <code>bizza-docker</code> directory, create a Dockerfile file – make sure the capital <em class="italic">D</em> is used in creating the Dockerfile file. Don’t worry about why; this is a convention:</p>
<pre class="source-code">FROM python:3.8.2-alpineWORKDIR /packt-bizza-docker
ADD . /packt-bizza-docker
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
RUN pip3 install -r requirements.txt
COPY . .
ENV FLASK_APP=app.py
ENV FLASK_ENV=development
EXPOSE 5001
CMD ["python3", "app.py"]</pre>
<p>To <a id="_idIndexMarker1151"/>simplify the deployment process and ensure consistent environments across different stages of development, testing, and production, let’s examine the anatomy of the preceding Dockerfile.</p>
<p>The preceding code is a Dockerfile used to build a Docker image for a Python Flask web application:</p>
<ul>
<li><code>FROM python:3.8.2-alpine</code>: This specifies the base image to use for building the Docker image. In this case, the base image is <code>python:3.8.2-alpine</code>, which is a lightweight version of Python 3.8.2 optimized for running in Alpine Linux.</li>
<li><code>WORKDIR /packt-bizza-docker</code>: This sets the working directory of the Docker container to <code>/packt-bizza-docker</code>. All subsequent commands in the Dockerfile will be executed relative to this directory.</li>
<li><code>ADD . /packt-bizza-docker</code>: This line copies all the files and directories in the current directory into the <code>/packt-bizza-docker</code> directory in the Docker container.</li>
<li><code>COPY requirements.txt .</code>: This copies the <code>requirements.txt</code> file from the current directory to the root directory of the Docker container.</li>
<li><code>RUN pip install --no-cache-dir -r requirements.txt</code>: This installs the Python dependencies specified in the <code>requirements.txt</code> file using <code>pip</code>. The <code>--no-cache-dir</code> option ensures that <code>pip</code> does not cache the downloaded packages.</li>
<li><code>RUN pip install -r requirements.txt</code>: This line installs the Python dependencies specified in the <code>requirements.txt</code> file using <code>pip3</code>.</li>
<li><code>COPY . .</code>: This copies all the files and directories in the current directory to the root directory of the Docker container. This includes the Flask application code.</li>
<li><code>ENV FLASK_APP=app.py, ENV FLASK_ENV=development</code>: This sets the <a id="_idIndexMarker1152"/>environment variables for the Flask application. <code>FLASK_APP</code> specifies the name of the main Flask application file (in this case, <code>app.py</code>). <code>FLASK_ENV</code> sets the Flask environment to development mode.</li>
<li><code>EXPOSE 5001</code>: This exposes port <code>5001</code> of the Docker container.</li>
<li><code>CMD ["python3", "app.py"]</code>: This specifies the command to run when the Docker container is started. In this case, it runs the <code>app.py</code> file using Python 3.</li>
</ul>
<p>Next, we will build the Docker image from the preceding defined <code>Dockerfile</code>.</p>
<h2 id="_idParaDest-295"><a id="_idTextAnchor335"/>Building the Docker image</h2>
<p>With<a id="_idIndexMarker1153"/> the Dockerfile defined, you can build a Docker image of the Flask application. This image contains all the dependencies and configuration files required to run the application.</p>
<p>To construct the Docker image, execute the following command in the Terminal from within the <code>bizza-docker</code> directory that contains the Dockerfile:</p>
<pre class="console">docker build -t packt-bizza-docker .</pre>
<p>We will get the following output:</p>
<div><div><img alt="Figure 16.6 – Output of the docker build command" src="img/Figure_16.06_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.6 – Output of the docker build command</p>
<p>The <a id="_idIndexMarker1154"/>preceding command will build the Docker image using the Dockerfile present in the current directory. The resulting image will be tagged as <code>packt-bizza-docker</code>. Now, let’s proceed to the next step and launch the container to make the simple Flask application functional.</p>
<h2 id="_idParaDest-296"><a id="_idTextAnchor336"/>Running the Docker container</h2>
<p>After <a id="_idIndexMarker1155"/>building the Docker image, you can run a Docker container from the image. This container provides a lightweight, isolated, and portable environment for running the Flask application.</p>
<p>To run the Docker container, use the following command:</p>
<pre class="console">docker run -d -p 5001:5001 packt-bizza-docker .</pre>
<p>We will get the following output:</p>
<div><div><img alt="Figure 16.7 – Output of docker run in detached mode" src="img/Figure_16.07_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.7 – Output of docker run in detached mode</p>
<p>The preceding command will run the container in detached mode (<code>-d</code>) and perform port mapping (<code>-p</code>) by mapping the host port <code>5001</code> to the container port <code>5001</code>. The container will be based on the <code>packt-bizza-docker</code> image. Alternatively, you can run the command without the <code>-d</code> flag to launch the container in a non-detached mode, as shown in the following figure:</p>
<div><div><img alt="Figure 16.8 – Output of docker run in a non-detached mode" src="img/Figure_16.08_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.8 – Output of docker run in a non-detached mode</p>
<p>The <a id="_idIndexMarker1156"/>preceding <code>docker run</code> command allows us to access the Flask application running inside the Docker container. You need to expose the ports on the container to the host machine with <code>-p </code><code>5001:5001 .</code>.</p>
<p>Now that we have the Docker container running, we can test the Flask application by accessing it through a web browser or using a command-line tool such as <code>curl-</code> <code>http://127.0.0.1:5001</code>. Make sure that the application is functioning as expected and that all the dependencies are working correctly.</p>
<p>Finally, you can push the Docker image to a Docker registry such as Docker Hub or AWS ECS. This makes it easy to share the image with other developers or deploy it to production environments.</p>
<p>To stop a running Docker container, you can use the <code>docker stop</code> command followed by the <em class="italic">container ID</em> or <em class="italic">name</em>.</p>
<p>For example, if the container ID is <code>c2d8f8a4b5e3</code>, you can stop the container using the <code>docker stop c2d8f8a4b5e3</code> command, as shown in the following figure:</p>
<div><div><img alt="Figure 16.9 – Output of the docker stop command" src="img/Figure_16.09_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.9 – Output of the docker stop command</p>
<p>And if you don’t know the container ID or name, you can use the <code>docker ps</code> command to list all running containers and their details, including the ID and name. Once you have identified the container that you want to stop, you can use the <code>docker stop</code> command as described earlier.</p>
<p>Let’s glance at another important Docker command: <code>docker </code><code>container prune</code>.</p>
<p>The <code>docker container prune</code> command is used to remove stopped containers and free up disk space. When you run a Docker container, the container consumes system resources such as memory and CPU cycles. When you stop a container, those resources are freed up, but the container still exists on your system. With time, if you run multiple containers, you may be housing many stopped containers, which can take up significant disk space on your system.</p>
<p>Running <a id="_idIndexMarker1157"/>the <code>docker container prune</code> command is a simple way to remove all stopped containers and reclaim disk space. This <code>docker container prune</code> command will prompt you to confirm that you want to remove the containers before proceeding, so make sure you review the list of containers carefully before confirming.</p>
<p>It’s important to note that the <code>docker container prune</code> command will only remove stopped containers. If you have any running containers, they will not be affected by this command.</p>
<p>Next, we will discuss the process of dockerizing React and Flask applications. We will use the full stack Bizza web application as a case study.</p>
<h1 id="_idParaDest-297"><a id="_idTextAnchor337"/>Dockerizing React and Flask applications</h1>
<p>Dockerizing<a id="_idIndexMarker1158"/> web applications allows developers to set up a consistent development environment across different machines. Dockerizing tools reduce the time and effort required to set up a new development environment. With Docker, developers can easily replicate the production environment on their local machines, test their code, and debug any issues before deploying it.</p>
<p>In this section, we will dockerize working applications for React and Flask, and make them ready to be shipped for production.</p>
<p>Let’s start with the React.</p>
<h2 id="_idParaDest-298"><a id="_idTextAnchor338"/>Bizza frontend application with React</h2>
<p>Once you<a id="_idIndexMarker1159"/> have created your React application, the<a id="_idIndexMarker1160"/> initial step toward making it accessible to internet users is to build the application. Building a React application is an essential step in the development process to ensure that the application is optimized for production and performs as expected.</p>
<p>The building process takes the source code of a React project and transforms it into a production-ready format<a id="_idIndexMarker1161"/> that can be deployed and served to users:</p>
<ol>
<li>Let’s download the <em class="italic">Bizza</em> app directory from the GitHub repo – <a href="https://github.com/PacktPublishing/Full-Stack-Flask-and-React/tree/main/Chapter16/bizza/frontend">https://github.com/PacktPublishing/Full-Stack-Flask-and-React/tree/main/Chapter16/bizza/frontend</a>.</li>
<li>To install the dependencies required for the application, navigate to the <code>bizza/frontend</code> directory and execute the <code>npm install</code> command in the Terminal.</li>
<li>To run the frontend application, execute the <code>npm start</code> command in the Terminal.</li>
<li>Now, let’s build the application with the <code>npm run </code><code>build</code> command.</li>
</ol>
<p>Now that <a id="_idIndexMarker1162"/>the <em class="italic">bizza</em> React application has been built, the resulting files can be deployed to a web server or cloud platform and served to users. The eventual build directory is located inside <code>bizza/frontend/src/build</code>.</p>
<p>During the build process, the following steps were taken:</p>
<ol>
<li><strong class="bold">Transpiling JavaScript and JSX code</strong>: React applications are typically written<a id="_idIndexMarker1163"/> in JavaScript and JSX, a syntax extension for JavaScript. However, modern web browsers can only execute JavaScript code. Therefore, before deploying a React application, the JavaScript and JSX code needs to be transpiled into plain JavaScript using a tool such as Babel.</li>
<li><strong class="bold">Bundling the code and assets</strong>: React <a id="_idIndexMarker1164"/>applications often consist of multiple components, modules, and assets such as images, CSS files, and fonts. Bundling involves grouping all the required code and assets into a single file or set of files that can be served to the user.</li>
<li><strong class="bold">Optimizing the code and assets</strong>: To improve performance, the bundled code and assets<a id="_idIndexMarker1165"/> can be optimized by minifying, compressing, or removing unnecessary code.</li>
<li><code>build</code> or <code>dist</code>.</li>
</ol>
<p>Now, typically<a id="_idIndexMarker1167"/> at this stage, the <code>build</code> directory <a id="_idIndexMarker1168"/>contents are deployed to a web server or cloud for end users. However, for the deployment process outlined in this book, you will utilize a Docker functionality known <a id="_idIndexMarker1169"/>as <strong class="bold">multi-stage builds</strong>. A multi-stage build is a feature in Docker that allows you to create a Docker image that consists of multiple stages, where each stage is a self-contained Docker image with a specific purpose.</p>
<p>The purpose of a multi-stage build is to optimize the size and efficiency of Docker images. With a multi-stage build, you can reduce the size of your final Docker image by only including the necessary files and dependencies. This results in faster builds, smaller image sizes, and more efficient use of resources.</p>
<p>The multi-stage build process involves creating multiple Docker images, each with a specific purpose. The first stage of the build typically contains the source code, dependencies, libraries, and other necessary files.</p>
<p>The final stage of the build usually contains only the essential files and dependencies required to run the application, resulting in a smaller and more efficient Docker image. The essence of a multi-stage build is to ensure that the intermediate stages are used to build and compile the application but are not included in the final image.</p>
<p>Right now, let’s examine a <code>Dockerfile</code> for the React frontend app that uses multi-stage builds:</p>
<pre class="source-code"># Build stageFROM node:14.17.0-alpine3.13 as build-stage
WORKDIR /frontend
COPY package*.json ./
RUN npm install --production
COPY . .
RUN npm run build
# Production stage
FROM nginx:1.21.0-alpine
COPY --from=build-stage /frontend/build /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
# Clean up unnecessary files
RUN rm -rf /var/cache/apk/* \
          /tmp/* \
          /var/tmp/* \
          /frontend/node_modules \
          /frontend/.npm \
          /frontend/.npmrc \
          /frontend/package*.json \
          /frontend/tsconfig*.json \
          /frontend/yarn.lock</pre>
<p>Let’s break <a id="_idIndexMarker1170"/>the preceding <code>Dockerfile</code> image-building <a id="_idIndexMarker1171"/>instruction down:</p>
<ul>
<li><code>Dockerfile</code> creates a build stage using the Node.js <code>14.17.0-alpine3.13</code> image as the base. The <code>Dockerfile</code> sets the working directory to <code>/frontend</code> and copies the <code>package*.json</code> files from the local directory to the image. The <code>npm install --production</code> command is then run to install the <a id="_idIndexMarker1173"/>production dependencies. Next, the Dockerfile copies the entire project directory to the image and runs the <code>npm run build</code> command to build the React app.</li>
<li><code>Dockerfile</code> creates a production stage using the smaller <code>nginx:1.21.0-alpine image</code> as the base. The Dockerfile copies the built React app from the build stage, located at <code>/frontend/build</code>, to the <code>nginx</code> HTML directory at <code>/usr/share/nginx/html</code>.</li>
<li><code>EXPOSE</code> command <a id="_idIndexMarker1175"/>exposes port <code>80</code> to allow communication with the container.</li>
<li><code>CMD</code> command sets <a id="_idIndexMarker1176"/>the default command to run when the container starts up. In this case, the <code>Dockerfile</code> starts the <code>nginx</code> server in the foreground with the <code>nginx -g 'daemon </code><code>off;'</code> command.</li>
<li><code>Dockerfile</code> cleans up unnecessary files, such as the <code>node_modules</code> directory and other configuration <a id="_idIndexMarker1178"/>files, using the <code>RUN</code> command with the <code>rm</code> command <a id="_idIndexMarker1179"/>to remove them from the image. This cleaning-up process reduces the overall size of the image, making it faster to deploy.</li>
</ul>
<p>Now that we have the Docker image of the bizza frontend React app. Let’s create the Flask backend Docker image.</p>
<h2 id="_idParaDest-299"><a id="_idTextAnchor339"/>Bizza backend application with Flask</h2>
<p>In the <a id="_idIndexMarker1180"/>Flask backend, we are going to create two Docker images. Download the full Flask backend application here: <a href="https://github.com/PacktPublishing/Full-Stack-Flask-and-React/tree/main/Chapter16/bizza/backend">https://github.com/PacktPublishing/Full-Stack-Flask-and-React/tree/main/Chapter16/bizza/backend</a>.</p>
<p>We will <a id="_idIndexMarker1181"/>create a Docker image for the Flask application and another Docker image for PostgreSQL. While it is possible to fuse the two images into a single Docker image, it is a best practice to separate the concerns for scalability and to reduce the image size.</p>
<p>Let’s review the Flask application multi-stage build Dockerfile definition.</p>
<p>The Dockerfile for the Flask application will be stored in the project <code>root</code> directory while a subdirectory named <code>postgres</code> will house the Dockerfile for PostgreSQL:</p>
<pre class="source-code"># Build StageFROM python:3.8.12-slim-buster AS build
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -U pip==21.3.1 &amp;&amp; \
    pip install --no-cache-dir --user -r requirements.txt
COPY . .
# Run Stage
FROM python:3.8.12-slim-buster AS run
WORKDIR /app
COPY --from=build /root/.local /root/.local
COPY --from=build /app .
ENV PATH=/root/.local/bin:$PATH
ENV FLASK_APP=app.py
ENV FLASK_ENV=production
EXPOSE 5001
CMD ["python3", "app.py"]</pre>
<p>Let’s break<a id="_idIndexMarker1182"/> down the preceding Dockerfile.</p>
<p>This<a id="_idIndexMarker1183"/> Dockerfile defines a multi-stage build for a Flask application. The Dockerfile has two stages: <code>build</code> and <code>run</code>.</p>
<p>The first stage, <code>build</code>, is responsible for building the application and installing the required dependencies. Right now, let’s check what each line of the build stage does:</p>
<ul>
<li><code>FROM python:3.8.12-slim-buster AS build</code>: This line sets the base image for the build stage to <code>python:3.8.12-slim-buster</code>.</li>
<li><code>WORKDIR /app</code>: This line sets the working directory to <code>/app</code>.</li>
<li><code>COPY requirements.txt .</code>: This line copies the <code>requirements.txt</code> file from the host machine to the <code>/app</code> directory in the container.</li>
<li><code>RUN pip install --no-cache-dir -U pip==21.3.1 &amp;&amp; \    pip install --no-cache-dir --user -r requirements.txt</code>: These lines update <code>pip</code> to version <code>21.3.1</code> and install the Python packages specified in the <code>requirements.txt</code> file.<p class="list-inset">The <code>--no-cache-dir</code> option is used to prevent the installation from using any cached data from previous runs, which helps ensure that the installed packages are up to date and match the versions specified in <code>requirements.txt</code>. The <code>--user</code> option is used to install the packages to the user’s home directory, which helps avoid permission issues.</p></li>
<li><code>COPY . .</code>: This line copies the entire application directory from the host machine to the <code>/app</code> directory in the container.</li>
<li><code>FROM python:3.8.12-slim-buster AS run</code>: This represents the start of the second stage.</li>
</ul>
<p>The <a id="_idIndexMarker1184"/>second stage, <code>run</code>, is responsible for running the application in a production environment. The line sets the base image for <a id="_idIndexMarker1185"/>the <code>run</code> stage to <code>python:3.8.12-slim-buster</code>:</p>
<ul>
<li><code>WORKDIR /app</code>: This line sets the working directory to <code>/app</code>.</li>
<li><code>COPY --from=build /root/.local /root/.local</code> and <code>COPY --from=build /app .</code>: These two lines copy the application directory and the installed packages from the build stage to the <code>run</code> stage. The first line copies the installed packages from the build stage to the <code>/root/.local</code> directory in the run stage. The second line copies the application directory from the build stage to the <code>/app</code> directory in the run stage.</li>
<li><code>ENV PATH=/root/.local/bin:$PATH</code>, <code>ENV FLASK_APP=app.py</code>, and <code>ENV FLASK_ENV=production</code>: These three lines set the environment variables for the application. The <code>PATH</code> environment variable is updated to include the <code>/root/.local/bin</code> directory, which contains the installed packages.<p class="list-inset">This ensures <a id="_idIndexMarker1186"/>that the installed packages are available in the system <code>PATH</code>. The <code>FLASK_APP</code> environment variable is set to <code>app.py</code>, which specifies the main application file for Flask to run. The <code>FLASK_ENV</code> environment variable is set to <code>production</code>, which enables features such as better error handling and improved performance.</p></li>
<li><code>EXPOSE 5001</code>: This line exposes port <code>5001</code>, which is the port that the Flask application will listen on.</li>
<li><code>CMD ["python3", "app.py"]</code>: This line specifies the default command to run when the container starts. It runs the <code>app.py</code> file using the <code>python3</code> command.</li>
</ul>
<p>Having discussed the Dockerfile for the main Flask application, let’s examine the Dockerfile for PostgreSQL.</p>
<p>Here’s the Dockerfile <a id="_idIndexMarker1187"/>for Postgres to create a database image:</p>
<pre class="source-code">FROM postgres:13-alpineENV POSTGRES_DB=&lt;databse_name&gt;
ENV POSTGRES_USER= &lt;databse_user&gt;
ENV POSTGRES_PASSWORD= &lt;databse_password&gt;
RUN apk add --no-cache --update bash
COPY init.sql /docker-entrypoint-initdb.d/
EXPOSE 5432</pre>
<p>Let’s go through the <a id="_idIndexMarker1188"/>Postgres Dockerfile:</p>
<ul>
<li><code>FROM postgres:13-alpine</code>: This line specifies the base image for our Docker container, which is <code>postgres:13-alpine</code>. This image is based on the Alpine Linux distribution and includes PostgreSQL version 13.</li>
<li><code>ENV POSTGRES_DB=&lt;database_name&gt;</code>, <code>ENV POSTGRES_USER=&lt;database_user&gt;</code>, and <code>ENV POSTGRES_PASSWORD=&lt;database_password&gt;</code>: These three lines set the environment variables for the Postgres container. The <code>POSTGRES_DB</code> variable specifies the name of the database to be created. The <code>POSTGRES_USER</code> variable specifies the username to be created for the database, and the <code>POSTGRES_PASSWORD</code> variable specifies the password for that user.</li>
<li><code>RUN apk add --no-cache --update bash</code>: This line copies the <code>init.sql</code> file to the <code>/docker-entrypoint-initdb.d/</code> directory in the container. This directory is used by the Postgres image to run initialization scripts when the container is first started. In this case, the <code>init.sql</code> file is a script that will create the database and any necessary tables.</li>
<li><code>EXPOSE 5432</code>: This line exposes port <code>5432</code>, which is the default port used by PostgreSQL, to allow connections from outside the container. However, this does not actually publish the port, as this needs to be done at runtime using the <code>docker run</code> or <code>docker-compose</code> commands.</li>
</ul>
<p>This <a id="_idIndexMarker1189"/>Postgres Dockerfile can be used to build a Docker <a id="_idIndexMarker1190"/>image for a Postgres database, which can be used in conjunction with React and Flask application Docker containers to build a complete web application stack.</p>
<p>With the Flask application and Postgres images well defined, we will be pushing the created Docker images to AWS ECR for online storage of Docker images.</p>
<h1 id="_idParaDest-300"><a id="_idTextAnchor340"/>Understanding AWS ECR</h1>
<p>Amazon ECR <a id="_idIndexMarker1191"/>is a fully managed Docker registry service that makes it easy to store, manage, and deploy Docker images. Amazon ECR is integrated with Amazon ECS to provide a seamless experience for building, deploying, and managing containerized applications at scale. Amazon ECR is designed to scale to meet the needs of even the most demanding containerized applications. Amazon ECR has security features to protect your container images, including encryption<a id="_idIndexMarker1192"/> at rest and in transit, and <strong class="bold">role-based access </strong><strong class="bold">control</strong> (<strong class="bold">RBAC</strong>).</p>
<p>To begin using <a id="_idIndexMarker1193"/>Amazon ECR, the first step is to create an ECR repository. Please refer to the following screenshot of the Amazon ECR interface.</p>
<p>Click on the <strong class="bold">Get Started</strong> button to initiate the repository creation process. This will allow you to establish a dedicated location for storing your Docker images.</p>
<div><div><img alt="Figure 16.10 ﻿– AWS ECR" src="img/Figure_16.10_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.10 – AWS ECR</p>
<p>Next, we have a screenshot showcasing a public repository named <code>packt-bizza-web-app</code> in Amazon ECR:</p>
<div><div><img alt="Figure 16.11 – The public repository" src="img/Figure_16.11_B18554.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.11 – The public repository</p>
<p>A <strong class="bold">repository</strong> is a<a id="_idIndexMarker1194"/> logical container for storing your Docker images. Once <a id="_idIndexMarker1195"/>you have created a repository, you can push your Docker images to the repository. You can then pull your images from the repository to deploy them to your ECS clusters.</p>
<p>Amazon ECR is a powerful tool that can help you to simplify the management of your container images. Interestingly, Amazon ECR is very cost-effective in storing and managing container images.</p>
<p>Using ECR is free; you only pay for the storage and bandwidth that you use. Next, we will use Docker Compose to define and run the React, Flask, and Postgres containers.</p>
<h1 id="_idParaDest-301"><a id="_idTextAnchor341"/>Using Docker Compose</h1>
<p><strong class="bold">Docker Compose</strong> is a<a id="_idIndexMarker1196"/> tool for defining and running multi-container Docker applications. Docker Compose provides a tool to define a set of containers and their relationships to each other, and then run them all with a single command.</p>
<p>With<a id="_idIndexMarker1197"/> Docker Compose, developers can define the exact configuration of the application’s containers, including the images, environment variables, and network settings. This ensures that the application runs consistently across different environments and can be easily reproduced.</p>
<p>The following are a <a id="_idIndexMarker1198"/>few components of Docker Compose we need to understand before we delve into details for configuration definitions:</p>
<ul>
<li><strong class="bold">YAML file</strong>: A <a id="_idIndexMarker1199"/>YAML file is used to define the configuration of your application’s containers. The YAML file specifies the images to use, ports to expose, environment variables, and any other settings that are required.</li>
<li><strong class="bold">Services</strong>: Each <a id="_idIndexMarker1200"/>container in your application is defined as a service in the YAML file. Services can depend on each other and can be started and stopped together.</li>
<li><strong class="bold">Networks</strong>: Docker Compose <a id="_idIndexMarker1201"/>creates a network for your application, allowing the containers to communicate with each other.</li>
<li><strong class="bold">Volumes</strong>: Volumes <a id="_idIndexMarker1202"/>are used to persist data between container runs.</li>
<li><strong class="bold">Commands</strong>: Docker Compose <a id="_idIndexMarker1203"/>provides a set of commands to start, stop, and manage your application.</li>
</ul>
<p>Now, let’s create<a id="_idIndexMarker1204"/> a Docker Compose file that manages the relationship between the React frontend, Flask backend, and PostgreSQL database containers:</p>
<ol>
<li>Inside the main project directory, <code>bizza/</code>, create <code>docker-compose.yaml</code>.</li>
<li>Define services for each container. In the <code>docker-compose.yaml</code> file, define a separate service for each container:<pre class="source-code">version: '3'services:  frontend:    image: &lt;your-ecr-repository&gt;/bizza-frontend-react-      app    ports:      - "3000:3000"  backend:    image: &lt;your-ecr-repository&gt;/bizza-backend-flask-      app    ports:      - "5000:5000"    depends_on:      - db  db:    image: &lt;your-ecr-repository&gt;/bizza-postgresql    environment:      POSTGRES_USER: &lt;your-db-username&gt;      POSTGRES_PASSWORD: &lt;your-db-password&gt;      POSTGRES_DB: &lt;your-db-name&gt;    ports:      - "5432:5432"</pre></li>
</ol>
<p>In the <a id="_idIndexMarker1205"/>preceding code, we define three services: <code>frontend</code>, <code>backend</code>, and <code>db</code>. The <code>frontend</code> service runs the <em class="italic">Bizza</em> frontend React app, the <code>backend</code> service runs the <em class="italic">Bizza</em> backend Flask app, and the <code>db</code> service runs the PostgreSQL database.</p>
<p>Now, let’s configure<a id="_idIndexMarker1206"/> networking and<a id="_idIndexMarker1207"/> dependencies. Use the <code>ports</code> and <code>depend_ on</code> options to configure the network connections between the services. For instance, the frontend service is exposed on port <code>3000</code>, the backend service is exposed on port <code>5000</code>, and the <code>db</code> service is exposed on port <code>5432</code>. The backend service also depends on the <code>db</code> service, so the backend will start after the <code>db</code> service is running.</p>
<p>Once <a id="_idIndexMarker1208"/>we’ve <a id="_idIndexMarker1209"/>defined the services in the <code>docker-compose.yaml</code> file, we can start the containers using the <code>docker-compose up</code> command. This will start the containers and connect them to the appropriate network.</p>
<p>With Docker Compose managing the application’s containers, we can simplify the process of starting and stopping our application, as well as ensure that all the required components are running correctly and communicating with each other.</p>
<p>Interestingly, Docker Compose<a id="_idIndexMarker1210"/> is a useful tool for managing containers; however, Docker Compose is more suited to small-scale deployments and development environments. Docker Compose serves the purpose of the <em class="italic">bizza</em> project, being a small-scale application for learning purposes.</p>
<p>However, AWS Elastic Beanstalk, on the other hand, is designed to handle production-grade workloads and provides many features and benefits that can help simplify the management and scaling of web applications. Regardless, we will pivot the <em class="italic">bizza</em> application's final deployment on AWS Elastic Beanstalk.</p>
<p>In the next section, we will explore AWS Elastic Beanstalk, a service for deploying and managing applications in the cloud.</p>
<h1 id="_idParaDest-302"><a id="_idTextAnchor342"/>Deploying React and Flask applications to AWS Elastic Beanstalk</h1>
<p><strong class="bold">AWS Elastic Beanstalk</strong> is a<a id="_idIndexMarker1211"/> fully managed AWS cloud service that <a id="_idIndexMarker1212"/>allows developers to easily <a id="_idIndexMarker1213"/>deploy and manage web applications and services on AWS. AWS Elastic Beanstalk <a id="_idIndexMarker1214"/>provides a<a id="_idIndexMarker1215"/> platform that simplifies the process of deploying and managing web applications on AWS by automatically handling the infrastructure provisioning, load balancing, and scaling of the application.</p>
<p>You can deploy Elastic Beanstalk on a wide range of programming languages and web frameworks, including Node.js, Python, Ruby, and Go. Elastic Beanstalk also integrates with other AWS services such as Amazon RDS, Amazon DynamoDB, and Amazon SNS to provide a complete solution for building and scaling web applications.</p>
<p>With <a id="_idIndexMarker1216"/>Elastic Beanstalk, developers <a id="_idIndexMarker1217"/>can easily focus on coding. Once you are ready to deploy your <a id="_idIndexMarker1218"/>application, you can simply upload your application package or link to a repository, and then choose the appropriate platform and environment for your application. Elastic Beanstalk<a id="_idIndexMarker1219"/> automatically provisions the required resources and sets up the environment and can also automatically scale the application based on demand.</p>
<p>Also, AWS Elastic Beanstalk provides a range of capabilities and tools that help developers streamline their development <a id="_idIndexMarker1220"/>workflows, such as <strong class="bold">continuous integration and continuous delivery</strong> (<strong class="bold">CI/CD</strong>) pipelines, monitoring and logging tools, and integration with popular development tools such as Git and Jenkins.</p>
<p>Now, let’s get started with using Elastic Beanstalk to deploy our application. This guide assumes you have created an <a id="_idIndexMarker1221"/>AWS account. If not, go to <a href="https://aws.amazon.com/free/">https://aws.amazon.com/free/</a> and follow the instructions to create an AWS account. The AWS free tier is enough to deploy this book project:</p>
<ol>
<li>Log in to your AWS account and go to the <a id="_idIndexMarker1222"/>Amazon ECR console at <a href="https://console.aws.amazon.com/ecr/">https://console.aws.amazon.com/ecr/</a>.</li>
<li>To create an Amazon ECR repository, you can use the following steps:<ol><li class="upper-roman">Go to the Amazon ECR console.</li>
<li class="upper-roman">In the navigation pane, select <strong class="bold">Repositories</strong>.</li>
<li class="upper-roman">Select <strong class="bold">Create repository</strong>.</li>
<li class="upper-roman">In the <strong class="bold">Repository name</strong> field, enter a name for your repository.</li>
<li class="upper-roman">In the <strong class="bold">Repository type</strong> field, select <strong class="bold">Public</strong> or <strong class="bold">Private</strong>.</li>
<li class="upper-roman">Select <strong class="bold">Create</strong>.</li>
</ol></li>
<li>Alternatively, you <a id="_idIndexMarker1223"/>can create an Amazon ECR repository with the following AWS CLI command:<pre class="source-code"><strong class="bold">aws ecr create-repository --repository-name nameofyourrepository</strong></pre><p class="list-inset">However, to successfully run the preceding command you need to have the following sorted:</p><ul><li>Have an AWS account <a id="_idIndexMarker1224"/>and an IAM user with permissions to create ECR repositories. You can find the link to the permissions JSON file on the GitHub at <a href="B18554_16.xhtml">https://github.com/PacktPublishing/Full-Stack-Flask-and-React/blob/main/Chapter16/bizza/Deployment/ecr-permissions.json</a></li>
<li>Have AWS CLI installed and configured with your AWS credentials.</li>
</ul></li>
<li>Next, we need to push the Docker images to the Amazon ECR repository. To push the bizza application Docker images to the Amazon ECR repository, follow these steps:<ol><li class="upper-roman">On the command line, navigate to the directory that contains each of the applications’ Dockerfile. Build the Docker image with the following command:<pre class="source-code"><strong class="bold">docker build -t &lt;image-name&gt; .</strong></pre></li>
</ol><ol><li class="upper-roman" value="2">Then, tag your image with the following command:<pre class="source-code"><strong class="bold">docker tag &lt;docker_image_name&gt;:&lt;tag_name&gt; &lt;AWS_ACCOUNT_ID&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/&lt;AWS_REPOSITORY_NAME&gt;:&lt;tag_name&gt;</strong></pre></li>
</ol><ol><li class="upper-roman" value="3">Push each of the Docker images to the Amazon ECR repository. Inside your project directory, run <code>docker login</code> and enter docker login credentials. Once done, run the <code>aws configure</code> command to log in to AWS as well.</li>
<li class="upper-roman">Once you are logged in to both Docker and AWS in your terminal, run the following command:<pre class="source-code"><strong class="bold">aws ecr get-login-password --region &lt;region&gt; | docker login --username AWS --password-stdin AWS_ACCOUNT_ID.dkr.ecr.&lt;region&gt;.amazonaws.com</strong></pre></li>
</ol><p class="list-inset">Let’s go over the aspects of the preceding command:</p><ul><li><code>aws ecr get-login-password</code>:- This command retrieves an authentication token from ECR.</li>
<li><code>--region &lt;region&gt;</code>: This specifies the region where the ECR registry is located. If you do not know where your ECR repository is located, run the following command: <code>aws ecr describe-repositories –</code><code>repository-names nameofyourrepository</code>.</li>
<li><code>|</code>: This is the pipe operator. It tells the shell to take the output of the first command and pass it as input to the second command.</li>
<li><code>docker login</code>: This command logs you in to a Docker registry.</li>
<li><code>--username AWS</code>: This specifies the username to use when logging in to the registry.</li>
<li><code>--password-stdin</code>:- This <a id="_idIndexMarker1225"/>tells the <a id="_idIndexMarker1226"/>Docker CLI to read the password from standard input.</li>
<li><code>&lt;AWS_ACCOUNT_ID&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com</code>:- This is the registry ID of the ECR registry you want to log in to.</li>
</ul><ol><li class="upper-roman" value="5">Enter <code>docker push &lt;account-id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/&lt;nameof yourrepository:&lt;tag_name&gt;&gt;</code> in each of the project component directories.</li>
</ol></li>
<li>To create an Elastic Beanstalk environment, you can use the following steps:<ol><li class="upper-roman">Go to the Elastic Beanstalk console at <a href="https://console.aws.amazon.com/elasticbeanstalk">https://console.aws.amazon.com/elasticbeanstalk</a>.</li>
<li class="upper-roman">In the navigation pane, select <strong class="bold">Create environment</strong>.</li>
<li class="upper-roman">In the <strong class="bold">Platform</strong> section, select <strong class="bold">Docker</strong>.</li>
<li class="upper-roman">In the <strong class="bold">Application</strong> code section, select <strong class="bold">Use an </strong><strong class="bold">existing application</strong>.</li>
<li class="upper-roman">In the <strong class="bold">Application code repository</strong> field, enter the URL of your Docker image repository.</li>
<li class="upper-roman">In the <strong class="bold">Application name</strong> field, enter a name for your environment.</li>
<li class="upper-roman">Select <strong class="bold">Create environment</strong>.</li>
</ol></li>
<li>To configure the Elastic Beanstalk environment to use the Amazon ECR repository, you can use the following steps:<ol><li class="upper-roman">In the Elastic Beanstalk console, select the name of your environment.</li>
<li class="upper-roman">In the navigation pane, select <strong class="bold">Configuration</strong>.</li>
<li class="upper-roman">In the <strong class="bold">Software</strong> section, select <strong class="bold">Docker</strong>.</li>
<li class="upper-roman">In the <strong class="bold">Repository URL</strong> field, enter the URL of your Amazon ECR repository.</li>
<li class="upper-roman">Select <strong class="bold">Save</strong>.</li>
</ol></li>
<li>To <a id="_idIndexMarker1227"/>deploy <a id="_idIndexMarker1228"/>the application to <a id="_idIndexMarker1229"/>the Elastic Beanstalk environment, you <a id="_idIndexMarker1230"/>can use the following steps:<ol><li class="upper-roman">In the Elastic Beanstalk console, select the name of your environment.</li>
<li class="upper-roman">In the navigation pane, select <strong class="bold">Deploy</strong>.</li>
<li class="upper-roman">In the <strong class="bold">Deployment method</strong> section, select <strong class="bold">One-click deploy</strong>.</li>
<li class="upper-roman">Select <strong class="bold">Deploy</strong>.</li>
</ol><p class="list-inset">Now the application is deployed to the Elastic Beanstalk environment. You can access the application by using the URL that is displayed in the Elastic Beanstalk console.</p></li>
</ol>
<p>AWS Elastic Beanstalk is undoubtedly an excellent choice for developers who want to focus on building applications and services rather than managing infrastructure. AWS Elastic Beanstalk provides a simple, scalable, and flexible platform that can help developers quickly and easily deploy applications on the AWS cloud platform.</p>
<h1 id="_idParaDest-303"><a id="_idTextAnchor343"/>Summary</h1>
<p>In this chapter, we explored the world of containerization and deployment. We began by discussing what containerization is and why it is useful for modern software development. We then introduced Docker, the most popular containerization technology, and learned how to use it to package and deploy React and Flask applications.</p>
<p>Next, we explored the use of Docker Compose, a tool for defining and running multi-container Docker applications. We learned how to use Docker Compose to orchestrate the deployment of our applications across multiple containers.</p>
<p>We also delved into AWS ECR, a fully managed container registry service that allows developers to store, manage, and deploy Docker container images securely and reliably. Finally, we looked at AWS Elastic Beanstalk, a service that simplifies the process of deploying, managing, and scaling web applications. We learned how to deploy our dockerized React and Flask applications to Elastic Beanstalk with all the features with security and scalability.</p>
<p>In a nutshell, containerization and deployment are critical components of modern software development, and tools such as Docker and AWS services such as Elastic Container Registry and Elastic Beanstalk are essential for managing and scaling container-based applications.</p>
<p>We extend our sincere gratitude to you for selecting this book as your guide in mastering the art of full stack development. Your choice reflects your determination to embark on a transformative journey that combines the power of modern web technologies. It is our honor to accompany you on this path of discovery and learning.</p>
<p>Throughout the pages of this book, we have meticulously crafted a comprehensive roadmap to equip you with the skill set needed to conquer the realms of both frontend and backend development. We delved into the depths of React, unraveling its component-based architecture, state management, and dynamic user interfaces. Simultaneously, we navigated the intricacies of Flask, empowering you to construct robust APIs, manage databases, and handle server-side operations with finesse.</p>
<p>As you turn the final pages of this book, please take a moment to appreciate the knowledge you’ve gained and the skills you’ve honed. You now possess the tools to craft stunning user interfaces, harness the power of server-side applications, and seamlessly connect frontend and backend functionalities. Your journey as a full stack developer has begun, and the possibilities are limitless.</p>
<p>But wait, your expedition doesn’t end here! As you close this chapter, new horizons await you. The world of technology is ever-evolving, and your dedication to mastering full stack development aligns perfectly with the opportunities that lie ahead. Whether you choose to build intricate web applications, design intuitive user experiences, or contribute to innovative projects, your expertise will be a cornerstone of success.</p>
<p>So, with your newfound proficiency in React and Flask, what’s next? Perhaps you’ll explore advanced React frameworks such as <code>Next.js</code>, dive deeper into microservices with Flask, or even embark on creating your own groundbreaking applications. The road ahead is paved with endless prospects, and your ability <a id="_idTextAnchor344"/>to shape digital experiences has never been more significant.</p>
<p>Once again, thank you for choosing <em class="italic">Full Stack with Flask and React</em> as your guide. Your commitment to learning and growth is inspiring, and we eagerly anticipate the remarkable contributions you will make to the ever-evolving world of technology.</p>
</div>
</body></html>