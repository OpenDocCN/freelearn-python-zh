<html><head></head><body>
        

            
                <h1 class="header-title">C Performance with Cython</h1>
            

            
                
<p>Cython is a language that extends Python by supporting the declaration of types for functions, variables, and classes. These typed declarations enable Cython to compile Python scripts to efficient C code. Cython can also act as a bridge between Python and C as it provides easy-to-use constructs to write interfaces to external C and C++ routines.</p>
<p>In this chapter, we will learn the following things:</p>
<ul>
<li>Cython syntax basics</li>
<li>How to compile Cython programs</li>
<li>How to use <strong>static typing</strong> to generate fast code</li>
<li>How to efficiently manipulate arrays using typed <strong>memoryviews</strong></li>
<li>Optimizing a sample particle simulator</li>
<li>Tips on using Cython in the Jupyter notebook</li>
<li>The profiling tools available for Cython</li>
</ul>
<p>While a minimum knowledge of C is helpful, this chapter focuses only on Cython in the context of Python optimization. Therefore, it doesn't require any C background.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Compiling Cython extensions</h1>
            

            
                
<p>The Cython syntax is, by design, a superset of Python. Cython can compile, with a few exceptions, most Python modules without requiring any change. Cython source files have the <kbd>.pyx</kbd> extension and can be compiled to produce a C file using the <kbd>cython</kbd> command.</p>
<p>Our first Cython script will contain a simple function that prints <kbd>Hello, World!</kbd> as the output. Create a new <kbd>hello.pyx</kbd> file containing the following code:</p>
<pre>
    def hello(): <br/>      print('Hello, World!') 
</pre>
<p>The <kbd>cython</kbd> command will read <kbd>hello.pyx</kbd> and generate the <kbd>hello.c</kbd> file:</p>
<pre>
<strong>$ cython hello.pyx</strong>
</pre>
<p>To compile <kbd>hello.c</kbd> to a Python extension module, we will use the GCC compiler. We need to add some Python-specific compilation options that depend on the operating system. It's important to specify the directory that contains the header files; in the following example, the directory is <kbd>/usr/include/python3.5/</kbd>:</p>
<pre>
<strong>$ gcc -shared -pthread -fPIC -fwrapv -O2 -Wall -fno-strict-aliasing -lm -I/usr/include/python3.5/ -o hello.so hello.c</strong>
</pre>
<p>To find your Python include directory, you can use the <kbd>distutils</kbd> utility:  <kbd>sysconfig.get_python_inc</kbd>. To execute it, you can simply issue the following <kbd>python -c "from distutils import sysconfig; print(sysconfig.get_python_inc())"</kbd> command.</p>
<p>This will produce a file called <kbd>hello.so</kbd>, a C extension module that is directly importable into a Python session:</p>
<pre>
    &gt;&gt;&gt; import hello <br/>    &gt;&gt;&gt; hello.hello() <br/>    Hello, World!
</pre>
<p>Cython accepts both Python 2 and Python 3 as input and output languages. In other words, you can compile a Python 3 script <kbd>hello.pyx</kbd> file using the <kbd>-3</kbd> option:</p>
<pre>
<strong>$ cython -3 hello.pyx</strong>
</pre>
<p>The generated <kbd>hello.c</kbd> can be compiled without any changes to Python 2 and Python 3 by including the corresponding headers with the <kbd>-I</kbd> option, as follows:</p>
<pre>
<strong>$ gcc -I/usr/include/python3.5 # ... other options</strong><br/><strong>$ gcc -I/usr/include/python2.7 # ... other options</strong>
</pre>
<p>A Cython program can be compiled in a more straightforward way using <kbd>distutils</kbd>, the standard Python packaging tool. By writing a <kbd>setup.py</kbd> script, we can compile the <kbd>.pyx</kbd> file directly to an extension module. To compile our <kbd>hello.pyx</kbd> example, we can write a minimal <kbd>setup.py</kbd> containing the following code:</p>
<pre>
    from distutils.core import setup <br/>    from Cython.Build import cythonize <br/><br/>    setup( <br/>      name='Hello',<br/>      ext_modules = cythonize('hello.pyx')<br/>    ) 
</pre>
<p>In the first two lines of the preceding code, we import the <kbd>setup</kbd> function and the <kbd>cythonize</kbd> helper. The <kbd>setup</kbd> function contains a few key-value pairs that specify the name of the application and the extensions that need to be built.</p>
<p>The <kbd>cythonize</kbd> helper takes either a string or a list of strings containing the Cython modules we want to compile. You can also use glob patterns using the following code:</p>
<pre>
    cythonize(['hello.pyx', 'world.pyx', '*.pyx']) 
</pre>
<p>To compile our extension module using <kbd>distutils</kbd>, you can execute the <kbd>setup.py</kbd> script using the following code:</p>
<pre>
<strong>$ python setup.py build_ext --inplace</strong>
</pre>
<p>The <kbd>build_ext</kbd> option tells the script to build the extension modules indicated in <kbd>ext_modules</kbd>, while the <kbd>--inplace</kbd> option tells the script to place the <kbd>hello.so</kbd> output file in the same location as the source file (instead of a build directory).</p>
<p>Cython modules can also be automatically compiled using <kbd>pyximport</kbd>. All that's needed is a call to <kbd>pyximport.install()</kbd> at the beginning of your script (or you need to issue the command in your interpreter). After doing that, you can import <kbd>.pyx</kbd> files directly and <kbd>pyximport</kbd> will transparently compile the corresponding Cython modules:</p>
<pre>
    &gt;&gt;&gt; import pyximport <br/>    &gt;&gt;&gt; pyximport.install() <br/>    &gt;&gt;&gt; import hello # This will compile hello.pyx 
</pre>
<p>Unfortunately, <kbd>pyximport</kbd> will not work for all kinds of configurations (for example, when they involve a combination of C and Cython files), but it comes handy for testing simple scripts.</p>
<p>Since version 0.13, IPython includes the <kbd>cythonmagic</kbd> extension to interactively write and test a series of Cython statements. You can load the extensions in an IPython shell using <kbd>load_ext</kbd>:</p>
<pre>
    %load_ext cythonmagic 
</pre>
<p>Once the extension is loaded, you can use the <kbd>%%cython</kbd> <em>cell magic</em> to write a multiline Cython snippet. In the following example, we define a <kbd>hello_snippet</kbd> function that will be compiled and added to the IPython session namespace:</p>
<pre>
    %%cython <br/>    def hello_snippet(): <br/>        print("Hello, Cython!") <br/><br/>    hello_snippet()<br/>    Hello,  Cython! 
</pre>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Adding static types</h1>
            

            
                
<p>In Python, a variable can be associated to objects of different types during the execution of the program. While this feature is desirable as it makes the language flexible and dynamic, it also adds a significant overhead to the interpreter as it needs to look up type and methods of the variables at runtime, making it difficult to perform various optimizations. Cython extends the Python language with explicit type declarations so that it can generate efficient C extensions through compilation.</p>
<p>The main way to declare data types in Cython is through <kbd>cdef</kbd> statements. The <kbd>cdef</kbd> keyword can be used in multiple contexts, such as variables, functions, and extension types (statically-typed classes).</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Variables</h1>
            

            
                
<p>In Cython, you can declare the type of a variable by prepending the variable with <kbd>cdef</kbd> and its respective type. For example, we can declare the <kbd>i</kbd> variable as a 16 bit integer in the following way:</p>
<pre>
    cdef int i 
</pre>
<p>The <kbd>cdef</kbd> statement supports multiple variable names on the same line along with optional initialization, as seen in the following line:</p>
<pre>
    cdef double a, b = 2.0, c = 3.0 
</pre>
<p>Typed variables are treated differently in comparison to regular variables. In Python, variables are often described as <em>labels</em> that refer to objects in memory. For example, we could assign the value <kbd>'hello'</kbd> to the <kbd>a</kbd> variable at any point in the program without restriction:</p>
<pre>
    a = 'hello' 
</pre>
<p>The <kbd>a</kbd> variable holds a reference to the <kbd>'hello'</kbd> string. We can also freely assign another value (for example, the integer <kbd>1</kbd>) to the same variable later in the code:</p>
<pre>
    a = 1 
</pre>
<p>Python will assign the integer <kbd>1</kbd> to the <kbd>a</kbd> variable without any problem.</p>
<p>Typed variables behave quite differently and are usually described as <em>data containers:</em> we can only store values that fit into the container that is determined by its data type. For example, if we declare the <kbd>a</kbd> variable as <kbd>int</kbd>, and then we try to assign it to a <kbd>double</kbd>, Cython will trigger an error, as shown in the following code:</p>
<pre>
    %%cython <br/>    cdef int i <br/>    i = 3.0 <br/><br/>    # Output has been cut <br/>    ...cf4b.pyx:2:4 Cannot assign type 'double' to 'int' 
</pre>
<p>Static typing makes it easy for the compiler to perform useful optimizations. For example, if we declare a loop index as <kbd>int</kbd>, Cython will rewrite the loop in pure C without needing to step into the Python interpreter. The typing declaration guarantees that the type of the index will always be <kbd>int</kbd> and cannot be overwritten at runtime so that the compiler is free to perform the optimizations without compromising the program correctness.</p>
<p>We can assess the speed gain in this case with a small test case. In the following example, we implement a simple loop that increments a variable 100 times. With Cython, the <kbd>example</kbd> function can be coded as follows:</p>
<pre>
    %%cython <br/>    def example(): <br/>       cdef int i, j=0 <br/>       for i in range(100):<br/>           j += 1 <br/>       return j <br/><br/>    example() <br/>    # Result:<br/>    # 100 
</pre>
<p>We can compare the speed of an analogous, untyped, pure Python loop:</p>
<pre>
    def example_python(): <br/>        j=0 <br/>        for i in range(100):<br/>            j += 1 <br/>        return j <br/><br/>    %timeit example() <br/>    10000000 loops, best of 3: 25 ns per loop <br/>    %timeit example_python() <br/>    100000 loops, best of 3: 2.74 us per loop 
</pre>
<p>The speedup obtained by implementing this simple type declaration is a whopping 100x! This works because the Cython loop has first been converted to pure C and then to efficient machine code, while the Python loop still relies on the slow interpreter.</p>
<p>In Cython, it is possible to declare a variable to be of any standard C type, and it is also possible to define custom types using classic C constructs, such as <kbd>struct</kbd>, <kbd>enum</kbd>, and <kbd>typedef</kbd>.</p>
<p>An interesting example is that if we declare a variable to be of the <kbd>object</kbd> type, the variable will accept any kind of Python object:</p>
<pre>
    cdef object a_py <br/>    # both 'hello' and 1 are Python objects <br/>    a_py = 'hello' <br/>    a_py = 1 
</pre>
<p>Note that declaring a variable as <kbd>object</kbd> has no performance benefits as accessing and operating on the object will still require the interpreter to look up the underlying type of the variable and its attributes and methods.</p>
<p>Sometimes, certain data types (such as <kbd>float</kbd> and <kbd>int</kbd> numbers) are compatible in the sense that they can be converted into each other. In Cython, it is possible to convert (<em>cast</em>) between types by surrounding the destination type between pointy brackets, as shown in the following snippet:</p>
<pre>
    cdef int a = 0 <br/>    cdef double b <br/>    b = &lt;double&gt; a 
</pre>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Functions</h1>
            

            
                
<p>You can add type information to the arguments of a Python function by specifying the type in front of each of the argument names. Functions specified in this way will work and perform like regular Python functions, but their arguments will be type-checked. We can write a <kbd>max_python</kbd> function, which returns the greater value between two integers:</p>
<pre>
    def max_python(int a, int b):<br/>        return a if a &gt; b else b 
</pre>
<p>A function specified in this way will perform type-checking and treat the arguments as typed variables, just like in <kbd>cdef</kbd> definitions. However, the function will still be a Python function, and calling it multiple times will still need to switch back to the interpreter. To allow Cython for function call optimizations, we should declare the type of the return type using a <kbd>cdef</kbd> statement:</p>
<pre>
    cdef int max_cython(int a, int b): <br/>        return a if a &gt; b else b 
</pre>
<p>Functions declared in this way are translated to native C functions and have much less overhead compared to Python functions. A substantial drawback is that they can't be used from Python, but only from Cython, and their scope is restricted to the same Cython file unless they're exposed in a definition file (refer to the <em>Sharing declarations</em> section).</p>
<p>Fortunately, Cython allows you to define functions that are both callable from Python and translatable to performant C functions. If you declare a function with a <kbd>cpdef</kbd> statement, Cython will generate two versions of the function: a Python version available to the interpreter, and a fast C function usable from Cython. The <kbd>cpdef</kbd> syntax is equivalent to <kbd>cdef</kbd>, shown as follows:</p>
<pre>
    cpdef int max_hybrid(int a, int b): <br/>        return a if a &gt; b else b 
</pre>
<p>Sometimes, the call overhead can be a performance issue even with C functions, especially when the same function is called many times in a critical loop. When the function body is small, it is convenient to add the <kbd>inline</kbd> keyword in front of the function definition; the function call will be replaced by the function body itself. Our <kbd>max</kbd> function is a good candidate for <em>inlining</em>:</p>
<pre>
    cdef inline int max_inline(int a, int b): <br/>        return a if a &gt; b else b 
</pre>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Classes</h1>
            

            
                
<p>We can define an extension type using the <kbd>cdef class</kbd> statement and declaring its attributes in the class body. For example, we can create an extension type--<kbd>Point</kbd>--as shown in the following code, which stores two coordinates (<em>x</em>, <em>y</em>) of the <kbd>double</kbd> type:</p>
<pre>
    cdef class Point<br/>        cdef double x <br/>        cdef double y<br/>        def __init__(self, double x, double y): <br/>            self.x = x <br/>            self.y = y 
</pre>
<p>Accessing the declared attributes in the class methods allows Cython to bypass expensive Python attribute look-ups by direct access to the given fields in the underlying C <kbd>struct</kbd>. For this reason, attribute access in typed classes is an extremely fast operation.</p>
<p>To use the <kbd>cdef class</kbd> in your code, you need to explicitly declare the type of the variables you intend to use at compile time. You can use the extension type name (such as <kbd>Point</kbd>) in any context where you will use a standard type (such as <kbd>double</kbd>, <kbd>float</kbd>, and <kbd>int</kbd>). For example, if we want a Cython function that calculates the distance from the origin (in the example, the function is called <kbd>norm</kbd>) of a <kbd>Point</kbd>, we have to declare the input variable as <kbd>Point</kbd>, as shown in the following code:</p>
<pre>
    cdef double norm(Point p): <br/>        return (p.x**2 + p.y**2)**0.5 
</pre>
<p>Just like typed functions, typed classes have some limitations. If you try to access an extension type attribute from Python, you will get an <kbd>AttributeError</kbd>, as follows:</p>
<pre>
    &gt;&gt;&gt; a = Point(0.0, 0.0) <br/>    &gt;&gt;&gt; a.x <br/>    AttributeError: 'Point' object has no attribute 'x' 
</pre>
<p>In order to access attributes from Python code, you have to use the <kbd>public</kbd> (for read/write access) or <kbd>readonly</kbd> specifiers in the attribute declaration, as shown in the following code:</p>
<pre>
    cdef class Point: <br/>        cdef public double x 
</pre>
<p>Additionally, methods can be declared with the <kbd>cpdef</kbd> statement, just like regular functions.</p>
<p>Extension types do not support the addition of extra attributes at runtime. In order to do that, a solution is defining a Python class that is a subclass of the typed class and extends its attributes and methods in pure Python.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Sharing declarations</h1>
            

            
                
<p>When writing your Cython modules, you may want to reorganize your most used functions and classes declaration in a separate file so that they can be reused in different modules. Cython allows you to put these components in a <em>definition file</em> and access them with <kbd>cimport</kbd> statements<em>.</em></p>
<p>Let's say that we have a module with the <kbd>max</kbd> and <kbd>min</kbd> functions, and we want to reuse those functions in multiple Cython programs. If we simply write a bunch of functions in a <kbd>.pyx</kbd> file, the declarations will be confined to the same file.</p>
<p>Definition files are also used to interface Cython with external C code. The idea is to copy (or, more accurately, translate) the types and function prototypes in the definition file and leave the implementation in the external C code that will be compiled and linked in a separate step.</p>
<p>To share the <kbd>max</kbd> and <kbd>min</kbd> functions, we need to write a definition file with a <kbd>.pxd</kbd> extension. Such a file only contains the types and function prototypes that we want to share with other modules--a <em>public</em> interface. We can declare the prototypes of our <kbd>max</kbd> and <kbd>min</kbd> functions in a file named <kbd>mathlib.pxd</kbd>, as follows:</p>
<pre>
    cdef int max(int a, int b) <br/>    cdef int min(int a, int b) 
</pre>
<p>As you can see, we only write the function name and arguments without implementing the function body.</p>
<p>The function implementation goes into the implementation file with the same base name but the <kbd>.pyx</kbd> extension--<kbd>mathlib.pyx</kbd>:</p>
<pre>
    cdef int max(int a, int b): <br/>      return a if a &gt; b else b <br/><br/>    cdef int min(int a, int b): <br/>      return a if a &lt; b else b 
</pre>
<p>The <kbd>mathlib</kbd> module is now importable from another Cython module.</p>
<p>To test our new Cython module, we will create a file named <kbd>distance.pyx</kbd> containing a function named <kbd>chebyshev</kbd>. The function will calculate the Chebyshev distance between two points, as shown in the following code. The Chebyshev distance between two coordinates--<kbd>(x1, y1)</kbd> and <kbd>(x2, y2)</kbd>--is defined as the maximum value of the difference between each coordinate:</p>
<pre>
    max(abs(x1 - x2), abs(y1 - y2)) 
</pre>
<p>To implement the <kbd>chebyshev</kbd> function, we will use the <kbd>max</kbd> function declared in <kbd>mathlib.pxd</kbd> by importing it with the <kbd>cimport</kbd> statement, as shown in the following code snippet:</p>
<pre>
    from mathlib cimport max <br/><br/>    def chebyshev(int x1, int y1, int x2, int y2): <br/>        return max(abs(x1 - x2), abs(y1 - y2)) 
</pre>
<p>The <kbd>cimport</kbd> statement will read <kbd>hello.pxd</kbd> and the <kbd>max</kbd> definition will be used to generate the <kbd>distance.c</kbd> file.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Working with arrays</h1>
            

            
                
<p>Numerical and high performance calculations often make use of arrays. Cython provides an easy way to interact with them, using directly low-level C arrays, or the more general <em>typed memoryviews</em>.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">C arrays and pointers</h1>
            

            
                
<p>C arrays are a collection of items of the same type, stored contiguously in memory. Before digging into the details, it is helpful to understand (or review) how memory is managed in C.</p>
<p>Variables in C are like containers. When creating a variable, a space in memory is reserved to store its value. For example, if we create a variable containing a 64 bit floating point number (<kbd>double</kbd>), the program will allocate 64 bit (16 bytes) of memory. This portion of memory can be accessed through an address to that memory location.</p>
<p>To obtain the address of a variable, we can use the <em>address operator</em> denoted by the <kbd>&amp;</kbd> symbol. We can also use the <kbd>printf</kbd> function, as follows, available in the <kbd>libc.stdio</kbd> Cython module to print the address of this variable:</p>
<pre>
    %%cython <br/>    cdef double a <br/>    from libc.stdio cimport printf <br/>    printf("%p", &amp;a)<br/>    # Output:<br/>    # 0x7fc8bb611210 
</pre>
<p>Memory addresses can be stored in special variables, <em>pointers</em>, that can be declared by putting a <kbd>*</kbd> prefix in front of the variable name, as follows:</p>
<pre>
    from libc.stdio cimport printf <br/>    cdef double a <br/>    cdef double *a_pointer <br/>    a_pointer = &amp;a # a_pointer and &amp;a are of the same type 
</pre>
<p>If we have a pointer, and we want to grab the value contained in the address it's pointing at, we can use the <em>dereference operator</em> denoted by the <kbd>*</kbd> symbol. Be careful, the <kbd>*</kbd> used in this context has a different meaning from the <kbd>*</kbd> used in the variable declaration:</p>
<pre>
    cdef double a <br/>    cdef double *a_pointer <br/>    a_pointer = &amp;a <br/><br/>    a = 3.0 <br/>    print(*a_pointer) # prints 3.0 
</pre>
<p>When declaring a C array, the program allocates enough space to accommodate all the elements requested. For instance, to create an array that has 10 <kbd>double</kbd> values (16 bytes each), the program will reserve <em>16 * 10 = 160</em> bytes of contiguous space in memory. In Cython, we can declare such arrays using the following syntax:</p>
<pre>
    cdef double arr[10]
</pre>
<p>We can also declare a multidimensional array, such as an array with <kbd>5</kbd> rows and <kbd>2</kbd> columns, using the following syntax:</p>
<pre>
    cdef double arr[5][2] 
</pre>
<p>The memory will be allocated in a single block of memory, row after row. This order is commonly referred to as <em>row-major</em> and is depicted in the following figure. Arrays can also be ordered <em>column-major</em>, as is the case for the FORTRAN programming language:</p>
<div><img class="aligncenter size-full image-border" height="188" src="img/image_04_001.png" width="420"/></div>
<p>Array ordering has important consequences. When iterating a C array over the last dimension, we access contiguous memory blocks (in our example, 0, 1, 2, 3 ...) while when we iterate on the first dimension, we skip a few positions (0, 2, 4, 6, 8, 1 ... ). You should always try to access memory sequentially as this optimizes cache and memory usage.</p>
<p>We can store and retrieve elements from the array using standard indexing; C arrays don't support fancy indexing or slices:</p>
<pre>
    arr[0] = 1.0 
</pre>
<p>C arrays have many of the same behaviors as pointers. The <kbd>arr</kbd> variable, in fact, points to the memory location of the first element of the array. We can verify that the address of the first element of the array is the same as the address contained in the <kbd>arr</kbd> variable using the dereference operator, as follows:</p>
<pre>
    %%cython <br/>    from libc.stdio cimport printf <br/>    cdef double arr[10] <br/>    printf("%pn", arr) <br/>    printf("%pn", &amp;arr[0]) <br/><br/>    # Output<br/>    # 0x7ff6de204220 <br/>    # 0x7ff6de204220 
</pre>
<p>You should use C arrays and pointers when interfacing with the existing C libraries or when you need a fine control over the memory (also, they are very performant). This level of fine control is also prone to mistakes as it doesn't prevent you from accessing the wrong memory locations. For more common use cases and improved safety, you can use NumPy arrays or typed memoryviews.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">NumPy arrays</h1>
            

            
                
<p>NumPy arrays can be used as normal Python objects in Cython using their already optimized broadcasted operations. However, Cython provides a <kbd>numpy</kbd> module with better support for direct iteration.</p>
<p>When we normally access an element of a NumPy array, a few other operations take place at the interpreter level causing a major overhead. Cython can bypass those operations and checks by acting directly on the underlying memory area used by NumPy arrays, and thus obtaining impressive performance gains.</p>
<p>NumPy arrays can be declared as the <kbd>ndarray</kbd> data type. To use the data type in our code, we first need to <kbd>cimport</kbd> the <kbd>numpy</kbd> Cython module (which is not the same as the Python NumPy module). We will bind the module to the <kbd>c_np</kbd> variable to make the difference with the Python <kbd>numpy</kbd> module more explicit:</p>
<pre>
    cimport numpy as c_np<br/>    import numpy as np
</pre>
<p>We can now declare a NumPy array by specifying its type and the number of dimensions between square brackets (this is called <em>buffer syntax</em>). To declare a two-dimensional array of type <kbd>double</kbd>, we can use the following code:</p>
<pre>
    cdef c_np.ndarray[double, ndim=2] arr 
</pre>
<p>Access to this array will be performed by directly operating on the underlying memory area; the operation will avoid stepping into the interpreter, giving us a tremendous speed boost.</p>
<p>In the next example, we will show the usage of typed numpy arrays and compare them with the normal Python version.</p>
<p>We first write the <kbd>numpy_bench_py</kbd> function that increments each element of <kbd>py_arr</kbd>. We declare the <kbd>i</kbd> index as an integer so that we avoid the for-loop overhead:</p>
<pre>
    %%cython <br/>    import numpy as np <br/>    def numpy_bench_py(): <br/>        py_arr = np.random.rand(1000) <br/>        cdef int i <br/>        for i in range(1000): <br/>            py_arr[i] += 1 
</pre>
<p>Then, we write the same function using the <kbd>ndarray</kbd> type. Note that after we define the <kbd>c_arr</kbd> variable using <kbd>c_np.ndarray</kbd>, we can assign to it an array from the <kbd>numpy</kbd> Python module:</p>
<pre>
    %%cython <br/>    import numpy as np <br/>    cimport numpy as c_np <br/><br/>    def numpy_bench_c(): <br/>        cdef c_np.ndarray[double, ndim=1] c_arr <br/>        c_arr = np.random.rand(1000) <br/>        cdef int i<br/><br/>        for i in range(1000): <br/>           c_arr[i] += 1 
</pre>
<p>We can time the results using <kbd>timeit</kbd>, and we can see how the typed version is 50x faster:</p>
<pre>
    %timeit numpy_bench_c() <br/>    100000 loops, best of 3: 11.5 us per loop <br/>    %timeit numpy_bench_py() <br/>    1000 loops, best of 3: 603 us per loop 
</pre>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Typed memoryviews</h1>
            

            
                
<p>C and NumPy arrays as well as the built-in <kbd>bytes</kbd>, <kbd>bytearray</kbd>, and <kbd>array.array</kbd> objects are similar in the sense that they all operate on a contiguous memory area (also called memory <em>buffer</em>). Cython provides a universal interface--the <em>typed memoryview--</em>that unifies and simplifies the access to all these data types.</p>
<p>A <strong>memoryview</strong> is an object that maintains a reference on a specific memory area. It doesn't actually own the memory, but it can read and change its contents; in other words, it is a <em>view</em> on the underlying data. Memoryviews can be defined using a special syntax. For example, we can define a memoryview of <kbd>int</kbd> and a  two-dimensional memoryview of <kbd>double</kbd> in the following way:</p>
<pre>
    cdef int[:] a <br/>    cdef double[:, :] b 
</pre>
<p>The same syntax applies to the declaration of any type in variables, function definitions, class attributes, and so on. Any object that exposes a buffer interface (for example, NumPy arrays, <kbd>bytes</kbd>, and <kbd>array.array</kbd> objects) will be bound to the memoryview automatically. For example, we can bind the memoryview to a NumPy array using a simple variable assignment:</p>
<pre>
    import numpy as np <br/><br/>    cdef int[:] arr <br/>    arr_np = np.zeros(10, dtype='int32') <br/>    arr = arr_np # We bind the array to the memoryview 
</pre>
<p>It is important to note that the memoryview does not <em>own</em> the data, but it only provides a way to <em>access</em> and <em>change</em> the data it is bound to; the ownership, in this case, is left to the NumPy array. As you can see in the following example, changes made through the memoryview will act on the underlying memory area and will be reflected in the original NumPy structure (and vice versa):</p>
<pre>
    arr[2] = 1 # Changing memoryview <br/>    print(arr_np) <br/>    # [0 0 1 0 0 0 0 0 0 0] 
</pre>
<p>In a certain sense, the mechanism behind memoryviews is similar to what NumPy produces when we slice an array. As we have seen in <a href="fb5356db-d238-4571-b5de-663a8400ad6d.xhtml">Chapter 3</a>, <em>Fast Array Operations with NumPy and Pandas</em>, slicing a NumPy array does not copy the data but returns a view on the same memory area, and changes to the view will reflect on the original array.</p>
<p>Memoryviews also support array slicing with the standard NumPy syntax:</p>
<pre>
    cdef int[:, :, :] a <br/>    arr[0, :, :] # Is a 2-dimensional memoryview <br/>    arr[0, 0, :] # Is a 1-dimensional memoryview <br/>    arr[0, 0, 0] # Is an int 
</pre>
<p>To copy data between one memoryview and another, you can use syntax similar to slice assignment, as shown in the following code:</p>
<pre>
    import numpy as np <br/><br/>    cdef double[:, :] b <br/>    cdef double[:] r <br/>    b = np.random.rand(10, 3) <br/>    r = np.zeros(3, dtype='float64') <br/><br/>    b[0, :] = r # Copy the value of r in the first row of b 
</pre>
<p>In the next section, we will use the typed memoryviews to declare types for the arrays in our particle simulator.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Particle simulator in Cython</h1>
            

            
                
<p>Now that we have a basic understanding of how Cython works, we can rewrite the <kbd>ParticleSimulator.evolve</kbd> method. Thanks to Cython, we can convert our loops in C, thus removing the overhead introduced by the Python interpreter.</p>
<p>In <a href="fb5356db-d238-4571-b5de-663a8400ad6d.xhtml">Chapter 3</a>, <em>Fast Array Operations with NumPy and Pandas</em>, we wrote a fairly efficient version of the <kbd>evolve</kbd> method using NumPy. We can rename the old version as <kbd>evolve_numpy</kbd> to differentiate it from the new version:</p>
<pre>
    def evolve_numpy(self, dt): <br/>        timestep = 0.00001 <br/>        nsteps = int(dt/timestep) <br/><br/>        r_i = np.array([[p.x, p.y] for p in self.particles])     <br/>        ang_speed_i = np.array([p.ang_speed for p in self.particles]) <br/>        v_i = np.empty_like(r_i) <br/><br/>        for i in range(nsteps): <br/>            norm_i = np.sqrt((r_i ** 2).sum(axis=1)) <br/><br/>            v_i = r_i[:, [1, 0]] <br/>            v_i[:, 0] *= -1 <br/>            v_i /= norm_i[:, np.newaxis]         <br/><br/>            d_i = timestep * ang_speed_i[:, np.newaxis] * v_i <br/><br/>            r_i += d_i <br/><br/>        for i, p in enumerate(self.particles): <br/>            p.x, p.y = r_i[i] 
</pre>
<p>We want to convert this code to Cython. Our strategy will be to take advantage of the fast indexing operations by removing the NumPy array broadcasting, thus reverting to an indexing-based algorithm. Since Cython generates efficient C code, we are free to use as many loops as we like without any performance penalty.</p>
<p>As a design choice, we can decide to encapsulate the loop in a function that we will rewrite in a Cython module called <kbd>cevolve.pyx</kbd>. The module will contain a single Python function, <kbd>c_evolve</kbd>, that will take the particle positions, angular velocities, timestep, and number of steps as input.</p>
<p>At first, we are not adding typing information; we just want to isolate the function and ensure that we can compile our module without errors:</p>
<pre>
    # file: simul.py <br/>    def evolve_cython(self, dt): <br/>        timestep = 0.00001 <br/>        nsteps = int(dt/timestep) <br/><br/>        r_i = np.array([[p.x, p.y] for p in self.particles])     <br/>        ang_speed_i = np.array([p.ang_speed for p in self.particles]) <br/><br/>        c_evolve(r_i, ang_speed_i, timestep, nsteps) <br/><br/>        for i, p in enumerate(self.particles): <br/>            p.x, p.y = r_i[i] <br/><br/>    # file: cevolve.pyx <br/>    import numpy as np <br/><br/>    def c_evolve(r_i, ang_speed_i, timestep, nsteps): <br/>        v_i = np.empty_like(r_i) <br/><br/>        for i in range(nsteps): <br/>            norm_i = np.sqrt((r_i ** 2).sum(axis=1)) <br/><br/>            v_i = r_i[:, [1, 0]] <br/>            v_i[:, 0] *= -1 <br/>            v_i /= norm_i[:, np.newaxis]         <br/>     <br/>            d_i = timestep * ang_speed_i[:, np.newaxis] * v_i <br/><br/>            r_i += d_i 
</pre>
<p>Note that we don't need a return value for <kbd>c_evolve</kbd> as values are updated in the <kbd>r_i</kbd> array in-place. We can benchmark the untyped Cython version against the old NumPy version by slightly changing our benchmark function, as follows:</p>
<pre>
    def benchmark(npart=100, method='python'): <br/>        particles = [Particle(uniform(-1.0, 1.0),<br/>                              uniform(-1.0, 1.0),<br/>                              uniform(-1.0, 1.0)) <br/>                              for i in range(npart)] <br/>        simulator = ParticleSimulator(particles) <br/>        if method=='python': <br/>            simulator.evolve_python(0.1)<br/>        elif method == 'cython': <br/>            simulator.evolve_cython(0.1) <br/>        elif method == 'numpy': <br/>            simulator.evolve_numpy(0.1) 
</pre>
<p>We can time the different versions in an IPython shell:</p>
<pre>
    %timeit benchmark(100, 'cython') <br/>    1 loops, best of 3: 401 ms per loop <br/>    %timeit benchmark(100, 'numpy') <br/>    1 loops, best of 3: 413 ms per loop 
</pre>
<p>The two versions have the same speed. Compiling the Cython module without static typing doesn't have any advantage over pure Python. The next step is to declare the type of all the important variables so that Cython can perform its optimizations.</p>
<p>We can start adding types to the function arguments and see how the performance changes. We can declare the arrays as typed memoryviews containing <kbd>double</kbd> values. It's worth mentioning that if we pass an array of the <kbd>int</kbd> or <kbd>float32</kbd> type, the casting won't happen automatically and we will get an error:</p>
<pre>
    def c_evolve(double[:, :] r_i,<br/>                 double[:] ang_speed_i,<br/>                 double timestep,<br/>                 int nsteps): 
</pre>
<p>At this point, we can rewrite the loops over the particles and timesteps. We can declare the <kbd>i</kbd> and <kbd>j</kbd> iteration indices and the <kbd>nparticles</kbd> particle number as <kbd>int</kbd>:</p>
<pre>
    cdef int i, j <br/>    cdef int nparticles = r_i.shape[0] 
</pre>
<p>The algorithm is very similar to the pure Python version; we iterate over the particles and timesteps, and we compute the velocity and displacement vectors for each particle coordinate using the following code:</p>
<pre>
      for i in range(nsteps): <br/>          for j in range(nparticles): <br/>              x = r_i[j, 0] <br/>              y = r_i[j, 1] <br/>              ang_speed = ang_speed_i[j] <br/><br/>              norm = sqrt(x ** 2 + y ** 2) <br/><br/>              vx = (-y)/norm <br/>              vy = x/norm <br/><br/>              dx = timestep * ang_speed * vx <br/>              dy = timestep * ang_speed * vy <br/><br/>              r_i[j, 0] += dx <br/>              r_i[j, 1] += dy 
</pre>
<p>In the preceding code, we added the <kbd>x</kbd>, <kbd>y</kbd>, <kbd>ang_speed</kbd>, <kbd>norm</kbd>, <kbd>vx</kbd>, <kbd>vy</kbd>, <kbd>dx</kbd>, and <kbd>dy</kbd> variables. To avoid the Python interpreter overhead, we have to declare them with their corresponding types at the beginning of the function, as follows:</p>
<pre>
    cdef double norm, x, y, vx, vy, dx, dy, ang_speed 
</pre>
<p>We also used a function called <kbd>sqrt</kbd> to calculate the norm. If we use the <kbd>sqrt</kbd> present in the <kbd>math</kbd> module or the one in <kbd>numpy</kbd>, we will again include a slow Python function in our critical loop, thus killing our performance. A fast <kbd>sqrt</kbd> is available in the standard C library, already wrapped in the <kbd>libc.math</kbd> Cython module:</p>
<pre>
    from libc.math cimport sqrt 
</pre>
<p>We can rerun our benchmark to assess our improvements, as follows:</p>
<pre>
    In [4]: %timeit benchmark(100, 'cython') <br/>    100 loops, best of 3: 13.4 ms per loop <br/>    In [5]: %timeit benchmark(100, 'numpy') <br/>    1 loops, best of 3: 429 ms per loop 
</pre>
<p>For small particle numbers, the speed-up is massive as we obtained a 40x performance over the previous version. However, we should also try to test the performance scaling with a larger number of particles:</p>
<pre>
    In [2]: %timeit benchmark(1000, 'cython') <br/>    10 loops, best of 3: 134 ms per loop <br/>    In [3]: %timeit benchmark(1000, 'numpy') <br/>    1 loops, best of 3: 877 ms per loop
</pre>
<p>As we increase the number of particles, the two versions get closer in speed. By increasing the particle size to 1000, we already decreased our speed-up to a more modest 6x. This is likely due to the fact that, as we increase the number of particles, the Python for-loop overhead becomes less and less significant compared to the speed of other operations.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Profiling Cython</h1>
            

            
                
<p>Cython provides a feature, called <em>annotated view</em>, that helps find which lines are executed in the Python interpreter and which are good candidates for ulterior optimizations. We can turn this feature on by compiling a Cython file with the <kbd>-a</kbd> option. In this way, Cython will generate an HTML file containing our code annotated with some useful information. The usage of the <kbd>-a</kbd> option is as follows:</p>
<pre>
<strong>$ cython -a cevolve.pyx</strong><br/><strong>$ firefox cevolve.html</strong>
</pre>
<p>The HTML file displayed in the following screenshot shows our Cython file line by line:</p>
<div><div><img class="aligncenter size-full image-border" height="599" src="img/Screenshot-from-2017-02-01-19-11-43.png" width="733"/></div>
<div><p>Each line in the source code can appear in different shades of yellow. A more intense color corresponds to more interpreter-related calls, while white lines are translated to regular C code. Since interpreter calls substantially slow down execution, the objective is to make the function body as white as possible. By clicking on any of the lines, we can inspect the code generated by the Cython compiler. For example, the <kbd>v_y = x/norm</kbd> line checks that the norm is not <kbd>0</kbd> and raises a <kbd>ZeroDivisionError</kbd> if the condition is not verified. The <kbd>x = r_i[j, 0]</kbd> line shows that Cython checks whether the indexes are within the bounds of the array. You may note that the last line is of a very intense color; by inspecting the code, we can see that this is actually a glitch; the code refers to a boilerplate related to the end of the function.</p>
<p>Cython can shut down checks, such as division by zero, so that it can remove those extra interpreter related calls; this is usually accomplished through compiler directives. There are a few different ways to add compiler directives:</p>
<ul>
<li>Using a decorator or a context manager</li>
<li>Using a comment at the beginning of the file</li>
<li>Using the Cython command-line options</li>
</ul>
<p>For a complete list of the Cython compiler directives, you can refer to the official documentation at <a href="http://docs.cython.org/src/reference/compilation.html#compiler-directives">http://docs.cython.org/src/reference/compilation.html#compiler-directives</a>.</p>
<p>For example, to disable bounds checking for arrays, it is sufficient to decorate a function with <kbd>cython.boundscheck</kbd>, in the following way:</p>
<pre>
    cimport cython <br/><br/>    @cython.boundscheck(False) <br/>    def myfunction(): <br/>        # Code here 
</pre>
<p>Alternatively, we can use <kbd>cython.boundscheck</kbd> to wrap a block of code into a context manager, as follows:</p>
<pre>
    with cython.boundscheck(False): <br/>        # Code here 
</pre>
<p>If we want to disable bounds checking for a whole module, we can add the following line of code at the beginning of the file:</p>
<pre>
    # cython: boundscheck=False 
</pre>
<p>To alter the directives with the command-line options, you can use the <kbd>-X</kbd> option as follows:</p>
<pre>
<strong>$ cython -X boundscheck=True</strong>
</pre>
<p>To disable the extra checks in our <kbd>c_evolve</kbd> function, we can disable the <kbd>boundscheck</kbd> directive and enable <kbd>cdivision</kbd> (this prevents checks for <kbd>ZeroDivisionError</kbd>), as in the following code:</p>
<pre>
    cimport cython <br/><br/>    @cython.boundscheck(False) <br/>    @cython.cdivision(True) <br/>    def c_evolve(double[:, :] r_i,<br/>                 double[:] ang_speed_i,<br/>                 double timestep,<br/>                 int nsteps): 
</pre>
<p>If we look at the annotated view again, the loop body has become completely white--we removed all traces of the interpreter from the inner loop. In order to recompile, just type <kbd>python setup.py build_ext --inplace</kbd> again. By running the benchmark, however, we note that we didn't obtain a performance improvement, suggesting that those checks are not part of the bottleneck:</p>
<pre>
    In [3]: %timeit benchmark(100, 'cython') <br/>    100 loops, best of 3: 13.4 ms per loop 
</pre>
<p>Another way to profile Cython code is through the use of the <kbd>cProfile</kbd> module. As an example, we can write a simple function that calculates the Chebyshev distance between coordinate arrays. Create a <kbd>cheb.py</kbd> file:</p>
<pre>
    import numpy as np <br/>    from distance import chebyshev <br/><br/>    def benchmark(): <br/>        a = np.random.rand(100, 2) <br/>        b = np.random.rand(100, 2) <br/>        for x1, y1 in a: <br/>            for x2, y2 in b: <br/>                chebyshev(x1, x2, y1, y2) 
</pre>
<p>If we try profiling this script as-is, we won't get any statistics regarding the functions that we implemented in Cython. If we want to collect profiling information for the <kbd>max</kbd> and <kbd>min</kbd> functions, we need to add the <kbd>profile=True</kbd> option to the <kbd>mathlib.pyx</kbd> file, as shown in the following code:</p>
<pre>
    # cython: profile=True <br/><br/>    cdef int max(int a, int b): <br/>        # Code here 
</pre>
<p>We can now profile our script with <kbd>%prun</kbd> using IPython, as follows:</p>
<pre>
    import cheb <br/>    %prun cheb.benchmark() <br/><br/><strong># Output:</strong><br/><strong>2000005 function calls in 2.066 seconds </strong><br/><br/><strong>  Ordered by: internal time </strong><br/><br/><strong>  ncalls tottime percall cumtime percall filename:lineno(function) </strong><br/><strong>       1   1.664   1.664   2.066   2.066 cheb.py:4(benchmark) </strong><br/><strong> 1000000   0.351   0.000   0.401   0.000 {distance.chebyshev} </strong><br/><strong> 1000000   0.050   0.000   0.050   0.000 mathlib.pyx:2(max) </strong><br/><strong>       2   0.000   0.000   0.000   0.000 {method 'rand' of        'mtrand.RandomState' objects} </strong><br/><strong>       1   0.000   0.000   2.066   2.066 &lt;string&gt;:1(&lt;module&gt;) </strong><br/><strong>       1   0.000   0.000   0.000   0.000 {method 'disable' of        '_lsprof.Profiler' objects}</strong> 
</pre>
<p>From the output, we can see that the <kbd>max</kbd> function is present and is not a bottleneck. Most of the time seems to be spent in the <kbd>benchmark</kbd> function, meaning that the bottleneck is likely the pure Python for-loop. In this case, the best strategy will be rewriting the loop in NumPy or porting the code to Cython.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Using Cython with Jupyter</h1>
            

            
                
<p>Optimizing Cython code requires substantial trial and error. Fortunately, Cython tools can be conveniently accessed through the Jupyter notebook for a more streamlined and integrated experience.</p>
<p>You can launch a notebook session by typing <kbd>jupyter notebook</kbd> in the command line and you can load the Cython magic by typing <kbd>%load_ext cython</kbd> in a cell.</p>
<p>As already mentioned earlier, the <kbd>%%cython</kbd> magic can be used to compile and load the Cython code inside the current session. As an example, we may copy the contents of <kbd>cheb.py</kbd> into a notebook cell:</p>
<pre>
    %%cython<br/>    import numpy as np<br/><br/>    cdef int max(int a, int b):<br/>        return a if a &gt; b else b<br/><br/>    cdef int chebyshev(int x1, int y1, int x2, int y2):<br/>        return max(abs(x1 - x2), abs(y1 - y2))<br/><br/>    def c_benchmark():<br/>        a = np.random.rand(1000, 2)<br/>        b = np.random.rand(1000, 2)<br/><br/>        for x1, y1 in a:<br/>           for x2, y2 in b:<br/>               chebyshev(x1, x2, y1, y2)
</pre>
<p>A useful feature of the <kbd>%%cython</kbd> magic is the <kbd>-a</kbd> option that will compile the code and produce an annotated view (just like the command line <kbd>-a</kbd> option) of the source directly in the notebook, as shown in the following screenshot:</p>
<p><img class="aligncenter size-full image-border" src="img/Screenshot-from-2017-02-02-18-49-37.png"/></p>
<p>This allows you to quickly test different versions of your code and also use the other integrated tools available in Jupyter. For example, we can time and profile the code (provided that we activate the profile directive in the cell) in the same session using tools such as <kbd>%prun</kbd> and <kbd>%timeit</kbd>. For example, we can inspect the profiling results by taking advantage of the <kbd>%prun</kbd> magic, as shown in the following screenshot:</p>
<p><img class="aligncenter size-full image-border" src="img/Screenshot-from-2017-02-02-18-56-35.png"/></p>
<p>It is also possible to use the <kbd>line_profiler</kbd> tool we discussed in <a href="4db2c3e6-3485-41a5-8450-07220f6d80ec.xhtml">Chapter 1</a>, <em>Benchmarking and Profiling</em>, directly in the notebook. In order to support line annotations, it is necessary to do the following things:</p>
<ul>
<li>Enable the <kbd>linetrace=True</kbd> and <kbd>binding=True</kbd> compiler directives</li>
<li>Enable the <kbd>CYTHON_TRACE=1</kbd> flag at compile time</li>
</ul>
<p>This can be easily accomplished by adding the respective arguments to the <kbd>%%cython</kbd> magic, and by setting the compiler directives, as shown in the following code:</p>
<pre>
<strong>    %%cython -a -f -c=-DCYTHON_TRACE=1</strong><br/><strong>    # cython: linetrace=True</strong><br/><strong>    # cython: binding=True</strong><br/><br/>    import numpy as np<br/><br/>    cdef int max(int a, int b):<br/>        return a if a &gt; b else b<br/><br/>    def chebyshev(int x1, int y1, int x2, int y2):<br/>        return max(abs(x1 - x2), abs(y1 - y2))<br/><br/>    def c_benchmark():<br/>        a = np.random.rand(1000, 2)<br/>        b = np.random.rand(1000, 2)<br/>    <br/>        for x1, y1 in a:<br/>            for x2, y2 in b:<br/>                chebyshev(x1, x2, y1, y2)
</pre>
<p>Once the code is instrumented, we can profile using the <kbd>%lprun</kbd> magic:</p>
<pre>
%lprun -f c_benchmark c_benchmark()<br/><strong># Output:</strong><br/><strong>Timer unit: 1e-06 s</strong><br/><br/><strong>Total time: 2.322 s</strong><br/><strong>File: /home/gabriele/.cache/ipython/cython/_cython_magic_18ad8204e9d29650f3b09feb48ab0f44.pyx</strong><br/><strong>Function: c_benchmark at line 11</strong><br/><br/><strong>Line #      Hits         Time  Per Hit   % Time  Line Contents</strong><br/><strong>==============================================================</strong><br/><strong>    11                                           def c_benchmark():</strong><br/><strong>    12         1          226    226.0      0.0      a = np.random.rand...</strong><br/><strong>    13         1           67     67.0      0.0      b = np.random.rand...    </strong><br/><strong>    14                                               </strong><br/><strong>    15      1001         1715      1.7      0.1      for x1, y1 in a:</strong><br/><strong>    16   1001000      1299792      1.3     56.0          for x2, y2 in b:</strong><br/><strong>    17   1000000      1020203      1.0     43.9              chebyshev...</strong>
</pre>
<p>As you can see, a good chunk of time is actually spent in line 16, which is a pure Python loop and a good candidate for further optimization.</p>
<p>The tools available in Jupyter notebook allow for a fast edit-compile-test cycle so that you can quickly prototype and save time when testing different solutions.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    

        

            
                <h1 class="header-title">Summary</h1>
            

            
                
<p>Cython is a tool that bridges the convenience of Python with the speed of C. Compared to C bindings, Cython programs are much easier to maintain and debug, thanks to the tight integration and compatibility with Python and the availability of excellent tools.</p>
<p>In this chapter, we introduced the basics of the Cython language and how to make our programs faster by adding static types to our variables and functions. We also learned how to work with C arrays, NumPy arrays, and memoryviews.</p>
<p>We optimized our particle simulator by rewriting the critical <kbd>evolve</kbd> function, obtaining a tremendous speed gain. Finally, we learned how to use the annotated view to spot hard-to-find interpreter related calls and how to enable <kbd>cProfile</kbd> support in Cython. Also, we learned how to take advantage of the Jupyter notebook for integrated profiling and analysis of Cython codes.</p>
<p>In the next chapter, we will explore other tools that can generate fast machine code on the fly, without requiring compilation of our code to C ahead of time.</p>


            

            <footer style="margin-top: 5em;">
                
            </footer>

        
    </body></html>