- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding Microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are always trying to improve how we create software. Computer programming
    is less than 100 years old, and we have evolved rapidly through technology, design,
    and philosophy to improve the tools and applications we produce.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices have revolutionized software products by improving the readability
    and scalability of services, and have allowed organizations to speed up their
    release cycles and be more responsive to the needs of their customers. Everybody
    wants to ship new products and new features to their customers as fast as possible.
    They want to be *agile* by iterating often, and they want to ship, ship, and ship
    again.
  prefs: []
  type: TYPE_NORMAL
- en: With thousands of customers using your service simultaneously, it is considered
    good practice to push an experimental feature to production and remove it again
    if needed, instead of waiting for months to publish it and many other features
    at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Companies such, as Netflix, are promoting their continuous delivery techniques
    where small changes are made very often in production and tested on a subset of
    the user base. They've developed tools such as **Spinnaker** ([http://www.spinnaker.io/](http://www.spinnaker.io/))
    to automate as many steps as possible to update production and ship their features
    in the cloud as independent microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'But if you read Hacker News or Reddit, it can be quite hard to untangle what''s
    useful for you and what''s just buzzword-compliant journalistic-style information.
    As *Edsger Dijkstra*, noted computer science researcher and discoverer of the
    famous shortest-path routing algorithm, put it:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Write a paper promising salvation, make it a structured something or a virtual
    something, or abstract, distributed or higher-order or applicative and you can
    almost be certain of having started a new cult."'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Edsger W. Dijkstra
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This book will take you through the creation of a traditional monolithic service
    and provide guidance on how to identify components that will be more effective
    as microservices. We will cover ways to integrate with other services, pass messages
    and schedule tasks, and securely deploy our service in Amazon Web Services.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter is going to help you understand what microservices are, and will
    then focus on the various ways in which you can implement them using Python. It
    is composed of the following sections:'
  prefs: []
  type: TYPE_NORMAL
- en: The origins of service-oriented architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The monolithic approach to building an application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The microservices approach to building applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benefits of microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Potential pitfalls in microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing microservices with Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hopefully, once you've reached the end of the chapter, you will be able to dive
    into the rest of the book and build microservices with a good understanding of
    what they are and what they're not—and how you can use Python.
  prefs: []
  type: TYPE_NORMAL
- en: The origins of service-oriented architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is no official standard for microservices, so it is helpful to look at
    a bit of the history in this area of software design. When discussing microservices,
    **Service-Oriented Architecture** (**SOA**) is often used as a starting point.
    SOA is a way of thinking about software architecture that encourages reusable
    software components that provide well-defined interfaces. This allows those components
    to be reused and applied to new situations.
  prefs: []
  type: TYPE_NORMAL
- en: Each unit in the preceding definition is a self-contained service that implements
    one facet of a business and provides its feature through some interface.
  prefs: []
  type: TYPE_NORMAL
- en: While SOA clearly states that services should be standalone processes, it does
    not enforce what protocols should be used for those processes to interact with
    each other and is quite vague about how you deploy and organize your application.
  prefs: []
  type: TYPE_NORMAL
- en: If you read the **SOA Manifesto** ([http://www.soa-manifesto.org](http://www.soa-manifesto.org)),
    first published on the web circa 2009, the authors don't even mention whether
    the services interact via a network, although contemporary understanding of the
    principles mostly involves networked services.
  prefs: []
  type: TYPE_NORMAL
- en: SOA services could communicate via **Inter-Process Communication** (**IPC**)
    using sockets on the same machine, through shared memory, through indirect message
    queues, or even with **Remote Procedure Calls** (**RPC**). The options are extensive,
    and SOA is a useful set of principles for a wide variety of situations.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is common to say that microservices are one specialization of SOA,
    because they allow us to focus on the needs of the organization, its safety, and
    the scaling and separation of its software.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to give a complete definition of microservices, the best way to understand
    it is in the context of different software architectures. We will start with a
    monolith, and then discuss how microservices are different.
  prefs: []
  type: TYPE_NORMAL
- en: The monolithic approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With a monolith, everything about the service is in one place – the API, database,
    and all associated tools are managed as part of one code base. Let''s take a very
    simple example of a traditional monolithic application: a hotel booking website.'
  prefs: []
  type: TYPE_NORMAL
- en: Besides the static HTML content, the website has a booking feature that will
    let its users book hotels in any city in the world. Users can search for hotels,
    then book them with their credit cards.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a user performs a search on the hotel website, the application goes through
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: It runs a couple of SQL queries against its hotel database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An HTTP request is made to a partner's service to add more hotels to the list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Results are sent to the JavaScript embedded in the web page, to render the information
    for the viewer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From there, once the user has found the perfect hotel and selected the booking
    option, the application performs these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The customer gets created in the database, if needed, and has to authenticate
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Payment is carried out by interacting with the bank's web service
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The app saves the payment details in the database for legal reasons
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A receipt is generated using a PDF generator
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A recap email is sent to the user using the email service
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A reservation email is forwarded to the third-party hotel using the email service
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A database entry is added to keep track of the reservation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This process is a simplified model, of course, but describes enough for us to
    learn from.
  prefs: []
  type: TYPE_NORMAL
- en: The application interacts with a database that contains the hotel's information,
    the reservation details, the billing, the user information, and so on. It also
    interacts with external services for sending emails, making payments, and getting
    more hotels from partners.
  prefs: []
  type: TYPE_NORMAL
- en: In the early days of the web, a new service would commonly use a **LAMP** (**Linux-Apache-MySQL-Perl/PHP/Python**)
    architecture. With this approach, every incoming request generates a cascade of
    SQL queries on the database, and a few network calls to external services, then
    the server generates the HTML response using a template engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates this centralized architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17108_01_01_.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.1: A sample monolithic service architecture'
  prefs: []
  type: TYPE_NORMAL
- en: This application is a typical monolith, and it has a lot of benefits. The biggest
    one is that the whole application is in a single code base, and when the project
    coding starts, it makes everything simpler. Building a good test coverage is easy,
    and you can organize your code in a clean and structured way inside the code base.
    Storing all the data in a single database also simplifies the development of the
    application. You can tweak the data model, and how the code will query it.
  prefs: []
  type: TYPE_NORMAL
- en: The deployment is also straightforward; we can build a package, install it,
    and run it somewhere. To scale up, we can run several instances of the booking
    app, and run several databases with some replication mechanism in place.
  prefs: []
  type: TYPE_NORMAL
- en: If your application stays small, this model works well and is easy to maintain
    for a single team. But projects usually grow, and they get bigger than what was
    first intended. And having the whole application in a single code base brings
    some nasty issues along the way. For instance, if you need to make a sweeping
    change that is large in scope, such as changing your banking service or your database
    layer, the risks impact the whole application. These changes can have a huge impact
    on the project and need to be tested well before being deployed, and such testing
    often can't be exhaustive. Changes like this will happen in a project's life.
  prefs: []
  type: TYPE_NORMAL
- en: Small changes can also generate collateral damage because different parts of
    the system have different uptime and stability requirements. Putting the billing
    and reservation processes at risk because the function that creates a PDF crashes
    the server is a bit of a problem.
  prefs: []
  type: TYPE_NORMAL
- en: Uncontrolled growth is another issue. The application is bound to get new features,
    and with developers leaving and joining the project, the code might start to get
    messy, the tests a bit slower, and the deployment more fragile. This growth usually
    ends up with a spaghetti code base that's hard to maintain, with a hairy database
    that needs complicated migration plans every time some developer refactors the
    data model.
  prefs: []
  type: TYPE_NORMAL
- en: The other form of growth that makes the project interesting is capacity management.
    If just one element in the application needs to scale very differently than the
    rest, then scaling the application becomes much trickier; for example, if the
    hotel room availability starts being used to generate website advertising, as
    well as serving people visiting the website.
  prefs: []
  type: TYPE_NORMAL
- en: Large software projects usually take a couple of years to mature, and then they
    slowly start to turn into an incomprehensible mess that's hard to maintain. And
    it does not happen because developers are bad. It happens because as the complexity
    grows, fewer people fully understand the implications of every small change they
    make.
  prefs: []
  type: TYPE_NORMAL
- en: So, they try to work in isolation with a fragment of the code base, and the
    mess only becomes visible when you view the entire structure of the project. We've
    all been there.
  prefs: []
  type: TYPE_NORMAL
- en: It's not fun, and developers who work on such a project dream of building the
    application from scratch with the newest framework. And by doing so, they usually
    face the same issues again – the same story is repeated.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, with a monolithic architecture there are benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Starting a project as a monolith is easy, and probably the best approach.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A centralized database simplifies the design and organization of the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying one application is simple.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However:'
  prefs: []
  type: TYPE_NORMAL
- en: Any change in the code can impact unrelated features. When something breaks,
    the whole application may break.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Solutions to scale your application are limited: you can deploy several instances,
    but if one particular feature inside the app takes all the resources, it impacts
    everything.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the code base grows, it's hard to keep it clean and under control.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are, of course, some ways to avoid some of the issues described here.
  prefs: []
  type: TYPE_NORMAL
- en: The obvious solution is to split the application into separate pieces, even
    if the resulting code is still going to run in a single process. Developers do
    this by building their apps with external libraries and frameworks. Those tools
    can be in-house or from the **Open-Source Software** (**OSS**) community.
  prefs: []
  type: TYPE_NORMAL
- en: If you build a web app in Python using a framework like **Quart** or **Flask**,
    you are able to focus on the business logic, and it becomes very appealing to
    externalize some of your code into framework extensions and small Python packages.
    And splitting your code into small packages is often a good idea to control your
    application growth.
  prefs: []
  type: TYPE_NORMAL
- en: '"Small is beautiful."'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —The UNIX philosophy
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For instance, the PDF generator described in the hotel booking app could be
    a separate Python package that uses **ReportLab** and some templates to do the
    work. It's highly likely that this package could be reused in some other applications,
    and maybe even published to the **Python Package Index** (**PyPI**) for the community.
  prefs: []
  type: TYPE_NORMAL
- en: But you're still building a single application and some problems persist, like
    the inability to scale parts differently, or any indirect issue introduced by
    a buggy dependency.
  prefs: []
  type: TYPE_NORMAL
- en: You'll even face new challenges because you're now using dependencies. One problem
    that you'll face is *dependency hell*. If two parts of your application use the
    same library, you could get into the situation where one part of your application
    requires a new version for a feature that has been added, but another component
    can't use the newer one because something else has changed, and you are now in
    *dependency hell*. There's a good chance you will eventually have some ugly workaround
    for this problem in a large project, such as having a copy of the dependency that
    you now need to maintain separately to keep the fix up to date.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, all the problems described in this section do not appear on day one
    when the project starts, but rather pile up over time.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now look at how the same application would look if we were to use microservices
    to build it.
  prefs: []
  type: TYPE_NORMAL
- en: The microservice approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we were to build the same application using microservices, we would organize
    the code into several separate components that run in separate processes. We have
    already discussed the PDF report generator, and we can examine the rest of the
    application and see where we could split it into different microservices, as shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17108_01_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2: A sample microservice architecture'
  prefs: []
  type: TYPE_NORMAL
- en: 'Don''t be afraid of the number of components displayed in this diagram. The
    internal interactions of the monolithic application are just being made visible
    by separate pieces. We''ve shifted some of the complexity and ended up with these
    seven standalone components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Booking UI**: A frontend service that generates the web user interface, and
    interacts with all the other microservices.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**PDF reports**: A very simple service that will create PDFs for receipts or
    any other document given a template and some data. Also known as the PDF reporting
    service.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Search**: A service that can be queried to get a list of hotels when given
    a location. This service has its own database.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Payments**: A service that interacts with the third-party bank service, and
    manages a billing database. It also sends emails on successful payment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reservations**: Manages reservations and changes to bookings.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Users**: Stores the user information, and interacts with users via emails.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Authentication**: An OAuth 2-based service that returns authentication tokens,
    which each microservice can use to authenticate when calling others.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Those microservices, along with a few external services, like the email service,
    would provide a feature set similar to the monolithic application. In this design,
    each component communicates using the HTTP protocol, and features are made available
    through RESTful web services.
  prefs: []
  type: TYPE_NORMAL
- en: There's no centralized database, as each microservice deals internally with
    its own data structures, and the data that gets in and out uses a language-agnostic
    format like JSON. It could use XML or YAML as long as it can be produced and consumed
    by any language, and travel through HTTP requests and responses.
  prefs: []
  type: TYPE_NORMAL
- en: The Booking UI service is a bit particular in that regard, since it generates
    the **User Interface** (**UI**). Depending on the frontend framework used to build
    the UI, the Booking UI output could be a mix of HTML and JSON, or even plain JSON
    if the interface uses a static JavaScript-based client-side tool to generate the
    interface directly in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: But besides this particular UI case, a web application designed with microservices
    is a composition of several microservices, which may interact with each other
    through HTTP to provide the whole system.
  prefs: []
  type: TYPE_NORMAL
- en: 'In that context, microservices are logical units that focus on a very particular
    task. Here''s a full definition attempt:'
  prefs: []
  type: TYPE_NORMAL
- en: A microservice is a lightweight application that provides a narrow list of features
    with a well-defined contract. It's a component with a single responsibility that
    can be developed and deployed independently.
  prefs: []
  type: TYPE_NORMAL
- en: This definition does not mention HTTP or JSON, because you could consider, for
    example, a small UDP-based service that exchanges binary data as a microservice,
    or a service that communicates using gRPC. (gRPC is a recursive acronym that stands
    for gRPC Remote Procedure Call, an open-source remote procedure call system.)
  prefs: []
  type: TYPE_NORMAL
- en: But in our case, and throughout the book, all our microservices are just simple
    web applications that use the HTTP protocol and consume and produce JSON when
    it's not a UI.
  prefs: []
  type: TYPE_NORMAL
- en: Microservice benefits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While the microservices architecture looks more complicated than its monolithic
    counterpart, it offers multiple advantages. It offers the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Separation of concerns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Smaller projects to deal with
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More scaling and deployment options
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will discuss them in more detail in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Separation of concerns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First of all, each microservice can be developed independently by a separate
    team. For instance, building a reservation service can be a full project on its
    own. The team in charge can code it in the programming language and database of
    their choice, as long as it has a well-documented HTTP API.
  prefs: []
  type: TYPE_NORMAL
- en: That also means the evolution of the app is more under control than with monoliths.
    For example, if the payment system changes its underlying interactions with the
    bank, the impact is localized inside that service, and the rest of the application
    stays stable and is probably unaffected.
  prefs: []
  type: TYPE_NORMAL
- en: This is known as loose coupling, and improves the overall project velocity as
    we apply, at the service level, a philosophy similar to the *single responsibility* principle.
    By contrast, a tightly coupled payment service would need inside knowledge of
    how the system represents its data or performs its task.
  prefs: []
  type: TYPE_NORMAL
- en: Robert Martin, the author of many widely respected books about software engineering,
    defined the single responsibility principle to explain that a class should have
    only one reason to change; in other words, each class should provide a single,
    well-defined feature. Applied to microservices, it means that we want to make
    sure that each microservice focuses on a single role.
  prefs: []
  type: TYPE_NORMAL
- en: Smaller projects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second benefit is breaking the complexity of the project. When you add a
    feature to an application such as PDF reporting, even if you do it cleanly, you
    make the code base bigger, more complicated, and sometimes slower. Building that
    feature in a separate application avoids this problem and makes it easier to write
    it with whatever tools you want. You can refactor it often, shorten your release
    cycles, and stay on top of things. The growth of the application remains under
    your control.
  prefs: []
  type: TYPE_NORMAL
- en: 'Dealing with a smaller project also reduces risks when improving the application:
    if a team wants to try out the latest programming language or framework, they
    can iterate quickly on a prototype that implements the same microservice API,
    try it out, and decide whether or not to stick with it.'
  prefs: []
  type: TYPE_NORMAL
- en: One real-life example is the Firefox Sync storage microservice. There were experiments
    to switch from storing data in MySQL, to an implementation that stores users'
    data in standalone SQLite databases. The risks of an experimental prototype were
    mitigated by isolating the storage feature in a microservice with a well-defined
    HTTP API. This minimized the unexpected interactions with other components and
    allowed a small subset of the user base to try out the new version of the service.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the size of each component also makes it easier to think about for
    developers, especially new ones joining the team or ones who are stressed about
    handling an outage with the service. Instead of having to work through an entire
    system, a developer can focus on a smaller area and not worry about the rest of
    the application's features.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling and deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, having your application split into components makes it easier to scale
    depending on your constraints. Let's say your business grows and there are many
    more customers who book hotels each day, and the PDF generation starts to use
    more resources and slows down. To tackle this problem, you can deploy that specific
    microservice in some servers that have bigger CPUs or more memory.
  prefs: []
  type: TYPE_NORMAL
- en: Another typical example is a high memory usage microservice, such as ones that
    interact with in-memory databases such as **Redis** or **Memcached**. You could
    tweak your deployments, consequently, by using servers with less CPU and a lot
    more RAM.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can, thus, summarize the benefits of microservices as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A team can develop each microservice independently, and use whatever technology
    stack makes sense. They can define a custom release cycle. All they need to define
    is a language-agnostic HTTP API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developers split the application complexity into logical components. Each microservice
    focuses on doing one thing well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since microservices are standalone applications, there's finer control over
    deployments, which makes scaling easier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The microservices architecture is good at solving a lot of the problems that
    may arise once your application starts to grow. However, we need to be aware of
    some of the new issues that are brought along.
  prefs: []
  type: TYPE_NORMAL
- en: Pitfalls of microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed earlier, building an application with microservices has many benefits,
    but it's not a silver bullet by any means.
  prefs: []
  type: TYPE_NORMAL
- en: 'You need to be aware of these main problems you might have to deal with when
    coding microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: Illogical splitting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More network interactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data storing and sharing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compatibility issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These issues will be covered in detail in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Illogical splitting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first issue of a microservice architecture is how it gets designed. There's
    no way a team can come up with the perfect microservice architecture on their
    first shot. Some microservices like the PDF generator are an obvious use case.
    But as soon as you deal with the business logic, there's a good chance that your
    code will move around before you get a good grasp of how to split things into
    the right set of microservices.
  prefs: []
  type: TYPE_NORMAL
- en: The design needs to mature with some try-and-fail cycles. And adding and removing
    microservices can be more painful than refactoring a monolithic application. You
    can mitigate this problem by avoiding splitting your app into microservices if
    the split is not evident.
  prefs: []
  type: TYPE_NORMAL
- en: If there's any doubt that the split makes sense, keeping the code in the same
    app is the safe bet. It's always easier to split apart some of the code into a
    new microservice later than to merge two microservices back in the same code base
    because the decision turned out to be wrong.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if you always have to deploy two microservices together, or if
    one change in a microservice impacts the data model of the other one, the odds
    are that you did not split the application correctly and that those two services
    should be reunited.
  prefs: []
  type: TYPE_NORMAL
- en: More network interactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second problem is the number of network interactions added to build the
    same application. In the monolithic version, even if the code gets messy, everything
    happens in the same process, and you can send back the result without having to
    call too many backend services to build the actual response.
  prefs: []
  type: TYPE_NORMAL
- en: 'That requires extra attention to how each backend service is called and raises
    a lot of questions, like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What happens when the Booking UI cannot reach the PDF reporting service because
    of a network split or a laggy service?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the Booking UI call the other services synchronously or asynchronously?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will that impact the response time?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will need to have a solid strategy to be able to answer all those questions,
    and we will address those in *Chapter 6*, *Interacting with Other Services*.
  prefs: []
  type: TYPE_NORMAL
- en: Data storing and sharing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another problem is data storing and sharing. An effective microservice needs
    to be independent of other microservices, and ideally, should not share a database.
    What does this mean for our hotel booking app?
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, that raises a lot of questions, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Do we use the same users' IDs across all databases, or do we have independent
    IDs in each service and keep it as a hidden implementation detail?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once a user is added to the system, do we replicate some of her information
    in other services' databases via strategies like data pumping, or is that overkill?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we deal with data removal?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are hard questions to answer, and there are many different ways to solve
    those problems, as we'll learn throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding data duplication as much as possible while keeping microservices in
    isolation is one of the biggest challenges in designing microservices-based applications.
  prefs: []
  type: TYPE_NORMAL
- en: Compatibility issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another problem happens when a feature change impacts several microservices.
    If a change affects, in a backward-incompatible way, the data that travels between
    services, you're in for some trouble.
  prefs: []
  type: TYPE_NORMAL
- en: Can you deploy your new service, and will it work with older versions of other
    services? Or do you need to change and deploy several services at once? Does it
    mean you've just stumbled on some services that should probably be merged back
    together?
  prefs: []
  type: TYPE_NORMAL
- en: Good versioning and API design hygiene helps to mitigate those issues, as we
    will discover in the second part of the book, when we'll build our application.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Lastly, when you want to do some end-to-end tests and deploy your whole app,
    you have to deal with many components. You need to have a robust and agile deployment
    process to be efficient. You need to be able to play with your whole application
    when you develop it. You can't fully test things out with just one piece of the
    puzzle, although having a clean and well-defined interface does help.
  prefs: []
  type: TYPE_NORMAL
- en: Many of the recent developments in cloud orchestration tools, such as Kubernetes,
    Terraform, and CloudFormation make life much easier when deploying an application
    that consists of several components. They can be used to create test and staging
    environments as well as production, customer-facing deployments. The popularity
    of these tools has helped in the success and adoption of microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices-style architecture boosts deployment tools' innovation, and deployment
    tools lower the bar for the approval of microservices-style architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pitfalls of using microservices can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Premature splitting of an application into microservices can lead to architectural
    problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network interactions between microservices add potential points of failure and
    additional overhead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing and deploying microservices can be complex.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And the biggest challenge—data sharing between microservices is hard.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should not worry too much about all the pitfalls described in this section
    for now. They may seem overwhelming, and the traditional monolithic application
    may look like a safer bet, but in the long term, splitting your project into microservices
    will make many of your tasks, as a developer or as an **operations person** (**ops**),
    easier. It can also make running a service cheaper. To add more capacity to a
    monolithic application, you need a larger server, or the ability to add more large
    servers. If the architecture is distributed and based around microservices, then
    extra resources can be added in smaller increments, holding far closer to the
    amount actually needed. And as we will discover in *Chapter 9:* *Deployment, Running,
    and Scaling*, it can be easier to set a cloud service provider up to automatically
    scale based on demand.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing microservices with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is an amazingly versatile language. As you probably already know, Python
    is used to build many different kinds of applications – from simple system scripts
    that perform tasks on a server to large object-oriented applications that run
    services for millions of users. Python is also used in machine learning and data
    analysis tools.
  prefs: []
  type: TYPE_NORMAL
- en: Python sits comfortably in the top five languages in the TIOBE index ([http://www.tiobe.com/tiobe-index/](http://www.tiobe.com/tiobe-index/)),
    and has reached as high as number two. It's probably even bigger in the web development
    world since languages like C are rarely used as main languages to build web applications.
  prefs: []
  type: TYPE_NORMAL
- en: This book makes the assumption that you are already familiar with the Python
    programming language. If you are not an experienced Python developer, you can
    read the book *Expert Python Programming*, *Third Edition*, where you will learn
    advanced programming skills in Python.
  prefs: []
  type: TYPE_NORMAL
- en: However, some developers criticize Python for being slow and unfit for building
    efficient web services. Python is slow, and this is undeniable, though it is fast
    enough for most situations. But it still is the language of choice for building
    microservices, and many major companies happily use it.
  prefs: []
  type: TYPE_NORMAL
- en: This section will give you some background on the different ways you can write
    microservices using Python, offer some insights on asynchronous versus synchronous
    programming, and conclude with some details on Python performance.
  prefs: []
  type: TYPE_NORMAL
- en: How web services work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we imagine a simple program that answers queries on the web, the description
    is straightforward. A new connection is made, and the protocol is negotiated.
    A request is made, and some processing is done: perhaps a database is queried.
    Then a response is structured and sent, and the connection is closed. This is
    often how we want to think about our application''s logic, because it keeps things
    simple for the developer as well as anyone else responsible for the program once
    it''s running.'
  prefs: []
  type: TYPE_NORMAL
- en: The web is a big, complicated place, though. Various parts of the internet will
    try to do malicious things to a vulnerable web service they find. Others just
    behave badly because they have not been set up well. Even when things are working
    well, there are different HTTP protocol versions, encryption, load balancing,
    access control, and a whole set of other things to think about.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than reinvent all of this technology, there are **interfaces** and **frameworks**
    that let us use the tools that other people have built, and spend more of our
    time working on our own applications. They let us use web servers such as **Apache**
    and **nginx** and let them handle the difficult parts of being on the web, such
    as certificate management, load balancing, and handling multiple website identities.
    Our application then has a smaller, more manageable configuration to control its behavior.
  prefs: []
  type: TYPE_NORMAL
- en: The WSGI standard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What strikes most web developers who start with Python is how easy it is to
    get a web application up and running.
  prefs: []
  type: TYPE_NORMAL
- en: Inspired by the older **Common Gateway Interface** (**CGI**), the Python web
    community has created a standard called the **Web Server Gateway Interface** (**WSGI**).
    It simplifies how you can write a Python application in order to serve HTTP requests.
    When your code uses this standard, your project can be executed by standard web
    servers like Apache or nginx, using WSGI extensions like `uwsgi` or `mod_wsgi`.
  prefs: []
  type: TYPE_NORMAL
- en: Your application just has to deal with incoming requests and send back JSON
    responses, and Python includes all that goodness in its standard library.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create a fully functional microservice that returns the server''s local
    time with a vanilla Python module of fewer than 10 lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Since its introduction, the WSGI protocol has become an essential standard,
    and the Python web community has widely adopted it. Developers have written middleware,
    which are functions you can hook before or after the WSGI application function
    itself, to do something within the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Some web frameworks, such as **Bottle** ([http://bottlepy.org](http://bottlepy.org)),
    were created specifically around that standard, and soon enough, every framework
    out there could be used through WSGI in one way or another.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest problem with WSGI, though, is its synchronous nature. More recently,
    the **Asynchronous Server Gateway Interface** (**ASGI**) has emerged as a successor
    to WSGI, allowing frameworks to operate asynchronously with the same seamless
    behavior as before. What are synchronous and asynchronous applications? We will
    cover that now.
  prefs: []
  type: TYPE_NORMAL
- en: Workers, threads, and synchronicity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Thinking back to our simple application that handles requests, our model of
    the program is synchronous. This means that it accepts a piece of work, does that
    work, and returns the result, but while it's doing all of that, the program can't
    do anything else. Any other requests that come in when it's already working on
    something will have to wait.
  prefs: []
  type: TYPE_NORMAL
- en: There are several approaches to solving this problem, from using worker pools
    to early context switching environments, and more recently, full asynchronous
    Python.
  prefs: []
  type: TYPE_NORMAL
- en: A worker pool approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Accepting a new request is often very fast, and the bulk of the time is taken
    up by doing the work that has been requested. Reading a request that tells you
    "Give me a list of all our customers in Paris" takes much less time than putting
    the list together and sending it back.
  prefs: []
  type: TYPE_NORMAL
- en: When an application has lots of requests arriving, an effective strategy is
    to ensure that all the heavy lifting is done using other processes or threads.
    Starting a new thread can be slow, and starting a new process is even slower,
    and so a common technique is to start these workers early and keep them around,
    giving them new work to do as it arrives.
  prefs: []
  type: TYPE_NORMAL
- en: This is an old technique and a very effective one, but it does have limitations.
    As far as each worker is concerned, it receives work, and can't do anything else
    until it has finished. This means that if you have eight worker processes, you
    can only handle eight simultaneous requests. Your application could create more
    workers if it is running low, but there is always a bottleneck.
  prefs: []
  type: TYPE_NORMAL
- en: There is also a practical limit to the number of processes and threads that
    an application can create, and swapping between them takes a lot of time that
    a responsive application can't always afford.
  prefs: []
  type: TYPE_NORMAL
- en: Being asynchronous
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One important thing to realize is that computers interacting with each other
    is a slow process. Not from a human perspective, where a new message from a family
    member can appear on our phones in the blink of an eye, but from the perspective
    of the computer itself.
  prefs: []
  type: TYPE_NORMAL
- en: There are several charts available that suggest "*Latency Numbers Every Programmer
    Should Know*," originally by *Jeff Dean* and *Peter Norvig*. A version of it can
    be found at [https://colin-scott.github.io/personal_website/research/interactive_latency.html](https://colin-scott.github.io/personal_website/research/interactive_latency.html).
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of numbers in these tables, but the important ones for us are
    the ones about network traffic. We can learn that reading about 1 MB from a computer's
    memory takes about 3,000 ns, but sending a packet over the network to a computer
    in the same building, and getting a response, can take about 500,000 ns. Talking
    to a computer on another continent can take hundreds of milliseconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'To put this in human terms: it might take you a few seconds to remember that
    you need to ask someone a question. Sending them the question and hearing back
    that they''ve read it, whether or not you get the answer you need, might take
    two days.'
  prefs: []
  type: TYPE_NORMAL
- en: You don't really want to be sitting there doing nothing while waiting for an
    answer, but that's what a process usually does if it's synchronous. An asynchronous
    program is aware that some tasks it has been told to perform might take a long
    time, and so it can get on with some other work while it is waiting, without necessarily
    having to use other processes or threads.
  prefs: []
  type: TYPE_NORMAL
- en: Twisted, Tornado, Greenlets, and Gevent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For a long time, non-WSGI frameworks like **Twisted** and **Tornado** were the
    popular answers for concurrency when using Python, allowing developers to specify
    **callbacks** for many simultaneous requests. In a sequential program, you might
    call a function and wait for it to return a value to you. A callback is a technique
    where the calling part of the program doesn't wait but instead tells the function
    what it should do with the result it generates. Often this is another function
    that it should call.
  prefs: []
  type: TYPE_NORMAL
- en: Another popular approach involved Greenlets and Gevent. The **Greenlet** project
    ([https://github.com/python-greenlet/greenlet](https://github.com/python-greenlet/greenlet))
    is a package based on the **Stackless** project, a particular CPython implementation,
    and provides *greenlets*.
  prefs: []
  type: TYPE_NORMAL
- en: Greenlets are *pseudo-threads* that are very cheap to instantiate, unlike real
    threads, and that can be used to call Python functions. Within those functions,
    you can *switch*, and give back the control to another function. The switching
    is done with an event loop and allows you to write an asynchronous application
    using a thread-like interface paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: However, switching from one greenlet to another has to be done explicitly, and
    the resulting code can quickly become messy and hard to understand. That's where
    Gevent can become very useful. The **Gevent** project ([http://www.gevent.org/](http://www.gevent.org/))
    is built on top of Greenlet and offers an implicit and automatic way of switching
    between greenlets, among many other things.
  prefs: []
  type: TYPE_NORMAL
- en: With the experience from all of these options, Python now has `asyncio` as a
    core feature of the language since 3.5, and this is what we will be using in our
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When *Guido* *van Rossum* started to work on adding async features in Python
    3, part of the community pushed for a Gevent-like solution, because it made a
    lot of sense to write applications in a synchronous, sequential fashion rather
    than having to add explicit callbacks like in Tornado or Twisted.
  prefs: []
  type: TYPE_NORMAL
- en: But Guido picked the explicit technique and experimented in a project called
    **Tulip** inspired by Twisted. Eventually, the `asyncio` module was born out of
    that side project and added into Python.
  prefs: []
  type: TYPE_NORMAL
- en: In hindsight, implementing an explicit event loop mechanism in Python instead
    of going the Gevent way makes a lot of sense. The way the Python core developers
    coded asyncio, and how they extended the language with the `async` and `await`
    keywords to implement coroutines, made asynchronous applications built with vanilla
    Python 3.5+ code look very elegant and close to synchronous programming.
  prefs: []
  type: TYPE_NORMAL
- en: Python 3 has introduced a full set of features and helpers in the asyncio package
    to build asynchronous applications; refer to [https://docs.python.org/3/library/asyncio.html](https://docs.python.org/3/library/asyncio.html).
  prefs: []
  type: TYPE_NORMAL
- en: '**aiohttp** ([http://aiohttp.readthedocs.io](http://aiohttp.readthedocs.io))
    is one of the most mature asyncio packages, and building the earlier "time" microservice
    with it would simply need these few lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this small example, we're very close to how we would implement a synchronous
    app. The only hint we're using asynchronous code is the `async` keyword, which
    marks the `handle` function as being a coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: 'And this concept is what''s going to be used at every level of an async Python
    app going forward. Here''s another example using `aiopg`, a PostgreSQL library
    for asyncio from the project documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: With a few `async` and `await` prefixes, the function that performs an SQL query
    and sends back the result looks a lot like a synchronous function. We will explain
    more about this code in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: If you need to use a library that is not asynchronous in your code, to use it
    from your asynchronous code means that you will need to go through some extra
    and challenging work if you want the different libraries to work well together.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many great synchronous frameworks to build microservices with Python,
    like **Bottle**, **Pyramid** with **Cornice**, or **Flask**. We will be using
    one that is very similar to Flask, but is also asynchronous: **Quart**.'
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that whatever Python web framework you use, you should be able
    to transpose all the examples in this book. This is because most of the coding
    involved when building microservices is very close to plain Python, and the framework
    is mostly to route the requests and offer a few helpers.
  prefs: []
  type: TYPE_NORMAL
- en: Language performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous sections, we went through the two different ways to write microservices:
    asynchronous versus synchronous, and whatever technique you use, the speed of
    Python directly impacts the performance of your microservice.'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, everyone knows Python is slower than Java or Go, but execution speed
    is not always the top priority. A microservice is often a thin layer of code that
    sits most of its life waiting for some network responses from other services.
    Its core speed is usually less important than how fast your SQL queries will take
    to return from your Postgres server, because the latter will represent most of
    the time spent building the response.
  prefs: []
  type: TYPE_NORMAL
- en: It's also important to remember that how long you spend developing the software
    can be just as important. If your services are rapidly changing, or a new developer
    joins and has to understand the code, it is important to have code that is easy
    to understand, develop, and deploy.
  prefs: []
  type: TYPE_NORMAL
- en: But wanting an application that's as fast as possible is legitimate.
  prefs: []
  type: TYPE_NORMAL
- en: One controversial topic in the Python community around speeding up the language
    is how the **Global Interpreter Lock** (**GIL**) can affect performance, because
    multi-threaded applications cannot use several processes.
  prefs: []
  type: TYPE_NORMAL
- en: The GIL has good reasons to exist. It protects non-thread-safe parts of the
    CPython interpreter and exists in other languages like Ruby. And all attempts
    to remove it so far have failed to produce a faster CPython implementation.
  prefs: []
  type: TYPE_NORMAL
- en: For microservices, besides preventing the usage of multiple cores in the same
    process, the GIL will slightly degrade performance under high load because of
    the system calls overhead introduced by the mutex.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, all the scrutiny around the GIL has been beneficial: work has been
    done in the past to reduce GIL contention in the interpreter, and in some areas,
    Python''s performance has improved a lot. Changes in Python 3.8 to introduce subinterpreters
    and multiple locks have also helped with some areas.'
  prefs: []
  type: TYPE_NORMAL
- en: Bear in mind that even if the core team removes all the GIL performance issues,
    Python is an interpreted and garbage collected language and suffers performance
    penalties for those properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python provides the `dis` module if you are interested in seeing how the interpreter
    decomposes a function. In the following example, the interpreter will decompose
    a simple function that yields incremented values from a sequence in no less than
    22 steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: A similar function written in a statically compiled language will dramatically
    reduce the number of operations required to produce the same result. There are
    ways to speed up Python execution, though.
  prefs: []
  type: TYPE_NORMAL
- en: One is to write a part of your code in compiled code by building extensions
    in C, Rust, or another compiled language, or using a static extension of the language
    like **Cython** ([http://cython.org/](http://cython.org/)), but that makes your
    code more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: Another solution is by simply running your application using the **PyPy** interpreter
    ([http://pypy.org/](http://pypy.org/)). This can give noticeable performance improvements
    just by swapping out the Python interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: PyPy implements a **Just-In-Time** (**JIT**) compiler. This compiler directly
    replaces, at runtime, pieces of Python with machine code that can be directly
    used by the CPU. The whole trick for the JIT compiler is to detect in real time,
    ahead of the execution, when and how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Even if PyPy is always a few Python versions behind CPython, it has reached
    a point where you can use it in production, and its performance can be quite amazing.
    In one of our projects at Mozilla that needs fast execution, the PyPy version
    was almost as fast as the Go version, and we decided to use Python there instead.
  prefs: []
  type: TYPE_NORMAL
- en: The Pypy Speed Center website is a great place to look at how PyPy compares
    to CPython ( [http://speed.pypy.org/](http://speed.pypy.org/)).
  prefs: []
  type: TYPE_NORMAL
- en: However, if your program uses C extensions or has any other compiled dependencies,
    you will need to recompile them for PyPy, and that extra work must be balanced
    against the speed improvements, especially if you are depending on another project
    or other developers to maintain the extensions you are using.
  prefs: []
  type: TYPE_NORMAL
- en: But if you build your microservice with a standard set of libraries, chances
    are that it will work out of the box with the PyPy interpreter, so that's worth
    a try. In any case, for most projects, the benefits of Python and its ecosystem
    largely surpass the performance issues described in this section, because the
    overhead in a microservice is rarely a problem. And if performance is a problem,
    the microservice approach allows you to rewrite and scale performance-critical
    components without affecting the rest of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've compared the monolithic and microservice approaches to
    building web applications, and it became apparent that there's not a binary choice
    where you have to pick one model on day one and stick with it.
  prefs: []
  type: TYPE_NORMAL
- en: You should see microservices as an improvement of an application that started
    its life as a monolith. As the project matures, parts of the service logic should
    migrate into microservices. It is a useful approach, as we've learned in this
    chapter, but it should be done carefully to avoid falling into some common traps.
  prefs: []
  type: TYPE_NORMAL
- en: Another important lesson is that Python is considered to be one of the best
    languages to write web applications and, therefore, microservices. For the same
    reasons, it's a language of choice in other areas, and also because it provides
    many mature frameworks and packages to do the work.
  prefs: []
  type: TYPE_NORMAL
- en: Python can be a slow language, and that can be a problem in very specific cases.
    Knowing what makes it slow, and the different solutions to avoid this issue, will
    usually be enough to work through any trouble.
  prefs: []
  type: TYPE_NORMAL
- en: We've rapidly looked at several frameworks, both synchronous and asynchronous,
    and for the rest of the book, we'll be using Quart. The next chapter will introduce
    this fantastic framework.
  prefs: []
  type: TYPE_NORMAL
