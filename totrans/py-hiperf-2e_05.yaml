- en: Exploring Compilers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is a mature and widely used language and there is a large interest in
    improving its performance by compiling functions and methods directly to machine
    code rather than executing instructions in the interpreter. We have already seen
    a compiler example in [Chapter 4](ce893a62-a46c-4575-8163-01921cf8bb7b.xhtml),
    *C Performance with Cython*, where Python code is enhanced with types, compiled
    to efficient C code, and the interpreter calls are side-stepped.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore two projects--Numba and PyPy--that approach
    compilation in a slightly different way. **Numba** is a library designed to compile
    small functions on the fly. Instead of transforming Python code to C, Numba analyzes
    and compiles Python functions directly to machine code. **PyPy** is a replacement
    interpreter that works by analyzing the code at runtime and optimizing the slow
    loops automatically.
  prefs: []
  type: TYPE_NORMAL
- en: These tools are called **Just**-**In**-**Time** (**JIT**) compilers because
    the compilation is performed at runtime rather than before running the code (in
    other cases, the compiler is called ahead-of-time or AOT).
  prefs: []
  type: TYPE_NORMAL
- en: 'The list of topics to be covered in this chapter is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Numba
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing fast functions with native mode compilation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding and implementing universal functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JIT classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up PyPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the particle simulator with PyPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other interesting compilers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Numba
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Numba was started in 2012 by Travis Oliphant, the original author of NumPy,
    as a library for compiling individual Python functions at runtime using the **Low-Level
    Virtual Machine** (**LLVM**) toolchain.
  prefs: []
  type: TYPE_NORMAL
- en: LLVM is a set of tools designed to write compilers. LLVM is language agnostic
    and is used to write compilers for a wide range of languages (an important example
    is the clang compiler). One of the core aspects of LLVM is the intermediate representation
    (the LLVM IR), a very low-level platform-agnostic language similar to assembly,
    that can be compiled to machine code for the specific target platform.
  prefs: []
  type: TYPE_NORMAL
- en: Numba works by inspecting Python functions and by compiling them, using LLVM,
    to the IR. As we have already seen in the last chapter, the speed gains can be
    obtained when we introduce types for variables and functions. Numba implements
    clever algorithms to guess the types (this is called type inference) and compiles
    type-aware versions of the functions for fast execution.
  prefs: []
  type: TYPE_NORMAL
- en: Note that Numba was developed to improve the performance of numerical code.
    The development efforts often prioritize the optimization of applications that
    intensively use NumPy arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Numba is evolving really fast and can have substantial improvements between
    releases and, sometimes, backward incompatible changes.  To keep up, ensure that
    you refer to the release notes for each version. In the rest of this chapter,
    we will use Numba version 0.30.1; ensure that you install the correct version
    to avoid any error.
  prefs: []
  type: TYPE_NORMAL
- en: The complete code examples in this chapter can be found in the `Numba.ipynb` notebook.
  prefs: []
  type: TYPE_NORMAL
- en: First steps with Numba
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Getting started with Numba is fairly straightforward. As a first example, we
    will implement a function that calculates the sum of squares of an array. The
    function definition is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To set up this function with Numba, it is sufficient to apply the `nb.jit`
    decorator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `nb.jit` decorator won't do much when applied. However, when the function
    will be invoked for the first time, Numba will detect the type of the input argument, `a`
    , and compile a specialized, performant version of the original function.
  prefs: []
  type: TYPE_NORMAL
- en: 'To measure the performance gain obtained by the Numba compiler, we can compare
    the timings of the original and the specialized functions. The original, undecorated
    function can be easily accessed through the `py_func` attribute. The timings for
    the two functions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'From the previous code, you can see how the Numba version (11.7 µs) is one
    order of magnitude faster than the Python version (6.11 ms). We can also compare
    how this implementation stacks up against NumPy standard operators:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the Numba compiled function is marginally faster than NumPy vectorized
    operations. The reason for the extra speed of the Numba version is likely that
    the NumPy version allocates an extra array before performing the sum in comparison
    with the in-place operations performed by our `sum_sq` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we didn''t use array-specific methods in `sum_sq`, we can also try to apply
    the same function on a regular Python list of floating point numbers. Interestingly,
    Numba is able to obtain a substantial speed up even in this case, as compared
    to a list comprehension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Considering that all we needed to do was apply a simple decorator to obtain
    an incredible speed up over different data types, it's no wonder that what Numba
    does looks like magic. In the following sections, we will dig deeper and understand
    how Numba works and evaluate the benefits and limitations of the Numba compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Type specializations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As shown earlier, the `nb.jit` decorator works by compiling a specialized version
    of the function once it encounters a new argument type. To better understand how
    this works, we can inspect the decorated function in the `sum_sq` example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Numba exposes the specialized types using the `signatures` attribute. Right
    after the `sum_sq` definition, we can inspect the available specialization by
    accessing the `sum_sq.signatures`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If we call this function with a specific argument, for instance, an array of
    `float64` numbers, we can see how Numba compiles a specialized version on the
    fly. If we also apply the function on an array of `float32`, we can see how a
    new entry is added to the `sum_sq.signatures` list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: It is possible to explicitly compile the function for certain types by passing
    a signature to the `nb.jit` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'An individual signature can be passed as a tuple that contains the type we
    would like to accept. Numba provides a great variety of types that can be found
    in the `nb.types` module, and they are also available in the top-level `nb` namespace.
    If we want to specify an array of a specific type, we can use the slicing operator, `[:]`,
    on the type itself. In the following example, we demonstrate how to declare a
    function that takes an array of `float64` as its only argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that when we explicitly declare a signature, we are prevented from using
    other types, as demonstrated in the following example. If we try to pass an array, `x`,
    as `float32`, Numba will raise a `TypeError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Another way to declare signatures is through type strings. For example, a function
    that takes a `float64` as input and returns a `float64` as output can be declared
    with the `float64(float64)` string. Array types can be declared using a `[:]`
    suffix. To put this together, we can declare a signature for our `sum_sq` function,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also pass multiple signatures by passing a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Object mode versus native mode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have shown how Numba behaves when handling a fairly simple function.
    In this case, Numba worked exceptionally well, and we obtained great performance
    on arrays and lists.
  prefs: []
  type: TYPE_NORMAL
- en: The degree of optimization obtainable from Numba depends on how well Numba is
    able to infer the variable types and how well it can translate those standard
    Python operations to fast type-specific versions. If this happens, the interpreter
    is side-stepped and we can get performance gains similar to those of Cython.
  prefs: []
  type: TYPE_NORMAL
- en: When Numba cannot infer variable types, it will still try and compile the code,
    reverting to the interpreter when the types can't be determined or when certain
    operations are unsupported. In Numba, this is called **object mode** and is in
    contrast to the interpreter-free scenario, called **native mode**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Numba provides a function, called `inspect_types`, that helps understand how
    effective the type inference was and which operations were optimized. As an example,
    we can take a look at the types inferred for our `sum_sq` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'When this function is called, Numba will print the type inferred for each specialized
    version of the function. The output consists of blocks that contain information
    about variables and types associated with them. For example, we can examine the `N
    = len(a)` line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: For each line, Numba prints a thorough description of variables, functions,
    and intermediate results. In the preceding example, you can see (second line)
    that the argument `a` is correctly identified as an array of `float64` numbers.
    At `LINE 4`, the input and return type of the `len` function is also correctly
    identified (and likely optimized) as taking an array of `float64` numbers and
    returning an `int64`.
  prefs: []
  type: TYPE_NORMAL
- en: If you scroll through the output, you can see how all the variables have a well-defined
    type. Therefore, we can be certain that Numba is able to compile the code quite
    efficiently. This form of compilation is called **native mode**.
  prefs: []
  type: TYPE_NORMAL
- en: As a counter example, we can see what happens if we write a function with unsupported
    operations. For example, as of version 0.30.1, Numba has limited support for string
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can implement a function that concatenates a series of strings, and compiles
    it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can invoke this function with a list of strings and inspect the types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Numba will return the output of the function for the `reflected list (str)` type.
    We can, for instance, examine how line 3 gets inferred. The output of `concatenate.inspect_types()`
    is reproduced here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see how this time, each variable or function is of the generic `pyobject`
    type rather than a specific one. This means that, in this case, Numba is unable
    to compile this operation without the help of the Python interpreter. Most importantly,
    if we time the original and compiled function, we note that the compiled function
    is about three times *slower* than the pure Python counterpart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This is because the Numba compiler is not able to optimize the code and adds
    some extra overhead to the function call.
  prefs: []
  type: TYPE_NORMAL
- en: As you may have noted, Numba compiled the code without complaints even if it
    is inefficient. The main reason for this is that Numba can still compile other
    sections of the code in an efficient manner while falling back to the Python interpreter
    for other parts of the code. This compilation strategy is called **object mode**.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible to force the use of native mode by passing the `nopython=True`
    option to the `nb.jit` decorator. If, for example, we apply this decorator to
    our concatenate function, we observe that Numba throws an error on first invocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This feature is quite useful for debugging and ensuring that all the code is
    fast and correctly typed.
  prefs: []
  type: TYPE_NORMAL
- en: Numba and NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Numba was originally developed to easily increase performance of code that uses
    NumPy arrays. Currently, many NumPy features are implemented efficiently by the
    compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Universal functions with Numba
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Universal functions are special functions defined in NumPy that are able to
    operate on arrays of different sizes and shapes according to the broadcasting
    rules. One of the best features of Numba is the implementation of fast `ufuncs`.
  prefs: []
  type: TYPE_NORMAL
- en: We have already seen some `ufunc` examples in [Chapter 3](fb5356db-d238-4571-b5de-663a8400ad6d.xhtml)*,
    Fast Array Operations with NumPy and Pandas*. For instance, the `np.log` function
    is a `ufunc` because it can accept scalars and arrays of different sizes and shapes.
    Also, universal functions that take multiple arguments still work according to
    the  broadcasting rules. Examples of universal functions that take multiple arguments
    are `np.sum` or `np.difference`.
  prefs: []
  type: TYPE_NORMAL
- en: Universal functions can be defined in standard NumPy by implementing the scalar
    version and using the `np.vectorize` function to enhance the function with the
    broadcasting feature. As an example, we will see how to write the *Cantor pairing
    function*.
  prefs: []
  type: TYPE_NORMAL
- en: 'A pairing function is a function that encodes two natural numbers into a single
    natural number so that you can easily interconvert between the two representations.
    The Cantor pairing function can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'As already mentioned, it is possible to create a ufunc in pure Python using
    the `np.vectorized` decorator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Except for the convenience, defining universal functions in pure Python is not
    very useful as it requires a lot of function calls affected by interpreter overhead.
    For this reason, ufunc implementation is usually done in C or Cython, but Numba
    beats all these methods by its convenience.
  prefs: []
  type: TYPE_NORMAL
- en: 'All that is needed to do in order to perform the conversion is using the equivalent
    decorator, `nb.vectorize`. We can compare the speed of the standard `np.vectorized`
    version which, in the following code, is called `cantor_py`, and the same function
    is implemented using standard NumPy operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: You can see how the Numba version beats all the other options by a large margin!
    Numba works extremely well because the function is simple and type inference is
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: An additional advantage of universal functions is that, since they depend on
    individual values, their evaluation can also be executed in parallel. Numba provides
    an easy way to parallelize such functions by passing the `target="cpu"` or `target="gpu"`
    keyword argument to the `nb.vectorize` decorator.
  prefs: []
  type: TYPE_NORMAL
- en: Generalized universal functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main limitations of universal functions is that they must be defined
    on scalar values. A generalized universal function, abbreviated `gufunc`, is an
    extension of universal functions to procedures that take arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'A classic example is the matrix multiplication. In NumPy, matrix multiplication
    can be applied using the `np.matmul` function, which takes two 2D arrays and returns
    another 2D array. An example usage of `np.matmul` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As we saw in the previous subsection, a `ufunc` broadcasts the operation over
    arrays of *scalars*, its natural generalization will be to broadcast over an array
    of *arrays*. If, for instance, we take two arrays of 3 by 3 matrices, we will
    expect `np.matmul` to take to match the matrices and take their product. In the
    following example, we take two arrays containing 10 matrices of shape `(3, 3)`.
    If we apply `np.matmul`, the product will be applied *matrix-wise* to obtain a
    new array containing the 10 results (which are, again, `(3, 3)` matrices):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The usual rules for broadcasting will work in a similar way. For example, if
    we have an array of `(3, 3)` matrices, which will have a shape of `(10, 3, 3)`,
    we can use `np.matmul` to calculate the matrix multiplication of each element
    with a single `(3, 3)` matrix. According to the broadcasting rules, we obtain
    that the single matrix will be repeated to obtain a size of `(10, 3, 3)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Numba supports the implementation of efficient generalized universal functions
    through the `nb.guvectorize` decorator. As an example, we will implement a function
    that computes the euclidean distance between two arrays as a `gufunc`. To create
    a `gufunc`, we have to define a function that takes the input arrays, plus an
    output array where we will store the result of our calculation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `nb.guvectorize` decorator requires two arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The types of the input and output: two 1D arrays as input and a scalar as output'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The so called layout string, which is a representation of the input and output
    sizes; in our case, we take two arrays of the same size (denoted arbitrarily by
    `n`), and we output a scalar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following example, we show the implementation of the `euclidean` function
    using the `nb.guvectorize` decorator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: There are a few very important points to be made. Predictably, we declared the
    types of the inputs `a` and `b` as `float64[:]`, because they are 1D arrays. However, what
    about the output argument? Wasn't it supposed to be a scalar? Yes, however, **Numba
    treats scalar argument as arrays of size 1**. That's why it was declared as `float64[:]`.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the layout string indicates that we have two arrays of size `(n)`
    and the output is a scalar, denoted by empty brackets--`()`. However, the array
    out will be passed as an array of size 1.
  prefs: []
  type: TYPE_NORMAL
- en: Also, note that we don't return anything from the function; all the output has
    to be written in the `out` array.
  prefs: []
  type: TYPE_NORMAL
- en: The letter `n` in the layout string is completely arbitrary; you may choose
    to use `k`  or other letters of your liking. Also, if you want to combine arrays
    of uneven sizes, you can use layouts strings, such as `(n, m)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our brand new `euclidean` function can be conveniently used on arrays of different
    shapes, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'How does the speed of `euclidean` compare to standard NumPy? In the following
    code, we benchmark a NumPy vectorized version with our previously defined `euclidean`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The Numba version, again, beats the NumPy version by a large margin!
  prefs: []
  type: TYPE_NORMAL
- en: JIT classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As of today, Numba doesn't support optimization of generic Python objects. This
    limitation, however, doesn't have a huge impact on numerical codes as they usually
    involve arrays and math operations exclusively.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, certain data structures are much more naturally implemented using
    objects; therefore, Numba provides support for defining classes that can be used
    and compiled to fast, native code.
  prefs: []
  type: TYPE_NORMAL
- en: Bear in mind that this is one of the newest (almost experimental) features,
    and it is extremely useful as it allows us to extend Numba to support fast data
    structures that are not easily implemented with arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, we will show how to implement a simple linked list using JIT
    classes. A linked list can be implemented by defining a `Node` class that contains
    two fields: a value and the next item in the list. As you can see in the following
    figure, each **Node** connects to the next and holds a value, and the last node
    contains a broken link, to which we assign a value of **None**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/linked_list.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Python, we can define the `Node` class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We can manage the collection of `Node` instances by creating another class,
    called `LinkedList`. This class will keep track of the head of the list (in the
    preceding figure, this corresponds to the **Node** with **value** **3**). To insert
    an element in the front of the list, we can simply create a new **Node** and link
    it to the current head.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we develop the initialization function for `LinkedList`
    and the `LinkedList.push_back` method that inserts an element in the front of
    the list using the strategy outlined earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'For debugging purposes, we can also implement the `LinkedList.show` method
    that traverses and prints each element in the list. The method is shown in the
    following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we can test our `LinkedList` and see whether it behaves correctly.
    We can create an empty list, add a few elements, and print its content. Note that
    since we are pushing elements at the front of the list, the last elements inserted
    will be the first to be printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can implement a function, `sum_list`, that returns the sum of the
    elements in the linked list. We will use this method to time differences between
    the Numba and pure Python version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'If we measure the execution time of the original `sum_list` version and the
    `nb.jit` version, we see that there is not much difference. The reason is that
    Numba cannot infer the type of classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We can improve the performance of `sum_list` by compiling the `Node` and `LinkedList`
    classes using the `nb.jitclass` decorator.
  prefs: []
  type: TYPE_NORMAL
- en: The `nb.jitclass` decorator takes a single argument that contains the attribute
    types. In the `Node` class, the attribute types are `int64` for `value` and `Node`
    for `next`. The `nb.jitclass` decorator will also compile all the methods defined
    for the class. Before delving into the code, there are two observations that need
    to be made.
  prefs: []
  type: TYPE_NORMAL
- en: First, the attribute declaration has to be done before the class is defined,
    but how do we declare a type we haven't defined yet? Numba provides the `nb.deferred_type()`
    function, which can be used for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Second, the `next` attribute can be either `None` or a `Node` instance. This
    is what is called an optional type, and Numba provides a utility, called `nb.optional`,
    that lets you declare variables that can be (optionally) `None`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This `Node` class is illustrated in the following code sample. As you can see, 
    `node_type` is predeclared using `nb.deferred_type()`. The attributes are declared
    as a list of pairs containing the attribute name and the type (also note the use
    of `nb.optional`). After the class declaration, we are required to declare the
    deferred type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The `LinkedList` class can be easily compiled, as follows. All that''s needed
    is to define the `head` attribute and to apply the `nb.jitclass` decorator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now measure the execution time of the `sum_list` function when we pass
    a JIT `LinkedList`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Interestingly, when using a JIT class from a compiled function, we obtain a
    substantial performance improvement against the pure Python version. However,
    using the JIT class from the original `sum_list.py_func` actually results in worse
    performance. Ensure that you use JIT classes only inside compiled functions!
  prefs: []
  type: TYPE_NORMAL
- en: Limitations in Numba
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are some instances where Numba cannot properly infer the variable types
    and will refuse to compile. In the following example, we define a function that
    takes a nested list of integers and returns the sum of the element in every sublist.
    In this case, Numba will raise `ValueError` and refuse to compile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The problem with this code is that Numba is not able to determine the type
    of the list and fails. A way to fix this problem is to help the compiler determine
    the right type by initializing the list with a sample element and removing it
    at the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Among other features that are not yet implemented in the Numba compiler are
    function and class definitions, list, set and dict comprehension, generators,
    the `with` statement, and `try` `except` blocks. Note, however, that many of these
    features may become supported in the future.
  prefs: []
  type: TYPE_NORMAL
- en: The PyPy project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyPy is a very ambitious project at improving the performance of the Python
    interpreter. The way PyPy improves performance is by automatically compiling slow
    sections of the code at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: PyPy is written in a special language called RPython (rather than C) that allows
    developers to quickly and reliably implement advanced features and improvements.
    RPython means *Restricted Python* because it implements a restricted subset of
    the Python language targeted to the compiler development.
  prefs: []
  type: TYPE_NORMAL
- en: As of today, PyPy version 5.6 supports a lot of Python features and is a possible
    choice for a large variety of applications.
  prefs: []
  type: TYPE_NORMAL
- en: PyPy compiles code using a very clever strategy, called *tracing JIT compilation*.
    At first, the code is executed normally using interpreter calls. PyPy then starts
    to profile the code and identifies the most intensive loops. After the identification
    takes place, the compiler then observes (*traces*) the operations and is able
    to compile its optimized, interpreter-free version.
  prefs: []
  type: TYPE_NORMAL
- en: Once an optimized version of the code is present, PyPy is able to run the slow
    loop much faster than the interpreted version.
  prefs: []
  type: TYPE_NORMAL
- en: This strategy can be contrasted with what Numba does. In Numba, the units of
    compilation are methods and functions, while the PyPy focus is just slow loops.
    Overall, the focus of the projects is also very different as Numba has a limited
    scope for numerical code and requires a lot of instrumentation while PyPy aims
    at replacing the CPython interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will demonstrate and benchmark PyPy on our particle simulator
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up PyPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyPy is distributed as a precompiled binary that can be downloaded from [http://pypy.org/download.html](http://pypy.org/download.html),
    and it currently supports Python versions 2.7 (beta support in PyPy 5.6) and 3.3
    (alpha support in PyPy 5.5). In this chapter, we will demonstrate the usage of
    the 2.7 version.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once PyPy is downloaded and unpacked, you can locate the interpreter in the
    `bin/pypy` directory relative to the unpacked archive. You can initialize a new
    virtual environment where we can install additional packages using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'To activate the environment, we will use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, you can verify that the binary Python is linked to the PyPy
    executable by typing `python -V`. At this point, we can go ahead and install some
    packages we may need. As of version 5.6, PyPy has limited support for software
    that uses the Python C API (most notably, packages such as `numpy` and `matplotlib`).
    We can go ahead and install them in the usual way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: On certain platforms, installation of `numpy` and `matplotlib` can be tricky.
    You can skip the installation step and remove any imports on these two packages
    from the scripts we will run.
  prefs: []
  type: TYPE_NORMAL
- en: Running a particle simulator in PyPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have successfully set up the PyPy installation, we can go ahead
    and run our particle simulator. As a first step, we will time the particle simulator
    from [Chapter 1](4db2c3e6-3485-41a5-8450-07220f6d80ec.xhtml), *Benchmarking and
    Profiling*, on the standard Python interpreter. If the virtual environment is
    still active, you can issue the command deactivate to exit the environment. We
    can confirm that the Python interpreter is the standard one by using the `python
    -V` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we can time our code using the `timeit` command-line interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We can reactivate the environment and run the exact same code from PyPy. On
    Ubuntu, you may have problems importing the `matplotlib.pyplot` module. You can
    try issuing the following `export` command to fix the issue or removing the `matplotlib`
    imports from `simul.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can go ahead and time the code using PyPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we obtained a large, more than eight times, speedup! PyPy, however,
    warns us that the `timeit` module can be unreliable. We can confirm our timings
    using the `perf` module, as suggested by PyPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Other interesting projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the years, many projects attempted to improve Python performance through
    several strategies and, sadly, many of them failed. As of today, there are a few
    projects that survive and hold the promise for a faster Python.
  prefs: []
  type: TYPE_NORMAL
- en: Numba and PyPy are mature projects that are steadily improving over the years.
    Features are continuously being added and they hold great promise for the future
    of Python.
  prefs: []
  type: TYPE_NORMAL
- en: '**Nuitka** is a program developed by Kay Hayen that compiles Python code to
    C. As of right now (version 0.5.x), it provides extreme compatibility with the
    Python language and produces efficient code that results in moderate performance
    improvements over CPython.'
  prefs: []
  type: TYPE_NORMAL
- en: Nuitka is quite different than Cython in the sense that it focuses on extreme
    compatibility with the Python language, and it doesn't extend the language with
    additional constructs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pyston** is a new interpreter developed by Dropbox that powers JIT compilers.
    It differs substantially from PyPy as it doesn''t employ a tracing JIT, but rather
    a method-at-a-time JIT (similar to what Numba does). Pyston, like Numba, is also
    built on top of the LLVM compiler infrastructure.'
  prefs: []
  type: TYPE_NORMAL
- en: Pyston is still in early development (alpha stage) and only supports Python
    2.7\. Benchmarks show that it is faster than CPython but slower than PyPy; that
    said, it is still an interesting project to follow as new features are added and
    compatibility is increased.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Numba is a tool that compiles fast, specialized versions of Python functions
    at runtime. In this chapter, we learned how to compile, inspect, and analyze functions
    compiled by Numba. We also learned how to implement fast NumPy universal functions
    that are useful in a wide array of numerical applications. Finally, we implemented
    more complex data structures using the `nb.jitclass` decorator.
  prefs: []
  type: TYPE_NORMAL
- en: Tools such as PyPy allow us to run Python programs unchanged to obtain significant
    speed improvements. We demonstrated how to set up PyPy, and we assessed the performance
    improvements on our particle simulator application.
  prefs: []
  type: TYPE_NORMAL
- en: We also, briefly, described the current ecosystem of the Python compilers and
    compared them with each other.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about concurrency and asynchronous programming.
    Using these techniques, we will be able to improve the responsiveness and design of
    applications that spend a lot of time waiting for network and disk resources.
  prefs: []
  type: TYPE_NORMAL
