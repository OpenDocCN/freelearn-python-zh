- en: '10'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Working with Type Matching and Annotations
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will look at how we can work with data structures that have a variety
    of data types. This often means inspecting the type of an attribute, an element
    of a tuple, or a value in a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: In previous chapters, we’ve avoided spending too much time on data validation
    considerations. In this chapter, we’ll look closely at validating input values
    to be sure they conform to expected data types and value ranges.
  prefs: []
  type: TYPE_NORMAL
- en: This data validation is a kind of type-checking. It validates a narrower domain
    of values than the very broad classes of integer or string. The application must
    check the values of objects to be sure they’re valid for the intended purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Some data structures like JSON or XML documents can contain objects of a variety
    of data types. A common situation is summarized as First Normal Form (1NF), where
    each item in a collection is of the same type. This isn’t universal, however.
    When parsing complex files like programming language statements, we’ll see a sequence
    of distinct data types. The presence of diverse types means that the application
    software can’t simply assume a single, consistent type, but must process the available
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll look at a number of recipes related to types and type
    matching:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Designing with type hints](ch014.xhtml#x1-5740001)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using the built-in type matching functions](ch014.xhtml#x1-5820002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using the match statement](ch014.xhtml#x1-5880003)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Handling type conversions](ch014.xhtml#x1-5940004)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Implementing more strict type checks with Pydantic](ch014.xhtml#x1-6000005)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Including run-time valid value checks](ch014.xhtml#x1-6060006)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.1 Designing with type hints
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Annotations in function definitions were introduced to the language syntax back
    in 2006, without any formal semantics. The annotations idea came with a list of
    potential use cases, one of which was type checking. In 2014, the idea of type
    hints were solidified and formalized into a typing module and some associated
    tools including the mypy tool.
  prefs: []
  type: TYPE_NORMAL
- en: For a few years, annotations were a general kind of syntax and type hints were
    a specific use case for annotations. By 2017, other uses for annotations were
    deprecated and the annotation syntax was expressly focused on type hints. While
    there was once a subtle difference between annotations and type hints, the distinction
    has since evaporated, leaving us with two synonyms.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three important aspects of using type hints:'
  prefs: []
  type: TYPE_NORMAL
- en: Type hints are optional. We can write Python without type hints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type hints can be applied gradually. Part of an application can have hints,
    where another part lacks them. Tools like mypy can tolerate mixtures of code with
    and without hints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type hints are not used at run time and have no performance overhead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughout this book, we’ve treated hints as essential to good software design.
    They’re as essential as unit tests and coherent documentation, both of which are
    also technically optional, but essential for trustworthy software. We’ve found
    them to help prevent problems by enforcing a level of rigor and formality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python’s processing relies on duck typing rules. For more background, see Chapter [8](ch012.xhtml#x1-4520008),
    specifically, the [Leveraging Python’s duck typing](ch012.xhtml#x1-4670003) recipe.
    There are two broad design patterns available to us:'
  prefs: []
  type: TYPE_NORMAL
- en: A strict hierarchy with a common superclass.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging duck typing, a collection of classes can have common features, often
    defined as a protocol that specifies the relevant features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this recipe, we’ll look at two approaches to designing code that includes
    type hints and can be checked by tools like mypy.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll look at a problem that involves working with two distinct types of data
    that are mingled together in a source file. In this case, we’re going to classify
    the contents of the data directory with a large number of data files. Additionally,
    we have an src directory with a large number of sub-directories that contain application
    programs and scripts. We want to create a collection of data structures to represent
    two distinct classes of data files:'
  prefs: []
  type: TYPE_NORMAL
- en: Data files not named by any application program or script
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data files that are referenced by one or more application programs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.1.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two broad strategies for designing this kind of program:'
  prefs: []
  type: TYPE_NORMAL
- en: Sketch out the data types and transformations first, then write code to fit
    the types.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write code first and then add type hints to the working code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neither can be described as best. In many cases, the two evolve side by side.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll look at each of these in separate variations in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Type hints first design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We’re going to work with diverse classes of objects. In this variation, we’ll
    define the type hints first, and then fill in the needed processing. Here’s how
    we can define a classifier and the related classes starting from the class definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: Define the two subclasses. In this example, we’ll call them Unreferenced and
    Referenced files. For each class, write a sentence describing the unique purpose
    for the instances of each class. These serve as the starting point for the class
    definitions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Chose an appropriate variety of available classes. This might be an ordinary
    class with mutable attributes, a NamedTuple, or a @dataclass. Starting with a
    @dataclass often gives the most flexibility. Switching between named tuples, dataclasses,
    and frozen dataclasses involves minimal syntax changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The Unreferenced class definition would be similar, with an appropriate docstring.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Add the attributes with values that will define the state of each instance.
    For the Referenced class, this is the Path and a collection of Path objects for
    each source file that has a reference. These two attribute definitions look like
    this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For the Unreferenced class, however, there really aren’t very many other attributes
    beyond the path. This raises an interesting question: does this deserve a separate
    class declaration, or can it simply be a Path object?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Because Python permits type aliases and type unions, there’s no real need for
    an Unreferenced class; the existing Path will do. It is helpful to provide a type
    alias for this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Formalize the union of these distinct classes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have the type definitions, we can write a function that is an iterator
    over the ContentType union of classes. This function will yield a sequence of
    Unreferenced and Referenced objects, one for each data file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The datafile_iter() function skips past any non-file names in the data directory.
    It also skips some source code directories, __pycache__, and.venv. Additionally,
    we have to ignore some of the files in Chapter 10 because these files will have
    test cases that contain names of data files, creating confusing results.
  prefs: []
  type: TYPE_NORMAL
- en: If a data file name appears in a source file, the reference is saved in the
    used_by collection. Files with a non-empty used_by collection will create a Referenced
    instance. The remaining files are Path objects; because of the TypeAlias these
    are recognized as Unreferenced instances, also. We don’t need to formally cast
    or convert a Path object to the Unreferenced type. Tools like mypy will use the
    TypeAlias to see the equivalence without any additional code.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting iterator provides a mix of objects of distinct types. In the [Using
    the match statement](ch014.xhtml#x1-5880003) recipe, we’ll look at convenient
    ways to process objects of diverse types.
  prefs: []
  type: TYPE_NORMAL
- en: Code first design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We’re going to work with diverse classes of objects. In this variation, we’ll
    define the processing first, and then fold in type hints to clarify our intent.
    Here’s how we can define a classifer and the related classes starting from a function
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with a function definition that provides the needed parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Write the processing to accumulate the required data values. In this case, we
    need to iterate through the names of the data files. For each data file, we need
    to look for references in all of the source files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Decide what the various outputs from the function need to be. In some cases,
    we can yield tuple objects with the various kinds of values that are available.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For paths without any references in the source, we yield the Path object. For
    paths that have references in the source, we can yield the data Path and a list
    of source Path instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For objects with more complicated internal state, consider introducing a class
    definition to properly encapsulate the state. For this example, it makes sense
    to introduce a type for data files that have references. This would lead to replacing
    a simple, anonymous tuple with a NamedTuple like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This, in turn, leads to revising the yield statement for the Referenced instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Revisit the function definition to add type hints.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The processing in both variants of the recipe is nearly identical. The differences
    are minor choices on how best to present the results. In the previous example,
    an explicit union named Content_Type was created. For this version, the union
    is implicit.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python duck typing permits a great deal of latitude in design. We can start
    with type definitions or we can start from code and add type hints. The final
    code will tend to be similar because it performs the same processing on the same
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The choice between a code first or type first approach may lead to an insight
    about performance or optimization. Each choice emphasizes distinct attributes
    of the final code. The code-first approach can emphasize simple processing, where
    type first might emphasize uniformity of the objects being processed. The choice
    of approach can also stem from the author’s degree of comfort with Python’s types.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, the process of writing the type hints may suggest algorithms
    or optimizations. This can lead to beneficial refactoring of code already written.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that the presence or absence of type hints has no performance
    impact. Any performance gains (or losses) are ordinary design issues that might
    be made more visible through the use of type hints.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When decomposing a large problem into smaller pieces, the interfaces among the
    smaller pieces are essential design decisions that must be made early in the design
    process. An early decision on data structures often leads to a type first design
    process overall. The externally facing components must have well-defined interfaces.
    The functions or methods that support these external components may be designed
    more freely with fewer constraints.
  prefs: []
  type: TYPE_NORMAL
- en: This leads to type first for the overall architecture of complicated software,
    reserving a choice of type first or code first design when working on the more
    detailed layers. When we consider distributed applications – like web services
    – where servers and clients are on separate machines, we find that type first
    is essential.
  prefs: []
  type: TYPE_NORMAL
- en: As the volume of code grows, the importance of type hints also grows. It’s challenging
    to keep a lot of details in the space between one’s ears. Having a type hint to
    summarize a more complicated data structure can reduce the clutter of details
    around the code.
  prefs: []
  type: TYPE_NORMAL
- en: In distributed computing environments, we’ll often need to consider that some
    components may not be Python programs. In these cases, we can’t share Python type
    hints. This means we’re forced to use a schema definition that exists outside
    Python, but provides needed mappings to Python types.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of these kinds of formal definitions that transcend languages include
    JSON Schema, Protocol Buffers, AVRO, and many others. The JSON Schema approach
    is typical, and is supported by a number of Python tools. Later in this chapter,
    we’ll look at using Pydantic, which has support for defining data using JSON Schema.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [Reading JSON and YAML documents](ch015_split_001.xhtml#x1-6520006) recipe
    in Chapter [11](ch015_split_000.xhtml#x1-61500011), we’ll return to using JSON
    documents for complicated data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the [Using the match statement](ch014.xhtml#x1-5880003) recipe, later in
    this chapter, we’ll look at how to use the match statement to process data of
    a variety of types. This makes it relatively easy to work with unions of types.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the [Implementing more strict type checks with Pydantic](ch014.xhtml#x1-6000005)
    recipe, later in this chapter, we’ll look at stronger type definitions using the
    pydantic package.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.2 Using the built-in type matching functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we have a collection of objects with mixed types, we often need to distinguish
    among the types. When working with classes that we’ve defined, it’s possible to
    define classes that are properly polymorphic. This is not generally the case when
    working with Python’s internal objects, or working with collections of data that
    involve a mixture of classes we’ve defined, and built-in classes that are part
    of Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'When working entirely with our own classes, we can design them to have common
    methods and attributes, but offer distinct behavior depending on which of the
    subclasses is involved. This kind of design fits the ”L” design principle in the
    S.O.L.I.D design principles: the Liskov Substitution Principle. Any of the subclasses
    can be used in place of the superclass, because they all have a common set of
    method definitions. For more information on this, see Chapter [8](ch012.xhtml#x1-4520008).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This kind of abstraction-driven design is not always needed with Python. Because
    of Python’s duck-typing, designs don’t require a common superclass. In some cases,
    it isn’t even practical: we may have diverse types without a unifying abstraction.
    It’s very common to work with mixtures of objects from built-in classes, as well
    as objects from our own class definitions. We can’t impose polymorphism on the
    built-in classes.'
  prefs: []
  type: TYPE_NORMAL
- en: How can we leverage the built-in functions to write functions and methods that
    are flexible with respect to type? For this recipe, we’ll reuse the processing
    from the [Designing with type hints](ch014.xhtml#x1-5740001) recipe earlier in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 10.2.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the [Designing with type hints](ch014.xhtml#x1-5740001) recipe, we defined
    a function datafile_iter() that emitted two distinct types of objects: Path objects
    and Referenced objects. A Referenced object was a bundle of Path instances, showing
    a data file that was used by one or more application programs. A stand-alone Path
    object was a data file not used by any application program. These unreferenced
    paths are candidates for removal to reduce clutter.'
  prefs: []
  type: TYPE_NORMAL
- en: We need to process these two classes of objects in distinct ways. They’re created
    by a single generator function, datafile_iter(). This function emits a sequence
    of Unreferenced and Referenced instances. This mixture means an application must
    filter objects by their type.
  prefs: []
  type: TYPE_NORMAL
- en: 'The application will work with a sequence of objects. These will be created
    by a function with the following definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The datafile_iter() function will produce a sequence of Unreferenced and Referenced
    objects. This will reflect the current state of files in a given directory. Some
    will have references in source code; others will lack any references. See the
    [Designing with type hints](ch014.xhtml#x1-5740001) recipe for this function.
  prefs: []
  type: TYPE_NORMAL
- en: 10.2.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The application function to do analysis will consume objects of a variety of
    types. The function is designed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with a definition like the following that shows the types consumed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an empty list that will hold the data files that have references. Write
    the for statement to consume objects from the source iterable, and populate that
    list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To distinguish objects by type, we can use the isinstance() function to see
    if an object is a class of a given type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To distinguish the class, use the isinstance() function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'While it’s technically unnecessary, it always seems prudent to include an else
    condition to raise an exception in the unlikely event that the datafile_iter function
    was changed in some astonishing way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For more about this design pattern, see the [Designing complex if...elif chains](ch006_split_000.xhtml#x1-1170005)
    recipe in Chapter [2](ch006_split_000.xhtml#x1-840002).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Write the final summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 10.2.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The isinstance() function examines an object to see what classes it belongs
    to. The second argument can be single class or a tuple of alternative classes.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that an object often has a number of parent classes,
    forming a lattice, stemming from the class object. If multiple inheritance is
    being used, there can be a large number of paths through the super class definitions.
    The isinstance() function examines all the alternative parent classes.
  prefs: []
  type: TYPE_NORMAL
- en: The isinstance() function is aware of TypeAlias names in addition to the classes
    imported and defined within the application. This gives us a great deal of flexibility
    to use meaning names in type hints.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python 3.12, the TypeAlias construct can be replaced with the new type statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'See [Mypy Issue #15238](https://github.com/python/mypy/issues/15238) for more
    information on support for the type statement by the mypy tool.'
  prefs: []
  type: TYPE_NORMAL
- en: Until this is resolved, we’ve elected to use TypeAlias in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 10.2.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The isinstance() function is the kind of Boolean function that works well with
    the filter() higher-order function. For more information, see the [Picking a subset
    – three ways to filter](ch013_split_000.xhtml#x1-5270004) recipe in Chapter [9](ch013_split_000.xhtml#x1-5020009).
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the built-in isinstance() to interrogate objects, there is also
    a issubclass() function that lets an application examine type definitions. It’s
    important to distinguish between instances of a class and a class object; the
    issubclass() function is used to examine type definitions. The issubclass() function
    is often used for metaprogramming: software that’s concerned with software rather
    than the application data. When designing functions that work with types of objects,
    rather than objects, the issubclass() function is necessary.'
  prefs: []
  type: TYPE_NORMAL
- en: When examining the type of objects, the match statement is often a better choice
    than the isinstance() function. The reason is that a match statement’s case clause
    has very sophisticated type pattern matching, where the isinstance() function
    is limited to ensuring the object has a given class (or a class in a tuple of
    classes) in its parents.
  prefs: []
  type: TYPE_NORMAL
- en: 10.2.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: See the [Using the match statement](ch014.xhtml#x1-5880003) recipe for an alternative
    to this, using the match statement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See Chapter [7](ch011_split_000.xhtml#x1-3760007) and Chapter [8](ch012.xhtml#x1-4520008)
    for several recipes related to playing cards and the interesting class hierarchies
    they involve.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.3 Using the match statement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One important reason for defining a collection of closely-related types is
    to distinguish the processing that applies to the objects. One technique for providing
    distinct behavior is by using a polymorphic design: a number of subclasses provide
    distinct implementations of a common function. When working entirely with our
    own classes, we can design them to have common methods and attributes, but offer
    distinct behavior depending on which of the subclasses is involved. This is covered
    in Chapter [8](ch012.xhtml#x1-4520008).'
  prefs: []
  type: TYPE_NORMAL
- en: This is not generally possible when working with Python’s internal objects,
    or when working with collections of data that involve a mixture of classes we’ve
    defined, and built-in classes that are part of Python. In these cases, it’s simpler
    to rely on type matching to implement distinct behaviors. One approach was shown
    in the [Using the built-in type matching functions](ch014.xhtml#x1-5820002) recipe
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use the match statement to write functions and methods that are
    flexible and work with argument values of a variety of types. For the recipe,
    we’ll reuse the processing from the [Designing with type hints](ch014.xhtml#x1-5740001)
    and [Using the built-in type matching functions](ch014.xhtml#x1-5820002) recipes
    earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 10.3.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the [Designing with type hints](ch014.xhtml#x1-5740001) recipe, we defined
    a datafile_iter() function that emitted two distinct types of objects: Path objects
    and Referenced objects.'
  prefs: []
  type: TYPE_NORMAL
- en: We need to process these two classes of objects in distinct ways. This mixture
    means an application must filter them by their type.
  prefs: []
  type: TYPE_NORMAL
- en: 10.3.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The application will work with a sequence of objects of distinct types. The
    function is designed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with a definition like the following that shows the types consumed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This function will consume an iterable sequence of objects. This function will
    count the ones that have references. It will suggest deleting the files with no
    references.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create an empty list that will hold the data files that have references. Write
    the for statement to consume objects from the source iterable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Write the start of the match statement with the file variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To process a file of the various classes, create case statements that show
    the kinds of objects that must be matched. These cases are indented within the
    match statement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'While it’s technically unnecessary, it always seems prudent to include a case _:
    condition. The _ will match anything. The body of this clause can raise an exception
    in the unlikely event that the datafile_iter function was changed in some astonishing
    way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For more about this design pattern, see the [Designing complex if...elif chains](ch006_split_000.xhtml#x1-1170005)
    recipe in Chapter [2](ch006_split_000.xhtml#x1-840002).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Write the final summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 10.3.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The match statement uses a sequence of case clauses to establish a class that
    matches the given object. While there are a wide variety of case clauses, one
    common case is the case class() as name: variant, called the class pattern. Within
    (), we can provide sub-patterns to match objects with specific kinds of parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we didn’t need the more sophisticated matching patterns. We
    can provide what looks like an instance – made from the class name and() – to
    show that the case clause will match an instance of the class. No additional detail
    regarding the structure of the instance is necessary.
  prefs: []
  type: TYPE_NORMAL
- en: The use of case Unreferenced() almost looks as if the expression Unreferenced()
    will create an instance of the Unreferenced class. The intent here is not to create
    an object, but to write an expression that looks very much like object creation.
    This syntax helps to clarify the intent of using the case to match any object
    of the named class.
  prefs: []
  type: TYPE_NORMAL
- en: Other patterns are available that allow matching simple literal values, sequences,
    and mappings, as well as classes. Further, there are ways to provide groups of
    alternatives, and even apply additional filtering via a guard condition that’s
    used in conjunction with the pattern matching.
  prefs: []
  type: TYPE_NORMAL
- en: The case _ clause is a wildcard clause. It will match anything provided in the
    match statement. The _ variable name has special significance here, and only this
    variable can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Central to this design is the clarity of the case definitions. These are much
    more readable than isinstance() function evaluation in a series of elif clauses.
  prefs: []
  type: TYPE_NORMAL
- en: 10.3.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ll extend this recipe to show some of the sophisticated type matching available
    in these case clauses. Consider the case where we want to separate a referenced
    file that has only a single item in the list of applications that refer to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re looking for objects that look like this specific example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This case can be summarized as Referenced(_, [Path()]). We want to match an
    instance of the Referenced class where the second parameter is a list with a single
    Path instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'This turns into a new case clause. Here’s the new, more specific case, followed
    by the more general case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The match statement works through the cases in order. The more-specific cases
    must precede the less-specific cases. If we flip the order of these two cases,
    case Referenced() would match before case Referenced(_, [Path()]) would even be
    examined. The most general case, case _: must be last.'
  prefs: []
  type: TYPE_NORMAL
- en: 10.3.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: See the [Using the built-in type matching functions](ch014.xhtml#x1-5820002)
    recipe for an alternative approach using the built-in isinstance() function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See Chapter [8](ch012.xhtml#x1-4520008) for several recipes related to polymorphic
    class design. Sometimes, this can reduce the need for type matching.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.4 Handling type conversions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the useful features of Python is the ”numeric tower” idea. See The Numeric
    Tower in the Python standard library documentation. The idea is that numeric values
    can move ”up” the tower from integral to rational to real to complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'The numeric conversions are based on the idea that there are a several overlapping
    domains of numbers. These include ℤ integers, ℚ rational numbers, ℙ irrational
    numbers, ℝ real numbers, and ℂ complex numbers. The idea is that these form a
    nested series of sets: ℤ ⊂ℚ ⊂ℝ ⊂ℂ. Also, ℚ ∪ℙ = ℝ: the real numbers include rational
    and irrational numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These built-in numeric types follow the abstract concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: ℂ is implemented by the complex type. Any of the types below this type can be
    converted to a complex value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ℝ is supported by the float type. It’s important to note that float involves
    approximations, and doesn’t fully match the mathematical ideal of real numbers.
    When an operator in this class encounters int or fraction values, it will create
    the equivalent float value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ℚ uses the Fraction class in the fractions module. When an arithmetic operator
    in the Fraction class encounters an int it will quietly create a Fraction with
    the same value as the integer. ![z 1](img/file73.png) = z.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ℤ is the int class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally, the Python language avoids too many conversions to other types. Strings,
    for example, are not automatically parsed to create numeric values. An explicit
    built-in function like int() or float() needs to be used to process strings with
    numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll often want our own types to share this kind of behavior. We’d like our
    functions to be flexible, and convert objects to other types when needed. We may,
    for example, want to permit a number of representations for a latitude-longitude
    point. These alternatives might include:'
  prefs: []
  type: TYPE_NORMAL
- en: A tuple of two floating-point numeric values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A pair of strings, with each string representing a floating-point value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A single string with two numeric values separated by a "," character
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As with the numeric tower, our own class definitions need to convert other types
    into the needed target type.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ll consider a function to compute distances between points on the surface
    of the Earth. This involves some clever spherical trigonometry. For more information,
    see Chapter [3](ch007_split_000.xhtml#x1-1610003), specifically, the [Picking
    an order for parameters based on partial functions](ch007_split_001.xhtml#x1-1940006)
    recipe. Also see the [Creating contexts and context managers](ch011_split_001.xhtml#x1-43700011)
    recipe in Chapter [7](ch011_split_000.xhtml#x1-3760007).
  prefs: []
  type: TYPE_NORMAL
- en: 'The function is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This definition requires converting source data into individual float values.
    In applications that integrate data from a number of sources, these conversions
    are so common that it seems better to centralize them into a function that wraps
    the essential haversine() computation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want a function like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This function will compute distances among points defined as a variety of data
    types. The *args parameter means all of the positional argument values will be
    combined into a single tuple. A number of validation rules must be applied to
    make sense of this tuple. Here are the rules we’ll start with: Four float values:
    use these directly. Example: distance(36.12, -86.67, 33.94, -118.40, R=6372.8).
    Four strings: convert these to float. Example: distance("36.12", "-86.67", "33.94", "-118.40", R=6372.8).
    two strings: parse each string, breaking on a ”,”. Each string should have two
    float values. Example: distance("36.12,-86.67", "33.94,-118.40", R=6372.8). Two
    tuples: unpack each tuple to make sure it has two float values. Example: distance((36.12, -86.67), (33.94, -118.40), R=6372.8).'
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, it might be nice to support combinations of these, also. We’ll design
    a function that performs the needed type conversions.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A function that includes type conversions is often built separately from the
    underlying processing. It can help testing and debugging if these two aspects
    of processing – conversions and computations – are separated:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the needed literal_eval() function to do the conversions of strings
    that are expected to be Python literals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With this function, we can evaluate literal_eval("2,3") to get a result of a
    proper tuple, (2, 3). We don’t need to use a regular expression to decompose the
    string to see the pattern of the text.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the distance function that performs conversions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Start the match statement for the various kinds of argument patterns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Write the individual cases, moving from more specific to less specific. Start
    with four distinct float values, since no conversion needs to be done. The tuple
    of float values has a more complex type structure, but doesn’t require any conversion.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We’ve provided the lat_1, lon_1, lat_2, and on_2 variables to bind the values
    from the args structure to variable names. This saves us from having to write
    assignment statements to unpack an argument tuple. The pass statement placeholder
    is used because no further processing is required beyond unpacking the data structure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Write the cases that involve conversions of the supplied values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: When the argument values are four strings, we provided four variables to unpack
    the four strings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When the argument pattern is two strings, we provided two variables, ll1 and
    ll2, that each needed to be converted into two tuples of numbers and then unpacked.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Write the default case that will match anything else and raise an exception:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that the arguments have been properly unpacked and any conversions applied,
    use the haversine() function to compute the required result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 10.4.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The essential feature for type conversions is using a match statement to provide
    appropriate conversions for the supported types. In this example, we tolerated
    a mixture of strings and tuples that could be converted and unpacked to locate
    the required four argument values. The match statement has many clever type-matching
    rules. For example, an expression like ((float(f1), float(f2)), (float(f3), float(f4)))
    will match two tuples, each with two float values. Further, it unpacks the values
    from the tuples and assigns them to four variables.
  prefs: []
  type: TYPE_NORMAL
- en: The mechanics of converting the values are also based on a built-in feature.
    The float() function converts numeric strings to float values or raises a ValueError
    exception.
  prefs: []
  type: TYPE_NORMAL
- en: The ast.literal_eval() function is very handy for evaluating strings that are
    Python literals. The function is safe from evaluating dangerous expressions because
    it is limited to literal values, and a few simple data structures – tuples, lists,
    dicts, and sets – built from literal values. It permits us to parse a string like
    "36.12,-86.67" into (36.12, -86.67) directly.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The use of independent case clauses makes it relatively easy to add additional
    type conversions. We might, for example, want to handle a tuple of two dictionary
    structures that look like {"lat": 36.12, "lon": -86.67}. This can be matched with
    the following case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The argument tuple pattern has () around it, making it easy to break it into
    multiple lines. The four values extracted from the dictionaries will be bound
    to four target variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to permit more flexibility, we can consider the case where we have
    two argument values of a mixture of type patterns. For example, distance("36.12,-86.67", (33.94, -118.40), R=6372.8).
    This has two distinct formats: a string and a tuple with a pair of float values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rather than enumerate all of the possible combinations, we can decompose the
    parsing of a pair of values into a separate function, parse(), that applies the
    same conversion to both argument values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This new parse() function must handle all the cases where a latitude and longitude
    are provided together. This includes strings, tuples, and mappings. It looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This will slightly simplify the match statement in the distance function. The
    refactored statement only handles four cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The first two cases handle the situation where four argument values are provided.
    The third case looks at a pair of values, which can have any of the pair formats.
  prefs: []
  type: TYPE_NORMAL
- en: We expressly avoid the case where three argument values are provided. This requires
    a bit more care to interpret, since one of the three argument values must be a
    latitude and longitude pair. The other two values must be separated latitude and
    longitude values. The logic is not overwhelmingly complicated, but the details
    stray from the central idea of this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: While the recipe focuses on built-in types including str and float, any type
    can be used. A customized Leg type, for example, with start and stop locations
    could easily be added in a case clause.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For more information on numbers and conversions, see the [Choosing between float,
    decimal, and fraction](ch005_split_000.xhtml#x1-180001) recipe in Chapter [1](ch005_split_000.xhtml#x1-170001).
    This provides some more information about the limitations of the float approximation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information on the haversine() function, see the [Picking an order
    for parameters based on partial functions](ch007_split_001.xhtml#x1-1940006) recipe
    in Chapter [3](ch007_split_000.xhtml#x1-1610003). Also see the [Creating contexts
    and context managers](ch011_split_001.xhtml#x1-43700011) recipe in Chapter [7](ch011_split_000.xhtml#x1-3760007).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.5 Implementing more strict type checks with Pydantic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the most part, Python’s internal processing will handle a great many simple
    validity checks properly. If we’ve written a function to convert a string to float,
    the function will work with float values and string values. It will raise a ValueError
    exception if we try to apply the float() function to a Path object.
  prefs: []
  type: TYPE_NORMAL
- en: In order for type hints to be optional, run-time type-checking is the minimum
    level of checking required to make sure some processing can proceed. This is emphatically
    distinct from the strict checks that tools like mypy make.
  prefs: []
  type: TYPE_NORMAL
- en: Type hints do no run-time processing.
  prefs: []
  type: TYPE_NORMAL
- en: Python (without any add-on packages) does no data type checks or value range
    checks at run-time. Exceptions are raised when an operator is confronted with
    a type it can’t process, without regard to the type hints.
  prefs: []
  type: TYPE_NORMAL
- en: This means that Python may be able to process a type that was excluded by a
    hint. It’s possible to write a narrow hint like list[str]. An object of set[str]
    may also work with the given body of the function.
  prefs: []
  type: TYPE_NORMAL
- en: There are applications where we’d like stronger checks at run-time. These are
    often helpful in applications where extensions or plug-ins are used, and we’d
    like to be sure the additional plug-in code behaves properly.
  prefs: []
  type: TYPE_NORMAL
- en: One way to provide for run-time type checking is to use the Pydantic package.
    This module allows us to define complex objects that are accompanied by run-time
    type checking, as well as management of schema definitions that can be shared
    widely.
  prefs: []
  type: TYPE_NORMAL
- en: In Chapter [5](ch009.xhtml#x1-2890005), in the [Creating dictionaries – inserting
    and updating](ch009.xhtml#x1-2900001) recipe, we looked at a log file that we
    needed to parse into a more useful structure. In Chapter [9](ch013_split_000.xhtml#x1-5020009),
    in the [Writing generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)
    recipe, we looked at writing a generator function that would parse and yield the
    parsed objects. We called the resulting objects RawLog, with no type checks or
    type conversions. We applied a simple transformation to create a DatedLog instance
    with the date-time stamp converted from text to a datetime.datetime object.
  prefs: []
  type: TYPE_NORMAL
- en: The pydantic package can handle some of this conversion to a DatedLog instance,
    saving us some programming. Further, because the schema can be generated automatically,
    we can build a JSON Schema definition and do JSON serialization without a lot
    of complicated work.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Pydantic package must be downloaded and installed. Generally, this is done
    with the following terminal command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Using the python -m pip command ensures that we will use the pip command that
    goes with the currently active virtual environment, shown as cookbook3 in the
    example.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The log data has date-time stamps represented as string values. We need to parse
    these to create proper datetime objects. To keep things focused in this recipe,
    we’ll use a simplified log produced by a web server written with Flask.
  prefs: []
  type: TYPE_NORMAL
- en: 'The entries start out as lines of text that look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: We’ve seen other examples of working with this kind of log in the [Using more
    complex structures – maps of lists](ch012.xhtml#x1-4810005) recipe in Chapter [8](ch012.xhtml#x1-4520008).
    Using REs from the [String parsing with regular expressions](ch005_split_000.xhtml#x1-350003)
    recipe in Chapter [1](ch005_split_000.xhtml#x1-170001), we can decompose each
    line into a more useful structure.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the other recipes, the regular expression used for parsing had an
    important feature. The names used in the (?P<name>...) groups were specifically
    designed to be ordinary Python attribute names. This will fit nicely with the
    class definition we’ll build later.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll need to define a class that captures the essential content of each log
    line in a useful form. We’ll use the Pydantic package to define and populate this
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll need the following imports to create this class definition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In order to properly validate a string that has a number of values, an Enum
    class is required. We’ll define a subclass of StrEnum to list the valid string
    values. Each class-level variable provides a name and the string literal that
    is the serialization for the name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this class, the Python attribute names and the string literals match. This
    isn’t a requirement. It happens to be convenient for this collection of enumerated
    string values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The class will be a subclass of the BaseModel class from the pydantic package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The BaseModel class must be the superclass for any model that makes use of pydantic
    features.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We’ll define each field with a field name that matches the group name in the
    regular expression used to parse the fields. This is not a requirement, but it
    makes it very easy to build instances of the LogData class from the group dictionary
    that’s part of a regular expression Match object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The date is defined to be a datetime.datetime instance. The inherited methods
    from the BaseModel class will handle this conversion. The level is an instance
    of the LevelClass. Again, features from BaseModel will handle this conversion
    for us. We’ve used the Annotated type to provide a type, str, and an annotation
    argument, Field(...). This will be used by the methods of BaseModel to validate
    the field’s content.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here’s a generator function to read and parse log records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: This will use the regular expression pattern, pattern to parse each record.
    The group dictionary, match.groupdict() will have the group names and the parsed
    text. The model_validate() method of the BaseModel will build an instance of the
    LogData class from the dictionary created by the compiled regular expression.
  prefs: []
  type: TYPE_NORMAL
- en: 'It looks like the following example when we use this logdata_iter function
    to create instances of the LogData class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'This function has transformed lines of text into LogData objects populated
    with proper Python objects: datetime.datetime instances and enumerated values
    from the LevelClass. Further, it’s validated the module names to be sure they
    match a specific regular expression pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Pydantic package includes numerous tools for data validation and class definition.
    Python’s use of types, and more detailed Annotated types, provides syntax that
    helps us define the members of a class, including data conversions and data validations.
    In this example, the conversions were implied; the class provided the target type,
    and the methods inherited from the BaseModel class made sure that source data
    was properly converted to the desired target type.
  prefs: []
  type: TYPE_NORMAL
- en: 'This small class definition had three distinct kinds of types hints:'
  prefs: []
  type: TYPE_NORMAL
- en: The date and level field involved conversions to a target type.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The module field used an annotated type to provide a Pydantic Field definition
    for the attribute. The regular expression pattern will check each string value
    to be sure it matches the required pattern.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The message field provided a simple type that will match the source data type.
    No additional validation will be performed for this field.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are some parallels between the way the @dataclass and a BaseModel subclass
    work. The Pydantic package provides considerably more sophisticated definitions
    than a dataclass definition. A @dataclass, for example, does not do type checking
    or any automatic data conversion. The type information provided when defining
    a dataclass is primarily of interest to tools like mypy. In contrast, the subclasses
    of BaseModel do considerably more automated conversion and run-time type checking.
  prefs: []
  type: TYPE_NORMAL
- en: The subclasses of DataModel come with a large number of methods.
  prefs: []
  type: TYPE_NORMAL
- en: The model_dump_json() and model_validate_json() methods are particularly helpful
    for web services where the application often works with RESTful transfers of object
    state in JSON notation. These can be serialized into newline-delimited files to
    collect a number of complicated objects into files in a standardized physical
    format.
  prefs: []
  type: TYPE_NORMAL
- en: The Pydantic package tends to be extremely fast. The current version involves
    Python extensions that are compiled to provide very high performance. Clearly,
    a dataclass – which lacks a number of Pydantic features – will be faster, but
    do less. However, the additional data validation is often worth the overhead.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the benefits of working with Pydantic is the automatic support for JSON
    Schema definitions and JSON serialization.
  prefs: []
  type: TYPE_NORMAL
- en: 'This shows how we can get the JSON Schema for a model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The details of the JSON Schema are long and match the Python definition of the
    class. We’ve omitted the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can serialize these LogData instances in JSON notation. Here’s how this
    looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: We’ve used the model_dump_json() method to serialize the object as a JSON document.
    This lets us convert documents from a variety of sources to a common format. This
    makes it easy to create analytic processing around the common format, separating
    parsing, merging, and validating from the analysis and the interesting results
    of the analytic processing.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: See the [Including run-time valid value checks](ch014.xhtml#x1-6060006) recipe
    for some additional validation rules that are possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the [Using dataclasses for mutable objects](ch011_split_000.xhtml#x1-4010005)
    recipe in Chapter [7](ch011_split_000.xhtml#x1-3760007) for more on dataclasses.
    The Pydantic variant on dataclasses is often more useful than the dataclasses
    module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the [Reading JSON and YAML documents](ch015_split_001.xhtml#x1-6520006)
    recipe in Chapter [11](ch015_split_000.xhtml#x1-61500011) for information related
    to reading data in JSON format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.6 Including run-time valid value checks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data analytics often involves a great deal of ”data wrangling”: dealing with
    invalid data, or unusual data. It’s common for source application software to
    change, leading to new formats for data files, causing problems in downstream
    analytic applications when parsing those files. A change in enterprise processes
    or policies may lead to new data types or new coded values that can disrupt analytic
    processing.'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, when working with machines and robots, sometimes called the Internet
    of Things, it’s common for a device to provide invalid data when it’s starting
    up, or when it’s failing to operate normally. In some cases, it may be necessary
    to raise alarms when bad data arrives. In other cases, the out-of-range data needs
    to be quietly ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Pydantic package offers very sophisticated validation functions that allow
    us two choices:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert data from unusual formats into Python objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raise an exception for data that cannot be converted or fails to pass more specific
    domain checks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In some cases, we also need to validate the resulting object is internally consistent.
    This often means that several fields must be checked for consistency with each
    other. This is called model validation, which is distinct from isolated field
    validation.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of validation can be extended. It can embrace both rejecting invalid
    data and filtering out data that’s valid, but uninteresting, for a given application.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’re looking at the US National Oceanographic and Atmospheric Administration
    (NOAA) data on coastal tides. Moving a large sailboat means making sure there’s
    enough water for it to float. This constraint requires checking predictions for
    the height of the tides at places that are known to be shallow and difficult to
    pass.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, a place called El Jobean, on the Myakka river, has a shallow
    spot that requires some care when transiting it. We can get the tidal prediction
    from the NOAA [Tides and Currents](https://tidesandcurrents.noaa.gov/noaatidepredictions.html?id=8725769)
    web site. This web page allows putting in a range of dates and downloading a text
    file with tide predictions for the given range of dates.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting text file looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This data is almost in CSV format, but a few quirks make it difficult to process.
    Here are some complicating factors:'
  prefs: []
  type: TYPE_NORMAL
- en: The file has 19 lines of data before the useful column heading line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The columns use the tab character \t as a delimiter instead of a comma.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The heading row for the relevant data has some extraneous whitespace hidden
    in it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following function will provide clean CSV rows for further processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The Extra tab in the header comment handles the heading, which has an extra
    whitespace character in it. This header row has two \t characters between the
    Date and Day column names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: See the [Slicing and dicing a list](ch008_split_000.xhtml#x1-2400003) recipe
    in Chapter [4](ch008_split_000.xhtml#x1-2240004) for more on this technique for
    removing an item from a list.
  prefs: []
  type: TYPE_NORMAL
- en: This list of column names can be used to build a DictReader instance to consume
    the rest of the data. (See the [Reading delimited files with the CSV module](ch015_split_000.xhtml#x1-6320003)
    recipe in Chapter [11](ch015_split_000.xhtml#x1-61500011) for more on CSV files.)
  prefs: []
  type: TYPE_NORMAL
- en: We can convert each from a dictionary to a class instance using Pydantic validation
    features.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The core data model will validate rows of data, creating an instance of a class.
    We can add features to this class to handle the application-specific processing.
    Here’s how we build this class:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with the imports for the the data types within each row, plus the BaseModel
    class and some related classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the domain of values for the High/Low column. The two codes are enumerated
    as an Enum subclass:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Since the date text is not in the default format used by Pydantic, we need
    to define a validation function that will produce a date object from the given
    string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The Pydantic validators can be used on internal Python objects as well as strings
    from source CSV files or JSON documents. When applied to a datetime.date object,
    no additional conversion is needed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the model. The validation_alias parameter of the Field definition will
    pluck data from a source field in the dictionary that’s not exactly the same as
    the target attribute name in the class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Each field uses an Annotated type to define the base type, and additional details
    required to validate strings and convert them to that type.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The day field – with the day of the week – is not actually useful. It’s derived
    data from the date. For debugging purposes, this is preserved.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Given this class, we can use it to validate model instances from a sequence
    of dictionary instances. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: This sequence of objects contains too much data. We can use Pydantic to also
    filter the data, and pass only the useful rows. We’ll do this by revising this
    class definition and creating an alternative that includes the rules for the data
    to be passed.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The BaseModel class includes a number of operations that work with the annotated
    type hints of the class attributes. Consider this type hint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: This provides a base type, datetime.date. It provides a Field object that will
    extract the field named ’Date ’ from a dictionary, and apply validation rules
    to it. Finally, the PlainValidator object provides a one-step validation rule
    that’s applied to the source data. The validate_date() function was written to
    accept date objects as already valid, and convert string objects into date objects.
    This allows the validation to be used for raw data as well as Python objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our application involves some narrowing of the domains of data for this example.
    There are three important criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: We’re only interested in high tide predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’d prefer the tide be at least 1.5 (45 cm) feet above baseline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need this to occur after 10:00 and before 17:00.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can leverage Pydantic to perform additional validations to narrow the data
    domains. These additional validations can reject high tides less than the minimum
    of 1.5 feet.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can extend this model to add validation rules that narrow the domain of valid
    rows to those that match our selection criteria based on time of day and height
    of tide. We’ll be applying these more narrow data validation rules after any data
    conversions. These rules will raise ValidationError exceptions. This expands the
    imports from the pydantic package.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll define a number of additional validation functions. Here’s a validator
    that raises an exception for low-tide data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The assert statement is elegantly simple for this task. This can also be done
    with if and raise.
  prefs: []
  type: TYPE_NORMAL
- en: 'A similar validator can raise an exception for data outside the acceptable
    time window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can combine these additional validators into the annotated type
    definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: The additional validators will reject data where the criteria don’t match our
    narrow requirements. The output will only have high tides, greater than 1.5 feet,
    and during daylight hours.
  prefs: []
  type: TYPE_NORMAL
- en: 'This data forms a sequence of HighTideTable instances, like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: We’ve omitted some rows to show just the first row, a row from the middle, and
    the last row. These are HighTideTable objects with attributes that are Python
    objects, suitable for further analysis and processing.
  prefs: []
  type: TYPE_NORMAL
- en: The general approach to Pydantic design means individual rules for combining
    raw data fields, converting data, and filtering data are all separated. We can
    confidently change one of these rules without having to worry about breaking other
    parts of the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'This recipe included three varieties of checks:'
  prefs: []
  type: TYPE_NORMAL
- en: A range check to be sure a continuous value is within the allowed range. AfterValidator
    is used to make sure a string is converted to a time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A minimum check to be sure a continuous value is above a limit. For numbers,
    this can be done by the Field definition directly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A required value check to be sure a discrete value has one of the required values.
    AfterValidator is used to make sure a string is converted the enumerated type.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These kinds of checks are performed after the essential type matching and used
    to apply narrower validation rules.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Chapter [11](ch015_split_000.xhtml#x1-61500011) we’ll look more deeply at
    reading files of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the [Implementing more strict type checks with Pydantic](ch014.xhtml#x1-6000005)
    recipe for additional examples of using Pydantic. Pydantic uses compiled Python
    extensions to apply the validation rules with little overhead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Python Discord workspace to discuss and find out more about the book:
    [https://packt.link/dHrHU](https://packt.link/dHrHU)'
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file1.png)'
  prefs: []
  type: TYPE_IMG
