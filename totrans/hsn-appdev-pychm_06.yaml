- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Seamless Testing, Debugging, and Profiling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 5*](B19644_05.xhtml#_idTextAnchor112), *Version Control with Git
    in PyCharm*, I talked about *The Joel Test*. This test is just a list of best
    practices. At the top of the list is the use of version control, which was the
    subject of the previous chapter. If you looked up the list, you were probably
    not surprised to see testing was also on the list. Formalized software testing
    practices such as **test-driven development** (**TDD**) and **behavior-driven
    development** (**BDD**) are the cornerstones of software quality control. Working
    with these methodologies helps you create software that is less likely to fail
    in production. Done correctly, it also has side benefits, such as preventing scope
    creep and allowing for effective refactoring on projects that might have neglected
    best practices and taken on a lot of technical debt.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several levels of testing are in practice today, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit testing**, which aims to test basic low-level functionality at the level
    of functions or classes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration testing**, which aims to test how components within a larger
    system work together'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User interface testing**, which aims to test how interactive elements of
    a system work'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**End-to-end testing**, which tests an entire system in a production-like environment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like all well-established programming languages, Python has a rich set of testing
    libraries available. And since Python is “batteries included,” there are some
    fine testing tools built into the standard library. Naturally, third-party solutions
    have evolved and are available via [PyPi.org](http://PyPi.org).
  prefs: []
  type: TYPE_NORMAL
- en: I cut my teeth on Java’s **JUnit** library, and later on its .NET port called
    **NUnit**. I found it made software development very enjoyable. There’s just something
    fun about starting your day with a set of tests that don’t pass, and throughout
    the day, writing the code to make each one pass. If you’re disciplined, you will
    write the bare minimum code needed, and gradually you will see progress as your
    testing tool changes color from red to green. You shouldn’t take shortcuts, and
    you shouldn’t be tempted to write in functionality that seems cool but that you
    might not need later. When I made the leap to Python years ago, I was pleased
    to see so many options regarding testing libraries and frameworks. I was equally
    pleased to see that PyCharm supports most of the popular ones right in the IDE.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll be looking at creating unit tests in Python code while
    following the tenets of TDD. In TDD, you generally create a set of tests designed
    to prove your software meets a set of requirements. These tests are written before
    you create any functionality in your program, and they start as failures. Your
    job is to make the tests pass with the simplest code possible.
  prefs: []
  type: TYPE_NORMAL
- en: Along the way, you’ll need to use a debugger to step through problematic code
    that either inexplicably fails, or perhaps worse, inexplicably works. Once your
    code works and passes tests, you usually want to consider the speed of execution.
    The **National Health Service** (**NHS**) in Great Britain developed an algorithm
    that matched organ donations to patients in the system. The complex algorithm
    had to be fast because there is a limited window of time during which a harvested
    organ is viable for transplant. Similar time constraints exist in many other types
    of applications. As developers, we need tools to help us pinpoint efficiency bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing in Python with PyCharm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using PyCharm’s powerful visual debugger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with PyCharm’s profiling tools to find performance bottlenecks in your
    code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the prerequisites for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: A working installation of Python 3.10 or later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A working installation of PyCharm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sample code for this chapter, which can be found at [https://github.com/PacktPublishing/Hands-On-Application-Development-with-PyCharm---Second-Edition/tree/main/chapter-06](https://github.com/PacktPublishing/Hands-On-Application-Development-with-PyCharm---Second-Edition/tree/main/chapter-06
    )
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing, testing, 1-2-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Unit testing is a practice designed to prove your code works as designed. A
    good set of tests will match a functional specification. A great set of tests
    will do that but also account for any obvious paths of failure. To get started,
    let’s get our feet wet with something simple: your bank account. OK, it doesn’t
    have to be yours. Consider a typical transaction where you buy something at a
    store using your ATM card.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You visit your favorite brick-and-mortar bookstore to pick up your next excellent
    read in the field of software development. Let’s say you find a copy of my first
    book, *Real World Implementation of C# Design Patterns*, published by Packt. Given
    its status as an instant classic, you can’t resist picking up a copy at any price.
    You tap your card on the bookstore’s point-of-sale system and two things happen:'
  prefs: []
  type: TYPE_NORMAL
- en: The equivalent of $39.95 – which is an absolute steal by the way – is taken
    out of your bank account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The same amount is transferred into the bank account of the bookstore.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is a transactional operation. Formally speaking, a transaction is a multi-step
    operation where every step must complete without errors. It should be an all-or-nothing
    set of operations. If the first step completes but the second fails, then $39.95
    just vanishes from your bank account and you don’t get to go home with your book.
    If the second step works but the first fails, you get a free book, but the local
    bookseller goes broke. We need both steps to complete, or at worst, fail completely
    so that no money changes hands.
  prefs: []
  type: TYPE_NORMAL
- en: This level of criticality is a good scenario for learning about unit testing.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing in Python using PyCharm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Create a new project in PyCharm using the plain Python project template. Let’s
    call it `bank_account`. You’ll find the completed example in the source repository
    for this chapter, but if you’d like to practice creating and testing the necessary
    code, just follow along.
  prefs: []
  type: TYPE_NORMAL
- en: 'PyCharm created a file called `main.py`. We’ll use it in a moment, but let’s
    put our bank transaction code in a separate module. One of the tenets of writing
    good code is writing **testable code**, and the best way to write testable code
    is to follow the **single-responsibility principle** (**SRP**), where you create
    units of code that have only one responsibility. SRP is part of a larger set of
    rules for creating a resilient coding architecture called **SOLID**, which is
    an acronym for the following principles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Single-responsibility** **principle** (**SRP**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Open-closed** **principle** (**OCP**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Liskov substitution** **principle** (**LSP**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interface segregation** **principle** (**ISP**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependency inversion** **principle** (**DIP**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SOLID is normally considered when developing a **fully object-oriented** (**FOO**)
    architecture using static languages that are strictly object-oriented. Java, C++,
    and C# are classic examples of such languages. Python allows for many different
    development paradigms, and its implementation of **object-oriented programming**
    (**OOP**) isn’t as complete, or maybe not as traditional, as many others. If you’ve
    never heard of SOLID as a Python developer, that’s probably why. Books and blogs
    exist where people have tried to shoehorn Python code to fit, but in my opinion,
    it often feels forced.
  prefs: []
  type: TYPE_NORMAL
- en: SRP is one you should absolutely follow. It fits into any language and any paradigm.
    Simply put, the elements you make, be they functions, Python packages, or objects,
    should do only one thing, and do it well. By breaking up the responsibilities
    of your code, you can create reusable elements that can easily be unit tested,
    and therefore easily maintained. Everything should do one thing. Of course, there
    will be something tying it all together – maybe a `main` function in a program
    whose only purpose is to call everything else and provide a flow for your program.
  prefs: []
  type: TYPE_NORMAL
- en: OCP states that once you have shipped a class to production, you should never
    change it. You should write your code in such a way that your classes are open
    to extension, but closed for modification. This principle is designed to protect
    the functionality you’ve already tested and shipped. If you open the class and
    change it, then you introduce the risk of bugs and you have to retest your entire
    program. If you limit your changes to an extension, then you only need to worry
    about testing the extension.
  prefs: []
  type: TYPE_NORMAL
- en: LSP doesn’t translate easily to Python. It states that any sub-class should
    be able to replace its superclass without affecting the correctness of the program.
    In other words, if a program is using a base class, it should be able to work
    correctly when you substitute a derived class for the base class. When you adhere
    to LSP, you are promoting the concept of polymorphism within your classes. This
    allows different objects to be treated uniformly through their common supertype,
    which leads to more flexible and modular designs. Implementing LSP is hard in
    dynamic languages such as Python since these languages allow for dynamic typing
    and late binding of method calls. For this reason, LSP is even more crucial than
    it is in static, strongly typed languages. The challenge comes with the lack of
    a strict compile type check you get in C#, C++, or Java. Any design mistakes you
    make will not surface until runtime. As a Python developer, you must design very
    carefully, and test with more intensity than you might in other languages.
  prefs: []
  type: TYPE_NORMAL
- en: ISP states that classes or modules should have interfaces that are tailored
    to their specific needs. An interface that specifies the structure and behavior
    of a class should not contain anything that is not needed by that class. This
    doesn’t translate well into Python since Python lacks the traditional interfaces
    found in languages such as Java and C#. The word interface can be taken to mean
    a regular superclass, in which case the superclass shouldn’t contain properties
    and methods that are never used within a subclass.
  prefs: []
  type: TYPE_NORMAL
- en: DIP is a fundamental principle in object-oriented programming that deals with
    the dependencies between classes and modules. It states that high-level modules
    should not depend on low-level modules, but both should depend on abstractions.
    Additionally, it emphasizes that abstractions should not depend on details; rather,
    details should depend on abstractions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the key ideas of DIP:'
  prefs: []
  type: TYPE_NORMAL
- en: '**High-level modules should not depend on low-level modules**: High-level modules
    represent the higher-level logic or functionality of an application, while low-level
    modules deal with the implementation details and lower-level operations. According
    to DIP, high-level modules should not directly depend on low-level modules. Instead,
    both should depend on abstractions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Abstractions should not depend on details**: Abstractions, such as interfaces
    or abstract classes, define contracts that specify the behavior and functionality
    expected from the collaborating objects. DIP states that these abstractions should
    not depend on the specific implementation details of the lower-level modules.
    It promotes the idea of programming to interfaces rather than concrete implementations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To adhere to DIP, it is essential to introduce abstractions, such as interfaces
    or abstract classes, and program against those abstractions rather than concrete
    implementations. This promotes loose coupling and allows for greater flexibility
    and maintainability in the code base. Ensure you don’t confuse this with **dependency
    injection** (**DI**). They are related, but not the same thing.
  prefs: []
  type: TYPE_NORMAL
- en: DI is a design pattern or technique that facilitates the implementation of DIP.
    DI is a way to provide the dependencies required by a class from an external source,
    rather than having the class create or manage its dependencies internally.
  prefs: []
  type: TYPE_NORMAL
- en: In DI, the responsibility of creating and providing dependencies is delegated
    to an external entity, typically called an “injector” or “container.” The container
    is responsible for creating instances of classes and injecting their dependencies.
    This allows for better decoupling and flexibility and easier testing since dependencies
    can easily be substituted or mocked during unit testing.
  prefs: []
  type: TYPE_NORMAL
- en: DI can be seen as an implementation strategy for achieving the principles outlined
    in DIP. It helps in adhering to DIP by providing a mechanism that inverts the
    control of dependencies and separates the creation of objects from their usage.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, DIP is a guideline for designing modular, loosely coupled systems,
    while DI is a technique or pattern that’s used to implement DIP, which it does
    by externalizing the responsibility of managing dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in this kind of architecture, you should check out that
    book I plugged earlier as SOLID is covered extensively throughout, albeit with
    C# as the language. SRP, however, fits nicely with any language or paradigm, Python
    included.
  prefs: []
  type: TYPE_NORMAL
- en: When you stick with functions and classes that only do one thing, and do it
    well, testing them is a breeze because the functionality is isolated. Functions
    or classes that try to do too much are harder to test because of the interplay
    between dependencies. Let’s build something to make this clear.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a test library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Several popular unit testing libraries are available for Python 3\. Some of
    the most widely used include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`unittest`: This is Python’s built-in unit testing framework, often referred
    to as `unittest`. It provides a set of classes and methods for writing and running
    tests. `unittest` follows the xUnit style of unit testing and offers features
    such as test discovery, test fixtures, and assertion methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pytest`: `pytest` is a popular, feature-rich testing framework that provides
    a more concise and expressive way of writing tests compared to `unittest`. It
    supports test discovery, fixtures, parameterized tests, and powerful assertion
    methods. `pytest` is known for its simplicity and flexibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nose`: `nose` is another popular testing framework that extends the capabilities
    of `unittest`. It provides additional features, such as automatic test discovery,
    test generators, plugins, and advanced test selection and filtering options. While
    `nose` is widely used, its popularity has declined in recent years in favor of
    `pytest`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`doctest`: `doctest` is a unique testing framework that allows you to write
    tests in the form of interactive examples within docstrings or documentation comments.
    It extracts and executes the examples as tests, verifying that the actual output
    matches the expected output. `doctest` is well-suited for testing code documentation
    and examples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just a few examples of popular unit testing libraries in Python. Each
    library has its own features, style, and strengths, so it’s worth exploring them
    to find the one that aligns best with your project’s requirements and your personal
    preferences. The neat thing about working with PyCharm is that it supports all
    of these testing libraries, and the UI for running tests and viewing the results
    is always the same.
  prefs: []
  type: TYPE_NORMAL
- en: Since this is a book on PyCharm rather than an exposition on testing frameworks,
    I’m going to be using the `unittest` library, which is part of Python’s standard
    library. This will keep our sample code free of external dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a bank account class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Right-click the project title in the project window and select `bank_account.py.`
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'So far, we’ve created a class called `BankAccount`, created a constructor,
    and initialized three member variables called `name`, `account number`, and `balance`.
    Next, we’ll add a method designed to handle withdrawing money, but only if the
    amount is less than the balance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If the amount that’s withdrawn is more than `balance`, we throw a `ValueError`
    and issue a message stating `Account overdrawn!`. Next, we need a method to add
    money to the account. It needs to be a positive number; otherwise, we’ll be doing
    a withdrawal, not a deposit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: So far, so good, right? Since our methods have some business logic in them,
    we should create a unit test for them.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the bank account class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Right-click the title of the project in the project window and select **New**
    | **Python File**, but this time, make it a Python unit test, as shown in *Figure
    6**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1: There are several templates for a new Python file](img/B19644_Figure_6.01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: There are several templates for a new Python file'
  prefs: []
  type: TYPE_NORMAL
- en: There are several conventions for working with test files. Some think it’s a
    good idea to have a folder that contains just tests. Others think the test file
    should be right next to the file it is testing. I like this convention because
    it allows me to easily see which files in my project lack testing. Per a similar
    convention, I’m going to name the file `back_account_test.py`. Conventions dictate
    I either start or end the name of my file with the word *test*. I have put it
    at the end because if I don’t, the test file won’t be next to the file it is testing
    within the file explorer.
  prefs: []
  type: TYPE_NORMAL
- en: 'PyCharm creates the file, but it isn’t empty. The code in the file looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The IDE has presented us with a template containing a testing class that inherits
    from Python’s built-in unit testing framework. The framework is simply but unimaginatively
    called `unittest`. The template contains the required import at the top of the
    file, a testing class, one test method, and a `dunder-main` block that allows
    the script to run standalone. To get the test working, you need to modify this
    file. Start by adding an import to the file containing the class you want to test.
    The added line is in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, change the name of the class to `BankAccountTestCase`. Then, take out
    the `test_something(self)` method entirely and replace it with this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: To be honest, this is kind of a silly test because the constructor logic is
    extremely simple. Even I would be tempted to skip it. That isn’t always the case,
    though. If you’re doing something complicated in the constructor, you should unit-test
    it. Here, the example serves as a simple one to get us moving. All we did here
    was create a new instance of the `BankAccount` class and pass in a name, an account
    number, and an initial balance. Then, we used the `unittest` class’ `assertEqual`
    method to check each of the member variables to make sure they were set properly.
    There’s pretty much no way they weren’t unless you made a mistake, which is exactly
    the point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Beware of the pesky self-typing self):'
  prefs: []
  type: TYPE_NORMAL
- en: Having done a whole chapter on the miracles of auto-completion, I have to admit
    that sometimes, it can be annoying. This is one of those times. The instant you
    type the opening parenthesis of your test method, PyCharm is going to fill in
    the word `self`, along with the closing parenthesis and the colon for the end
    of the line. Because I type rapidly, I used to often wind up with something like
    `test_init(selfsel):` before I caught what happened. I’ve trained my right hand
    to find the *End* key on the keyboard as soon as I hit the opening parenthesis.
    This jumps you to the end of the auto-completed line. Hit *Enter*, and you’ll
    be right where you want to be.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re going to add two more tests below the first one. The first test will
    test the `withdraw` method. Type in the new method below the first test, but above
    the line with the `dunder-main` test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Type the test for the deposit below the `test_withdraw` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If you haven’t guessed yet, these two tests are going to fail. That’s OK. I
    like to see them fail so that I know the whole testing setup is working. One of
    the benefits and side effects of being a long-time software developer is you don’t
    just assume anything will just work, regardless of who wrote it or how much the
    thing costs. Call it a survival instinct. If you skip this step, then may the
    odds be ever in your favor.
  prefs: []
  type: TYPE_NORMAL
- en: Running the tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s run our tests. Like many things, there are lots of ways to run the tests.
    You have no doubt noticed the appearance of green arrows in your test code, as
    seen in *Figure 6**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2: Green run arrows will appear in the IDE as you create your tests](img/B19644_Figure_6.02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.2: Green run arrows will appear in the IDE as you create your tests'
  prefs: []
  type: TYPE_NORMAL
- en: 'These green arrows trigger a menu when you click them. For now, we’ll click
    the first item, which is `BankAccountTestCase`, the test runner will appear in
    the tool window at the bottom of the IDE window. You can see mine in *Figure 6**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3: The test runner shows the tests that run, including those that
    passed and failed, and the console output](img/B19644_Figure_6.03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.3: The test runner shows the tests that run, including those that
    passed and failed, and the console output'
  prefs: []
  type: TYPE_NORMAL
- en: 'The test runner itself has a complete set of tools integrated into its window.
    I’ve numbered them in *Figure 6**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: This pane shows the tests that passed and those that failed. They are displayed
    in a hierarchy that matches the call hierarchy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This pane shows the console output from the test run itself.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Above the output pane is a summary of the number of passing tests, along with
    how long the test suite ran.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To the left on the same toolbar is a collection of five buttons, followed by
    a vertical ellipsis. The ✓ and ⃠ buttons will filter out all the passed and failed
    tests, respectively. Filtering out the passed tests lets you focus solely on what
    failed. Filtering out the failed tests reduces the general malaise and utter hopelessness
    that you’ll feel when you have 5 out of 100 tests that passed. When this happens,
    I usually eat a sandwich and I feel better. Look at it this way: so long as you
    have failing tests, your job is probably safe because it would take longer to
    train a replacement than it would to wait until everything starts working. See
    it as a glass half-full. The next three before the ellipsis allow you to sort
    your test results, import tests from another file, and review your test run history.
    Say you have a test that was passing, then it failed and you wanted to go back
    and look at the last time it passed. That history is there if you need it. The
    ellipsis holds a few more options, including some miscellaneous settings for the
    test runner itself.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This toolbar allows you to rerun all the tests, rerun only those that failed,
    and stop a long-running test. Again, we have a vertical ellipsis, but this one
    has an interesting option for toggling **Auto Test**. Turning this option on will
    continually run your tests, for those of you who can’t stand the cursor travel
    time back down to the rerun button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you run tests for the first time, PyCharm will create run configurations
    for you automatically. You can see them in the **Run configuration** dropdown
    on the top toolbar.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing the failing tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have two tests that will always fail, no matter what we do. Let’s start
    by altering the `test_withdraw(self)` method in the `bank_account_test.py` file.
    Change it to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The first line instantiates the `BankAccount` class with some testable values.
    Next, we invoke the `withdraw` method and withdraw $2,000\. I hope it is for something
    fun! Usually, it is my daughters borrowing my wallet to either shop for clothes
    or maybe buy raw materials for an engineering project. I can hope, right? I now
    expect my balance to drop from $4,000 to $2,000\. So, I use the `assertEqual`
    method on the `unittest` class, which is the superclass for my `BankAccountTestCase`
    class. I pass in `test_account.balance`, which will be compared with the expected
    result.
  prefs: []
  type: TYPE_NORMAL
- en: 'I fully expect this test to pass! Click the rerun failed tests button shown
    in *Figure 6**.3*. It passed! Now, let’s write the `test_deposit` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The explanation here is the same as the last one, except this time, we are depositing
    $5,000 into my account. This rarely happens in real life, so give me a moment
    while I celebrate.
  prefs: []
  type: TYPE_NORMAL
- en: Rerun the failed tests. They should all pass now! But we’re not done yet, are
    we?
  prefs: []
  type: TYPE_NORMAL
- en: So far, these tests have followed the no-fault path. This means that so far,
    I’ve only tested the methods while running them as I designed them. Users in the
    real world will never do this. We need to test fault paths as well.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the fault paths
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is one obvious fault path we designed into the system: the overdraft.
    What will happen if we try to take out more money than is available in the current
    balance? Or as my daughters might say, how do we generate a signal that tells
    us it’s time to come home from the mall and hide the receipts?'
  prefs: []
  type: TYPE_NORMAL
- en: 'We account for this in our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we check if the new balance will be a negative number. If it
    is, we throw a `ValueError`. This test is going to be a little different. Instead
    of using `assertEquals` to test a no-fault result, we want to verify that when
    this condition exists, we not only throw an error but that we throw the right
    kind of error. This is important because we expect `ValueError`, but if some other
    error is produced, the tests will give us a false positive if we only test for
    a generic `Exception`. Add the following test `BankAccountTestCase` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As before, we instantiate the `BankAccount` class with some testable values.
    For the test, we want to assert that the withdraw method raises a `ValueError`
    if we pass in more money than what exists in the balance. Here, we use `self.assertRaises`,
    which takes three arguments. The first argument is the type of error we expect.
  prefs: []
  type: TYPE_NORMAL
- en: The second argument is the method under test. Note that we’re passing a reference
    to the function lambda-style. We aren’t executing the function since we need the
    `assertRaises` function to do that. Finally, we need to pass in the value of any
    arguments – in this case, some numbers that are bigger than the four grand I used
    for instantiation. In this case, I pass in `5000`. When I run this test, it should
    pass because the function will fail with the `ValueError` exception I expect.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is just one test left: we need to be sure that when we pass a negative
    number into the `deposit` method, we get a `ValueError`. I’ll leave this one for
    you to practice with. The full working code is in the repository code for this
    chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating tests automatically
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far, we’ve spent some time writing the `BankAccout` class, but think back
    to our original idea for a use case for unit testing: a financial transaction.
    This time, we’re going to write some code that needs to be tested, but instead
    of a generic test template, we’re going to generate a more exact test.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with the code we will be testing. Create a new file in your project
    called `transaction.py`. The contents of this file should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll need the `BankAccount` class since the whole idea is to write code that
    transfers money from one account to another in response to the sale of an item.
    Speaking of *item*, let’s make a class to represent what we’ll be buying:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'There’s nothing too crazy here – just two instance variables called `name`
    and `price`. Now for the hard part: we need a class to represent a transaction.
    Remember, a transaction is an atomic operation. All the steps should be completed.
    If there are any errors along the way, everything that happened before the error
    needs to be rolled back:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We started the class with a constructor that initializes two bank accounts
    and an item. After this comes the logic for the transaction itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to store the original balances. If anything goes awry, we’ll need this
    information to put everything back the way it was. Next comes the part where money
    changes hands. I’ll wrap it in a `try`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We attempt to withdraw money from the buyer’s account, then deposit the same
    amount into the seller’s account. If a `ValueError` is thrown, we put all the
    money back by restoring the balances to their original values. Once the money
    has been restored, we should still raise an error so that the primary application
    knows the error occurred. This function will need to report the result to a user
    interface to let the user know what happened with the transaction. The last line
    handles this for us. In a real application, you might want to create your own
    custom error that might yield more information, but this one serves us well for
    demonstrative purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Generating the transaction test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Earlier, we created a new test using the `class Transaction`. Then, click the
    **Generate…** menu option, as seen in *Figure 6**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4: The Generate… menu item can be found when you right-click your
    class definition](img/B19644_Figure_6.04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.4: The Generate… menu item can be found when you right-click your
    class definition'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click **Test…**, as seen in *Figure 6**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5: Click the Test… button to generate your test](img/B19644_Figure_6.05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.5: Click the Test… button to generate your test'
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, a dialog box will appear where you can control the test that
    will be generated, as seen in *Figure 6**.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6: PyCharm is about to generate a unit test file based on these
    settings](img/B19644_Figure_6.06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.6: PyCharm is about to generate a unit test file based on these settings'
  prefs: []
  type: TYPE_NORMAL
- en: PyCharm is about to create a file called `test_transaction.py`. Within that
    file, instead of a generic test class name, there will be a class definition called
    `TestTransaction`. Finally, within the file, assuming you leave the checkbox ticked,
    a test method stub will be generated called `test_do_transaction`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting file contains this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Way back in [*Chapter 1*](B19644_01.xhtml#_idTextAnchor014), I told you that
    one of the benefits of an IDE is that it can reduce boilerplate. The first time,
    PyCharm generated some generic boilerplate for us. At least we didn’t have to
    type it in, but it was almost as much effort to change what it generated. This
    time, there is even less work to do. If I had many methods in my class, there
    would be a correctly named stub for each of them.
  prefs: []
  type: TYPE_NORMAL
- en: All I must do now is write the code that makes the `test_do_transaction` method
    pass. Behold!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We started with the required imports. I know I’m going to need two tests, rather
    than just the one PyCharm generated. PyCharm generated one test method, which
    I’m using for the no-fault path. I’ll pass in something that works the way the
    method is intended to work. Since I know I have two tests, I can reuse the seller
    account to keep my test **DRY**. If you’re not familiar with the acronym, it stands
    for **Don’t Repeat Yourself**. By hoisting this code to the top of the file, I
    only need to type it once. This code will initialize a seller’s bank account with
    a balance of $4,000\. It also sets up the item we will be purchasing, which will
    not change between tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will move on to the test class itself, which was generated for us.
    We already have this part:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'I’m replacing the generated `self.fail()` with code that I hope will cause
    the test to pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As usual, I instantiate the classes I’ll be using in the test. So far, I’ve
    made two accounts and an item with a price. Next, I’ll run the method under test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, I’ll check my results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: You might be tempted to get fancy with the test code. Be careful with this.
    Fancy test code is as likely to break as the purposefully fancy code it is meant
    to test. If you are testing complicated math, please don’t duplicate the calculation
    in the test and then compare it to the code under test. You should be plugging
    in known inputs and checking for known outputs. Nothing more!
  prefs: []
  type: TYPE_NORMAL
- en: 'This test represents the no-fault path. I fully expect this to pass since this
    exercise merely entails everything working under ideal conditions. Let’s see if
    I’m right. Click any of the green run buttons. My result is shown in *Figure 6**.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7: So far, so good! My test is passing!](img/B19644_Figure_6.07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.7: So far, so good! My test is passing!'
  prefs: []
  type: TYPE_NORMAL
- en: We need a test for at least one fault path. In this case, it will be to test
    what happens when I don’t have enough in my account to cover buying a book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s my test for that case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'When I left for work today, I had at least $9,000 in my account. But my daughter
    Phoebe “borrowed” my card out of my jacket pocket. She said she was going to create
    a robotic bicycle factory. I thought nothing of it. She was kidding, right? So,
    I go to the bookstore after work, intent on picking up the latest masterpiece:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The transaction occurs. Do you know that sound that Pac-Man makes when he gets
    eaten by a ghost? I’m making that sound now. The sale will fail; let’s see if
    the transaction rolls back correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This last piece of code verifies that both the buyer and seller balances are
    returned to their original values. Run the tests – they should both pass! See
    *Figure 6**.8* for my triumphant test run. I can’t wait to go home and relax!
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8: I’d better call my wife and tell her to keep dinner warm for
    me](img/B19644_Figure_6.08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.8: I’d better call my wife and tell her to keep dinner warm for me'
  prefs: []
  type: TYPE_NORMAL
- en: It looks like I was a little overconfident. The output window shows a set of
    stack traces for everything that went wrong. It’s so long that I had to scroll
    down quite a bit to get to the good part of this screenshot. In the trace (which
    is not shown), I can see that a few of the errors I thought would be thrown were,
    and that’s fine. The two we can see here are not. First, I intended to verify
    that the message coming from the exception matched the value I assigned in the
    definition. Again, I’m doing this to make sure the error I threw is the one we’re
    seeing and not some other error resulting from a mistake. It looks like I didn’t
    understand the structure of the error, and in fact, there is no attribute called
    message. I coulda swore! Wait – that’s probably from some other language. OK,
    I can look that up.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other, more disturbing error is that my transaction didn’t roll back! As
    you look at the trace, you’ll see that there are hyperlinks throughout that allow
    you to navigate directly to the fault code mentioned in the trace. It is very
    easy to move around and look for problems. I can find the line for the first problem
    in the list of stack traces, as shown in *Figure 6**.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9: The stack traces are riddled with hyperlinks that will jump you
    to the offending section of your code](img/B19644_Figure_6.09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.9: The stack traces are riddled with hyperlinks that will jump you
    to the offending section of your code'
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking this link takes me to the problematic code shown in *Figure 6**.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10: Fiddlesticks! The IDE even told me line 34 was wrong, but I
    didn’t listen](img/B19644_Figure_6.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.10: Fiddlesticks! The IDE even told me line 34 was wrong, but I didn’t
    listen'
  prefs: []
  type: TYPE_NORMAL
- en: 'I have a few options here, don’t I? I could use the documentation features
    in PyCharm by hovering over the `e` variable. We talked about automatic documentation
    features in [*Chapter 4*](B19644_04.xhtml#_idTextAnchor077). *Figure 6**.11* shows
    what this looks like in case you’ve been skipping around:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.11: The auto-documentation feature will give me a link to the official
    documentation](img/B19644_Figure_6.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.11: The auto-documentation feature will give me a link to the official
    documentation'
  prefs: []
  type: TYPE_NORMAL
- en: There’s no easy answer here, is there? Sure, I could click on the link at the
    bottom and go to the Python site and read the documentation. If I do that, though,
    I’ll lose any credibility with you, the reader. Read the manual with y’all watching?
    No chance! I’m sure I’d find the answer but at the expense of my pride.
  prefs: []
  type: TYPE_NORMAL
- en: 'I have another idea! I’ve talked about PyCharm’s console before. I’d like to
    try something out. Check out *Figure 6**.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12: If the PyCharm Console button (2) isn’t on your toolbar, click
    the ellipses (1) to turn it on](img/B19644_Figure_6.12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.12: If the PyCharm Console button (2) isn’t on your toolbar, click
    the ellipses (1) to turn it on'
  prefs: []
  type: TYPE_NORMAL
- en: 'The arrow pointing to *2* will open the PyCharm console. If you’ve never done
    this, that icon won’t be on the toolbar. You’ll need to click the ellipsis at
    *1* and click the **Python Console** area. This will add it to your toolbar. My
    console session is shown in *Figure 6**.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.13: Revisiting the console allows us to do a quick experiment to
    solve our error](img/B19644_Figure_6.13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.13: Revisiting the console allows us to do a quick experiment to solve
    our error'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the console, I first hit *Enter* on the first line. I did that for you.
    If I hadn’t, the console would have bunched everything up and it wouldn’t look
    as pretty. Next, I typed the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: I suspect that if I convert the check into a string, I will get the message
    I am looking for. Call it intuition. Or call it “I looked it up with **ChatGPT**
    while your back was turned.” I’m going with intuition.
  prefs: []
  type: TYPE_NORMAL
- en: 'If I type in `str(check)`, the Python REPL will evaluate the expression and
    print the result. The idea works. I can correct my code. Line 34 in `test_transaction.py`
    will now be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if I run the test again, it will fail, as shown in *Figure 6**.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14: Progress can be measured in software development by the rate
    at which the list of errors is reduced](img/B19644_Figure_6.14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.14: Progress can be measured in software development by the rate at
    which the list of errors is reduced'
  prefs: []
  type: TYPE_NORMAL
- en: We expected this. The list of problems got shorter, so it’s a victory! Let’s
    clear out the last problem. The transaction is failing to correctly reset the
    value of the seller’s account after the transaction fails. We could stare at it
    for a while, or we could take a more proactive approach by firing up PyCharm’s
    debugger and stepping through the whole test.
  prefs: []
  type: TYPE_NORMAL
- en: Working with PyCharm’s debugger
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 1*](B19644_01.xhtml#_idTextAnchor014), I lauded PyCharm’s debugger
    as the single biggest reason to use an IDE versus a command-line debugger such
    as the standard Python debugger, which is called **pdb**. Don’t get me wrong –
    you should learn to use pdb because there will be times when the IDE isn’t available.
    However, I suspect that once you use PyCharm’s, you’ll prefer it over anything
    else. Let’s see if I’m right.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a problem in our `Transaction` class that isn’t quite accurate. When
    it comes to testing, there are always two possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: The code is failing because of a flaw in the code under test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code is failing because of the test code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since we don’t know which possibility is correct at this point, the debugger
    is going to allow us to step through our code one line at a time and inspect its
    inner workings. To do this, we need to set a breakpoint. A breakpoint marks a
    spot in your code where you would like to halt its execution and inspect the contents
    of the variables, the stack, and so on. You can create a breakpoint by clicking
    the line number in the gutter within the editor, as shown in *Figure 6**.15*.
    I’m going to add a breakpoint to the beginning of the test so that we can walk
    through it. The test starts on line 25, so I’ll click on that line number; observe
    that the line number has been replaced with a red dot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15: Click a line number to create a breakpoint, which will replace
    the number with a red dot](img/B19644_Figure_6.15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.15: Click a line number to create a breakpoint, which will replace
    the number with a red dot'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to run the debugger. Click the green arrow in the editor window
    next to the method definition for the `test_transaction_overdraw_fault(self)`
    method. This time, click the **Debug ‘Python tests for tes…’** option, shown in
    *Figure 6**.16*, to run the failed test:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16: Clicking the green arrows provides a menu that can be used to
    make variations to a running test, including running the debugger](img/B19644_Figure_6.16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.16: Clicking the green arrows provides a menu that can be used to
    make variations to a running test, including running the debugger'
  prefs: []
  type: TYPE_NORMAL
- en: 'When the debugger is run, the program will start, then stop on line 25 of our
    test. The IDE transformed significantly. Let’s look at *Figure 6**.17*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.17: The paused debugger in PyCharm](img/B19644_Figure_6.17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.17: The paused debugger in PyCharm'
  prefs: []
  type: TYPE_NORMAL
- en: There are a few things you might notice right away. First, the run buttons at
    the top of the IDE are now green, and the red stop button is illuminated (*1*).
    These are all visual clues showing that something is running, which of course
    we do.
  prefs: []
  type: TYPE_NORMAL
- en: The bottom half of the IDE is now taken up by the debugger tools (*2*). There
    is also a tab bar present (*3*), which allows you to run multiple debugging sessions
    at the same time. This can be handy when developing RESTful microservice architectures,
    which we’ll talk about in several of the upcoming chapters, most notably in *Chapter
    9*, *Creating a RESTful API* *with FastAPI*.
  prefs: []
  type: TYPE_NORMAL
- en: There is a list of threads on the right-hand side (*4*), which allows you to
    switch between and inspect the various threads at play. However, most of the time,
    you’re going to land in the right place and might use this only rarely. The area
    at location *5* shows everything that is currently in scope. Right now, that is
    just `self`, which you can see is an instance of the `TestTransaction` class.
  prefs: []
  type: TYPE_NORMAL
- en: '*6* shows two tabs that allow you to switch between the view we’re seeing right
    now, which allows you to inspect the state of the program at area *5*. If you
    switch this tab to `print` statements will appear so that you can review the output
    as the program runs.'
  prefs: []
  type: TYPE_NORMAL
- en: The toolbar marked with *7* houses a set of very useful tools, while the expression
    window (*8*) allows you to add a watch or evaluate an expression using whatever
    is currently in scope.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most useful parts of the debugging window are the inspection area (*5*),
    the tab switch, which you can use to swap between the variable and thread inspector
    and console output (*6*), and the debugging toolbar (*7*). Let’s take a closer
    look at the debugging toolbar:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.18: The debugging toolbar in PyCharm](img/B19644_Figure_6.18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.18: The debugging toolbar in PyCharm'
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ve numbered each button. Let’s review them:'
  prefs: []
  type: TYPE_NORMAL
- en: This button restarts the debugging run. You can find a duplicate restart button
    at the top of the IDE window near the run button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This button stops the debugging run. You can find a duplicate stop button at
    the top of the IDE window near the restart button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is the **Continue** button. The debugger will stop at any breakpoint it
    hits and wait until you use one of the step buttons (*5* – *8*) or you hit this
    button to continue the run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **Pause** button will pause the run. This can be useful if you’re running
    a loop or an algorithm that takes a while and you want to pause the run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **Step Over** button will execute the current line where the debugger has
    paused. If that line is a function call to a function in your program, the function
    will execute normally and return, after which you’ll be taken to the next line
    of your code, where the debugger will remain paused. Here, you’re stepping over
    the execution of the next line.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In contrast, this is the **Step Into** button. If your debugger has paused on
    a line containing a function call, clicking this button will allow you to step
    into that function and step through as if you had placed a breakpoint at the beginning
    of the function. **Step Over** skips past this execution, while this button steps
    into it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Step Into My Code** is a game changer! This button is just like the **Step
    Into** button (*6*), except this one will not step into code that you didn’t create.
    By that, I mean the **Step Into** button will happily step you into the bowels
    of your third-party library code, or into the code comprising Python itself. This
    is rarely useful. The **Step Into My Code** button will only step into code that
    is part of your project.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is the **Step Out** button. If you find yourself stepping into some code
    that clearly isn’t a problem, or maybe you’ve taken into library code you didn’t
    create, the step-out code will jump you back out to the point where you entered.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Attention Visual Studio users
  prefs: []
  type: TYPE_NORMAL
- en: The buttons in the PyCharm debugger work differently than they do in Visual
    Studio! This took some getting used to for me. In Visual Studio, you can click
    the green button on the top toolbar to start the debugging session. When you hit
    a breakpoint, you can hit the same button to continue. In PyCharm, the continue
    button is in the debugging toolbar, in area *3* in *Figure 6**.18*. If you were
    to click the same button you used to launch the debugger, you would launch a second
    debug session. PyCharm will generally complain when you do this unless you’ve
    checked the box in the run configuration that allows multiple runs at the same
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Using the debugger to find and fix our test problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our unit test revealed a problem in our code. When our transaction fails due
    to an overdraft error, we expect the balances of our buyer and seller to revert
    to their original values. At this point, the seller is getting $39.95 in credit
    following a failed transaction. Let’s use the debugger to step through and see
    if we can figure out why this is happening.
  prefs: []
  type: TYPE_NORMAL
- en: 'Per *Figure 6**.19*, we’ve started the debugger on our unit test and we’ve
    stopped at line 25 in `test_transaction.py`. At this stage, nothing in the test
    method has run. When you’re looking at a highlighted line in PyCharm’s debugger,
    you need to remember that the highlighted line has not been executed yet. To execute
    the line, click the `buyer_account` has been instantiated, and our highlight will
    move to and stop on line 26, as shown in *Figure 6**.19*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19: Having clicked the Step Over button, the debugger has been stopped
    on line 26](img/B19644_Figure_6.19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.19: Having clicked the Step Over button, the debugger has been stopped
    on line 26'
  prefs: []
  type: TYPE_NORMAL
- en: To see the content of the objects, you’ll need to twirl open the caret, which
    I’ve circled in *Figure 6**.19*. You can see that `buyer_account` has a balance
    of $5\. However, what we’re interested in here is the seller account since that’s
    where the problem lies.
  prefs: []
  type: TYPE_NORMAL
- en: Click line 30 to add a breakpoint there, then click the `do_transaction()` method
    to watch it execute. Click the **Step Into My Code** button. Refer to *Figure
    6**.18* and look at *7* if you don’t remember which button I mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will take us to line 17 in `transaction.py`. Step over lines 17 and 18
    to arrive at line 19 and inspect our state. You’ll see the problem, which is shown
    in *Figure 6**.20*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20: The debugger reveals that the starting value of the seller balance
    is wrong](img/B19644_Figure_6.20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.20: The debugger reveals that the starting value of the seller balance
    is wrong'
  prefs: []
  type: TYPE_NORMAL
- en: The debugger reveals that the original seller balance is $4,039.95, where we
    would expect it to be $4,000\. You can see this value in two places. The variables
    window shows it to us (*1*), but you can also hover over any in-scope variable
    in the editor window (*2*) and see its value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, why would our starting balance be wrong? It’s a scope problem! Since I
    hoisted the `seller_account` variable to line 5 in `test_transaction.py` up to
    a global, the first test successfully changes the balance to $4,039.95 just like
    it should. Since it is global, that number remains. To fix this, we need to reset
    the balance of the seller account at the beginning of the `test_transaction_overdraw_fault(self)`
    method. We started our debugging efforts on line 25\. Let’s just make our change
    there. Click the stop button on the debugger toolbar, then add this line on line
    25:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Rerun your tests without debugging. Be bold! Assume it worked! If you’re not
    following along, kindly move to the edge of your seat and begin biting your nails
    nervously. Will our hero triumph in *Figure 6**.21*? Cue organ music: duhn duhn
    duuuuuhn!'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.21: Victory!](img/B19644_Figure_6.21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.21: Victory!'
  prefs: []
  type: TYPE_NORMAL
- en: It works! Now, it’s time to head home and heat up dinner since we’ve restored
    everyone’s faith in the international banking industry.
  prefs: []
  type: TYPE_NORMAL
- en: Checking test coverage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unit tests are most effective when there are tests to cover every class, method,
    function, or module in your program. As your software code grows, it is easy to
    forget to write tests or maybe to put them off until you have more time. PyCharm
    has a tool that can tell you what your test coverage is and helps you find unexploited
    opportunities for testing more of your work than you might have on your own.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check your test coverage, you just need to run your tests a little bit differently.
    We’ve been running our tests individually from within the test files. We need
    to run all the tests together so that we can have a comprehensive report of where
    we are missing coverage. For this, we will make a new run configuration. Click
    the run configurations dropdown on the toolbar and click `unittest` template.
    Make sure you use my settings, as shown in *Figure 6**.22*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.22: Create a run configuration that runs all your tests at once](img/B19644_Figure_6.22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.22: Create a run configuration that runs all your tests at once'
  prefs: []
  type: TYPE_NORMAL
- en: For the script path, enter the folder where your tests are located. Set the
    pattern to `*_test.py`. This will make the test runner find all files that end
    with `_test.py`, which is different from the defaults. The defaults will look
    for files beginning with “test.” I don’t particularly like this because it bunches
    all the tests together in the project file window instead of putting the test
    right next to the file it is testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'By setting the pattern and setting the test runner to a folder rather than
    a single file, the runner will find all files matching the pattern and run them
    as tests. Speaking of running, you can do that by clicking the ellipsis next to
    the run and debug buttons. See *Figure 6**.23* to locate the **Run ‘All Tests’**
    **with Coverage** menu item:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.23: Run ‘All Tests’ with Coverage allows you to run your tests and
    find out how much of your application isn’t covered by unit tests](img/B19644_Figure_6.23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.23: Run ‘All Tests’ with Coverage allows you to run your tests and
    find out how much of your application isn’t covered by unit tests'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first time you do this, you’ll likely see an error message – not from your
    code, but from PyCharm. See *Figure 6**.24* to see what I mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.24: The first time you run test coverage, you’ll be warned if you
    haven’t installed the coverage software or enabled the bundled copy](img/B19644_Figure_6.24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.24: The first time you run test coverage, you’ll be warned if you
    haven’t installed the coverage software or enabled the bundled copy'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running with coverage requires some software, `coverage.py`, which we haven’t
    installed. You have two options here: you can either add `coverage.py` to your
    project, or you can use the bundled version that ships with PyCharm. I prefer
    using the bundled version. You can click the word *enable* in the error message,
    which is displayed as a blue hyperlink, and PyCharm will turn on this setting
    for you. If you’d like to manage this setting yourself, see *Figure 6**.25* to
    see where the setting can be found:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.25: The setting for using the bundled coverage.py file allows you
    to use coverage.py without you having to add it to your project](img/B19644_Figure_6.25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.25: The setting for using the bundled coverage.py file allows you
    to use coverage.py without you having to add it to your project'
  prefs: []
  type: TYPE_NORMAL
- en: 'With `coverage.py` enabled, rerun your coverage test. Let’s see how we do:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.26: I wish my grades in college were this good!](img/B19644_Figure_6.26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.26: I wish my grades in college were this good!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Holy smokes! We have 100% coverage in the transaction tests, but a miserable
    failure in the `bank_account_test.py` file – that is, if you consider 94% coverage
    a failure. Being a perfectionist, I would like to see how I missed those points.
    I can double-click the line showing the 94% in `bank_account_test.py` and I’ll
    be treated to a color-coded gutter. Here, again, I must apologize for the book
    being printed in black and white. Area *1* in *Figure 6**.26* is colored red.
    These are the lines that are not covered by the tests. To be truthful, I don’t
    remember typing these in. I don’t need them since my test runner is executing
    my tests for me. I can simply remove these lines and re-format my file with *Ctrl*
    + *Alt* + *L*/*Cmd* + *Opt* + *L*. Rerun the test with coverage. My results in
    *Figure 6**.27* show that we’re close:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.27: We have achieved 100% coverage! Keep this up and you might get
    a raise](img/B19644_Figure_6.27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.27: We have achieved 100% coverage! Keep this up and you might get
    a raise'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `bank_account_test.py` file now has 100% coverage, but at the top, I can
    still see that the `bank_account` folder only has 98% coverage. This simply will
    not stand! Right now, I have my project explorer window closed to maximize space
    for the editor and coverage window. If I open it back up, having run with coverage,
    I will get some more information. *Figure 6**.28* shows where we should look.
    The `bank_account.py` file only has 92% coverage. Upon double-clicking to open
    it, I’ll see the lines I’m missing colored red, as seen in *Figure 6**.28*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.28: The grayish-red area in the gutter indicates that lines 17 and
    18 are not covered by any unit test](img/B19644_Figure_6.28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.28: The grayish-red area in the gutter indicates that lines 17 and
    18 are not covered by any unit test'
  prefs: []
  type: TYPE_NORMAL
- en: It looks like we have another unit test to write. I forgot to write a test for
    the error condition. This is legitimate! As you may recall, I left the deposit
    test as a challenge for you. I wrote it in my code for this book, but I forgot
    to write the error test. Coverage saves the day!
  prefs: []
  type: TYPE_NORMAL
- en: 'Open `bank_account_test.py` and add the following test, which will cover the
    case of trying to deposit a negative number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the test and verify it passes, then rerun the **All Tests** configuration
    with coverage. My result is shown in *Figure 6**.29*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.29: We have achieved 100% coverage for all files](img/B19644_Figure_6.29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.29: We have achieved 100% coverage for all files'
  prefs: []
  type: TYPE_NORMAL
- en: This time, we should have a perfect score! Now that we’re feeling fine, I’ll
    point out the coverage window on the right-hand side of the screen. It shows a
    list of the results, which we’ve already seen. Note the shield icon in the right
    toolbar. You can show or hide the coverage window by clicking this shield.
  prefs: []
  type: TYPE_NORMAL
- en: Test coverage output
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In addition to the graphical display, PyCharm outputs a report for the coverage
    run. You will see the output mentioned in the output window alongside the usual
    test output. Mine states the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The XML file is generated by `coverage.py`, which we enabled earlier. As you
    might have guessed, `coverage.py` is a popular Python tool for measuring code
    coverage during test runs. It is an open source tool that helps you identify which
    parts of your Python code are being exercised by your tests and which parts are
    not. The tool works by collecting information about which lines of code are executed
    during a test run and then generating a report that shows the percentage of code
    coverage. The XML output is used by PyCharm to render the color-coded UI displays
    we’ve been using. The XML output can also be used by your `coverage.py` to fail
    a build if test coverage is below a set threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first step in creating a great program is getting the program fully working.
    The second step is to perform automated testing to prove that the program works
    as intended. The final step ought to be tweaking the code so that the program
    runs as fast and as efficiently as possible. Poorly performing programs run the
    risk of having a low adoption rate at best, and may simply be unusable at worst.
    In England, the NHS has an algorithm that was designed to match organ transplant
    recipients to recently harvested organs. The algorithm is complicated but extremely
    time-sensitive. Harvested organs must be transplanted quickly; otherwise, their
    tissues will die and become useless. In short, the algorithm must be extremely
    accurate; otherwise, the transplanted organ may be rejected, resulting in the
    patient’s death. It must also be fast since the organ will lose viability, which
    may also result in patient death. Suddenly, I’m very glad for my job dealing with
    hardware system capacity planning and forecasting. Nobody has ever died because
    my database queries were too slow. At least, not that I know of.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to being able to run your tests with coverage, you can also run
    with performance profiling. While the coverage report tells you graphically which
    areas of your code remain untested, PyCharm’s profiler gives you reports on which
    parts of your code are consuming the lion’s share of the overall runtime. This
    allows you to spot bottlenecks so that you can focus your refactoring efforts
    toward making the code, and its execution, more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to there being several testing libraries that are widely used by Python
    developers, there is also a variety of profiling tools, including Yappi, cProfile,
    and VMProf. PyCharm supports them all, but they do not work the same. cProfile
    is built into Python, and so is the default profiler. Yappi is an improvement
    over cProfile because it allows you to profile multithreaded applications and
    supports CPU time profiling. VMProf supports statistical sampling. When you profile
    using this tool, it won’t simply time a single run of your program; instead, it
    will run and sample multiple runs, providing you with a more realistic performance
    profile. PyCharm will use VMProf if it is available. If not, it will look for
    Yappi. If it can’t find Yappi, then it will use the cProfile solution built into
    Python. For this book, I will stick to the default cProfile tool.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling in PyCharm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The code we’ll be profiling can be found in this book’s repository, in the
    `chapter-06` folder. The `profiling.py` file contains the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This code will compare two ways of computing the sum of the integers, ranging
    from one to an upper limit expressed as *n*, whose default value is 1,000,000\.
    The `custom_sum` function loops through all the elements, adding each to a running
    sum. The `built_in_sum` function utilizes the built-in `sum()` method of Python.
  prefs: []
  type: TYPE_NORMAL
- en: In the main scope, we will use commenting to swap between the two function calls
    to test both methods. We will be looking at our custom summing function first,
    so the call to `built_in_sum` is commented out for now.
  prefs: []
  type: TYPE_NORMAL
- en: The typical claim is that built-in functions are generally faster than any code
    you might write. In this example, we will be able to fact-check that claim and
    further qualify it with runtime statistics through our profiling process. Let’s
    get started.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with testing and coverage, we can start a profiling run by using either
    the green arrows within the editor or the run button ellipsis at the top of the
    screen. *Figure 6**.30* shows both options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.30: You can run a profile using either the ellipsis menu at the
    top right or by clicking the green arrow next to the dunder-main entry point on
    line 14](img/B19644_Figure_6.30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.30: You can run a profile using either the ellipsis menu at the top
    right or by clicking the green arrow next to the dunder-main entry point on line
    14'
  prefs: []
  type: TYPE_NORMAL
- en: 'When the profile run is complete, we will be provided with a performance report,
    as seen in *Figure 6**.31*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.31: The performance profile for the custom_sum function](img/B19644_Figure_6.31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.31: The performance profile for the custom_sum function'
  prefs: []
  type: TYPE_NORMAL
- en: On my computer, which in this case is a VMWare virtual machine with a very modest
    configuration (2 cores, 4 GB of RAM, and a 7,200 RPM spinning disk), the `custom_sum`
    function completed in 41 ms. The time and the percentage are a little bunched
    together on my display, but we can see that 100% of the time was spent in the
    `custom_sum` function. If this were a more complicated program with many functions
    being called during the run, we’d see a full listing of each function and how
    much time was spent on each. Pay attention to the **Own Time** column versus the
    **Time** column.
  prefs: []
  type: TYPE_NORMAL
- en: In PyCharm’s performance profiler, the **Time** column shows the total time
    spent executing a particular function or method, including the time spent executing
    any sub-functions or methods called within it.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the **Own Time** column shows the time spent executing only
    the code within the function or method itself, excluding any time spent executing
    sub-functions or methods. This means that the **Own Time** column can give you
    a better understanding of the performance of the code within a specific function
    or method, independent of any external factors such as the performance of other
    functions or methods it calls.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate the difference, consider a function, *A()*, that calls two other
    functions, *B()* and *C()*. If you look at the **Time** column for *A()*, it will
    include the time spent executing both *B()* and *C()* in addition to the time
    spent executing the code within *A()* itself. However, if you look at the **Own
    Time** column for *A()*, it will only show the time spent executing the code within
    *A()* and not the time spent executing *B()* and *C()*.
  prefs: []
  type: TYPE_NORMAL
- en: In general, the **Time** column can give you a sense of the overall performance
    impact of a particular function or method, while the **Own Time** column can help
    you focus on the performance of the code within that function or method.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing performance versus the built-in sum() function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s see how my 72 ms runtime fares against the built-in Python `sum()` function.
    Alter the bottom of the `main.py` file by commenting out the `custom_sum` function
    and commenting in the `built_in_sum` function, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Run a profile with this configuration. You can see my result in *Figure 6**.32*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.32: The built-in sum function appears to run significantly faster
    at 11 ms](img/B19644_Figure_6.32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.32: The built-in sum function appears to run significantly faster
    at 11 ms'
  prefs: []
  type: TYPE_NORMAL
- en: Wow, there’s no contest! On my computer, leveraging the built-in `sum()` function
    is seven times faster! In real life, I advise running each profile a few times
    and taking an average since the runtimes can vary. In my case, subsequent runs
    of the `built_in_sum` function ranged from 11 ms to 26 ms, which is a pretty wide
    variance.
  prefs: []
  type: TYPE_NORMAL
- en: Viewing the call graph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In addition to the statistics table, you can also view the profile as a call
    graph. This graph represents a tree-like view of your program’s run, as shown
    in *Figure 6**.33*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.33: The call graph shows a tree-like view of the program run](img/B19644_Figure_6.33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.33: The call graph shows a tree-like view of the program run'
  prefs: []
  type: TYPE_NORMAL
- en: The nodes in the call graph are shaded green and red. The darker the shade of
    red, the more time was spent on the function indicated by that node. In *Figure
    6**.33*, pretty much all of the time is being spent in the `custom_sum` function,
    which is as dark a red as it gets (trust me). The built-in `print` method takes
    up a tiny but non-zero amount of time when it prints the sum in the main function.
  prefs: []
  type: TYPE_NORMAL
- en: Navigating using the performance profile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can navigate to a function using either the statistics table or the corresponding
    node in the call graph. Just right-click, as shown in *Figure 6**.34*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.34: You can navigate to your code by right-clicking the function
    and selecting Navigate to Source](img/B19644_Figure_6.34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.34: You can navigate to your code by right-clicking the function and
    selecting Navigate to Source'
  prefs: []
  type: TYPE_NORMAL
- en: You can do the same thing on the call graph. Upon right-clicking a node on the
    call graph, you’ll get the same navigation option to take you to the source. This
    can help you navigate straight to any code you might want to inspect.
  prefs: []
  type: TYPE_NORMAL
- en: Performance cProfile snapshots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you do a profile run with cProfile, PyCharm will save a `.pstat` files
    are generated in my home folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: When I’m doing serious profiling work, I will often copy these files into a
    more convenient folder and alter their names to indicate the conditions under
    which they were run. For example, in our example, I might call the first `.pstat`
    file something like `custom_sum_performance_1.pstat`; the second might be called
    `built_in_sum_performance_1.pstat`.
  prefs: []
  type: TYPE_NORMAL
- en: I’m doing this so that I have a baseline performance profile for each. In real
    life, I suspect you will rarely have such an easy alternative to what we’ve presented
    here. You’ll more likely have several versions of a function using different approaches
    to algorithm design. In those cases, keeping your `.pstat` files so that you can
    compare them with future runs can be very handy, if for no other reason than to
    brag at your next employee review.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can open your older `.pstat` files using the **Tools** menu, as shown in
    *Figure 6**.35*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.35: You can open your old snapshots via the Tools menu](img/B19644_Figure_6.35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.35: You can open your old snapshots via the Tools menu'
  prefs: []
  type: TYPE_NORMAL
- en: Opening this `.pstat` file will show the statistics table and call graph. If
    you’ve refactored the names of the functions, then you shouldn’t expect the navigation
    to still work; however, you can see the old results and compare them against a
    newer run.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, PyCharm’s ability to open and compare old `.pstat` files can be a useful
    tool for tracking the performance of your code over time and identifying areas
    where performance improvements can be made.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing, debugging, and profiling are high-level tasks we can use to analyze
    applications to look for improvements in correctness and performance, but they
    can be quite confusing to beginner developers. PyCharm offers straightforward
    and intuitive interfaces for these processes, making them more accessible and
    streamlined.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing is the process of making sure the individual components of a large
    system work as intended. PyCharm has convenient commands to generate test skeletons/boilerplate
    code that usually takes time for developers to write manually. While testing a
    program, it is important to consider expected faults, as well as the obvious tests
    for intended functionality.
  prefs: []
  type: TYPE_NORMAL
- en: In a debugging session, developers attempt to narrow down and identify the causes
    of bugs and errors that are detected during testing. With a graphical interface,
    combined with various options to track the values of variables throughout a program,
    PyCharm allows us to debug our programs dynamically with considerable freedom.
    The various stepping functions also provide us with a flexible way to step through
    the program we are trying to debug.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, the goal of profiling is to analyze the performance of a program and
    find ways to improve it. This can include looking for faster ways to compute a
    value or identifying a bottleneck in the program. With the ability to generate
    comprehensive statistics on the running time of each function that’s executed,
    as well as call graphs, PyCharm helps developers navigate the different components
    of a profiled program with ease.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also marks the end of the second part of this book, where we focused
    on improving our development productivity. From here, we will be considering the
    usage of PyCharm in more specialized fields, namely web development and data science
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover the basics of three universal web development
    languages – JavaScript, HTML, and CSS – within the context of PyCharm.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Answer the following questions to test your knowledge of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What is testing in the context of software development? What are the different
    testing methods?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does PyCharm support testing processes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is debugging in the context of software development?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does PyCharm support debugging processes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is profiling in the context of software development?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does PyCharm support profiling processes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the significance of run arrows in PyCharm’s editor?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Agile Software Development, Principles, Patterns, and Practices*, Martin,
    R. C. (2003). Prentice Hall.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Clean Architecture: A Craftsman’s Guide to Software Structure and Design*,
    Martin, R. C. (2017). Prentice Hall.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Real-World Implementation of C# Design Patterns*, Van Horn, B and Symons,
    V. (2022). Packt Publishing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be sure to check out the companion website for the book at[https://www.pycharm-book.com](https://www.pycharm-book.com)*.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 3: Web Development in PyCharm'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part of the book focuses on web development processes in Python programming
    and what support PyCharm has in store for web projects. Readers will be able to
    use PyCharm and its features to efficiently develop their web applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B19644_07.xhtml#_idTextAnchor172), *Web Development with JavaScript,
    HTML, and CSS*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B19644_08.xhtml#_idTextAnchor203), *Building a Dynamic Web Application
    with Flask*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B19644_09.xhtml#_idTextAnchor223), *Creating a RESTful API with
    FastAPI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B19644_10.xhtml#_idTextAnchor243), *More full stack frameworks:
    Django and Pyramid*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 11*, *Understanding Database Management in PyCharm*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
