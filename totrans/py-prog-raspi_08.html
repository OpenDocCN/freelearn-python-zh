<html><head></head><body>
        <section>

            <header>
                <h1 class="header-title">Awesome Things You Could Develop Using Python</h1>
            </header>

            <article>
                
<p>In this chapter, we will discuss some advanced topics in Python. We will also discuss certain unique topics (such as image processing) that let you get started with application development in Python.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Image processing using a Raspberry Pi Zero</h1>
            </header>

            <article>
                
<p>The Raspberry Pi Zero is an inexpensive piece of hardware that is powered by a 1 GHz processor. While it is not powerful to run certain advanced image processing operations, it can help you learn the basics on a $25 budget (the cost of Raspberry Pi Zero and a camera).</p>
<div class="packt_infobox">We recommend using a 16 GB card (or higher) with your Raspberry Pi Zero in order to install the image processing tool set discussed in this section.</div>
<p>For example, you could use a Raspberry Pi Zero to track a bird in your backyard. In this chapter, we are going to discuss different ways to get started with image processing on the Raspberry Pi Zero.</p>
<p>In order to test some examples using the camera in this section, a Raspberry Pi Zero v1.3 or later is required. Check the back of your Raspberry Pi Zero to verify the board version:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="281" src="assets/image_08_001.png" width="281"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Identifying your Raspberry Pi Zero's version</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">OpenCV</h1>
            </header>

            <article>
                
<p><strong>OpenCV</strong> is an open source toolbox that consists of different software tools developed for image processing. OpenCV is a cross-platform toolbox that has been developed with support for different operating systems. Because OpenCV is available under an open source license, researchers across the world have contributed to its growth by developing tools and techniques. This has made developing applications with relative ease. Some applications of OpenCV include face recognition and license plate recognition.</p>
<div class="packt_infobox">Due to its limited processing power, it can take several hours to complete the installation of the framework. It took us approximately 10 hours at our end.</div>
<p>We followed the instructions to install OpenCV on the Raspberry Pi Zero from <a href="http://www.pyimagesearch.com/2015/10/26/how-to-install-opencv-3-on-raspbian-jessie/"><span class="URLPACKT">http://www.pyimagesearch.com/2015/10/26/how-to-install-opencv-3-on-raspbian-jessie/</span></a>.We specifically followed the instructions to install OpenCV with Python 3.x bindings and verified the installation process. It took us approximately 10 hours to finish installing OpenCV on the Raspberry Pi Zero. We are not repeating the instructions in the interest of not reinventing the wheel.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">The verification of the installation</h1>
            </header>

            <article>
                
<p>Let's make sure that the OpenCV installation and its Python bindings work. Launch the command-line terminal and make sure that you have launched the <kbd>cv</kbd> virtual environment by executing the <kbd>workon cv</kbd> command (you can verify that you are in the <kbd>cv</kbd> virtual environment):</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="63" src="assets/image_08_002.png" width="310"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Verify that you are in the cv virtual environment</div>
<p>Now, let's make sure that our installation works correctly. Launch the Python interpreter from the command line and try to import the <kbd>cv2</kbd> module:</p>
<pre>
    <strong>&gt;&gt;&gt; import cv2</strong><br/><strong>    &gt;&gt;&gt; cv2.__version__</strong><br/><strong>    '3.0.0'</strong>
</pre>
<p>This proves that OpenCV is installed on the Raspberry Pi Zero. Let's write a <em>hello world</em> example involving OpenCV. In this example, we are going to open an image (this can be any color image on your Raspberry Pi Zero's desktop) and display it after converting it to grayscale. We will be using the following documentation to write our first example: <a href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html"><span class="URLPACKT">http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html</span></a>.</p>
<p>According to the documentation, we need to make use of the <kbd>imread()</kbd> function to read the contents of the image file. We also need to specify the format in which we would like to read the image. In this case, we are going to read the image in grayscale format. This is specified by <kbd>cv2.IMREAD_GRAYSCALE</kbd> that is passed as the second argument to the function:</p>
<pre>
import cv2 <br/><br/>img = cv2.imread('/home/pi/screenshot.jpg',cv2.IMREAD_GRAYSCALE)
</pre>
<p>Now that the image is loaded in grayscale format and saved to the <kbd>img</kbd> variable, we need to display it in a new window. This is enabled by the <kbd>imshow()</kbd> function. According to the documentation, we can display an image by specifying the window name as the first argument and the image as the second argument:</p>
<pre>
cv2.imshow('image',img)
</pre>
<p>In this case, we are going to open a window named <kbd>image</kbd> and display the contents of <kbd>img</kbd> that we loaded in the previous step. We will display the image until a keystroke is received. This is achieved using the <kbd>cv2.waitKey()</kbd> function. According to the documentation, the <kbd>waitkey()</kbd> function listens for keyboard events:</p>
<pre>
cv2.waitKey(0)
</pre>
<p>The <kbd>0</kbd> argument indicates that we are going to wait indefinitely for a keystroke. According to the documentation, when the duration, in milliseconds, is passed as an argument, the <kbd>waitkey()</kbd> function listens to keystrokes for the specified duration. When any key is pressed, the window is closed by the <kbd>destroyAllWindows()</kbd> function:</p>
<pre>
cv2.destroyAllWindows()
</pre>
<p>Putting it all together, we have this:</p>
<pre>
import cv2<br/><br/>img = cv2.imread('/home/pi/screenshot.jpg',cv2.IMREAD_GRAYSCALE)<br/>cv2.imshow('image',img)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()
</pre>
<p>The preceding code sample is available for download along with this chapter as <kbd>opencv_test.py</kbd>. Once you are done installing OpenCV libraries, try loading an image as shown in this example. It should load an image in grayscale, as shown in the following figure:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="340" src="assets/image_08_003.jpg" width="425"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">The Raspberry Pi desktop loaded in grayscale</div>
<p>This window would close at the press of any key.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">A challenge to the reader</h1>
            </header>

            <article>
                
<p>In the preceding example, the window closes at the press of any key. Take a look at the documentation and determine if it is possible to close all windows at the press of a mouse button.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Installing the camera to the Raspberry Zero</h1>
            </header>

            <article>
                
<p>A camera connector and a camera is required for testing our next example. One source to buy the camera and the adapter is provided here:</p>
<table class="MsoTableGrid">
<tbody>
<tr>
<td><strong>Name</strong></td>
<td><strong>Source</strong></td>
</tr>
<tr>
<td>Raspberry Pi Zero camera adapter</td>
<td><a href="https://thepihut.com/products/raspberry-pi-zero-camera-adapter"><span class="URLPACKT">https://thepihut.com/products/raspberry-pi-zero-camera-adapter</span></a></td>
</tr>
<tr>
<td>Raspberry Pi camera</td>
<td><a href="https://thepihut.com/products/raspberry-pi-camera-module"><span class="URLPACKT">https://thepihut.com/products/raspberry-pi-camera-module</span></a></td>
</tr>
</tbody>
</table>
<p>Perform the following steps to install a camera to the Raspberry Pi Zero:</p>
<ol>
<li>The first step is interfacing the camera to the Raspberry Pi Zero. The camera adapter can be installed as shown in the following figure. Lift the connector tab and slide the camera adapter and press the connector gently:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="297" src="assets/image_08_004.jpg" width="223"/></div>
<ol start="2">
<li>We need to enable the camera interface on the Raspberry Pi Zero. On your desktop, go to <span class="packt_screen">Preferences</span> and launch <span class="packt_screen">Raspberry Pi Configuration</span>. Under the <span class="packt_screen">Interfaces</span> tab of the Raspberry Pi configuration, enable the camera, and save the configuration:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref"><img class=" image-border" height="247" src="assets/image_08_005.png" width="294"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Enable the camera interface</div>
<ol start="3">
<li>Let's test the camera by taking a picture by running the following command from the command-line terminal:</li>
</ol>
<pre>
       <strong>raspistill -o /home/pi/Desktop/test.jpg</strong>
</pre>
<ol start="4">
<li>It should take a picture and save it to your Raspberry Pi's desktop. Verify that the camera is functioning correctly. If you are not able to get the camera working, we recommend the troubleshooting guide published by the Raspberry Pi Foundation: <a href="https://www.raspberrypi.org/documentation/raspbian/applications/camera.md"><span class="URLPACKT">https://www.raspberrypi.org/documentation/raspbian/applications/camera.md</span></a>.</li>
</ol>
<p><span class="URLPACKT">The camera cable is a bit unwieldy, and it can make things difficult while trying to take a picture. We recommend using a camera mount. We found this one to be useful (shown in the following image) at</span> <a href="http://a.co/hQolR7O"><span class="URLPACKT">http://a.co/hQolR7O</span></a>:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="174" src="assets/image_08_006.png" width="233"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Use a mount for your Raspberry Pi's camera</div>
<p><span class="URLPACKT">Let's take the camera for a spin and use it alongside OpenCV libraries:</span></p>
<ol>
<li><span class="URLPACKT">We are going to take a picture using the camera and display it using the OpenCV framework. In order to access the camera in Python, we need the</span> <kbd>picamera</kbd> <span class="URLPACKT">package. This can be installed as follows:</span></li>
</ol>
<pre>
       <strong>pip3 install picamera</strong>
</pre>
<ol start="2">
<li>Let's make sure that the package works as intended with a simple program. The documentation for the <kbd>picamera</kbd> package is available at <a href="https://picamera.readthedocs.io/en/release-1.12/api_camera.html"><span class="URLPACKT">https://picamera.readthedocs.io/en/release-1.12/api_camera.html</span></a>.</li>
<li>The first step is initializing the <kbd>PiCamera</kbd> class. This is followed by flipping the image across the vertical axis. This is only required because the camera is mounted upside down on the mount. This may not be necessary with other mounts:</li>
</ol>
<pre>
       with PiCamera() as camera: <br/>       camera.vflip = True
</pre>
<ol start="4">
<li>Before taking a picture, we can preview the picture that is going to be captured using the <kbd>start_preview()</kbd> method:</li>
</ol>
<pre>
       camera.start_preview()
</pre>
<ol start="5">
<li>Let's preview for <kbd>10</kbd> seconds before we take a picture. We can take a picture using the <kbd>capture()</kbd> method:</li>
</ol>
<pre>
       sleep(10) <br/>       camera.capture("/home/pi/Desktop/desktop_shot.jpg") <br/>       camera.stop_preview()
</pre>
<ol start="6">
<li>The <kbd>capture()</kbd> method requires the file location as an argument (as shown in the preceding snippet). Once we are done, we can close the camera preview using <kbd>stop_preview()</kbd>.</li>
<li>Putting it altogether, we have this:</li>
</ol>
<pre>
       from picamera import PiCamera <br/>       from time import sleep<br/><br/>       if __name__ == "__main__": <br/>         with PiCamera() as camera: <br/>           camera.vflip = True <br/>           camera.start_preview() <br/>           sleep(10) <br/>           camera.capture("/home/pi/Desktop/desktop_shot.jpg") <br/>           camera.stop_preview()
</pre>
<p style="padding-left: 90px">The preceding code sample is available for download along with this chapter as <kbd>picamera_test.py</kbd>. A snapshot taken using the camera is shown in the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="205" src="assets/image_08_007.png" width="279"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Image captured using the Raspberry Pi camera module</div>
<ol start="8">
<li>Let's combine this example with the previous one—convert this image to grayscale and display it until a key is pressed. Ensure that <span>you</span> are still within the <kbd>cv</kbd> virtual environment workspace.</li>
<li>Let's convert the captured image to grayscale as follows:</li>
</ol>
<pre>
       img = cv2.imread("/home/pi/Desktop/desktop_shot.jpg",<br/>       cv2.IMREAD_GRAYSCALE)
</pre>
<p style="padding-left: 60px">The following is the image converted upon capture:</p>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref"><img class=" image-border" height="225" src="assets/image_08_008.png" width="358"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Image converted to grayscale upon capture</div>
<ol start="10">
<li>Now we can display the grayscale image as follows:</li>
</ol>
<pre>
       cv2.imshow("image", img) <br/>       cv2.waitKey(0) <br/>       cv2.destroyAllWindows()
</pre>
<p>The modified example is available for download as <kbd>picamera_opencvtest.py</kbd>.</p>
<p>So far, we have demonstrated developing image processing applications in Python. In <a href="8ab7d103-3b8b-459e-b64c-fb95200c8a52.xhtml"><span class="ChapterrefPACKT">Chapter 10</span></a>, <em>Home Automation Using the Raspberry Pi Zero</em>, we have demonstrated another example using OpenCV. This should get you kick-started with learning OpenCV in Python. We also recommend checking out examples available with the OpenCV Python binding documentation (link provided in the introduction part of this section).</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Speech recognition</h1>
            </header>

            <article>
                
<p>In this section, we will discuss developing a speech recognition example in Python involving speech recognition. We will make use of the <kbd>requests</kbd> module (discussed in the previous chapter) to transcribe audio using <kbd>wit.ai</kbd> (<a href="https://wit.ai/">https://wit.ai/</a>).</p>
<div class="packt_infobox">There are several speech recognition tools, including Google's Speech API, IBM Watson, Microsoft Bing's speech recognition API. We are demonstrating <kbd>wit.ai</kbd> as an example.</div>
<p>Speech recognition can be useful in applications where we would like to enable the Raspberry Pi Zero responses to voice commands. For example, in <a href="8ab7d103-3b8b-459e-b64c-fb95200c8a52.xhtml"><span class="ChapterrefPACKT">Chapter 10</span></a><span>,</span> <em>Home Automation Using the Raspberry Pi Zero</em>, we will be working on a home automation project. We could make use of speech recognition to respond to voice commands.</p>
<p>Let's review building the speech recognition application in Python using <kbd>wit.ai</kbd> (its documentation is available here at <a href="https://github.com/wit-ai/pywit"><span class="URLPACKT">https://github.com/wit-ai/pywit</span></a>). In order to perform speech recognition and recognize voice commands, we will need a microphone. However, we will demonstrate using a readily available audio sample. We will make use of audio samples made available by a research publication (available at <a href="http://ecs.utdallas.edu/loizou/speech/noizeus/clean.zip"><span class="URLPACKT">http://ecs.utdallas.edu/loizou/speech/noizeus/clean.zip</span></a>).</p>
<div class="packt_infobox">The <kbd>wit.ai</kbd> API license states that the tool is free to use, but the audio uploaded to their servers are used to tune their speech transcription tool.</div>
<p>We will now attempt transcribing the <kbd>sp02.wav</kbd> audio sample performing the following steps:</p>
<ol>
<li>The first step is signing up for an account with <kbd>wit.ai</kbd>. Make a note of the API as shown in the following screenshot:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="146" src="assets/image_08_009.png" width="535"/></div>
<ol start="2">
<li>The first step is installing the requests library. It could be installed as follows:</li>
</ol>
<pre>
       <strong>pip3 install requests </strong>
</pre>
<ol start="3">
<li>According to the <kbd>wit.ai</kbd> documentation, we need to add custom headers to our request that includes the API key (replace <kbd>$TOKEN</kbd> with the token from your account). We also need to specify the file format in the header. In this case, it is a <kbd>.wav</kbd> file, and the sampling frequency is 8000 Hz:</li>
</ol>
<pre>
       import requests <br/><br/>       if __name__ == "__main__": <br/>         url = 'https://api.wit.ai/speech?v=20161002' <br/>         headers = {"Authorization": "Bearer $TOKEN", <br/>                    "Content-Type": "audio/wav"}
</pre>
<ol start="4">
<li>In order to transcribe the audio sample, we need to attach the audio sample in the request body:</li>
</ol>
<pre>
       files = open('sp02.wav', 'rb') <br/>       response = requests.post(url, headers=headers, data=files) <br/>       print(response.status_code) <br/>       print(response.text)
</pre>
<ol start="5">
<li>Putting it all together, gives us this:</li>
</ol>
<pre>
       #!/usr/bin/python3 <br/><br/>       import requests <br/><br/>       if __name__ == "__main__": <br/>         url = 'https://api.wit.ai/speech?v=20161002' <br/>         headers = {"Authorization": "Bearer $TOKEN", <br/>                    "Content-Type": "audio/wav"} <br/>         files = open('sp02.wav', 'rb') <br/>         response = requests.post(url, headers=headers, data=files) <br/>         print(response.status_code) <br/>         print(response.text)
</pre>
<p>The preceding code sample is available for download along with this chapter as <kbd>wit_ai.py</kbd>. Try executing the preceding code sample, and it should transcribe the audio sample: <kbd>sp02.wav</kbd>. We have the following code:</p>
<pre>
200<br/>{<br/>  "msg_id" : "fae9cc3a-f7ed-4831-87ba-6a08e95f515b",<br/>  "_text" : "he knew the the great young actress",<br/>  "outcomes" : [ {<br/>    "_text" : "he knew the the great young actress",<br/>    "confidence" : 0.678,<br/>    "intent" : "DataQuery",<br/>    "entities" : {<br/>      "value" : [ {<br/>        "confidence" : 0.7145905790744499,<br/>        "type" : "value",<br/>        "value" : "he",<br/>        "suggested" : true<br/>      }, {<br/>        "confidence" : 0.5699616515542044,<br/>        "type" : "value",<br/>        "value" : "the",<br/>        "suggested" : true<br/>      }, {<br/>        "confidence" : 0.5981701138805214,<br/>        "type" : "value",<br/>        "value" : "great",<br/>        "suggested" : true<br/>      }, {<br/>        "confidence" : 0.8999612482250062,<br/>        "type" : "value",<br/>        "value" : "actress",<br/>        "suggested" : true<br/>      } ]<br/>    }<br/>  } ],<br/>  "WARNING" : "DEPRECATED"<br/>}
</pre>
<p>The audio sample contains the following recording: <em>He knew the skill of the great young actress</em>. According to the <kbd>wit.ai</kbd> API, the transcription is <em>He knew the the great young actress</em>. The word error rate is 22% (<a href="https://en.wikipedia.org/wiki/Word_error_rate"><span class="URLPACKT">https://en.wikipedia.org/wiki/Word_error_rate</span></a>).</p>
<div class="packt_infobox">We will be making use of the speech transcription API to issue voice commands in our home automation project.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Automating routing tasks</h1>
            </header>

            <article>
                
<p>In this section, we are going to discuss automating routing tasks in Python. We took two examples such that they demonstrate the ability of a Raspberry Pi Zero acting as a personal assistant. The first example involves improving your commute, whereas the second example serves as an aid to improve your vocabulary. Let's get started.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Improving daily commute</h1>
            </header>

            <article>
                
<p>Many cities and public transit systems have started sharing data with the public in the interest of being transparent and improving their operational efficiency. Transit systems have started sharing advisories and transit information to the public through an API. This enables anyone to develop mobile applications that provide information to commuters. At times, it helps with easing congestion within the public transit system.</p>
<p>This example was inspired by a friend who tracks bicycle availability in San Francisco's bike share stations. In the San Francisco Bay Area, there is a bicycle sharing program that enables commuters to rent a bike from a transit center to their work. In a crowded city like San Francisco, bike availability at a given station fluctuates depending on the time of day.</p>
<p>This friend wanted to plan his day based on bike availability at the nearest bike share station. If there are very few bikes left at the station, this friend preferred leaving early to rent a bike. He was looking for a simple hack that would push a notification to his phone when the number of bikes is below a certain threshold. San Francisco's bike share program makes this data available at <a href="http://feeds.bayareabikeshare.com/stations/stations.json"><span class="URLPACKT">http://feeds.bayareabikeshare.com/stations/stations.json</span></a>.</p>
<p>Let's review building a simple example that would enable sending a push notification to a mobile device. In order to send a mobile push notification, we will be making use of <strong>If This Then That</strong> (<strong>IFTTT</strong>)—a service that enables connecting your project to third-party services.</p>
<p>In this example, we will parse the data available in JSON format, check the number of available bikes at a specific station, and if it is lower than the specified threshold, it triggers a notification on your mobile device.</p>
<p>Let's get started:</p>
<ol>
<li>The first step is retrieving the bike availability from the bike share service. This data is available in JSON format at <a href="http://feeds.bayareabikeshare.com/stations/stations.json"><span class="URLPACKT">http://feeds.bayareabikeshare.com/stations/stations.json</span></a>. The data includes bike availability throughout the network.</li>
<li>The bike availability at each station is provided with parameters, such as station ID, station name, address, number of bikes available, and so on.</li>
<li>In this example, we will retrieve the bike availability for the <kbd>Townsend at 7th</kbd> station in San Francisco. The station ID is <kbd>65</kbd> (open the earlier-mentioned link in a browser to find <kbd>id</kbd>). Let's write some Python code to retrieve the bike availability data and parse this information:</li>
</ol>
<pre>
       import requests <br/><br/>       BIKE_URL = http://feeds.bayareabikeshare.com/stations <br/>       /stations.json <br/><br/>       # fetch the bike share information <br/>       response = requests.get(BIKE_URL) <br/>       parsed_data = response.json()
</pre>
<p style="padding-left: 60px">The first step is fetching the data using a <kbd>GET</kbd> request (via the <kbd>requests</kbd> module). The <kbd>requests</kbd> module provides an inbuilt JSON decoder. The JSON data can be parsed by calling the <kbd>json()</kbd> function.</p>
<ol start="4">
<li>Now, we can iterate through the dictionary of stations and find the bike availability at <kbd>Townsend at 7th</kbd>, by performing the following steps:</li>
</ol>
<div style="margin-left: 2em">
<ol>
<li>In the retrieved data, each station's data is furnished with an ID. The station ID in question is <kbd>65</kbd> (open the data feed URL provided earlier in a browser to understand the data format; a snippet of the data is shown in the following screenshot):</li>
</ol>
</div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="20" src="assets/image_08_010.png" width="603"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">A snippet of the bike share data feed fetched using a browser</div>
<div style="margin-left: 2em">
<ol start="2">
<li>We need to iterate through the values and determine if the station <kbd>id</kbd> matches that of <kbd>Townsend at 7th</kbd>:</li>
</ol>
</div>
<pre>
              station_list = parsed_data['stationBeanList'] <br/>              for station in station_list: <br/>                if station['id'] == 65 and <br/>                   station['availableBikes'] &lt; 2: <br/>                  print("The available bikes is %d" % station<br/>                  ['availableBikes'])
</pre>
<ol start="5">
<li style="list-style: none; display: inline">
<ol start="3">
<li>If there are less than <kbd>2</kbd> bikes available at the station, we push a mobile notification to our mobile device.</li>
</ol>
</li>
<li>In order to receive mobile notifications, you need to install <em>IF by IFTTT</em> app (available for Apple and Android devices).</li>
<li>We also need to set up a recipe on IFTTT to trigger mobile notifications. Sign up for an account at <a href="https://ifttt.com/">https://ifttt.com/</a>.</li>
</ol>
<p style="padding-left: 60px">IFTTT is a service that enables creating recipes that connecting devices to different applications and automating tasks. For example, it is possible to log events tracked by the Raspberry Pi Zero to a spreadsheet on your Google Drive.</p>
<p style="padding-left: 60px">All recipes on IFTTT follow a common template—<em>if this then that</em>, that is, if a particular event has occurred, then a specific action is triggered. For this example, we need to create an applet that triggers a mobile notification on receiving a web request.</p>
<ol start="7">
<li>You can start creating an applet using the drop-down menu under your account, as shown in the following screenshot:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="163" src="assets/image_08_011.png" width="522"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Start creating a recipe on IFTTT</div>
<ol start="8">
<li>It should take you to a recipe setup page (shown as follows). Click on <span class="packt_screen">this</span> and set up an incoming web request:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="75" src="assets/image_08_012.png" width="266"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Click on this</div>
<ol start="9">
<li>Select the <span class="packt_screen">Maker Webhooks</span> channel as the incoming trigger:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="151" src="assets/image_08_013.png" width="250"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Select the Maker Webhooks channel</div>
<ol start="10">
<li>Select <span class="packt_screen">Receive a web request</span>. A web request from the Raspberry Pi would act as a trigger to send a mobile notification:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="228" src="assets/image_08_014.png" width="388"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Select Receive a web request</div>
<ol start="11">
<li>Create a trigger named <kbd>mobile_notify</kbd>:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="295" src="assets/image_08_015.png" width="260"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Create a new trigger named mobile_notify</div>
<ol start="12">
<li>It is time to create an action for the incoming trigger. Click on <span class="packt_screen">that</span>.</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="61" src="assets/image_08_016.png" width="234"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Click on that</div>
<ol start="13">
<li>Select <span class="packt_screen">N</span><span class="packt_screen">otifications</span>:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="153" src="assets/image_08_017.png" width="258"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Select Notifications</div>
<ol start="14">
<li>Now, let's format the notification that we would like to receive on our devices:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="211" src="assets/image_08_018.png" width="304"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Setup notification for your device</div>
<ol start="15">
<li>In the mobile notification, we need to receive the number of bikes available at the bike share station. Click on the <span class="packt_screen">+ Ingredient</span> button and select <kbd>Value1</kbd>.</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="262" src="assets/image_08_019.png" width="252"/></div>
<p style="padding-left: 60px">Format the message to suit your needs. For example, when a notification is triggered by the Raspberry Pi, it would be great to receive a message in the following format: <kbd>Time to go home! Only 2 bikes are available at Townsend &amp; 7th!</kbd></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="275" src="assets/image_08_020.png" width="239"/></div>
<ol start="16">
<li>Once you are satisfied with the message format, select <span class="packt_screen">Create action</span> and your recipe should be ready!</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="311" src="assets/image_08_021.png" width="205"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Create a recipe</div>
<ol start="17">
<li>In order to trigger a notification on our mobile device, we need a URL to make the <kbd>POST</kbd> request and a trigger key. This is available under <span class="packt_screen">Services</span> | <span class="packt_screen">Maker Webhooks</span> | <span class="packt_screen">Settings</span> in your IFTTT account.</li>
</ol>
<p style="padding-left: 60px">The trigger can be located here:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="118" src="assets/image_08_022.png" width="343"/></div>
<p style="padding-left: 60px">Open the URL listed in <span>the</span> preceding screenshot in a new browser window. It provides the URL for the <kbd>POST</kbd> request as well as an explanation on (shown in the following screenshot) how to make a web request:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="343" src="assets/image_08_023.png" width="619"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Making a POST request using the earlier-mentioned URL (key concealed for privacy)</div>
<ol start="18">
<li>While making a request (as explained in the IFTTT documentation), if we include the number of bikes in the JSON body of request (using <kbd>Value1</kbd>), it can be shown on the mobile notification.</li>
<li>Let's revisit the Python example to make a web request when the number of bikes is below a certain threshold. Save the <kbd>IFTTT</kbd> URL and your IFTTT access key (retrieved from your IFTTT account) to your code as follows:</li>
</ol>
<pre>
       IFTTT_URL = "https://maker.ifttt.com/trigger/mobile_notify/ <br/>       with/key/$KEY"
</pre>
<ol start="20">
<li>When the number of bikes is below a certain threshold, we need to make a <kbd>POST</kbd> request with the bike information encoded in the JSON body:</li>
</ol>
<pre>
       for station in station_list: <br/>         if station['id'] == 65 and <br/>            station['availableBikes'] &lt; 3: <br/>           print("The available bikes is %d" % <br/>           station['availableBikes']) <br/>           payload = {"value1": station['availableBikes']} <br/>           response = requests.post(IFTTT_URL, json=payload) <br/>           if response.status_code == 200: <br/>             print("Notification successfully triggered")
</pre>
<ol start="21">
<li>In the preceding code snippet, if there are less than three bikes, a <kbd>POST</kbd> request is made using the <kbd>requests</kbd> module. The number of available bikes is encoded with the key <kbd>value1</kbd>:</li>
</ol>
<pre>
       payload = {"value1": station['availableBikes']}
</pre>
<ol start="22">
<li>Putting it all together, we have this:</li>
</ol>
<pre>
       #!/usr/bin/python3 <br/><br/>       import requests <br/>       import datetime <br/><br/>       BIKE_URL = "http://feeds.bayareabikeshare.com/stations/<br/>       stations.json" <br/>       # find your key from ifttt <br/>       IFTTT_URL = "https://maker.ifttt.com/trigger/mobile_notify/<br/>       with/key/$KEY" <br/><br/>       if __name__ == "__main__": <br/>         # fetch the bike share information <br/>         response = requests.get(BIKE_URL) <br/>         parsed_data = response.json() <br/>         station_list = parsed_data['stationBeanList'] <br/>         for station in station_list: <br/>           if station['id'] == 65 and <br/>              station['availableBikes'] &lt; 10: <br/>             print("The available bikes is %d" % station<br/>             ['availableBikes']) <br/><strong>       </strong>  payload = {"value1": station['availableBikes']} <br/>             response = requests.post(IFTTT_URL, json=payload) <br/>             if response.status_code == 200: <br/>               print("Notification successfully triggered")
</pre>
<p>The preceding code sample is available for download along with this chapter as <kbd>bike_share.py</kbd>. Try executing it after setting up a recipe on IFTTT. If necessary, adjust the threshold for the number of available bikes. You should receive a mobile notification on your device:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="202" src="assets/image_08_024.png" width="281"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Notification on your mobile device</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">A challenge to the reader</h1>
            </header>

            <article>
                
<p>In this example, the bike information is fetched and parsed and if necessary, a notification is triggered. How would you go about modifying this code example to make sure that it is executed between a given time of the day? (hint: make use of <kbd>datetime</kbd> module).</p>
<p>How would you go about building a desktop display that serves as a visual aid?</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Project challenge</h1>
            </header>

            <article>
                
<p>Try to find out if the transit systems in your area provide such data to its users. How would you make use of the data to help commuters save time? For example, how would you provide transit system advisories to your friends/colleagues using such data?</p>
<div class="packt_infobox">On completion of the book, we will post a similar example using the data from San Francisco <strong>Bay Area Rapid Transit</strong> (<strong>BART</strong>).</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Improving your vocabulary</h1>
            </header>

            <article>
                
<p>It is possible to improve your vocabulary using Python! Imagine setting up a large display that is installed somewhere prominently and updated on a daily basis. We will be making use of the <kbd>wordnik</kbd> API (sign up for an API key at <a href="https://www.wordnik.com/signup"><span class="URLPACKT">https://www.wordnik.com/signup</span></a>):</p>
<ol>
<li>The first step is to install the <kbd>wordnik</kbd> API client for <kbd>python3</kbd>:</li>
</ol>
<pre>
       <strong>git clone https://github.com/wordnik/wordnik-python3.git</strong><br/><strong>       cd wordnik-python3/</strong><br/><strong>       sudo python3 setup.py install</strong>
</pre>
<div class="packt_infobox">There are restrictions on the wordnik API usage. Refer to the API documentation for more details.</div>
<ol start="2">
<li>Let's review writing our first example using the <kbd>wordnik</kbd> Python client. In order to fetch the word of the day, we need to initialize the <kbd>WordsApi</kbd> class. According to the API documentation, this could be done as follows:</li>
</ol>
<pre>
       # sign up for an API key <br/>       API_KEY = 'API_KEY' <br/>       apiUrl = 'http://api.wordnik.com/v4' <br/>       client = swagger.ApiClient(API_KEY, apiUrl) <br/>       wordsApi = WordsApi.WordsApi(client)
</pre>
<ol start="3">
<li>Now that the <kbd>WordsApi</kbd> class is initialized, let's go ahead and fetch the word of the day:</li>
</ol>
<pre>
       example = wordsApi.getWordOfTheDay()
</pre>
<ol start="4">
<li>This returns a <kbd>WordOfTheDay</kbd> object. According to the <kbd>wordnik</kbd> Python client documentation, this object consists of different parameters including the word, its synonym, source, usage, and so on. The word of the day and its synonym could be printed as follows:</li>
</ol>
<pre>
       print("The word of the day is %s" % example.word) <br/>       print("The definition is %s" %example.definitions[0].text)
</pre>
<ol start="5">
<li>Putting it all together, we have this:</li>
</ol>
<pre>
       #!/usr/bin/python3 <br/><br/>       from wordnik import * <br/><br/>       # sign up for an API key <br/>       API_KEY = 'API_KEY' <br/>       apiUrl = 'http://api.wordnik.com/v4' <br/><br/>       if __name__ == "__main__": <br/>         client = swagger.ApiClient(API_KEY, apiUrl) <br/>         wordsApi = WordsApi.WordsApi(client) <br/>         example = wordsApi.getWordOfTheDay() <br/>         print("The word of the day is %s" % example.word) <br/>         print("The definition is %s" %example.definitions[0].text)
</pre>
<p>The preceding code snippet is available for download along with this chapter as <kbd>wordOfTheDay.py</kbd>. Sign up for an API key, and you should be able to retrieve the word of the day:</p>
<pre>
       <strong>The word of the day is transpare</strong><br/><strong>       The definition is To be, or cause to be, transparent; to appear,<br/>       or cause to appear, or be seen, through something.</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">A challenge to the reader</h1>
            </header>

            <article>
                
<p>How would you daemonize this application such that the word of the day is updated every day? (hint: cronjob or <kbd>datetime</kbd>).</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Project challenge</h1>
            </header>

            <article>
                
<p>It is possible to build a word game using the <kbd>wordnik</kbd> API. Think of a word game that is entertaining as well as helps improve your vocabulary. How would you go about building something that prompts questions to the player and accepting answer inputs?</p>
<p>Try displaying the word of the day on a display. How would you implement this?</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Logging</h1>
            </header>

            <article>
                
<p>This is a topic that is going to be useful for the next two chapters. Logging (<a href="https://docs.python.org/3/library/logging.html"><span class="URLPACKT">https://docs.python.org/3/library/logging.html</span></a>) helps with troubleshooting a problem. It helps with determining the root cause of a problem by tracing back through the sequence of events logged by the application. While we will be making extensive use of logging in the next two chapters, let's review logging using a simple application. In order to review logging, let's review it by making a <kbd>POST</kbd> request:</p>
<ol>
<li>The first step in logging is setting the log file location and the log level:</li>
</ol>
<pre>
       logging.basicConfig(format='%(asctime)s : %(levelname)s :<br/>       %(message)s', filename='log_file.log', level=logging.INFO)
</pre>
<p style="padding-left: 60px">While initializing the <kbd>logging</kbd> class, we need to specify the format for logging information, errors, and so on to the file. In this case, the format is as follows:</p>
<pre>
       format='%(asctime)s : %(levelname)s : %(message)s'
</pre>
<p style="padding-left: 60px">The log messages are in the following format:</p>
<pre>
       2016-10-25 20:28:07,940 : INFO : Starting new HTTPS<br/>       connection (1):<br/>       maker.ifttt.com
</pre>
<p style="padding-left: 60px">The log messages are saved to a file named <kbd>log_file.log</kbd>.</p>
<p style="padding-left: 60px">The logging level determines the level of logging needed for our application. The different log levels include <kbd>DEBUG</kbd>, <kbd>INFO</kbd>, <kbd>WARN</kbd>, and <kbd>ERROR</kbd>.</p>
<p style="padding-left: 60px">In this example, we have set the logging level to <kbd>INFO</kbd>. So, any log message belonging to <kbd>INFO</kbd>, <kbd>WARNING</kbd>, or <kbd>ERROR</kbd> levels are saved to the file.</p>
<p style="padding-left: 60px">If the logging level is set to <kbd>ERROR</kbd>, only those log messages are saved to the file.</p>
<ol start="2">
<li>Let's log a message based on the outcome of the <kbd>POST</kbd> request:</li>
</ol>
<pre>
       response = requests.post(IFTTT_URL, json=payload) <br/>       if response.status_code == 200: <br/>         logging.info("Notification successfully triggered") <br/>       else: <br/>         logging.error("POST request failed")
</pre>
<ol start="3">
<li>Putting it all together, we have this:</li>
</ol>
<pre>
       #!/usr/bin/python3 <br/><br/>       import requests <br/>       import logging <br/><br/>       # find your key from ifttt <br/>       IFTTT_URL = "https://maker.ifttt.com/trigger/rf_trigger/<br/>       with/key/$key" <br/><br/>       if __name__ == "__main__": <br/>         # fetch the bike share information <br/>         logging.basicConfig(format='%(asctime)s : %(levelname)s<br/>         : %(message)s', filename='log_file.log', level=logging.INFO) <br/>         payload = {"value1": "Sample_1", "value2": "Sample_2"} <br/>         response = requests.post(IFTTT_URL, json=payload) <br/>         if response.status_code == 200: <br/>           logging.info("Notification successfully triggered") <br/>         else: <br/>           logging.error("POST request failed")
</pre>
<p>The preceding code sample (<kbd>logging_example.py</kbd>) is available for download along with this chapter. This is a very soft introduction to the concept of logging in Python. We are going to make use of logging to troubleshoot any errors in our project.</p>
<p>In the final chapter, we will discuss best practices in logging.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Threading in Python</h1>
            </header>

            <article>
                
<p>In this section, we are going to discuss the concept of threading in Python. We will be making use of threading in the next chapter. Threads enable running multiple processes at the same time. For example, we can run motors while listening to incoming events from sensors. Let's demonstrate this with an example.</p>
<p>We are going to emulate a situation where we would like to process events from sensors of the same type. In this example, we are just going to print something to the screen. We need to define a function that listens to events from each sensor:</p>
<pre>
def sensor_processing(string): <br/>  for num in range(5): <br/>    time.sleep(5) <br/>    print("%s: Iteration: %d" %(string, num))
</pre>
<p>We can make use of the preceding function to listen for sensor events from three different sensors at the same time using the <kbd>threading</kbd> module in Python:</p>
<pre>
thread_1 = threading.Thread(target=sensor_processing, args=("Sensor 1",)) <br/>thread_1.start() <br/><br/>thread_2 = threading.Thread(target=sensor_processing, args=("Sensor 2",)) <br/>thread_2.start() <br/><br/>thread_3 = threading.Thread(target=sensor_processing, args=("Sensor 3",)) <br/>thread_3.start()
</pre>
<p>Putting it all together, we have this:</p>
<pre>
import threading <br/>import time <br/><br/>def sensor_processing(string): <br/>  for num in range(5): <br/>    time.sleep(5) <br/>    print("%s: Iteration: %d" %(string, num)) <br/><br/>if __name__ == '__main__': <br/>  thread_1 = threading.Thread(target=sensor_processing, args=("Sensor 1",)) <br/>  thread_1.start() <br/><br/>  thread_2 = threading.Thread(target=sensor_processing, args=("Sensor 2",)) <br/>  thread_2.start() <br/><br/>  thread_3 = threading.Thread(target=sensor_processing, args=("Sensor 3",)) <br/>  thread_3.start()
</pre>
<p>The preceding code sample (available for download as <kbd>threading_example.py</kbd>) starts three threads that listens to events from three sensors at the same time. The output looks something like this:</p>
<pre>
<strong>Thread 1: Iteration: 0 </strong><br/><strong>Thread 2: Iteration: 0 </strong><br/><strong>Thread 3: Iteration: 0 </strong><br/><strong>Thread 2: Iteration: 1 </strong><br/><strong>Thread 1: Iteration: 1 </strong><br/><strong>Thread 3: Iteration: 1 </strong><br/><strong>Thread 2: Iteration: 2 </strong><br/><strong>Thread 1: Iteration: 2 </strong><br/><strong>Thread 3: Iteration: 2 </strong><br/><strong>Thread 1: Iteration: 3 </strong><br/><strong>Thread 2: Iteration: 3 </strong><br/><strong>Thread 3: Iteration: 3 </strong><br/><strong>Thread 1: Iteration: 4 </strong><br/><strong>Thread 2: Iteration: 4 </strong><br/><strong>Thread 3: Iteration: 4</strong>
</pre>
<p>In the next chapter, we are going to make use of threading to control the motors of a robot-based on sensor inputs.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">PEP8 style guide for Python</h1>
            </header>

            <article>
                
<p><strong>PEP8</strong> is a style guide for Python that helps programmers write readable code. It is important to follow certain conventions to make our code readable. Some examples of coding conventions include the following:</p>
<ul>
<li>Inline comments should start with a <kbd># </kbd> and be followed by a single space.</li>
<li>Variables should have the following convention: <kbd>first_var</kbd>.</li>
<li>Avoiding trailing whitespaces on each line. For example, <kbd>if name == "test":</kbd> should not be followed by whitespaces.</li>
</ul>
<div class="packt_infobox">You can read the entire PEP8 standards at <a href="https://www.python.org/dev/peps/pep-0008/#block-comments"><span class="URLPACKT">https://www.python.org/dev/peps/pep-0008/#block-comments</span></a>.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Verifying PEP8 guidelines</h1>
            </header>

            <article>
                
<p>There are tools to verify PEP8 standards of your code. After writing a code sample, ensure that your code adheres to PEP8 standards. This can be done using the <kbd>pep8</kbd> package. It can be installed as follows:</p>
<pre>
    <strong>pip3 install pep8</strong>
</pre>
<p>Let's check whether one of our code samples has been written according to the PEP8 convention. This can be done as follows:</p>
<pre>
    <strong>pep8 opencv_test.py</strong>
</pre>
<p>The check indicated the following errors:</p>
<pre>
    <strong>opencv_test.py:5:50: E231 missing whitespace after ','</strong><br/><strong>    opencv_test.py:6:19: E231 missing whitespace after ','</strong>
</pre>
<p>As the output indicates, the following lines are missing a whitespace after a comma on lines <kbd>5</kbd> and <kbd>6</kbd>:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="38" src="assets/image_08_025.png" width="618"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Missing trailing whitespace after the comma</div>
<p>Let's fix the problem, and our code should adhere to PEP8 conventions. Recheck the file and the errors would have disappeared. In order to make your code readable, always run a PEP8 check before checking in your code to a public repository.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Summary</h1>
            </header>

            <article>
                
<p>In this chapter, we discussed advanced topics in Python. We discussed topics including speech recognition, building a commuter information tool, and a Python client to improve your vocabulary. There are advanced tools in Python that are widely used in the fields of data science, AI, and so on. We hope that the topics discussed in this chapter are the first step in learning such tools.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </body></html>