- en: Applying Machine Learning in Robotics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provides a hands-on introduction to **machine learning **(**ML**)
    in robotics. Although we assume that you have not yet worked in such a field,
    it will be helpful to have some background in statistics and data analytics. In
    any case, this chapter intends to be a gentle introduction to the topic, favoring
    intuition instead of complex mathematical formulations, and putting the focus
    on understanding the common concepts used in the field of ML.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, we will devote the discussion to such concepts by providing
    specific examples of robots. This is somewhat original because most references
    and books on ML give examples oriented to data science. Hence, as you become more
    familiar with robotics, it should be easier for you to understand the concepts
    this way.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: With the explanations about deep learning, you will understand how crucial this
    technique is for the robot to acquire knowledge of its surroundings through the
    processing of raw data coming from the robot's camera (2D and/or 3D) and specific
    distance sensors. With the specific example of object recognition explained in
    this chapter, you will learn how raw image data is processed in order to build
    robot's knowledge in the robot, making it capable to take smart actions.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the system for TensorFlow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How ML is being applied in Robotics
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ML pipeline
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A methodology to programmatically apply ML in robotics
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning applied to robotics— computer vision
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concrete application we will do for GoPiGo3 deals with computer vision,
    the most common perception task in robotics. Equipped with this capability, the
    robot should be aware of the objects around itself, making it capable to interact
    with them. As a result of this chapter, we expect you to develop the basic insight
    of when and how to apply deep learning in robotics.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the examples in this chapter, we will use **TensorFlow** ([https://www.tensorflow.org/](https://www.tensorflow.org/)),
    the ML framework open-sourced by Google in 2015, which has become the big brother
    in the data science community because of all of the people involved as active
    developers or end users.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: The main TensorFlow API is developed in Python and is the one we are going to
    use. To install it, we need to have the well-known `pip` Python package manager
    in our system. Even though it comes bundled with the Ubuntu OS, we provide the
    instructions for installing it. Later, we will cover the TensorFlow installation
    process.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Let's first provide the path for the code of this chapter, and then describe
    the step-by-step procedure to configure your laptop with TensorFlow.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will make use of the code located in the `Chapter10_Deep_Learning_` folder
    at [https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter10_Deep_Learning_](https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter10_Deep_Learning_).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用位于[https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter10_Deep_Learning_](https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter10_Deep_Learning_)的`Chapter10_Deep_Learning_`文件夹中的代码。
- en: 'Copy its files to the **ROS**(short for** Robot Operating System**) workspace
    to have them available and leave the rest outside the `src` folder:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 将其文件复制到**ROS**（即**机器人操作系统**）工作空间，以便它们可用，并将其余部分留在`src`文件夹之外：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This way, you will have a cleaner ROS environment. As usual, you need to rebuild
    the workspace on the laptop:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，你将拥有一个更干净的ROS环境。像往常一样，你需要在笔记本电脑上重新构建工作空间：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then, let's start with the setup for TensorFlow.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们开始设置TensorFlow。
- en: Setting up the system for TensorFlow
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置TensorFlow的系统环境
- en: First, we will set up `pip`, the Python package manager and afterward the framework
    for performing ML, that is, TensorFlow.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将设置`pip`，Python包管理器，然后是执行机器学习（ML）的框架，即TensorFlow。
- en: Installing pip
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装pip
- en: Ubuntu distributions typically ship with `pip` preinstalled. Unless a Python
    library requests you to upgrade, you can stay with the same version. In any case,
    we recommend working with the latest one, as explained in the following.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Ubuntu发行版通常预装了`pip`。除非Python库要求你升级，否则你可以保持相同的版本。在任何情况下，我们建议使用最新版本，如下所述。
- en: Installing the latest version
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装最新版本
- en: 'This section applies to the case in which you need to install `pip` or upgrade
    it:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分适用于你需要安装或升级`pip`的情况：
- en: 'First, remove the previous version if there is one:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，如果有旧版本，请先删除它：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We do this because the Ubuntu repository may not have the latest version of
    `pip`. In the next step, you will access the original source to get all of the
    updates.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这样做是因为Ubuntu仓库可能没有`pip`的最新版本。在下一步中，你将访问原始源以获取所有更新。
- en: 'Download the installation script and execute it:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载安装脚本并执行它：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Check which version is installed:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查已安装的版本：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If it was already present in your system, you can easily upgrade using `pip`
    itself:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它已经存在于你的系统中，你可以很容易地使用`pip`本身进行升级：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now, you are ready to proceed with the installation of the ML environment.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已准备好进行ML环境的安装。
- en: Installing TensorFlow and other dependencies
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装TensorFlow和其他依赖项
- en: 'OpenCV, the well-known and open source computer vision library ([https://opencv.org/](https://opencv.org/)),
    brings to ROS the capability of image processing. It is used by TensorFlow to
    deal with images that you will obtain from the robot camera. To install it in
    your system, you need the `pip` package manager that we explained earlier:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV，这个知名的开源计算机视觉库（[https://opencv.org/](https://opencv.org/)），为ROS带来了图像处理的能力。它被TensorFlow用来处理从机器人摄像头获取的图像。要在你的系统中安装它，你需要我们之前解释过的`pip`包管理器：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `--user` flag ensures that the package is installed locally to the user
    home folder at `~/.local/lib/python2.7/site-packages`. Otherwise, it should be
    installed system-wide at the `/usr/local/lib/python2.7/dist-packages` path, as
    is the case of `pip` (in such cases, you should perform the installation with `sudo`).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`--user`标志确保包被安装到用户主目录的`~/.local/lib/python2.7/site-packages`下。否则，它应该被安装到系统范围内的`/usr/local/lib/python2.7/dist-packages`路径，就像`pip`一样（在这种情况下，你应该使用`sudo`进行安装）。'
- en: 'The OpenCV ROS bridge ([http://wiki.ros.org/cv_bridge](http://wiki.ros.org/cv_bridge)) ships
    with the full-stack installation of ROS. If, for some reason, the package is missing
    in your environment, you can easily install it with this line:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV ROS桥（[http://wiki.ros.org/cv_bridge](http://wiki.ros.org/cv_bridge)）与ROS的全栈安装一起提供。如果由于某种原因，你的环境中缺少这个包，你可以很容易地使用以下命令安装它：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For the `<ROS_VERSION>` tag, use the `kinetic` value or `melodic` depending
    on the ROS distribution you have.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`<ROS_VERSION>`标签，使用`kinetic`值或`melodic`，具体取决于你拥有的ROS发行版。
- en: 'Finally, install TensorFlow as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，按照以下步骤安装TensorFlow：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `--upgrade` flag gives you the advantage to update the package if it is
    already installed. If you are working in Ubuntu 16.04, TensorFlow V2 will throw
    compatibility issues. In such a case, install TensorFlow V1 as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`--upgrade`标志，如果你已经安装了该包，你可以更新它。如果你在使用Ubuntu 16.04，TensorFlow V2将会抛出兼容性问题。在这种情况下，按照以下步骤安装TensorFlow
    V1：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In Ubuntu 18.04, you will be ready with the upgraded version of TensorFlow.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Ubuntu 18.04 中，你将准备好升级版的 TensorFlow。
- en: Achieving better performance using the GPU
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 GPU 实现更好的性能
- en: Alternatively, you could use the GPU version of TensorFlow to take advantage
    of this hardware on your laptop. The **GPU** (short for **Graphical Processing** **Unit**)
    card of your laptop is primarily used to power the display output on the screen.
    Therefore, it is very good at image processing.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你也可以使用 TensorFlow 的 GPU 版本来利用笔记本电脑上的这种硬件。**GPU**（即**图形处理单元**）卡主要用于为屏幕上的显示输出供电。因此，它在图像处理方面非常出色。
- en: As the kinds of calculations we need to do in ML are very similar (that is,
    floating-point, vector, and matrix operations), you can speed up the training
    and usage of your ML models by using the GPU for calculations instead of the CPU.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在机器学习中需要进行的计算类型非常相似（即，浮点、向量和矩阵运算），你可以通过使用 GPU 而不是 CPU 进行计算来加速你的机器学习模型的训练和使用。
- en: 'By using the GPU, you may achieve at least a factor of 10 in speed calculation
    for using the CPU, even in the case of the cheapest GPU cards. Hence, the choice
    of GPU is worth it. The command to install the corresponding TensorFlow library
    in Ubuntu 18.04 is pretty simple:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 GPU，你可能在速度计算上至少能比使用 CPU 快 10 倍，即使在最便宜的 GPU 卡上也是如此。因此，选择 GPU 是值得的。在 Ubuntu
    18.04 中安装相应 TensorFlow 库的命令相当简单：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As before, if you are working in Ubuntu 16.04, install TensorFlow V1 to avoid
    compatibility issues:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，如果你正在使用 Ubuntu 16.04，请安装 TensorFlow V1 以避免兼容性问题：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: With TensorFlow installed, being the normal version or the GPU-performant one,
    you are ready to use ML within ROS.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了 TensorFlow 后，无论是正常版本还是具有 GPU 性能的版本，你就可以在 ROS 中使用机器学习了。
- en: ML comes to robotics
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习进入机器人领域
- en: ML has its roots in statistical science. Remember when you have a cloud of points
    on an x-y frame and try to find the straight line that best fits all of them at
    the same time? This is what we call a linear regression and can be solved with
    a simple analytical formula. **Regression** is the first algorithm that you typically
    study when getting started with ML.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的根源在于统计学。记得当你有一个在 x-y 坐标系上的点云，并试图找到同时最适合所有这些点的直线吗？这就是我们所说的线性回归，可以用一个简单的解析公式来解决。**回归**
    是你开始学习机器学习时通常学习的第一个算法。
- en: To acquire perspective, be aware that, before 1980, artificial intelligence
    and ML were part of the same corpora of knowledge. Then, artificial intelligence
    researchers focused their efforts on using logical, knowledge-based approaches,
    and ML kept the algorithmic approach, *regression* being the most basic and having
    neural network-based algorithms as its main bundle. Hence, this fact favored that
    ML evolved as a separated discipline.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得视角，请注意，在 1980 年之前，人工智能和机器学习是同一知识体系的一部分。然后，人工智能研究人员将他们的努力集中在使用逻辑、基于知识的途径上，而机器学习保持算法途径，*回归*
    是最基本的方法，其主要的算法包是基于神经网络的。因此，这一事实有利于机器学习作为一个独立的学科发展。
- en: Following path of the traditional research in neural networks in the '60s and
    '70s, ML kept on developing in this field. Then, its first golden age came in
    the '90s.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 沿着 60 年代和 70 年代神经网络传统研究的路径，机器学习在这个领域持续发展。然后，它的第一个黄金时代出现在 90 年代。
- en: However, 25 years ago, the computer resources that a neural network required
    were not within the reach of normal PCs, since a huge amount of data needed to
    be processed to obtain accurate results. It was more than one decade later that
    computing capacity was available to everyone, and then problem-solving based on
    neural network algorithms finally became a commodity.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，25 年前，神经网络所需的计算机资源超出了普通个人电脑的范畴，因为需要处理大量数据才能获得准确的结果。直到十多年后，计算能力才对每个人开放，然后基于神经网络算法的问题解决最终成为了一种商品。
- en: This fact brings us to the present boom of ML, where functionalities such as
    content recommendation (shops, films, and music) and facial/ object recognition
    (camera-based apps) are used ubiquitously in most modern smartphones.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这个事实将我们带到了当前机器学习（ML）的繁荣时期，在这个时期，内容推荐（如商店、电影和音乐）以及面部/物体识别（基于摄像头的应用程序）等功能在大多数现代智能手机中被广泛使用。
- en: On the other side, robots started their path in the industry by 1950, being at
    the beginning just mechanical devices that performed repetitive motions. As artificial
    intelligence and its accompanying discipline, ML, developed in parallel, practical
    results in these fields could be transferred, since robots were also powered by
    similar CPUs to those with which ML problems were solved. Then, robots gradually
    acquired the capability to better accomplish actions by being aware of their effects
    in the environment. Data came from the robot's camera and sensors provides feedback
    to the *learning system* that allowed it to perform better every time. This learning
    system is just an ML pipeline.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，机器人从1950年开始在工业领域展开其道路，最初只是执行重复动作的机械装置。随着人工智能及其伴随的学科机器学习（ML）的并行发展，这些领域的实际成果可以转移，因为机器人也由与解决机器学习问题相似的CPU供电。然后，机器人逐渐获得了通过意识到它们在环境中的影响来更好地完成动作的能力。来自机器人的摄像头和传感器的数据为*学习系统*提供反馈，使得它每次都能表现得更好。这个学习系统实际上就是一个机器学习流程。
- en: And how different is robot learning from human learning? Well, our brain is
    far more efficient. To recognize for the first time whether an animal is a dog,
    a kid just needs four or five samples, while an ML algorithm needs hundreds to
    be accurate in its answers. This is the underlying reason why ML models used by
    robots need to be pretrained with lots of data so that the robot can respond—both
    **accurately** and in **real time**—with a smart action, that is, by picking an
    object from one location and moving it to another previously marked as the target
    (a typical problem in the logistics industry).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习与人类学习有何不同？嗯，我们的大脑要高效得多。要首次识别一个动物是狗还是孩子，一个小孩只需要四到五个样本，而一个机器学习算法需要数百个样本才能在答案上准确无误。这就是为什么机器人使用的机器学习模型需要用大量数据进行预训练的根本原因，这样机器人就可以通过智能动作——即从一个位置拿起一个物体并将其移动到另一个之前标记为目标的位置（这是物流行业的一个典型问题）——来**准确**和**实时**地做出反应。
- en: This task of identifying objects is what we will do in the practical example
    of this chapter. We will supply the robot with a trained model able to recognize
    different kinds of common objects (balls, mouses, keyboards, and so on) and will
    observe the response when putting it in front of several of these objects. Hence,
    let's keep on explaining the following concepts surrounding this practical example
    regarding the recognition of several kinds of objects.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个识别对象的任务就是我们将在本章的实际例子中要做的。我们将为机器人提供能够识别不同种类常见对象（如球、鼠标、键盘等）的训练模型，并将观察当将其置于这些对象之前时的反应。因此，让我们继续解释围绕这个实际例子中关于识别多种对象的相关概念。
- en: Core concepts in ML
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的核心概念
- en: 'Before going into the use case of object recognition in images, let''s take
    a much simpler example, the prediction of the price of a house as a function of
    several independent variables: area, number of rooms, distance to the center of
    the city, population density, and more.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入图像中对象识别的使用案例之前，让我们先来看一个更为简单的例子，即根据几个独立变量（如面积、房间数量、距离市中心距离、人口密度等）预测房价。
- en: 'First, to have a working ML algorithm, we need an underlying model that, when
    fed with input data, can produce a prediction. The data has to be supplied according
    to the features, that is, independent variables, that we have selected for our
    model. Then, establishing the correspondence with our simple example, we can explain
    the several concepts involved in an ML problem:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，为了有一个可以工作的机器学习算法，我们需要一个基础模型，当输入数据时，它可以产生预测结果。数据必须根据我们为模型选择的特征（即独立变量）提供。然后，通过与我们简单例子的对应，我们可以解释在机器学习问题中涉及的几个概念：
- en: The algorithm is the computation as a whole, specified as a sequence of instructions
    or steps that are to be followed to produce a result. All of the instructions
    have to be unambiguous and the actor that is running the algorithm does not have
    to make any additional decision; all of them are covered by the algorithm, which
    specifies what to do at a certain point if a condition needs to be evaluated.
    Then, you can easily infer that an algorithm is something that can be programmed
    in a computer, no matter which language is used. In the case of the example of
    the prediction of the price of a house, the algorithm consists of applying the
    sequence of instructions given sample data—that is, area, number of rooms, and
    so on—to obtain a prediction of its price.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法是整体计算，指定为一系列要遵循的指令或步骤，以产生一个结果。所有的指令都必须明确无误，执行算法的参与者不需要做出任何额外的决策；所有决策都包含在算法中，算法指定在需要评估条件时在某个特定点要做什么。然后，你可以轻松推断出算法是可以用计算机编程的，无论使用哪种语言。在预测房价的例子中，算法包括将给定的样本数据（即面积、房间数量等）的指令序列应用到数据上，以获得其价格预测。
- en: The model provides an assumption of the analytical function to apply to the
    input data to obtain a prediction. For example, we can say that the model for
    the price of the house is a linear function of the inputs, that is, given an increment
    in the percentage of the area of the house leads to the same percentual increment
    in its predicted price. For the rest of the independent variables, the same reasoning
    would apply because we have assumed a linear dependence. The model is applied
    in some steps of the algorithm.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型提供了一种分析函数的假设，该函数应用于输入数据以获得预测。例如，我们可以说房价模型是输入的线性函数，也就是说，给定房屋面积的百分比增加会导致其预测价格的百分比增加。对于其他独立变量，同样的推理也适用，因为我们假设了线性依赖。模型在算法的一些步骤中应用。
- en: The features are the independent variables of our model, that is to say, the
    available data that you have to predict the price of a house. In our example,
    these are area, number of rooms, distance to the center of the city, and population
    density.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征是我们模型的独立变量，也就是说，你必须用这些可用的数据来预测房价。在我们的例子中，这些是面积、房间数量、距离市中心和人口密度。
- en: The dataset is a structured data collection providing values for each of the
    selected features for a large number of items. In our example, the dataset should
    be a table in which each row contains the available data of a concrete house,
    and each column contains the values of each selected feature, that is, a surface
    column, number of rooms column, distance to the center of the city column, population
    density column, and so on.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集是一个结构化数据集合，为所选的每个特征提供大量物品的值。在我们的例子中，数据集应该是一个表格，其中每一行包含一个具体房屋的可供数据，每一列包含每个所选特征的值，即面积列、房间数量列、距离市中心列、人口密度列等。
- en: 'When facing a new problem, the data scientist has to decide for all of these
    three elements: the algorithm, the model, and the features. The last topic, feature
    selection, is where there''s the added value that a human provides to solving
    an ML problem; the rest of the tasks are automated and accomplished by a computer.
    The next subsection explains in detail what features are and emphasizes the importance
    of their selection to obtain accurate predictions.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 面对新的问题时，数据科学家必须决定这三个要素：算法、模型和特征。最后一个话题，特征选择，是人为解决机器学习问题提供额外价值的地方；其余任务都是自动化的，由计算机完成。下一个小节将详细解释特征是什么，并强调其选择对于获得准确预测的重要性。
- en: Selecting features in ML
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的特征选择
- en: Features in ML constitute a set of characteristics that have to be selected
    by the user, and it is this selection upon which the dataset is built. The expertise
    for making a good feature selection is more a question of experience and insight
    than a structured process. Hence, a good data scientist is one who understands
    the problem and can decompose it in its essential parts to find what the relevant
    features are. These act as the independent variables from which accurate predictions
    can be made.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的特征构成一组必须由用户选择的特性，并且数据集的构建是基于这个选择的。做出良好特征选择的专业知识更多的是一个问题，即经验和洞察力，而不是一个结构化的过程。因此，一个好的数据科学家是理解问题并能将其分解为其基本部分以找到相关特征的人。这些特征作为独立变量，可以从它们中做出准确的预测。
- en: 'To solve an ML problem, it is crucial to perform the right feature selection.
    If you do not detect the relevant features, no matter how much data you put in
    the solver, you will never get a good prediction. As shown in the following diagram,
    we will feed the ML algorithm with a data collection to obtain a result, that
    is, a prediction:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决一个机器学习问题，进行正确的特征选择是至关重要的。如果你没有检测到相关的特征，无论你向求解器投入多少数据，你都不会得到一个好的预测。如下所示，我们将数据集输入到机器学习算法中，以获得一个结果，即预测：
- en: '![](img/4835e387-64c0-47ef-b82e-3487f14183ae.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4835e387-64c0-47ef-b82e-3487f14183ae.png)'
- en: Data collection has been built according to the selected features. For example,
    if you decide to build the model for price prediction of the houses in a given
    city based on three features—area, number of rooms, and distance to the center
    of the city—for every new house you want to predict the price of, you will have
    to feed the algorithm with the specific values of such features, for example,
    85 square meters, 4 rooms, and 1.5 kilometers to the center of the city.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集是根据选定的特征构建的。例如，如果你决定基于三个特征——面积、房间数量和距离市中心——为给定城市的房屋建立价格预测模型，那么对于你想要预测价格的每一座新房屋，你必须向算法提供这些特征的特定值，例如，85平方米、4个房间和距离市中心1.5公里。
- en: Next, it is crucial to understand how the values of these features are combined
    to obtain the prediction.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，理解这些特征值是如何组合起来以获得预测的是至关重要的。
- en: The ML pipeline
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习流程
- en: 'Problem-solving is split into two parts. The first is training the model according
    to the pipeline shown in this diagram:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 问题解决分为两部分。第一部分是根据此图所示的流程训练模型：
- en: '![](img/0e8f3cab-07f2-491d-99e1-16ab3d6c723a.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0e8f3cab-07f2-491d-99e1-16ab3d6c723a.png)'
- en: 'Since we are assuming a simple model where the output depends linearly on the
    values of the features, the goal of training consists of determining the weights
    to be applied to each of them to obtain the prediction. Let''s explain it with
    this mathematical formulation:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们假设一个简单的模型，其中输出线性依赖于特征值，因此训练的目标是确定应用于每个特征的权重，以获得预测。让我们用这个数学公式来解释它：
- en: '*Price = W1 * area + W2 * nº rooms + W3 * distance*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*价格 = W1 * 面积 + W2 * 房间数 + W3 * 距离*'
- en: As you may infer, the weights, *W1*, *W2*, and *W3*, are the coefficients that
    multiply each feature. After making the sum of the three products, we obtain the
    predicted price. So, the training phase consists of finding the set of weights
    that best fit the dataset we have available. In the training set, the data contains
    both the features and the actual prices. Hence, by applying the algorithm of least
    square regression ([https://www.statisticshowto.datasciencecentral.com/least-squares-regression-line/](https://www.statisticshowto.datasciencecentral.com/least-squares-regression-line/)),
    we determine the set of values for *W1*, *W2*, and *W3* that best fit all of the
    actual prices supplied. This algorithm guarantees that the resulting equation
    is the one that provides the minimum global error for all of the items used for
    the training.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所推断，权重，*W1*、*W2*和*W3*，是乘以每个特征的系数。在将三个乘积相加后，我们得到预测价格。因此，训练阶段包括找到最适合我们现有数据集的权重集。在训练集中，数据包含特征和实际价格。因此，通过应用最小二乘回归算法（[https://www.statisticshowto.datasciencecentral.com/least-squares-regression-line/](https://www.statisticshowto.datasciencecentral.com/least-squares-regression-line/)），我们确定*W1*、*W2*和*W3*的最佳值，以最适合所有提供的实际价格。此算法保证所得方程是提供所有用于训练的项目最小全局误差的方程。
- en: 'But we do not want to best fit only the supplied data since we already know
    these prices. We wish that the resulting equation also be the best fit for any
    other house for which we do not know the price. So, the way to validate such an
    equation is by using a different dataset, called the test set, from the one we
    used for training. The programmatic way to do this is by splitting the available
    data before performing the training. The typical approach is to make two random
    sets: one containing 70%-90% of the data for training and another with the remaining
    30-10% to perform the validation. This way, the training set provides us with
    the provisional best-fit weights, *W1*, *W2*, and *W3*, and the validation set
    is used to estimate how well our ML model is operationally defined as the least
    square error.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们不想仅仅拟合提供的数据，因为我们已经知道这些价格。我们希望得到的方程也能是任何其他未知价格的房子的最佳拟合。因此，验证这种方程的方法是使用一个不同的数据集，称为测试集，而不是我们用于训练的数据集。在执行训练之前，程序化的方法是分割可用的数据。典型的方法是制作两个随机集：一个包含70%-90%的数据用于训练，另一个包含剩余的30%-10%用于验证。这样，训练集为我们提供了暂时的最佳拟合权重W1、W2和W3，而验证集用于估计我们的机器学习模型在操作上定义得有多好，即最小平方误差。
- en: 'The second part corresponds to the prediction itself, that is, when our ML
    algorithm is put in production in a real application. In the prediction (production)
    phase, we have the following:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分对应于预测本身，即当我们的机器学习算法在实际应用中投入生产时。在预测（生产）阶段，我们有以下内容：
- en: '![](img/57329b5c-ad0c-4a9a-9fb9-8bfdbef7228b.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/57329b5c-ad0c-4a9a-9fb9-8bfdbef7228b.png)'
- en: The process of ML, in reality, is more a circular one than a linear one because,
    as we get more data for training, we can improve the calculation of the weights,
    and then rewrite the equation with the new set of coefficients, *W1*, *W2*, and *W3*.
    This way, ML is an iterative process that can improve the accuracy of predictions
    as more data is available and the model is retrained again and again.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，机器学习的过程更像是循环的，而不是线性的，因为随着我们获得更多的训练数据，我们可以改进权重的计算，然后用新的系数集重新编写方程，即W1、W2和W3。这样，机器学习是一个迭代的过程，随着更多数据的可用性和模型的反复重新训练，可以提高预测的准确性。
- en: From ML to deep learning
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从机器学习到深度学习
- en: In this section, you will understand what deep learning is and how it relates
    to ML. And the most straightforward way to get this insight is by giving a quick
    overview of the most commonly used algorithms. Then, from that perspective, you
    could appreciate why deep learning is the most active area of research nowadays.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将了解深度学习是什么以及它与机器学习的关系。而获得这种洞察力的最直接方法就是简要概述最常用的算法。然后，从那个角度来看，你可以理解为什么深度学习现在是研究最活跃的领域。
- en: ML algorithms
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法
- en: As pointed out in the preceding diagram and explanations, the algorithm is the
    central part of ML problem-solving. A data scientist has also to select which
    one to apply depending on the kind of problem they are facing. So, let's have
    a quick overview of the most commonly used algorithms.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图和解释所指出的，算法是机器学习问题解决的中心部分。数据科学家还必须根据他们面临的问题类型选择应用哪种算法。所以，让我们快速概述一下最常用的算法。
- en: Regression
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归
- en: 'Regression tries to find the curve that best fits a cloud of points, and it
    has been described in detail with the case of the prediction of house prices.
    In such a case, we have been talking about a linear dependency, but the algorithm
    can be generalized to any kind of curve that can be represented as a sum of dot
    products between coefficients (weights) and independent variables (features),
    that is, a polynomial. A common case is that of a term that is the square of a
    feature. In this case, the curve is a parabola and, mathematically, can be expressed
    as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 回归试图找到最适合点云的曲线，并且已经在预测房价的案例中进行了详细描述。在这种情况下，我们一直在谈论线性依赖，但算法可以推广到任何可以用系数（权重）和自变量（特征）之间的点积之和表示的曲线，即多项式。一个常见的例子是特征的平方项。在这种情况下，曲线是抛物线，从数学上可以表示如下：
- en: '*y = W1 * x + W2 * x² + W3 * 1*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*y = W1 * x + W2 * x² + W3 * 1*'
- en: 'Let''s review this with a real-life example. Given an independent variable,
    the years of experience of a candidate, we wish to predict what their salary will
    be when applying for a job opportunity. You can easily understand that the dependence
    of the salary, at least during the first years of experience, does not follow
    a linear dependence, that is, a candidate with 2 years will not get twice the
    salary with respect to when he/she had one year of experience. Percentual increments
    in salary will be gradually higher as he/she accumulates more experience. This
    kind of relationship can be modeled as a parabola. Then, from the independent
    variable, *x*, and the salary, we define two features: *x* and *x²*.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个现实生活中的例子来回顾一下。给定一个独立变量，即候选人的工作经验年数，我们希望预测他们在申请工作机会时的薪资。您很容易理解，至少在工作经验的前几年，薪资的依赖性并不遵循线性依赖，也就是说，拥有2年工作经验的候选人不会比拥有1年工作经验时获得两倍的薪资。随着他们积累更多经验，薪资的百分比增长将逐渐更高。这种关系可以用抛物线来建模。然后，从独立变量*x*和薪资，我们定义两个特征：*x*和*x²*。
- en: Logistic regression
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Logistic regression is used in classification problems, a very common type in
    ML. In this case, we try to predict a binary classification such as pass/fail,
    win/lose, alive/dead, or healthy/sick. This algorithm can be understood as a special
    case of regression, where the predicted variable is categorical, that is, it can
    only take a finite set of values (two if it is a binary classification). The underlying
    model is a probability function and, given a value of the independent variable,
    if the resulting probability is greater than 50%, we predict pass, win, alive,
    or healthy, and if lower, the prediction is the other category, that is, fail,
    lose, dead, or sick.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归用于分类问题，这是机器学习中非常常见的一种类型。在这种情况下，我们试图预测一个二元分类，例如通过/失败、赢/输、生/死或健康/生病。这个算法可以理解为回归的特殊情况，其中预测变量是分类的，也就是说，它只能取有限集合的值（如果是二元分类，则为两个）。基础模型是一个概率函数，给定一个独立变量的值，如果得到的概率大于50%，我们预测通过、赢、生或健康，如果低于50%，预测就是另一个类别，即失败、输、死或生病。
- en: Product recommendation
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 产品推荐
- en: Product recommendation is the most used functionality in the consumer sector,
    for example, shopping, watching films, and readings books, taking as input user
    characteristics and well-rated items by other users with similar characteristics.
    There are several algorithms to implement this functionality such as collaborative
    filtering or featurized matrix factorization. If you are interested in this field,
    we provide good introduction references in the *Further reading* section at the
    end of this chapter.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 产品推荐是消费者领域最常用的功能，例如购物、看电影和阅读书籍，输入用户特征以及具有相似特征的其他用户的高评分项目。实现此功能有多种算法，如协同过滤或特征化矩阵分解。如果您对这个领域感兴趣，我们在本章末尾的*进一步阅读*部分提供了良好的介绍性参考文献。
- en: Clustering
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: 'Clusteringis a scenario where we have many items and we want to group them
    by similarity. In this case, items are unlabeled and we ask the algorithm to do
    two things:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是一种场景，其中我们有许多项目，我们希望根据相似性将它们分组。在这种情况下，项目是无标签的，我们要求算法做两件事：
- en: Make a group of similar items.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将相似的项目组成一组。
- en: Label these groups so that new items are both classified and labeled by the
    algorithm.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '标记这些组，以便新项目既被算法分类又被标记。 '
- en: 'As an example, think of a collection of texts about many topics and you wish
    the algorithm to group similar texts and identify the main topic of each group,
    that is, label them: history, science, literature, philosophy, and so on. One
    of the classical algorithms for this scenario is the nearest neighbor method,
    where you define a metric, calculate it for each pair of items, and group together
    those pairs that are close enough (based on the defined metric). It can be though
    as a distance-like function that is computed between each set of two points.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个关于许多主题的文本集合，您希望算法将相似文本分组并识别每个组的主要主题，即对它们进行标记：历史、科学、文学、哲学等。用于这种场景的经典算法之一是最近邻方法，其中您定义一个度量标准，为每一对项目计算它，并将足够接近的（基于定义的度量标准）对分组在一起。它可以被认为是一种计算在每一对两点之间的距离类似的函数。
- en: 'A **multiclassification scenario**, where there are more than two categories—let''s
    say n—is addressed by solving n logistic regressions where each one performs a
    binary classification for each of the possible categories. For example, if we
    want to detect the dominant color in an image (of four possible categories: red,
    green, blue, or yellow), we can build a classifier consisting of four logistic
    regressions, as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Red/NOT red
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Green/NOT green
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blue/NOT blue
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yellow/NOT yellow
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There could be a fifth category, which we can call *unknown*, for cases in which
    the image is not classified in any of the red, green, blue, or yellow colors.
    Finally, this type of multi-logistic regression applied to images is the entrance
    door to the last algorithm, deep learning, on which we will focus from now until
    the end of this chapter.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning is the most active research field in ML nowadays. The underlying
    model of this algorithm is a neural network whose way of working tries to mimic
    what the human brain does. Each neuron in the model performs a regression from
    its input with a special function, called **sigmoid**, that provides a sharp but
    continuous probability distribution of the output event. This function is the
    same as that of the probability function used in **logistic regression,** as described
    earlier. In this particular case of a neuron, if the resulting probability is
    greater than 50%, the neuron is activated and feeds another neuron or neurons
    downstream. If lower than 50%, the neuron is not active and hence it has negligible
    influence downstream.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are going to provide more details about how deep learning works so
    that when you perform the practical exercise with GoPiGo3, you know what it is
    going on under the hood in ROS.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning and neural networks
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From now on, we will base our explanations on the practical example of the recognition
    of objects in images, which, in the case of the robot, will be supplied by the
    Raspberry Pi camera. In the following diagram, you can see a representation of
    a neural network that differentiates the three kinds of layers that there can
    be:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: The input layer is where we feed the dataset. Remember that such data has to
    be structured according to the selected features, that is, one neuron per feature.
    We will later discuss this particular and very common case of image datasets.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The hidden layer(s)—one or more—are the intermediate steps in the deep learning
    pipeline that extract more features so that the algorithm is more capable of discriminating
    between objects. These hidden features are implicit, and the end user does not
    necessarily need to know about them because their extraction is intrinsic (automatic)
    to the network structure itself.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The output layer provides the prediction. Each neuron provides a logical 1
    if activated (a probability greater than 50%) or a 0 if not activated (lower than
    50%). So, the resulting probability in the output layer will be the answer with
    a certain probability:'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/251eae31-f607-45ba-a251-52ce7c9e502e.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: License CC-BY-SA-2.5 source: https://commons.wikimedia.org/wiki/File:Neural_Network.gif
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Following a sequential approach, let's explain how a neural network works by
    covering what each layer makes on the supplied input data.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The input layer
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is the first step of the deep learning pipeline, and the most common structure
    of this layer is to have as many input neurons (features) as three times the number
    of pixels the image has:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: For images of a size of 256 x 256 pixels, this means 65.536 pixels.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In general, we will deal with color images, so each pixel will have three channels:
    red, blue, and green; each value stands for the intensity ranging from 0 to 255
    for 8 bits of color depth.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, the number of features is *65.536 x 3 = 196.608* and the value of each
    feature will be a number between 0 and 255\. Each feature is represented with
    one neuron in the input layer.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Afterwards, the neural network is asked to answer this question: is there a
    cat in the picture? And the goal of the next layers is to extract the essential
    aspects of the image to answer that question.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: The hidden layer(s)
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For understanding how this layer works, let''s go back to the regression algorithm we
    explain earlier. There, we expressed the predicted variable as a linear combination
    of features—area, number of rooms, and distance to the center multiplied by weights,
    respectively, *W1*, *W2*, and *W3*. Establishing the analogy with our neural network,
    the features would apply to the neurons and the weights to the edges that connect
    each pair of neurons:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b9b28ae-5bc2-4294-90c5-a3a1156d488f.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: 'Source: https://commons.wikimedia.org/wiki/File:Artificial_neural_network_pso.png,
    Cyberbotics Ltd.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: CC BY-SA 3.0 https://creativecommons.org/licenses/by-sa/3.0
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: The value of each feature would be processed with the sigmoid function of its
    neuron (input layer; *j* neurons) to produce a probability value, *Sij*, which
    is then multiplied by the weight, *Wij*, of the edge that connects it to each
    neuron downstream (hidden layer ; *i* neurons). Hence, the feature input to this
    neuron, *i*, in the hidden layer is a sum of products, there being as many terms
    as neurons are connected to it upstream (input layer ; *j* neurons).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Such a result is the sum over *j* of all of the terms, *Sij*, with the index, *j*,
    which is an iterator that ranges over all of the neurons connected to *i* neurons
    in the input layer. The weights *Wij* of the edges connecting pairs of neurons
    are more properly called **hyperparameters**.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: The neural structure of the hidden layers provides what we call intrinsic features,
    which are inherent properties of the network and do not have to be selected by
    the user (they are established by the designer of the neural network). What the
    user has to do is to train the network to obtain the best set of weights, *Wij*,
    that makes the network to as predictive as possible with the available dataset.
    Here is where the magic of deep learning resides because a well-designed architecture
    of layers can provide a very accurate predictive model. The downside is that you
    need a lot of data to get a well-trained network.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Recapping from the beginning, given an input image, you can calculate the feature
    input to the neurons of each layer, *Fi*, based on the probabilities from the
    previous layer, *Sij*, and the weights, *Wij*, of the edges connecting to neuron
    *i*:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '*Fi = (sum over j) [Sij * Wij]*'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Proceeding downstream layer by layer, you can finally obtain the probabilities
    of the neurons of the output layer and, therefore, answer with the prediction
    of what the analyzed image contains.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: As was mentioned earlier, and given that complexity of the network structure,
    you may guess that, for training such a model, you would need much more data than
    for traditional ML algorithms such as regression. More specially, what you have
    to calculate are the values of how many hyperparameters as edges connecting pairs
    of neurons there are. Once you achieve this milestone, you get a trained network
    that can be applied to unlabeled images to predict its content.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: The output layer
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the question of our example, that is, there is a cat in the picture? yes
    if the image shows a cat, or not if it doesn''t. So we only need a neuron in the
    output layer, as shown in the diagram below. Then, if trained with many photos
    of cats, this network could classify an image to say whether it contains a cat
    (1) or not (0). An important point here is that the model should be able to identify the
    cat whatever position it occupies in the image, center, left, right, top, down,
    and so on:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/38dc3fe0-59c4-4718-9f10-86034d2c1d88.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
- en: Source: https://commons.wikimedia.org/wiki/File:NeuralNetwork.png
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: If we need to classify 10 kinds of objects (several types of pets, for example),
    we would need an output layer with 10 neurons. The result of the computation of
    the network would be a vector with 10 probabilities—each one linked to each neuron,
    and the one that provides the largest value (the closest to 100%) would tell us
    what kind of pet there is in the input image with more probability.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, you can make the network more complex and add more output neurons
    (and possibly more hidden layers) to obtain more details of the images. Consider
    the following:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Identify whether there is one cat or two or more.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Identify characteristics of the face, such as whether the eyes and/or mouth
    are open or closed:'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/58274728-a20d-4abb-bcfd-cb5a5a82d307.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
- en: 'Source: https://www.flickr.com/photos/55855622@N06/5173363938 by jeici1, License:
    CC BY 2.0'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: This is a quite complex topic and beyond of the scope of this introductory chapter,
    whose goal is just to provide a descriptive understanding of what deep learning
    is and how it works. Anyway, the reader is encouraged to delve deeper into the
    topic, and for that, two didactic references are included in the *Further reading*
    section at the end of this chapter: *Intuitive Deep Learning Parts 1 and 2*.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: From this point, we move to the practical part and start by stating a general
    methodology to tackle ML problems in robotics.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: A methodology to programmatically apply ML in robotics
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A specific aspect of ML is that robot responses have to happen in real time,
    without delays, so that the actions taken are effective. For example, if it finds
    an obstacle crossing the path it is following, we expect that it avoids it. To
    do so, obstacle identification has to occur as it appears in the robot's field
    of view. Hence, the subsequent action of avoiding the obstacle has to be taken
    immediately to avoid a crash.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: We will support our methodology description with an end-to-end example that
    covers all that GoPiGo3 can do up to this point. Then, with this example, we expect
    that GoPiGo3 can carry a load on top of its chassis from its current location
    to a target location (a common case in garbage collector robots).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: A general approach to application programming
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps involved in solving this challenge are as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Determine what high-level tasks are involved.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List the atomic tasks that, put together, are capable of accomplishing the high-level
    tasks. This is the level at which we create our program in ROS, writing node scripts
    and launch files.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Program the robot application by adapting the algorithms of the high-level tasks
    to the specific situation we are trying to solve.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we provide a breakdown of each of these steps so that we can implement
    the functionality in the real robot:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the high-level tasks to be carried out:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**SLAM**: This is **Simultaneous Localization and Mapping **(**SLAM**) to build
    a map of the actual environment.'
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Navigation**: Setting a target pose, GoPiGo3 can move autonomously until
    achieving it.'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visual recognition**: GoPiGo3 can identify where it has to be placed so that
    the garbage it carries can be collected.'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'List the atomic tasks that are involved in the example. Let''s say that, to
    be successful, GoPiGo3 has to be able to do the following:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load a map of the environment.
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate an optimum path to achieve the target location given the information
    from the map.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Start navigating toward the goal.
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Avoid obstacles found along the path.
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Stop if unexpected conditions are found in the environment that do not let it
    advance anymore. Then, ask for help.
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: After receiving help, resume the path to the target location.
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Recognize the garbage store entrance and stop at the exact position where a
    hoist will hook the loaded garbage.
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Program the robot application. Each of the preceding atomic tasks will correspond
    to a ROS node script, which can be expressed as a launch file with just one `<node>`
    tag. Then, you have to put these seven nodes on a ROS graph and draw the edges
    that should connect pairs using topics:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each published topic, you should determine which frequency the topic should
    be published with so that the robot can react quickly enough. For example, since
    the typical speed of GoPiGo3 is 1 m/s, we wish the scan distance to be updated
    10 times every 1 m traveled. This means that the robot will receive a perception
    update every 10 cm(=0.1 m) traveled and will be able to detect the presence of
    obstacles outside of a circumference of 0.1 m radius. The minimum publishing rate
    so that the robot can react to avoid the obstacle is calculated with this simple
    formula: *(1 m/s) /0.1 m = 10 Hz*.
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For each topic a node is subscribed to the code should trigger a robot action
    that allows it to successfully adapt to such conditions in the environment. For
    example, given the topic providing distances around GoPiGo3, when its value is
    below a threshold, 20 cm, for example (you will see now where this number comes
    from), GoPiGo3 recalculates the local path to avoid the obstacle. We should select
    this threshold according to the 10 Hz rate of publishing we decided previously;
    remember that this rate came from the fact that the robot will receive a perception
    update every 10 cm traveling. Taking a safety factor of 2, the threshold is simply
    *10 cm * 2 = 20 cm*, providing room and time so that it avoids the obstacle.
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: There's no need for ML currently now for atomic tasks 1 through 6\. But when
    it comes to aligning with the garbage stop entrance, GoPiGo3 needs to know not
    only its pose but also its relative position to the entrance, so that the hoist
    can successfully hook the loaded garbage.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Integrating an ML task
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This node of step 7 formulates its functionality as* recognize the garbage
    store entrance and stop at the exact position where a hoist will hook the loaded
    garbage*. Hence, the Pi camera comes to the rescue and image recognition capability
    has to be included in the logic programming of this node. This logic can be briefly
    expressed as publishing the `cmd_vel` messages to robot differential drives that
    allow GoPiGo3 to be put right in place. So, it is a feedback mechanism between
    visual perception, that is, entrance shape alignment in the image or not, and
    a motion command to correct and center:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: If the entrance is shifted to the left in the image, the robot should rotate
    left.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And if deviated to the right, it should rotate right an angle proportional to
    the distance from the entrance to the center of the image.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And your very first question should be: how can we integrate such an ML task
    with our robotic application? And the answer comes to enlighten how the ROS publish/subscribe
    mechanism is both powerful and simple at the same time. Its neutral nature allows
    us to integrate any kind of task that can be packaged into a black box by adhering
    to the following two rules:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Input is supplied via a subscribed topic.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output is delivered using a published topic.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the concrete case of ML applied to center the robot in the entrance door,
    we have the following:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Input to the ML node (subscribed topic) is the image feed from the Pi camera.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output from the ML node (published topic) is the horizontal distance from the
    shape of the door to the center of the image.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, the GoPiGo3 drive node takes that output topic as the data to determine
    which `cmd_vel` command should be sent to the motors. This establishes a feedback
    loop with the ML node that makes it possible that the robot position converges
    to get finally centered in the entrance door:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b1e991b3-3f41-4469-b7b5-6eb06bbf72e2.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
- en: The ML published topic, `object_position`, is an integer that provides the distance
    in pixels from the centroid of the object (entrance door) to the center of the
    image frame.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'Although it is out of the scope of this chapter, it is good to know at this
    point that ROS provides other interaction mechanisms between nodes, and the programmer''s
    choice about which one to use depends on the specific functionality to be implemented:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: A ROS service is the classical implementation of the server/client architecture.
    The client node (*drive node*) makes a request to the server node (*ML node*) and
    this performs the calculation (the distance in pixels from the entrance door to
    the center of the image frame). Then, the response is sent back to the client.
    The key difference with the publish/ subscribe mechanism is that this is not expecting
    to receive requests; it publishes messages at the rate set within the code of
    the node, independently, whether other nodes are listening or not.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A ROS action is similar to a ROS service, that is, it provides a response to
    a request from a node, with the difference that, in this case, the client node
    does not block the execution (until it receives the answer). That is to say, it
    keeps executing other code instructions and, when it receives the response, the
    client triggers the programmed action (rotates the robot for alignment). This
    behavior is called asynchronous, unlike a ROS service, which is synchronous in
    nature, that is, it blocks the node execution until the response is received.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, let's dive into how to make GoPiGo3 aware of the objects it has around,
    and we will do this in the final section of this chapter where we will build a
    general ML node that is able to detect a wide range of object types.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning applied to robotics – computer vision
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The practical part of this chapter consists of operationally implementing the
    ML node described earlier. What we represented there as a black box is developed
    now as a ROS package that you may integrate with the functionalities you discovered
    in previous chapters:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: The remote control in [Chapter 7](0653ab6b-8710-41e7-9c01-5024865e3e27.xhtml),
    *Robot Control and Simulation**,* for both the virtual robot in Gazebo and the
    physical GoPiGo3
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robot navigation for a virtual robot in [Chapter 8](25ac032c-5bfe-47ff-aa5a-f178dbff7c57.xhtml),
    *Virtual SLAM and Navigation Using Gazebo*, and the physical GoPiGo3 in [Chapter
    9](7b6ae4e6-2cd1-44e5-8f11-459b83987f42.xhtml), *SLAM for Robot Navigation*
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, we divide this section into two parts:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: The first section, *Object recognition in Gazebo*, provides you with the tools
    to integrate the ML node for image recognition in Gazebo so that, after finishing
    the practice, you may let your creativity fly to combine object recognition with
    any of the drive nodes from **remote control** or **robot navigation** and make
    the virtual robot smarter.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second section, *Object recognition in the real world*, provides the same
    integration with the physical GoPiGo3 and you will discover the ML node black
    box is the same no matter where the images come from, that is, objects in Gazebo
    or the real world. The choice is made by you when linking the ML node subscription
    to images of any of those scenarios.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This procedure also gives an operational way to test a new robot application.
    Start with the validation in Gazebo, where you will mainly check that the developed
    code has no significant bugs and the robot works as expected; then, proceed with
    it to the real world—understand how all of the external variables that are not
    present in Gazebo act on the robot, see how it responds, and then decide which
    code refinements you need to make to get it to work.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Object recognition in Gazebo
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get the code, follow the instructions we provided at the beginning of this
    chapter under the section, *Technical requirements*. The exercise in Gazebo is
    going to be pretty simple and very effective at the same time. You will check
    how the virtual GoPiGo3 can recognize a common *tennis ball* from the image feed
    coming from the robot''s camera:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by spawning a model of the ball in Gazebo:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, launch a `rqt_image_view` node to watch the subjective view as perceived
    from the robot''s camera:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Click on the top-left empty box, and select ;`/gopigo/camera1/image_raw` topic.
    Then, you will see the subjective view of the robot as acquired by its front camera.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, spawn a model of the ball in Gazebo:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Bear in mind that the `models_spawn_library` package requires you to execute
    the launch file as superuser. As soon as the ball is spawned in Gazebo, the process
    finishes and `T3` is released.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, launch the remote control node so that you can control GoPiGo with the
    keyboard as usual:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This package was installed in [Chapter 7](0653ab6b-8710-41e7-9c01-5024865e3e27.xhtml),
    *Robot Control and Simulation*. If you did not install it, do so now. The source
    of this ROS package is at [https://github.com/ros-teleop/teleop_tools](https://github.com/ros-teleop/teleop_tools).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, launch the image recognition node and watch the screen output. Use
    `T3` where you already have `sudo` enabled:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You can get a more condensed feed by subscribing to the `/result` topic, which
    provides just the name of the recognized objects:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'See the composition of the following screenshots showing how the tennis ball
    is recognized in the Terminal window (bottom-left side):'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4ac87985-ba8e-41f4-9353-8d06e7198b33.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
- en: Is it easy to replicate? We expect so. Now,let's proceed to repeat the process
    with the physical robot.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Object recognition in the real world
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, remember to point the ROS master URI to the robot as usual:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Apply this for every new Terminal in the laptop, or include the line in the
    `.bashrc` file. The physical robot configuration is as shown here, with GoPiGo3
    in front of a small yellow ball:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ce2fdd35-516e-4f94-ab6f-48371dbc66bd.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
- en: 'Run the following two commands in two independent Terminals in the Raspberry
    Pi:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The packages you are using in the preceding are the ones in [Chapter 6](0b20bdff-f1dc-42e8-ae83-fc290da31381.xhtml),
    *Programming in ROS- Commands and Tools*. So make sure you did not delete them,
    and if so, get them back. In the laptop is where you run the new packages to perform
    image recognition:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The `image_transport-` package (you can find its ROS wiki page at [http://wiki.ros.org/image_transport](http://wiki.ros.org/image_transport))
    is commonly used in ROS to provide transparent support for transmitting images
    in low-bandwidth compressed formats.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, `T1` makes `raspicam_node/image`—output from `r2`—available in raw format,
    that is, the `/raspicam_node/image_raw` topic, the output of `T1`. This facilitates
    the image feed, which can then be processed later by `start_image_recognition.launch`.
    At this point, it is very useful to look at the ROS graph:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3b6c683c-4a22-47ca-afb4-6c0501ae747f.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
- en: 'Remember that this visualization is launched with the `rqt_graph` command in
    another Terminal. Find that the transport operation is carried out by the `image_republisher_157...` node. Then,
    launch a `rqt_image_view` node to watch the subjective view as perceived through
    the Pi camera:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In the pop-up window, you have to select the `/raspicam_node/image_raw` topic to
    get the subjective view from the Pi camera.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, as we did in simulation, launch the image recognition node and subscribe
    to the `/result` topic:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The only difference for the Gazebo scenario is that you have to remap the topic
    supplied by the Pi camera with `raspicam_node`, to the topic named `rgb_image_topic`,
    which is the one accepted by the image recognition node.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'We have presented three different objects to the robot successively: the yellow
    ball, the mouse, and the monitor. Find out how the three of them are recognized
    by the robot in real time. Is it surprising?'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'The yellow ball can be seen here:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c83af262-0045-4c88-8622-397ac4e6c7d3.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
- en: 'Then, the mouse can be seen here:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e7577bb-ef5c-4d6a-81c9-297f98f9988e.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
- en: 'And, finally, the monitor can be seen here:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8e976bec-8aaf-4ae4-b05e-19596bdbc209.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
- en: If you have arrived at this point, you are in a good position to start creating
    advanced applications in ROS that integrate object recognition as an ability that
    uses GoPiGo3 to execute smart actions.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided a quick introduction to ML in robotics. We expect you
    to have acquired insight into what ML and deep learning are, qualitatively understood
    how a neural network processes images to recognize objects, and can operationally
    implement the algorithm in a simulated and/or physical robot.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: ML is a very wide field and you should not expect nor really need to get an
    expert in the field. What you need to assimilate is the knowledge to integrate
    deep learning capabilities in your robots.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: As you have seen in the practical case, we have used a pretrained model that
    covers common objects. Then, we have simply used this model and have not needed
    additional training. There are plenty of trained models on the web shared by data
    science companies and open source developers. You should spend time looking for
    these models, and only go to train your own models when the scenario that the
    robot is facing is so specific that general-purpose ML models do not cover it
    with decent accuracy.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: In the final two chapters, we will focus on reinforcement learning, a task that
    is complementary to the deep learning technique described in this chapter. With
    the latter, the robot gets the perception of the environment, and with the former,
    it chains several actions oriented to a goal.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the task for solving ML that requires more experience and insight from
    the data scientist?
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A) The algorithm selection
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: B) The feature selection
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: C) The model
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: What is the relationship between ML and deep learning?
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A) ML covers many algorithms and deep learning only algorithms to find deep
    features.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: B) Deep learning is a subset of ML.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: C) Deep learning deals with all of the ML algorithms except neural networks.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: How should you integrate an ML task with a ROS application?
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A) You should train the model outside and then provide ROS with a file of results.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: B) You have the choice of using publish/subscribe, a ROS service, or an action
    server.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: C) You have to use the specific communication protocol of the ML model.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: What is the main difference between the publish/subscribe mechanism and the
    ROS service mechanism?
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A) ROS service is synchronous while publish/subscribe is asynchronous.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: B) ROS service is asynchronous while publish/subscribe is synchronous.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: C) Publish/subscribe does not need to receive requests from other nodes in order
    to publish messages.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: If the practical example explained in the *Deep learning applied to robotics
    – computer vision* section was carried out with a red ball instead of a yellow
    one, will the prediction with the same model we are using?
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A) Yes, the color is not a feature for object shape recognition.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: B) Yes, and in addition to identifying a ball, it will also tell that it is
    red.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: C) It depends on whether the model was trained with balls of different colors.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To delve deeper into the concepts explained in this chapter, you can check
    out the following references:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '*A Brief History of ML:* [https://www.dataversity.net/a-brief-history-of-machine-learning](https://www.dataversity.net/a-brief-history-of-machine-learning)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*A Brief History of Robotics Since 1950:* [https://www.encyclopedia.com/science/encyclopedias-almanacs-transcripts-and-maps/brief-history-robotics-1950](https://www.encyclopedia.com/science/encyclopedias-almanacs-transcripts-and-maps/brief-history-robotics-1950)'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ML for Recommender systems -Part 1 (algorithms, evaluation and cold start):* [https://medium.com/recombee-blog/machine-learning-for-recommender-systems-part-1-algorithms-evaluation-and-cold-start-6f696683d0ed](https://medium.com/recombee-blog/machine-learning-for-recommender-systems-part-1-algorithms-evaluation-and-cold-start-6f696683d0ed)'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ML for Recommender systems - Part 2 (Deep Recommendation, Sequence Prediction,
    AutoML, and Reinforcement Learning in Recommendation):* [https://medium.com/recombee-blog/machine-learning-for-recommender-systems-part-2-deep-recommendation-sequence-prediction-automl-f134bc79d66b](https://medium.com/recombee-blog/machine-learning-for-recommender-systems-part-2-deep-recommendation-sequence-prediction-automl-f134bc79d66b)'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Intuitive Deep Learning Part 1a: Introduction to Neural Networks:* [https://medium.com/intuitive-deep-learning/intuitive-deep-learning-part-1a-introduction-to-neural-networks-d7b16ebf6b99](https://medium.com/intuitive-deep-learning/intuitive-deep-learning-part-1a-introduction-to-neural-networks-d7b16ebf6b99)'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Intuitive Deep Learning Part 2: CNNs for Computer Vision:* [https://medium.com/intuitive-deep-learning/intuitive-deep-learning-part-2-cnns-for-computer-vision-24992d050a27](https://medium.com/intuitive-deep-learning/intuitive-deep-learning-part-2-cnns-for-computer-vision-24992d050a27)'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Build your first Convolutional Neural Network to recognize images:* [https://medium.com/intuitive-deep-learning/build-your-first-convolutional-neural-network-to-recognize-images-84b9c78fe0ce](https://medium.com/intuitive-deep-learning/build-your-first-convolutional-neural-network-to-recognize-images-84b9c78fe0ce)'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
