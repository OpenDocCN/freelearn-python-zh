<html><head></head><body>
<div><div><div><h1 id="_idParaDest-75"><em class="italic"><a id="_idTextAnchor068"/>Chapter 4</em>: C Performance with Cython</h1>
			<p>Cython is a language that extends Python by supporting the declaration of types for functions, variables, and classes. These typed declarations enable Cython to compile Python scripts to efficient C code. Cython can also act as a bridge between Python and C as it provides easy-to-use constructs to write interfaces to external C and C++ routines.</p>
			<p>In this chapter, we will learn about the following topics:</p>
			<ul>
				<li>Compiling Cython extensions</li>
				<li>Adding static types</li>
				<li>Sharing declarations</li>
				<li>Working with arrays</li>
				<li>Using a particle simulator in Cython</li>
				<li>Profiling Cython</li>
				<li>Using Cython with Jupyter</li>
			</ul>
			<p>Through this chapter, we will learn how to leverage Cython to improve the efficiency of our programs. While a minimum knowledge of C is helpful, this chapter focuses only on Cython in the context of Python optimization. Therefore, it doesn't require any C background.</p>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor069"/>Technical requirements</h1>
			<p>You can access the code used in this chapter on GitHub at <a href="https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter04">https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter04</a>.</p>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor070"/>Compiling Cython extensions</h1>
			<p>The Cython syntax is, by design, a superset of Python. Cython can compile, with a few exceptions, most Python <a id="_idIndexMarker259"/>modules without requiring any change. Cython source files have the <code>.pyx</code> extension and can be compiled to produce a C file using the <code>cython</code> command.</p>
			<p>All that is required to convert Python code to Cython is some syntactic modifications that we will see throughout this chapter (such as when declaring variables and functions) as well as compilation. While this procedure may seem intimidating at first, Cython will more than make up for itself via the computational benefits that it offers.</p>
			<p>First off, to install Cython, we can simply run the <code>pip</code> command, like this:</p>
			<pre>$pip install cython</pre>
			<p>Refer to the documentation at <a href="https://pypi.org/project/Cython/">https://pypi.org/project/Cython/</a> for more details. Our first Cython script will <a id="_idIndexMarker260"/>contain a simple function that prints <code>Hello, World!</code> as the output. Follow these next steps:</p>
			<ol>
				<li>Create a new <code>hello.pyx</code> file containing the following code:<pre>    def hello(): 
      print('Hello, World!') </pre></li>
				<li>The <code>cython</code> command will read <code>hello.pyx</code> and generate a <code>hello.c</code> file, as follows:<pre>$ cython hello.pyx</pre></li>
				<li>To compile <code>hello.c</code> to a <a id="_idIndexMarker261"/>Python extension module, we will use the <code>/usr/include/python3.5/</code>:<pre>$ gcc -shared -pthread -fPIC -fwrapv -O2 -Wall -fno-
strict-aliasing -lm -I/usr/include/python3.5/ -o 
hello.so hello.c</pre><p class="callout-heading">Note</p><p class="callout">To find your Python <code>include</code> directory, you can use the <code>distutils</code> utility and run <code>sysconfig.get_python_inc</code>. To execute it, you can simply issue the following command: <code>python -c "from distutils import sysconfig;</code> <code>print(sysconfig.get_python_inc())"</code>.</p></li>
				<li>This will produce a file called <code>hello.so</code>, a C extension module that is directly importable into a Python session. The code is illustrated in the following snippet:<pre>    &gt;&gt;&gt; import hello 
    &gt;&gt;&gt; hello.hello() 
    Hello, World!</pre></li>
				<li>Cython accepts both Python 2 and Python 3 as <code>hello.pyx</code> file using the <code>-3</code> option, as illustrated in the following code snippet:<pre>$ cython -3 hello.pyx</pre></li>
				<li>The generated <code>hello.c</code> file can be compiled without any changes to Python 2 and Python 3 by including the corresponding headers with the <code>-I</code> option, as follows:<pre>$ gcc -I/usr/include/python3.5 # ... other options
$ gcc -I/usr/include/python2.7 # ... other options</pre></li>
				<li>A Cython program can be compiled in a more straightforward way using <code>distutils</code>, the standard Python packaging tool. By writing a <code>setup.py</code> script, we can compile the <code>.pyx</code> file directly to an extension module. To compile our <code>hello.pyx</code> example, we can write a minimal <code>setup.py</code> script containing the following code:<pre>    from distutils.core import setup 
    from Cython.Build import cythonize 
    setup( 
      name='Hello',
      ext_modules = cythonize('hello.pyx')
    ) </pre></li>
			</ol>
			<p>In the first two lines of the preceding code snippet, we import the <code>setup</code> function and the <code>cythonize</code> helper. The <code>setup</code> function contains a few key-value pairs that specify the name of the application and the extensions that need to be built.</p>
			<ol>
				<li value="8">The <code>cythonize</code> helper takes either a string or a list of strings containing the Cython modules <a id="_idIndexMarker264"/>we want to compile. You can also use glob patterns by running the following code:<pre>    cythonize(['hello.pyx', 'world.pyx', '*.pyx']) </pre></li>
				<li>To compile our extension module using <code>distutils</code>, you can execute the <code>setup.py</code> script using the following code:<pre>$ python setup.py build_ext --inplace</pre></li>
			</ol>
			<p>The <code>build_ext</code> option tells the script to build the extension modules indicated in <code>ext_modules</code>, while the <code>--inplace</code> option tells the script to place the <code>hello.so</code> output file in the same location as the source file (instead of a build directory).</p>
			<ol>
				<li value="10">Cython modules can also be automatically compiled using <code>pyximport</code>. All that's needed is a call to <code>pyximport.install()</code> at the beginning of your script (or you need to issue the command in your interpreter), as illustrated in the following code snippet. After doing that, you can import <code>.pyx</code> files directly and <code>pyximport</code> will transparently compile the corresponding Cython modules:<pre>    &gt;&gt;&gt; import pyximport 
    &gt;&gt;&gt; pyximport.install() 
    &gt;&gt;&gt; import hello # This will compile hello.pyx </pre></li>
			</ol>
			<p>Unfortunately, <code>pyximport</code> will not work for all kinds of configurations (for example, when they involve a combination of C and Cython files), but it comes in handy for testing simple scripts.</p>
			<ol>
				<li value="11">Since version 0.13, IPython includes the <code>cythonmagic</code> extension to interactively write and test a series of Cython statements. You can load the extensions in an IPython shell using <code>load_ext</code>, as follows:<pre>    %load_ext Cython</pre></li>
			</ol>
			<p>Once the extension is loaded, you can use the <code>%%cython</code> <em class="italic">cell magic</em> to write a multiline Cython snippet. In <a id="_idIndexMarker265"/>the following example, we define a <code>hello_snippet</code> function that will be compiled and added to the IPython session namespace:</p>
			<pre>    %%cython 
    def hello_snippet(): 
        print("Hello, Cython!") 
    hello_snippet()
    Hello,  Cython! </pre>
			<p>It is that simple to work with Cython source code. In the next section, we will see how we can add static types to our program, getting it closer to C code.</p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor071"/>Adding static types</h1>
			<p>In Python, a variable can be associated with objects of different types during the execution of the <a id="_idIndexMarker266"/>program. While this feature is desirable as it makes the language flexible and dynamic, it also adds significant overhead to the interpreter as it needs to look up the type and methods of the variables at runtime, making it difficult to perform various optimizations. Cython extends the Python language with explicit type declarations so that it can generate efficient C extensions through compilation.</p>
			<p>The main way to declare data types in Cython is through <code>cdef</code> statements. The <code>cdef</code> keyword can be used in multiple contexts, such as variables, functions, and extension types (statically typed classes). We will see how to do this in the following subsections.</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor072"/>Declaring variables</h2>
			<p>In Cython, you can declare the type <a id="_idIndexMarker267"/>of a variable by prepending the<a id="_idIndexMarker268"/> variable with <code>cdef</code> and its respective type. For example, we can declare the <code>i</code> variable as a 16-bit integer in the following way:</p>
			<pre>    cdef int i </pre>
			<p>The <code>cdef</code> statement supports multiple variable names on the same line along with optional initialization, as seen in the following line of code:</p>
			<pre>    cdef double a, b = 2.0, c = 3.0 </pre>
			<p>Typed variables are treated differently from regular variables. In Python, variables are often described as <em class="italic">labels</em> that refer to objects in memory. For example, we could assign the value <code>'hello'</code> to the <code>a</code> variable at any point in the program without restriction, as illustrated here:</p>
			<pre>    a = 'hello' </pre>
			<p>The <code>a</code> variable holds a reference to the <code>'hello'</code> string. We can also freely assign another value (for example, the integer <code>1</code>) to the same variable later in the code, as follows:</p>
			<pre>    a = 1 </pre>
			<p>Python will assign the integer <code>1</code> to the <code>a</code> variable without any problem.</p>
			<p>Typed variables behave quite differently and are usually described as <em class="italic">data containers</em>: we can only store<a id="_idIndexMarker269"/> values that fit into the container that is determined by its data type. For example, if we declare the <code>a</code> variable as <code>int</code>, and then we try to assign it to a <code>double</code> data type, Cython will trigger an error, as shown in the following code snippet:</p>
			<pre>    %%cython 
    cdef int i 
    i = 3.0 
    # Output has been cut 
    ...cf4b.pyx:2:4 Cannot assign type 'double' to 'int' </pre>
			<p>Static typing makes it easy for the compiler to perform useful optimizations. For example, if we declare a loop index as <code>int</code>, Cython will rewrite the loop in pure C without needing <a id="_idIndexMarker270"/>to step into the Python interpreter. The typing declaration guarantees<a id="_idIndexMarker271"/> that the type of the index will always be <code>int</code> and cannot be overwritten at runtime so that the compiler is free to perform optimizations without compromising the program's correctness.</p>
			<p>We can assess the speed gain in this case with a small test case. In the following example, we implement a simple loop that increments a variable <code>100</code> times. With Cython, the <code>example</code> function can be coded as follows:</p>
			<pre>    %%cython 
    def example(): 
       cdef int i, j=0 
       for i in range(100):
           j += 1 
       return j 
    example() 
    # Result:
    # 100 </pre>
			<p>We can compare the speed of an analogous, untyped, pure Python loop, as follows:</p>
			<pre>    def example_python(): 
        j=0 
        for i in range(100):
            j += 1 
        return j 
    %timeit example() 
    10000000 loops, best of 3: 25 ns per loop 
    %timeit example_python() 
    100000 loops, best of 3: 2.74 us per loop </pre>
			<p>The speedup obtained by implementing this simple type declaration is a whopping 100 times! This <a id="_idIndexMarker272"/>works because the Cython loop has first been converted to pure C and<a id="_idIndexMarker273"/> then to efficient machine code, while the Python loop still relies on the slow interpreter.</p>
			<p>In Cython, it is possible to declare a variable to be of any standard C type, and it is also possible to define custom types using classic C constructs, such as <code>struct</code>, <code>enum</code>, and <code>typedef</code>.</p>
			<p>An interesting example is that if we declare a variable to be of the <code>object</code> type, the variable will accept any kind of Python object, as illustrated in the following code snippet:</p>
			<pre>    cdef object a_py 
    # both 'hello' and 1 are Python objects 
    a_py = 'hello' 
    a_py = 1 </pre>
			<p>Note that declaring a variable as <code>object</code> has no performance benefits, as accessing and operating on the object will still require the interpreter to look up the underlying type of the variable and its attributes and methods.</p>
			<p>Sometimes, certain data types (such as <code>float</code> and <code>int</code> numbers) are compatible in the sense that they <a id="_idIndexMarker274"/>can be converted into each other. In Cython, it is possible to convert (<em class="italic">cast</em>) between<a id="_idIndexMarker275"/> types by surrounding the destination type with pointy brackets, as shown in the following code snippet:</p>
			<pre>    cdef int a = 0 
    cdef double b 
    b = &lt;double&gt; a </pre>
			<p>Together with static types for variables, we can provide information about functions, which we will learn how to do next.</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor073"/>Declaring functions</h2>
			<p>You can add type information to the arguments of a Python function by specifying the type in front of each <a id="_idIndexMarker276"/>of the argument names. Functions specified in this way will work<a id="_idIndexMarker277"/> and perform like regular Python functions, but their arguments will be type-checked. We can write a <code>max_python</code> function that returns the greater value between two integers, as follows:</p>
			<pre>    def max_python(int a, int b):
        return a if a &gt; b else b </pre>
			<p>A function specified in this way will perform type checking and treat the arguments as typed variables, just as in <code>cdef</code> definitions. However, the function will still be a Python function, and calling it multiple times will still need to switch back to the interpreter. To allow Cython for function call optimizations, we should declare the type of the return type using a <code>cdef</code> statement, as follows:</p>
			<pre>    cdef int max_cython(int a, int b): 
        return a if a &gt; b else b </pre>
			<p>Functions declared in this way are translated to native C functions and have much less overhead compared to Python functions. A substantial drawback is that they can't be used from Python but only from Cython, and their scope is restricted to the same Cython file unless they're exposed in a definition file (refer to the <em class="italic">Sharing declarations</em> section).</p>
			<p>Fortunately, Cython allows you to define functions that are both callable from Python and translatable to performant C functions. If you declare a function with a <code>cpdef</code> statement, Cython will generate two versions of the function: a Python version available to the interpreter, and a fast C function usable from Cython. The <code>cpdef</code> syntax is equivalent to <code>cdef</code>, shown as follows:</p>
			<pre>    cpdef int max_hybrid(int a, int b): 
        return a if a &gt; b else b </pre>
			<p>Sometimes, the call overhead can be a performance issue even with C functions, especially when <a id="_idIndexMarker278"/>the same function is called many times in a critical loop. When the function<a id="_idIndexMarker279"/> body is small, it is convenient to add the <code>inline</code> keyword in front of the function definition; the function call will be replaced by the function body itself. Our <code>max</code> function is a good candidate for <em class="italic">inlining</em>, as illustrated in the following code snippet:</p>
			<pre>    cdef inline int max_inline(int a, int b): 
        return a if a &gt; b else b </pre>
			<p>Finally, we will see how to work with class types next.</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor074"/>Declaring classes</h2>
			<p>We can define an extension type using the <code>cdef class</code> statement and declare its attributes in <a id="_idIndexMarker280"/>the class body. For example, we can create a <code>Point</code> extension type, as shown<a id="_idIndexMarker281"/> in the following code snippet, which stores two coordinates (<code>x</code>, <code>y</code>) of the <code>double</code> type:</p>
			<pre>    cdef class Point:
        cdef double x 
        cdef double y
        def __init__(self, double x, double y): 
            self.x = x 
            self.y = y </pre>
			<p>Accessing the declared attributes in the class methods allows Cython to bypass expensive Python attribute lookups by direct access to the given fields in the underlying C struct. For this reason, attribute access in typed classes is an extremely fast operation.</p>
			<p>To use the <code>cdef class</code> statement in your code, you need to explicitly declare the type of the variables you intend to use at compile time. You can use the extension type name (such as <code>Point</code>) in any context where you will use a standard type (such as <code>double</code>, <code>float</code>, and <code>int</code>). For example, if we want a Cython function that calculates the distance from the origin (in the example, the function is called <code>norm</code>) of a <code>Point</code>, we have to declare the input variable as <code>Point</code>, as shown in the following code snippet:</p>
			<pre>    cdef double norm(Point p): 
        return (p.x**2 + p.y**2)**0.5 </pre>
			<p>Just as with typed functions, typed classes have some limitations. If you try to access an extension type attribute from Python, you will get an <code>AttributeError</code> warning, as follows:</p>
			<pre>    &gt;&gt;&gt; a = Point(0.0, 0.0) 
    &gt;&gt;&gt; a.x 
    AttributeError: 'Point' object has no attribute 'x' </pre>
			<p>In order to access attributes from Python code, you have to use the <code>public</code> (for read/write access) or <code>readonly</code> specifiers in the attribute declaration, as shown in the following code snippet:</p>
			<pre>    cdef class Point: 
        cdef public double x </pre>
			<p>Additionally, methods <a id="_idIndexMarker282"/>can be declared with the <code>cpdef</code> statement, just as with regular<a id="_idIndexMarker283"/> functions.</p>
			<p>Extension types do not support the addition of extra attributes at runtime. To do that, a solution is defining a Python class that is a subclass of the typed class and extends its attributes and methods in pure Python.</p>
			<p>And with that, we have seen how to add static types to various objects in Cython. In the next section, we will begin our discussion regarding declarations.</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor075"/>Sharing declarations</h1>
			<p>When writing your Cython modules, you may want to reorganize your most-used functions and classes declaration in <a id="_idIndexMarker284"/>a separate file so that they can be reused in different modules. Cython allows you to put these components in a <em class="italic">definition file</em> and access them with <code>cimport</code> statements.</p>
			<p>Let's say that we have a module with the <code>max</code> and <code>min</code> functions, and we want to reuse those functions in multiple Cython programs. If we simply write a bunch of functions in a <code>.pyx</code> file, the declarations will be confined to the same file.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Definition files are also used to interface Cython with external C code. The idea is to copy (or, more accurately, translate) the types and function prototypes in the definition file and leave <a id="_idIndexMarker285"/>the implementation in the external C code that will be compiled and linked in a separate step.</p>
			<p>To share the <code>max</code> and <code>min</code> functions, we need to write a definition file with a <code>.pxd</code> extension. Such a file only contains the types and function prototypes that we want to share with other modules—a <em class="italic">public</em> interface. We can declare the prototypes of our <code>max</code> and <code>min</code> functions in a file named <code>mathlib.pxd</code>, as follows:</p>
			<pre>    cdef int max(int a, int b) 
    cdef int min(int a, int b) </pre>
			<p>As you can see, we only write the function name and arguments without implementing the function body.</p>
			<p>The function implementation goes into the implementation file with the same base name but the <code>.pyx</code> extension <code>mathlib.pyx</code>, as follows:</p>
			<pre>    cdef int max(int a, int b): 
      return a if a &gt; b else b 
    cdef int min(int a, int b): 
      return a if a &lt; b else b </pre>
			<p>The <code>mathlib</code> module is now importable from another Cython module.</p>
			<p>To test our new Cython module, we will create a file named <code>distance.pyx</code> containing a function named <code>chebyshev</code>. The function will calculate the Chebyshev distance between two points, as shown in the following code snippet. The Chebyshev distance between two coordinates—<code>(x1,</code> <code>y1)</code> and <code>(x2, y2</code>—is defined as the maximum value of the difference between each coordinate:</p>
			<pre>    max(abs(x1 - x2), abs(y1 - y2)) </pre>
			<p>To implement the <code>chebyshev</code> function, we will use the <code>max</code> function declared in <code>mathlib.pxd</code> by importing it with the <code>cimport</code> statement, as shown in the following code snippet:</p>
			<pre>    from mathlib cimport max 
    def chebyshev(int x1, int y1, int x2, int y2): 
        return max(abs(x1 - x2), abs(y1 - y2)) </pre>
			<p>The <code>cimport</code> statement will read <code>mathlib.pxd</code> and the <code>max</code> definition will be used to generate a <code>distance.c</code> file.</p>
			<p>Along with static types and declarations, one factor that allows C to be generally faster than Python<a id="_idIndexMarker286"/> is its highly optimized array operations, which we will examine in the next section.</p>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor076"/>Working with arrays</h1>
			<p>Numerical and high-performance calculations often make use of arrays. Cython provides an easy way to interact with <a id="_idIndexMarker287"/>different types of arrays, using directly low-level C arrays, or the more general <em class="italic">typed memoryviews</em>. We will see how to do this in the following subsections.</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor077"/>C arrays and pointers</h2>
			<p>C arrays are a collection <a id="_idIndexMarker288"/>of items of the same type, stored contiguously in memory. Before <a id="_idIndexMarker289"/>digging into<a id="_idIndexMarker290"/> the details, it is helpful<a id="_idIndexMarker291"/> to understand (or review) how memory is managed in C.</p>
			<p>Variables in C are like containers. When creating a variable, a space in memory is reserved to store its value. For example, if we create a variable containing a 64-bit floating-point number (<code>double</code>), the program will allocate 64 bits (16 bytes) of memory. This portion of memory can be accessed through an address to that memory location.</p>
			<p>To obtain the <a id="_idIndexMarker292"/>address of a variable, we can use the <em class="italic">address operator</em> denoted by the <code>&amp;</code> symbol. We can also use <a id="_idIndexMarker293"/>the <code>printf</code> function, as follows, available<a id="_idIndexMarker294"/> in the <code>libc.stdio</code> Cython module<a id="_idIndexMarker295"/> to print the address of this variable:</p>
			<pre>    %%cython 
    cdef double a 
    from libc.stdio cimport printf 
    printf("%p", &amp;a)
    # Output:
    # 0x7fc8bb611210 </pre>
			<p class="callout-heading">Note </p>
			<p class="callout">The output will only be generated when the code is run from a standard Python terminal. This <a id="_idIndexMarker296"/>limitation of IPython is detailed at <a href="https://github.com/ipython/ipython/issues/1230">https://github.com/ipython/ipython/issues/1230</a>.</p>
			<p>Memory addresses can be stored in special variables, <em class="italic">pointers</em>, that can be declared by putting a <code>*</code> prefix in front of the variable name, as follows:</p>
			<pre>    from libc.stdio cimport printf 
    cdef double a 
    cdef double *a_pointer 
    a_pointer = &amp;a # a_pointer and &amp;a are of the same type </pre>
			<p>If we have a pointer and we want to grab the value contained in the address it's pointing at, we can use the zero-index notation shown here:</p>
			<pre>    cdef double a 
    cdef double *a_pointer 
    a_pointer = &amp;a 
    a = 3.0 
    print(a_pointer[0]) # prints 3.0 </pre>
			<p>When declaring <a id="_idIndexMarker297"/>a C array, the program allocates enough space to accommodate all the <a id="_idIndexMarker298"/>elements requested. For instance, to create<a id="_idIndexMarker299"/> an array that has 10 <code>double</code> values (16 bytes each), the program<a id="_idIndexMarker300"/> will reserve <em class="italic">16 </em> * <em class="italic">10 </em> = <em class="italic">160</em> bytes of contiguous space in memory. In Cython, we can declare such arrays using the following syntax:</p>
			<pre>    cdef double arr[10]</pre>
			<p>We can also declare a multidimensional array, such as an array with <code>5</code> rows and <code>2</code> columns, using the following syntax:</p>
			<pre>    cdef double arr[5][2] </pre>
			<p>The memory will be allocated in a single block of memory, row after row. This order is commonly referred to as <em class="italic">row-major</em> and is depicted <a id="_idIndexMarker301"/>in the following screenshot. Arrays can <a id="_idIndexMarker302"/>also be <em class="italic">column-major</em> ordered, as is the case for the Fortran programming language:</p>
			<div><div><img src="img/B17499_Figure_4.1.jpg" alt="Figure 4.1 – Row-major order " width="921" height="266"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.1 – Row-major order</p>
			<p>Array ordering has important consequences. When iterating a C array over the last dimension, we access contiguous memory blocks (in our example, 0, 1, 2, 3 ...), while when we iterate on the first dimension, we skip a few positions (0, 2, 4, 6, 8, 1 ... ). You should always try to access memory sequentially as this optimizes cache and memory usage.</p>
			<p>We can store and retrieve elements from the array using standard indexing, as shown here; C arrays don't support fancy indexing or slices:</p>
			<pre>    arr[0] = 1.0 </pre>
			<p>C arrays have many of the same behaviors as pointers. The <code>arr</code> variable, in fact, points to the memory <a id="_idIndexMarker303"/>location of the first element of the array. We can verify that the address of <a id="_idIndexMarker304"/>the first element of the array<a id="_idIndexMarker305"/> is the same as the address<a id="_idIndexMarker306"/> contained in the <code>arr</code> variable using the dereference operator, as follows:</p>
			<pre>%%cython 
from libc.stdio cimport printf 
cdef double arr[10] 
printf("%p\n", arr) 
printf("%p\n", &amp;arr[0])
# Output
# 0x7ff6de204220 
# 0x7ff6de204220</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The output will only be generated when the aforementioned code is run from a standard Python terminal. This limitation of IPython is detailed at <a href="https://github.com/ipython/ipython/issues/1230">https://github.com/ipython/ipython/issues/1230</a>.</p>
			<p>You should use C arrays and pointers when interfacing with existing C libraries or when you need fine control over the memory (also, they are very performant). This level of fine control is also prone to mistakes as it doesn't prevent you from accessing the wrong memory locations. For more common use cases and improved safety, you can use NumPy arrays or typed memoryviews.</p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor078"/>Working with NumPy arrays</h2>
			<p>NumPy arrays can be used as normal Python objects in Cython, using their already optimized <a id="_idIndexMarker307"/>broadcasted operations. However, Cython provides a <code>numpy</code> module with<a id="_idIndexMarker308"/> better support for direct iteration.</p>
			<p>When we normally access an element of a NumPy array, a few other operations take place at the interpreter level, causing a major overhead. Cython can bypass those operations and checks by acting directly on the underlying memory area used by NumPy arrays, thus obtaining impressive performance gains.</p>
			<p>NumPy arrays can be declared as the <code>ndarray</code> data type. To use the data type in our code, we first need to <code>cimport</code> the <code>numpy</code> Cython module (which is not the same as the Python <code>numpy</code> module). We will bind the module to the <code>c_np</code> variable to make the difference with the Python <code>numpy</code> module more explicit, as follows:</p>
			<pre>    cimport numpy as c_np
    import numpy as np</pre>
			<p>We can now <a id="_idIndexMarker309"/>declare a NumPy array by specifying its type and the number of dimensions <a id="_idIndexMarker310"/>between square brackets (this is called <em class="italic">buffer syntax</em>). To declare a <code>double</code>, we can use the following code:</p>
			<pre>    cdef c_np.ndarray[double, ndim=2] arr </pre>
			<p>Access to this array will be performed by directly operating on the underlying memory area; the operation will avoid stepping into the interpreter, giving us a tremendous speed boost.</p>
			<p>In the next example, we will show the usage of typed NumPy arrays and compare them with the normal Python version.</p>
			<p>We first write a <code>numpy_bench_py</code> function that increments each element of <code>py_arr</code>. We declare the <code>i</code> index as an integer so that we avoid the <code>for</code> loop overhead, as follows:</p>
			<pre>    %%cython 
    import numpy as np 
    def numpy_bench_py(): 
        py_arr = np.random.rand(1000) 
        cdef int i 
        for i in range(1000): 
            py_arr[i] += 1 </pre>
			<p>Then, we write the same function using the <code>ndarray</code> type. Note that after we define the <code>c_arr</code> variable using <code>c_np.ndarray</code>, we can assign to it an array from the <code>numpy</code> Python module. The code is illustrated in the following snippet:</p>
			<pre>    %%cython 
    import numpy as np 
    cimport numpy as c_np 
    def numpy_bench_c(): 
        cdef c_np.ndarray[double, ndim=1] c_arr 
        c_arr = np.random.rand(1000) 
        cdef int i
        for i in range(1000): 
           c_arr[i] += 1 </pre>
			<p>We can time <a id="_idIndexMarker311"/>the results using <code>timeit</code>, and we can see here how the typed version<a id="_idIndexMarker312"/> is 50 times faster:</p>
			<pre>    %timeit numpy_bench_c() 
    100000 loops, best of 3: 11.5 us per loop 
    %timeit numpy_bench_py() 
    1000 loops, best of 3: 603 us per loop </pre>
			<p>This gives us a significant speedup from the Python code!</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor079"/>Working with typed memoryviews</h2>
			<p>C and NumPy arrays, as well as the built-in <code>bytes</code>, <code>bytearray</code>, and <code>array.array</code> objects, are similar <a id="_idIndexMarker313"/>in the sense that they all operate on a <a id="_idIndexMarker314"/>contiguous memory area (also called a memory <em class="italic">buffer</em>). Cython provides<a id="_idIndexMarker315"/> a universal interface—a <em class="italic">typed memoryview</em>—that unifies and simplifies access to all these data types.</p>
			<p>A <code>int</code> and a 2D memoryview of <code>double</code> in the following way:</p>
			<pre>    cdef int[:] a 
    cdef double[:, :] b </pre>
			<p>The same syntax applies to the declaration of any type in variables, function definitions, class attributes, and so on. Any object that exposes a buffer interface (for example, NumPy arrays, <code>bytes</code>, and <code>array.array</code> objects) will be bound to the memoryview automatically. For example, we can bind the memoryview to a NumPy array using a simple variable assignment, as follows:</p>
			<pre>    import numpy as np 
    cdef int[:] arr 
    arr_np = np.zeros(10, dtype='int32') 
    arr = arr_np # We bind the array to the memoryview </pre>
			<p>It is important to note that the memoryview does not <em class="italic">own</em> the data, but it only provides a way to <em class="italic">access</em> and <em class="italic">change</em> the data it is bound to; the ownership, in this case, is left to the NumPy array. As you can see in the following example, changes made through the memoryview will act on the underlying memory area and will be reflected in the original NumPy structure (and vice versa):</p>
			<pre>    arr[2] = 1 # Changing memoryview 
    print(arr_np) 
    # [0 0 1 0 0 0 0 0 0 0] </pre>
			<p>In a certain sense, the mechanism behind memoryviews is similar to what NumPy produces when we slice an array. As we have seen in <a href="B17499_03_Final_SS_ePub.xhtml#_idTextAnchor047"><em class="italic">Chapter 3</em></a>, <em class="italic">Fast Array Operations with NumPy, Pandas, and Xarray</em>, slicing a NumPy array does not copy the data but returns a <a id="_idIndexMarker317"/>view on the same memory area, and changes to the view will reflect<a id="_idIndexMarker318"/> on the original array.</p>
			<p>Memoryviews also support array slicing with the standard NumPy syntax, as illustrated in the following code snippet:</p>
			<pre>    cdef int[:, :, :] a 
    arr[0, :, :] # Is a 2-dimensional memoryview 
    arr[0, 0, :] # Is a 1-dimensional memoryview 
    arr[0, 0, 0] # Is an int </pre>
			<p>To copy data between one memoryview and another, you can use syntax similar to slice assignment, as shown in the following code snippet:</p>
			<pre>    import numpy as np 
    cdef double[:, :] b 
    cdef double[:] r 
    b = np.random.rand(10, 3) 
    r = np.zeros(3, dtype='float64') 
    b[0, :] = r # Copy the value of r in the first row of b </pre>
			<p>In the next section, we will use typed memoryviews to declare types for the arrays in our particle simulator.</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor080"/>Using a particle simulator in Cython</h1>
			<p>Now that we have <a id="_idIndexMarker319"/>a basic understanding of how Cython works, we can rewrite the <code>ParticleSimulator.evolve</code> method. Thanks <a id="_idIndexMarker320"/>to Cython, we can convert our loops in C, thus removing the overhead introduced by the Python interpreter.</p>
			<p>In <a href="B17499_03_Final_SS_ePub.xhtml#_idTextAnchor047"><em class="italic">Chapter 3</em></a>, <em class="italic">Fast Array Operations with NumPy, Pandas, and Xarray</em>, we wrote a fairly efficient version of the <code>evolve</code> method using NumPy. We can rename the old version <code>evolve_numpy</code> to differentiate it from the new version. The code is illustrated in the following snippet:</p>
			<pre>    def evolve_numpy(self, dt): 
        timestep = 0.00001 
        nsteps = int(dt/timestep) 
        r_i = np.array([[p.x, p.y] for p in \
            self.particles])     
        ang_speed_i = np.array([p.ang_speed for p in \
          self.particles]) 
        v_i = np.empty_like(r_i) 
        for i in range(nsteps): 
            norm_i = np.sqrt((r_i ** 2).sum(axis=1)) 
            v_i = r_i[:, [1, 0]] 
            v_i[:, 0] *= -1 
            v_i /= norm_i[:, np.newaxis]         
            d_i = timestep * ang_speed_i[:, np.newaxis] * \
                v_i 
            r_i += d_i 
        for i, p in enumerate(self.particles): 
            p.x, p.y = r_i[i] </pre>
			<p>We want to convert this code to Cython. Our strategy will be to take advantage of the fast indexing operations by removing the NumPy array broadcasting, thus reverting to an indexing-based algorithm. Since Cython generates efficient C code, we are free to use as many loops as we like without any performance penalty.</p>
			<p>As a design choice, we can decide to encapsulate the loop in a function that we will rewrite in a Cython module called <code>cevolve.pyx</code>. The module will contain a single Python function, <code>c_evolve</code>, that will take the particle positions, angular velocities, timestep, and the number of steps as input.</p>
			<p>At first, we are <a id="_idIndexMarker321"/>not adding typing information; we just want <a id="_idIndexMarker322"/>to isolate the function and ensure that we can compile our module without errors. The code is illustrated in the following snippet:</p>
			<pre>    # file: simul.py 
    def evolve_cython(self, dt): 
        timestep = 0.00001 
        nsteps = int(dt/timestep) 
    
        r_i = np.array([[p.x, p.y] for p in \
            self.particles])     
        ang_speed_i = np.array([p.ang_speed for p in \
            self.particles]) 
    
        c_evolve(r_i, ang_speed_i, timestep, nsteps) 
    
        for i, p in enumerate(self.particles): 
            p.x, p.y = r_i[i] 
    
    # file: cevolve.pyx 
    import numpy as np 
    
    def c_evolve(r_i, ang_speed_i, timestep, nsteps): 
        v_i = np.empty_like(r_i) 
    
        for i in range(nsteps): 
            norm_i = np.sqrt((r_i ** 2).sum(axis=1)) 
    
            v_i = r_i[:, [1, 0]] 
            v_i[:, 0] *= -1 
            v_i /= norm_i[:, np.newaxis]         
     
            d_i = timestep * ang_speed_i[:, np.newaxis] * 
                v_i 
    
            r_i += d_i </pre>
			<p>Note that we don't need a return value for <code>c_evolve</code> as values are updated in place in the <code>r_i</code> array. We can <a id="_idIndexMarker323"/>benchmark the untyped Cython version <a id="_idIndexMarker324"/>against the old NumPy version by slightly changing our <code>benchmark</code> function, as follows:</p>
			<pre>    def benchmark(npart=100, method='python'): 
        particles = [
                     Particle(uniform(-1.0, 1.0),
                              uniform(-1.0, 1.0),
                              uniform(-1.0, 1.0)) 
                              for i in range(npart)
            ] 
        simulator = ParticleSimulator(particles) 
        if method=='python': 
            simulator.evolve_python(0.1)
        elif method == 'cython': 
            simulator.evolve_cython(0.1) 
        elif method == 'numpy': 
            simulator.evolve_numpy(0.1) </pre>
			<p>We can time the different versions in an IPython shell, as follows:</p>
			<pre>    %timeit benchmark(100, 'cython') 
    1 loops, best of 3: 401 ms per loop 
    %timeit benchmark(100, 'numpy') 
    1 loops, best of 3: 413 ms per loop </pre>
			<p>The two versions have the same speed. Compiling the Cython module without static typing doesn't have any advantage over pure Python. The next step is to declare the type of all the important variables so that Cython can perform its optimizations.</p>
			<p>We can start adding types to the function arguments and see how the performance changes. We can declare the arrays as typed memoryviews containing <code>double</code> values. It's worth mentioning that if we pass an array of the <code>int</code> or <code>float32</code> type, the casting won't happen automatically and we will get an error. The code is illustrated in the following snippet:</p>
			<pre>    def c_evolve(double[:, :] r_i,
                 double[:] ang_speed_i,
                 double timestep,
                 int nsteps): </pre>
			<p>At this point, we can rewrite the loops over the particles and timesteps. We can declare the <code>i</code> and <code>j</code> iteration indices and the <code>nparticles</code> particle number as <code>int</code>, as follows:</p>
			<pre>    cdef int i, j 
    cdef int nparticles = r_i.shape[0] </pre>
			<p>The algorithm is very <a id="_idIndexMarker325"/>similar to the pure Python version; we <a id="_idIndexMarker326"/>iterate over the particles and timesteps, and we compute the velocity and displacement vectors for each particle coordinate using the following code:</p>
			<pre>      for i in range(nsteps): 
          for j in range(nparticles): 
              x = r_i[j, 0] 
              y = r_i[j, 1] 
              ang_speed = ang_speed_i[j] 
    
              norm = sqrt(x ** 2 + y ** 2) 
    
              vx = (-y)/norm 
              vy = x/norm 
    
              dx = timestep * ang_speed * vx 
              dy = timestep * ang_speed * vy 
    
              r_i[j, 0] += dx 
              r_i[j, 1] += dy </pre>
			<p>In the preceding code snippet, we added the <code>x</code>, <code>y</code>, <code>ang_speed</code>, <code>norm</code>, <code>vx</code>, <code>vy</code>, <code>dx</code>, and <code>dy</code> variables. To avoid the Python interpreter overhead, we have to declare them with their corresponding types at the beginning of the function, as follows:</p>
			<pre>    cdef double norm, x, y, vx, vy, dx, dy, ang_speed </pre>
			<p>We also used a function called <code>sqrt</code> to calculate the norm. If we use the <code>sqrt</code> function present in the <code>math</code> module or the one in <code>numpy</code>, we will again include a slow Python function in our <a id="_idIndexMarker327"/>critical loop, thus killing our performance. A fast <code>sqrt</code> function is <a id="_idIndexMarker328"/>available in the standard C library, already wrapped in the <code>libc.math</code> Cython module. Run the following code to import it:</p>
			<pre>    from libc.math cimport sqrt </pre>
			<p>We can rerun our benchmark to assess our improvements, as follows:</p>
			<pre>    In [4]: %timeit benchmark(100, 'cython') 
    100 loops, best of 3: 13.4 ms per loop 
    In [5]: %timeit benchmark(100, 'numpy') 
    1 loops, best of 3: 429 ms per loop </pre>
			<p>For small particle numbers, the speedup is massive as we obtained a 40 times faster performance over the previous version. However, we should also try to test the performance scaling with a larger number of particles, as follows:</p>
			<pre>    In [2]: %timeit benchmark(1000, 'cython') 
    10 loops, best of 3: 134 ms per loop 
    In [3]: %timeit benchmark(1000, 'numpy') 
    1 loops, best of 3: 877 ms per loop</pre>
			<p>As we increase the number of particles, the two versions get closer in speed. By increasing the particle size to <code>1000</code>, we already decreased our speedup to a more modest 6 times. This is likely because, as we increase the number of particles, the Python <code>for</code> loop <a id="_idIndexMarker329"/>overhead becomes less and less significant <a id="_idIndexMarker330"/>compared to the speed of other operations.</p>
			<p>The topic of benchmarking naturally transitions us to our next section: profiling.</p>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor081"/>Profiling Cython</h1>
			<p>Cython provides a feature called <em class="italic">annotated view</em> that helps find which lines are executed in the Python interpreter <a id="_idIndexMarker331"/>and which are good candidates for ulterior optimizations. We can <a id="_idIndexMarker332"/>turn this feature on by compiling <a id="_idIndexMarker333"/>a Cython file with the <code>-a</code> option. In this way, Cython will generate a <code>-a</code> option is shown here:</p>
			<pre>$ cython -a cevolve.pyx
$ firefox cevolve.html</pre>
			<p>The HTML file displayed in the following screenshot shows our Cython file line by line:</p>
			<div><div><img src="img/B17499_Figure_4.2.jpg" alt="Figure 4.2 – Generated HTML containing annotated code " width="883" height="763"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.2 – Generated HTML containing annotated code</p>
			<p>Each line in the source code can appear in different shades of yellow. A more intense color corresponds to more interpreter-related calls, while white lines are translated to regular C code. Since interpreter calls substantially slow down execution, the objective is to make <a id="_idIndexMarker334"/>the function body as white as possible. By clicking on any of the lines, we can inspect the code generated by the Cython compiler. For example, the <code>v_y = x/norm</code> line checks that the norm is not <code>0</code> and raises a <code>ZeroDivisionError</code> error if the condition is not verified. The <code>x = r_i[j, 0]</code> line shows that Cython checks whether the indexes are within the bounds of the array. You may have noted that the last line is of a very intense color; by inspecting the code, we can see that this is actually a glitch—the code refers to a boilerplate related to the end of the function.</p>
			<p>Cython can shut down checks such as division by zero so that it can remove those extra interpreter-related <a id="_idIndexMarker335"/>calls; this is usually accomplished through compiler directives. There are a few different ways to add compiler directives, as outlined here:</p>
			<ul>
				<li>Using a decorator or a context manager</li>
				<li>Using a comment at the beginning of the file</li>
				<li>Using the Cython command-line options</li>
			</ul>
			<p>For a complete <a id="_idIndexMarker336"/>list of the Cython compiler directives, you can refer to the official documentation at <a href="http://docs.cython.org/src/reference/compilation.html#compiler-directives">http://docs.cython.org/src/reference/compilation.html#compiler-directives</a>.</p>
			<p>For example, to disable bounds checking for arrays, it is sufficient to decorate a function with <code>cython.boundscheck</code>, in the following way:</p>
			<pre>    cimport cython 
    @cython.boundscheck(False) 
    def myfunction(): 
        # Code here </pre>
			<p>Alternatively, we can use <code>cython.boundscheck</code> to wrap a block of code into a context manager, as follows:</p>
			<pre>    with cython.boundscheck(False): 
        # Code here </pre>
			<p>If we want to disable bounds checking for a whole module, we can add the following line of code at the beginning of the file:</p>
			<pre>    # cython: boundscheck=False </pre>
			<p>To alter the directives with the command-line options, you can use the <code>-X</code> option, as follows:</p>
			<pre>$ cython -X boundscheck=True</pre>
			<p>To disable the extra checks in our <code>c_evolve</code> function, we can disable the <code>boundscheck</code> directive and enable <code>cdivision</code> (this prevents checks for <code>ZeroDivisionError</code>), as in the following code snippet:</p>
			<pre>    cimport cython 
    @cython.boundscheck(False) 
    @cython.cdivision(True) 
    def c_evolve(double[:, :] r_i,double[:] ang_speed_i, \
                 double timestep,int nsteps): </pre>
			<p>If we look at the annotated view again, the loop body has become completely white—we removed all <a id="_idIndexMarker337"/>traces of the interpreter from the inner loop. In order to recompile, just type <code>python setup.py build_ext --inplace</code> again. By running the benchmark, however, we note that we didn't obtain a performance improvement, suggesting that those checks are not part of the bottleneck, as we can see here:</p>
			<pre>    In [3]: %timeit benchmark(100, 'cython') 
    100 loops, best of 3: 13.4 ms per loop </pre>
			<p>Another way to profile Cython code is using the <code>cProfile</code> module. As an example, we can write a simple function that calculates the Chebyshev distance between coordinate arrays. Create a <code>cheb.py</code> file, as follows:</p>
			<pre>    import numpy as np 
    from distance import chebyshev 
    def benchmark(): 
        a = np.random.rand(100, 2) 
        b = np.random.rand(100, 2) 
        for x1, y1 in a: 
            for x2, y2 in b: 
                chebyshev(x1, x2, y1, y2) </pre>
			<p>If we try profiling this script as-is, we won't get any statistics regarding the functions that we <a id="_idIndexMarker338"/>implemented in Cython. If we want to collect profiling information for the <code>max</code> and <code>min</code> functions, we need to add the <code>profile=True</code> option to the <code>mathlib.pyx</code> file, as shown in the following code snippet:</p>
			<pre>    # cython: profile=True 
    cdef int max(int a, int b): 
        # Code here </pre>
			<p>We can now profile our script with <code>%prun</code> using IPython, as follows:</p>
			<pre>    import cheb 
    %prun cheb.benchmark() 
# Output:
2000005 function calls in 2.066 seconds 
  Ordered by: internal time 
  ncalls tottime percall cumtime percall 
  filename:lineno(function) 
       1   1.664   1.664   2.066   2.066 
 cheb.py:4(benchmark) 
 1000000   0.351   0.000   0.401   0.000
 {distance.chebyshev} 
 1000000   0.050   0.000   0.050   0.000 mathlib.pyx:2(max) 
       2   0.000   0.000   0.000   0.000 {method 'rand' of 
'mtrand.RandomState' objects} 
       1   0.000   0.000   2.066   2.066 
 &lt;string&gt;:1(&lt;module&gt;) 
       1   0.000   0.000   0.000   0.000 {method 'disable' 
 of        '_lsprof.Profiler' objects} </pre>
			<p>From the output, we can see that the <code>max</code> function is present and is not a bottleneck. Most of the <a id="_idIndexMarker339"/>time seems to be spent in the <code>benchmark</code> function, meaning that the bottleneck is likely a pure Python <code>for</code> loop. In this case, the best strategy will be rewriting the loop in NumPy or porting the code to Cython.</p>
			<p>One feature in Python that many users enjoy is the ability to work with Jupyter Notebooks. When working with Cython, you don't have to give up on this feature. In the next and last section of this chapter, we will see how we can use Cython with Jupyter.</p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor082"/>Using Cython with Jupyter</h1>
			<p>Optimizing Cython code requires substantial trial and error. Fortunately, Cython tools can be conveniently <a id="_idIndexMarker340"/>accessed through Jupyter Notebooks for <a id="_idIndexMarker341"/>a more streamlined and integrated experience.</p>
			<p>You can launch a notebook session by typing <code>jupyter notebook</code> in the command line, and you can load the Cython magic by typing <code>%load_ext cython</code> in a cell.</p>
			<p>As mentioned earlier, the <code>%%cython</code> magic can be used to compile and load the Cython code inside the current session. As an example, we may copy the contents of the <code>cheb.py</code> file into a notebook cell, like this:</p>
			<pre>    %%cython
    import numpy as np
    cdef int max(int a, int b):
        return a if a &gt; b else b
    cdef int chebyshev(int x1, int y1, int x2, int y2):
        return max(abs(x1 - x2), abs(y1 - y2))
    def c_benchmark():
        a = np.random.rand(1000, 2)
        b = np.random.rand(1000, 2)
        for x1, y1 in a:
           for x2, y2 in b:
               chebyshev(x1, x2, y1, y2)</pre>
			<p>A useful feature <a id="_idIndexMarker342"/>of the <code>%%cython</code> magic is the <code>-a</code> option that will <a id="_idIndexMarker343"/>compile the code and produce an annotated view (just as with the <code>-a</code> command-line option) of the source code directly in the notebook, as shown in the following screenshot:</p>
			<div><div><img src="img/B17499_Figure_4.3.jpg" alt="Figure 4.3 – Generated annotated code " width="661" height="731"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.3 – Generated annotated code</p>
			<p>This allows you <a id="_idIndexMarker344"/>to quickly test different versions of your code and use <a id="_idIndexMarker345"/>the other integrated tools available in Jupyter. For example, we can time and profile the code (provided that we activate the profile directive in the cell) in the same session using tools such as <code>%prun</code> and <code>%timeit</code>. We can also inspect the profiling results by taking advantage of the <code>%prun</code> magic, as shown in the following screenshot:</p>
			<div><div><img src="img/B17499_Figure_4.4.jpg" alt="Figure 4.4 – Profiling output " width="1025" height="349"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.4 – Profiling output</p>
			<p>It is also possible to use the <code>line_profiler</code> tool we discussed in <a href="B17499_01_Final_SS_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Benchmarking and Profiling</em>, directly in the notebook. To support line annotations, it is necessary to do the following things:</p>
			<ul>
				<li>Enable the <code>linetrace=True</code> and <code>binding=True</code> compiler directives.</li>
				<li>Enable the <code>CYTHON_TRACE=1</code> flag at compile time.</li>
			</ul>
			<p>This can be <a id="_idIndexMarker346"/>easily accomplished by adding the respective <a id="_idIndexMarker347"/>arguments to the <code>%%cython</code> magic and by setting the compiler directives, as shown in the following code snippet:</p>
			<pre><strong class="bold">    %%cython -a -f -c=-DCYTHON_TRACE=1</strong>
<strong class="bold">    # cython: linetrace=True</strong>
<strong class="bold">    # cython: binding=True</strong>
    import numpy as np
    cdef int max(int a, int b):
        return a if a &gt; b else b
    def chebyshev(int x1, int y1, int x2, int y2):
        return max(abs(x1 - x2), abs(y1 - y2))
    def c_benchmark():
        a = np.random.rand(1000, 2)
        b = np.random.rand(1000, 2)
    
        for x1, y1 in a:
            for x2, y2 in b:
                chebyshev(x1, x2, y1, y2)</pre>
			<p>Once the code <a id="_idIndexMarker348"/>is instrumented, we can install the <code>line_profiler</code> package <a id="_idIndexMarker349"/>via <code>pip install line_profiler</code> and profile using the <code>%lprun</code> magic, as follows:</p>
			<pre>%load_ext line_profiler
%lprun -f c_benchmark c_benchmark()
# Output:
Timer unit: 1e-06 s
Total time: 2.322 s
File: /home/gabriele/.cache/ipython/cython/_cython_
magic_18ad8204e9d29650f3b09feb48ab0f44.pyx
Function: c_benchmark at line 11
Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    11                                           def 
c_benchmark():
    12         1          226    226.0      0.0      a = 
np.random.rand...
    13         1           67     67.0      0.0      b = 
np.random.rand...    
    14                                               
    15      1001         1715      1.7      0.1      for 
x1, y1 in a:
    16   1001000      1299792      1.3     56.0          
for x2, y2 in b:
    17   1000000      1020203      1.0     43.9              
chebyshev...</pre>
			<p>As you can see, a good <a id="_idIndexMarker350"/>chunk of time is spent in <em class="italic">line 16</em>, which is a pure <a id="_idIndexMarker351"/>Python loop and a good candidate for further optimization.</p>
			<p>The tools available in Jupyter Notebook allow for a fast edit-compile-test cycle so that you can quickly prototype and save time when testing different solutions.</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor083"/>Summary</h1>
			<p>Cython is a tool that bridges the convenience of Python with the speed of C. Compared to C bindings, Cython programs are much easier to maintain and debug, thanks to the tight integration and compatibility with Python and the availability of excellent tools.</p>
			<p>In this chapter, we introduced the basics of the Cython language and how to make our programs faster by adding static types to our variables and functions. We also learned how to work with C arrays, NumPy arrays, and memoryviews.</p>
			<p>We optimized our particle simulator by rewriting the critical <code>evolve</code> function, obtaining a tremendous speed gain. Finally, we learned how to use the annotated view to spot hard-to-find interpreter-related calls and how to enable <code>cProfile</code> support in Cython. Also, we learned how to take advantage of the Jupyter Notebook for integrated profiling and analysis of Cython code.</p>
			<p>All these tasks provide us with the high level of flexibility, which we already enjoy with Python, when working with Cython, while allowing our programs to be more optimized with low-level C code.</p>
			<p>In the next chapter, we will explore other tools that can generate fast machine code on the fly, without requiring the compilation of our code to C <strong class="bold">ahead of time</strong> (<strong class="bold">AOT</strong>).</p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor084"/>Questions</h1>
			<ol>
				<li value="1">What is the benefit of implementing static types?</li>
				<li>What is the benefit of a memoryview?</li>
				<li>Which tools for profiling Cython were introduced in this chapter?</li>
			</ol>
		</div>
	</div>
</div>
</body></html>