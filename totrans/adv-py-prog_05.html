<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer052">
			<h1 id="_idParaDest-75"><em class="italic"><a id="_idTextAnchor068"/>Chapter 4</em>: C Performance with Cython</h1>
			<p>Cython is a language that extends Python by supporting the declaration of types for functions, variables, and classes. These typed declarations enable Cython to compile Python scripts to efficient C code. Cython can also act as a bridge between Python and C as it provides easy-to-use constructs to write interfaces to external C and C++ routines.</p>
			<p>In this chapter, we will learn about the following topics:</p>
			<ul>
				<li>Compiling Cython extensions</li>
				<li>Adding static types</li>
				<li>Sharing declarations</li>
				<li>Working with arrays</li>
				<li>Using a particle simulator in Cython</li>
				<li>Profiling Cython</li>
				<li>Using Cython with Jupyter</li>
			</ul>
			<p>Through this chapter, we will learn how to leverage Cython to improve the efficiency of our programs. While a minimum knowledge of C is helpful, this chapter focuses only on Cython in the context of Python optimization. Therefore, it doesn't require any C background.</p>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor069"/>Technical requirements</h1>
			<p>You can access the code used in this chapter on GitHub at <a href="https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter04">https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter04</a>.</p>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor070"/>Compiling Cython extensions</h1>
			<p>The Cython syntax is, by design, a superset of Python. Cython can compile, with a few exceptions, most Python <a id="_idIndexMarker259"/>modules without requiring any change. Cython source files have the <strong class="source-inline">.pyx</strong> extension and can be compiled to produce a C file using the <strong class="source-inline">cython</strong> command.</p>
			<p>All that is required to convert Python code to Cython is some syntactic modifications that we will see throughout this chapter (such as when declaring variables and functions) as well as compilation. While this procedure may seem intimidating at first, Cython will more than make up for itself via the computational benefits that it offers.</p>
			<p>First off, to install Cython, we can simply run the <strong class="source-inline">pip</strong> command, like this:</p>
			<p class="source-code">$pip install cython</p>
			<p>Refer to the documentation at <a href="https://pypi.org/project/Cython/">https://pypi.org/project/Cython/</a> for more details. Our first Cython script will <a id="_idIndexMarker260"/>contain a simple function that prints <strong class="source-inline">Hello, World!</strong> as the output. Follow these next steps:</p>
			<ol>
				<li>Create a new <strong class="source-inline">hello.pyx</strong> file containing the following code:<p class="source-code">    def hello(): </p><p class="source-code">      print('Hello, World!') </p></li>
				<li>The <strong class="source-inline">cython</strong> command will read <strong class="source-inline">hello.pyx</strong> and generate a <strong class="source-inline">hello.c</strong> file, as follows:<p class="source-code">$ cython hello.pyx</p></li>
				<li>To compile <strong class="source-inline">hello.c</strong> to a <a id="_idIndexMarker261"/>Python extension module, we will use the <strong class="bold">GNU Compiler Collection</strong> (<strong class="bold">GCC</strong>) compiler (more details on how to install it can be found at <a href="https://gcc.gnu.org/install/">https://gcc.gnu.org/install/</a>). We need to add some Python-specific compilation options that depend on the operating system. It's important to specify the directory that contains the header files; in the following example, the directory is <strong class="source-inline">/usr/include/python3.5/</strong>:<p class="source-code">$ gcc -shared -pthread -fPIC -fwrapv -O2 -Wall -fno-</p><p class="source-code">strict-aliasing -lm -I/usr/include/python3.5/ -o </p><p class="source-code">hello.so hello.c</p><p class="callout-heading">Note</p><p class="callout">To find your Python <strong class="source-inline">include</strong> directory, you can use the <strong class="source-inline">distutils</strong> utility and run <strong class="source-inline">sysconfig.get_python_inc</strong>. To execute it, you can simply issue the following command: <strong class="source-inline">python -c "from distutils import sysconfig;</strong> <strong class="source-inline">print(sysconfig.get_python_inc())"</strong>.</p></li>
				<li>This will produce a file called <strong class="source-inline">hello.so</strong>, a C extension module that is directly importable into a Python session. The code is illustrated in the following snippet:<p class="source-code">    &gt;&gt;&gt; import hello </p><p class="source-code">    &gt;&gt;&gt; hello.hello() </p><p class="source-code">    Hello, World!</p></li>
				<li>Cython accepts both Python 2 and Python 3 as <strong class="bold">input and output</strong> (<strong class="bold">I/O</strong>) languages. In other <a id="_idIndexMarker262"/>words, you can compile a Python 3 <a id="_idIndexMarker263"/>script <strong class="source-inline">hello.pyx</strong> file using the <strong class="source-inline">-3</strong> option, as illustrated in the following code snippet:<p class="source-code">$ cython -3 hello.pyx</p></li>
				<li>The generated <strong class="source-inline">hello.c</strong> file can be compiled without any changes to Python 2 and Python 3 by including the corresponding headers with the <strong class="source-inline">-I</strong> option, as follows:<p class="source-code">$ gcc -I/usr/include/python3.5 # ... other options</p><p class="source-code">$ gcc -I/usr/include/python2.7 # ... other options</p></li>
				<li>A Cython program can be compiled in a more straightforward way using <strong class="source-inline">distutils</strong>, the standard Python packaging tool. By writing a <strong class="source-inline">setup.py</strong> script, we can compile the <strong class="source-inline">.pyx</strong> file directly to an extension module. To compile our <strong class="source-inline">hello.pyx</strong> example, we can write a minimal <strong class="source-inline">setup.py</strong> script containing the following code:<p class="source-code">    from distutils.core import setup </p><p class="source-code">    from Cython.Build import cythonize </p><p class="source-code">    setup( </p><p class="source-code">      name='Hello',</p><p class="source-code">      ext_modules = cythonize('hello.pyx')</p><p class="source-code">    ) </p></li>
			</ol>
			<p>In the first two lines of the preceding code snippet, we import the <strong class="source-inline">setup</strong> function and the <strong class="source-inline">cythonize</strong> helper. The <strong class="source-inline">setup</strong> function contains a few key-value pairs that specify the name of the application and the extensions that need to be built.</p>
			<ol>
				<li value="8">The <strong class="source-inline">cythonize</strong> helper takes either a string or a list of strings containing the Cython modules <a id="_idIndexMarker264"/>we want to compile. You can also use glob patterns by running the following code:<p class="source-code">    cythonize(['hello.pyx', 'world.pyx', '*.pyx']) </p></li>
				<li>To compile our extension module using <strong class="source-inline">distutils</strong>, you can execute the <strong class="source-inline">setup.py</strong> script using the following code:<p class="source-code">$ python setup.py build_ext --inplace</p></li>
			</ol>
			<p>The <strong class="source-inline">build_ext</strong> option tells the script to build the extension modules indicated in <strong class="source-inline">ext_modules</strong>, while the <strong class="source-inline">--inplace</strong> option tells the script to place the <strong class="source-inline">hello.so</strong> output file in the same location as the source file (instead of a build directory).</p>
			<ol>
				<li value="10">Cython modules can also be automatically compiled using <strong class="source-inline">pyximport</strong>. All that's needed is a call to <strong class="source-inline">pyximport.install()</strong> at the beginning of your script (or you need to issue the command in your interpreter), as illustrated in the following code snippet. After doing that, you can import <strong class="source-inline">.pyx</strong> files directly and <strong class="source-inline">pyximport</strong> will transparently compile the corresponding Cython modules:<p class="source-code">    &gt;&gt;&gt; import pyximport </p><p class="source-code">    &gt;&gt;&gt; pyximport.install() </p><p class="source-code">    &gt;&gt;&gt; import hello # This will compile hello.pyx </p></li>
			</ol>
			<p>Unfortunately, <strong class="source-inline">pyximport</strong> will not work for all kinds of configurations (for example, when they involve a combination of C and Cython files), but it comes in handy for testing simple scripts.</p>
			<ol>
				<li value="11">Since version 0.13, IPython includes the <strong class="source-inline">cythonmagic</strong> extension to interactively write and test a series of Cython statements. You can load the extensions in an IPython shell using <strong class="source-inline">load_ext</strong>, as follows:<p class="source-code">    %load_ext Cython</p></li>
			</ol>
			<p>Once the extension is loaded, you can use the <strong class="source-inline">%%cython</strong> <em class="italic">cell magic</em> to write a multiline Cython snippet. In <a id="_idIndexMarker265"/>the following example, we define a <strong class="source-inline">hello_snippet</strong> function that will be compiled and added to the IPython session namespace:</p>
			<p class="source-code">    %%cython </p>
			<p class="source-code">    def hello_snippet(): </p>
			<p class="source-code">        print("Hello, Cython!") </p>
			<p class="source-code">    hello_snippet()</p>
			<p class="source-code">    Hello,  Cython! </p>
			<p>It is that simple to work with Cython source code. In the next section, we will see how we can add static types to our program, getting it closer to C code.</p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor071"/>Adding static types</h1>
			<p>In Python, a variable can be associated with objects of different types during the execution of the <a id="_idIndexMarker266"/>program. While this feature is desirable as it makes the language flexible and dynamic, it also adds significant overhead to the interpreter as it needs to look up the type and methods of the variables at runtime, making it difficult to perform various optimizations. Cython extends the Python language with explicit type declarations so that it can generate efficient C extensions through compilation.</p>
			<p>The main way to declare data types in Cython is through <strong class="source-inline">cdef</strong> statements. The <strong class="source-inline">cdef</strong> keyword can be used in multiple contexts, such as variables, functions, and extension types (statically typed classes). We will see how to do this in the following subsections.</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor072"/>Declaring variables</h2>
			<p>In Cython, you can declare the type <a id="_idIndexMarker267"/>of a variable by prepending the<a id="_idIndexMarker268"/> variable with <strong class="source-inline">cdef</strong> and its respective type. For example, we can declare the <strong class="source-inline">i</strong> variable as a 16-bit integer in the following way:</p>
			<p class="source-code">    cdef int i </p>
			<p>The <strong class="source-inline">cdef</strong> statement supports multiple variable names on the same line along with optional initialization, as seen in the following line of code:</p>
			<p class="source-code">    cdef double a, b = 2.0, c = 3.0 </p>
			<p>Typed variables are treated differently from regular variables. In Python, variables are often described as <em class="italic">labels</em> that refer to objects in memory. For example, we could assign the value <strong class="source-inline">'hello'</strong> to the <strong class="source-inline">a</strong> variable at any point in the program without restriction, as illustrated here:</p>
			<p class="source-code">    a = 'hello' </p>
			<p>The <strong class="source-inline">a</strong> variable holds a reference to the <strong class="source-inline">'hello'</strong> string. We can also freely assign another value (for example, the integer <strong class="source-inline">1</strong>) to the same variable later in the code, as follows:</p>
			<p class="source-code">    a = 1 </p>
			<p>Python will assign the integer <strong class="source-inline">1</strong> to the <strong class="source-inline">a</strong> variable without any problem.</p>
			<p>Typed variables behave quite differently and are usually described as <em class="italic">data containers</em>: we can only store<a id="_idIndexMarker269"/> values that fit into the container that is determined by its data type. For example, if we declare the <strong class="source-inline">a</strong> variable as <strong class="source-inline">int</strong>, and then we try to assign it to a <strong class="source-inline">double</strong> data type, Cython will trigger an error, as shown in the following code snippet:</p>
			<p class="source-code">    %%cython </p>
			<p class="source-code">    cdef int i </p>
			<p class="source-code">    i = 3.0 </p>
			<p class="source-code">    # Output has been cut </p>
			<p class="source-code">    ...cf4b.pyx:2:4 Cannot assign type 'double' to 'int' </p>
			<p>Static typing makes it easy for the compiler to perform useful optimizations. For example, if we declare a loop index as <strong class="source-inline">int</strong>, Cython will rewrite the loop in pure C without needing <a id="_idIndexMarker270"/>to step into the Python interpreter. The typing declaration guarantees<a id="_idIndexMarker271"/> that the type of the index will always be <strong class="source-inline">int</strong> and cannot be overwritten at runtime so that the compiler is free to perform optimizations without compromising the program's correctness.</p>
			<p>We can assess the speed gain in this case with a small test case. In the following example, we implement a simple loop that increments a variable <strong class="source-inline">100</strong> times. With Cython, the <strong class="source-inline">example</strong> function can be coded as follows:</p>
			<p class="source-code">    %%cython </p>
			<p class="source-code">    def example(): </p>
			<p class="source-code">       cdef int i, j=0 </p>
			<p class="source-code">       for i in range(100):</p>
			<p class="source-code">           j += 1 </p>
			<p class="source-code">       return j </p>
			<p class="source-code">    example() </p>
			<p class="source-code">    # Result:</p>
			<p class="source-code">    # 100 </p>
			<p>We can compare the speed of an analogous, untyped, pure Python loop, as follows:</p>
			<p class="source-code">    def example_python(): </p>
			<p class="source-code">        j=0 </p>
			<p class="source-code">        for i in range(100):</p>
			<p class="source-code">            j += 1 </p>
			<p class="source-code">        return j </p>
			<p class="source-code">    %timeit example() </p>
			<p class="source-code">    10000000 loops, best of 3: 25 ns per loop </p>
			<p class="source-code">    %timeit example_python() </p>
			<p class="source-code">    100000 loops, best of 3: 2.74 us per loop </p>
			<p>The speedup obtained by implementing this simple type declaration is a whopping 100 times! This <a id="_idIndexMarker272"/>works because the Cython loop has first been converted to pure C and<a id="_idIndexMarker273"/> then to efficient machine code, while the Python loop still relies on the slow interpreter.</p>
			<p>In Cython, it is possible to declare a variable to be of any standard C type, and it is also possible to define custom types using classic C constructs, such as <strong class="source-inline">struct</strong>, <strong class="source-inline">enum</strong>, and <strong class="source-inline">typedef</strong>.</p>
			<p>An interesting example is that if we declare a variable to be of the <strong class="source-inline">object</strong> type, the variable will accept any kind of Python object, as illustrated in the following code snippet:</p>
			<p class="source-code">    cdef object a_py </p>
			<p class="source-code">    # both 'hello' and 1 are Python objects </p>
			<p class="source-code">    a_py = 'hello' </p>
			<p class="source-code">    a_py = 1 </p>
			<p>Note that declaring a variable as <strong class="source-inline">object</strong> has no performance benefits, as accessing and operating on the object will still require the interpreter to look up the underlying type of the variable and its attributes and methods.</p>
			<p>Sometimes, certain data types (such as <strong class="source-inline">float</strong> and <strong class="source-inline">int</strong> numbers) are compatible in the sense that they <a id="_idIndexMarker274"/>can be converted into each other. In Cython, it is possible to convert (<em class="italic">cast</em>) between<a id="_idIndexMarker275"/> types by surrounding the destination type with pointy brackets, as shown in the following code snippet:</p>
			<p class="source-code">    cdef int a = 0 </p>
			<p class="source-code">    cdef double b </p>
			<p class="source-code">    b = &lt;double&gt; a </p>
			<p>Together with static types for variables, we can provide information about functions, which we will learn how to do next.</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor073"/>Declaring functions</h2>
			<p>You can add type information to the arguments of a Python function by specifying the type in front of each <a id="_idIndexMarker276"/>of the argument names. Functions specified in this way will work<a id="_idIndexMarker277"/> and perform like regular Python functions, but their arguments will be type-checked. We can write a <strong class="source-inline">max_python</strong> function that returns the greater value between two integers, as follows:</p>
			<p class="source-code">    def max_python(int a, int b):</p>
			<p class="source-code">        return a if a &gt; b else b </p>
			<p>A function specified in this way will perform type checking and treat the arguments as typed variables, just as in <strong class="source-inline">cdef</strong> definitions. However, the function will still be a Python function, and calling it multiple times will still need to switch back to the interpreter. To allow Cython for function call optimizations, we should declare the type of the return type using a <strong class="source-inline">cdef</strong> statement, as follows:</p>
			<p class="source-code">    cdef int max_cython(int a, int b): </p>
			<p class="source-code">        return a if a &gt; b else b </p>
			<p>Functions declared in this way are translated to native C functions and have much less overhead compared to Python functions. A substantial drawback is that they can't be used from Python but only from Cython, and their scope is restricted to the same Cython file unless they're exposed in a definition file (refer to the <em class="italic">Sharing declarations</em> section).</p>
			<p>Fortunately, Cython allows you to define functions that are both callable from Python and translatable to performant C functions. If you declare a function with a <strong class="source-inline">cpdef</strong> statement, Cython will generate two versions of the function: a Python version available to the interpreter, and a fast C function usable from Cython. The <strong class="source-inline">cpdef</strong> syntax is equivalent to <strong class="source-inline">cdef</strong>, shown as follows:</p>
			<p class="source-code">    cpdef int max_hybrid(int a, int b): </p>
			<p class="source-code">        return a if a &gt; b else b </p>
			<p>Sometimes, the call overhead can be a performance issue even with C functions, especially when <a id="_idIndexMarker278"/>the same function is called many times in a critical loop. When the function<a id="_idIndexMarker279"/> body is small, it is convenient to add the <strong class="source-inline">inline</strong> keyword in front of the function definition; the function call will be replaced by the function body itself. Our <strong class="source-inline">max</strong> function is a good candidate for <em class="italic">inlining</em>, as illustrated in the following code snippet:</p>
			<p class="source-code">    cdef inline int max_inline(int a, int b): </p>
			<p class="source-code">        return a if a &gt; b else b </p>
			<p>Finally, we will see how to work with class types next.</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor074"/>Declaring classes</h2>
			<p>We can define an extension type using the <strong class="source-inline">cdef class</strong> statement and declare its attributes in <a id="_idIndexMarker280"/>the class body. For example, we can create a <strong class="source-inline">Point</strong> extension type, as shown<a id="_idIndexMarker281"/> in the following code snippet, which stores two coordinates (<strong class="source-inline">x</strong>, <strong class="source-inline">y</strong>) of the <strong class="source-inline">double</strong> type:</p>
			<p class="source-code">    cdef class Point:</p>
			<p class="source-code">        cdef double x </p>
			<p class="source-code">        cdef double y</p>
			<p class="source-code">        def __init__(self, double x, double y): </p>
			<p class="source-code">            self.x = x </p>
			<p class="source-code">            self.y = y </p>
			<p>Accessing the declared attributes in the class methods allows Cython to bypass expensive Python attribute lookups by direct access to the given fields in the underlying C struct. For this reason, attribute access in typed classes is an extremely fast operation.</p>
			<p>To use the <strong class="source-inline">cdef class</strong> statement in your code, you need to explicitly declare the type of the variables you intend to use at compile time. You can use the extension type name (such as <strong class="source-inline">Point</strong>) in any context where you will use a standard type (such as <strong class="source-inline">double</strong>, <strong class="source-inline">float</strong>, and <strong class="source-inline">int</strong>). For example, if we want a Cython function that calculates the distance from the origin (in the example, the function is called <strong class="source-inline">norm</strong>) of a <strong class="source-inline">Point</strong>, we have to declare the input variable as <strong class="source-inline">Point</strong>, as shown in the following code snippet:</p>
			<p class="source-code">    cdef double norm(Point p): </p>
			<p class="source-code">        return (p.x**2 + p.y**2)**0.5 </p>
			<p>Just as with typed functions, typed classes have some limitations. If you try to access an extension type attribute from Python, you will get an <strong class="source-inline">AttributeError</strong> warning, as follows:</p>
			<p class="source-code">    &gt;&gt;&gt; a = Point(0.0, 0.0) </p>
			<p class="source-code">    &gt;&gt;&gt; a.x </p>
			<p class="source-code">    AttributeError: 'Point' object has no attribute 'x' </p>
			<p>In order to access attributes from Python code, you have to use the <strong class="source-inline">public</strong> (for read/write access) or <strong class="source-inline">readonly</strong> specifiers in the attribute declaration, as shown in the following code snippet:</p>
			<p class="source-code">    cdef class Point: </p>
			<p class="source-code">        cdef public double x </p>
			<p>Additionally, methods <a id="_idIndexMarker282"/>can be declared with the <strong class="source-inline">cpdef</strong> statement, just as with regular<a id="_idIndexMarker283"/> functions.</p>
			<p>Extension types do not support the addition of extra attributes at runtime. To do that, a solution is defining a Python class that is a subclass of the typed class and extends its attributes and methods in pure Python.</p>
			<p>And with that, we have seen how to add static types to various objects in Cython. In the next section, we will begin our discussion regarding declarations.</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor075"/>Sharing declarations</h1>
			<p>When writing your Cython modules, you may want to reorganize your most-used functions and classes declaration in <a id="_idIndexMarker284"/>a separate file so that they can be reused in different modules. Cython allows you to put these components in a <em class="italic">definition file</em> and access them with <strong class="source-inline">cimport</strong> statements.</p>
			<p>Let's say that we have a module with the <strong class="source-inline">max</strong> and <strong class="source-inline">min</strong> functions, and we want to reuse those functions in multiple Cython programs. If we simply write a bunch of functions in a <strong class="source-inline">.pyx</strong> file, the declarations will be confined to the same file.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Definition files are also used to interface Cython with external C code. The idea is to copy (or, more accurately, translate) the types and function prototypes in the definition file and leave <a id="_idIndexMarker285"/>the implementation in the external C code that will be compiled and linked in a separate step.</p>
			<p>To share the <strong class="source-inline">max</strong> and <strong class="source-inline">min</strong> functions, we need to write a definition file with a <strong class="source-inline">.pxd</strong> extension. Such a file only contains the types and function prototypes that we want to share with other modules—a <em class="italic">public</em> interface. We can declare the prototypes of our <strong class="source-inline">max</strong> and <strong class="source-inline">min</strong> functions in a file named <strong class="source-inline">mathlib.pxd</strong>, as follows:</p>
			<p class="source-code">    cdef int max(int a, int b) </p>
			<p class="source-code">    cdef int min(int a, int b) </p>
			<p>As you can see, we only write the function name and arguments without implementing the function body.</p>
			<p>The function implementation goes into the implementation file with the same base name but the <strong class="source-inline">.pyx</strong> extension <strong class="source-inline">mathlib.pyx</strong>, as follows:</p>
			<p class="source-code">    cdef int max(int a, int b): </p>
			<p class="source-code">      return a if a &gt; b else b </p>
			<p class="source-code">    cdef int min(int a, int b): </p>
			<p class="source-code">      return a if a &lt; b else b </p>
			<p>The <strong class="source-inline">mathlib</strong> module is now importable from another Cython module.</p>
			<p>To test our new Cython module, we will create a file named <strong class="source-inline">distance.pyx</strong> containing a function named <strong class="source-inline">chebyshev</strong>. The function will calculate the Chebyshev distance between two points, as shown in the following code snippet. The Chebyshev distance between two coordinates—<strong class="source-inline">(x1,</strong> <strong class="source-inline">y1)</strong> and <strong class="source-inline">(x2, y2</strong>—is defined as the maximum value of the difference between each coordinate:</p>
			<p class="source-code">    max(abs(x1 - x2), abs(y1 - y2)) </p>
			<p>To implement the <strong class="source-inline">chebyshev</strong> function, we will use the <strong class="source-inline">max</strong> function declared in <strong class="source-inline">mathlib.pxd</strong> by importing it with the <strong class="source-inline">cimport</strong> statement, as shown in the following code snippet:</p>
			<p class="source-code">    from mathlib cimport max </p>
			<p class="source-code">    def chebyshev(int x1, int y1, int x2, int y2): </p>
			<p class="source-code">        return max(abs(x1 - x2), abs(y1 - y2)) </p>
			<p>The <strong class="source-inline">cimport</strong> statement will read <strong class="source-inline">mathlib.pxd</strong> and the <strong class="source-inline">max</strong> definition will be used to generate a <strong class="source-inline">distance.c</strong> file.</p>
			<p>Along with static types and declarations, one factor that allows C to be generally faster than Python<a id="_idIndexMarker286"/> is its highly optimized array operations, which we will examine in the next section.</p>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor076"/>Working with arrays</h1>
			<p>Numerical and high-performance calculations often make use of arrays. Cython provides an easy way to interact with <a id="_idIndexMarker287"/>different types of arrays, using directly low-level C arrays, or the more general <em class="italic">typed memoryviews</em>. We will see how to do this in the following subsections.</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor077"/>C arrays and pointers</h2>
			<p>C arrays are a collection <a id="_idIndexMarker288"/>of items of the same type, stored contiguously in memory. Before <a id="_idIndexMarker289"/>digging into<a id="_idIndexMarker290"/> the details, it is helpful<a id="_idIndexMarker291"/> to understand (or review) how memory is managed in C.</p>
			<p>Variables in C are like containers. When creating a variable, a space in memory is reserved to store its value. For example, if we create a variable containing a 64-bit floating-point number (<strong class="source-inline">double</strong>), the program will allocate 64 bits (16 bytes) of memory. This portion of memory can be accessed through an address to that memory location.</p>
			<p>To obtain the <a id="_idIndexMarker292"/>address of a variable, we can use the <em class="italic">address operator</em> denoted by the <strong class="source-inline">&amp;</strong> symbol. We can also use <a id="_idIndexMarker293"/>the <strong class="source-inline">printf</strong> function, as follows, available<a id="_idIndexMarker294"/> in the <strong class="source-inline">libc.stdio</strong> Cython module<a id="_idIndexMarker295"/> to print the address of this variable:</p>
			<p class="source-code">    %%cython </p>
			<p class="source-code">    cdef double a </p>
			<p class="source-code">    from libc.stdio cimport printf </p>
			<p class="source-code">    printf("%p", &amp;a)</p>
			<p class="source-code">    # Output:</p>
			<p class="source-code">    # 0x7fc8bb611210 </p>
			<p class="callout-heading">Note </p>
			<p class="callout">The output will only be generated when the code is run from a standard Python terminal. This <a id="_idIndexMarker296"/>limitation of IPython is detailed at <a href="https://github.com/ipython/ipython/issues/1230">https://github.com/ipython/ipython/issues/1230</a>.</p>
			<p>Memory addresses can be stored in special variables, <em class="italic">pointers</em>, that can be declared by putting a <strong class="source-inline">*</strong> prefix in front of the variable name, as follows:</p>
			<p class="source-code">    from libc.stdio cimport printf </p>
			<p class="source-code">    cdef double a </p>
			<p class="source-code">    cdef double *a_pointer </p>
			<p class="source-code">    a_pointer = &amp;a # a_pointer and &amp;a are of the same type </p>
			<p>If we have a pointer and we want to grab the value contained in the address it's pointing at, we can use the zero-index notation shown here:</p>
			<p class="source-code">    cdef double a </p>
			<p class="source-code">    cdef double *a_pointer </p>
			<p class="source-code">    a_pointer = &amp;a </p>
			<p class="source-code">    a = 3.0 </p>
			<p class="source-code">    print(a_pointer[0]) # prints 3.0 </p>
			<p>When declaring <a id="_idIndexMarker297"/>a C array, the program allocates enough space to accommodate all the <a id="_idIndexMarker298"/>elements requested. For instance, to create<a id="_idIndexMarker299"/> an array that has 10 <strong class="source-inline">double</strong> values (16 bytes each), the program<a id="_idIndexMarker300"/> will reserve <em class="italic">16 </em> * <em class="italic">10 </em> = <em class="italic">160</em> bytes of contiguous space in memory. In Cython, we can declare such arrays using the following syntax:</p>
			<p class="source-code">    cdef double arr[10]</p>
			<p>We can also declare a multidimensional array, such as an array with <strong class="source-inline">5</strong> rows and <strong class="source-inline">2</strong> columns, using the following syntax:</p>
			<p class="source-code">    cdef double arr[5][2] </p>
			<p>The memory will be allocated in a single block of memory, row after row. This order is commonly referred to as <em class="italic">row-major</em> and is depicted <a id="_idIndexMarker301"/>in the following screenshot. Arrays can <a id="_idIndexMarker302"/>also be <em class="italic">column-major</em> ordered, as is the case for the Fortran programming language:</p>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="image/B17499_Figure_4.1.jpg" alt="Figure 4.1 – Row-major order " width="921" height="266"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.1 – Row-major order</p>
			<p>Array ordering has important consequences. When iterating a C array over the last dimension, we access contiguous memory blocks (in our example, 0, 1, 2, 3 ...), while when we iterate on the first dimension, we skip a few positions (0, 2, 4, 6, 8, 1 ... ). You should always try to access memory sequentially as this optimizes cache and memory usage.</p>
			<p>We can store and retrieve elements from the array using standard indexing, as shown here; C arrays don't support fancy indexing or slices:</p>
			<p class="source-code">    arr[0] = 1.0 </p>
			<p>C arrays have many of the same behaviors as pointers. The <strong class="source-inline">arr</strong> variable, in fact, points to the memory <a id="_idIndexMarker303"/>location of the first element of the array. We can verify that the address of <a id="_idIndexMarker304"/>the first element of the array<a id="_idIndexMarker305"/> is the same as the address<a id="_idIndexMarker306"/> contained in the <strong class="source-inline">arr</strong> variable using the dereference operator, as follows:</p>
			<p class="source-code">%%cython </p>
			<p class="source-code">from libc.stdio cimport printf </p>
			<p class="source-code">cdef double arr[10] </p>
			<p class="source-code">printf("%p\n", arr) </p>
			<p class="source-code">printf("%p\n", &amp;arr[0])</p>
			<p class="source-code"># Output</p>
			<p class="source-code"># 0x7ff6de204220 </p>
			<p class="source-code"># 0x7ff6de204220</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The output will only be generated when the aforementioned code is run from a standard Python terminal. This limitation of IPython is detailed at <a href="https://github.com/ipython/ipython/issues/1230">https://github.com/ipython/ipython/issues/1230</a>.</p>
			<p>You should use C arrays and pointers when interfacing with existing C libraries or when you need fine control over the memory (also, they are very performant). This level of fine control is also prone to mistakes as it doesn't prevent you from accessing the wrong memory locations. For more common use cases and improved safety, you can use NumPy arrays or typed memoryviews.</p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor078"/>Working with NumPy arrays</h2>
			<p>NumPy arrays can be used as normal Python objects in Cython, using their already optimized <a id="_idIndexMarker307"/>broadcasted operations. However, Cython provides a <strong class="source-inline">numpy</strong> module with<a id="_idIndexMarker308"/> better support for direct iteration.</p>
			<p>When we normally access an element of a NumPy array, a few other operations take place at the interpreter level, causing a major overhead. Cython can bypass those operations and checks by acting directly on the underlying memory area used by NumPy arrays, thus obtaining impressive performance gains.</p>
			<p>NumPy arrays can be declared as the <strong class="source-inline">ndarray</strong> data type. To use the data type in our code, we first need to <strong class="source-inline">cimport</strong> the <strong class="source-inline">numpy</strong> Cython module (which is not the same as the Python <strong class="source-inline">numpy</strong> module). We will bind the module to the <strong class="source-inline">c_np</strong> variable to make the difference with the Python <strong class="source-inline">numpy</strong> module more explicit, as follows:</p>
			<p class="source-code">    cimport numpy as c_np</p>
			<p class="source-code">    import numpy as np</p>
			<p>We can now <a id="_idIndexMarker309"/>declare a NumPy array by specifying its type and the number of dimensions <a id="_idIndexMarker310"/>between square brackets (this is called <em class="italic">buffer syntax</em>). To declare a <strong class="bold">two-dimensional</strong> (<strong class="bold">2D</strong>) array of type <strong class="source-inline">double</strong>, we can use the following code:</p>
			<p class="source-code">    cdef c_np.ndarray[double, ndim=2] arr </p>
			<p>Access to this array will be performed by directly operating on the underlying memory area; the operation will avoid stepping into the interpreter, giving us a tremendous speed boost.</p>
			<p>In the next example, we will show the usage of typed NumPy arrays and compare them with the normal Python version.</p>
			<p>We first write a <strong class="source-inline">numpy_bench_py</strong> function that increments each element of <strong class="source-inline">py_arr</strong>. We declare the <strong class="source-inline">i</strong> index as an integer so that we avoid the <strong class="source-inline">for</strong> loop overhead, as follows:</p>
			<p class="source-code">    %%cython </p>
			<p class="source-code">    import numpy as np </p>
			<p class="source-code">    def numpy_bench_py(): </p>
			<p class="source-code">        py_arr = np.random.rand(1000) </p>
			<p class="source-code">        cdef int i </p>
			<p class="source-code">        for i in range(1000): </p>
			<p class="source-code">            py_arr[i] += 1 </p>
			<p>Then, we write the same function using the <strong class="source-inline">ndarray</strong> type. Note that after we define the <strong class="source-inline">c_arr</strong> variable using <strong class="source-inline">c_np.ndarray</strong>, we can assign to it an array from the <strong class="source-inline">numpy</strong> Python module. The code is illustrated in the following snippet:</p>
			<p class="source-code">    %%cython </p>
			<p class="source-code">    import numpy as np </p>
			<p class="source-code">    cimport numpy as c_np </p>
			<p class="source-code">    def numpy_bench_c(): </p>
			<p class="source-code">        cdef c_np.ndarray[double, ndim=1] c_arr </p>
			<p class="source-code">        c_arr = np.random.rand(1000) </p>
			<p class="source-code">        cdef int i</p>
			<p class="source-code">        for i in range(1000): </p>
			<p class="source-code">           c_arr[i] += 1 </p>
			<p>We can time <a id="_idIndexMarker311"/>the results using <strong class="source-inline">timeit</strong>, and we can see here how the typed version<a id="_idIndexMarker312"/> is 50 times faster:</p>
			<p class="source-code">    %timeit numpy_bench_c() </p>
			<p class="source-code">    100000 loops, best of 3: 11.5 us per loop </p>
			<p class="source-code">    %timeit numpy_bench_py() </p>
			<p class="source-code">    1000 loops, best of 3: 603 us per loop </p>
			<p>This gives us a significant speedup from the Python code!</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor079"/>Working with typed memoryviews</h2>
			<p>C and NumPy arrays, as well as the built-in <strong class="source-inline">bytes</strong>, <strong class="source-inline">bytearray</strong>, and <strong class="source-inline">array.array</strong> objects, are similar <a id="_idIndexMarker313"/>in the sense that they all operate on a <a id="_idIndexMarker314"/>contiguous memory area (also called a memory <em class="italic">buffer</em>). Cython provides<a id="_idIndexMarker315"/> a universal interface—a <em class="italic">typed memoryview</em>—that unifies and simplifies access to all these data types.</p>
			<p>A <strong class="bold">memoryview</strong> is an object that maintains a reference on a specific memory area. It doesn't actually own the <a id="_idIndexMarker316"/>memory, but it can read and change its contents; in other words, it is a <em class="italic">view</em> of the underlying data. Memoryviews can be defined using a special syntax. For example, we can define a memoryview of <strong class="source-inline">int</strong> and a 2D memoryview of <strong class="source-inline">double</strong> in the following way:</p>
			<p class="source-code">    cdef int[:] a </p>
			<p class="source-code">    cdef double[:, :] b </p>
			<p>The same syntax applies to the declaration of any type in variables, function definitions, class attributes, and so on. Any object that exposes a buffer interface (for example, NumPy arrays, <strong class="source-inline">bytes</strong>, and <strong class="source-inline">array.array</strong> objects) will be bound to the memoryview automatically. For example, we can bind the memoryview to a NumPy array using a simple variable assignment, as follows:</p>
			<p class="source-code">    import numpy as np </p>
			<p class="source-code">    cdef int[:] arr </p>
			<p class="source-code">    arr_np = np.zeros(10, dtype='int32') </p>
			<p class="source-code">    arr = arr_np # We bind the array to the memoryview </p>
			<p>It is important to note that the memoryview does not <em class="italic">own</em> the data, but it only provides a way to <em class="italic">access</em> and <em class="italic">change</em> the data it is bound to; the ownership, in this case, is left to the NumPy array. As you can see in the following example, changes made through the memoryview will act on the underlying memory area and will be reflected in the original NumPy structure (and vice versa):</p>
			<p class="source-code">    arr[2] = 1 # Changing memoryview </p>
			<p class="source-code">    print(arr_np) </p>
			<p class="source-code">    # [0 0 1 0 0 0 0 0 0 0] </p>
			<p>In a certain sense, the mechanism behind memoryviews is similar to what NumPy produces when we slice an array. As we have seen in <a href="B17499_03_Final_SS_ePub.xhtml#_idTextAnchor047"><em class="italic">Chapter 3</em></a>, <em class="italic">Fast Array Operations with NumPy, Pandas, and Xarray</em>, slicing a NumPy array does not copy the data but returns a <a id="_idIndexMarker317"/>view on the same memory area, and changes to the view will reflect<a id="_idIndexMarker318"/> on the original array.</p>
			<p>Memoryviews also support array slicing with the standard NumPy syntax, as illustrated in the following code snippet:</p>
			<p class="source-code">    cdef int[:, :, :] a </p>
			<p class="source-code">    arr[0, :, :] # Is a 2-dimensional memoryview </p>
			<p class="source-code">    arr[0, 0, :] # Is a 1-dimensional memoryview </p>
			<p class="source-code">    arr[0, 0, 0] # Is an int </p>
			<p>To copy data between one memoryview and another, you can use syntax similar to slice assignment, as shown in the following code snippet:</p>
			<p class="source-code">    import numpy as np </p>
			<p class="source-code">    cdef double[:, :] b </p>
			<p class="source-code">    cdef double[:] r </p>
			<p class="source-code">    b = np.random.rand(10, 3) </p>
			<p class="source-code">    r = np.zeros(3, dtype='float64') </p>
			<p class="source-code">    b[0, :] = r # Copy the value of r in the first row of b </p>
			<p>In the next section, we will use typed memoryviews to declare types for the arrays in our particle simulator.</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor080"/>Using a particle simulator in Cython</h1>
			<p>Now that we have <a id="_idIndexMarker319"/>a basic understanding of how Cython works, we can rewrite the <strong class="source-inline">ParticleSimulator.evolve</strong> method. Thanks <a id="_idIndexMarker320"/>to Cython, we can convert our loops in C, thus removing the overhead introduced by the Python interpreter.</p>
			<p>In <a href="B17499_03_Final_SS_ePub.xhtml#_idTextAnchor047"><em class="italic">Chapter 3</em></a>, <em class="italic">Fast Array Operations with NumPy, Pandas, and Xarray</em>, we wrote a fairly efficient version of the <strong class="source-inline">evolve</strong> method using NumPy. We can rename the old version <strong class="source-inline">evolve_numpy</strong> to differentiate it from the new version. The code is illustrated in the following snippet:</p>
			<p class="source-code">    def evolve_numpy(self, dt): </p>
			<p class="source-code">        timestep = 0.00001 </p>
			<p class="source-code">        nsteps = int(dt/timestep) </p>
			<p class="source-code">        r_i = np.array([[p.x, p.y] for p in \</p>
			<p class="source-code">            self.particles])     </p>
			<p class="source-code">        ang_speed_i = np.array([p.ang_speed for p in \</p>
			<p class="source-code">          self.particles]) </p>
			<p class="source-code">        v_i = np.empty_like(r_i) </p>
			<p class="source-code">        for i in range(nsteps): </p>
			<p class="source-code">            norm_i = np.sqrt((r_i ** 2).sum(axis=1)) </p>
			<p class="source-code">            v_i = r_i[:, [1, 0]] </p>
			<p class="source-code">            v_i[:, 0] *= -1 </p>
			<p class="source-code">            v_i /= norm_i[:, np.newaxis]         </p>
			<p class="source-code">            d_i = timestep * ang_speed_i[:, np.newaxis] * \</p>
			<p class="source-code">                v_i </p>
			<p class="source-code">            r_i += d_i </p>
			<p class="source-code">        for i, p in enumerate(self.particles): </p>
			<p class="source-code">            p.x, p.y = r_i[i] </p>
			<p>We want to convert this code to Cython. Our strategy will be to take advantage of the fast indexing operations by removing the NumPy array broadcasting, thus reverting to an indexing-based algorithm. Since Cython generates efficient C code, we are free to use as many loops as we like without any performance penalty.</p>
			<p>As a design choice, we can decide to encapsulate the loop in a function that we will rewrite in a Cython module called <strong class="source-inline">cevolve.pyx</strong>. The module will contain a single Python function, <strong class="source-inline">c_evolve</strong>, that will take the particle positions, angular velocities, timestep, and the number of steps as input.</p>
			<p>At first, we are <a id="_idIndexMarker321"/>not adding typing information; we just want <a id="_idIndexMarker322"/>to isolate the function and ensure that we can compile our module without errors. The code is illustrated in the following snippet:</p>
			<p class="source-code">    # file: simul.py </p>
			<p class="source-code">    def evolve_cython(self, dt): </p>
			<p class="source-code">        timestep = 0.00001 </p>
			<p class="source-code">        nsteps = int(dt/timestep) </p>
			<p class="source-code">    </p>
			<p class="source-code">        r_i = np.array([[p.x, p.y] for p in \</p>
			<p class="source-code">            self.particles])     </p>
			<p class="source-code">        ang_speed_i = np.array([p.ang_speed for p in \</p>
			<p class="source-code">            self.particles]) </p>
			<p class="source-code">    </p>
			<p class="source-code">        c_evolve(r_i, ang_speed_i, timestep, nsteps) </p>
			<p class="source-code">    </p>
			<p class="source-code">        for i, p in enumerate(self.particles): </p>
			<p class="source-code">            p.x, p.y = r_i[i] </p>
			<p class="source-code">    </p>
			<p class="source-code">    # file: cevolve.pyx </p>
			<p class="source-code">    import numpy as np </p>
			<p class="source-code">    </p>
			<p class="source-code">    def c_evolve(r_i, ang_speed_i, timestep, nsteps): </p>
			<p class="source-code">        v_i = np.empty_like(r_i) </p>
			<p class="source-code">    </p>
			<p class="source-code">        for i in range(nsteps): </p>
			<p class="source-code">            norm_i = np.sqrt((r_i ** 2).sum(axis=1)) </p>
			<p class="source-code">    </p>
			<p class="source-code">            v_i = r_i[:, [1, 0]] </p>
			<p class="source-code">            v_i[:, 0] *= -1 </p>
			<p class="source-code">            v_i /= norm_i[:, np.newaxis]         </p>
			<p class="source-code">     </p>
			<p class="source-code">            d_i = timestep * ang_speed_i[:, np.newaxis] * </p>
			<p class="source-code">                v_i </p>
			<p class="source-code">    </p>
			<p class="source-code">            r_i += d_i </p>
			<p>Note that we don't need a return value for <strong class="source-inline">c_evolve</strong> as values are updated in place in the <strong class="source-inline">r_i</strong> array. We can <a id="_idIndexMarker323"/>benchmark the untyped Cython version <a id="_idIndexMarker324"/>against the old NumPy version by slightly changing our <strong class="source-inline">benchmark</strong> function, as follows:</p>
			<p class="source-code">    def benchmark(npart=100, method='python'): </p>
			<p class="source-code">        particles = [</p>
			<p class="source-code">                     Particle(uniform(-1.0, 1.0),</p>
			<p class="source-code">                              uniform(-1.0, 1.0),</p>
			<p class="source-code">                              uniform(-1.0, 1.0)) </p>
			<p class="source-code">                              for i in range(npart)</p>
			<p class="source-code">            ] </p>
			<p class="source-code">        simulator = ParticleSimulator(particles) </p>
			<p class="source-code">        if method=='python': </p>
			<p class="source-code">            simulator.evolve_python(0.1)</p>
			<p class="source-code">        elif method == 'cython': </p>
			<p class="source-code">            simulator.evolve_cython(0.1) </p>
			<p class="source-code">        elif method == 'numpy': </p>
			<p class="source-code">            simulator.evolve_numpy(0.1) </p>
			<p>We can time the different versions in an IPython shell, as follows:</p>
			<p class="source-code">    %timeit benchmark(100, 'cython') </p>
			<p class="source-code">    1 loops, best of 3: 401 ms per loop </p>
			<p class="source-code">    %timeit benchmark(100, 'numpy') </p>
			<p class="source-code">    1 loops, best of 3: 413 ms per loop </p>
			<p>The two versions have the same speed. Compiling the Cython module without static typing doesn't have any advantage over pure Python. The next step is to declare the type of all the important variables so that Cython can perform its optimizations.</p>
			<p>We can start adding types to the function arguments and see how the performance changes. We can declare the arrays as typed memoryviews containing <strong class="source-inline">double</strong> values. It's worth mentioning that if we pass an array of the <strong class="source-inline">int</strong> or <strong class="source-inline">float32</strong> type, the casting won't happen automatically and we will get an error. The code is illustrated in the following snippet:</p>
			<p class="source-code">    def c_evolve(double[:, :] r_i,</p>
			<p class="source-code">                 double[:] ang_speed_i,</p>
			<p class="source-code">                 double timestep,</p>
			<p class="source-code">                 int nsteps): </p>
			<p>At this point, we can rewrite the loops over the particles and timesteps. We can declare the <strong class="source-inline">i</strong> and <strong class="source-inline">j</strong> iteration indices and the <strong class="source-inline">nparticles</strong> particle number as <strong class="source-inline">int</strong>, as follows:</p>
			<p class="source-code">    cdef int i, j </p>
			<p class="source-code">    cdef int nparticles = r_i.shape[0] </p>
			<p>The algorithm is very <a id="_idIndexMarker325"/>similar to the pure Python version; we <a id="_idIndexMarker326"/>iterate over the particles and timesteps, and we compute the velocity and displacement vectors for each particle coordinate using the following code:</p>
			<p class="source-code">      for i in range(nsteps): </p>
			<p class="source-code">          for j in range(nparticles): </p>
			<p class="source-code">              x = r_i[j, 0] </p>
			<p class="source-code">              y = r_i[j, 1] </p>
			<p class="source-code">              ang_speed = ang_speed_i[j] </p>
			<p class="source-code">    </p>
			<p class="source-code">              norm = sqrt(x ** 2 + y ** 2) </p>
			<p class="source-code">    </p>
			<p class="source-code">              vx = (-y)/norm </p>
			<p class="source-code">              vy = x/norm </p>
			<p class="source-code">    </p>
			<p class="source-code">              dx = timestep * ang_speed * vx </p>
			<p class="source-code">              dy = timestep * ang_speed * vy </p>
			<p class="source-code">    </p>
			<p class="source-code">              r_i[j, 0] += dx </p>
			<p class="source-code">              r_i[j, 1] += dy </p>
			<p>In the preceding code snippet, we added the <strong class="source-inline">x</strong>, <strong class="source-inline">y</strong>, <strong class="source-inline">ang_speed</strong>, <strong class="source-inline">norm</strong>, <strong class="source-inline">vx</strong>, <strong class="source-inline">vy</strong>, <strong class="source-inline">dx</strong>, and <strong class="source-inline">dy</strong> variables. To avoid the Python interpreter overhead, we have to declare them with their corresponding types at the beginning of the function, as follows:</p>
			<p class="source-code">    cdef double norm, x, y, vx, vy, dx, dy, ang_speed </p>
			<p>We also used a function called <strong class="source-inline">sqrt</strong> to calculate the norm. If we use the <strong class="source-inline">sqrt</strong> function present in the <strong class="source-inline">math</strong> module or the one in <strong class="source-inline">numpy</strong>, we will again include a slow Python function in our <a id="_idIndexMarker327"/>critical loop, thus killing our performance. A fast <strong class="source-inline">sqrt</strong> function is <a id="_idIndexMarker328"/>available in the standard C library, already wrapped in the <strong class="source-inline">libc.math</strong> Cython module. Run the following code to import it:</p>
			<p class="source-code">    from libc.math cimport sqrt </p>
			<p>We can rerun our benchmark to assess our improvements, as follows:</p>
			<p class="source-code">    In [4]: %timeit benchmark(100, 'cython') </p>
			<p class="source-code">    100 loops, best of 3: 13.4 ms per loop </p>
			<p class="source-code">    In [5]: %timeit benchmark(100, 'numpy') </p>
			<p class="source-code">    1 loops, best of 3: 429 ms per loop </p>
			<p>For small particle numbers, the speedup is massive as we obtained a 40 times faster performance over the previous version. However, we should also try to test the performance scaling with a larger number of particles, as follows:</p>
			<p class="source-code">    In [2]: %timeit benchmark(1000, 'cython') </p>
			<p class="source-code">    10 loops, best of 3: 134 ms per loop </p>
			<p class="source-code">    In [3]: %timeit benchmark(1000, 'numpy') </p>
			<p class="source-code">    1 loops, best of 3: 877 ms per loop</p>
			<p>As we increase the number of particles, the two versions get closer in speed. By increasing the particle size to <strong class="source-inline">1000</strong>, we already decreased our speedup to a more modest 6 times. This is likely because, as we increase the number of particles, the Python <strong class="source-inline">for</strong> loop <a id="_idIndexMarker329"/>overhead becomes less and less significant <a id="_idIndexMarker330"/>compared to the speed of other operations.</p>
			<p>The topic of benchmarking naturally transitions us to our next section: profiling.</p>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor081"/>Profiling Cython</h1>
			<p>Cython provides a feature called <em class="italic">annotated view</em> that helps find which lines are executed in the Python interpreter <a id="_idIndexMarker331"/>and which are good candidates for ulterior optimizations. We can <a id="_idIndexMarker332"/>turn this feature on by compiling <a id="_idIndexMarker333"/>a Cython file with the <strong class="source-inline">-a</strong> option. In this way, Cython will generate a <strong class="bold">HyperText Markup Language</strong> (<strong class="bold">HTML</strong>) file containing our code annotated with some useful information. The usage of the <strong class="source-inline">-a</strong> option is shown here:</p>
			<p class="source-code">$ cython -a cevolve.pyx</p>
			<p class="source-code">$ firefox cevolve.html</p>
			<p>The HTML file displayed in the following screenshot shows our Cython file line by line:</p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/B17499_Figure_4.2.jpg" alt="Figure 4.2 – Generated HTML containing annotated code " width="883" height="763"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.2 – Generated HTML containing annotated code</p>
			<p>Each line in the source code can appear in different shades of yellow. A more intense color corresponds to more interpreter-related calls, while white lines are translated to regular C code. Since interpreter calls substantially slow down execution, the objective is to make <a id="_idIndexMarker334"/>the function body as white as possible. By clicking on any of the lines, we can inspect the code generated by the Cython compiler. For example, the <strong class="source-inline">v_y = x/norm</strong> line checks that the norm is not <strong class="source-inline">0</strong> and raises a <strong class="source-inline">ZeroDivisionError</strong> error if the condition is not verified. The <strong class="source-inline">x = r_i[j, 0]</strong> line shows that Cython checks whether the indexes are within the bounds of the array. You may have noted that the last line is of a very intense color; by inspecting the code, we can see that this is actually a glitch—the code refers to a boilerplate related to the end of the function.</p>
			<p>Cython can shut down checks such as division by zero so that it can remove those extra interpreter-related <a id="_idIndexMarker335"/>calls; this is usually accomplished through compiler directives. There are a few different ways to add compiler directives, as outlined here:</p>
			<ul>
				<li>Using a decorator or a context manager</li>
				<li>Using a comment at the beginning of the file</li>
				<li>Using the Cython command-line options</li>
			</ul>
			<p>For a complete <a id="_idIndexMarker336"/>list of the Cython compiler directives, you can refer to the official documentation at <a href="http://docs.cython.org/src/reference/compilation.html#compiler-directives">http://docs.cython.org/src/reference/compilation.html#compiler-directives</a>.</p>
			<p>For example, to disable bounds checking for arrays, it is sufficient to decorate a function with <strong class="source-inline">cython.boundscheck</strong>, in the following way:</p>
			<p class="source-code">    cimport cython </p>
			<p class="source-code">    @cython.boundscheck(False) </p>
			<p class="source-code">    def myfunction(): </p>
			<p class="source-code">        # Code here </p>
			<p>Alternatively, we can use <strong class="source-inline">cython.boundscheck</strong> to wrap a block of code into a context manager, as follows:</p>
			<p class="source-code">    with cython.boundscheck(False): </p>
			<p class="source-code">        # Code here </p>
			<p>If we want to disable bounds checking for a whole module, we can add the following line of code at the beginning of the file:</p>
			<p class="source-code">    # cython: boundscheck=False </p>
			<p>To alter the directives with the command-line options, you can use the <strong class="source-inline">-X</strong> option, as follows:</p>
			<p class="source-code">$ cython -X boundscheck=True</p>
			<p>To disable the extra checks in our <strong class="source-inline">c_evolve</strong> function, we can disable the <strong class="source-inline">boundscheck</strong> directive and enable <strong class="source-inline">cdivision</strong> (this prevents checks for <strong class="source-inline">ZeroDivisionError</strong>), as in the following code snippet:</p>
			<p class="source-code">    cimport cython </p>
			<p class="source-code">    @cython.boundscheck(False) </p>
			<p class="source-code">    @cython.cdivision(True) </p>
			<p class="source-code">    def c_evolve(double[:, :] r_i,double[:] ang_speed_i, \</p>
			<p class="source-code">                 double timestep,int nsteps): </p>
			<p>If we look at the annotated view again, the loop body has become completely white—we removed all <a id="_idIndexMarker337"/>traces of the interpreter from the inner loop. In order to recompile, just type <strong class="source-inline">python setup.py build_ext --inplace</strong> again. By running the benchmark, however, we note that we didn't obtain a performance improvement, suggesting that those checks are not part of the bottleneck, as we can see here:</p>
			<p class="source-code">    In [3]: %timeit benchmark(100, 'cython') </p>
			<p class="source-code">    100 loops, best of 3: 13.4 ms per loop </p>
			<p>Another way to profile Cython code is using the <strong class="source-inline">cProfile</strong> module. As an example, we can write a simple function that calculates the Chebyshev distance between coordinate arrays. Create a <strong class="source-inline">cheb.py</strong> file, as follows:</p>
			<p class="source-code">    import numpy as np </p>
			<p class="source-code">    from distance import chebyshev </p>
			<p class="source-code">    def benchmark(): </p>
			<p class="source-code">        a = np.random.rand(100, 2) </p>
			<p class="source-code">        b = np.random.rand(100, 2) </p>
			<p class="source-code">        for x1, y1 in a: </p>
			<p class="source-code">            for x2, y2 in b: </p>
			<p class="source-code">                chebyshev(x1, x2, y1, y2) </p>
			<p>If we try profiling this script as-is, we won't get any statistics regarding the functions that we <a id="_idIndexMarker338"/>implemented in Cython. If we want to collect profiling information for the <strong class="source-inline">max</strong> and <strong class="source-inline">min</strong> functions, we need to add the <strong class="source-inline">profile=True</strong> option to the <strong class="source-inline">mathlib.pyx</strong> file, as shown in the following code snippet:</p>
			<p class="source-code">    # cython: profile=True </p>
			<p class="source-code">    cdef int max(int a, int b): </p>
			<p class="source-code">        # Code here </p>
			<p>We can now profile our script with <strong class="source-inline">%prun</strong> using IPython, as follows:</p>
			<p class="source-code">    import cheb </p>
			<p class="source-code">    %prun cheb.benchmark() </p>
			<p class="source-code"># Output:</p>
			<p class="source-code">2000005 function calls in 2.066 seconds </p>
			<p class="source-code">  Ordered by: internal time </p>
			<p class="source-code">  ncalls tottime percall cumtime percall </p>
			<p class="source-code">  filename:lineno(function) </p>
			<p class="source-code">       1   1.664   1.664   2.066   2.066 </p>
			<p class="source-code"> cheb.py:4(benchmark) </p>
			<p class="source-code"> 1000000   0.351   0.000   0.401   0.000</p>
			<p class="source-code"> {distance.chebyshev} </p>
			<p class="source-code"> 1000000   0.050   0.000   0.050   0.000 mathlib.pyx:2(max) </p>
			<p class="source-code">       2   0.000   0.000   0.000   0.000 {method 'rand' of </p>
			<p class="source-code">'mtrand.RandomState' objects} </p>
			<p class="source-code">       1   0.000   0.000   2.066   2.066 </p>
			<p class="source-code"> &lt;string&gt;:1(&lt;module&gt;) </p>
			<p class="source-code">       1   0.000   0.000   0.000   0.000 {method 'disable' </p>
			<p class="source-code"> of        '_lsprof.Profiler' objects} </p>
			<p>From the output, we can see that the <strong class="source-inline">max</strong> function is present and is not a bottleneck. Most of the <a id="_idIndexMarker339"/>time seems to be spent in the <strong class="source-inline">benchmark</strong> function, meaning that the bottleneck is likely a pure Python <strong class="source-inline">for</strong> loop. In this case, the best strategy will be rewriting the loop in NumPy or porting the code to Cython.</p>
			<p>One feature in Python that many users enjoy is the ability to work with Jupyter Notebooks. When working with Cython, you don't have to give up on this feature. In the next and last section of this chapter, we will see how we can use Cython with Jupyter.</p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor082"/>Using Cython with Jupyter</h1>
			<p>Optimizing Cython code requires substantial trial and error. Fortunately, Cython tools can be conveniently <a id="_idIndexMarker340"/>accessed through Jupyter Notebooks for <a id="_idIndexMarker341"/>a more streamlined and integrated experience.</p>
			<p>You can launch a notebook session by typing <strong class="source-inline">jupyter notebook</strong> in the command line, and you can load the Cython magic by typing <strong class="source-inline">%load_ext cython</strong> in a cell.</p>
			<p>As mentioned earlier, the <strong class="source-inline">%%cython</strong> magic can be used to compile and load the Cython code inside the current session. As an example, we may copy the contents of the <strong class="source-inline">cheb.py</strong> file into a notebook cell, like this:</p>
			<p class="source-code">    %%cython</p>
			<p class="source-code">    import numpy as np</p>
			<p class="source-code">    cdef int max(int a, int b):</p>
			<p class="source-code">        return a if a &gt; b else b</p>
			<p class="source-code">    cdef int chebyshev(int x1, int y1, int x2, int y2):</p>
			<p class="source-code">        return max(abs(x1 - x2), abs(y1 - y2))</p>
			<p class="source-code">    def c_benchmark():</p>
			<p class="source-code">        a = np.random.rand(1000, 2)</p>
			<p class="source-code">        b = np.random.rand(1000, 2)</p>
			<p class="source-code">        for x1, y1 in a:</p>
			<p class="source-code">           for x2, y2 in b:</p>
			<p class="source-code">               chebyshev(x1, x2, y1, y2)</p>
			<p>A useful feature <a id="_idIndexMarker342"/>of the <strong class="source-inline">%%cython</strong> magic is the <strong class="source-inline">-a</strong> option that will <a id="_idIndexMarker343"/>compile the code and produce an annotated view (just as with the <strong class="source-inline">-a</strong> command-line option) of the source code directly in the notebook, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B17499_Figure_4.3.jpg" alt="Figure 4.3 – Generated annotated code " width="661" height="731"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.3 – Generated annotated code</p>
			<p>This allows you <a id="_idIndexMarker344"/>to quickly test different versions of your code and use <a id="_idIndexMarker345"/>the other integrated tools available in Jupyter. For example, we can time and profile the code (provided that we activate the profile directive in the cell) in the same session using tools such as <strong class="source-inline">%prun</strong> and <strong class="source-inline">%timeit</strong>. We can also inspect the profiling results by taking advantage of the <strong class="source-inline">%prun</strong> magic, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/B17499_Figure_4.4.jpg" alt="Figure 4.4 – Profiling output " width="1025" height="349"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.4 – Profiling output</p>
			<p>It is also possible to use the <strong class="source-inline">line_profiler</strong> tool we discussed in <a href="B17499_01_Final_SS_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Benchmarking and Profiling</em>, directly in the notebook. To support line annotations, it is necessary to do the following things:</p>
			<ul>
				<li>Enable the <strong class="source-inline">linetrace=True</strong> and <strong class="source-inline">binding=True</strong> compiler directives.</li>
				<li>Enable the <strong class="source-inline">CYTHON_TRACE=1</strong> flag at compile time.</li>
			</ul>
			<p>This can be <a id="_idIndexMarker346"/>easily accomplished by adding the respective <a id="_idIndexMarker347"/>arguments to the <strong class="source-inline">%%cython</strong> magic and by setting the compiler directives, as shown in the following code snippet:</p>
			<p class="source-code"><strong class="bold">    %%cython -a -f -c=-DCYTHON_TRACE=1</strong></p>
			<p class="source-code"><strong class="bold">    # cython: linetrace=True</strong></p>
			<p class="source-code"><strong class="bold">    # cython: binding=True</strong></p>
			<p class="source-code">    import numpy as np</p>
			<p class="source-code">    cdef int max(int a, int b):</p>
			<p class="source-code">        return a if a &gt; b else b</p>
			<p class="source-code">    def chebyshev(int x1, int y1, int x2, int y2):</p>
			<p class="source-code">        return max(abs(x1 - x2), abs(y1 - y2))</p>
			<p class="source-code">    def c_benchmark():</p>
			<p class="source-code">        a = np.random.rand(1000, 2)</p>
			<p class="source-code">        b = np.random.rand(1000, 2)</p>
			<p class="source-code">    </p>
			<p class="source-code">        for x1, y1 in a:</p>
			<p class="source-code">            for x2, y2 in b:</p>
			<p class="source-code">                chebyshev(x1, x2, y1, y2)</p>
			<p>Once the code <a id="_idIndexMarker348"/>is instrumented, we can install the <strong class="source-inline">line_profiler</strong> package <a id="_idIndexMarker349"/>via <strong class="source-inline">pip install line_profiler</strong> and profile using the <strong class="source-inline">%lprun</strong> magic, as follows:</p>
			<p class="source-code">%load_ext line_profiler</p>
			<p class="source-code">%lprun -f c_benchmark c_benchmark()</p>
			<p class="source-code"># Output:</p>
			<p class="source-code">Timer unit: 1e-06 s</p>
			<p class="source-code">Total time: 2.322 s</p>
			<p class="source-code">File: /home/gabriele/.cache/ipython/cython/_cython_</p>
			<p class="source-code">magic_18ad8204e9d29650f3b09feb48ab0f44.pyx</p>
			<p class="source-code">Function: c_benchmark at line 11</p>
			<p class="source-code">Line #      Hits         Time  Per Hit   % Time  Line Contents</p>
			<p class="source-code">==============================================================</p>
			<p class="source-code">    11                                           def </p>
			<p class="source-code">c_benchmark():</p>
			<p class="source-code">    12         1          226    226.0      0.0      a = </p>
			<p class="source-code">np.random.rand...</p>
			<p class="source-code">    13         1           67     67.0      0.0      b = </p>
			<p class="source-code">np.random.rand...    </p>
			<p class="source-code">    14                                               </p>
			<p class="source-code">    15      1001         1715      1.7      0.1      for </p>
			<p class="source-code">x1, y1 in a:</p>
			<p class="source-code">    16   1001000      1299792      1.3     56.0          </p>
			<p class="source-code">for x2, y2 in b:</p>
			<p class="source-code">    17   1000000      1020203      1.0     43.9              </p>
			<p class="source-code">chebyshev...</p>
			<p>As you can see, a good <a id="_idIndexMarker350"/>chunk of time is spent in <em class="italic">line 16</em>, which is a pure <a id="_idIndexMarker351"/>Python loop and a good candidate for further optimization.</p>
			<p>The tools available in Jupyter Notebook allow for a fast edit-compile-test cycle so that you can quickly prototype and save time when testing different solutions.</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor083"/>Summary</h1>
			<p>Cython is a tool that bridges the convenience of Python with the speed of C. Compared to C bindings, Cython programs are much easier to maintain and debug, thanks to the tight integration and compatibility with Python and the availability of excellent tools.</p>
			<p>In this chapter, we introduced the basics of the Cython language and how to make our programs faster by adding static types to our variables and functions. We also learned how to work with C arrays, NumPy arrays, and memoryviews.</p>
			<p>We optimized our particle simulator by rewriting the critical <strong class="source-inline">evolve</strong> function, obtaining a tremendous speed gain. Finally, we learned how to use the annotated view to spot hard-to-find interpreter-related calls and how to enable <strong class="source-inline">cProfile</strong> support in Cython. Also, we learned how to take advantage of the Jupyter Notebook for integrated profiling and analysis of Cython code.</p>
			<p>All these tasks provide us with the high level of flexibility, which we already enjoy with Python, when working with Cython, while allowing our programs to be more optimized with low-level C code.</p>
			<p>In the next chapter, we will explore other tools that can generate fast machine code on the fly, without requiring the compilation of our code to C <strong class="bold">ahead of time</strong> (<strong class="bold">AOT</strong>).</p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor084"/>Questions</h1>
			<ol>
				<li value="1">What is the benefit of implementing static types?</li>
				<li>What is the benefit of a memoryview?</li>
				<li>Which tools for profiling Cython were introduced in this chapter?</li>
			</ol>
		</div>
	</div>
</div>
</body></html>