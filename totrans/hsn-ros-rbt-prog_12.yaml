- en: SLAM for Robot Navigation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器人导航的 SLAM
- en: In this chapter, you will deep dive into robot navigation, a ubiquitous task
    in robotics engineering. Typical use cases include self-driving cars and transporting
    materials in a factory. You will find that the map we generated previously by
    applying **SLAM (Simultaneous localization and mapping)** is used for path planning
    along the way. Given an initial pose, the robot will travel along the optimal
    path and should be capable of reacting to dynamic events, that is, it should be
    able to avoid the obstacles (static or dynamic) that appeared after the map was
    built.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将深入了解机器人导航，这是机器人工程中的一个普遍任务。典型用例包括自动驾驶汽车和工厂中的物料运输。您会发现我们之前通过应用 **SLAM（同时定位与建图）**
    生成的地图在路径规划过程中被使用。给定一个初始姿态，机器人将沿着最佳路径移动，并且应该能够对动态事件做出反应，也就是说，它应该能够避开在地图构建后出现的障碍物（静态或动态）。
- en: This chapter is a natural extension of the previous one. In the previous chapter,
    you gained a practical understanding of SLAM and navigation, and you did that
    inside the Gazebo simulator using a virtual model of GoPiGo3\. Now, you are ready
    to complete the exercise again with a physical robot. By doing so, you will discover
    how many details and practical questions arise when you complete a robotic task
    in a real environment. Simulation is a good start, but the real proof that your
    robot performs as expected is by executing the task in an actual scenario.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是前一章的自然延伸。在前一章中，您获得了对 SLAM 和导航的实践理解，并且您是在 Gazebo 模拟器中使用 GoPiGo3 的虚拟模型来做到这一点的。现在，您准备好再次使用物理机器人完成练习。通过这样做，您将发现当您在真实环境中完成机器人任务时会出现多少细节和实际问题。模拟是一个好的开始，但真正证明您的机器人按预期运行的证据是在实际场景中执行任务。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Preparing **Laser Distance Sensor** (**LDS**) for your robot
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为您的机器人准备**激光测距传感器**（**LDS**）
- en: Creating a navigation application in ROS, including explanations about common
    algorithms that are used in navigation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 ROS 中创建导航应用程序，包括关于在导航中使用的常见算法的解释
- en: Practicing navigation with GoPiGo3
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GoPiGo3 练习导航
- en: The main sensor for the navigation task will be the low-cost LDS by EAI model
    YDLIDAR X4 ([https://www.aliexpress.com/item/32908156152.html](https://es.aliexpress.com/item/32908156152.html)),
    which we've simulated already within Gazebo. We will dedicate a large portion
    of this chapter to learning how to set up the LDS, understand how it works, and
    what practical information it provides to the robot.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 导航任务的主要传感器将是低成本的 LDS，由 EAI 模型 YDLIDAR X4 提供（[https://www.aliexpress.com/item/32908156152.html](https://es.aliexpress.com/item/32908156152.html)），我们已经在
    Gazebo 中对其进行了模拟。我们将在本章中投入大量篇幅来学习如何设置 LDS，了解其工作原理以及它为机器人提供哪些实用信息。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will make use of the code located in the `Chapter9_GoPiGo_SLAM` folder
    ([https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter9_GoPiGo_SLAM](https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter9_GoPiGo3_SLAM)).
    Copy its files to the ROS workspace so that they''re available and leave the rest
    outside the `src` folder. This way, you will have a cleaner ROS environment:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用位于 `Chapter9_GoPiGo_SLAM` 文件夹中的代码（[https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter9_GoPiGo_SLAM](https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter9_GoPiGo3_SLAM)）。将其文件复制到
    ROS 工作空间，以便它们可用，并将其余部分放在 `src` 文件夹之外。这样，您将拥有一个更干净的 ROS 环境：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The code in the aforementioned folder contains two new ROS packages, each one
    located within a folder that has the same name:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 上述文件夹中的代码包含两个新的 ROS 软件包，每个软件包都位于一个具有相同名称的文件夹中：
- en: '`ydlidar`, the officially supported ROS package for the selected LDS.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ydlidar`，为所选 LDS 官方支持的 ROS 软件包。'
- en: '`gopigo3_navigation`, the top-level package for performing navigation with
    GoPiGo3.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gopigo3_navigation`，用于执行 GoPiGo3 导航的最高级软件包。'
- en: You will use both on the laptop environment, but in the robot – that is, the
    Raspberry Pi – you will only need `ydlidar` since the computationally expensive
    task of navigation is recommended to be run on the laptop. This way, GoPiGo3 will
    receive the drive command through the familiar `cmd_vel` topic and publish a 360°
    range scan from the LDS through the `/scan` topic.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在笔记本电脑环境中使用这两个软件包，但在机器人（即 Raspberry Pi）中，您只需要 `ydlidar`，因为建议将计算密集型的导航任务在笔记本电脑上运行。这样，GoPiGo3
    将通过熟悉的 `cmd_vel` 主题接收驱动命令，并通过 `/scan` 主题发布来自 LDS 的 360° 扫描。
- en: 'As usual, you need to rebuild the workspace separately, both for the robot
    and the laptop:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常一样，您需要分别重新构建机器人和工作站的空间，包括机器人和笔记本电脑：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Check that the packages have been installed correctly by selecting them and
    listing the files:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 通过选择它们并列出文件来检查包是否已正确安装：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next, we have to point the ROS master to the robot.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须将 ROS 主指向机器人。
- en: Setting the ROS master to be in the robot
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 ROS 主设置为在机器人上
- en: 'Since you''ll be working with the physical robot once more, you need to reconfigure
    the ROS master URI so that it points to GoPiGo3\. So that your laptop reflects
    such a configuration, open your local `.bashrc` file and uncomment the line at
    the end that specifies what URL to point to in order to find the ROS master:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您将再次与物理机器人一起工作，您需要重新配置 ROS 主 URI，使其指向 GoPiGo3。这样，您的笔记本电脑才能反映这种配置，打开您本地的 `.bashrc`
    文件，取消注释末尾指定要指向以找到 ROS 主的 URL 的行：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Close any open Terminals, open a new one, and check the `ROS_MASTER_URI` variable:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭任何打开的终端，打开一个新的终端，并检查 `ROS_MASTER_URI` 变量：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You should find that the environment variable has reverted to the default server
    (localhost) and default port (`11311`). Now, we are ready to switch to the virtual
    robot. If, for some reason, `gopigo3.local` does not resolve the robot IP, set
    up its IPv4 address directly. You can get it from the robot OS like so:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该会发现环境变量已恢复到默认服务器（localhost）和默认端口（`11311`）。现在，我们准备好切换到虚拟机器人。如果由于某种原因，`gopigo3.local`
    无法解析机器人 IP，请直接设置其 IPv4 地址。您可以从机器人操作系统中获得它，如下所示：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, in the `.bashrc` file, modify the following line accordingly:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 `.bashrc` 文件中，相应地修改以下行：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Close the Terminal on your laptop and open a new one so that the configuration
    takes effect. Then, check for the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭笔记本电脑上的终端，打开一个新的终端，以便配置生效。然后，检查以下内容：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, we can get familiar with our new sensor.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以熟悉我们的新传感器。
- en: Preparing an LDS for your robot
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为您的机器人准备一个 LDS
- en: 'Before you begin, you should take some time to review all the documentation
    provided by the manufacturer EAI. You can find all the resources at [http://www.ydlidar.com/download](http://www.ydlidar.com/download).
    Pay special attention to the following items:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，您应该花些时间回顾一下制造商 EAI 提供的所有文档。您可以在 [http://www.ydlidar.com/download](http://www.ydlidar.com/download)
    找到所有资源。请特别注意以下项目：
- en: The YDLIDAR X4 user manual, to get familiar with the hardware and install it
    safely with your robot.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了熟悉硬件并安全地将其与您的机器人一起安装，请参阅 YDLIDAR X4 用户手册。
- en: The YDLIDAR X4 ROS manual, located within the compressed `ROS.zip` file. The
    `ros` folder inside corresponds to the ROS package, but you should clone it from
    GitHub to make sure you get the latest version and stay updated. Follow the instructions
    at [https://github.com/EAIBOT/ydlidar](https://github.com/EAIBOT/ydlidar) to get
    the most recent version of the code.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 位于压缩文件 `ROS.zip` 内的 YDLIDAR X4 ROS 手册。`ros` 文件夹对应于 ROS 包，但您应该从 GitHub 克隆它以确保您获得最新版本并保持更新。按照
    [https://github.com/EAIBOT/ydlidar](https://github.com/EAIBOT/ydlidar) 中的说明获取代码的最新版本。
- en: EAI has removed** CAD (**short for **Computer-Aided Design)** models from the
    download page.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: EAI 已从下载页面移除了**CAD**（即**计算机辅助设计**）模型。
- en: The YDLIDAR X4 development manual, which describes the communication protocol
    so that you can build your own driver to control the device.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YDLIDAR X4 开发手册，它描述了通信协议，以便您可以构建自己的驱动程序来控制设备。
- en: Now, you are ready to get started with the hardware.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经准备好开始使用硬件了。
- en: Setting up YDLIDAR
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 YDLIDAR
- en: 'Follow the instructions provided in the user manual to physically connect the
    device to your laptop or to the robot. The following screenshot shows what it
    looks like once the sensor itself has been wired to the control board via the
    set of five colored cables:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 按照用户手册中的说明，将设备物理连接到您的笔记本电脑或机器人。以下截图显示了传感器本身通过一组五色电缆连接到控制板后的样子：
- en: '![](img/24067c30-5a0b-49fa-8260-a9c9115d8499.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/24067c30-5a0b-49fa-8260-a9c9115d8499.png)'
- en: Although the software instructions are also provided in the manual, we will
    list all the steps here since they refer to the core integration with ROS. First,
    we will integrate with the laptop, and then with the Raspberry Pi of the robot.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然软件说明也包含在手册中，但我们将在这里列出所有步骤，因为它们涉及与 ROS 的核心集成。首先，我们将与笔记本电脑集成，然后与机器人的 Raspberry
    Pi 集成。
- en: Integrating with the remote PC
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与远程 PC 集成
- en: 'As with any other hardware we integrate with ROS, we follow the standard procedure
    of cloning the package supplied by the manufacturer and building it with our workspace:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们与其他任何与ROS集成的硬件一样，我们遵循克隆制造商提供的包并使用我们的工作空间构建的标准程序：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: By running `catkin_make`, the `ydlidar_client` and  `ydlidar_node` nodes will
    be available.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行`catkin_make`，`ydlidar_client`和`ydlidar_node`节点将可用。
- en: This code is also bundled with the rest of the YDLIDAR models at [https://github.com/YDLIDAR/ydlidar_ros](https://github.com/YDLIDAR/ydlidar_ros).
    For a specific model, you just have to select the corresponding branch, X4\. In
    our case, this is `git clone https://github.com/YDLIDAR/ydlidar_ros -b X4 --single-branch`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码也包含在YDLIDAR模型的其余部分中，在[https://github.com/YDLIDAR/ydlidar_ros](https://github.com/YDLIDAR/ydlidar_ros)。对于特定型号，你只需选择相应的分支，X4。在我们的情况下，这是`git
    clone https://github.com/YDLIDAR/ydlidar_ros -b X4 --single-branch`。
- en: 'After connecting X4 to a USB port of the laptop, change the permissions in
    order to access the new LDS:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在将X4连接到笔记本电脑的USB端口后，更改权限以访问新的LDS：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding command assumes that your user is `ubuntu`. If it isn''t, replace
    it with your actual user. Then, initiate the device:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令假设你的用户是`ubuntu`。如果不是，请将其替换为你的实际用户。然后，启动设备：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This script creates a symbolic link to the `/dev/ydlidar--> /dev/ttyUSB0` device.
    The next step is to run a test inside ROS to check everything works as expected.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本创建一个指向`/dev/ydlidar--> /dev/ttyUSB0`设备的符号链接。下一步是在ROS内部运行一个测试，以检查一切是否按预期工作。
- en: Running the YDLIDAR ROS package
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行YDLIDAR ROS包
- en: Now, we are going to launch the laser scan node and visualize the results with
    a console client, before doing the same with RViz.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将启动激光扫描节点，并使用控制台客户端可视化结果，然后再使用RViz进行同样的操作。
- en: 'Follow these steps to do so:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤进行：
- en: 'Launch the YDLIDAR node with the following command:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令启动YDLIDAR节点：
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: For this part of this chapter, you should temporarily point the ROS master to
    the laptop, not the robot. Remember that you can do this for single Terminals
    by specifying `$ export ROS_MASTER_URI=http://localhost:11311` in each. Once you
    close any of these, the temporal definition will be thrown away.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章的这一部分，你应该暂时将ROS主节点指向笔记本电脑，而不是机器人。记住，你可以通过在每个终端中指定`$ export ROS_MASTER_URI=http://localhost:11311`来为单个终端这样做。一旦关闭其中任何一个，临时定义将被丢弃。
- en: 'From another Terminal, list the scan data using a client node:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在另一个终端中，使用客户端节点列出扫描数据：
- en: '[PRE12]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You should see the YDLIDAR node''s scan result in the console, as well as the
    ROS graph (obtained by running `rqt_graph` in a separate Terminal, `T3`):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在控制台看到YDLIDAR节点的扫描结果，以及ROS图（通过在另一个终端中运行`rqt_graph`获得），`T3`：
- en: '![](img/0d7ecd57-76e2-4e01-9739-feaa02a10687.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0d7ecd57-76e2-4e01-9739-feaa02a10687.png)'
- en: Note that `base_link_to_laser4` provides the coordinate frame transformation
    in the `/tf` topic, while `ydlidar_node` provides the sensor data feed in the
    `/scan` topic, which is visualized in the Terminal thanks to the `ydlidar_client` node.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`base_link_to_laser4`在`/tf`主题中提供坐标帧转换，而`ydlidar_node`在`/scan`主题中提供传感器数据流，这些数据流通过`ydlidar_client`节点在终端中可视化。
- en: 'Finally, launch RViz to see the distribution of red points at the positions
    where obstacles were found:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，启动RViz以查看在发现障碍物位置的红点分布：
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now, we will repeat this exercise with the LDS connected to the robot.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将重复此练习，将LDS连接到机器人。
- en: Integrating with Raspberry Pi
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与Raspberry Pi集成
- en: 'We will repeat the process we described in the preceding section, *Setting
    up YDLIDAR*, in order to connect the LDS to the Raspberry Pi. After attaching
    the sensor to a USB port of the Raspberry Pi, open a Terminal in the robot and
    follow these steps:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重复上一节中描述的过程，即*设置YDLIDAR*，以便将LDS连接到Raspberry Pi。在将传感器连接到Raspberry Pi的USB端口后，在机器人上打开一个终端并按照以下步骤操作：
- en: 'Clone the repository and rebuild the workspace:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆存储库并重建工作空间：
- en: '[PRE14]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'When you''ve connected YDLIDAR to a USB port, check that the connection has
    been established properly:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你将YDLIDAR连接到USB端口时，检查连接是否已正确建立：
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, change the permissions so that your normal user, `pi`, has access to
    the new device:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，更改权限，以便你的普通用户`pi`可以访问新设备：
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, initiate the device:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，启动设备：
- en: '[PRE17]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This script creates a symbolic link to the `/dev/ydlidar--> /dev/ttyUSB0` device.
    If this is not the case, you can do this by hand, like so:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本创建一个指向`/dev/ydlidar--> /dev/ttyUSB0`设备的符号链接。如果不是这种情况，你可以手动完成，如下所示：
- en: '[PRE18]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This way, you make sure that the `ydlidar_node` node finds the device.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，你可以确保`ydlidar_node`节点找到了设备。
- en: Checking that YDLIDAR works with GoPiGo3
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查YDLIDAR与GoPiGo3一起工作
- en: 'Just like we did with the laptop, use the `ydlidar_client` script to check
    that you have received data from the sensor:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在笔记本电脑上做的那样，使用`ydlidar_client`脚本来检查您是否已从传感器接收到数据：
- en: '[PRE19]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The letter `r` in the preceding code snippet stands for the Terminals in the
    Raspberry Pi. If you receive data in `r2`, then this will be proof that the sensor
    is sending its readings to ROS.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码片段中的字母`r`代表Raspberry Pi上的终端。如果您在`r2`中收到数据，那么这将证明传感器正在将其读数发送到ROS。
- en: Visualizing scan data in the Raspberry Pi desktop
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Raspberry Pi桌面上可视化扫描数据
- en: 'Now, let''s check the RViz visualization in the Raspberry Pi, just like we
    did for the laptop. For this, you need to use **VNC (Virtual Network Computing)**,
    as we explained in [Chapter 6](0b20bdff-f1dc-42e8-ae83-fc290da31381.xhtml), *Programming
    in ROS – Commands and Tools*, in the *Setting up the physical robot* section.
    Set up a VNC server (`x11vnc`). Once connected from the remote laptop, launch
    the following four Terminals in the Raspberry Pi desktop:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查Raspberry Pi上的RViz可视化效果，就像我们检查笔记本电脑上的那样。为此，您需要使用**VNC（虚拟网络计算**），正如我们在[第6章](0b20bdff-f1dc-42e8-ae83-fc290da31381.xhtml)，“在ROS中编程
    - 命令和工具”部分中*设置物理机器人*一节所解释的。设置一个VNC服务器（`x11vnc`）。一旦从远程笔记本电脑连接，请在Raspberry Pi桌面上启动以下四个终端：
- en: '[PRE20]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This is the whole screen:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是整个屏幕：
- en: '![](img/44cabf11-2872-45b7-991d-47c7d85181e6.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/44cabf11-2872-45b7-991d-47c7d85181e6.png)'
- en: 'The laser scan view in RViz (top-right window in the preceding screenshot)
    is provided by `lidar_view.launch`. The ROS graph (bottom-right window) shows
    that the `key_teleop` node allows you to teleoperate the robot with the arrow
    keys by publishing messages in the `/cmd_vel` topic:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: RViz中的激光扫描视图（前一个截图中的右上角窗口）由`lidar_view.launch`提供。ROS图（右下角窗口）显示`key_teleop`节点允许您通过在`/cmd_vel`主题中发布消息使用箭头键远程操作机器人：
- en: '![](img/4c3c1b3a-1548-472d-8e2b-e9235f9533e7.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4c3c1b3a-1548-472d-8e2b-e9235f9533e7.png)'
- en: 'Let''s take a look at what the RViz window is showing:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看RViz窗口显示的内容：
- en: '![](img/bd42aa49-815b-402b-8637-8418a7cb70c1.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/bd42aa49-815b-402b-8637-8418a7cb70c1.png)'
- en: The arrow marked as **GoPiGo3** shows the location of the robot in a corner
    of the room. The external straight red lines stand for the walls, while the arrow
    pointing to **me** shows the contour of myself as I am leaving the room through
    the access door (the free space – no red points – in front of me).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 标记为**GoPiGo3**的箭头显示了机器人在房间角落的位置。外部直线红色线条代表墙壁，而指向**我**的箭头显示了我通过入口门离开房间时的轮廓（我前面的空白空间
    - 没有红色点）。
- en: Grouping launch files
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组合启动文件
- en: 'For efficiency, we should offload the Raspberry Pi from visualization tasks
    and move them to the remote laptop. In order to so, we need to rework the launch
    files so that GoPiGo3 strictly runs the code that''s necessary for the robot to
    work, that is, the `gopigo3_driver.py` part of the `mygopipo` package we described
    in [Chapter 6](0b20bdff-f1dc-42e8-ae83-fc290da31381.xhtml), *Programming in ROS –
    Commands and Tools*, plus the `lidar.launch` part of the `ydlidar` package. These
    two components can be launched with the following commands:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高效率，我们应该将Raspberry Pi从可视化任务中卸载，并将它们移动到远程笔记本电脑。为了做到这一点，我们需要重新工作启动文件，以便GoPiGo3严格运行机器人工作所需的代码，即我们在[第6章](0b20bdff-f1dc-42e8-ae83-fc290da31381.xhtml)，“在ROS中编程
    - 命令和工具”中描述的`mygopipo`包中的`gopigo3_driver.py`部分，以及`ydlidar`包中的`lidar.launch`部分。这两个组件可以使用以下命令启动：
- en: '[PRE21]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The launch files in `r1` and `r2` can be grouped into one, like so. We will
    call this script `gopigo3_ydlidar.launch`:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`r1`和`r2`中的启动文件可以合并为一个，如下所示。我们将把这个脚本命名为`gopigo3_ydlidar.launch`：'
- en: '[PRE22]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Thanks to this grouping, all the code of GoPiGo3 can be run with the following
    command:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了这种分组，GoPiGo3的所有代码都可以使用以下命令运行：
- en: '[PRE23]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This launches the `ydlidar` and `gopigo3` nodes, which provide a software interface
    so that we can talk to the robot sensors and actuators. This also creates the
    following ROS graph:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这启动了`ydlidar`和`gopigo3`节点，它们提供了一个软件接口，使我们能够与机器人传感器和执行器通信。这也创建了一个如下的ROS图：
- en: '![](img/30a81460-081c-4b52-b632-fda7b362a4b6.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/30a81460-081c-4b52-b632-fda7b362a4b6.png)'
- en: 'Next, to listen for the scan data, you need to execute the YDLIDAR client in
    the robot:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了监听扫描数据，您需要在机器人上执行YDLIDAR客户端：
- en: '[PRE24]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This results in the following output:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE25]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The ROS graph looks like this:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ROS图看起来像这样：
- en: '![](img/29e2c41b-4c9f-422e-9cd4-1a4423258768.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/29e2c41b-4c9f-422e-9cd4-1a4423258768.png)'
- en: The `rqt_graph` command that throws the preceding graph can be executed either
    from the Raspberry Pi or a remote laptop. Since our goal is to offload the Raspberry
    Pi, you should run it from the laptop. In such cases, you won't need the desktop
    interface of the Raspberry Pi anymore.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 扔出前面图表的 `rqt_graph` 命令可以从 Raspberry Pi 或远程笔记本电脑执行。由于我们的目标是卸载 Raspberry Pi，你应该在笔记本电脑上运行它。在这种情况下，你将不再需要
    Raspberry Pi 的桌面界面。
- en: The preceding graph shows that `ydlidar_node` publishes laser scan data in the `/scan` topic,
    which it is read by the `ydlidar_client` node and is printed in the Terminal where
    the node was launched from, that is, `r2`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表显示，`ydlidar_node` 在 `/scan` 主题中发布激光扫描数据，这些数据被 `ydlidar_client` 节点读取，并在启动该节点的终端（即
    `r2`）中打印出来。
- en: Visualizing scan data from the remote laptop
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在远程笔记本电脑上可视化扫描数据
- en: The final step is to get the RViz laser scan data on the desktop of the laptop.
    This is what we will accomplish in this section.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是从笔记本电脑的桌面上获取 RViz 激光扫描数据。这是我们将在本节中完成的内容。
- en: In the following paragraphs, the letter `r` in the code snippets stands for
    the Terminals in the robot, while `T` refers to the Terminals in the laptop.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下段落中，代码片段中的字母 `r` 代表机器人的终端，而 `T` 代表笔记本电脑的终端。
- en: 'Follow these steps to build the ROS environment:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤构建 ROS 环境：
- en: 'First, launch the processes in the robot using the unified launch file that
    we built in the previous section:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用我们在上一节中构建的统一启动文件在机器人上启动进程：
- en: '[PRE26]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'From the laptop, find the content of the last message that was published in
    the `/scan` topic:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从笔记本电脑中找到在 `/scan` 主题中发布的最后一条消息的内容：
- en: '[PRE27]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Ranges are provided in the `ranges` array field for 720 orientations, corresponding
    to an angle resolution of 0.5° for a 360° coverage. Then, find which message type
    it is:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 范围在 `ranges` 数组字段中提供，对应于 720 个方向，对应于 360° 覆盖范围的 0.5° 角分辨率。然后，找到它是哪种消息类型：
- en: '[PRE28]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Finally, inspect the message structure:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，检查消息结构：
- en: '[PRE29]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, run the ROS visualization node in the laptop:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在笔记本电脑上运行 ROS 可视化节点：
- en: '[PRE30]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `T1` Terminal will launch the visualization in RViz, while `T2` will let
    you teleoperate the robot to check how its perception of the environment changes
    as it moves by modifying the ranges of the laser scan. The visualization provided
    by `display.launch` adds the URDF model of YDLIDAR to RViz. The black circle in
    the following diagram represents the sensor:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`T1` 终端将启动 RViz 中的可视化，而 `T2` 将允许你通过修改激光扫描的范围来远程操作机器人，以检查其感知环境如何随着运动而改变。`display.launch`
    提供的可视化添加了 YDLIDAR 的 URDF 模型到 RViz。以下图表中的黑色圆圈代表传感器：'
- en: '![](img/73dd3803-f380-454d-8536-a2a93e6e1b7a.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/73dd3803-f380-454d-8536-a2a93e6e1b7a.png)'
- en: Be aware that since the URDF model only includes the sensor, it doesn't move
    like the physical GoPiGo3 robot moves. The scan data – the red points – will change
    according to the robot's motion, but the virtual sensor will remain in the initial
    position, which is not its actual location anymore (unless you stop `T1` and launch
    it again). Hence, at this point, it is more coherent that you use `display_scan.launch` (which
    does not include a URDF model, just the scan data), instead of `display.launch`.
    In the *Practising navigation with GoPiGo3* section, you will link the URDF models
    of GoPiGo3 and the LDS sensor so that RViz shows the motion of the robot.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于 URDF 模型仅包括传感器，它不会像物理 GoPiGo3 机器人那样移动。扫描数据——即红色点——将根据机器人的运动而改变，但虚拟传感器将保持在初始位置，这不再是其实际位置（除非你停止
    `T1` 并重新启动它）。因此，在这种情况下，使用 `display_scan.launch`（不包含 URDF 模型，仅包含扫描数据）比使用 `display.launch`
    更为合理。在 *使用 GoPiGo3 练习导航* 部分中，你将链接 GoPiGo3 和 LDS 传感器的 URDF 模型，以便 RViz 显示机器人的运动。
- en: In the *Running the YDLIDAR ROS package* section, you will run a distributed
    system, where the Raspberry Pi collects sensor data and the remote laptop provides
    a visualization of it.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *运行 YDLIDAR ROS 软件包* 部分中，你将运行一个分布式系统，其中 Raspberry Pi 收集传感器数据，远程笔记本电脑提供其可视化。
- en: Processing YDLIDAR data from a remote laptop
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从远程笔记本电脑处理 YDLIDAR 数据
- en: 'Now, it''s time to interpret the scan data. This can be accomplished with a
    simple snippet called `scan.py`, which is provided with the ROS package:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候解释扫描数据了。这可以通过一个简单的名为 `scan.py` 的代码片段来完成，该代码片段包含在 ROS 软件包中：
- en: '[PRE31]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Type the following command into a Terminal on a laptop to see it in action:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本电脑的终端中输入以下命令以查看其运行效果：
- en: '[PRE32]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding code lists the detected range along the main axes, *X* and *Y*,
    on the screen. Keep the following photograph in mind regarding the reference frame
    of the sensor, which was extracted from the X4 documentation. The angle is measured
    clockwise, taking the *X* axis as its origin. In the following photograph, you
    can see the LDS mounted on the GoPiGo3 and the *X* and *Y* axes directions drawn
    on top:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码列出了屏幕上沿主要轴（*X*和*Y*）检测到的范围。请记住有关传感器参考框架的以下照片，该框架是从X4文档中提取的。角度是按顺时针方向测量的，以*X*轴为起点。在以下照片中，你可以看到安装在GoPiGo3上的LDS以及*X*和*Y*轴的方向绘制在上面：
- en: '![](img/f21d8ec6-c80b-46e7-a667-be60c3ebd066.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f21d8ec6-c80b-46e7-a667-be60c3ebd066.png)'
- en: 'Going back to the screenshot in the *Visualizing data from the remote laptop *section,
    you can guess how the robot is oriented in the room. Take into account that the
    green axis corresponds to *X* and that the red lines corresponds to *Y*:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 回到“可视化远程笔记本电脑数据”部分的截图，你可以猜测机器人在房间中的朝向。请注意，绿色轴对应于*X*轴，而红色线条对应于*Y*轴：
- en: '![](img/73c88c4e-7c9e-4689-8521-e4c74a1b5c73.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/73c88c4e-7c9e-4689-8521-e4c74a1b5c73.png)'
- en: The callback function ranges along the main axes (*+X (0°)*, *+Y (-90°)*, *-X
    (180°)*, *-Y (90)°*), where you can detect obstacles for the right (*+X*), front
    (*+Y*), left (*-X*), or back (*-Y*), respectively.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 回调函数沿着主要轴（*+X（0°）*，*+Y（-90°）*，*-X（180°）*，*-Y（90°）*），在这些轴上可以检测到右侧（*+X*），前方（*+Y*），左侧（*-X*）或后方（*-Y*）的障碍物。
- en: Creating a navigation application in ROS
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在ROS中创建导航应用程序
- en: 'An application that provides a robot with navigation capabilities has to take
    into account the following points:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 一个提供机器人导航能力的应用程序必须考虑以下要点：
- en: '**Sensing**: This provides us with the ability to acquire motion data so that
    the robot is able to estimate its position in real time. This kind of information
    is known as **robot** **odometry**. There are two main sources of sensor data:
    the encoders, which let us know the rotation of the robot wheels, and the IMU
    sensor, which provides acceleration and rotation information about the robot as
    a whole. Generally speaking, data from encoders is used the most, although it
    may be combined with IMU data to improve the accuracy of the pose estimation.
    This is an advanced topic called **fusion sensor**, which is out of the scope
    of this book.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**感知**：这为我们提供了获取运动数据的能力，以便机器人能够实时估计其位置。这类信息被称为**机器人****里程计**。传感器数据的主要来源有两个：编码器，它让我们知道机器人轮子的旋转，以及IMU传感器，它提供有关机器人整体加速度和旋转的信息。一般来说，编码器数据使用得最多，尽管它可能结合IMU数据以提高姿态估计的准确性。这是一个称为**融合传感器**的高级主题，它超出了本书的范围。'
- en: '**Localization/pose estimation**: As a result of odometry and the current map
    of the environment, the **AMCL (Adaptive Monte Carlo localization)** algorithm
    allows us to update the robot pose estimation in real time, as we introduced in
    the previous chapter.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定位/姿态估计**：由于里程计和当前的环境地图，**AMCL（自适应蒙特卡洛定位）**算法允许我们在实时中更新机器人的姿态估计，正如我们在上一章中介绍的那样。'
- en: '**Path planning**: Given a target pose, such planning consists of creating
    a global optimum path of the whole map and a local path that covers a small area
    around the robot so that it is able to follow a precise path while avoiding obstacles.
    Local path planning is dynamic; that is, as the robot moves, the area around the
    robot changes accordingly.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**路径规划**：给定一个目标姿态，此类规划包括创建整个地图的全局最优路径和覆盖机器人周围小区域的局部路径，以便机器人能够跟随精确路径并避开障碍物。局部路径规划是动态的；也就是说，随着机器人的移动，机器人周围的区域会相应地改变。'
- en: '**Move/obstacle avoidance**: As we previously, there is a global optimum path
    that is combined with a local path, and this happens for every position of the
    robot as it moves to the target location. This is like making a zoom window of
    the surroundings. Hence, the local path is calculated by taking the global path
    and the close obstacles into account (for example, a person crossing in front
    of the robot). Local path planning is able to avoid such obstacles without losing
    the global path. This local zoom window is built using the real-time information
    provided by the LDS.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移动/避障**：正如我们之前所做的那样，有一个全局最优路径与局部路径相结合，并且这发生在机器人移动到目标位置时的每个位置。这就像在周围环境中创建一个缩放窗口。因此，局部路径是通过考虑全局路径和附近的障碍物（例如，有人从机器人前方穿过）来计算的。局部路径规划能够避开此类障碍物而不会丢失全局路径。这个局部缩放窗口是通过使用LDS提供的实时信息构建的。'
- en: 'As a result of the aforementioned points, the following data has to be available
    to ROS so that navigation is possible:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 由于上述几点，以下数据必须提供给ROS，以便进行导航：
- en: '**Odometry**: It is published by the `gopigo3` node in the `/odom` topic.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**里程计**: 由`gopigo3`节点在`/odom`主题中发布。'
- en: '**Coordinate transformation**: The position of the sensors in the robot frame
    of reference is published in the `/tf` topic.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**坐标变换**: 传感器在机器人坐标系中的位置发布在`/tf`主题中。'
- en: '**Scan data**: The distances from the robot to the obstacles around it are
    obtained from the LDS and made available in the `/scan` topic.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扫描数据**: 从LDS获取到机器人周围障碍物的距离，并在`/scan`主题中提供。'
- en: '**Map**: The occupancy grid that''s built when executing SLAM is saved to a
    `map.pgm` file, with the configuration in the `map.yml` file.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地图**: 执行SLAM时构建的占用栅格地图保存到`map.pgm`文件中，配置在`map.yml`文件中。'
- en: '**Target pose**: This will be specified by the user in an RViz window once
    the ROS navigation''s setup has been launched.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标姿态**: 一旦启动ROS导航的设置，用户将在RViz窗口中指定。'
- en: '**Velocity commands**: This is the final output of the algorithm. Commands
    are published in the `/cmd_vel` topic that the `gopigo3` node is subscribed to.
    Then, the robot moves accordingly to follow the planned path.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度命令**: 这是算法的最终输出。命令发布在`/cmd_vel`主题中，该主题由`gopigo3`节点订阅。然后，机器人相应地移动以遵循计划路径。'
- en: 'Given the preceding topics and concepts, the steps to create a navigation application
    in ROS are as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面讨论的主题和概念，创建ROS导航应用程序的步骤如下：
- en: 'Build a map of the environment. Taking the data from the LDS, the robot will
    create a map of the environment based on the range of data coming from the sensor.
    It will use the SLAM technique we discussed in the previous chapter to do so.
    This process of building the map follows a practical sequence:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建环境地图。通过从LDS获取数据，机器人将根据来自传感器的数据范围创建环境地图。它将使用我们在前一章中讨论的SLAM技术来完成此操作。构建地图的过程遵循以下实用序列：
- en: Start ROS in the physical robot, meaning that the necessary nodes will be exposing
    the topics where sensor data is published, as well as the topic that will receive
    motion commands. The set of rules to publish the motion commands as a function
    of the acquired sensor data conforms to what we will call the **robot application
    logic**.
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在物理机器人上启动ROS，这意味着必要的节点将公开发布传感器数据的主题，以及接收运动命令的主题。发布运动命令的规则作为获取的传感器数据的函数，符合我们所说的**机器人应用程序逻辑**。
- en: Establish the connection from the remote PC. If it's been configured properly,
    it should be automatic when launching ROS in the laptop. This topic was covered
    in the *Technical requirements* section at the beginning of this chapter.
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从远程PC建立连接。如果配置正确，当在笔记本电脑上启动ROS时应该是自动的。这个主题在本章开头的技术要求部分已经介绍过。
- en: Launch the SLAM process from the laptop. This will allow ROS to acquire real-time
    range data from the LDS so that it can start building a map of the environment.
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从笔记本电脑启动SLAM过程。这将允许ROS从LDS获取实时范围数据，以便开始构建环境地图。
- en: Teleoperate the robot and check the zones that are mapped and the ones to be
    scanned in an RViz visualization. In this case, the robot application logic named
    in the first bullet is driven by you as a human, where you decide what motion
    GoPiGo3 has to perform at every instance. You may also automate teleoperation
    by letting the robot wander around randomly (remember the *Simulating the LDS*
    section of the previous chapter, where you let GoPiGo3 autonomously explore the
    environment while applying a set of rules to surround the obstacles it might encounter
    on its way). In this case, the robot application logic is implemented in a Python
    script and there is no human intervention.
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过RViz可视化检查已映射区域和待扫描区域，远程操作机器人。在这种情况下，名为第一个项目符号的机器人应用程序逻辑由你作为人类驱动，你决定GoPiGo3在每一个实例中必须执行什么动作。你也可以通过让机器人随机漫游来自动化远程操作（记住前一章中提到的*模拟LDS*部分，在那里你让GoPiGo3在应用一系列规则的同时自主探索环境，以避开可能遇到的障碍）。在这种情况下，机器人应用程序逻辑由Python脚本实现，没有人为干预。
- en: Once the environment has been fully explored, you have to save the map so that
    it can be used in the next step for autonomous navigation.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦环境被完全探索，你必须保存地图，以便在下一步中进行自主导航。
- en: 'Launch the navigation task by telling the robot the target location you want
    it to move to. This process of autonomous navigation follows the following sequence:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过告诉机器人你希望它移动到的目标位置来启动导航任务。这个自主导航的过程遵循以下顺序：
- en: Start ROS in the physical robot. In this case, the robot application logic is
    part of the navigation task, which is intended to be performed autonomously by
    GoPiGo3, without any human intervention.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在物理机器人上启动ROS。在这种情况下，机器人应用程序逻辑是导航任务的一部分，旨在由GoPiGo3自主执行，无需任何人为干预。
- en: Load the map of the environment that was created in the first part of the navigation
    application.
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载导航应用程序第一部分创建的环境地图。
- en: Indicate a target pose to the robot, something you can directly perform on an
    RViz visualization, which shows the map of the environment.
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向机器人指示一个目标姿态，你可以在RViz的可视化中直接执行，该可视化显示了环境的地图。
- en: Let the robot navigate by itself to the target location, checking that it is
    able to plan an optimum path while avoiding the obstacles it may encounter.
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让机器人自行导航到目标位置，检查它是否能够规划出避开可能遇到的障碍物的最佳路径。
- en: We will illustrate this process with a real-world example in the next section.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中用一个现实世界的例子来说明这个过程。
- en: Practicing navigation with GoPiGo3
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GoPiGo3练习导航
- en: In this section, we'll cover the steps that we followed in the *Practising SLAM
    and navigation with GoPiGo3* section of the previous chapter by substituting the
    virtual robot and the Gazebo simulator with the actual GoPiGo3 and the physical
    environment, respectively.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍在上一章的“*使用GoPiGo3练习SLAM和导航*”部分所遵循的步骤，通过用实际的GoPiGo3和物理环境分别替换虚拟机器人和Gazebo模拟器。
- en: Building a map of the environment
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建环境地图
- en: 'First, let''s consider a physical environment that''s simple enough for our
    learning purposes. This can be seen in the following photograph:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们考虑一个足够简单，适合我们学习目的的物理环境。这可以在以下照片中看到：
- en: '![](img/d993b2ff-272a-45a0-ba4e-1b21bdc59ddd.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d993b2ff-272a-45a0-ba4e-1b21bdc59ddd.jpg)'
- en: Be aware that this almost-square space has three limiting sides and one step
    that cannot be detected by the laser sensor because it is below the floor level
    of the robot.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这个几乎正方形的区域有三个限制边和一个激光传感器无法检测到的步骤，因为它位于机器人的地板水平以下。
- en: 'Going to ROS, the first step consists of mapping the environment so that the
    robot can localize its surroundings and navigate around it. Follow these steps:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在ROS中，第一步是绘制环境地图，以便机器人能够定位其周围环境并绕其导航。按照以下步骤操作：
- en: 'Launch all the ROS nodes in the robot. From a remote Terminal connected to
    the Raspberry Pi, this means running the ROS launch files that control the drives
    and the LDS:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动机器人上的所有ROS节点。从连接到树莓派的远程终端，这意味着运行控制驱动和LDS的ROS启动文件：
- en: '[PRE33]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Recall the *Integrating with Raspberry Pi* section: grouping launch files is
    how we built a unique launch file to run the robot configuration in one shot.
    This ensures that GoPiGo3 is ready to interact with ROS in the laptop, where all
    the processing related to the map of the environment and the navigation command
    will be done.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下“*与树莓派集成*”部分：分组启动文件是我们构建一个独特的启动文件来一次性运行机器人配置的方法。这确保了GoPiGo3准备好在笔记本电脑上与ROS交互，在那里将完成与环境地图和导航命令相关的所有处理。
- en: 'Launch the SLAM mapping ROS package, whose launch file includes a RViz visualization
    that overimposes the virtual model of the robot with the actual scan data:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动SLAM映射ROS包，其启动文件包括一个RViz可视化，该可视化将机器人的虚拟模型与实际扫描数据叠加：
- en: '[PRE34]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Teleoperate the robot to make it cover as much of the surface of the virtual
    environment as possible. We can do this as follows:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过远程操作机器人，使其覆盖尽可能多的虚拟环境表面。我们可以这样做：
- en: '[PRE35]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'As you explore the robot''s surroundings, you should see something similar
    to the following in the RViz window:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 当你探索机器人的周围环境时，你应在RViz窗口中看到以下类似内容：
- en: '![](img/ca2f5b14-4c2f-43dc-8a7b-a404317152cf.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ca2f5b14-4c2f-43dc-8a7b-a404317152cf.png)'
- en: Here, you can see the three limiting walls of the square space. The rest of
    the map shows the first obstacles the laser finds in the remaining directions.
    Remember that the step in the fourth side cannot be detected because it is below
    the floor level of the robot.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到正方形空间的三个限制墙。地图的其余部分显示了激光在剩余方向上找到的第一个障碍物。记住，第四边的步骤无法检测到，因为它位于机器人的地板水平以下。
- en: 'Once you''ve finished exploring, save the map we generated into the two files
    we specified previously, that is, `.pgm` and `.yaml`:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你完成探索，将我们生成的地图保存到之前指定的两个文件中，即`.pgm`和`.yaml`：
- en: '[PRE36]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Again, you will have the map files in the root folders of your workspace, that
    is, `test_map.pgm` and `test_map.yaml`. Now, we are ready to make GoPiGo3 navigate
    in the physical environment.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，你将在工作区的根目录中找到地图文件，即`test_map.pgm`和`test_map.yaml`。现在，我们准备让GoPiGo3在物理环境中导航。
- en: Navigating GoPiGo3 in the real world
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在现实世界中导航GoPiGo3
- en: 'This second part requires that you stop all ROS processes on the laptop, but
    not necessarily on GoPiGo3\. Remember that, in the robot, you have the minimum
    ROS configuration so that the robot is able to perceive the environment (LDS X4
    sensor) and move around (drives). All the remaining logic for navigation will
    run in the laptop. Hence, close any open Terminals in your PC and start the new
    phase by following these steps:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这第二部分要求你在笔记本电脑上停止所有ROS进程，但不必在GoPiGo3上停止。记住，在机器人上，你有最小的ROS配置，这样机器人就能够感知环境（LDS
    X4传感器）并移动（驱动）。所有剩余的导航逻辑将在笔记本电脑上运行。因此，关闭PC上任何打开的终端，并按照以下步骤开始新阶段：
- en: 'Launch the ROS nodes in the robot if you stopped the Terminal previously:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果之前停止了终端，请在机器人上启动ROS节点：
- en: '[PRE37]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Launch the AMCL navigation by providing the cost map that the robot built previously.
    To do so, you have to reference the `.yaml` map file you created previously. Make
    sure that the corresponding `.pgm` file has the same name and is placed in the
    same location:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提供机器人之前构建的成本图来启动AMCL导航。为此，你必须参考之前创建的`.yaml`地图文件。确保相应的`.pgm`文件具有相同的名称，并且放置在同一位置：
- en: '[PRE38]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This launch file includes an RViz visualization that will let us interact with
    the map so that we can set a target location, as shown in the following screenshot:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 此启动文件包括一个RViz可视化，它将允许我们与地图交互，以便我们可以设置目标位置，如下面的截图所示：
- en: '![](img/10af7274-4e17-49a2-8085-c039ec9303ec.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10af7274-4e17-49a2-8085-c039ec9303ec.png)'
- en: As in the case of the Gazebo simulation, the goal location is set by pressing the **2D
    Nav Goal** button at the top right of the RViz window and selecting the target
    pose, which is composed of both the position and orientation (a green arrow in
    RViz lets you define it graphically). As soon as you pick such a location, the
    AMCL algorithm starts path planning and sends motion commands via the `/cmd_vel`
    topic. Consequently, the robot moves to the specified location as the sequence
    of commands is executed.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 与Gazebo模拟的情况一样，通过按下RViz窗口右上角的**2D Nav Goal**按钮并选择目标姿态来设置目标位置，该姿态由位置和方向组成（RViz中的绿色箭头允许你图形化定义它）。一旦选择这样的位置，AMCL算法就开始路径规划并通过`/cmd_vel`主题发送运动命令。因此，当命令序列执行时，机器人将移动到指定的位置。
- en: Summary
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you finally completed an autonomous task using GoPiGo3\. This
    is only the entry point to the fascinating field of artificial intelligence applied
    to robotics. The most obvious functionality to be built on top of robot navigation
    is self-driving, which is the functionality that is currently being implemented
    by many vehicle manufacturers to make safer and more comfortable vehicles for
    the end users.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你最终完成了使用GoPiGo3的自主任务。这仅仅是进入机器人领域应用人工智能这一迷人领域的起点。在机器人导航之上最明显的功能是自动驾驶，这是许多汽车制造商目前正在实施的功能，以制造更安全、更舒适的车辆供最终用户使用。
- en: In the fourth and last part of this book, you will learn how machine learning
    techniques are applied nowadays to build smarter robots.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第四和最后一部分，你将了解机器学习技术是如何应用于当今构建更智能的机器人的。
- en: Questions
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Which of these sensors is of the LDS type?
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个传感器是LDS类型的？
- en: A) LIDAR
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: A) 激光雷达
- en: B) Ultrasonic distance sensor
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: B) 超声波距离传感器
- en: C) Capacitive sensors
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: C) 电容式传感器
- en: Where does the ROS master node have to live to perform navigation?
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ROS主节点必须位于何处才能执行导航？
- en: A) In the robot
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: A) 在机器人上
- en: B) In the robot and the laptop
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: B) 在机器人和笔记本电脑上
- en: C) In either the robot or the laptop
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: C) 在机器人或笔记本电脑上
- en: What will happen if an obstacle is placed in the environment after the map has
    been built?
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在地图构建之后在环境中放置障碍物，会发生什么？
- en: A) The robot will not detect it and may crash with it if it interferes with
    the planned path.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: A) 机器人将无法检测到它，如果它与预定路径发生冲突，可能会与之相撞。
- en: B) The local path planning will be taken into account to provide a modified
    path that avoids the obstacle.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: B) 考虑到局部路径规划，将提供一个避开障碍物的修改路径。
- en: C) You should rebuild the map with the new conditions before proceeding to the
    navigation task.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: C) 在进行导航任务之前，你应该在新条件下重新构建地图。
- en: Can you perform navigation without previously running SLAM with the robot?
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能否在之前没有用机器人运行SLAM的情况下进行导航？
- en: A) No, because you have to build the map with the same robot that you will use
    for navigation.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: A) 不可以，因为你必须使用你将用于导航的同一台机器人来构建地图。
- en: B) Yes, the only condition is that you provide a premade map of the environment.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: B) 是的，唯一条件是你提供一个预先制作的环境地图。
- en: C) No, SLAM and navigation are two sides of the same coin.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: C) 不可以，SLAM和导航是同一枚硬币的两面。
- en: What is the odometry of a robot?
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器人的里程计是什么？
- en: A) The total distance it has covered since the ROS application was started.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: A) 自从ROS应用启动以来，它所覆盖的总距离。
- en: B) The use of data from motion sensors to estimate the changes in the robot's
    pose over time.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: B) 使用运动传感器的数据来估计机器人随时间变化的姿态。
- en: C) The use of data from motion sensors to estimate the current robot's pose.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: C) 使用运动传感器的数据来估计当前机器人的姿态。
- en: Further reading
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The main resource that you can read in order to deepen your knowledge of SLAM
    is the official documentation of the ROS Navigation Stack, which is located at
    [http://wiki.ros.org/navigation](http://wiki.ros.org/navigation). For those of
    you who are interested, here are some additional references:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以阅读的主要资源是ROS导航堆栈的官方文档，它位于[http://wiki.ros.org/navigation](http://wiki.ros.org/navigation)。对于那些感兴趣的人，这里有一些额外的参考文献：
- en: '*ROS Navigation: Concepts and Tutorial, Federal University of Technology*, Longhi
    R., Schneider A., Fabro J., Becker T., and Amilgar V. (2018), Parana, Curitiba,
    Brazil.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ROS导航：概念与教程*，联邦技术大学，Longhi R.，Schneider A.，Fabro J.，Becker T.，和Amilgar V.
    (2018)，巴拉那，库里蒂巴，巴西。'
- en: '*Lidar design, use, and calibration concepts for correct environmental detection*,
    in IEEE Transactions on Robotics and Automation, M. D. Adams (2000) vol. 16, no.
    6, pp. 753-761, Dec. 2000, doi: 10.1109/70.897786. URL: [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=897786&isnumber=19436](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=897786&isnumber=19436).'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用于正确环境检测的激光雷达设计、使用和校准概念*，在IEEE机器人与自动化杂志，M. D. Adams (2000) 第16卷，第6期，第753-761页，2000年12月，doi:
    10.1109/70.897786。URL: [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=897786&isnumber=19436](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=897786&isnumber=19436)。'
- en: '*The LIDAR Odometry in the SLAM*, V. Kirnos, V. Antipov, A. Priorov, and V.
    Kokovkina, 23rd Conference of Open Innovations Association (FRUCT), Bologna, 2018,
    pp. 180-185. doi: 10.23919/FRUCT.2018.8588026, URL: [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8588026&isnumber=8587913](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8588026&isnumber=8587913).'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SLAM中的激光雷达里程计*，V. Kirnos, V. Antipov, A. Priorov, 和 V. Kokovkina，第23届开放创新协会（FRUCT）会议，博洛尼亚，2018年，第180-185页。doi:
    10.23919/FRUCT.2018.8588026，URL: [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8588026&isnumber=8587913](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8588026&isnumber=8587913)。'
