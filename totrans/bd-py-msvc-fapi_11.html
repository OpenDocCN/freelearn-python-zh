<html><head></head><body>
		<div><h1 id="_idParaDest-317" class="chapter-number"><a id="_idTextAnchor321"/>11</h1>
			<h1 id="_idParaDest-318"><a id="_idTextAnchor322"/>Adding Other Microservice Features</h1>
			<p>Our long journey of exploring FastAPI’s extensibility in building microservice applications will end with this chapter, which covers standard recommendations on project setup, maintenance, and deployment using some microservice-related tools based on design patterns. This chapter will discuss the <em class="italic">OpenTracing</em> mechanism and its use in a distributed FastAPI architecture setup using tools such as <em class="italic">Jaeger</em> and <code>StarletteTracingMiddleWare</code>. The <em class="italic">service registry</em> and <em class="italic">client-side discovery</em> design patterns are included likewise in the detailed discussions on how to manage access to the API endpoints of the microservices. A microservice component that checks for the <em class="italic">health</em> of the API endpoints will also be part of the discussion. Moreover, the chapter will not end without recommendations on the FastAPI application’s <em class="italic">deployment</em>, which might lead to other design strategies and network setups.</p>
			<p>The main goal of this chapter is to complete the design architecture of a FastAPI application before its sign-off. Here are the topics that will complete our FastAPI application development venture:</p>
			<ul>
				<li>Setting up the virtual environment</li>
				<li>Checking the API properties</li>
				<li>Implementing open tracing mechanisms</li>
				<li>Setting up service registry and client-side service discovery</li>
				<li><a id="_idTextAnchor323"/>Deploying and running applications using Docker</li>
				<li>Using Docker Compose for deployment</li>
				<li>Utilizing NGINX as an API gateway </li>
				<li>Integrating Django and Flask sub-applications</li>
			</ul>
			<h1 id="_idParaDest-319"><a id="_idTextAnchor324"/>Technical requirements</h1>
			<p>Our last software prototype will be an <code>ch11</code> and other <a href="B17975_11.xhtml#_idTextAnchor321"><em class="italic">Chapter 11</em></a>-related projects.</p>
			<h1 id="_idParaDest-320"><a id="_idTextAnchor325"/>Setting up the virtual environment</h1>
			<p>Let us start<a id="_idIndexMarker906"/> with the proper way of setting up the development environment of our FastAPI application. In Python development, it is common to manage the libraries and extension modules that are needed using a virtual environment. A virtual environment is a way of creating multiple different and parallel installations of Python interpreters and their dependencies where each has the application(s) to be compiled and run. Each instance has its own set of libraries depending on the requirements of its application(s). But first, we need to install the <code>virtualenv</code> module to pursue the creation of these instances:</p>
			<pre>pip install virtualenv</pre>
			<p>The following list describes<a id="_idIndexMarker907"/> the benefits of having a virtual environment:</p>
			<ul>
				<li>To avoid the overlapping of the library version</li>
				<li>To avoid broken installed module files due to namespace collisions</li>
				<li>To localize the libraries to avoid conflicts with the globally installed modules on which some applications are very dependent</li>
				<li>To create a template or baseline copy of the set of modules to be replicated on some related projects</li>
				<li>To maintain operating system performance and setup</li>
			</ul>
			<p>After the installation, we need to run the <code>python -m virtualenv</code> command to create an instance. <em class="italic">Figure 11.1</em> shows how the <code>ch01-env</code> virtual environment for the <code>ch01</code> project is created:</p>
			<div><div><img src="img/Figure_11.01_B17975.jpg" alt="Figure 11.1 – Creating a Python virtual environment&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1 – Creating a Python virtual environment</p>
			<p>To use the <a id="_idIndexMarker908"/>virtual environment, we need to configure our <em class="italic">VS Code editor</em> to utilize the Python interpreter of the virtual environment instead of the global interpreter to install modules, compile, and run the application. Pressing <em class="italic">Ctrl </em>+<em class="italic"> Shift </em>+<em class="italic"> P</em> will open the <em class="italic">Command Palette</em> showing the Python command to <em class="italic">select the interpreter</em>. <em class="italic">Figure 11.2</em> shows the process of choosing the Python interpreter for the <code>ch01</code> project:</p>
			<div><div><img src="img/Figure_11.02_B17975.jpg" alt="Figure 11.2 – Choosing the Python interpreter&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> </p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.2 – Choosing the Python interpreter</p>
			<p>The select command will open a pop-up Windows <em class="italic">File Explorer</em> window to search for the appropriate virtual environment with the Python interpreter, as shown in <em class="italic">Figure 11.3</em>:</p>
			<div><div><img src="img/Figure_11.03_B17975.jpg" alt="Figure 11.3 – Searching for the virtual environment&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.3 – Searching for the virtual environment</p>
			<p>Opening a <em class="italic">Terminal console</em> for the project will automatically activate the virtual environment<a id="_idIndexMarker909"/> by running the <code>/Scripts/activate.bat</code> command for the Windows operating system. Additionally, this <code>activate.bat</code> script can be manually run if the automated activation was not successful. By the way, the activation will not be feasible with the Powershell terminal, but only with the command console, as shown in <em class="italic">Figure 11.4</em>:</p>
			<div><div><img src="img/Figure_11.04_B17975.jpg" alt="Figure 11.4 – Activating the virtual environment&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.4 – Activating the virtual environment</p>
			<p>After activation, we can determine the name of the activated virtual environment from the leftmost part of the command line. <em class="italic">Figure 11.4</em> shows that the Python interpreter of <code>ch11-env</code> is the chosen interpreter for the project. Anything installed by its <code>pip</code> command will only be available within that instance.</p>
			<p>Each of our projects has a virtual environment, thus having multiple virtual environments containing different set of installed module dependencies, as shown in <em class="italic">Figure 11.5</em>:</p>
			<div><div><img src="img/Figure_11.05_B17975.jpg" alt="Figure 11.5 – Creating multiple virtual environments&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.5 – Creating multiple virtual environments</p>
			<p>Setting up <a id="_idIndexMarker910"/>the virtual environment is only one of the best practices when it comes to initiating a Python microservice application. Aside from localizing the module installation, it helps prepare the deployment of the application in terms of identifying what modules to install in the cloud servers. However, before we discuss FastAPI deployment approaches, first, let us discuss what microservice utilities to include before deploying a project, such as <strong class="bold">Prometheus</strong>.</p>
			<h1 id="_idParaDest-321"><a id="_idTextAnchor326"/>Checking the API properties</h1>
			<p><strong class="bold">Prometheus</strong> is a<a id="_idIndexMarker911"/> popular monitoring total that can monitor and check<a id="_idIndexMarker912"/> API services in any microservice application. It can check the number of concurrent request transactions, the number of responses at a certain period, and the total incoming requests of an endpoint. To apply Prometheus to FastAPI applications, first, we need to install the following module:</p>
			<pre>pip install starlette-exporter</pre>
			<p>Then, we add <code>PrometheusMiddleware</code> to the application and enable its endpoint to observe the API’s properties at runtime. The following script shows the application setup with the Prometheus monitoring module:</p>
			<pre class="source-code">
<strong class="bold">from starlette_exporter import PrometheusMiddleware, </strong>
         <strong class="bold">handle_metrics</strong>
app = FastAPI()
<strong class="bold">app.add_middleware(PrometheusMiddleware, app_name=”osms”</strong>) 
<strong class="bold">app.add_route(“/metrics”, handle_metrics)</strong></pre>
			<p>Here, we add <code>PrometheusMiddleware</code> using the <code>add_middleware()</code> method of FastAPI. Then, we add an arbitrary URI pattern to the <code>handle_metrics()</code> utility to expose all of the <a id="_idIndexMarker913"/>API health details. Accessing <code>http://localhost:8000/metrics</code> will provide us with something as shown in <em class="italic">Figure 11.6</em>:</p>
			<div><div><img src="img/Figure_11.06_B17975.jpg" alt="Figure 11.6 – Monitoring the endpoints&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.6 – Monitoring the endpoints</p>
			<p>The data in <em class="italic">Figure 11.6</em> displays the time duration, in seconds, used by each API in processing requests, providing response to clients, and emitting the status code of each API transaction. Additionally, it includes some buckets that are built-in values used by the tool to create histograms. Aside from the histogram, Prometheus also allows the customization of some metrics inherent to a particular application.</p>
			<p>Another way of monitoring a FastAPI microservice application is by adding an open tracing tool.</p>
			<h1 id="_idParaDest-322"><a id="_idTextAnchor327"/>Implementing open tracing mechanisms</h1>
			<p>When <a id="_idIndexMarker914"/>monitoring multiple, independent, and distributed microservices, the <em class="italic">OpenTracing</em> mechanism is preferred when managing API logs and traces. Tools such as <em class="italic">Zipkin</em>, <em class="italic">Jaeger</em>, and <em class="italic">Skywalking</em> are popular distributed tracing systems that can provide the setup for trace and log collections. In this prototype, we will be using the Jaeger tool to manage the application’s API traces and logs.</p>
			<p>The current way to integrate an OpenTracing tool into FastAPI microservices is through the <em class="italic">OpenTelemetry</em> modules since the <em class="italic">Opentracing for Python</em> extension is already a deprecated module. To use Jaeger as the tracing service, OpenTelemetry has an <em class="italic">OpenTelemetry Jaeger Thrift Exporter</em> utility, which allows you to export traces to the Jaeger client applications. This exporter utility sends these traces to the configured agent using the Thrift compact protocol over UDP. But first, we need to install the following<a id="_idIndexMarker915"/> extension to utilize this exporter:</p>
			<pre>pip install opentelemetry-exporter-jaeger</pre>
			<p>Afterward, add the following configuration to the <code>main.py</code> file:</p>
			<pre class="source-code">
from opentelemetry import trace
<strong class="bold">from opentelemetry.exporter.jaeger.thrift import </strong>
          <strong class="bold">JaegerExporter</strong>
from opentelemetry.sdk.resources import SERVICE_NAME, 
          Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import 
          BatchSpanProcessor
from opentelemetry.instrumentation.fastapi import 
          FastAPIInstrumentor
from opentelemetry.instrumentation.logging import 
         LoggingInstrumentor
app = FastAPI()
resource=Resource.create(
        {SERVICE_NAME: “online-sports-tracer”})
tracer = TracerProvider(resource=resource)
trace.set_tracer_provider(tracer)
<strong class="bold">jaeger_exporter = JaegerExporter(</strong>
    # configure client / agent
    agent_host_name=’localhost’,
    agent_port=6831,
    # optional: configure also collector
    # collector_endpoint=
    #     ‘http://localhost:14268/api/traces?
    #            format=jaeger.thrift’,
    # username=xxxx, # optional
    # password=xxxx, # optional
    # max_tag_value_length=None # optional
)
span_processor = BatchSpanProcessor(jaeger_exporter)
<strong class="bold">tracer.add_span_processor(span_processor)</strong>
<strong class="bold">FastAPIInstrumentor.instrument_app(app, </strong>
          <strong class="bold">tracer_provider=tracer)</strong>
LoggingInstrumentor().instrument(set_logging_format=True)</pre>
			<p>The first step<a id="_idIndexMarker916"/> in the preceding setup is to create a tracing service with a name using OpenTelemetry’s <code>Resource</code> class. Then, we instantiate a tracer from the service resource. To complete the setup, we need to provide the tracer with <code>BatchSpanProcessor</code> instantiated through the <code>JaegerExporter</code> details to manage all of the traces and logs using a Jaeger client. A <em class="italic">trace</em> includes full-detailed information about the exchange of requests and responses among all API services and other components across the distributed setup. This is unlike a <em class="italic">log</em>, which only contains the details regarding a transaction within an application.</p>
			<p>After the<a id="_idIndexMarker917"/> completed Jaeger tracer setup, we integrate the <code>tracer</code> client with FastAPI through <code>FastAPIInstrumentor</code>. To utilize this class, first, we need to install the following extension:</p>
			<pre>pip install opentelemetry-instrumentation-fastapi</pre>
			<p>Before we can run our application, first, we need to download a Jaeger client from <code>https://www.jaegertracing.io/download/</code>, unzip the <code>jaeger-xxxx-windows-amd64.tar.gz</code> file, and run <code>jaeger-all-in-one.exe</code>. Installers for Linux and macOS are also available.</p>
			<p>Now, open a browser and access the Jaeger client through the default <code>http://localhost:16686</code>. <em class="italic">Figure 11.7</em> shows a snapshot of the tracer client:</p>
			<div><div><img src="img/Figure_11.07_B17975.jpg" alt="Figure 11.7 – Monitoring microservices through a Jaeger client&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.7 – Monitoring microservices through a Jaeger client</p>
			<p>After some browser reloads, the Jaeger app will detect our tracer through its service name, <code>online-sports-tracer</code>, after running our microservice application. All accessed API endpoints are detected and monitored, thus creating traces and visual analyses regarding all requests and response transactions incurred by these endpoints. <em class="italic">Figure 11.8</em> shows the traces and graphical plots generated by Jaeger:</p>
			<div><div><img src="img/Figure_11.08_B17975.jpg" alt="Figure 11.8 – Searching the traces of every API transaction&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.8 – Searching the traces of every API transaction</p>
			<p>A span in<a id="_idIndexMarker918"/> OpenTelemetry is equivalent to a trace with a unique <em class="italic">ID</em>, and we can scrutinize each span to view all the details by clicking on the search traces for every endpoint. Clicking on the searched trace for the <code>/ch11/login/list/all</code> endpoint, as shown in <em class="italic">Figure 11.8</em>, can provide us with the following trace details:</p>
			<div><div><img src="img/Figure_11.09_B17975.jpg" alt="Figure 11.9 – Scrutinizing the trace details of an endpoint&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.9 – Scrutinizing the trace details of an endpoint</p>
			<p>Aside from the traces shown in <em class="italic">Figure 11.9</em>, the Jaeger client can also collect the <em class="italic">uvicorn logs</em> through an OpenTelemetry module called <code>opentelemetry-instrumentation-logging</code>. After installing the module, we can enable the integration by instantiating <code>LoggingInstrumentor</code> in the <code>main.py</code> file, as shown in the previous code snippet.</p>
			<p>Now, let us add the <em class="italic">service registry</em> and <em class="italic">client-side service discovery</em> mechanisms to our application.</p>
			<h1 id="_idParaDest-323"><a id="_idTextAnchor328"/>Setting up service registry and client-side service discovery</h1>
			<p>A service registry tool such<a id="_idIndexMarker919"/> as <em class="italic">Netflix Eureka</em> enables the registration of microservice applications without knowing the exact DNS locations of their servers. It manages all access to <a id="_idIndexMarker920"/>these registered services using a load-balancing algorithm and dynamically assigns these service instances with network locations. This service registration is helpful to microservice applications deployed to servers with changing DNS names due to failures, upgrades, and enhancements.</p>
			<p>For the service registry to work, the service instances should have a mechanism to discover the registry server before the server registration. For FastAPI, we need to utilize the <code>py_eureka_client</code> module to implement the service discovery design pattern.</p>
			<h2 id="_idParaDest-324"><a id="_idTextAnchor329"/>Implementing client-side service discovery</h2>
			<p>Creating a<a id="_idIndexMarker921"/> FastAPI microservice application to discover and register to a service registry server such as <em class="italic">Netflix Eureka</em> is straightforward. First, we need to install <code>py_eureka_client</code> through <code>pip</code>:</p>
			<pre>pip install py_eureka_client</pre>
			<p>Then, we instantiate its <code>EurekaClient</code> component class with the correct <code>eureka_server</code>, <code>app_name</code>, <code>instance_port</code>, and <code>instance_host</code> parameter details. The <code>eureka_server</code>  parameter must be the exact machine address of the Eureka server and not <code>localhost</code>. Additionally, the client instance must have the appropriate <code>app_name</code> parameter for the FastAPI microservice application (or client app), with the <code>instance_port</code> parameter set to <code>8000</code> and the <code>instance_host </code>to <code>192.XXX.XXX.XXX</code> (not <code>localhost</code> or <code>127.0.0.1</code>). The following snippet depicts the location in <code>main.py</code> in which to instantiate the <code>EurekaClient</code> component class:</p>
			<pre class="source-code">
<strong class="bold">from py_eureka_client.eureka_client import EurekaClient</strong>
app = FastAPI()
<strong class="bold">@app.on_event(“startup”)</strong>
async def init():
    create_async_db() 
    global client
    <strong class="bold">client = EurekaClient(</strong>
     <strong class="bold">eureka_server=”http://DESKTOP-56HNGC9:8761/eureka”, </strong>
     <strong class="bold">app_name=”sports_service”, instance_port=8000, </strong>
     <strong class="bold">instance_host=”192.XXX.XXX.XXX”)</strong>
    await <strong class="bold">client.start()</strong>
<strong class="bold">@app.on_event(“shutdown”)</strong>
async def destroy():
    close_async_db() 
    await <strong class="bold">client.stop()</strong></pre>
			<p>The <a id="_idIndexMarker922"/>client discovery happens in the <code>startup</code> event of the application. It starts with the instantiation of the <code>EurekaClient</code> component class and invoking its <code>start()</code> method either asynchronously or not. The <code>EurekaClient</code> component class can handle asynchronous or synchronous FastAPI startup events. To close the server discovery process, always invoke <code>Eurek</code> <code>a</code> <code>Client</code>’s <code>stop()</code> method in the <code>shutdown</code> event. Now, let us build our Netflix Eureka server registry before running and performing the client-side service discovery.</p>
			<h2 id="_idParaDest-325"><a id="_idTextAnchor330"/>Setting up the Netflix Eureka service registry</h2>
			<p>Let us <a id="_idIndexMarker923"/>utilize the Spring Boot platform to create our Eureka server. We can create an application through <code>https://start.spring.io/</code> or the <em class="italic">Spring STS IDE</em>, using either a Maven- or Gradle-driven application. Ours is a Maven application with <code>pom.xml</code> that has the following dependency for the Eureka Server setup:</p>
			<pre class="source-code">
&lt;dependency&gt;
      &lt;groupId&gt;<strong class="bold">org.springframework.cloud</strong>&lt;/groupId&gt;
      &lt;artifactId&gt;
       <strong class="bold">spring-cloud-starter-netflix-eureka-server</strong>
     &lt;/artifactId&gt;
&lt;/dependency&gt;</pre>
			<p>In this case, <code>application.properties</code> must have <code>server.port</code> set to <code>8761</code>, <code>server.shutdown</code> enabled for a <code>graceful</code> server shutdown, and a <code>spring.cloud.inetutils.timeout-seconds</code> property set to <code>10</code> for its hostname calculation.</p>
			<p>Now, run the Eureka Server application before the FastAPI client application. The Eureka server’s logs will show us the automatic detection and registration of FastAPI’s <code>EurekaClient</code>, as shown in <em class="italic">Figure 11.10</em>:</p>
			<div><div><img src="img/Figure_11.10_B17975.jpg" alt="Figure 11.10 – Discovering the FastAPI microservice application&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.10 – Discovering the FastAPI microservice application</p>
			<p>The result of the client-side service discovery is also evident on the Eureka server’s dashboard at <code>http://localhost:8761</code>. The page will show us all the services that consist of the registry and through which we can access and test each service. <em class="italic">Figure 11.11</em> shows a sample snapshot of the dashboard:</p>
			<div><div><img src="img/Figure_11.11_B17975.jpg" alt="Figure 11.11 – Creating the service registry&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.11 – Creating the service registry</p>
			<p>Our <strong class="bold">SPORTS_SERVICE</strong> being <a id="_idIndexMarker924"/>part of the Eureka server registry, as depicted in <em class="italic">Figure 11.11</em>, means we successfully implemented the <em class="italic">client-side service discovery design pattern</em>, and it is time to deploy our application to a Docker container.</p>
			<h1 id="_idParaDest-326"><a id="_idTextAnchor331"/>Deploying and running applications using Docker</h1>
			<p><em class="italic">Dockerization</em> is a <a id="_idIndexMarker925"/>process of packaging, deploying, and running applications using Docker containers. Containerizing FastAPI microservices saves <a id="_idIndexMarker926"/>installation and setup time, space, and resources. And containerized apps are replaceable, replicable, efficient, and scalable compared to the usual deployment packaging.   </p>
			<p>To pursue Dockerization, we need to install <em class="italic">Docker Hub</em> and/or <em class="italic">Docker Engine</em> for the CLI commands. But be aware of the new Docker Desktop License Agreement (<a href="https://www.docker.com/legal/docker-software-end-user-license-agreement/">https://www.docker.com/legal/docker-software-end-user-license-agreement/</a>) regarding its new subscription model. This chapter mainly focuses on how to run CLI commands rather than the Docker Hub GUI tool. Now, let us generate the list of modules to be installed in the docker image.</p>
			<h2 id="_idParaDest-327"><a id="_idTextAnchor332"/>Generating the requirements.txt file</h2>
			<p>Since <a id="_idIndexMarker927"/>we are using a virtual environment instance for module management, it is easy to identify what extension modules to install in the Docker image. We can run the following command to generate a complete list of modules and their versions to the <code>requirements.txt</code> file:</p>
			<pre>pip freeze &gt; requirements.txt </pre>
			<p>Then, we can create a command to copy this file to the image through the <code>Dockerfile</code>.</p>
			<h2 id="_idParaDest-328"><a id="_idTextAnchor333"/>Creating the Docker image </h2>
			<p>The<a id="_idIndexMarker928"/> next step is to build a container image from any available Linux-based container images in <em class="italic">Docker Hub</em>. But we need a <code>Dockerfile</code> containing all the commands associated with pulling an available Python image from Docker Hub, creating a working directory, and copying project files from the local directory. The following is a <code>Dockerfile</code> set of instructions we use to deploy our prototype to a Python image:</p>
			<pre class="source-code">
FROM python:3.9
WORKDIR <strong class="bold">/code</strong>
COPY <strong class="bold">./requirements.txt</strong> <strong class="bold">/code/requirements.txt</strong>
RUN pip install --no-cache-dir --upgrade -r 
                <strong class="bold">/code/requirements.txt</strong>
COPY <strong class="bold">./ch11</strong> <strong class="bold">/code</strong>
EXPOSE <strong class="bold">8000</strong>
CMD [“uvicorn”, “main:app”, “--host=0.0.0.0” , “--reload” ,
     “--port”, “8000”]</pre>
			<p>The first line is an instruction that will derive a Python image, usually Linux-based, with an installed Python 3.9 interpreter. The command after that creates an arbitrary folder, <code>/code</code>, which<a id="_idIndexMarker929"/> will become the application’s main folder. The <code>COPY</code> command copies our <code>requirements.txt</code> file to the <code>/code</code> folder, and then the <code>RUN</code> instruction installs the updated modules from the <code>requirements.txt</code> list using the following command:</p>
			<pre>pip install -r requirements.txt </pre>
			<p>Afterward, the second <code>COPY</code> command copies our <code>ch11</code> application to the working directory. The <code>EXPOSE</code> command binds port <code>8000</code> to the local machine’s port <code>8000</code> to run the <code>CMD</code> command, which is the last instruction of the <code>Dockerfile</code>. The <code>CMD</code> instruction uses <em class="italic">uvicorn</em> to run the application at port <code>8000</code> using host <code>0.0.0.0</code> and not <code>localhost</code> to automatically map and utilize the IP address assigned to the image.</p>
			<p>The <code>Dockerfile</code> must be in the same folder as the <code>requirements.txt</code> file and the <code>ch11</code> application. <em class="italic">Figure 11.12</em> shows the organization of the files and folders that needed to be Dockerized to a Python container image:</p>
			<div><div><img src="img/Figure_11.12_B17975.jpg" alt="Figure 11.12 – Setting up the Docker folder structure&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.12 – Setting up the Docker folder structure</p>
			<p>Once all the files and folders are complete, we run the following CLI command within the folder using the terminal console:</p>
			<pre>docker build -t ch11-app .</pre>
			<p>To check the image, run the <code>docker image ls</code> CLI command.</p>
			<h2 id="_idParaDest-329"><a id="_idTextAnchor334"/>Using the Mongo Docker image</h2>
			<p>The <a id="_idIndexMarker930"/>backend of our application is MongoDB, so we need to pull the latest <code>mongo</code> image from Docker Hub using the following CLI command:</p>
			<pre>docker pull mongo:latest</pre>
			<p>And before we run both the <code>ch11-app</code> application and the <code>mongo:latest</code> images, first, we need to create a <code>ch11-network</code> by running the following command:</p>
			<pre>docker network create ch11-network</pre>
			<p>This<a id="_idIndexMarker931"/> network becomes a bridge between <code>mongo</code> and <code>ch11-app</code> once they are deployed as containers. It will establish the connectivity between the two containers to pursue the <em class="italic">Motor-ODM</em> transactions.</p>
			<h2 id="_idParaDest-330"><a id="_idTextAnchor335"/>Creating the containers</h2>
			<p>A <code>docker run</code> command to start and run a pulled or created image. So, running the Mongo image using the <code>ch11-network</code> routes requires the execution of the following CLI command:</p>
			<pre>docker run --name=mongo --rm -p 27017:27017 -d                 --network=ch11-network mongo</pre>
			<p>Inspect the <code>mongo:latest</code> container using the <code>docker inspect</code> command to derive and use its IP address for Motor-ODM’s connectivity. Replace the <code>localhost</code> used in <code>AsyncIOMotorClient</code>, which is found in the <code>config/db.py</code> module of <code>ch11-app</code> with the “inspected” IP address. Be sure to re-build the <code>ch11-app</code> Docker image after the update.</p>
			<p>Now, run the <code>ch11-app</code> image with <code>ch11-network</code> using the following command:</p>
			<pre>docker run --name=ch11-app --rm -p 8000:8000-d             --network=ch11-network ch11-app</pre>
			<p>Access the application through <code>http://localhost:8000/docs</code> to check all the API endpoints from the OpenAPI documentation.</p>
			<p>Now, another approach to simplifying containerization is to use the <em class="italic">Docker Compose</em> tool.</p>
			<h1 id="_idParaDest-331"><a id="_idTextAnchor336"/>Using Docker Compose for deployment</h1>
			<p>However, you <a id="_idIndexMarker934"/>need to install the Docker Compose utility in your operating system, which requires Docker Engine as the pre-installation requirement. After the installation, the next step is to create the <code>docker-decompose.yaml</code> file containing all the services needed to build the images, process the Dockerfile, build the Docker network, and create and run the containers. The following snippet shows the content of our configuration file that sets up the <code>mongo</code> and <code>ch11-app</code> containers: </p>
			<pre class="source-code">
version: “3”
services: 
    <strong class="bold">ch11-mongo</strong>:
        image: “mongo”
        ports:
            - 27017:27017
        expose:
            - 27017
        networks:
            - ch11-network
    
    <strong class="bold">ch11-app</strong>:
        <strong class="bold">build: .     # requires the Dockerfile</strong>
        depends_on: 
            - ch11-mongo
        ports:
            - 8000:8000
        networks:
            - ch11-network
networks:
    <strong class="bold">ch11-network</strong>:
      driver: bridge </pre>
			<p>Instead of running separate Docker CLI commands, Docker Compose creates services, such as <code>ch11-mongo</code> and <code>ch11-app</code>, to manage the containerization and only uses one CLI command to execute these services, <code>docker-compose up</code>. The command not only creates the network of images but also runs all the containers.</p>
			<p>One <a id="_idIndexMarker935"/>advantage <a id="_idIndexMarker936"/>of using Docker Compose is the ease of ORM and ODM configuration. Instead of performing a container inspection to understand which IP address to use, we can use the <em class="italic">service name of the database setup</em> as the hostname to establish database connectivity. It is convenient since the IP address of the <code>mongo</code> container varies for every instance created. The following is the new <code>AsyncIOMotorClient</code> with the <code>ch11-mongo</code> service as the hostname:</p>
			<pre class="source-code">
def create_async_db():
    global client
    client = AsyncIOMotorClient(str(“<strong class="bold">ch11-mongo</strong>:27017”))</pre>
			<p>Now, let us implement an API Gateway design pattern for the containerized applications using the <em class="italic">NGINX</em> utility.</p>
			<h1 id="_idParaDest-332"><a id="_idTextAnchor337"/>Using NGINX as an API Gateway</h1>
			<p>In <a href="B17975_04.xhtml#_idTextAnchor080"><em class="italic">Chapter 4</em></a><em class="italic">, Building the Microservice Application</em>, we implemented the API Gateway <a id="_idIndexMarker937"/>design pattern using only some FastAPI components. In this last chapter, we will build a <em class="italic">reverse proxy server</em> through NGINX that will assign a proxy IP address to each containerized microservice application. These proxy IPs will redirect client requests to the actual microservices running on their respective containers.</p>
			<p>Instead of building an actual NGINX environment, we will be pulling an available NGINX image from Docker Hub to implement the reverse proxy server. This image creation requires a new Docker app folder with a different <code>Dockerfile</code> containing the following instructions:</p>
			<pre class="source-code">
FROM nginx:latest
COPY ./nginx_config.conf /etc/nginx/conf.d/default.conf</pre>
			<p>The <code>Dockerfile</code> instructs the creation of the latest <em class="italic">NGINX</em> image and a copy of a <code>nginx_config.conf</code> file to that image. The file is an <em class="italic">NGINX configuration file</em> that contains<a id="_idIndexMarker938"/> the mapping of a proxy IP address to the actual container address of each microservice application. It also exposes <code>8080</code> as its official port. The following is the content of our <code>nginx_config.conf</code> file:</p>
			<pre class="source-code">
server {
    <strong class="bold">listen 8080;</strong>
    <strong class="bold">location /</strong> {
        <strong class="bold">proxy_pass http://192.168.1.7:8000;</strong>
    }
} </pre>
			<p>The application’s OpenAPI documentation can now be accessed through <code>http://localhost:8080/docs</code>.</p>
			<p>The Dockerization of NGINX must come after deploying applications to the containers. But another approach is to include NGINX’s <code>Dockerfile</code> instructions in the application’s <code>Dockerfile</code> to save time and effort. Or we can create another service in the <code>docker-decompose.yaml</code> file to build and run the NGINX image.  </p>
			<p>And for the last time, let us explore the power of FastAPI in its integration with other popular Python frameworks such as <em class="italic">Flask</em> and <em class="italic">Django</em>.</p>
			<h1 id="_idParaDest-333"><a id="_idTextAnchor338"/>Integrating Flask and Django sub-applications</h1>
			<p><em class="italic">Flask</em> is a <a id="_idIndexMarker939"/>lightweight framework that is popular for its <em class="italic">Jinja2</em> templates and <em class="italic">WSGI</em> server. On<a id="_idIndexMarker940"/> the other hand, <em class="italic">Django</em> is <a id="_idIndexMarker941"/>a Python <a id="_idIndexMarker942"/>framework that promotes rapid development using CLI commands and applies the scaffolding of files and folders to build projects and applications. Django applications can run on either WSGI- or ASGI-based servers. </p>
			<p>We can create, deploy, and run Flask and Django projects inside a FastAPI microservice application. The framework has <code>WSGIMiddleware</code> to wrap both Flask and Django applications and integrate them into the FastAPI platform. Running the FastAPI application through <em class="italic">uvicorn</em> will also run both applications. </p>
			<p>Of the<a id="_idIndexMarker943"/> two, it is easier to integrate the Flask application <a id="_idIndexMarker944"/>with a project than Django. We only need to import the Flask <code>app</code> object into the <code>main.py</code> file, wrap it with <code>WSGIMiddleware</code>, and mount it into the FastAPI <code>app</code> object. The following script shows the part of <code>main.py</code> that integrates our <code>ch11_flask</code> project:</p>
			<pre class="source-code">
<strong class="bold">from ch11_flask.app import app as flask_app</strong>
from fastapi.middleware.wsgi import WSGIMiddleware
app.mount(“/ch11/flask”, <strong class="bold">WSGIMiddleware(flask_app)</strong>)</pre>
			<p>All API endpoints implemented in <code>ch11_flask</code> will be accessed using the URL prefix, <code>/ch11/flask</code>, as indicated in the <code>mount()</code> method. <em class="italic">Figure 11.13</em> shows the location of <code>ch11_flask</code> inside the <code>ch11</code> project:</p>
			<div><div><img src="img/Figure_11.13_B17975.jpg" alt="Figure 11.13 – Creating a Flask application inside the FastAPI project&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.13 – Creating a Flask application inside the FastAPI project</p>
			<p>On the <a id="_idIndexMarker945"/>other hand, the following <code>main.py</code> script integrates our <code>ch11_django</code> application<a id="_idIndexMarker946"/> into the <code>ch11</code> project:</p>
			<pre class="source-code">
import os
<strong class="bold">from django.core.wsgi import get_wsgi_application</strong>
<strong class="bold">from importlib.util import find_spec</strong>
<strong class="bold">from fastapi.staticfiles import StaticFiles</strong>
os.environ.setdefault(‘DJANGO_SETTINGS_MODULE’, 
           <strong class="bold">‘ch11_django.settings’</strong>)
django_app = <strong class="bold">get_wsgi_application()</strong>
app = FastAPI()
app.mount(‘/static’,
    StaticFiles(
         directory=os.path.normpath(
              os.path.join(
           find_spec(‘<strong class="bold">django.contrib.admin</strong>’).origin, 
                  ‘..’, ‘static’)
         )
   ),
   name=’static’,
)
app.mount(‘/ch11/django’, <strong class="bold">WSGIMiddleware(django_app)</strong>)</pre>
			<p>The Django framework has a <code>get_wsgi_application()</code> method that is uses to retrieve its <code>app</code> instance. This instance needs to be wrapped by <code>WSGIMiddleware</code> and <a id="_idIndexMarker947"/>mounted into the FastAPI <code>app</code> object. Moreover, we need to load the <code>settings.py</code> module of the <code>ch11_django</code> project into the FastAPI platform for global access. Also, we need to mount all the static files of the <code>django.contrib.main</code> module, which includes some HTML templates of the Django <em class="italic">security module</em>. </p>
			<p>All views <a id="_idIndexMarker948"/>and endpoints created by the <code>sports</code> application of the <code>ch11_django</code> project must be accessed using the <code>/ch11/django</code> URL prefix. <em class="italic">Figure 11.14</em> shows the placement of the <code>ch11_django</code> project within the ch11 app:</p>
			<div><div><img src="img/Figure_11.14_B17975.jpg" alt="Figure 11.14 – Creating a Django project and application inside a FastAPI object&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.14 – Creating a Django project and application inside a FastAPI object</p>
			<h1 id="_idParaDest-334"><a id="_idTextAnchor339"/>Summary</h1>
			<p>The last chapter has given us the avenue on how to start, deploy, and run a FastAPI microservice application that follows the standards and best practices. It introduces the use of a virtual environment instance to control and manage the installation of modules from the start of the development until the deployment of our applications to Docker containers. The chapter has extensively explained the approaches on how to package, deploy, and run containerized applications. And lastly, the chapter has implemented an NGINX reverse proxy server for the application to build the API Gateway for our specimen.</p>
			<p>Right from the start, we have witnessed the simplicity, power, adaptability, and scalability of the FastAPI framework, from creating background processes to rendering data using HTML templates. Its fast execution of API endpoints through its coroutines gives the framework the edge to become one of the most popular Python frameworks in the future. As the community of FastAPI continues to grow, we hope for more promising features in its future updates, such as support for reactive programming, circuit breakers, and a signature security module. We're hoping for the best for the FastAPI framework!</p>
		</div>
		<div><div></div>
		</div>
	</body></html>