<html><head></head><body><div class="chapter" title="Chapter&#xA0;8.&#xA0;Introducing Shaders"><div class="titlepage"><div><div><h1 class="title"><a id="ch08"/>Chapter 8. Introducing Shaders</h1></div></div></div><p>Congratulations on making it this far! The last two chapters will somewhat stand out from the rest of the book, as we will take a completely different perspective on Kivy and dive into low-level details of the OpenGL renderer, such as the <span class="strong"><strong>OpenGL Shading Language </strong></span>(<span class="strong"><strong>GLSL</strong></span>). This will allow us to write high-performance code with very little overhead.</p><p>Starting from an unscientific introduction to OpenGL, we will proceed to writing a fast sprite-based engine for a starfield demonstration (basically, a screensaver) and finally, a shoot-em-up game (commonly abbreviated as just <span class="emphasis"><em>shmup</em></span>). The code from this chapter will serve as a basis for the next one, unlike other projects in this book that were largely self-contained. We will lay the foundation here and then build upon it in the next chapter, turning a technical demo into a playable game.</p><p>This chapter attempts to cover many complex topics with a sufficient level of detail, but it is way too short to serve as an all-encompassing reference guide. In addition to this, OpenGL, as a standard, evolves very quickly, introducing new features and deprecating the obsolete stuff. So, if you notice a discrepancy between the material presented in the chapter and the objective reality, please look it up—chances are that you're living in the bright future of computing, where things have changed significantly.</p><p>It should be mentioned upfront that the approach to high-performance rendering discussed here, despite being wildly different from the regular Kivy code, for the most part stays compatible with it and can be used side by side with ordinary widgets. Therefore, it's perfectly feasible to implement only the resource-hungry parts of an app in GLSL—those that will otherwise become a performance bottleneck.</p><div class="section" title="Unscientific introduction to OpenGL"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec53"/>Unscientific introduction to OpenGL</h1></div></div></div><p>This section will provide a<a id="id521" class="indexterm"/> quick introduction to the basics of OpenGL. It's next to impossible to meaningfully summarize all the nooks and crannies of the standard here; hence it is "unscientific," superficial.</p><p>OpenGL is a popular low-level graphical API. It's standardized and almost ubiquitous. Desktop and mobile operating systems commonly ship with an implementation of OpenGL (in the case of mobile, OpenGL ES, a feature-restricted subset of the standard; here, <span class="strong"><strong>ES</strong></span> stands for <a id="id522" class="indexterm"/>
<span class="strong"><strong>embedded systems</strong></span>). Modern web browsers also implement a variant of OpenGL ES called WebGL.</p><p>Wide distribution<a id="id523" class="indexterm"/> and a well-defined compatibility makes OpenGL a good target for cross-platform apps, especially video games and graphical toolkits. Kivy also relies on OpenGL to perform rendering across all the supported platforms.</p><div class="section" title="Concepts and parallelism"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec99"/>Concepts and parallelism</h2></div></div></div><p>OpenGL operates<a id="id524" class="indexterm"/> on basic primitives such as individual vertices and pixels on screen. For example, we can feed three vertices to it and render a triangle, thus computing color for each affected pixel (depending on the pipeline described in the next image). You might have guessed that working at this level of abstraction is extremely<a id="id525" class="indexterm"/> cumbersome. This pretty much summarizes the raison d'être of high-level graphical frameworks, including Kivy: they're there to conceal the gory details of a rendering pipeline behind a more comfortable abstraction, such as working with widgets and layouts.</p><p>The low-level rendering pipeline functions as follows:</p><div class="mediaobject"><img src="graphics/B01620_08_01.jpg" alt="Concepts and parallelism"/><div class="caption"><p>An OpenGL pipeline (oversimplified)</p></div></div><p>The complete explanation of the preceding figure is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The application gives OpenGL an array of <a id="id526" class="indexterm"/><span class="strong"><strong>vertices</strong></span> (points), <span class="strong"><strong>indices</strong></span> that allow us to reuse the points, and other arbitrary values (called <a id="id527" class="indexterm"/><span class="strong"><strong>uniforms</strong></span>).</li><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>vertex shader</strong></span> is<a id="id528" class="indexterm"/> invoked for every vertex, transforming it if needed and optionally doing other calculations. Its output is then passed to a corresponding fragment shader.</li><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>fragment shader</strong></span> (sometimes <a id="id529" class="indexterm"/>called <span class="strong"><strong>pixel shader</strong></span>) is invoked for every affected pixel, computing that pixel's color. More often than not, it takes into account the vertex shader's output but might also return, for example, a constant color.</li><li class="listitem" style="list-style-type: disc">Pixels are rendered on screen, and other bookkeeping tasks are performed; these tasks are of no interest to us at this point.</li></ul></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note47"/>Note</h3><p>A collection of vertices used together as a batch is commonly called a<a id="id530" class="indexterm"/> <span class="strong"><strong>model</strong></span> or <span class="strong"><strong>mesh</strong></span>. It is not <a id="id531" class="indexterm"/>necessarily continuous and might consist of scattered polygons as well; the rationale for such models will be mentioned shortly.</p></div></div><p>The "secret sauce" behind the blazing speed of OpenGL is its inherent massive parallelism. The functions mentioned earlier (namely, vertex and pixel shaders) might not be crazy fast by themselves, but as they are invoked simultaneously on a GPU, the delay imposed by shaders usually doesn't grow exponentially with the shaders' complexity; such growth can be close to linear on a decent hardware.</p><p>To put things in scale, given today's personal computers (at the time of writing this book), we're talking about multitasking and parallel programming with anywhere from 2 to 16 CPU cores in commodity hardware. Mid-range graphics cards, on the other hand, effectively have thousands of GPU cores; this makes them capable of running way more computations in parallel.</p><p>As a consequence though, each task runs in isolation. Unlike the threads in general-purpose programming, a shader cannot wait for the other shader's output without significantly degrading performance, except where implied by pipeline architecture (as mentioned earlier, a vertex shader passes values to a fragment shader). This restriction might be a bit mind-bending to work around as you start writing GLSL.</p><p>This is also why some algorithms can be implemented to run efficiently on GPU while others cannot. Interestingly, modern cryptography functions such as<a id="id532" class="indexterm"/> <span class="strong"><strong>bcrypt</strong></span> are specifically designed to reduce performance of a highly parallelized implementation—this makes such functions inherently more secure by limiting the effectiveness of a brute-force attack.</p></div><div class="section" title="Performance gains, or lack thereof"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec100"/>Performance gains, or lack thereof</h2></div></div></div><p>It is important to <a id="id533" class="indexterm"/>understand that there are no immediate performance gains from using raw OpenGL calls at all times; in many cases, high-level frameworks such as Kivy will do just fine. For example, when rendering a polygon somewhere on a screen, roughly the following sequence of actions takes place:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The geometry and position of a polygon are defined in Python.</li><li class="listitem">The vertices, indices, and related assets (such as textures) are uploaded to the graphics driver.</li><li class="listitem">The vertex shader is invoked. It applies the necessary transformations, including positioning, rotation, scaling, and so on.</li><li class="listitem">Finally, the corresponding fragment shader is invoked; this results in a raster image that might be displayed on the screen.</li></ol></div><p>It doesn't matter<a id="id534" class="indexterm"/> whether you use Kivy widgets for this task or stick with writing raw OpenGL commands and GLSL shaders—both the performance and result will likely be the same, with negligible differences at best. This is because Kivy runs very similar OpenGL code behind the scenes.</p><p>In other words, this example bears very little potential for low-level optimization, and this is exactly the reason why a game such as <span class="emphasis"><em>Kivy Bird</em></span>, consisting of scarce rectangles and very little else, should be implemented at the highest level of abstraction available. Basically, we could have optimized away the creation of a widget or two in Kivy Bird, but this is hardly even measurable.</p><div class="section" title="Improving performance"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec27"/>Improving performance</h3></div></div></div><p>So, how do we actually<a id="id535" class="indexterm"/> boost performance? The answer is, by reducing the amount of work done on the Python side of things and batching similar objects together for rendering.</p><p>Let's consider the scenario where we need to render over 9,000 similar polygons (a particle system, for example, autumn leaves scattered on the ground or a cluster of stars in space).</p><p>If we use Kivy widgets for individual polygons, we're creating a large number of Python objects that exist solely for the purpose of serializing themselves to OpenGL instructions. Moreover, each widget has its own set of vertices that it feeds to the graphics driver, thus issuing excessive API calls and creating a lot of distinct (yet very similar) meshes.</p><p>Manually, we're able to, at the very least, do the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Avoid the instantiation of many Python classes and just keep all the coordinates in an array. If we store them in a format suitable for direct OpenGL consumption, there is no need for the serialization step.</li><li class="listitem" style="list-style-type: disc">Lump all geometry together as a single model and thus make much less API calls. Batching is always a nice optimization, as it allows OpenGL to do a better job at the parallel execution of things.</li></ul></div><p>We will implement the described approach by the end of this chapter.</p></div></div><div class="section" title="Taking a closer look at GLSL"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec101"/>Taking a closer look at GLSL</h2></div></div></div><p>As a language, GLSL<a id="id536" class="indexterm"/> is closely related to C; in particular, syntactically, they're very similar. GLSL is strongly, statically typed (more so than C).</p><p>If you aren't familiar with the<a id="id537" class="indexterm"/> C syntax, here's a very quick primer. First of all, unlike Python, in C-like languages, indentation is insignificant, and ending statements with a semicolon is mandatory. Logical blocks are enclosed in curly braces.</p><p>GLSL supports both C and C++ style comments:</p><div class="informalexample"><pre class="programlisting">/* ANSI C-style comment */
// C++ one-line comment</pre></div><p>Variable declarations are in the <code class="literal">[type] [name] [= optional value];</code> format:</p><div class="informalexample"><pre class="programlisting">float a; // this has no direct Python equivalent
int b = 1;</pre></div><p>Functions are defined using the <code class="literal">[type] [name] ([arguments]) { [body of function] }</code> syntax:</p><div class="informalexample"><pre class="programlisting">float pow2(float x)
{
    return x * x;
}</pre></div><p>Control structures are written like this:</p><div class="informalexample"><pre class="programlisting">if (x &lt; 9.0)
{
    x = 9.0;
}</pre></div><p>That's it for the most part; you should be able to read the GLSL code now, regardless of whether you have a background in C programming or not.</p><p>The entry point of a shader is designated by a <code class="literal">main()</code> function. In the following code, we'll put both vertex and fragment shaders together in one file; so, there will be two <code class="literal">main()</code> functions per file. This is how these functions look:</p><div class="informalexample"><pre class="programlisting">void main(void)
{
    // code
}</pre></div><p>A special <code class="literal">void</code> type means absence of value, and unlike Python's <code class="literal">NoneType</code>, you cannot declare a variable of type <code class="literal">void</code>. In the case of the preceding <code class="literal">main()</code> function, both the return value and arguments are omitted; hence the function's declaration reads <code class="literal">void main(void)</code>. Instead of returning the result of a computation from the function, shaders write it to special built-in variables, <code class="literal">gl_Position</code>, <code class="literal">gl_FragColor</code>, and others, depending on the shader type and the desired effect. This also holds true for input parameters.</p><p>A GLSL type system closely reflects its usage domain. Unlike C, it has highly specialized types for vectors and matrices; these types support mathematical operations on them (so, you can multiply matrices with just the <code class="literal">mat1 * mat2</code> syntax; how cool is that!). In computer graphics, matrices are commonly used to mess with the coordinate system, as you will see shortly.</p><p>In the next section, we'll <a id="id538" class="indexterm"/>write a couple of simple GLSL shaders to demonstrate some of the concepts discussed earlier.</p></div></div></div>
<div class="section" title="Using custom shaders in Kivy"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec54"/>Using custom shaders in Kivy</h1></div></div></div><p>Apart from <a id="id539" class="indexterm"/>GLSL, we also <a id="id540" class="indexterm"/>need to have the usual Python code that initializes the window, loads shaders, and so on. The following program will serve as a good<a id="id541" class="indexterm"/> starting point:</p><div class="informalexample"><pre class="programlisting">from kivy.app import App
from kivy.base import EventLoop
from kivy.graphics import Mesh
from kivy.graphics.instructions import RenderContext
from kivy.uix.widget import Widget

class GlslDemo(Widget):
    def __init__(self, **kwargs):
        Widget.__init__(self, **kwargs)
        self.canvas = RenderContext(use_parent_projection=True)
        self.canvas.shader.source = 'basic.glsl'
        # Set up geometry here.

class GlslApp(App):
    def build(self):
        EventLoop.ensure_window()
        return GlslDemo()

if __name__ == '__main__':
    GlslApp().run()</pre></div><p>We created just one widget named <code class="literal">GlslDemo</code> in this example; it will host all the rendering. <code class="literal">RenderContext</code> is a customizable <code class="literal">Canvas</code> subclass that allows us to replace shaders easily, as shown in the listing. The <code class="literal">basic.glsl</code> file contains both vertex and fragment shaders; we will get to it in a minute.</p><p>Note that this time, we aren't using the Kivy language at all, because no layout hierarchy is planned, so there is no accompanying <code class="literal">glsl.kv</code> file. Instead, we will designate the root widget manually by returning it from the <code class="literal">GlslApp.build()</code> method.</p><p>The call to <code class="literal">EventLoop.ensure_window()</code> is needed, because we want to be able to access OpenGL features, such as the GLSL compiler, while running <code class="literal">GlslDemo.__init__()</code>. If there is still no application window (and more importantly, no corresponding OpenGL context) at that point in time, the program will crash.</p><div class="section" title="Building the geometry"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec102"/>Building the geometry</h2></div></div></div><p>Before we begin writing shaders, we need something to render—a series of vertices, that is, a model. We'll stick<a id="id542" class="indexterm"/> with a simple rectangle that consists of two right triangles with a common hypotenuse (the subdivision is because baseline polygons are essentially triangular).</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note48"/>Note</h3><p>Kivy, albeit two-dimensional for the most part, does not impose this limitation in any way. OpenGL, on the other hand, is inherently three-dimensional, so you can use realistic models seamlessly to create modern-looking games, and even mix them with regular Kivy widgets for UI (in-game menus and so on). This possibility is not further detailed in the book, but the underlying mechanics are just the same as described here.</p></div></div><p>This is the updated <code class="literal">__init__()</code> method of the <code class="literal">GlslDemo</code> widget, with an explanation following it:</p><div class="informalexample"><pre class="programlisting">def __init__(self, **kwargs):
    Widget.__init__(self, **kwargs)
    self.canvas = RenderContext(use_parent_projection=True)
    self.canvas.shader.source = 'basic.glsl'

    fmt = ( # Step 1
        (b'vPosition', 2, 'float'),
    )

    vertices = ( # Step 2
        0,   0,
        255, 0,
        255, 255,
        0,   255,
    )

    indices = (0, 1, 2, 2, 3, 0)  # Step 3

    with self.canvas:
        Mesh(fmt=fmt, mode='triangles',  # Step 4
             indices=indices, vertices=vertices)</pre></div><p>Let's walk through this function, because it's essential to understand it correctly before moving on to more complex things:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">When writing code that makes use of OpenGL, the first thing you'll notice is that there is no built-in standard format for vertices that we need to adhere to; instead, we need to define such a format ourselves. In the simplest case, we need just the position of each vertex; this is called <code class="literal">vPosition</code>. Our rectangle is two-dimensional, so we'll pass just two coordinates, which are floating point by default. Hence, we get the resulting line <code class="literal">(b'vPosition', 2, 'float')</code>.</li><li class="listitem" style="list-style-type: disc">Now that we have decided on the format of the vertices, it's time to put these vertices in an array that will soon be handed over to the renderer. This is exactly what the <code class="literal">vertices = (...)</code> line does. It's important that the tuple is flat and unstructured. We will define the record format separately and then pack all the values tightly together, without field delimiters and the like—all in the name of efficiency. This is also how C structs typically work.</li><li class="listitem" style="list-style-type: disc">Indices are needed to duplicate (reuse) vertices. More often than not, a vertex is used in more than one triangle. Instead of repeating it literally in the array of vertices, we resort to repeating its index in the array of indices—it's typically smaller, so the whole thing ends up taking less memory, proportional to the size of an individual vertex. See the next section for a more detailed explanation of indices.</li><li class="listitem" style="list-style-type: disc">With all the required data structures in place, we can finally assemble the mesh using the homonymous Kivy canvas instruction, <code class="literal">Mesh</code>. Now, it will be rendered over the course of normal widget rendering, which has a nice side effect of composability with other Kivy widgets. Our GLSL code can be effortlessly used in conjunction with all the previous developments. This is certainly a good thing.</li></ul></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note49"/>Note</h3><p>Throughout this chapter, we have used the word <span class="emphasis"><em>array</em></span> in a C sense—a continuous memory region containing homogeneous data. This is only tentatively related to the Python data structure having the same name; in fact, on the Python side of things, we're mostly using tuples or lists as a substitute.</p></div></div><div class="section" title="Illustrating the Indices"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec28"/>Illustrating the Indices</h3></div></div></div><p>To explain<a id="id543" class="indexterm"/> OpenGL indices better, let's visualize our example. These are <a id="id544" class="indexterm"/>our vertices from the preceding sample code, in the format of (<span class="emphasis"><em>x</em></span>, <span class="emphasis"><em>y</em></span>):</p><div class="informalexample"><pre class="programlisting">vertices = (
    0,   0,
    255, 0,
    255, 255,
    0,   255,
)</pre></div><p>An index is just that—a serial number of a vertex in the <code class="literal">vertices</code> list, and it is zero-based. The following figure illustrates the assignment of indices to the vertices in this setup:</p><div class="mediaobject"><img src="graphics/B01620_08_02.jpg" alt="Illustrating the Indices"/><div class="caption"><p>Vertices scattered on a plane</p></div></div><p>Right now, the vertices aren't connected, so they form a point cloud at best, not a structured polygonal shape. To fix this, we need to specify the <code class="literal">indices</code> list—it will group the existing vertices into triangles. Its definition, again taken from the sample code, is as follows:</p><div class="informalexample"><pre class="programlisting">indices = (
    0, 1, 2,<span class="strong"><strong>  # Three vertices make a triangle.</strong></span>
    2, 3, 0,<span class="strong"><strong>  # And another one.</strong></span>
)</pre></div><p>We've built two triangles here: the first one consists of vertices 0 to 2, and the second one out of vertices 2, 3, and 0. Note how the 0<sup>th</sup> and 2<sup>nd</sup> vertices are reused.</p><p>This is illustrated in the following figure. Never mind the colors; they are strictly explanatory and not "real" colors yet. We'll get to coloring things on the screen shortly.</p><div class="mediaobject"><img src="graphics/B01620_08_03.jpg" alt="Illustrating the Indices"/><div class="caption"><p>Building triangles out of vertices</p></div></div><p>This pretty much <a id="id545" class="indexterm"/>summarizes the utility and usage of indices in OpenGL-related code.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note50"/>Note</h3><p>The tendency of optimizing in-memory sizes of data structures in OpenGL has very little to do with saving RAM per se—the video card interface throughput is a more serious bottleneck in most scenarios, so we're aiming at passing more stuff per frame, not just compressing data for the sake of economy. This distinction, while very important, makes no difference early on.</p></div></div></div></div><div class="section" title="Writing GLSL"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec103"/>Writing GLSL</h2></div></div></div><p>This is where things <a id="id546" class="indexterm"/>will get more interesting. In a moment, we'll be writing GLSL code that executes on a GPU. As we've already mentioned, it's C-like and crazy fast.</p><p>Let's start with the basics. Kivy<a id="id547" class="indexterm"/> expects that both the vertex and the fragment shaders live in the same file, delimited using a special syntax, <code class="literal">'---vertex'</code> and <code class="literal">'---fragment'</code> (shown in the next code snippet). It's important to stress out that both these delimiters and the <code class="literal">$HEADER$</code> syntax are specific to Kivy; they are not part of any standard, and you won't see them elsewhere.</p><p>This is how the boilerplate for a typical Kivy shader file looks:</p><div class="informalexample"><pre class="programlisting">---vertex
$HEADER$

void main(void)
{
    // vertex shader
    gl_Position = ...
}

---fragment
$HEADER$

void main(void)
{
    // fragment shader
    gl_FragColor = ...
}</pre></div><p>Henceforth, we'll omit most of the boilerplate code to shorten listings—but keep in mind that it's always assumed to be there; otherwise, things might not work as expected, or not at all.</p><p>The <code class="literal">$HEADER$</code> macro<a id="id548" class="indexterm"/> is context-sensitive and means different things depending on the type of shader.</p><p>Inside a vertex shader, <code class="literal">$HEADER$</code> is a shortcut for roughly the following code:</p><div class="informalexample"><pre class="programlisting">varying vec4 frag_color;
varying vec2 tex_coord0;

attribute vec2 vPosition;
attribute vec2 vTexCoords0;

uniform mat4  modelview_mat;
uniform mat4  projection_mat;
uniform vec4  color;
uniform float opacity;</pre></div><p>In a fragment shader, <code class="literal">$HEADER$</code> expands to the following code:</p><div class="informalexample"><pre class="programlisting">varying vec4 frag_color;
varying vec2 tex_coord0;

uniform sampler2D texture0;</pre></div><p>(Some not very important bits have been redacted for clarity.)</p><p>Clearly, these might be subject to change in future versions of Kivy.</p><div class="section" title="Storage classes and types"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec29"/>Storage classes and types</h3></div></div></div><p>In the previous code, variables are annotated not only with a type, but also with a storage qualifier. Here is a<a id="id549" class="indexterm"/> quick rundown of both:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th colspan="2" style="text-align: center" valign="bottom">
<p>Storage classes</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">attribute</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This denotes the properties of vertices as specified by the vertex format. Attributes <a id="id550" class="indexterm"/>are passed from an application.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">uniform</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Uniforms are global variables at the GLSL level. They are also passed from an<a id="id551" class="indexterm"/> application, but unlike attributes these do not vary with each vertex.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">varying</code>
</p>
</td><td style="text-align: left" valign="top">
<p>These are variables <a id="id552" class="indexterm"/>passed from the vertex shader to the fragment shader.</p>
</td></tr><tr><td colspan="2" style="text-align: center" valign="top">
<p>
<span class="strong"><strong>Commonly used data types</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">float</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is<a id="id553" class="indexterm"/> the scalar floating-point variable type, similar to<a id="id554" class="indexterm"/> other languages.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">vec2</code>, <code class="literal">vec3</code>, <code class="literal">vec4</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is a tuple<a id="id555" class="indexterm"/> of length 2, 3, and 4; it contains floats. It might represent points, colors, and so on.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">mat2</code>, <code class="literal">mat3</code>, <code class="literal">mat4</code>
</p>
</td><td style="text-align: left" valign="top">
<p>These refer to<a id="id556" class="indexterm"/> matrices of sizes 2 × 2, 3 × 3, 4 × 4, respectively.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">sampler2D</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This represents a<a id="id557" class="indexterm"/> texture that allows lookups (getting the color from specified coordinates).</p>
</td></tr></tbody></table></div></div><div class="section" title="Basic shaders"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec30"/>Basic shaders</h3></div></div></div><p>Now, without further preliminaries, let's write our first and simplest shaders that do nothing special.</p><p>The default-like <a id="id558" class="indexterm"/>vertex shader reads:</p><div class="informalexample"><pre class="programlisting">void main(void)
{
    vec4 pos = vec4(vPosition.xy, 0.0, 1.0);
    gl_Position = projection_mat * modelview_mat * pos;
}</pre></div><p>This transforms the location of each vertex into Kivy's preferred coordinate system, with the origin at the lower-left corner.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note51"/>Note</h3><p>We will not attempt to describe the nuances of the transformation of coordinates here, as the topic is way too complex for an entry-level tutorial. Moreover, it isn't even necessary to fully understand this code, or to finish reading the book.</p><p>If you're interested in a more comprehensive description of the topic, a nice short summary of the OpenGL coordinate space and<a id="id559" class="indexterm"/> the use of matrices can be found at <a class="ulink" href="http://www.learnopengles.com/understanding-opengls-matrices/">http://www.learnopengles.com/understanding-opengls-matrices/</a>.</p></div></div><p>The easiest<a id="id560" class="indexterm"/> fragment shader is a function that returns a constant color:</p><div class="informalexample"><pre class="programlisting">void main(void)
{
    gl_FragColor = vec4(1.0, 0.0, 0.5, 1.0);
}</pre></div><p>This outputs an RGBA color equal to <code class="literal">#FF007F</code> for every pixel.</p><p>If you run the program now, you would see output similar to the following screenshot:</p><div class="mediaobject"><img src="graphics/B01620_08_04.jpg" alt="Basic shaders"/><div class="caption"><p>Basic shaders in action: default transformation and flat color</p></div></div><p>Finally, we have a visible result of our ordeal. It isn't particularly interesting right now, but it is still better than nothing. Let's fiddle with it and see where this takes us.</p></div><div class="section" title="Procedural coloring"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec31"/>Procedural coloring</h3></div></div></div><p>Another lazy way<a id="id561" class="indexterm"/> to compute color, apart from always returning the same value, is to derive it from something that is immediately available in a corresponding shader, for<a id="id562" class="indexterm"/> example, fragment coordinates.</p><p>Let's assume that we want to compute each pixel's RGB color as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <code class="literal">R</code> channel will be proportional to the <span class="emphasis"><em>x</em></span> coordinate</li><li class="listitem" style="list-style-type: disc">The <code class="literal">G</code> channel will be proportional to the <span class="emphasis"><em>y</em></span> coordinate</li><li class="listitem" style="list-style-type: disc"><code class="literal">B</code> will be an average of <code class="literal">R</code> and <code class="literal">G</code>.</li></ul></div><p>This simple algorithm can be easily implemented in a fragment shader as follows:</p><div class="informalexample"><pre class="programlisting">void main(void)
{
    float r = gl_FragCoord.x / 255.0;
    float g = gl_FragCoord.y / 255.0;
    float b = 0.5 * (r + g);
    gl_FragColor = vec4(r, g, b, 1.0);
}</pre></div><p>The <code class="literal">gl_FragCoord</code> built-in variable contains fragment coordinates (not necessarily representing a whole <a id="id563" class="indexterm"/>physical pixel) relative to the application window. A division by <code class="literal">255.0</code>—the size of the mesh, inlined for simplicity—is necessary to put color components in the range of [0...1].</p><p>This replaces the previously seen flat color with a gradient as follows:</p><div class="mediaobject"><img src="graphics/B01620_08_05.jpg" alt="Procedural coloring"/><div class="caption"><p>Computing color based on fragment coordinates</p></div></div></div><div class="section" title="Colorful vertices"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec32"/>Colorful vertices</h3></div></div></div><p>A similar effect can be made data-driven by giving vertices their own colors. For this, we need to expand the vertex format to <a id="id564" class="indexterm"/>contain another per-vertex attribute, <code class="literal">vColor</code>. In Python code, this amounts to the following definition:</p><div class="informalexample"><pre class="programlisting">fmt = (
    (b'vPosition', 2, 'float'),
    (b'vColor', 3, 'float'),
)

vertices = (
    0,   0,   0.462, 0.839, 1,
    255, 0,   0.831, 0.984, 0.474,
    255, 255, 1,     0.541, 0.847,
    0,   255, 1,     0.988, 0.474,
)

indices = (0, 1, 2, 2, 3, 0)</pre></div><p>With an updated format, a vertex now consists of five floats, up from two. It's crucial to keep the <code class="literal">vertices</code> list in sync with the format; otherwise, weird things will happen.</p><p>As per our declaration, <code class="literal">vColor</code> is an RGB color, and for a vertex shader, we ultimately need RGBA. Instead <a id="id565" class="indexterm"/>of passing a constant alpha channel for each vertex, we'll pad it in the vertex shader, similar to how we expand <code class="literal">vPosition</code> from <code class="literal">vec2</code> to <code class="literal">vec4</code>.</p><p>This is what our revised vertex shader looks like:</p><div class="informalexample"><pre class="programlisting">attribute vec3 vColor;

void main(void)
{
    frag_color = vec4(vColor.rgb, 1.0);
    vec4 pos = vec4(vPosition.xy, 0.0, 1.0);
    gl_Position = projection_mat * modelview_mat * pos;
}</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note52"/>Note</h3><p>GLSL notations such as <code class="literal">vColor.rgb</code> and <code class="literal">vPosition.xy</code> are called <span class="emphasis"><em>swizzling.</em></span> They can be used to efficiently manipulate parts of a vector, similar in concept to Python slices.</p><p>By itself, <code class="literal">vColor.rgb</code> simply means "take the first three vector components;" in Python code, we would write <code class="literal">vColor[:3]</code>. It's also possible to, for example, reverse the order of the color channels easily using <code class="literal">vColor.bgr</code>, or take just one channel using <code class="literal">vColor.ggg</code> (this will turn the resulting picture into grayscale).</p><p>Up to four vector components can be addressed in this fashion, using either <code class="literal">.xyzw</code>, <code class="literal">.rgba</code>, or a more obscure <code class="literal">.stpq</code> notation; they all do exactly the same thing.</p></div></div><p>Having done this, the fragment shader becomes very simple:</p><div class="informalexample"><pre class="programlisting">void main(void)
{
    gl_FragColor = frag_color;
}</pre></div><p>Interestingly enough, we get <a id="id566" class="indexterm"/>color interpolation between vertices for free, resulting in a smooth gradient; this is how OpenGL works. The next screenshot depicts the output of the program:</p><div class="mediaobject"><img src="graphics/B01620_08_06.jpg" alt="Colorful vertices"/><div class="caption"><p>Passing color as a vertex attribute</p></div></div></div><div class="section" title="Texture mapping"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec33"/>Texture mapping</h3></div></div></div><p>To wrap up this series of simple demos, let's apply a texture to our rectangle. Once again, we need to expand the<a id="id567" class="indexterm"/> definition of a vertex format, this time, to assign texture coordinates to each vertex:</p><div class="informalexample"><pre class="programlisting">fmt = (
    (b'vPosition', 2, 'float'),
    (b'vTexCoords0', 2, 'float'),
)

vertices = (
    0,   0,   0, 1,
    255, 0,   1, 1,
    255, 255, 1, 0,
    0,   255, 0, 0,
)</pre></div><p>Texture coordinates are usually in the [0...1] range, with the origin in the upper-left corner—note that this is different from the default Kivy's coordinate system. If, at some point, you see a texture flipped upside down for no apparent reason, check the texture coordinates first—they're likely the culprit.</p><p>One more thing that we need to take care of on the Python side of things is loading the texture and passing it to renderer. This is how it's done:</p><div class="informalexample"><pre class="programlisting">from kivy.core.image import Image

with self.canvas:
    Mesh(fmt=fmt, mode='triangles',
         indices=indices, vertices=vertices,
         texture=Image('kivy.png').texture)</pre></div><p>This will load a<a id="id568" class="indexterm"/> file named <code class="literal">kivy.png</code> from the current directory and convert it into a usable texture. For the sake of demonstration, we will use the following image:</p><div class="mediaobject"><img src="graphics/B01620_08_08.jpg" alt="Texture mapping"/><div class="caption"><p>The texture used for the demo</p></div></div><p>As for the shaders, they aren't very different from the previous iteration. The vertex shader simply passes texture coordinates through, untouched:</p><div class="informalexample"><pre class="programlisting">void main(void)
{
    tex_coord0 = vTexCoords0;
    vec4 pos = vec4(vPosition.xy, 0.0, 1.0);
    gl_Position = projection_mat * modelview_mat * pos;
}</pre></div><p>The fragment<a id="id569" class="indexterm"/> shader uses the interpolated <code class="literal">tex_coord0</code> coordinates to perform a lookup on the <code class="literal">texture0</code> texture, thus returning the corresponding color:</p><div class="informalexample"><pre class="programlisting">void main(void)
{
    gl_FragColor = texture2D(texture0, tex_coord0);
}</pre></div><p>When put together, our code delivers the expected result:</p><div class="mediaobject"><img src="graphics/B01620_08_07.jpg" alt="Texture mapping"/><div class="caption"><p>Simple GLSL texture mapping</p></div></div><p>To summarize, this introduction to shaders should have given you enough courage to try to write your own small shader-based programs. Most importantly, don't feel intimidated if certain things<a id="id570" class="indexterm"/> don't make much sense—GLSL is a complex subject, and learning it systematically is not a small endeavor.</p><p>It pays off, however, in giving you a much better understanding of how things work under the hood. Even if you don't write low-level code on a daily basis, you can still use this knowledge to identify and avoid performance bottlenecks and generally improve the architecture of your applications.</p></div></div></div>
<div class="section" title="Making the Starfield app"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec55"/>Making the Starfield app</h1></div></div></div><p>Armed with our newfound knowledge of GLSL, let's build a starfield screensaver, that is, a non-interactive <a id="id571" class="indexterm"/>demonstration of stars fleeing from the center of the screen to its sides, under the influence of an imaginary centrifugal force or something.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip41"/>Tip</h3><p>As dynamic visual effects are hard to describe unequivocally and screenshots aren't very helpful in this regard either, run the code that accompanies the chapter to get a better idea of what's going on.</p></div></div><p>Conceptually, each star goes through the same action sequence:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">It spawns randomly near the center of the screen.</li><li class="listitem">The star moves in the opposite direction from the screen center until it's no longer visible.</li><li class="listitem">Then it respawns, going back to square one.</li></ol></div><p>We will also make<a id="id572" class="indexterm"/> stars accelerate and grow in size as they approach the edges of the screen to simulate the faux depth.</p><p>The following screenshot attempts (or, to be more specific, fails due to the highly dynamic nature of the demo) to illustrate what the end result will look like:</p><div class="mediaobject"><img src="graphics/B01620_08_09.jpg" alt="Making the Starfield app"/><div class="caption"><p>A screenshot cannot convey the motion sickness, but it's there</p></div></div><div class="section" title="Application structure"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec104"/>Application structure</h2></div></div></div><p>The new <a id="id573" class="indexterm"/>application class bears a striking resemblance to what we did earlier<a id="id574" class="indexterm"/> in this chapter. Similar to the examples discussed earlier, we aren't using the Kivy language to describe the (non-existent) widget hierarchy, so there is no <code class="literal">starfield.kv</code> file.</p><p>The class consists of two methods, which are shown here:</p><div class="informalexample"><pre class="programlisting">from kivy.base import EventLoop
from kivy.clock import Clock

class StarfieldApp(App):
    def build(self):
        EventLoop.ensure_window()
        return Starfield()

    def on_start(self):
        Clock.schedule_interval(self.root.update_glsl,
                                60 ** -1)</pre></div><p>The <code class="literal">build()</code> method <a id="id575" class="indexterm"/>creates and returns the root widget, <code class="literal">Starfield</code>; it will be in charge of all the math and rendering—basically, everything that happens throughout the application.</p><p>The <code class="literal">on_start()</code> handler tells the aforementioned root widget to update 60 times per second by calling its <code class="literal">update_glsl()</code> method after the application has been started.</p><p>The <code class="literal">Starfield</code> class<a id="id576" class="indexterm"/> is also split in two: there is the usual <code class="literal">__init__()</code> method, which is responsible<a id="id577" class="indexterm"/> for the creation of the data structures, and the <code class="literal">update_glsl()</code> method, which advances the scene (calculates an updated <a id="id578" class="indexterm"/>position of each star) and renders stars on the screen.</p></div><div class="section" title="Data structures and initializers"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec105"/>Data structures and initializers</h2></div></div></div><p>Let's <a id="id579" class="indexterm"/>now review<a id="id580" class="indexterm"/> the<a id="id581" class="indexterm"/> initialization <a id="id582" class="indexterm"/>code:</p><div class="informalexample"><pre class="programlisting">from kivy.core.image import Image
from kivy.graphics.instructions import RenderContext
from kivy.uix.widget import Widget

NSTARS = 1000

class Starfield(Widget):
    def __init__(self, **kwargs):
        Widget.__init__(self, **kwargs)
        self.canvas = RenderContext(use_parent_projection=True)
        self.canvas.shader.source = 'starfield.glsl'

        self.vfmt = (
            (b'vCenter',     2, 'float'),
            (b'vScale',      1, 'float'),
            (b'vPosition',   2, 'float'),
            (b'vTexCoords0', 2, 'float'),
        )

        self.vsize = sum(attr[1] for attr in self.vfmt)

        self.indices = []
        for i in range(0, 4 * NSTARS, 4):
            self.indices.extend((
                i, i + 1, i + 2, i + 2, i + 3, i))

        self.vertices = []
        for i in range(NSTARS):
            self.vertices.extend((
                0, 0, 1, -24, -24, 0, 1,
                0, 0, 1,  24, -24, 1, 1,
                0, 0, 1,  24,  24, 1, 0,
                0, 0, 1, -24,  24, 0, 0,
            ))

        self.texture = Image('star.png').texture

        self.stars = [Star(self, i) for i in range(NSTARS)]</pre></div><p>
<code class="literal">NSTARS</code> is the total number of stars; try raising or lowering it to alter the density of the starfield. Regarding <a id="id583" class="indexterm"/>performance, even a mediocre machine boasting a slow, integrated Intel video card easily supports thousands of stars. Any half-decent<a id="id584" class="indexterm"/> dedicated graphics hardware will handle tens of thousands of simultaneously rendered sprites with ease.</p><p>Unlike the previous examples, this time we will <a id="id585" class="indexterm"/>not fill the indices and vertices with the final, useful data right away; instead, we will prepare placeholder arrays that will be continuously updated later, as part of the <code class="literal">update_glsl()</code> routine.</p><p>The <code class="literal">vfmt</code> vertex format includes the following properties; a part of these has already been showcased in this chapter:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Vertex attribute</p>
</th><th style="text-align: left" valign="bottom">
<p>Its function</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">vCenter</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This denotes the <a id="id586" class="indexterm"/>coordinates of the star's center point on the screen</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">vScale</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the star's <a id="id587" class="indexterm"/>size factor, 1 being the original size (48 × 48 pixels)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">vPosition</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the <a id="id588" class="indexterm"/>position of each vertex relative to the star's center point</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">vTexCoords0</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This refers to<a id="id589" class="indexterm"/> the texture coordinates</p>
</td></tr></tbody></table></div><p>The property that we haven't mentioned yet, <code class="literal">vsize</code>, is the length of a single vertex in the array of vertices. It's computed from the vertex format as a sum of its middle column.</p><p>The <code class="literal">vertices</code> list contains nearly all data about stars that we need to retain; however, as it is flat and not implicitly<a id="id590" class="indexterm"/> structured, it's very unwieldy to operate on. This is where a helper class, <code class="literal">Star</code>, comes into play. It encapsulates the gory details of accessing and updating a selected entry in the array of vertices so that we don't have to compute offsets throughout our code.</p><p>The <code class="literal">Star</code> class also keeps track of<a id="id591" class="indexterm"/> various properties that aren't part of the vertex format, that is, polar coordinates (<code class="literal">angle</code> and <code class="literal">distance</code> from the center) and <code class="literal">size</code>, which increases with time.</p><p>This is the initiali<a id="id592" class="indexterm"/>zation of the <code class="literal">Star</code> class:</p><div class="informalexample"><pre class="programlisting">import math
from random import random

class Star:
    angle = 0
    distance = 0
    size = 0.1

    def __init__(self, sf, i):
        self.sf = sf
        self.base_idx = 4 * i * sf.vsize
        self.reset()

    def reset(self):
        self.angle = 2 * math.pi * random()
        self.distance = 90 * random() + 10
        self.size = 0.05 * random() + 0.05</pre></div><p>Here, <code class="literal">base_idx</code> is the <a id="id593" class="indexterm"/>index of this star's first vertex in the array of vertices; we also kept a reference, <code class="literal">sf</code>, to the <code class="literal">Starfield</code> instance to be able to access <code class="literal">vertices</code> later.</p><p>The <code class="literal">reset()</code> function, when called, reverts the star's attributes to default (slightly randomized) values.</p></div><div class="section" title="Advancing the scene"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec106"/>Advancing the scene</h2></div></div></div><p>The <code class="literal">Starfield.update_glsl()</code> method<a id="id594" class="indexterm"/> implements the algorithm of the starfield motion and is frequently<a id="id595" class="indexterm"/> invoked by Kivy's clock scheduled in the <code class="literal">on_start()</code> handler of the application class. Its source code is as follows:</p><div class="informalexample"><pre class="programlisting">from kivy.graphics import Mesh

def update_glsl(self, nap):
    x0, y0 = self.center
    max_distance = 1.1 * max(x0, y0)

    for star in self.stars:
        star.distance *= 2 * nap + 1
        star.size += 0.25 * nap

        if (star.distance &gt; max_distance):
            star.reset()
        else:
            star.update(x0, y0)

    self.canvas.clear()

    with self.canvas:
        Mesh(fmt=self.vfmt, mode='triangles',
             indices=self.indices, vertices=self.vertices,
             texture=self.texture)</pre></div><p>First off, we calculate the distance limit, <code class="literal">max_distance</code>, after which the stars respawn near the center of the screen. Then, we iterate over the list of stars, setting them in motion and enlarging them slightly on the way. Stars that have escaped the terminal distance are reset.</p><p>The final part of the<a id="id596" class="indexterm"/> function should look familiar. It's the same rendering code as seen in the preceding examples. A call to <code class="literal">canvas.clear()</code> is necessary; otherwise, a new mesh will be added on each call, swiftly bringing the overwhelmed graphics card to a grinding halt.</p><p>The last piece of Python code that hasn't been revealed is the <code class="literal">Star.update()</code> method. It refreshes the four vertices belonging to a star, writing new coordinates to appropriate places in the <code class="literal">vertices</code> array:</p><div class="informalexample"><pre class="programlisting">def iterate(self):
    return range(self.j,
                 self.j + 4 * self.sf.vsize,
                 self.sf.vsize)

def update(self, x0, y0):
    x = x0 + self.distance * math.cos(self.angle)
    y = y0 + self.distance * math.sin(self.angle)

    for i in self.iterate():
        self.sf.vertices[i:i + 3] = (x, y, self.size)</pre></div><p>The <code class="literal">iterate()</code> helper is for convenience only and could have been inlined, but there's no such thing as superfluous readability, so let's keep it this way.</p><p>To reiterate (pun intended), this whole memory-mapping process serves a noble goal of eliminating the <a id="id597" class="indexterm"/>need to serialize our numerous objects in each frame; this helps performance.</p></div><div class="section" title="Writing a corresponding GLSL"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec107"/>Writing a corresponding GLSL</h2></div></div></div><p>Shaders used<a id="id598" class="indexterm"/> in the following program are also reminiscent of<a id="id599" class="indexterm"/> what we've seen earlier; they are only a little lengthier. This is the vertex shader:</p><div class="informalexample"><pre class="programlisting">attribute vec2  vCenter;
attribute float vScale;

void main(void)
{
    tex_coord0 = vTexCoords0;
    mat4 move_mat = mat4
        (1.0, 0.0, 0.0, vCenter.x,
         0.0, 1.0, 0.0, vCenter.y,
         0.0, 0.0, 1.0, 0.0,
         0.0, 0.0, 0.0, 1.0);
    vec4 pos = vec4(vPosition.xy * vScale, 0.0, 1.0) * move_mat;
    gl_Position = projection_mat * modelview_mat * pos;
}</pre></div><p>Simply put, we're multiplying the relative coordinates of all the vertices by a factor of <code class="literal">vScale</code>, which resizes the mesh proportionally, and then translating them to the position given by a <code class="literal">vCenter</code> attribute. The <code class="literal">move_mat</code> matrix is the translation matrix, an affine transformation method that you might or might not remember from your linear algebra class.</p><p>To compensate, the fragment shader is very simple:</p><div class="informalexample"><pre class="programlisting">void main(void)
{
    gl_FragColor = texture2D(texture0, tex_coord0);
}</pre></div><p>Its ultimate purpose is to put this beautiful thing on the screen:</p><div class="mediaobject"><img src="graphics/B01620_08_10.jpg" alt="Writing a corresponding GLSL"/><div class="caption"><p>Star texture, zoomed in</p></div></div><p>That's it. Our <a id="id600" class="indexterm"/>starfield is now finished and<a id="id601" class="indexterm"/> ready for astronomical observation with the unaided eye (or any other usage you can think of).</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec56"/>Summary</h1></div></div></div><p>This chapter aimed (and hopefully succeeded) to introduce you to a beautiful hardware-accelerated world of low-level OpenGL and GLSL development filled with vertices, indices, and shaders.</p><p>Direct programming of the GPU is an insanely powerful concept, and with this power always comes responsibility. Shaders are much harder to grasp than regular Python code; debugging might involve a fair measure of guesswork, and there is no convenient interactive environment, such as Python's REPL, to speak of. That said, there is no clear heuristic whether writing a raw GLSL would be useful for any particular application—it should be decided on a case-by-case basis.</p><p>Examples in this chapter were deliberately simple to serve as a gentle learning experience, not a test of cognitive abilities. This is mainly because GLSL programming is a very non-trivial, convoluted subject to study, with numerous books and online tutorials dedicated to mastering it, and this short chapter is by no means a comprehensive guide to all things OpenGL.</p><p>So far, we've just barely scratched the surface of what's possible. The next chapter will capitalize on the code we wrote here to do a slightly more interesting thing: create a blazing fast shoot-em-up game.</p></div></body></html>