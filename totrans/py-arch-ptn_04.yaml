- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The core of any application is its data. At the very root of any computer application,
    it's a system designed to deal with information, receiving it, transforming it,
    and returning either the same information or insightful elements extracted from
    it. The stored data is a crucial part of this cycle, as it allows you to use information
    that has been communicated before.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will talk about how we can model the stored data from our
    application and what the different options are to store and structure the data
    to be persisted.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by describing the different database options that are available,
    which are critical to understanding their different applications, but we will
    mostly focus, during the chapter, on relational databases, as they are the most
    common type. We will describe the concept of a transaction to ensure that different
    changes are applied in one go.
  prefs: []
  type: TYPE_NORMAL
- en: We will describe different ways that we can increase the scope of a relational
    database by using multiple servers, and what the use cases for each option are.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we will describe different alternatives when designing a schema
    to ensure that our data is structured in the best possible way. We will discuss
    how to enable fast access to data through the usage of indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Types of databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database transactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed relational databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schema design
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data indexing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start with an introduction to the different databases out there.
  prefs: []
  type: TYPE_NORMAL
- en: Types of databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the persistent data from an application should live in a database. As we've
    discussed, data is the most critical aspect of any application, and proper handling
    of it is critical to ensure the viability of the project.
  prefs: []
  type: TYPE_NORMAL
- en: Technically, databases are collections of data themselves and are handled by
    the **database management system** (**DBMS**), the software that allows the input
    and output of data. Normally, the word "database" is used for both the collection
    and the management system, depending on the context. Most DBMSes will allow access
    to multiple databases of the same kind, without being able to cross data between
    them, to allow logical separation of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Databases have been a critical tool for most of the time software systems have
    been available. They create an abstraction layer that allows accessing data without
    having to worry too much about how the data is structured by the hardware. Most
    databases allow the structure of the data to be defined without having to worry
    about how that's implemented behind the curtains.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in *Chapter 2*, *API Design*, this abstraction is not perfect and
    sometimes we will have to understand the internals of databases to improve the
    performance or do things in "the proper way."
  prefs: []
  type: TYPE_NORMAL
- en: 'DBMSes are among the most invested and mature projects in software. Each DBMS
    has its own quirks, to the point where there''s a specific job role for a "database
    expert": the **Database Administrator** (**DBA**).'
  prefs: []
  type: TYPE_NORMAL
- en: The DBA role was quite popular for a long time and required highly specialized
    engineers, to the point of DBAs specializing in a single specific DBMS. The DBA
    will act as the expert in the database, both in knowing how to access it and ensuring
    that any changes done to it work adequately. They normally are the only ones allowed
    to perform changes or maintenance tasks in the database.
  prefs: []
  type: TYPE_NORMAL
- en: Performance improvements in hardware and software and external tools to handle
    database complexity have made this role less common, though it's still in use
    by some organizations. To a certain degree, the architect role overtakes parts
    of this role, though with more of a supervising role and less of a gatekeeping
    one.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple DBMSes available on the market, with a good selection of
    open source software that covers most use cases. Roughly speaking, we can divide
    the existing DBMS alternatives into this non-exhaustive classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Relational databases**: The default standard in databases. Use SQL query
    language and have a defined schema. Examples are open source projects like MySQL
    or PostgreSQL, or commercial ones like Oracle or MS SQL Server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-relational databases**: New alternatives to the traditional databases.
    This is a diverse group with multiple alternatives, and includes very different
    options like MongoDB, Riak, or Cassandra.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Small databases**: These databases are aimed to be embedded into the system.
    The most famous example is SQLite.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a more in-depth look at them.
  prefs: []
  type: TYPE_NORMAL
- en: Relational databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These are the most common databases and the first idea that comes to mind when
    talking about databases. The relational model for databases was developed in the
    1970s, and it's based on creating a series of tables that can be related to each
    other. Since the 1980s, they have become incredibly popular.
  prefs: []
  type: TYPE_NORMAL
- en: Each defined table has a number of fields or columns that are fixed and data
    is described as records or rows. Tables are theoretically infinite, so more and
    more rows can be added. One of the columns is defined as the *primary key* and
    uniquely describes the row. Therefore, it needs to be unique.
  prefs: []
  type: TYPE_NORMAL
- en: If there is a value that's unique and descriptive enough, it can be used for
    the primary key; this is called a *natural key*. Natural keys can also be a combination
    of fields, though that limits their convenience. When a natural key is not available,
    an increasing counter can be handled directly by the database to ensure it is
    unique per row. This is called a *surrogate key*.
  prefs: []
  type: TYPE_NORMAL
- en: The primary key is used to reference that record, when necessary, in other tables.
    This creates the relation aspect of the database. When a column in a table makes
    reference to another table, this is called a *foreign* *key*.
  prefs: []
  type: TYPE_NORMAL
- en: These references can produce one-to-one relationships; one-to-many, when a single
    row can be referenced in multiple rows in another table; or even many-to-many,
    which requires an intermediary table to cross over the data.
  prefs: []
  type: TYPE_NORMAL
- en: All this information needs to be described in the schema. The schema describes
    each table, what the fields and types of each are, as well as the relations between
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Relations in relational databases are really constraints. That means that a
    value can't be deleted if it's still referenced somewhere. Relational databases
    come from a strict mathematical background, though that background's implemented
    in different degrees of strictness.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to note that defining the schema requires thinking ahead and
    being aware of the changes that can be made. Defining types before having data
    also requires keeping in mind possible improvements. While the schema can be changed,
    it's always a serious operation that, if not taken with proper care, can lead
    to the database not being available for some time, or, in the worst-case scenario,
    data can be changed or processed inconsistently.
  prefs: []
  type: TYPE_NORMAL
- en: A query can also be executed that searches for data fulfilling certain conditions.
    For that, tables can be joined based on their relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Virtually all relational databases are interacted with using Structured Query
    Language, or SQL. This language has become the standard to work with relational
    databases and follow the same concepts that we've described here. It describes
    both how to query the database and how to add or change data contained there.
  prefs: []
  type: TYPE_NORMAL
- en: The most relevant characteristic of SQL is that it is a declarative language.
    This means that the statements describe the result instead of the procedure to
    obtain it, as is typical with imperative languages. This abstracts the internal
    details away from the *how* to focus on the *what*.
  prefs: []
  type: TYPE_NORMAL
- en: Imperative languages describe the control flow and are the most common languages.
    Examples of imperative languages are Python, JavaScript, C, and Java. Declarative
    languages are normally restricted to specific domains (Domain-Specific Languages,
    or DSLs) that allow you to describe the result in simpler terms, while imperative
    languages are more flexible.
  prefs: []
  type: TYPE_NORMAL
- en: This characteristic makes SQL portable between systems, as the internals of
    the *how* can be different in different databases. Using a specific relational
    database and adapting to another is relatively easy.
  prefs: []
  type: TYPE_NORMAL
- en: This is used sometimes to set up a local database for running tests that's different
    from the final database that will be in place once the system is in production.
    This is possible in some web frameworks, but it requires some caveats, as complex
    systems sometimes have to use specific characteristics for a particular database,
    making it impossible to perform an easy replacement of this kind.
  prefs: []
  type: TYPE_NORMAL
- en: While relational databases are very mature and flexible and are used in very
    different scenarios, there are two main problems that are difficult to deal with.
    One is requiring a predefined schema, as we said above. The other, and more serious
    after a certain size, is dealing with scale. Relational databases are thought
    to be a central access point that's accessed, and there need to be some techniques
    to scale once the limit of vertical scaling has been reached.
  prefs: []
  type: TYPE_NORMAL
- en: We will talk about specific techniques to deal with this issue and increase
    the scalability of relational databases later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Non-relational databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Non-relational databases are a diverse group of DBMSes that do not fit into
    the relational paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: Non-relational databases are also called NoSQL, emphasizing the relational nature
    of the SQL language, standing for either "not SQL" or "Not Only SQL," to be more
    reflective of adding possibilities and not removing them.
  prefs: []
  type: TYPE_NORMAL
- en: While there have been non-relational databases even before the introduction
    of relational databases and alongside them, since the 2000s, there has been an
    introduction or recovery of methods and designs that look to alternative options.
    Most of them aim to address the two main weak spots in relational databases, their strictness
    and scalability issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'They are very varied and have very different structures, but the most common
    kinds of non-relational systems are the following groups:'
  prefs: []
  type: TYPE_NORMAL
- en: Key-value stores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Document stores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wide-column databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graph databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's describe each of them.
  prefs: []
  type: TYPE_NORMAL
- en: Key-value stores
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Key-value stores are arguably the simplest of all databases in terms of functionality.
    They define a single key that stores a value. The value is totally opaque to the
    system, not being able to be queried in any way. There's even, in some implementations,
    no way of querying keys in the system; instead, they need to be an input to any
    operation.
  prefs: []
  type: TYPE_NORMAL
- en: This is very similar to a hash table or dictionary but on a bigger scale. Cache
    systems are normally based on this kind of data store.
  prefs: []
  type: TYPE_NORMAL
- en: While the technology is similar, there's an important differentiation between
    a cache and a database. A cache is a system that stores data already calculated
    to speed up its retrieval, while a database stores raw data. If the data is not
    in the cache, it can be retrieved from a different system, but if it's not in
    the database, either the data is not stored or there has been a big problem.
  prefs: []
  type: TYPE_NORMAL
- en: That's why cache systems tend to store information only in memory and are more
    resilient to restarts or problems, making them easier to deal with. If a cache
    is missing, the system works, just slower.
  prefs: []
  type: TYPE_NORMAL
- en: It's very important that information is not ultimately stored in cache systems
    that are not backed up by proper storage. It's a mistake that sometimes happens
    inadvertently, for example, with temporal data, but the risk is to get a problem
    at the wrong time and lose the data, so be aware of it.
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage of this system is, on the one hand, the simplicity of it,
    allowing the quick storage and retrieval of data. It also allows you to horizontally
    scale to a great extent. As each key is independent of the rest, they can even
    be stored in different servers. Redundancy can also be introduced in the system,
    making multiple copies for each key and value, though this makes the retrieval
    of information slower, as the multiple copies need to be compared to detect data
    corruption.
  prefs: []
  type: TYPE_NORMAL
- en: Some examples of key-value databases are **Riak** and **Redis** (if used with
    durability enabled).
  prefs: []
  type: TYPE_NORMAL
- en: Document stores
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Document stores revolve around the concept of a "document," which is similar
    to a "record" in relational databases. Documents, though, are more flexible, as
    they don't need to follow a predefined format. They also typically allow embedding
    more data in subfields, something that relational databases normally don't do,
    relying instead on creating a relationship and storing that data in a different
    table.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a document can look like this, here represented as JSON:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Documents are normally grouped in collections, which are similar to "tables."
    Normally documents are retrieved by a unique ID that acts as the primary key,
    but queries can also be constructed to search fields created in the document.
  prefs: []
  type: TYPE_NORMAL
- en: So, in our case, we could retrieve the key (ID) `ABCDEFG`, like in a key-value
    store; or make richer queries like "get me all entries in the `detectives` collection
    whose `address.country` equals `UK`," for example.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that, while it is technically possible to create a collection with
    documents totally independent and with different formats, in practice, all documents
    in a collection will follow a somewhat *similar* format, with optional fields
    or embedded data.
  prefs: []
  type: TYPE_NORMAL
- en: Documents in one collection can be related to documents in another collection
    by their ID, creating a reference, but normally these databases don't allow you
    to create join queries. Instead, the application layer should allow you to retrieve
    this linked information.
  prefs: []
  type: TYPE_NORMAL
- en: In general, documents favor embedding information over creating references.
    This could lead to denormalizing information, repeating the information in several
    places. We will talk more about denormalization later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Some examples of document stores are **MongoDB** ([https://www.mongodb.com/](https://www.mongodb.com/))
    and **Elasticsearch** ([https://www.elastic.co/elasticsearch/](https://www.elastic.co/elasticsearch/)).
  prefs: []
  type: TYPE_NORMAL
- en: Wide-column databases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Wide-column databases are structured with their data separated by columns. They
    create tables with certain columns, but they are optional. They also can't natively
    relate a record in one table with another.
  prefs: []
  type: TYPE_NORMAL
- en: They are a bit more capable of being queried than pure key-value stores but
    require more upfront design work on what kinds of queries are possible in the
    system. This is more restrictive than in document-oriented stores where there
    is more flexibility in doing that after the design is done.
  prefs: []
  type: TYPE_NORMAL
- en: Normally, columns are related and can only be queried in a particular order,
    meaning that if columns A, B, and C exist, a row can query based on either A,
    A and B, or A, B, and C, but not just C or B and C, for example.
  prefs: []
  type: TYPE_NORMAL
- en: They are aimed at very big database deployments with high availability and replicated
    data. Some examples of wide-column databases are **Apache Cassandra** ([https://cassandra.apache.org/](https://cassandra.apache.org/))
    and Google's **Bigtable** ([https://cloud.google.com/bigtable](https://cloud.google.com/bigtable)).
  prefs: []
  type: TYPE_NORMAL
- en: Graph databases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While the previous non-relational databases are based on giving up the ability
    to create relationships between elements to gain other features (like scalability
    or flexibility), graph databases go in the opposite direction. They greatly enhance
    the relationship aspect of the elements to create complex graphs.
  prefs: []
  type: TYPE_NORMAL
- en: They store objects that are nodes and edges, or relationships between the nodes.
    Both edges and nodes may have properties to better describe them.
  prefs: []
  type: TYPE_NORMAL
- en: The query capabilities of graph databases are aimed at retrieving information
    based on relationships. For example, given a list of companies and providers,
    is there any provider in a supply chain of a specific company that is in a specific
    country? Up to how many levels? These questions may be easy to answer for the
    first level in a relational database (obtain the suppliers of the company and
    their countries), but quite complex and consuming for the third-level relations.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_01.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.1: Example of data that is typical of graph databases'
  prefs: []
  type: TYPE_NORMAL
- en: They are typically used for social graphs, where there are connections between
    people or organizations. Some examples are **Neo4j** ([https://neo4j.com/](https://neo4j.com/))
    or **ArangoDB** ([https://www.arangodb.com/](https://www.arangodb.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: Small databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This group is a bit special compared with the rest. It's composed of database
    systems that are not differentiated as an independent process, working as an independent
    client-server structure. Instead, they are embedded into the code of the application,
    reading directly from the hard drive. They are normally used in simple applications
    that run as a single process and want to keep the information in a structured
    way.
  prefs: []
  type: TYPE_NORMAL
- en: A crude, yet effective, way of representing this method is to save information
    as a JSON object into a file and recover it when required, for example, client
    settings for a smartphone app. The settings file is loaded when the application
    starts from memory, then saved if there's any change.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in Python code, this could be represented like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: For small amounts of data, this structure may work, but it has the limitation
    that it's difficult to query. The most complete alternative is SQLite, which is
    a full-fledged SQL database, but it's embedded into the system, without requiring
    external calls. The database is stored in a binary file.
  prefs: []
  type: TYPE_NORMAL
- en: SQLite is so popular that it's even supported in a lot of standard libraries,
    without requiring an external module, for example, in the Python standard library.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This module follows the DB-API 2.0 standard, which is the Python standard to
    connect to databases. It aims to standardize access to different database backends.
    This makes it easy to create a higher-level module that can access multiple SQL
    databases and swap them with minimal changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check the full DB-API 2.0 specification in PEP-249: [https://www.python.org/dev/peps/pep-0249/](https://www.python.org/dev/peps/pep-0249/).'
  prefs: []
  type: TYPE_NORMAL
- en: SQLite implements most of the SQL standard.
  prefs: []
  type: TYPE_NORMAL
- en: Database transactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Storing data can be a complex operation internally for a database. In some cases,
    it can include changing the data in a single place, but there are operations that
    can affect millions of records in a single operation, for example, "update all
    records created before this timestamp."
  prefs: []
  type: TYPE_NORMAL
- en: How broad and possible these operations are highly depends on the database,
    but they are very similar to relational databases. In that case, normally there's
    the concept of a *transaction*.
  prefs: []
  type: TYPE_NORMAL
- en: A transaction is an operation that happens in one go. It either happens or it
    doesn't, but the database is not left in an inconsistent state in the middle.
    For example, if the operation described before of "update all records created
    before this timestamp" can produce an effect where, through an error, only half
    of the records are changed, then it's not a transaction, but multiple independent
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: It can happen that there's an error in the middle of a transaction. In that
    case, it will go back all the way to the start of it, so no record will change.
  prefs: []
  type: TYPE_NORMAL
- en: This characteristic can become a strong requirement for the database in some
    applications, and it's called *atomicity*. That means the transaction is atomic
    when it's applied. This characteristic is the main one of the so-called ACID properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other properties are consistency, isolation, and durability. The four properties
    are, then:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Atomicity*, which means that the transaction is applied as one unit. It is
    either applied completely or not.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Consistency*, which means that the transaction is applied taking into account
    all restrictions that are defined in the database. For example, foreign key constraints
    are respected, or any stored triggers that modify the data applied.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Isolation*, which means that parallel transactions work in the same way that
    they were run one after the other, ensuring that one transaction is not affecting
    another. Obviously, the exception is the order in which they are run, which may
    have an impact.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Durability*, which means that, after a transaction is reported as completed,
    it won''t be lost even in the event of a catastrophic failure, like the database
    process crashing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These properties are the gold standard to take care of data. It means that the
    data is safe and consistent.
  prefs: []
  type: TYPE_NORMAL
- en: Most relational databases have the concept of starting a transaction, performing
    several operations, and then finally committing the transaction so all the changes
    are applied in one go. If there's a problem, the transaction will fail, reverting
    to the previous state. A transaction can also be aborted if, during the performance
    of operations, any problem, like a constraint issue, is detected.
  prefs: []
  type: TYPE_NORMAL
- en: This way of operating allows creating extra verification steps, as inside the
    transaction, data can still be queried and be validated before finally committing
    it.
  prefs: []
  type: TYPE_NORMAL
- en: ACID transactions have a cost in terms of performance, and especially in terms
    of scalability. The need for durability means that data needs to be stored on
    disk or other permanent support before being returned from the transaction. The
    requirement for isolation means that each open transaction requires operating
    in a way that it can't see new updates, which may require temporary data to be
    stored until the transaction is completed. Consistency also requires checks to
    ensure that all constraints are fulfilled, which may require complex checks.
  prefs: []
  type: TYPE_NORMAL
- en: Virtually all relational databases are fully ACID compliant, and that has become
    a defining characteristic of them. In the non-relational world, things are more
    flexible.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling the database with multiple servers or nodes with these properties proves
    difficult, though. This system creates distributed transactions, running on multiple
    servers at the same time. Maintaining full ACID transactions in databases with
    more than one server is extremely difficult, and has a heavy penalty in terms
    of performance, because of the extra delay caused by understanding what the other
    nodes have done and rolling back the transaction if there's a failure in any of
    them. The problems also increase in a non-linear way, sort of working against
    the advantages of having multiple servers.
  prefs: []
  type: TYPE_NORMAL
- en: While this is possible, a lot of applications can work around these limitations.
    We will see some useful patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed relational databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've discussed before, relational databases weren't designed with scalability
    in mind. They are great for enforcing strong data assurances, including ACID transactions,
    but their preferred way of operating is through a single server.
  prefs: []
  type: TYPE_NORMAL
- en: This can impose limitations in terms of how big an application can be using
    relational databases.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that a database server can grow vertically, which means using
    better hardware. Increasing the capacity of a server or replacing it with a bigger
    one is an easier solution for high demand than applying some of these techniques,
    but there's a limit. In any case, please double-check that the expected size is
    big enough. These days, there are servers in cloud providers that reach 1 terabyte
    of RAM or more. That's enough to cover a huge number of cases.
  prefs: []
  type: TYPE_NORMAL
- en: Note that these techniques are useful to grow a system after it is up and running,
    and can be added to most usages of relational databases.
  prefs: []
  type: TYPE_NORMAL
- en: The disadvantage of the ACID properties is *eventual consistency*. Instead of
    an atomic operation that gets processed in a single go, the system gradually translates
    to the desired system. Not every part of the system has the same state at the
    same time. Instead, there are certain delays while this change is propagating
    in the system. The other big advantage is that we can increase the availability,
    as it won't depend on a single node to make the change, and any non-available
    elements will catch up after recovering. Because of the distributed nature of
    the cluster, this may involve consulting different sources and trying to reach
    a quorum between them.
  prefs: []
  type: TYPE_NORMAL
- en: It depends greatly on the application you have in mind when considering if loosening
    some of the ACID properties is worth doing. Critical data, where a delay or data
    corruption has a higher impact and may not be acceptable, may not be a good fit
    for a distributed database.
  prefs: []
  type: TYPE_NORMAL
- en: In order to increase the capacity, the first thing is to understand what the
    data access of the application is.
  prefs: []
  type: TYPE_NORMAL
- en: Primary/replica
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A very common case is that the number of reads is much higher than writes. Or,
    talking in SQL terms, the number of `SELECT` statements is much higher than the
    `UPDATE` or `DELETE` ones. This is very typical of applications where there's
    way more access to information than updates to information, for example, a newspaper,
    where there's a lot of access to read a news article, but not so many new articles
    comparatively.
  prefs: []
  type: TYPE_NORMAL
- en: 'A common pattern for this situation is to create a cluster adding one or more
    read-only copies of the database, and then spread the reads across them, a situation
    similar to this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_02.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.2: Dealing with multiple Read queries'
  prefs: []
  type: TYPE_NORMAL
- en: All the writes go to the primary node, and then that gets disseminated to the
    replica nodes automatically. Because the replicas contain the whole database,
    and the only write activity comes from the primary, this increases the number
    of queries that can run at the same time in the system.
  prefs: []
  type: TYPE_NORMAL
- en: This system is natively supported by most relational databases, especially the
    most common ones, MySQL and PostgreSQL. The write nodes are configured as primary,
    and the replicas are pointed at the primary to start copying the data. After some
    time, they'll be up to date and in sync with the primary.
  prefs: []
  type: TYPE_NORMAL
- en: Every new change in the primary will be replicated automatically. This, though,
    has a delay, called a replication lag. This means that the data just written won't
    be available to read for some time, typically less than a second.
  prefs: []
  type: TYPE_NORMAL
- en: Replication lag is a good indicator of the wellbeing of the database. If the
    lag increases over time, it's an indication that the cluster is not capable of
    handling the level of traffic and requires adjustments. This time will be greatly
    influenced by the network and general performance of each of the nodes.
  prefs: []
  type: TYPE_NORMAL
- en: An operation to avoid, then, is to write and immediately read the same or related
    data in an external operation, as this can cause inconsistent results. This can
    be solved either by keeping the data temporarily, avoiding the need for the query,
    or by making it possible to address a specific read to the primary node, to ensure
    that the data is consistent.
  prefs: []
  type: TYPE_NORMAL
- en: These direct reads should be used only when necessary, as they go against the
    idea of reducing the number of queries to the primary server. That was the reason
    to set up multiple servers!
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, schematic'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_03.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.3: A specific Read query on the primary node'
  prefs: []
  type: TYPE_NORMAL
- en: This system also allows there to be redundancy of data, as it's always being
    copied to the replicas. If there's a problem, a replica can be promoted to be
    the new primary.
  prefs: []
  type: TYPE_NORMAL
- en: A replica server doesn't fulfill exactly the same role as a backup, though it
    can be used with a similar intent. A replica is intended to perform a quick action
    and maintain the availability of the system. Backups are easier and cheaper to
    run and allow you to keep a historical record of the data. Backups can also be
    located in a very different location than the replica, while a replica requires
    a good network connection with the primary.
  prefs: []
  type: TYPE_NORMAL
- en: Do not skip doing backups, even if there are replicas available. Backups will
    add a security layer in case of catastrophic failure.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this way of structuring the database may require adapting the application
    level to be aware of all the changes and access to different database servers.
    There are existing tools such as Pgpool (for PostgreSQL) or ProxySQL (for MySQL)
    that stay in the middle of the path and redirect the queries. The application
    addresses the queries to the proxies, and then the proxy redirects them based
    on the configuration. There are cases, like the write and read pattern that we've
    seen above, that are not covered easily and may require specific changes in the
    application code. Be sure to understand how these kinds of tools work and run
    some tests before running them in your application.
  prefs: []
  type: TYPE_NORMAL
- en: A simpler case of this structure is to create offline replicas. These can be
    created from a backup and not updated from the live system. These replicas can
    be useful to create queries that don't require up-to-date information, in cases
    where perhaps a daily snapshot is good enough. They are common in applications
    like statistical analysis or data warehousing.
  prefs: []
  type: TYPE_NORMAL
- en: Sharding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the application has a higher number of writes, the primary-replica structure
    may not be good enough. Too many writes are directed to the same server, which
    creates a bottleneck. Or if the system traffic grows enough, there's a limit to
    the number of writes that a single server can accept.
  prefs: []
  type: TYPE_NORMAL
- en: A possible solution is to horizontally partition the data. This means dividing
    the data into different databases according to a specific key, so all related
    data can go to the same server. Each of the different partitions is called a shard.
  prefs: []
  type: TYPE_NORMAL
- en: Note that "partitioning" and "sharding" can be considered synonyms, though in
    reality sharding is only if the partition is horizontal, separating a single table
    into different servers. Partitioning can be more general, like dividing a table
    into two, or splitting into different columns, which is not typically called sharding.
  prefs: []
  type: TYPE_NORMAL
- en: The partition key is called the shard key, and based on its value, each row
    will be allocated a specific shard.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_04.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.4: Shard keys'
  prefs: []
  type: TYPE_NORMAL
- en: The name *shard* comes from the videogame Ultima Online, which, in the late
    90s, used this strategy to create a "multiverse" where different players could
    play the same game on different servers. They called them "shards," as they were
    aspects of the same reality, but contained different players in them. The name
    stuck and it's still used to describe the architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Any query needs to be able to determine what the proper shard is to be applied
    to. Any query that affects two or more shards may be impossible to do or can only
    be performed in succession. Of course, this excludes the possibility of performing
    these queries in a single transaction. In any case, these operations will be very
    expensive, and should be avoided as much as possible. Sharding is a fantastic
    idea when the data is naturally partitioned, and very bad when queries affecting
    multiple shards are performed.
  prefs: []
  type: TYPE_NORMAL
- en: Some NoSQL databases allow native sharding that will take care of all these
    options automatically. A common example is MongoDB, which is even capable of running
    queries in multiple shards in a transparent manner. These queries will be slow,
    in any case.
  prefs: []
  type: TYPE_NORMAL
- en: The choosing of the sharding key is also crucial. A good key should follow natural
    partitions between data, so performing cross-shard queries is not required. For
    example, if the data of a user is independent of the rest, which may happen with
    a photo-sharing application, the user identifier could be a good shard key.
  prefs: []
  type: TYPE_NORMAL
- en: Another important quality is that the shard to address the query needs to be
    determined based on the shard key. That means that every query needs to have the
    shard key available. This means that the shard key should be an input of every
    operation.
  prefs: []
  type: TYPE_NORMAL
- en: Another property of the shard key is that the data should be ideally portioned
    in a way that shards have the same size, or at least they are similar enough.
    If one shard is much bigger than the rest, that could lead to problems of imbalanced
    data, not enough distributing of the queries, and having one shard being the bottleneck.
  prefs: []
  type: TYPE_NORMAL
- en: Pure sharding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: On pure shards, the data is all partitioned in shards and the shard key is an
    input of every operation. The shard is determined based on the shard key.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure that the shards are balanced, each key is hashed in a way that is
    equally distributed between the number of shards. A typical case is to use a modulo
    operation, for example. If we have 8 shards, we determine which shard the data
    is partitioned into based on a number that's equally distributed.
  prefs: []
  type: TYPE_NORMAL
- en: '| User ID | Operation | Shard |'
  prefs: []
  type: TYPE_TB
- en: '| 1234 | 1234 mod 8 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 2347 | 2347 mod 8 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 7645 | 7645 mod 8 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 1235 | 1235 mod 8 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 4356 | 4356 mod 8 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 2345 | 2345 mod 8 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2344 | 2344 mod 8 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'If the shard key is not a number, or if it''s not evenly distributed, a hash
    function can be applied. For example, in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This strategy is only possible if the shard key is **always** available as input
    for every operation. When this is not an option, we need to look at other options.
  prefs: []
  type: TYPE_NORMAL
- en: Changing the number of shards is not an easy task, as the destination for each
    key is decided by a fixed formula. It is possible, though, to grow or reduce the
    number of shards with some preparation in advance.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create "virtual shards" that point to the same server. For example,
    to create 100 shards, and use two servers, initially the virtual shard distribution
    will be like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Virtual Shard | Server |'
  prefs: []
  type: TYPE_TB
- en: '| 0-49 | Server A |'
  prefs: []
  type: TYPE_TB
- en: '| 50-99 | Server B |'
  prefs: []
  type: TYPE_TB
- en: If the number of servers needs to be increased, the virtual shard structure
    will change in this way.
  prefs: []
  type: TYPE_NORMAL
- en: '| Virtual Shard | Server |'
  prefs: []
  type: TYPE_TB
- en: '| 0-24 | Server A |'
  prefs: []
  type: TYPE_TB
- en: '| 25-49 | Server C |'
  prefs: []
  type: TYPE_TB
- en: '| 50-74 | Server B |'
  prefs: []
  type: TYPE_TB
- en: '| 75-99 | Server D |'
  prefs: []
  type: TYPE_TB
- en: This change to the specific server that corresponds to each shard may require
    some code change, but it's easier to handle as the shard key calculation won't
    change. The same operation can be applied in reverse, though it may create imbalance,
    so it needs to be done with care.
  prefs: []
  type: TYPE_NORMAL
- en: '| Virtual Shard | Server |'
  prefs: []
  type: TYPE_TB
- en: '| 0-24 | Server A |'
  prefs: []
  type: TYPE_TB
- en: '| 25-49 | Server C |'
  prefs: []
  type: TYPE_TB
- en: '| 50-99 | Server B |'
  prefs: []
  type: TYPE_TB
- en: Each of the operations requires changing the location of data based on the shard
    key. This is a costly operation, especially if a lot of data needs to be exchanged.
  prefs: []
  type: TYPE_NORMAL
- en: Mixed sharding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes it is not possible to create pure shards and a translation from the
    input is required to determine the shard key. This is the case, for example, when
    a user is logging in if the shard key is the user ID. The user will log in using
    their email, but that needs to be translated to the user ID to be able to determine
    the shard to search the information.
  prefs: []
  type: TYPE_NORMAL
- en: In that case, an external table can be used purely to translate the input of
    a particular query to the shard key.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_05.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.5: External tables to translate the input of shard keys'
  prefs: []
  type: TYPE_NORMAL
- en: This creates a situation where a single shard is responsible for this translation
    layer. This shard can be used exclusively for this, or also act as any other shard.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that this requires a translation layer for each possible input
    parameter that's not directly the shard key, and that it requires keeping all
    the information of all shards in a single database. This needs to be kept under
    control and store as little information as possible, to avoid issues.
  prefs: []
  type: TYPE_NORMAL
- en: This strategy can be used as well to store, directly, what shard key goes to
    what shard, and perform a query instead of a direct operation, as we saw above.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_06.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.6: Storing shard keys to shards'
  prefs: []
  type: TYPE_NORMAL
- en: This has the inconvenience that determining the shard based on the key requires
    a query in a database, especially with a big database. But it also allows changing
    the shard of the data in a consistent way, which can be used to adapt the number
    of shards, like growing or reducing the number. And it can be done without requiring
    downtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the specific shard, not only the shard key, is stored in this translation
    table, the assignment of the shard to the key can be changed one by one, and in
    a continuous manner. The process will be approximately like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Shard key X is assigned to server A in the reference table. This is the start
    state.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data from server A for shard key X is copied to server B. Note that no query
    involving shard key X is directed to server B yet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once all the data is copied, the entry for the reference table for shard key
    X is changed to server B.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All queries for shard key X are directed to server B.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data from shard key X in server A can be cleaned.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Step 3* is the critical step, and needs to happen only after all the data
    is copied, and before any new write is performed. A way of ensuring this is to
    create a flag in the reference table that can stop or delay the writing of data
    while the operation is in place. This flag will be set up right before *step 2*
    and removed after *step 3* is completed.'
  prefs: []
  type: TYPE_NORMAL
- en: This process will produce a smooth migration over time, but it requires enough
    space to work, and can take a significant amount of time.
  prefs: []
  type: TYPE_NORMAL
- en: Downscale operations are more complicated than upscale, as the increase in space
    allows for ample room. Fortunately, it is rare that a database cluster needs to
    downscale, as most applications will grow over time.
  prefs: []
  type: TYPE_NORMAL
- en: Please allow ample time to complete the migration. Depending on the size and
    complexity of the dataset, it can take a lot of time to migrate, up to hours or
    even days for extreme cases.
  prefs: []
  type: TYPE_NORMAL
- en: Table sharding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An alternative to sharding by shard key, for smaller clusters, is to separate
    tables or collections by server. This means that any query in table X is directed
    to a specific server, and the rest of the queries are directed to another. This
    strategy only works for unrelated tables, as it's not possible to perform joins
    between tables in different servers.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this can be considered, being pedantic, as not properly sharding,
    though the structure is similar.
  prefs: []
  type: TYPE_NORMAL
- en: This works as a less complicated alternative, but it's way less flexible. It's
    only recommended for relatively small clusters where there's a big imbalance in
    size between one or two tables and the rest, for example, if one table stores
    logs that are much bigger than the rest of the database and are sparingly accessed.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and disadvantages of sharding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In summary, the main advantages of sharding are:'
  prefs: []
  type: TYPE_NORMAL
- en: Allows spreading writes over multiple servers, increasing the write throughput
    of the system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data gets stored in multiple servers, so massive amounts of data can be
    stored, without limiting the data that can be stored in a single server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In essence, sharding allows the creation of big, scalable systems. But it also
    has disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Sharded systems are more complicated to run and have some overhead in terms
    of configuring different servers, and so forth. While any big deployment will
    have its problems, sharding requires more work than a primary-replica setup, as
    the maintenance and operation need to be planned with more care and operations
    will take longer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Native support for sharding is available only in a small number of databases,
    like MongoDB, but relational databases don't have the feature implemented natively.
    This means that the complexity needs to be handled with ad hoc code, which will
    require an investment in developing it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some queries will be impossible or almost impossible to do once the data is
    sharded. Aggregation and joins, depending on how the data is partitioned, won't
    be possible. The shard key needs to be selected carefully, as it will have a big
    implication on what queries are possible or not. We also lose the ACID properties,
    as some operations may need to involve more than one shard. A sharded database
    is less flexible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we've seen, designing, operating, and maintaining a sharded database only
    makes sense for very big systems, when the number of actions in the database requires
    such a complex system.
  prefs: []
  type: TYPE_NORMAL
- en: Schema design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For databases that need to define a schema, the specific design to use is something
    that needs to be considered.
  prefs: []
  type: TYPE_NORMAL
- en: This section will talk specifically about relational databases, as they are
    the ones that enforce a stricter schema. Other databases are more flexible in
    their changes, but they also benefit from spending some time thinking about their
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: Changing the schema is an important action that will require planning and, certainly,
    a long-term view needs to be applied to the design.
  prefs: []
  type: TYPE_NORMAL
- en: We will talk later in the chapter about how to change the schema of a database.
    We only need to remark here that mutating the database schema is an unavoidable
    part of the process of building a system. Nonetheless, it's a process that needs
    to be taken with respect and understanding what the possible problems are. It's
    definitely a good idea to spend time thinking about and ensuring an adequate design
    for the schema.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to start the design of a schema is to draw the different tables,
    fields, and their relationships, if there are foreign keys pointing to other tables.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_07.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.7: Drawing a schema'
  prefs: []
  type: TYPE_NORMAL
- en: The presentation of this data should allow you to detect possible blind spots
    or the repetition of elements. If the number of tables is too big, it may be necessary
    to divide it into several groups.
  prefs: []
  type: TYPE_NORMAL
- en: Though there are tools that can help with this work, personally, it helps me
    to hand-draw these relationships, as it helps me think of the different relationships
    and construct a mental image of the design.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of the tables can have foreign key relationships with others of different
    kinds:'
  prefs: []
  type: TYPE_NORMAL
- en: '**One-to-many**, where a single reference is added for multiple elements of
    another table. For example, a single author is referenced in all their books.
    A simple foreign key relationship works in this case, as the Books table will
    have a foreign key to the entry in Authors. Multiple book rows can have a reference
    to the same author.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_08.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.8: The key in the first table references multiple rows in the second'
  prefs: []
  type: TYPE_NORMAL
- en: '**One-to-zero or -one** are specific cases where a row can be related to only
    another. For example, let''s assume an editor can be working on a book (and only
    one book at a time). The reference for the editor in the Books table is a foreign
    key that can be set to `null` if there''s no editing process. Another back reference
    from the editor to the book will ensure that the relationship is unique. Both
    references need to be changed in a transaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strict one-to-one relationships, like a book and a title, where both are always
    related, are typically better modeled as adding all the information into a single
    table.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17580_03_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: The relationship only makes it possible to match two rows'
  prefs: []
  type: TYPE_NORMAL
- en: '**Many-to-many**,where there can be multiple assignments in both directions.
    For example, a book may be categorized under different genres. A single genre
    will be assigned to multiple books, and a single book can be assigned to more
    than one genre. Under a relational data structure, there''s a need for an intermediary
    extra table that makes that relationship, which will point to both the book and
    the genre.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This extra table may include more information, for example, how accurate the
    genre is for the book. That way, it could describe books that are 50% horror and
    90% adventure.
  prefs: []
  type: TYPE_NORMAL
- en: Outside of the relational data world, sometimes there's not such a pressing
    need for creating many-to-many relationships, and instead they can be directly
    added as a collection of tags. Some relational databases now allow more flexibility
    in allowing fields that are lists or JSON objects, which can be used in this way,
    simplifying the design.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_10.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.10: Note the intermediary table allows multiple combinations. The
    first table can reference multiple rows of the second, and the second multiple
    rows of the first'
  prefs: []
  type: TYPE_NORMAL
- en: 'In most cases, the types of fields to store for each of the tables are straightforward,
    though certain details should be considered:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Allowing enough space to grow in the future**. Some fields, like strings,
    require defining a maximum size to store. For example, storing a string representing
    an email address will require a maximum of 254 characters. But sometimes the size
    is not obvious, like storing the name of a customer. In these cases, it''s better
    to err on the safe size and increase the limit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The limits should be enforced not only for the database, but also above this
    level, to always allow any API or UI that deals with the field to handle it gracefully.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When dealing with numbers, in most cases regular integers will be enough to
    represent most used numbers. Though some databases accept categories like `smallint`
    for 2 bytes or `tinyint` for 1-byte values, it's not recommended to make use of
    them. The difference in space used will be minimal.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**The internal database representation doesn''t need to be the same as what''s
    externally available**. For example, the time stored in the database should always
    be in UTC, and then translated to the user''s time zone.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing the time always in UTC format allows using a consistent time in the
    server, in particular if there are users in different time zones. Storing the
    time by applying the time zone for the user produces non-comparable times in the
    database and using the default time zone of the server can produce different results
    based on the position of the server, or even worse, inconsistent data if more
    than one server in different time zones is involved. Ensure that all times are
    stored in the database in UTC.
  prefs: []
  type: TYPE_NORMAL
- en: Another example is if prices are stored, it's better to store them in cents,
    to avoid float numbers, and then present them as dollars and cents.
  prefs: []
  type: TYPE_NORMAL
- en: For example, this means that a price of $99.95 will be stored as the integer
    `9995`. Dealing with float arithmetic can create problems for prices, and prices
    can be translated into cents for easy handling.
  prefs: []
  type: TYPE_NORMAL
- en: The internal representation doesn't need to follow the same conventions if storing
    them in a different format is better for some reason.
  prefs: []
  type: TYPE_NORMAL
- en: '**At the same time, it''s better to represent the data naturally**. A typical
    example of that is the overabundance of using numeric IDs to represent rows that
    have natural keys or using `Enums` (small integers assigned to represent a list
    of options) instead of using short strings instead. While these choices made sense
    some time ago, when space and processing power were more restrictive, now the
    performance improvement is negligible, and storing data in an understandable way
    helps greatly while developing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, instead of using an integer field to store colors, where `1` means
    `RED`, `2` means `BLUE`, and `3` means `YELLOW`, use a short string field using
    the strings `RED`, `BLUE`, and `YELLOW`. The storing difference is negligible
    even if there are millions of records, and it's way easier to navigate the database.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We will see a bit later about normalization and denormalization, which are related
    to this concept.
  prefs: []
  type: TYPE_NORMAL
- en: '**No design will be perfect or complete**. In a system under development, the
    schema will always require changes. This is totally normal and expected and should
    be accepted as such. Perfect is the enemy of good. The design should try to be
    as simple as possible to adjust for the current needs of the system. Overdesign,
    trying to advance every possible future need and complicating the design, is a
    real problem that can waste efforts in laying the ground for needs that never
    materialize. Keep your design simple and flexible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schema normalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we've seen, in relational databases, a key concept is the foreign key one.
    Data can be stored in a table and linked to another. This split in data means
    that a set of limited data can, instead of being stored in a single table, be
    split in two.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s take a look at this table, initially with the field `House`
    as a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Characters**'
  prefs: []
  type: TYPE_NORMAL
- en: '| id | Name | House |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Eddard Stark | Stark |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Jon Snow | Stark |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Daenerys Targaryen | Targaryen |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Jaime Lannister | Lannister |'
  prefs: []
  type: TYPE_TB
- en: To ensure that the data is consistent and there are no errors, the field `House`
    can be normalized. This means that it's stored in a different table, and a `FOREIGN
    KEY` constraint is enforced, in this way.
  prefs: []
  type: TYPE_NORMAL
- en: '**Characters** **Houses**'
  prefs: []
  type: TYPE_NORMAL
- en: '| id | Name | HouseId (FK) |  | id | Name | Words |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Eddard Stark | 1 |  | 1 | Stark | Winter is coming |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Jon Snow | 1 |  | 2 | Lannister | Hear me roar |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Daenerys Targaryen | 3 |  | 3 | Targaryen | Fire and blood |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Jaime Lannister | 2 |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: This way of operating *normalizes* the data. No new entry with a new `House`
    can be added unless it is first introduced in the `Houses` table. In the same
    way, an entry in `Houses` cannot be deleted while a single entry in `Characters`
    contains a reference. This ensures that the data is very consistent and there
    are no problems, like introducing a typo like `House` *Lanister* (single n) for
    a new entry, which may complicate later queries.
  prefs: []
  type: TYPE_NORMAL
- en: It also has the advantage of being able to add extra information for each of
    the entries in `Houses`. In this case, we can add the `Words` of the `House`.
    The data is also more compact, as repeated information is stored in a single pace.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, this has a couple of issues. First of all, any reference
    to a `Character` that needs to know the information of the `House` needs to perform
    a `JOIN` query. In the first `Characters` table, we could generate our query in
    this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'While in the second schema, we will require this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This query will take longer to execute, as information needs to be compounded
    from two tables. For big tables, this time can be extensive. This can also require
    a `JOIN` from different tables if we add, for example, a `PreferredWeapon` field
    and a `Weapons` normalized table for each `Character`. Or we can add even more
    tables as the `Characters` table grows in fields.
  prefs: []
  type: TYPE_NORMAL
- en: It will also take longer to insert and delete data, as more checks need to be
    performed. In general, operations will take longer.
  prefs: []
  type: TYPE_NORMAL
- en: Normalized data is also difficult to shard. The concept of normalization of
    keeping every element described in its own table and reference from there is inherently
    difficult to shard, as it makes partitioning very difficult.
  prefs: []
  type: TYPE_NORMAL
- en: Another problem is that the database is more difficult to read and operate.
    Deletes need to happen in an ordered fashion, which gets more difficult to follow
    as more fields are being added. Also, complex `JOIN` queries need to be performed
    for simple operations. The queries are longer and more complicated to generate.
  prefs: []
  type: TYPE_NORMAL
- en: While this normalization structure, creating foreign keys through numerical
    identifiers, is pretty typical, it's not the only option.
  prefs: []
  type: TYPE_NORMAL
- en: To improve the clarity of the database, natural keys can be used to simplify
    them, describing the data in this way. Instead of using an integer as the primary
    key, we use the `Name` field on the `Houses` table.
  prefs: []
  type: TYPE_NORMAL
- en: '**Characters** **Houses**'
  prefs: []
  type: TYPE_NORMAL
- en: '| Id | Name | House (FK) |  | Name (PK) | Words |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Eddard Stark | Stark |  | Stark | Winter is coming |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Jon Snow | Stark |  | Lannister | Hear me roar |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Daenerys Targaryen | Targaryen |  | Targaryen | Fire and blood |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Jaime Lannister | Lannister |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: This not only removes the usage of an extra field, but it also allows you to
    make the reference with a descriptive value. We recover our original query, even
    if the data is normalized.
  prefs: []
  type: TYPE_NORMAL
- en: As we described before, the extra space of storing a string instead of a single
    integer is negligible. Some developers are very much against natural keys and
    prefer to use integer values, but nowadays there's not really a solid technical
    reason for limiting yourself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Only when we want to obtain the information in the `Words` field will we need
    to perform a `JOIN` query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This trick, anyway, may not avoid the usage of `JOIN` queries in normal operation.
    Perhaps there are a lot of references and the system is having problems with the
    amount of time that it's taking to perform queries. In that case, it may be necessary
    to reduce the need to `JOIN` tables.
  prefs: []
  type: TYPE_NORMAL
- en: Denormalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Denormalization is the opposing action to normalization. Where normalizing data
    splits it into different tables to ensure that all the data is consistent, denormalizing
    regroups information into a single table to avoid the necessity to `JOIN` tables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following our example above, we want to replace a `JOIN` query like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Which follows this schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Characters** **Houses**'
  prefs: []
  type: TYPE_NORMAL
- en: '| Id | Name | House (FK) |  | Name (PK) | Words |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Eddard Stark | Stark |  | Stark | Winter is coming |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Jon Snow | Stark |  | Lannister | Hear me roar |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Daenerys Targaryen | Targaryen |  | Targaryen | Fire and blood |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Jaime Lannister | Lannister |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: 'For a query similar to this, querying a single table, use something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: To do so, the data needs to be structured in a single table.
  prefs: []
  type: TYPE_NORMAL
- en: '**Characters**'
  prefs: []
  type: TYPE_NORMAL
- en: '| id | Name | House | Words |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Eddard Stark | Stark | Winter is coming |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Jon Snow | Stark | Winter is coming |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Daenerys Targaryen | Targaryen | Fire and blood |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Jaime Lannister | Lannister | Hear me roar |'
  prefs: []
  type: TYPE_TB
- en: Note that information is duplicated. Every `Character` has a copy of the `Words`
    of the `House`, something that was not required before. This means denormalization
    uses more space; in a big table with many rows, way more space.
  prefs: []
  type: TYPE_NORMAL
- en: Denormalization also increases the risk of inconsistent data, as there's nothing
    ensuring that there's not a new value that's a typo of an old value, or that,
    by mistake, incorrect `Words` are added to a different `House`.
  prefs: []
  type: TYPE_NORMAL
- en: But, on the other hand, we are now free of having to `JOIN` tables. For big
    tables this can speed up processing, both read and writes, quite a lot. It also
    removes the concerns for sharding, as now the table can be partitioned on whatever
    shard key that's convenient and will contain all the information.
  prefs: []
  type: TYPE_NORMAL
- en: Denormalization is an extremely common option for the use cases that typically
    fall under NoSQL databases, which remove the capability to perform `JOIN` queries.
    For example, document databases embed data as subfields into a bigger entity.
    While it certainly has its cons, it's a trade-off that makes sense in some operations.
  prefs: []
  type: TYPE_NORMAL
- en: Data indexing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As data grows, the access to data starts getting slower. Retrieving exactly
    the proper data from a big table full of information requires performing more
    internal operations to locate it.
  prefs: []
  type: TYPE_NORMAL
- en: While we will describe data indexing in relation to relational databases, most
    of the fundamentals are applicable to other databases.
  prefs: []
  type: TYPE_NORMAL
- en: This process can be greatly speeded up by organizing the data smartly in a way
    that is easy to search. This leads to creating indexes that allow you to locate
    data very quickly by searching through them. The basics of an index is to create
    an external sorted data structure that points to one or more fields of each of
    the records of the database. This index structure is always kept sorted as data
    in the table changes.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a short table may contain this information
  prefs: []
  type: TYPE_NORMAL
- en: '| id | Name | Height (cm) |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Eddard | 178 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | John | 173 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Daenerys | 157 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Jaime | 188 |'
  prefs: []
  type: TYPE_TB
- en: In the absence of an index, to query what entry has the highest height, the
    database will need to individually check each of the rows and sort them. This
    is called a **full table scan**. A full table scan can be very costly if the table
    has millions of rows.
  prefs: []
  type: TYPE_NORMAL
- en: By creating an index for the `Height` field, a data structure that is always
    sorted is kept in sync with the data.
  prefs: []
  type: TYPE_NORMAL
- en: '| id | Name | Height (cm) |  | Height (cm) | id |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Eddard | 178 |  | 188 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | John | 173 |  | 178 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Daenerys | 157 |  | 173 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Jaime | 188 |  | 157 | 3 |'
  prefs: []
  type: TYPE_TB
- en: Because it is always sorted, making any query related to the height is easy
    to fulfill. For example, obtaining what the top 3 heights are doesn't require
    any checking, just retrieving the first three records from the index, and determining
    heights between 180 and 170 is also easy, using search methods in sorted lists,
    like a binary search. Once again, if this index doesn't exist, the only way to
    find these queries is by checking each record in the table.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the index doesn't cover all the fields. The `Name` field is not indexed,
    for example. Another index may be required to cover other fields. The same table
    accepts multiple indices.
  prefs: []
  type: TYPE_NORMAL
- en: The primary key of a table is always indexed, as it needs to be a unique value.
  prefs: []
  type: TYPE_NORMAL
- en: Indexes can be combined, creating an index for two or more fields. These composite
    indices sort the data based on the ordered combination of both fields, for example,
    a composite index that is `(Name, Height)` will quickly return the height for
    `Names` starting with `J`. A composite index of `(Height, Name)` will do the opposite,
    priming the height and then sorting the `Name` field.
  prefs: []
  type: TYPE_NORMAL
- en: Querying in composite indices for only the first part of the index is possible.
    In our example, an index of `(Height, Name)` will always work for querying `Height`.
  prefs: []
  type: TYPE_NORMAL
- en: The usage or not of indexes to retrieve the information is done automatically
    by the database; the SQL query doesn't change at all. Internally, the database
    will run the query analyzer before running a query. This part of the database
    software will determine how to retrieve the data, and what indexes to use, if
    any.
  prefs: []
  type: TYPE_NORMAL
- en: The query analyzer needs to run quickly, as determining what the best possible
    way to search for information is can take more time than running a naïve approach
    and returning the data. This means that, sometimes, it will make mistakes and
    not use the optimal combination. The SQL command `EXPLAIN`, used before another
    SQL statement, will display how the query will be interpreted and run, which allows
    you to understand and tweak it to improve its execution time.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that using different independent indices in the same query may
    not be possible. Sometimes the database won't be able to perform a faster query
    by combining two indices as the data needs to be correlated between them, and
    that may be a costly operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Indexes greatly speed up the queries that use them, especially for big tables
    with thousands or millions of rows. They are also used automatically, so they
    don''t add extra complexity to the generation of queries. So, if they are so great,
    why not index absolutely everything? Well, indices also have some issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Each index requires extra space. While this is optimized, adding a lot of indexes
    in a single table will use more space, both in the hard drive and in RAM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each time the table changes, all indices in the table need to be adjusted to
    be sure that the index is properly sorted. This is more noticeable in new data
    being written, like records being added or indexed fields being updated. Indices
    are a trade-off between spending more time on writing to speed up the reading.
    For tables that are write heavy, this trade-off may not be adequate, and maintaining
    one or more indices can be counterproductive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Small tables don't really benefit from being indexed. The difference between
    a full table scan and an indexed search is small if the number of rows is below
    the thousands.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a rule of thumb, it's better to try to create indices *after* the need is
    detected. Once a slow query is discovered, analyze if an index will improve the
    situation, and only then create it.
  prefs: []
  type: TYPE_NORMAL
- en: Cardinality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An important characteristic of the usefulness of each index is its **cardinality**.This
    is the number of different values that an index contains.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the `Height` index in this table has a cardinality of 4\. There
    are four different values.
  prefs: []
  type: TYPE_NORMAL
- en: '| id | Height (cm) |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 178 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 165 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 167 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 192 |'
  prefs: []
  type: TYPE_TB
- en: A table like this has only a cardinality of 2.
  prefs: []
  type: TYPE_NORMAL
- en: '| id | Height (cm) |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 178 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 165 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 178 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 165 |'
  prefs: []
  type: TYPE_TB
- en: An index with low cardinality has low quality, as it's not able to speed up
    the search as much as expected. An index can be understood as a filter that allows
    you to reduce the number of rows to search. If, after applying the filter, the
    table has not been greatly reduced, the index won't be useful. Let's use an extreme
    example to describe it.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a table with a million rows indexed by a field that's the same in all
    of them. Now imagine that we make a query to find a single row in a different
    field that's not indexed. If we use the index, we won't be able to speed up the
    process, as the index will return every single row in the database.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, shoji, crossword puzzle'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_11.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.11: Returning every single row from a query using an unhelpful index'
  prefs: []
  type: TYPE_NORMAL
- en: Now imagine it with two values. Half of the rows of the table are returned first,
    and then we need to query them. This is better, but using the index has some overhead
    compared with just performing a full table scan, so in practice, this is not very
    advantageous.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, clock'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/B17580_03_12.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.12: Returning rows using an index with two values'
  prefs: []
  type: TYPE_NORMAL
- en: As we increase the cardinality of the index, adding more and more values, the
    index is more useful.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, box and whisker chart'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated with medium confidence](img/B17580_03_13.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.13: Returning rows using an index with four values'
  prefs: []
  type: TYPE_NORMAL
- en: With a higher cardinality, the database is able to discriminate better and to
    point to a smaller subsection of values, which speeds up greatly access to the
    proper data.
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, ensure that the cardinality of an index is always 10 or
    higher. Lower than that is probably not good enough to use as an index. The query
    analyzer will take the cardinality value into account to see whether to use the
    index or not.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the cardinality of fields that only allow a small number of
    values, such as `Booleans` and `Enums`, is always limited and makes them bad candidates
    to be indexed, at least on their own. On the other hand, values that are unique
    will always have the highest possible cardinality and they are good candidates
    for indexing. Primary keys are always indexed automatically for this reason.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we described different methods and techniques to deal with
    the storage layer, both from the point of view of the different capacities and
    options available in the database itself, and how the code of our application
    can interact to store and retrieve information.
  prefs: []
  type: TYPE_NORMAL
- en: We described the different kinds of databases, both relational and non-relational,
    and what the differences and usages of each are, and how the concept of a transaction,
    one of the fundamental characteristics of relational databases, allows compliance
    with ACID properties. As some of the non-relational databases are aimed at dealing
    with data on a large scale and are distributed, we presented some of the techniques
    to scale up relational systems, as that kind of database was not initially designed
    to deal with multiple servers.
  prefs: []
  type: TYPE_NORMAL
- en: We continued by describing how we can design a schema and what the pros and
    cons are for normalizing and denormalizing the data. We also described why we
    index fields and when it's counterproductive.
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapter 4*, *The Data Layer*, we will see how to design the data layer.
  prefs: []
  type: TYPE_NORMAL
