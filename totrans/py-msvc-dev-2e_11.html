<html><head></head><body>
  <div id="_idContainer078">
    <h1 class="chapterNumber">11</h1>
    <h1 id="_idParaDest-176" class="chapterTitle">What's Next?</h1>
    <p class="normal">In this book, we have discussed the design and development of microservices written in Python using the Quart framework. We have built a monolithic application from which to work, and covered strategies to migrate from that architecture to one that makes the best use of microservices, along with the potential errors that could arise and how to avoid them. We have also learned about deploying our application to cloud providers using container-based services.</p>
    <p class="normal">However, this is not the end of the story, and there are other topics that are beneficial to learn more about. There is always going to be more room for improvement in our automation and tooling to help services keep up to date, more questions to answer about performance and capacity management that our monitoring and logging can help with, and considerations about how to scale and change our deployment architecture to improve the service's reliability and availability. Finally, we need to remember that – unless writing code for a hobby – the software itself is not the end goal, and we must keep our promises to the people who need the software.</p>
    <h1 id="_idParaDest-177" class="title">Automation</h1>
    <p class="normal">We briefly<a id="_idIndexMarker679"/> discussed <strong class="keyword">Terraform</strong> as <a id="_idIndexMarker680"/>a way to automate the creation of cloud-based resources, and there is a lot more to learn about this tool as well as others that can automate some of the work involved in running a service.</p>
    <p class="normal">To configure inside an instance, configuration management tools such as <strong class="keyword">Ansible</strong>, <strong class="keyword">Chef</strong>, and <strong class="keyword">Puppet</strong> allow you to copy files, change file contents, install packages, and set up a computer how you like it in a repeatable, predictable manner. </p>
    <p class="normal">Building operating system images for your own environment can be done with HashiCorp's <strong class="keyword">Packer</strong>, which lets you use the configuration management tools above to create operating system images for use in AWS, GCP, VMware, or Docker, among many others.</p>
    <p class="normal">Even if your infrastructure is small, using automation to create and maintain it is still valuable. In the event of a disaster, you are a few short commands away from recreating your entire suite of applications, instead of weeks of painstaking work.</p>
    <p class="normal">When creating <a id="_idIndexMarker681"/>infrastructure as code, it's very easy to accidentally create a new monolith, responsible for creating and maintaining every component. If that is a deliberate, considered choice then it will work well, but it's also worth remembering <a id="_idIndexMarker682"/>the other principles of privilege separation and ease of maintenance that come <a id="_idIndexMarker683"/>with separating <a id="_idIndexMarker684"/>out the features into<a id="_idIndexMarker685"/> smaller projects. Here are some relevant links:</p>
    <ul>
      <li class="bullet">Terraform: <a href="https://www.terraform.io/"><span class="url">https://www.terraform.io/</span></a></li>
      <li class="bullet">Ansible: <a href="https://www.ansible.com/"><span class="url">https://www.ansible.com/</span></a></li>
      <li class="bullet">Chef: <a href="https://www.chef.io/"><span class="url">https://www.chef.io/</span></a></li>
      <li class="bullet">Puppet: <a href="https://puppet.com/"><span class="url">https://puppet.com/</span></a></li>
    </ul>
    <h1 id="_idParaDest-178" class="title">Scaling</h1>
    <p class="normal">When an application<a id="_idIndexMarker686"/> needs to do more work, the historical approach has been to run the application on a bigger computer. Give it more memory, more CPU cores, and even more disk space. This does not increase the application's reliability, as it still relies on a single computer, and it comes with added complications once your application is large enough that there simply aren't any computers large enough to run it on.</p>
    <p class="normal">Giving a program a larger computer to run on is called scaling vertically. By contrast, scaling horizontally is the approach of using many smaller computers. We came across this idea when discussing deploying on container-based services and increasing the number of instances that our Docker swarm used. An application must have a replicated, scalable idea of its current state to operate in this way, for client sessions, shopping basket contents, and anything else that a visitor would expect to be persistent between different pages of a website.</p>
    <p class="normal">Microservices allow you to scale an application much more easily, although it is important to remember that every component communicates with other microservices and that an increased load in one area will have consequences in others. </p>
    <p class="normal">Careful monitoring will allow you to discover the bottlenecks in the overall system, and so prioritize which area needs the most urgent work in order to give the system more capacity.</p>
    <h1 id="_idParaDest-179" class="title">Content Delivery Networks</h1>
    <p class="normal">Some of the content our <a id="_idIndexMarker687"/>applications deliver does not change very often, such as HTML pages, JavaScript, images, and video streams. <strong class="keyword">Content Delivery Networks</strong> (<strong class="keyword">CDNs</strong>) aim to provide static content that is distributed around the world. Acting either as a layer in front of your application or alongside it, they can provide cacheable content to clients much more quickly than a customized service. Some CDNs will also allow you to dynamically scale images and video based on the client and its network quality, or provide protection against distributed denial of service attacks, making them a valuable tool for any web-based service.</p>
    <h1 id="_idParaDest-180" class="title">Multi-cloud deployments</h1>
    <p class="normal">When assessing the risks <a id="_idIndexMarker688"/>involved in running a service, it's easy to come to the realization that your organization is completely dependent on one cloud provider. A common desire to improve redundancy is to deploy services to multiple providers and spread the workload across Azure, GCP, Amazon, and others. This might seem like a great idea, but it also introduces a lot of complexity as different providers have different feature sets available, will need unique security arrangements, and be unable to share storage and secrets management.</p>
    <p class="normal">While <code class="Code-In-Text--PACKT-">Terraform</code> can help with this situation, it is often more achievable to aim for multiple regions within the same provider, and if several cloud providers are really required, to separate what's running in them based on how things interact. It's far easier to put a completely independent service somewhere else. There are parallels with the strategic approach and splitting a monolith into microservices, as a successful migration requires a clean interface between different components and well-structured isolation of concerns and requirements.</p>
    <h1 id="_idParaDest-181" class="title">Lambda Functions</h1>
    <p class="normal">Lambda, or Cloud <a id="_idIndexMarker689"/>Functions, is a type of serverless deployment intended for small, short-lived tasks that can scale up and down very rapidly. While asynchronous frameworks have limited support in this area in 2021, they are widely used with synchronous code as the way they are run means that the responsiveness is controlled by the sheer number of them that can run simultaneously.</p>
    <h1 id="_idParaDest-182" class="title">Expanding monitoring</h1>
    <p class="normal">In <em class="chapterRef">Chapter 5</em>, <em class="italic">Splitting the Monolith</em>, we discussed monitoring<a id="_idIndexMarker690"/> and collecting metrics to record what an application is doing. Measurements can tell some of the story and give a picture involving a count, a size, or time passing. To get even more information, we can use logging services to record messages our application produces.</p>
    <p class="normal">If you have set up a Linux server, you may be familiar with the logs that pass through <code class="Code-In-Text--PACKT-">rsyslog</code> and end up in a file that exists in <code class="Code-In-Text--PACKT-">/var/log</code>. In a cloud service, and especially in a container, logging locally is far less useful, as we would have to then investigate all the running containers and cloud instances to discover what was happening. Instead, we can use a centralized logging service.</p>
    <p class="normal">This could be done using tools such as AWS CloudWatch or Google's Cloud Logging, but it's also possible to run services such as <code class="Code-In-Text--PACKT-">Splunk</code> or <code class="Code-In-Text--PACKT-">Logstash</code>. The latter is part of a popular open source trio of tools called the <code class="Code-In-Text--PACKT-">ELK</code> stack, as it contains Elasticsearch, Logstash, and Kibana, to collect, search, and visualize logged data. Using these tools, all the logs from the systems and applications can end up in a single place and be easily examined.</p>
    <p class="normal">Using structured logging techniques, it is also straightforward to annotate all the log entries to easily determine which microservice produced them, and so to better correlate events. A centralized logging service will allow you to connect the dots between errors in one component and reports from a separate area. At the same time, each microservice being more isolated means that any impact they have on other components should be through the designed interfaces, instead of being side effects due to resource constraints on the same server, or in the same process tree.</p>
    <p class="normal">The ELK stack<a id="_idIndexMarker691"/> is a great starting point for collecting large numbers of logs and metrics, and you can discover more about it at <a href="https://www.elastic.co/what-is/elk-stack"><span class="url">https://www.elastic.co/what-is/elk-stack</span></a>.</p>
    <h1 id="_idParaDest-183" class="title">Making promises</h1>
    <p class="normal">When writing <a id="_idIndexMarker692"/>software, we are often not doing so in isolation, but instead to help our company or open source project achieve a goal. Relying on our intuition to tell us whether we're doing a good job is often misleading, as our instinct is affected by all the different biases humans have. Instead, we must measure – collect numbers, watch for patterns, and analyze data.</p>
    <p class="normal">To demonstrate how well our software is doing, both to ourselves and to others, there are three levels we can think about. The first is the list of possible things we can measure, and these are<a id="_idIndexMarker693"/> known as <strong class="keyword">Service-Level Indicators</strong> (<strong class="keyword">SLIs</strong>). As developers, it is easy to come up with a list of technology-related SLIs, such as:</p>
    <ul>
      <li class="bullet">The API response time in milliseconds</li>
      <li class="bullet">A count of the different HTTP status codes</li>
      <li class="bullet">The number of bytes transferred in each request</li>
    </ul>
    <p class="normal">However, it is vitally important to include organization-level indicators as well, such as:</p>
    <ul>
      <li class="bullet">How long an <a id="_idIndexMarker694"/>online shop's check-out process takes</li>
      <li class="bullet">How many potential customers abandon a purchase during check-out</li>
      <li class="bullet">The financial cost of running a service, especially one that automatically scales up and down</li>
    </ul>
    <p class="normal">Both types of indicators, when used together, can make for very useful reports and dashboards for an organization, but you also don't want to be constantly checking on things – there is other work to be done! A <strong class="keyword">Service-Level Objective</strong> (<strong class="keyword">SLO</strong>) sets a threshold or alert value on top of an <a id="_idIndexMarker695"/>SLI, such as:</p>
    <ul>
      <li class="bullet">Fewer than 1% of HTTP status codes must indicate a server error</li>
      <li class="bullet">The rate of completed check-out operations must exceed 75%</li>
      <li class="bullet">Users can successfully complete at least 99.9% of their requests without an error</li>
    </ul>
    <p class="normal">What should we do if an SLO is not met? That's where <strong class="keyword">Service-Level Agreements</strong> (<strong class="keyword">SLAs</strong>) come in. SLAs <a id="_idIndexMarker696"/>are a contract – official or otherwise – between the providers of a service and the people using it and describe what should happen when an SLO is not met.</p>
    <p class="normal">Here is an example covering all the levels:</p>
    <ul>
      <li class="bullet">Service-level indicator: The number of HTTP 500 errors recorded</li>
      <li class="bullet">Service-level objective: The HTTP 500 errors should not be more than 1% of the total requests</li>
      <li class="bullet">Service-level agreement: A site reliability engineer is alerted and affected customers are informed</li>
    </ul>
    <p class="normal">Creating SLOs helps developers and product team members understand what's important about an application and lets us demonstrate to everyone involved that the application is doing what it is meant to do.</p>
    <h1 id="_idParaDest-184" class="title">Summary</h1>
    <p class="normal">As software developers we never stop improving our skills and knowledge, trying out new technologies and architectures, and building on the work of many others. Our profession's core skill is approaching a situation in a rational and methodical manner, breaking down each part of the problem into manageable chunks, and making sure that we – and others who have a stake in our work – can make sense of it all.</p>
    <p class="normal">The microservices approach uses the same techniques in systems design, making each component easier to reason about and investigate. Like many approaches, it works very well when it is done with careful consideration, rather than a desire to follow a fashion.</p>
    <p class="normal">Designing applications well takes a combination of knowledge, skill, and experience, and we hope that this book has contributed to the expertise that you bring to your work, whether it's paid, volunteering, or a hobby.</p>
  </div>
</body></html>