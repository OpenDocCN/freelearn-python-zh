- en: Dividing Text Data and Building Text Classifiers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分割文本数据并构建文本分类器
- en: 'This chapter presents the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了以下食谱：
- en: Building a text classifier
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建文本分类器
- en: Preprocessing data using tokenization
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分词进行数据处理
- en: Stemming text data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对文本数据进行词干提取
- en: Dividing text using chunking
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分块划分文本
- en: Building a bag-of-words model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建词袋模型
- en: Applications of text classifiers
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本分类器的应用
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: This chapter presents recipes to build text classifiers. This includes extracting
    vital features from the database, training, testing, and validating the text classifier.
    Initially, a text classifier is trained using commonly used words. Later, the
    trained text classifier is used for prediction. Building a text classifier includes
    preprocessing the data using tokenization, stemming text data, dividing text using
    chunking, and building a bag-of-words model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了构建文本分类器的配方。这包括从数据库中提取关键特征、训练、测试和验证文本分类器。最初，文本分类器使用常用词汇进行训练。随后，训练好的文本分类器用于预测。构建文本分类器包括使用分词对数据进行预处理、对文本数据进行词干提取、使用分块对文本进行划分，以及构建词袋模型。
- en: Building a text classifier
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建文本分类器
- en: Classifier units are normally considered to separate a database into various
    classes. The Naive Bayes classifier scheme is widely considered in literature
    to segregate the texts based on the trained model. This section of the chapter
    initially considers a text database with keywords; feature extraction extracts
    the key phrases from the text and trains the classifier system. Then, **term frequency-inverse
    document frequency** (**tf-idf**) transformation is implemented to specify the
    importance of the word. Finally, the output is predicted and printed using the
    classifier system.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分类单元通常被认为是将数据库划分为各种类别。在文献中，朴素贝叶斯分类方案被广泛认为可以根据训练模型来分离文本。本章的这一部分最初考虑了一个包含关键词的文本数据库；特征提取从文本中提取关键短语并训练分类系统。然后，实施**词频-逆文档频率**（**tf-idf**）转换来指定单词的重要性。最后，使用分类系统预测并打印输出。
- en: How to do it...
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Include the following lines in a new Python file to add datasets:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个新的Python文件中包含以下行以添加数据集：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Perform feature extraction to extract the main words from the text:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对文本执行特征提取以提取主要单词：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Train the classifier:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练分类器：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Implement the Multinomial Naive Bayes classifier:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现多项式朴素贝叶斯分类器：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Predict the output categories:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测输出类别：
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Print the output:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印输出：
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following screenshot provides examples of predicting the object based on
    the input from the database:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图提供了基于数据库输入预测对象的示例：
- en: '![](img/18727b52-014c-4371-b8b5-87afba4948fc.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/18727b52-014c-4371-b8b5-87afba4948fc.png)'
- en: How it works...
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The previous section of this chapter provided insight regarding the implemented
    classifier section and some sample results. The classifier section works based
    on a comparison between the previous text in the trained Naive Bayes with the
    key test in the test sequence*.*
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的前一部分提供了关于实现分类器部分和一些样本结果的见解。分类器部分是基于在训练好的朴素贝叶斯分类器中的先前文本与测试序列中的关键测试之间的比较来工作的**。**
- en: See also
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'Please refer to the following articles:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅以下文章：
- en: '*Sentiment analysis algorithms and applications: A survey *at [https://www.sciencedirect.com/science/article/pii/S2090447914000550](https://www.sciencedirect.com/science/article/pii/S2090447914000550).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*情感分析算法与应用：综述* [https://www.sciencedirect.com/science/article/pii/S2090447914000550](https://www.sciencedirect.com/science/article/pii/S2090447914000550).'
- en: 'S*entiment classification of online reviews: using sentence-based language
    model* to learn how sentiment prediction works at [https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20](https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线评论的情感分类：使用基于句子的语言模型来学习情感预测是如何工作的。[https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20](https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20).
- en: '*Sentiment analysis using product review data* and *Sentence-level sentiment
    analysis in the presence of modalities* to learn more about various metrics used
    in recommendation systems at [https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2)
    and ;[https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1](https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用产品评论数据进行情感分析* 和 *在存在模态的情况下进行句子级情感分析*，以了解更多在[https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2)
    和 [https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1](https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1)中使用的推荐系统指标。'
- en: Pre-processing data using tokenization
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分词进行数据预处理
- en: The pre-processing of data involves converting the existing text into acceptable
    information for the learning algorithm.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理涉及将现有文本转换为学习算法可接受的信息。
- en: Tokenization is the process of dividing text into a set of meaningful pieces.
    These pieces are called tokens.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 分词是将文本划分为一组有意义的片段的过程。这些片段被称为标记。
- en: How to do it...
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何进行操作...
- en: 'Introduce sentence tokenization:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 介绍句子分词：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Form a new text tokenizer:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 形成一个新的文本分词器：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Form a new word tokenizer:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 形成一个新的单词分词器：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Introduce a new WordPunct tokenizer:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 介绍一个新的WordPunct分词器：
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result obtained by the tokenizer is shown here. It divides a sentence into
    word groups:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 分词器得到的结果在此展示。它将一个句子划分为词组：
- en: '![](img/edefd48e-c6ec-4a05-8c74-06f86de0fe71.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/edefd48e-c6ec-4a05-8c74-06f86de0fe71.png)'
- en: Stemming text data
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本数据归一化
- en: The stemming procedure involves creating a suitable word with reduced letters
    for the words of the tokenizer.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 词干处理过程涉及为分词器中的单词创建一个带有减少字母的合适单词。
- en: How to do it...
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Initialize the stemming process with a new Python file:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用新的 Python 文件初始化词干提取过程：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s describe some words to consider, as follows:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们描述一些需要考虑的词汇，如下所示：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Identify a group of `stemmers` to be used:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定要使用的一组`词干提取器`：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Initialize the necessary tasks for the chosen `stemmers`:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化所选`stemmers`所需的必要任务：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Format a table to print the results:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 格式化表格以打印结果：
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Repeatedly check the list of words and arrange them using chosen `stemmers`:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反复检查单词列表，并使用选定的`词干提取器`对它们进行排列：
- en: '[PRE15]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The result obtained from the stemming process is shown in the following screenshot:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从词干处理过程中获得的结果显示在下述截图：
- en: '![](img/028b5d01-6a9b-47d5-a58c-1f20e599e27c.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/028b5d01-6a9b-47d5-a58c-1f20e599e27c.png)'
- en: Dividing text using chunking
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分块划分文本
- en: The chunking procedure can be used to divide the large text into small, meaningful
    words.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 块状处理程序可以用来将大文本分割成小而有意义的单词。
- en: How to do it...
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Develop and import the following packages using Python:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Python 开发并导入以下包：
- en: '[PRE16]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Describe a function that divides text into chunks:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述一个将文本分割成块的功能：
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Initialize the following programming lines to get the assigned variables:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化以下编程行以获取指定的变量：
- en: '[PRE18]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Start the iteration using words:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下词汇开始迭代：
- en: '[PRE19]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After getting the essential amount of words, reorganize the variables:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在获得基本词汇量后，重新组织变量：
- en: '[PRE20]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Attach the chunks to the output variable:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将块附加到输出变量：
- en: '[PRE21]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Import the data of `Brown corpus` and consider the first `10000` words:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`布朗语料库`的数据，并考虑前`10000`个单词：
- en: '[PRE22]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Describe the word size in every chunk:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述每个块中的字大小：
- en: '[PRE23]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Initiate a pair of significant variables:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一对重要变量：
- en: '[PRE24]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Print the result by calling the `splitter` function:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用`splitter`函数来打印结果：
- en: '[PRE25]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The result obtained after chunking is shown in the following screenshot:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据块化后得到的结果如下截图所示：
- en: '![](img/eb43cd8a-4d36-444a-bfcd-106fb68016f2.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/eb43cd8a-4d36-444a-bfcd-106fb68016f2.png)'
- en: Building a bag-of-words model
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建词袋模型
- en: When working with text documents that include large words, we need to switch
    them to several types of arithmetic depictions. We need to formulate them to be
    suitable for machine learning algorithms. These algorithms require arithmetical
    information so that they can examine the data and provide significant details.
    The bag-of-words procedure helps us to achieve this. Bag-of-words creates a text
    model that discovers vocabulary using all the words in the document. Later, it
    creates the models for every text by constructing a histogram of all the words
    in the text.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理包含大量单词的文本文档时，我们需要将它们转换为几种不同的算术表示形式。我们需要将它们制定成适合机器学习算法的形式。这些算法需要算术信息，以便它们可以检查数据并提供重要的细节。词袋（Bag-of-words）过程帮助我们实现这一点。词袋通过使用文档中的所有单词来发现词汇，创建一个文本模型。随后，它通过构建文本中所有单词的直方图来为每篇文本创建模型。
- en: How to do it...
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Initialize a new Python file by importing the following file:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过导入以下文件来初始化一个新的 Python 文件：
- en: '[PRE26]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Define the `main` function and read the input data from `Brown corpus`:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`main`函数并从`Brown语料库`读取输入数据：
- en: '[PRE27]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Split the text content into chunks:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文本内容分成块：
- en: '[PRE28]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Build a vocabulary based on these `text` chunks:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于这些`文本`块构建词汇：
- en: '[PRE29]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Extract a document word matrix, which effectively counts the amount of incidences
    of each word in the document:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取文档词矩阵，该矩阵有效地统计文档中每个单词出现的次数：
- en: '[PRE30]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Extract the document term `matrix:`
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取文档术语 `matrix:`
- en: '[PRE31]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Extract the vocabulary and print it:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取词汇并打印：
- en: '[PRE32]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Print the document term `matrix`:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印文档项`矩阵`：
- en: '[PRE33]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Iterate throughout the words, and print the reappearance of every word in various
    chunks:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历所有单词，并打印每个单词在各种块中的重复出现：
- en: '[PRE34]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The result obtained after executing the bag-of-words model is shown as follows:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行词袋模型后得到的结果如下所示：
- en: '![](img/9d8a48dd-5943-4e49-8134-cf93269fd1df.png)![](img/db6c5542-f530-4b93-aa57-327b956e6d99.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图片1](img/9d8a48dd-5943-4e49-8134-cf93269fd1df.png)![](img/db6c5542-f530-4b93-aa57-327b956e6d99.png)'
- en: 'In order to understand how it works on a given sentence, refer to the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解它在特定句子中的工作原理，请参考以下内容：
- en: '*Introduction to Sentiment Analysis*, explained here: [https://blog.algorithmia.com/introduction-sentiment-analysis/](https://blog.algorithmia.com/introduction-sentiment-analysis/)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*情感分析简介*，在此处解释：[https://blog.algorithmia.com/introduction-sentiment-analysis/](https://blog.algorithmia.com/introduction-sentiment-analysis/)'
- en: Applications of text classifiers
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本分类器的应用
- en: Text classifiers are used to analyze customer sentiments, in product reviews,
    when searching queries on the internet, in social tags, to predict the novelty
    of research articles, and so on.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类器用于分析客户情绪，在产品评论中，在互联网搜索查询时，在社会标签中，预测研究文章的新颖性，等等。
