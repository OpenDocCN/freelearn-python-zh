- en: '11'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Input/Output, Physical Format, and Logical Layout
  prefs: []
  type: TYPE_NORMAL
- en: 'Computing often works with persistent data. There may be source data to be
    analyzed, or output to be created using Python input and output operations. The
    map of the dungeon that’s explored in a game is data that will be input to the
    game application. Images, sounds, and movies are data output by some applications
    and input by other applications. Even a request through a network will involve
    input and output operations. The common aspect to all of these is the concept
    of a file of data. The term file is overloaded with many meanings:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The operating system (OS) uses a file as a way to organize bytes of data on
    a device. It’s the responsibility of application software to make sense of the
    bytes. Two common kinds of devices offer variations in terms of the features of
    OS files:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Block devices such as disks or solid-state drives (SSDs): A file on this kind
    of device can seek any specific byte, making them particularly good for databases,
    where any row can be processed at any time.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Character devices such as a network connection, a keyboard, or a GPS antenna.
    A file on this kind of device is viewed as a stream of individual bytes in transit.
    There’s no way to seek forward or backward; the bytes must be captured in a buffer
    and processed as they arrive.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The word file also defines a data structure used by the Python runtime. A uniform
    Python file abstraction wraps the various OS file implementations. When we open
    a Python file, there is a binding between the Python abstraction, an OS implementation,
    and the underlying collection of bytes on a block device or stream of bytes of
    a character device.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Python gives us two common modes for working with a file’s content:'
  prefs: []
  type: TYPE_NORMAL
- en: In ”b” (binary) mode, our application sees the bytes, without further interpretation.
    This can be helpful for processing media data like images, audio, and movies,
    which have complex encodings. We’ll often import libraries like pillow to handle
    the details of image file encoding into bytes and decoding from bytes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In ”t” (text) mode, the bytes of the file are encodings of string values. Python
    strings are made of Unicode characters, and there are a variety of schemes for
    decoding bytes into text and encoding text into bytes. Generally, the OS has a
    preferred encoding and Python respects this. The UTF-8 encoding is popular. Pragmatically,
    a file can have any of the available Unicode encodings, and it may not be obvious
    which encoding was used to create a file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, Python modules like shelve and pickle have unique ways of representing
    more complex Python objects than simple strings. There are a number of pickle
    protocols available; all of them are based on binary mode file operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout this chapter, we’ll talk about how Python objects are serialized.
    Serialization creates a representation of the Python object’s state as a series
    of bytes. Deserialization is the reverse process: it recovers a Python object’s
    state from the bytes of a file. Saving and transferring a representation of the
    object state is the foundational concept behind REST web services.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When we process data from files, we have two common concerns:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The physical format of the data: We need to know how the bytes on the file
    are interpreted to reconstruct a Python object. The bytes could represent a JPEG-encoded
    image or an MPEG-encoded movie. One very common example is the bytes of the file
    representing Unicode text, organized into lines. Generally, physical format concerns
    are handled by Python libraries like csv, json, and pickle, among many others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The logical layout of the data: A given data collection may have flexible positions
    for storing data items. The arrangement of CSV columns or JSON fields can vary.
    In cases where the data includes labels, the logical layout is clear. Without
    labels, the layout is positional, and some additional schema information is required
    to identify which data items occupy the various positions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both the physical format decoding and logical layout schema are essential to
    interpreting the data on a file. We’ll look at a number of recipes for working
    with different physical formats. We’ll also look at ways to divorce our program
    from some aspects of the logical layout.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll look at the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Using pathlib to work with filenames](ch015_split_000.xhtml#x1-6160001)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Replacing a file while preserving the previous version](ch015_split_000.xhtml#x1-6260002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reading delimited files with the CSV module](ch015_split_000.xhtml#x1-6320003)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using dataclasses to simplify working with CSV files](ch015_split_000.xhtml#x1-6380004)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reading complex formats using regular expressions](ch015_split_001.xhtml#x1-6440005)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reading JSON and YAML documents](ch015_split_001.xhtml#x1-6520006)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reading XML documents](ch015_split_001.xhtml#x1-6600007)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reading HTML documents](ch015_split_001.xhtml#x1-6660008)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to work with files, we’ll start with objects that help control the
    OS filesystem. The common features of the directory structure of files and devices
    are described by Python’s pathlib module. This module has consistent behavior
    across a number of operating systems, allowing a Python program to work similarly
    on Linux, macOS, and Windows.
  prefs: []
  type: TYPE_NORMAL
- en: 11.1 Using pathlib to work with filenames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Most operating systems use a hierarchical tree of directories that contain
    files. The path from the root directory to a specific file is often shown as a
    string. Here’s an example path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This full path name lists seven named directories contained in the (unnamed)
    root directory. The final name has a stem of recipe_01 and a suffix of .py.
  prefs: []
  type: TYPE_NORMAL
- en: We can represent this as a string, and parse the string to locate directory
    names, file stems, and suffix strings. Doing this isn’t portable between the macOS
    and Linux operating systems, which use "/" for a separator, and Windows, which
    uses "\" for a separator. Further, Windows files may also have device names as
    a prefix to the path.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with edge cases like "/" in a filename or "." in a directory name can
    make string processing needlessly difficult. We can simplify parsing and many
    filesystem operations by using pathlib.Path objects instead of strings.
  prefs: []
  type: TYPE_NORMAL
- en: 11.1.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It’s important to separate three concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: A path that identifies a file, including the name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metadata for a file – like creation timestamps and ownership – kept in the directory
    tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The contents of the file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The contents of the files are independent of the directory information. It’s
    common for multiple directory entries to be linked to the same content. This can
    be done with hard links, where the directory information is shared among multiple
    paths, and soft links, where a special kind of file contains a reference to another
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Often, a filename has a suffix (or extension) used as a hint as to what the
    physical format is. A filename ending in .csv is likely a text file that can be
    interpreted as rows and columns of data. This binding between name and physical
    format is not absolute. File suffixes are only a hint and can be wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, the pathlib module handles all path-related processing. The module
    makes several distinctions among paths:'
  prefs: []
  type: TYPE_NORMAL
- en: Pure paths that may or may not refer to an actual file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concrete paths that are resolved; these refer to an actual file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This distinction allows us to create pure paths for files that our application
    will possibly create or refer to. We can also create concrete paths for those
    files that actually exist on the OS. An application often resolves a pure path
    to a concrete path.
  prefs: []
  type: TYPE_NORMAL
- en: While the pathlib module can make a distinction between Linux path objects and
    Windows path objects, this distinction is rarely needed. An important reason for
    using pathlib is because we want processing that is isolated from the details
    of the underlying OS.
  prefs: []
  type: TYPE_NORMAL
- en: 'All of the mini recipes in this section will leverage the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll also presume the argparse module is used to gather the file or directory
    names. For more information on argparse, see the [Using argparse to get command-line
    input](ch010.xhtml#x1-3490004) recipe in Chapter [6](ch010.xhtml#x1-3300006).
    We’ll use an options variable as a namespace that contains the input filename
    or directory name that the recipe works with. As an example, we’ll use the following
    Namespace object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Frequently, we’ll define argparse options to use type=Path so that the argument
    parsing creates Path objects for us. For the purposes of showing how Path objects
    work, the path information is provided as string values.
  prefs: []
  type: TYPE_NORMAL
- en: 11.1.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll show a number of common pathname manipulations in the following mini-recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Making the output filename by changing the input filename’s suffix](ch015_split_000.xhtml#x1-6190002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Making a number of sibling output files with distinct names](ch015_split_000.xhtml#x1-6200002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparing file dates to see which is newer](ch015_split_000.xhtml#x1-6210002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Finding all files that match a given pattern](ch015_split_000.xhtml#x1-6220002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first two reflect techniques for working with the path of directories to
    a file; using a Path object is much easier than doing sophisticated string manipulation.
    The last two gather information about concrete paths and the related files on
    a computer.
  prefs: []
  type: TYPE_NORMAL
- en: Making the output filename by changing the input filename’s suffix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Perform the following steps to create the output filename from an input filename
    by changing the input name’s suffix:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Path object from the input filename string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The PosixPath class is displayed because the author is using macOS. On a Windows
    machine, the class would be WindowsPath.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create the output Path object using the with_suffix() method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: All of the filename parsing is handled seamlessly by the Path class. This doesn’t
    create the concrete output file; it merely creates a new Path for it.
  prefs: []
  type: TYPE_NORMAL
- en: Making a number of sibling output files with distinct names
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Perform the following steps to make a number of sibling output files with distinct
    names:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Path object from the input filename string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the parent directory and the stem from the filename. The stem is the
    name without the suffix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the desired output name. For this example, we’ll append _pass to the
    stem and build the complete Path object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The / operator assembles a new Path from Path components. We need to put the
    / operation in parentheses to be sure that it’s performed first, to create a new
    Path object before changing the suffix.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing file dates to see which is newer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are the steps to see newer file dates by comparing them:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the Path objects from the input filename strings. The Path class will
    properly parse the string to determine the elements of the path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: When exploring this example, be sure the names in the options object are actual
    files.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the stat() method of each Path object to get timestamps for the file. Within
    the stat object, the st_mtime— attribute provides the most recent modification
    time for the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The values are timestamps measured in seconds. Your values will depend on the
    files on your system. If we want a timestamp that seems sensible to most people,
    we can use the datetime module to create a more useful object from this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can use any of a number of methods to format the datetime object.
  prefs: []
  type: TYPE_NORMAL
- en: Finding all files that match a given pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are the steps to find all the files that match a given pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the Path object from the input directory name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the glob() method of the Path object to locate all files in this directory
    that match a given pattern. For non-existent directories, the iterator will be
    empty. Using ** as part of the pattern will recursively walk the directory tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We’ve elided a number of the files in the results.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The glob() method is an iterator, and we’ve used the sorted() function to consume
    the values from this iterator and create a single list object from them.
  prefs: []
  type: TYPE_NORMAL
- en: 11.1.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Inside the OS, the sequence of directories to find a file is a path through
    the filesystem. In some cases, a simple string representation can be used to summarize
    the path. The string representation, however, makes many kinds of path operations
    into complex string parsing problems. A string is an unhelpfully opaque abstraction
    for working with OS paths.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Path class definition simplifies operations on paths. These attributes,
    methods, and operators on a Path instance include the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: .parent extracts the parent directory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: .parents enumerates all the enclosing directories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: .name is the final name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: .stem is the stem of the final name (without any suffix).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: .suffix is the final suffix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: .suffixes is the sequence of suffix values, used with file.tag.gz kinds of names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .with_suffix() method replaces the suffix of the file with a new suffix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .with_name() method replaces the name in the path with a new name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The / operator builds Path objects from Path and string components.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A concrete path represents an actual filesystem resource. For concrete path
    objects, we can do a number of additional manipulations of the directory information:'
  prefs: []
  type: TYPE_NORMAL
- en: Determine what kind of directory entry this is; that is, an ordinary file, a
    directory, a link, a socket, a named pipe (or FIFO), a block device, or a character
    device.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get the directory details, including information such as timestamps, permissions,
    ownership, size, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unlink (that is, remove) the directory entry. Note that unlinking ordinary files
    is distinct from removing an empty directory. We’ll look at this in the There’s
    more... section of this recipe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rename the file to place it in a new path. We’ll also look at this in the There’s
    more... section of this recipe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just about anything we might want to do with directory entries for files can
    be done with the pathlib module. The few exceptions are part of the os module,
    because they are generally OS-specific.
  prefs: []
  type: TYPE_NORMAL
- en: 11.1.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In addition to manipulating the path and gathering information about a file,
    we can also make some changes to the filesystem. Two common operations are renaming
    a file and unlinking (or removing) a file. We can use a number of methods to make
    changes to the filesystem:'
  prefs: []
  type: TYPE_NORMAL
- en: The .unlink() method removes ordinary files. It doesn’t remove directories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .rmdir() method removes empty directories. Removing a directory with files
    requires a two-step operation to first unlink all the files in the directory,
    then remove the directory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .rename() method renames a file to a new path.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .replace() method replaces a file without raising an exception if the target
    already exists.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .symlink_to() method creates a soft link file with a link to an existing
    file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .hardlink_to() method creates an OS hard link; two distinct directory entries
    will now own the underlying file content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can open a Path either using the built-in open() function or the open()
    method. Some people like to see open(some_path), where others prefer some_path.open().
    Both do the same thing: create an open file object.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create directories using the mkdir() method. There are two keyword parameters
    for this method:'
  prefs: []
  type: TYPE_NORMAL
- en: exist_ok=False is the default; if the directory already exists, an exception
    is raised. Changing this to True makes the code tolerant of an existing directory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: parents=False is the default; the parents are not created, only the child-most
    directory in the path. Changing this to True will create the entire path, parents
    and children.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can also read and write files as large string or bytes objects:'
  prefs: []
  type: TYPE_NORMAL
- en: The .read_text() method reads a file as a single string.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .write_text() method creates or replaces a file with the given string.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .read_bytes() method reads a file as a single bytes instance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The .write_bytes() method creates or replaces a file with the given bytes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are yet more file system operations, like changing ownership or changing
    permissions. These operations are available in the os module.
  prefs: []
  type: TYPE_NORMAL
- en: 11.1.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [Replacing a file while preserving the previous version](ch015_split_000.xhtml#x1-6260002)
    recipe, later in this chapter, we’ll look at how to leverage the features of a
    Path object to create a temporary file and then rename the temporary file to replace
    the original file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the [Using argparse to get command-line input](ch010.xhtml#x1-3490004) recipe
    in Chapter [6](ch010.xhtml#x1-3300006), we looked at one very common way to use
    a string to create a Path object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The os module offers a number of filesystem operations that are less commonly
    used than the ones provided by pathlib.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 11.2 Replacing a file while preserving the previous version
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can leverage the power of the pathlib module to support a variety of filename
    manipulations. In the [Using pathlib to work with filenames](ch015_split_000.xhtml#x1-6160001)
    recipe in this chapter, we looked at a few of the most common techniques for managing
    directories, filenames, and file suffixes.
  prefs: []
  type: TYPE_NORMAL
- en: One common file processing requirement is to create output files in a fail-safe
    manner; that is, the application should preserve any previous output file, no
    matter how or where the application fails.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: At time T[0], there’s a valid output.csv file from a previous run of the long_complex.py
    application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At time T[1], we start running the long_complex.py application using new data.
    It begins overwriting the output.csv file. Until the program finishes, the bytes
    will be unusable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At time T[2], the application crashes. The partial contents of the output.csv
    file are useless. Worse, the valid file from time T[0] is no longer available
    either because it was overwritten.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this recipe, we’ll look at an approach to creating output files that’s safe
    in the event of a failure.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For files that don’t span across physical devices, fail-safe file output generally
    means creating a new copy of the file using a temporary name. If the new file
    can be created successfully, then the old file should be replaced using a single,
    atomic rename operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to have the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: The important output file must be preserved in a valid state at all times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A temporary version of the file is written by the application. There are a
    variety of conventions for naming this file. Sometimes, extra characters such
    as ~ or # are placed on the filename to indicate that it’s a temporary, working
    file; for example, output.csv~. We’ll use a longer suffix, .new; for example,
    output.csv.new.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The previous version of the file is also preserved. Sometimes, the previous
    version has a suffix of .bak, meaning ”backup.” We’ll use a longer suffix and
    call it output.csv.old. This also means any previous .old file must be removed
    as part of finalizing the output; only a single version is preserved.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To create a concrete example, we’ll work with a file that has a very small
    but precious piece of data: a sequence of Quotient objects. Here’s the definition
    for the Quotient class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The following function will write an object to a file in CSV notation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: If a problem arises when writing the data object to the file, we could be left
    with a corrupted, unusable file. We’ll wrap this function with another to provide
    a reliable write.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We start creating a wrapper function by importing the classes we need:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a function to encapsulate the save_data() function along with a few
    extra features. The function signature is the same as the save_data() function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Save the original suffix and create a new name with .new at the end of the
    suffix. This is a temporary file. If it is written properly, with no exceptions,
    then we can rename it so that it’s the target file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The save_data() function is the original process to create the new file being
    wrapped by this function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Before replacing the previous file with the new, good file, remove any previous
    backup copy. We’ll unlink an .old file, if one exists:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can preserve any previous good file with the name of .old:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final step is to make the temporary .new file the official output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This multi-step process uses two rename operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Rename the previous version to a backup version with .old appended to the suffix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rename the new version, which had .new appended to the suffix, to be the current
    version of the file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Path object has a replace() method. This always overwrites the target file,
    with no warning if overwriting an existing file. The choice between rename() and
    replace() depends on how our application needs to handle cases where old versions
    of files may be left in the filesystem. We’ve used rename() in this recipe to
    try and avoid overwriting files in the case of multiple problems.
  prefs: []
  type: TYPE_NORMAL
- en: Because these are applied serially, there’s a tiny span of time between preserving
    the old file and renaming the new file where an application failure would fail
    to put a new file in place. We’ll look at this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This process involves three separate OS operations: an unlink and two renames.
    This is designed to ensure that an .old file is preserved and can be used to recover
    the previously good state.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a timeline that shows the state of the various files. We’ve labeled
    the content as version 0 (some previous data), version 1 (the current, valid data),
    and version 2 (the newly created data):'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Time | Operation | .csv.old | .csv | .csv.new |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| T[0] |  | version 0 | version 1 |  |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| T[1] | Mid-creation | version 0 | version 1 | Will appear corrupt if used
    |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| T[2] | Post-creation, closed | version 0 | version 1 | version 2 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| T[3] | After unlinking .csv.old |  | version 1 | version 2 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| T[4] | After renaming .csv to .csv.old | version 1 |  | version 2 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| T[5] | After renaming .csv.new to .csv | version 1 | version 2 |  |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11.1: Timeline of file operations'
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are several opportunities for failure, there’s no ambiguity about
    which file is valid:'
  prefs: []
  type: TYPE_NORMAL
- en: If there’s a .csv file, it’s the current, valid file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there’s no .csv file, then the .csv.old file is a valid backup copy, which
    should be used for recovery. See the T[4] moment in time, for this condition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since none of these operations involve actually copying the files, the operations
    are all extremely fast and reliable. They are, however, not guaranteed to work.
    The state of the filesystem can be changed by any user with the right permissions,
    leading to the need for care when creating new files that replace old files.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure the output file is valid, some applications will take an additional
    step and write a final checksum row in the file to provide unambiguous evidence
    that the file is complete and consistent.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In some enterprise applications, output files are organized into directories
    with names based on timestamps. These operations can be handled gracefully by
    the pathlib module. We might, for example, have an archive directory for old files.
    This directory has date-stamped subdirectories for keeping temporary or working
    files.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then do the following to define a working directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[firstline=58,lastline=58,gobble=4][python]src/ch11/recipe˙02.py [firstline=60,lastline=65,gobble=4][python]src/ch11/recipe˙02.py'
  prefs: []
  type: TYPE_NORMAL
- en: The mkdir() method will create the expected directory. By including the parents=True
    argument, any needed parent directories will also be created. This can be handy
    to create the archive_path the very first time an application is executed. The
    exists_ok=True will avoid raising an exception if the archive directory already
    exists.
  prefs: []
  type: TYPE_NORMAL
- en: For some applications it can be appropriate to use the tempfile module to create
    temporary files. This module can create filenames that are guaranteed to be unique.
    This allows a complex server process to create temporary files without regard
    to filename conflicts.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the [Using pathlib to work with filenames](ch015_split_000.xhtml#x1-6160001)
    recipe, earlier in this chapter, we looked at the fundamentals of the Path class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Chapter [15](ch019_split_000.xhtml#x1-79400015), we’ll look at some techniques
    for writing unit tests that can ensure that parts of this recipe’s example code
    will behave properly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Chapter [6](ch010.xhtml#x1-3300006), the [Creating contexts and context managers](ch011_split_001.xhtml#x1-43700011)
    recipe shows additional details regarding working with the with statement to ensure
    file operations complete properly, and that all of the OS resources are released.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The shutil module provides a number of methods for copying files and directories
    full of files. This package reflects features of Linux shell programs like cp,
    as well as Windows programs like copy and xcopy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 11.3 Reading delimited files with the CSV module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One commonly used data format is comma-separated values (CSV). We can generalize
    this to think of the comma character as simply one of many candidate separator
    characters. For example, a CSV file can use the | character as the separator between
    columns of data. This generalization for separators other than the literal , makes
    CSV files particularly powerful.
  prefs: []
  type: TYPE_NORMAL
- en: How can we process data in one of the wide varieties of CSV formats?
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A summary of a file’s content is called a schema. It’s essential to distinguish
    between two aspects of a schema.
  prefs: []
  type: TYPE_NORMAL
- en: The physical format of a CSV file’s bytes encode lines of text. For CSV files,
    the text is organized into rows and columns using a row separator character (or
    characters) and a column separator character. Many spreadsheet products will use
    , (comma) as the column separator and the \r\n sequence of characters as the row
    separator. The specific combination of punctuation characters in use is called
    the CSV dialect.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, column data can be quoted when it contains one of the separators.
    The most common quoting rules are to surround the column value with " characters.
    In order to include the quote character in column data, the quote character is
    doubled. For example, "He said, ""Thanks.""".
  prefs: []
  type: TYPE_NORMAL
- en: 'The logical layout of the data in the file is a sequence of data columns that
    are present. There are several common cases for handling the logical layout in
    CSV files:'
  prefs: []
  type: TYPE_NORMAL
- en: The file may have one line of headings. This fits nicely with the way the csv
    module works. It can be even more helpful when the headings are also proper Python
    variable names. The schema is stated explicitly in the first line of the file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The file has no headings, but the column positions are fixed. In this case,
    we can impose headings on the file when we open it. Pragmatically, this involves
    some risk because it’s difficult to confirm that the data meets the imposed schema.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the file has no headings and the column positions aren’t fixed. In this case,
    additional external schema information is required to interpret the columns of
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are, of course, some common complications that can arise with any data.
    Some files are not in First Normal Form (1NF). In 1NF, each row is independent
    of all other rows. When a file is not in this normal form, we’ll need to add a
    generator function to rearrange the data into 1NF rows. See the [Slicing and dicing
    a list](ch008_split_000.xhtml#x1-2400003) recipe in Chapter [4](ch008_split_000.xhtml#x1-2240004),
    and the [Using stacked generator expressions](ch013_split_000.xhtml#x1-5180003)
    recipe in Chapter [9](ch013_split_000.xhtml#x1-5020009), for other recipes that
    show how to normalize data structures.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll look at a CSV file that has some real-time data recorded from the log
    of a sailboat. This is the waypoints.csv file. The data looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This data contains four columns named in the first line of the file: lat, lon,
    date, and time. These describe a waypoint and need to be reformatted to create
    more useful information.'
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before starting to write any code, examine the data file to confirm the following
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: The column separator character is ’,’, which is the default.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The row separator characters are ’\r\n’, also widely used in both Windows and
    Linux.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a single-row heading. If this isn’t present, the headings should be
    provided separately when the reader object is created.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once the format has been confirmed, we can start creating the needed functions
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the csv module and the Path class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a raw() function to read raw data from a Path object that refers to
    the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the Path object to open the file in a with statement. Build the reader
    from the open file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Consume (and process) the rows of data from the iterable reader. This is properly
    indented inside the with statement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output from the raw() function is a series of dictionaries that look as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We can now process the data by referring to the columns as dictionary items,
    using syntax like, for example, row[’date’]. Using the column names is more descriptive
    than referring to the column by position; for example, row[0] is hard to understand.
  prefs: []
  type: TYPE_NORMAL
- en: To be sure that we’re using the column names correctly, the typing.TypedDict
    type hint can be used to provide the expected column names.
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The csv module handles the work of parsing the physical format. This separates
    the rows from each other, and also separates the columns within each row. The
    default rules ensure that each input line is treated as a separate row and that
    the columns are separated by ’,’.
  prefs: []
  type: TYPE_NORMAL
- en: 'What happens when we need to use the column separator character as part of
    data? We might have data like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The notes column has data in the first row, which includes the ’,’ column separator
    character. The rules for CSV allow a column’s value to be surrounded by quotes.
    By default, the quoting characters are ". Within these quoting characters, the
    column and row separator characters are ignored.
  prefs: []
  type: TYPE_NORMAL
- en: In order to embed the quote character within a quoted string, the character
    is doubled. The second example row shows how the value blowing "like stink" is
    encoded by doubling the quote characters when they are part of the value of a
    column.
  prefs: []
  type: TYPE_NORMAL
- en: The values in a CSV file are always strings. A string value like 7331 may look
    like a number to us, but it’s always text when processed by the csv module. This
    makes the processing simple and uniform, but it can be awkward for our Python
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: When data is saved from a manually prepared spreadsheet, the data may reveal
    the quirks of the desktop software’s internal rules for data display. Data that
    is displayed as a date on the desktop software is stored as a floating-point number
    in the CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: There are two solutions to the date-as-number problem. One is to add a column
    in the source spreadsheet to properly format the date data as a string. Ideally,
    this is done using ISO rules so that the date is represented in the YYYY-MM-DD
    format. The other solution is to recognize the spreadsheet date as a number of
    seconds past some epochal date. The epochal dates vary slightly with versions
    of various tools, but they’re generally Jan 1, 1900\. (A few spreadsheet applications
    used Jan 1, 1904.)
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we saw in the [Combining the map and reduce transformations](ch013_split_001.xhtml#x1-5440006)
    recipe in Chapter [9](ch013_split_000.xhtml#x1-5020009), there’s often a pipeline
    of processing that includes cleaning and transforming the source data. This idea
    of stacked generator functions lets a Python program process large volumes of
    data. Reading one row at a time can avoid reading all the data into a vast, in-memory
    list. In this specific example, there are no extra rows that need to be eliminated.
    However, each column needs to be converted into something more useful.
  prefs: []
  type: TYPE_NORMAL
- en: In Chapter [10](ch014.xhtml#x1-57300010), a number of recipes use Pydantic to
    perform these kinds of data conversions. See the [Implementing more strict type
    checks with Pydantic](ch014.xhtml#x1-6000005) recipe for an example of this alternative
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: To transform the data into a more useful form, we’ll define a row-level cleansing
    function. A function can apply this cleansing function to each row of the source
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we’ll create a dictionary object and insert additional values
    that are derived from the input data. The core type hints for this Waypoint dictionary
    are these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on this definition of a Waypoint type, a clean_row() function can look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The clean_row() function creates several new column values from the raw string
    data. The column named lat_lon has a two-tuple with proper floating-point values
    instead of strings. We’ve also parsed the date and time values to create datetime.date
    and datetime.time objects, respectively. We’ve combined the date and time into
    a single, useful value, which is the value of the timestamp column.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have a row-level function for cleaning and enriching our data, we can
    map this function to each row in the source data. We can use map(clean_row, reader)
    or we can write a function that embodies this processing loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This can be used to provide more useful data from each row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'These cleansed and enriched rows look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The new columns such as lat_lon have proper numeric values instead of strings.
    The timestamp value has a full date-time value that can be used for simple computations
    of elapsed time between waypoints.
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: See the [Combining the map and reduce transformations](ch013_split_001.xhtml#x1-5440006)
    recipe in Chapter [9](ch013_split_000.xhtml#x1-5020009) for more information on
    the idea of a processing pipeline or stack.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See the [Slicing and dicing a list](ch008_split_000.xhtml#x1-2400003) recipe
    in Chapter [4](ch008_split_000.xhtml#x1-2240004), and the [Using stacked generator
    expressions](ch013_split_000.xhtml#x1-5180003) recipe in Chapter [9](ch013_split_000.xhtml#x1-5020009),
    for more information on processing a CSV file that isn’t in a proper 1NF.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information on the with statement, see the [Creating contexts and context
    managers](ch011_split_001.xhtml#x1-43700011) recipe in Chapter [7](ch011_split_000.xhtml#x1-3760007).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Chapter [10](ch014.xhtml#x1-57300010), a number of recipes use Pydantic to
    perform these kinds of data conversions. See the [Implementing more strict type
    checks with Pydantic](ch014.xhtml#x1-6000005) recipe for an example of this alternative
    approach.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See [https://www.packtpub.com/product/learning-pandas-second-edition/9781787123137](https://www.packtpub.com/product/learning-pandas-second-edition/9781787123137)
    Learning pandas for an approach to CSV files using the pandas framework.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 11.4 Using dataclasses to simplify working with CSV files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One commonly used data format is known as Comma-Separated Values (CSV). Python’s
    csv module has a very handy DictReader class definition. When a file contains
    a one-row header, the header row’s values become keys that are used for all the
    subsequent rows. This allows a great deal of flexibility in the logical layout
    of the data. For example, the column ordering doesn’t matter, since each column’s
    data is identified by a name taken from the header row.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a dictionary forces us to write, for example, row[’lat’] or row[’date’]
    to refer to data in specific columns. The built-in dict class has no provision
    for derived data. If we switch to a dataclass, we have a number of benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Nicer attribute syntax like row.lat or row.date.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Derived values can be lazy properties.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A frozen dataclass is immutable, and the objects can be keys to dictionaries
    and members of sets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we improve data access and processing using dataclasses?
  prefs: []
  type: TYPE_NORMAL
- en: 11.4.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll look at a CSV file that has some real-time data recorded from the log
    of a sailboat. This file is the waypoints.csv file. For more information, see
    the [Reading delimited files with the CSV module](ch015_split_000.xhtml#x1-6320003)
    recipe in this chapter. The data looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The first line contains a header that names the four columns, lat, lon, date,
    and time. The data can be read by a csv.DictReader object. We’d like to do more
    sophisticated work, so we’ll create a @dataclass class definition encapsulating
    the data and the processing we need to do.
  prefs: []
  type: TYPE_NORMAL
- en: 11.4.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We need to start with a dataclass that reflects the available data, and then
    we can use this dataclass with a dictionary reader:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the definitions from the various libraries that are needed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a dataclass narrowly focused on the input, precisely as it appears in
    the source file. We’ve called the class RawRow. In a complex application, a more
    descriptive name than RawRow would be appropriate. This definition of the attributes
    may change as the source file organization changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As a practical matter, enterprise file formats are likely to change whenever
    new software versions are introduced. It’s often helpful to formalize file schema
    as class definitions to facilitate unit testing and problem resolution when changes
    occur.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define a second dataclass where objects are built from the source dataclass
    attributes. This second class is focused on the real work of the application.
    The source data is in a single attribute, raw, in this example. Fields computed
    from this source data are all initialized with field(init=False) because they’ll
    be computed after initialization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the __post_init__() method to eagerly initialize all the derived fields:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Given these two dataclass definitions, we can create an iterator that will
    accept individual dictionaries from a csv.DictReader object and create the needed
    Waypoint objects. The intermediate representation, RawRow, is a convenience so
    that we can assign attribute names to the source data columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The waypoint_iter() function creates RawRow objects from the input dictionary,
    and then creates the final Waypoint objects from the RawRow instances. This two-step
    process is helpful for isolating code changes to the source or the processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the following function to read and display the CSV data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 11.4.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The source dataclass, the RawRow class in this example, is designed to match
    the input document. The field names and types match the CSV input types. Because
    the names match, the RawRow(**row) expression will create an instance of the RawRow
    class from the DictReader dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: From this initial, or raw, data, we can derive the more useful data, as shown
    in the Waypoint class definition. The __post_init__() method transforms the initial
    value in the self.raw attribute into a number of more useful attribute values.
  prefs: []
  type: TYPE_NORMAL
- en: 'This separation lets us manage the following two kinds of common changes to
    application software:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The source data can change because the spreadsheet was adjusted manually. This
    is common: a person may change column names or change the order of the columns.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The required computations may change as the application’s focus expands or shifts.
    More derived columns may be added, or the algorithms may change.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It’s helpful to disentangle the various aspects of a program so that we can
    let them evolve independently. Gathering, cleaning, and filtering source data
    is one aspect of this separation of concerns. The resulting computations are a
    separate aspect, unrelated to the format of the source data.
  prefs: []
  type: TYPE_NORMAL
- en: 11.4.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many cases, the source CSV file will have headers that do not map directly
    to valid Python attribute names. In these cases, the keys present in the source
    dictionary must be mapped to the column names. This can be managed by expanding
    the RawRow class definition to include a @classmethod that builds the RawRow dataclass
    object from the source dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example defines a class called RawRow_HeaderV2\. This definition
    reflects a variant spreadsheet with different column names in the header:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The instances of the RawRow_HeaderV2 class are built using the expression RawRow_HeaderV2.from_csv(row).
    The objects are compatible with the RawRow class. Either of these classes of objects
    can also be transformed into Waypoint instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'For an application that works with a variety of data sources, these kinds of
    ”raw data transformation” dataclasses can be handy for mapping the minor variations
    in a logical layout to a consistent internal structure for further processing.
    As the number of input transformation classes grows, additional type hints are
    required. For example, the following type hint provides a common name for the
    variations in input format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This type hint helps to unify the original RawRow and the alternative RawRow_HeaderV2
    types, which are alternative definitions with compatible features. The most important
    feature is the use of generators to process rows individually and avoid creating
    large list objects with all of the data.
  prefs: []
  type: TYPE_NORMAL
- en: 11.4.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [Reading delimited files with the CSV module](ch015_split_000.xhtml#x1-6320003)
    recipe, earlier in this chapter, also covers CSV file reading.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Chapter [6](ch010.xhtml#x1-3300006), the [Using dataclasses for mutable objects](ch011_split_000.xhtml#x1-4010005)
    recipe also covers ways to use Python’s dataclasses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 11.5 Reading complex formats using regular expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many file formats lack the elegant regularity of a CSV file. One common file
    format that’s rather difficult to parse is a web server log file. These files
    tend to have complex data without a single, uniform separator character or consistent
    quoting rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we looked at a simplified log file in the [Writing generator functions
    with the yield statement](ch013_split_000.xhtml#x1-5030001) recipe in Chapter [9](ch013_split_000.xhtml#x1-5020009),
    we saw that the rows look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: There are a variety of punctuation marks being used in this file. The csv module
    can’t parse this complexity.
  prefs: []
  type: TYPE_NORMAL
- en: We’d like to write programs with the elegant simplicity of CSV processing. This
    means we’ll need to encapsulate the complexities of log file parsing and keep
    this aspect separate from analysis and summary processing.
  prefs: []
  type: TYPE_NORMAL
- en: 11.5.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Parsing a file with a complex structure generally involves writing a function
    that behaves somewhat like the reader() function in the csv module. In some cases,
    it can be easier to create a small class that behaves like the DictReader class.
  prefs: []
  type: TYPE_NORMAL
- en: The core feature of reading a complex file is a function that will transform
    one line of text into a dictionary or tuple of individual field values. Parts
    of this job can often be done by the re package.
  prefs: []
  type: TYPE_NORMAL
- en: Before we can start, we’ll need to develop (and debug) the regular expression
    that properly parses each line of the input file. For more information on this,
    see the [String parsing with regular expressions](ch005_split_000.xhtml#x1-350003)
    recipe in Chapter [1](ch005_split_000.xhtml#x1-170001).
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we’ll use the following code. We’ll define a pattern string
    with a series of regular expressions for the various elements of the line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: We’ve used the re.X option so that we can include extra whitespace in the regular
    expression. This can help to make it more readable by separating prefix and suffix
    characters.
  prefs: []
  type: TYPE_NORMAL
- en: When we write a regular expression, we wrap the interesting sub-strings to capture
    in (). After performing a match() or search() operation, the resulting Match object
    will have the captured text for the matched substrings. The groups() method of
    a Match object and the groupdict() method of a Match object will provide the captured
    strings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how this pattern works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: We’ve provided a line of sample data in the sample_data variable. The resulting
    Match object has a groups() method that returns each of the interesting fields.
    The value of the groupdict() method of a match object is a dictionary, with the
    name provided in the ?P<name> preface to the regular expression in brackets, ().
  prefs: []
  type: TYPE_NORMAL
- en: 11.5.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe is split into two mini-recipes. The first part defines a log_parser()
    function to parse a single line, while the second part applies the log_parser()
    function for each line of input.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the parse function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Perform the following steps to define the log_parser() function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the compiled regular expression object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a class to model the resulting complex data object. This can have additional
    derived properties or other complex computations. Minimally, a NamedTuple must
    define the fields that are extracted by the parser. The field names should match
    the regular expression capture name in the (?P<name>...) prefix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that accepts a line of text as an argument and produces a
    parsed LogLine instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the regular expression to create a match object. We’ve assigned it to
    the match variable and also checked to see it is not None:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When the value of match is not None, return a useful data structure with the
    various pieces of data from this input line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When the match is None, either log the problem or raise an exception to stop
    processing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Using the log_parser() function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This portion of the recipe will apply the log_parser() function to each line
    of the input file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the pathlib module, import useful class and function definitions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Path object that identifies the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the Path object to open the file in a with statement. Create the log file
    reader from the open file object, data_file. In this case, we’ll use the built-in
    map() function to apply the log_parser() function to each line from the source
    file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Read (and process) the various rows of data. For this example, we’ll print
    each row:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is a series of LogLine tuples that looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: We can do more meaningful processing on these tuple instances than we can on
    a line of raw text. These allow us to filter the data by severity level, or create
    a counter based on the module providing the message.
  prefs: []
  type: TYPE_NORMAL
- en: 11.5.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This log file is in First Normal Form (1NF): the data is organized into lines
    that represent independent entities or events. Each row has a consistent number
    of attributes or columns, and each column has data that is atomic or can’t be
    meaningfully decomposed further. Unlike CSV files, however, this particular format
    requires a complex regular expression to parse.'
  prefs: []
  type: TYPE_NORMAL
- en: In our log file example, the timestamp contains a number of individual elements
    – year, month, day, hour, minute, second, and millisecond – but there’s little
    value in further decomposing the timestamp. It’s more helpful to use it as a single
    datetime object and derive details (like the hour of the day) from this object,
    rather than assembling individual fields into a new piece of composite data.
  prefs: []
  type: TYPE_NORMAL
- en: In a complex log processing application, there may be several varieties of message
    fields. It may be necessary to parse these message types using separate patterns.
    When we need to do this, it reveals that the various lines in the log aren’t consistent
    in terms of the format and number of attributes, breaking one of the 1NF assumptions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve generally followed the design pattern from the [Reading delimited files
    with the CSV module](ch015_split_000.xhtml#x1-6320003) recipe, so that reading
    a complex log is nearly identical to reading a simple CSV file. Indeed, we can
    see that the primary difference lies in one line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[firstline=93,lastline=93,gobble=8][python]src/ch11/recipe˙05.py'
  prefs: []
  type: TYPE_NORMAL
- en: 'Compare that to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[firstline=95,lastline=95,gobble=8][python]src/ch11/recipe˙05.py'
  prefs: []
  type: TYPE_NORMAL
- en: This parallel construct allows us to reuse analysis functions across many input
    file formats. This allows us to create a library of tools that can be used on
    a number of data sources. It can help to make analytic applications resilient
    when data sources change.
  prefs: []
  type: TYPE_NORMAL
- en: 11.5.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most common operations when reading very complex files is to rewrite
    them into an easier-to-process format. We’ll often want to save data in the CSV
    format for later processing.
  prefs: []
  type: TYPE_NORMAL
- en: Some of this is similar to the [Managing multiple contexts with multiple resources](ch011_split_001.xhtml#x1-44300012)
    recipe in Chapter [7](ch011_split_000.xhtml#x1-3760007). This recipe shows multiple
    open file-processing contexts. We’ll read from one file and write to another file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The file writing process looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: The first portion of this script defines a CSV writer for the target file. The
    path for the output file, target_path, is based on the input name, data_path.
    The suffix is changed to .csv.
  prefs: []
  type: TYPE_NORMAL
- en: The target file is opened with the newline character turned off by the newline=’’
    option. This allows the csv.DictWriter class to insert newline characters appropriate
    for the desired CSV dialect.
  prefs: []
  type: TYPE_NORMAL
- en: A DictWriter object is created to write to the given file. The sequence of column
    headings is provided by the LogLines class definition. This makes sure the output
    CSV file will contain correct, consistent column names.
  prefs: []
  type: TYPE_NORMAL
- en: The writeheader() method writes the column names as the first line of output.
    This makes reading the file slightly easier because the column names are provided.
    The first row of a CSV file can contain an explicit schema definition that shows
    what data is present.
  prefs: []
  type: TYPE_NORMAL
- en: The source file is opened, as shown in the preceding recipe. Because of the
    way the csv module writers work, we can provide the reader generator expression
    to the writerows() method of the writer. The writerows() method will consume all
    of the data produced by the reader generator. This will, in turn, consume all
    the rows produced by the open file.
  prefs: []
  type: TYPE_NORMAL
- en: We don’t need to write any explicit for statements to ensure that all of the
    input rows are processed. The writerows() function makes this guarantee for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output file looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The file has been transformed from the rather complex input format into a simpler
    CSV format, suitable for further analysis and processing.
  prefs: []
  type: TYPE_NORMAL
- en: 11.5.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For more information on the with statement, see the [Creating contexts and context
    managers](ch011_split_001.xhtml#x1-43700011) recipe in Chapter [7](ch011_split_000.xhtml#x1-3760007).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [Writing generator functions with the yield statement](ch013_split_000.xhtml#x1-5030001)
    recipe in Chapter [9](ch013_split_000.xhtml#x1-5020009) shows other processing
    of this log format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the [Reading delimited files with the CSV module](ch015_split_000.xhtml#x1-6320003)
    recipe, earlier in this chapter, we looked at other applications of this general
    design pattern.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the [Using dataclasses to simplify working with CSV files](ch015_split_000.xhtml#x1-6380004)
    recipe, earlier in this chapter, we looked at other sophisticated CSV processing
    techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 11.6 Reading JSON and YAML documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: JavaScript Object Notation (JSON) is often used for serializing data. For details,
    see [http://json.org](http://json.org). Python includes the json module in order
    to serialize and deserialize data in this notation.
  prefs: []
  type: TYPE_NORMAL
- en: JSON documents are used widely by web applications. It’s common to exchange
    data between RESTful web clients and servers using documents in JSON notation.
    These two tiers of an application stack communicate via JSON documents sent via
    the HTTP protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'The YAML format is a more sophisticated and flexible extension to JSON notation.
    For details, see [https://yaml.org](https://yaml.org). Any JSON document is also
    a valid YAML document. The reverse is not true: YAML syntax is more complex and
    includes constructs that are not valid JSON.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To use YAML, an additional module has to be installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: The PyYAML project offers a yaml module that is popular and works well. See
    [https://pypi.org/project/PyYAML/](https://pypi.org/project/PyYAML/).
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we’ll use the json module to parse JSON format data in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 11.6.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve gathered some sailboat racing results in race_result.json. This file contains
    information on the teams, the legs of the race, and the order in which the various
    teams finished each individual leg of the race. JSON handles this complex data
    elegantly.
  prefs: []
  type: TYPE_NORMAL
- en: 'An overall score can be computed by summing the finish position in each leg:
    the lowest score is the overall winner. In some cases, there are null values when
    a boat did not start, did not finish, or was disqualified from the race.'
  prefs: []
  type: TYPE_NORMAL
- en: When computing the team’s overall score, the null values are assigned a score
    of one more than the number of boats in the competition. If there are seven boats,
    then the team is given eight points for their failure to finish, a hefty penalty.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data has the following schema. There are two fields within the overall
    document:'
  prefs: []
  type: TYPE_NORMAL
- en: 'legs: An array of strings that shows the starting port and ending port.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'teams: An array of objects with details about each team. Within each teams
    object, there are several fields of data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'name: String team name.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'position: An array of integers and nulls with a position. The order of the
    items in this array matches the order of the items in the legs array.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The data looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: We’ve only shown the first team’s details. There were a total of seven teams
    in this particular race. Each team is represented by a Python dictionary, with
    the team’s name and their history of finish positions on each leg. For the team
    shown here, Abu Dhabi Ocean Racing, they finished in first place in the first
    leg, and then third place in the next leg. Their worst performance was fifth place
    in both the seventh and ninth legs of the race, which were the legs from Newport,
    Rhode Island, USA, to Lisbon, Portugal, and from Lorient, France, to Gothenburg,
    Sweden.
  prefs: []
  type: TYPE_NORMAL
- en: 'The JSON-formatted data can look like a Python dictionary that contains lists
    within it. This overlap between Python syntax and JSON syntax can be thought of
    as a happy coincidence: it makes it easier to visualize the Python data structure
    that will be built from the JSON source document.'
  prefs: []
  type: TYPE_NORMAL
- en: 'JSON has a small set of data structures: null, Boolean, number, string, list,
    and object. These map to objects of Python types in a very direct way. The json
    module makes the conversions from source text into Python objects for us.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the strings contains a Unicode escape sequence, \u00cd, instead of the
    actual Unicode character Í. This is a common technique used to encode characters
    beyond the 128 ASCII characters. The parser in the json module handles this for
    us.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we’ll write a function to disentangle this document and show
    the team finishes for each leg.
  prefs: []
  type: TYPE_NORMAL
- en: 11.6.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This recipe will start by importing the necessary modules. We’ll then use these
    modules to transform the contents of the file into a useful Python object:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll need the json module to parse the text. We’ll also need a Path object
    to refer to the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a race\_summary() function to read the JSON document from a given Path
    instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a Python object by parsing the JSON document. It’s often easiest to
    use source_path.read_text() to read the file named by the Path object. We provided
    this string to the json.loads() function for parsing. For very large files, an
    open file can be passed to the json.load() function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Display the data: The document object contains a dictionary with two keys,
    teams and legs. Here’s how we can iterate through each leg, showing the team’s
    position in the leg:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The data for each team will be a dictionary with two keys: name and position.
    We can navigate down into the team details to get the name of the first team:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'We can look inside the legs field to see the names of each leg of the race:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 11.6.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A JSON document is a data structure in JavaScript Object Notation. JavaScript
    programs can parse the document trivially. Other languages must do a little more
    work to translate the JSON to a native data structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'A JSON document contains three kinds of structures:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Objects that map to Python dictionaries: JSON has a syntax similar to Python:
    {"key": "value", ...}.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Arrays that map to Python lists: JSON syntax uses [item, ...], which is also
    similar to Python.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Primitive values: There are five classes of values: string, number, true, false,
    and null. Strings are enclosed in " and use a variety of \ escape sequences, which
    are similar to Python’s. Numbers follow the rules for floating-point values. The
    other three values are simple literals; these parallel Python’s True, False, and
    None literals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a special case, numbers with no decimal point become Python int objects.
    This is an extension of the JSON standard.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: There is no provision for any other kinds of data. This means that Python programs
    must convert complex Python objects into a simpler representation so that they
    can be serialized in JSON notation.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, we often apply additional conversions to reconstruct complex Python
    objects from the simplified JSON representation. The json module has places where
    we can apply additional processing to the simple structures to create more sophisticated
    Python objects.
  prefs: []
  type: TYPE_NORMAL
- en: 11.6.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A file, generally, contains a single JSON document. The JSON standard doesn’t
    provide an easy way to encode multiple documents in a single file. If we want
    to analyze a web log, for example, the original JSON standard may not be the best
    notation for preserving a huge volume of information.
  prefs: []
  type: TYPE_NORMAL
- en: There are common extensions, like Newline Delimited JSON ( [http://ndjson.org](http://ndjson.org))
    and JSON Lines, [http://jsonlines.org](http://jsonlines.org), to define a way
    to encode multiple JSON documents into a single file.
  prefs: []
  type: TYPE_NORMAL
- en: 'While these approaches handle collections of documents, there is an additional
    problem that we often have to tackle: serializaing (and deserializing) complex
    objects, for example, datetime objects.'
  prefs: []
  type: TYPE_NORMAL
- en: When we represent a Python object’s state as a string of text characters, we’ve
    serialized the object’s state. Many Python objects need to be saved in a file
    or transmitted to another process. These kinds of transfers require a representation
    of the object state. We’ll look at serializing and deserializing separately.
  prefs: []
  type: TYPE_NORMAL
- en: Serializing a complex data structure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The serialization to JSON works out the best if we create Python objects limited
    to values of the built-in types dict, list, str, int, float, bool, and the special
    type for None. This subset of Python types can be used to build objects the json
    module can serialize and can be used widely by a number of programs, written in
    different languages.
  prefs: []
  type: TYPE_NORMAL
- en: One commonly used data structure that doesn’t serialize easily is the datetime.datetime
    object.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding the TypeError exception exceptions when trying to serialize an unusual
    Python object can be done in one of two ways. We can either convert the data into
    a JSON-friendly structure before building the document, or we can add a default
    type handler to the JSON serialization process that gives us a way to provide
    a serializable version of the data.
  prefs: []
  type: TYPE_NORMAL
- en: To convert a datetime object into a string prior to serializing it as JSON,
    we need to make a change to the underlying data. It seems awkward to mangle the
    data or Python’s data types because of a serialization concern.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other technique for serializing complex data is to provide a function that’s
    used by the json module during serialization. This function must convert a complex
    object into something that can be safely serialized. In the following example,
    we’ll convert a datetime object into a simple string value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: We’ve defined a function, default_date(), which will apply a special conversion
    rule to datetime objects. Any datetime.datetime instance will be replaced with
    a dictionary with an obvious key – "$date$" – and a string value. This dictionary
    can then be serialized by the json module.
  prefs: []
  type: TYPE_NORMAL
- en: 'We provide this serialization helper function to the json.dumps() function.
    This is done by assigning the default_date() function to the default parameter,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: When the json module can’t serialize an object, it passes the object to the
    given default function, default_date(). In any given application, we’ll need to
    expand this function to handle a number of Python object types that we might want
    to serialize in JSON notation. If there is no default function provided, an exception
    is raised when an object can’t be serialized.
  prefs: []
  type: TYPE_NORMAL
- en: Deserializing a complex data structure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When deserializing JSON to create Python objects, there’s a hook that can be
    used to convert data from a JSON dictionary into a more complex Python object.
    This is called object_hook and it is used during processing by the json.loads()
    function. This hook is used to examine each JSON dictionary to see if something
    else should be created from the dictionary instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function we provide will either create a more complex Python object, or
    it will simply return the original dictionary object unmodified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'This function will check each object that’s decoded to see if the object has
    a single field, and if that single field is named "$date$". If that is the case,
    the value of the entire object is replaced with a datetime.datetime object. The
    return type is a union of Any and dict[str, Any] to reflect the two possible results:
    either some object or the original dictionary.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We provide a function to the json.loads() function using the object_hook parameter,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: This parses a very small JSON document. All objects are provided to the as_date()
    object hook. Of these objects, one dictionary meets the criteria for containing
    a date. A Python object is built from the string value found in the JSON serialization.
  prefs: []
  type: TYPE_NORMAL
- en: The Pydantic package offers a number of serialization features. Recipes are
    shown in Chapter [10](ch014.xhtml#x1-57300010) for working with this package.
  prefs: []
  type: TYPE_NORMAL
- en: 11.6.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [Reading HTML documents](ch015_split_001.xhtml#x1-6660008) recipe, later
    in this chapter, will show how we prepared this data from an HTML source.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [Implementing more strict type checks with Pydantic](ch014.xhtml#x1-6000005)
    recipe in Chapter [10](ch014.xhtml#x1-57300010) covers some features of the Pydantic
    package.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 11.7 Reading XML documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The XML markup language is widely used to represent the state of objects in
    a serialized form. For details, see [http://www.w3.org/TR/REC-xml/](http://www.w3.org/TR/REC-xml/).
    Python includes a number of libraries for parsing XML documents.
  prefs: []
  type: TYPE_NORMAL
- en: XML is called a markup language because the content of interest is marked with
    tags, written with a start <tag> and an end </tag>, used to define the structure
    of the data. The overall file text includes both the content and the XML markup.
  prefs: []
  type: TYPE_NORMAL
- en: Because the markup is intermingled with the text, there are some additional
    syntax rules that must be used to distinguish markup from text. A document must
    use &lt; instead of <, &gt; instead of >, and &amp; instead of & in text. Additionally,
    &quot; is also used to embed a " character in an attribute value. For the most
    part, XML parsers will handle this transformation when consuming XML.
  prefs: []
  type: TYPE_NORMAL
- en: 'The example document, then, will have items as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: The <team> tag contains the <name> tag, which contains the text of the team’s
    name. The <position> tag contains more data about the team’s finish position in
    each leg of a race.
  prefs: []
  type: TYPE_NORMAL
- en: The overall document forms a large, nested collection of containers. We can
    think of a document as a tree with a root tag that contains all the other tags
    and their embedded content. Between tags, there can be additional content. In
    some applications, the additional content between the ends of tags is entirely
    whitespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the beginning of the document we’ll be looking at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: The top-level container is the <results> tag. Within this is a <teams> tag.
    Within the <teams> tag are many repetitions of data for each individual team,
    each enclosed in the <team> tag. We’ve used ... to show where parts of the document
    were elided.
  prefs: []
  type: TYPE_NORMAL
- en: It’s very, very difficult to parse XML with regular expressions. Regular expressions
    don’t cope well with the kinds of recursion and repetition present in XML. We
    need more sophisticated parsers to handle the syntax of nested tags.
  prefs: []
  type: TYPE_NORMAL
- en: There are two binary libraries, part of the modules xml.sax and xml.parsers.expat,
    to parse XML. These have the advantage of being very fast.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to these, there’s a very sophisticated set of tools in the xml.etree
    package. We’ll focus on using the ElementTree class in this package to parse and
    analyze XML documents. This has the advantage of offering a large number of useful
    features like XPath searching to find tags in a complicated document.
  prefs: []
  type: TYPE_NORMAL
- en: 11.7.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve gathered some sailboat racing results in race_result.xml. This file contains
    information on teams, legs, and the order in which the various teams finished
    each leg. For more information on this data, see the [Reading JSON and YAML documents](ch015_split_001.xhtml#x1-6520006)
    recipe in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The root tag for this data is a <results> document. This has the following
    schema:'
  prefs: []
  type: TYPE_NORMAL
- en: The <legs> tag contains individual <leg> tags that name each leg of the race.
    Each <leg> tag will contain both a starting port and an ending port in the text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The <teams> tag contains a number of <team> tags with details of each team.
    Each team has data structured with internal tags:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The <name> tag contains the team name.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The <position> tag contains a number of <leg> tags with the finish position
    for the given leg. Each leg is numbered, and the numbering matches the leg definitions
    in the <legs> tag.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In XML notation, the application data shows up in two kinds of places. The first
    is between the start and the end tags – for example, <name>Abu Dhabi Ocean Racing</name>,
    has text, ”Abu Dhabi Ocean Racing”, as well as <name> and </name> tags.
  prefs: []
  type: TYPE_NORMAL
- en: Also, data will also show up as an attribute of a tag; for example, in <leg n="1">.
    The tag is <leg>, with an attribute, n, with a value of "1". A tag can have an
    indefinite number of attributes.
  prefs: []
  type: TYPE_NORMAL
- en: The <leg> tags point out an interesting problem with XML. These tags include
    the leg number given as an attribute, while the position for the leg is given
    as the text inside the tag. There’s no real pattern or preference to where useful
    data is located. Ideally, it’s always between tags, but that’s not generally true.
  prefs: []
  type: TYPE_NORMAL
- en: 'XML permits a mixed content model. This reflects the case where XML is mixed
    in with text and there is text inside and outside XML tags. Here’s an example
    of mixed content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: The content of the <p> tag is a mixture of text and a tag. The data we’re working
    with in this recipe does not rely on this kind of mixed content model, meaning
    all the data is within a single tag or an attribute of a tag. The whitespace between
    tags can be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 11.7.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll define a function to convert the XML document to a dictionary with leg
    descriptions and team results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll need the xml.etree module to parse the XML text. We’ll also need a Path
    object to refer to the file. We’ve assigned a shorter name of XML to the ElementTree
    class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The cast() function is needed to force tools like mypy to treat the result as
    if it were a given type. This lets us ignore the possibility of None results.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define a function to read the XML document from a given Path instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a Python ElementTree object by parsing the XML text. It’s often easiest
    to use source_path.read_text() to read the file named by path. We provided this
    string to the XML.fromstring() method for parsing. For very large files, an incremental
    parser is sometimes more helpful. Here’s the version for smaller files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Display the data. The XML element objects has two useful methods for navigating
    the XML structure, the find() and findall() methods, to locate the first instance
    of a tag and locate all instances of a tag, respectively. Using these, we can
    create a dictionary with two keys, "teams" and "legs":'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Within the <legs> tag, there are a number of individual <leg> tags. Each of
    those tags has the following structure:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The Python expression leg.attrib[’n’] extracts the value of the attribute named
    n from the given element. The expression leg.text.strip() will find all the text
    within the <leg> tag, stripped of extra whitespace.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The find() and findall() methods of an element use XPath notation to locate
    tags. We’ll examine the features in detail in the There’s more... section of this
    recipe.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'It’s important to note that the results of the find() function have a type
    hint of XML.Element | None. We have two choices for handling the possibility of
    a None result:'
  prefs: []
  type: TYPE_NORMAL
- en: Use an if statement to handle the cases where the result is None.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cast(XML.Element, tag.find(...)) to claim that the result is never going
    to be None. If the tag is missing, the exception raised will help diagnose the
    mismatch between the source document and processing expectations by our consumer
    application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each leg of the race, we need to print the finish positions, which are contained
    within the <teams> tag. Within this tag, we need to find the proper <leg> tag
    with the finish position for this team on the given leg. For this, we use a complex
    XPath search, f"position/leg[@n=’{n}’]", to locate a specific instance of the
    <position> tag based on the presence of a <leg> tag with a specific attribute
    value. The value of n is the leg number. For the ninth leg, n=9, the f-string
    will be "position/leg[@n=’9’]". This will locate the <position> tag containing
    a <leg> tag that has an attribute n equal to 9.
  prefs: []
  type: TYPE_NORMAL
- en: Because XML supports a mixed content model, all the \n, \t, and space characters
    in the content are perfectly preserved by the parsing operation. We rarely want
    any of this whitespace, and it makes sense to use the strip() method to remove
    any extraneous characters before and after the meaningful content.
  prefs: []
  type: TYPE_NORMAL
- en: 11.7.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The XML parser modules transform XML documents into a fairly complex tree structure
    based on a standardized Document Object Model (DOM). In the case of the xml.etree
    module, the document will be built from Element objects, which generally represent
    tags and text.
  prefs: []
  type: TYPE_NORMAL
- en: XML can also include processing instructions and comments. We’ll ignore them
    and focus on the document structure and content here.
  prefs: []
  type: TYPE_NORMAL
- en: Each Element instance has the text of the tag, the text within the tag, attributes
    that are part of the tag, and a tail. The tag is the name inside <tag>. The attributes
    are the fields that follow the tag name, for example, the <leg n="1"> tag has
    a tag name of leg and an attribute named n. Values are always strings in XML;
    any conversion to a different data type is the responsibility of the application
    using the data.
  prefs: []
  type: TYPE_NORMAL
- en: The text is contained between the start and end of a tag. Therefore, a tag such
    as <name>Team SCA</name> has "Team SCA" for the value of the text attribute of
    the Element that represents the <name> tag.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that a tag also has a tail attribute. Consider this sequence of two tags:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: There’s a \n whitespace character after the closing </name> tag and before the
    opening of the <position> tag. This extra text is collected into the tail attribute
    of the <name> tag. These tail values can be important when working with a mixed
    content model. The tail values are generally whitespace when working in an element
    content model.
  prefs: []
  type: TYPE_NORMAL
- en: 11.7.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because we can’t trivially translate an XML document into a Python dictionary,
    we need a handy way to search through the document’s content. The ElementTree
    class provides a search technique that’s a partial implementation of the XML Path
    Language (XPath) for specifying a location in an XML document. The XPath notation
    gives us considerable flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'The XPath queries are used with the find() and findall() methods. Here’s how
    we can find all of the team names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: The XPath query looks for the top-level <teams> tag. Within that tag, we want
    <team> tags. Within those tags, we want the <name> tags. This will search for
    all the instances of this nested tag structure.
  prefs: []
  type: TYPE_NORMAL
- en: 11.7.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a number of security issues related to XML documents. See the OWASP
    [XML Security Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/XML_Security_Cheat_Sheet.html)
    for more information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [lxml](https://pypi.org/project/lxml/) library extends the core features
    of the element tree library, offering additional capabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [Reading HTML documents](ch015_split_001.xhtml#x1-6660008) recipe, later
    in this chapter, shows how we prepared this data from an HTML source.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 11.8 Reading HTML documents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A great deal of content on the web is presented using HTML. A browser renders
    the data very nicely. We can write applications to extract content from HTML pages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parsing HTML involves two complications:'
  prefs: []
  type: TYPE_NORMAL
- en: Ancient HTML dialects that are distinct from modern XML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Browsers that tolerate HTML that’s incorrect and create a proper display
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first complication is the history of HTML and XML. Modern HTML is a specific
    document type of XML. Historically, HTML started with its own unique document
    type definitions, based on the older SGML. These original SGML/HTML concepts were
    revised and extended to create a new language, XML. During the transition from
    legacy HTML to XML-based HTML, web servers provided content using a variety of
    transitional document type definitions. Most modern web servers use a <DOCTYPE html>
    preamble to state that the document is properly structured XML syntax, using the
    HTML document model. Some web servers will use other DOCTYPE references in the
    preamble and provide HTML that’s not proper XML.
  prefs: []
  type: TYPE_NORMAL
- en: A further complication to parsing HTML is the design of browsers. Browsers are
    obligated to render a web page in spite of poorly structured or even outright
    invalid HTML. The design objective is to provide something to the user that reflects
    the content – not display an error message stating the content is invalid.
  prefs: []
  type: TYPE_NORMAL
- en: HTML pages may be filled with problems and still display a good-looking page
    in a browser.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the standard library html.parser module, but it’s not as helpful
    as we’d like. The Beautiful Soup package provides more helpful ways to parse HTML
    pages into useful data structures. This is available from the Python Package Index
    (PyPI). See [https://pypi.python.org/pypi/beautifulsoup4](https://pypi.python.org/pypi/beautifulsoup4).
  prefs: []
  type: TYPE_NORMAL
- en: 'This must be downloaded and installed with the following terminal command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 11.8.1 Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve gathered some historical sailboat racing results in Volvo Ocean Race.html.
    This file contains information on teams, legs, and the order in which the various
    teams finished each leg. It’s been scraped from the Volvo Ocean Race website,
    and it looks wonderful when opened in a browser. For more information on this
    data, see the [Reading JSON and YAML documents](ch015_split_001.xhtml#x1-6520006)
    recipe in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: While Python’s standard library has the urllib package to acquire documents,
    it’s common to use the Requests package to read web pages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, an HTML page has the following overall structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Within the <head> tag, there will be metadata, links to JavaScript libraries,
    and links to Cascading Style Sheet (CSS) documents. The content is in the <body>
    tag.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the race results are in an HTML <table> tag inside the <body>
    tag. The table has the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The <thead> tag defines the column titles for a table. There’s a single row
    tag, <tr>, with table heading tags, <th>, that include the column titles. For
    the example data, each of the <th> tags look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: The essential display is an identifier for each leg of the race; LEG 1, in this
    example. This is the text content of the <th> tag. There’s also an attribute value,
    data, that’s used by a JavaScript function. This attribute value has the name
    of the leg, and it is displayed when the cursor hovers over a column heading.
  prefs: []
  type: TYPE_NORMAL
- en: 'The <tbody> tag includes rows with the results for each team and race. Each
    <tr> table row tag contains <td> table data tags with the name of a team and its
    results. Here’s a typical <tr> row from the HTML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: The <tr> tag has a class attribute that defines the CSS style for this row.
    This class attribute can help our data-gathering application locate the relevant
    content.
  prefs: []
  type: TYPE_NORMAL
- en: The <td> tags also have class attributes. For this well-designed data, the class
    clarifies what the content of the <td> cell is. Not all CSS class names are as
    well defined as these.
  prefs: []
  type: TYPE_NORMAL
- en: One of the cells – with the tooltipster attribute – has no text content. Instead,
    this cell has an <a> tag and an empty <div> tag. That cell also contains several
    attributes, including data, among others. These attributes are used by a JavaScript
    function to display additional information in the cell.
  prefs: []
  type: TYPE_NORMAL
- en: Another complexity here is that the data attribute contains text that’s actually
    HTML content. Parsing this bit of text will require creating a separate BeautifulSoup
    parser.
  prefs: []
  type: TYPE_NORMAL
- en: 11.8.2 How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll define a function to convert the HTML <table> to a dictionary with leg
    descriptions and team results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the BeautifulSoup class from the bs4 module to parse the text. We’ll
    also need a Path object to refer to the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function to read the HTML document from a given Path instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the soup structure from the HTML content. We’ll assign it to a variable,
    soup. As an alternative, we could also read the content using the Path.read_text()
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'From the soup object, we need to navigate to the first <table> tag. Within
    that, we need to find the first <thead> and <tr> tags. Navigating to the first
    instance of a tag is done by using the tag name as an attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A special comment is used to silence a mypy warning. The # type: ignore [union-attr]
    is needed because each tag property has a type hint of Tag | None. For some applications,
    additional if statements can be used to confirm the expected combinations of tags
    that are present.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We must accumulate heading data from each <th> cell within the row:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To find the table’s content, we navigate down into the <table> and <tbody>
    tags:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need to visit all of the <tr> tags. Within each row, we want to convert
    the content of all <td> tags into team names and a collection of team positions,
    depending on the attributes of the td tag:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the legs and teams have been extracted, we can create a useful dictionary
    that will contain the two collections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We’ve created a list of legs showing the order and names for each leg, and
    we parsed the body of the table to create a dict-of-list structure with each leg’s
    results for a given team. The resulting object looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: Within the body of the table, many cells have None for the final race position
    and a complex value in data attribute for the specific <TD> tag. Parsing the HTML
    embedded in this text follows the pattern shown in the recipe, using another BeautifulSoup
    instance.
  prefs: []
  type: TYPE_NORMAL
- en: 11.8.3 How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The BeautifulSoup class transforms HTML documents into fairly complex objects
    based on a Document Object Model (DOM). The resulting structure will be built
    from instances of the Tag, NavigableString, and Comment classes.
  prefs: []
  type: TYPE_NORMAL
- en: Each Tag object has a name, string, and attributes. The name is the word inside
    < and > characters. The attributes are the fields that follow the tag name. For
    example, <td class="ranking-number">1</td> has a tag name of td and an attribute
    named class. Values are often strings, but in a few cases, the value can be a
    list of strings. The string attribute of the Tag object is the content enclosed
    by the tag; in this case, it’s a very short string, 1.
  prefs: []
  type: TYPE_NORMAL
- en: HTML is a mixed content model. When looking at the children of a given tag,
    there will be a sequence of child Tags and child NavigableText objects freely
    intermixed.
  prefs: []
  type: TYPE_NORMAL
- en: The BeautifulSoup parser class depends on a lower-level library to do some of
    the parsing work. It’s easiest to use the built-in html.parser module for this.
    The alternatives offer some advantages, like better performance or better handling
    of damaged HTML.
  prefs: []
  type: TYPE_NORMAL
- en: 11.8.4 There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Tag objects of Beautiful Soup represent the hierarchy of the document’s
    structure. There are several kinds of navigation among tags. In this recipe, we
    relied on the way soup.html is the same as soup.find("html"). We can also search
    by attribute values, including class and id. These often provide semantic information
    about the content.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, a document will have a well-designed organization, and a search
    by the id attribute or class attribute will find the relevant data. Here’s a typical
    search for a given structure using the HTML class attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: Note that we have to use class_ in our Python query to search for the attribute
    named class. The token class is a reserved word in Python and cannot be used as
    a parameter name. Given the overall document, we’re searching for any <table class="ranking-list">
    tag. This will find the first such table in a web page. Since we know there will
    only be one of these, this attribute-based search helps distinguish between what
    we are trying to find and any other tabular data on a web page.
  prefs: []
  type: TYPE_NORMAL
- en: 11.8.5 See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [Requests](https://pypi.org/project/requests/) package can greatly simplify
    the code required to interact with complex websites.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Se the [https://www.robotstxt.org](https://www.robotstxt.org) website for information
    on the robots.txt file and the [RFC 9309 Robots Exclusion Protocol](https://www.rfc-editor.org/rfc/rfc9309.html#name-informative-references).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [Reading JSON and YAML documents](ch015_split_001.xhtml#x1-6520006) and
    [Reading XML documents](ch015_split_001.xhtml#x1-6600007) recipes, shown earlier
    in this chapter, both use similar data. The example data was created for them
    by scraping the original HTML page using these techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Python Discord workspace to discuss and find out more about the book:
    [https://packt.link/dHrHU](https://packt.link/dHrHU)'
  prefs: []
  type: TYPE_NORMAL
- en: '![PIC](img/file1.png)'
  prefs: []
  type: TYPE_IMG
