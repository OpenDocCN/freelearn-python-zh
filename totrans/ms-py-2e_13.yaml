- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: asyncio – Multithreading without Threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter showed us how to track our application performance. In
    this chapter, we will use asynchronous programming to switch between functions
    whenever we have to wait for **input/output** (**I/O**) operations. This effectively
    fakes the effects of multiple threads or processes without introducing the overhead
    that comes with those solutions. In the next chapter, we will also cover multiple
    threads and processes for the cases where I/O is not your bottleneck or where
    `asyncio` is not an option.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever you are dealing with external resources such as reading/writing files,
    interacting with APIs or databases, and other I/O operations, you can achieve
    great benefits from using `asyncio`. Where normally a single stalling remote connection
    can make your entire process hang, with `asyncio,` it will simply switch to a
    different part of your code.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will explain how asynchronous functions can be used in Python and
    how code can be restructured in such a way that it still functions, even though
    it doesn’t follow the standard procedural coding pattern of returning the values.
    The potential downside is that, similar to working with multiple threads and multiple
    processes, the possibility exists of your code executing in an unexpected order.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics are covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to `asyncio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asyncio` basic concepts, including coroutines, event loops, futures, and tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions using `async def`, `async for`, `async with`, and `await`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel execution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of implementation with `asyncio`, including clients and servers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging `asyncio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to asyncio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `asyncio` library was created to make using asynchronous processing much
    easier and more predictable. It was meant as a replacement for the `asyncore`
    module, which has been available for a very long time (since Python 1.5 even)
    but was not all that usable. The `asyncio` library was officially introduced for
    Python 3.4 and has seen many improvements with each newer Python release since.
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, the `asyncio` library allows you to switch to the execution of
    a different function whenever you need to wait for I/O operations. So instead
    of Python waiting for your operating system to finish reading a file for you,
    blocking the entire application in the process, it can do something useful in
    a different function in the meantime.
  prefs: []
  type: TYPE_NORMAL
- en: Backward compatibility and async/await statements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we continue with any examples, it is important to know how `asyncio`
    has changed within Python versions. Even though the `asyncio` library was only
    introduced in Python 3.4, a large portion of the generic syntax has been replaced
    in Python 3.5\. Using the old Python 3.4 syntax is still possible, but an easier
    and therefore recommended syntax using `await` has been introduced.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will assume Python 3.7 or newer in all examples unless specified
    differently. If you are still running an older version, however, please look at
    the following sections, which illustrate how to run `asyncio` on older systems.
    If you have Python 3.7+, feel free to skip to the section titled *A basic example
    of parallel execution*.
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the traditional Python 3.4 usage, a few things need to be considered:'
  prefs: []
  type: TYPE_NORMAL
- en: Functions should be declared using the `asyncio.coroutine` decorator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asynchronous results should be fetched using `yield from coroutine()`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Asynchronous loops are not directly supported, but can be emulated using a
    `while True: yield from coroutine()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Python 3.5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Python 3.5 syntax is much more obvious than the Python 3.4 version. While
    the `yield from` is understandable given the origins of coroutines in earlier
    Python versions, it is actually the wrong name for the job. Let `yield` be used
    for generators and `await` be used in coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Functions should be declared using `async def` instead of `def`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asynchronous results should be fetched using `await coroutine()`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asynchronous loops can be created using `async for ... in ...`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Python 3.7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since Python 3.7 it has become slightly easier and more obvious to run `asyncio`
    code. If you have the luxury of a newer Python version, you can use the following
    to run your `async` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'With older Python versions, we need a fairly advanced bit of code to properly
    replace `asyncio.run()`, but if you are not concerned with potentially reusing
    existing event loops (detailed information about event loops can be found later
    in the chapter) and take care of shutting down your tasks yourself, you can get
    away with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Or a shorter version that is certainly not equivalent but will handle many
    of your test cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: If at all possible, I would certainly recommend using `asyncio.run()`, of course.
    Even without `asyncio.run()`, you are likely to run into library compatibility
    issues with older versions of Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have to, however, you can find the source for `asyncio.run()` in the
    Python Git so you can implement a simplified version yourself: [https://github.com/python/cpython/blob/main/Lib/asyncio/runners.py](https://github.com/python/cpython/blob/main/Lib/asyncio/runners.py).'
  prefs: []
  type: TYPE_NORMAL
- en: A basic example of parallel execution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When it comes to code performance, you will usually encounter one of the two
    following bottlenecks:'
  prefs: []
  type: TYPE_NORMAL
- en: Waiting for external I/O such as web servers, the filesystem, a database server,
    anything network-related, and others
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The CPU, in the case of heavy calculations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your CPU is the bottleneck due to heavy calculations, you will need to resort
    to using faster algorithms, faster or more processors, or offloading the calculations
    to dedicated hardware such as video cards. In these cases, the `asyncio` library
    won’t help you much.
  prefs: []
  type: TYPE_NORMAL
- en: If your code is mostly waiting for the user, the kernel, the filesystem, or
    external servers, `asyncio` can help you a lot while being a fairly easy solution
    with few side effects. As we will see in the *asyncio concepts* section, there
    are some caveats, however. Making existing code `asyncio`-compatible can be a
    lot of work.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with a very simple example to show the difference between regular
    and `asyncio` code when having to wait.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the regular Python version that executes a 1-second `sleep` two times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'And now the `asyncio` version that executes a 1-second `sleep` two times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it still had to wait 1 second for the actual `sleep`, but it
    could run them in parallel. The `asyncio_sleep()` functions started simultaneously,
    as can be seen by the `before sleep` output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s analyze the components used in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '`async def`: This tells the Python interpreter that our function is a coroutine
    function instead of a regular function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asyncio.sleep()`: Asynchronous version of `time.sleep()`. The big difference
    between these two is that `time.sleep()` will keep the Python process busy while
    it’s sleeping, while `asyncio.sleep()` will allow switching to a different task
    within the event loop. This process is very similar to the workings of task switching
    in most operating systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asyncio.run()`: A wrapper that executes a coroutine in the default event loop.
    This is effectively the `asyncio` task switcher; more about this in the next section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asyncio.gather()`: Wraps a sequence of awaitable objects and gathers the results
    for you. The wait time is configurable, as is the manner of waiting. You can choose
    to wait until the first result, until all results are available, or until the
    first exception occurs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This immediately demonstrates a few of the caveats and pitfalls of `asyncio`
    code as well.
  prefs: []
  type: TYPE_NORMAL
- en: If we had accidentally used `time.sleep()` instead of `asyncio.sleep()`, the
    code would have taken 2 seconds to run instead and blocked the entire loop while
    doing so. More about this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: If we had used `await asyncio.sleep()` instead of using `await asyncio.gather()`
    at the end, the code would have run sequentially, and not in parallel, as you
    are probably looking for.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen a basic example of `asyncio`, we need to learn more about
    the internals so the limitations become more apparent.
  prefs: []
  type: TYPE_NORMAL
- en: asyncio concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `asyncio` library has several basic concepts that have to be explained before
    venturing further into examples and uses. The example shown in the previous section
    actually uses several of them, but a little explanation about the how and why
    might still be useful.
  prefs: []
  type: TYPE_NORMAL
- en: The main concepts of `asyncio` are coroutines and event loops. Within those
    there are several helper classes available such as `Streams`, `Futures`, and `Processes`.
    The next few paragraphs will explain the basics of them so we can understand the
    implementations as examples in the later sections.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines, Futures, and Tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `coroutine`, `asyncio.Future`, and `asyncio.Task` objects are essentially
    promises of a result; they return the results if they are available and can be
    used to cancel the execution of the promise if they have not finished processing
    yet. It should be noted that the creation of these objects will not guarantee
    that the code will be executed. The actual execution starts happening when you
    either `await` the results or tell an event loop to execute the promise. This
    is covered in the next section about event loops.
  prefs: []
  type: TYPE_NORMAL
- en: The most basic object you will encounter when using `asyncio` is the `coroutine`.
    The result of any regular `async def` (such as `asyncio.sleep()`) is a `coroutine`
    object. Once you `await` that `coroutine`, it will be executed and you will get
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: The `asyncio.Future` and `asyncio.Task` classes can also be executed through
    `await`, but also allow you to register callback functions that receive the results
    (or exceptions) as soon as they are available. Additionally, they maintain a state
    variable internally, which allows an outside party to cancel the future and stop
    (or prevent) its execution. The API is very similar to the `concurrent.futures.Future`
    class, but they are not fully compatible, so make sure you do not confuse the
    two.
  prefs: []
  type: TYPE_NORMAL
- en: 'To clarify a bit further, all of these are awaitable but have different levels
    of abstraction:'
  prefs: []
  type: TYPE_NORMAL
- en: '`coroutine`: The result of a called `async def` that has not yet been awaited.
    You will mostly use these.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asyncio.Future`: A class that represents an eventual result. It does not need
    to wrap a `coroutine` and the result can be set manually.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asyncio.Task`: An implementation of `asyncio.Future` that is meant to wrap
    a `coroutine` to have a convenient and consistent interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually the creation of these classes is not something you need to worry about
    directly; instead of creating the class yourself, the recommended way is through
    either `asyncio.create_task()` or `loop.create_task()`. The former actually executes
    `loop.create_task()` internally, but it’s more convenient if you simply want to
    execute it on the running event loop through `asyncio.get_running_loop()` without
    having to specify it. If you need to extend the `Task` class for some reason,
    that is easily possible through the `loop.set_task_factory()` method.
  prefs: []
  type: TYPE_NORMAL
- en: Before Python 3.7, `asyncio.create_task()` was called `asyncio.ensure_future()`.
  prefs: []
  type: TYPE_NORMAL
- en: Event loops
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The event loop concept is actually the most important one within `asyncio`.
    You might suspect that the coroutines themselves are what everything is about,
    but without the event loop they are useless. Event loops function as task switchers,
    similar to how operating systems switch between active tasks on the CPU. Even
    with multicore processors, there still needs to be a main process to tell the
    CPU which tasks to run and which need to wait or sleep for a bit. That is exactly
    what the event loop does: it decides which task to run.'
  prefs: []
  type: TYPE_NORMAL
- en: Effectively, every time you do `await`, the event loop will look at the pending
    awaitables and will continue the execution of one that is currently pending. This
    is also where the danger of a single event loop comes in. If, for some reason,
    you have a slow/blocking function in your coroutine, such as accidentally using
    `time.sleep()` instead of `asyncio.sleep()`, it will block the entire event loop
    until it finishes.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, this means that `await asyncio.sleep(5)` only guarantees that your
    code will wait *at least* 5 seconds. If, during that `await`, some other coroutine
    blocked the event loop for 10 seconds, the `asyncio.sleep(5)` would take at least
    10 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Event loop implementations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'So far we have only seen `asyncio.run()`, which uses `asyncio.get_event_loop()`
    internally to return the default event loop with the default event loop policy.
    Currently, there are two bundled event loop implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: The `asyncio.SelectorEventLoop` implementation, which is used by default on
    Unix and Linux systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `asyncio.ProactorEventLoop` implementation, which is only supported (and
    the default) on Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Internally, the `asyncio.ProactorEventLoop` implementation uses I/O completion
    ports, a system that is supposedly faster and more efficient than the `select`
    implementation of the `asyncio.SelectorEventLoop` on Windows systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `asyncio.SelectorEventLoop` is based on selectors, which, since Python
    3.4, are available through the `select` module in the core Python module. There
    are several selectors available: the traditional `selectors.SelectSelector`, which
    uses `select.select` internally, but also more modern solutions such as `selectors.KqueueSelector`,
    `selectors.EpollSelector`, and `selectors.DevpollSelector`. Even though `asyncio.SelectorEventLoop`
    will select the most efficient selector by default, there are cases where the
    most efficient one is not suitable in some way or another.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The most efficient selector is chosen by process of elimination. If the `select`
    module has a `kqueue` attribute, the `KqueueSelector` will be used. If `kqueue`
    is not available, the next best option will be chosen in the following order:'
  prefs: []
  type: TYPE_NORMAL
- en: '`KqueueSelector`: `kqueue` is an event notification interface for BSD systems.
    It is currently supported on FreeBSD, NetBSD, OpenBSD, DragonFly BSD, and macOS
    (OS X).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`EpollSelector`: `epoll` is the Linux kernel version of `kqueue`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`DevpollSelector`: This selector uses `/dev/poll`, a system that is similar
    to `kqueue` and `epoll` but is supported on Solaris systems.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`PollSelector`: `poll()` is a system call that will call your function when
    an update is available. The actual implementation depends on the system.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`SelectSelector`: Very similar to `poll()`, but `select()` builds a bitmap
    for all file descriptors and walks through that list for every update, which is
    quite a bit less efficient than `poll()`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In those cases, the selector event loop allows you to specify a different selector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It should be noted that the differences between these are generally too small
    to notice in most real-world applications. This is why I would recommend ignoring
    optimizations like these wherever possible, as they will most likely have very
    little effect and might actually cause problems if used incorrectly. The only
    situation I have come across where these would actually matter is when building
    a server that has to handle a lot of simultaneous connections. By “a lot,” I refer
    to over 100,000 concurrent connections on a single server, which is a problem
    only a few people on this planet have to deal with.
  prefs: []
  type: TYPE_NORMAL
- en: If performance is important to you (and you are running Linux/OS X) I would
    recommend looking at `uvloop`, a really fast event loop that is built on `libuv`,
    an asynchronous I/O library written in C that’s supported on most platforms. According
    to the `uvloop` benchmarks, it can make your event loop 2-4 times faster.
  prefs: []
  type: TYPE_NORMAL
- en: Event loop policies
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The event loop policies are merely the constructs that store and create event
    loops for you and have been written with maximum flexibility in mind. The only
    reason I can think of for modifying the event loop policy is if you want to make
    specific event loops run on specific processors and/or systems, such as enabling
    `uvloop` only if you are running Linux or OS X. Beyond that, it offers more flexibility
    than most people will ever need. To make `uvloop` the default loop if installed,
    you could do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Beyond overriding the `new_event_loop()` to customize the creation of new event
    loops, you can also override how the re-use of event loops works by overriding
    the `get_event_loop()` and `set_event_loop()` methods. I have personally never
    had any use for it beyond enabling `uvloop`, however.
  prefs: []
  type: TYPE_NORMAL
- en: Event loop usage
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now that we know what event loops are, what they do, and how an event loop is
    selected, let’s look at how they can be applied beyond `asyncio.run()`.
  prefs: []
  type: TYPE_NORMAL
- en: If you get into running your own event loops you will likely use `loop.run_forever()`,
    which, as you might expect, keeps running forever. Or at least until `loop.stop()`
    has been run. But you can also run a single task using `loop.run_until_complete()`.
    The latter is very useful for one-off operations, but can cause bugs in some scenarios.
    If you create a task from a very small/quick coroutine, odds are that the task
    will not have any time to run so it won’t be executed until the next time you
    execute `loop.run_until_complete()` or `loop.run_forever()`. More about that later
    in this chapter, however; for now, we will assume a long-running loop using `loop.run_forever()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we have an event loop running forever now, we need to add tasks to
    it – this is where things get interesting. There are quite a few choices available
    within the default event loops:'
  prefs: []
  type: TYPE_NORMAL
- en: '`call_soon()`: Add an item to the end of the (FIFO) queue so the functions
    will be executed in the order they were inserted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`call_soon_threadsafe()`: The same as `call_soon()` except for being thread-safe.
    The `call_soon()` method isn’t thread-safe because thread safety requires the
    usage of the **global interpreter lock** (**GIL**), which effectively makes your
    program single-threaded at the moment of thread safety. *Chapter 14, Multiprocessing
    – When a Single CPU Core is Not Enough,* explains both the GIL and thread safety
    in detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`call_later()`: Call the function after the given number of seconds; if two
    jobs would run at the same time, they will run in an undefined order. If the undefined
    order is an issue, you can also opt to use `asyncio.gather()` or increase the
    `delay` parameter for one of the two tasks slightly. Note that the `delay` is
    a minimum – if the event loop is locked/busy, it could run later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`call_at()`: Call a function at a specific time related to the output of `loop.time()`,
    which is the number of seconds since the `loop` started. So, if the current value
    of `loop.time()` is `90` (which means the `loop` started running `90` seconds
    ago), then you could run `loop.call_at(95, ...)` to run after `5` seconds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All of these functions return `asyncio.Handle` objects. These objects allow
    the cancelation of the task if it hasn’t been executed yet through the `handle.cancel()`
    function. Be careful with canceling from other threads, however, as cancelation
    is not thread-safe either. To execute it in a thread-safe way, we have to execute
    the cancelation function as a task as well: `loop.call_soon_threadsafe(handle.cancel)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Example usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You might be wondering why we are using `time.sleep()` instead of `asyncio.sleep()`
    here. That is an intentional choice to show how none of these functions offer
    any guarantee of when the function is executed if the `loop` is somehow blocked.
    Even though we specified a `0.1` second delay for the `loop.call_later()` call,
    it took `0.4` seconds to actually start. If we had used `asyncio.sleep()` instead,
    the functions would have run in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: The `call_soon()`, `call_soon_threadsafe()`, and `call_later()` functions are
    all just wrappers for `call_at()`. In the case of `call_soon()`, it just wraps
    `call_later()` with a delay of `0`, and `call_at()` is simply a `call_soon()`
    with `asyncio.time()` added to the delay.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the type of event loop, there are actually many other methods for
    creating connections, file handlers, and more, similar to `asyncio.create_task()`.
    Those will be explained with examples in the later sections, since they have less
    to do with the event loop and are more about programming with coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Executors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since even a simple `time.sleep()` can completely block your event loop, you
    might be wondering what the practical use for `asyncio` is. It would mean you
    have to rewrite your entire code base to be `asyncio`-compatible, right? Ideally
    that would be the best solution, but we can work around this limitation by executing
    sync code from `asyncio` code using executors. An `Executor` creates the other
    type of `Future` (`concurrent.futures.Future` as opposed to `asyncio.Future`)
    we talked about earlier, and runs your code in a separate thread or process to
    provide an `asyncio` interface to synchronous code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a basic example of the synchronous `time.sleep()` executed through
    an executor to make it asynchronous:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: So, instead of running `executor_sleep()` directly, we are creating a future
    through `loop.run_in_executor()`. This makes `asyncio` execute this function through
    the default executor, which is normally a `concurrent.futures.ThreadPoolExecutor`,
    and return the results when it’s done. You do need to be aware of thread safety
    because it is handled in a separate thread, but more about that topic in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'For operations that are blocking but not CPU-bound (in other words, no heavy
    calculations), the default threading-based executor will work great. For CPU-bound
    operations it will not help you, since the operations will still be limited to
    a single CPU core. For those scenarios, we can use `concurrent.futures.ProcessPoolExecutor()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'While this example looks nearly identical to the previous example, the internal
    mechanism is quite different and the use of multiple Python processes instead
    of multiple threads comes with several caveats:'
  prefs: []
  type: TYPE_NORMAL
- en: Memory cannot easily be shared between processes. This means that anything you
    want to pass as an argument and anything that you need to return has to be supported
    by the `pickle` process so Python can send the data, through the network, to the
    other Python process. This is explained in detail in *Chapter 14*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main script has to be run from an `if __name__ == '__main__'` block, otherwise
    the executor would end up in an infinite loop spawning itself.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most resources cannot be shared between processes. This is similar to not being
    able to share memory, but it goes beyond that. If you have a database connection
    in your main process, that connection cannot be used from the process so it will
    need to have its own connections.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Killing/exiting the process can be more difficult since killing the main process
    is not always a guarantee of killing the child processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on your operating system, every new process will use its own memory,
    resulting in greatly increased memory usage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a new process is generally a far heavier operation than creating a
    new thread, so you have a lot more overhead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synchronization between processes is much slower than with threads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these reasons definitely shouldn’t prevent you from using `ProcessPoolExecutor`,
    but you should always ask yourself if you actually need it. It can be an amazing
    solution if you need to run many heavy calculations in parallel. If at all possible,
    I would recommend using functional programming with `ProcessPoolExecutor`. *Chapter
    14*,*Multiprocessing – When a Single CPU Core Is Not Enough*, covers multiprocessing
    in much more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a basic grasp of `asyncio`, it is time to continue with some
    examples of where `asyncio` can be useful.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most common reasons for stalling scripts and applications is the
    usage of remote resources, where *remote* means any interaction with the network,
    filesystem, or other resources. With `asyncio`, at least a large portion of that
    is easily fixable. Fetching multiple remote resources and serving to multiple
    clients is quite a bit easier and more lightweight than it used to be. While both
    multithreading and multiprocessing can be used for these cases as well, `asyncio`
    is a much lighter alternative that is actually easier to manage in many cases.
  prefs: []
  type: TYPE_NORMAL
- en: The next few sections show a few examples of how to implement certain operations
    using `asyncio`.
  prefs: []
  type: TYPE_NORMAL
- en: Before you start implementing your own code and copying the examples here, I
    would recommend doing a quick search on the web for whichever library you are
    looking for and seeing if there is an `asyncio` version available.
  prefs: []
  type: TYPE_NORMAL
- en: In general, looking for “asyncio <protocol>” will give you great results. Alternatively,
    many libraries use the `aio` prefix for the library name, such as `aiohttp`, so
    that can help your search as well.
  prefs: []
  type: TYPE_NORMAL
- en: Processes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have simply executed simple `async` functions within Python such
    as `asyncio.sleep()`, but some things are a tad more difficult to run asynchronously.
    For example, let’s assume we have some long-running external application that
    we wish to run without blocking our main thread completely.
  prefs: []
  type: TYPE_NORMAL
- en: 'The options for running external processes in a non-blocking mode are generally:'
  prefs: []
  type: TYPE_NORMAL
- en: Threading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiprocessing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polling (periodically checking) for output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both threading and multiprocessing are covered in *Chapter 14*.
  prefs: []
  type: TYPE_NORMAL
- en: Without resorting to more complex solutions such as threading and multiprocessing,
    which introduce variable synchronization issues, we only have polling remaining.
    With polling, we check if there is new output at an interval, which can slow down
    your results by as much as the poll interval. That is, if your poll interval is
    1 second and the process generates output 0.1 seconds after the last poll, the
    next 0.9 seconds are wasted waiting. To alleviate this, you could reduce the poll
    interval, of course, but with a lower poll interval more time is wasted checking
    to see if there are results.
  prefs: []
  type: TYPE_NORMAL
- en: With `asyncio`, we can have the advantages of the polling method without the
    time wasted between the poll intervals. Using `asyncio.create_subprocess_shell`
    and `asyncio.create_subprocess_exec`, we can `await` output just like other coroutines.
    The usage of the class is very similar to `subprocess.run` except that the functions
    have been made asynchronous, resulting in the removal of the poll function, of
    course.
  prefs: []
  type: TYPE_NORMAL
- en: The examples below expect the `sleep` command to be available in your environment.
    On all Unix/Linux/BSD systems, this is the case by default. On Windows, it is
    not available by default, but can be installed easily. The `timeout` command can
    be used as an alternative.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you do wish to use `sleep` and other Unix tools, the easiest method I have
    found is to install Git for Windows and let it install the **optional Unix tools**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_13_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.1: Git for Windows installer'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s look at the traditional sequential version of a script that runs
    external processes (in this case the `sleep` command) through the `subprocess`
    module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: After the first `print()`, we use `subprocess.Popen()` to run the `sleep` command
    with argument `0.1` so it will sleep for `0.1` seconds. As opposed to `subprocess.run()`,
    which blocks your Python process and waits until the external process has finished
    running, `subprocess.Popen()` creates and starts the process and returns a reference
    to the running process, but it won’t automatically wait for the output.
  prefs: []
  type: TYPE_NORMAL
- en: This allows us to explicitly call `process.wait()` to wait or poll for the results,
    as we will see in the next example. Internally, `subprocess.run()` is actually
    a convenient shortcut for a common use case of `subprocess.Popen()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When running the code, we get the following output, as you would expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Since everything is executed sequentially, it takes two times the 0.1 seconds
    that the `sleep` command is sleeping for. This is, of course, the worst-case scenario:
    it completely blocks your Python process while it is running.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of waiting for the `sleep` command immediately after running, we are
    now going to start all processes in parallel and only wait for the results once
    they have all started in the background:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are returning the process by returning `subprocess.Popen()`
    without executing `process.wait()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we start all processes immediately and only wait for output after they
    have all started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The processes should be running in the background now, so let’s wait for the
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: While that looks a lot better in terms of runtime, it still blocks the main
    process when we run `process.wait()`. It also required restructuring in such a
    way that the teardown (the `Finished` print statement) is not in the same block
    as the start process, as was the case with the earlier example. This means that
    if something were to go wrong with your application, you would manually need to
    keep track of which process was failing, which is a bit inconvenient.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the `asyncio` version, we can once again go back to processing everything
    related to the `sleep` command in a single function, very similar to the first
    example with `subprocess.Popen()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it is trivial to run multiple applications at the same time
    this way. The syntax is essentially the same as it would be with `subprocess`
    without having to block or poll.
  prefs: []
  type: TYPE_NORMAL
- en: If you are running this from a long-running `asyncio` event loop and you don’t
    need to capture the results, you could skip the entire `asyncio.gather()` step
    and use `asyncio.create_task(async_process_sleep())` instead.
  prefs: []
  type: TYPE_NORMAL
- en: Interactive processes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Starting processes is the easy part; the more difficult part is interactive
    input and output with processes. The `asyncio` module has several measures to
    make that part easier, but it can still be difficult when actually working with
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of calling the Python interpreter as an external subprocess,
    executing some code, and exiting again in a simple one-off fashion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we added a pipe to `stdout` (standard output) and `stdin` (standard
    input) so we can read from `stdout` and write to `stdin` manually. After the process
    has started, we can use `process.communicate()` to write to `stdin`, and `process.communicate()`
    will automatically read all output from `stdout` and `stderr` if they are available.
    Since we did not declare what `stderr` is supposed to be, Python will automatically
    send all `process.stderr` output to `sys.stderr` for us, so we can ignore `stderr`
    here as it will be `None`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now the actual challenge comes when we want interactive subprocesses with two-way
    communication through `stdin`/`stdout`/`stderr` that keep on running for a longer
    time. That is also possible of course, but it can be hard to avoid deadlocks in
    situations where both sides are waiting for input. Here’s a very simple example
    of a Python subprocess that does effectively the same as `communicate()` above,
    but manually, to give you granular control over the input and output of the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The code might appear largely as you would expect, but there are a few parts
    that are non-obvious to use, yet required to function. While the creation of the
    subprocess is identical to the previous example, the writing of the code to `stdin`
    is slightly different.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of using `process.communicate()`, we now write directly to the `process.stdin`
    pipe. When you run `process.stdin.write(),` Python will *try* to write to the
    stream, but might not be able to because the process hasn’t started running yet.
    Because of that, we need to manually flush these buffers by using `process.stdin.drain()`.
    Once that is done, we send an end-of-file (`EOF`) character so the Python subprocess
    knows that no more input is coming.
  prefs: []
  type: TYPE_NORMAL
- en: Once the input is written, we need to read the output from the Python subprocess.
    We could use `process.stdout.readline()` in a loop for this, but similar to how
    we can do `for line in open(filename)`, we can also read `process.stdout` line
    by line using an `async for` loop until the stream is closed.
  prefs: []
  type: TYPE_NORMAL
- en: If at all possible, I would recommend abstaining from using `stdin` to send
    data to subprocesses and instead use some network, pipe, or file communication
    instead. As we will see in the next section covering an echo client and server,
    those are much more convenient to handle and less prone to deadlocks.
  prefs: []
  type: TYPE_NORMAL
- en: Echo client and server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most basic kind of server you can get is an “echo” server, which sends all
    messages received back. Since we can run multiple tasks in parallel with `asyncio`,
    we can run both the server and the client from the same script here. Splitting
    them into two processes is also possible, of course.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a basic client and server is easy to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we can see that we sent the server to the background using
    `asyncio.create_task()`. After that, we have to wait just a tiny amount of time
    for the background task to start working, which we are doing using `asyncio.sleep()`.
    The sleep time of `0.01` was chosen arbitrarily (and `0.001` is probably enough
    as well), but it should be enough for most systems to communicate with the kernel
    to create a listening socket. Once the server is running, we start our client
    to send a message and wait for the response.
  prefs: []
  type: TYPE_NORMAL
- en: 'Naturally, this example could have been written in many different ways. Instead
    of `async for`, you could use `reader.readline()` to read until the next newline,
    or you could use `reader.read(number_of_bytes)` to read a specific number of characters.
    It all depends on the protocol you wish to write. In the case of the HTTP/1.1
    protocol, the server expects a `Connection: close`; in the case of the SMTP protocol,
    a `QUIT` message should be sent. In our case, we use the `EOF` character as an
    indicator.'
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous file operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the operations you would prefer to be asynchronous is file operations.
    Even though storage devices have become much faster over the years, you are not
    always working on fast local storage. If you want to write to a network drive
    over a Wi-Fi connection, for example, you can experience quite a lot of latency.
    By using `asyncio`, you can make sure this won’t stall your entire interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, there is currently no easy way to do file operations through
    `asyncio` in a cross-platform way because most operating systems have no (scalable)
    asynchronous file operations support. Luckily, someone created a workaround for
    this issue. The `aiofiles` library uses the `threading` library internally to
    give you an `asyncio` interface to file operations. While you could easily use
    an `Executor` to handle the file operations for you, the `aiofiles` library is
    a very convenient wrapper that I recommend using.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, install the library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can use `aiofiles` to open, read, and write files in a non-blocking
    manner through `asyncio`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The usage of `aiofiles` is very similar to a regular `open()` call, except with
    the `async` prefix in all cases.
  prefs: []
  type: TYPE_NORMAL
- en: Creating async generators to support async for
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the earlier examples, you might have wondered how to support `async for`
    statements. Essentially it is very easy to do so; instead of a regular generator
    that you could create with the `__iter__` and `__next__` magic functions in a
    class, you would now use `__aiter__` and `__anext__` instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Effectively, the code is identical to regular generators and `with` statements,
    but you can also access `asyncio` code from the functions. There is really nothing
    special about these methods except that they need the `async` prefix and the `a`
    in the name, so you get `__aiter__` instead of `__iter__`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating async context managers to support async with
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the `async` generator, we can also create an `async` context manager.
    Instead of the `__iter__` method, we now have to replace the `__enter__` and `__exit__`
    methods with `__aenter__` and `__aexit__,` respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Effectively the code is identical to a `with` statement, but you can also access
    `asyncio` code from the functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Similar to the `async` generator, there really is nothing special about these
    methods. But the `async` context manager in particular is very useful for setup/teardown
    methods, as we will see in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous constructors and destructors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At some point, you will probably want to run some asynchronous code from your
    constructors and/or destructors, perhaps to initialize a database connection or
    other type of network connection. Unfortunately, that is not really possible.
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, using `__await__` or metaclasses, you could hack around this for
    your constructor. And with an `asyncio.run(...)` you could do something similar
    for your destructor. Neither is really a great solution though – I would suggest
    restructuring your code instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on the scenario I would suggest using either:'
  prefs: []
  type: TYPE_NORMAL
- en: Context managers to properly enter/exit using an `async with` statement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Factory pattern where an `async def` generates and initializes the class for
    you, together with an `async def close()` as an async destructor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have already seen the context manager in the previous section, and that would
    be the method I would recommend in most cases, such as creating database connections
    and/or transactions, since you cannot accidentally forget to run the teardown
    using that.
  prefs: []
  type: TYPE_NORMAL
- en: The Factory design pattern uses a function to facilitate the creation of an
    object. In this case, that means instead of doing `instance = SomeClass(...),`
    you would have `instance = await SomeClass.create(...)` so you can have an asynchronous
    initialization method.
  prefs: []
  type: TYPE_NORMAL
- en: 'But a Factory pattern with an explicit create and close method is, of course,
    a good possibility too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: With the order of operations as shown before, you can properly create and tear
    down an `asyncio` class that way. As a failsafe (explicitly calling `close()`
    is always the better solution), you can add an `async` destructor to your `__del__`
    by calling the loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the next example, we will use the `asyncpg` library, so make sure to install
    it first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, an `asyncio` database connection to PostgreSQL could be implemented like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: You could also create a registry to easily close all classes that were created
    so you can’t forget to do so on exit. But if possible, I would still recommend
    the context manager-style solution. You could also make a convenient shortcut
    using a decorator by creating an `async` version of `contextlib.ContextDecorator`.
  prefs: []
  type: TYPE_NORMAL
- en: Next up, we will look at how to debug `asyncio` code and how to catch common
    mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging asyncio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `asyncio` module has a few special provisions to make debugging somewhat
    easier. Given the asynchronous nature of functions within `asyncio`, this is a
    very welcome feat. While the debugging of multithreaded/multiprocessing functions
    or classes can be difficult – since concurrent classes can easily change environment
    variables in parallel – with `asyncio`, it’s just as difficult, if not more, because
    `asyncio` background tasks run in the stack of the event loop, not your own stack.
  prefs: []
  type: TYPE_NORMAL
- en: If you wish to skip this part of the chapter, I urge you to at least read the
    section on *Exiting before all tasks are done*. That covers a **huge** pitfall
    with `asyncio`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first and most obvious way of debugging `asyncio` is to use the event loop
    debug mode. We have several options for enabling the debug mode:'
  prefs: []
  type: TYPE_NORMAL
- en: Set the `PYTHONASYNCIODEBUG` environment variable to `True`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable the Python development mode using the `PYTHONDEVMODE` environment variable
    or by executing Python with the `-X dev` command-line option
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pass the `debug=True` argument to `asyncio.run()`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Call `loop.set_debug()`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of these methods, I recommend using the `PYTHONASYNCIODEBUG` or `PYTHONDEVMODE`
    environment variables because these are applied very early and can therefore catch
    several errors that the others might miss. We will see an example of that in the
    next section about forgotten `await` statements.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note about setting environment variables**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Within most Linux/Unix/Mac shell sessions, environment variables can be set
    using `variable=value` as a prefix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, environment variables can be configured for the current shell (when using
    ZSH or Bash) session using `export`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The current value can be fetched using the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'On Windows, you can configure an environment variable for your local shell
    session using the `set` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The current value can be fetched using this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'When the debug mode is enabled, the `asyncio` module will check a few common
    `asyncio` mistakes and issues. Specifically:'
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines that have not been yielded will raise an exception.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calling coroutines from the “wrong” thread raises an exception. This can occur
    if you have code running in different threads from the thread running the current
    event loop. This is effectively a case of thread safety, which is covered in *Chapter
    14*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The execution time of the selector will be logged.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slow coroutines (more than 100 ms) will be logged. This timeout can be modified
    through `loop.slow_callback_duration`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Warnings will be raised when resources are not closed properly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tasks that were destroyed before execution will be logged.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s showcase a few of these mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: Forgetting to await a coroutine
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is probably the most common `asyncio` bug and it has bitten me many, many
    times. It is so easy to do `some_coroutine()` instead of `await some_coroutine()`
    and you usually find out when it’s already too late.
  prefs: []
  type: TYPE_NORMAL
- en: 'Luckily, Python can help us with this one, so let’s look at what happens when
    you forget to `await` a coroutine with `PYTHONASYNCIODEBUG` set to `1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in an error for the `printer` coroutine, which we forgot to `await`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Note that this will only occur when the event loop has been closed. The event
    loop can’t know if you intended to execute the coroutine at a later moment, so
    this can still be difficult to debug.
  prefs: []
  type: TYPE_NORMAL
- en: This is also one of the cases where using the `PYTHONASYNCIODEBUG` environment
    variable instead of `loop.set_debug(True)` can make a difference. Think about
    a scenario where you have multiple event loops and forget to enable debug mode
    for all of them, or where a forgotten coroutine is created before debug mode is
    enabled, which means it will not be tracked.
  prefs: []
  type: TYPE_NORMAL
- en: Slow blocking functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Not considering that a function might be slow and blocking your loop is easy
    to do. If it is somewhat slow but not slow enough that you’ll notice, you will
    probably never find out about it unless you enable the debug mode. Let’s look
    at how the debug mode helps us here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we “accidentally” used `time.sleep()` instead of `asyncio.sleep()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For these issues, `debug=True` works great, but it never hurts to use `PYTHONASYNCIODEBUG=1`
    when developing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: As we expected, we get a warning with this slow function.
  prefs: []
  type: TYPE_NORMAL
- en: The default warning threshold is set to 100 ms and we are sleeping for 200 ms,
    so it is reported. The threshold can be changed through `loop.slow_callback_duration=<seconds>`
    if needed. This could be useful if you are working on a slower system such as
    a Raspberry Pi, or if you want to look for slow code.
  prefs: []
  type: TYPE_NORMAL
- en: Forgetting to check the results or exiting early
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A common way to write code with `asyncio` is to use fire-and-forget with `asyncio.create_task()`
    without storing the resulting future. While this is not inherently wrong, if an
    exception unexpectedly occurs in your code, it can be very difficult to find the
    culprit without the debug mode enabled.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate, we are going to use the following uncaught exception and execute
    it both with and without debug mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'If we execute this without debug mode, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: While this does nicely show us where the exception occurred and what exception
    occurred, it does not show us who or what created the coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now if we repeat the same with debug mode enabled, we get this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This might still be a bit hard to read, but now we see that the exception originated
    from `asyncio.create_task(throw_exception())` and we can even see the `asyncio.run(main())`
    call.
  prefs: []
  type: TYPE_NORMAL
- en: For a slightly larger code base, this can be essential in tracing the source
    of your exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Exiting before all tasks are done
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pay attention here, because this issue is extremely subtle but can have huge
    consequences if you don’t notice it.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to forgetting to fetch the results, when you create a task while the
    loop is already tearing down, the task will *not* always run. In some cases, it
    does not have the chance to run and you most likely won’t notice it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at this example where we have a task spawning another task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, even the debug mode cannot help you. To illustrate, let’s look
    at what happens when we call this with debug mode enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The call to `sub_printer()` seems to have disappeared. It really hasn’t, but
    we did not explicitly wait for it to finish so it never got a chance to run.
  prefs: []
  type: TYPE_NORMAL
- en: The **best** solution by far is to keep track of all futures created by `asyncio.create_task()`
    and do an `await asyncio.gather(*futures)` at the end of your `main()` function.
    But this is not always an option – you might not have access to the futures created
    by other libraries, or the futures might be created in a scope you cannot easily
    access. So what can you do?
  prefs: []
  type: TYPE_NORMAL
- en: 'As a very simple workaround, you can simply wait at the end of your `main()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'For this case, adding that little bit of sleep time works fine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: But this only does the trick if your task is fast enough or if you increase
    the sleep time. If we had a database teardown method that takes several seconds,
    we could still end up with an issue. As a very crude workaround, it can be useful
    to add this to your code since it will be more obvious when you’re missing a task.
  prefs: []
  type: TYPE_NORMAL
- en: A slightly better solution is to ask `asyncio` what tasks are still running
    and wait until they have finished. The drawback of this method is that if you
    have a task that runs forever (in other words, `while True`), you will wait forever
    for the script to exit.
  prefs: []
  type: TYPE_NORMAL
- en: 'So let’s look at how we could implement a feature like this, with a fixed timeout
    so we won’t wait forever:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This time, we have added a `shutdown()` method that fetches all tasks from `asyncio`
    using `asyncio.all_tasks()`. After collecting the tasks, we need to make sure
    that we don’t get our current task because that would result in a chicken-and-egg
    problem. The `shutdown()` task will never exit while waiting for the `shutdown()`
    task to finish.
  prefs: []
  type: TYPE_NORMAL
- en: When all tasks are gathered, we use `asyncio.as_completed()` to wait for them
    to finish and return after. If the waiting takes more than `timeout` seconds,
    `asyncio.as_completed()` will raise an `asyncio.TimeoutError` for us.
  prefs: []
  type: TYPE_NORMAL
- en: You can easily modify this to try and cancel all tasks so all non-shielded tasks
    will be canceled right away. And you can also change the exception to a warning
    instead if the pending tasks are not critical in your use case.
  prefs: []
  type: TYPE_NORMAL
- en: '`task = asyncio.shield(...)` protects against `task.cancel()` and functions
    like an onion. A single `asyncio.shield()` protects against a single `task.cancel()`;
    to protect against multiple cancelations, you will need to shield in a loop, or
    at least multiple times.'
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, it should be noted that this solution is not without its flaws either.
    It could happen that one of the tasks spawns new tasks while running; this is
    not something that is handled by this implementation, and handling it improperly
    might lead to waiting forever.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to debug the most common `asyncio` issues, it’s time to
    end with a few exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with `asyncio` will require active thought throughout most of your development
    process. Besides `asyncio.run()` and similar methods, there is no way to run an
    `async def` from synchronous code. This means that every intermediate function
    between your main `async def` and the code that needs `asyncio` will have to be
    `async` as well.
  prefs: []
  type: TYPE_NORMAL
- en: You could make a synchronous function return a coroutine so one of the parent
    functions can run it within an event loop. But that usually results in a very
    confusing execution order of the code, so I would not recommend going down that
    route.
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, this means that any `asyncio` project you try with the `asyncio`
    debug setting enabled is good practice. We can create a few challenges, however:'
  prefs: []
  type: TYPE_NORMAL
- en: Try to create a `asyncio` base class that automatically registers all instances
    for easy closing/destructuring when you are done
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an `asyncio` wrapper class for a synchronous process such as file or
    network operations using executors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert any of your scripts or projects to `asyncio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example answers for these exercises can be found on GitHub: [https://github.com/mastering-python/exercises](Chapter_13.xhtml).
    You are encouraged to submit your own solutions and learn about alternative solutions
    from others.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have seen:'
  prefs: []
  type: TYPE_NORMAL
- en: The basic concepts of `asyncio` and how they interact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to run external processes using `asyncio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to create a server and client using `asyncio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to create context managers with `asyncio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to create generators with `asyncio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to debug common issues when using `asyncio`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to avoid the unfinished task pitfall
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By now you should know how to keep your main loop responsive while waiting for
    results without having to resort to polling. In *Chapter 14*,*Multiprocessing
    – When a Single CPU Core Is Not Enough*, we will learn about `threading` and `multiprocessing`
    as an `asyncio` alternative to running multiple functions in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: For new projects, I would strongly consider using `asyncio` from the ground
    up because it is usually the fastest solution for handling external resources.
    For existing scripts, however, this can be a very invasive process. So knowing
    about `threading` and `multiprocessing` is certainly important, also because `asyncio`
    can leverage them and you should be aware of thread and process safety.
  prefs: []
  type: TYPE_NORMAL
- en: When building utilities based on the `asyncio` library, make sure to search
    for pre-made libraries to solve your problems as `asyncio` is gaining more adoption
    every year. In many cases, someone has already created a library for you.
  prefs: []
  type: TYPE_NORMAL
- en: Next up is parallel execution using `threading` and `multiprocessing`.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers: [https://discord.gg/QMzJenHuJf](https://discord.gg/QMzJenHuJf)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code156081100001293319171.png)'
  prefs: []
  type: TYPE_IMG
