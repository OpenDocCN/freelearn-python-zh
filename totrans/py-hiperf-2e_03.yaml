- en: Fast Array Operations with NumPy and Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NumPy is the *de facto* standard for scientific computing in Python. It extends
    Python with a flexible multidimensional array that allows fast and concise mathematical
    calculations.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy provides common data structures and algorithms designed to express complex
    mathematical operations using a concise syntax. The multidimensional array, `numpy.ndarray`, is
    internally based on C arrays. Apart from the performance benefits, this choice
    allows NumPy code to easily interface with the existing C and FORTRAN routines;
    NumPy is helpful in bridging the gap between Python and the legacy code written
    using those languages.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to create and manipulate NumPy arrays. We
    will also explore the NumPy broadcasting feature used to rewrite complex mathematical
    expressions in an efficient and succinct manner.
  prefs: []
  type: TYPE_NORMAL
- en: Pandas is a tool that relies heavily on NumPy and provides additional data structures
    and algorithms targeted toward data analysis. We will introduce the main Pandas
    features and its usage.  We will also learn how to achieve high performance from
    Pandas data structures and vectorized operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics covered in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating and manipulating NumPy arrays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mastering NumPy's broadcasting feature for fast and succinct vectorized operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving our particle simulator with NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reaching optimal performance with `numexpr`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas fundamentals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database-style operations with Pandas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The NumPy library revolves around its multidimensional array object, `numpy.ndarray`.
    NumPy arrays are collections of elements of the same data type; this fundamental
    restriction allows NumPy to pack the data in a way that allows for high-performance
    mathematical operations.
  prefs: []
  type: TYPE_NORMAL
- en: Creating arrays
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can create NumPy arrays using the `numpy.array` function. It takes a list-like
    object (or another array) as input and, optionally, a string expressing its data
    type. You can interactively test array creation using an IPython shell, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Every NumPy array has an associated data type that can be accessed using the `dtype`
    attribute. If we inspect the `a` array, we find that its  `dtype` is `int64`,
    which stands for 64-bit integer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We may decide to convert those integer numbers to `float` type. To do this, we
    can either pass the `dtype` argument at array initialization or cast the array
    to another data type using the `astype` method. The two ways to select a data
    type are shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To create an array with two dimensions (an array of arrays), we can perform
    the initialization using a nested sequence, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The array created in this way has two dimensions, which are called **axes** in
    NumPy''s jargon. An array formed in this way is like a table that contains two
    rows and three columns. We can access the axes using the `ndarray.shape` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Arrays can also be reshaped as long as the product of the shape dimensions
    is equal to the total number of elements in the array (that is, the total number
    of elements is conserved). For example, we can reshape an array containing 16
    elements in the following ways: `(2, 8)`, `(4, 4)`, or `(2, 2, 4)`. To reshape
    an array, we can either use the `ndarray.reshape` method or assign a new value
    to the `ndarray.shape` tuple. The following code illustrates the use of the `ndarray.reshape`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Thanks to this property, you can freely add dimensions of size one. You can
    reshape an array with 16 elements to `(16, 1)`, `(1, 16)`, `(16, 1, 1)`, and so
    on. In the next section, we will extensively use this feature to implement complex
    operations through *broadcasting*.
  prefs: []
  type: TYPE_NORMAL
- en: 'NumPy provides convenience functions, shown in the following code, to create
    arrays filled with zeros, ones, or with no initial value (in this case, their
    actual value is meaningless and depends on the memory state). Those functions
    take the array shape as a tuple and, optionally, its `dtype`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In our examples, we will use the `numpy.random` module to generate random floating
    point numbers in the `(0, 1)` interval. The `numpy.random.rand` will take a shape
    and return an array of random numbers with that shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes it is convenient to initialize arrays that have the same shape as
    that of some other array. For that purpose, NumPy provides some handy functions,
    such as `zeros_like`, `empty_like`, and `ones_like`. These functions can be used
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Accessing arrays
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The NumPy array interface is, on a shallow level, similar to that of Python
    lists. NumPy arrays can be indexed using integers and iterated using a `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In NumPy, array elements and sub-arrays can be conveniently accessed by using
    multiple values separated by commas inside the subscript operator, `[]`. If we
    take a `(3,3)` array (an array containing three triplets), and we access the element
    with index `0`, we obtain the first row, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can index the row again by adding another index separated by a comma. To
    get the second element of the first row, we can use the `(0, 1)` index. An important
    observation is that the `A[0, 1]` notation is actually a shorthand for `A[(0,
    1)]`, that is, we are actually indexing using a *tuple*! Both the versions are
    shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'NumPy allows you to slice arrays into multiple dimensions. If we slice on the
    first dimension, we can obtain a collection of triplets, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If we slice the array again on the second dimension with `0:2`, we are basically
    extracting the first two elements from the collection of triplets shown earlier.
    This results in an array of shape `(2, 2)`, shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Intuitively, you can update the values in the array using both numerical indexes
    and slices. An example is illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Indexing with the slicing syntax is very fast because, unlike lists, it doesn''t
    produce a copy of the array. In NumPy''s terminology, it returns a *view* of the
    same memory area. If we take a slice of the original array, and then we change
    one of its values, the original array will be updated as well. The following code
    illustrates an example of this feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It is important to be extra careful when mutating NumPy arrays. Since views
    share data, changing the values of a view can result in hard-to-find bugs. To
    prevent side effects, you can set the `a.flags.writeable = False` flag, which
    will prevent accidental mutation of the array or any of its views.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can take a look at another example that shows how the slicing syntax can
    be used in a real-world setting. We define an `r_i` array, shown in the following
    line of code, which contains a set of 10 coordinates (*x*, *y*). Its shape will
    be `(10, 2)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: If you have a hard time distinguishing arrays that differ in the axes order,
    for example between an a array of shape `(10, 2)` and `(2, 10)`, it is useful
    to think that every time you say the word *of*, you should introduce a new dimension.
    An array with ten elements *of* size two will be `(10, 2)`. Conversely, an array
    with two elements *of* size ten will be `(2, 10)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical operation we may be interested in is the extraction of the *x* component
    from each coordinate. In other words, you want to extract the `(0, 0)`, `(1, 0)`,
    `(2, 0)`, and so on items, resulting in an array with shape `(10,)`. It is helpful
    to think that the first index is *moving* while the second one is *fixed* (at
    `0`). With this in mind, we will slice every index on the first axis (the moving
    one) and take the first element (the fixed one) on the second axis, as shown in
    the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, the following expression will keep the first index fixed
    and the second index moving, returning the first (*x*, *y*) coordinate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Slicing all the indexes over the last axis is optional; using `r_i[0]` has the
    same effect as `r_i[0, :]`.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy allows you to index an array using another NumPy array made of either
    integer or Boolean values--a feature called *fancy indexing*.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you index an array (say, `a`) with another array of integers (say, `idx`),
    NumPy will interpret the integers as indexes and will return an array containing
    their corresponding values. If we index an array containing 10 elements with `np.array([0,
    2, 3])`, we obtain an array of shape `(3,)` containing the elements at positions
    `0`, `2`, and `3`. The following code gives us an illustration of this concept:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use fancy indexing on multiple dimensions by passing an array for each
    dimension. If we want to extract the `(0, 2)` and `(1, 3)` elements, we have to
    pack all the indexes acting on the first axis in one array, and the ones acting
    on the second axis in another. This can be seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also use normal lists as index arrays, but not tuples. For example,
    the following two statements are equivalent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'However, if you use a tuple, NumPy will interpret the following statement as
    an index on multiple dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The index arrays are not required to be one-dimensional; we can extract elements
    from the original array in any shape. For example, we can select elements from
    the original array to form a `(2,2)` array, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The array slicing and fancy-indexing features can be combined. This is useful,
    for instance, when we want to swap the *x* and *y* columns in a coordinate array.
    In the following code, the first index will be running over all the elements (a
    slice) and, for each of those, we extract the element in position `1` (the *y*)
    first and then the one in position `0` (the *x*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'When the index array is of the `bool` type, the rules are slightly different.
    The `bool` array will act like a *mask*; every element corresponding to `True`
    will be extracted and put in the output array. This procedure is shown in the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The same rules apply when dealing with multiple dimensions. Furthermore, if
    the index array has the same shape as the original array, the elements corresponding
    to `True` will be selected and put in the resulting array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Indexing in NumPy is a reasonably fast operation. Anyway, when speed is critical,
    you can use the slightly faster `numpy.take` and `numpy.compress` functions to
    squeeze out a little more performance. The first argument of `numpy.take` is the
    array we want to operate on, and the second is the list of indexes we want to
    extract. The last argument is `axis`; if not provided, the indexes will act on
    the flattened array; otherwise, they will act along the specified axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The similar, but faster version for Boolean arrays is `numpy.compress`, which
    works in the same way. The use of `numpy.compress` is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Broadcasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The true power of NumPy lies in its fast mathematical operations. The approach
    used by NumPy is to avoid stepping into the Python interpreter by performing element-wise
    calculation using optimized C code. **Broadcasting** is a clever set of rules
    that enables fast array calculations for arrays of similar (but not equal!) shape.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever you do an arithmetic operation on two arrays (like a product), if
    the two operands have the same shape, the operation will be applied in an element-wise
    fashion. For example, upon multiplying two shape `(2,2)` arrays, the operation
    will be done between pairs of corresponding elements, producing another `(2, 2)`
    array, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'If the shapes of the operands don''t match, NumPy will attempt to match them
    using broadcasting rules. If one of the operands is a *scalar* (for example, a
    number), it will be applied to every element of the array, as the following code
    illustrates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'If the operand is another array, NumPy will try to match the shapes starting
    from the last axis. For example, if we want to combine an array of shape `(3,
    2)` with one of shape `(2,)`, the second array will be repeated three times to
    generate a `(3, 2)` array. In other words, the array is *broadcasted* along a
    dimension to match the shape of the other operand, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B06440_03CHPNO_01-1.png)'
  prefs: []
  type: TYPE_IMG
- en: If the shapes mismatch, for example, when combining a `(3, 2)` array with a
    `(2, 2)` array, NumPy will throw an exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'If one of the axis''s size is 1, the array will be repeated over this axis
    until the shapes match. To illustrate that point, consider that we have an array
    of the following shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, consider that we want to broadcast it with an array of shape `(5, 1, 2)`;
    the array will be repeated on the second axis 10 times, which is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Earlier, we saw that it is possible to freely reshape arrays to add axes of
    size 1\. Using the `numpy.newaxis` constant while indexing will introduce an extra
    dimension. For instance, if we have a `(5, 2)` array and we want to combine it
    with one of shape `(5, 10, 2)`, we can add an extra axis in the middle, as shown
    in the following code, to obtain a compatible `(5, 1, 2)` array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This feature can be used, for example, to operate on all possible combinations
    of the two arrays. One of these applications is the *outer product*. Consider
    that we have the following two arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The outer product is a matrix containing the product of all the possible combinations
    (i, j) of the two array elements, as shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To calculate this using NumPy, we will repeat the `[a1, a2, a3]` elements in
    one dimension, the `[b1, b2, b3]` elements in another dimension, and then take
    their element-wise product, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_03_002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using code, our strategy will be to transform the `a` array from shape `(3,)`
    to shape `(3, 1)`, and the `b` array from shape `(3,)` to shape `(1, 3)`. The
    two arrays are broadcasted in the two dimensions and get multiplied together using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This operation is very fast and extremely effective as it avoids Python loops
    and is able to process a high number of elements at speeds comparable with pure
    C or FORTRAN code.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'NumPy includes the most common mathematical operations available for broadcasting,
    by default, ranging from simple algebra to trigonometry, rounding, and logic.
    For instance, to take the square root of every element in the array, we can use `numpy.sqrt`,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The comparison operators are useful when trying to filter certain elements
    based on a condition. Imagine that we have an array of random numbers from `0`
    to `1`, and we want to extract all the numbers greater than `0.5`. We can use
    the `>` operator on the array to obtain a `bool` array, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting `bool` array can then be reused as an index to retrieve the elements
    greater than `0.5`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'NumPy also implements methods such as `ndarray.sum`, which takes the sum of
    all the elements on an axis. If we have an array of shape `(5, 3)`, we can use
    the `ndarray.sum` method to sum the elements on the first axis, the second axis,
    or over all the elements of the array, as illustrated in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Note that by summing the elements over an axis, we eliminate that axis. From
    the preceding example, the sum on the axis `0` produces an array of shape `(3,)`,
    while the sum on the axis `1` produces an array of shape `(5,)`.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the norm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can review the basic concepts illustrated in this section by calculating
    the *norm* of a set of coordinates. For a two-dimensional vector, the norm is
    defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Given an array of 10 coordinates (*x*, *y*), we want to find the norm of each
    coordinate. We can calculate the norm by taking these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Square the coordinates, obtaining an array that contains `(x**2, y**2)` elements.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sum those with `numpy.sum` over the last axis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take the square root, element-wise, with `numpy.sqrt`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The final expression can be compressed in a single line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Rewriting the particle simulator in NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will optimize our particle simulator by rewriting some
    parts of it in NumPy. We found, from the profiling we did in [Chapter 1](4db2c3e6-3485-41a5-8450-07220f6d80ec.xhtml),
    *Benchmarking and Profiling*, that the slowest part of our program is the following
    loop contained in the `ParticleSimulator.evolve` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: You may have noticed that the body of the loop acts solely on the current particle.
    If we had an array containing the particle positions and angular speed, we could
    rewrite the loop using a broadcasted operation. In contrast, the loop's steps
    depend on the previous step and cannot be parallelized in this way.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is natural then, to store all the array coordinates in an array of shape
    `(nparticles, 2)` and the angular speed in an array of shape `(nparticles,)`,
    where `nparticles` is the number of particles. We''ll call those arrays `r_i`
    and `ang_vel_i`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The velocity direction, perpendicular to the vector (*x*, *y*), was defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The norm can be calculated using the strategy illustrated in the *Calculating
    the norm* section under the *Getting started with NumPy* heading:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'For the (*-y*, *x*) components, we first need to swap the x and y columns in
    `r_i` and then multiply the first column by -1, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'To calculate the displacement, we need to compute the product of `v_i`, `ang_vel_i`,
    and `timestep`. Since `ang_vel_i` is of shape `(nparticles,)`, it needs a new
    axis in order to operate with `v_i` of shape `(nparticles, 2)`. We will do that
    using `numpy.newaxis`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Outside the loop, we have to update the particle instances with the new coordinates,
    *x* and *y*, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'To summarize, we will implement a method called `ParticleSimulator.evolve_numpy`
    and benchmark it against the pure Python version, renamed as `ParticleSimulator.evolve_python`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'We also update the benchmark to conveniently change the number of particles
    and the simulation method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s run the benchmark in an IPython session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We have some improvement, but it doesn''t look like a huge speed boost. The
    power of NumPy is revealed when handling big arrays. If we increase the number
    of particles, we will note a more significant performance boost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot in the following figure was produced by running the benchmark with
    different particle numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_03_003.png)'
  prefs: []
  type: TYPE_IMG
- en: The plot shows that both the implementations scale linearly with particle size,
    but the runtime in the pure Python version grows much faster than the NumPy version;
    at greater sizes, we have a greater NumPy advantage. In general, when using NumPy,
    you should try to pack things into large arrays and group the calculations using
    the broadcasting feature.
  prefs: []
  type: TYPE_NORMAL
- en: Reaching optimal performance with numexpr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When handling complex expressions, NumPy stores intermediate results in memory.
    David M. Cooke wrote a package called `numexpr`, which optimizes and compiles
    array expressions on the fly. It works by optimizing the usage of the CPU cache
    and by taking advantage of multiple processors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Its usage is generally straightforward and is based on a single function--`numexpr.evaluate`.
    The function takes a string containing an array expression as its first argument.
    The syntax is basically identical to that of NumPy. For example, we can calculate
    a simple `a + b * c` expression in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The `numexpr` package increases the performances in almost all cases, but to
    get a substantial advantage, you should use it with large arrays. An application
    that involves a large array is the calculation of a *distance matrix*. In a particle
    system, a distance matrix contains all the possible distances between the particles.
    To calculate it, we should first calculate all the vectors connecting any two
    particles `(i,j)`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we calculate the length of this vector by taking its norm, as in the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We can write this in NumPy by employing the usual broadcasting rules (the operation
    is similar to the outer product):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we calculate the norm over the last axis using the following line
    of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Rewriting the same expression using the `numexpr` syntax is extremely easy.
    The `numexpr` package doesn''t support slicing in its array expression; therefore,
    we first need to prepare the operands for broadcasting by adding an extra dimension,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: At that point, we should try to pack as many operations as possible in a single
    expression to allow a significant optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the NumPy mathematical functions are also available in `numexpr`. However,
    there is a limitation--the reduction operations (the ones that reduce an axis,
    such as sum) have to happen last. Therefore, we have to first calculate the sum,
    then step out of `numexpr`, and finally calculate the square root in another expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The `numexpr` compiler will avoid redundant memory allocation by not storing intermediate
    results. When possible, it will also distribute the operations over multiple processors.
    In the `distance_matrix.py` file, you will find two functions that implement the
    two versions: `distance_matrix_numpy` and `distance_matrix_numexpr`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: By simply converting the expressions to use `numexpr`, we were able to obtain
    a 4.5x increase in performance over standard NumPy. The `numexpr` package can
    be used every time you need to optimize a NumPy expression that involves large
    arrays and complex operations, and you can do so with minimal changes in the code.
  prefs: []
  type: TYPE_NORMAL
- en: Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pandas is a library originally developed by Wes McKinney, which was designed
    to analyze datasets in a seamless and performant way. In recent years, this powerful
    library has seen an incredible growth and huge adoption by the Python community.
    In this section, we will introduce the main concepts and tools provided in this
    library, and we will use it to increase performance of various usecases that can't
    otherwise be addressed with NumPy's vectorized operations and broadcasting.
  prefs: []
  type: TYPE_NORMAL
- en: Pandas fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While NumPy deals mostly with arrays, Pandas main data structures are `pandas.Series`,
    `pandas.DataFrame`, and `pandas.Panel`. In the rest of this chapter, we will abbreviate
    `pandas` with `pd`.
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between a `pd.Series` object and an `np.array` is that a `pd.Series`
    object associates a specific *key* to each element of an array. Let’s see how
    this works in practice with an example.
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume that we are trying to test a new blood pressure drug, and we want
    to store, for each patient, whether the patient's blood pressure improved after
    administering the drug. We can encode this information by associating to each
    subject ID (represented by an integer),  `True` if the drug was effective, and
    `False` otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a `pd.Series` object by associating an array of keys, the patients,
    to the array of values that represent the drug effectiveness. The array of keys
    can be passed to the `Series` constructor using the `index` argument, as shown
    in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Associating a set of integers from 0 to *N* to a set of values can technically
    be implemented with `np.array`, since, in this case, the key will simply be the
    position of the element in the array. In Pandas, keys are not limited to integers
    but can also be strings, floating point numbers, and also generic (hashable) Python
    objects. For example, we can easily turn our IDs into strings with little effort,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: An interesting observation is that, while NumPy arrays can be thought of as
    a contiguous collection of values similar to Python lists, the Pandas `pd.Series`
    object can be thought of as a structure that maps keys to values, similar to Python
    dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: What if you want to store the initial and final blood pressure for each patient?
    In Pandas, one can use a `pd.DataFrame` object to associate multiple data to each
    key.
  prefs: []
  type: TYPE_NORMAL
- en: '`pd.DataFrame` can be initialized, similarly to a `pd.Series` object, by passing
    a dictionary of columns and an index. In the following example, we will see how
    to create a `pd.DataFrame` containing four columns that represent the initial
    and final measurements of systolic and dyastolic blood pressure for our patients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Equivalently, you can think of a `pd.DataFrame` as a collection of `pd.Series`.
    In fact, it is possible to directly initialize a `pd.DataFrame`, using a dictionary
    of `pd.Series` instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'To inspect the content of a `pd.DataFrame` or `pd.Series` object, you can use
    the `pd.Series.head` and `pd.DataFrame.head` methods, which print the first few
    rows of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Just like a `pd.DataFrame` can be used to store a collection of `pd.Series`,
    you can use a `pd.Panel` to store a collection of `pd.DataFrames`. We will not
    cover the usage of `pd.Panel` as it is not used as often as `pd.Series` and `pd.DataFrame`.
    To learn more about `pd.Panel`, ensure that you refer to the excellent documentation
    at [http://pandas.pydata.org/pandas-docs/stable/dsintro.html#panel](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#panel).
  prefs: []
  type: TYPE_NORMAL
- en: Indexing Series and DataFrame objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Retrieving data from a `pd.Series`, given its *key*, can be done intuitively
    by indexing the `pd.Series.loc` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to access the elements, given its *position* in the underlying
    array, using the `pd.Series.iloc` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also use the `pd.Series.ix` attribute for mixed access. If the key
    is not an integer, it will try to match by key, otherwise it will extract the
    element at the position indicated by the integer. A similar behavior will take
    place when you access the `pd.Series` directly. The following example demonstrates
    these concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Note that if the index is made of integers, this method will fall back to the
    key-only method (like `loc`). To index by position in this scenario, the `iloc`
    method is your only option.
  prefs: []
  type: TYPE_NORMAL
- en: 'Indexing `pd.DataFrame` works in a similar way. For example, you can use `pd.DataFrame.loc`
    to extract a row by key, and you can use `pd.DataFrame.iloc` to extract a row
    by position:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'An important aspect is that the return type in this case is a `pd.Series`,
    where each column is a new key. In order to retrieve a specific row and column,
    you can use the following code. The `loc` attribute will index both row and column
    by key, while the `iloc` version will index row and column by an integer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Indexing a `pd.DataFrame` using the `ix` attribute is convenient to mix and
    match index and location-based indexing. For example, retrieving the `"sys_initial"`
    column for the row at position 0 can be accomplished as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Retrieving a column from a `pd.DataFrame` by name can be achieved by regular
    indexing or attribute access.  To retrieve a column by position, you can either
    use `iloc` or use the `pd.DataFrame.column` attribute to retrieve the name of
    the column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: The mentioned methods also support more advanced indexing similar to those of
    NumPy, such as `bool`, lists, and `int` arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Now it's time for some performance considerations. There are some differences
    between an index in Pandas and a dictionary. For example, while the keys of a
    dictionary cannot contain duplicates, Pandas indexes can contain repeated elements.
    This flexibility, however, comes at a cost--if we try to access an element in
    a non-unique index, we may incur substantial performance loss--the access will
    be *O*(*N*), like a linear search, rather than *O*(1), like a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: 'A way to mitigate this effect is to sort the index; this will allow Pandas
    to use a binary search algorithm with a computational complexity of *O*(*log*(*N*)),
    which is much better. This can be accomplished using the `pd.Series.sort_index`
    function, as in the following code (the same applies for `pd.DataFrame`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The timings for the different versions are summarized in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Index type** | **N=10000** | **N=20000** | **N=30000** | **Time** |'
  prefs: []
  type: TYPE_TB
- en: '| Unique | 12.30 | 12.58 | 13.30 | *O*(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Non unique | 494.95 | 814.10 | 1129.95 | *O*(N) |'
  prefs: []
  type: TYPE_TB
- en: '| Non unique (sorted) | 145.93 | 145.81 | 145.66 | *O*(*log*(*N*)) |'
  prefs: []
  type: TYPE_TB
- en: Database-style operations with Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may have noted that the “tabular” data is similar to what is usually stored
    in a database. A database is usually indexed using a primary key, and the various
    columns can have different data types, just like in a `pd.DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: The efficiency of the index operations in Pandas makes it suitable for database
    style manipulations, such as counting, joining, grouping, and aggregations.
  prefs: []
  type: TYPE_NORMAL
- en: Mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Pandas supports element-wise operations just like NumPy (after all, `pd.Series`
    stores their data using `np.array`). For example, it is possible to apply transformation
    very easily on both `pd.Series` and `pd.DataFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also perform element-wise operations between two `pd.Series` in a way
    similar to NumPy. An important difference is that the operands will be matched
    by key, rather than by position; if there is a mismatch in the index, the resulting
    value will be set to `NaN`. Both the scenarios are exemplified in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: For added flexibility, Pandas exposes the `map`, `apply`, and `applymap` methods that
    can be used to apply specific transformations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pd.Series.map` method can be used to execute a function to each value
    and return a `pd.Series` containing each result. In the following example, we
    show how to apply the `superstar` function to each element of a `pd.Series`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The `pd.DataFrame.applymap` function is the equivalent of `pd.Series.map`,
    but for `DataFrames`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `pd.DataFrame.apply` function can apply the passed function to
    each column or each row, rather than element-wise. The selection can be performed
    with the argument axis, where a value of `0` (the default) corresponds to columns,
    and `1` corresponds to rows. Also, note that the return value of `apply` is a
    `pd.Series`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Pandas also supports efficient `numexpr`-style expressions with the convenient `eval`
    method. For example, if we want to calculate the difference in the final and initial
    blood pressure, we can write the expression as a string, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to create new columns using the assignment operator in
    the `pd.DataFrame.eval` expression. Note that, if the `inplace=True` argument
    is used, the operation will be applied directly on the original `pd.DataFrame`;
    otherwise, the function will return a new dataframe. In the next example, we compute
    the difference between `sys_final` and `sys_initial`, and we store it in the `sys_delta`
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Grouping, aggregations, and transforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the most appreciated features of Pandas is the simple and concise expression
    of data analysis pipelines that requires grouping, transforming, and aggregating
    the data. To demonstrate this concept, let''s extend our dataset by adding two
    new patients to whom we didn''t administer the treatment (this is usually called
    a *control group*). We also include a column, `drug_admst`, which records whether the
    patient was administered the treatment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we may be interested to know how the blood pressure changed
    between the two groups. You can group the patients according to `drug_amst` using
    the `pd.DataFrame.groupby` function. The return value will be the `DataFrameGroupBy`
    object, which can be iterated to obtain a new `pd.DataFrame` for each value of
    the `drug_admst` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Iterating on the `DataFrameGroupBy` object is almost never necessary, because,
    thanks to method chaining, it is possible to calculate group-related properties directly.
    For example, we may want to calculate mean, max, or standard deviation for each
    group. All those operations that summarize the data in some way are called aggregations
    and can be performed using the `agg` method. The result of `agg` is another `pd.DataFrame` that
    relates the grouping variables and the result of the aggregation, as illustrated
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '**It is also possible to perform processing on the DataFrame groups that do
    not represent a summarization. One common example of such an operation is filling
    in missing values. Those intermediate steps are called *transforms*.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can illustrate this concept with an example. Let''s assume that we have
    a few missing values in our dataset, and we want to replace those values with
    the average of the other values in the same group. This can be accomplished using
    a transform, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: Joining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Joins are useful to aggregate data that is scattered among different tables.
    Let’s say that we want to include the location of the hospital in which patient
    measurements were taken in our dataset. We can reference the location for each
    patient using the `H1`, `H2`, and `H3` labels, and we can store the address and
    identifier of the hospital in a `hospital` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: Now, we want to find the city where the measure was taken for each patient.
    We need to *map* the keys from the `hospital_id` column to the city stored in
    the `hospitals` table.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can surely be implemented in Python using dictionaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'This algorithm runs efficiently with an *O*(*N*) time complexity, where *N*
    is the size of `hospital_id`. Pandas allows you to encode the same operation using
    simple indexing; the advantage is that the join will be performed in heavily optimized
    Cython and with efficient hashing algorithms. The preceding simple Python expression
    can be easily converted to Pandas in this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'More advanced joins can also be performed with the `pd.DataFrame.join` method,
    which will produce a new `pd.DataFrame` that will attach the hospital information
    for each patient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to manipulate NumPy arrays and how to write
    fast mathematical expressions using array broadcasting. This knowledge will help
    you write more concise, expressive code and, at the same time, to obtain substantial
    performance gains. We also introduced the `numexpr` library to further speed up
    NumPy calculations with minimal effort.
  prefs: []
  type: TYPE_NORMAL
- en: Pandas implements efficient data structures that are useful when analyzing large
    datasets. In particular, Pandas shines when the data is indexed by non-integer
    keys and provides very fast hashing algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy and Pandas work well when handling large, homogenous inputs, but they
    are not suitable when the expressions grow complex and the operations cannot be
    expressed using the tools provided by these libraries. In such cases, we can leverage
    Python capabilities as a glue language by interfacing it with C using the Cython
    package.
  prefs: []
  type: TYPE_NORMAL
