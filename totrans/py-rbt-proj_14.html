<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Giving Voice to Jarvis</h1>
                </header>
            
            <article>
                
<p>Ever wondered whether using robots to get our work done is possible? Well yes! Certainly in some high-tech fiction or Marvel movies or even comic books. So, get your seat belt tight and get ready for this amazing chapter where you will actually be implementing what I just mentioned. </p>
<p>This chapter will cover the following topics:</p>
<ul>
<li>Basic installation</li>
<li>Automatic delivery answering machine</li>
<li>Making an interactive door answering robot</li>
<li>Making Jarvis understand our voice</li>
</ul>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Basic installation</h1>
                </header>
            
            <article>
                
<p class="mce-root">There are various ways and methods through which we can control our smart home Jarvis, some of which we have explored earlier such as controlling it through. So, to start with, we need to prepare our system to be able to do speech synthesis; to do that, let's perform the following process.</p>
<p class="mce-root">First, go to the terminal and enter the following command:</p>
<pre><strong>sudo apt-get install alsa-utils</strong></pre>
<p>What this will do is install the dependency <kbd>alsa-utils</kbd>. <span>The</span> <kbd>alsa-utils</kbd> <span>package contains various utilities that are useful for controlling your sound drivers.</span></p>
<p>Once this is done, you need to edit the file. To do it, we need to open the file. Use the following command:</p>
<pre><strong>sudo nano /etc/modules</strong></pre>
<p>Once that is done, a file will open; at the bottom of that file, you need to add the following line:</p>
<pre><strong>snd_bcm2835</strong></pre>
<p>You don't need to get too much into why we are doing it. It's just there to set things up. I can give you an explanation; however, I do not wish to bore you at this exciting moment. </p>
<p>Also, if you are lucky, then sometimes, you might find the line to be already present. If that is the case, then let it be there and don't touch it. </p>
<p>Now, to play the sounds that we need the Jarvis to say, we need an audio player. No, not the one that you have at your home. We are talking about the software that would play it. </p>
<p>To install the player, we need to run the following commands:</p>
<pre><strong>sudo apt-get install mplayer</strong></pre>
<p>All right, we are done with audio player; let's see what we have next. Now, again, we need to edit the file of the media player. We will use the same steps to open the file and edit it:</p>
<pre><strong>sudo nano /etc/mplayer/mplayer.conf</strong></pre>
<p>This will open the file. As before, simply add the following line: </p>
<pre><strong>nolirc=yes</strong></pre>
<p>Finally, we need to give it some voice, so run the following command:</p>
<pre><strong>sudo apt-get install festvox-rablpc16k</strong></pre>
<p>This will install a 16 kHz, British, male, voice to Jarvis. We love British accents, don't we? </p>
<p>Perfect. Once we have done all of the steps mentioned previously, we would be good to go. To test the voice, simply connect a USB speaker to the Raspberry Pi and run the following code:</p>
<pre>import os<br/>from time import sleep<br/>os.system('echo "hello! i am raspberry pi robot"|festival --tts ')<br/>sleep(2)<br/>os.system('echo "how are you?"| festival --tts ')<br/>sleep(2)<br/>os.system('echo "I am having fun."| festival --tts ')<br/>sleep(2)</pre>
<p>All right then, let's see what we have actually done: </p>
<pre>import os</pre>
<p>As you might have figured out, we are importing the library named <kbd>os</kbd>. This library provides a <span>way of using operating-system-dependent functionality:<br/></span></p>
<pre>os.system('echo "Hello from the other side"|festival --tts ')</pre>
<p>Here, we are using a method called <kbd>system()</kbd>; what this does is that it executes a shell command. You might be wondering what this is. A shell command is a command used by the user to access the functionality of a system to interact with it. So now that we want to convert our text to voice, we would be providing two arguments to this function. First, what is the text? In our case, it is <kbd>Hello from the other side</kbd>; the second argument that we have here is <kbd>festival --tts</kbd>. Now <kbd>festival</kbd> is a library, and <kbd>tts</kbd> stands for text to speech conversion. So when we pass it on to the argument, the system will know that the text passed on to the argument has to be converted from text to speech.</p>
<p>And that's it! Yes, that's it. That's all we have to do to make your Raspberry speak. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Automatic delivery answering machine </h1>
                </header>
            
            <article>
                
<p>These days, we all order things online. Yet no matter how automated the process of Amazon is, when talking about 2018, we still have humans delivering the packages to our doorsteps. Sometimes, you want them to know a few things about where to leave the parcel. Now that we are becoming more and more automated, gone are the days when you might leave a note outside your gate. It's time to make something really interesting with our technology. To do that, we hardly need to do anything serious. All we need to do is to wire up the components as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign CDPAlignLeft"><img src="Images/8c510d45-0f99-45ac-a675-5a2769835770.png"/></p>
<p>The PIR sensor must be placed so that it gives a logic high whenever there is movement around the gate.</p>
<p>Once that is done, go ahead and upload the following code:</p>
<pre>import RPi.GPIO as GPIO<br/>import time<br/>Import os<br/>GPIO.setmode(GPIO.BCM)<br/>PIR = 13<br/>GPIO.setup(PIR,GPIO.IN)<br/>while True:<br/><br/>  if GPIO.input(PIR) == 1 :<br/>     os.system('echo "Hello, welcome to my house"|festival --tts ')<br/>     time.sleep(0.2)<br/>     os.system('echo "If you are a delivery agent then please leave the package here"|festival --tts ')<br/>     time.sleep(0.2)<br/>     os.system('echo "If you are a guest then I'm sorry I have to leave I will be back after 7pm"|festival --tts ')<br/>     time.sleep(0.2)<br/>     os.system('echo "also Kindly don't step over the grass, its freshly grown and needs some time"|festival --tts ')<br/>     time.sleep(1)<br/>     os.system('echo "Thank you !"|festival --tts ')</pre>
<p>Now what we have done is very simple. As soon as the PIR sensor gives a logic high, a certain instruction is spoken. There is no need of an explanation. You can refer to the previous code if you need any clarification.</p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Making an interactive door – answering robot</h1>
                </header>
            
            <article>
                
<p>In the previous chapter we have used a PIR sensor to sense any human activity, however the problem with the sensor is, that no matter who comes or leaves it would deliver the same message. That basically means that even when you come home after a long day, it would end up asking the same question. Pretty dumb huh? </p>
<p>So in this chapter we would use the previous repository and integrate the vision and the voice together to make an amazing duo. In this, the camera would identify who is on the gate and would recognize if it is a human and a stranger, if so then, it would deliver the message you intend to give. On the other hand if its you then it would simply let you pass with a simple greeting. However if the face is detected but not recognized then it would give a set of instructions to the person standing in-front of the camera. </p>
<p>To implement it all you need to do is to set up a camera on the gate of your door along with the PIR. The PIR is basically to activate the camera. In other words the camera would not get activated till the time no movement is detected. This set up is very straight forward and does not need any GPIO to be used. Simply fix the camera and PIR and upload the following code:</p>
<pre>import RPi.GPIO as GPIO<br/>import time<br/>Import os<br/>import cv2<br/>import numpy as np<br/>import cv2<br/><br/>faceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')<br/>cam = cv2.VideoCapture(0)<br/>rec = cv2.face.LBPHFaceRecognizer_create()<br/>rec.read("recognizer/trainningData.yml")<br/>id = 0<br/><br/>while True:<br/><br/>  GPIO.setmode(GPIO.BCM)<br/>PIR = 13<br/>GPIO.setup(PIR, GPIO.IN)<br/><br/>if GPIO.input(PIR) == 1:<br/><br/>  ret, img = cam.read()<br/>gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br/>faces = faceDetect.detectMultiScale(gray, 1.3, 5)<br/>for (x, y, w, h) in faces:<br/>  cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)<br/>id, conf = rec.predict(gray[y: y + h, x: x + w])<br/><br/>if id == 1:<br/>  id = "BEN"<br/>os.system('echo "Hello, welcome to the house BEN"|festival --tts ')<br/>time, sleep(0.2)<br/><br/>else :<br/><br/>  os.system('echo "If you are a delivery agent then please leave the package here"|festival --tts ')<br/>time, sleep(0.2)<br/><br/>os.system('echo "If you are a guest then I'<br/>    m sorry I have to leave I will be back after 7 pm "|festival --tts ')<br/>    time, sleep(0.2)<br/><br/>    os.system('echo "also Kindly don'<br/>      t step over the grass, its freshly grown and needs some time "|festival --tts ')<br/>      time.sleep(1)<br/><br/>      os.system('echo "Thank you !"|festival --tts ') cv2.imshow("face", img) if cv2.waitKey(1) == ord('q'):<br/>      break cam.release()<br/><br/>      cv2.destroyAllWindows()</pre>
<pre>faceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')</pre>
<p>In the preceding code, we are creating a cascade classifier using the method <kbd>CascadeClassifier</kbd> so that faces can be detected by the camera.</p>
<pre>cam = cv2.VideoCapture(0)<br/>rec = cv2.face.LBPHFaceRecognizer_create()</pre>
<p><span>In the preceding code, we are r</span>eading the frames from the camera using <kbd>VideoCapture(0)</kbd> method of <kbd>cv2</kbd>. Also, the face recognizer is being created to recognize a particular face. </p>
<pre> ret, img = cam.read()</pre>
<p>Now read the data from the camera using <kbd>cam.read()</kbd> as done in the previous code. </p>
<pre>gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)<br/>faces = faceDetect.detectMultiScale(gray,1.3,5)</pre>
<p>The images are converted into gray color. Then, <kbd>faceDetect.detectMultiScale()</kbd> will be using the gray color-converted images. </p>
<pre> for (x,y,w,h) in faces:<br/>     cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,255), 2)<br/>     id, conf = rec.predict(gray[y:y+h, x:x+w])<br/>     if id==1:<br/>         id = "BEN" <br/>         os.system('echo "Hello, welcome to my house BEN"|festival --tts ')<br/>         time, sleep(0.2)</pre>
<p>As the face is detected, the part of the image containing the face will be converted into gray and passed to a predict function. This method will tell if the face is known or not, it also returns the ID if the face is identified. Suppose the person is <kbd>BEN</kbd>, then Jarvis would say <kbd>Hello, welcome to my house BEN</kbd>. Now <kbd>BEN</kbd> can tell the Jarvis to turn on the lights, and the Jarvis would respond as the wake word Jarvis gets activated. And if the person is not recognized, then maybe it was a delivery boy. Then, the following commands get executed: </p>
<pre>os.system('echo "If you are a delivery agent then please leave the package here"|festival --tts ')<br/>time, sleep(0.2)<br/><br/>os.system('echo "If you are a guest then I'm sorry I have to leave I will be back after 7pm"|festival --tts ')<br/> time, sleep(0.2)<br/><br/>os.system('echo "also Kindly don't step over the grass, its freshly grown and needs some time"|festival --tts ')<br/>time.sleep(1)<br/><br/>os.system('echo "Thank you !"|festival --tts ')</pre>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Making Jarvis understand our voice</h1>
                </header>
            
            <article>
                
<p>Voice is an essence of communication. It helps us transfer huge amounts of data in a very short period of time. It is certainly faster and easier than typing. Hence, more and more companies are working toward making systems that understands human voice and language and work according to them. It is certainly not easy because of the huge variations that are present in the language; however, we have come a considerable distance. So without much time, let's make our system get ready to recognize our voice. </p>
<div class="container">
<div class="columns">
<div class="column is-8 is-offset-2">
<div>
<div>
<div class="medium-editor-element">
<p>So here, we would be using an API from Google Voice. As you may know, Google is really good at understanding what you say. Like, very literally. So it makes sense to use their API. Now, the way it works is very simple. We capture the voice, and we convert it into the text. Then, we compare if the text is similar to something we have defined in the configuration file. If it matches with anything, the bash command associated with it will be executed. </p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="container">
<div class="columns">
<div class="column is-8 is-offset-2">
<div>
<div>
<div class="medium-editor-element">
<p>First, we need to check whether the microphone is connected. To do that, run the following command:</p>
<pre><strong>lsusb</strong></pre>
<p><span>This command will show you a list of devices connected on USB. If you see yours on the list, then thumbs up, you are on the right track. Otherwise, try finding it with the connection or maybe try another hardware. </span></p>
<p>We also need to set the recording volume to high. To do this, go ahead and type the following command on the serial:</p>
<pre><strong>alsamixer</strong></pre>
<p>Now once the GUI pops on to the screen, toggle the volume using the arrow keys.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="container">
<div class="columns">
<div class="column is-8 is-offset-2">
<div class="medium-editor-element">
<p>It's best to hear the sound recorded by yourself rather than directly giving it down to the Raspberry. To do that first, we need to record our voice, so we need to run the following command:</p>
<pre><strong>arecord -l</strong></pre>
<p>This will check whether the webcam is on the list. Then, write the following command to record:</p>
<pre><strong>arecord -D plughw:1,0 First.wav</strong></pre>
<p>The sound will be recorded with the following name, <kbd>First.wav</kbd>.</p>
<p>Now we would also like to listen to what we just recorded. The simple way to do that is by typing the following command:</p>
<pre><strong>aplay test.wav</strong></pre>
<p>Check whether the voice is correct. If not, then you are free to make any adjustments to the system. </p>
<p>Once we are done with checking the sound and the microphone, it's time to install the real software for the job. There are simple ways with which you can do it. The following is a list of commands that you need to run: </p>
<pre><strong>wget –- no-check-certificate “http://goo.gl/KrwrBa” -O PiAUISuite.tar.gz</strong><br/><br/><strong>tar -xvzf PiAUISuite.tar.gz</strong><br/><br/><strong>cd PiAUISuite/Install/</strong><br/><br/><strong>sudo ./InstallAUISuite.sh</strong></pre>
<div>
<p><span>Now when you run this, very interesting things will start to happen. It will start to ask you various questions. Some of them will be </span>straightforward. You can use your right mind to give the answers to it in the form of yes or no. Others could be very technical. As these questions might change over time, there seems to be no need to explicitly mention the answers that you need to fill, but as a general rule of thumb—Give it a yes unless it's something you really want to say no to. </p>
</div>
<p><span>Perfect then, we have installed the software. Now before you go any further in that software, let's go ahead and write the following programs:</span></p>
</div>
</div>
</div>
</div>
<pre>import RPi.GPIO as GPIO<br/>import time<br/>import os<br/>GPIO.setmode(GPIO.BCM)<br/>LIGHT = 2<br/>GPIO.setup(LIGHT,GPIO.OUT)<br/>GPIO.output(LIGHT, GPIO.HIGH)<br/>os.system('echo "LIGHTS TURNED ON "|festival --tts')</pre>
<p>Whenever this program runs, the light that is connected on PIN number <kbd>2</kbd> will be turned on. Also, it will read out <kbd>LIGHTS TURNED ON</kbd>. Save this file with the name <kbd>lighton.py</kbd>:</p>
<pre>import RPi.GPIO as GPIO<br/>import time<br/>import os<br/>GPIO.setmode(GPIO.BCM)<br/>LIGHT = 23<br/>GPIO.setup(LIGHT,GPIO.OUT)<br/>GPIO.output(LIGHT, GPIO.LOW)<br/>os.system('echo "LIGHTS TURNED OFF "|festival --tts')</pre>
<p><span>Similarly, in this program, the light would be turned off and it would read out <kbd>LIGHTS TURNED OFF</kbd>. Save it by the name</span> <kbd>lightoff.py</kbd>:</p>
<pre>import RPi.GPIO as GPIO<br/>import time<br/>Import os<br/>GPIO.setmode(GPIO.BCM)<br/>FAN = 22<br/>GPIO.setup(FAN,GPIO.OUT)<br/>GPIO.output(LIGHT, GPIO.HIGH)<br/>os.system('echo "FAN TURNED ON "|festival --tts')</pre>
<p><span>Now we are doing the same thing for the fan as well. In this one, the fan will be switched on; save it with the name <kbd>fanon.py</kbd></span>:</p>
<pre>import RPi.GPIO as GPIO<br/>import time<br/>Import os<br/>GPIO.setmode(GPIO.BCM)<br/>FAN = 22<br/>GPIO.setup(FAN,GPIO.OUT)<br/>GPIO.output(LIGHT, GPIO.LOW)os.system('echo "FAN TURNED OFF "|festival --tts')</pre>
<p>I don't need to explain the same thing for this do I? As you will have guessed, save it with the name <kbd>fanoff.py</kbd>.</p>
<p><span>All right! When all of this is done, then type the following command </span><span>to check whether the software is installed properly: </span></p>
<div class="medium-editor-element">
<pre><strong>voicecommand -c</strong> </pre>
<p>Raspberry Pi responds to the wake word <kbd>pi</kbd>; let's change it to <kbd>jarvis</kbd>. All these changes can be made after opening the configuration file using the following command:</p>
<pre><strong>voicecommand -e.</strong> </pre>
<p>In that file, enter the commands of your own. Here, let's add the following code:</p>
<pre>LIGHT_ON<br/><br/>LIGHT_OFF<br/><br/>FAN_ON<br/><br/>FAN_OFF</pre>
<p>Now for each command, define the action. The action would be to run the Python file that contains the code for switching the lights and fan on or off. The code is basic and simple to understand. <span>Add the following to the file:</span></p>
</div>
<pre>LIGHT ON = sudo python lighton.py<br/><br/>LIGHT OFF = sudo python lightoff.py<br/><br/>FAN ON = sudo python fanon.py<br/><br/>FAN OFF = sudo python fanoff.py</pre>
<p>Now, let's see what we have done. Whenever you say <q>Jarvis, light on</q>, it will convert your speed to text, compare it with the program that it has to run corresponding to it and will do whatever is there in the program. Hence, in this program, whenever we say <q>Light on,</q> the lights will be turned on and similarly for the rest of the commands as well. Remember to make it listen to what you are saying. You would have to say the word, <q>Jarvis,</q> which will make it attentive to the commands and ready to listen. </p>


            </article>

            
        </section>
    </div>
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we understood how to interact and make the Jarvis work according to our needs. If this chapter was about verbal communication, then the next chapter is about gesture recognition where, using advanced capacitive techniques, you will be able to control your automation system just by waving at it.</p>
<p> </p>


            </article>

            
        </section>
    </div></body></html>