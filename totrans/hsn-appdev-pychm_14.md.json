["```py\nBirthYear: 1952\nGender: Female\nParkinsons: True\nTremors: True\nDiagnosisYear: 2000\nSided: Left\nUPDRS: Don't know\nImpact: Severe\nLevodopa: True\nDA: True\nMAOB: False\nOther: False\n```", "```py\ngit lfs version\n```", "```py\nsudo apt update\nsudo apt install git-lfs\n```", "```py\ncd ~/\nmkdir git-lfs-test\ncd git-lfs-test\ngit init\n```", "```py\ngit lfs track \"*.txt\"\n```", "```py\ngit add 0EA27ICBLF_1607.txt\ngit commit -m \"adding big file\"\ngit lfs ls-files\n```", "```py\nGit add .gitattributes\nGit commit -m \"Added .gitattributes to repo\"\n```", "```py\nBirthYear: 1952\nGender: Female\nParkinsons: True\nTremors: True\nDiagnosisYear: 2000\nSided: Left\nUPDRS: Don't know\nImpact: Severe\nLevadopa: True\nDA: True\nMAOB: False\nOther: False\n```", "```py\nimport pandas as pd\nimport numpy as np\nimport os\nimport gc\n```", "```py\n#%% Read in data\nuser_file_list = os.listdir('data/Archived users/')\nuser_set_v1 = set(map(lambda x: x[5: 15], user_file_list)) # [5: 15] to return just the user IDs\n```", "```py\ntappy_file_list = os.listdir('data/Tappy Data/')\nuser_set_v2 = set(map(lambda x: x[: 10], tappy_file_list)) # [: 10] to return just the user IDs\n```", "```py\nuser_set = user_set_v1.intersection(user_set_v2)\n```", "```py\nprint(len(user_set))\n```", "```py\n#%% Format into a Pandas dataframe\n```", "```py\ndef read_user_file(file_name):\n  f = open('data/Archived users/' + file_name)\n  data = [line.split(': ')[1][:-1] for line in f.readlines()]\n  f.close()\n  return data\n```", "```py\nBirthYear: 1952\nGender: Female\nParkinsons: True\n```", "```py\nfiles = os.listdir('data/Archived users/')\n```", "```py\ncolumns = [\n  'BirthYear', 'Gender', 'Parkinsons', 'Tremors', 'DiagnosisYear',\n  'Sided', 'UPDRS', 'Impact', 'Levadopa', 'DA', 'MAOB', 'Other'\n]\n```", "```py\nuser_df = pd.DataFrame(columns=columns) # empty Data Frame for now\n```", "```py\nfor user_id in user_set:\n  temp_file_name = 'User_' + user_id + '.txt'\n```", "```py\n  if temp_file_name in files:\n    temp_data = read_user_file(temp_file_name)\n    user_df.loc[user_id] = temp_data\n```", "```py\nprint(user_df.head())\n```", "```py\n#%% Change numeric data into appropriate format\n# force some columns to have numeric data type\nuser_df['BirthYear'] = pd.to_numeric(user_df['BirthYear'], errors='coerce')\nuser_df['DiagnosisYear'] = pd.to_numeric(user_df['DiagnosisYear'], errors='coerce')\n```", "```py\nParkinsons: True\nTremors: True\nLevodopa: True\nDA: True\nMAOB: False\nOther: False\n```", "```py\n#%% \"Binarize\" true-false data\nuser_df = user_df.rename(index=str, columns={'Gender': 'Female'})\nuser_df['Female'] = user_df['Female'] == 'Female'\nuser_df['Female'] = user_df['Female'].astype(int)\n```", "```py\nstr_to_binary_columns = ['Parkinsons', 'Tremors', 'Levadopa', 'DA', 'MAOB', 'Other'] # columns to be converted to binary data\nfor column in str_to_binary_columns:\n  user_df[column] = user_df[column] == 'True'\n  user_df[column] = user_df[column].astype(int)\n```", "```py\n# prior processing for `Impact` column\nuser_df.loc[\n  (user_df['Impact'] != 'Medium') &\n  (user_df['Impact'] != 'Mild') &\n  (user_df['Impact'] != 'Severe'), 'Impact'] = 'None'\n```", "```py\nto_dummy_column_indices = ['Sided', 'UPDRS', 'Impact'] # columns to be one-hot encoded\n```", "```py\nfor column in to_dummy_column_indices:\n  user_df = pd.concat([\n    user_df.iloc[:, : user_df.columns.get_loc(column)],\n    pd.get_dummies(user_df[column], prefix=str(column)),\n    user_df.iloc[:, user_df.columns.get_loc(column) + 1 :]\n  ], axis=1)\nprint(user_df.head())\n```", "```py\n#%% Explore the second dataset\nfile_name = '0EA27ICBLF_1607.txt'\n```", "```py\ndf = pd.read_csv(\n  'data/Tappy Data/' + file_name,\n  delimiter = '\\t',\n  index_col = False,\n  names = ['UserKey', 'Date', 'Timestamp', 'Hand', 'Hold time', 'Direction', 'Latency time', 'Flight time']\n)\n```", "```py\ndf = df.drop('UserKey', axis=1)\nprint(df.head())\n```", "```py\n#%% Format datetime data\n```", "```py\ndf['Date'] = pd.to_datetime(df['Date'], errors='coerce', format='%y%M%d').dt.date\n# converting time data to numeric\nfor column in ['Hold time', 'Latency time', 'Flight time']:\n  df[column] = pd.to_numeric(df[column], errors='coerce')\n```", "```py\ndf = df.dropna(axis=0)\n```", "```py\nprint(df.head())\n```", "```py\n# cleaning data in Hand\ndf = df[\n  (df['Hand'] == 'L') |\n  (df['Hand'] == 'R') |\n  (df['Hand'] == 'S')\n]\n```", "```py\n# cleaning data in Direction\ndf = df[\n  (df['Direction'] == 'LL') |\n  (df['Direction'] == 'LR') |\n  (df['Direction'] == 'LS') |\n  (df['Direction'] == 'RL') |\n  (df['Direction'] == 'RR') |\n  (df['Direction'] == 'RS') |\n  (df['Direction'] == 'SL') |\n  (df['Direction'] == 'SR') |\n  (df['Direction'] == 'SS')\n]\n```", "```py\nprint(df.head())\n```", "```py\n#%% Group by direction (hand transition)\n```", "```py\n direction_grouped_df = df.groupby('Direction')[numeric_columns].mean()\n```", "```py\nprint(direction_grouped_df)\n```", "```py\n#%% Combine into one function\ndef read_tappy(file_name):\n```", "```py\n  df = pd.read_csv(\n    'data/Tappy Data/' + file_name,\n    delimiter='\\t',\n    index_col=False,\n    names=['UserKey', 'Date', 'Timestamp', 'Hand', 'Hold time',\n        'Direction', 'Latency time', 'Flight time']\n  )\n```", "```py\n  df = df.drop('UserKey', axis=1)\n```", "```py\n  df['Date'] = pd.to_datetime(df['Date'], errors='coerce', format='%y%M%d').dt.date\n  # Convert time data to numeric\n  for column in ['Hold time', 'Latency time', 'Flight time']:\n    df[column] = pd.to_numeric(df[column], errors='coerce')\n  df = df.dropna(axis=0)\n```", "```py\n  # Clean data in `Hand`\n  df = df[\n    (df['Hand'] == 'L') |\n    (df['Hand'] == 'R') |\n    (df['Hand'] == 'S')\n    ]\n```", "```py\n  # Clean data in `Direction`\n  df = df[\n    (df['Direction'] == 'LL') |\n    (df['Direction'] == 'LR') |\n    (df['Direction'] == 'LS') |\n    (df['Direction'] == 'RL') |\n    (df['Direction'] == 'RR') |\n    (df['Direction'] == 'RS') |\n    (df['Direction'] == 'SL') |\n    (df['Direction'] == 'SR') |\n    (df['Direction'] == 'SS')\n    ]\n```", "```py\n     direction_group_df = df.groupby('Direction')[numeric_columns][numeric_columns][numeric_columns] direction_group_df = df.groupby('Direction')[numeric_columns].mean()\n  del df\n  gc.collect()\n```", "```py\n  direction_group_df = direction_group_df.reindex(\n    ['LL', 'LR', 'LS', 'RL', 'RR', 'RS', 'SL', 'SR', 'SS'])\n  direction_group_df = direction_group_df.sort_index() # to ensure correct order of data\n```", "```py\n  return direction_group_df.values.flatten()\n```", "```py\ndef process_user(user_id, filenames):\n  running_user_data = np.array([])\n```", "```py\n  for filename in filenames:\n    if user_id in filename:\n      running_user_data = np.append(running_user_data, read_tappy(filename))\n```", "```py\n  running_user_data = np.reshape(running_user_data, (-1, 27))\n```", "```py\n  return np.nanmean(running_user_data, axis=0)\n```", "```py\n#%% Run through all available data\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n```", "```py\nfilenames = os.listdir('data/Tappy Data/')\n```", "```py\ncolumn_names = [first_hand + second_hand + '_' + time\n        for first_hand in ['L', 'R', 'S']\n        for second_hand in ['L', 'R', 'S']\n        for time in ['Hold time', 'Latency time', 'Flight time']]\nuser_tappy_df = pd.DataFrame(columns=column_names)\n```", "```py\nfor user_id in user_df.index:\n  user_tappy_data = process_user(str(user_id), filenames)\n  user_tappy_df.loc[user_id] = user_tappy_data\n```", "```py\nuser_tappy_df = user_tappy_df.fillna(0)\nuser_tappy_df[user_tappy_df < 0] = 0\n```", "```py\nprint(user_tappy_df.head())\n```", "```py\n#%% Save processed data\n```", "```py\ncombined_user_df = pd.concat([user_df, user_tappy_df], axis=1)\nprint(combined_user_df.head())\n```", "```py\ncombined_user_df.to_csv('data/combined_user.csv')\n```", "```py\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncombined_user_df = pd.read_csv('../data/combined_user.csv', index_col=0)\ncombined_user_df.head()\n```", "```py\n#%%\nmissing_data = combined_user_df.isnull().sum()\ng = sns.barplot(x=missing_data.index, y=missing_data)\ng.set_xticklabels(labels=missing_data.index, rotation=90)\nplt.show()\n```", "```py\n#%%\nf, ax = plt.subplots(2, 2, figsize=(20, 10))\nsns.distplot(\ncombined_user_df.loc[combined_user_df['Parkinsons'] == 0,\n'BirthYear'].dropna(axis=0),\nkde_kws = {'label': \"Without Parkinson's\"},\nax = ax[0][0]\n)\nsns.distplot(\ncombined_user_df.loc[combined_user_df['Parkinsons'] == 1,\n'BirthYear'].dropna(axis=0),\nkde_kws = {'label': \"With Parkinson's\"},\nax = ax[0][1]\n)\nsns.countplot(x='Female', hue='Parkinsons', data=combined_user_df, ax=ax[1][0])\nsns.countplot(x='Tremors', hue='Parkinsons', data=combined_user_df, ax=ax[1][1])\nplt.show()\n```", "```py\n#%%\ncolumn_names = [first_hand + second_hand + '_' + time\nfor first_hand in ['L', 'R', 'S']\nfor second_hand in ['L', 'R', 'S']\nfor time in ['Hold time', 'Latency time', 'Flight time']]\nf, ax = plt.subplots(3, 3, figsize=(10, 5))\nplt.subplots_adjust(\nright = 3,\ntop = 3\n)\nfor i in range(9):\ntemp_columns = column_names[3 * i : 3 * i + 3]\nstacked_df = combined_user_df[temp_columns].stack().reset_index()\nstacked_df = stacked_df.rename(\ncolumns={'level_0': 'index', 'level_1': 'Type', 0: 'Time'})\nstacked_df = stacked_df.set_index('index')\nfor index in stacked_df.index:\nstacked_df.loc[index, 'Parkinsons'] = combined_user_df.loc[index,\n'Parkinsons']\nsns.boxplot(x='Type', y='Time',\nhue='Parkinsons',\ndata=stacked_df,\nax=ax[i // 3][i % 3]\n).set_title(column_names[i * 3][: 2], fontsize=20)\nplt.show()\n```", "```py\ncorr_matrix = combined_user_df.corr()\n```", "```py\nf, ax = plt.subplots(1, 1, figsize=(15, 10))\nsns.heatmap(corr_matrix)\nplt.show()\n```", "```py\n#%%\nfrom sklearn.svm import LinearSVC\ncombined_user_df['BirthYear'].fillna(combined_user_df['BirthYear'].mode(dropna=True)[0], inplace=True)\ncombined_user_df['DiagnosisYear'].fillna(combined_user_df['DiagnosisYear'].mode(dropna=True)[0], inplace=True)\nX_train = combined_user_df.drop(['Parkinsons'], axis=1)\ny_train = combined_user_df['Parkinsons']\nclf = LinearSVC()\nclf.fit(X_train, y_train)\nnfeatures = 10\ncoef = clf.coef_.ravel()\ntop_positive_coefs = np.argsort(coef)[-nfeatures :]\ntop_negative_coefs = np.argsort(coef)[: nfeatures]\ntop_coefs = np.hstack([top_negative_coefs, top_positive_coefs])\n```", "```py\nplt.figure(figsize=(15, 5))\ncolors = ['red' if c < 0 else 'blue' for c in coef[top_coefs]]\nplt.bar(np.arange(2 * nfeatures), coef[top_coefs], color=colors)\nfeature_names = np.array(X_train.columns)\n# Make sure the number of tick locations matches the number of tick labels.\nplt.xticks(np.arange(0, 2 * nfeatures), feature_names[top_coefs], rotation=60, ha='right')\nplt.show()\n```"]