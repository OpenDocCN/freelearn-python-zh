- en: Testing Flask Apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout the book, every time that we've made a modification to our application's
    code, we've had to manually load the affected web pages into our browser to test
    if the code was working correctly. As the application grows, this process becomes
    more and more tedious, especially if you change something that is low-level and
    used everywhere, such as SQLAlchemy model code.
  prefs: []
  type: TYPE_NORMAL
- en: In order to automate the process of verifying that our code works the way we
    want it to, we will use a built-in feature of Python that allows us to write tests,
    normally named unit tests or integration tests, which are checked against our
    application's code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn how to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Writing simple tests with Python's unitest library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing security, and validating logins and role based access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing a test for a REST API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing your user interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring test coverage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are unit tests?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing a program is very simple. All it involves is developing code that will
    run particular pieces of your program and specifying what you expect the results
    to be, and then comparing it to what the results from the piece of the program
    actually are. If the results are the same, the test passes. If the results are
    different, the test fails. Typically, these tests are run upon Pull Request creation
    on your CI server, so all the reviewers of the PR can immediately check if the
    requested change breaks something or not.
  prefs: []
  type: TYPE_NORMAL
- en: In program testing, there are three main types of tests. **Unit tests** are
    tests that verify the correctness of individual pieces of code, such as functions.
    Second is **integration testing**, which tests the correctness of various units
    of programs working in tandem. The last type of testing is **end-to-end testing**,
    which tests the correctness of the whole system at once, rather than individual
    pieces. Many other types of testing exist, some of which include load tests, security
    tests, and recovery tests.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will be using unit testing and end-to-end testing in order
    to verify that our code is working as planned.
  prefs: []
  type: TYPE_NORMAL
- en: 'This brings us to some of the first rules of code testing: make sure your tests
    can actually fail, write simple test functions that test only one thing, and make
    your test code easy to read and write.'
  prefs: []
  type: TYPE_NORMAL
- en: How does testing work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start with a very simple Python function for us to test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In order to verify the correctness of this code, we pass a value, and will test
    if the result of the function is what we expect. For example, we could give it
    an input of 5, and would expect the result to be 25.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the concept, we can manually test this function in the command
    line using the `assert` statement. The `assert` statement in Python simply says
    that if the conditional statement after the `assert` keyword returns `False`,
    then it will throw an exception as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Using these `assert` statements, we verified that the square function was working
    as intended.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Unit testing** in Python works by combining `assert` statements into their
    own functions inside a class. This *collection of testing functions* inside the
    class is called a **test case**. Each function inside the test case should test
    only one thing, which is the main idea behind unit testing. Testing only one thing
    in your unit tests forces you to verify each piece of code individually, and not
    gloss over any of the functionality of your code. If you write your unit tests
    correctly, you will end up with lots and lots of them. While this may seem overly
    verbose, it will save you from headaches further down the road.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this configuration, we will use SQLLite in the memory engine database, which
    allows us to guarantee that the tests will not interfere with our actual database.
    Also, the configuration disables WTForms'' CSRF checks, to allow us to submit
    forms from the tests without the CSRF token:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Testing the route functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's build our first test case. In this test case, we will be testing if the
    route functions successfully return a response when we access its URL. In a new
    directory named `tests`, at the root of the project directory, create a new file
    named `test_urls.py`, which will hold all of the unit tests for the routes. Each
    test case should have its own file, and each test case should focus on one area
    of the code that you are testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `test_urls.py`, let''s start creating what the built-in Python `unittest`
    library needs. The code will use the `unittest` library from Python in order to
    run all the tests that we create in the test case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see what happens when this code is run. We will use the `unittest` library''s
    ability to automatically find our test cases to run the tests. The pattern that
    the `unittest` library looks for is `test*.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Because there are no tests in the test case, the test case passed successfully.
  prefs: []
  type: TYPE_NORMAL
- en: The test script was run from the parent directory of the script, and not in
    the test folder itself. This is to allow imports of the application code inside
    the test scripts.
  prefs: []
  type: TYPE_NORMAL
- en: In order to test the URLs, we need to have a way to query the application's
    routes without actually running a server, so our requests are returned. Flask
    provides a way of accessing routes in tests, called the *test client*. The test
    client gives methods to create HTTP requests on our routes, without having to
    actually run the application with `app.run()`.
  prefs: []
  type: TYPE_NORMAL
- en: We will need the test client object for each of the tests in this test case,
    but adding in code to each `unittest` to create the test client doesn't make much
    sense when we have the `setUp` method. The `setUp` method is run before each unit
    test, and can attach variables to itself in order for the test method to access
    them. In our `setUp` method, we need to create the application object with our
    `TestConfig` object and create the test client.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, there are three bugs that we need to work around. The first two are in
    the Flask Admin and Flask Restful extensions, which do not remove the Blueprint
    objects stored internally when the application object they are applied to is destroyed.
    Third, Flask SQLAlchemy''s initializer doesn''t correctly add the application
    object while outside the `webapp` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: All of the bugs listed here existed at the time of writing, but may no longer
    exist when you read this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along with the `setUp` method, there is also the `tearDown` method, which is
    run every time a unit test ends. The `tearDown` method''s goal is to destroy any
    objects, created in the `setUp` method, that cannot automatically be deleted or
    closed. In our case, we will use the `tearDown` method to close and remove our
    database sessions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can create our first unit test. The first test will test whether accessing
    the root of our application returns a `302 redirect` code to the blog home page,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Each unit test must start with the word `test` to tell the `unittest` library
    that the function is a unit test, and not just some utility function inside the
    test case class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if we run the tests again, we can see its progress and how it passes the
    checks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The best way to write tests is to ask yourself what you are looking for ahead
    of time, write the `assert` statements, and write the code needed to execute those
    asserts. This forces you to ask what you are really testing, before you actually
    start writing the test. It's also the practice to write a Python doc string for
    each unit test, as it will be printed with the name of the test whenever the test
    fails. After you write 50 or more tests, this can be very helpful to know exactly
    what the test is for.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than using the built-in `assert` keyword from Python, we can use some
    of the methods provided by the `unittest` library. These methods provide specialized
    error messages and debug information when the `assert` statements inside these
    functions fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a list of all of the special `assert` statements given by
    the `unittest` library and what they do:'
  prefs: []
  type: TYPE_NORMAL
- en: '`assertEqual(x, y)`: Asserts that `x == y`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertNotEqual(x, y)`: Asserts that `x != y`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertTrue(x)`: Asserts that `x` is `True`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertFalse(x)`: Asserts that `x` is `False`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertIs(x, y)`: Asserts that `x` is `y`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertIsNot(x, y)`: Asserts that `x` is not `y`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertIsNone(x)`: Asserts that `x` is `None`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertIsNotNone(x)`: Asserts that `x` is not `None`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertIn(x, y)`: Asserts that `y` contains `x`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertNotIn(x, y)`: Asserts that `x` is not in `y`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertIsInstance(x, y)`: Asserts that `isinstance(x, y)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assertNotIsInstance(x, y)`: Asserts not `isinstance(x, y)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we wanted to test the return value of a normal page, the unit test would
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Remember that the preceding code only tests if the URLs give returns successfully.
    The content of the return data is not a part of these tests.
  prefs: []
  type: TYPE_NORMAL
- en: Testing security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing security is obviously very important—if you expose your application
    to the web, you can be sure that your security will be heavily tested, and not
    for the right reasons. All of your secured endpoints will be tested and exploited
    if not correctly secured. First of all, we should test our login and logout processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we wanted to test submitting a form, such as the login form, we can use
    the post method of the test client. Let''s create a `test_login` method to see
    if the login form works correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The additional check for the string in the return data exists because the return
    code is not affected by the validity of the entered data. The `post` method will
    work for testing any of the form objects we have created throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create a failed login attempt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding snippet, we make sure that a login attempt with failed credentials
    does not give the user a successful login, and in the same test, we also make
    sure that a failed login will not give the user sufficient access to add a new
    blog post. This may seem trivial, and it is easy to implement, but as previously
    stated, you should make each test simple, and only test one thing with each test,
    but aim to cover all your features and possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example of an important test covers unauthorized access from a logged-in
    user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we make sure that a low-privileged user does not have access to an high
    privilege area of our application: the admin interface.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing the REST API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Still in the context of security, we will now learn how to test our REST API.
    Remember that we have implemented JWT security, so for each request, we need to
    use a previously acquired access token.
  prefs: []
  type: TYPE_NORMAL
- en: 'JWT authentication tests should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Some important details to note here include the way we set our HTTP header to
    JSON, and how we pass the JSON payload on the HTTP POST method—this will happen
    on all our REST API tests.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's see how to develop a test for the new post REST API. `/api/post` is
    the endpoint for blog posts, and the POST HTTP method is the method for adding
    a new post to the Blog application. Revisit [Chapter 8](e6143102-d0e2-4134-a6db-28fb38643ea7.xhtml), *Building
    RESTful APIs* if this is not clear.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, this is a simple test to develop—notice the way that we request
    an access token from our authentication JWT API using the `/auth/api` endpoint,
    and how we use it to make the call to `/api/post`. has expected the access token
    is used to construct the HTTP authorization header using the form `Authorization:
    Bearer <ACCESS_TOKEN>`. This can be a bit cumbersome to repeat on each API test,
    so make sure to write a helper function to keep your code "DRY"—that is, "Don''t
    Repeat Yourself".'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you understand the mechanics of unit testing, you can use unit testing
    in order to test all the parts of your application. This can include testing all
    the routes in the application; testing any utility function that we have made,
    such as `sidebar_data`; and testing all possible combinations of roles and access
    protected pages.
  prefs: []
  type: TYPE_NORMAL
- en: If your application's code has a feature, no matter how small, you should have
    a test for it. Why? Because whatever can go wrong, will go wrong. If the validity
    of your application's code relies entirely on manual testing, then something is
    going to get overlooked as your app grows. When something gets overlooked, then
    broken code is deployed to live servers, which annoys your users.
  prefs: []
  type: TYPE_NORMAL
- en: User interface testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to test the high level of our application's code and to create system
    tests, we will write tests that work with browsers, and verify that the UI code
    is functioning properly. Using a tool called Selenium, we will create Python code
    that hooks into a browser and controls it purely from code. This works by finding
    elements on the screen, and then performing actions on those elements through
    Selenium. Click on it or input keystrokes. Also, Selenium allows you to perform
    checks on the page content by giving you access to the elements' content, such
    as their attributes and inner text. For more advanced checks, Selenium even has
    an interface which can run arbitrary JavaScript on the page. If the JavaScript
    returns a value, it is automatically converted into a Python type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we touch the code, Selenium needs to be installed. Make sure you have
    your virtualenv activated, and that Selenium is included in the `requirements.txt` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'To begin with the code, our UI tests need a file of their own in the `tests`
    directory, named `test_ui.py`. Because system tests do not test one specific thing,
    the best way to write user interface tests is to think of the test as going through
    a typical user''s flow. Before you write the test itself, write down the specific
    steps that our fake user is going to simulate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we know exactly what our test is going to do, let''s start adding
    in the Selenium code. In the `setUp` and `tearDown` methods, we need code to start
    up a web browser that will Selenium control, and then close it when the test is
    over:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This code spawns a new Firefox window with Selenium controlling it. For this
    to work, of course, you need Firefox installed on your computer. Selenium does
    have support for other browsers, but using others requires an extra program in
    order for it to work correctly. Firefox thus has the best support out of all the
    browsers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we write the code for the test, let''s explore the Selenium API as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: These are the main functions from Selenium that we will be using, but there
    are many other ways to find and interact with elements on the web page.
  prefs: []
  type: TYPE_NORMAL
- en: For the full list of available features, refer to the Selenium-Python documentation
    at [http://selenium-python.readthedocs.org](http://selenium-python.readthedocs.org).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two gotchas in Selenium that need to be kept in mind while writing
    your tests, or you will run into very odd bugs that are almost impossible to debug
    from their error messages:'
  prefs: []
  type: TYPE_NORMAL
- en: Selenium is designed to work as if there is an actual person controlling the
    browser. This means that, if an element cannot be seen on the page, Selenium cannot
    interact with it. For example, if an element covers another element that you wish
    to click on—say, a modal window is in front of a button—then the button cannot
    be pushed. If the element's CSS has its display set to `none`, or its visibility
    set to `hidden`, the results will be the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of the variables that point toward elements on the screen are stored as
    pointers to those elements in the browser, meaning they are not stored in Python's
    memory. If the page changes without using the `get` method, such as when a link
    is clicked and a new element pointer is created, then the test will crash. This
    happens because the driver will continuously be looking for the elements on the
    previous page, and not finding them on the new one. The `get` method of the driver
    clears out all those references.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the preceding tests, we used the test client in order to simulate a request
    to the application object. However, because we are now using something that needs
    to directly interface with the application through a web browser, we need an actual
    server to be running. This server needs to be run in a separate Terminal window
    before the user interface tests are run, so that the latter have something to
    request. To do this, we need a separate Python file in order to run the server
    with our test configuration, as well as needing to set up some models for our
    UI tests to use. At the root of the project directory, in a new file named `run_test_server.py`,
    add the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have both the test server script and some knowledge of Selenium''s
    API, we can finally write the code for our test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Most of this test uses the methods that we introduced earlier. However, there
    is a new method in this test, named `switch_to`. The `switch_to` method is the
    context of the driver that allows the selection of elements inside an `iframe`
    element. Normally, it's impossible for the parent window to select any elements
    inside an `iframe` element using JavaScript, but because we are directly interfacing
    with the browser itself, we can access an `iframe` element's contents. We need
    to switch contacts like these, because the WYSIWYG editor inside the post creation
    page uses `iframe` in order to create itself. After we are done with selecting
    elements within the `iframe`, we need to switch back to the parent context using
    the `parent_frame` method.
  prefs: []
  type: TYPE_NORMAL
- en: You now have the tools that you need to completely test both your server code
    and your user interface code. For the rest of the chapter, we will focus on tools
    and methodologies, in order to make your testing even more effective in ensuring
    your application's correctness.
  prefs: []
  type: TYPE_NORMAL
- en: Test coverage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that our tests have been written, we have to know whether our code is sufficiently
    tested. The concept of **test coverage**, also known as **code coverage**, was
    invented to solve this issue. In any project, the test coverage represents what
    percentage of the code in the project was executed when the tests were run, and
    which lines were never run. This gives an idea of what parts of the project aren''t
    being tested by our unit tests. To add coverage reports to our project, install
    the coverage library with `pip`, and make sure it''s included in the `requirements.txt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The coverage library can be run as a command-line program that will run your
    test suite, and take its measurements while the tests are running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The `--source` flag tells `coverage` to only report on the test coverage for
    the files in the `webapp` directory. If that weren't included, the percentages
    for all the libraries used in the app would be included as well. By default, if
    any code in an `if` statement is executed, the entire `if` statement is said to
    have executed. The `--branch` flag tells `coverage` to disable this, and measure
    everything.
  prefs: []
  type: TYPE_NORMAL
- en: 'After `coverage` runs our tests and takes its measurements, we can see a report
    of its findings in two ways. The first is to see a printout of each file''s coverage
    percentage on the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The second way to see the report is to use the HTML generating ability of `coverage`
    to see a detailed breakdown of each file in the browser, using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command creates a directory named `htmlcov`. When the `index.html`
    file is opened in the browser, each file name can be clicked on to reveal the
    breakdown of which lines were run, and which were not, during the tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6e4f6711-c002-4e0a-a7b0-5fbff0adb5a4.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot, the `blog/controllers.py` file was opened, and
    the coverage report clearly shows that the post route was never executed. However,
    this also gives some false negatives. As the user interface tests are not testing
    code that is being run by the coverage program, it doesn't count toward our coverage
    report. In order to fix this, just to make sure that you have tests in your test
    cases for each individual function that would have been tested in the user interface
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: In most projects, the percentage to aim for is around 90% code coverage. It's
    very rare that a project will have 100% of its code testable, and this possibility
    decreases as the size of the project increases.
  prefs: []
  type: TYPE_NORMAL
- en: Test-driven development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have our tests written, how can they be integrated into the development
    process? Currently, we are using our tests in order to ensure code correctness
    after we create a feature. But, what if we flipped the order and used tests in
    order to create correct code from the beginning? This is what **test-driven development**
    (**TDD**) advocates.
  prefs: []
  type: TYPE_NORMAL
- en: 'TDD follows a simple loop to write the code of a new feature in your application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/55a76ee5-c1da-4c76-adc3-4a1af6308ab1.png)'
  prefs: []
  type: TYPE_IMG
- en: In a project that uses TDD, the first thing that you write, before any of the
    code that controls what you are actually building, is the tests. What this forces
    the programmers on the project to do is to plan out the project's scope, design,
    and requirements before writing any code. While designing APIs, it also forces
    the programmer to design the interface (or contract) of the API from a consumer's
    perspective, rather than design the interface after all the backend code has been
    written.
  prefs: []
  type: TYPE_NORMAL
- en: In TDD, tests are designed to fail the first time that you run them. There is
    a saying in TDD, that if your tests don't fail the first time that you run them,
    you're not really testing anything. What this means is that you are most likely
    testing to the tested unit's function, rather than how it should function while
    writing tests after the fact.
  prefs: []
  type: TYPE_NORMAL
- en: After your tests fail the first time, you then continuously write code until
    all the tests pass. This process is repeated for each new feature.
  prefs: []
  type: TYPE_NORMAL
- en: Once all of the original tests pass and the code is refactored, TDD tells you
    to stop writing code. By only writing code until the tests pass, TDD also enforces
    the **You Aren't Going To Need It** (**YAGNI**) philosophy, which states that
    programmers should only implement what they actually need, rather than what they
    perceive they will need. A huge amount of wasted effort is made during development
    when programmers try to preemptively add functionality when no-one needed it.
  prefs: []
  type: TYPE_NORMAL
- en: TDD also promotes the idea of **Keep It Simple, Stupid** (**KISS**), which dictates
    that simplicity should be a design goal from the beginning. TDD promotes KISS
    because it requires small, testable units of code that can be separated from each
    other and don't rely on a shared global state.
  prefs: []
  type: TYPE_NORMAL
- en: Also, in projects that follow TDD, there is an always-current documentation
    throughout the tests. One of the axioms of programming is that with any sufficiently
    large program, the documentation will always be out of date. This is because the
    documentation is one of the last things on the mind of the programmer when they
    are changing the code. However, with tests, there are clear examples of each piece
    of functionality in the project (if the project has a large code coverage percentage).
    The tests are updated all the time, and therefore, show good examples of how the
    functions and API of the program should work.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you understand Flask's functionality and how to write tests for Flask,
    the next project that you create in Flask can be made entirely with TDD.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you understand testing and what it can do for your application, you
    can create applications that are guaranteed to be less bug-ridden. You will spend
    less time fixing bugs, and more time adding features that are requested by your
    users.
  prefs: []
  type: TYPE_NORMAL
- en: As a final challenge to the reader, before moving onto the next chapter, try
    to get your code coverage over 95%.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will finish the book by going over the ways by which
    you can deploy your application into a production environment on a server.
  prefs: []
  type: TYPE_NORMAL
