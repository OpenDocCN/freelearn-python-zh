- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performance Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we covered concurrency and asynchronous patterns, useful
    for writing efficient software that can handle multiple tasks at once. Next, we
    are going to discuss specific performance patterns that help enhance the speed
    and resource utilization of applications.
  prefs: []
  type: TYPE_NORMAL
- en: Performance patterns address common bottlenecks and optimization challenges,
    providing developers with proven methodologies to improve execution time, reduce
    memory usage, and scale effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The Cache-Aside pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Memoization pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Lazy Loading pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'See the requirements presented in [*Chapter 1*](B21896_01.xhtml#_idTextAnchor017).
    The additional technical requirements for the code discussed in this chapter are
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the `Faker` module to your Python environment using the following command:
    `python -m pip` `install faker`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Add the `Redis` module to your Python environment using the following command:
    `python -m pip` `install redis`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Install the Redis server and run it using Docker: `docker run --name myredis
    -p` `6379:6379 redis`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If needed, follow the documentation at [https://redis.io/docs/latest/](https://redis.io/docs/latest/)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The Cache-Aside pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In situations where data is more frequently read than updated, applications
    use a cache to optimize repeated access to information stored in a database or
    data store. In some systems, that type of caching mechanism is built in and works
    automatically. When this is not the case, we must implement it in the application
    ourselves, using a caching strategy that is suitable for the particular use case.
  prefs: []
  type: TYPE_NORMAL
- en: One such strategy is called **Cache-Aside**, where, to improve performance,
    we store frequently accessed data in a cache, reducing the need to fetch data
    from the data store repeatedly.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can cite the following examples in the software realm:'
  prefs: []
  type: TYPE_NORMAL
- en: Memcached is commonly used as a cache server. It is a popular in-memory key-value
    store for small chunks of data from the results of database calls, API calls,
    or HTML page content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redis is another server solution that is used for cache. Nowadays, it is my
    go-to server for caching or application in-memory storage use cases where it shines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon’s ElastiCache, according to the documentation site ([https://docs.aws.amazon.com/elasticache/](https://docs.aws.amazon.com/elasticache/)),
    is a web service that makes it easy to set up, manage, and scale a distributed
    in-memory data store or cache environment in the cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cases for the cache-aside pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The cache-aside pattern is useful when we need to reduce the database load in
    our application. By caching frequently accessed data, fewer queries are sent to
    the database. It also helps improve application responsiveness, since cached data
    can be retrieved faster.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this pattern works for data that doesn’t change often and for data
    storage that doesn’t depend on the consistency of a set of entries in the storage
    (multiple keys). For example, it might work for certain kinds of document stores
    or databases where keys are never updated and occasionally data entries are deleted
    but there is no strong requirement to continue to serve them for some time (until
    the cache is refreshed).
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the cache-aside pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can summarize the steps needed when implementing the Cache-Aside pattern,
    involving a database and a cache, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 1 – When we want to fetch a data item**: Return the item from the cache
    if found in it. If not found in the cache, read the data from the database. Put
    the item we got in the cache and return it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Case 2 – When we want to update a data item**: Write the item in the database
    and remove the corresponding entry from the cache.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s try a simple implementation with a database of quotes from which the user
    can ask to retrieve some quotes via an application. Our focus here will be implementing
    the *Case* *1* part.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are our choices for the additional software dependencies we need to install
    on the machine for this implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: An SQLite database, since we can query an SQLite database using Python’s standard
    module, `sqlite3`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Redis server and the `redis-py` Python module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use a script (in the `ch08/cache_aside/populate_db.py` file) to handle
    the creation of a database and a `quotes` table and add example data to it. For
    practical reasons, we also use the `Faker` module there to generate fake quotes
    that are used when populating the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our code starts with the imports we need, followed by the creation of the Faker
    instance that we will use to generate fake quotes, as well as some constants or
    module-level variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we write a function to take care of the database setup part, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define a central function that takes care of adding a set of new quotes
    based on a list of sentences or text snippets. Among different things, we associate
    a quote identifier to the quote, for the `id` column in the database table. To
    make things easier, we just pick a number randomly using `quote_id = randint(1,
    100)`. The `add_quotes()` function is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we add a `main()` function, which in fact will have several parts; we
    want to use command-line argument parsing. Note the following:'
  prefs: []
  type: TYPE_NORMAL
- en: If we pass the `init` argument, we call the `setup_db()` function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we pass the `update_all` argument, we inject the quotes into the database
    and add them to the cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we pass the `update_db_only` argument, we only inject the quotes into the
    database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code of the `main()` function, called when running the Python script, is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: That part is done. Now, we will create another module and script for the cache-aside-related
    operations themselves (in the `ch08/cache_aside/cache_aside.py` file).
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a few imports needed here too, followed by constants:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define a `get_quote()` function to fetch a quote by its identifier.
    If we do not find the quote in the cache, we query the database to get it and
    we put the result in the cache before returning it. The function is defined as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, in the main part of the script, we ask for user input of a quote identifier,
    and we call `get_quote()` to fetch the quote. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now is the time to test our scripts, using the following steps.
  prefs: []
  type: TYPE_NORMAL
- en: First, by calling `python ch08/cache_aside/populate_db.py`, and choosing `"init"`
    for the mode option, we can see that a `quotes.sqlite3` file is created (in the
    `ch08/cache_aside/` folder), so we can conclude the database has been created
    and a `quotes` table created in it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we call `python ch08/cache_aside/populate_db.py` and pass the `update_all`
    mode; we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Choose your mode! Enter ''init'' or ''update_db_only'' or ''update_all'': update_db_only'
  prefs: []
  type: TYPE_NORMAL
- en: 'New (fake) quotes added to the database ONLY:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Added to DB: (73, ''Whose determine group what site.'')'
  prefs: []
  type: TYPE_NORMAL
- en: 'Added to DB: (77, ''Standard much career either will when chance.'')'
  prefs: []
  type: TYPE_NORMAL
- en: 'Added to DB: (5, ''Nature when event appear yeah.'')'
  prefs: []
  type: TYPE_NORMAL
- en: 'Added to DB: (81, ''By himself in treat.'')'
  prefs: []
  type: TYPE_NORMAL
- en: 'Added to DB: (88, ''Establish deal sometimes stage college everybody close
    thank.'')'
  prefs: []
  type: TYPE_NORMAL
- en: 'Added to DB: (99, ''Room recently authority station relationship our knowledge
    occur.'')'
  prefs: []
  type: TYPE_NORMAL
- en: 'Added to DB: (63, ''Price who a crime garden doctor eat.'')'
  prefs: []
  type: TYPE_NORMAL
- en: 'Added to DB: (43, ''Significant hot those think heart shake ago.'')'
  prefs: []
  type: TYPE_NORMAL
- en: 'Added to DB: (80, ''Understand and view happy.'')'
  prefs: []
  type: TYPE_NORMAL
- en: 'python ch08/cache_aside/cache_aside.py command, and we are asked for an input
    to try to fetch the matching quote. Here are the different outputs I got depending
    on the values I provided:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: So, each time I entered an identifier number that matched a quote stored only
    in the database (as shown by the previous output), the specific output showed
    that the data was obtained from the database first, before being returned from
    the cache (where it was immediately added).
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: We can see that things work as expected. The update part of the cache-aside
    implementation (to write the item in the database and remove the corresponding
    entry from the cache) is left to you to try. You could add an `update_quote()`
    function used to update a quote when you pass `quote_id` to it and call it using
    the right command line (such as `python` `cache_aside.py update`).
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: The Memoization pattern
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: The **Memoization** pattern is a crucial optimization technique in software
    development that improves the efficiency of programs by caching the results of
    expensive function calls. This approach ensures that if a function is called with
    the same inputs more than once, the cached result is returned, eliminating the
    need for repetitive and costly computations.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Real-world examples
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: We can think of calculating Fibonacci numbers as a classic example of the memoization
    pattern. By storing previously computed values of the sequence, the algorithm
    avoids recalculating them, which drastically speeds up the computation of higher
    numbers in the sequence.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Another example is a text search algorithm. In applications dealing with large
    volumes of text, such as search engines or document analysis tools, caching the
    results of previous searches means that identical queries can return instant results,
    significantly improving user experience.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Use cases for the memoization pattern
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The memoization pattern can be useful for the following use cases:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Speeding up recursive algorithms**: Memoization transforms recursive algorithms
    from having a high time complexity. This is particularly beneficial for algorithms
    such as those calculating Fibonacci numbers.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reducing computational overhead**: Memoization conserves CPU resources by
    avoiding unnecessary recalculations. This is crucial in resource-constrained environments
    or when dealing with high-volume data processing.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Improving application performance**: The direct result of memoization is
    a noticeable improvement in application performance, making applications feel
    more responsive and efficient from the user’s perspective.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Implementing the memoization pattern
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s discuss an implementation of the memoization pattern using Python’s `functools.lru_cache`
    decorator. This tool is particularly effective for functions with expensive computations
    that are called repeatedly with the same arguments. By caching the results, subsequent
    calls with the same arguments retrieve the result from the cache, significantly
    reducing execution time.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For our example, we will apply memoization to a classic problem where a recursive
    algorithm is used: calculating Fibonacci numbers.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We start with the `import` statements we need:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Second, we create a `fibonacci_func1` function that does the Fibonacci numbers
    computation using recursion (without any caching involved). We will use this for
    comparison:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Third, we define a `fibonacci_func2` function, with the same code, but this
    one is decorated with `lru_cache`, to enable memoization. What happens here is
    that the results of the function calls are stored in a cache in memory, and repeated
    calls with the same arguments fetch results directly from the cache rather than
    executing the function’s code. The code is as follows:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we create a `main()` function to test calling both functions using
    `n=30` as input and measuring the time spent for each execution. The testing code
    is as follows:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To test the implementation, run the following command: `python ch08/memoization.py`.
    You should get an output like the following one:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Of course, the durations you get would probably be different than mine, but
    the duration for the second function, the one using caching, should be less than
    the one for the function without caching. Also, the difference between both durations
    should be important.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: This was a demonstration that memoization reduces the number of recursive calls
    needed to calculate Fibonacci numbers, especially for large `n` values. By reducing
    the computational overhead, memoization not only speeds up calculations but also
    conserves system resources, leading to a more efficient and responsive application.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: The Lazy Loading pattern
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: The **Lazy Loading** pattern is a critical design approach in software engineering,
    particularly useful in optimizing performance and resource management. The idea
    with lazy loading is to defer the initialization or loading of resources to the
    moment they are really needed. This way, applications can achieve more efficient
    resource utilization, reduce initial load times, and enhance the overall user
    experience.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Real-world examples
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Browsing an online art gallery provides a first example. Instead of waiting
    for hundreds of high-resolution images to load upfront, the website loads only
    images currently in view. As you scroll, additional images load seamlessly, enhancing
    your browsing experience without overwhelming your device’s memory or network
    bandwidth.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Another example is an on-demand video streaming service, such as Netflix or
    YouTube. Such a platform offers an uninterrupted viewing experience by loading
    videos in chunks. This approach not only minimizes buffering times at the start
    but also adapts to changing network conditions, ensuring consistent video quality
    with minimal interruptions.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: In applications such as Microsoft Excel or Google Sheets, working with large
    datasets can be resource-intensive. Lazy loading allows these applications to
    load only data relevant to your current view or operation, such as a particular
    sheet or a range of cells. This significantly speeds up operations and reduces
    memory usage.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Use cases for the lazy loading pattern
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can think of the following performance-related use cases for the lazy loading
    pattern:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Reducing initial load time**: This is particularly beneficial in web development,
    where a shorter load time can translate into improved user engagement and retention
    rates.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Conserving system resources**: In an era of diverse devices, from high-end
    desktops to entry-level smartphones, optimizing resource usage is crucial for
    delivering a uniform user experience across all platforms.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Enhancing user experience**: Users expect fast, responsive interactions with
    software. Lazy loading contributes to this by minimizing waiting times and making
    applications feel more responsive.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Implementing the lazy loading pattern – lazy attribute loading
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Consider an application that performs complex data analysis or generates sophisticated
    visualizations based on user input. The computation behind this is resource-intensive
    and time-consuming. Implementing lazy loading, in this case, can drastically improve
    performance. But for demonstration purposes, we will be less ambitious than the
    complex data analysis application scenario. We will use a function that simulates
    an expensive computation and returns a value used for an attribute on a class.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: For this lazy loading example, the idea is to have a class that initializes
    an attribute only when it’s accessed for the first time. This approach is commonly
    used in scenarios where initializing an attribute is resource-intensive, and you
    want to postpone this process until it’s necessary.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We start with the initialization part of the `LazyLoadedData` class, where
    we set the `_data` attribute to `None`. Here, the expensive data hasn’t been loaded
    yet:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We add a `data()` method, decorated with `@property`, making it act like an
    attribute (a property) with the added logic for lazy loading. Here, we check if
    `_data` is `None`. If it is, we call the `load_data()` method:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We add the `load_data()` method simulating an expensive operation, using `sum(i
    * i for i in range(100000))`. In a real-world scenario, this could involve fetching
    data from a remote database, performing a complex calculation, or other resource-intensive
    tasks:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We then add a `main()` function to test the implementation. We create an instance
    of the `LazyLoadedData` class and access the `_data` attribute twice:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'To test the implementation, run the `python ch08/lazy_loading/lazy_attribute_loading.py`
    command. You should get the following output:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: import time
  prefs: []
  type: TYPE_NORMAL
- en: from datetime import timedelta
  prefs: []
  type: TYPE_NORMAL
- en: from functools import lru_cache
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'def recursive_factorial(n):'
  prefs: []
  type: TYPE_NORMAL
- en: '"""Calculate factorial (expensive for large n)"""'
  prefs: []
  type: TYPE_NORMAL
- en: 'if n == 1:'
  prefs: []
  type: TYPE_NORMAL
- en: return 1
  prefs: []
  type: TYPE_NORMAL
- en: 'else:'
  prefs: []
  type: TYPE_NORMAL
- en: return n * recursive_factorial(n - 1)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '@lru_cache(maxsize=128)'
  prefs: []
  type: TYPE_NORMAL
- en: 'def cached_factorial(n):'
  prefs: []
  type: TYPE_NORMAL
- en: return recursive_factorial(n)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'def main():'
  prefs: []
  type: TYPE_NORMAL
- en: '# Testing the performance'
  prefs: []
  type: TYPE_NORMAL
- en: n = 20
  prefs: []
  type: TYPE_NORMAL
- en: '# Without caching'
  prefs: []
  type: TYPE_NORMAL
- en: start_time = time.time()
  prefs: []
  type: TYPE_NORMAL
- en: 'print(f"Recursive factorial of {n}: {recursive_factorial(n)}")'
  prefs: []
  type: TYPE_NORMAL
- en: duration = timedelta(time.time() - start_time)
  prefs: []
  type: TYPE_NORMAL
- en: 'print(f"Calculation time without caching: {duration}.")'
  prefs: []
  type: TYPE_NORMAL
- en: '# With caching'
  prefs: []
  type: TYPE_NORMAL
- en: start_time = time.time()
  prefs: []
  type: TYPE_NORMAL
- en: 'print(f"Cached factorial of {n}: {cached_factorial(n)}")'
  prefs: []
  type: TYPE_NORMAL
- en: duration = timedelta(time.time() - start_time)
  prefs: []
  type: TYPE_NORMAL
- en: 'print(f"Calculation time with caching: {duration}.")'
  prefs: []
  type: TYPE_NORMAL
- en: start_time = time.time()
  prefs: []
  type: TYPE_NORMAL
- en: 'print(f"Cached factorial of {n}, repeated: {cached_factorial(n)}")'
  prefs: []
  type: TYPE_NORMAL
- en: duration = timedelta(time.time() - start_time)
  prefs: []
  type: TYPE_NORMAL
- en: 'print(f"Second calculation time with caching: {duration}.")'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Recursive factorial of 20: 2432902008176640000'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculation time without caching: 0:00:04.840851'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cached factorial of 20: 2432902008176640000'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculation time with caching: 0:00:00.865173'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cached factorial of 20, repeated: 2432902008176640000'
  prefs: []
  type: TYPE_NORMAL
- en: 'Second calculation time with caching: 0:00:00.350189'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
