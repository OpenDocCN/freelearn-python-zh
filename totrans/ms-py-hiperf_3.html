<html><head></head><body><div class="chapter" title="Chapter&#xA0;3.&#xA0;Going Visual &#x2013; GUIs to Help Understand Profiler Output"><div class="titlepage"><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Going Visual – GUIs to Help Understand Profiler Output</h1></div></div></div><p>Although we already covered profiling in the previous chapter, the process we went through was like walking in the dark, or at least, in a place with very little light. We kept looking at numbers. Basically, we kept trying to decrease the number of hits, number of seconds, or other similar numbers. However, it was hard to understand how those numbers related to each other based on the representation we had of them.</p><p>We couldn't easily see the big blueprint of our system, based off of that output. If our systems would've been even bigger, seeing that blueprint would've been even harder.</p><p>Simply because we're human beings and not computers ourselves, we work better when we have some sort of visual aid. In this particular case, our work would benefit if we could better understand how everything is related. To do this, we have tools that provide visual representations of the numbers we saw in the previous chapter. These tools will provide us with much needed help. In turn, we'll be able to locate and fix the bottlenecks of our systems much faster. As an added bonus, we'll have a better understanding of our system.</p><p>In this chapter, we'll cover two tools that fall into this category:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>KCacheGrind / pyprof2calltree</strong></span>: This combo will provide the ability to transform the output of <code class="literal">cProfile</code> into the format required by KCacheGrind, which in turn will help us visualize the information.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>RunSnakeRun</strong></span> (<a class="ulink" href="http://www.vrplumber.com/programming/runsnakerun/">http://www.vrplumber.com/programming/runsnakerun/</a>): This tool will also allow<a id="id163" class="indexterm"/> us to visualize and analyze the output from <a id="id164" class="indexterm"/><code class="literal">cProfile</code>. It provides square maps and sortable lists to help us in our task.</li></ul></div><p>For each one, we'll go over the basics of installation and UI explanation. Then, we'll grab the examples from <a class="link" href="ch02.html" title="Chapter 2. The Profilers">Chapter 2</a>, <span class="emphasis"><em>The Profilers</em></span>, and reanalyze them based on the output from these tools.</p><div class="section" title="KCacheGrind – pyprof2calltree"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec19"/>KCacheGrind – pyprof2calltree</h1></div></div></div><p>The first GUI tool <a id="id165" class="indexterm"/>we will see is KCacheGrind. It is a data visualization tool designed to parse and display different formats of profiling data. For our case, we will display the output from <code class="literal">cProfile</code>. However, to do this, we'll also need the help from the<a id="id166" class="indexterm"/> command-line tool called <code class="literal">pyprof2calltree</code>.</p><p>This tool is a rebranding <a id="id167" class="indexterm"/>of a very popular one called <code class="literal">lsprofcalltree.py</code> (<a class="ulink" href="https://people.gnome.org/~johan/lsprofcalltree.py">https://people.gnome.org/~johan/lsprofcalltree.py</a>). It tries to behave <a id="id168" class="indexterm"/>more like the <code class="literal">kcachegrind-converter</code> (<a class="ulink" href="https://packages.debian.org/en/stable/kcachegrind-converters">https://packages.debian.org/en/stable/kcachegrind-converters</a>) package from Debian. We'll use the tool to transform the output from <code class="literal">cProfile</code> into something KCacheGrind can understand.</p><div class="section" title="Installation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec32"/>Installation</h2></div></div></div><p>To install <code class="literal">pyprof2calltree</code>, you'll first need to install the <code class="literal">pip</code> command-line utility. Then, just <a id="id169" class="indexterm"/>use the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ pip install pyprof2calltree</strong></span>
</pre></div><p>Note that all installation steps and instructions are meant for the Ubuntu 14.04 Linux distribution, unless otherwise noted.</p><p>Now, for KCacheGrind, the installation is a bit different. The visualizer is part of the KDE desktop environment, so if you already have it installed, chances are that you already have KCacheGrind also. However, if you don't have it (maybe you're a Gnome user), you can just use your package manager and install it. For instance, in Ubuntu, you'd use the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo apt-get install kcachegrind</strong></span>
</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note07"/>Note</h3><p>With this command, you'll probably have to install a lot of packages not directly related to the utility, but to KDE. So, the installation might take some time depending on your Internet connection.</p></div></div><p>For Windows and OS X users, there <a id="id170" class="indexterm"/>is the option of installing the QCacheGrind branch of KCacheGrind, which is already precompiled and can be installed as a binary.</p><p>Windows <a id="id171" class="indexterm"/>users can download it from <a class="ulink" href="http://sourceforge.net/projects/qcachegrindwin/">http://sourceforge.net/projects/qcachegrindwin/</a>, and OS X users can install it using brew:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ brew install qcachegrind</strong></span>
</pre></div></div><div class="section" title="Usage"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec33"/>Usage</h2></div></div></div><p>There are two ways to use <code class="literal">pyprof2calltree</code>: one is from the command line, passing in arguments, and the <a id="id172" class="indexterm"/>other one is directly from the <span class="strong"><strong>read–eval–print loop</strong></span>(<span class="strong"><strong>REPL</strong></span>) (or even from our own scripts being profiled).</p><p>The first <a id="id173" class="indexterm"/>one (command-line version) comes in very handy when we already have the profiling results stored somewhere. So, with this tool, we can simply run the following command and get the output when needed:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ pyprof2calltree -o [output-file-name] -i input-file.prof</strong></span>
</pre></div><p>There are some optional parameters, which can help us in different cases. Two of them are explained here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">-k</code>: If we want to run KCacheGrind on the output data right away, this option will do it for us</li><li class="listitem" style="list-style-type: disc"><code class="literal">-r</code>: If we don't have the profiling data already saved in a file, we can use this parameter to pass in the Python script we'll use to collect the said data</li></ul></div><p>Now, if you want to use it from the REPL instead, you can simply import either (or both) the <code class="literal">convert</code> function or the <code class="literal">visualize</code> function from the <code class="literal">pyprof2calltree</code> package. The first one will save the data into a file, and the second one will launch KCacheGrind with the output from the profiler.</p><p>Here is an example:</p><div class="informalexample"><pre class="programlisting">from xml.etree import ElementTree
from cProfile import Profile
import pstats
xml_content = '&lt;a&gt;\n' + '\t&lt;b/&gt;&lt;c&gt;&lt;d&gt;text&lt;/d&gt;&lt;/c&gt;\n' * 100 + '&lt;/a&gt;'
profiler = Profile()
profiler.runctx(
"ElementTree.fromstring(xml_content)",
locals(), globals())

from pyprof2calltree import convert, visualize
stats = pstats.Stats(profiler)
visualize(stats)      # run kcachegrind</pre></div><p>This code will call KCacheGrind. It'll show something like what you see in the following screenshot:</p><div class="mediaobject"><img src="graphics/B02088_03_01.jpg" alt="Usage"/></div><p>In the preceding <a id="id174" class="indexterm"/>screenshot, you can see the list on the left-hand side (<span class="strong"><strong>1</strong></span>) showing some of the numbers we saw in the previous chapter. On the right-hand side (<span class="strong"><strong>2</strong></span>), we've selected one of the tabs, specifically the <span class="strong"><strong>Callee Map</strong></span> tab. It shows a set of boxes, representing the hierarchy of function calls from the one selected on the left-hand side all the way down.</p><p>On the list from the left-hand side, there are two columns that we'll want to pay special attention to:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Incl. (from Inclusive time) column</strong></span>: This shows an indicator of how long each function takes in aggregate. This means it adds up the time its code takes plus the time that other functions called by it take. If a function has a high number in this column, it doesn't necessarily mean that the function takes too long. It could mean that the functions called by it do.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Self column</strong></span>: This shows the time spent inside a particular function, without taking into account the ones called by it. So, if a function has a high <span class="strong"><strong>Self</strong></span> value, then it probably means that a lot of time is spent inside it, and it's a good place to start looking for optimization paths.</li></ul></div><p>Another useful view is <span class="strong"><strong>Call Graph</strong></span>, which can be found on the lower-right box once a function is selected on the list. It'll show a representation of the functions that will help explain how each one calls the next one (and how many times). Here is an example from the preceding code:</p><div class="mediaobject"><img src="graphics/B02088_03_10.jpg" alt="Usage"/></div></div><div class="section" title="A profiling example – TweetStats"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec34"/>A profiling example – TweetStats</h2></div></div></div><p>Let's now go back to the examples of <a class="link" href="ch02.html" title="Chapter 2. The Profilers">Chapter 2</a>, <span class="emphasis"><em>The Profilers</em></span>, and tackle them using the <code class="literal">pyprof2calltree</code>/<code class="literal">kcachegrind</code> combo.</p><p>Let's avoid<a id="id175" class="indexterm"/> the Fibonacci examples, since they're quite simple and <a id="id176" class="indexterm"/>we've been over them already. So, let's jump directly to the code from the TweetStats module. It would read a list of tweets and get some statistics from it. We're not modifying the code. So, for reference, just take a look at it in <a class="link" href="ch02.html" title="Chapter 2. The Profilers">Chapter 2</a>, <span class="emphasis"><em>The Profilers</em></span>.</p><p>As for the script using the class and printing the actual stats, we're modifying it to save the stats instead. This is a very simple change as you can see here:</p><div class="informalexample"><pre class="programlisting">import cProfile
import pstats
import sys

from tweetStats import build_twit_stats

profiler = cProfile.Profile()
profiler.enable()


build_twit_stats()
profiler.create_stats()
stats = pstats.Stats(profiler)
stats.strip_dirs().sort_stats('cumulative')<span class="strong"><strong>.dump_stats('tweet-stats.prof') #saves the stats into a file called tweet-stats.prof, instead of printing them into stdout</strong></span>
</pre></div><p>Now, with the <a id="id177" class="indexterm"/>stats saved into the <code class="literal">tweet-stats.prof</code> file, we<a id="id178" class="indexterm"/> can use the following command to transform it and start the visualizer all at once:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$pyprof2calltree -i tweet-stats.prof -k</strong></span>
</pre></div><p>This, in turn, will show us something like the following screenshot:</p><div class="mediaobject"><img src="graphics/B02088_03_02.jpg" alt="A profiling example – TweetStats"/></div><p>Again, with the <span class="strong"><strong>Callee Map</strong></span> selected for the first function call, we can see the entire map of our script. It clearly shows where the bottlenecks are (biggest blocks on the right-hand side): <code class="literal">read_data</code>, the <code class="literal">split</code> method, and the <code class="literal">get_data</code> function on the far right of the map.</p><p>Inside the <code class="literal">get_stats</code> section of the map, we can see how there are two functions that make up for part of the size: <code class="literal">inc_stat</code> and <code class="literal">find</code> from string. We know the first one from seeing the code. This function does very little, so it's entire size will only be due to lookup times accumulated (we're calling it around 760k times after all). The same thing happens<a id="id179" class="indexterm"/> for the <code class="literal">find</code> method. We're calling it way too many <a id="id180" class="indexterm"/>times, so the lookup time accumulates and starts to be of notice. So, let's apply a set of very simple improvements to this function. Let's remove the <code class="literal">inc_stat</code> function and inline it's behavior. Let's also change the <code class="literal">find</code> method line and use the in operator. The result will look like the one shown in this screenshot: :</p><div class="mediaobject"><img src="graphics/B02088_03_03.jpg" alt="A profiling example – TweetStats"/></div><p>That other side of the map changed drastically. Now, we can see that the <code class="literal">get_stats</code> function no longer calls other functions, so the lookup times were removed. It now only represents 9.45 percent of the total execution time, down from 23.73 percent.</p><p>Yes, the preceding conclusions are the same ones we arrived at in the previous chapter, but we did so using a different method. Let's then keep doing the same optimization we did earlier and see how the map changes again:</p><div class="mediaobject"><img src="graphics/B02088_03_04.jpg" alt="A profiling example – TweetStats"/></div><p>In the preceding screenshot, we see that by selecting the <code class="literal">build_twitt_stats</code> function (in the list on the left-hand side), the functions that get called are simply methods of the string<a id="id181" class="indexterm"/> objects.</p><p>Sadly, KCacheGrind <a id="id182" class="indexterm"/>isn't showing us the total time of execution. However, the map clearly shows that we've simplified and optimized our code anyway.</p></div><div class="section" title="A profiling example – Inverted Index"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec35"/>A profiling example – Inverted Index</h2></div></div></div><p>Again, let's <a id="id183" class="indexterm"/>get another example from <a class="link" href="ch02.html" title="Chapter 2. The Profilers">Chapter 2</a>, <span class="emphasis"><em>The Profilers</em></span>: the inverted index. Let's update its code in order to generate the stats data and <a id="id184" class="indexterm"/>save it into a file so that we can later analyze it with KCacheGrind.</p><p>The only thing we need to change is the last line of the file, instead of just calling the <code class="literal">__start__</code> function. We have the following code:</p><div class="informalexample"><pre class="programlisting">profiler = cProfile.Profile()
profiler.enable()
__start__()
profiler.create_stats()
stats = pstats.Stats(profiler)
stats.strip_dirs().sort_stats('cumulative').dump_stats('inverted-index-stats.prof')</pre></div><p>So now, executing the script will save the data into the <code class="literal">inverted-index-stats.prof</code> file. Later, we can use the following command to start up KCacheGrind:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ pyprof2calltree -i inverted-index-stats.prof -k</strong></span>
</pre></div><p>This is what we will see first:</p><div class="mediaobject"><img src="graphics/B02088_03_05.jpg" alt="A profiling example – Inverted Index"/></div><p>Let's first do a<a id="id185" class="indexterm"/> resort of the functions on the left-hand side<a id="id186" class="indexterm"/> by the second column (<span class="strong"><strong>Self</strong></span>). So, we can look at the functions that take the longest to execute because of their code (not because of how long the functions it calls take). We will get the following list:</p><div class="mediaobject"><img src="graphics/B02088_03_06.jpg" alt="A profiling example – Inverted Index"/></div><p>So, according to the preceding list, the two most problematic functions right now are <code class="literal">getWords</code> and <code class="literal">list2dict</code>.</p><p>The first one <a id="id187" class="indexterm"/>can be improved in several ways, as <a id="id188" class="indexterm"/>follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <code class="literal">wordIndexDict</code> attribute can be changed to be of the <code class="literal">defaultdict</code> type, which will remove the <code class="literal">if</code> statement checking for an existing index</li><li class="listitem" style="list-style-type: disc">The strip statements can be removed from the <code class="literal">readFileContent</code> function, simplifying our code here</li><li class="listitem" style="list-style-type: disc">A lot of assignments can be removed, so avoid spending milliseconds in them, since we can use the values directly</li></ul></div><p>So, our new <code class="literal">getWords</code> function looks like this:</p><div class="informalexample"><pre class="programlisting">def getWords(content, filename, wordIndexDict):
  currentOffset = 0
  for line in content:
    localWords = line.split()
    for (idx, word) in enumerate(localWords):
      currentOffset = getOffsetUpToWord(localWords, idx) + currentOffset 
      wordIndexDict[word].append([filename, currentOffset])
  return wordIndexDict</pre></div><p>Now, if we run the stats again, the map and the numbers look a bit different:</p><div class="mediaobject"><img src="graphics/B02088_03_07.jpg" alt="A profiling example – Inverted Index"/></div><p>So, our function<a id="id189" class="indexterm"/> is now using less time, both overall (<span class="strong"><strong>Incl.</strong></span> column) and inside it (<span class="strong"><strong>Self</strong></span> column). However, there is still another detail we <a id="id190" class="indexterm"/>might want to look into before leaving this function alone. The <code class="literal">getWords</code> function is calling <code class="literal">getOffsetUpToWord</code> a total of <span class="strong"><strong>141,295</strong></span> times, the lookup time spent in there alone, should be enough to merit a review. So, let's see what we can do.</p><p>We've already solved this issue in the earlier chapter. We saw that we can reduce the entire <code class="literal">getOffsetUpToWord</code> function to a one-liner, which we can later write directly inside the <code class="literal">getWords</code> function to avoid lookup time. With this in mind, let see what our new map looks like:</p><div class="mediaobject"><img src="graphics/B02088_03_08.jpg" alt="A profiling example – Inverted Index"/></div><p>Now, we have<a id="id191" class="indexterm"/> increased the overall time, but that's <a id="id192" class="indexterm"/>nothing to worry about. It is due to the fact that now we have one function less to spread the timing between, so the number changed for all other functions. However, the one we really care about (the <span class="strong"><strong>Self</strong></span> time) went down, by about 4 percent.</p><p>The preceding screenshot also shows the <span class="strong"><strong>Call Graph</strong></span> view, which helps us see that even though we made an improvement, the <code class="literal">reduce</code> function is still being called over <span class="strong"><strong>100,000</strong></span> times. If you look at the code of the <code class="literal">getWords</code> function, you would notice we don't really need the <code class="literal">reduce</code> function. This is because on every call, we're adding up all the numbers we added on the previous call plus one more, so we can simplify this in the following code:</p><div class="informalexample"><pre class="programlisting">def getWords(content, filename, wordIndexDict):
  currentOffset = 0
  prevLineLength = 0
  for lineIndex, line in enumerate(content):
    lastOffsetUptoWord = 0
    localWords = line.split()

    if lineIndex &gt; 0:
      prevLineLength += len(content[lineIndex - 1]) + 1
    for idx, word in enumerate(localWords):
      if idx &gt; 0:
        lastOffsetUptoWord += len(localWords[idx-1])
      currentOffset = lastOffsetUptoWord + idx +  1 + prevLineLength

      wordIndexDict[word].append([filename, currentOffset])</pre></div><p>With this <a id="id193" class="indexterm"/>final touch to the functions, the numbers change<a id="id194" class="indexterm"/> once again:</p><div class="mediaobject"><img src="graphics/B02088_03_09.jpg" alt="A profiling example – Inverted Index"/></div><p>The inclusive amount of time of the function was lowered significantly, so overall, this function now takes less time to execute (which was our goal). The internal time (<span class="strong"><strong>Self</strong></span> column) went down, which is a good thing. This is because it also means that we're doing the same in less time (specially because we know that we're not calling any other function).</p></div></div></div>
<div class="section" title="RunSnakeRun"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec20"/>RunSnakeRun</h1></div></div></div><p>RunSnakeRun <a id="id195" class="indexterm"/>is yet another GUI tool to help us visualize the profiling output and, in turn, help us make sense of it. This particular project is a simplified version of KCacheGrind. Whereas the latter is also useful for C and C++ developers, RunSnakeRun is specifically designed and written for Python developers.</p><p>Earlier, with KCacheGrind, if we wanted to plot the output of <code class="literal">cProfile</code>, we needed an extra tool (<code class="literal">pyprof2calltree</code>). This time we won't. RunSnakeRun knows how to interpret it and display it, so all we need to do is call it and pass in the path to the file.</p><p>The features<a id="id196" class="indexterm"/> provided by this tool are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Sortable data grid views with fields, such as:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">function name</li><li class="listitem" style="list-style-type: disc">number of total calls</li><li class="listitem" style="list-style-type: disc">cumulative time</li><li class="listitem" style="list-style-type: disc">filename and line number</li></ul></div></li><li class="listitem" style="list-style-type: disc">Function-specific information, such as all callers of this function and all callee's of this function</li><li class="listitem" style="list-style-type: disc">Square map of the call tree with size proportional to the amount of time spent inside each function</li></ul></div><div class="section" title="Installation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec36"/>Installation</h2></div></div></div><p>In order to<a id="id197" class="indexterm"/> install this tool, you have to make sure that several dependencies are covered, mainly the following ones:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Python profiler</li><li class="listitem" style="list-style-type: disc">wxPython (2.8 or above) (<a class="ulink" href="http://www.wxpython.org/">http://www.wxpython.org/</a>)</li><li class="listitem" style="list-style-type: disc">Python (of course!) 2.5 or<a id="id198" class="indexterm"/> above, but lower than 3.x</li></ul></div><p>You'll also need to<a id="id199" class="indexterm"/> have <code class="literal">pip</code> (<a class="ulink" href="https://pypi.python.org/pypi/pip">https://pypi.python.org/pypi/pip</a>) installed in order to run the installation command.</p><p>So, make sure you have all these installed before moving forward. If you're in a Debian-based distribution of Linux (say Ubuntu), you can use the following line to make sure you have everything you need (provided you already have Python installed):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ apt-get install python-profiler python-wxgtk2.8 python-setuptools</strong></span>
</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note08"/>Note</h3><p>Windows and OS X users will need to find the correct precompiled binaries for their current OS version for each of the dependencies mentioned earlier.</p></div></div><p>After that, you can just run this command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ pip install  SquareMap RunSnakeRun</strong></span>
</pre></div><p>After that, you should be ready to go.</p></div><div class="section" title="Usage"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec37"/>Usage</h2></div></div></div><p>Now, to <a id="id200" class="indexterm"/>quickly show you how to use it, let's go back to previous last example: <code class="literal">inverted-index.py</code>.</p><p>Let's execute that script using the <code class="literal">cProfile</code> profiler as a parameter and save that output into a file. Then, we can just call <code class="literal">runsnake</code> and pass it the file path:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ python -m cProfile -o inverted-index-cprof.prof inverted-index.py</strong></span>
<span class="strong"><strong>$ runsnake inverted-index-cprof.prof</strong></span>
</pre></div><p>This will generate the following screenshot:</p><div class="mediaobject"><img src="graphics/B02088_03_11.jpg" alt="Usage"/></div><p>From the preceding screenshot, you can see the three main areas of interest:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The sortable list, which contains all the numbers returned by <code class="literal">cProfile</code></li><li class="listitem" style="list-style-type: disc">The function-specific info section, which has several tabs of interest, such as the <span class="strong"><strong>Callees</strong></span>, <span class="strong"><strong>Callers</strong></span> and <span class="strong"><strong>Source Code</strong></span> tabs</li><li class="listitem" style="list-style-type: disc">The square map section, which graphically represents the call tree of the execution</li></ul></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note09"/>Note</h3><p>A nice little<a id="id201" class="indexterm"/> feature that the GUI has is that it'll highlight the related box on the right-hand side if you hover your mouse over a function in the list from the left-hand side. The same thing will happen if you hover over a box on the right-hand side; its corresponding entry in the list will be highlighted.</p></div></div></div><div class="section" title="Profiling examples – the lowest common multiplier"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec38"/>Profiling examples – the lowest common multiplier</h2></div></div></div><p>Let's take a look at a very basic, non-practical example of a function in need of serious optimization and what it would look like using this GUI.</p><p>Our example<a id="id202" class="indexterm"/> function takes care of finding the lowest common multiplier between two numbers. It's a pretty basic example: one you can find all over the Internet. However, it's also a good place to start getting a feel of this UI.</p><p>The function's code is as follows:</p><div class="informalexample"><pre class="programlisting">def lowest_common_multiplier(arg1, arg2):
    i = max(arg1, arg2)
    while i &lt; (arg1 * arg2):
        if i % min(arg1,arg2) == 0:
            return i
        i += max(arg1,arg2)
    return(arg1 * arg2)

print lowest_common_multiplier(41391237, 2830338)</pre></div><p>I'm pretty sure you can spot every single possible optimization just by looking at it, but stay with me. Let's profile this bad boy and load up the resulting output on RunSnakeRun.</p><p>So, to run it, use this command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ python -m cProfile -o lcm.prof lcm.py</strong></span>
</pre></div><p>To start the GUI, use this command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ runsnake lcm.prof</strong></span>
</pre></div><p>This is what we get:</p><div class="mediaobject"><img src="graphics/B02088_03_12.jpg" alt="Profiling examples – the lowest common multiplier"/></div><p>One thing <a id="id203" class="indexterm"/>we didn't mention earlier, but that is a nice add-on to the square map, is the fact that next to each box's name, we can see how much time it takes to run that function.</p><p>So, at first sight, we can spot several issues already:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We see that both <code class="literal">max</code> and <code class="literal">min</code> functions only take up to 0,228 seconds out of the total 0,621 seconds that our function takes to run. So, there is more to our function than simply max and min.</li><li class="listitem" style="list-style-type: disc">We can also see that both <code class="literal">max</code> and <code class="literal">min</code> functions are called <span class="strong"><strong>943,446</strong></span> times each. No matter how small the lookup time is, if you call a function almost 1 million times it's going to add up.</li></ul></div><p>Let's perform some obvious fixes to our code and see how it looks again, through the <span class="emphasis"><em>eyes of the snake</em></span>:</p><div class="informalexample"><pre class="programlisting">def lowest_common_multiplier(arg1, arg2):
    i = max(arg1, arg2)
    _max = i
    _min = min(arg1,arg2)
    while i &lt; (arg1 * arg2):
        if i % _min == 0:
            return i
        i += _max
    return(arg1 * arg2)

print lowest_common_multiplier(41391237, 2830338)</pre></div><p>You should get something like what's shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/B02088_03_13.jpg" alt="Profiling examples – the lowest common multiplier"/></div><p>Now, neither <code class="literal">min</code> nor <code class="literal">max</code> even register on the square map. This is because we're just only <a id="id204" class="indexterm"/>calling them once, and the function went from 0.6 seconds to 0.1 second. This is the power of not doing unnecessary function lookups for you folks.</p><p>Now, let's take a look at another, more complex, and thus, interesting function in dire need of optimization.</p></div><div class="section" title="A profiling example – search using the inverted index"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec39"/>A profiling example – search using the inverted index</h2></div></div></div><p>Since the previous chapter, we've been over the code of the inverted index from all possible<a id="id205" class="indexterm"/> angles. This is great, since we've analyzed it from several perspectives and using different approaches. However, it would make no sense to also look at it using RunSnakeRun, since this tool is very similar to the one we just tried (KCacheGrind).</p><p>So instead, let's use the output of the inverted search script and code ourselves, a search script that will use that output. We will initially shoot for a simple search function that will only look<a id="id206" class="indexterm"/> for one single word in the index. The steps are quite straightforward:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Load the index in memory.</li><li class="listitem">Search for the word and grab the indexing information.</li><li class="listitem">Parse the indexing information.</li><li class="listitem">For each index entry, read the corresponding file and grab the surrounding string as a result.</li><li class="listitem">Print the results.</li></ol></div><p>Here's the initial version of our code:</p><div class="informalexample"><pre class="programlisting">import re
import sys

#Turns a list of entries from the index file into a dictionary indexed
#by words
def list2dict(l):
  retDict = {}
  for item in l:
    lineParts = item.split(',')
    word = lineParts.pop(0)
    data = ','.join(lineParts)
    indexDataParts = re.findall('\(([a-zA-Z0-9\./, ]{2,})\)' ,data)
    retDict[word] = indexDataParts
  return retDict

#Load the index's content into memory and parse itdef loadIndex():
  indexFilename = "./index-file.txt"
  with open(indexFilename, 'r') as fh: 
    indexLines = []
    for line in fh:
      indexLines.append(line)
    index = list2dict(indexLines)

    return index

#Reads the content of a file, takes care of fixing encoding issues with utf8 and removes unwanted characters (the ones we didn't want when generating the index)
def readFileContent(filepath):
    with open(filepath, 'r') as f:
    return [x.replace(",", "").replace(".","").replace("\t","").replace("\r","").replace("|","").strip(" ") for x in f.read().decode("utf-8-sig").encode("utf-8").split( '\n' )]
def findMatch(results):
  matches = []
  for r in results:
    parts = r.split(',')
    filepath = parts.pop(0)
    fileContent = ' '.join(readFileContent(filepath))
    for offset in parts:
      ioffset = int(offset)
      if ioffset &gt; 0:
        ioffset -= 1
      matchLine = fileContent[ioffset:(ioffset + 100)]
      matches.append(matchLine)
  return matches

#Search for the word inside the index
def searchWord(w):
  index = None
  index = loadIndex()
  result = index.get(w)
  if result:
    return findMatch(result)
  else:
      return []

#Let the user define the search word...
searchKey = sys.argv[1] if len(sys.argv) &gt; 1 else None
if searchKey is None: #if there is none, we output a usage message
 print "Usage: python search.py &lt;search word&gt;"
else: #otherwise, we search
  results = searchWord(searchKey)
  if not results:
      print "No results found for '%s'" % (searchKey)
  else:
      for r in results:
      print r</pre></div><p>To run<a id="id207" class="indexterm"/> the code, just run the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ python -m cProfile -o search.prof search.py John</strong></span>
</pre></div><p>The output we will get is similar to the following screenshot (given we have a few books inside the <code class="literal">files</code> folder):</p><div class="mediaobject"><img src="graphics/B02088_03_14.jpg" alt="A profiling example – search using the inverted index"/></div><p>The output<a id="id208" class="indexterm"/> could be improved by highlighting the search term or showing some of the previous words for more context. However, we'll run with it for the time being.</p><p>Now, let's see how our code looks when we open the <code class="literal">search.prof</code> file inside <code class="literal">RunSnakeRun</code>:</p><div class="mediaobject"><img src="graphics/B02088_03_15.jpg" alt="A profiling example – search using the inverted index"/></div><p>That's a <a id="id209" class="indexterm"/>lot of boxes, especially comparing it to our previous example of the lowest common multiplier. However, let's see what insight can be gathered from it at first sight.</p><p>The two most time-consuming functions are <code class="literal">loadIndex</code> and <code class="literal">list2dict</code>, closely followed by <code class="literal">readFileContent</code>. We can see this on the left-side column:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">All these functions are actually spending most of their time inside other functions they call. So, their cumulative time is high, but their local time is considerably lower.</li><li class="listitem" style="list-style-type: disc">If we sort by local time on the list, we would see that the top five functions are:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <code class="literal">read</code> method from the file object</li><li class="listitem" style="list-style-type: disc">The <code class="literal">loadIndex</code> function</li><li class="listitem" style="list-style-type: disc">The <code class="literal">list2dict</code> function</li><li class="listitem" style="list-style-type: disc">The <code class="literal">findAll</code> method of the regular expression object</li><li class="listitem" style="list-style-type: disc">And the <code class="literal">readFileContent</code> function</li></ul></div></li></ul></div><p>So, let's first take a look at the <code class="literal">loadIndex</code> function. Even though most of its time is spent inside the <code class="literal">list2dict</code> function, we still have one minor optimization to do, which will simplify its<a id="id210" class="indexterm"/> code and significantly reduce its local time:</p><div class="informalexample"><pre class="programlisting">def loadIndex():
  indexFilename = "./index-file.txt"
  with open(indexFilename, 'r') as fh:
    #instead of looping through every line to append it into an array, we use the readlines method which does that already
    indexLines = fh.readlines()
    index = list2dict(indexLines)
    return index</pre></div><p>This simple change took the local time of the function from 0.03s down to 0.00002s. Even though it wasn't already a big pain, we both increased its readability and improved its time. So, overall, we did well.</p><p>Now, based on the last analysis, we knew that most of the time spent inside this function was actually spent inside another one called by it. So, now that we basically decreased its local time to almost nothing, we need to focus on our next target: <code class="literal">list2dict</code>.</p><p>However, first, let's see how the picture has changed with the simple improvement we did earlier:</p><div class="mediaobject"><img src="graphics/B02088_03_16.jpg" alt="A profiling example – search using the inverted index"/></div><p>Now, let's move on to <code class="literal">list2dict</code>. This function is the one in charge of parsing every line of the index file into something we can use later. It will parse every line of the index file, more specifically, into a hash table (or dictionary) indexed by a word, which will make our <a id="id211" class="indexterm"/>search be of O(1) in average (read back to <a class="link" href="ch01.html" title="Chapter 1. Profiling 101">Chapter 1</a>, <span class="emphasis"><em>Profiling 101,</em></span> if you don't remember what this means) when we search. The values of the dictionary are the path to the actual files and the different offsets where the word is.</p><p>From our analysis, we can see that though we spend some time inside the function itself, most of the complexity is inside the regular expression methods. Regular expressions are great for many reasons, but sometimes, we tend to overuse them in cases where using simple <code class="literal">split</code> and <code class="literal">replace</code> functions would do. So, let's see how we can parse our data, get the same output without the regular expressions, and see if we can do it in less <code class="literal">time:def list2dict(l)</code>:</p><div class="informalexample"><pre class="programlisting">  retDict = {}
  for item in l:
    lineParts = item.split(',(')
    word = lineParts[0]
    ndexDataParts = [x.replace(")","") for x in lineParts[1:]]
  retDict[word] = indexDataParts
  return retDict</pre></div><p>The code looks cleaner already. There are no regular expressions anywhere (which will help readability sometimes, since not everyone is an expert in reading regular expressions). We have less lines of code. We removed the <code class="literal">join</code> line, and we even got rid of the nasty <code class="literal">del</code> line, which was not necessary.</p><p>We, however, added a list comprehension line, but this is just a simple <code class="literal">replace</code> method on every item of the list in one line, that's all.</p><p>Let's see what our map looks like now:</p><div class="mediaobject"><img src="graphics/B02088_03_17.jpg" alt="A profiling example – search using the inverted index"/></div><p>Well, there is definitely a change there. If you compare the last two screenshots, you would notice the box for the <code class="literal">list2dict</code> function has moved to the right. This means it now takes<a id="id212" class="indexterm"/> less time than the <code class="literal">readFileContent</code> function. Our function's box is also simpler now. The only things inside it are the <code class="literal">split</code> and the <code class="literal">replace</code> methods. Finally, in case there was any doubt, let's look at the numbers:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Local time went down from 0.024s to 0.019s. It makes sense that the local time didn't decrease that much, because we're still doing all the work inside the function. This decrease is mainly due to the absence of the <code class="literal">del</code> line and the <code class="literal">join</code> line.</li><li class="listitem" style="list-style-type: disc">The total cumulative time decreased considerably. It went down from 0.094s to 0.031s, due to the lack of complex functions (regular expressions) used for the job.</li></ul></div><p>We took the total cumulative time of the function down to a third of what is was. So, it was a good optimization, especially considering that if we had larger indexes, then the time would be much bigger.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note10"/>Note</h3><p>The last assumption is not always true. It depends greatly on the type of algorithm being used. However, in our case, since we're looping over all the lines of the index file, we can safely assume it is.</p></div></div><p>Let's take a quick look at the numbers from the first analysis of the code and the last one so that we <a id="id213" class="indexterm"/>can see if there is actually an improvement on the overall time:</p><div class="mediaobject"><img src="graphics/B02088_03_18.jpg" alt="A profiling example – search using the inverted index"/></div><p>Finally, as you can see, we went from around 0.2 seconds of execution with the original code all the way down to 0.072 seconds.</p><p>Here's the final version of the code, all put together with the earlier improvements:</p><div class="informalexample"><pre class="programlisting">import sys

#Turns a list of entries from the index file into a dictionary indexed
#by words
def list2dict(l):
  retDict = {}
  for item in l:
    lineParts = item.split(',(')
  word = lineParts[0]
    indexDataParts = [x.replace(")","") for x in lineParts[1:]]
  retDict[word] = indexDataParts
  return retDict

#Load the index's content into memory and parse it
def loadIndex():
  indexFilename = "./index-file.txt"
  with open(indexFilename, 'r') as fh:
    #instead of looping through every line to append it into an array, we use the readlines method which does that already
    indexLines = fh.readlines()
    index = list2dict(indexLines)
    return index

#Reads the content of a file, takes care of fixing encoding issues with utf8 and removes unwanted characters (the ones we didn't want when generating the index)#
def readFileContent(filepath):
    with open(filepath, 'r') as f:
    return [x.replace(",", "").replace(".","").replace("\t","").replace("\r","").replace("|","").strip(" ") for x in f.read().decode("utf-8-sig").encode("utf-8").split( '\n' )]

def findMatch(results):
  matches = []
  for r in results:
    parts = r.split(',')

    filepath = parts[0]
    del parts[0]
    fileContent = ' '.join(readFileContent(filepath))
    for offset in parts:
      ioffset = int(offset)
      if ioffset &gt; 0:
        ioffset -= 1
      matchLine = fileContent[ioffset:(ioffset + 100)]
      matches.append(matchLine)
  return matches

#Search for the word inside the index
def searchWord(w):
  index = None
  index = loadIndex()
  result = index.get(w)
  if result:
    return findMatch(result)
  else:
    return []

#Let the user define the search word...
searchKey = sys.argv[1] if len(sys.argv) &gt; 1 else None

if searchKey is None: #if there is none, we output a usage message
  print "Usage: python search.py &lt;search word&gt;"
else: #otherwise, we search
  results = searchWord(searchKey)
  if not results:
    print "No results found for '%s'" % (searchKey)
  else:
    for r in results:
    print r</pre></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec21"/>Summary</h1></div></div></div><p>To summarize, in this chapter, we covered two of the most popular and common tools used by Python developers trying to make sense of the numbers returned by profilers such as <code class="literal">cProfile</code>. We analyzed the old code under this new light. We even got to analyze some new code.</p><p>In the next chapter, we'll start talking about optimization in more detail. We will cover some of the things we've already seen in practice and some recommendations of good practices when profiling and optimizing code.</p></div></body></html>