- en: '*Chapter 10*: Concurrent Image Processing'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter discusses the task of processing and manipulating images via concurrent
    programming, specifically multiprocessing. Since images are processed independently
    of one another, concurrent programming is an attractive option for achieving a
    significant speedup. This chapter lays out the basics behind image processing
    techniques, illustrates the improvements that concurrent programming provides,
    and goes over some of the best practices that are used in image processing applications.
    This discussion will consolidate our knowledge of how to leverage concurrent and
    parallel processing tools in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Image processing fundamentals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying concurrency to image processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Good concurrent image processing practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is a list of prerequisites for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: You must have Python 3 installed on your computer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You must have OpenCV and NumPy installed for your Python 3 distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code for this chapter can be found in the following GitHub repository:
    [https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter10](https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter10).'
  prefs: []
  type: TYPE_NORMAL
- en: Image processing fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Digital/computational image processing** (which we will refer to as **image
    processing** from this point forward) has become so popular in the modern era
    that it exists in numerous aspects of our everyday life. Image processing and
    manipulation are involved when you take a picture with your camera or phone using
    different filters, such as when advanced image editing software such as Adobe
    Photoshop is used, or even when you simply edit images using Microsoft Paint.'
  prefs: []
  type: TYPE_NORMAL
- en: Many of the techniques and algorithms that are used in image processing were
    developed in the early 1960s for various purposes such as medical imaging, satellite
    image analysis, character recognition, and so on. However, these image processing
    techniques required significant computing power, and the fact that the available
    computer equipment at the time was unable to accommodate the need for fast number-crunching
    slowed down the use of image processing.
  prefs: []
  type: TYPE_NORMAL
- en: Fast-forwarding to the future, when powerful computers with fast, multicore
    processors were developed, image processing techniques became much more accessible,
    and research on image processing increased significantly. Nowadays, numerous image
    processing applications are being actively developed and studied, including pattern
    recognition, classification, feature extraction, and more. Some of the specific
    image processing techniques that take advantage of concurrent and parallel programming,
    and would otherwise be extremely computationally time-consuming, include **Hidden
    Markov models**, **independent component analysis**, and even **neural network
    models**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is one of the simplest forms of image processing, where we convert
    a fully colored image into a grayscale one. This process is called **grayscaling**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – An example use of image processing – grayscaling ](img/B17499_Figure_10.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – An example use of image processing – grayscaling
  prefs: []
  type: TYPE_NORMAL
- en: Later in this chapter, we will see how grayscaling, along with other processing
    techniques, can be done using Python. To do this, we must install the necessary
    libraries and packages.
  prefs: []
  type: TYPE_NORMAL
- en: Python as an image processing tool
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have stated multiple times throughout this book, the Python programming
    language is on its way to becoming the most popular programming language. This
    is especially true in the field of computational image processing, which, most
    of the time, requires fast prototyping and designing, as well as significant automation
    capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: As we will find out in the following section, digital images are represented
    in two-dimensional and three-dimensional matrices so that computers can process
    them easily. Consequently, most of the time, digital image processing involves
    matrix calculation. Multiple Python libraries and modules not only provide efficient
    matrix calculation options but also interact seamlessly with other libraries that
    handle image reading/writing.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we already know, automating tasks and making them concurrent is Python''s
    strong suit. This makes Python the prime candidate to implement your image processing
    applications. For this chapter, we will be working with two main Python libraries:
    **OpenCV** (which stands for **Open Source Computer Vision**), which is a library
    that provides image processing and computer vision options in C++, Java, and Python,
    and NumPy, which, as we know, is one of the most popular Python modules and performs
    efficient and parallelizable number-crunching calculations. Let''s see how we
    can install these libraries.'
  prefs: []
  type: TYPE_NORMAL
- en: Installing OpenCV and NumPy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To install NumPy for your Python distribution using the `pip` package manager,
    run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are using Anaconda/Miniconda to manage your packages, you must run the
    following command instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Installing OpenCV might be more complicated, depending on your operating system.
    The easiest option is to have Anaconda handle the installation process by following
    the guide at [https://anaconda.org/conda-forge/opencv](https://anaconda.org/conda-forge/opencv)
    after installing Anaconda ([https://www.anaconda.com/download/](https://www.anaconda.com/download/))
    as your main Python package manager. If, however, you are not using Anaconda,
    the main option for installing OpenCV is to follow its official documentation
    guide, which can be found at [https://docs.opencv.org/master/df/d65/tutorial_table_of_content_introduction.html](https://docs.opencv.org/master/df/d65/tutorial_table_of_content_introduction.html).
    After successfully installing OpenCV, open a Python interpreter and try importing
    the library, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We will import OpenCV using the name `cv2`, which is the library alias of OpenCV
    in Python. The success message indicates the version of the OpenCV library that
    has been downloaded (4.5.2).
  prefs: []
  type: TYPE_NORMAL
- en: Computer image basics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we jump into processing and manipulating digital image files, we need
    to discuss the fundamentals of those files and how computers interpret data from
    them. Specifically, we need to understand how data regarding the colors and coordinates
    of individual pixels in an image file is represented, as well as how to extract
    it using Python.
  prefs: []
  type: TYPE_NORMAL
- en: RGB values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: RGB values are the basics of how colors are represented digitally. Standing
    for **red**, **green**, and **blue** (**RGB**), these values are constructed from
    the fact that all colors can be generated from a specific combination of red,
    green, and blue. So, an RGB value is a tuple of three integer numbers, each of
    which ranges from 0 (which indicates no color at all) to 255 (which indicates
    the deepest shade of that specific color).
  prefs: []
  type: TYPE_NORMAL
- en: For example, red corresponds to the tuple (255, 0, 0); in this tuple, there
    is only the highest value for red and no values for the other colors, so the whole
    tuple represents the pure color red. Similarly, blue is represented by (0, 0,
    255), while green is represented by (0, 255, 0). Yellow is the result of mixing
    equal amounts of red and green and is therefore represented by (255, 255, 0) (the
    maximum amount of red and green, with no blue). White, which is the combination
    of all three colors, is (255, 255, 255), while black, which is the opposite of
    white and therefore lacks all colors, is represented by (0, 0, 0).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is illustrated by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Illustration of RGB values ](img/B17499_Figure_10.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – Illustration of RGB values
  prefs: []
  type: TYPE_NORMAL
- en: Pixels and image files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So, an RGB value indicates a specific color, but how do we connect this to
    a computer image? If we were to view an image on our computer and try to zoom
    in as much as we could, we would observe that as we zoom in deeper and deeper,
    the image will start breaking apart into increasingly discernible colored squares.
    These squares are called pixels, which are the smallest units of color on a computer
    display or in a digital image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Examples of pixels in digital images ](img/B17499_Figure_10.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Examples of pixels in digital images
  prefs: []
  type: TYPE_NORMAL
- en: A set of different pixels arranged in a tabular format (rows and columns of
    pixels) makes up a computer image. Each pixel, in turn, is an RGB value; in other
    words, a pixel is a tuple of three integers. This means that a computer image
    is simply a two-dimensional array of tuples, whose sides correspond to the size
    of the image. For example, a 128 x 128 image has 128 rows and 128 columns of RGB
    tuples for its data.
  prefs: []
  type: TYPE_NORMAL
- en: Coordinates inside an image
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like indexing two-dimensional arrays, the coordinate for a digital image pixel
    is a pair of two integers, representing the *x*- and *y*-coordinates of that pixel;
    the *x*-coordinate indicates the pixel's location along the horizontal axis starting
    from the left, while the *y*-coordinate indicates the pixel's location along the
    vertical axis starting from the top.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see how heavy computational number-crunching processes are typically
    involved when it comes to image processing since each image is a matrix of integer
    tuples. This also suggests that, with the help of the NumPy library and concurrent
    programming, we can achieve significant improvements in execution time for Python
    image processing applications.
  prefs: []
  type: TYPE_NORMAL
- en: Following the convention of indexing two-dimensional arrays in NumPy, the location
    of a pixel is still a pair of integers, but the first number indicates the index
    of the row containing the pixel, which corresponds to the *y*-coordinate, and
    similarly, the second number indicates the *x*-coordinate of the pixel.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a surprising number of methods for reading in, performing image processing,
    and displaying a digital image file in Python. However, OpenCV provides some of
    the easiest and most intuitive options to do this. One important thing to note
    regarding OpenCV is that it inverts RGB values as BGR values when interpreting
    its images. So, instead of red, green, and blue in order, the tuples in an image
    matrix will represent blue, green, and red, in that order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example of interacting with OpenCV in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a few methods from OpenCV that have been used in this script that
    we need to discuss:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cv2.imread()`: This method takes in a path to an image file (compatible file
    extensions include `.jpeg`, `.jpg`, `.png`, and so on) and returns an image object,
    which, as we will see later, is represented by a NumPy array.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.imshow()`: This method takes in a string and an image object and displays
    it in a separate window. The title of the window is specified by the passed-in
    string. The method should always be followed by the `cv2.waitKey()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.waitKey()`: This method takes in a number and blocks the program for a
    corresponding number of milliseconds unless the number `0` is passed in, in which
    case it will block indefinitely until the user presses a key on their keyboard.
    This method should always follow the `cv2.imshow()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After calling `cv2.imshow()` on the `ship.jpg` file inside the input subfolder
    so that it''s displayed from the Python interpreter, the program will stop until
    a key is pressed, at which point it will execute the rest of the program. If run
    successfully, the script will display the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Displaying an image using OpenCV ](img/B17499_Figure_10.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – Displaying an image using OpenCV
  prefs: []
  type: TYPE_NORMAL
- en: 'You should also obtain the following output for the rest of the main program
    after pressing any key to close the displayed picture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output confirms a few of the things that we discussed earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: First, when printing out the image object that was returned by the `cv2.imread()`
    function, we obtained a matrix of numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using the `type()` method from Python, we found that the class of this matrix
    is indeed a NumPy array: `numpy.ndarray`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calling the `shape` attribute of the array, we can see that the image is a three-dimensional
    matrix of the shape (`1118`, `1577`, `3`), which corresponds to a table with `1118`
    rows and `1577` columns, each element of which is a pixel (three-number tuple).
    The numbers for the rows and columns also correspond to the size of the image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focusing on the top-left pixel in the matrix (the first pixel in the first row;
    that is, `im[0, 0]`), we obtained the BGR value of (`199`, `136`, `86`) – `199`
    blue, `136` green, and `86` red. By looking up this BGR value through any online
    converter, we can see that this is a light blue that corresponds to the sky, which
    is the upper part of the image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image processing techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already seen some Python APIs that are provided by OpenCV to read data
    from image files. Before we can use OpenCV to perform various image processing
    tasks, let's discuss the theoretical foundation for several techniques that are
    commonly used in image processing.
  prefs: []
  type: TYPE_NORMAL
- en: Grayscaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We saw an example of grayscaling earlier in this chapter. Arguably one of the
    most widely used image processing techniques, grayscaling is the process of reducing
    the dimensionality of the image pixel matrix by only considering the intensity
    information of each pixel, which is represented by the amount of light available.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, the pixels of grayscale images no longer hold three-dimensional
    information (red, green, and blue), and only one-dimensional black-and-white data.
    These images are exclusively composed of shades of gray, with black indicating
    the weakest light intensity and white indicating the strongest.
  prefs: []
  type: TYPE_NORMAL
- en: Grayscaling serves many important purposes in image processing. Firstly, as
    we mentioned previously, it reduces the dimensionality of the image pixel matrix
    by mapping traditional three-dimensional color data to one-dimensional gray data.
    So, instead of having to analyze and process three layers of color data, image
    processing programs only have to do one-third of the job with grayscale images.
    Additionally, by only representing colors using one spectrum, important patterns
    in the image are more likely to be recognized with just black and white data.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple algorithms for converting color into grayscale: colorimetric
    conversion, luma coding, single-channel, and more. Luckily, we do not have to
    implement one ourselves, as the OpenCV library provides a one-line method to convert
    normal images into grayscale ones. Still using the image of a ship from the previous
    example, let''s look at another example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we are using the `cvtColor()` method from OpenCV to convert
    our original image into a grayscale one. After running this script, the following
    output should be displayed on your computer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Output from grayscaling ](img/B17499_Figure_10.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – Output from grayscaling
  prefs: []
  type: TYPE_NORMAL
- en: 'By pressing any key to unblock your program, you should obtain the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that the structure of our grayscale image object is different
    from what we saw with our original image object. Even though it is still represented
    by a NumPy array, it is now a two-dimensional array of integers, each of which
    ranges from 0 (for black) to 255 (for white). The table of pixels, however, still
    consists of `1118` rows and `1577` columns.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we also used the `cv2.imwrite()` method, which saves the image
    object to your local computer. This means that the grayscale image can be found
    in the output subfolder of this chapter's folder, as specified in our code.
  prefs: []
  type: TYPE_NORMAL
- en: Thresholding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another important technique in image processing is **thresholding**. Intending
    to categorize each pixel in a digital image into different groups (also known
    as **image segmentation**), thresholding provides a quick and intuitive way to
    create binary images (with just black and white pixels).
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind thresholding is to replace each pixel in an image with a white
    pixel if the pixel's intensity is greater than a previously specified threshold,
    and with a black pixel if the pixel's intensity is less than that threshold. Similar
    to the goal of grayscaling, thresholding amplifies the differences between high-
    and low-intensity pixels, and from that, important features and patterns in an
    image can be recognized and extracted.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that grayscaling converts a fully colored image into a version that only
    has different shades of gray; in this case, each pixel has a value of an integer
    ranging from 0 to 255\. From a grayscale image, thresholding can convert it into
    a fully black-and-white one, each pixel of which is now only either 0 (black)
    or 255 (white). So, after performing thresholding on an image, each pixel of that
    image can only hold two possible values, further reducing the complexity of our
    image data.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the key to an effective thresholding process is finding an appropriate
    threshold so that the pixels in an image are segmented in a way that allows separate
    regions in the image to become more obvious. The simplest form of thresholding
    is to use a constant threshold to process all the pixels throughout a whole image.
    Let''s consider an example of this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, after converting the image of a ship that we have been using
    to grayscale, we called the `threshold(src, thresh, maxval, type)` function from
    OpenCV, which takes in the following arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`src`: This argument takes in the input/source image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`thresh`: This is the constant threshold to be used throughout the image. Here,
    we are using `127`, as it is simply the middle point between 0 and 255.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxval`: Pixels whose original values are greater than the constant threshold
    will take this value after the thresholding process. We pass in 255 to specify
    that those pixels should be completely white.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`type`: This value indicates the thresholding type that''s used by OpenCV.
    We are performing simple binary thresholding, so we pass in `cv2.THRESH_BINARY`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After running the script, you should be able to find the following image in
    the output with the name `custom_thresh_ship.jpg`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17499_Figure_10.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – Output from simple thresholding
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that with a simple threshold (`127`), we have obtained an
    image that highlights separate regions of the image: the sky, the ship, and the
    sea. However, there are several problems that this simple thresholding method
    poses, the most common of which is finding the appropriate constant threshold.
    Since different images have different color tones, lighting conditions, and so
    on, it is undesirable to use a static value across different images as their thresholds.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This issue is addressed by adaptive thresholding methods, which use different
    thresholds whose values are dynamically determined for small regions of an image.
    This process allows the threshold to adjust according to the input image, and
    not depend solely on a static value. Let''s consider two examples of these adaptive
    thresholding methods, namely **Adaptive Mean Thresholding** and **Adaptive Gaussian
    Thresholding**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Similar to what we did with the `cv2.threshold()` method earlier, here, we are
    converting the original image into its grayscale version, and then we are passing
    it to the `adaptiveThreshold()` method from OpenCV. This method takes in similar
    arguments to the `cv2.threshold()` method, except that instead of taking in a
    constant to be the threshold, it takes in an argument for the adaptive method.
    We used `cv2.ADAPTIVE_THRESH_MEAN_C` and `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The second to last argument specifies the size of the window to perform thresholding
    on; this number has to be an odd positive integer. Specifically, we used 11 in
    our example, so for each pixel in the image, the algorithm will consider the neighboring
    pixels (in an 11 x 11 square surrounding the original pixel). The last argument
    specifies the adjustment to make for each pixel in the final output. These two
    arguments, again, help localize the threshold for different regions of the image,
    thus making the thresholding process more dynamic and, as its name suggests, adaptive.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the script, you should be able to find the following images as
    output with the names `mean_thresh_ship.jpg` and `gauss_thresh_ship.jpg`. The
    output for `mean_thresh_ship.jpg` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Output from mean thresholding ](img/B17499_Figure_10.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – Output from mean thresholding
  prefs: []
  type: TYPE_NORMAL
- en: 'The output for `gauss_thresh_ship.jpg` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Output from Gaussian thresholding ](img/B17499_Figure_10.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.8 – Output from Gaussian thresholding
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that with adaptive thresholding, details in specific regions
    will be thresholded and highlighted in the final output image. These techniques
    are useful when we need to recognize small details in an image, while simple thresholding
    is useful when we only want to extract big regions of an image.
  prefs: []
  type: TYPE_NORMAL
- en: We have talked a lot about the basics of image processing and some common image
    processing techniques. We also know why image processing is a heavy number-crunching
    task, and that concurrent and parallel programming can be applied to speed up
    independent processing tasks. In the next section, we will look at a specific
    example of how to implement a concurrent image processing application that can
    handle a large number of input images.
  prefs: []
  type: TYPE_NORMAL
- en: Applying concurrency to image processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, head to the current folder for this chapter's code. Inside the `input`
    folder, there is a subfolder called `large_input`, which contains 400 images that
    we will be using for this example. These pictures are of different regions in
    our original ship image, and they have been cropped from it using the *array-indexing*
    and *-slicing* options that NumPy provides for slicing OpenCV image objects. If
    you are curious as to how these images were generated, check out the `generate_input.py`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our goal in this section is to implement a program that can concurrently process
    these images using thresholding. To do this, let''s look at the `example5.py`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we are using the `Pool` class from the `multiprocessing` module
    to manage our processes. As a refresher, a `Pool` object supplies convenient options
    to map a sequence of inputs to separate processes using the `Pool.map()` method.
    We are using the `Pool.starmap()` method in our example, however, to pass multiple
    arguments to the target function.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the beginning of our program, we make several housekeeping assignments:
    the thresholding method to perform adaptive thresholding when processing the images,
    the paths for the input and output folders, and the names of the images to process.
    The `process_threshold()` function is what we use to process the images; it takes
    in an image object, the name for the processed version of the image, and which
    thresholding method to use. Again, this is why we need to use the `Pool.starmap()`
    method instead of the traditional `Pool.map()` method.'
  prefs: []
  type: TYPE_NORMAL
- en: In the main program, to demonstrate the difference in performance between sequential
    and multiprocessing image processing, we want to run our program with different
    numbers of processes, specifically from one single process to six different processes.
    In each iteration of the `for` loop, we initialize a `Pool` object and map the
    necessary arguments of each image to the `process_threshold()` function, while
    keeping track of how much time it takes to process and save all of the images.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the script, the processed images can be found in the `output/large_output/`
    subfolder in our current chapter''s folder. You should obtain an output similar
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We can see a big difference in execution time when we go from one single process
    to two separate processes. However, there is negligible or even negative speedup
    after going from two to higher numbers of processes. Generally, this is because
    of the heavy overhead, which is the product of implementing many separate processes,
    in comparison to a relatively low number of inputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we have seen that concurrent programming could provide a significant
    speedup for image processing applications. However, if we take a look at our preceding
    program, we can see that there are additional adjustments that we can make to
    improve the execution time even further. Specifically, in the preceding program,
    we are sequentially reading in images by using list comprehension in the following
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Theoretically, if we were to make the process of reading in different image
    files concurrent, we could also gain additional speedup with our program. This
    is especially true in an image processing application that deals with large input
    files, where significant time is spent waiting for input to be read. With that
    in mind, let''s consider the following example, in which we will implement concurrent
    input/output processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The structure of this program is similar to that of the previous one. However,
    instead of preparing the necessary images to be processed and other relevant input
    information, we implement them inside the `process_threshold()` function, which
    now only takes the name of the input image and handles reading the image itself.
  prefs: []
  type: TYPE_NORMAL
- en: As a side note, we are using Python's built-in `functools.partial()` method
    in our main program to pass in a partial argument (hence the name), specifically
    `thresh_method`, to the `process_threshold()` function, as this argument is fixed
    across all images and processes. More information about this tool can be found
    at [https://docs.python.org/3/library/functools.html](https://docs.python.org/3/library/functools.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the script, you should obtain an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Compared to our previous output, this implementation of the application gives
    us a significantly better execution time!
  prefs: []
  type: TYPE_NORMAL
- en: Good concurrent image processing practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, you have most likely realized that image processing is quite an involved
    process and that implementing concurrent and parallel programming in an image
    processing application can add more complexity to our work. There are, however,
    good practices that will guide us in the right direction while developing our
    image processing applications. The following sections discuss some of the most
    common practices that we should keep in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the correct way (out of many)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have hinted at this practice briefly when we learned about thresholding.
    How an image processing application handles and processes its image data heavily
    depends on the problems it is supposed to solve, and what kind of data will be
    fed to it. Therefore, there is significant variability when it comes to choosing
    specific parameters when processing your image.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, as we saw earlier, there are various ways to threshold an image,
    and each will result in a very different output: if you want to focus on only
    the large, distinct regions of an image, **simple constant thresholding** will
    prove to be more beneficial than **adaptive thresholding**; if, however, you want
    to highlight small changes in the details of an image, adaptive thresholding will
    be significantly better.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's consider another example, in which we will see how tuning a specific parameter
    for an image processing function results in better output. In this example, we
    are using a simple **Haar Cascade model** to detect faces in images. We will not
    go too deeply into how the model handles and processes its data since it is already
    built into OpenCV; again, we are only using this model at a high level, changing
    its parameters to obtain different results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the `example7.py` file in this chapter''s folder. The script is
    designed to detect the faces in the `obama1.jpeg` and `obama2.jpg` images in our
    input folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: First, the program loads the pre-trained Haar Cascade model from the `input`
    folder using the `cv2.CascadeClassifier` class. For each input image, the script
    converts it into grayscale and feeds it to the pre-trained model. The script then
    draws a green rectangle around each face it found in the image and displays it
    in a separate window.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the program; you will see the following image with the title `5 face(s)
    found`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.9 – Correct face detection ](img/B17499_Figure_10.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.9 – Correct face detection
  prefs: []
  type: TYPE_NORMAL
- en: 'It looks like our program is working well so far. Press any key to continue.
    You should see the following image with the title `7 face(s) found`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Incorrect face detection ](img/B17499_Figure_10.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.10 – Incorrect face detection
  prefs: []
  type: TYPE_NORMAL
- en: Now, our program is mistaking some other objects as actual faces, resulting
    in two false positives. The reason behind this involves how the pre-trained model
    was created. Specifically, the Haar Cascade model used a training dataset with
    images of specific (pixel) sizes, and when an input image contains faces of different
    sizes – which is common when it is a group picture with some people being close
    to the camera, while others being far away – is fed into this model, it will cause
    false positives in the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `scaleFactor` parameter in the `detectMultiScale` method of the `cv2.CascadeClassifier`
    class addresses this issue. This parameter will scale down different areas of
    the input image before trying to predict whether those areas contain a face or
    not – doing this negates the potential difference in face sizes. To implement
    this, change the line where we pass the input images to the model to the following
    to specify the `scaleFactor` parameter as `1.2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Run the program; you will see that this time, our application can correctly
    detect all of the faces in our input images without making any false positives.
  prefs: []
  type: TYPE_NORMAL
- en: From this example, we can see that it is important to know about the potential
    challenges that the input images will pose to your image processing application
    in execution, as well as to try different methods or parameters within one method
    of processing to achieve the best results.
  prefs: []
  type: TYPE_NORMAL
- en: Spawning an appropriate number of processes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One point we noticed in our example of concurrent image processing is that the
    task of spawning processes takes a considerable amount of time. Due to this, if
    the number of processes available to analyze the data is too high in comparison
    to the amount of input, the improvement in execution time that's obtained from
    increasing the number of working processes will diminish and sometimes even become
    negative.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is no concrete way to tell whether a specific number of separate
    processes is appropriate for a program unless we also take into account its input
    images. For example, if the input images are relatively large files, and it takes
    a significant amount of time for the program to load them from storage, having
    a larger number of processes might be beneficial; when some processes are waiting
    for their images to load, others can proceed to perform processing on theirs.
    In other words, having a larger number of processes will allow for some overlapping
    between loading and processing time, which will result in better speedup.
  prefs: []
  type: TYPE_NORMAL
- en: In short, it is important to test out different processes that are available
    for your image processing application to see what the optimal number for scalability
    is.
  prefs: []
  type: TYPE_NORMAL
- en: Processing input/output concurrently
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We saw that loading input images in a sequential way might harm the execution
    time of an image processing application, as opposed to allowing separate processes
    to load their inputs. This is specifically true if the image files are significantly
    large, as the loading time in separate processes might overlap with the loading/processing
    time in other processes. The same is applicable for writing output images to files.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image processing is the task of analyzing and manipulating digital image files
    to create new versions of the images or to extract important data from them. These
    digital images are represented by tables of pixels, which are RGB values or, in
    essence, tuples of numbers. Therefore, digital images are simply multi-dimensional
    matrices of numbers, which results in the fact that image processing tasks typically
    come down to heavy number-crunching.
  prefs: []
  type: TYPE_NORMAL
- en: Since images can be analyzed and processed independently from each other in
    an image processing application, concurrent and parallel programming – specifically,
    multiprocessing – provides a way for us to make significant improvements to the
    execution time of the application. Additionally, there are several good practices
    to follow while implementing a concurrent image processing program.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen how we can apply parallel programming to accelerate the task of
    image processing. The exercises in this chapter allowed us to examine various
    aspects of the workflow and how each of them could be parallelized, thus allowing
    us to build up more confidence in implementing concurrent applications in Python.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will go through a similar exercise, where we aim to
    use asynchronous programming to build communication channels.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is an image processing task?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the smallest unit of digital imaging? How is it represented in computers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is grayscaling? What purpose does this technique serve?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is thresholding? What purpose does this technique serve?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why should image processing be made concurrent?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are some good practices for concurrent image processing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Automate the Boring Stuff with Python: Practical Programming for Total Beginners*,
    Al Sweigart, No Starch Press, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Learning Image Processing with OpenCV*, Garcia, Gloria Bueno, et al, Packt
    Publishing Ltd, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*A Computational Introduction to Digital Image Processing*, Alasdair McAndrew,
    Chapman and Hall/CRC, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Howse, J., P. Joshi, and M. Beyeler. OpenCV: *Computer Vision Projects with
    Python.* Packt Publishing Ltd, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
