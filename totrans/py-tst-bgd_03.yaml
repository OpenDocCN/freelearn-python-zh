- en: Chapter 3. Unit Testing with Doctest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Okay, so we''ve talked about what doctest does, and how to make it behave
    the way we want. We''ve talked about testing things with doctest too. What''s
    left to talk about in this chapter, then? In this chapter, we''ll be talking about
    the programming discipline called Unit testing. We''ll still be using doctest,
    but this time the focus is on what you''re doing and why, rather than on the details
    of how to do it.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we shall:'
  prefs: []
  type: TYPE_NORMAL
- en: Discuss in detail what Unit testing is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Talk about the ways in which Unit testing helps various stages of development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Work with examples that illustrate Unit testing and its advantages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, let's get on with it!
  prefs: []
  type: TYPE_NORMAL
- en: What is Unit testing and what it is not?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The title of this section, begs another question: "Why do I care?" One answer
    is that Unit testing is a best practice that has been evolving toward its current
    form over most of the time that programming has existed. Another answer is that
    the core principles of Unit testing are just good sense; it might actually be
    a little embarrassing to our community as a whole that it took us so long to recognize
    them.'
  prefs: []
  type: TYPE_NORMAL
- en: Alright, so what is Unit testing? In its most fundamental form, Unit testing
    can be defined as testing the smallest meaningful pieces of code (such pieces
    are called units), in such a way that each piece's success or failure depends
    only on itself. For the most part, we've been following this principle already.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s a reason for each part of this definition: we test the smallest meaningful
    pieces of code because, when a test fails, we want that failure to tell where
    the problem is us as specifically as possible. We make each test independent because
    we don''t want a test to make any other test succeed, when it should have failed;
    or fail when it should have succeeded. When tests aren''t independent, you can''t
    trust them to tell you what you need to know.'
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, automated testing is associated with Unit testing. Automated
    testing makes it fast and easy to run unit tests, which tend to be amenable to
    automation. We'll certainly make heavy use of automated testing with doctest and
    later with tools such as unittest and Nose as well.
  prefs: []
  type: TYPE_NORMAL
- en: Any test that involves more than one unit is automatically not a unit test.
    That matters because the results of such tests tend to be confusing. The effects
    of the different units get tangled together, with the end result that not only
    do you not know where the problem is (is the mistake in this piece of code, or
    is it just responding correctly to bad input from some other piece of code?),
    you're also often unsure exactly what the problem is this output is wrong, but
    how does each unit contribute to the error? Empirical scientists must perform
    experiments that check only one hypothesis at a time, whether the subject at hand
    is chemistry, physics, or the behavior of a body of program code.
  prefs: []
  type: TYPE_NORMAL
- en: Time for action – identifying units
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine that you''re responsible for testing the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this example, what are the units? Is the whole class a single unit, or is
    each method a separate unit. How about each statement, or each expression? Keep
    in mind that the definition of a unit is somewhat subjective (although never bigger
    than a single class), and make your own decision.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Think about what you chose. What would the consequences have been if you chose
    otherwise? For example, if you chose to think of each method as a unit, what would
    be different if you chose to treat the whole class as a unit?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Consider `method4`. Its result depends on all of the other methods working correctly.
    On top of that, it depends on something that changes from one test run to another,
    the unique ID of the `self` object. Is it even possible to treat `method4` as
    a unit in a self-contained test? If we could change anything except `method4`,
    what would we have to change to enable `method4` to run in a self-contained test
    and produce a predictable result?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*What just happened?*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By answering those three questions, you thought about some of the deeper aspects
    of unit testing.
  prefs: []
  type: TYPE_NORMAL
- en: The question of what constitutes a unit, is fundamental to how you organize
    your tests. The capabilities of the language affects this choice. C++ and Java
    make it difficult or impossible to treat methods as units, for example, so in
    those languages each class is usually treated as a single unit. C, on the other
    hand, doesn't support classes as language features at all, so the obvious choice
    of unit is the function. Python is flexible enough that either classes or methods
    could be considered units, and of course it has stand-alone functions as well,
    which are also natural to think of as units. Python can't easily handle individual
    statements within a function or method as units, because they don't exist as separate
    objects when the test runs. They're all lumped together into a single code object
    that's part of the function.
  prefs: []
  type: TYPE_NORMAL
- en: The consequences of your choice of unit are far-reaching. The smaller the units
    are, the more useful the tests tend to be, because they narrow down the location
    and nature of bugs more quickly. For example, one of the consequences of choosing
    to treat the testable class as a single unit is that tests of the class will fail
    if there is a mistake in any of the methods. That tells you that there's a mistake
    in testable, but not (for example) that it's in `method2`. On the other hand,
    there is a certain amount of rigmarole involved in treating `method4` and its
    like as units, to such an extent that the next chapter of the book is dedicated
    to dealing with such situations. Even so, I recommend using methods and functions
    as units most of the time, because it pays off in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: In answering the third question, you probably discovered that the functions
    `id` and `self.method3` would need to have different definitions, definitions
    that produced a predictable result, and did so without invoking code in any of
    the other units. In Python, replacing the real function with such stand-ins is
    fairly easy to do in an ad hoc manner, but we'll be discussing a more structured
    approach in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Pop quiz – understanding units
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Consider this code and then try to answer the questions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Assuming that methods are units, how many units exist in the above code?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which units make assumptions about the correct operation of other units? In
    other words, which units are not independent?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What would you need to do to create a test for `method2` that was independent
    of other units?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unit testing throughout the development process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll walk through the development of a single class, treating it with all the
    dignity of a real project. We'll be strictly careful to integrate unit testing
    into every phase of the project. This may seem silly at times, but just play along.
    There's a lot to learn from the experience.
  prefs: []
  type: TYPE_NORMAL
- en: The example we'll be working with is a PID controller. The basic idea is that
    a PID controller is a feedback loop for controlling some piece of real-world hardware.
    It takes input from a sensor that can measure some property of the hardware, and
    generates a control signal that adjusts that property toward some desired state.
    The position of a robot arm in a factory might be controlled by a PID controller.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you want to know more about `PID` controllers, the Internet is rife with
    information. The Wikipedia entry is a good place to start: [http://en.wikipedia.org/wiki/PID_controller](http://en.wikipedia.org/wiki/PID_controller).'
  prefs: []
  type: TYPE_NORMAL
- en: Design phase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our notional client comes to us with the following (rather sparse) specification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Time for action – unit testing during design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time to make that specification a bit more formal—and complete—by writing unit
    tests that describe the desired behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to write a test that describes the PID constructor. After checking
    our references, we determine that a PID controller is defined by three `gains`,
    and a `setpoint`. The controller has three components: proportional, integral
    and derivative (hence the name PID). Each `gain` is a number that determines how
    much one of the three parts of the controller has on the final result. The `setpoint`
    determines what the goal of the controller is; in other words, to where it''s
    trying to move the controlled variable. Looking at all that, we decide that the
    constructor should just store the `gains` and the `setpoint`, along with initializing
    some internal state that we know we''ll need due to reading up on the workings
    of a PID controller:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need to write tests that describe measurement processing. This is the controller
    in action, taking a measured value as its input and producing a control signal
    that should smoothly move the measured variable to the `setpoint`. For this to
    work correctly, we need to be able to control what the controller sees as the
    current time. After that, we plug our test input values into the math that defines
    a PID controller, along with the `gains`, to figure out what the correct outputs
    would be:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We need to write tests that describe `setpoint` handling. Our client asked for
    a `setpoint` stack, so we write tests that check such stack behavior. Writing
    code that uses this stack behavior brings to our attention that fact that a PID
    controller with no `setpoint` is not a meaningful entity, so we add a test that
    checks that the PID class rejects that situation by raising an exception.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*What just happened?*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our clients gave us a pretty good initial specification, but it left a lot of
    details to assumption. By writing these tests, we've codified exactly what our
    goal is. Writing the tests forced us to make our assumptions explicit. Additionally,
    we've gotten a chance to use the object, which gives us an understanding of it
    that would otherwise be hard to get at this stage.
  prefs: []
  type: TYPE_NORMAL
- en: Normally we'd place the doctests in the same file as the specification, and
    in fact that's what you'll find in the book's code archive. In the book format,
    we used the specification text as the description for each step of the example.
  prefs: []
  type: TYPE_NORMAL
- en: You could ask how many tests we should write for each piece of the specification.
    After all, each test is for certain specific input values, so when code passes
    it, all it proves is that the code produces the right results for that specific
    input. The code could conceivably do something entirely wrong, and still pass
    the test. The fact is that it's usually a safe assumption that the code you'll
    be testing was supposed to do the right thing, and so a single test for each specified
    property fairly well distinguishes between working and non-working code. Add to
    that tests for any boundaries specified—for "The X input may be between the values
    1 and 7, inclusive" you might add tests for X values of 0.9 and 7.1 to make sure
    they weren't accepted—and you're doing fine.
  prefs: []
  type: TYPE_NORMAL
- en: There were a couple of tricks we pulled to make the tests repeatable and independent.
    In every test after the first, we called the `reload` function on the `pid` module,
    to reload it from the disk. That has the effect of resetting anything that might
    have changed in the module, and causes it to re-import any modules that it depends
    on. That latter effect is particularly important, since in the tests of measure,
    we replaced `time.time` with a dummy function. We want to be sure that the `pid`
    module uses the dummy time function, so we reload the `pid` module. If the real
    time function is used instead of the dummy, the test won't be useful, because
    there will be only one time in all of history at which it would succeed. Tests
    need to be repeatable.
  prefs: []
  type: TYPE_NORMAL
- en: The dummy time function is created by making an iterator that counts through
    the integers from 1 to 999 (as floating point values), and binding `time.time`
    to that iterator's `next` method. Once we were done with the time-dependent tests,
    we replaced the original `time.time`.
  prefs: []
  type: TYPE_NORMAL
- en: Right now, we have tests for a module that doesn't exist. That's good! Writing
    the tests was easier than writing the module will be, and it gives us a stepping
    stone toward getting the module right, quickly and easily. As a general rule,
    you always want to have tests ready before the code that they test is written.
  prefs: []
  type: TYPE_NORMAL
- en: Pop quiz – unit testing during design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Why should we care whether tests are independent of each other, when the code
    they're testing is imaginary and the tests can't even be run?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are you, as a programmer, writing tests during this phase? Should this be
    part of the job of the people writing the specification instead?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tests at this phase try to make use of code that hasn't been written yet, and
    so they end up—in a sense—defining that code. What advantages and disadvantages
    does this have?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Have a go hero
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Try this a few times on your own: Describe some program or module that you''d
    enjoy having access to in real life, using normal language. Then go back through
    it and try writing tests, describing the program or module. Keep an eye out for
    places where writing the test makes you aware of ambiguities in your prior description,
    or makes you realize that there''s a better way to do something.'
  prefs: []
  type: TYPE_NORMAL
- en: Development phase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With tests in hand, we're ready to write some code. The tests will act as a
    guide to us, a specification that actively tells us when we get something wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Time for action – unit testing during development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first step is to run the tests. Of course, we have a pretty good idea of
    what's going to happen; they're all going to fail. Still, it's useful to know
    exactly what the failures are, because those are the things that we need to address
    by writing code.![Time for action – unit testing during development](img/8846_03_01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are many more failing tests after that, but you get the idea.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Taking our cue from the tests, and our references on PID controllers, we write
    the `pid.py` module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next we run the tests again. We're hoping that they will all pass, but unfortunately
    the measure method seems to have some sort of bug.![Time for action – unit testing
    during development](img/8846_03_02.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are several more reports showing similar things (five tests in total should
    fail). The measure function is working backwards, returning positive numbers when
    it should be returning negative, and vice-versa.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We know we need to look for a sign error in the measure method, so we don''t
    have too much trouble finding and fixing the bug. The measured value should be
    subtracted from the setpoint, not the other way around, on the fourth line of
    the `measure` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After fixing that, we find that all the tests pass.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*What just happened?*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We used our tests to tell us what needed to be done and when our code was finished.
    Our first run of the tests gave us a list of things that needed to be written;
    a to-do list, of sorts. After we wrote some code, we ran the tests again to see
    if it was doing what we expected, which gave us a new to-do list. We keep on alternating
    between running the tests and writing code until the tests all passed. When all
    the tests pass, either we're done, or we need to write more tests.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we find a bug that isn't already caught by a test, the right thing
    to do is to add a test that catches it, and then to fix it. That way, you not
    only have a fixed bug, you have a test that covers some aspect of the program
    that wasn't tested before. That test may well catch other bugs in the future,
    or tell you if you accidentally re-introduced the original bug.
  prefs: []
  type: TYPE_NORMAL
- en: This "test a little, code a little" style of programming is called *Test-Driven
    Development*, and you'll find that it's very productive.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the pattern in the way the tests failed was immediately apparent.
    There's no guarantee that this will always be the case, of course, but it's quite
    common. Combined with the ability to narrow your attention to the specific units
    that are having problems, debugging is usually a snap.
  prefs: []
  type: TYPE_NORMAL
- en: Another thing to think about is test isolation. The methods of the `PID` class
    make use of variables stored in `self`, which means that in order for the tests
    to be isolated, we have to make sure that none of the changes to `self` variables
    made by any method propagate to any other method. We did that by just reloading
    the `pid` module and making a new instance of the `PID` class for each test. As
    long as the test (and the code being tested) doesn't invoke any other methods
    on `self`, that's all that we need.
  prefs: []
  type: TYPE_NORMAL
- en: Feedback phase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, we have a PID controller, and it passes all the tests. We're feeling pretty
    good. Time to brave the lions, and show it to the client!
  prefs: []
  type: TYPE_NORMAL
- en: 'Luckily for us, for the most part they like it. They do have a few requests,
    though: They want us to let them optionally specify the current time as a parameter
    to `measure`, instead of just using `time.time` to figure it out. They also want
    us to change the signature of the constructor so that it takes an initial measurement
    and optional time as parameters. Finally, they want us to rename the `measure`
    function to `calculate_response`, because they think that more clearly describes
    what it does.'
  prefs: []
  type: TYPE_NORMAL
- en: Time for action – unit testing during feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, how are we going to deal with this? The program passes all the tests, but
    the tests no longer reflect the requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Add the initial parameter to the constructor test, and update the expected results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a second constructor test, which tests the optional time parameter that
    is now expected to be part of the constructor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the `measure` method's name to `calculate_response` in all tests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the initial constructor parameter in the `calculate_response` test – while
    we're doing that, we notice that this is going to change the way the `calculate_response`
    function behaves. We contact the client for clarification, and they decide it's
    okay, so we update the expectations to match what we calculate should happen after
    the change.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a second `calculate_response` test, which checks its behavior when the optional
    time parameter is supplied.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After making all those changes, our specification/test file looks like the following.
    Lines that have been changed or added are formatted differently, to help you spot
    them more easily.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*What just happened?*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our tests didn't match the requirements any more, so they had to change.
  prefs: []
  type: TYPE_NORMAL
- en: Well and good, but we don't want them to change too much, because our collection
    of tests helps us avoid regressions in our code. Regressions are changes that
    cause something that used to work, to stop working. One of the best ways to avoid
    them is to avoid deleting tests. If you still have tests in place that check for
    every desired behavior and every bug fixed, then if you introduce a regression
    you find out about it immediately.
  prefs: []
  type: TYPE_NORMAL
- en: That's one reason why we added new tests to check the behavior when the optional
    time parameters are supplied. The other reason is that if we added those parameters
    to the existing tests, we wouldn't have any tests of what happens when you don't
    use those parameters. We always want to check every code path through each unit.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, a test just isn't right any more. For example, tests that make use
    of the `measure` method are just plain wrong, and need to be updated to call `calculate_response`
    instead. When we change these tests, though, we still change them as little as
    possible. After all, we don't want the test to stop checking for old behavior
    that's still correct, and we don't want to introduce a bug in the test itself.
  prefs: []
  type: TYPE_NORMAL
- en: The addition of the `initial` parameter to the constructor is a big deal. It
    not only changes the way the constructor should behave, it also changes the way
    the `calculate_response` (née `measure`) method should behave in a rather dramatic
    way. Since this is a change in the correct behavior (a fact which we didn't realize
    until the tests pointed it out to us, which in turn allowed us to get confirmation
    of what the correct behavior should be from our clients *before* we started writing
    the code), we have no choice but to go through and change the tests, recalculating
    the expected outputs. However, doing all that work has a benefit over and above
    the future ability to check that the function is working correctly; it makes it
    much easier to comprehend how the function should work when we actually write
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Back to the development phase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Well, it's time to go back into development. In real life, there's no telling
    how often we'd have to cycle back and forth between development and feedback,
    but we would want to keep the cycle short. The more often we switch back and forth,
    the more in contact we are with what our clients really want, and that makes for
    a more productive, more rewarding job.
  prefs: []
  type: TYPE_NORMAL
- en: Time for action – unit testing during development... again
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've got our updated tests, so now it's time to get back into a state where
    all of our tests pass.
  prefs: []
  type: TYPE_NORMAL
- en: First off, let's run the tests, and so get a new list of things that need to
    be done.![Time for action – unit testing during development... again](img/8846_03_03.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are several more error reports after this, of course. Doctest reports
    a total of 32 failing examples, although that's not particularly meaningful since
    none of the tests are able to even construct a PID object right now. Fixing that
    constructor would be a reasonable place to start.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Using the doctest report as a guide, we set about adjusting the PID class.
    This is going to work best as an iterative process, where we make a few changes,
    then run the tests, then make a few changes, and so on. In the end, though, we''ll
    end up with something like the following (the `push_setpoint` and `pop_setpoint`
    methods are unchanged, so they''ve been omitted here to save space):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We check the tests again, and they all pass.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*What just happened?*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This wasn't very different from our first time through the development phase.
    Just as before, we had a set of tests, and the error report from those tests gives
    us a checklist of things we need to fix. As we work, we keep an eye out for things
    that need to be tested, but aren't yet, and add those tests. When all the tests
    pass, we check with our client again (which means we go back to the feedback phase).
    Eventually the client will be satisfied. Then we can move on to releasing the
    code, and then into the maintenance phase.
  prefs: []
  type: TYPE_NORMAL
- en: As we're working, the tests give us a nice, fast way to get a sense of whether
    what we're doing works, and how far along we are. It makes it easy for us to see
    that the code we're writing does something, which in turn makes the coding process
    flow better, and even makes it more fun. Writing code that just sits there is
    boring and bug-prone, but because we have the tests, our code doesn't just sit
    there. It's active, and we can see the results at any time.
  prefs: []
  type: TYPE_NORMAL
- en: Maintenance phase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we've passed on our work to our client, we have to make sure that they
    stay happy with it. That means fixing any bugs that may have slipped past our
    tests (hopefully not many) and making small improvements on request.
  prefs: []
  type: TYPE_NORMAL
- en: Time for action – unit testing during maintenance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our client has come to us with a change request: they don''t want the `PID`
    class to accept negative gain values in its constructor, because negative gains
    make its output push things further away from the `setpoint`, instead of pulling
    them toward it.'
  prefs: []
  type: TYPE_NORMAL
- en: We add new tests that describe what should happen when negative gains are passed
    to the constructor. We're testing something that the old tests don't describe,
    so we get to leave the old tests alone and just add new tests. That's a good thing,
    because it means that the old tests will be certain to catch any regressions that
    we might introduce while we're working on this.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the tests to see what needs doing. As we might expect in this case, doctest
    reports three failures, one for each of the tests we just added – The `PID` class
    didn't raise the expected `ValueError`s.![Time for action – unit testing during
    maintenance](img/8846_03_05.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now we write the code that will make the `PID` class pass the tests. That''s
    easily done by adding the following to the constructor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We run the tests again, and when they all pass, we can report to our client
    that the change has been implemented.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember, if doctest doesn't print anything, then all the tests passed. It only
    tells you about errors, unless you pass `-v` on its command line.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*What just happened?*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: That looked pretty straightforward, but the fact is that our body of tests was
    a big help to us here. When we're mucking around in a codebase, trying to update
    its behavior, or to fix a bug that we've never even considered might exist, it's
    easy to break other parts of the program. This is doubly so when the codebase
    is one that we haven't worked with for a while, as is often the case with maintenance
    requests. Thanks to the expertise stored inthe tests that we wrote, we don't have
    to worry about forgetting details of what constitutes correct behavior, or what
    might go wrong in various parts of the code. We don't have to waste time or effort
    re-learning those details when we come back to the code. Instead, we can just
    execute the tests.
  prefs: []
  type: TYPE_NORMAL
- en: Our clients don't necessarily know about our testing process, but they appreciate
    the fast turnaround time we can give them because of it.
  prefs: []
  type: TYPE_NORMAL
- en: Reuse phase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Eventually, there comes a time when—if the code we wrote is useful—we'll want
    to use it again in a different project. That means we're going to be putting it
    in a context where the assumptions made in the code may no longer be valid.
  prefs: []
  type: TYPE_NORMAL
- en: Time for action – unit testing during reuse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our client wants to use a PID controller in a new project, but there''s a twist:
    The value that''s going to be measured and controlled is represented as a complex
    number. When we wrote the PID controller, there was an implicit assumption that
    the values would always be representable as floating point numbers. What do we
    have to do to re-use this code? Let''s find out.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By the way, if you don't know what complex numbers are, don't worry. They're
    not actually complicated; a complex number is just a pair of coordinates, much
    like latitude and longitude.
  prefs: []
  type: TYPE_NORMAL
- en: Write some tests that use complex numbers for `setpoint`, `initial` and the
    measurements. Since we want to make sure we don't break code that still uses floating
    point numbers, we don't replace the older tests, we just add more.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You''ll notice that we''re using some very random-looking numbers here. They''re
    not random at all. Complex numbers can be thought of as representing coordinates;
    they represent the same values that we used in our earlier tests, except rotated
    `45` degrees and translated by `1+1j`. For example, where before we used the value
    `12`, we now use the value of `12 * complex(cos(0.25 * pi), sin(0.25 * pi))+ (1+1j)`,
    which is `9.4852813742385695+9.4852813742385695j`. If you don''t understand, or
    don''t care, it''s enough to know that the same expression can be used to calculate
    the value of every complex number in this example: just substitute the appropriate
    number in place of the `12`. You can find `sin`, `cos` and `pi` in the `math`
    module.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (Some of the input lines here are very long, and have to be wrapped to fit onto
    the page. They shouldn't be wrapped in the doctest file.)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Okay, the correct behavior has been calculated and the tests have been written.
    Let's run them and see what doesn't work. We run the doctests, and the first thing
    that comes out of it is an exception raised in the constructor. It looks like
    our floating point assumption is already causing trouble. There are several more
    error reports after this, but since the constructor didn't work, we can't expect
    them to make much sense.![Time for action – unit testing during reuse](img/8846_03_04.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The problems in the constructor arise from passing complex numbers into the
    constructor for the `float` class, which is not allowed. Do we really need to
    call `float` there? Sometimes we do, because we don't want to use integers for
    `setpoint` and `initial`. Integer division doesn't work the same way as floating
    point division in versions of Python less than 3.0, so integers could severely
    mess up the behavior of the system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'So, we want to call the `float` constructor on `initial` and `setpoint`, *unless*
    they are complex numbers. That makes the constructor look like this (again, watch
    out for the wrapping of long lines):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Okay, we've fixed the constructor. We run the tests again, and all the tests
    pass! Somewhat surprisingly, perhaps, the `calculate_response` function is already
    compatible with complex numbers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*What just happened?*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Writing our tests originally helped us to determine what assumptions we were
    making, and the tests check those assumptions explicitly. Furthermore, even the
    assumptions that we didn't know we were making have a tendency to be checked by
    our tests, because they are implicit in our expectations. An example of this is
    the floating point results that the tests expected. If we had just removed the
    calls to float in the constructor entirely, all of those tests that were expecting
    a float would have failed, telling us that we'd violated an implicit assumption
    about the behavior of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Our tests give us confidence that our code is correct (even when its operating
    on complex numbers), and that we haven't broken anything else by changing the
    code. No muss, no fuss; it works. If one of the tests had failed, that would have
    told us where the problems lay. Either way, we know where we are in the project
    and what needs to be done next, which lets us keep the process rolling along.
  prefs: []
  type: TYPE_NORMAL
- en: Pop quiz – unit testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you write a test, should you do it while referring to the code being tested,
    or should you do it based on your expectations of what correct behavior should
    be, before the code is even written?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True or false: You should avoid changing or deleting tests whenever possible,
    and prefer changing them to deleting them when you aren''t able to keep them untouched.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How often do you think your tests should be run? Can you think of any particularly
    good times to execute the tests?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If your development process is test driven, you as a programmer will spend most
    of your time doing what?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Have a go hero – test-driven development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Try using the methods that we''ve talked about in this chapter to implement
    this plain language specification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We learned a lot in this chapter about Unit testing and Test-Driven Development,
    which are best-practice disciplines for quickly building reliable programs.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, we covered the definition of Unit testing, how unit testing can
    help during each stage of the development process, what it feels like to use unit
    testing to drive development, and how it can make the process quicker and more
    pleasant.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've learned about Unit testing, we're ready to talk about making
    it easier to isolate tests with the help of mock objects—which is the topic of
    the next chapter.
  prefs: []
  type: TYPE_NORMAL
