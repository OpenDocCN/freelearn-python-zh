- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Strings, Serialization, and File Paths
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we get involved with higher-level design patterns, let''s take a deep
    dive into one of Python''s most common objects: the string. We''ll see that there
    is a lot more to the string than meets the eye, and we''ll also cover searching
    strings for patterns, and serializing data for storage or transmission.'
  prefs: []
  type: TYPE_NORMAL
- en: 'All of these topics are elements of making objects persistent. Our application
    can create objects in files for use at a later time. We often take persistence
    – the ability to write data to a file and retrieve it at an arbitrary later date
    – for granted. Because persistence happens via files, at the byte level, via OS
    writes and reads, it leads to two transformations: data we have stored must be
    decoded into a nice, useful object collection of objects in memory; objects from
    memory need to be encoded to some kind of clunky text or bytes format for storage,
    transfer over the network, or remote invocation on a distant server.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll look at the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The complexities of strings, bytes, and byte arrays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ins and outs of string formatting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The mysterious regular expression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use the `pathlib` module to manage the filesystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A few ways to serialize data, including Pickle and JSON
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter will extend the case study to examine how best to work with collections
    of data files. We'll look at another serialization format, CSV, in the case study.
    This will help us explore alternative representations for the training and testing
    data.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start by looking Python strings. They do so much and it's easy to overlook
    the wealth of available features.
  prefs: []
  type: TYPE_NORMAL
- en: Strings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Strings are a basic primitive in Python; we've used them in nearly every example
    we've discussed so far. All they do is represent an immutable sequence of characters.
    However, though you may not have considered it before, *character* is a bit of
    an ambiguous word; can Python strings represent sequences of accented characters?
    Chinese characters? What about Greek, Cyrillic, or Farsi?
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python 3, the answer is yes. Python strings are all represented in Unicode,
    a character definition standard that can represent virtually any character in
    any language on the planet (and some made-up languages and random characters as
    well). This is done seamlessly. So, let''s think of Python 3 strings as an immutable
    sequence of Unicode characters. We''ve touched on many of the ways strings can
    be manipulated in previous examples, but let''s quickly cover it all in one place:
    a crash course in string theory!'
  prefs: []
  type: TYPE_NORMAL
- en: It's very important to step away from the older encodings we used to know and
    love. The ASCII encoding, for example, was limited to one byte per character.
    Unicode has several ways to encode a character into bytes. The most popular, called
    UTF-8, tends to parallel the old ASCII encoding for some punctuation and letters.
    It's approximately one byte per character. But, if you need one of the thousands
    of other Unicode characters, there may be multiple bytes involved.
  prefs: []
  type: TYPE_NORMAL
- en: 'The important rule is this: we *encode* our characters to create bytes; we
    *decode* bytes to recover the characters. The two are separated by a high fence
    with a gate labeled encode on one side and decode on the other. We can visualize
    it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17070_09_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: Strings and bytes'
  prefs: []
  type: TYPE_NORMAL
- en: There's a potential source of confusion that arises from the canonical display
    of a bytes value. Python will show a bytes value as `b'Flamb\xc3\xa9'`. In a bytes
    value, the letters are shorthand for numbers and use the older ASCII encoding
    scheme.
  prefs: []
  type: TYPE_NORMAL
- en: For most letters, the UTF-8 and ASCII encoding are the same. The `b'` prefix
    tells us these are bytes, and the letters are really only ASCII codes, not proper
    Unicode characters. We can see this because the Unicode `é` – encoded in UTF-8
    – takes two bytes, and there's no ASCII shorthand for either of those bytes.
  prefs: []
  type: TYPE_NORMAL
- en: String manipulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you know, strings can be created in Python by wrapping a sequence of characters
    in single or double quotes. Multiline strings can easily be created using three
    quote characters, and multiple hardcoded strings can be concatenated together
    by placing them side by side. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: That last string is automatically composed into a single string by the interpreter.
    It is also possible to concatenate strings using the `+` operator (as in `"hello
    " + "world"`). Of course, strings don't have to be hardcoded. They can also come
    from various outside sources, such as text files and user input, or can be transmitted
    on the network.
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch for missing operators**'
  prefs: []
  type: TYPE_NORMAL
- en: The automatic concatenation of adjacent strings can make for some hilarious
    bugs when a comma is missed. It is, however, extremely useful when a long string
    needs to be placed inside a function call without exceeding the 79-character line-length
    limit suggested by PEP-8, the Python style guide.
  prefs: []
  type: TYPE_NORMAL
- en: Like other sequences, strings can be iterated over (character by character),
    indexed, sliced, or concatenated. The syntax is the same as for lists and tuples.
  prefs: []
  type: TYPE_NORMAL
- en: The `str` class has numerous methods on it to make manipulating strings easier.
    The `dir()` and `help()` functions can tell us how to use all of them; we'll consider
    some of the more common ones directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several Boolean convenience methods help us identify whether or not the characters
    in a string match a certain pattern. Most of these, such as `isalpha()`, `isupper()`,
    `islower()`, `startswith()`, and `endswith()`, have reasonably easy-to-understand
    interpretations. The `isspace()` method is also fairly obvious, but remember that
    all whitespace characters (including tab and newline) are considered, not just
    the space character. When in doubt, the `help()` function is useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `istitle()` method returns `True` if the first character of each word is
    capitalized and all other characters are lowercase. Note that it does not strictly
    enforce the English grammatical definition of title formatting. For example, Leigh
    Hunt's poem *The Glove and the Lions* follows common style guides for a title,
    but doesn't fit the narrow rule of Python's method. Similarly, Robert Service's *The
    Cremation of Sam McGee* follows the usual English rules for a valid title, even
    though there is an uppercase letter in the middle of the last word; Python's `istitle()`
    method will return `False`, unaware of the rules for capitalizing a name like
    McGee or words like *and* *the* in a title.
  prefs: []
  type: TYPE_NORMAL
- en: 'Be careful with the `isdigit()`, `isdecimal()`, and `isnumeric()` methods,
    as they are more nuanced than we would expect. Many Unicode characters are considered
    numbers besides the 10 digits we are used to. Worse, the period character that
    we use to construct floats from strings is not considered a decimal character,
    so `''45.2''.isdecimal()` returns `False`. The real decimal character is represented
    by the Unicode value 0660, as in 45.2 (or `45\u06602`). Further, these methods
    do not verify whether the strings are valid numbers; `127.0.0.1` returns `True` for
    all three methods. We might think we should use that decimal character instead
    of a period for all numeric quantities, but passing that character into the `float()` or `int()` constructor
    converts that decimal character to a zero:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of all these inconsistencies is that the Boolean numeric checks
    must be used carefully, knowing the details of the rules. We''ll often need to
    write a regular expression (discussed later in this chapter) to confirm whether
    the string matches a specific numeric pattern. We call this LBYL-style programming:
    "Look Before You Leap." One very common approach is to use a `try/except` block
    wrapped around an `int()` or `float()` conversion attempt. We call this EAFP-style
    programming: "It''s Easier to Ask Forgiveness than to Ask Permission." The EAFP
    style fits naturally with Python.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other methods useful for pattern-matching do not return Booleans. The `count()`
    method tells us how many times a given substring shows up in the string, while
    `find()`, `index()`, `rfind()`, and `rindex()` tell us the position of a given
    substring within the original string. Most operations start at the zero index
    and work from left to right. The two `r` (for *right* or *reverse*) methods start
    searching from the highest index end of the string and work from right to left.
    The `find()` methods return `-1` if the substring can''t be found, while `index()`
    raises a `ValueError` exception in this situation. Have a look at some of these
    methods in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Most of the remaining string methods return transformations of the string. The
    `upper()`, `lower()`, `capitalize()`, and `title()` methods create new strings
    with all alphabetical characters following the given format rules. The `translate()` method
    can use a dictionary to map arbitrary input characters to specified output characters.
  prefs: []
  type: TYPE_NORMAL
- en: For all of these methods, note that the input string remains unmodified; a brand
    new `str` instance is created. If we need to manipulate the resultant string,
    we should assign it to a new variable, as in `new_value = value.capitalize()`.
    Often, once we've performed the transformation, we don't need the old value anymore,
    so a common idiom is to assign it to the same variable, as in `value = value.title()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, a couple of string methods return or operate on lists. The `split()` method
    accepts a substring and splits the string into a list of strings breaking wherever
    that substring occurs. You can pass a number as a second parameter to limit the
    number of resultant strings. The `rsplit()` method behaves identically to `split()` if
    you don''t limit the number of strings, but if you do supply a limit, it starts
    splitting from the end of the string. The `partition()` and `rpartition()` methods
    split the string at only the first or last occurrence of the substring, and return
    a tuple of three values: characters before the substring, the substring itself,
    and the characters after the substring.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As the inverse of `split()`, the `join()` method accepts a list of strings,
    and returns all of those strings combined together by placing the original string
    between them. The `replace()` method accepts two arguments, and returns a string
    where each instance of the first argument has been replaced with the second. Here
    are some of these methods in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: There you have it, a whirlwind tour of the most common methods on the `str` class!
    Now, let's look at Python 3's approach to composing strings and values from variables
    and other expressions to create new strings.
  prefs: []
  type: TYPE_NORMAL
- en: String formatting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python 3 has powerful string formatting and templating mechanisms that allow
    us to construct strings comprised of template text and interspersed representations
    of objects usually from variables, but also from expressions. We've used it in
    many previous examples, but it is much more versatile than the simple formatting
    specifiers we've used.
  prefs: []
  type: TYPE_NORMAL
- en: 'A format string (also called an **f-string**) has a prefix on the opening quotation
    mark of `f`, as in `f"hello world"`. If such a string contains the special characters `{` and `}`,
    expressions, including variables from the surrounding scope, are evaluated and
    then interpolated into the string. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run these statements, it replaces the braces with variables, in order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Escaping braces
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Brace characters are often useful in strings, aside from formatting. We need
    a way to escape them in situations where we want them to be displayed as themselves,
    rather than being replaced. This can be done by doubling the braces. For example,
    we can use Python to format a basic Java program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Where we see the `{{` and `}}` sequence in the template – that is, the braces
    enclosing the Java class and method definition – we know the f-string will replace
    them with single braces, rather than some argument in the surrounding methods.
    Here''s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The class name and contents of the output have been replaced with two parameters,
    while the double braces have been replaced with single braces, giving us a valid
    Java file. Turns out, this is about the simplest possible Python program to print
    the simplest possible Java program that can print the simplest possible Python
    program.
  prefs: []
  type: TYPE_NORMAL
- en: f-strings can contain Python code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We aren't restricted to interpolating the values of simple string variables
    into an f-string template. Any primitives, such as integers or floats, can be
    formatted. More interestingly, complex objects, including lists, tuples, dictionaries,
    and arbitrary objects, can be used, and we can access indexes and variables or
    call functions on those objects from within the `format` string.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if our email message had grouped the `From` and `To` email addresses
    into a tuple and placed the subject and message in a dictionary, for some reason
    (perhaps because that''s the input required for an existing `send_mail` function
    we want to use), we can format it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The variables inside the braces in the template string look a little weird,
    so let's look at what they're doing. The two email addresses are looked up by
    the expression `emails[x]`, where `x` is either `0` or `1`. This is an ordinary
    tuple indexing operation, so `emails[0]` refers to the first item in the `emails` tuple.
    Similarly, the expression `message['subject']` gets an item from a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: 'This works out particularly well when we have a more complex object to display.
    We can extract object attributes and properties and even call methods inside the
    f-string. Let''s change our email message data once again, this time to a class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s an instance of the `Notification` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use this email instance to fill in an f-string as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Pretty much any Python code that you would expect to return a string (or a
    value that can convert to a string with the `str()` function) can be executed
    inside an f-string. As an example of how powerful it can get, you can even use
    a list comprehension or ternary operator in a format string parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In some cases, we''ll want to include a label on the value. This is great for
    debugging; we can add an `=` suffix to the expression. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This technique creates a label and a value for us. It can be very helpful. Of
    course, there are a number of more sophisticated formatting options available
    to us.
  prefs: []
  type: TYPE_NORMAL
- en: Making it look right
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It''s nice to be able to include variables in template strings, but sometimes
    the variables need a bit of coercion to make them look the way we want them to
    in the output. We''re planning a sailing trip around the Chesapeake Bay. Starting
    from Annapolis, we want to visit Saint Michaels, Oxford, and Cambridge. To do
    this, we''ll need to know the distances among these sailing ports. Here''s a useful
    distance computation for relatively short distances. First, the formal math, because
    that can help explain the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17070_09_001.png)'
  prefs: []
  type: TYPE_IMG
- en: This follows the same pattern as the hypotenuse of a triangle computation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17070_09_002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are some differences, which are important:'
  prefs: []
  type: TYPE_NORMAL
- en: We wrote ![](img/B17070_09_003.png) for the differences in the north-south latitudes,
    converted to radians from degrees. This seemed simpler than ![](img/B17070_09_004.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We wrote ![](img/B17070_09_005.png) for the differences in the east-west longitudes,
    converted to radians from degrees. This is simpler than ![](img/B17070_09_006.png).
    In some parts of the world, the longitudes will be a mix of positive and negative
    numbers, and we'll need to sort out the minimum positive-valued distance rather
    than compute a trip all the way around the world.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The value of R converts radians to nautical miles (about 1.85 km, 1.15 statute
    miles, exactly 1/60th of a degree of latitude).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cosine computation reflects the way longitude distances compress toward
    zero at the pole. At the north pole, we can walk in a tiny circle and cover all
    360°. At the equator, we have to walk (or walk and sail) 40,000 km to cover the
    same 360°.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Otherwise, this is similar to the `math.hypot()` function we used in the *Chapter
    3* case study, which means it involves square roots and awkwardly too-precise
    floating-point numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s our test case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: That sounds like fun. A `17.070608794` nautical mile trip in a sailboat going
    about 6 knots will take 2.845101465666667 hours to cross the bay. If the wind
    is lighter, maybe we'll only go 5 knots, and the trip will take 3.4141217588000004
    hours.
  prefs: []
  type: TYPE_NORMAL
- en: This is too many decimal places to be really useful. The boat is 42 feet (12.8m)
    long; that's 0.007 nautical miles; so, anything after the third decimal place
    is noise, not a useful result. We'll need to adjust these distances to provide
    useful information. Also, we have multiple legs, and we don't want to treat each
    leg as a special case. We need to provide better organization and better display
    of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Here's how we'd like to plan this trip. First, we'll define our four waypoints
    for the places we want to go. Then we'll combine the waypoints into legs.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then use the distance computation to figure out how far it is to each
    destination. We can figure the speed to cover the distance, and we can even compute
    the fuel required if we can''t sail and have to motor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: While we've structured the whole journey, we still have too many digits. Distances
    only need two decimal places at most. A tenth of an hour is six minutes; we don't
    need too many digits there. And fuel, similarly, can be computed to the nearest
    tenth of a gallon. (A tenth of a gallon is 0.4 liters.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The f-string substitution rules include formatting that can help us. After
    the expression (a variable is a very simple expression), we can use `:` followed
    by a detailed description of the layout of the numbers. We''ll return to the details
    after an example. Here''s an improved plan with more useful print formatting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'As an example, the `:5.2f` format specifier says the following, from left to
    right:'
  prefs: []
  type: TYPE_NORMAL
- en: '`5`: take up at most five spaces – this guarantees column alignment when using
    a fixed-width font'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.`: show the decimal point'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2`: show two places after the decimal'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`f`: format the input value as a floating-point numeric value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nifty! The location is formatted as `16s`. This follows the same pattern as
    the float format:'
  prefs: []
  type: TYPE_NORMAL
- en: '`16` means it should take up 16 characters. By default, with strings, if the
    string is shorter than the specified number of characters, it appends spaces to
    the right-hand side of the string to make it long enough (beware, however: if
    the original string is too long, it won''t be truncated!).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s` means it is a string value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we wrote the headings, we used an odd-looking f-string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This has string literals like `'leg'` with a format of `16s`, and `'dist'` with
    a format of `5s`. The sizes are copied from the detail lines to make sure the
    headers fit over their respective columns. Making sure the sizes match makes it
    easy to be sure the heading and the details align.
  prefs: []
  type: TYPE_NORMAL
- en: 'All these format specifiers have the same pattern; the details are optional:'
  prefs: []
  type: TYPE_NORMAL
- en: A filler character (space if nothing is provided) that's used to pad out the
    number to fill in the specified size.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The alignment rule. By default, numbers are right-aligned and strings are left-aligned.
    Characters like `<`, `^`, and `>` can force left, centered, or right alignment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to handle the sign (default is `–` for negative, nothing for positive.)
    You can use `+` to show all signs. Also, " " (a space) leaves a space for positive
    numbers and `-` for negative numbers to assure proper alignment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `0` if you want leading zeroes to fill in the front of the number.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The overall size of the field. This should include signs, decimal places, commas,
    and the period itself for floating-point numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `,` if you want 1,000 groups separated by ",". Use `_` to separate groups
    with an "_". If you have a locale where grouping is done with ".", and the decimal
    separator is ",", you'll want to use the `n` format to use all of the locale settings.
    The `f` format is biased toward locales that use "," for grouping.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `.` if it's a float (`f`) or general (`g`) number, followed by the number
    of digits to the right of the decimal point.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The type. Common types are `s` for strings, `d` for decimal integers, and `f`
    for floating-point. The default is `s` for string. Most of the other format specifiers
    are alternative versions of these; for example, `o` represents octal format and `X` represents
    hexadecimal format for integers. The `n` type specifier can be useful for formatting
    any kind of number in the current locale's format. For floating-point numbers,
    the `%` type will multiply by 100 and format a float as a percentage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a very sophisticated way to display numbers. It can simplify otherwise
    confusing output, by reducing clutter and aligning data into columns when the
    information is related.
  prefs: []
  type: TYPE_NORMAL
- en: '**Faulty Navigation Advice**'
  prefs: []
  type: TYPE_NORMAL
- en: These waypoints are a little misleading. The route from St. Michaels to Oxford
    is only 6.41 miles if you're a bird. There's a big peninsula in the way, and it's
    actually a delightfully longer trip outside Poplar and Tilghman Islands and up
    the Choptank River. A superficial analysis of distances needs to be backed up
    with actually looking at the nautical chart and inserting a number of additional
    waypoints. Our algorithm permits this, and updating the list of legs is easy.
  prefs: []
  type: TYPE_NORMAL
- en: Custom formatters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'While these standard formatters apply to most built-in objects, it is also
    possible for other objects to define nonstandard specifiers. For example, if we
    pass a `datetime` object into `format`, we can use the specifiers used in the
    `datetime.strftime()` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: It is even possible to write custom formatters for objects we create ourselves,
    but that is beyond the scope of this book. Look into overriding the `__format__()` special
    method if you need to do this in your code.
  prefs: []
  type: TYPE_NORMAL
- en: The Python formatting syntax is quite flexible, but it is a difficult mini-language
    to remember. It's helpful to bookmark the page in the Python standard library
    to help look up details. While good for many things, this formatting capability
    isn't powerful enough for larger-scale templating needs, such as generating web
    pages. There are several third-party templating libraries you can look into if
    you need to do more than basic formatting of a few strings.
  prefs: []
  type: TYPE_NORMAL
- en: The format() method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'F-strings were introduced in Python 3.6\. Since Python 3.5''s support ended
    in 2020 (see PEP-478 for details), we no longer need to worry about old Python
    runtimes without f-strings. There''s a slightly more general tool for plugging
    values into a string template: the `format()` method of a string. It uses the
    same formatting specifiers as f-strings. The values come from parameter values
    to the `format()` method. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The `format()` method behaves similarly to an f-string with one important distinction:
    you can access values provided as the arguments to the `format()` method only.
    This permits us to provide message templates as configuration items in a complex
    application.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have three ways to refer to the arguments that will be inserted into the
    template string:'
  prefs: []
  type: TYPE_NORMAL
- en: '**By name**: The example has `{label}` and `{number}` in the template and provides
    the `label=` and `number=` named arguments to the `format()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**By position**: We can use `{0}` in the template, and this will use the first
    positional argument to `format()`, like this: `"Hello {0}!".format("world")`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**By implied position**: We can use `{}` in the template, and this will use
    the positional arguments in order from the template, like this: `"{} {}!".format("Hello",
    "world")`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Between f-strings and the `format()` method of a template, we can create complex
    string values by interpolating expressions or values into a template. In most
    cases, the f-string is what we need. In rare cases where a format string might
    be a configuration parameter for a complex application, the `format()` method
    is helpful.
  prefs: []
  type: TYPE_NORMAL
- en: Strings are Unicode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the beginning of this section, we defined strings as immutable collections
    of Unicode characters. This actually makes things very complicated at times, because
    Unicode isn't a storage format. If you get a string of bytes from a file or a
    socket, for example, they won't be in Unicode. They will, in fact, be the built-in
    type `bytes`. Bytes are immutable sequences of...well, bytes. Bytes are the basic
    storage format in computing. They represent 8 bits, usually described as an integer
    between 0 and 255, or a hexadecimal equivalent between `0x00` and `0xFF`. Bytes
    don't represent anything specific; a sequence of bytes may store characters of
    an encoded string, or pixels in an image, or represent an integer, or part of
    a floating-point value.
  prefs: []
  type: TYPE_NORMAL
- en: If we print a `bytes` object, Python uses a canonical display that's reasonably
    compact. Any of the individual byte values that map to ASCII characters are displayed
    as characters, while non-character ASCII bytes are printed as escapes, either
    a one-character escape like `\n` or a hex code like `\x1b`. You may find it odd
    that a byte, represented as an integer, can map to an ASCII character. But the
    old ASCII code defined Latin letters for many different byte values. In ASCII
    the character `a` is represented by the same byte as the integer 97, which is
    the hexadecimal number `0x61`. All of these are an interpretation of the binary
    pattern `0b1100001`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how the canonical display bytes might look when they have a mixture
    of values that have ASCII character representations and values that don''t have
    a simple character:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The first byte used a hexadecimal escape, `\x89`. The next three bytes had ASCII
    characters, `P`, `N`, and `G`. The next two characters had one-character escapes,
    `\r` and `\n`. The seventh byte also had a hexadecimal escape, `\x1a`, because
    there was no other encoding. The final byte is another one-character escape, `\n`.
    The eight bytes were expanded into 17 printable characters, not counting the prefix
    `b'` and the final `'`.
  prefs: []
  type: TYPE_NORMAL
- en: Many I/O operations only know how to deal with `bytes`, even if the `bytes` object
    is the encoding of textual data. It is therefore vital to know how to convert
    between `bytes` values and Unicode `str` values.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is that there are many encodings that map `bytes` to Unicode text.
    Several are true international standards, but many others are parts of commercial
    offerings, making them really popular, but not – exactly – standardized. The Python
    `codecs` module provides many of these code-decode rules for decoding bytes into
    a string and encoding a string into bytes.
  prefs: []
  type: TYPE_NORMAL
- en: The important consequence of multiple encodings is that the same sequence of
    bytes represents completely different text characters when mapped using different
    encodings! So, `bytes` must be decoded using the same character set with which
    they were encoded. It's not possible to get text from bytes without knowing how
    the bytes should be decoded. If we receive unknown bytes without a specified encoding,
    the best we can do is guess what format they are encoded in, and we are likely
    to be wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Decoding bytes to text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If we have an array of `bytes` from somewhere, we can convert it to Unicode
    using the `.decode()` method on the `bytes` class. This method accepts a string
    for the name of the character encoding. There are many such encodings; common
    ones include ASCII, UTF-8, latin-1, and cp-1252\. Of these, UTF-8 is one of the
    most commonly used.
  prefs: []
  type: TYPE_NORMAL
- en: 'The sequence of bytes (in hex), `63 6c 69 63 68 c3 a9`, actually represents
    the characters of the word cliche in UTF-8 encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The first line creates a `bytes` literal as a `b''` string. The `b` character
    immediately before the string tells us that we are defining a `bytes` object instead
    of a normal Unicode text string. Within the string, each byte is specified using
    – in this case – a hexadecimal number. The `\x` character escapes within the byte
    string, and each says *the next two characters represent a byte using hexadecimal
    digits*.
  prefs: []
  type: TYPE_NORMAL
- en: The final line is the output, showing us Python's canonical representation of
    a `bytes` object. The first five of the seven bytes had an ASCII character that
    could be used. The final two bytes, however, don't have ASCII characters, and
    `\xc3\xa9` had to be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Provided we are using a shell that understands UTF-8 encoding, we can decode
    the bytes to Unicode and see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The `decode` method returns a text (Unicode) `str` object, with the correct
    characters. Note that the `\xc3\xa9` sequence of bytes maps to a single Unicode
    character.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, the Python terminal may not have the correct encodings defined
    so the operating system can pick the right characters from the OS font. Yes, there's
    a very complex mapping from bytes to text to displayed characters, part of which
    is a Python problem, and part of which is an OS problem. Ideally, your computer
    is using UTF-8 encodings and has fonts with the full Unicode character set. If
    not, you may need to research the `PYTHONIOENCODING` environment variable. See
    [https://docs.python.org/3.9/using/cmdline.html#envvar-PYTHONIOENCODING](https://docs.python.org/3.9/using/cmdline.html#envvar-PYTHONIOENCODING).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if we had decoded this same string using the Cyrillic `iso8859-5` encoding,
    we''d have ended up with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This is because the `\xc3\xa9`  bytes map to different characters in the other
    encoding. Over the years a lot of different encodings have been invented, and
    not all of them are in wide use.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This is why we need to know the encoding used. Generally, UTF-8 should be the
    encoding of choice. This is a common default, but it isn't universal.
  prefs: []
  type: TYPE_NORMAL
- en: Encoding text to bytes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The flip side of converting bytes to Unicode is situations where we convert
    outgoing Unicode into byte sequences. This is done with the `encode()` method
    on the `str` class, which, like the `decode()` method, requires an encoding name.
    The following code creates a Unicode string and encodes it in different character
    sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Now you should understand the importance of encodings! The accented character
    is represented as a different byte by most of these encodings; if we use the wrong
    one when we are decoding bytes to text, we get the wrong character.
  prefs: []
  type: TYPE_NORMAL
- en: 'The exception in the last case is not always the desired behavior; there may
    be cases where we want the unknown characters to be handled in a different way.
    The `encode` method takes an optional string argument named `errors` that can
    define how such characters should be handled. This string can be one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`"strict"`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"replace"`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"ignore"`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"xmlcharrefreplace"`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `strict` replacement strategy is the default we just saw. When a byte sequence
    is encountered that does not have a valid representation in the requested encoding,
    an exception is raised. When the `replace` strategy is used, the character is
    replaced with a different character. In ASCII, it is a question mark; other encodings
    may use different symbols, such as an empty box.
  prefs: []
  type: TYPE_NORMAL
- en: The `ignore` strategy simply discards any bytes it doesn't understand, while
    the `xmlcharrefreplace` strategy creates an `xml` entity representing the Unicode
    character. This can be useful when converting unknown strings for use in an XML
    document.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how each of the strategies affects our sample word:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: It is possible to call the `str.encode()` and `bytes.decode()` methods without
    passing an encoding name. The encoding will be set to the default encoding for
    the current platform. This will depend on the current operating system and locale
    or regional settings; you can look it up using the `sys.getdefaultencoding()`
    function. It is usually a good idea to specify the encoding explicitly, though,
    since the default encoding for a platform may change, or the program may one day
    be extended to work on text from a wider variety of sources.
  prefs: []
  type: TYPE_NORMAL
- en: If you are encoding text and don't know which encoding to use, it is best to
    use UTF-8 encoding. UTF-8 is able to represent any Unicode character. In modern
    software, it is a widely used, standard encoding to ensure documents in any language—or
    even multiple languages—can be exchanged. The various other possible encodings
    are useful for legacy documents or in software that uses different character encodings
    by default.
  prefs: []
  type: TYPE_NORMAL
- en: The UTF-8 encoding uses one byte to represent ASCII and other common characters,
    and up to four bytes for other characters. UTF-8 is special because it is (mostly)
    backward-compatible with ASCII; an ASCII document encoded using UTF-8 will be
    almost identical to the original ASCII document.
  prefs: []
  type: TYPE_NORMAL
- en: '**Encode vs. Decode**'
  prefs: []
  type: TYPE_NORMAL
- en: It's hard to remember whether to use `encode` or `decode` to convert from binary
    bytes to Unicode text. The problem is that the letters "code" in Uni*code* can
    be confusing. I suggest ignoring them. If we think of bytes as code, we encode
    plain text to bytes and decode bytes back to plain text.
  prefs: []
  type: TYPE_NORMAL
- en: Mutable byte strings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `bytes` type, like `str`, is immutable. We can use index and slice notation
    on a `bytes` object and search for a particular sequence of bytes, but we can't
    extend or modify them. This can be inconvenient when dealing with I/O, as it is
    often necessary to buffer incoming or outgoing bytes until they are ready to be
    sent. For example, if we are receiving data from a socket, we may have to accumulate
    the results of several `recv` calls before we have received an entire message.
  prefs: []
  type: TYPE_NORMAL
- en: This is where the `bytearray` built-in comes in. This type behaves something
    like a list, except it only holds bytes. The constructor for the class can accept
    a `bytes` object to initialize it. The `extend` method can be used to append another `bytes` object
    to the existing array (for example, when more data comes from a socket or other
    I/O channel).
  prefs: []
  type: TYPE_NORMAL
- en: 'Slice notation can be used on `bytearray` to modify the item in place, without
    the overhead of creating a new object. For example, this code constructs a `bytearray` from
    a `bytes` object and then replaces two bytes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: We used slice notation to replace bytes in the `[4:6]` slice with two replacement
    bytes, `b"\x15\xa3"`.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to manipulate a single element in `bytearray`, the value must be
    an integer between 0 and 255 (inclusive), which is a specific `bytes` pattern.
    If we try to pass a character or `bytes` object, it will raise an exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'A single byte character can be converted to an integer using the `ord()` (short
    for *ordinal*) function. This function returns the integer representation of a
    single character:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: After constructing the array, we replace the character at index `3` (the fourth
    character, as indexing starts at `0`, as with lists) with byte `103`. This integer
    was returned by the `ord()` function and is the ASCII character for the lowercase `g`.
  prefs: []
  type: TYPE_NORMAL
- en: For illustration, we also replaced the next character up with byte number `68`,
    which maps to the ASCII character for the uppercase `D`.
  prefs: []
  type: TYPE_NORMAL
- en: The `bytearray` type has methods that allow it to behave like a list (we can
    append integer bytes to it, for example). It can also behave like a `bytes` object
    (we can use methods such as `count()` and `find()`). The difference is that `bytearray` is
    a mutable type, which can be useful for building up complex sequences of bytes
    from a specific input source. We may, for example, have to read a four byte header
    with length information before reading the payload bytes. It's handy to be able
    to perform the reads directly into a mutable `bytearray` to save creating lots
    of small objects in memory.
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You know what's really hard to do using object-oriented principles? Parsing
    strings to match arbitrary patterns, that's what. There have been a fair number
    of academic papers written in which object-oriented design is used to set up string-parsing,
    but the results seem too verbose and hard to read, and they are not widely used
    in practice.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, string-parsing in most programming languages is handled by
    regular expressions. These are not verbose, but, wow, are they ever hard to read,
    at least until you learn the syntax. Even though regular expressions are not object-oriented,
    the Python regular expression library provides a few classes and objects that
    you can use to construct and run regular expressions.
  prefs: []
  type: TYPE_NORMAL
- en: While we use regular expressions to "match" a string, this is only a partial
    description of what a regular expression really is. It can help to think of a
    regular expression as a mathematical rule that could generate a (potentially infinite)
    collection of strings. When we "match" a regular expression, it's similar to asking
    if a given string is in the set generated by the expression. What's tricky is
    rewriting some fancy math using the paltry collection of punctuation marks available
    in the original ASCII character set. To help explain the syntax of regular expressions,
    we'll take a little side-tour through some of these typographic problems that
    make regular expressions a challenge to read.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an idealized mathematical regular expression for a small set of strings:
    *world*. We want to match these five characters. The set has one string, `"world"`,
    that matches. This doesn''t seem too complex; the expression amounts to w AND
    o AND r AND l AND d with "AND" being implied. This parallels the way ![](img/B17070_09_007.png)
    means d = r *times* t; the multiplication is implied.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a regular expression for a pattern with repeats: ![](img/B17070_09_008.png).
    We want to match five characters, but one of them must occur twice. This set has
    one string, `"hello"`, that matches. This emphasizes the parallel between regular
    expressions, multiplication, and exponents. It also points out the use of exponents
    to distinguish between matching the `2` character and matching the previous regular
    expression two times.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, we want some flexibility, and we want to match any digit. Mathematical
    typesetting lets us use a new font for this: we can say ![](img/B17070_09_009.png).
    This fancy-looking D means any digit, or ![](img/B17070_09_010.png), and the raised
    4 means four copies. This describes a set that has 10,000 possible matching strings
    from "0000" to "9999". Why use the fancy math typesetting? We can use different
    fonts and letter arrangements to distinguish the concept of "any digit" and "four
    copies" from the letter `D` and the digit `4`. Code – as we''ll see – lacks the
    fancy fonts, forcing designers to work around the distinction between letters
    meaning themselves, like `D`, and letters having other useful meanings, like ![](img/B17070_09_011.png).'
  prefs: []
  type: TYPE_NORMAL
- en: And yes, a regular expression looks a lot like a long multiplication. There's
    a very strong parallel with "must have these" and multiplication. Is there a parallel
    with addition? Yes, it's the idea of optional or alternative constructs; in effect
    an "or" instead of the default "and."
  prefs: []
  type: TYPE_NORMAL
- en: What if we want to describe years in a date where there could be two digits
    or four digits? Mathematically, we might say ![](img/B17070_09_012.png). What
    if we're not sure how many digits? We have a special "to any power," the Kleene
    star. We can say ![](img/B17070_09_013.png) to mean any number of repeats of a
    character in the ![](img/B17070_09_014.png) set.
  prefs: []
  type: TYPE_NORMAL
- en: All of this math typesetting has to be implemented in the regular expression
    language. This can make it difficult to sort out precisely what a regular expression
    means.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regular expressions are used to solve a common problem: given a string, determine
    whether that string matches a given pattern and, optionally, collect substrings
    that contain relevant information. They can be used to answer questions such as
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Is this string a valid URL?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the date and time of all warning messages in a log file?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which users in `/etc/passwd` are in a given group?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What username and document were requested by the URL a visitor typed?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many similar scenarios where regular expressions are the correct answer.
    In this section, we'll gain enough knowledge of regular expressions to compare
    strings against relatively common patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are important limitations here. Regular expressions don''t describe languages
    with recursive structures. When we look at XML or HTML, for example, a `<p>` tag
    can contain inline `<span>` tags, like this: `<p><span>hello</span><span>world</span></p>`.
    This recursive nesting of tag-within-tag is generally not a great thing to try
    and process with a regular expression. We can recognize the individual elements
    of the XML language, but higher-level constructs like a paragraph tag with other
    tags inside it require more powerful tools than regular expressions. The XML parsers
    in the Python standard library can handle these more complex constructs.'
  prefs: []
  type: TYPE_NORMAL
- en: Matching patterns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Regular expressions are a complicated mini-language. We need to be able to
    describe individual characters as well as classes of characters, as well as operators
    that group and combine characters, all using a few ASCII-compatible characters.
    Let''s start with literal characters, such as letters, numbers, and the space
    character, which always match themselves. Let''s see a basic example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The Python Standard Library module for regular expressions is called `re`. We
    import it and set up a search string and pattern to search for; in this case,
    they are the same string. Since the search string matches the given pattern, the
    conditional passes and the `print` statement executes.
  prefs: []
  type: TYPE_NORMAL
- en: A successful match returns a `re.Match` object describing what – exactly – matched.
    A failing match returns `None`, which is equivalent to `False` in the Boolean
    context of an `if`-statement.
  prefs: []
  type: TYPE_NORMAL
- en: We've used the "walrus" operator (`:=`) to compute the results of `re.match()`
    and save those results in a variable all as part of an `if`-statement. This is
    one of the most common ways to use the walrus operator to compute a result and
    then test the result to see if it's truthy. This is a little optimization that
    can help clarify how the results of the matching operation will be used if they
    are not `None`.
  prefs: []
  type: TYPE_NORMAL
- en: We'll almost always use "raw" strings with the `r` prefix for regular expressions.
    Raw strings do not have the backslash escapes processed by Python into other letters.
    In an ordinary string, for example, `\b` is transformed to a single backspace
    character. In a raw string, it's two characters, `\` and `b`. In this example,
    the r-string wasn't really needed because the pattern didn't involve any special
    `\d` or `\w` kinds of regular expression symbols. Using r-strings is a good habit,
    and we'll try to do it consistently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bear in mind that the `match` function matches the pattern anchored at the
    beginning of the string. Thus, if the pattern were `r"ello world"`, no match would
    be found because the `search_string` value starts with "h" not "e". With confusing
    asymmetry, the parser stops searching as soon as it finds a match, so the pattern `r"hello
    wo"` matches the `search_string` value successfully, with a few characters left
    over. Let''s build a small example program to demonstrate these differences and
    help us learn other regular expression syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The `matchy()` function expands on the earlier example; it accepts the pattern
    and search string as parameters. We can see how the start of the pattern must
    match, but a value is returned as soon as a match is found.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of using this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: We'll be using this function throughout the next few sections. A sequence of
    test cases is a common way to develop a regular expression – from a bunch of examples
    of text we want to match and text we don't want to match, we test to make sure
    our expression works as expected.
  prefs: []
  type: TYPE_NORMAL
- en: If you need control over whether items happen at the beginning or end of a line
    (or if there are no newlines in the string, or at the beginning and end of the
    string), you can use the `^` and `$` characters to represent the start and end
    of the string respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want a pattern to match an entire string, it''s a good idea to include
    both of these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We call the `^` and `$` characters "anchors." They anchor the match to the beginning
    or end of the string. What's important is that they don't literally match themselves;
    they're also called meta-characters. If we were doing fancy math typesetting,
    we'd use a different font to distinguish between `^` meaning anchored at the beginning
    and `^` meaning the actual `"^"` character. Since we don't have fancy math typesetting
    in Python code, we use `\` to distinguish between meta-character and ordinary
    character. In this case, `^` is a meta-character, and `\^` is the ordinary character.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Because we used `\^`, we need to match the `^` character in the string; this
    is not the meta-character acting as an anchor. Note that we used `r"\^hello…"`
    to create a raw string. Python's canonical display came back as `'\\^hello…'`.
    The canonical version – with double `\\` – can be awkward to type. While raw strings
    are easier to work with, they don't display the way we entered them.
  prefs: []
  type: TYPE_NORMAL
- en: Matching a selection of characters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s start with matching an arbitrary character. The period character, when
    used in a regular expression pattern, is a meta-character that stands for a set
    containing all characters. This will match any single character. Using a period
    in the string means you don''t care what the character is, just that there is
    a character there. Here is some example output from the `matchy()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the last example does not match because there is no character at
    the period's position in the pattern. We can't match "nothing" without some extra
    features. We'll get to the idea of optional characters later in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s all well and good, but what if we only want a smaller set of characters
    to match? We can put a set of characters inside square brackets to match any one
    of those characters. So, if we encounter the string `[abc]` in a regular expression
    pattern, this defines a set of alternatives to match one character in the string
    being searched; this one character will be in the set of characters. Note that
    the `[]` around the set are meta-characters; they enclose the set and don''t match
    themselves. Let''s see a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: As with `^` and `$`, the characters `.`, `[` and `]` are meta-characters. Meta-characters
    define a more complex feature of a regular expression. If we want to actually
    match a `[` character, we'd use `\[` to escape the meta-meaning and understand
    this to match `[` instead of starting the definition of a class of characters.
  prefs: []
  type: TYPE_NORMAL
- en: 'These square bracket sets could be named *character sets*, but they are more
    often referred to as **character classes**. Often, we want to include a large
    range of characters inside these sets, and typing them all out can be monotonous
    and error-prone. Fortunately, the regular expression designers thought of this
    and gave us a shortcut. The dash character, in a character set, will create a
    range. This is especially useful if you want to match *all lowercase letters*, *all
    letters*, or *all numbers,* as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'There are some character classes that are so common they have their own abbreviations.
    `\d` is digits, `\s` is whitespace, and `\w` is "word" characters. Instead of
    `[0-9]`, use `\d`. Instead of trying to enumerate all the Unicode whitespace characters,
    use `\s`. Instead of `[a-z0-9_]`, use `\w`. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Without the defined sets, this pattern would start out as `[0-9][0-9][ \t\n\r\f\v][A-Za-z0-9_][A-Za-z0-9_][A-Za-z0-9_]`.
    It gets quite long as we repeat the `[ \t\n\r\f\v]` class and the `[0-9]` class
    four more times.
  prefs: []
  type: TYPE_NORMAL
- en: When defining a class with `[]`'s, the `–` becomes a meta-character. What if
    we want to match `[A-Z]` and `-`, too? We can do this by including the `–` at
    the very beginning or the very end; `[A-Z-]` means any character between `A` and
    `Z`, and the `-`, also.
  prefs: []
  type: TYPE_NORMAL
- en: Escaping characters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we've noted above, a lot of characters have special meanings. For example,
    putting a period character in a pattern matches any arbitrary character. How do
    we match just a period in a string? We'll use backslashes to escape the special
    meaning and change the character from a meta-character (like a class definition,
    or an anchor or the start of a class) and understand it as an ordinary character.
    This means we'll often have a bunch of `\` characters in a regular expression,
    making r-strings really helpful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a regular expression to match two-digit decimal numbers between 0.00
    and 0.99:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: For this pattern, the two characters `\.` match the single `.` character. If
    the period character is missing or is a different character, it will not match.
  prefs: []
  type: TYPE_NORMAL
- en: This backslash escape sequence is used for a variety of special characters in
    regular expressions. You can use `\[` to insert a square bracket without starting
    a character class, and `\(` to insert a parenthesis, which we'll later see is
    also a meta-character.
  prefs: []
  type: TYPE_NORMAL
- en: More interestingly, we can also use the escape symbol followed by a character
    to represent special characters such as newlines (`\n`) and tabs (`\t`). As we
    saw earlier, some character classes can be represented more succinctly using escape
    strings.
  prefs: []
  type: TYPE_NORMAL
- en: To make the raw strings and backslashes more clear, we'll include the function
    calls again to show the code we wrote separate from Python's canonical display
    of the raw strings.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'To summarize, this use of a backslash has two distinct meanings:'
  prefs: []
  type: TYPE_NORMAL
- en: For meta-characters, a backslash escapes the meta-meaning. For example, `.`
    is a class of characters, whereas `\.` is a single character; similarly, `^` is
    an anchor at the start of a string, but `\^` is the hat character.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a few ordinary characters, a backslash is used to name a character class.
    There aren't many examples of this; the most commonly used are `\s`, `\d`, `\w`,
    `\S`, `\D`, and `\W`. The uppercase variants, `\S`, `\D`, and `\W`, are the inverses
    of the lower case. For example, `\d` is any digit, and `\D` is any non-digit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This odd distinction can be confusing at first. What's often helpful is to remember
    `\` in front of a letter creates a special case, whereas `\` in front of punctuation
    removes a meta-character meaning.
  prefs: []
  type: TYPE_NORMAL
- en: Repeating patterns of characters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With this information, we can match most strings of a known length, but most
    of the time, we don't know how many characters to match inside a pattern. Regular
    expressions can take care of this, too. We can modify a pattern with a suffix
    character. When we think of a regular expression as a product, a repeating sequence
    is like raising to a power. This follows the pattern of `a*a*a*a == a**4`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The asterisk (`*`) character says that the previous pattern can be matched
    zero or more times. This probably sounds silly, but it''s one of the most useful
    repetition characters. Before we explore why, consider some silly examples to
    make sure we understand what it does:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: So, the `*` character in the pattern says that the previous pattern (the `l` character)
    is optional, and if present, can be repeated as many times as possible to match
    the pattern. The rest of the characters (`h`, `e`, and `o`) have to appear exactly
    once.
  prefs: []
  type: TYPE_NORMAL
- en: 'This gets more interesting if we combine the asterisk with patterns that match
    multiple characters. So, `.*`, for example, will match any string, whereas `[a-z]*`
    matches any collection of lowercase letters, including the empty string. Here
    are a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The plus (`+`) sign in a pattern behaves similarly to an asterisk; it states
    that the previous pattern can be repeated one or more times; this means the expression
    is not optional. The question mark (`?`) ensures a pattern shows up exactly zero
    or one times, but not more. Let''s explore some of these by playing with numbers
    (remember that `\d` matches the same character class as `[0-9]`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: These examples illustrate the two different uses of `\`, also. For the `.` character,
    `\.` changes it from a meta-character that matches anything to a literal period.
    For the `d` character, `\d` changes it from a literal `d` to a class of characters,
    `[0-9]`. Don't forget that `*`, `+`, and `?` are meta-characters, and matching
    them literally means using `\*`, `\+`, or `\?`.
  prefs: []
  type: TYPE_NORMAL
- en: Grouping patterns together
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So far, we''ve seen how we can repeat a pattern multiple times, but we are
    restricted in what patterns we can repeat. If we want to repeat individual characters,
    we''re covered, but what if we want a repeating sequence of characters? Enclosing
    any set of patterns in parentheses allows them to be treated as a single pattern
    when applying repetition operations. Compare these patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: This follows from the core mathematics behind regular expressions. The formulas
    ![](img/B17070_09_015.png) and ![](img/B17070_09_016.png) have dramatically different
    meanings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Combined with complex patterns, this grouping feature greatly expands our pattern-matching
    repertoire. Here''s a regular expression that matches simple English sentences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: The first word starts with a capital, followed by zero or more lowercase letters,
    `[A-Z][a-z]*`. Then, we enter a parenthetical that matches a single space followed
    by a word of one or more lowercase letters, `[a-z]+`. This entire parenthetical
    is repeated zero or more times, `( [a-z]+)*`. The pattern is terminated with a
    period. There cannot be any other characters after the period, as indicated by
    the `$` anchor at the end of the pattern.
  prefs: []
  type: TYPE_NORMAL
- en: We've seen many of the most basic patterns, but the regular expression language
    supports many more. It is worth bookmarking Python's documentation for the `re` module
    and reviewing it frequently. There are very few things that regular expressions
    cannot match, and they should be the first tool you reach for when parsing strings
    that don't involve complex recursive definitions.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing information with regular expressions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's now focus on the Python side of things. The regular expression syntax
    is the furthest thing from object-oriented programming. However, Python's `re` module
    provides an object-oriented interface to enter the regular expression engine.
  prefs: []
  type: TYPE_NORMAL
- en: We've been checking whether the `re.match()` function returns a valid object
    or not. If a pattern does not match, that function returns `None`. If it does
    match, however, it returns a useful object that we can inspect for information
    about the pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, our regular expressions have answered questions such as *does this
    string match this pattern?* Matching patterns is useful, but in many cases, a
    more interesting question is *if this string matches this pattern, what is the
    value of a relevant substring?* If you use groups to identify parts of the pattern
    that you want to reference later, you can get them out of the match return value,
    as illustrated in the next example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The full specification describing all valid email addresses is extremely complicated,
    and the regular expression that accurately matches all possibilities is obscenely
    long. So, we cheated and made a smaller regular expression that matches many common
    email addresses; the point is that we want to access the domain name (after the `@` sign)
    so we can connect to that address. This is done easily by wrapping that part of
    the pattern in parentheses and calling the `group()` method on the object returned
    by `match()`.
  prefs: []
  type: TYPE_NORMAL
- en: We've used an additional argument value, `re.IGNORECASE`, to mark this pattern
    as case-independent. This saves us from having to use `[a-zA-Z…]` in three places
    in the pattern. It is a handy simplification when case doesn't matter.
  prefs: []
  type: TYPE_NORMAL
- en: There are three ways to collect the groups that match. We've used the `group()`
    method, which provides one matching group. Since there's only one pair of `()`'s,
    this seems prudent. The more general `groups()` method returns a tuple of all
    the `()` groups matched inside the pattern, which we can index to access a specific
    value. The groups are ordered from left to right. However, bear in mind that groups
    can be nested, meaning you can have one or more groups inside another group. In
    this case, the groups are returned in the order of their leftmost `(`'s, so the
    outermost group will be returned before its inner matching groups.
  prefs: []
  type: TYPE_NORMAL
- en: We can also provide names for groups. The syntax is very complex-looking. We
    have to use `(?P<name>…)` instead of `(…)` to collect the matched text as a group.
    The `?P<name>` is how we provide a group name of `name` inside the `()`'s. This
    lets us use the `groupdict()` method to extract names and their contents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an alternative to the email domain parser; this one uses named groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: We've changed the pattern to add `?P<name>` and `?<domain>` inside the `()`'s
    to provide names to these capture groups. This part of the regular expression
    doesn't change what is matched, it provides names to the capture groups.
  prefs: []
  type: TYPE_NORMAL
- en: Other features of the re module
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to the `match()` function, the `re` module provides a couple of
    other useful functions, `search()` and `findall()`. The `search()` function finds
    the first instance of a matching pattern, relaxing the restriction that the pattern
    should be implicitly anchored to the first letter of the string. Note that you
    can get a similar effect by using `match()` and putting a  `.*` character at the
    front of the pattern to match any characters between the start of the string and
    the pattern you are looking for.
  prefs: []
  type: TYPE_NORMAL
- en: The `findall()` function behaves similarly to `search()`, except that it finds
    all non-overlapping instances of the matching pattern, not just the first one.
    Think of it searching for the first match, then continuing the search after the
    end of the first matching to find the next one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of returning a list of `re.Match` objects, as you would expect, it
    returns a list of matching strings, or tuples. Sometimes it''s strings, sometimes
    it''s tuples. It''s not a very good API at all! As with all bad APIs, you''ll
    have to memorize the differences and not rely on intuition. The type of the return
    value depends on the number of bracketed groups inside the regular expression:'
  prefs: []
  type: TYPE_NORMAL
- en: If there are no groups in the pattern, `re.findall()` will return a list of
    strings, where each value is a complete substring from the source string that
    matches the pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there is exactly one group in the pattern, `re.findall()` will return a list
    of strings where each value is the contents of that group
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there are multiple groups in the pattern, `re.findall()` will return a list
    of tuples where each tuple contains a value from a matching group, in order
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consistency Helps**'
  prefs: []
  type: TYPE_NORMAL
- en: When you are designing function calls in your own Python libraries, try to make
    the function always return a consistent data structure. It is often good to design
    functions that can take arbitrary inputs and process them, but the return value
    should not switch from a single value to a list, or a list of values to a list
    of tuples depending on the input. Let `re.findall()` be a lesson!
  prefs: []
  type: TYPE_NORMAL
- en: 'The examples in the following interactive session will hopefully clarify the
    differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: It seems like it's always a good practice to decompose the data elements to
    the extent possible. In this case, we separated the numeric value from the units,
    hours, minutes, or seconds, making it easier to convert a complex string into
    a time interval.
  prefs: []
  type: TYPE_NORMAL
- en: Making regular expressions efficient
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Whenever you call one of the regular expression methods, the `re module` has
    to convert the pattern string into an internal structure that makes searching
    strings fast. This conversion takes a non-trivial amount of time. If a regular
    expression pattern is going to be reused multiple times (for example, inside a `for` or `while` statement),
    it would be better if this conversion step could be done only once.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is possible with the `re.compile()` method. It returns an object-oriented
    version of the regular expression that has been compiled down and has the methods
    we''ve explored (`match()`, `search()`, and `findall()`), among others. The changes
    to what we''ve seen are minor. Here''s what we''ve been using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: We can create a two-step operation, where a single pattern is reused for a number
    of strings.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Compiling the patterns in advance of using them is a handy optimization. It
    makes the application slightly simpler and a bit more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: 'This has definitely been a condensed introduction to regular expressions. At
    this point, we have a good feel for the basics and will recognize when we need
    to do further research. If we have a string pattern-matching problem, regular
    expressions will almost certainly be able to solve them for us. However, we may
    need to look up new syntax in a more comprehensive coverage of the topic. But
    now we know what to look for! Some tools, like Pythex at [https://pythex.org](https://pythex.org),
    can help develop and debug regular expressions. Let''s move on to a completely
    different topic: filesystem paths.'
  prefs: []
  type: TYPE_NORMAL
- en: Filesystem paths
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most operating systems provide a *filesystem*, a way of mapping a logical abstraction
    of *directories* (often depicted as *folders*) and *files* to the bits and bytes
    stored on a hard drive or another storage device. As humans, we typically interact
    with the filesystem using a drag-and-drop interface with images of folders and
    files of different types. Or we can use command-line programs such as `cp`, `mv`,
    and `mkdir`.
  prefs: []
  type: TYPE_NORMAL
- en: As programmers, we have to interact with the filesystem with a series of system
    calls. You can think of these as library functions supplied by the operating system
    so that programs can call them. They have a clunky interface with integer file
    handles and buffered reads and writes, and that interface is different depending
    on which operating system you are using. The Python `os` module exposes some of
    these underlying calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the `os` module is the `os.path` module. While it works, it''s not very
    intuitive. It requires a lot of string concatenation and you have to be conscious
    of OS differences. For example, there is an `os.sep` attribute representing the
    path separator; that''s a "`/`" on POSIX-compliant OSes and "`\`" for Windows.
    Using it can lead to code that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The `os.path` module conceals some of the platform-specific details. But this
    still forces us to work with paths as strings.
  prefs: []
  type: TYPE_NORMAL
- en: Working with filesystem paths in the form of strings is often irritating. Paths
    that are easy to type on the command line become illegible in Python code. When
    working with multiple paths (for example, when processing images in a data pipeline
    for a machine learning computer vision problem), just managing those directories
    becomes a bit of an ordeal.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the Python language designers included a module called `pathlib` in the
    standard library. It''s an object-oriented representation of paths and files that
    is much more pleasant to work with. The preceding path, using `pathlib`, would
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it's quite a bit easier to see what's going on. Notice the unique
    use of the division operator as a path separator so you don't have to do anything
    with `os.sep`. This is an elegant use of overloading Python's `__truediv__()`
    method to provide this feature for `Path` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a more real-world example, consider some code that counts the number of
    lines of code – excluding whitespace and comments – in all Python files in a given
    directory and subdirectories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: In typical `pathlib` usage, we rarely have to construct many `Path` objects.
    In this example, the base `Path` is provided as a parameter. The bulk of the `Path`
    manipulation is locating other files or directories relative to a given `Path`.
    The rest of the `Path`-related processing is asking for attributes of a specific
    `Path`.
  prefs: []
  type: TYPE_NORMAL
- en: The `count_sloc()` function looks at the name of the path, skipping names beginning
    with "`.`". This avoids the "`.`" and "`..`" directories, but it also skips directories
    like `.tox`, `.coverage`, or `.git` that are created by our tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three general cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Actual files that might have Python source. We make sure the suffix of the file
    name is `.py` to be sure we want to open the file. We'll call the given `scanner()`
    function to open and read each Python file. There are several approaches to counting
    source code; we've shown one here, in the `scan_python_1()` function that should
    be provided as an argument value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Directories. In this case, we iterate through the directory's content, calling
    `count_sloc()` on the items we find inside this directory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other filesystem objects like device mount names, symbolic links, devices, FIFO
    queues, and sockets. We ignore these.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Path.open` method takes similar arguments to the `open` built-in function,
    but it uses a more object-oriented syntax. We can use `Path('./README.md').open()` to
    open the file for reading, if the path already exists.
  prefs: []
  type: TYPE_NORMAL
- en: The `scan_python_1()` function iterates over each line in the file and adds
    it to the count. We skip whitespace and comment lines, since these don't represent
    actual source code. The total count is returned to the calling function.
  prefs: []
  type: TYPE_NORMAL
- en: Here's how we invoke this function to count lines of code in one directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: This shows the one-and-only `Path()` constructor in this fairly complex example.
    We leap up to the parent directory from the **current working directory** (**CWD**).
    From there we can descend into the `ch_02` subdirectory and rummage around, looking
    at directories and Python files.
  prefs: []
  type: TYPE_NORMAL
- en: This also shows how we provide the `scan_python_1()` function as the argument
    value for the scanner parameter. For more insight into using functions as parameters
    to other functions, see *Chapter 8*, *The Intersection of Object-Oriented and
    Functional Programming*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Path` class in the `pathlib` module has a method or property to cover
    pretty much everything you might want to do with a path. In addition to those
    we covered in the example, here are a few more methods and attributes of a `Path`
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '`.absolute()` returns the full path from the root of the filesystem. This helps
    show where relative paths came from.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.parent` returns a path to the parent directory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.exists()` checks whether the file or directory exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.mkdir()` creates a directory at the current path. It takes Boolean `parents` and `exist_ok` arguments
    to indicate that it should recursively create the directories if necessary and
    that it shouldn''t raise an exception if the directory already exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the standard library documentation at [https://docs.python.org/3/library/pathlib.html](https://docs.python.org/3/library/pathlib.html) for
    even more uses. The authors are proud to have contributed to this library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Almost all of the standard library modules that accept a string path can also
    accept a `pathlib.Path` object. An `os.PathLike` type hint is used to describe
    parameters that accept a `Path`. For example, you can open a ZIP file by passing
    a path into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Some external packages may not work with `Path` objects. In those cases, you'll
    have to cast the path to a string using `str(pathname)`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Statements vs. Lines of Code**'
  prefs: []
  type: TYPE_NORMAL
- en: The `scan_python_1()` function counts each line of a triple-quoted, multi-line
    strings as if they're lines of code. If we're sure each *physical* line matters,
    then a long docstring might be relevant, even when it's not really code. On the
    other hand, we might decide that we want to count meaningful *statements* instead
    of physical lines; in this case, we'll need a smarter function that uses the `ast`
    module. It's far, far better to work with the **Abstract Syntax Trees** (**ASTs**)
    than it is to try and work with the source text. Using the `ast` module doesn't
    change the `Path` processing. It's a little more complex than reading the text,
    and outside the scope of this book. If we count statements (not lines that could
    be statements or could be triple-quoted comments) there are 257 statements, in
    542 lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: We've looked at working strings, bytes, and filesystem paths. The next concept
    we need to cover is how to save our application's objects to files and recovering
    objects from the bytes of a file. We call this process serialization.
  prefs: []
  type: TYPE_NORMAL
- en: Serializing objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've been working with bytes and file paths as foundations that support working
    with persistent objects. To make an object persistent, we need to create a series
    of bytes that represent the state of the object, and write those bytes to a file.
    The missing piece of persistence, then, is this process of encoding objects as
    a series of bytes. We also want to decode objects and their relationships from
    a series of bytes. This encoding and decoding is also described as **serializing**
    and **deserializing**.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we look at web services, we''ll often see a service described as RESTful.
    The "REST" concept is REpresentational State Transfer; the server and client will
    exchange representations of object states. The distinction here can be helpful:
    the two pieces of software don''t exchange objects. The applications have their
    own internal objects; they exchange a representation of object state.'
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to serialize objects. We'll start with a simple and general
    approach using the `pickle` module. Later, we'll look at the `json` package as
    an alternative.
  prefs: []
  type: TYPE_NORMAL
- en: The Python `pickle` module is an object-oriented way to store object state directly
    in a special storage format. It essentially converts an object's state (and all
    the state of all the objects it holds as attributes) into a series of bytes that
    can be stored or transported however we see fit.
  prefs: []
  type: TYPE_NORMAL
- en: 'For basic tasks, the `pickle` module has an extremely simple interface. It
    comprises four basic functions for storing and loading data: two for manipulating
    file-like objects, and two for manipulating `bytes` objects so we can work with
    pickled objects without necessarily having an open file.'
  prefs: []
  type: TYPE_NORMAL
- en: The `dump()` method accepts an object to be written and a file-like object to
    write the serialized bytes to. A file-like object must have a `write()` method,
    and that method must know how to handle a `bytes` argument. This means a file
    opened for text output wouldn't work; we need to open the file with a mode value
    of `wb`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `load()` method does exactly the opposite; it reads a serialized object''s
    state from a file-like object. This object must have the proper file-like `read()`
    and `readline()` methods, each of which must, of course, return `bytes`. The `pickle` module
    will read the bytes and the `load()` method will return the fully reconstructed
    object. Here''s an example that stores and then loads some data in a list object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: This code serializes the object referred to by `some_list`. This includes the
    associated strings, and dictionaries, and even an integer. This is stored in the
    file and then loaded from the same file. In each case, we open the file using
    a `with` statement so that it is automatically closed. We've been careful to use
    modes of `wb` and `rb` to be sure the file is in bytes mode instead of text mode.
  prefs: []
  type: TYPE_NORMAL
- en: The `assert` statement at the end would raise an error if the newly loaded object
    was not equal to the original object. Equality does not imply that they are the
    same object. Indeed, if we were to print the `id()` of both objects, we would
    discover they are distinct objects with distinct internal identifiers. However,
    because they are both lists whose contents are equal, the two lists are also considered
    equal.
  prefs: []
  type: TYPE_NORMAL
- en: The `dumps()` and `loads()` functions behave much like their file-like counterparts,
    except they return or accept `bytes` instead of file-like objects. The `dumps` function
    requires only one argument, the object to be stored, and it returns a serialized `bytes` object.
    The `loads()` function requires a `bytes` object and returns the restored object.
    The `'s'` character in the method names is short for string; it's a legacy name
    from ancient versions of Python, where `str` objects were used instead of `bytes`.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to call `dump()` or `load()` on a single open file more than
    once. Each call to `dump` will store a single object (plus any objects it is composed
    of or contains), while a call to `load()` will load and return just one object.
    So, for a single file, each separate call to `dump()` when storing the object
    should have an associated call to `load()` when restoring at a later date.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to be aware that the representation of the state of an object
    is highly focused on a specific major release of Python. A pickle file created
    in Python 3.7, for example, may not be usable by Python 3.8\. This suggests that
    pickle files are good for temporary persistence, but not suitable for long-term
    storage or sharing among Python applications that might not all have a common
    version.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process of recovering the state of an object from a pickled representation
    can – under some circumstances – result in evaluating arbitrary code buried in
    the pickle file. This means a pickle file can be a vector for malicious code.
    This leads to a prominent warning in the documentation for the pickle module:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Warning**'
  prefs: []
  type: TYPE_NORMAL
- en: The pickle module is not secure. Only unpickle data you trust.
  prefs: []
  type: TYPE_NORMAL
- en: This advice generally leads us to avoid accepting pickle-format files without
    trusting the sender and having assurance no person in the middle has tampered
    with the file. An application that uses a pickle for a temporary cache has nothing
    to worry about.
  prefs: []
  type: TYPE_NORMAL
- en: Customizing pickles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With most common Python objects, pickling *just works*. Basic primitive types
    such as integers, floats, and strings can be pickled, as can any container objects,
    such as lists or dictionaries, provided the contents of those containers are also
    picklable. Further, and importantly, any object can be pickled, so long as all
    of its attributes are also picklable.
  prefs: []
  type: TYPE_NORMAL
- en: So, what makes an attribute unpicklable? Usually, it has something to do with
    dynamic attribute values subject to change. For example, if we have an open network
    socket, open file, running thread, subprocess, processing pool, or database connection
    stored as an attribute on an object, it will not make sense to pickle these objects.
    Device and operating system state will be meaningless when we attempt to reload
    the object later. We can't just pretend the original thread or socket connection
    exists when we reload! No, we need to somehow customize how such transient and
    dynamic data is dumped and loaded.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a class that loads the contents of a web page every hour to ensure
    that they stay up to date. It uses the `threading.Timer` class to schedule the
    next update:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Objects like `url`, `contents`, and `last_updated` are all picklable, but if
    we try to pickle an instance of this class, things go a little nutty on the `self.timer` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: That's not a very useful error, but it looks like we're trying to pickle something
    we shouldn't be pickling. That would be the `Timer` instance; we're storing a
    reference to `self.timer` in the `schedule()` method, and that attribute cannot
    be serialized.
  prefs: []
  type: TYPE_NORMAL
- en: When `pickle` tries to serialize an object, it simply tries to store the state,
    the value of the object's `__dict__` attribute; `__dict__` is a dictionary mapping
    all the attribute names on the object to their values. Luckily, before checking `__dict__`, `pickle` checks
    to see whether a `__getstate__()` method exists. If it does, it will store the
    return value of that method instead of the `__dict__` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add a `__getstate__()` method to our `URLPolling` class that simply
    returns a copy of the `__dict__` without the unpicklable timer object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: If we pickle an instance of this expanded version of `URLPolling`, it will no
    longer fail. And we can even successfully restore that object using `loads()`.
    However, the restored object doesn't have a `self.timer` attribute, so it will
    not be refreshing the content like it is designed to do. We need to somehow create
    a new timer (to replace the missing one) when the object is unpickled.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we might expect, there is a complementary `__setstate__()` method that can
    be implemented to customize unpickling. This method accepts a single argument,
    which is the object returned by `__getstate__`. If we implement both methods,
    `__getstate__()` is not required to return a dictionary, since `__setstate__()`
    will know what to do with whatever object `__getstate__()` chooses to return.
    In our case, we simply want to restore the `__dict__`, and then create a new timer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The parallels between `__init__()` and `__setstate__()` are important. Both
    involve a call to `self.schedule()` to create (or recreate) the internal timer
    object. This is a common pattern for working with pickled objects that have dynamic
    state that must be recovered.
  prefs: []
  type: TYPE_NORMAL
- en: The `pickle` module is very flexible and provides other tools to further customize
    the pickling process if you need them. However, these are beyond the scope of
    this book. The tools we've covered are sufficient for many basic pickling tasks.
    Objects to be pickled are normally relatively simple data objects. Some of the
    popular machine learning frameworks, like scikit-learn, use `pickle` to preserve
    the model that was created. This lets a data scientist use the model for predictions
    or for further testing.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the security limitation, we need an alternative format for exchanging
    data. A text-based format can be helpful because it's often easier to inspect
    a text file to be sure it isn't malicious. We'll look at JSON as a popular text-based
    serialization format.
  prefs: []
  type: TYPE_NORMAL
- en: Serializing objects using JSON
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many formats that have been used for text-based data exchange over
    the years. **Extensible Markup Language** (**XML**) is popular, but the files
    tend to be large. **Yet Another Markup Language** (**YAML**) is another format
    that you may see referenced occasionally. Tabular data is frequently exchanged
    in the **Comma-Separated Value** (**CSV**) format. Many of these are fading into
    obscurity and there are many more that you will encounter over time. Python has
    solid standard or third-party libraries for all of them.
  prefs: []
  type: TYPE_NORMAL
- en: Before using such libraries on untrusted data, make sure to investigate security
    concerns with each of them. XML and YAML, for example, both have obscure features
    that, used maliciously, can allow arbitrary commands to be executed on the host
    machine. These features may not be turned off by default. Do your research. Even
    something as simple-seeming as a ZIP file or a JPEG image can be hacked to create
    a data structure that can crash a web server.
  prefs: []
  type: TYPE_NORMAL
- en: '**JavaScript Object Notation** (**JSON**) is a human-readable format for exchanging
    data. JSON is a standard format that can be interpreted by a wide array of heterogeneous
    client systems. This means JSON is extremely useful for transmitting data between
    completely decoupled systems. The JSON format does not have any support for executable
    code; because only data can be serialized, it is more difficult to inject malicious
    content.'
  prefs: []
  type: TYPE_NORMAL
- en: Because JSON can be easily interpreted by JavaScript engines, it is often used
    for transmitting data from a web server to a JavaScript-capable web browser. If
    the web application serving the data is written in Python, the server needs a
    way to convert internal data into the JSON format.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a module to do this, predictably named `json`. This module provides
    a similar interface to the `pickle` module, with `dump()`, `load()`, `dumps()`,
    and `loads()` functions. The default calls to these functions are nearly identical
    to those in `pickle`, so let''s not repeat the details. There are a couple of
    differences: obviously, the output of these calls is valid JSON notation, rather
    than a pickled object. In addition, the `json` functions operate on `str` objects,
    rather than `bytes`. Therefore, when dumping to or loading from a file, we need
    to create text files rather than binary ones.'
  prefs: []
  type: TYPE_NORMAL
- en: The JSON serializer is not as robust as the `pickle` module; it can only serialize
    basic types such as integers, floats, and strings, and simple containers such
    as dictionaries and lists. Each of these has a direct mapping to a JSON representation,
    but JSON is unable to represent objects unique to Python like class or function
    definitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, the `json` module''s functions try to serialize the object''s state
    using the value of the object''s `__dict__` attribute. A better approach is to
    supply custom code to serialize an object''s state into a JSON-friendly dictionary.
    We also want to go the other way: deserializing a JSON dictionary to recover a
    Python object''s state.'
  prefs: []
  type: TYPE_NORMAL
- en: In the `json` module, both the object encoding and decoding functions accept
    optional arguments to customize the behavior. The `dump()` and `dumps()` functions
    accept a poorly named `cls` keyword argument. (It's short for "class", which we
    have to spell funny because `class` is a reserved keyword.) If this argument value
    is provided to the function, it should be a subclass of the `JSONEncoder` class,
    with the `default()` method overridden. This overridden `default()` method accepts
    an arbitrary Python object and converts it to a dictionary that `json` can serialize.
    If it doesn't know how to process the object, we should call the `super()` method,
    so that it can take care of serializing basic types in the normal way.
  prefs: []
  type: TYPE_NORMAL
- en: The `load()` and `loads()` methods also accept such a `cls` argument that can
    be a subclass of the inverse class, `JSONDecoder`. However, it is normally sufficient
    to pass a function into these methods using the `object_hook` keyword argument.
    This function accepts a dictionary and returns an object; if it doesn't know what
    to do with the input dictionary, it can return it unmodified.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example. Imagine we have the following simple contact class
    that we want to serialize:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'We can try to serialize the `__dict__` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'But accessing the special `__dict__` attribute in this fashion is kind of crude.
    This can lead to problems when an attribute has a value that''s not already serialized
    by the `json` module; `datetime` objects are a common problem. Also, what if the
    receiving code (perhaps some JavaScript on a web page) wanted that `full_name` property
    to be supplied? Of course, we could construct the dictionary by hand, but let''s
    create a custom encoder instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The `default` method needs to check to see what kind of object we're trying
    to serialize. If it's a `Contact`, we convert it to a dictionary manually. Otherwise,
    we let the parent class handle serialization (by assuming that it is a basic type,
    which `json` knows how to handle). Notice that we pass an extra attribute to identify
    this object as a contact, since there would be no way to tell upon loading it.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, we may want to provide a more complete, fully qualified name,
    including the package and module. Remember that the format of the dictionary depends
    on the code at the receiving end; there has to be an agreement as to how the data
    is going to be specified.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use this class to encode a contact by passing the class (not an instantiated
    object) to the `dump` or `dumps` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'For decoding, we can write a function that accepts a dictionary and checks
    the existence of the `__class__` attribute to decide whether to convert it to
    a `Contact` instance or leave it as a default dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'We can pass this function to the `load()` or `loads()` function using the `object_hook` keyword
    argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: These examples show how we can use JSON to exchange objects that encode a number
    of common Python objects. For uncommon Python objects, there are straightforward
    ways to add an encoder or a decoder to handle more complex cases. In larger applications,
    we might include a special `to_json()` method to produce a useful serialization
    of an object.
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters of the case study, we've been skirting an issue that
    arises frequently when working with complex data. Files have both a logical layout
    and a physical format. We've been laboring under a tacit assumption that our files
    are in CSV format, with a layout defined by the first line of the file. In *Chapter
    2,* we touched on file loading. In *Chapter 6*, we revisited loading data and
    partitioning it into training and testing sets.
  prefs: []
  type: TYPE_NORMAL
- en: In both previous chapters, we trusted that the data would be in a CSV format.
    This isn't a great assumption to make. We need to look at the alternatives and
    elevate our assumptions into a design choice. We also need to build in the flexibility
    to make changes as the context for using our application evolves.
  prefs: []
  type: TYPE_NORMAL
- en: It's common to map complex objects to dictionaries, which have a tidy JSON representation.
    For this reason, the `Classifier` web application makes use of dictionaries. We
    can also parse CSV data into dictionaries. The idea of working with dictionaries
    provides a kind of grand unification of CSV, Python, and JSON. We'll start by
    looking at the CSV format before moving on to some alternatives for serialization,
    like JSON.
  prefs: []
  type: TYPE_NORMAL
- en: CSV format designs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can make use of the `csv` module to read and write files. **CSV** stands
    for **Comma-Separated Values**, designed (originally) to export and import data
    from a spreadsheet.
  prefs: []
  type: TYPE_NORMAL
- en: The CSV format describes a sequence of rows. Each row is a sequence of strings.
    That's all there is, and it can be a bit of a limitation.
  prefs: []
  type: TYPE_NORMAL
- en: The "comma" in CSV is a role, not a specific character. The purpose of this
    character is to separate the columns of data. For the most part, the role of the
    comma is played by the literal "`,`". But other actors can fill this role. It's
    common to see the tab character, written as "`\t`" or "`\x09`", fill the role
    of the comma.
  prefs: []
  type: TYPE_NORMAL
- en: The end-of-line is often the CRLF sequence, written as "`\r\n`" or `\x0d\x0a`.
    On macOS X and Linux, it's also possible to use a single newline character, `\n`,
    at the end of each row. Again, this is a role, and other characters could be used.
  prefs: []
  type: TYPE_NORMAL
- en: In order to contain the comma character within a column's data, the data can
    be quoted. This is often done by surrounding a column's value with the `"` character.
    It's possible to specify a different quote character when describing a CSV dialect.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because CSV data is simply a sequence of strings, any other interpretation
    of the data requires processing by our application. For example, within the `TrainingSample` class,
    the `load()` method includes processing like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: This `load()` method extracts specific column values from each row, applies
    a conversion function to build a Python object from the text, and uses all of
    the attribute values to build a resulting object.
  prefs: []
  type: TYPE_NORMAL
- en: There are two ways to consume (and produce) CSV-formatted data. We can work
    with each row as a dictionary, or we can process each row as a simple list of
    strings. We'll look at both alternatives to see how well they apply to the data
    in our case study.
  prefs: []
  type: TYPE_NORMAL
- en: CSV dictionary reader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can read CSV files as a sequence of strings, or as a dictionary. When we
    read the file as a sequence of strings, there are no special provisions for column
    headers. We're forced to manage the details of which column has a particular attribute.
    This is unpleasantly complex, but sometimes necessary.
  prefs: []
  type: TYPE_NORMAL
- en: We can also read a CSV file so each row becomes a dictionary. We can provide
    a sequence of keys, or the first line of the file can provide the keys. This is
    relatively common, and it saves a little bit of confusion when the column headers
    are part of the data.
  prefs: []
  type: TYPE_NORMAL
- en: We've been looking at the Bezdek Iris data for our case study. There's a copy
    of the data in the Kaggle repository, [https://www.kaggle.com/uciml/iris](https://www.kaggle.com/uciml/iris).
    The data is also available at [https://archive.ics.uci.edu/ml/datasets/iris](https://archive.ics.uci.edu/ml/datasets/iris).
    The UCI Machine Learning Repository file, `bezdekIris.data`, does not have column
    titles; these are provided separately in a file named `iris.names`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `iris.names` file has a great deal of information in it, including this
    in section 7 of the document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: This defines the five columns of data. This separation between the metadata
    and the sample data isn't ideal, but we can copy and paste this information into
    code to make something useful from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll use it to define an Iris reader class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: We transformed the documentation into a sequence of column names. The transformation
    isn't arbitrary. We matched the resulting `KnownSample` class attribute names.
  prefs: []
  type: TYPE_NORMAL
- en: In relatively simple applications, there's a single source of data, so the attribute
    names for classes and column names for CSV files are easy to keep aligned. This
    isn't always the case. In some problem domains, the data may have several variant
    names and formats. We may choose attribute names that seem good, but may not simply
    match any of the input files.
  prefs: []
  type: TYPE_NORMAL
- en: The `data_iter()` method has a name suggesting it is an iterator over multiple
    data items. The type hint (`Iterator[Dict[str, str]]`) confirms this. The function
    uses `yield from` to provide rows from the CSV `DictReader` object as they're
    demanded by a client process.
  prefs: []
  type: TYPE_NORMAL
- en: This is a "lazy" way to read lines from the CSV as they're required by another
    object. The iterator is like a factory using kanban techniques – it prepares data
    in response to demand. This doesn't slurp in the entire file, creating a gigantic
    list of dictionaries. Instead, the iterator produces one dictionary at a time,
    as they're requested.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to request data from an iterator is to use the built-in `list()` function.
    We can use this class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: The CSV `DictReader` produces a dictionary. We provided the keys for this dictionary
    with the `self.header` value; an alternative is to use the first row of the file
    as the keys. In this case, the file doesn't have column headers in the first row,
    so we provided column headers.
  prefs: []
  type: TYPE_NORMAL
- en: The `data_iter()` method produces rows for a consuming class or function. In
    this example, the `list()` function consumes the available rows. As expected,
    the dataset has 150 rows. We've shown the first row.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the attribute values are strings. This is always true when reading
    CSV files: all of the input values are strings. Our application must convert the
    strings to `float` values to be able to create `KnownSample` objects.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to consume values is with a `for` statement. This how the `load()`
    method of the `TrainingData` class works. It uses code that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'We combine an `IrisReader` object with this object to load the samples. It
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: The `load()` method will consume values produced by the `data_iter()` method.
    The loading of the data is a cooperative process from the two objects.
  prefs: []
  type: TYPE_NORMAL
- en: Working with CSV data as dictionaries seems to be very handy. To show an alternative,
    we'll turn to reading data using a non-dictionary CSV reader.
  prefs: []
  type: TYPE_NORMAL
- en: CSV list reader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The non-dictionary CSV reader produces a list of strings from each row. This
    is not what our `TrainingData` collection's `load()` method expects, however.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have two choices to meet the interface requirement for the `load()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert the list of column values to a dictionary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change `load()` to use a list of values in a fixed order. This would have the
    unfortunate consequence of forcing the `load()` method of the `TrainingData` class to
    match a specific file layout. Alternatively, we'd have to re-order input values
    to match the requirements of `load()`; doing this is about as complex as building
    a dictionary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building a dictionary seems relatively easy; this allows the `load()` method
    to work with data where the column layout varies from our initial expectation.
  prefs: []
  type: TYPE_NORMAL
- en: Here's a `CSVIrisReader_2` class that uses `csv.reader()` to read a file, and
    builds dictionaries based on the attribute information published in the `iris.names` file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: The `data_iter()` method yields individual dictionary objects. This `for-with-yield`
    summarizes what a `yield from` does. When we write `yield from X`, that is effectively
    the same as the longer
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: For this application, the non-dictionary processing works by creating a dictionary
    from the input row. This doesn't seem to have any advantage over the `csv.DictReader`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: The other big alternative is JSON serialization. We'll look at ways to apply
    the techniques shown in this chapter to our case study data.
  prefs: []
  type: TYPE_NORMAL
- en: JSON serialization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The JSON format can serialize a number of commonly used Python object classes,
    including:'
  prefs: []
  type: TYPE_NORMAL
- en: None
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boolean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Float and integer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: String
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lists of compatible objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionaries with string keys and compatible objects as values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The "compatible objects" can include nested structures. This dictionary-within-list
    and dictionary-within-dictionary recursion can allow JSON to represent very complex
    things.
  prefs: []
  type: TYPE_NORMAL
- en: 'We might consider a theoretical (but invalid) type hint like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'This hint isn''t directly supported by **mypy**, because it involves explicit
    recursion: the JSON type is defined based on the JSON type. This hint can be a
    helpful conceptual framework for understanding what we can represent in JSON notation.
    As a practical matter, we often use `Dict[str, Any]` to describe JSON objects,
    ignoring the details of other structures that might be present. We can be a little
    more specific, though, when we know the expected keys for the dictionary; we''ll
    expand on this below.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In JSON notation, our data will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: Note that the numeric values don't have quotation marks, and they will be converted
    to `float` values if they have a `.` character or converted to an integer if they
    lack the `.` character.
  prefs: []
  type: TYPE_NORMAL
- en: 'The [json.org](http://json.org) standards require a single JSON object in a
    file. This encourages us to create a "list-of-dict" structure. Pragmatically,
    the structure of the file can be summarized by this type hint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: The document – as a whole – is a list. It contains a number of dictionaries
    that map string keys to either float or string values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Above, we noted that we can be more specific about the keys expected. In this
    case, we want to limit our application to working with specific dictionary keys.
    We can be a bit more precise, by using the `typing.TypedDict` hint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: This can be helpful to **mypy** (and other people reading our code) by showing
    what the expected structure *should* be. We can even add `total=True` to assert
    that the definition shows the entire domain of valid keys.
  prefs: []
  type: TYPE_NORMAL
- en: This `TypedDict` hint doesn't really confirm the contents of the JSON document
    are valid or sensible, however. Remember, **mypy** is only a static check on the
    code, and has no runtime impact. To check the JSON document's structure, we'll
    need something more sophisticated than a Python type hint.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s our JSON reader class definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: We've opened the source file and loaded the list-of-dict objects. We can then
    yield the individual sample dictionaries by iterating over the list.
  prefs: []
  type: TYPE_NORMAL
- en: This has a hidden cost. We'll look at how newline-delimited JSON – a modification
    to the standard – can help reduce the memory used.
  prefs: []
  type: TYPE_NORMAL
- en: Newline-delimited JSON
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For large collections of objects, reading a single, massive list into memory
    first isn't ideal. The "newline-delimited" JSON format, described by [ndjson.org](http://ndjson.org),
    provides a way to put a large number of separate JSON documents into a single
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The file would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: There's no overall `[]` to create a list. Each individual sample *must* be complete
    on one physical line of the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads to a slight difference in the way we process the sequence of documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve read each line of the file and used `json.loads()` to parse the single
    string into a sample dictionary. The interface is the same: an `Iterator[SampleDict]`.
    The technique for producing that iterator is unique to newline-delimited JSON.'
  prefs: []
  type: TYPE_NORMAL
- en: JSON validation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We noted that our **mypy** type hint doesn't really guarantee the JSON document
    is – in any way – what we expected. There is a package in the Python Package Index
    that can be used for this. The `jsonschema` package lets us provide a specification
    for a JSON document, and then confirm whether or not the document meets the specification.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll need to install an additional library to do the validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: The JSON Schema validation is a runtime check, unlike the **mypy** type hint.
    This means using validation will make our program slower. It can also help to
    diagnose subtly incorrect JSON documents. For details, see [https://json-schema.org](https://json-schema.org). This
    is evolving toward standardization, and there are several versions of compliance
    checking available.
  prefs: []
  type: TYPE_NORMAL
- en: We'll focus on newline-delimited JSON. This means we need a schema for each
    sample document within the larger collection of documents. This kind of additional
    validation might be relevant when receiving a batch of unknown samples to classify.
    Before doing anything, we'd like to be sure the sample document has the right
    attributes.
  prefs: []
  type: TYPE_NORMAL
- en: A JSON Schema document is also written in JSON. It includes some metadata to
    help clarify the purpose and meaning of the document. It's often a little easier
    to create a Python dictionary with the JSON Schema definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a candidate definition for the Iris schema for an individual sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: Each sample is an `object`, the JSON Schema term for a dictionary with keys
    and values. The `properties` of an object are the dictionary keys. Each one of
    these is described with a type of data, `number` in this case. We can provide
    additional details, like ranges of values. We provided a description, taken from
    the `iris.names` file.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the `species` property, we've provided an enumeration of the
    valid string values. This can be handy for confirming that the data meets our
    overall expectations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use this schema information by creating a `jsonschema` validator and applying
    the validator to check each sample we read. An extended class might look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: We've accepted an additional parameter in the `__init__()` method with the schema
    definition. We use this to create the `Validator` instance that will be applied
    to each document.
  prefs: []
  type: TYPE_NORMAL
- en: The `data_iter()` method uses the `is_valid()` method of `validator` to process
    only samples that pass the JSON Schema validation. The others will be reported
    and ignored. We've printed the output using the `print()` function. It would be
    smarter to use the `file=sys.stderr` keyword parameter to direct the output to
    the error output. It would be even better to use the `logging` package to write
    error messages to a log.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we now have two separate, but similar definitions for the raw data
    that builds a `Sample` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: A type hint, `SampleDict`, describing the expected Python intermediate data
    structure. This can be applied to CSV as well as JSON data, and helps summarize
    the relationship between the `load()` method of the `TrainingData` class, and
    the various readers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A JSON Schema that *also* describes an expected external data structure. This
    doesn't describe a Python object, it describes the JSON serialization of a Python
    object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For very simple cases, these two descriptions of the data seem redundant. In
    more complex situations, however, these two will diverge, and fairly complex conversions
    between external schema, intermediate results, and the final class definition
    is a common feature of Python applications. This occurs because there are a variety
    of ways to serialize Python objects. We need to be flexible enough to work with
    a useful variety of representations.
  prefs: []
  type: TYPE_NORMAL
- en: Recall
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we''ve looked at the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The ways to encode strings into bytes and decode bytes into strings. While some
    older character encodings (like ASCII) treat bytes and characters alike, this
    leads to confusion. Python text can be any Unicode character and Python bytes
    are numbers in the range 0 to 255.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: String formatting lets us prepare string objects that have template pieces and
    dynamic pieces. This works for a lot of situations in Python. One is to create
    readable output for people, but we can use f-strings and the string `format()`
    method everywhere we're creating a complex string from pieces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use regular expressions to decompose complex strings. In effect, a regular
    expression is the opposite of a fancy string formatter. Regular expressions struggle
    to separate the characters we're matching from "meta-characters" that provide
    additional matching rules, like repetition or alternative choices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We've looked at a few ways to serialize data, including Pickle, CSV, and JSON.
    There are other formats, including YAML, that are similar enough to JSON and Pickle
    that we didn't need to cover them in detail. Other serializations like XML and
    HTML are quite a bit more complex, and we've avoided them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've covered a wide variety of topics in this chapter, from strings to regular
    expressions, to object serialization, and back again. Now it's time to consider
    how these ideas can be applied to your own code.
  prefs: []
  type: TYPE_NORMAL
- en: Python strings are very flexible, and Python is an extremely powerful tool for
    string-based manipulations. If you don't do a lot of string processing in your
    daily work, try designing a tool that is exclusively intended for manipulating
    strings. Try to come up with something innovative, but if you're stuck, consider
    writing a web log analyzer (how many requests per hour? How many people visit
    more than five pages?) or a template tool that replaces certain variable names
    with the contents of other files.
  prefs: []
  type: TYPE_NORMAL
- en: Spend a lot of time toying with the string formatting operators until you've
    got the syntax memorized. Write a bunch of template strings and objects to pass
    into the format function, and see what kind of output you get. Try the exotic
    formatting operators, such as percentage or hexadecimal notation. Try out the
    fill and alignment operators, and see how they behave differently for integers,
    strings, and floats. Consider writing a class of your own that has a `__format__` method;
    we didn't discuss this in detail, but explore just how much you can customize
    formatting.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you understand the difference between `bytes` and `str` objects. The
    way that Python's canonical display of bytes looks like a string can be confusing.
    The only tricky part is knowing how and when to convert between the two. For practice,
    try writing text data to a file opened for writing `bytes` (you'll have to encode
    the text yourself), and then reading from the same file.
  prefs: []
  type: TYPE_NORMAL
- en: Do some experimenting with `bytearray`. See how it can act both like a `bytes` object
    and a list or container object at the same time. Try writing to a buffer that
    holds data in the bytes array until it is a certain length before returning it.
    You can simulate the code that puts data into the buffer by using `time.sleep` calls
    to ensure data doesn't arrive too quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Study regular expressions online. Study them some more. Especially learn about
    named groups, greedy versus lazy matching, and regex flags, three features that
    we didn't cover in this chapter. Make conscious decisions about when not to use
    them. Many people have very strong opinions about regular expressions and either
    overuse them or refuse to use them at all. Try to convince yourself to use them
    only when appropriate, and figure out when that is.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''ve ever written an adapter to load small amounts of data from a file
    or database and convert it to an object, consider using a pickle instead. Pickles
    are not efficient for storing massive amounts of data, but they can be useful
    for loading configuration or other simple objects. Try coding it multiple ways:
    using a pickle, a text file, or a small database. Which do you find easiest to
    work with?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Try experimenting with pickling data, then modifying the class that holds the
    data, and loading the pickle into the new class. What works? What doesn''t? Is
    there a way to make drastic changes to a class, such as renaming an attribute
    or splitting it into two new attributes and still get the data out of an older
    pickle? (Hint: try placing a private pickle version number on each object and
    update it each time you change the class; you can then put a migration path in `__setstate__`.)'
  prefs: []
  type: TYPE_NORMAL
- en: If you do any web development at all, the JSON serializer will be central. It
    can simplify things to stick with standard JSON serializable objects, rather than
    writing custom encoders or `object_hooks`, but the design depends on the complexity
    of the objects and the state representations being transferred.
  prefs: []
  type: TYPE_NORMAL
- en: In the case study, we applied the JSON Schema validation to a JSON file. It
    can also be applied to the rows read from a file in CSV format. This is a powerful
    combination of tools to work with data in two common formats; it helps to apply
    rigorous validation rules to assure that the rows meet the application's expectations.
    To see how this works, modify the `CSVIrisReader` class to include JSON Schema
    validation of the rows of data.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've covered string manipulation, regular expressions, and object serialization
    in this chapter. Hardcoded strings and program variables can be combined into
    outputtable strings using the powerful string formatting system. It is important
    to distinguish between binary and textual data, and `bytes` and `str` have specific
    purposes that must be understood. Both are immutable, but the `bytearray` type
    can be used when manipulating bytes.
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions are a complex topic, and we only scratched the surface.
    There are many ways to serialize Python data; pickles and JSON are two of the
    most popular.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we''ll look at a design pattern that is so fundamental
    to Python programming that it has been given special syntax support: the iterator
    pattern.'
  prefs: []
  type: TYPE_NORMAL
