<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer151">
    <h1 class="chapterNumber">10</h1>
    <h1 class="chapterTitle" id="_idParaDest-231">Introduction to Async IO</h1>
    <p class="normal">In the previous chapters, we have been interacting with the network devices directly via API or other Python libraries that abstracted us from low-level interactions with a remote device. When we need to interact with multiple devices, we use loops to allow us to pragmatically execute commands. One issue that we might start to see is that the end-to-end process begins to slow down when we need to interact with many devices. The bottleneck is usually the time spent waiting between the time we send the command until we receive the proper response from the remote device. If we need to spend 5 seconds of wait time per operation, we could wait for a few minutes when we need to operate on 30 devices. </p>
    <p class="normal">This is partially true because our operations are sequential. We are only operating on one device at a time, in sequence. What if we can process multiple devices at the same time? That would speed things up, right? Yes, you are correct. But it is not as simple as “telling” our Python script to “go for” many devices simultaneously. We must consider the way computers schedule tasks, the language limitation, and the available tools at hand. </p>
    <p class="normal">In this chapter, we will discuss Async IO, the Python package that allows us to perform multiple tasks at the same time. We will also discuss related topics such as multiprocessing, parallelism, threading, and others. Asynchronous operations in Python is a topic that I would consider medium to advanced level. The async IO module itself was only introduced in Python 3.4. It also went through rapid changes between Python 3.4 to Python 3.7. Regardless, it is a very relatable topic for network automation. I believe it is worth a study for any network engineer looking to be familiar with network automation.</p>
    <p class="normal">In this chapter, we will discuss the following topics related to Async IO: </p>
    <ul>
      <li class="bulletList">Asynchronous operations overview</li>
      <li class="bulletList">Multiprocessing and threading</li>
      <li class="bulletList">Python asyncio module</li>
      <li class="bulletList">The <code class="inlineCode">Scrapli</code> project </li>
    </ul>
    <div class="note">
      <p class="normal">For more information on Python-related asynchronous operations, Real Python (<a href="https://realpython.com/search?q=asyncio"><span class="url">https://realpython.com/search?q=asyncio</span></a>) and Python documentation (<a href="https://docs.python.org/3/library/asyncio.html"><span class="url">https://docs.python.org/3/library/asyncio.html</span></a>) both offer good resources for learning.</p>
    </div>
    <p class="normal">Let’s start by looking at an overview of asynchronous operations. </p>
    <h1 class="heading-1" id="_idParaDest-232">Asynchronous operations overview</h1>
    <p class="normal">In the <em class="italic">Zen of Python; </em>we<a id="_idIndexMarker776"/> know one of the guiding principles in Python is to preferably have “one best way to do something.” When it comes to asynchronous operations, it is a bit complicated. We know it would help if we could do multiple tasks simultaneously but determining the correct solution might not be straightforward. </p>
    <p class="normal">First, we will need to determine what is slowing down our program. Typically, the bottleneck can be either CPU-bound or I/O-bound. In a CPU-bound situation, the program pushes the CPU to its limit. Operations such as solving mathematical questions or image processing are examples of CPU-bound programs. For example, when we pick an encryption algorithm for VPN, we know the more complex the algorithm, the more CPU it will consume. For CPU-bound tasks, the way to mitigate the bottleneck is to increase the CPU power or allow the task to use multiple CPUs simultaneously. </p>
    <p class="normal">In an IO-bound operation, the program spends most of its time waiting for some output from an input it has completed. When we make an API call to a device, we cannot move on to the next step until we receive what we need as the answer. If time is significant, this is time that otherwise could have been useful in doing something else. The way to mitigate IO-bound tasks is to work on multiple tasks simultaneously. </p>
    <p class="normal">If the work at hand is limited by CPU power or Input-Output latency, we can try to run multiple operations at once. This is called parallelism. Of course, not all tasks can be parallelized. As the great Warren Buffet saying goes, “You can’t produce a baby in one month by getting nine women pregnant.” However, if your task can be parallelized, we have a few parallel processing options: multiprocessing, threading, or the new asyncio module. </p>
    <h2 class="heading-2" id="_idParaDest-233">Python multiprocessing</h2>
    <p class="normal">Python’s <a id="_idIndexMarker777"/>multiprocessing allows CPU-bound <a id="_idIndexMarker778"/>tasks to be broken up into sub-tasks and spawning subprocesses to handle them. This is well-suited for CPU-bound tasks because it allows multiple CPUs to work simultaneously. If we look back at the history of computing, we notice that around 2005, a single CPU can no longer get any faster. We simply cannot fit more transistors onto a single CPU due to interference and heat issues. The way we have gotten more computing power is by having multi-core CPUs. This is beneficial in allowing us to spread our tasks among the multi-core CPUs. </p>
    <p class="normal">In Python’s multiprocessing module, processes are spawned by creating a <code class="inlineCode">Process</code> object and then calling its <code class="inlineCode">start()</code> method. Let’s see a simple example, <code class="inlineCode">multiprocess_1.py</code>: </p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#!/usr/bin/env python3</span>
<span class="hljs-comment"># Modified from </span>
<span class="hljs-comment"># https://docs.python.org/3/library/multiprocessing.html</span>
<span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">def</span> <span class="hljs-title">process_info</span>():
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'process id:'</span>, os.getpid())
<span class="hljs-keyword">def</span> <span class="hljs-title">worker</span>(<span class="hljs-params">number</span>):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'Worker number </span><span class="hljs-subst">{number}</span><span class="hljs-string">'</span>)
    process_info()
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):
        p = Process(target=worker, args=(i,))
        p.start()
    
</code></pre>
    <p class="normal">In the example, we have a worker function that calls another <code class="inlineCode">process_info()</code> function to get the process ID. Then we start the Process object five times, each one targeting the worker function. The output for the execution is below: </p>
    <pre class="programlisting con"><code class="hljs-con">(venv) $ python multiprocess_1.py 
Worker number 0
process id: 109737
Worker number 2
process id: 109739
Worker number 3
process id: 109740
Worker number 1
process id: 109738
Worker number 4
process id: 109741
</code></pre>
    <p class="normal">As we can see, each process has its process and process ID. Multiprocessing is great for CPU-bound<a id="_idIndexMarker779"/> tasks. If the work is IO-bound, before <a id="_idIndexMarker780"/>the asyncio module, our best bet is to use the threading module. </p>
    <h2 class="heading-2" id="_idParaDest-234">Python multithreading</h2>
    <p class="normal">As many of<a id="_idIndexMarker781"/> us know, Python has a <strong class="keyWord">Global Interpreter Lock</strong>, or <strong class="keyWord">GIL</strong>. It is <a id="_idIndexMarker782"/>used by the Python<a id="_idIndexMarker783"/> interpreter (CPython, to be exact) to assure that only one thread executes Python byte code at a time. This is mainly a safety measure to protect against race conditions in memory leaks. But it can become a performance bottleneck for IO-bound tasks. </p>
    <div class="note">
      <p class="normal">For more information, check out the article at <a href="https://realpython.com/python-gil/"><span class="url">https://realpython.com/python-gil/</span></a>. </p>
    </div>
    <p class="normal">One way to allow multiple threads to run is by using the <code class="inlineCode">threading</code> module. It allows a program to run multiple operations concurrently. We can see a simple example in <code class="inlineCode">threading_1.py</code>: </p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#!/usr/bin/env python3</span>
<span class="hljs-comment"># Modified from https://pymotw.com/3/threading/index.html</span>
<span class="hljs-keyword">import</span> threading
<span class="hljs-comment"># Get thread ID</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">thread_id</span>():
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'thread id:'</span>, threading.get_ident())
<span class="hljs-comment"># Worker function</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">worker</span>(<span class="hljs-params">number</span>):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'Worker number </span><span class="hljs-subst">{number}</span><span class="hljs-string">'</span>)
    thread_id()
threads = []
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):
    t = threading.Thread(target=worker, args=(i,))
    threads.append(t)
    t.start()
</code></pre>
    <p class="normal">The script is similar to our multiprocess example, with the exception of displaying the thread ID <a id="_idIndexMarker784"/>instead of the process ID. The output<a id="_idIndexMarker785"/> for the script execution is below:</p>
    <pre class="programlisting con"><code class="hljs-con">(venv) $ python threading_1.py 
Worker number 0
thread id: 140170712495680
Worker number 1
thread id: 140170704102976
Worker number 2
thread id: 140170695710272
Worker number 3
thread id: 140170704102976
Worker number 4
thread id: 140170695710272
</code></pre>
    <p class="normal">The threading module is a good option to mitigate the Python GIL with multiple threads. However, when Python passes the task to a thread, the main process has limited visibility in the threading process. The threads are harder to deal with, especially when coordinating between different threads and handling errors if they arise. For IO-bound tasks, instead of threads, asyncio in Python 3 is another great option.</p>
    <figure class="mediaobject"><img alt="Graphical user interface, diagram, application  Description automatically generated" src="../Images/B18403_10_01.png"/></figure>
    <p class="packt_figref">Figure 10.1: CPU-bound vs. IO-bound Python modules</p>
    <p class="normal">Let’s dig<a id="_idIndexMarker786"/> deeper into the asyncio<a id="_idIndexMarker787"/> module. </p>
    <h1 class="heading-1" id="_idParaDest-235">Python asyncio module</h1>
    <p class="normal">We can think of <a id="_idIndexMarker788"/>the asyncio module as Python’s way of allowing us to write code to run tasks concurrently. It uses the newly introduced <code class="inlineCode">async</code> and <code class="inlineCode">await</code> keywords. It can help us improve performance for many operations that might be IO-bound, such as web servers, databases, and, of course, communication toward devices over a network. The asyncio module is the foundation of popular new frameworks, such as FastAPI (<a href="https://fastapi.tiangolo.com/"><span class="url">https://fastapi.tiangolo.com/</span></a>). </p>
    <p class="normal">However, it is important to point out that asyncio is neither multiprocessing nor multithreaded. It is designed to be single-threaded with a single process. Python asyncio uses <em class="italic">cooperative multiprocessing</em> to give the feeling of concurrency.</p>
    <p class="normal">Unlike threading, Python controls the process from end to end instead of passing the threading process to the operating system. This lets Python know when the task is started and completed, thus coordinating between the processes. When we “pause” part of the code while waiting for results, Python will move on to other parts of the code before coming back to the “paused” code. </p>
    <p class="normal">This is an important concept to grasp before writing our asyncio code. We need to decide which part of the code can be paused to allow Python to temporarily move on from it. We have to tell Python, “Hey, I am just waiting for something. Go do something else and come back to check on me.”</p>
    <p class="normal">Let us start with a simple example of the asyncio module syntax in <code class="inlineCode">asyncio_1.py</code>: </p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#!/usr/bin/env python3</span>
<span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Hello ...'</span>)
    <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'... World!'</span>)
    <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">2</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'... and again.'</span>)
asyncio.run(main())
</code></pre>
    <p class="normal">When we <a id="_idIndexMarker789"/>execute it, here is the output: </p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span><span class="language-bash">python asyncio_1.py</span> 
Hello ...
... World!
... and again.
</code></pre>
    <p class="normal">There are several things we can take note of in this example: </p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">The asyncio module is in the standard library for Python 3.10. </li>
      <li class="numberedList">The <code class="inlineCode">async</code> keyword is used in front of the function. In asyncio, this is called a coroutine. </li>
      <li class="numberedList">The <code class="inlineCode">await</code> keyword is waiting for the return of some operations. </li>
      <li class="numberedList">Instead of simply calling the function/coroutine, we use <code class="inlineCode">asyncio.run()</code> to do so. </li>
    </ol>
    <p class="normal">At the heart of the asyncio module are coroutines, defined with the <code class="inlineCode">async</code> keyword. A coroutine is a specialized version of a Python generator function that can temporarily give back control to the Python interpreter while waiting. </p>
    <div class="note">
      <p class="normal">Generator functions are a type of function that can be iterated over like a list but do so without loading the content into memories first. This is useful when, for example, the dataset is so large that it might overwhelm a computer’s memory. For more information, check out this documentation: <a href="https://wiki.python.org/moin/Generators"><span class="url">https://wiki.python.org/moin/Generators</span></a>.</p>
    </div>
    <figure class="mediaobject"><img alt="" src="../Images/B18403_10_02.png"/></figure>
    <p class="packt_figref">Figure 10.2: Coroutine with async and await</p>
    <p class="normal">Let’s take this<a id="_idIndexMarker790"/> example further and see how we can build on it. The following examples were taken from the excellent tutorial from <em class="italic">RealPython.com</em> (<a href="https://realpython.com/async-io-python/#the-asyncio-package-and-asyncawait"><span class="url">https://realpython.com/async-io-python/#the-asyncio-package-and-asyncawait</span></a>). We will start with a synchronous count function with <code class="inlineCode">sync_count.py</code>: </p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#!/usr/bin/env python3</span>
<span class="hljs-comment"># Modified from https://realpython.com/async-io-python/#the-asyncio-package-and-asyncawait countsync.py example</span>
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">def</span> <span class="hljs-title">count</span>():
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"One"</span>)
    time.sleep(<span class="hljs-number">1</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Two"</span>)
<span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():
    count()
    count()
    count()
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"</span><span class="hljs-string">__main__"</span>:
    s = time.perf_counter()
    main()
    elapsed = time.perf_counter() - s
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Completed in </span><span class="hljs-subst">{elapsed:</span><span class="hljs-number">0.2</span><span class="hljs-subst">f}</span><span class="hljs-string"> seconds."</span>)
</code></pre>
    <p class="normal">Upon execution, we can see the script executes in three seconds by faithfully executing the function three times sequentially:</p>
    <pre class="programlisting con"><code class="hljs-con">(venv) $ python sync_count.py
One
Two
One
Two
One
Two
Completed in 3.00 seconds.
</code></pre>
    <p class="normal">Now, let’s see if <a id="_idIndexMarker791"/>we can build an asynchronous version of it, <code class="inlineCode">async_count.py</code>: </p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#!/usr/bin/env python3</span>
<span class="hljs-comment"># example from https://realpython.com/async-io-python/#the-asyncio-package-and-asyncawait countasync.py</span>
<span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">count</span>():
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"One"</span>)
    <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Two"</span>)
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():
    <span class="hljs-keyword">await</span> asyncio.gather(count(), count(), count())
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    <span class="hljs-keyword">import</span> time
    s = time.perf_counter()
    asyncio.run(main())
    elapsed = time.perf_counter() - s
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Completed in </span><span class="hljs-subst">{elapsed:</span><span class="hljs-number">0.2</span><span class="hljs-subst">f}</span><span class="hljs-string"> seconds."</span>)
</code></pre>
    <p class="normal">When we execute this file, we see that similar tasks were completed in 1/3 of the time: </p>
    <pre class="programlisting con"><code class="hljs-con">(venv) $ python async_count.py
One
One
One
Two
Two
Two
Completed in 1.00 seconds.
</code></pre>
    <p class="normal">Why is that? It is because now when we are counting and hit the sleep pause, we give the control back to the interpreter to allow it to process other tasks. </p>
    <figure class="mediaobject"><img alt="A picture containing text  Description automatically generated" src="../Images/B18403_10_03.png"/></figure>
    <p class="packt_figref">Figure 10.3: Event Loop</p>
    <p class="normal">There are a few <a id="_idIndexMarker792"/>important points to note in this example: </p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">The <code class="inlineCode">sleep()</code> function is changed to an <code class="inlineCode">asyncio.sleep()</code> function. It is an <code class="inlineCode">awaitable</code> function. </li>
      <li class="numberedList">Both the <code class="inlineCode">count()</code> and <code class="inlineCode">main()</code> functions are now coroutines. </li>
      <li class="numberedList">We used <code class="inlineCode">ansyncio.gather()</code> to collect all the coroutines. </li>
      <li class="numberedList">The <code class="inlineCode">asyncio.run()</code> is a loop that runs until everything is completed. </li>
    </ol>
    <p class="normal">From the example, we can see there are several changes we need to make to regular functions to allow the performance gain offered by asyncio. Remember we talked about cooperative multiprocessing? Asyncio requires all components within the Python programs to work together to achieve this goal. </p>
    <figure class="mediaobject"><img alt="Diagram  Description automatically generated" src="../Images/B18403_10_04.png"/></figure>
    <p class="packt_figref">Figure 10.4: Event loop</p>
    <p class="normal">In the next section, we will look at the Scrapli project that helps us speed up the network device<a id="_idIndexMarker793"/> interaction process by taking advantage of the Python 3 asyncio feature. </p>
    <h1 class="heading-1" id="_idParaDest-236">The Scrapli project</h1>
    <p class="normal">Scrapli is an<a id="_idIndexMarker794"/> open-source network library (<a href="https://github.com/carlmontanari/scrapli"><span class="url">https://github.com/carlmontanari/scrapli</span></a>) that uses Python 3’s asyncio capabilities to help connect to network devices faster. It was created by Carl Montanari (<a href="https://github.com/carlmontanari"><span class="url">https://github.com/carlmontanari</span></a>) while working on his network automation projects. The installation is straightforward: </p>
    <pre class="programlisting con"><code class="hljs-con">(venv) $ pip install scrapli
(venv) $ mkdir scrapli &amp;&amp; cd scrapli
</code></pre>
    <p class="normal">Let’s go ahead and start using Scrapli for our network device communication. </p>
    <h2 class="heading-2" id="_idParaDest-237">Scrapli example</h2>
    <p class="normal">We can use the <a id="_idIndexMarker795"/>following example, <code class="inlineCode">scrapli_example_1.py</code>, to perform a <code class="inlineCode">show</code> command on our lab NX-OS device, <code class="inlineCode">lax-cor-r1</code>: </p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Modified from https://github.com/carlmontanari/scrapli</span>
<span class="hljs-keyword">from</span> scrapli <span class="hljs-keyword">import</span> Scrapli
device = {
   "host": "<span class="hljs-number">192.168.2.50</span>",
   "auth_username": "cisco",
   "auth_password": "cisco",
   "auth_strict_key": <span class="hljs-literal">False</span>,
   "ssh_config_file": <span class="hljs-literal">True</span>,
   "platform": "cisco_nxos",
}
conn = Scrapli(**device)
conn.<span class="hljs-built_in">open</span>()
response = conn.send_command("show version")
<span class="hljs-built_in">print</span>(response.result)
</code></pre>
    <p class="normal">Executing the script will give us the <code class="inlineCode">show</code> <code class="inlineCode">version</code> output. Notice this is in a string format: </p>
    <pre class="programlisting con"><code class="hljs-con">(venv) $ python scrapli_example_1.py 
Cisco Nexus Operating System (NX-OS) Software
TAC support: http://www.cisco.com/tac
…
Software
  loader:    version N/A
  kickstart: version 7.3(0)D1(1)
  system:    version 7.3(0)D1(1)
Hardware
  cisco NX-Osv Chassis ("NX-Osv Supervisor Module")
  IntelI CITM) i5-7260U C with 3064740 kB of memory.
  Processor Board ID TM000940CCB
  Device name: lax-cor-r1
  bootflash:    3184776 kB
…
</code></pre>
    <p class="normal">On the surface, it might not look any different than some of the other libraries we have seen. But underneath the hood, the core drivers and associated platforms are using the asyncio module <a id="_idIndexMarker796"/>that can be turned into an <code class="inlineCode">awaitable</code> coroutine: </p>
    <figure class="mediaobject"><img alt="Table  Description automatically generated" src="../Images/B18403_10_05.png"/></figure>
    <p class="packt_figref">Figure 10.5: Scrapli Core Drivers (source: https://carlmontanari.github.io/scrapli/user_guide/basic_usage/) </p>
    <div class="note">
      <p class="normal">We can verify the code by going to the project’s GitHub page, <a href="https://github.com/carlmontanari/scrapli"><span class="url">https://github.com/carlmontanari/scrapli</span></a>. The NXOS Async driver, <a href="https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/core/cisco_nxos/async_driver.py"><span class="url">https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/core/cisco_nxos/async_driver.py</span></a>, can be traced back to the base async driver, <a href="https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/async_driver.py"><span class="url">https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/async_driver.py</span></a>, as well as the base driver, <a href="https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/base_driver.py"><span class="url">https://github.com/carlmontanari/scrapli/blob/main/scrapli/driver/base/base_driver.py</span></a>. This is part of the beauty of open-source projects, and we have the freedom to explore and build on each other’s knowledge. Thank you, Carl!</p>
    </div>
    <p class="normal">The core drivers include Cisco IOS-XE, Cisco NX-OS, Cisco IOS-XR, Arista EOS, and Juniper JunOS. By simply specifying the platform, Scrapli is able to correlate it with the particular driver. There is also a <code class="inlineCode">scrapli_community</code> project (<a href="https://github.com/scrapli/scrapli_community"><span class="url">https://github.com/scrapli/scrapli_community</span></a>) that extends beyond the core drivers. </p>
    <p class="normal">In our lab, we specify additional <code class="inlineCode">ssh</code> configurations. Therefore, we need to set <code class="inlineCode">ssh_config_file</code> to be <code class="inlineCode">true</code>: </p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span><span class="hljs-con-built_in">cat</span><span class="language-bash"> ~/.ssh/config</span>
…
Host 192.168.2.50
  HostKeyAlgorithms +ssh-rsa
  KexAlgorithms +diffie-hellman-group-exchange-sha1
</code></pre>
    <div class="note">
      <p class="normal">Scrapli’s documentation, <a href="https://carlmontanari.github.io/scrapli/"><span class="url">https://carlmontanari.github.io/scrapli/</span></a>, is a good place to start. Packet Coders, <a href="https://www.packetcoders.io/"><span class="url">https://www.packetcoders.io/</span></a>, also offers good network automation classes, including Scrapli.</p>
    </div>
    <p class="normal">We can now <a id="_idIndexMarker797"/>put this awaitable task into an asyncio run loop. </p>
    <h2 class="heading-2" id="_idParaDest-238">Scrapli async example</h2>
    <p class="normal">In this example, we <a id="_idIndexMarker798"/>will be more precise about the driver and transport. We will install the <code class="inlineCode">asyncssh</code> plugin (<a href="https://carlmontanari.github.io/scrapli/api_docs/transport/plugins/asyncssh/"><span class="url">https://carlmontanari.github.io/scrapli/api_docs/transport/plugins/asyncssh/</span></a>) from Scrapli to be used: </p>
    <pre class="programlisting con"><code class="hljs-con">(venv) $ pip install scrapli[asyncssh]
</code></pre>
    <p class="normal">The script, <code class="inlineCode">scraplie_example_2.py</code>, is listed below: </p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#!/usr/bin/env python3</span>
<span class="hljs-comment"># Modified from </span>
<span class="hljs-comment"># https://github.com/carlmontanari/scrapli/blob/main/examples/async_usage/async_multiple_connections.py</span>
<span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">from</span> scrapli.driver.core <span class="hljs-keyword">import</span> AsyncNXOSDriver
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">gather_cor_device_version</span>(<span class="hljs-params">ip, username, password</span>):
    device = {
        <span class="hljs-string">"host"</span>: ip,
        <span class="hljs-string">"auth_username"</span>: username,
        <span class="hljs-string">"auth_password"</span>: password,
        <span class="hljs-string">"auth_strict_key"</span>: <span class="hljs-literal">False</span>,
        <span class="hljs-string">"ssh_config_file"</span>: <span class="hljs-literal">True</span>,
        <span class="hljs-string">"transport"</span>: <span class="hljs-string">"asyncssh"</span>,
        <span class="hljs-string">"driver"</span>: AsyncNXOSDriver
    }
    driver = device.pop(<span class="hljs-string">"driver"</span>)
    conn = driver(**device)
    <span class="hljs-keyword">await</span> conn.<span class="hljs-built_in">open</span>()
    response = <span class="hljs-keyword">await</span> conn.send_command(<span class="hljs-string">"</span><span class="hljs-string">show version"</span>)
    <span class="hljs-keyword">await</span> conn.close()
    <span class="hljs-keyword">return</span> response
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():
    results = <span class="hljs-keyword">await</span> asyncio.gather(
                        gather_cor_device_version(<span class="hljs-string">'192.168.2.50'</span>, <span class="hljs-string">'cisco'</span>, <span class="hljs-string">'cisco'</span>),
                        gather_cor_device_version(<span class="hljs-string">'</span><span class="hljs-string">192.168.2.60'</span>, <span class="hljs-string">'cisco'</span>, <span class="hljs-string">'cisco'</span>)
                    )
    <span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results: 
        <span class="hljs-built_in">print</span>(result.result)
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>: 
    <span class="hljs-keyword">import</span> time
    s = time.perf_counter()
    asyncio.run(main())
    elapsed = time.perf_counter() - s
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Completed in </span><span class="hljs-subst">{elapsed:</span><span class="hljs-number">0.2</span><span class="hljs-subst">f}</span><span class="hljs-string"> seconds."</span>)
</code></pre>
    <p class="normal">The script creates two new coroutines, one for gathering device information and the other for collecting <a id="_idIndexMarker799"/>the coroutine tasks within the <code class="inlineCode">main()</code> function. We also created an <code class="inlineCode">asyncio.run()</code> loop to run the <code class="inlineCode">main()</code> function when the script is executed by itself. Let’s execute the script: </p>
    <pre class="programlisting con"><code class="hljs-con">(venv) $ python scrapli_example_2_async.py 
Cisco Nexus Operating System (NX-OS) Software
…
  loader:    version N/A
  kickstart: version 7.3(0)D1(1)
  system:    version 7.3(0)D1(1)
…
  Device name: lax-cor-r1
  bootflash:    3184776 kB
…
  Device name: nyc-cor-r1
  bootflash:    3184776 kB
…
Completed in 1.37 seconds.
</code></pre>
    <p class="normal">Besides the <code class="inlineCode">show</code> <code class="inlineCode">version</code> output from the two devices, we also saw that the execution was completed in little over 1 second. </p>
    <p class="normal">Let’s compare the performance difference between synchronous and asynchronous operations. Scrapli provides a <code class="inlineCode">GenericDriver</code> for synchronous operations. In the example script <code class="inlineCode">scrapli_example_3_sync.py</code>, we will use the <code class="inlineCode">GenericDriver</code> to gather the information repeatedly. Just <a id="_idIndexMarker800"/>for illustration purposes, the script connects to each of the devices three times: </p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#!/usr/bin/env python3</span>
<span class="hljs-comment"># Modified from </span>
<span class="hljs-comment"># https://github.com/carlmontanari/scrapli/blob/main/examples/async_usage/async_multiple_connections.py</span>
<span class="hljs-keyword">import</span> asyncio
<span class="hljs-comment"># from scrapli.driver.core import Paramiko</span>
<span class="hljs-keyword">from</span> scrapli.driver <span class="hljs-keyword">import</span> GenericDriver
<span class="hljs-keyword">def</span> <span class="hljs-title">gather_cor_device_version</span>(<span class="hljs-params">ip, username, password</span>):
    device = {
        <span class="hljs-string">"host"</span>: ip,
        <span class="hljs-string">"auth_username"</span>: username,
        <span class="hljs-string">"</span><span class="hljs-string">auth_password"</span>: password,
        <span class="hljs-string">"auth_strict_key"</span>: <span class="hljs-literal">False</span>,
        <span class="hljs-string">"ssh_config_file"</span>: <span class="hljs-literal">True</span>,
        <span class="hljs-string">"driver"</span>: GenericDriver
    }
    driver = device.pop(<span class="hljs-string">"driver"</span>)
    conn = driver(**device)
    conn.<span class="hljs-built_in">open</span>()
    response = conn.send_command(<span class="hljs-string">"show version"</span>)
    conn.close()
    <span class="hljs-keyword">return</span> response
<span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():
    results = []
    <span class="hljs-keyword">for</span> device <span class="hljs-keyword">in</span> [
                    <span class="hljs-string">'192.168.2.50'</span>, 
                    <span class="hljs-string">'192.168.2.60'</span>,
                    <span class="hljs-string">'192.168.2.50'</span>, 
                    <span class="hljs-string">'192.168.2.60'</span>,
                    <span class="hljs-string">'192.168.2.50'</span>, 
                    <span class="hljs-string">'192.168.2.60'</span>,
                    <span class="hljs-string">'</span><span class="hljs-string">192.168.2.50'</span>, 
                    <span class="hljs-string">'192.168.2.60'</span>,
                  ]:
        results.append(gather_cor_device_version(device, <span class="hljs-string">'cisco'</span>, <span class="hljs-string">'cisco'</span>))
    <span class="hljs-keyword">return</span> results
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>: 
    <span class="hljs-keyword">import</span> time
    s = time.perf_counter()
    main()
    elapsed = time.perf_counter() - s
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Completed in </span><span class="hljs-subst">{elapsed:</span><span class="hljs-number">0.2</span><span class="hljs-subst">f}</span><span class="hljs-string"> seconds."</span>)
</code></pre>
    <p class="normal">There is also a comparable async version, <code class="inlineCode">scrapli_example_3_async.py</code>. When we run the two scripts, here is the performance difference: </p>
    <pre class="programlisting con"><code class="hljs-con">(venv) $ python scrapli_example_3_sync.py 
Completed in 5.97 seconds.
(venv) $ python scrapli_example_3_async.py 
Completed in 4.67 seconds.
</code></pre>
    <p class="normal">This might not <a id="_idIndexMarker801"/>seem much of an improvement, but as we scale up our operations, the performance gain will become more significant.</p>
    <h1 class="heading-1" id="_idParaDest-239">Summary</h1>
    <p class="normal">In this chapter, we learned about the concepts of asynchronous processing. We touched on the concepts behind CPU-bound and IO-bound tasks. We previously addressed the bottlenecks caused by them with multiprocessing and multithreading. </p>
    <p class="normal">Starting with Python 3.4, the new asyncio module was introduced to address IO-bound tasks. It is similar to multithreading but uses a special cooperative multitasking design. They use special keywords – the <code class="inlineCode">async</code> keyword to create functions that are special types of Python generators and the <code class="inlineCode">await</code> keyword to specify tasks that can be temporarily “paused.” The asyncio module can then collect these tasks and run them in a loop until completed. </p>
    <p class="normal">In the latter part of the chapter, we learned about using Scrapli, a project created by Carl Montanari for the network engineering community. It is designed to utilize the asyncio feature in Python 3 for network device management. </p>
    <p class="normal">Asyncio is not easy. The new terminology of async, await, loop, and generators can feel overwhelming. The asyncio module has also been under rapid development from Python version 3.4 to 3.7, making some online documents outdated. Hopefully, the information presented in this chapter can help us understand this useful feature. </p>
    <p class="normal">In the next chapter, we will switch gears toward cloud computing and the network features surrounding cloud computing.</p>
    <h1 class="heading-1">Join our book community</h1>
    <p class="normal">To join our community for this book – where you can share feedback, ask questions to the author, and learn about new releases – follow the QR code below:</p>
    <p class="normal"><a href="https://packt.link/networkautomationcommunity"><span class="url">https://packt.link/networkautomationcommunity</span></a></p>
    <p class="normal"><img alt="" src="../Images/QR_Code2903617220506617062.png"/></p>
  </div>
</body></html>