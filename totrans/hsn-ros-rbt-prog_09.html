<html><head></head><body>
        

                            
                    <h1 class="header-title">Programming in ROS - Commands and Tools</h1>
                
            
            
                
<p>This chapter focuses on running ROS within GoPiGo3. In the previous chapter, we did the same for a remote laptop, and in the next chapter, we will teach you how to make both a robot and your laptop work together as a single ROS environment.</p>
<p>In this chapter, you will finally learn how to use ROS in the depth required for the advanced chapters later on, which deal with robot navigation and machine learning. ROS can be hard to use at the beginning due to the following factors:</p>
<ul>
<li>It is command-line-based.</li>
<li>It handles asynchronous events.</li>
<li>It is a distributed computing environment.</li>
</ul>
<p>Paradoxically, these are the three features that make it really powerful for programming robots. The  effort you've invested will be worth it, as you will soon discover.</p>
<p>By working through this chapter, you will become familiar with ROS's command-line interaction and understand the scope of several types of ROS command. You will get used to working with the most frequently used communication pattern in ROS: publish-subscribe. To access real-time robot data while ROS is running, you will be introduced to the <em>rqt</em> GUI tools, which ease the work of developing and debugging an application. Additionally, ROS parameters will be introduced to give you an overview of their power to manage robot configuration at a high level.</p>
<p>We will be covering the following topics in this chapter:</p>
<ul>
<li>Setting up the physical robot</li>
<li>A quick introduction to ROS programming</li>
<li>How to write a ROS package (<strong>case study 1</strong>)</li>
<li style="font-weight: 400">An overview of ROS commands</li>
</ul>
<ul>
<li>Creating and running publisher and subscriber nodes</li>
<li>Automating the execution of nodes with roslaunch</li>
<li>ROS GUI development tools (<strong>case study 2</strong>)</li>
<li style="font-weight: 400">How to use ROS parameters</li>
</ul>
<p>We will provide explanations of these concepts based on two practical case studies:</p>
<ul>
<li><strong>Case study 1</strong>: Publishing and reading distance sensors</li>
<li><strong>Case study 2</strong>: Acquiring and visualizing images from the Pi camera</li>
</ul>
<p>There is a third case study dealing with robot control and simulation – <strong>case study 3</strong>: robot drives (motors and encoders) – which as a practical example will support the concepts that will be covered in <a href="0653ab6b-8710-41e7-9c01-5024865e3e27.xhtml" target="_blank">Chapter 7</a>, <em>Robot Control and Simulation.</em></p>
<p>So, we have three case studies and, as a result of both this chapter and the next chapter, we will have our first complete version of the ROS package for GoPiGo3. This will be the foundation on which smart robot behaviors will be built in the remaining chapters of the book.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>The code files for this chapter are available at <a href="https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter6_ROS_programming">https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter6_ROS_programming</a>.</p>
<p>When you have completed the Raspberry Pi setup, as explained in the <em>Setting up a physical robot </em>section, clone the book repository (<a href="https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming">https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming</a>) in your home folder:</p>
<pre><strong>$ cd ~</strong><br/><strong>$ git clone https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming</strong> </pre>
<p>Remember this location in order to keep a check of your work because, in this chapter, our intention is that you create all the code by yourself. Alternatively, if you decide to use the provided code, you will just need to copy the <kbd>Chapter6_ROS_programming</kbd> folder to the ROS workspace as usual:</p>
<pre><strong>$ cp -R ~/Hands-On-ROS-for-Robotics-Programming/Chapter6_ROS_programming ~/catkin_ws/src</strong></pre>
<p>The ROS workspace in the robot is initialized in the next section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up a physical robot</h1>
                
            
            
                
<p>As mentioned in <a href="f3ecc0de-28c4-4140-9a9c-ed351c68d121.xhtml" target="_blank">Chapter 3</a>, <em>Getting Started with ROS</em>, we will now start working with a physical robot. Therefore, the first thing to do is to prepare the software you need to be running in the Raspberry Pi. This section will guide you through the process step by step.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Downloading and setting up Ubuntu Mate 18.04 </h1>
                
            
            
                
<p><strong>Mate</strong> is, at the time of writing, the recommended Ubuntu desktop to run under Raspberry Pi. It is a complete Ubuntu distribution with a nice desktop interface. Follow these steps to make it run in your GoPiGo3:</p>
<ol>
<li>Download the image from <a href="https://ubuntu-mate.org/download/">https://ubuntu-mate.org/download/</a>, selecting the Raspberry Pi version (recommended): AArch32 (ARMv7). Burn the image onto a micro SD card. Afterward, place it in the slot in the Raspberry Pi, plug in a mouse and keyboard, connect to an HDMI screen, and then power on the board.</li>
<li>The first time you initiate it, a setup assistant will guide you through the process of configuring the operating system. In this book, we assume that the Ubuntu user is named <kbd>pi</kbd>. Change the code as necessary if you use another username.</li>
<li>Make sure that you connect to the local WiFi by selecting a network from the list that is deployed when clicking on the wireless icon in the upper-right corner of the screen. It is strongly recommended that you add a second mobile WiFi network preferably like the one that your smartphone provides. This will avoid the need to connect to the HDMI screen, keyboard, and mouse when you move the robot away from home in the future.</li>
</ol>
<p>The following instructions are optional and are believed to provide a friendlier way to access the Raspberry Pi.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Access customization</h1>
                
            
            
                
<p>For more friendly access to your system, it is recommended that you allow your Ubuntu user to access <kbd>sudo</kbd> without a password:</p>
<ol>
<li>In a terminal, type the following:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo visudo</strong></pre>
<ol start="2">
<li>Then, add this line at the end of the file:</li>
</ol>
<pre style="padding-left: 60px"><strong>pi</strong> ALL=(ALL) NOPASSWD: ALL</pre>
<ol start="3">
<li>Save your changes and exit so that they take effect.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Updating your system and installing basic utilities</h1>
                
            
            
                
<p>By running the following command, first you will update the Ubuntu repositories in your system; afterward, the system packages will be upgraded:</p>
<pre><strong>$ sudo apt update &amp;&amp; sudo apt upgrade -y</strong></pre>
<p>You will need a <kbd>git</kbd> package in order to clone the repositories of code. If this is not on your system, then you can install it using the following command:</p>
<pre><strong>$ sudo apt install git</strong></pre>
<p>We will also add another useful package, <kbd>tree</kbd>, in order to get information from the filesystem:</p>
<pre><strong>$ sudo apt install tree</strong></pre>
<p>The <kbd>tree</kbd> package is a utility that enables you to view the content of a folder and its subfolders at the same time, representing it visually via a tree structure.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Enabling SSH access</h1>
                
            
            
                
<p>It is common to have issues with the SSH server that comes preinstalled with Ubuntu:</p>
<ol>
<li>To avoid any problems, remove the OpenSSH package and install it again:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ sudo apt remove openssh-server</strong><br/><strong>$ sudo apt install openssh-server</strong></pre>
<ol start="2">
<li>Enable the service so that it starts on boot:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ sudo systemctl enable ssh</strong><br/><strong>$ sudo systemctl start ssh</strong></pre>
<ol start="3">
<li>Confirm that the SSH server is up and running:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ sudo systemctl status ssh</strong></pre>
<p class="mce-root">At this stage, you should be able to log in from this host to any other SSH-enabled Ubuntu server, such as your laptop.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up a VNC server (x11vnc)</h1>
                
            
            
                
<p>OpenSSH allows us to log in remotely to our Raspberry Pi using a terminal. We will also equip our robot with another remote way of connection, that is, by accessing its desktop. In order to do this, we will use <kbd>x11vnc</kbd>, a package that implements a remote desktop using <strong>Virtual Network Computing</strong> (<strong>VNC</strong>):</p>
<ol>
<li>Update the Ubuntu repositories and install:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo apt-get update</strong><br/><strong>$ sudo apt-get install x11vnc</strong></pre>
<ol start="2">
<li>Now create a password to connect with a client:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ x11vnc -storepasswd</strong></pre>
<ol start="3">
<li>Type in a password and remember it. The password is stored in <kbd>/home/pi/.vnc</kbd> assuming that the current user is <kbd>pi</kbd>. Then, start the <kbd>x11vnc</kbd> server:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ sudo x11vnc -auth guess -forever -loop -noxdamage -repeat \</strong><br/><strong>              -rfbauth /home/pi/.vnc/passwd -rfbport 5900 -shared</strong></pre>
<ol start="4">
<li class="mce-root">If you want to start the server without needing a password, just remove the option from the command:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ sudo x11vnc -auth guess -forever -loop -noxdamage -repeat \</strong><br/><strong>                                            -rfbport 5900 -shared</strong></pre>
<p class="mce-root">Now you are ready to connect with a client using a VNC client such as RealVNC (<a href="https://www.realvnc.com/download/viewer/">https://www.realvnc.com/download/viewer/</a>).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up autostart on boot</h1>
                
            
            
                
<p>We want <kbd>x11vnc</kbd> to start automatically when we reboot or power on the Pi. Hence, create a script named <kbd>x11vnc.service</kbd> at location<kbd> /lib/systemd/system/</kbd>, perform the following:</p>
<pre><strong>$ sudo nano /lib/systemd/system/x11vnc.service</strong></pre>
<p>While editing, add the following lines:</p>
<pre>[Unit]<br/>Description=Start x11vnc at startup.<br/>After=multi-user.target<br/><br/>[Service]<br/>Type=simple<br/># If  using a password<br/>ExecStart=/usr/bin/x11vnc -auth guess -forever -loop -noxdamage -repeat -rfbauth /home/pi/.vnc/passwd -rfbport 5900 -shared<br/><br/>[Install]<br/>WantedBy=multi-user.target</pre>
<p>Then, enable and start the newly created service:</p>
<pre><strong>$ sudo systemctl daemon-reload</strong><br/><strong>$ sudo systemctl enable x11vnc.service</strong><br/><strong>$ sudo systemctl start x11vnc.service</strong></pre>
<p>To connect with the RealVNC viewer from a remote PC, enter the IP address of the Raspberry Pi followed by the display number, that is, <kbd>&lt;IP address&gt;:&lt;display number&gt;</kbd>. If no display is specified, then it takes <kbd>0</kbd> as default. Hence, the <kbd>0</kbd> value will be assigned to the first server you launch (which is your unique server).</p>
<p>As you are running VNC with the default port, <kbd>5900</kbd>, you do not need to specify it for the connection. If this is not the case, you should specify the custom port in the connection string.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Forcing the HDMI output and screen layout</h1>
                
            
            
                
<p>For debugging purposes, it is useful to make sure that you can always access the Ubuntu Mate desktop from a screen, even though the system does not start with it. In order to achieve this, you have to modify the configuration options of the Raspberry Pi:</p>
<pre><strong>$ sudo nano /boot/config.txt</strong></pre>
<p>The content of the file will be accessible on the screen. Uncomment the following lines, setting the shown values:</p>
<pre>hdmi_force_hotplug=1<br/><br/>hdmi_group=2   <br/>hdmi_mode=47</pre>
<p>The last two lines enforce the following display: at 1440 x 900 at 60 Hz. If you want to increase this to full HD resolution (1080 px), then you can do so as follows, depending on the refresh rate:</p>
<ul>
<li style="font-weight: 400">For a 50 Hz monitor, use the following:</li>
</ul>
<pre style="padding-left: 60px">hdmi_group=1<br/>hdmi_mode=31</pre>
<ul>
<li style="font-weight: 400">For a 60 Hz monitor, use the following:</li>
</ul>
<pre style="padding-left: 60px">hdmi_group=2<br/>hdmi_mode=82</pre>
<p>These commands make it easy to get 1080 px.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Geany IDE</h1>
                
            
            
                
<p>Ubuntu Mate comes with a lightweight editor called <strong>Pluma</strong>. While it is good for editing, it does not include a terminal window or other common characteristics that are found in a typical development environment. For this reason, we will install <strong>Geany</strong>, a lightweight IDE suitable for running on a Raspberry Pi that supports common programming languages:</p>
<pre><strong>$ sudo apt-get update<br/>$ sudo apt-get install -y geany</strong></pre>
<p>We will be mainly using Python, so Geany is perfect for us.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing drivers for the GoPiGo3 and DI Sensors</h1>
                
            
            
                
<p>Now we will prepare the system to work with GoPiGo3. Dexter Industries supplies automated scripts to accomplish all the installations tasks:</p>
<ul>
<li>The GoPiGo3 library, with the following script <a href="https://dexterindustries.com/update_gopigo3">https://dexterindustries.com/update_gopigo3</a></li>
<li>The DI Sensors library, with the following script <a href="https://dexterindustries.com/update_sensors">https://dexterindustries.com/update_sensors</a></li>
</ul>
<p>The relevant steps are provided in the official documentation at <a href="https://gopigo3.readthedocs.io/en/master/quickstart.html#program-your-gopigo3">https://dexterindustries.com/update_gopigo3</a>. In short, you only have to open a terminal and execute following two commands, one after another:</p>
<div><div><pre><strong>$ curl -kL dexterindustries.com/update_gopigo3 | bash</strong><br/><strong>$ curl -kL dexterindustries.com/update_sensors | bash</strong></pre></div>
</div>
<p>The installation process takes several minutes, so be patient. When finished, you will see the following new icons on your desktop:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b738f345-95fb-4067-8e5e-050fa293c275.png" style="width:42.58em;height:13.42em;"/></p>
<p>These additional utilities are as follows:</p>
<ul>
<li><strong>Advanced Communication Options</strong>: This icon is used to enable Bluetooth and/or infrared receivers.</li>
<li><strong>Line Follower Calibration</strong>: This icon is used to adjust sensor sensibility to the current illumination conditions.</li>
<li><strong>gopigo3_control_panel</strong>: This icon is used to drive the robot with a simple panel shown on the screen.</li>
<li><strong>Test and Troubleshoot</strong>: This utility generates a log file for your robot that can be sent to the manufacturer so that it can provide technical support.</li>
</ul>
<p>As an example, double-click on the <strong>Test and Troubleshoot</strong> icon. It will generate a log file of your robot that should look like the following globally:</p>
<pre>GoPiGo3 Troubleshooting Script log<br/><br/>Checking for hardware, and checking hardware and firmware version.<br/>==================================================================<br/>Manufacturer : Dexter Industries<br/>Board : GoPiGo3<br/>Serial Number : F92DD433514E343732202020FF112535<br/>Hardware version: 3.x.x<br/>Firmware version: 1.0.0<br/>Battery voltage : 9.414<br/>5v voltage : 4.889</pre>
<p>At this point, your operating system is ready to run any GoPiGo3 code, that is, the Python scripts that we used in <a href="7a2b1b82-c666-42df-9f10-9777eabe82df.xhtml" target="_blank">Chapter 2</a>, <em>Unit Testing of GoPiGo3</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up the Pi Camera</h1>
                
            
            
                
<p>The setup is done in steps 1-2. First, we will enable access to the camera hardware from the Raspberry Pi, and second, we will install the Python module to handle the camera:</p>
<ol>
<li>First, we need to edit the <kbd>/boot/config.txt</kbd> file:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo nano /boot/config.txt</strong></pre>
<ol start="2">
<li>Then, we add these two lines at the end:</li>
</ol>
<pre style="padding-left: 60px">start_x=1<br/>gpu_mem=128</pre>
<ol start="3">
<li>Alternatively, you can get the same result by adding these lines from the command line:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo bash -c "echo 'start_x=1' &gt;&gt; /boot/config.txt"</strong><br/><strong>$ sudo bash -c "echo 'gpu_mem=128' &gt;&gt; /boot/config.txt"</strong></pre>
<ol start="4">
<li>Next, install the Python module as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo pip install picamera</strong></pre>
<ol start="5">
<li class="mce-root">To check that the camera works properly, create this Python script and name it <kbd>captureFile.py</kbd> (you can find it inside the <kbd>piCamera</kbd> folder in the code for this chapter):</li>
</ol>
<div><pre style="padding-left: 60px">from time import sleep<br/>from picamera import PiCamera<br/><br/>camera = PiCamera()<br/>camera.resolution = (1024, 768)<br/><br/>camera.start_preview()<br/><br/># Camera warm-up time<br/>sleep(2)<br/><br/>camera.capture('test.jpg')</pre></div>
<ol start="6">
<li class="mce-root">Give execution permissions and run the Python module:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ chmod +x captureFile.py</strong><br/><strong>$ ./captureFile.py</strong></pre>
<p>The camera will be active for 2 seconds. Check that the red LED on the camera board is on. This is a visual sign that it is acquiring images. After this period, the LED will switch off and you should find – in the same path as the script – a new file called <kbd>test.jpg</kbd>. If you open it, you should see what the camera was viewing at the end of those 2 seconds; this is performed by: <kbd>camera.capture(test.jpg)</kbd>.</p>
<p>The last step in getting ready with the Raspberry Pi is to install ROS.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing ROS Melodic</h1>
                
            
            
                
<p>The instructions on the ROS Melodic installation page (<a href="http://wiki.ros.org/melodic/Installation/Ubuntu">http://wiki.ros.org/melodic/Installation/Ubuntu</a>) are pretty clear and straightforward. We include them here for the sake of completeness:</p>
<ol>
<li>First, add the ROS source repositories:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ sudo sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" &gt; /etc/apt/sources.list.d/ros-latest.list'</strong></pre>
<ol start="2">
<li>Then, set up your keys:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654</strong></pre>
<p style="padding-left: 60px">If you don't get a validated key, then it might have been changed (for security reasons). If that's the case, then go to the official installation page (<a href="http://wiki.ros.org/melodic/Installation/Ubuntu">http://wiki.ros.org/melodic/Installation/Ubuntu</a>), search for the line, and then replace it with the new one.</p>
<ol start="3">
<li>Next, update your sources:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo apt-get update</strong></pre>
<ol start="4">
<li>Install the desktop version of ROS so that you can take advantage of the Mate desktop environment. This will allow you to use ROS GUI tools (such as rqt or RViz):</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo apt-get install ros-melodic-desktop</strong></pre>
<ol start="5">
<li>Initialize <kbd>rosdep</kbd>. This is the component that enables you to easily install system dependencies for your source code to compile. It also requires you to run some core components in ROS:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo rosdep init
$ rosdep update</strong></pre>
<ol start="6">
<li>Set up the ROS environment for your interactive shell session:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ source /opt/ros/melodic/setup.bash</strong></pre>
<p style="padding-left: 60px">To avoid having to run this command each time, you can open a new terminal and include it in your <kbd>.bashrc</kbd> file:</p>
<pre style="padding-left: 60px"><strong>$ echo "source /opt/ros/melodic/setup.bash" &gt;&gt; ~/.bashrc
$ source ~/.bashrc</strong></pre>
<p>Now all that remains is to configure the Pi Camera. Let's do that next.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing a Pi Camera ROS package</h1>
                
            
            
                
<p>As part of the ROS installation, we should include software that will allow you to access the Pi Camera from ROS. The most used package is that from Ubiquity Robotics, and it is hosted on GitHub at <a href="https://github.com/UbiquityRobotics/raspicam_node">https://github.com/UbiquityRobotics/raspicam_node</a>.</p>
<p>To install the package, we first need to have a ROS workspace and to have mastered some practical concepts for cloning and creating ROS packages. This installation will be accomplished later on in the chapter; you will find it in the <em>Case study 2 – ROS GUI development tools – the Pi Camera</em> <em>globally</em>.</p>
<p>Hence, let's proceed now to create a workspace and add the first package inside it.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">A quick introduction to ROS programming</h1>
                
            
            
                
<p>This section is devoted to explaining an easy ROS example with GoPiGo3. By doing this, we can put our robot to work quickly so that, in later sections, we can deal with ROS commands and tools in a practical way, applying such commands and understanding what they do.</p>
<p>This very simple example is based on the distance sensor in GoPiGo3. It consists of publishing sensor readings and accessing them from other ROS nodes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up the workspace</h1>
                
            
            
                
<p>To start using contributed ROS packages or to create your own, you will need to have a workspace in which to put the code. The step-by-step procedure to accomplish such a task is as follows:</p>
<ol>
<li>From a bash terminal, create a folder and initialize the workspace:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ mkdir -p ~/catkin_ws/src</strong><br/><strong>$ cd ~/catkin_ws/src</strong><br/><strong>$ catkin_init_workspace</strong></pre>
<p style="padding-left: 60px">The initialization is as simple as creating a symlink to a file definition located in the ROS installation folder. If you list files in the <kbd>src</kbd> folder, then you will see the new <kbd>CMakeLists.txt</kbd> file pointing to <kbd>/opt/ros/melodic/share/catkin/cmake/toplevel.cmake</kbd>:</p>
<pre style="padding-left: 60px"><strong>$ ls -la</strong><br/><br/><strong>... CMakeLists.txt -&gt; /opt/ros/melodic/share/catkin/cmake/toplevel.cmake</strong></pre>
<ol start="2">
<li>Next, build the workspace:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ cd ~/catkin_ws</strong><br/><strong>$ catkin_make</strong></pre>
<ol start="3">
<li>Then, add it to your ROS environment:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ source ~/catkin_ws/devel/setup.bash</strong></pre>
<ol start="4">
<li>Alternatively, you can automate the execution of this command by including it at the end of your <kbd>.bashrc</kbd> file. To do so, execute the following command, and, afterward, run the file so that its contents take effect in the system:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ echo "source ~/catkin_ws/devel/setup.bash" &gt;&gt; ~/.bashrc</strong><br/><strong>$ source ~/.bashrc</strong></pre>
<p>At this point, you should have the following two lines at the end of the file (the first one is for the ROS global environment, while the second is for your private workspace):</p>
<pre>source /opt/ros/kinetic/setup.bash<br/>source ~/catkin_ws/devel/setup.bash</pre>
<p>Everything is now ready to include the ROS packages we need. In the following section, we will add two of them: one cloning an existing repository and another one creating a package from scratch.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Cloning a ROS package</h1>
                
            
            
                
<p>For the cloning option, we are going to use a basic GoPiGo3 ROS package that is publicly available in GitHub from <a href="https://github.com/ros-gopigo/gopigo3_node">https://github.com/ros-gopigo/gopigo3_node</a>. Change to the <kbd>src</kbd> folder, which is the location where we will place all ROS packages, and then clone the source code:</p>
<pre><strong>$ cd ~/catkin_ws/src</strong><br/><strong>$ git clone https://github.com/ros-gopigo/gopigo3_node</strong></pre>
<p>Every time you add a new package, you have to rebuild the workspace so that ROS is aware of its existence and can add it to the execution environment. Hence, run the following commands:</p>
<pre><strong>$ cd ~/catkin_ws</strong><br/><strong>$ catkin_make</strong></pre>
<p>Now, you will see a number of lines indicating the progress in % and what the current building step is doing. If everything is okay, the last line displays 100% complete and returns the control to the command line. This means that you have just successfully installed the <kbd>gopigo3_node</kbd> package.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Our first execution of a ROS node</h1>
                
            
            
                
<p>Since ROS will be running on the Raspberry Pi, you will have to remotely connect to it. In order to do so, open a VNC connection to GoPiGo. Then, open a terminal in its desktop and install Terminator (the same utility we used in <a href="f3ecc0de-28c4-4140-9a9c-ed351c68d121.xhtml" target="_blank">Chapter 3</a>, <em>Getting Started with ROS</em>) to have as many terminals as you need in the same window:</p>
<pre><strong>$ sudo apt-get update</strong><br/><strong>$ sudo apt-get install terminator</strong></pre>
<p>Move to the location of the newly added ROS package and list the files inside:</p>
<pre><strong>$ cd ~/catkin_ws/src/gopigo3_node/src</strong><br/><strong>$ ls</strong></pre>
<p class="mce-root">You will see several Python files for controlling GoPiGo3 sensors and drives. Assuming that you have installed the GoPiGo3 and DI Sensors libraries, as explained in the <em>Setting up a physical robot </em>section, open Terminator and divide the window into at least three terminals. We are going to execute the <kbd>distance_sensor.py</kbd> file under ROS. For that, we will need to issue three commands as follows:</p>
<pre class="mce-root"><strong>T1 $ roscore</strong><br/><strong>T2 $ rosrun gopigo3_node distance_sensor.py</strong><br/><strong>T3 $ rostopic echo /distance_sensor/distance</strong></pre>
<p>The following is globally what each command performs:</p>
<ul>
<li><kbd>T1</kbd> launches the roscore process. This is necessary for all subsequent processes that can communicate in ROS.</li>
<li><kbd>T2</kbd> executes the <kbd>distance_sensor</kbd> node, which takes the readings and publishes them under the <kbd>/distance_sensor/distance</kbd> topic. </li>
<li><kbd>T3</kbd> listens to published data in real time and prints a new message each time a reading is acquired.</li>
</ul>
<p class="mce-root">In the following screenshot, you can see what each terminal shows. Each reading of the sensor delivers a message that has several fields. Later on, in the <em>Case study 1 – writing a ROS package – distance sensor</em> section, we will explain how this message is created. For now, it is enough that you know that the <kbd>range</kbd> field, boxed in red, is the sensor measurement in a meters:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1388 image-border" src="img/cd92f53f-4cd4-4a06-acaf-b52e18252b40.png" style="width:29.33em;height:22.50em;"/></p>
<p>To take just the last measurement, simply run the following command, where the number after <em>-n</em> indicates how many messages you want to print, which, in our case, is 1:</p>
<pre class="mce-root"><strong>T4 $ rostopic echo /distance_sensor/distance -n 1</strong></pre>
<p>The next step will be to create your own ROS package. The code we are going to write makes the same package as the <kbd>distance_sensor.py</kbd> script but uses the <kbd>EasyDistanceSensor</kbd> class (from the <kbd>di_sensors.easy_distance_sensor</kbd> library) instead of the full <kbd>DistanceSensor</kbd> version (from the <kbd>di_sensors.distance_sensor</kbd> library), which was used by the script in the package that we cloned previously.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Case study 1 – writing a ROS distance-sensor package</h1>
                
            
            
                
<p>In this section, you will create a ROS package from scratch and produce the code to provide minimal ROS functionality with GoPiGo3, that is, reading its distance sensor. Be aware that the code you previously cloned at this location is the working solution for what your code is expected to do:</p>
<pre><strong> ~/Hands-On-ROS-for-Robotics-Programming/Chapter6_ROS_programming/pkg_mygopigo</strong></pre>
<p>We encourage you to try to build the ROS package by yourself, following the explanations that are provided next in this chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a new package</h1>
                
            
            
                
<p>First, let's set up a folder in the workspace where we will place the package files:</p>
<ol>
<li>Move to the <kbd>src</kbd> location in the <kbd>catkin_ws worspace</kbd> folder:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ cd ~/catkin_ws/src</strong></pre>
<ol start="2">
<li>Create a package called <kbd>mygopigo</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ catkin_create_pkg mygopigo</strong></pre>
<p>This command creates two files of the package definition <kbd>CMakeLists.txt</kbd> and <kbd>package.xml</kbd>, which were already introduced in the previous chapter. As there is a new package, you should rebuild the workspace:</p>
<pre class="mce-root"><strong>$ cd ~/catkin_ws</strong><br/><strong>$ catkin_make</strong></pre>
<p class="mce-root">If, at some point, you wish to change the project name, then you need to complete these three steps:</p>
<ol>
<li class="mce-root">Edit in the <kbd>&lt;name&gt;mygopigo&lt;/name&gt;</kbd> tag in package.xml.</li>
<li class="mce-root">Edit the line project (<kbd>mygopigo</kbd>) in CMakeLists.txt, where the project has to be the same as the <kbd>package.xml</kbd> &lt;name&gt; tag.</li>
<li class="mce-root">Rebuild the workspace.</li>
</ol>
<p class="mce-root">The folder under which the files of the package are stored can be named however you like – it does not have to be the same as the package name.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Producing your source code</h1>
                
            
            
                
<p>The <kbd>mygopigo</kbd> folder is ready so that we can create the package structure and place the files:</p>
<ol>
<li>Create the <kbd>src</kbd> folder inside the package – note that this is a convention we use to standardize where the code is placed in repositories:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ roscd mygopigo</strong><br/><strong>$ mkdir src</strong><br/><strong>$ cd src</strong></pre>
<p style="padding-left: 60px">The <kbd>roscd</kbd> ROS command is equivalent to the Linux bash <kbd>cd</kbd> command. Its advantage is that you only have to specify the package name in order to move to the package's folder, which is <kbd>~/catkin_ws/src/mygopigo/</kbd>. Then, create a Python file to acquire data from the distance sensor:</p>
<pre style="padding-left: 60px"><strong>$ nano distance-sensor.py</strong></pre>
<ol start="2">
<li>Copy and paste the following lines globally inside the file:</li>
</ol>
<pre style="padding-left: 60px">#!/usr/bin/env python<br/><br/># import the modules<br/>from di_sensors.easy_distance_sensor import EasyDistanceSensor<br/>from time import sleep<br/><br/># instantiate the distance object<br/>my_sensor = EasyDistanceSensor()<br/><br/># and read the sensor iteratively<br/>while True:<br/>  read_distance = my_sensor.read()<br/>  print("distance from object: {} cm".format(read_distance))<br/>  sleep(0.1)</pre>
<p style="padding-left: 60px">This is the unit test file for the distance sensor that we reviewed in the previous chapter. We will explain how to convert it into a ROS-integrated script.</p>
<p>ROS requires that source code be in files with the following execution permission: <kbd>$ chmod +x distance-sensor.py</kbd>.</p>
<ol start="3">
<li>To run, just invoke it from the command line:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ ./distance-sensor.py</strong></pre>
<p style="padding-left: 60px">This will print the measured distance in centimeters every 0.1 seconds. At this point, the code is still pure Python.</p>
<p>We will now explain what changes need to be carried out so that it can be integrated into ROS:</p>
<ol>
<li>First, import the modules required by ROS:</li>
</ol>
<pre style="padding-left: 60px">import rospy<br/>from sensor_msgs.msg import Range</pre>
<p style="padding-left: 60px">The <kbd>rospy</kbd> library is the Python client and <kbd>sensor_msgs.msg</kbd> defines message types for handling data from sensors within ROS. In our particular case, we only need the <kbd>Range</kbd> type message, which is what we will need for the distance sensor.</p>
<ol start="2">
<li>Python's <kbd>time</kbd> library is no longer required since <kbd>rospy</kbd> provides methods to handle time features in ROS. Hence, you may remove the line:</li>
</ol>
<pre style="padding-left: 60px">from time import sleep</pre>
<ol start="3">
<li>Next, we put the code under the <kbd>main()</kbd> function definition: </li>
</ol>
<pre style="padding-left: 60px">def main():<br/>    my_sensor = EasyDistanceSensor()<br/>    rospy.init_node("distance_sensor")<br/>    pub_distance = rospy.Publisher("~distance", Range, queue_size=10)<br/>    msg_range = Range()<br/>    msg_range.header.frame_id = "distance"<br/>    msg_range.radiation_type = Range.INFRARED<br/>    msg_range.min_range = 0.02<br/>    msg_range.max_range = 3.0<br/>    rate = rospy.Rate(rospy.get_param('~hz', 1))<br/></pre>
<ol start="4">
<li>We launch a ROS node called <kbd>distance_sensor</kbd>, define a publisher called <kbd>pub_distance</kbd>, set the characteristics of the sensor in the <kbd>msg_range message</kbd>, and specify the rate we want to read the sensor at, which is 1 Hz. We complete the code of the main function by running an infinite loop that takes a reading of the sensor in each iteration:</li>
</ol>
<pre>    while not rospy.is_shutdown():<br/>        <br/>        read_distance = my_sensor.read()/100.0<br/>        msg_range.range = read_distance<br/>        msg_range.header.stamp = rospy.Time.now()<br/><br/>        print msg_range.range*1000," mm"<br/>        pub_distance.publish(msg_range)<br/><br/>        rate.sleep()</pre>
<p>In each iteration, this code saves the sensor data in the <kbd>msg_range</kbd> instance, publishes the message to the <kbd>/distance_sensor/distance</kbd> topic, and runtime-delays the next reading to respect the specified rate. Finally, we tell Python to run the <kbd>main()</kbd> function:</p>
<div><pre>comment ...<br/>if __name__ == '__main__':<br/>    main()<br/></pre></div>
<p>In the following subsections, we will cover more information about these pieces of code in detail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Including the required libraries – rospy and msgs.msg </h1>
                
            
            
                
<div><p>The following two lines import the required ROS libraries:</p>
<pre>import rospy<br/>from sensor_msgs.msg import Range</pre></div>
<p>These libraries are explained as follows:</p>
<ul>
<li><kbd>rospy</kbd> (<a href="http://wiki.ros.org/rospy">http://wiki.ros.org/rospy</a>): This is the official Python client for ROS. It implements  API methods so that you can integrate ROS nodes coded in Python.</li>
<li><kbd>sensor_msgs</kbd> (<a href="http://wiki.ros.org/sensor_msgs">http://wiki.ros.org/sensor_msgs</a>): This is the ROS package that lets you handle different types of ROS message depending on the sensors and drives of your robot; for example, <kbd>BatteryState</kbd>, <kbd>FluidPressure</kbd>, and <kbd>LaserScan</kbd>. In the case of the distance sensor, we use the <kbd>Range</kbd> type.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Assigning a node name to the script</h1>
                
            
            
                
<p>This task is accomplished using the <kbd>init_node</kbd> method of the <kbd>rospy</kbd> library:</p>
<pre>rospy.init_node("distance_sensor")</pre>
<p>Using the <kbd>distance_sensor</kbd> name, we will reference the distance sensor node anywhere in ROS.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Defining the publisher</h1>
                
            
            
                
<p>The publisher is a function – again, a <kbd>rospy</kbd> method that permits you to assign to the <kbd>pub_distance</kbd> variable the result of the measurement, which, in our case, is of the <kbd>Range</kbd> type:</p>
<pre>pub_distance = rospy.Publisher("~distance", Range, queue_size=10)</pre>
<p>The value between the quotation marks is the topic name, <kbd>~distance</kbd>. The prepended symbol, <kbd>~</kbd>, is equivalent to <kbd>&lt;name of node&gt;/</kbd>, which, in our case, is <kbd>distance_sensor</kbd>. Following this, the namespace topic will be as follows: </p>
<pre>/distance_sensor/distance</pre>
<p>The <kbd>queue_size</kbd> parameter specifies how many messages ROS keeps in memory to ensure that the subscriber nodes read them. A value of <kbd>10</kbd> is a good default.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up the msg_range object</h1>
                
            
            
                
<p>The distance sensor uses the message type defined in the <kbd>Range</kbd> class of the <kbd>sensor_msgs.msg</kbd> library, whose structure is as follows:</p>
<pre>uint8 ULTRASOUND=0<br/>uint8 INFRARED=1<br/><br/>std_msgs/Header <strong>header</strong><br/>uint8 <strong>radiation_type</strong><br/>float32 <strong>field_of_view</strong><br/>float32 <strong>min_range</strong><br/>float32 <strong>max_range</strong><br/>float32 <strong>range</strong></pre>
<p>These are the fields that will be part of any message involving the data flow from the sensor, and its syntax is explained in detail in the documentation (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Range.html">http://docs.ros.org/api/sensor_msgs/html/msg/Range.html</a>). All the fields are specific characteristics of the sensor except for the measurement itself, <kbd>range</kbd>. Hence, the following snippet gives a particular definition for our distance sensor:</p>
<div><pre>msg_range = Range()<br/><br/>msg_range.header.frame_id = "distance"<br/>msg_range.radiation_type = Range.INFRARED<br/>msg_range.min_range = 0.02<br/>msg_range.max_range = 3.0</pre></div>
<p>Here, the first line initiates the <kbd>msg_range</kbd> variable to be of the <kbd>Range()</kbd> type. In the <kbd>header.frame_id</kbd> field, we indicate the physical magnitude we are going to measure, which is <kbd>distance</kbd>.</p>
<p>The <kbd>radiation</kbd> type is set to <kbd>INFRARED</kbd> (there is no option to set this to <kbd>LASER</kbd>, but specifying it as <kbd>INFRARED</kbd> is more adequate than the other option, <kbd>ULTRASOUND</kbd>, for which you would have a wide field of view instead of a straight ray). <kbd>LASER</kbd> is directional, as is <kbd>INFRARED</kbd>, so it is better to use this type.</p>
<p>The last two lines specify the maximum (3 meters) and minimum (2 centimeters) distances the sensor can measure.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Changing units to the International System of Units</h1>
                
            
            
                
<p>Adopting the <strong>International System of Units</strong> (<strong>SI</strong>) is the ROS convention stated in its specification (<a href="https://www.ros.org/reps/rep-0103.html">https://www.ros.org/reps/rep-0103.html</a>). Since the <kbd>read()</kbd> method provides measurements in centimeters, we only have to divide by 100 to obtain the distance in meters and feed this to the system according to the ROS standard:</p>
<pre>read_distance = my_sensor.read()/100.0</pre>
<p>This value will be inserted afterward into the <kbd>msg_range</kbd> object, which we will cover next.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding a measured distance and timestamp to the msg_range object</h1>
                
            
            
                
<p>In the <kbd>msg_range.range</kbd> field, we allocate the measured distance, and in the other field –  <kbd>msg_range.header.stamp</kbd> – we allocate the current timestamp:</p>
<pre>msg_range.<strong>range</strong> = read_distance<br/>msg_range.<strong>header.stamp</strong> = rospy.Time.now()</pre>
<p>The timestamp is obtained from the <kbd>Time.now()</kbd> method of the <kbd>rospy</kbd> library. In this way, we have a full record of the measurement.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting the reading frequency</h1>
                
            
            
                
<p>Using the <kbd>Rate</kbd> method, we can set the reading frequency to 1 Hz (this is equal to 1 sample per second; in SI units) as follows:</p>
<pre>rate = rospy.Rate(rospy.get_param('~hz', 1))</pre>
<p>We do this by defining a ROS parameter at the same time whose name is as follows (remember the meaning of the <kbd>~</kbd> symbol):</p>
<pre>distance_sensor/hz</pre>
<p>With this setup, the sensor will be read once per second.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Running an infinite loop</h1>
                
            
            
                
<p>We run the infinite loop using a specific ROS method from <kbd>rospy</kbd>:</p>
<pre>while not rospy.is_shutdown():</pre>
<p>Its syntax is self-explanatory, that is, it will run unless ROS is shutdown.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Publishing each new event</h1>
                
            
            
                
<p>We publish a new <kbd>msg_range</kbd> message each time a measure is available by using the <kbd>pub_distance</kbd> publisher defined previously:</p>
<pre>pub_distance.publish(msg_range)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Waiting until the next reading</h1>
                
            
            
                
<p>To ensure we respect the acquisition rate of 1 Hz, we apply the <kbd>sleep</kbd> method to the <kbd>rate</kbd> object that we defined above (for which we set a frequency of 1 Hz, that is, one cycle per second):</p>
<pre>rate.sleep()</pre>
<p>Bear in mind that this does not block ROS execution (it just blocks the script of this node), that is, just the code of this <kbd>distance_sensor</kbd> node. If there were other nodes in the environment, then they would have their own independent execution threads. If you were using a native asynchronous language such as JavaScript, then you could also run asynchronous code within the node and also avoid the blockage in the execution of the script, that is, your node could be executing other lines while waiting for the next sensor reading</p>
<p>If you are curious about this, you can investigate the ROS client library, <kbd>rosnodejs</kbd> (<a href="https://www.npmjs.com/package/rosnodejs">https://www.npmjs.com/package/rosnodejs</a>), which allows you to write nodes in the JavaScript language. At this point, remember that one of the cool characteristics of ROS is that you can mix the same ROS graph nodes written in Python with nodes written in JavaScript or in any of the other ROS client libraries (<a href="http://wiki.ros.org/Client%20Libraries">http://wiki.ros.org/Client%20Libraries</a>).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Launching the ROS execution environment</h1>
                
            
            
                
<p>Now that we have understood how the Python script integrates with ROS, we will execute it in one terminal as part of the ROS runtime environment using the following steps:</p>
<ol>
<li>Prepare your divided Terminator window again for better visibility, and then run each of the following commands in independent terminals:</li>
</ol>
<pre style="padding-left: 60px"><strong>T1 $ roscore</strong><br/><strong>T2 $ rosrun mygopigo distance-sensor.py</strong><br/><strong>T3 $ rostopic echo /distance_sensor/distance</strong></pre>
<p style="padding-left: 60px">The first one launches the ROS master node. The second one is the script we have just explained, while the third allows us to watch messages published under the <kbd>/distance_sensor/distance</kbd> topic in real time. This is what you should see:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1389 image-border" src="img/89d44587-8ad5-4888-aaec-aaf266d05997.png" style="width:41.50em;height:31.58em;"/></p>
<ol start="2">
<li>Then, draw the ROS graph to get a visual insight into how nodes and topics are wired:</li>
</ol>
<pre style="padding-left: 60px"><strong>T4 $ rqt_graph</strong></pre>
<p style="padding-left: 60px">A new window pops up showing the current ROS graph: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1390 image-border" src="img/53110697-034d-4eb7-af1b-37cdbc51f858.png" style="width:47.83em;height:4.33em;"/></p>
<p>Here, you can see that it reproduces what we are doing in the three terminals: we execute the <kbd>/easyDistance_sensor</kbd> node, which is publishing sensor data at the <kbd>/easyDistance_sensor/distance</kbd> topic, and then we show the readings with a topic subscription node, <kbd>/rostopic_2797_156571927410</kbd>.</p>
<p>After going through this example, we will use it to illustrate the various ROS commands and tools that you have available.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Working with ROS commands</h1>
                
            
            
                
<p>In the first part of this section, we will cover three categories: commands to be used inside bash (shell), ROS execution commands, and information commands.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Shell commands</h1>
                
            
            
                
<p>Shell commands are bundled into a ROS core package, <kbd>rosbash</kbd> (<a href="http://wiki.ros.org/rosbash">http://wiki.ros.org/rosbash</a>). Let's move on to see what each one provides.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Changing the current location</h1>
                
            
            
                
<p>First, we will cover <kbd>roscd</kbd>, which is equivalent to the Linux bash <kbd>cd</kbd> command. Its advantage is that you only have to specify the package name in order to move to the location of the package:</p>
<pre><strong>$ roscd mygopigo</strong></pre>
<p>This will take you to the <strong><kbd>~/catkin_ws/src/mygopigo/</kbd> </strong>folder. You can also navigate through the package folder structure by appending the relative path of the desired location. For example, to move to the <kbd>src</kbd> folder of the <kbd>mygopigo</kbd> package, use the following command:</p>
<pre><strong>$ roscd mygopigo/src</strong></pre>
<div><kbd>roscd</kbd> is equivalent to the Linux <kbd>cd</kbd> command. It will change the prompt to the directory of any ROS package in your system by referencing its path with the package name. No matter what the actual path is, ROS will automatically drive you there.</div>


            

            
        
    

        

                            
                    <h1 class="header-title">Listing files and folders inside a package</h1>
                
            
            
                
<p>Next, we have <kbd>rosls</kbd>, which is the equivalent of Linux <kbd>ls</kbd>. To list the source code of your package wherever you are, simply write the following:</p>
<pre><strong>$ rosls mygopigo/src</strong></pre>
<div><kbd>rosls</kbd> allows you to easily list files and folders inside any ROS package in your system by referencing its path with the package name. No matter what the actual path is, ROS will automatically take you there.</div>


            

            
        
    

        

                            
                    <h1 class="header-title">Editing any file inside a package</h1>
                
            
            
                
<p>Finally, we have <kbd>rosed</kbd>, which opens a terminal editor, such as <kbd>nano</kbd>, so that you can modify any file in the package:</p>
<pre><strong>$ rosed mygopigo distance-sensor.py</strong></pre>
<p>For <kbd>rosed</kbd> to work properly, you have to specify an editor:</p>
<pre>export EDITOR=nano</pre>
<p>To make it part of your configuration, add the preceding line to the end of your <kbd>.bashrc</kbd> file:</p>
<pre>echo 'export EDITOR=nano' &gt;&gt; ~/.bashrc</pre>
<div><kbd>rosed</kbd> is equivalent to launching the Linux terminal editor, which is <kbd>nano</kbd>.  It will allow you to edit any file inside a ROS package by simply telling it the package name, no matter which subfolder the file is actually in.</div>
<p>This command is a convenient way to modify a file when you are connected remotely to the robot and you only have a terminal to interact with. If you are on a desktop session, you can even use a desktop IDE if you wish:</p>
<pre>EDITOR=geany rosed <strong>mygopigo</strong> distance-sensor.py</pre>
<p>In this case, you are calling the editor on the fly and superseding the default set in <kbd>.bashrc</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Execution commands</h1>
                
            
            
                
<p>In <a href="f3ecc0de-28c4-4140-9a9c-ed351c68d121.xhtml" target="_blank">Chapter 3</a>, <em>Getting Started with ROS</em>, we already introduced the <kbd>roscore</kbd> and <kbd>rosrun</kbd> commands for running our first project.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The central process of the ROS environment</h1>
                
            
            
                
<p><kbd>roscore</kbd> is the first process you have to launch so that the ROS environment works.<kbd>roscore</kbd> allows nodes to communicate between themselves. It has no parameters, so write this line in a terminal:</p>
<pre><strong>$ roscore</strong></pre>
<div><kbd>roscore</kbd> launches the master node, which is the central process of your ROS environment and keeps all nodes that are actually running connected.</div>


            

            
        
    

        

                            
                    <h1 class="header-title">Executing a single node</h1>
                
            
            
                
<p class="mce-root"><kbd>rosrun</kbd> allows you to manually launch a node from a package. The syntax is quite simple:</p>
<pre><strong>$ rosrun &lt;name_of_package&gt; &lt;name_of_script&gt;</strong></pre>
<p class="mce-root">The script includes a declaration of a node. In the case of our <kbd>distance-sensor.py</kbd> example, this is accomplished in the following line:</p>
<div><pre>rospy.init_node("distance_sensor")</pre></div>
<p>Then, to launch the node, write this command in another terminal:</p>
<pre><strong>$ rosrun mygopigo distance-sensor.py</strong></pre>
<p>After these two commands, you already have a ROS functional environment that provides sensor readings. The node also prints the current measure in the terminal process, transformed into millimeters (there is no need to open another terminal to listen to the topic). The usage of millimeters is just for visualization purposes. The ROS message keeps its distance units as meters, which you can check by subscribing to the topic in another terminal:</p>
<div><div><pre>print<strong> msg_range</strong>.range*1000," mm"</pre></div>
</div>
<div><kbd>rosrun</kbd> allows you to launch a single node from a package. It is a command for performing manual node execution within your ROS environment.</div>
<p>Finally, we have <kbd>roslaunch</kbd>. This is the most relevant execution command since it allows you to describe a robot with an XML file. You can declare its nodes and link each one with the scripts that execute it. We will view this command in more detail in the <em>Automating the execution of a node using roslaunch</em> section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Information commands</h1>
                
            
            
                
<p>This category groups several commands that allow you to extract information from ROS environment as well as interactively modify some values. All of the commands are prepended with <kbd>ros-</kbd>. Simply writing the command in the terminal, supplies help with the different options regarding how to use each of them. A brief description and an example for each command are provided next.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Exploring topics</h1>
                
            
            
                
<p><kbd>rostopic</kbd> provides information about published topics:</p>
<pre><strong>$ rostopic list</strong></pre>
<p>This lists all the topics that are currently alive. From the list, you can access the real-time feed of any of them:</p>
<pre><strong>$ rostopic echo distance_sensor/distance</strong></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Exploring nodes</h1>
                
            
            
                
<p><kbd>rosnode</kbd><strong> </strong>provides information about nodes that are alive:</p>
<pre><strong>$ rosnode list</strong></pre>
<p>This lists all the nodes of the current ROS graph. From the list, you can access information about any of them:</p>
<pre><strong>$ rosnode info distance_sensor</strong></pre>
<p>Here, <kbd>info</kbd> will provide you with useful information about the <kbd>distance_sensor</kbd> node. Do not confuse this with the name of the Python script where the node is declared, <kbd>distance-sensor.py</kbd>. The <kbd>rosnode</kbd> command always refers to the name of the node.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The rosmsg command</h1>
                
            
            
                
<p><kbd>rosmsg</kbd><strong> </strong>provides information about the types of message used by topics during runtime. To give you a practical example, we select the <kbd>distance_sensor/distance</kbd> topic and get the following information about it:</p>
<pre><strong>$ rostopic info</strong><strong> distance_sensor/distance</strong><br/></pre>
<p>This command tells us that the topic has a message type of <kbd>sensor_msgs/Range</kbd>. Then, <kbd>rosmsg</kbd> informs us of the message structure:</p>
<pre><strong>$ rosmsg info sensor_msgs/Range</strong></pre>
<p>The output of this command is what we showed and explained in the <em>Setting up the msg_range object</em> subsection of the <em>Case study 1 – writing a ROS package – distance sensor</em> section. In the next chapter, we will provide extended explanations about the new message types we will be using in the GoPiGo3 ROS package. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">The rosbag command</h1>
                
            
            
                
<p>This command allows you to save a session and play it back on demand. Let's look at how to do that:</p>
<pre><strong>T1 $ roslaunch mygopigo easyDistance.launch<br/>T2 $ rosbag record /distance_sensor/distance</strong></pre>
<p>Press <em>Ctrl</em> + <em>C</em> in the T2 terminal when you want to end the recording. Type <kbd>rosbag info &lt;bag filename&gt;</kbd> into <kbd>T2</kbd> to get information about the recorded file (the default name for the file is composed by the sequence <kbd>date-time-topic_name</kbd>, and it is given the <kbd>.bag</kbd> extension):</p>
<pre><strong>T2 $ rosbag info 2019-08-15-20-36-36_distanceSensor.bag<br/><br/>path: 2019-08-15-20-36-36.bag<br/>version: 2.0<br/>duration: 46.0s<br/>start: Aug 15 2019 20:36:37.48 (1565894197.48)<br/>end: Aug 15 2019 20:37:23.50 (1565894243.50)<br/>size: 14.5 KB<br/>messages: 47<br/>compression: none [1/1 chunks]<br/>types: sensor_msgs/Range [c005c34273dc426c67a020a87bc24148]<br/>topics: /distance_sensor/distance 47 msgs : sensor_msgs/Range</strong></pre>
<p>Bear in mind that the bag file is placed in the location from which you launched the recording session in the <kbd>T2</kbd> terminal.</p>
<p>The recorded bag file allows to reproduce the topic history whenever we want, just as we do when we play a recorded song. One example of a typical situation where you would use this is to replay the robot behavior without the robot itself, using ROS on your laptop. This method eases debugging of the application and enables you to drastically reduce the number of times you need to run the software in the actual robot.</p>
<p>First, let's play it back in the Raspberry Pi by running the following set of commands, which include the visualization of the ROS graph (the <kbd>rqt_graph</kbd> command) and the measured distance over time (the <kbd>rqt_plot</kbd> command):</p>
<pre><strong>T1 $ roscore</strong><br/><strong>T2 $ rosbag play 2019-08-15-20-36-36_distanceSensor.bag<br/><br/>T3 $ rostopic echo /distance_sensor/distance<br/>T4 $ rqt_graph<br/>T5 $ rqt_plot</strong></pre>
<p>In this snippet, we have introduced a new command, <kbd>rqt_plot</kbd>, that will be explained later in the <em>Case study 2– ROS GUI development tools – the Pi camera</em> section. Briefly, it plots a selected ROS topic over time.</p>
<p>Now you can playback the session on the laptop by<strong> </strong>launching the same set of commands. You will get the following result for <kbd>rqt_plot</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1391 image-border" src="img/6093c672-283b-4a00-a5e9-8d2a0c59231b.png" style="width:41.58em;height:23.33em;"/></p>
<p>From the point of view of ROS, the result is exactly the same as if you were running the actual launch file in GoPiGo3. The difference, with respect to the figures, is due to the fact that you have ROS Kinetic on your laptop, while the robot has the Melodic version (which is more recent).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Packages and the catkin workspace</h1>
                
            
            
                
<p>Some commands in this section have already been used when configuring your ROS environment. Let's briefly review them now:</p>
<ul>
<li><kbd>catkin_init_workspace</kbd><strong> </strong>initializes a new workspace, as you did at the beginning of this chapter.</li>
<li><kbd>catkin_create_pkg</kbd><strong> </strong>creates a new package.</li>
<li><kbd>catkin_make</kbd> builds a workspace and should be invoked each time you add a package or remove one.</li>
</ul>
<p class="mce-root">These are the essential commands. Nevertheless, there are some additional commands that are worth mentioning:</p>
<ul>
<li class="mce-root"><kbd>catkin_find</kbd><strong> </strong>lists the working folders of your ROS environment.</li>
<li class="mce-root"><kbd>rospack</kbd><strong> </strong>provides information about a ROS package, be it from the core, contributed, or made by yourself. If you want to know which ROS packages are installed when dealing with GoPiGo, you can do so with this command:</li>
</ul>
<pre style="padding-left: 60px"><strong>$ rospack list | grep gopigo</strong><br/><strong>    gopigo3_node /home/pi/catkin_ws/src/gopigo3_node</strong><br/><strong>    mygopigo /home/pi/catkin_ws/src/mygopigo</strong></pre>
<p class="mce-root">The only caution you should have is that all of them should have the letters <kbd>gopigo</kbd> within their name so that <kbd>grep</kbd> can filter them without missing any.</p>
<p>In this section, we have provided an overview of the most frequent commands. Take all the time that you need to feel comfortable using them as you will be continuously using them when working with ROS. In the next section, we will extend our knowledge of the publish-subscribe pattern by explaining the syntax of the subscriber node, which is the node that will read messages from the selected topic. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating and running publisher and subscriber nodes</h1>
                
            
            
                
<p>If you have understood how the requirement, <kbd>distance-sensor.py</kbd>, publisher script works, then the following subscriber script should be pretty straightforward to follow:</p>
<pre>#!/usr/bin/env python<br/><br/>import rospy<br/>from sensor_msgs.msg import Range<br/><br/>def callback(msg):<br/>    print msg.data<br/>    rospy.loginfo(rospy.get_caller_id() + 'GoPiGo3 measures distance %s mm', msg.data*1000)<br/><br/>rospy.init_node('distance_sensor_subscriber')<br/><br/>sub = rospy.Subscriber('distance_sensor/distance', Range, callback)<br/><br/>rospy.spin()</pre>
<p>This snippet corresponds to the <kbd>distance-sensor_subscriber.py</kbd> file in the <kbd>./pkg_mygopigo/src</kbd> folder of the code for this chapter. The main difference in the subscriber script is that, since we are listening to a topic, we do not need to specify a rate of execution. We simply loop forever with the following line:</p>
<pre>rospy.<strong>spin</strong>()</pre>
<p>Whenever a message is received in the topic, a callback function will be executed:</p>
<pre>sub = rospy.Subscriber('distance_sensor/distance', Range, <strong>callback</strong>)</pre>
<p>In this case, this callback function is defined to print the measured distance in millimeters:</p>
<pre>def callback(msg):<br/>    print msg.data<br/>    rospy.loginfo(rospy.get_caller_id() + 'GoPiGo3 measures distance %s mm', msg.data*1000)</pre>
<p>Execute the script within ROS by using several terminals in the Terminator window:</p>
<pre><strong>T1 $ roscore</strong><br/><strong>T2 $ rosrun mygopigo distance-sensor.py</strong><br/><strong>T3 $ rostopic echo distance_sensor/distance</strong><br/><strong>T4 $ rosrun mygopigo distance-sensor_subscriber.py</strong><br/><strong>T5 $ rqt_graph</strong></pre>
<p>Take a look at the terminal window, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1392 image-border" src="img/81801fe8-0f93-436c-bae6-90c564c73ed0.png" style="width:55.08em;height:37.83em;"/></p>
<p>The following is globally the ROS graph:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1393 image-border" src="img/4d8030c9-7fce-4e2b-b257-c32b88a7a8a4.png" style="width:44.33em;height:8.58em;"/></p>
<p>There are two nodes listening to the same topic. One is the subscriber script we have explained with the <kbd>/distance_subscriber</kbd> node, and the other is the node created by the <kbd>rostopic echo</kbd> command.</p>
<p>So far, you have manually launched each ROS node. In the next section, you will learn how to do it programmatically to run the robot software as an automated task.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Automating the execution of nodes using roslaunch</h1>
                
            
            
                
<p class="mce-root">Once you have decided which nodes you want to run as part of your robot, you can automate the launch process for all scripts by using the <kbd>roslaunch</kbd> command. Its syntax is as follows:</p>
<pre><strong>$ roslaunch &lt;name_of_package&gt; &lt;name_of_launch_file&gt;</strong></pre>
<p>For our example, this is pretty simple as there is only one node. The launch file is in the repository at <kbd>./pkg_mygopigo/launch/easyDistance.launch</kbd> and its syntax is based on XML:</p>
<div><pre>&lt;launch&gt;<br/>   &lt;node name="easyDistance_sensor" pkg="mygopigo" type="distance-sensor.py" output="screen" /&gt;<br/>   node name="distance_subscriber" pkg="mygopigo" type="distance-sensor_subscriber.py" output="screen" /&gt;<br/>&lt;/launch&gt;</pre></div>
<p>The <kbd>&lt;launch&gt;</kbd> tag delineates the robot description. Then, you include one <kbd>&lt;node&gt;</kbd> tag for each node you want to launch. In our case, there is only one: the <kbd>distance_sensor</kbd> node. The description of its attributes is as follows:</p>
<ul>
<li class="mce-root"><kbd>name</kbd>: The designation to identify the node. This supersedes the given name in the line of the script:</li>
</ul>
<pre style="color: black;padding-left: 60px">rospy.init_node("distance_sensor")</pre>
<p style="padding-left: 60px">We set a different name in this launch file, <kbd>easyDistance_sensor</kbd>:</p>
<ul>
<li><kbd>pkg</kbd>: This is the name of the package, which is <kbd>mygopigo</kbd>.</li>
<li><kbd>type</kbd>: This is a reference to the script that launches the node, <kbd>easyDistance.py</kbd>.</li>
<li><kbd>output</kbd>: We specify the screen (the default is the log that directs the output to <kbd>$ROS_HOME/log</kbd>).</li>
</ul>
<p>Once you understand the XML launch file, repeat the process of raising up the robot, but, this time, use the automated way:</p>
<div><pre><strong>T1 $ roslaunch mygopigo easyDistance.launch<br/>T2 $ rostopic echo /easyDistance_sensor/distance</strong></pre>
<p><kbd>roslaunch</kbd> implicitly initiates <kbd>roscore</kbd>. You should see the same output as when you run it manually with <kbd>rosrun</kbd>. Obviously, <kbd>roslaunch</kbd> is really useful when you have to launch many nodes at the same time. We will see examples of this later.</p>
</div>
<p>Execute the script within ROS by using several terminals under the Terminator window:</p>
<pre><strong>T1 $ roslaunch mygopigo easyDistance.launch<br/>T2 $ rostopic echo distance_sensor/distance</strong><br/><strong>T3 $ rqt_graph</strong></pre>
<p>Take a look at the following terminal window:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1394 image-border" src="img/f3760ca9-60e7-4f59-acc7-a4fa33d2a883.png" style="width:98.17em;height:67.08em;"/></p>
<p>Here is the ROS graph:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1395 image-border" src="img/a51490a0-db4f-4816-92f0-cbdf9d454f52.png" style="width:35.92em;height:6.67em;"/></p>
<p>You will find exactly the same result as in the previous section. Let's now look at the ROS visual tools that ease our life as a software robotics developer.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Case study 2 – ROS GUI development tools – the Pi Camera </h1>
                
            
            
                
<p>As we mentioned at the end of the <em>Installing ROS Melodic</em> section, in order to be able to use the camera, we first need to install its ROS package. Since the binaries are not available for ROS Melodic (only for Kinetic), we need to build the package from the source, and this is a perfect example in that you will know how to do it with any other package. Let's do this with the following steps:</p>
<ol>
<li>Go to your <kbd>catkin</kbd> workspace and download the source code:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ cd ~/catkin_ws/src</strong><br/><strong>$ git clone https://github.com/UbiquityRobotics/raspicam_node.git</strong></pre>
<ol start="2">
<li>There are some dependencies to be installed for ROS. To carry out this task, we are going to create the <kbd>30-ubiquity.list</kbd> file:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo -s</strong><br/><strong>$ echo “yaml https://raw.githubusercontent.com/UbiquityRobotics/rosdep/master/raspberry-pi.yaml” &gt; /etc/ros/rosdep/sources.list.d/30-ubiquity.list</strong><br/><strong>$ exit</strong></pre>
<ol start="3">
<li>Afterward, run the ROS dependencies update as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ rosdep update</strong></pre>
<ol start="4">
<li>Now install the ROS dependencies:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ cd ~/catkin_ws</strong><br/><strong>$ rosdep install --from-paths src --ignore-src --rosdistro=melodic -y</strong></pre>
<ol start="5">
<li>Compile the new package as follows:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ catkin_make --only-pkg-with-deps raspicam_node<br/>$ catkin_make -DCATKIN_WHITELIST_PACKAGES=""</strong></pre>
<p style="padding-left: 60px">If you were using <kbd>catkin_make</kbd> without any option, the build process would  traverse all the packages in the workspace. So, this snippet shows you how to compile a single package while ignoring the rest. The second line allows you to switch back to enable building all the packages the next item you need to compile the workspace.</p>
<ol start="6">
<li>To run the Pi Camera node, simply launch the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>T1 $ roslaunch raspicam_node camerav2_1280x960.launch</strong></pre>
<ol start="7">
<li>If you own the previous Pi Camera version, <kbd>V1</kbd>, use the following instead:</li>
</ol>
<pre style="padding-left: 60px"><strong>T1 $ roslaunch raspicam_node camerav1_1280x720.launch</strong></pre>
<ol start="8">
<li>Then, in another terminal, run the image viewer utility that comes with the package to check that the camera is working properly:</li>
</ol>
<pre style="padding-left: 60px"><strong>T2 $ rosrun raspicam_node imv_view.py</strong></pre>
<p style="padding-left: 60px">You should see a new window similar to the following:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f324979f-5367-46df-8fe9-2b27319c96bd.png" style="width:21.75em;height:17.67em;"/></p>
<p>If you move the robot, you will find that the image also changes, so you are watching a live camera stream. Now we are ready to proceed with practical explanations for the ROS GUI development tools, which is the scope of this section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Analyzing the ROS graph using rqt_graph</h1>
                
            
            
                
<p>By issuing this command, you can visualize the current ROS graph:</p>
<pre><strong>T3 $ rqt_graph</strong></pre>
<p>It will show the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/c09ca960-8abf-4fa1-89c9-5e9610c89ca9.png" style="width:36.17em;height:3.75em;"/></p>
<p><kbd>raspicam_node</kbd> is the root node of the package that interfaces with the physical Pi Camera. It publishes images in the <kbd>/raspicam_node/image/compressed</kbd> topic. The other node, <kbd>imv_view</kbd>, from the process in the <kbd>T2</kbd> terminal, launches a window where you can watch the live stream (as shown in the preceding section).</p>
<p>Finally, inspecting the topic's <kbd>raspicam_node</kbd> provides the following:</p>
<pre><strong>T4 $ rostopic list | grep raspicam_node</strong><br/><br/><strong>/raspicam_node/camera_info</strong><br/><strong>/raspicam_node/image/compressed</strong><br/><strong>/raspicam_node/parameter_descriptions</strong><br/><strong>/raspicam_node/parameter_updates</strong></pre>
<p>You can find in the list the node that the <kbd>imv_view</kbd> node is subscribed to, which is <kbd>/raspicam_node/image/compressed</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Displaying image data using rqt_image_view</h1>
                
            
            
                
<p>This plugin allows you to visualize image data that is published in a ROS topic. Kill the previous two terminals and launch the following new ones:</p>
<pre><strong>T1 $ roslaunch raspicam_node camerav2_410x308_30fps.launch</strong><br/><strong>T2 $ rqt_image_view</strong></pre>
<p>In the upper-left drop-down list, select the topic of the image that you want to visualize. It needs to be in compressed format as it is published by <kbd>raspicam_node</kbd>. The following screenshot shows the result:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1396 image-border" src="img/34696f23-cd46-48b4-ad83-36d3d1e675a0.png" style="width:35.67em;height:28.00em;"/></p>
<p>In the event you have several topics with image data, the plugin allows you to interactively select what feed to watch and also change between them on demand.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Graphing time series of sensor data with rqt_plot</h1>
                
            
            
                
<p>This is a plugin to visualize two-dimensional data. As we want to see two-dimensional data, let's briefly switch to the distance sensor case study so that we can view the measured distance over time. The process is straightforward: launch the robot, list the topics, and then launch the plugin:</p>
<pre><strong>T1 $ roslaunch mygopigo easyDistance.launch<br/>T2 $ rostopic list | grep distance_sensor</strong><br/><strong>T3 $ rqt_plot</strong></pre>
<p>In the upper-left box, write the name of the topic you want to visualize, that is, <kbd>/distance_sensor/distance</kbd> as per <kbd>T2</kbd>. A window will pop up showing the distance to the obstacle over time:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1397 image-border" src="img/6c5007ce-e548-48c7-a300-68aba2c0d44f.png" style="width:54.25em;height:29.75em;"/></p>
<p>The green line, <kbd>msg_range.range</kbd>, is the actual measurement. The other fields of the <kbd>msg_range</kbd> object (this is the content of <kbd>topic/distance_sensor/distance</kbd>) display the maximum and minimum values of all the measurements: <kbd>msg_range.max_range</kbd> and <kbd>msg_range.min_range</kbd>, respectively.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Playing a recorded ROS session with rqt_bag </h1>
                
            
            
                
<p>The <kbd>rqt_bag</kbd> plugin plays a bag file, which is the same as the <kbd>rosbag</kbd> command explained in the <em>ROS commands</em> section. Here, the advantage is that you have interactive control of the playback: you can jump to any instant, play single time steps, rewind to the beginning, and so on. Let's examine this with the distance sensor case study first, and then with the Pi Camera.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Distance sensor</h1>
                
            
            
                
<p>You can perform the playback wherever you want, using the robot or the laptop. As with <kbd>rosbag</kbd>, you will need prior access to a <kbd>roscore</kbd> process, then you can issue <kbd>rqt_bag</kbd>:</p>
<pre><strong>T1 $ roscore</strong><br/><strong>T2 $ rqt_bag</strong></pre>
<p>A new window pops up. Select the bag file to play, that is, <kbd>2019-08-15-20-36-36_distanceSensor.bag</kbd>, right-click on the windows, and then mark the <kbd>/distance_sensor/distance</kbd> topic to be published. Run the same set of commands as when you used <kbd>rosbag</kbd>:</p>
<pre><strong>T3 $ rostopic echo /distance_sensor/distance<br/>T4 $ rqt_graph<br/>T5 $ rqt_plot</strong></pre>
<p>In the following screenshot, you can check that the result is the same:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/ecc4d4cb-1789-4fa3-9735-abb2fe0a8467.png" style="width:41.50em;height:30.08em;"/></p>
<p>Now we will play the image stream from the Pi Camera case study.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Pi Camera</h1>
                
            
            
                
<p>First, we need to record a session with the robot:</p>
<pre><strong>T1 $ roslaunch raspicam_node camerav2_410x308_30fps.launch</strong><br/><strong>T2 $ rosbag record /raspicam_node/image/compressed</strong></pre>
<p>Check the information about the recorded file:</p>
<pre><strong>$ rosbag info 2019-08-15-20-44-53_raspicamImage.bag</strong><br/><br/><strong>path: 2019-08-15-20-44-53_raspicamImage.bag</strong><br/><strong>version: 2.0</strong><br/><strong>duration: 13.3s</strong><br/><strong>start: Aug 15 2019 20:44:54.09 (1565894694.09)</strong><br/><strong>end: Aug 15 2019 20:45:07.38 (1565894707.38)</strong><br/><strong>size: 37.5 MB</strong><br/><strong>messages: 400</strong><br/><strong>compression: none [47/47 chunks]</strong><br/><strong>types: sensor_msgs/CompressedImage [8f7a12909da2c9d3332d540a0977563f]</strong><br/><strong>topics: /raspicam_node/image/compressed 400 msgs : sensor_msgs/CompressedImage</strong></pre>
<p>You can perform the playback wherever you want, using the robot or the laptop. In this case, the image data is bulkier. So, it is much better to play the session on the laptop. Launch the processes as before:</p>
<pre><strong>T1 $ roscore</strong><br/><strong>T2 $ rqt_bag</strong></pre>
<p>In the launched <kbd>rqt_bag</kbd> plugin, select the bag file to play, which is <kbd>2019-08-15-20-44-53_raspicamImage.bag</kbd>, right-click on the windows, and then mark the <kbd>/raspicam_node/image/compressed</kbd> topic to be published. Afterward, run the following set of commands:</p>
<pre><strong>T3 $ rostopic echo /raspicam_node/image/compressed<br/>T4 $ rqt_graph<br/>T5 $ rqt_image_view</strong></pre>
<p>In the upper-left drop-down list of <kbd>rqt_image_view</kbd>, select the topic of the image that you want to visualize. It needs to be in compressed format as it is published by <kbd>raspicam_node</kbd>. In the following screenshot, you can check that the result is the same:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1398 image-border" src="img/11f0baf0-73ae-4571-b9f6-c5924762d91d.png" style="width:34.67em;height:27.92em;"/></p>
<p>While playing the <em>bag</em> file, you can check that the image stream is very fluent thanks to the fact that your laptop has a powerful GPU compared to what the Raspberry Pi provides. So, it is clear that, when you are dealing with computer vision tasks, you will take advantage of this visualization capability of robot sessions within your laptop.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Customizing robot features using ROS parameters</h1>
                
            
            
                
<p>ROS parameters store the global configuration of the robot. This is a convenient way in which to define your application so that you can abstract the functionality to a high level and make it available for the end user. We are going to illustrate how ROS parameters work by using a <kbd>rqt</kbd> plugin that allows for dynamically reconfiguring of some of them. It is as it sounds; you can modify robot characteristics on the fly:</p>
<ol>
<li>Launch <kbd>raspicam_node</kbd> and then the <kbd>rqt</kbd> plugins:</li>
</ol>
<pre style="padding-left: 60px"><strong>T1 $ roslaunch raspicam_node camerav2_410x308_30fps.launch</strong><br/><strong>T2 $ rqt_image_view</strong><br/><strong>T3 $ rosrun rqt_reconfigure rqt_reconfigure</strong></pre>
<p style="padding-left: 60px">Your desktop should show the following two windows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1399 image-border" src="img/e4624f05-067b-4e2b-b110-4f568f7c7533.png" style="width:132.83em;height:57.00em;"/></p>
<ol start="2">
<li>Check the parameters on the right-hand side and focus on the brightness (the box marked in red). Modify its value from <kbd>51</kbd> to <kbd>81</kbd> and then check the result:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/4128ffb6-35cd-40f7-bc82-09489fc000e3.png"/></p>
<p style="padding-left: 60px">Wow! You can dynamically modify the configuration of the robot without needing to restart it.</p>
<ol start="3">
<li>You also have the <kbd>rosbash</kbd> command, which allows you to inspect the parameters. List them with the following line:</li>
</ol>
<pre style="padding-left: 60px"><strong>T4 $ rosparam list | grep raspicam_node</strong><br/><br/><strong>/raspicam_node/ISO</strong><br/><strong>/raspicam_node/awb_mode</strong><br/><strong>/raspicam_node/brightness</strong><br/><strong>/raspicam_node/camera_frame_id</strong><br/><strong>/raspicam_node/camera_id</strong><br/><strong>/raspicam_node/camera_info_url</strong><br/><strong>/raspicam_node/camera_name</strong><br/><strong>/raspicam_node/contrast</strong><br/><strong>/raspicam_node/enable_imv</strong><br/><strong>/raspicam_node/enable_raw</strong><br/><strong>/raspicam_node/exposure_compensation</strong><br/><strong>...</strong><br/><strong>/raspicam_node/zoom</strong></pre>
<p style="padding-left: 60px">Additionally, get the state of the one we have dynamically modified:</p>
<pre style="padding-left: 60px"><strong>T4 $ rosparam get /raspicam_node/brightness</strong><br/><strong>      81</strong></pre>
<p>If you have arrived at this point and understand the concepts in the practical exercises, you now know almost everything that you need to work with ROS from now on.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we have established the basis for programming in ROS. You have built your own package with a simple GoPiGo3 functionality: reading a distance sensor in order to work on programming concepts. You have also learned how to read Pi Camera images and make them available to ROS for further processing, which is the starting point for performing computer vision tasks.</p>
<p>In the next chapter, you will put the two ROS worlds together: the robot and your laptop. This way, once you have the GoPiGo3 package running in the robot, you will have the power to undertake all computing and processing tasks from your powerful laptop.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li>What is the difference between ROS topics and ROS messages?</li>
</ol>
<p style="padding-left: 60px">A) Both stand for the data transmitted from one node to the other.<br/>
B) A topic is how you identify a transmission channel and a message is one sample of the content that flows through that channel.<br/>C) Any topic name has to be unique, while several topics can transmit the same message.</p>
<ol start="2">
<li>Which command would use to record a ROS session?</li>
</ol>
<p style="padding-left: 60px">A) <kbd>rosbag</kbd><br/>
B) <kbd>rosrecord</kbd><br/>
C) <kbd>roswrite</kbd></p>
<ol start="3">
<li>Can a ROS node have a publisher and a subscriber at the same time?</li>
</ol>
<p style="padding-left: 60px">A) Yes, if the topic subscriber is the same as the topic publisher.<br/>
B) No, because it would imply a programming conflict: a node with a publisher loops at a constant rate, that is, <kbd>rate.sleep()</kbd>, while a node with a subscriber only runs an iteration if it receives a message, that is, <kbd>rospy.spin()</kbd>.<br/>
C) Yes, and the node is driven by the subscriber, that is, the node broadcasts a new message each time it receives a message from the topic it is subscribed to.</p>
<ol start="4">
<li>How many <kbd>roslaunch</kbd> commands can you run in the same ROS session?</li>
</ol>
<p style="padding-left: 60px">A) As many as you need; <kbd>roslaunch</kbd> is a description file that tells ROS what nodes to launch when the command is called.<br/>
B) Just one, because <kbd>roslaunch</kbd> implicitly runs a <kbd>roscore</kbd> process, and you can only have one ROS master node in the session.<br/>
C) If you need two sets of nodes, it is recommended that you launch each of them manually when you need to add each to the execution environment. Then, start a <kbd>roscore</kbd> process and later execute a <kbd>rosrun</kbd> for every new node you need.</p>
<ol start="5">
<li>Is there a programmatic way to visualize an image that is published in a ROS topic?</li>
</ol>
<p style="padding-left: 60px">A) Yes, using <kbd>rqt_plot</kbd><br/>
B) Yes, using <kbd>rqt_image_view</kbd><br/>
C) Yes, using <kbd>rqt_image_view</kbd>, but it is necessary that the image is in a compressed format</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p>To go deeper into the concepts we have explained in this chapter, you can follow the following references and tutorials:</p>
<ul>
<li>ROS technical overview: <a href="http://wiki.ros.org/ROS/Technical%20Overview">http://wiki.ros.org/ROS/Technical%20Overview</a></li>
<li>ROS cheatsheet: <a href="https://kapeli.com/cheat_sheets/ROS.docset/Contents/Resources/Documents/index">https://kapeli.com/cheat_sheets/ROS.docset/Contents/Resources/Documents/index</a></li>
<li>ROS command line – the <kbd>rosbash</kbd> commands: <a href="http://wiki.ros.org/rosbash">http://wiki.ros.org/rosbash</a></li>
<li>Master node – the <kbd>roscore</kbd> command and process: <a href="http://wiki.ros.org/roscore">http://wiki.ros.org/roscore</a></li>
<li>ROS topics – the <kbd>rostopic</kbd> command description: <a href="http://wiki.ros.org/rostopic">http://wiki.ros.org/rostopic</a></li>
<li>ROS nodes – the  <kbd>rosnode</kbd> command description: <a href="http://wiki.ros.org/rosnode">http://wiki.ros.org/rosnode</a></li>
<li>Messages – the <kbd>rosmsg</kbd> command description: <a href="http://wiki.ros.org/rosmsg">http://wiki.ros.org/rosmsg</a></li>
<li>ROS parameters – the <kbd>rosparam</kbd> command description: <a href="http://wiki.ros.org/rosparam">http://wiki.ros.org/rosparam</a></li>
<li>Record sessions – the <kbd>rosbag</kbd> command description: <a href="http://wiki.ros.org/rosbag">http://wiki.ros.org/rosbag</a></li>
<li>Recording and playing back data with <kbd>rosbag</kbd>: <a href="http://wiki.ros.org/rosbag/Tutorials/Recording%20and%20playing%20back%20data">http://wiki.ros.org/rosbag/Tutorials/Recording%20and%20playing%20back%20data</a></li>
<li>Catkin command-line tools: <a href="https://catkin-tools.readthedocs.io">https://catkin-tools.readthedocs.io</a></li>
<li>The Pi Camera official documentation: <a href="https://picamera.readthedocs.io">https://picamera.readthedocs.io</a></li>
<li>ROS <kbd>rqt</kbd> GUI tools: <a href="http://wiki.ros.org/rqt">http://wiki.ros.org/rqt</a></li>
<li>The <kbd>rqt_graph</kbd> plugin: <a href="http://wiki.ros.org/rqt_graph">http://wiki.ros.org/rqt_graph</a></li>
<li>The <kbd>rqt_image_view</kbd> plugin: <a href="http://wiki.ros.org/rqt_image_view">http://wiki.ros.org/rqt_image_view</a></li>
<li>The <kbd>rqt_plot</kbd> plugin: <a href="http://wiki.ros.org/rqt_plot">http://wiki.ros.org/rqt_plot</a></li>
<li>The <kbd>rqt_bag</kbd> plugin: <a href="http://wiki.ros.org/rqt_bag">http://wiki.ros.org/rqt_bag</a></li>
<li>Using <kbd>rqt</kbd> tools for analysis – <kbd>rqt_console</kbd>, <kbd>rqt_graph</kbd>, and <kbd>urdf_to_graphviz</kbd>: <a href="https://industrial-training-master.readthedocs.io/en/melodic/_source/session6/Using-rqt-tools-for-analysis.html">http</a><a href="https://industrial-training-master.readthedocs.io/en/melodic/_source/session6/Using-rqt-tools-for-analysis.html">s://industrial-training-master.readthedocs.io/en/melodic/_source/session6/Using-rqt-tools-for-analysis.html</a></li>
</ul>


            

            
        
    </body></html>