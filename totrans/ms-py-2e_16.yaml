- en: '16'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '16'
- en: Artificial Intelligence
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能
- en: In the last chapter, we saw a collection of scientific Python libraries that
    allow for really fast and easy processing of large data files. In this chapter,
    we will use some of these and a few others for machine learning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看到了一组科学Python库，它们允许快速轻松地处理大型数据文件。在这一章中，我们将使用其中的一些库和几个其他库来进行机器学习。
- en: Machine learning is a complex subject, and many completely distinct subjects
    within it are entire branches of research by themselves. This should not discourage
    you from diving in, however; many of the libraries mentioned in this chapter are
    really powerful and allow you to get started with a very reasonable amount of
    effort.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个复杂的主题，它内部许多完全不同的主题本身就是研究分支。然而，这不应该让你却步；本章中提到的许多库都非常强大，并且允许你以非常合理的努力开始。
- en: It should be noted that there is a huge difference between applying a pre-trained
    model and generating your own. Applying a model is usually possible in a few lines
    of code and barely requires any processing power; building your own model usually
    takes many lines of code and hours or more to process. This makes the training
    of models outside of the scope of this book in all but the most trivial cases.
    In these cases, you will get an overview of what the library can do with some
    explanation of where this would be useful, without explicit examples.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，应用预训练模型和生成自己的模型之间有很大的区别。应用模型通常只需要几行代码，几乎不需要任何处理能力；而构建自己的模型通常需要许多行代码，并且需要数小时或更长时间来处理。这使得在除最简单情况之外的所有情况下，模型的训练都不在本书的范围内。在这些情况下，你将获得库可以做什么的概述，以及一些解释说明在哪里会有用，而不需要具体的示例。
- en: Artificial intelligence is the branch of computer science relating to the study
    of all types of machine learning, which includes neural networks and deep learning,
    Bayesian networks, evolutionary algorithms, computer vision, **natural language
    processing** (**NLP**), and **support-vector machines** (**SVM**s), among others.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能是计算机科学的一个分支，涉及所有类型机器学习的理论研究，包括神经网络和深度学习、贝叶斯网络、进化算法、计算机视觉、**自然语言处理（NLP**）和**支持向量机（SVM**）等。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将涵盖以下主题：
- en: Introduction to artificial intelligence
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能简介
- en: Libraries for image processing
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像处理库
- en: Libraries for NLP
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言处理库
- en: Libraries for neural networks and deep learning
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络和深度学习库
- en: Generic AI libraries and utilities
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用AI库和工具
- en: Introduction to artificial intelligence
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能简介
- en: Before we continue with this chapter, we need to establish a few definitions.
    Because **artificial intelligence** (**AI**) is such a broad subject, the lines
    tend to blur a bit, so we need to make sure that we are all talking about the
    same thing.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续本章内容之前，我们需要确立一些定义。因为**人工智能（AI**）是一个如此宽泛的主题，所以界限往往有些模糊，因此我们需要确保我们都在谈论同一件事。
- en: First of all, we define AI as *any algorithm with a human-like ability to solve
    problems*. While I admit that this statement is very broad, any narrower definition
    would exclude valid AI strategies. What is and is not AI is more a philosophical
    question than a technical one. While (almost) anyone would consider a neural network
    to be AI, once you get to algorithms such as (Bayesian) decision trees, not everyone
    agrees anymore.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将AI定义为**任何具有类似人类解决问题能力的算法**。虽然我承认这个定义非常宽泛，但任何更窄的定义都会排除有效的AI策略。AI是什么，什么不是AI，这更多是一个哲学问题，而不是技术问题。虽然（几乎）每个人都认为神经网络是AI，但一旦涉及到像（贝叶斯）决策树这样的算法，就不再人人同意了。
- en: With that broad definition in mind, here is a list of technologies and terms
    we are going to cover, with a short explanation of what they are and what they
    can do.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在心中牢记这个宽泛的定义，以下是我们将要介绍的技术和术语列表，以及它们是什么以及它们能做什么的简要说明。
- en: Types of AI
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能类型
- en: Within the broad scope of AI, we have two major branches, **machine learning**
    (**ML**) and the rest. Machine learning covers any method that can learn by itself.
    You might wonder, is it even AI if it does not involve learning? This is a bit
    of a philosophical question, but I personally think that there are several non-learning
    algorithms that can still be considered AI because they can produce human-like
    decisions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI的广泛范围内，我们有两个主要分支，**机器学习（ML**）和其他。机器学习包括任何可以自我学习的算法。你可能想知道，如果不涉及学习，这还是AI吗？这是一个有点哲学性质的问题，但我个人认为，有一些非学习算法仍然可以被认为是AI，因为它们可以产生类似人类的决策。
- en: 'Within self-learning systems, we have further distinctions with their own goals
    and applications:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在自学习系统中，我们还有进一步的区分，它们有各自的目标和应用：
- en: Supervised learning
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习
- en: Reinforcement learning
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习
- en: Unsupervised learning
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习
- en: The use of one of these does not exclude the others from being used too, so
    many practical implementations use combinations of multiple methods.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用其中一种方法并不排除使用其他方法，因此许多实际应用都使用多种方法的组合。
- en: 'Non-machine learning systems are quite a bit more diverse because they can
    mean just about anything, so here are a few examples of non-learning algorithms
    that can rival humans in some ways:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 非机器学习系统要多样化得多，因为它们几乎可以意味着任何东西，所以这里有一些非学习算法的例子，它们在某些方面可以与人类相媲美：
- en: '**NLP**: It should be noted that NLP by itself does not use ML. Many NLP algorithms
    are still written by hand, because it is far easier for a human to explain to
    a machine how and why certain grammar and semantics work than to have a computer
    figure out the oddities and complexities of human languages. That field is changing
    very rapidly, however, and this might not be the case for much longer.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言处理（NLP）**：需要注意的是，NLP本身并不使用机器学习。许多NLP算法仍然是手工编写的，因为人类向机器解释某些语法和语义如何以及为什么工作，比让计算机弄清楚人类语言的奇特性和复杂性要容易得多。然而，该领域正在迅速变化，这可能不会持续太久。'
- en: '**Expert systems**: This is the first type of AI that was actually successful
    in practice. The first expert systems were created in 1970 and they have been
    used ever since. These systems work by asking you a string of questions and narrowing
    down a list of potential solutions/answers based on those. You have certainly
    encountered many of these when going through problem-solving wizards at some point,
    perhaps in the FAQ on websites or when calling a helpdesk. These systems allow
    the capturing of expert information and compress it down into a simple system
    that can make decisions. Many of these have been used (and are still used today)
    in diagnosing medical issues.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专家系统**：这是在实践上真正成功的第一种AI。最早的专家系统是在1970年创建的，并且自那时以来一直在使用。这些系统通过向您提出一系列问题，并根据这些问题缩小潜在解决方案/答案的列表来工作。您肯定在某个时候遇到过这些问题，比如在网站上的常见问题解答（FAQ）或拨打帮助台时。这些系统允许捕获专家信息并将其压缩成一个简单的系统，该系统可以做出决策。许多这样的系统（并且至今仍在使用）被用于诊断医疗问题。'
- en: Before we continue with actual AI implementations, it is a good idea to look
    at a few image processing libraries that are used as a basis in many of the AI
    examples.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续实际的AI实现之前，查看一些作为许多AI示例基础的图像处理库是个好主意。
- en: Installing the packages
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装包
- en: As was the case with installing the scientific Python libraries in *Chapter
    15*, installing the packages in this chapter directly using `pip` can be troublesome
    in some cases. Using one of the Jupyter Docker Stacks or `conda` can be more convenient.
    Additionally, most of these projects have very well-documented installation instructions
    for many scenarios.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在第15章中安装科学Python库时的情况一样，在本章中直接使用`pip`安装包在某些情况下可能会有麻烦。使用Jupyter Docker Stacks或`conda`可能更方便。此外，这些项目中的大多数都有针对许多场景的非常详细的安装说明。
- en: 'For the neural networks portion of this chapter, it would be best to get a
    notebook stack that has most libraries available. I would recommend giving the
    `jupyter/tensorflow-notebook` stack a test: [https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-tensorflow-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-tensorflow-notebook).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章的神经网络部分，最好获取一个包含大多数库的笔记本堆栈。我建议您尝试使用`jupyter/tensorflow-notebook`堆栈：[https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-tensorflow-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-tensorflow-notebook)。
- en: Image processing
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像处理
- en: Image processing is an essential part of many types of machine learning, such
    as **computer vision** (**CV**), so it is essential that we show you a few of
    the options and their possibilities here. These range from image-only libraries
    to libraries that have full machine learning capabilities while also supporting
    image inputs.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图像处理是许多类型机器学习（如**计算机视觉（CV）**）的基本组成部分，因此我们在这里向您展示一些选项及其可能性是至关重要的。这些选项从仅图像的库到具有完整机器学习功能同时支持图像输入的库。
- en: scikit-image
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scikit-image
- en: The scikit-image (`skimage`) library is part of the scikit project with the
    main project being scikit-learn (`sklearn`), covered later in this chapter. It
    offers a range of functions for reading, processing, transforming, and generating
    images. The library builds on `scipy.ndimage`, which provides several image processing
    options as well.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: The scikit-image (`skimage`) library is part of the scikit project with the
    main project being scikit-learn (`sklearn`), covered later in this chapter. It
    offers a range of functions for reading, processing, transforming, and generating
    images. The library builds on `scipy.ndimage`, which provides several image processing
    options as well.
- en: 'We need to talk about what an image is in terms of these Python libraries first.
    In the case of `scipy` (and consequently, `skimage`), an **image** is a `numpy.ndarray`
    object with 2 or more dimensions. The conventions are:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要讨论在这些Python库中什么是图像。在`scipy`（以及随之而来的`skimage`）的情况下，**图像**是一个具有2个或更多维度的`numpy.ndarray`对象。约定如下：
- en: '2D grayscale: Row, column'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2D灰度：行，列
- en: '2D color (for example, RGB): Row, column, color channel'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2D颜色（例如，RGB）：行，列，颜色通道
- en: '3D grayscale: Plane, row, column'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3D灰度：平面，行，列
- en: '3D color: Plane, row, column, color channel'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3D颜色：平面，行，列，颜色通道
- en: All of these are just conventions, however; you can shape your arrays in other
    ways as well. A multichannel image could also mean **CMYK** (**cyan, magenta,
    yellow, and key/black**) colors instead of **RGB** (**red, green, and blue**),
    or something completely different.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，所有这些都是约定；你还可以以其他方式塑造你的数组。多通道图像也可以意味着**CMYK**（青色，品红色，黄色和关键/黑色）颜色而不是**RGB**（红色，绿色和蓝色），或者完全不同的东西。
- en: Naturally you could have more dimensions as well, such as a dimension for time
    (in other words, video). Since the arrays are regular `numpy` arrays, you can
    manipulate them by slicing as usual.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，你也可以有更多的维度，例如时间维度（换句话说，视频）。由于数组是常规的`numpy`数组，你可以通过通常的切片方式来操作它们。
- en: Often you will not use the scikit-image library for machine learning directly,
    but rather for *pre-processing* image data before you feed it to your machine
    learning algorithms. In many types of detections, for example, color is not that
    relevant, which means you can make your machine learning system three times as
    fast by going from RGB to grayscale. Additionally, there are often fast algorithms
    available to pre-process the data so your machine learning system only needs to
    look at the relevant sections of the image.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通常你不会直接使用scikit-image库进行机器学习，而是在你将图像数据输入机器学习算法之前进行**预处理**。在许多类型的检测中，例如，颜色并不那么相关，这意味着你可以通过从RGB转换为灰度使你的机器学习系统速度提高三倍。此外，通常有快速算法可用于预处理数据，这样你的机器学习系统只需查看图像的相关部分。
- en: Installing scikit-image
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装scikit-image
- en: 'The package is easily installable through `pip` for many platforms; I would
    suggest installing not just the base package but the `optional` extras as well,
    which add extra capabilities to scikit-image, such as parallel processing:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 'The package is easily installable through `pip` for many platforms; I would
    suggest installing not just the base package but the `optional` extras as well,
    which add extra capabilities to scikit-image, such as parallel processing:'
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Edge detection
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 边缘检测
- en: 'Let’s look at how we can display one of the built-in images and do some basic
    processing on it:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何显示内置图像之一，并在其上进行一些基本处理：
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this case, we are using the `coins` dataset that is bundled with `skimage`.
    It contains a few coins and we can use it to display some of the nice features
    of `skimage`. First, let’s look at the results:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们使用`skimage`附带的数据集`coins`。它包含一些硬币，我们可以用它来展示`skimage`的一些优秀功能。首先，让我们看看结果：
- en: '![/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/6A6F4AA2.tmp](img/B15882_16_01.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15882_16_01.png)'
- en: 'Figure 16.1: scikit-image coins'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.1：scikit-image硬币
- en: 'As an example of what kind of processing we can do, let’s do some edge detection
    using the Canny edge detection algorithm. This is a prime example of a non-ML
    algorithm that can be really useful for pre-processing your data before you feed
    it to your ML system. To display the results a bit better, first we will slice
    the image so only the top-right three coins are visible. In *Figure 16.1*, the
    numbers indicate the actual pixel indices for the *x* and *y* axes, which can
    be used to estimate where to slice. After that, we will apply the `canny()` function
    to detect the edges:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 作为我们可以进行何种处理的例子，让我们使用Canny边缘检测算法来进行一些边缘检测。这是一个非机器学习算法的典型例子，在将数据输入到机器学习系统之前，它对于预处理你的数据非常有用。为了更好地显示结果，我们首先将图像切割，只显示右上角的三个硬币。在*图16.1*中，数字表示*x*和*y*轴的实际像素索引，这些可以用来估计切割的位置。之后，我们将应用`canny()`函数来检测边缘：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The results are shown in the following image, where you can see the auto-detected
    edges of coins we have selected:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在下面的图像中，你可以看到我们选择的硬币的自动检测到的边缘：
- en: '![/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/748E410E.tmp](img/B15882_16_02.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片链接](img/B15882_16_02.png)'
- en: 'Figure 16.2: Coins after edge detection'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.2：边缘检测后的硬币
- en: scikit-image can do much more, but this is a nice and basic example of how you
    can do edge detection in a single line of code, which can make your data much
    more useful for ML systems.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-image可以做更多的事情，但这是一个很好的基本示例，展示了你如何用一行代码进行边缘检测，这可以使你的数据对机器学习系统更有用。
- en: Face detection
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人脸检测
- en: 'We will now use one of the examples from the fantastic scikit-image documentation:
    [https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html](https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用来自出色的scikit-image文档中的一个示例：[https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html](https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html)。
- en: This is a machine learning example that uses a pre-trained model to automatically
    detect faces. The specific model uses a multi-block **local binary pattern** (**LBP**).
    An LBP looks at points surrounding a center point and indicates whether these
    points are greater (lighter) or smaller (darker) than the center point. The multi-block
    part is an optional extension to this method and performs the LBP algorithm across
    multiple block sizes of 9 identically sized rectangles. The first iteration might
    look at a 3x3 pixel square; the second iteration could look at 6x6; the third
    9x9; and so on.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个使用预训练模型自动检测人脸的机器学习示例。该特定模型使用多块**局部二值模式**（**LBP**）。LBP查看中心点周围的点，并指示这些点是否大于（较亮）或小于（较暗）中心点。多块部分是此方法的可选扩展，并在多个块大小为9个相同大小的矩形的块上执行LBP算法。第一次迭代可能查看3x3像素的正方形；第二次迭代可能查看6x6；第三次9x9；依此类推。
- en: The model was trained using the OpenCV cascade classifier training, which can
    train your model, generate samples, and run the detection. A cascade classifier
    concatenates the results of multiple classifiers to reach a combined model that
    is expected to perform better than the separate classifiers by themselves.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型使用OpenCV级联分类器训练，它可以训练你的模型，生成样本，并运行检测。级联分类器将多个分类器的结果连接起来，形成一个预期比单独的分类器表现更好的组合模型。
- en: 'To test the face detection, we will apply it to a photo of the NASA astronaut
    Eileen Collins. First, we will import the libraries, load the image, and tell
    `matplotlib` to draw it:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试人脸检测，我们将将其应用于NASA宇航员Eileen Collins的照片。首先，我们将导入库，加载图像，并告诉`matplotlib`绘制它：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Looking at the code above, you might notice a few magic numbers such as the
    `scale_factor`, `step_ratio`, `min_object_size`, and `max_object_size`. These
    parameters are ones that you will have to tune to your input image. These specific
    numbers are straight from the OpenCV documentation, but depending on your input
    you will need to experiment with these values until they suit your scenario.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 观察上面的代码，你可能会注意到一些魔法数字，如`scale_factor`、`step_ratio`、`min_object_size`和`max_object_size`。这些参数是你必须根据输入图像进行调整的。这些特定的数字直接来自OpenCV文档，但根据你的输入，你可能需要对这些值进行实验，直到它们适合你的场景。
- en: Since these parameters are somewhat arbitrary and dependent on your input, it
    can be a good idea to apply a bit of automation to find them. An evolutionary
    algorithm could be useful in helping you find effective parameters.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些参数有些任意且依赖于您的输入，因此应用一些自动化来寻找它们是一个好主意。进化算法可以帮助您找到有效的参数。
- en: 'Now we are ready to start the detection and illustrate what we found:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好开始检测并展示我们的发现：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After loading the cascade, we run the model using the `detect_multi_scale`
    method. This method searches for matching objects (faces) with sizes varying from
    `min_size` to `max_size`, which is needed because we don’t know how large the
    subject (face) is. Once we have the matches, we draw a rectangle around them to
    indicate where they are:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载级联后，我们使用`detect_multi_scale`方法运行模型。该方法在`min_size`到`max_size`之间搜索匹配的对象（人脸），这是必需的，因为我们不知道主题（人脸）的大小。一旦我们找到匹配项，我们就在它们周围画一个矩形来指示它们的位置：
- en: '![](img/B15882_16_03.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15882_16_03.png)'
- en: 'Figure 16.3: Face detected by scikit-image'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.3：由scikit-image检测到的人脸
- en: By itself, scikit-image does not have many machine learning features available,
    but the coupling with other libraries is what makes this library very useful for
    machine learning. In addition to the frontal face dataset we loaded above, you
    can also use pre-trained cascades from OpenCV.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 单独来看，scikit-image没有很多机器学习功能可用，但与其他库的结合使得这个库在机器学习中非常有用。除了我们上面加载的前脸数据集外，您还可以使用来自OpenCV的预训练级联。
- en: 'Several pre-trained models are available in the OpenCV Git repository: [https://github.com/opencv/opencv/tree/master/data/lbpcascades](https://github.com/opencv/opencv/tree/master/data/lbpcascades).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV Git仓库中提供了几个预训练模型：[https://github.com/opencv/opencv/tree/master/data/lbpcascades](https://github.com/opencv/opencv/tree/master/data/lbpcascades)。
- en: scikit-image overview
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: scikit-image概述
- en: 'The scikit-image library can do much more than we have covered. Here’s a quick
    overview of a few of the available submodules:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-image库的功能远不止我们所涵盖的。以下是几个可用子模块的简要概述：
- en: '`exposure`: Functions for analyzing and fixing photo exposure levels, which
    can be essential for cleaning data before you feed it to your AI system.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`曝光`：用于分析和修复照片曝光水平的函数，这在将数据输入到您的AI系统之前清理数据时可能至关重要。'
- en: '`feature`: Feature detection such as the `canny()` edge detection function
    we used earlier. This allows for detecting objects, blobs of content, and more
    to pre-filter your input so you can reduce the processing time needed by your
    AI system.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`特征`：如我们之前使用的`canny()`边缘检测函数之类的特征检测。这允许检测对象、内容块等，以便在AI系统之前对输入进行预过滤，从而减少AI系统所需的处理时间。'
- en: '`filters`: Image filtering functions, such as thresholding to automatically
    filter noise, and many others. Similar to the `exposure` functions, these can
    be very useful for cleanup.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`滤波器`：图像滤波函数，例如阈值滤波以自动过滤噪声，以及其他许多功能。与`曝光`函数类似，这些功能在清理过程中非常有用。'
- en: '`morphology`: Many functions to sharpen edges, fill sections, find minima/maxima,
    and so on.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`形态学`：许多功能用于锐化边缘、填充区域、寻找最小/最大值等。'
- en: '`registration`: Functions for calculating the optical flow in an image. With
    these functions, you can estimate what part of the image is moving, and how fast
    objects are moving. Given two images, this can help to calculate the intermediate
    image.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`注册`：用于计算图像中光流的函数。使用这些函数，您可以估计图像的哪个部分在移动，以及物体移动的速度有多快。给定两个图像，这有助于计算中间图像。'
- en: '`segmentation`: Functions for segmenting images. In the case of the coins above,
    the separate coins can be extracted and/or labeled.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`分割`：用于分割图像的函数。在上述硬币的例子中，可以提取和/或标记单独的硬币。'
- en: As you can see, the scikit-image library offers an extensive list of image manipulation
    and processing functions. Additionally, it is well integrated into the scientific
    Python ecosystem.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，scikit-image库提供了丰富的图像操作和处理函数。此外，它还很好地集成到科学Python生态系统中。
- en: OpenCV
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenCV
- en: The big “competitor” to scikit-image is **OpenCV** (**Open Source Computer Vision
    library**). The OpenCV library is written in C/C++ but has bindings for several
    languages such as Python and Java. The reason I put “competitor” between quotes
    is that these libraries don’t have to compete; you can easily combine the strengths
    of both if you wish to do so, and it is something I have done myself in several
    projects.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-image的“主要竞争对手”是**OpenCV**（**开源计算机视觉库**）。OpenCV库是用C/C++编写的，但为Python和Java等几种语言提供了绑定。我把“竞争对手”放在引号中是因为这些库不必竞争；如果您愿意，可以轻松地结合两者的优势，我自己在几个项目中就是这样做的。
- en: We will first look at installing the Python OpenCV package.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先查看如何安装 Python OpenCV 包。
- en: Installing OpenCV for Python
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 Python OpenCV
- en: The `opencv-python` package comes in several variants depending on your needs.
    Besides the main OpenCV package, OpenCV also has many “contrib” and “extra” packages,
    which can be very useful. The contrib packages are mainly for following tutorials
    and trying examples, and the extra modules contain many useful additional algorithms.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`opencv-python` 包根据您的需求有多种变体。除了主要的 OpenCV 包之外，OpenCV 还有许多“贡献”和“额外”包，这些包非常有用。贡献包主要用于跟随教程和尝试示例，而额外模块包含许多有用的附加算法。'
- en: 'The list of extra modules can be found in the documentation: [https://docs.opencv.org/5.x/](https://docs.opencv.org/5.x/).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 额外模块的列表可以在文档中找到：[https://docs.opencv.org/5.x/](https://docs.opencv.org/5.x/)。
- en: I strongly recommend installing the extra modules as well, since many very useful
    modules are part of the extra package.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈建议安装额外模块，因为许多非常有用的模块都是额外包的一部分。
- en: 'You have the following options if you are installing the package on a desktop
    machine where you will be using a GUI:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在将包安装在将使用 GUI 的桌面机器上，您有以下选项：
- en: '`opencv-python`: The main modules, the bare minimum'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opencv-python`：主要模块，最基本的形式'
- en: '`opencv-contrib-python`: The full package including the main modules from the
    `opencv-python` package, but also the contrib and extra modules'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opencv-contrib-python`：包括 `opencv-python` 包中的主要模块，但也包括贡献和额外模块'
- en: 'For servers that are not running a GUI, you have these options:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不运行 GUI 的服务器，您有以下选项：
- en: '`opencv-python-headless`: Beyond not including any GUI output functions such
    as `cv2.imshow()`, this is identical to `opencv-python`'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opencv-python-headless`：除了不包含任何 GUI 输出函数，如 `cv2.imshow()`，这与 `opencv-python`
    相同'
- en: '`opencv-contrib-python-headless`: As above, this is the headless version of
    `opencv-contrib-python`'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opencv-contrib-python-headless`：如上所述，这是 `opencv-contrib-python` 的无头版本'
- en: Now that we have OpenCV installed, let’s see if we can replicate the Canny edge
    detection from scikit-image using OpenCV.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经安装了 OpenCV，让我们看看是否可以使用 OpenCV 复制 scikit-image 中的 Canny 边缘检测。
- en: Edge detection
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 边缘检测
- en: 'Let’s look at how we can perform the Canny algorithm using OpenCV, similar
    to what we did in the scikit-image example earlier. The Canny algorithm is not
    part of the OpenCV core, so you need to install the `opencv-contrib-python` package
    for this:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 OpenCV 执行 Canny 算法，类似于我们在之前的 scikit-image 示例中所做的。Canny 算法不是 OpenCV
    核心的一部分，因此您需要安装 `opencv-contrib-python` 包：
- en: '[PRE5]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will use the same coins image as before:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用之前相同的硬币图像：
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: At a first glance the code looks quite similar, but there are a few differences.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 初看代码看起来相当相似，但有一些差异。
- en: 'First, the `cv2.Canny()` function requires two extra parameters: `threshold_1`
    and `threshold_2`, or the lower and upper bounds. These parameters decide what
    should be considered noise and what parts are relevant for the edges. By increasing
    or decreasing these values, you can get finer details in the resulting edges,
    but doing so means the algorithm can also start wrongly detecting the background
    gradient as edges, which is already happening at the top right of the output image
    (*Figure 16.4*).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`cv2.Canny()` 函数需要两个额外的参数：`threshold_1` 和 `threshold_2`，即下限和上限。这些参数决定了什么应该被视为噪声，哪些部分与边缘相关。通过增加或减少这些值，您可以在结果边缘中获得更细的细节，但这样做意味着算法也可能开始错误地将背景渐变检测为边缘，这在输出图像的右上角（*图
    16.4*）已经发生。
- en: 'While you can pass these along to scikit-image if you wish, by default scikit-image
    automatically guesses some suitable parameters for you. With OpenCV you could
    easily do the same, but this is not included by default. The algorithm that scikit-image
    uses for this estimation can be seen in the source: [https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_canny.py](https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_canny.py)
    Second, OpenCV has no native support for Jupyter, so we are using `matplotlib`
    to render the output. Alternatively, we could also use the `IPython.display` module
    to display the image.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以选择将这些传递给 scikit-image，但默认情况下，scikit-image 会自动猜测一些合适的参数。使用 OpenCV，您可以轻松地做到这一点，但这不是默认包含的。scikit-image
    用于此估计的算法可以在源代码中看到：[https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_canny.py](https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_canny.py)。其次，OpenCV
    对 Jupyter 没有原生支持，所以我们使用 `matplotlib` 来渲染输出。或者，我们也可以使用 `IPython.display` 模块来显示图像。
- en: 'The generated output is similar, however:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的输出类似，然而：
- en: '![/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/9AF685DE.tmp](img/B15882_16_04.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图片路径](img/B15882_16_04.png)'
- en: 'Figure 16.4: OpenCV Canny'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.4：OpenCV Canny
- en: For more similar output, you could even use scikit-image to render the output
    from OpenCV. Since they both operate on `numpy` arrays, you can easily mix and
    match the functions if needed.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更相似的结果，你甚至可以使用scikit-image来渲染OpenCV的输出。由于它们都操作在`numpy`数组上，如果需要，你可以轻松地混合和匹配函数。
- en: Object detection
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标检测
- en: 'In the scikit-image face detection example, we were actually using an OpenCV-generated
    model, so we could easily use that model with `opencv-python` directly, with a
    few small changes:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在scikit-image人脸检测示例中，我们实际上使用了一个由OpenCV生成的模型，因此我们可以直接使用该模型与`opencv-python`，只需做一些小的修改：
- en: Instead of `skimage.feature.Cascade(filename)`, you need to use `cv2.CascadeClassifier(filename)`
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代替`skimage.feature.Cascade(filename)`，你需要使用`cv2.CascadeClassifier(filename)`
- en: Instead of `cascade.detect_multi_scale()` the function is called `cascade.detectMultiScale()`
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代替`cascade.detect_multi_scale()`函数，应调用`cascade.detectMultiScale()`
- en: This immediately illustrates one of the differences between scikit-image and
    `python-opencv`. Where scikit-image uses the Python convention of underscores
    between words in a function name, `opencv-python` uses the camelCase function
    names directly from the OpenCV source.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这立即展示了scikit-image和`python-opencv`之间的一个区别。其中scikit-image使用Python在函数名单词之间使用下划线的约定，而`opencv-python`直接使用从OpenCV源中来的camelCase函数名。
- en: With OpenCV we can easily go beyond the simple cascades we used for face detection;
    this time we will use a **DNN** (**deep neural network**) instead.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OpenCV，我们可以轻松地超越我们用于人脸检测的简单级联；这次我们将使用一个**DNN**（**深度神经网络**）。
- en: The network we will be using is called **YOLOv3** (**You Only Look Once, version
    3**) and is able to detect many types of objects such as cars, animals, fruit,
    and many more. Naturally this model is far larger as well. The face detection
    model was only about 50 KiB, while the YOLOv3 network is nearly 5000 times larger,
    at 237 MiB.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的网络被称为**YOLOv3**（**你只看一次，版本3**）并且能够检测许多类型的对象，如汽车、动物、水果等。自然地，这个模型也更大。人脸检测模型只有大约50
    KiB，而YOLOv3网络几乎大5000倍，达到237 MiB。
- en: 'Before we can start, we need to download a few files for the YOLO network to
    be fully functional:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们需要下载一些文件以使YOLO网络完全可用：
- en: 'The model (237 MiB): [https://pjreddie.com/media/files/yolov3.weights](https://pjreddie.com/media/files/yolov3.weights)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型（237 MiB）：[https://pjreddie.com/media/files/yolov3.weights](https://pjreddie.com/media/files/yolov3.weights)
- en: 'The YOLO configuration file: [https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg](https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YOLO配置文件：[https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg](https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg)
- en: 'The names for the objects: [https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names](https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物体的名称：[https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names](https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names)
- en: 'Once you have those files, we can demonstrate the YOLO network. First, we set
    up a few imports and variables, and then load the image:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了这些文件，我们可以展示YOLO网络。首先，我们设置了一些导入和变量，然后加载图像：
- en: '[PRE7]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now that we have the imports ready and the image converted to a blob that’s
    suitable for the model, we can load the model and show the results:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了导入，并将图像转换成了适合模型的blob格式，我们可以加载模型并展示结果：
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'For brevity this example is very condensed, but it shows you how you can do
    something as advanced as object detection in just a few lines. If we look at the
    output, the deep neural network has correctly identified the astronaut as being
    a person:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁，这个例子非常精简，但它展示了你如何在几行代码中完成像目标检测这样高级的操作。如果我们看输出，深度神经网络正确地将宇航员识别为一个人：
- en: '![/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/1F838D9C.tmp](img/B15882_16_05.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图片路径](img/B15882_16_05.png)'
- en: 'Figure 16.5: Object detection on astronaut'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.5：宇航员上的目标检测
- en: 'I highly encourage you to try the YOLOv3 network yourself with different images.
    For an old image of a street, I got the following results:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈建议你尝试使用不同的图像自己尝试YOLOv3网络。对于一张老街道的图片，我得到了以下结果：
- en: '![](img/B15882_16_06.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图片路径](img/B15882_16_06.png)'
- en: 'Figure 16.6: Applying YOLOv3 on an image of a street with cars'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.6：在带有汽车的街道图像上应用YOLOv3
- en: Isn’t it amazing how easy it is to do object detection these days and how well
    it works? If you take a good look at the image, you might notice that it’s even
    detecting cars and people that are partially obstructed. Training a new deep neural
    network and doing the research for it is a completely different question, of course,
    but at least applying these networks has become child’s play and they execute
    well within a second, including the loading of the network.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 难道不令人惊叹，如今进行目标检测是多么容易，而且效果多么好？如果您仔细观察图像，可能会注意到它甚至能够检测到部分遮挡的汽车和人。当然，训练一个新的深度神经网络及其研究是另一个完全不同的问题，但至少应用这些网络已经变得像玩一样简单，它们在不到一秒内就能执行完毕，包括网络的加载。
- en: The possibilities certainly don’t end here, and you could even use techniques
    like these to do real-time analysis of a video stream if you wanted. The OpenCV
    library really is an impressive bit of software.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 机会当然不止于此，如果您愿意，甚至可以使用这些技术来对视频流进行实时分析。OpenCV库确实是一款令人印象深刻的软件。
- en: OpenCV versus scikit-image
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenCV 与 scikit-image
- en: Both scikit-image and OpenCV have their own advantages over the other. This
    is one of the cases where you don’t really have to choose, however; you can easily
    use both simultaneously.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-image和OpenCV各自都有相对于对方的优点。然而，这并不是您必须做出选择的情况；您可以轻松同时使用两者。
- en: 'In my opinion, OpenCV has three major advantages over scikit-image:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，OpenCV相对于scikit-image有三个主要优势：
- en: OpenCV has native support for processing using your GPU
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV原生支持使用GPU进行处理。
- en: Since it is implemented in C++, you can do parallel processing in threads without
    having to worry about the GIL
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于它是用C++实现的，因此您可以在线程中执行并行处理，而无需担心全局解释器锁（GIL）。
- en: OpenCV has even more features than scikit-image
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV的功能甚至比scikit-image更多。
- en: 'Naturally, scikit-image has a few advantages as well:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，scikit-image也有一些优势：
- en: scikit-image is written in Python so it is very easy to view (or modify) the
    algorithms right from your editor.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-image是用Python编写的，因此可以直接从您的编辑器中查看（或修改）算法，非常方便。
- en: scikit-image is focused toward Python, so the naming conventions feel more natural.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-image专注于Python，因此命名约定感觉更自然。
- en: As scikit-image is only for Python, all documentation is immediately relevant.
    With OpenCV, many of the examples you will find on the web (and in the documentation)
    are about the C++ interface, which is slightly different.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于scikit-image仅适用于Python，因此所有文档都立即相关。对于OpenCV，您在网上（以及文档中）找到的许多示例都是关于C++接口的，这略有不同。
- en: If you need high performance for the live processing of video streams, then
    OpenCV would be my top recommendation because it has several methods built in
    to make that task a bit easier. If you simply need to read and modify some images
    and you can get away with scikit-image, then that would be my top recommendation.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要为视频流的实时处理提供高性能，那么OpenCV将是我的首选推荐，因为它有几个内置方法可以使这项任务变得更容易。如果您只需要读取和修改一些图像，并且可以使用scikit-image，那么这将是我的首选推荐。
- en: In either case, both libraries are great and I can confidently recommend both.
    If your needs span across both, use both.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，这两个库都非常出色，我可以自信地推荐两者。如果您的需求跨越两者，请使用两者。
- en: Now it is finally time to start discussing the artificial intelligence libraries
    themselves.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在终于到了讨论人工智能库本身的时刻。
- en: Natural language processing
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言处理
- en: '**NLP** is the process of parsing text and understanding its meaning. This
    can be used to extract knowledge from pieces of text, understand the differences
    between texts, and more.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**NLP**是解析文本并理解其意义的过程。这可以用来从文本片段中提取知识，理解文本之间的差异，等等。'
- en: There are several well-developed libraries available for this purpose that work
    quite well. Additionally, there are also hosted pre-trained networks available
    such as the **GPT-3** network, which can be accessed through the OpenAI API.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个专为这个目的而开发的库，它们工作得相当不错。此外，还有托管预训练网络可供使用，例如**GPT-3**网络，可以通过OpenAI API访问。
- en: This network can generate text of such high quality that it is often indistinguishable
    from human-generated text.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个网络可以生成如此高质量的文本，以至于它通常与人类生成的文本难以区分。
- en: NLTK – Natural Language Toolkit
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NLTK – 自然语言工具包
- en: NLTK is not really a machine learning library by itself like most of the other
    libraries here, but it’s the basis for many natural language processing libraries.
    The NLTK project started in 2001 with the purpose of understanding natural languages,
    and definitely deserves a place in this list.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK 并非像这里的大多数其他库那样是一个独立的机器学习库，但它却是许多自然语言处理库的基础。NLTK 项目始于2001年，旨在理解自然语言，并且绝对值得在这个列表中占有一席之地。
- en: The project comes bundled with a large collection of corpora and pre-trained
    models for many different languages.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目附带了一个大量语料库和多种不同语言的预训练模型的集合。
- en: Corpora are large collections of structured texts that can be used for training
    and testing models.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 语料库是大量结构化文本的集合，可用于训练和测试模型。
- en: Using these corpora and models, it can do sentiment analysis, tokenize the text
    to find the relevant keywords, and more.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些语料库和模型，它可以进行情感分析，对文本进行分词以找到相关关键词，等等。
- en: 'First, we need to install `nltk`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要安装`nltk`：
- en: '[PRE9]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As a basic example, let’s use the pre-trained sentiment analysis capability
    to see how positive or negative a sentence is:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 作为基本示例，让我们使用预训练的情感分析能力来看看一个句子的积极或消极程度：
- en: '[PRE10]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We start by downloading the pre-trained model for sentiment analysis. After
    that, we can use the `SentimentIntensityAnalyzer` to detect if a sentence is negative,
    neutral, positive, or a combination.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先下载用于情感分析的预训练模型。之后，我们可以使用`SentimentIntensityAnalyzer`来检测一个句子是负面的、中性的、积极的，还是它们的组合。
- en: The library can do much more, but this already gives you a nice indication of
    how easy it is to get started. If you need any basic human input parsing, make
    sure to give it a try as it offers very impressive results.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 该库可以做更多的事情，但这已经为你提供了一个很好的起点。如果你需要任何基本的人类输入解析，请确保尝试一下，因为它提供了非常令人印象深刻的成果。
- en: spaCy – Natural language processing with Cython
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: spaCy – 使用 Cython 进行自然语言处理
- en: The spaCy library is a very impressive and extremely fast NLP library. It comes
    with many pre-trained neural network models for over 60 languages and does a very
    good job at text classification and named entity recognition.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy 库是一个非常令人印象深刻且速度极快的自然语言处理库。它包含60多种语言的预训练神经网络模型，并在文本分类和命名实体识别方面做得非常好。
- en: The documentation is amazing and, while being fully open-source, it is developed
    by the company Explosion, which is doing a really good job of keeping up with
    the latest developments in NLP. If you want a high-level understanding of text,
    this library is one of your best options. If you only need basic text tokenization,
    then I would still recommend `NLTK` because it is faster and more effective.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 文档非常出色，并且虽然它是完全开源的，但它是由公司 Explosion 开发的，该公司在跟上自然语言处理领域的最新发展方面做得非常好。如果你想对文本有一个高级的理解，这个库是你的最佳选择之一。如果你只需要基本的文本分词，那么我仍然会推荐`NLTK`，因为它更快更有效。
- en: 'Before we continue with the example, we need to install spaCy and download
    the models:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续示例之前，我们需要安装 spaCy 并下载模型：
- en: '[PRE11]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `en_core_web_sm` dataset is a small and fast English dataset. If you need
    a more thorough dataset, you can download `en_core_web_trf` instead.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`en_core_web_sm` 数据集是一个小型且快速的英语数据集。如果你需要一个更全面的数据集，你可以下载`en_core_web_trf`。'
- en: 'To install a different language, I recommend you visit the spaCy website: [https://spacy.io/usage#quickstart](https://spacy.io/usage#quickstart).
    For example, the Dutch dataset is called `nl_core_news_sm`, as opposed to `nl_core_web_sm`,
    which you might have been expecting.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装不同的语言，我建议你访问 spaCy 网站：[https://spacy.io/usage#quickstart](https://spacy.io/usage#quickstart)。例如，荷兰数据集被称为`nl_core_news_sm`，而不是你可能预期的`nl_core_web_sm`。
- en: 'Now that we have that taken care of, let’s try to extract some information
    from a sentence:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经处理好了这些，让我们尝试从一个句子中提取一些信息：
- en: '[PRE12]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: After loading `spacy` and the `en_core_web_sm` model, we added the `merge_entities`
    pipe. This pipe automatically merges the tokens together so we get `"Guido van
    Rossum"` instead of `"Guido"`, `"van"`, and `"Rossum"` as separate tokens.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载`spacy`和`en_core_web_sm`模型后，我们添加了`merge_entities`管道。这个管道会自动将标记合并在一起，因此我们得到的是`"Guido
    van Rossum"`而不是`"Guido"`、`"van"`和`"Rossum"`作为单独的标记。
- en: Isn’t this an amazing result? It automatically understands that `"Guido van
    Rossum"` is a person, `"Stichting Mathematisch Centrum"` is an organisation, and
    `"Amsterdam"` is a geopolitical entity.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这难道不是一个令人惊叹的结果吗？它自动理解`"Guido van Rossum"`是一个人，`"Stichting Mathematisch Centrum"`是一个组织，而`"Amsterdam"`是一个地缘政治实体。
- en: Gensim – Topic modeling for humans
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Gensim – 为人类进行主题建模
- en: The Gensim library ([https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/))
    takes care of NLP for you. It is similar to NLTK but more focused on the modern
    machine learning libraries. It is well documented and easy to use and can be used
    to calculate similarities between texts, analyze the topic of a piece of text,
    and more. While there is a large overlap between NLTK and Gensim, I would argue
    that Gensim is a bit of a higher-level library and slightly easier to get started
    with. NLTK, on the other hand, has existed for over 20 years and has a huge amount
    of documentation available in the wild because of that.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Gensim库([https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/))为你处理NLP。它与NLTK类似，但更专注于现代机器学习库。它有很好的文档，易于使用，可以用来计算文本之间的相似性，分析文本的主题，等等。虽然NLTK和Gensim之间有很大的重叠，但我认为Gensim是一个稍微高级一些的库，更容易入门。另一方面，NLTK已经存在了20多年，由于这个原因，野外有大量的文档可用。
- en: Machine learning
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: Machine learning is the branch of artificial intelligence that can learn by
    itself. This can be fully autonomous learning, learning based on pre-labeled data,
    or a combination of these.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能的一个分支，它可以自我学习。这可以是完全自主的学习，基于预标记数据的学习，或者这两种学习的组合。
- en: We need a little bit of background information before we can dive into the libraries
    and the examples for this subject. Feel free to gloss over this section and jump
    straight to the libraries if you are already familiar with the types of machine
    learning.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨这个主题的库和示例之前，我们需要一点背景信息。如果你已经熟悉机器学习的类型，可以自由地跳过这一节，直接查看库。
- en: Types of machine learning
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的类型
- en: 'As we have briefly covered in the introduction, machine learning roughly splits
    up into three different methodologies, but often uses a combination of several.
    To recap, we have the following three major branches:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在简介中简要提到的，机器学习大致分为三种不同的方法，但通常使用几种方法的组合。为了回顾，我们有以下三个主要分支：
- en: Supervised learning
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习
- en: Reinforcement learning
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习
- en: Unsupervised learning
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Naturally, there are many combinations of these, so we will discuss a few important
    distinct types of learning that are based on the branches above. The names themselves
    should already give you a hint about how they function, but we will dive deeper.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，这些有很多组合，所以我们将讨论一些基于上述分支的重要的、独特的学习类型。这些名称本身应该已经给你一些关于它们如何工作的提示，但我们将更深入地探讨。
- en: Supervised learning
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习
- en: In the case of supervised learning, we provide the system with a lot of labeled
    data so the machine can learn the relationship between the input data and the
    labels. Once it has been trained on that data, we can test using new data to see
    if it works. If the results are not as expected, parameters or intermediate training
    steps are tuned until the results improve.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习的情况下，我们向系统提供大量的标记数据，以便机器可以学习输入数据和标签之间的关系。一旦它在这些数据上训练完毕，我们就可以使用新数据来测试它是否有效。如果结果不符合预期，就会调整参数或中间训练步骤，直到结果改善。
- en: 'Examples of these are:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子包括：
- en: 'Classification models where the models are trained on a large number of photos
    to recognize the objects in the photo. Or to answer a question such as: “Are we
    looking at a bird?”'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类模型，这些模型在大量照片上训练以识别照片中的对象。或者回答像：“我们是在看一只鸟吗？”这样的问题。
- en: Sentiment analysis of text. Is the person writing the message happy, sad, hostile,
    and so on?
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本情感分析。发信息的人是快乐的、悲伤的、敌对的，等等吗？
- en: Weather prediction. Since we have a huge amount of historical weather data available,
    this is a perfect case for supervised learning.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天气预报。由于我们有大量的历史天气数据可用，这是一个监督学习的完美案例。
- en: If you have the data available, this will probably be your best option. In many
    cases, however, you either don’t have the data or you have data without high-quality
    labels. That is where the other learning methods come in.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经有了数据，这可能是你的最佳选择。然而，在许多情况下，你可能没有数据，或者你有数据但没有高质量标签。这就是其他学习方法发挥作用的地方。
- en: Reinforcement learning
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强化学习
- en: Reinforcement learning is similar to supervised learning, but instead of using
    labeled input/output pairs it uses a **scoring** or **reward function** to provide
    feedback. The parameter that has to be tuned with reinforcement learning is whether
    to re-use existing knowledge or to investigate a new solution. Leaning too heavily
    toward re-use will result in a “local optimum,” where you will never get the best
    (or even a good) result because you get stuck on your previously found solution.
    Leaning too much toward investigation/exploration of new solutions, however, results
    in never reaching an optimal solution.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习与监督学习类似，但它不是使用标记的输入/输出对，而是使用**评分**或**奖励函数**来提供反馈。在强化学习中需要调整的参数是是否重新使用现有知识或探索新的解决方案。过度依赖重新使用现有知识会导致“局部最优”，因为你将永远无法获得最佳（甚至良好的）结果，因为你会卡在你之前找到的解决方案上。然而，过度依赖对新解决方案的探索/研究，则会导致永远无法达到最优解。
- en: 'Examples of these are:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子包括：
- en: Creating solvers/players for games. For a game such as Go or Chess, you could
    use win/lose as a scoring function. For a game such as Pong or Tetris, you could
    use the score as the reward.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为游戏创建求解器/玩家。对于像围棋或象棋这样的游戏，你可以使用胜负作为评分函数。对于像乒乓球或俄罗斯方块这样的游戏，你可以使用得分作为奖励。
- en: Robot navigation systems. As a scoring system, you could use “distance moved
    from origin” combined with “not hitting a wall.”
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人导航系统。作为一个评分系统，你可以使用“从起点移动的距离”加上“没有撞到墙”。
- en: Swarm intelligence. These are systems with many (a swarm) of independent, self-organizing
    systems that need to reach a common goal. As an example, some online supermarkets
    use swarms of robots to automatically fetch and package groceries with this method.
    The swarm intelligence takes care of collision avoidance and automatically replacing
    defective robots.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 群体智能。这些是许多（一群）独立、自我组织的系统，需要达到一个共同的目标。例如，一些在线超市使用机器人群体以这种方法自动抓取和包装杂货。群体智能负责避免碰撞和自动更换损坏的机器人。
- en: Reinforcement learning is the next best option after supervised learning, because
    it doesn’t require a large amount of high-quality data. You can combine these
    methods quite well, though. Creating a good scoring function can be difficult,
    and you can easily verify your function by testing it on known good data.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是监督学习之后的最佳选择，因为它不需要大量高质量的数据。尽管如此，你可以很好地结合这些方法。创建一个好的评分函数可能很困难，你可以通过在已知良好数据上测试它来轻松验证你的函数。
- en: Unsupervised learning
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督学习
- en: By the name alone, you might be confused by unsupervised learning.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 仅从名称上看，你可能会对无监督学习感到困惑。
- en: After all, how would an unsupervised system work if it has no idea when it has
    reached a useful solution? The point is that with unsupervised learning you don’t
    know what the solution will look like in the end, but you can declare how a solution
    *could* look.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果一个无监督系统不知道何时达到有用的解决方案，它将如何工作呢？关键是，在无监督学习中，你不知道最终解决方案会是什么样子，但你可以说出解决方案*可能*会是什么样子。
- en: 'Since the explanation of unsupervised learning is a bit vague, I hope some
    examples help:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 由于无监督学习的解释有些模糊，我希望一些例子能有所帮助：
- en: Clustering algorithms. With clustering, you feed the algorithm data with a lot
    of variables (for example, in the case of people, weight, height, gender, and
    so on) and tell the algorithm to find clusters.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类算法。在聚类中，你向算法提供包含许多变量（例如，在人的情况下，体重、身高、性别等）的数据，并告诉算法找到聚类。
- en: Anomaly detection. This is also an area where unsupervised learning can really
    shine. With anomaly detection, you never know what you are really looking for,
    but any patterns that are out of the ordinary could be important.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常检测。这也是无监督学习可以真正大放异彩的领域。在异常检测中，你永远不知道你真正在寻找什么，但任何异常的图案都可能很重要。
- en: Unsupervised learning is quite a different type of method from the other two
    machine learning methods we covered earlier because there is often no known target.
    However, that does not make it useless by any means. Finding patterns in seemingly
    random data can be really useful in uptime/stability monitoring or visitor analysis
    for e-commerce websites, among other things.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习与其他两种我们之前介绍过的机器学习方法有很大不同，因为它通常没有已知的靶点。然而，这并不意味着它毫无用处。在看似随机的数据中寻找模式，在许多方面都可以非常有用，比如在正常运行/稳定性监控或电子商务网站的访客分析中。
- en: Now it’s time to look at combinations of the previous methods.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候看看之前方法的组合了。
- en: Combinations of learning methods
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习方法的组合
- en: AI development is as active as it has ever been and I expect the field to keep
    growing in the foreseeable future. That is why more and more variants of algorithms
    are being used, which causes these clear-cut definitions to become more flexible
    all the time.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的发展正如火如荼，我预计这个领域在可预见的未来将继续增长。这就是为什么越来越多的算法变体正在被使用，这导致这些明确的定义变得更加灵活。
- en: In some cases, for example, you can get much better results by combining supervised
    and reinforcement learning together than you could by using either of these methods
    alone. That is why the lines between all of these methods can be extremely blurry,
    and if a method works for your goal, it is not wrong to combine them.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，例如，通过结合监督学习和强化学习，可以得到比单独使用这些方法更好的结果。这就是为什么所有这些方法之间的界限可能非常模糊，如果一种方法适用于你的目标，那么将它们结合起来并不是错误的。
- en: Deep learning
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习
- en: One of the most effective examples of machine learning is deep learning. This
    type of machine learning has become extremely popular over the last few years
    because it has proven to be one of the most effective types of neural networks
    in practical applications, in some cases even outperforming human experts.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中最有效的例子之一是深度学习。这种机器学习类型在过去的几年中变得极其流行，因为它已被证明是实际应用中最有效的神经网络类型之一，在某些情况下甚至超过了人类专家。
- en: This type of network is called **deep** because the neural network has multiple
    (often many) hidden internal layers, while traditional neural networks usually
    only have a single or a few hidden layers.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这种网络被称为**深度**网络，因为神经网络具有多个（通常是许多）隐藏的内部层，而传统的神经网络通常只有一层或几层隐藏层。
- en: Beyond that, it is just a regular neural network and can be supervised, unsupervised,
    reinforcement, or anything in between.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，它只是一个普通的神经网络，可以是监督学习、无监督学习、强化学习或介于两者之间的任何一种。
- en: Artificial neural networks and deep learning
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工神经网络和深度学习
- en: When thinking about AI, most people will immediately think of **artificial neural
    networks** (**ANNs**). These networks are an attempt to mimic the workings of
    animal brains by having artificial neurons and connections between them similar
    to synapses.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 当人们思考人工智能时，大多数人会立即想到**人工神经网络**（**ANNs**）。这些网络试图通过拥有类似突触的人工神经元和它们之间的连接来模仿动物大脑的工作方式。
- en: There are a few key differences, however. In an animal brain, a neuron can function
    both as input and output, whereas with an ANN there are usually a set of input
    neurons in an input layer, a set of neurons as an output layer, and the middle
    layer(s) that handles the processing.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有几个关键的区别。在动物大脑中，一个神经元可以同时作为输入和输出，而在人工神经网络（ANN）中，通常有一个输入层的输入神经元集合，一个输出层的神经元集合，以及处理中间层的中间层（s）。
- en: Currently (in 2021; it was launched in June 2020) by far the most impressive
    ANN is the GPT-3 network, which has been trained for NLP. It has an incredible
    175 billion machine learning parameters and in some cases the text it generates
    is indistinguishable from human-written text.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 目前（2021年；它于2020年6月推出）最令人印象深刻的ANN是GPT-3网络，它被用于NLP训练。它拥有惊人的1750亿个机器学习参数，在某些情况下，它生成的文本与人类撰写的文本难以区分。
- en: This text is likely to be outdated quite soon, however. The GPT-3 network is
    already 100 times bigger than GPT-2, which was released in 2019\. GPT-4 has already
    been announced and is supposed to be about 500 times larger than GPT-3.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这篇文本很快就会过时。GPT-3网络已经比2019年发布的GPT-2大100倍，而GPT-4已经被宣布，预计比GPT-3大500倍。
- en: It should be noted that while ANNs (and especially deep learning) networks are
    very powerful and can be self-learning, many of them are static. After they have
    been trained once, they do not improve or update anymore.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，尽管ANN（尤其是深度学习）网络非常强大并且可以自我学习，但其中许多都是静态的。一旦它们被训练过，它们就不会再改进或更新。
- en: The libraries in this section are made to build neural networks and to enable
    deep learning. Since this is an entirely distinct field in AI, it really deserves
    its own section. Note that you can still mix and match AI strategies if needed,
    of course.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的库是为了构建神经网络和实现深度学习而设计的。由于这是一个在人工智能中完全独立的领域，它确实值得拥有自己的部分。请注意，当然，如果需要，你仍然可以混合和匹配人工智能策略。
- en: Within Python, there are multiple large libraries for creating neural networks,
    but the biggest ones by far are **PyTorch** and **TensorFlow/Keras**. Until a
    few years ago, there was another large library with similar features called Theano.
    That library has since been discontinued and forked under a new name, Aesara.
    Neither of these is used very often these days, but Theano is considered to be
    the original Python neural network library. The TensorFlow library was actually
    created to replace Theano within Google.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，有多个用于创建神经网络的库，但最大的两个库无疑是**PyTorch**和**TensorFlow/Keras**。直到几年前，还有一个具有类似功能的大型库，名为Theano。该库已被停止使用，并以新名称Aesara进行分支。这两个库现在都不太常用，但Theano被认为是原始的Python神经网络库。TensorFlow库实际上是创建来替代Google中的Theano的。
- en: Tensors
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 张量
- en: The basis of an ANN is the tensor. Tensors are a mathematical representation
    for your data with descriptions of valid transformations that can be applied to
    this data. The actual story is much more complicated, of course, but for the purposes
    of the discussion here you can think of a tensor as a multi-dimensional array
    very similar to the `numpy.ndarray` object we have seen in the previous chapter.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ANN的基础是张量。张量是数据的数学表示，其中包含了可以应用于这些数据的有效变换的描述。当然，实际情况要复杂得多，但在这里讨论的目的上，你可以将张量视为与我们在上一章中看到的`numpy.ndarray`对象非常相似的多维数组。
- en: When people talk about a 0-dimensional or 0D Tensor, they are effectively talking
    about a single number. Going up from that, a 1D tensor is an array or vector,
    and a 2D tensor is a matrix.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当人们谈论零维或0D张量时，他们实际上是在谈论一个单独的数字。从那开始，一维张量是一个数组或向量，二维张量是一个矩阵。
- en: The big takeaway for now is that the difference between a regular number/array/matrix
    and a tensor is that the tensors specify what transformations are valid on them
    as well. It is basically the difference between a `list()` and a custom `class`
    that contains the data for the `list()` but has additional properties as well.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 目前最大的收获是，常规数字/数组/矩阵与张量之间的区别在于，张量指定了对其有效的变换。这基本上是`list()`与包含`list()`数据的自定义`class`之间的区别，该`class`还具有额外的属性。
- en: PyTorch – Fast (deep) neural networks
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch – 快速（深度）神经网络
- en: PyTorch is a library developed by Facebook and focuses on building neural networks,
    such as deep learning networks, using tensors.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是由Facebook开发的库，专注于使用张量构建神经网络，如深度学习网络。
- en: The tensors in PyTorch use a custom data structure (instead of `numpy.ndarray`)
    for performance reasons. The PyTorch library is heavily optimized for performance
    and it has built-in support for GPU acceleration for further speedups.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch中的张量使用自定义数据结构（而不是`numpy.ndarray`）以提高性能。PyTorch库在性能优化方面做了大量工作，并内置了对GPU加速的支持，以进一步加快速度。
- en: In many cases you can use `torch.Tensor` as a drop-in replacement for `numpy.ndarray`
    to enable GPU acceleration. The `torch.Tensor` API is largely identical to the
    `numpy.ndarray` API.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，你可以使用`torch.Tensor`作为`numpy.ndarray`的替代品来启用GPU加速。`torch.Tensor` API与`numpy.ndarray`
    API在很大程度上是相同的。
- en: The real strength of PyTorch (besides the performance) is the number of utility
    libraries included for different kinds of inputs. You can easily use it to process
    images, video, audio, and text using these APIs, and most processes can easily
    be run in parallel in a distributed fashion.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch（除了性能之外）的真正优势是包含了许多用于不同类型输入的实用库。你可以轻松使用这些API处理图像、视频、音频和文本，并且大多数过程都可以以分布式方式并行运行。
- en: 'Here is a little overview of the most useful modules:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个关于最有用模块的简要概述：
- en: '`torch.distributed`: For parallel training across multiple GPUs in a single
    system or across multiple systems.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.distributed`：用于在单个系统或多个系统中的多个GPU上并行训练。'
- en: '`torchaudio`: For processing audio, either from pre-recorded files or straight
    from (multiple) microphones.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torchaudio`：用于处理音频，无论是来自预先录制的文件还是直接来自（多个）麦克风。'
- en: '`torchtext`: For processing text; you can also combine this with NLP libraries
    such as NLTK.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torchtext`：用于处理文本；你还可以将其与NLP库如NLTK结合使用。'
- en: '`torchvision`: For processing images and sequences of images (videos).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torchvision`：用于处理图像和图像序列（视频）。'
- en: '`torchserve`: For setting up a server that hosts your models so you can build
    a service that runs your calculations. This is useful because starting a process
    and loading the model can be a slow and heavy task.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torchserve`：用于设置一个服务器，托管你的模型，这样你可以构建一个运行计算的服务。这很有用，因为启动进程和加载模型可能是一个缓慢且繁重的任务。'
- en: '`torch.utils`: Contains many useful utility functions, but above all, TensorBoard.
    With TensorBoard, you can interactively (through a web interface) inspect your
    models and make changes to your model parameters.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.utils`：包含许多有用的实用函数，但最重要的是 TensorBoard。使用 TensorBoard，您可以通过网络界面交互式地检查您的模型并对模型参数进行更改。'
- en: 'It’s time for a small example, but before we can get started we need to install
    both `pytorch` and `torchvision`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候做一个小的例子了，但在我们开始之前，我们需要安装 `pytorch` 和 `torchvision`：
- en: '[PRE13]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We will use the pre-trained **Mask R-CNN** model to do object recognition. This
    is a **region-based convolutional neural network** (**R-CNN**) that has been trained
    using a combination of images and labeled image masks (object outlines).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用预训练的 **Mask R-CNN** 模型进行对象识别。这是一个基于 **区域** 的卷积神经网络（R-CNN），它使用图像和标记的图像掩码（对象轮廓）的组合进行训练。
- en: CNNs are well suited for visual applications such as image classification and
    image segmentation. They can also be applied to other types of problems such as
    NLP as well.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）非常适合视觉应用，如图像分类和图像分割。它们还可以应用于其他类型的问题，如自然语言处理（NLP）。
- en: The R-CNN is a specialized version of the CNN specifically for computer vision
    tasks such as object detection. R-CNN tasks are trained by specifying the **region
    of interest** (**ROI**) in a set of images. The Mask R-CNN is a specialization
    that specifies the ROI not as a rectangle but as a mask that only highlights the
    specific object.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: R-CNN 是 CNN 的一个专门版本，专门用于计算机视觉任务，如目标检测。R-CNN 任务通过在一系列图像中指定 **感兴趣区域**（ROI）进行训练。Mask
    R-CNN 是一个专门化版本，它将 ROI 不是指定为矩形，而是指定为仅突出显示特定对象的掩码。
- en: 'Now we’ll do some object recognition using PyTorch. First, we load the photo
    and imports and convert the photo into a tensor:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用 PyTorch 进行一些对象识别。首先，我们加载照片并导入，将照片转换为张量：
- en: '[PRE14]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The conversion to a tensor can be done using the `ToTensor` transform operation.
    The `torchvision.transforms` module has many more operations available, such as
    resizing, cropping, and color normalization, to pre-filter the images before we
    send them to the model.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 将转换为张量的操作可以使用 `ToTensor` 转换操作完成。`torchvision.transforms` 模块提供了更多操作，例如调整大小、裁剪和颜色归一化，以便在我们将图像发送到模型之前预先过滤图像。
- en: 'Next up is the loading of the model and the labels:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是加载模型和标签：
- en: '[PRE15]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The label file is available on this book’s GitHub page.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 标签文件可在本书的 GitHub 页面上找到。
- en: 'As you can see, the model itself is bundled with PyTorch. After loading the
    model and setting it to `eval` mode (as opposed to training), we can quickly apply
    the model to our image. The labels are unfortunately not bundled, so we need to
    fetch those ourselves. Now we need to display the results:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，模型本身是捆绑在 PyTorch 中的。在加载模型并将其设置为 `eval` 模式（与训练模式相反）后，我们可以快速将模型应用于我们的图像。不幸的是，标签并没有捆绑在一起，因此我们需要自己获取这些标签。现在我们需要显示结果：
- en: '[PRE16]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can display the matches and their bounding boxes to get the following result:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以显示匹配项及其边界框，得到以下结果：
- en: '![/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/B561F30E.tmp](img/B15882_16_07.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15882_16_07.png)'
- en: 'Figure 16.7: Street in Amsterdam with objects labeled by PyTorch'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.7：阿姆斯特丹的街道，由 PyTorch 标注的对象
- en: With just a few lines of code, we managed to create an object recognizer that
    correctly identified a few cars, bicycles, and a boat.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 只需几行代码，我们就成功地创建了一个对象识别器，它可以正确地识别几辆汽车、自行车和一艘船。
- en: In practice, the model actually recognized far more objects in the image, but
    we filtered out small matches so the image is not too busy. It actually recognized
    seven more cars, four people, and two boats.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，模型实际上在图像中识别了更多的对象，但我们过滤掉了小的匹配项，以便图像不会太杂乱。实际上，它还识别了七辆汽车、四个人和两艘船。
- en: PyTorch Lightning and PyTorch Ignite – High-level PyTorch APIs
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch Lightning 和 PyTorch Ignite – 高级 PyTorch API
- en: The PyTorch Lightning and PyTorch Ignite libraries are convenient shortcuts
    for getting your network up and running with fewer steps and several useful features
    built in. You can do the same with PyTorch directly, but using the utility functions
    you can run several PyTorch steps at once, meaning less repetition while working.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Lightning 和 PyTorch Ignite 库是方便的快捷方式，可以以更少的步骤和内置的几个有用功能来启动和运行您的网络。您可以直接使用
    PyTorch 做同样的事情，但使用实用函数，您可以一次运行多个 PyTorch 步骤，这意味着在工作的过程中重复较少。
- en: These libraries were created independently, but serve roughly the same goal
    and are comparable in features. It depends on your personal preference as to which
    is the best for you. I would initially recommend you start with PyTorch directly,
    however. While these libraries are really great, it is important to understand
    the underlying principles before you start using shortcuts that you might not
    completely understand. The PyTorch documentation is quite easy to follow and largely
    identical in workings to PyTorch Ignite and PyTorch Lightning, besides being a
    bit more verbose.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这些库是独立创建的，但大致上服务于相同的目标，并且在功能上可以比较。这取决于您的个人喜好，至于哪个最适合您。我最初建议您直接从 PyTorch 开始。虽然这些库非常出色，但在开始使用您可能不完全理解的快捷方式之前，理解底层原理是很重要的。PyTorch
    文档很容易遵循，在操作上与 PyTorch Ignite 和 PyTorch Lightning 大致相同，除了稍微冗长一些。
- en: Skorch – Mixing PyTorch and scikit-learn
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Skorch – 混合 PyTorch 和 scikit-learn
- en: As was briefly mentioned, scikit-learn natively supports neural networks, but
    its performance is not good enough for large-scale networks. The Skorch library
    takes care of that; you can still use the scikit-learn API if you are familiar
    with that, but it runs on PyTorch internally to achieve great performance.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，scikit-learn 本地支持神经网络，但其性能对于大规模网络来说还不够好。Skorch 库负责解决这个问题；如果您熟悉 scikit-learn
    API，您仍然可以使用它，但它内部运行在 PyTorch 上以实现出色的性能。
- en: TensorFlow/Keras – Fast (deep) neural networks
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TensorFlow/Keras – 快速（深度）神经网络
- en: The TensorFlow library is developed by Google and focuses on building deep neural
    networks very similar to PyTorch. The library is well documented and has a large
    number of pre-trained models available to use; you may never have to train your
    own models, which can be a big advantage.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 库由 Google 开发，专注于构建与 PyTorch 非常相似的深度神经网络。该库文档齐全，提供了大量可用的预训练模型；您可能永远不需要训练自己的模型，这可以是一个很大的优势。
- en: Similar to PyTorch, TensorFlow is also based on tensors for the actual calculations,
    and it is highly optimized for performance on many platforms, including mobile
    phones for deployment and dedicated **tensor processing units** (**TPU**s) or
    GPU hardware for training the models.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 与 PyTorch 类似，TensorFlow 也基于张量进行实际计算，并且它在许多平台上高度优化以实现性能，包括用于部署的手机、专门的 **张量处理单元**（**TPU**）或用于训练模型的
    GPU 硬件。
- en: 'As an example, we will run the Mask R-CNN we used with PyTorch earlier again.
    Since this model is not bundled with `tensorflow`, we need to install `tensorflow-hub`
    in addition to `tensorflow`:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们将再次运行之前与 PyTorch 一起使用的 Mask R-CNN。由于此模型未与 `tensorflow` 一起打包，我们需要在安装 `tensorflow`
    的同时安装 `tensorflow-hub`：
- en: '[PRE17]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This will automatically install `tensorflow` with GPU support if available
    for your platform. Currently, that means either Windows or Ubuntu Linux. Now we
    can test some TensorFlow/Keras code. First, we import what we need, set some variables,
    and load the image:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的平台支持，这将自动安装带有 GPU 支持的 `tensorflow`。目前，这意味着 Windows 或 Ubuntu Linux。现在我们可以测试一些
    TensorFlow/Keras 代码。首先，我们导入所需的库，设置一些变量，并加载图像：
- en: '[PRE18]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now that the image is loaded, let’s load the model using `tensorflow_hub` and
    apply it on our image:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在图像已加载，让我们使用 `tensorflow_hub` 加载模型并在我们的图像上应用它：
- en: '[PRE19]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Once again, we don’t have the labels available, so we read that from our `coco_labels.txt`
    file. However, once we load the model we can easily apply it to our image.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我们没有可用的标签，因此我们从 `coco_labels.txt` 文件中读取它。然而，一旦我们加载了模型，我们就可以轻松地将它应用于我们的图像。
- en: 'Now we need to prepare the results for easy processing and display them:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要准备结果以便于处理，并将它们显示出来：
- en: '[PRE20]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The code is largely similar to the PyTorch code because it uses the same pre-trained
    model. The notable differences are:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它使用了相同的预训练模型，代码在很大程度上与 PyTorch 代码相似。值得注意的是差异：
- en: We loaded the model using `tensorflow_hub`. This automatically downloads and
    executes pre-trained models from [https://tfhub.dev/](https://tfhub.dev/).
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用 `tensorflow_hub` 加载了模型。这会自动从 [https://tfhub.dev/](https://tfhub.dev/) 下载并执行预训练模型。
- en: The box points are from 0 to 1 instead of being relative to the image size.
    So, coordinate `10x5` in a `20x20` image results in `0.5x0.25`.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩形框的坐标是从 0 到 1，而不是相对于图像大小。因此，在 `20x20` 图像中的 `10x5` 坐标将导致 `0.5x0.25`。
- en: 'The output variable names are different. It should be noted that these are
    dependent on the model and can be found on TensorFlow Hub for this model: [https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1](https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出变量名不同。应该注意的是，这些取决于模型，可以在 TensorFlow Hub 上找到此模型的这些变量名：[https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1](https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1)。
- en: The box points use the left, top, right, bottom order instead of top, left,
    bottom, right, as was the case with PyTorch.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 箱子点使用左、上、右、下的顺序，而不是 PyTorch 中的上、左、下、右。
- en: Beyond those small changes, the code is effectively identical.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些小的变化之外，代码实际上是相同的。
- en: NumPy compatibility
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: NumPy 兼容性
- en: The actual tensor objects in TensorFlow are slightly different from the PyTorch
    tensors. While the `pytorch.Tensor` API can be used as a `numpy.ndarray` alternative,
    with `tensorflow.Tensor` the API is a bit different.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 中的实际张量对象与 PyTorch 张量略有不同。虽然 `pytorch.Tensor` API 可以用作 `numpy.ndarray`
    的替代品，但 `tensorflow.Tensor` 的 API 略有不同。
- en: There is a `tensorflow.Tensor.numpy()` method, which returns a `numpy.ndarray`
    of the data. It is important to note that this is *not* a reference, however;
    modifying the `numpy` array will *not* update the original tensor, so you will
    need to convert it back after your changes.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个 `tensorflow.Tensor.numpy()` 方法，它返回数据的 `numpy.ndarray`。需要注意的是，这**不是**一个引用；修改
    `numpy` 数组**不会**更新原始张量，因此你需要在修改后将其转换回来。
- en: 'As an alternative, TensorFlow does offer an experimental `numpy` API if you
    prefer that API. It can be enabled like this:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 作为替代方案，TensorFlow 提供了一个实验性的 `numpy` API，如果你更喜欢这个 API，可以像这样启用：
- en: '[PRE21]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Usage is fairly straightforward, but it is by no means fully `numpy.ndarray`-compatible:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相当简单，但绝不是完全与 `numpy.ndarray` 兼容：
- en: '[PRE22]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Keras
  id: totrans-281
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Keras
- en: The Keras submodule of TensorFlow is similar to what PyTorch Lightning and PyTorch
    Ignite are for PyTorch. It offers a high-level interface for TensorFlow, making
    it easier to use and get started with. As opposed to the aforementioned PyTorch
    libraries, Keras is quite suitable as a starting point as well. Knowing the underlying
    TensorFlow functions can be useful, but it is not a requirement for being able
    to use Keras effectively.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 的 Keras 子模块类似于 PyTorch 的 PyTorch Lightning 和 PyTorch Ignite。它为 TensorFlow
    提供了一个高级接口，使其更容易使用和入门。与上述 PyTorch 库相反，Keras 作为起点也非常合适。了解底层 TensorFlow 函数可能很有用，但不是使用
    Keras 有效的必要条件。
- en: Keras might be for you if you are just getting started with TensorFlow and want
    to apply some machine learning to your project without going down the rabbit hole.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你刚开始使用 TensorFlow，并想在项目中应用一些机器学习而不深入到兔子洞中，Keras 可能适合你。
- en: TensorFlow versus PyTorch
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TensorFlow 与 PyTorch 的比较
- en: There are a few advantages and disadvantages to TensorFlow compared to PyTorch,
    so let’s list those before we continue.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 与 PyTorch 相比，TensorFlow 有一些优缺点，所以在继续之前，让我们列出这些优缺点。
- en: 'Here are some reasons you might choose TensorFlow over PyTorch:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些原因，你可能选择 TensorFlow 而不是 PyTorch：
- en: TensorFlow supports the execution of the pre-trained model in a web browser.
    While PyTorch does have a few libraries available to do this as well, they are
    either stale or far behind TensorFlow in terms of features and stability.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 支持在网页浏览器中执行预训练模型。虽然 PyTorch 也有一些库可以做到这一点，但它们要么过时，要么在功能和稳定性方面远远落后于
    TensorFlow。
- en: TensorFlow is largely language-agnostic. This means that it has bindings for
    multiple languages, whereas PyTorch is largely Python-only.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 大部分是语言无关的。这意味着它为多种语言提供了绑定，而 PyTorch 主要只支持 Python。
- en: TensorFlow, or more specifically, Keras, is a very high-level API that allows
    you to get started quickly. When comparing Keras to PyTorch Lightning/PyTorch
    Ignite, I personally feel that you can get a working result more quickly with
    TensorFlow. Keras has many utility functions and classes bundled that can save
    you some work while creating a model. Another big help is TensorFlow Hub, which
    offers many pre-trained models with example code for your convenience.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow，或者更具体地说，Keras，是一个非常高级的 API，它允许你快速入门。当比较 Keras 与 PyTorch Lightning/PyTorch
    Ignite 时，我个人觉得你可以用 TensorFlow 更快地得到一个可工作的结果。Keras 包含了许多实用函数和类，可以在创建模型时节省你一些工作。另一个大帮助是
    TensorFlow Hub，它提供了许多预训练模型和示例代码，方便你使用。
- en: TensorFlow has a slightly bigger community and slightly more tutorials available.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 有一个稍微大一点的社区和更多的教程可用。
- en: 'Conversely:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 相反：
- en: PyTorch was written around Python and has a much more Pythonic API.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch是围绕Python编写的，并且有一个更加Pythonic的API。
- en: PyTorch offers more fine-grained control and easily gives you many parameters
    to tune.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch提供了更细粒度的控制，并且可以轻松地给你许多可调整的参数。
- en: While this is a personal opinion, I find that debugging PyTorch is much nicer
    (from Python, at least) than TensorFlow or Keras because the codebase has fewer
    layers and seems less complicated. Stepping through the execution of your model
    with a regular Python debugger works great and is easy to follow in the case of
    PyTorch. In my experience, regular Python debuggers do not work at all with TensorFlow.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然这是一个个人观点，但我发现调试PyTorch（至少从Python来看）比TensorFlow或Keras要好得多，因为代码库层次较少，看起来不那么复杂。使用常规Python调试器逐步执行你的模型执行效果很好，并且很容易在PyTorch中跟踪。在我的经验中，常规Python调试器根本无法与TensorFlow一起工作。
- en: PyTorch is a bit faster than TensorFlow. This can be a huge help while developing
    and debugging.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch比TensorFlow快一点。这在开发和调试时可以提供巨大的帮助。
- en: Which of the libraries you should use depends on personal preference and factors
    such as pre-existing experience for you and/or the rest of your team. I can certainly
    recommend both of them.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该使用哪个库取决于个人偏好以及你和你团队的其他成员的现有经验等因素。我当然可以推荐这两个库。
- en: Evolutionary algorithms
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进化算法
- en: Evolutionary algorithms are a technique based on evolution in nature that improve
    by using a fitness function to determine quality, and by evolving the solution.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 进化算法是一种基于自然界进化的技术，通过使用适应度函数来确定质量，并通过进化解决方案来改进。
- en: The most common implementation is the **genetic algorithm**, which commonly
    encodes the solution, or chromosome, into a string or an array that can be tested
    by the fitness function. This chromosome could be a list of functions to apply,
    a list of parameters to a function, or something else entirely. How you wish to
    encode the chromosome is up to you, as long as the fitness function can use it
    to calculate a fitness score.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的实现是**遗传算法**，它通常将解决方案或染色体编码成一个字符串或数组，可以通过适应度函数进行测试。这个染色体可以是一系列要应用的函数，一个函数的参数列表，或者完全是其他东西。你希望如何编码染色体完全取决于你，只要适应度函数可以使用它来计算适应度分数。
- en: 'The genetic algorithm will employ one of the following operations to try and
    improve the fitness score:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传算法将采用以下操作之一来尝试提高适应度分数：
- en: '**Mutation**: This could be a bit flip from 0 to 1, or a more complex mutation
    of replacing multiple bits. For example, if we have bit-string `0101`, then a
    mutation could result in `0111`.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变异（Mutation）**：这可能是一个从0到1的位翻转，或者是一个更复杂的变异，即替换多个位。例如，如果我们有位串`0101`，那么一个变异可能导致`0111`。'
- en: '**Selection**: Given a set of different tested chromosomes using the fitness
    function, only keep the best few.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择（Selection）**：给定使用适应度函数测试的一组不同的染色体，只保留最好的几个。'
- en: '**Crossover**: Given a few different chromosomes, combine parts of them to
    try new solutions. For example, if we have two strings, AABB and DEFG, the crossover
    can split them and combine them; for instance, you could get AAFG, which combines
    the first two characters from the first string and the last two from the second
    string.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交叉（Crossover）**：给定几个不同的染色体，将它们的部分组合起来尝试新的解决方案。例如，如果我们有两个字符串，AABB和DEFG，交叉可以分割它们并组合它们；例如，你可以得到AAFG，它结合了第一个字符串的前两个字符和第二个字符串的最后两个字符。'
- en: The genetic algorithm takes a few parameters to control which strategy is employed
    at a given run. The **mutation rate** sets the probability of a mutation occurring;
    the **elitism parameter** decides how many results to keep in the selection process;
    and the **crossover rate** sets the probability of crossovers occurring. The difficult
    part is tuning these parameters to return a good and stable solution (in other
    words, one that does not change too much between runs), but not getting stuck
    in a local optimum where your solution appears the best but could be far better
    by attempting more genetic diversity.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传算法需要一些参数来控制在给定运行中采用哪种策略。**变异率**设置变异发生的概率；**精英主义参数**决定在选择过程中保留多少结果；**交叉率**设置交叉发生的概率。困难的部分是调整这些参数以返回一个好的和稳定的解决方案（换句话说，一个在运行之间变化不大的解决方案），但不要陷入局部最优，在那里你的解决方案看起来是最好的，但通过尝试更多的遗传多样性可能会更好。
- en: There are many applications where genetic algorithms (or more generally, genetic
    programming) are the most feasible option to get a good solution to your problem.
    One of the prime examples of where genetic algorithms shine is the **traveling
    salesman problem** (**TSP**). With the TSP, you have a list of cities that you
    want to visit, and you want to find the shortest route that covers all of them.
    The standard brute-force solution has a time complexity of `O(n!)`, which means
    that for 10 cities you need about 3,628,800 steps to calculate. That is a lot,
    but still easily manageable. For 20 cities, however, the number grows to 2,432,902,008,176,640,000,
    or, 2 quintillion (2 billion billion), and that growth continues very rapidly.
    With genetic programming, the fitness problem will almost immediately eliminate
    parts of the solution space that are completely infeasible and gives you a good
    (but possibly not the best) solution relatively fast.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多应用场景中，遗传算法（或更普遍的遗传编程）是获取你问题良好解决方案的最可行选项之一。遗传算法表现卓越的一个主要例子是**旅行商问题**（**TSP**）。在TSP中，你有一串想要访问的城市，你需要找到覆盖所有城市的最短路线。标准的暴力解决方案的时间复杂度为`O(n!)`，这意味着对于10个城市，你需要大约3,628,800步来计算。这确实很多，但仍然容易管理。然而，对于20个城市，数字增长到2,432,902,008,176,640,000，或者说2千万亿（2亿亿），而且这种增长非常迅速。使用遗传编程，适应性问题的解决方案将几乎立即消除那些完全不可行的解决方案空间的部分，并相对快速地给出一个良好（但可能不是最佳）的解决方案。
- en: Even though evolutionary algorithms offer a lot of power, implementing them
    is relatively easy to do and often highly specific to your specific use case.
    This makes it a scenario where applications and libraries usually opt for writing
    their own implementation instead of using a library for this goal.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管进化算法提供了很多功能，但实现它们相对容易，并且通常非常具体于你的特定用例。这使得在这种情况下，应用程序和库通常会选择编写自己的实现，而不是使用库来实现这个目标。
- en: There is at least one notable Python library for genetic algorithms however.
    The PyGAD library can make it easily possible for you to use genetic algorithms
    in your project. It also comes with built-in support for Keras and PyTorch to
    save you some work.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，至少有一个值得注意的Python遗传算法库。PyGAD库可以让你轻松地在项目中使用遗传算法。它还内置了对Keras和PyTorch的支持，以节省你一些工作。
- en: 'Let’s start by installing PyGAD:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从安装PyGAD开始：
- en: '[PRE23]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now we will attempt to solve a problem you might encounter in the real world.
    Let’s say that you need a new floor and you want wooden floorboards. Due to bulk
    discounts, it can be cheaper to buy a large stack of boards instead of just a
    few separate boards, so let’s assume we have a few different bulk quantities and
    make our algorithm optimize for cost. First, we need to define our list of bulk
    sizes with the prices. We will also define the number of boards we are looking
    for. Lastly, we will define the fitness function to tell PyGAD how good (or bad)
    the solution is:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将尝试解决你可能在现实世界中遇到的问题。假设你需要一个新的地板，并且你想要木地板。由于批量折扣，购买一大堆板子可能比购买几块单独的板子更便宜，所以让我们假设我们有几种不同的批量数量，并让我们的算法优化成本。首先，我们需要定义我们的批量大小列表及其价格。我们还将定义我们正在寻找的板子数量。最后，我们将定义适应度函数，告诉PyGAD解决方案有多好（或有多坏）：
- en: '[PRE24]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The fitness functions for PyGAD optimize for the highest number; since we are
    looking for the lowest price, we can simply invert the price. Additionally, we
    can return minus infinity when we want to rule out “bad” solutions.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: PyGAD的适应度函数优化的是最高值；由于我们寻找的是最低价格，我们可以简单地反转价格。此外，当我们想要排除“不良”解决方案时，我们可以返回负无穷大。
- en: 'To get some intermediate results, we can optionally add a function that will
    show us the state at every generation:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取一些中间结果，我们可以选择添加一个函数，它将在每一代显示状态：
- en: '[PRE25]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now it’s time to run the algorithm and show the output while doing so:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是运行算法并显示输出的时间：
- en: '[PRE26]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This will run 1,000 generations for us with 100 solutions per generation. A
    single solution contains the number of stacks of wood to buy for each stack size.
    When we run this code, we should get something similar to this:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们运行1000代，每代100个解决方案。单个解决方案包含每个堆叠大小需要购买的木材堆的数量。当我们运行这段代码时，我们应该得到类似以下的结果：
- en: '[PRE27]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The plot of our results:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果图：
- en: '![](img/B15882_16_08.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15882_16_08.png)'
- en: 'Figure 16.8: Genetic algorithm fitness result plot'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.8：遗传算法适应度结果图
- en: In this case, 495 is actually the optimal result; in most cases, though, you
    don’t know if you have reached the optimal result. This essentially means that
    you could keep your code running forever, which is why you should either configure
    a fixed number of generations, or tell PyGAD to stop once it has reached a steady
    state for a certain number of generations.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，495实际上是最佳结果；然而，在大多数情况下，你不知道你是否已经达到了最佳结果。这本质上意味着你可以让你的代码永远运行，这就是为什么你应该配置一个固定的代数数量，或者告诉PyGAD在达到一定代数的稳定状态后停止。
- en: More importantly, however, after about 50 generations we already had a great
    and very usable solution for our problem, whereas the optimal solution took roughly
    700 generations this run. In many of the other runs I did, it never even found
    the optimal solution. This shows you how quickly the genetic algorithm can give
    you a useful result.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，更重要的是，在大约50代之后，我们已经为我们的问题找到了一个非常出色且非常实用的解决方案，而最佳解决方案在这个运行中大约需要700代。在许多其他运行中，它甚至从未找到最佳解决方案。这表明遗传算法可以多么快速地给你一个有用的结果。
- en: Support-vector machines
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持向量机
- en: '**Support-vector machines** (**SVMs**) or support-vector networks are common
    models for supervised learning. Since it is a supervised learning method, it expects
    a dataset that is already labeled (for example, a list of photos with correct
    labels) to train on. Once the model has been trained, it can be used for classification
    and regression analysis.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVMs**）或支持向量网络是监督学习的常见模型。由于它是一种监督学习方法，它期望有一个已经标记的数据集（例如，带有正确标签的图片列表）来训练。一旦模型被训练，就可以用于分类和回归分析。'
- en: In statistics, **regression analysis** is a way to show the relationship between
    variables. These can be used to fit lines, create predictors, detect outliers,
    and more. We have seen several examples of regression analysis in *Chapter 15*,
    *Scientific Python and Plotting*, as well.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，**回归分析**是展示变量之间关系的一种方法。这些可以用来拟合线、创建预测器、检测异常值等。我们也在*第15章*，*科学Python和绘图*中看到了几个回归分析的例子。
- en: '**Classification** refers to statistical classification and is a method of
    splitting data. For example, the question as to whether an email is spam or not
    is a form of binary classification.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类**指的是统计分类，是一种分割数据的方法。例如，关于一封邮件是否为垃圾邮件的问题就是一种二元分类。'
- en: Bayesian networks
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 贝叶斯网络
- en: Bayesian networks are based on the idea that we have probabilities of an event
    occurring. This is usually expressed as `P(event)`, where `P(event)=1` is 100%
    probability of `event` occurring and `P(event)=0` is no probability at all.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯网络基于这样的想法：我们有事件发生的概率。这通常表示为`P(event)`，其中`P(event)=1`表示事件发生的100%概率，而`P(event)=0`则表示完全没有概率。
- en: 'These can be used for all sorts of applications and are particularly useful
    for expert systems, which can make recommendations based on your given data. For
    example, given that there is a thunderstorm outside, we know that there is a larger
    probability of rain than if it is sunny outside. In Bayesian terms, we would describe
    it like this:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可以用于各种应用，尤其是在专家系统中特别有用，因为它们可以根据你提供的数据做出推荐。例如，既然外面有雷暴，我们就知道下雨的概率比外面晴朗时要大。用贝叶斯术语来说，我们会这样描述：
- en: '[PRE28]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Bayesian networks are often used for spam filters that look for certain keywords
    and calculate the odds of an email being spam. Another possible use case for Bayesian
    networks is text prediction when typing. If you train your network with many sentences,
    you can calculate the next most likely word to occur given the previous word or
    words.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯网络常用于查找特定关键词并计算邮件是否为垃圾邮件的垃圾邮件过滤器。贝叶斯网络的另一个可能用例是在打字时的文本预测。如果你用许多句子训练你的网络，你可以根据前面的单词或单词计算下一个最可能出现的单词。
- en: As you have seen, there are many types of different machine learning models,
    and many more submodels that all have their own strengths and weaknesses. This
    list of examples is an extremely condensed and simplified list of available models,
    but it should give you at least some idea of the scenarios in which these different
    algorithms can do their magic.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，有各种各样的机器学习模型，以及更多具有各自优缺点的子模型。这个例子列表是一个非常浓缩和简化的可用模型列表，但它应该至少给你一些关于这些不同算法可以在哪些场景下施展魔力的想法。
- en: Versatile AI libraries and utilities
  id: totrans-334
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多功能AI库和工具
- en: Python is by far the most popular language when it comes to developing AI systems.
    The result of this popularity is that there are a huge number of libraries available
    for every branch of AI you can think of. There is at least a single good library
    for nearly every AI technique, and often dozens.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到开发AI系统时，Python无疑是最受欢迎的语言。这种受欢迎的结果是，对于您能想到的AI的每一个分支，都有大量的库可供选择。几乎每种AI技术都至少有一个好的库，而且通常有几十个。
- en: In this section of this chapter, you will find a curated (and incomplete) list
    of useful AI libraries split into segments. There are many more that are not mentioned
    due to being too specific, too new, or simply because I have omitted them owing
    to the great number of libraries that are out there.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的这一节中，您将找到一个经过精选（但不完整）的有用AI库列表，分为几个部分。由于过于具体、太新，或者仅仅是因为图书馆数量众多，许多库没有被提及。
- en: scikit-learn – Machine learning in Python
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scikit-learn – Python中的机器学习
- en: The scikit-learn library is an extremely versatile machine learning library
    that covers many AI topics; for many of them, this should be your starting point.
    We have already seen the scikit-image library earlier, which is a part of the
    scikit-learn project, but there are many more options.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn库是一个极其通用的机器学习库，涵盖了众多AI主题；对于其中许多主题，这应该是您的起点。我们之前已经看到了scikit-image库，它是scikit-learn项目的一部分，但还有许多其他选项。
- en: The complete list of possibilities is huge, so I will try to give you a very
    small list based on the scikit-learn modules that I have personally found useful.
    Many more methods are available, so make sure to read through the scikit-learn
    documentation if you are interested in anything specific.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 可能性的完整列表非常庞大，所以我将基于我个人认为有用的scikit-learn模块，尝试给您提供一个非常小的列表。还有很多其他方法可供选择，所以如果您对任何特定内容感兴趣，请务必阅读scikit-learn文档。
- en: This section is split between supervised and unsupervised options, since your
    dataset is the most important factor in deciding on an algorithm for your use
    case.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您的数据集是决定您用例算法的最重要因素，因此本节在监督学习和无监督选项之间划分。
- en: Supervised learning
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习
- en: Starting with supervised learning, scikit-learn offers a host of different options
    in many different categories.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 从监督学习开始，scikit-learn在许多不同类别中提供了大量不同的选项。
- en: Linear models
  id: totrans-343
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 线性模型
- en: 'First of all, scikit-learn offers dozens of different linear models for performing
    many types of regressions. It has functions for many specific use cases, such
    as:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，scikit-learn提供了数十种不同的线性模型，用于执行许多类型的回归。它具有针对许多特定用例的功能，例如：
- en: '**Ordinary least squares** regression, as we have seen several times in the
    previous chapter as well.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**普通最小二乘法**回归，正如我们在上一章中多次看到的。'
- en: '**Ridge regression and classifier**, a function similar to the ordinary least
    squares method but more resistant to collinearity.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**岭回归和分类器**，一个类似于普通最小二乘法但更能抵抗共线性的函数。'
- en: The **LASSO** (**least absolute shrinkage and selection operator**) **model**,
    which can be seen as the successor to the Ridge model for specific use cases.
    One of the advantages of the lasso model is that, in the case of machine learning,
    it can help filter out (usually irrelevant) features with very little data.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LASSO**（**最小绝对收缩和选择算子**）模型，可以看作是针对特定用例的Ridge模型的继任者。LASSO模型的一个优点是，在机器学习的情况下，它可以帮助用很少的数据过滤掉（通常是不相关的）特征。'
- en: '**Polynomial regression**: Methods such as the ordinary least squares method
    perform regression by creating a single straight line. In some cases, however,
    a straight line will never properly fit your data. In these cases, polynomial
    regression can help a lot since it can generate curved lines.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多项式回归**：例如，普通最小二乘法通过创建一条直线来进行回归。然而，在某些情况下，直线可能永远无法正确地拟合您的数据。在这些情况下，多项式回归可以非常有帮助，因为它可以生成曲线。'
- en: 'There are many more methods in this module, so make sure to take a look at
    the documentation: [https://scikit-learn.org/stable/modules/linear_model.html](https://scikit-learn.org/stable/modules/linear_model.html).'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 此模块中还有许多其他方法，所以请确保查看文档：[https://scikit-learn.org/stable/modules/linear_model.html](https://scikit-learn.org/stable/modules/linear_model.html)。
- en: Support-vector machines
  id: totrans-350
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Next up are support-vector machines. We already discussed SVMs briefly, but
    in short these can be used for classification, regression, and outlier detection.
    As opposed to the linear (2D) models above, these methods also function for higher-dimensional
    data.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是支持向量机。我们之前已经简要讨论了 SVMs，但简而言之，这些可以用于分类、回归和异常检测。与上述的线性（2D）模型相比，这些方法也适用于高维数据。
- en: 'Currently, scikit-learn supports these types of SVMs:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，scikit-learn 支持这些类型的 SVMs：
- en: '`SVC`/`SVR`: Support-vector classification and regression based on the C `libsvm`
    library. For smaller datasets (a few thousand samples), this is the most useful
    and flexible SVM implementation in scikit-learn. This method can also handle support
    vectors, which can increase the precision of classifiers.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SVC`/`SVR`: 基于 C `libsvm` 库的支持向量分类和回归。对于较小的数据集（几千个样本），这是 scikit-learn 中最有用和最灵活的
    SVM 实现。这种方法还可以处理支持向量，这可以提高分类器的精度。'
- en: '`NuSVC`/`NuSVR`: A modified version of SVC/SVR that introduces a parameter
    *v* (the Greek letter Nu) to approximate the fraction of training errors and support
    vectors.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NuSVC`/`NuSVR`: SVC/SVR 的一个修改版本，引入了一个参数 *v*（希腊字母 Nu），用于近似训练错误和支持向量的比例。'
- en: '`LinearSVC`/`LinearSVR`: A fast (faster than `SVC`/`SVR`) linear support vector
    classification and regression system. For large datasets (over 10,000 samples)
    this is the better alternative to `SVC`/`SVR`, but it does not handle separate
    support vectors.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LinearSVC`/`LinearSVR`: 一个快速（比 `SVC`/`SVR` 快）的线性支持向量分类和回归系统。对于大型数据集（超过 10,000
    个样本），这是 `SVC`/`SVR` 的更好替代品，但它不处理单独的支持向量。'
- en: SVMs are very robust prediction methods for higher-dimensional data while still
    maintaining decent execution speeds.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: SVMs 是针对高维数据非常稳健的预测方法，同时仍然保持相当快的执行速度。
- en: Decision trees
  id: totrans-357
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 决策树
- en: '**Decision trees** (**DTs**) also deserve special attention. While most of
    the machine learning models are still relatively expensive to use after training,
    with DTs you build a tree based on the training data to use in your classification
    or regression. If you are familiar with tree structures, you know that many lookups
    only take `O(log(n))` time to do. In addition to being really fast to calculate,
    it can also make it much easier to visualize your data, because `scikit-learn`
    can export the evaluated results to Graphviz, a tool for rendering graph structures.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策树**（**DTs**）也值得特别注意。虽然大多数机器学习模型在训练后仍然相对昂贵，但使用决策树时，你可以根据训练数据构建一个树，用于你的分类或回归。如果你熟悉树结构，你知道许多查找只需要
    `O(log(n))` 的时间。除了计算速度快之外，它还可以使你的数据可视化变得更加容易，因为 `scikit-learn` 可以将评估结果导出到 Graphviz，这是一个渲染图结构的工具。'
- en: To supercharge the DTs, you can also combine a collection of them into a forest
    using a `RandomForestClassifier` or `RandomForestRegressor`, which results in
    reduced variance. To take this a step further, you can also use the **extremely
    randomized trees** methods `ExtraTreesClassifier` or `ExtraTreesRegressor`, which
    also randomize the specific thresholds between the trees, for further reduced
    variance over the normal forest methods.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 要增强决策树，你还可以将它们组合成一个森林，使用 `RandomForestClassifier` 或 `RandomForestRegressor`，这会导致方差减少。更进一步，你还可以使用
    **极端随机树** 方法 `ExtraTreesClassifier` 或 `ExtraTreesRegressor`，这些方法还会随机化树之间的特定阈值，从而在正常森林方法之上进一步减少方差。
- en: Feature selection
  id: totrans-360
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 特征选择
- en: Using feature selection, you can input a large number of input parameters without
    specifying what they are for, and let the model figure out the most important
    features.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 使用特征选择，你可以输入大量输入参数，而不必指定它们的作用，让模型找出最重要的特征。
- en: For example, let’s say that you have collected a large set of weather and geographical
    data, such as temperature, humidity, air pressure, altitude, and coordinates,
    and you want to know which of these play a role in answering the question of whether
    it will snow. The coordinates and air pressure are probably less important factors
    than temperature is in this case.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你收集了大量天气和地理数据，例如温度、湿度、气压、海拔和坐标，你想要知道这些数据中哪些在回答是否会下雪的问题中起作用。在这种情况下，坐标和气压可能不如温度重要。
- en: 'The scikit-learn library has several different options available for feature
    selection:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 库为特征选择提供了几种不同的选项：
- en: '`sklearn.feature_selection.VarianceThreshold`: Excludes items with a small
    variance by satisfying the equation Var[X]=p(1-p)'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.feature_selection.VarianceThreshold`: 通过满足方程 Var[X]=p(1-p) 来排除方差较小的项'
- en: '`sklearn.feature_selection.SelectKBest`: Selects the k highest scoring features'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.feature_selection.SelectKBest`：选择评分最高的k个特征'
- en: '`sklearn.feature_selection.SelectPercentile`: Selects the top nth percentile
    scoring features'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.feature_selection.SelectPercentile`：选择评分最高的第n百分位数的特征'
- en: '`sklearn.feature_selection.SelectFromModel`: A special and very useful feature
    selector that can use previously generated models (such as an SVM) to filter features'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.feature_selection.SelectFromModel`：一个特殊且非常有用的特征选择器，可以使用先前生成的模型（如SVM）来过滤特征'
- en: There are several other feature selection and feature filtering methods available,
    so make sure to check the documentation to see if there is a better method available
    for your specific use case.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他几种特征选择和特征过滤方法可供选择，所以请确保查看文档，看看是否有更适合你特定用例的方法。
- en: Other models
  id: totrans-369
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 其他模型
- en: 'In addition to these methods, there are many other methods supported by scikit-learn,
    such as:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些方法之外，scikit-learn还支持许多其他方法，例如：
- en: '**Bayesian networks**: Gaussian, multinomial, complement, Bernoulli, categorical,
    and out-of-core.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯网络**：高斯、多项式、补集、伯努利、分类和离核。'
- en: '**Linear and quadratic discriminant analysis**: These are similar to the linear
    models but also offer quadratic solutions.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性与二次判别分析**：这些与线性模型类似，但也提供了二次解决方案。'
- en: '**Kernel ridge regression**: A combination of ridge regression and classification.
    This can be a faster alternative to SVR.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**核岭回归**：岭回归和分类的结合。这可以是一个比SVR更快的替代方案。'
- en: '**Stochastic gradient descent**: A very fast regression/classifier alternative
    to SVM for specific use cases.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机梯度下降**：对于特定用例，是SVM的一个非常快速的回归/分类替代方案。'
- en: '**Nearest neighbor**: These methods are useful for a range of different purposes
    and are at the core of many of the other functions in this library. At the very
    least, take a look at this section, because structures such as KD-trees have many
    applications outside of machine learning as well.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最近邻**：这些方法适用于多种不同的目的，并且是这个库中许多其他函数的核心。至少，请查看这一部分，因为像KD树这样的结构在机器学习之外也有许多应用。'
- en: While there are several other options as well, these are probably the ones that
    are most useful to you. Note that even though scikit-learn does support neural
    networks such as multi-layer perceptrons, I would not recommend you use scikit-learn
    for this purpose. While the implementation works well, it does not have support
    for GPU (video card) acceleration, which makes a huge performance difference.
    For neural networks I recommend using TensorFlow, as discussed earlier in this
    chapter.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管还有其他几种选择，但这些可能对你最有用。请注意，尽管scikit-learn支持多层感知器等神经网络，但我不会推荐你用它来达到这个目的。虽然实现效果不错，但它不支持GPU（显卡）加速，这会带来巨大的性能差异。对于神经网络，我推荐使用前面章节中提到的TensorFlow。
- en: Unsupervised learning
  id: totrans-377
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Due to the nature of unsupervised learning, it is a lot less versatile than
    supervised learning, but there are a few scenarios where unsupervised learning
    absolutely makes sense and is an easy solution. While the unsupervised learning
    portion of scikit-learn is smaller than the supervised portion, there are still
    several really useful functions available.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 由于无监督学习的特性，它比监督学习要少用得多，但在某些场景下，无监督学习绝对是有意义的简单解决方案。虽然scikit-learn的无监督学习部分比监督学习部分小，但仍然有几个非常有用的函数可用。
- en: 'Clustering is the prime example of where unsupervised learning shines. This
    comes down to giving the algorithm a whole bunch of data and telling it to cluster
    (split) it into useful sections wherever it can find a pattern. To facilitate
    this, scikit-learn has a range of different algorithms. The documentation explains
    this very well: [https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods](https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods).'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是无监督学习大放异彩的主要例子。这归结为给算法提供大量数据，并告诉它在找到模式的地方将其（分割）成有用的部分。为了便于实现这一点，scikit-learn提供了一系列不同的算法。文档对此解释得非常清楚：[https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods](https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods)。
- en: 'A subsection of this documentation is given below:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 本文档的一个子部分如下：
- en: '| **Method name** | **Scalability** | **Use case** |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| **方法名称** | **可扩展性** | **用例** |'
- en: '| K-Means | Very large `n_samples`, medium `n_clusters` with MiniBatch code
    | General-purpose, even cluster size, flat geometry, not too many clusters, inductive
    |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| K-Means | 非常大的 `n_samples`，中等 `n_clusters` 使用 MiniBatch 代码 | 通用，聚类大小均匀，平坦几何，聚类数量不多，归纳
    |'
- en: '| Affinity propagation | Not scalable with `n_samples` | Many clusters, uneven
    cluster size, non-flat geometry, inductive |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 相似传播 | 无法与 `n_samples` 规模化 | 许多聚类，聚类大小不均匀，非平坦几何，归纳 |'
- en: '| Mean-shift | Not scalable with `n_samples` | Many clusters, uneven cluster
    size, non-flat geometry, inductive |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| 均值漂移 | 无法与 `n_samples` 规模化 | 许多聚类，聚类大小不均匀，非平坦几何，归纳 |'
- en: '| Spectral clustering | Medium `n_samples`, small `n_clusters` | Few clusters,
    even cluster size, non-flat geometry, transductive |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 谱聚类 | 中等 `n_samples`，小型 `n_clusters` | 少数聚类，甚至聚类大小，非平坦几何，归纳 |'
- en: '| Ward hierarchical clustering | Large `n_samples` and `n_clusters` | Many
    clusters, possibly connectivity constraints, transductive |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '|  Ward 层次聚类 | 大型 `n_samples` 和 `n_clusters` | 许多聚类，可能存在连接约束，归纳 |'
- en: '| Agglomerative clustering | Large `n_samples` and `n_clusters` | Many clusters,
    possibly connectivity constraints, non-Euclidean distances, transductive |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 聚类 | 大型 `n_samples` 和 `n_clusters` | 许多聚类，可能存在连接约束，非欧几里得距离，归纳 |'
- en: '| DBSCAN | Very large `n_samples`, medium `n_clusters` | Non-flat geometry,
    uneven cluster sizes, transductive |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| DBSCAN | 非常大的 `n_samples`，中等的 `n_clusters` | 非平坦几何，聚类大小不均匀，归纳 |'
- en: '| OPTICS | Very large `n_samples`, large `n_clusters` | Non-flat geometry,
    uneven cluster sizes, variable cluster density, transductive |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| OPTICS | 非常大的 `n_samples`，大的 `n_clusters` | 非平坦几何，聚类大小不均匀，聚类密度可变，归纳 |'
- en: '| Gaussian mixtures | Not scalable | Flat geometry, good for density estimation,
    inductive |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 高斯混合模型 | 无法规模化 | 平坦几何，适合密度估计，归纳 |'
- en: '| BIRCH | Large `n_clusters` and `n_samples` | Large dataset, outlier removal,
    data reduction, inductive |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| BIRCH | 大型 `n_clusters` 和 `n_samples` | 大型数据集，异常值移除，数据降维，归纳 |'
- en: All of these methods have their own use cases and the scikit-learn documentation
    explains this much better than I could. In general, however, the K-Means algorithm,
    which we have also used in the previous chapter, is a very good starting point.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法都有它们自己的应用场景，scikit-learn 文档对此的解释比我所能说的要好得多。然而，总的来说，我们在上一章中也使用过的 K-Means
    算法是一个非常好的起点。
- en: Note that the clusters can also be used for learning features and the relationship
    between them. Once you have learned the features, you could use the feature selection
    in supervised learning to filter them for subselections.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，聚类也可以用于学习特征及其之间的关系。一旦您学习了特征，您就可以在监督学习中使用特征选择来过滤它们以进行子选择。
- en: To summarize, for the general machine learning cases, scikit-learn is probably
    your best bet. For special cases, there are often better libraries available;
    many of these are built on top of scikit-learn, however, so it is recommended
    that you familiarize yourself with the library if you plan to employ machine learning.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，对于一般的机器学习案例，scikit-learn 可能是您的最佳选择。对于特殊案例，通常有更好的库可用；其中许多是在 scikit-learn
    的基础上构建的，因此如果您计划使用机器学习，建议您熟悉这个库。
- en: auto-sklearn – Automatic scikit-learn
  id: totrans-395
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: auto-sklearn – 自动 scikit-learn
- en: The scikit-learn library can do so many things that it is often overwhelming
    to use. At the time of writing, there are 34 distinct regression functions and
    25 different classifiers, which can make it quite a challenge to select the right
    one for you.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 库能做很多事情，使用起来常常令人感到不知所措。在撰写本文时，有 34 个不同的回归函数和 25 种不同的分类器，这可能会使您选择正确的工具变得相当具有挑战性。
- en: This is where `auto-sklearn` can help. It can automatically select a classification
    function for you and fill in the parameters needed for it to work. If you’re just
    looking for something that just works, this is your best bet.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 `auto-sklearn` 可以帮助的地方。它可以自动为您选择一个分类函数，并填写它所需工作的参数。如果您只是寻找一个能直接使用的东西，这可能是您的最佳选择。
- en: mlxtend – Machine learning extensions
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: mlxtend – 机器学习扩展
- en: '`mlxtend` is a library with a range of relatively easy and well-documented
    machine learning examples.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlxtend` 是一个包含一系列相对简单且文档齐全的机器学习示例的库。'
- en: It uses `scikit-learn`, pandas, and `matplotlib` internally to provide a more
    user-friendly interface for machine learning compared to scikit-learn. If you
    are starting out with machine learning (or scikit-learn), this can be a nice introduction,
    since it’s a bit less complicated than using scikit-learn directly.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 它内部使用`scikit-learn`、`pandas`和`matplotlib`来提供比scikit-learn更用户友好的机器学习界面。如果你是机器学习（或scikit-learn）的初学者，这可以是一个很好的入门，因为它比直接使用scikit-learn要简单一些。
- en: scikit-lego – scikit-learn utilities
  id: totrans-401
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scikit-lego – scikit-learn 工具
- en: Even though scikit-learn already has a huge catalog of functions and features
    built in, there are still many things that it does not provide an easy interface
    for. This is where the scikit-lego library can help, it has many convenient functions
    for scikit-learn and pandas so you don’t need to repeat yourself too often.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管scikit-learn已经内置了一个庞大的函数和特性目录，但仍有许多事情它没有提供简单的接口。这就是scikit-lego库可以发挥作用的地方，它为scikit-learn和pandas提供了许多方便的函数，这样你就不需要经常重复自己。
- en: 'In the previous chapter, we used the Penguins dataset a few times. Loading
    that dataset and plotting the distribution can be done in just a few lines:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们多次使用了企鹅数据集。加载该数据集并绘制分布只需几行代码：
- en: '[PRE29]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This results in:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致：
- en: '![/var/folders/ph/3d51j84d2gg_pltczn6244q80000gn/T/com.microsoft.Word/Content.MSO/195F70F3.tmp](img/B15882_16_09.png)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15882_16_09.png)'
- en: 'Figure 16.9: Penguin distribution'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.9：企鹅分布
- en: scikit-lego can automatically perform some conversions for us (the `return_X_y`
    parameter here) so we can easily plot the results. There are many more of these
    functions available, which make it really easy to play around with Scikit-learn.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-lego可以自动为我们执行一些转换（这里的`return_X_y`参数），这样我们就可以轻松地绘制结果。还有许多其他这样的函数可用，这使得在Scikit-learn中玩耍变得非常容易。
- en: XGBoost – eXtreme Gradient Boosting
  id: totrans-409
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XGBoost – 极端梯度提升
- en: XGBoost is a fast and efficient library for gradient boosting, a regression/classification
    technique that produces forests of decision trees. The main advantage of this
    technique compared to many other regression/classification algorithms is the **scalability**.
    With XGBoost, you can easily spread your workload along clusters of many computers,
    and it happily scales to billions of data points.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost是一个用于梯度提升的快速高效库，梯度提升是一种产生决策树森林的回归/分类技术。与许多其他回归/分类算法相比，这种技术的优势在于**可扩展性**。使用XGBoost，你可以轻松地将你的工作负载分散到多台计算机的集群中，并且它能够扩展到数十亿的数据点。
- en: If you have very large datasets, XGBoost might be one of your best options.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你拥有非常大的数据集，XGBoost可能是你的最佳选择之一。
- en: Featuretools – Feature detection and prediction
  id: totrans-412
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Featuretools – 特征检测和预测
- en: The Featuretools library makes it really easy to transform your datasets into
    aggregated feature matrices based on either time-based datasets or relational
    ones. Once the feature matrix is constructed, the library can be used for predictions
    about these features.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: Featuretools库使得根据基于时间的数据集或关系型数据集将你的数据集转换为聚合特征矩阵变得非常容易。一旦特征矩阵构建完成，该库就可以用于对这些特征的预测。
- en: You could, for example, predict trip durations based on a collection of multiple
    trips, or predict when a customer will purchase from you again.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以根据多个行程的集合预测行程时长，或者预测客户何时会再次从你这里购买。
- en: Snorkel – Improving your ML data automatically
  id: totrans-415
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Snorkel – 自动改进你的机器学习数据
- en: Snorkel is a library that attempts to make the training of your ML models much
    easier. Getting enough training data to properly train your models can be really
    difficult, and this library has several clever methods to make this easier.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel是一个试图使你的机器学习模型训练变得更容易的库。获取足够的训练数据以正确训练你的模型可能非常困难，而这个库有几种巧妙的方法来简化这个过程。
- en: 'The library has three core operations to help you build your datasets:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 该库有三个核心操作来帮助你构建你的数据集：
- en: First, to help with labeling, the Snorkel library features several heuristic
    methods. While these labels will not be perfect, manually labeling all data can
    be a prohibitive task.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，为了帮助标注，Snorkel库提供了几种启发式方法。虽然这些标签可能不是完美的，但手动标注所有数据可能是一项繁重的任务。
- en: The second core operation is the transforming and augmenting of datasets. Once
    again, these use heuristic methods to (hopefully) improve your data quality.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个核心操作是对数据集进行转换和增强。再次强调，这些操作使用启发式方法（希望）来提高你的数据质量。
- en: The last core operation is the slicing of data so you only get data that is
    relevant for your use case. This operation is also heuristics-based.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后的核心操作是数据的切片，这样你只得到与你用例相关的数据。这个操作也是基于启发式的。
- en: You will not need this if you already have good-quality data available, but
    it is certainly worth looking at if your data could use some improvement. As is
    always the case with machine learning, care must be taken to avoid overfitting
    or underfitting data. Applying the Snorkel methods can quickly exacerbate problems
    in your dataset, since it uses the dataset as a source.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经有高质量的数据可用，你不需要这个，但如果你的数据需要一些改进，那么查看它肯定是有价值的。正如机器学习通常的情况一样，必须小心避免过拟合或欠拟合数据。应用Snorkel方法可能会迅速加剧你的数据集中的问题，因为它使用数据集作为来源。
- en: TPOT – Optimizing ML models using genetic programming
  id: totrans-422
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TPOT – 使用遗传编程优化机器学习模型
- en: TPOT (tea-pot) is a library that optimizes your learning pipelines through genetic
    programming. We already covered evolutionary algorithms earlier, but to remind
    you, they are algorithms that improve by changing themselves or their parameters
    through evolution.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: TPOT（茶壶）是一个通过遗传编程优化你的学习管道的库。我们之前已经讨论过进化算法，但为了提醒你，它们是通过进化改变自身或其参数来改进的算法。
- en: While genetic algorithms are relatively easy to implement by themselves, the
    complexity comes from the encoding of the solution so it is compatible with the
    genetic algorithm. This is what is very nice about the TPOT library; it makes
    it really easy to encode your features, cache parts of the pipeline, and even
    run the attempts in parallel using Dask.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管遗传算法本身相对容易实现，但复杂性来自于解决方案的编码，使其与遗传算法兼容。这正是TPOT库非常棒的地方；它使得编码你的特征、缓存管道的部分以及使用Dask并行运行尝试变得非常容易。
- en: 'To illustrate, here is the code needed to tell TPOT to automatically optimize
    a scikit-learn classifier with its parameters:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，以下是告诉TPOT自动优化scikit-learn分类器及其参数所需的代码：
- en: '[PRE30]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Once it is done trying multiple classifiers, it will write the optimized function
    calls to `optimized_classifier.py`. It is important to note that the classifier
    returned is also dependent on the optimizer results; it could be `sklearn.neighbors.KNeighborsClassifier`,
    but you could also get `sklearn.ensemble.RandomForestClassifier` or something
    else.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦尝试了多个分类器，它将把优化的函数调用写入`optimized_classifier.py`。重要的是要注意，返回的分类器也取决于优化器的结果；它可能是`sklearn.neighbors.KNeighborsClassifier`，但你也可能得到`sklearn.ensemble.RandomForestClassifier`或其他。
- en: Do not assume that `TPOT` is a fast solution for finding your parameters, though;
    getting a good solution using genetic algorithms can take a long time, and it
    can be beneficial to reduce your test set before you apply this algorithm.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 不要假设`TPOT`是寻找参数的快速解决方案；使用遗传算法得到一个好的解决方案可能需要很长时间，在你应用这个算法之前减少你的测试集可能是有益的。
- en: That was the last library, and it’s time to try things out for yourself in the
    *Exercises* section.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 那是最后一个库，现在是时候在*练习*部分尝试自己动手操作了。
- en: Exercises
  id: totrans-430
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Due to the nature of this chapter, all topics only cover the absolute basics
    of the mentioned libraries and they really do deserve much more. In this case,
    as an exercise, I recommend that you try and use some (or all) of the mentioned
    libraries and see if you can do something useful with them.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本章的性质，所有主题仅涵盖所提及库的绝对基础知识，它们确实值得更多。在这种情况下，作为一个练习，我建议你尝试使用一些（或全部）所提及的库，看看你是否可以用它们做一些有用的事情。
- en: 'Some suggestions:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 一些建议：
- en: Browse through TensorFlow Hub and apply some models to your own data. Perhaps
    you can apply object detection to your holiday photos.
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浏览TensorFlow Hub，并将一些模型应用于你自己的数据。也许你可以将目标检测应用于你的假日照片。
- en: After applying a model to your photos, try and improve the model by adding some
    new objects and finetuning it.
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在将模型应用于你的照片后，尝试通过添加一些新对象和微调来改进模型。
- en: Try to extract some data or information from this chapter’s summary by applying
    one of the NLP algorithms.
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试通过应用本章摘要中的一个NLP算法来从本章中提取一些数据或信息。
- en: AI is a complicated subject, and even simple example guides are often quite
    elaborate. Luckily, these days we can often immediately try examples online through
    Google Colab or by running a Jupyter Notebook. Dive in and don’t get discouraged;
    there is an incredible amount of high-quality information available online from
    field experts.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能是一个复杂的话题，即使是简单的示例指南也往往相当复杂。幸运的是，如今我们通常可以通过Google Colab或运行Jupyter Notebook立即在线尝试示例。大胆尝试，不要气馁；来自领域专家的优质信息量非常庞大。
- en: 'Example answers for these exercises can be found on GitHub: [https://github.com/mastering-python/exercises](Chapter_16.xhtml).
    You are encouraged to submit your own solutions and learn about alternative solutions
    from others.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习的示例答案可以在GitHub上找到：[https://github.com/mastering-python/exercises](Chapter_16.xhtml)。鼓励您提交自己的解决方案，并从他人的替代方案中学习。
- en: Summary
  id: totrans-438
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter gave you a sample of some of the largest and most popular Python
    AI libraries, but there are many more (large) libraries around that could be useful
    for your particular use case. There are, for example, also many libraries available
    for specific topics such as astronomy, geographical information systems (GISes),
    protein folding, and neurological imaging.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 本章为您展示了某些最大和最受欢迎的Python人工智能库的示例，但还有许多（大型）库可用于您特定的用例。例如，还有许多库可用于特定主题，如天文学、地理信息系统（GISes）、蛋白质折叠和神经影像学。
- en: After this chapter, you should have some idea of where to start searching for
    particular types of AI libraries. Additionally, you should know a little bit about
    when to apply a particular type of AI. For many use cases, you will need a combination
    of these methods to solve the problem in an efficient manner. A supervised ML
    system, for example, is a fantastic option if you have a vast amount of good-quality,
    labeled data. Often this is not the case, which is where the other algorithms
    come in.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章之后，您应该对在哪里开始搜索特定类型的AI库有所了解。此外，您应该对何时应用特定类型的AI有所了解。对于许多用例，您可能需要结合这些方法以高效的方式解决问题。例如，如果您拥有大量高质量、标记好的数据，监督式机器学习系统是一个绝佳的选择。通常情况下并非如此，这时其他算法就派上用场了。
- en: Surprisingly enough, many of the current “AI” start-up companies don’t actually
    use AI for their recommendation systems but humans instead, hoping to upgrade
    to an effective AI somewhere in the future when they have gathered enough training
    data. Effectively, they are trying to solve the data requirement for supervised
    ML systems with brute force. Similarly, algorithms are only part of the reason
    that voice recognition systems such as Alexa, Google Assistant, or Siri have become
    possible. Another large part is the availability of training data over the last
    several years. Naturally, these systems are not built on one algorithm specifically
    but use a combination of multiple algorithms; the system not only tries to convert
    your voice to words, but also attempts to understand what you are likely to say
    by constantly cross-validating those results with what would be a logical sentence
    structure.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，许多当前的“人工智能”初创公司实际上并没有使用人工智能来构建他们的推荐系统，而是使用人类，希望在未来某个时候，当他们收集到足够的训练数据时，能够升级到一个有效的AI。实际上，他们正在试图用蛮力解决监督式机器学习系统的数据需求。同样，算法只是语音识别系统（如Alexa、Google
    Assistant或Siri）成为可能的部分原因。另一个重要部分是过去几年训练数据的可获得性。自然地，这些系统不是基于一个特定的算法构建的，而是使用多个算法的组合；系统不仅试图将您的语音转换为文字，而且还试图通过不断交叉验证这些结果与逻辑句子结构，来理解您可能要说的话。
- en: The field of AI is improving and changing more rapidly with each year. With
    the increased processing power we have now, there are many more options than we
    had in the past. The currently used deep learning AI models were completely infeasible
    to build only 20 years ago, and in 10 years’ time the models will have far surpassed
    what is possible now. If there is no solution available for the issue you are
    facing today, the situation might be completely different a year from now.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 随着每年技术的进步和变化，人工智能领域也在快速发展。现在我们拥有的处理能力比过去有了更多选择。目前使用的深度学习人工智能模型在20年前是完全不可行的，而在10年后，模型将远远超出现在的可能性。如果您今天面临的问题没有解决方案，一年后的情况可能会有完全不同的变化。
- en: It is also perfectly reasonable to skip this part of Python entirely. While
    AI is becoming a larger and larger portion of what is being done with Python,
    a big part of that is in academic settings and might not be interesting for your
    field of work. AI can be a great help, but it is often a much more complicated
    solution than is actually needed.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 完全跳过 Python 的这部分内容也是完全可以理解的。虽然 AI 正在成为 Python 所做事情中越来越大的部分，但其中很大一部分是在学术环境中进行的，可能对你的工作领域不感兴趣。AI
    可以提供巨大的帮助，但它通常是一个比实际需要的更复杂的解决方案。
- en: In the next chapter, we will learn about creating extensions in C/C++ to increase
    performance and allow low-level access to memory and other hardware resources.
    While this can greatly help with performance, performance rarely comes free, as
    we will see.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何在 C/C++ 中创建扩展来提高性能并允许对内存和其他硬件资源的低级访问。虽然这可以大大提高性能，但正如我们将看到的，性能很少是免费的。
- en: Join our community on Discord
  id: totrans-445
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers: [https://discord.gg/QMzJenHuJf](https://discord.gg/QMzJenHuJf)'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 空间，与作者和其他读者进行讨论：[https://discord.gg/QMzJenHuJf](https://discord.gg/QMzJenHuJf)
- en: '![](img/QR_Code156081100001293319171.png)'
  id: totrans-447
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code156081100001293319171.png)'
