- en: Pure Python Optimizations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 纯Python优化
- en: As mentioned in the last chapter, one of the most effective ways of improving
    the performance of applications is through the use of better algorithms and data
    structures. The Python standard library provides a large variety of ready-to-use
    algorithms and data structures that can be directly incorporated in your applications.
    With the tools learned from this chapter, you will be able to use the right algorithm
    for the task and achieve massive speed gains.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如上章所述，提高应用程序性能的最有效方法之一是通过使用更好的算法和数据结构。Python标准库提供了一系列可直接集成到您应用程序中的现成算法和数据结构。通过本章学到的工具，您将能够使用适合任务的正确算法并实现巨大的速度提升。
- en: Even though many algorithms have been around for quite a while, they are especially
    relevant in today's world as we continuously produce, consume, and analyze ever
    increasing amounts of data. Buying a larger server or microoptimizing can work
    for some time, but achieving better scaling through algorithmic improvement can
    solve the problem once and for all.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多算法已经存在了很长时间，但它们在当今世界尤其相关，因为我们不断地生产、消费和分析越来越多的数据。购买更大的服务器或进行微优化可能暂时有效，但通过算法改进实现更好的扩展可以一劳永逸地解决问题。
- en: In this chapter, we will understand how to achieve better scaling using standard
    algorithms and data structures. More advanced use cases will also be covered by
    taking advantage of third-party libraries. We will also learn about tools to implement
    caching, a technique used to achieve faster response times by sacrificing some
    space on memory or on disk.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将了解如何使用标准算法和数据结构实现更好的扩展。通过利用第三方库，我们还将涵盖更高级的使用案例。我们还将学习有关实现缓存的工具，这是一种通过在内存或磁盘上牺牲一些空间来提高响应时间的技巧。
- en: 'The list of topics to be covered in this chapter is as follows:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖的主题列表如下：
- en: Introduction to computational complexity
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算复杂性简介
- en: Lists and deques
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表和双端队列
- en: Dictionaries
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字典
- en: How to build an inverted index using a dictionary
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用字典构建倒排索引
- en: Sets
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集合
- en: Heaps and priority queues
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆和优先队列
- en: Implementing autocompletion using tries
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用字典实现自动补全
- en: Introduction to caching
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存简介
- en: In-memory caching with the `functools.lru_cache` decorator
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `functools.lru_cache` 装饰器的内存缓存
- en: On-disk cache with `joblib.Memory`
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `joblib.Memory` 的磁盘缓存
- en: Fast and memory-efficient loops with comprehensions and generators
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成器和推导式实现快速且内存高效的循环
- en: Useful algorithms and data structures
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有用的算法和数据结构
- en: Algorithmic improvements are especially effective in increasing performance
    because they typically allow the application to scale better with increasingly
    large inputs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 算法改进在提高性能方面特别有效，因为它们通常允许应用程序在输入越来越大时更好地扩展。
- en: Algorithm running times can be classified according to their computational complexity,
    a characterization of the resources required to perform a task. Such classification
    is expressed through the Big-O notation, an upper bound on the operations required
    to execute the task, which usually depends on the input size.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 算法运行时间可以根据其计算复杂度进行分类，这是对执行任务所需资源的描述。这种分类通过大O符号表示，它是执行任务所需操作的上限，这通常取决于输入大小。
- en: 'For example, incrementing each element of a list can be implemented using a
    `for` loop, as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，可以使用 `for` 循环实现列表中每个元素的递增，如下所示：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If the operation does not depend on the size of the input (for example, accessing
    the first element of a list), the algorithm is said to take constant, or *O*(1),
    time. This means that, no matter how much data we have, the time to run the algorithm
    will always be the same.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果操作不依赖于输入的大小（例如，访问列表的第一个元素），则该算法被认为是常数时间，或 *O*(1) 时间。这意味着，无论我们有多少数据，运行算法的时间始终是相同的。
- en: In this simple algorithm, the `input[i] += 1` operation will be repeated 10
    times, which is the size of the input. If we double the size of the input array,
    the number of operations will increase proportionally. Since the number of operations
    is proportional to the input size, this algorithm is said to take *O*(*N*) time,
    where *N* is the size of the input array.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的算法中，`input[i] += 1` 操作将重复10次，这是输入的大小。如果我们加倍输入数组的大小，操作的数量将成比例增加。由于操作的数量与输入大小成正比，因此该算法被认为是
    *O*(*N*) 时间，其中 *N* 是输入数组的大小。
- en: In some instances, the running time may depend on the structure of the input
    (for example, if the collection is sorted or contains many duplicates). In these
    cases, an algorithm may have different best-case, average-case, and worst-case
    running times. Unless stated otherwise, the running times presented in this chapter
    are considered to be average running times.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，运行时间可能取决于输入的结构（例如，如果集合已排序或包含许多重复项）。在这些情况下，算法可能具有不同的最佳、平均和最坏情况运行时间。除非另有说明，本章中提供的运行时间被认为是平均运行时间。
- en: In this section, we will examine the running times of the main algorithms and
    data structures that are implemented in the Python standard library, and understand
    how improving running times results in massive gains and allows us to solve large-scale
    problems with elegance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将检查 Python 标准库中实现的主要算法和数据结构的运行时间，并了解提高运行时间如何带来巨大的收益，并使我们能够以优雅的方式解决大规模问题。
- en: You can find the code used to run the benchmarks in this chapter in the `Algorithms.ipynb` notebook,
    which can be opened using Jupyter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 `Algorithms.ipynb` 笔记本中找到本章中使用的基准测试代码，该笔记本可以使用 Jupyter 打开。
- en: Lists and deques
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列表和双端队列
- en: Python lists are ordered collections of elements and, in Python, are implemented
    as resizable arrays. An array is a basic data structure that consists of a series
    of contiguous memory locations, and each location contains a reference to a Python
    object.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Python 列表是有序元素集合，在 Python 中实现为可调整大小的数组。数组是一种基本的数据结构，由一系列连续的内存位置组成，每个位置包含对 Python
    对象的引用。
- en: Lists shine in accessing, modifying, and appending elements. Accessing or modifying
    an element involves fetching the object reference from the appropriate position
    of the underlying array and has complexity *O*(1). Appending an element is also
    very fast. When an empty list is created, an array of fixed size is allocated
    and, as we insert elements, the slots in the array are gradually filled up. Once
    all the slots are occupied, the list needs to increase the size of its underlying
    array, thus triggering a memory reallocation that can take *O*(*N*) time. Nevertheless,
    those memory allocations are infrequent, and the time complexity for the append
    operation is referred to as amortized O(1) time.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 列表在访问、修改和追加元素方面表现出色。访问或修改一个元素涉及从底层数组的适当位置获取对象引用，其复杂度为 *O*(1)。追加一个元素也非常快。当创建一个空列表时，会分配一个固定大小的数组，并且随着我们插入元素，数组中的槽位逐渐被填满。一旦所有槽位都被占用，列表需要增加其底层数组的大小，从而触发可能需要
    *O*(*N*) 时间的内存重新分配。尽管如此，这些内存分配并不频繁，追加操作的复杂度被称为摊销的 *O*(1) 时间。
- en: The list operations that may have efficiency problems are those that add or
    remove elements at the beginning (or somewhere in the middle) of the list. When
    an item is inserted, or removed, from the beginning of a list, all the subsequent
    elements of the array need to be shifted by a position, thus taking *O*(*N*) time.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 可能存在效率问题的列表操作是在列表的开始（或中间某处）添加或删除元素。当从列表的开始插入或删除一个项目时，数组中所有后续元素都需要移动一个位置，因此需要
    *O*(*N*) 的时间。
- en: 'In the following table, the timings for different operations on a list of size
    10,000 are shown; you can see how insertion and removal performances vary quite
    dramatically if performed at the beginning or at the end of the list:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下表中，展示了大小为 10,000 的列表上不同操作的计时；您可以看到，如果是在列表的开始或末尾执行插入和删除操作，性能会有相当大的差异：
- en: '| **Code** | ****N=10000 (******µs)** | ****N=20000 (******µs)** | ****N=30000
    (******µs)** | ****Time**** |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| **代码** | ****N=10000 (******µs)** | ****N=20000 (******µs)** | ****N=30000
    (******µs)** | ****时间**** |'
- en: '| `list.pop()` | 0.50 | 0.59 | 0.58 | *O*(1) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| `list.pop()` | 0.50 | 0.59 | 0.58 | *O*(1) |'
- en: '| `list.pop(0)` | 4.20 | 8.36 | 12.09 | *O*(*N*) |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `list.pop(0)` | 4.20 | 8.36 | 12.09 | *O*(*N*) |'
- en: '| `list.append(1)` | 0.43 | 0.45 | 0.46 | *O*(1) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `list.append(1)` | 0.43 | 0.45 | 0.46 | *O*(1) |'
- en: '| `list.insert(0, 1)` | 6.20 | 11.97 | 17.41 | *O*(*N*) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `list.insert(0, 1)` | 6.20 | 11.97 | 17.41 | *O*(*N*) |'
- en: In some cases, it is necessary to efficiently perform insertion or removal of
    elements both at the beginning and at the end of the collection. Python provides
    a data structure with those properties in the `collections.deque` class. The word
    **deque** stands for double-ended queue because this data structure is designed
    to efficiently put and remove elements at the beginning and at the end of the
    collection, as it is in the case of queues. In Python, deques are implemented
    as doubly-linked lists.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，需要在集合的开始和结束处有效地执行元素的插入或删除。Python 在 `collections.deque` 类中提供了一个具有这些属性的数据结构。单词
    **deque** 代表双端队列，因为这种数据结构被设计成在集合的开始和结束处高效地添加和删除元素，就像队列一样。在 Python 中，双端队列被实现为双链表。
- en: 'Deques, in addition to `pop` and `append`, expose the `popleft` and `appendleft` methods that
    have *O*(1) running time:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `pop` 和 `append`，双端队列还公开了 `popleft` 和 `appendleft` 方法，这些方法具有 *O*(1) 运行时间：
- en: '| **Code** | ****N=10000 (******µs)** | ****N=20000 (******µs)** | ****N=30000
    (******µs)** | ****Time**** |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| **代码** | ****N=10000 (******µs)** | ****N=20000 (******µs)** | ****N=30000
    (******µs)** | ****时间**** |'
- en: '| `deque.pop()` | 0.41 | 0.47 | 0.51 | *O*(1) |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| `deque.pop()` | 0.41 | 0.47 | 0.51 | *O*(1) |'
- en: '| `deque.popleft()` | 0.39 | 0.51 | 0.47 | *O*(1) |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| `deque.popleft()` | 0.39 | 0.51 | 0.47 | *O*(1) |'
- en: '| `deque.append(1)` | 0.42 | 0.48 | 0.50 | *O*(1) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| `deque.append(1)` | 0.42 | 0.48 | 0.50 | *O*(1) |'
- en: '| `deque.appendleft(1)` | 0.38 | 0.47 | 0.51 | *O*(1) |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `deque.appendleft(1)` | 0.38 | 0.47 | 0.51 | *O*(1) |'
- en: 'Despite these advantages, deques should not be used to replace regular lists
    in most cases. The efficiency gained by the `appendleft` and `popleft` operations
    comes at a cost: accessing an element in the middle of a deque is a O(N) operation,
    as shown in the following table:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这些优点，但在大多数情况下不应使用双端队列来替换常规列表。`appendleft` 和 `popleft` 操作获得的效率是以代价为代价的：在双端队列中间访问一个元素是一个
    O(N) 操作，如下表所示：
- en: '| **Code** | ****N=10000 (******µs)** | ****N=20000 (******µs)** | ****N=30000
    (******µs)** | ****Time**** |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| **代码** | ****N=10000 (******µs)** | ****N=20000 (******µs)** | ****N=30000
    (******µs)** | ****时间**** |'
- en: '| `deque[0]` | 0.37 | 0.41 | 0.45 | *O*(1) |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `deque[0]` | 0.37 | 0.41 | 0.45 | *O*(1) |'
- en: '| `deque[N -  1]` | 0.37 | 0.42 | 0.43 | *O*(1) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `deque[N -  1]` | 0.37 | 0.42 | 0.43 | *O*(1) |'
- en: '| `deque[int(N / 2)]` | 1.14 | 1.71 | 2.48 | *O*(N) |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| `deque[int(N / 2)]` | 1.14 | 1.71 | 2.48 | *O*(N) |'
- en: Searching for an item in a list is generally a *O*(*N*) operation and is performed
    using the `list.index` method. A simple way to speed up searches in lists is to
    keep the array sorted and perform a binary search using the `bisect` module.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表中搜索一个项目通常是一个 *O*(*N*) 操作，并且使用 `list.index` 方法执行。加快列表中搜索的一种简单方法是将数组排序并使用 `bisect`
    模块进行二分搜索。
- en: 'The `bisect` module allows fast searches on sorted arrays. The `bisect.bisect`
    function can be used on a sorted list to find the index to place an element while
    maintaining the array in sorted order. In the following example, we can see that
    if we want to insert the `3` element in the array while keeping `collection` in
    sorted order, we should put `3` in the third position (which corresponds to index
    2):'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`bisect` 模块允许在排序数组上进行快速搜索。`bisect.bisect` 函数可以用于排序列表，以找到放置元素的位置，同时保持数组排序。在以下示例中，我们可以看到，如果我们想在保持
    `collection` 排序顺序的情况下将 `3` 元素插入数组，我们应该将 `3` 放在第三个位置（对应索引 2）：'
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This function uses the binary search algorithm that has *O*(*log*(*N*)) running
    time. Such a running time is exceptionally fast, and basically means that your
    running time will increase by a constant amount every time you *double* your input
    size. This means that if, for example, your program takes `1` second to run on
    an input of size `1000`, it will take `2` seconds to process an input of size
    `2000`, `3` seconds to process an input of size `4000`, and so on. If you had
    `100` seconds, you could theoretically process an input of size `10^(33)`, which
    is larger than the number of atoms in your body!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数使用具有 *O*(*log*(*N*)) 运行时间的二分搜索算法。这样的运行时间非常快，基本上意味着每次你 *加倍* 输入大小时，运行时间将增加一个常数。这意味着，例如，如果你的程序在大小为
    `1000` 的输入上运行需要 `1` 秒，那么处理大小为 `2000` 的输入将需要 `2` 秒，处理大小为 `4000` 的输入将需要 `3` 秒，依此类推。如果你有
    `100` 秒，理论上可以处理大小为 `10^(33)` 的输入，这比你体内的原子数量还要大！
- en: 'If the value we are trying to insert is already present in the list, the `bisect.bisect`
    function will return the location *after* the already present value.  Therefore,
    we can use the `bisect.bisect_left` variant, which returns the correct index in
    the following way (taken from the module documentation at [https://docs.python.org/3.5/library/bisect.html](https://docs.python.org/3.5/library/bisect.html)):'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们试图插入的值已经在列表中存在，`bisect.bisect` 函数将返回已存在值之后的定位。因此，我们可以使用 `bisect.bisect_left`
    变体，它以以下方式返回正确的索引（摘自模块文档[https://docs.python.org/3.5/library/bisect.html](https://docs.python.org/3.5/library/bisect.html)）：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the following table, you can see how the running time of the `bisect` solution
    is barely affected at these input sizes, making it a suitable solution when searching
    through very large collections:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的表格中，你可以看到 `bisect` 解决方案的运行时间在这些输入大小下几乎不受影响，使其成为在非常大型集合中搜索时的合适解决方案：
- en: '| **Code** | **N=10000 (****µs)** | **N=20000 (****µs)** | **N=30000 (****µs)**
    | **Time** |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| **代码** | **N=10000 (****µs)** | **N=20000 (****µs)** | **N=30000 (****µs)**
    | **时间** |'
- en: '| `list.index(a)` | 87.55 | 171.06 | 263.17 | *O*(N) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| `list.index(a)` | 87.55 | 171.06 | 263.17 | *O*(N) |'
- en: '| `index_bisect(list, a)` | 3.16 | 3.20 | 4.71 | *O*(log(N)) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| `index_bisect(list, a)` | 3.16 | 3.20 | 4.71 | *O*(log(N)) |'
- en: Dictionaries
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字典
- en: Dictionaries are extremely versatile and extensively used in the Python language.
    Dictionaries are implemented as hash maps and are very good at element insertion,
    deletion, and access; all these operations have an average *O*(1) time complexity.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 字典在 Python 语言中非常灵活，并且被广泛使用。字典作为哈希表实现，非常擅长元素插入、删除和访问；所有这些操作的平均时间复杂度都是 *O*(1)。
- en: In Python versions up to 3.5, dictionaries are unordered collections. Since
    Python 3.6, dictionaries are capable of maintaining their elements by order of
    insertion.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 3.5 版本之前，字典是无序集合。从 Python 3.6 版本开始，字典能够根据插入顺序维护其元素。
- en: 'A hash map is a data structure that associates a set of key-value pairs. The
    principle behind hash maps is to assign a specific index to each key so that its
    associated value can be stored in an array. The index can be obtained through
    the use of a `hash` function; Python implements hash functions for several data
    types. As a demonstration, the generic function to obtain hash codes is `hash`.
    In the following example, we show you how to obtain the hash code given the `"hello"` string:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希表是一种将一组键值对关联起来的数据结构。哈希表背后的原理是为每个键分配一个特定的索引，以便其关联的值可以存储在数组中。索引可以通过使用 `hash`
    函数获得；Python 为几种数据类型实现了哈希函数。作为演示，获取哈希码的通用函数是 `hash`。在以下示例中，我们展示了如何为 `"hello"` 字符串获取哈希码：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Hash maps can be tricky to implement because they need to handle collisions
    that happen when two different objects have the same hash code. However, all the
    complexity is elegantly hidden behind the implementation and the default collision
    resolution works well in most real-world scenarios.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希表的实现可能有些棘手，因为它们需要处理两个不同对象具有相同哈希码时发生的冲突。然而，所有复杂性都被优雅地隐藏在实现背后，并且默认的冲突解决机制在大多数实际场景中工作得很好。
- en: Access, insertion, and removal of an item in a dictionary scales as *O*(1) with
    the size of the dictionary. However, note that the computation of the hash function
    still needs to happen and, for strings, the computation scales with the length
    of the string. As string keys are usually relatively small, this doesn't constitute
    a problem in practice.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 字典中一个元素的访问、插入和删除操作的时间复杂度与字典的大小成 *O*(1) 比例。然而，请注意，哈希函数的计算仍然需要发生，对于字符串，计算复杂度与字符串长度成正比。由于字符串键通常相对较小，这在实际中并不构成问题。
- en: 'A dictionary can be used to efficiently count unique elements in a list. In
    this example, we define the `counter_dict` function that takes a list and returns
    a dictionary containing the number of occurrences of each value in the list:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 字典可以用来高效地计算列表中唯一元素的数量。在这个例子中，我们定义了 `counter_dict` 函数，它接受一个列表并返回一个包含列表中每个值出现次数的字典：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The code can be somewhat simplified using `collections.defaultdict`, which
    can be used to produce dictionaries where each new key is automatically assigned
    a default value. In the following code, the `defaultdict(int)` call produces a
    dictionary where every new element is automatically assigned a zero value, and
    can be used to streamline the counting:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `collections.defaultdict` 可以在一定程度上简化代码，该工具可以用来生成字典，其中每个新的键都会自动分配一个默认值。在下面的代码中，`defaultdict(int)`
    调用生成一个字典，其中每个新元素都会自动分配一个零值，并可用于简化计数：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `collections` module also includes a `Counter` class that can be used for
    the same purpose with a single line of code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`collections`模块还包括一个`Counter`类，可以单行代码实现相同的目的：'
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Speed-wise, all these ways of counting have the same time complexity, but the
    `Counter` implementation is the most efficient, as shown in the following table:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在速度方面，所有这些计数方法都具有相同的时间复杂度，但`Counter`实现是最有效的，如下表所示：
- en: '| **Code** | **N=1000 (****µs)** | **N=2000 (****µs)** | **N=3000 (****µs)**
    | **Time** |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| **代码** | **N=1000 (****µs)** | **N=2000 (****µs)** | **N=3000 (****µs)**
    | **时间** |'
- en: '| `Counter(items)` | 51.48 | 96.63 | 140.26 | *O*(N) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| `Counter(items)` | 51.48 | 96.63 | 140.26 | *O*(N) |'
- en: '| `counter_dict(items)` | 111.96 | 197.13 | 282.79 | *O*(N) |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| `counter_dict(items)` | 111.96 | 197.13 | 282.79 | *O*(N) |'
- en: '| `counter_defaultdict(items)` | 120.90 | 238.27 | 359.60 | *O*(N) |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| `counter_defaultdict(items)` | 120.90 | 238.27 | 359.60 | *O*(N) |'
- en: Building an in-memory search index using a hash map
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用哈希表构建内存搜索索引
- en: 'Dictionaries can be used to quickly search for a word in a list of documents,
    similar to a search engine. In this subsection, we will learn how to build an
    inverted index based on a dictionary of lists. Let''s say we have a collection
    of four documents:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 字典可以用来快速在文档列表中搜索一个单词，类似于搜索引擎。在本小节中，我们将学习如何根据列表字典构建倒排索引。假设我们有一个包含四个文档的集合：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'A simple way to retrieve all the documents that match a query is to scan each
    document and test for the presence of a word. For example, if we want to look
    up the documents where the word `table` appears, we can employ the following filtering
    operation:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 获取与查询匹配的所有文档的一个简单方法是扫描每个文档并测试单词的存在。例如，如果我们想查找包含单词`table`的文档，我们可以使用以下过滤操作：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This approach is simple and works well when we have one-off queries; however,
    if we need to query the collection very often, it can be beneficial to optimize
    querying time. Since the per-query cost of the linear scan is *O*(*N*), you can
    imagine that a better scaling will allow us to handle much larger document collections.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法简单且在处理一次性查询时效果良好；然而，如果我们需要频繁查询集合，优化查询时间可能是有益的。由于线性扫描的每次查询成本为*O*(N)，你可以想象更好的扩展性将使我们能够处理更大的文档集合。
- en: A better strategy is to spend some time preprocessing the documents so that
    they are easier to find at query time. We can build a structure, called the **inverted
    index**, that associates each word in our collection with the list of documents
    where that word is present. In our earlier example, the word `"table"` will be
    associated to the `"the cat is under the table"` and `"the dog is under the table"` documents;
    they correspond to indices `0` and `1`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的策略是花些时间预处理文档，以便在查询时更容易找到。我们可以构建一个称为**倒排索引**的结构，将我们集合中的每个单词与包含该单词的文档列表关联起来。在我们之前的例子中，单词`"table"`将与`"the
    cat is under the table"`和`"the dog is under the table"`文档相关联；它们对应于索引`0`和`1`。
- en: 'Such a mapping can be implemented by going over our collection of documents
    and storing in a dictionary the index of the documents where that term appears.
    The implementation is similar to the `counter_dict` function, except that, instead
    of accumulating a counter, we are growing the list of documents that match the
    current term:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种映射可以通过遍历我们的文档集合，并在字典中存储该术语出现的文档索引来实现。实现方式与`counter_dict`函数类似，但不同之处在于，我们不是累积计数器，而是在匹配当前术语的文档列表中增长：
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once we have built our index, doing a query involves a simple dictionary lookup.
    For example, if we want to return all the documents containing the term table,
    we can simply query the index, and retrieve the corresponding documents:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们构建了索引，查询就涉及简单的字典查找。例如，如果我们想返回包含术语`table`的所有文档，我们只需查询索引，并检索相应的文档：
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Since all it takes to query our collection is a dictionary access, the index
    can handle queries with time complexity *O*(1)! Thanks to the inverted index,
    we are now able to query any number of documents (as long as they fit in memory)
    in constant time. Needless to say, indexing is a technique widely used to quickly
    retrieve data not only in search engines, but also in databases and any system
    that requires fast searches.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 由于查询我们的集合只需要字典访问，该索引可以处理时间复杂度为*O*(1)的查询！多亏了倒排索引，我们现在能够以恒定时间查询任意数量的文档（只要它们适合内存）。不用说，索引是一种广泛用于快速检索数据的技术，不仅用于搜索引擎，还用于数据库和任何需要快速搜索的系统。
- en: Note that building an inverted index is an expensive operation and requires
    you to encode every possible query. This is a substantial drawback, but the benefits
    are great and it may be worthwhile to pay the price in terms of decreased flexibility.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，构建倒排索引是一个昂贵的操作，需要你编码每个可能的查询。这是一个重大的缺点，但好处很大，可能值得为了减少灵活性而付出代价。
- en: Sets
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集合
- en: Sets are unordered collections of elements, with the additional restriction
    that the elements must be unique.  The main use-cases where sets are a good choice
    are membership tests (testing if an element is present in the collection) and,
    unsurprisingly, set operations such as union, difference, and intersection.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 集合是无序的元素集合，还有一个额外的限制，即元素必须是唯一的。集合是很好的选择的主要用例包括成员测试（测试元素是否存在于集合中）以及，不出所料，并集、差集和交集等集合操作。
- en: In Python, sets are implemented using a hash-based algorithm just like dictionaries;
    therefore, the time complexities for addition, deletion, and test for membership
    scale as *O*(1) with the size of the collection.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，集合使用与字典相同的哈希算法实现；因此，添加、删除和测试成员资格的时间复杂度与集合的大小成 *O*(1) 比例。
- en: 'Sets contain only unique elements. An immediate use case of sets is the removal
    of duplicates from a collection, which can be accomplished by simply passing the
    collection through the `set` constructor, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 集合只包含唯一元素。集合的一个直接用途是从集合中删除重复项，可以通过简单地通过 `set` 构造函数传递集合来实现，如下所示：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The time complexity for removing duplicates is *O*(*N*), as it requires to read
    the input and put each element in the set.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 删除重复项的时间复杂度为 *O*(*N*)，因为它需要读取输入并将每个元素放入集合中。
- en: 'Sets expose a number of operations like union, intersection, and difference.
    The union of two sets is a new set containing all the elements of both the sets;
    the intersection is a new set that contains only the elements in common between
    the two sets, and the difference is a new set containing the element of the first
    set that are not contained in the second set. The time complexities for these
    operations are shown in the following table. Note that since we have two different
    input sizes, we will use the letter S to indicate the size of the first set (called
    `s`), and T to indicate the size of the second set (called `t`):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 集合暴露出许多操作，如并集、交集和差集。两个集合的并集是一个新集合，包含两个集合的所有元素；交集是一个新集合，只包含两个集合共有的元素，差集是一个新集合，包含第一个集合中不包含在第二个集合中的元素。以下表格显示了这些操作的时间复杂度。请注意，由于我们有两个不同的输入大小，我们将使用字母
    S 来表示第一个集合的大小（称为 `s`），使用 T 来表示第二个集合的大小（称为 `t`）：
- en: '| **Code** | **Time** |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| **代码** | **时间** |'
- en: '| `s.union(t)` | *O*(*S* + *T*) |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| `s.union(t)` | *O*(*S* + *T*) |'
- en: '| `s.intersection(t)` | *O*(*min*(*S*, *T*)) |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `s.intersection(t)` | *O*(*min*(*S*, *T*)) |'
- en: '| `s.difference(t)` | *O*(*S*) |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `s.difference(t)` | *O*(*S*) |'
- en: An application of set operations are, for example, Boolean queries. Going back
    to the inverted index example of the previous subsection, we may want to support
    queries that include multiple terms. For example, we may want to search for all
    the documents that contain the words `cat` and `table`. This kind of a query can
    be efficiently computed by taking the intersection between the set of documents
    containing `cat` and the set of documents containing `table`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 集合操作的一个应用示例是布尔查询。回到前一小节中倒排索引的例子，我们可能希望支持包含多个术语的查询。例如，我们可能希望搜索包含单词 `cat` 和 `table`
    的所有文档。这种查询可以通过计算包含 `cat` 的文档集合与包含 `table` 的文档集合的交集来有效地计算。
- en: 'In order to efficiently support those operations, we can change our indexing
    code so that each term is associated to a set of documents (rather than a list).
    After applying this change, calculating more advanced queries is a matter of applying
    the right set operation. In the following code, we show the inverted index based
    on sets and the query using set operations:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地支持这些操作，我们可以更改我们的索引代码，使得每个术语都与一组文档相关联（而不是列表）。在应用此更改后，计算更高级的查询只需应用正确的集合操作。在以下代码中，我们展示了基于集合的倒排索引和使用了集合操作的查询：
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Heaps
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 堆
- en: Heaps are data structures designed to quickly find and extract the maximum (or
    minimum) value in a collection. A typical use-case for heaps is to process a series
    of incoming tasks in order of maximum priority.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 堆是一种数据结构，旨在快速查找和提取集合中的最大（或最小）值。堆的一个典型用途是按最大优先级顺序处理一系列传入的任务。
- en: One can theoretically use a sorted list using the tools in the `bisect` module;
    however, while extracting the maximum value will take *O*(1) time (using `list.pop`),
    insertion will still take *O*(N) time (remember that, even if finding the insertion
    point takes *O*(*log*(*N*)) time, inserting an element in the middle of a list
    is still a *O*(*N*) operation). A heap is a more efficient data structure that
    allows for insertion and extraction of maximum values with *O*(*log*(*N*)) time
    complexity.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，可以使用`bisect`模块中的工具来使用有序列表；然而，虽然提取最大值将花费*O*(1)时间（使用`list.pop`），插入操作仍然需要*O*(N)时间（记住，即使找到插入点需要*O*(*log*(*N*))时间，但在列表中间插入一个元素仍然是一个*O*(*N*)操作）。堆是一种更有效的数据结构，它允许以*O*(*log*(*N*))时间复杂度插入和提取最大值。
- en: 'In Python, heaps are built using the procedures contained in the `heapq` module
    on an underlying list. For example, if we have a list of 10 elements, we can reorganize it
    into a heap with the `heapq.heapify` function:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，堆是通过在底层列表上使用`heapq`模块中的过程构建的。例如，如果我们有一个包含10个元素的列表，我们可以使用`heapq.heapify`函数将其重新组织成堆：
- en: '[PRE13]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To perform the insertion and extraction operations on the heap, we can use
    the `heapq.heappush` and `heapq.heappop` functions. The `heapq.heappop` function
    will extract the minimum value in the collection in *O*(*log*(*N*)) time and can
    be used in the following way:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 要在堆上执行插入和提取操作，我们可以使用`heapq.heappush`和`heapq.heappop`函数。`heapq.heappop`函数将以*O*(*log*(*N*))时间从集合中提取最小值，并可以按以下方式使用：
- en: '[PRE14]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Similarly, you can push the integer `1`, with the `heapq.heappush` function,
    as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，你可以使用`heapq.heappush`函数将整数`1`推入堆中，如下所示：
- en: '[PRE15]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Another easy-to-use option is the `queue.PriorityQueue` class that, as a bonus,
    is thread and process-safe. The `PriorityQueue` class can be filled up with elements
    using the `PriorityQueue.put` method, while `PriorityQueue.get` can be used to
    extract the minimum value in the collection:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个易于使用的选项是`queue.PriorityQueue`类，它作为额外的好处是线程和进程安全的。可以使用`PriorityQueue.put`方法向`PriorityQueue`类填充元素，而`PriorityQueue.get`可以用来提取集合中的最小值：
- en: '[PRE16]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If the maximum element is required, a simple trick is to multiply each element
    of the list by `-1`. In this way, the order of the elements will be inverted.
    Also, if you want to associate an object (for example, a task to run) to each
    number (which can represent the priority), one can insert tuples of the `(number,
    object)` form; the comparison operator for the tuple will be ordered with respect
    to its first element, as shown in the following example:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要最大元素，一个简单的技巧是将列表中的每个元素乘以`-1`。这样，元素的顺序将被反转。此外，如果你想将对象（例如，要运行的任务）与每个数字（它可以表示优先级）关联起来，可以插入`(number,
    object)`形式的元组；元组的比较操作将根据其第一个元素进行排序，如下例所示：
- en: '[PRE17]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Tries
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字典树
- en: A perhaps less popular data structure, very useful in practice, is the trie
    (sometimes called prefix tree). Tries are extremely fast at matching a list of
    strings against a prefix. This is especially useful when implementing features
    such as search-as-you type and autocompletion, where the list of available completions
    is very large and short response times are required.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可能不太受欢迎但实际中非常有用的数据结构是字典树（有时称为前缀树）。字典树在匹配字符串列表与前缀方面非常快速。这在实现搜索即输入和自动完成等特性时特别有用，其中可用的完成列表非常大且需要短响应时间。
- en: Unfortunately, Python does not include a trie implementation in its standard
    library; however, many efficient implementations are readily available through
    PyPI. The one we will use in this subsection is `patricia-trie`, a single-file,
    pure Python implementation of trie. As an example, we will use `patricia-trie`
    to perform the task of finding the longest prefix in a set of strings (just like
    autocompletion).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Python的标准库中没有包含字典树的实现；然而，通过PyPI可以轻松获得许多高效的实现。在本小节中，我们将使用`patricia-trie`，这是一个单文件、纯Python实现的字典树。例如，我们将使用`patricia-trie`来执行在字符串集中查找最长前缀的任务（就像自动完成一样）。
- en: 'As an example, we can demonstrate how fast a trie is able to search through
    a list of strings. In order to generate a large amount of unique random strings,
    we can define a function, `random_string`. The `random_string` function will return
    a string composed of random uppercase characters and, while there is a chance
    to get duplicates, we can greatly reduce the probability of duplicates to the
    point of being negligible if we make the string long enough. The implementation
    of the `random_string` function is shown as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以展示 trie 如何快速搜索字符串列表。为了生成大量唯一的随机字符串，我们可以定义一个函数，`random_string`。`random_string`
    函数将返回由随机大写字母组成的字符串，虽然有可能得到重复的字符串，但如果我们使字符串足够长，我们可以将重复的概率大大降低到可以忽略不计的程度。`random_string`
    函数的实现如下：
- en: '[PRE18]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can build a list of random strings and time how fast it searches for a prefix
    (in our case, the `"AA"` string) using the `str.startswith` function:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以构建一个随机字符串列表，并使用 `str.startswith` 函数计时它搜索前缀（在我们的情况下，是 `"AA"` 字符串）的速度：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'List comprehension and `str.startwith` are already very optimized operations
    and, on this small dataset, the search takes only a millisecond or so:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 列推导和 `str.startwith` 已经是非常优化的操作了，在这个小数据集上，搜索只需一毫秒左右：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, let''s try using a trie for the same operation. In this example, we will
    use the `patricia-trie` library that is installable through `pip`. The `patricia.trie` class
    implements a variant of the trie data structure with an interface similar to a
    dictionary. We can initialize our trie by creating a dictionary from our list
    of strings, as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试使用 trie 进行相同的操作。在这个例子中，我们将使用可以通过 `pip` 安装的 `patricia-trie` 库。`patricia.trie`
    类实现了一种与字典接口相似的 trie 数据结构变体。我们可以通过创建一个字典来初始化我们的 trie，如下所示：
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'To query `patricia-trie` for a matching prefix, we can use the `trie.iter` method,
    which returns an iterator over the matching strings:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要查询 `patricia-trie` 以匹配前缀，我们可以使用 `trie.iter` 方法，它返回匹配字符串的迭代器：
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now that we know how to initialize and query a trie, we can time the operation:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何初始化和查询 trie，我们可以计时操作：
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: If you look closely, the timing for this input size is **60.1 µs**, which is
    about 30 times faster (1.76 ms = 1760 µs) than linear search! The speed up is
    so impressive because of the better computational complexity of the trie prefix
    search. Querying a trie has a time complexity *O*(*S*), where S is the length
    of the longest string in the collection, while the time complexity of a simple
    linear scan is *O*(*N*), where *N* is the size of the collection.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察，这个输入大小的计时为 **60.1 µs**，这比线性搜索快约30倍（1.76 ms = 1760 µs）！这种速度的提升如此令人印象深刻，是因为
    trie 前缀搜索的计算复杂度更好。查询 trie 的时间复杂度为 *O*(*S*)，其中 S 是集合中最长字符串的长度，而简单线性扫描的时间复杂度为 *O*(*N*)，其中
    *N* 是集合的大小。
- en: Note that if we want to return all the prefixes that match, the running time
    will be proportional to the number of results that match the prefix. Therefore,
    when designing timing benchmarks, care must be taken to ensure that we are always
    returning the same number of results.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果我们想返回所有匹配的前缀，运行时间将与匹配前缀的结果数量成比例。因此，在设计时间基准时，必须小心确保我们总是返回相同数量的结果。
- en: 'The scaling properties of a trie versus a linear scan for datasets of different
    sizes that contains ten prefix matches are shown in the following table:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了 trie 与线性扫描在包含十个前缀匹配的不同大小数据集上的缩放特性：
- en: '| **Algorithm** | ****N=10000 (******µs)** | ****N=20000 (******µs)** | ****N=30000
    (******µs)** | ****Time**** |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| **算法** | ****N=10000 (******µs)** | ****N=20000 (******µs)** | ****N=30000
    (******µs)** | ****时间**** |'
- en: '| Trie | 17.12 | 17.27 | 17.47 | *O*(*S*) |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| Trie | 17.12 | 17.27 | 17.47 | *O*(*S*) |'
- en: '| Linear scan | 1978.44 | 4075.72 | 6398.06 | *O*(*N*) |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 线性扫描 | 1978.44 | 4075.72 | 6398.06 | *O*(*N*) |'
- en: An interesting fact is that the implementation of `patricia-trie` is actually
    a single Python file; this clearly shows how simple and powerful a clever algorithm
    can be. For extra features and performance, other C-optimized trie libraries are
    also available, such as `datrie` and `marisa-trie`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的事实是，`patricia-trie` 的实现实际上是一个单独的 Python 文件；这清楚地展示了聪明算法的简单和强大。为了额外的功能和性能，还有其他
    C 优化的 trie 库可用，例如 `datrie` 和 `marisa-trie`。
- en: Caching and memoization
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存和记忆化
- en: Caching is a great technique used to improve the performance of a wide range
    of applications. The idea behind caching is to store expensive results in a temporary
    location, called cache, that can be located in memory, on-disk, or in a remote
    location.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存是一种用于提高各种应用程序性能的出色技术。缓存背后的想法是将昂贵的计算结果存储在临时位置，称为缓存，该缓存可以位于内存中、磁盘上或远程位置。
- en: Web applications make extensive use of caching. In a web application, it often
    happens that users request a certain page at the same time. In this case, instead
    of recomputing the page for each user, the web application can compute it once
    and serve the user the already rendered page. Ideally, caching also needs a mechanism
    for invalidation so that if the page needs to be updated, we can recompute it
    before serving it again. Intelligent caching allows web applications to handle
    increasing number of users with less resources. Caching can also be done preemptively,
    such as the later sections of the video get buffered when watching a video online.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 网络应用程序广泛使用缓存。在Web应用程序中，用户同时请求同一页面的情况经常发生。在这种情况下，而不是为每个用户重新计算页面，Web应用程序可以一次性计算并服务已经渲染的页面。理想情况下，缓存还需要一个失效机制，以便在页面需要更新时，我们可以在再次提供服务之前重新计算它。智能缓存允许Web应用程序以更少的资源处理越来越多的用户。缓存也可以预先进行，例如，在在线观看视频时，视频的后续部分会预先缓冲。
- en: Caching is also used to improve the performance of certain algorithms. A great
    example is computing the Fibonacci sequence. Since computing the next number in
    the Fibonacci sequence requires the previous number in the sequence, one can store
    and reuse previous results, dramatically improving the running time. Storing and
    reusing the results of the previous function calls in an application is usually
    termed as **memoization**, and is one of the forms of caching. Several other algorithms
    can take advantage of memoization to gain impressive performance improvements,
    and this programming technique is commonly referred to as **dynamic programming**.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存还用于提高某些算法的性能。一个很好的例子是计算斐波那契数列。由于计算斐波那契数列中的下一个数字需要序列中的前一个数字，因此可以存储和重用以前的结果，从而显著提高运行时间。在应用程序中存储和重用以前函数调用的结果通常被称为**记忆化**，它是缓存的一种形式。其他几种算法可以利用记忆化来获得令人印象深刻的性能提升，这种编程技术通常被称为**动态规划**。
- en: The benefits of caching, however, do not come for free. What we are actually
    doing is sacrificing some space to improve the speed of the application. Additionally,
    if the cache is stored in a location on the network, we may incur transfer costs
    and general time needed for communication. One should evaluate when it is convenient
    to use a cache and how much space we are willing to trade for an increase in speed.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，缓存的益处并非免费获得。我们实际上是在牺牲一些空间来提高应用程序的速度。此外，如果缓存存储在网络上的某个位置，我们可能会产生传输成本和通信所需的一般时间。应该评估何时使用缓存方便，以及我们愿意为速度的提升牺牲多少空间。
- en: 'Given the usefulness of this technique, the Python standard library includes
    a simple in-memory cache out of the box in the `functools` module. The `functools.lru_cache`
    decorator can be used to easily cache the results of a function. In the following
    example, we create a function, `sum2`, that prints a statement and returns the
    sum of two numbers. By running the function twice, you can see that the first
    time the `sum2` function is executed the `"Calculating ..."` string is produced,
    while the second time the result is returned without running the function:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这种技术的实用性，Python标准库在`functools`模块中提供了一个简单的内存缓存。可以使用`functools.lru_cache`装饰器轻松缓存函数的结果。在下面的示例中，我们创建了一个函数`sum2`，该函数打印一条语句并返回两个数字的和。通过运行该函数两次，你可以看到第一次执行`sum2`函数时会产生`"Calculating
    ..."`字符串，而第二次执行时则直接返回结果，而无需再次运行函数：
- en: '[PRE24]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `lru_cache` decorator also provides other basic features. To restrict the
    size of the cache, one can set the number of elements that we intend to maintain
    through the `max_size` argument. If we want our cache size to be unbounded, we
    can specify a value of `None`. An example usage of `max_size` is shown here:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`lru_cache`装饰器还提供了其他基本功能。为了限制缓存的大小，可以通过`max_size`参数设置我们打算维护的元素数量。如果我们想使缓存大小无限制，可以指定一个`None`值。这里展示了`max_size`的一个示例用法：'
- en: '[PRE25]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In this way, as we execute `sum2` with different arguments, the cache will reach
    a maximum size of `16` and, as we keep requesting more calculations, new values will
    replace older values in the cache. The `lru` prefix originates from this strategy,
    which means least recently used.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，当我们用不同的参数执行`sum2`时，缓存将达到最大大小`16`，并且随着我们不断请求更多的计算，新的值将替换缓存中的旧值。`lru`前缀来源于这种策略，这意味着最近最少使用。
- en: 'The `lru_cache` decorator also adds extra functionalities to the decorated
    function. For example, it is possible to examine the cache performance using the
    `cache_info` method, and it is possible to reset the cache using the `cache_clear`
    method, as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`lru_cache`装饰器还为装饰函数添加了额外的功能。例如，可以使用`cache_info`方法检查缓存性能，并且可以使用`cache_clear`方法重置缓存，如下所示：'
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As an example, we can see how a problem, such as computing the fibonacci series,
    may benefit from caching. We can define a `fibonacci` function and time its execution:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以看到计算斐波那契数列等问题如何从缓存中受益。我们可以定义一个`fibonacci`函数并测量其执行时间：
- en: '[PRE27]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The execution takes 5.57 ms, which is very high. The scaling of the function
    written in this way has poor performance; the previously computed fibonacci sequences are
    not reused, causing this algorithm to have an exponential scaling of roughly *O*(*2^N*).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 执行时间为5.57毫秒，这非常高。以这种方式编写的函数的扩展性表现很差；之前计算的斐波那契序列没有被重用，导致这个算法具有大约*O*(2^N)的指数扩展。
- en: 'Caching can improve this algorithm by storing and reusing the already-computed
    fibonacci numbers. To implement the cached version, it is sufficient to apply
    the `lru_cache` decorator to the original `fibonacci` function. Also, to design
    a proper benchmark, we need to ensure that a new cache is instantiated for every
    run; to do this, we can use the `timeit.repeat` function, as shown in the following
    example:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存可以通过存储和重用已经计算过的斐波那契数来提高这个算法。要实现缓存的版本，只需将`lru_cache`装饰器应用于原始的`fibonacci`函数即可。此外，为了设计一个合适的基准测试，我们需要确保每次运行时都实例化一个新的缓存；为此，我们可以使用`timeit.repeat`函数，如下面的示例所示：
- en: '[PRE28]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Even though we changed the algorithm by adding a simple decorator, the running
    time now is much less than a microsecond. The reason is that, thanks to caching,
    we now have a linear time algorithm instead of an exponential one.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们通过添加一个简单的装饰器改变了算法，但现在的运行时间现在比微秒还少。原因是，由于缓存，我们现在有一个线性时间算法而不是指数算法。
- en: The `lru_cache` decorator can be used to implement simple in-memory caching
    in your application. For more advanced use cases, third-party modules can be used
    for more powerful implementation and on-disk caching.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`lru_cache`装饰器在您的应用程序中实现简单的内存缓存。对于更高级的使用场景，可以使用第三方模块来实现更强大的实现和磁盘缓存。
- en: Joblib
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Joblib
- en: A simple library that, among other things, provides a simple on-disk cache is
    `joblib`. The package can be used in a similar way as `lru_cache`, except that
    the results will be stored on disk and will persist between runs.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的库，除了其他功能外，还提供了一个简单的磁盘缓存，就是`joblib`。该包可以像`lru_cache`一样使用，只不过结果将存储在磁盘上，并且会在运行之间持久化。
- en: The `joblib` module can be installed from PyPI using the `pip install joblib` command.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`pip install joblib`命令从PyPI安装`joblib`模块。
- en: 'The `joblib` module provides the `Memory` class that can be used to memoize
    functions using the `Memory.cache` decorator:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`joblib`模块提供了一个`Memory`类，可以使用`Memory.cache`装饰器来记忆化函数：'
- en: '[PRE29]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The function will behave similar to `lru_cache`, with the exception that the
    results will be stored on-disk in the directory specified by the `cachedir` argument
    during `Memory` initialization. Additionally, the cached results will persist over
    subsequent runs!
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数的行为类似于`lru_cache`，但结果将存储在初始化`Memory`时通过`cachedir`参数指定的目录中的磁盘上。此外，缓存的結果将在后续运行中持久化！
- en: The `Memory.cache` method also allows to limit recomputation only when certain
    arguments change, and the resulting decorated function supports basic functionalities
    to clear and analyze the cache.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`Memory.cache`方法还允许在仅当某些参数发生变化时才限制重新计算，并且结果装饰函数支持基本的清除和分析缓存的功能。'
- en: Perhaps the best `joblib` feature is that, thanks to intelligent hashing algorithms,
    it provides efficient memoization of functions that operate on `numpy` arrays,
    and is particularly useful in scientific and engineering applications.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 可能最好的`joblib`特性是，由于智能哈希算法，它提供了对操作`numpy`数组的函数的高效记忆化，这在科学和工程应用中尤其有用。
- en: Comprehensions and generators
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Comprehensions and generators
- en: In this section, we will explore a few simple strategies to speed up Python
    loops using comprehension and generators. In Python, comprehension and generator
    expressions are fairly optimized operations and should be preferred in place of
    explicit for-loops. Another reason to use this construct is readability; even
    if the speedup over a standard loop is modest, the comprehension and generator
    syntax is more compact and (most of the times) more intuitive.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一些简单的策略来使用推导式和生成器加快Python循环的速度。在Python中，推导式和生成器表达式是相当优化的操作，应该优先于显式for循环。使用这种结构的另一个原因是可读性；即使与标准循环相比速度提升不大，推导式和生成器语法更紧凑，并且（大多数时候）更直观。
- en: 'In the following example, we can see that both the list comprehension and generator
    expressions are faster than an explicit loop when combined with the `sum` function:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们可以看到列表推导式和生成器表达式与`sum`函数结合使用时比显式循环更快：
- en: '[PRE30]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Just like lists, it is possible to use `dict` comprehension to build dictionaries
    slightly more efficiently and compactly, as shown in the following code:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 就像列表一样，我们可以使用`dict`推导式以稍微高效和紧凑的方式构建字典，如下面的代码所示：
- en: '[PRE31]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Efficient looping (especially in terms of memory) can be implemented using
    iterators and functions such as `filter` and `map`. As an example, consider the
    problem of applying a series of operations to a list using list comprehension
    and then taking the maximum value:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 高效循环（特别是在内存方面）可以通过使用迭代器和如`filter`和`map`之类的函数来实现。例如，考虑这样一个问题：使用列表推导式对列表应用一系列操作，然后取最大值：
- en: '[PRE32]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The problem with this approach is that for every list comprehension, we are
    allocating a new list, increasing memory usage. Instead of using list comprehension,
    we can employ generators. Generators are objects that, when iterated upon, compute
    a value on the fly and return the result.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的缺点是，对于每个列表推导式，我们都在分配一个新的列表，从而增加内存使用。与其使用列表推导式，我们不如使用生成器。生成器是当迭代时即时计算值并返回结果的对象。
- en: For example, the `map` function takes two arguments--a function and an iterator--and
    returns a generator that applies the function to every element of the collection.
    The important point is that the operation happens only *while we are iterating*,
    and not when `map` is invoked!
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`map`函数接受两个参数——一个函数和一个迭代器——并返回一个生成器，该生成器将函数应用于集合中的每个元素。重要的是，操作仅在**我们迭代时**发生，而不是在调用`map`时发生！
- en: 'We can rewrite the previous function using `map` and by creating intermediate
    generators, rather than lists, thus saving memory by computing the values on the
    fly:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`map`和创建中间生成器而不是列表来重写前面的函数，从而通过即时计算值来节省内存：
- en: '[PRE33]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can profile the memory of the two solutions using the `memory_profiler`
    extension from an IPython session. The extension provides a small utility, `%memit`,
    that will help us evaluate the memory usage of a Python statement in a way similar
    to `%timeit`, as illustrated in the following snippet:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用来自IPython会话的`memory_profiler`扩展来分析这两个解决方案的内存。该扩展提供了一个小的实用工具`%memit`，它将帮助我们以类似于`%timeit`的方式评估Python语句的内存使用情况，如下面的代码片段所示：
- en: '[PRE34]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As you can see, the memory used by the first version is `102.54 MiB`, while
    the second version consumes `0.00 MiB`! For the interested reader, more functions
    that return generators can be found in the `itertools` module, which provides
    a set of utilities designed to handle common iteration patterns.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，第一个版本使用的内存为`102.54 MiB`，而第二个版本消耗的内存为`0.00 MiB`！对于感兴趣的读者，可以在`itertools`模块中找到更多返回生成器的函数，该模块提供了一组旨在处理常见迭代模式的实用工具。
- en: Summary
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: Algorithmic optimization can improve how your application scales as we process
    increasingly large data. In this chapter, we demonstrated use-cases and running
    times of the most common data structures available in Python, such as lists, deques,
    dictionaries, heaps, and tries. We also covered caching, a technique that can
    be used to trade some space, in memory or on-disk, in exchange for increased responsiveness
    of an application. We also demonstrated how to get modest speed gains by replacing
    for-loops with fast constructs, such as list comprehensions and generator expressions.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 算法优化可以提高我们处理越来越大的数据时应用程序的扩展性。在本章中，我们展示了Python中可用的一些最常见数据结构的使用案例和运行时间，例如列表、双端队列、字典、堆和前缀树。我们还介绍了缓存技术，这是一种可以在内存或磁盘上以牺牲一些空间为代价来提高应用程序响应性的技术。我们还演示了如何通过用快速结构（如列表推导式和生成器表达式）替换for循环来获得适度的速度提升。
- en: In the subsequent chapters, we will learn how to improve performance further
    using numerical libraries such as `numpy`, and how to write extension modules
    in a lower-level language with the help of *Cython*.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在随后的章节中，我们将学习如何使用如`numpy`等数值库进一步提高性能，以及如何在Cython的帮助下用更低级的语言编写扩展模块。
