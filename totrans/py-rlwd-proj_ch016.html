<html xml:lang="en-US" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<meta charset="utf-8"/>
<meta content="pandoc" name="generator"/>
<title>ch016.xhtml</title>

<!-- kobo-style -->
<style id="koboSpanStyle" type="text/css" xmlns="http://www.w3.org/1999/xhtml">.koboSpan { -webkit-text-combine: inherit; }</style>
</head>
<body epub:type="bodymatter">

<h1 data-number="16">Chapter 12<br/>
Project 3.8: Integrated Data Acquisition Web Service</h1>
<p>In many enterprise applications, data is provided to several consumers. One way to do this is to define an API that provides data (and the metadata) for subsequent use. In this chapter, we guide you through the transformation of Project 2.5 schema information into a larger OpenAPI specification. We will also build a small Flask application that provides the core acquire-cleanse-convert process as a web service.</p>
<p>We’ll cover a number of skills in the chapter:</p>
<ul>
<li><p>Creating an OpenAPI specification for a service to acquire and download data</p></li>
<li><p>Writing a web service application to implement the OpenAPI specification</p></li>
<li><p>Using a processing pool to delegate long-running background tasks</p></li>
</ul>
<p>This is a bit of a deviation from a straight path of acquiring and cleaning data. In some enterprises, this deviation is needed to publish useful data to a wider audience.</p>
<p>We’ll begin with a description of the behavior of this RESTful API server. </p>

<h2 data-number="16.1">12.1  Description</h2>
<p>In <a href="ch012.xhtml#x1-1950008"><em>Chapter</em><em> 8</em></a>, <a href="ch012.xhtml#x1-1950008"><em>Project 2.5: Schema and Metadata</em></a>, we used <strong>Pydantic </strong>to generate a schema for the analysis data model. This schema provides a formal, language-independent definition of the available data. This can then be shared widely to describe the data and resolve questions or ambiguities about the data, the processing provenance, the meaning of coded values, internal relationships, and other topics.</p>
<p>This specification for the schema can be extended to create a complete specification for a RESTful API that provides the data that meets the schema. The purpose of this API is to allow multiple users — via the <code>requests</code> module — to query the API for the analytical data as well as the results of the analysis. This can help users to avoid working with out-of-date data. An organization creates large JupyterLab servers to facilitate doing analysis processing on machines far larger than an ordinary laptop.</p>
<p>Further, an API provides a handy wrapper around the entire acquire-and-clean process. When a user requests data for the first time, the processing steps can be started and the results cached. Each subsequent request can download available data from a filesystem cache, providing rapid access. In the case of a failure, the logs can be provided as an alternative to the final data.</p>
<p>We won’t dive deeply into REST design concepts. For more information on RESTful design, see <a class="url" href="https://hub.packtpub.com/creating-restful-api/">https://hub.packtpub.com/creating-restful-api/</a>.</p>
<p>Generally, a RESTful API defines a number of paths to resources. A given path can be accessed by a number of methods, some of which will get the resource. Other methods may post, patch, put, or delete the resource. The defined HTTP methods offer handy mapping to the common <strong>Create-Retrieve-Update-Delete </strong>(<strong>CRUD</strong>) conceptual operations.</p>
<p>Here are the common cases:</p>
<ul>
<li><p>A path without a final identifier, for example, <code>/series/</code>. There are two common cases here:</p>
<ul>
<li><p>The <code>GET</code> method will retrieve the list of available resources of the given type.</p></li>
<li><p>The <code>POST</code> method can be used to create a new instance of this type. This is the conceptual “Create” operation.</p></li>
</ul></li>
<li><p>A path with an identifier. For example, <code>/series/Series_4</code>. This is a specific resource. There are several methods that might be implemented:</p>
<ul>
<li><p>The <code>GET</code> method will retrieve the resource. This is the “Retrieve” conceptual operation.</p></li>
<li><p>The <code>PUT</code> and <code>PATCH</code> methods can be used to replace or update the resource. These are two forms of the conceptual “Update” operation.</p></li>
<li><p>The <code>DELETE</code> method can be used to remove the resource. This is the “Delete” conceptual operation.</p></li>
</ul></li>
</ul>
<p>It becomes imperative to consider a RESTful web service as a collection of resources. Talking about resources can make it difficult to talk about a RESTful request that initiates processing. It raises the question of what resource describes an activity such as processing samples. We’ll start by considering the data series as the most important resource provided by this service. </p>

<h3 data-number="16.1.1">12.1.1  The data series resources</h3>
<p>The primary resource for this API is the data series. As shown in the previous section, <a href="#x1-2810001"><em>OpenAPI 3 specification</em></a>, a path with <code>/2023.02/series/&lt;id&gt;</code> can be used to extract the data for a named series. The 2023.02 prefix allows the API to evolve to a newer version while leaving older paths in place for compatibility purposes.</p>
<p>The use of <strong>semantic versioning </strong>(<strong>semver</strong>) is common, and many APIs have something like “v1” in the path. Yet another alternative is to include the version information in the <code>Accept</code> header. This means the URIs never change, but the schema for the response can change based on the version information provided in the header.</p>
<p>The various “series” routes provide direct access to the data resources. This seems appropriate since this is the primary purpose of the service.</p>
<p>There is an additional class of resources that might be of interest: the background processing used to create the data. As noted above, projects like <a href="ch015.xhtml#x1-26400011"><em>Chapter</em><em> 11</em></a>, <a href="ch015.xhtml#x1-26400011"><em>Project 3.7: Interim Data Persistence</em></a>, are the essential foundation for processing done by this RESTful API. The acquire and clean applications can be run in the background to create data for download.</p>
<div><div><p>A focus on resources is essential for making useful RESTful APIs.</p>
<p>Even when describing processing or state changes, the focus must be on the resource that undergoes the state change.</p>
<p>The methods available in HTTP (<code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>PATCH</code>, and <code>DELETE</code>, for example) are effectively the verbs of the API’s language. The resources are nouns.</p>
</div>
</div>
<p></p>


<h3 data-number="16.1.2">12.1.2  Creating data for download</h3>
<p>The primary purpose of the RESTful API is to store and download clean data for analysis work. This can be a relatively straightforward application that offers data files from a well-known directory. The work involves matching RESTful requests against available files, and returning appropriate status codes when requests are made for files that don’t exist.</p>
<p>A secondary purpose is to automate the creation of the data for download. The RESTful API can be a wrapper around the complete acquire, clean, and persist pipeline. To do this, the API will have two distinct kinds of requests:</p>
<ul>
<li><p>Requests to download existing, cached data. The resource type is clear here.</p></li>
<li><p>Requests to start the creation of new data; this will lead to cached data available for download. The resource type for processing isn’t as clear.</p></li>
</ul>
<p>An operation or action does have some static resources that can be used with a RESTful API. Here are two common resource types for activities:</p>
<ul>
<li><p>A ”current status” resource that reflects the work being done right now</p></li>
<li><p>A ”processing history” resource that reflects work completed: this is often the log file for the acquisition processing</p></li>
</ul>
<p>The control of processing by a RESTful API can work by creating and examining processing status or history as a distinct resource type:</p>
<ul>
<li><p>A path with a POST request will start an asynchronous, background process. This will also create a new processing history resource. The response body provides a transaction identifier referring to this new processing history.</p></li>
<li><p>A path with a transaction identifier and a GET request will return the background processing details; this should include the current or final status as well as the log.</p></li>
</ul>
<p>For sophisticated frontend processing, a web socket can be created to receive ongoing status reports from the background process. For a less sophisticated frontend, polling every few seconds can be done to see whether the processing has finished and the data is available for download.</p>
<p>With both processing history resources and data resources, the following two sets of paths are necessary:</p>
<ul>
<li><p><code>/series/&lt;id&gt;</code> paths that refer to specific series, already available in the cache. These resources are accessed exclusively with the GET method to download data.</p></li>
<li><p><code>/creation/&lt;id&gt;</code> paths that refer to background processing jobs to create a new series of data. These resources will use the POST method to start a background job, and the GET method to check the status of a job.</p></li>
</ul>
<p>This set of paths (and the associated methods) allows a user to control processing and check the results of processing. The user can ask for available datasets and download a specific dataset for analysis. </p>



<h2 data-number="16.2">12.2  Overall approach</h2>
<p>We’ll take some guidance from the C4 model ( <a class="url" href="https://c4model.com">https://c4model.com</a>) when looking at our approach.</p>
<ul>
<li><p><strong>Context </strong>For this project, the context diagram has several use cases: listing available data, downloading available data, starting a process to acquire data, and checking the status of a process acquiring data.</p></li>
<li><p><strong>Containers </strong>Ideally, this runs on a single container that hosts the web service as well as the processing. In some cases, multiple containers will be required because the processing demands are so huge.</p></li>
<li><p><strong>Components </strong>There are two significantly different collections of software components: the web service, and the application programs that run in the background to acquire and clean the data.</p></li>
<li><p><strong>Code </strong>The acquiring and cleaning applications have already been described as separate projects. We’ll focus on the web service.</p></li>
</ul>
<p>We’ll decompose the web service application into several components. The following diagram shows the relationship between the RESTful API service and the applications that are run to acquire and clean data.</p>
<p>The component diagram is shown in <a href="#12.1"><em>Figure 12.1</em></a>.</p>
<figure class="IMG---Figure">
<img alt="Figure 12.1: Application components " src="img/file52.jpg"/>
<figcaption class="IMG---Caption">Figure 12.1: Application components </figcaption>
</figure>
<p>This diagram shows three separate processes:</p>
<ul>
<li><p>The <strong>RESTful API </strong>process that handles HTTP requests from clients.</p></li>
<li><p>The <strong>Worker Pool </strong>collection of processes that are managed by the <code>concurrent.futures</code> module. Each worker will be running a single function, shown as <code>acquire_series</code>, that’s defined in the same module as the <strong>RESTful API </strong>service.</p></li>
<li><p>The <strong>Background </strong>process that is executed by a worker in the worker pool. This uses the <code>subprocess</code> module to run an existing CLI application.</p></li>
</ul>
<p>When the API service starts, it uses <code>concurrent.futures</code> to create a pool of workers. A request to acquire and clean data will use the <code>submit()</code> method of the pool to create a <strong>future</strong>. This future is a reference to a subprocess that will — eventually — return the final status of the acquire and clean job. The subprocess that implements the future will evaluate the <code>acquire_series()</code> function defined in the same module as the RESTful API application to do the work.</p>
<p>When the <code>acquire_series()</code> function finishes the processing, it will have created a file that can be downloaded. Via the future object, it will also provide some status information to the RESTful API service to indicate the processing is done.</p>
<p>One suggested implementation for the <code>acquire_series()</code> function is to use <code>subprocess.run()</code> to execute the acquire and clean applications to gather and cleanse source data. There are some other choices available. The most important alternative is to import these two other modules, and execute them directly, rather than creating a subprocess. This direct execution has the advantage of being slightly faster than spawning a subprocess. It has the disadvantage of making it more complicated to create a separate log file each time the <strong>acquire </strong>and <strong>clean </strong>application is executed.</p>
<p>We’ll take a look at the OpenAPI specification for the RESTful API first. This helps to characterize the overall UX. </p>

<h3 data-number="16.2.1">12.2.1  OpenAPI 3 specification</h3>
<p>A RESTful API requires a clear description of the requests and responses. The OpenAPI specification is a formal definition of RESTful web services. See <a class="url" href="https://www.openapis.org">https://www.openapis.org</a>. This document has a version identifier and some information about the service as a whole. For this project, the most important part is the <strong>paths </strong>section, which lists the various resource types and the paths used to locate those resources. The <strong>components </strong>section provides the needed schema definitions.</p>
<p>An OpenAPI document often has an outline like this:</p>
<div><div><pre class="source-code">{
        "openapi": "3.0.3",
        "info": {
                "title": "The name of this service",
                "description": "Some details.",
                "version": "2023.02"
        }
        "paths": {
                "..."
        }
        "components": {
                "parameters": {"..."},
                "schemas": {"..."}
        }
}</pre>
</div>
</div>
<p>The details of the paths and components have been elided from this overview. (We’ve used <code>"..."</code> in place of the details.) The idea is to show the general structure of an OpenAPI specification. While JSON is the underlying format commonly used for these specifications, it can be hard to read. For this reason, it’s common to use YAML notation for OpenAPI specifications.</p>
<div><div><p>Think of the OpenAPI specification as a binding contract.</p>
<p>The acceptance test suite should be Gherkin scenarios with a very direct mapping to the OpenAPI specification.</p>
<p>For more on the idea of OpenAPI to Gherkin, see <a class="url" href="https://medium.com/capital-one-tech/spec-to-gherkin-to-code-902e346bb9aa">https://medium.com/capital-one-tech/spec-to-gherkin-to-code-902e346bb9aa</a>.</p>
</div>
</div>
<p>The OpenAPI paths define the resources made available by a RESTful API. In this case, the resources are cleaned files, ready for analysis.</p>
<p>We’ll often see entries in the <strong>paths </strong>section that look like the following YAML snippet:</p>
<div><div><pre class="source-code">  "/2023.02/series":
    get:
      responses:
        "200":
          description: All of the available data series.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/series_list"</pre>
</div>
</div>
<p>This shows a path that starts with an API version number (in this example, calendar versioning, “calver”, is used) and a resource-type, <code>series</code>. Any given path can be accessed by a variety of methods; in this example, only the <strong>get</strong> method is defined.</p>
<p>One kind of response is defined for requests to this path and method combination. The response will have a status code of 200, meaning normal, successful completion. The description is there to explain what this resource will be. A response can define a variety of content types; in this example, only <code>application/json</code> is defined. The schema for this is provided elsewhere in the OpenAPI specification, in the <code>components/schemas</code> section of the document.</p>
<p>The use of a <code>$ref</code> tag within the specification permits common definitions, such as schemas and parameters, to be collected under the <code>components</code> section, permitting reuse. This follows the <strong>DRY </strong>(<strong>Don’t Repeat Yourself</strong>) principle of software design.</p>
<p>It can be difficult to get the syntax correct in an OpenAPI specification. It’s helpful to have an editor that validates the specification. For example, <a class="url" href="https://editor.swagger.io">https://editor.swagger.io</a> provides an editor that helps confirm the specification is internally consistent. For readers using tools such as JetBrains’ PyCharm, there’s a plug-in editor: <a class="url" href="https://plugins.jetbrains.com/plugin/14837-openapi-swagger-editor">https://plugins.jetbrains.com/plugin/14837-openapi-swagger-editor</a>.</p>
<p>When a path has an identifier in it, then this is shown with the path name of the form <code>"/2023.02/series/&lt;series_id&gt;"</code>. The <code>&lt;series_id&gt;</code> is defined in the <code>parameters</code> section of this request. Since parameters are sometimes reused, it’s helpful to have a reference to a component with the common definition.</p>
<p>The whole request might start like this:</p>
<div><div><pre class="source-code">  "/2023.02/series/&lt;series_id&gt;":
    get:
      description:
        Get series data as text ND JSON.
      parameters:
        - $ref:
            "#/components/parameters/series_id"
      responses:
        ...</pre>
</div>
</div>
<p>The details of the <strong>responses </strong>section have been omitted from this example. The parameter definition — in the <code>components</code> section — might look like this:</p>
<div><div><pre class="source-code">    series_id:
      name: series_id
      in: path
      required: true
      description: Series name.
      schema:
        type: string</pre>
</div>
</div>
<p>This provides a wealth of details about the <code>series_id</code> parameter, including the description and a formal schema definition. For simple APIs, the name of the parameter and the reference label under <code>components</code> are often the same. In more complex cases, a parameter name might be reused, but have distinct semantics in distinct contexts. A generic word such as <code>id</code> might be used in several different paths, leading to the reference label being something more descriptive than <code>id</code>.</p>
<p>The content for ND JSON is considered an extension to standard MIME types. Therefore the content definition for a response that includes data might look like this:</p>
<div><div><pre class="source-code">  content:
    application/x-ndjson:
      schema:
        $ref: "#/components/schemas/samples"</pre>
</div>
</div>
<p>The schema is a challenge because it pushes the boundaries of what JSON Schema can describe. It looks as follows:</p>
<div><div><pre class="source-code">    samples:
      description: &gt;
        Acquired data for a series in ND JSON format.
        See http://ndjson.org and https://jsonlines.org.
      type: string
      format: "(\\{.*?\\}\\n)+"</pre>
</div>
</div>
<p>The format information describes the physical organization of ND JSON data, but doesn’t provide any details on the structure of the schema for each individual row. The additional schema details can either be added to the description, or a separate label, distinct from other JSON schema labels, can be used, for example, ”ndjson-schema:”. </p>


<h3 data-number="16.2.2">12.2.2  RESTful API to be queried from a notebook</h3>
<p>The RESTful API service must be a wrapper around application programming that can perform the required processing. The idea is to put as little processing as possible into the RESTful API. It serves as a very thin — almost transparent — interface to the “real work” of the application. For this reason, projects such as <a href="ch015.xhtml#x1-26400011"><em>Chapter</em><em> 11</em></a>, <a href="ch015.xhtml#x1-26400011"><em>Project 3.7: Interim Data Persistence</em></a> are the essential foundation of this RESTful API.</p>
<p>As noted in <a href="#12.1"><em>Figure 12.1</em></a>, the <strong>Background </strong>processing is completely outside the RESTful API. This separation of concerns is absolutely essential. The general processing of samples can be performed with a CLI or through the RESTful API and create identical results.</p>
<p>If additional processing — for example, additional cleaning — is done by the RESTful service, then there are results that can’t be reproduced from the CLI. This means the acceptance test suites have distinct results. This will lead to problems when a change is made to the underlying <strong>acquire </strong>or <strong>clean </strong>application and the “extra” processing that was jammed into the RESTful service now appears to be broken.</p>
<p>A common source of problems in enterprise software is the failure to honor the <strong>I</strong><strong>nterface</strong> <strong>Segregation </strong>design principle. A complex application may be supported by several collaborating organizations. When one organization is slow to respond to requests for changes, another organization may step in and make a bad design decision, implementing processing in the API interface that should have been part of a background module with a proper CLI interface. The urge to be responsive to customers can often overshadow the importance of the separation of concerns.</p>
<p>For this project, the server can be built as a single process, avoiding the need for the distributed cache. Further, because the data series and the processing logs are all simple files, a database is not required; the local filesystem is perfectly suited to this service.</p>
<p>To create a more scalable solution, a library such as <strong>celery </strong>can be used to create a more robust distributed worker pool. This isn’t needed for a small server, however.</p>
<p>In the next section, we’ll review how processing can be started by a RESTful API. </p>


<h3 data-number="16.2.3">12.2.3  A POST request starts processing</h3>
<p>The general approach to creating a new resource is to make a <code>POST</code> request to a path. This will either return a 400 error status or it will issue a redirect (301) to a new path to retrieve the status of the background processing. This pattern is called the <strong>Post-Redirect-Get </strong>design pattern. It permits a user interacting with a browser to use the <strong>back </strong>button to perform the <code>GET</code> method again; it prevents the <strong>back </strong>button from submitting a duplicate request.</p>
<p>For a client application making a request via <code>requests</code> the redirect is essentially invisible. The request history will reveal the redirection. Also, the full URL recorded in the response will reflect the redirection.</p>
<p>The general processing for this route, then, is as follows:</p>
<ol>
<li><div><p>Validate all of the parameters to make sure they describe the series and the source of the data. If there is anything amiss, a JSON response with the details of the problem must be returned, with a status code of 400 to indicate the request is invalid and must be changed.</p>
</div></li>
<li><div><p>Use the worker pool <code>submit()</code> method to create a <code>Future</code> object. This object can be saved in a local cache by the RESTful API. This cache of <code>Future</code> objects can be queried to see the background processing currently being performed. The future’s result is usually something indicative of success or failure; for example, the return code from the subprocess – usually a zero indicates success.</p>
</div></li>
<li><div><p>Use the <code>redirect()</code> function in the Bottle framework to return the status code to direct a client to another URL for the status of the just-created <code>Future</code> object. Separately, a GET request will prepare a JSON document with the status of the job creating the data.</p>
</div></li>
</ol>
<p>When using a framework like Bottle, this function is marked with a <code>@post("/2023.02/creation")</code> decorator. This names the POST method and the path that will be handled by the function.</p>
<p>The log files from processing can be the longer-term repository of processing history. The GET request for status will return a log and possibly the state of an active <code>Future</code> object. We’ll look at this request next. </p>


<h3 data-number="16.2.4">12.2.4  The GET request for processing status</h3>
<p>The initial POST request to start processing will redirect to a GET request that reveals the status of the processing. The initial response may have almost no other details beyond the fact that the processing job has started.</p>
<p>This status path should return one of two things:</p>
<ul>
<li><p>A 404 status if the process ID is unknown. This would mean no previous request had been made with this identifier and no current request has this identifier, either.</p></li>
<li><p>A 200 status with JSON content that includes some combination of two things: the state of a future object and the log file.</p></li>
</ul>
<p>Most users will only care about the state of the <code>Future</code> object. In the case of developers, however, who are adding features to data acquire or data cleaning applications, then the log might be important support for observability.</p>
<p>When using a framework like Bottle, this function is marked with a <code>@get("/2023.02/creation/&lt;job_id&gt;")</code> decorator. This provides the method and the path that will be handled by the function. The use of <code>&lt;job_id&gt;</code> parses this section of the path and provides the value as a separate parameter to the function that implements this route.</p>
<p>Once the processing is complete, a subsequent request can provide the data. We’ll look at this next. </p>


<h3 data-number="16.2.5">12.2.5  The GET request for the results</h3>
<p>This path should return one of two things:</p>
<ul>
<li><p>A 404 status if the series identifier is unknown.</p></li>
<li><p>A 200 status with the ND JSON content. This has a MIME type of <code>application/x-ndjson</code> to indicate it’s an extension to the standard collection of MIME types.</p></li>
</ul>
<p>When using a framework like Bottle, this function is marked with a <code>@get("/2023.02/series/&lt;series_id&gt;")</code> decorator. The use of <code>&lt;series_id&gt;</code> parses this section of the path and provides the value as a separate parameter to the function that implements this route.</p>
<p>A more sophisticated implementation can check for an <code>Accept</code> header in the request. This header will state the preferred MIME type, and might have <code>text/csv</code> instead of <code>application/x-ndjson</code>. The use of this header permits a client to make requests for data in a format the application finds most useful. </p>


<h3 data-number="16.2.6">12.2.6  Security considerations</h3>
<p>A RESTful API requires some care to be sure the requests fit with the overall enterprise information access policies. In some cases, this might mean individual access controls to be sure each person can access permitted data. There are numerous <strong>Single Sign-On </strong>(<strong>SSO</strong>) products that can handle the identity of individuals.</p>
<p>Another common approach is to have an API work with assigned API keys. The team supporting the API can provide unique API key values to known users or teams. Within most enterprises, there’s little need for automating the assignment of API keys for internal-facing APIs. The set of valid API keys may be reduced or expanded to reflect organizational merges and splits.</p>
<div><div><p>API key values are sent from the client to the server to authenticate the user making a request. They are never sent from the server to a client. The API keys can be kept in a simple text file; the file’s permissions should restrict it to read-only access by the account handling the service as a whole. This requires administrators to take steps to manage the file of API keys to avoid damaging it or revealing it to unauthorized users.</p>
</div>
</div>
<p>When working with API keys, there are a number of ways the client can provide the key with each API request. One of the more popular techniques is to use these complementary security features:</p>
<ul>
<li><p>The HTTPS protocol, where all of the communication between client and server application is encrypted.</p></li>
<li><p>The HTTP <strong>Authorization </strong>header with <strong>Basic </strong>authorization. This header will have a username and the API key as the password.</p></li>
</ul>
<p>The use of the <strong>Authorization </strong>header is often very simple for a client tool. Many libraries — for example, the <strong>requests </strong>library — offer an object class that contains the username and API key. Using the <code>auth=</code> parameter on a request function will build the appropriate header.</p>
<p>The use of HTTPS includes <strong>Transport Layer Security </strong>(<strong>TLS</strong>) to keep the content of the <strong>Authorization </strong>header secret. The <strong>requests </strong>package handles this politely.</p>
<p>On the server side, each of these must be handled by our RESTful API application. Using HTTPS is best done by running the <strong>Bottle </strong>application inside another server. We could, for example, create an NGINX and uWSGI configuration that would run our RESTful app inside a containing server. Another choice is to use a Python-based server such as Paste or GUnicorn to contain the <strong>Bottle </strong>application. It’s essential to have a container server to handle the details of HTTPS negotiation.</p>
<p>Processing the <strong>Authorization </strong>header is something best done within the RESTful API. Some routes (i.e., the <code>openapi.yaml</code>) should not include any security considerations. Other routes — specifically those that cause state changes — may be limited to a subset of all users.</p>
<p>This suggests the list of users includes some permissions as well as their API key. Each route needs to confirm the <strong>Authorization </strong>header has a known user and the correct key. The <code>request.auth</code> property of the <code>request</code> object is a two-tuple with the username and API key value. This can be used to decide whether the request is generally acceptable, and also to decide whether a state-changing <strong>Post </strong>operation is permitted for the given user. This kind of processing is often implemented as a decorator.</p>
<p>We won’t dig deeply into the design of this decorator. For this project, with so few resources, a repeated <code>if</code> statement inside each function is acceptable. </p>



<h2 data-number="16.3">12.3  Deliverables</h2>
<p>This project has the following deliverables:</p>
<ul>
<li><p>Documentation in the <code>docs</code> folder</p></li>
<li><p>Acceptance tests in the <code>tests/features</code> and <code>tests/steps</code> folders</p></li>
<li><p>Unit tests for the application modules in the <code>tests</code> folder</p></li>
<li><p>An application for the RESTful API processing</p></li>
</ul>
<p>We’ll start by looking at the acceptance test cases, first. They’ll be rather complex because we need to start the RESTful API service before we can access it with a client request. </p>

<h3 data-number="16.3.1">12.3.1  Acceptance test cases</h3>
<p>Back in <a href="ch008.xhtml#x1-780004"><em>Chapter</em><em> 4</em></a>, <a href="ch008.xhtml#x1-780004"><em>Data Acquisition Features: Web APIs and Scraping</em></a>, specifically <a href="ch009.xhtml#x1-1360005"><em>Acceptance tests using a SQLite database</em></a>, we looked at ways to describe a scenario that involved a database service.</p>
<p>For this project, we’ll need to write scenarios that will lead to step definitions that start the RESTful API service.</p>
<p>There’s an important question about setting the state of the RESTful API server. One approach to setting a state is by making a sequence of requests as part of the scenario. This is often appropriate for this application.</p>
<p>If the server’s state is reflected in the file system, then seeding proper files can be a way to control the state of the API server. Rather than run an acquire and clean process, a test scenario can inject the appropriate status and log files into a working directory.</p>
<p>Some developers have a feeling that a database (or a distributed cache) is required for RESTful APIs. In practice, it’s often the case that a shared file system is sufficient.</p>
<div><div><p>Using files is not uncommon in practice. A database to share state is not <strong>always </strong>required for RESTful APIs.</p>
</div>
</div>
<p>Using the file system for the state makes acceptance testing work out nicely. The proper files can be created to initialize the service in the state described by the given steps in the test scenario.</p>
<p>A complicated scenario could look like the following:</p>
<div><div><pre class="source-code">@fixture.REST_server
Scenario: Service starts and finishes acquiring data.

  Given initial request is made with path "/api/2023.02/creation" and
      method "post" and
      body with {"series": "2", "source": "Anscombe_quartet_data.csv"}
  And initial response has status "200", content-type "application/json"
  And initial response has job-id
  When polling every 2 seconds with path "/api/2023.02/creation/job-id" and
      method "get" finally has response body with status "Done"
  Then response content-type is "application/json"
  And response body has log with more than 0 lines
  And response body has series "Series_2"
  And response body has status "done"</pre>
</div>
</div>
<p>For more background on creating a fixture, see <a href="ch008.xhtml#x1-910003"><em>Acceptance tests</em></a> in <a href="ch008.xhtml#x1-780004"><em>Chapter</em><em> 4</em></a>, <a href="ch008.xhtml#x1-780004"><em>Data Acquisition Features: Web APIs and Scraping</em></a>. This scenario references a fixture named <code>REST_server</code>. This means the <code>environment.py</code> must define this fixture, and provide a <code>before_tag()</code> function that will make sure the fixture is used.</p>
<p>The given steps specify an initial query and response. This should set the required state in the API server. This request for processing will initiate the acquire and clean processing. The <code>When</code> step specifies a sequence of actions that include polling periodically until the requested processing finishes.</p>
<p>Note the path provided in the <code>When</code> statement. The text <code>job-id</code> is in the scenario’s path. The step definition function must replace this template string with the actual job identifier. This identifier will be in response to the initial request in the given step. The <code>Given</code> step’s definition function must save the value in the context for use in later steps.</p>
<p>The <code>Then</code> step confirms that series data was returned. This example does not show a very complete check of the result. You are encouraged to expand on this kind of acceptance test scenario to be more complete in checking the actual results match the expected results.</p>
<p>For some applications, the retrieval of a tiny test case dataset may be a feature that helps test the application. The ordinary datasets the users want may be quite large, but a special, exceptionally small dataset may also be made available to confirm all the parts are working in concert.</p>
<div><div><p>A self-test resource is often essential for health checks, diagnostics, and general site reliability.</p>
<p>Network load balancers often need to probe a server to be sure it’s capable of handling requests. A self-test URI can be helpful for this purpose.</p>
</div>
</div>
<p>A very subtle issue arises when trying to stop this service. It contains a worker pool, and the parent process needs to use the Linux <code>wait()</code> to properly terminate the children.</p>
<p>One reliable way to do this is to use <code>server.send_signal(signal.SIGINT)</code> in the function that starts the service to create the fixture for a scenario. This means the fixture function will have the following outline:</p>
<div><div><pre class="source-code">@fixture
def rest_server(context: Context) -&gt; Iterator[Any]:
        # Create log file, base URI (code omitted)

        server = subprocess.Popen([sys.executable, "src/service.py"],
    shell=False, stdout=context.log_file, stderr=subprocess.STDOUT)
    time.sleep(0.5)  # 500 ms delay to allow the service to open a socket

    yield server  # Scenario can now proceed.

    # 100 ms delay to let server’s workers become idle.
    time.sleep(0.10)
    server.send_signal(signal.SIGINT)
    # 100 ms delay to let API’s subprocesses all terminate.
    time.sleep(0.10)</pre>
</div>
</div>
<p>The various <code>sleep()</code> timings are generous over-estimations of the time required for the server subprocess to complete the various startup and shut-down tasks. In some cases, the OS scheduler will handle this gracefully. In other cases, however, disconnected child processes can be left in the list of running processes. These “zombie processes” need to be terminated manually, something we’d like to avoid.</p>
<div><div><p>On most Linux-derived OSs, the <code>ps</code><code> -ef</code> command will show all processes. The <code>ps</code><code> -ef</code><code> |</code><code> grep</code><code> python</code> pipeline will show all Python processes.</p>
<p>From this list, any zombie worker pool processes should be apparent.</p>
</div>
</div>
<p><code>signal.SIGINT</code> is the control-C interrupt signal. The Python process makes this an exception that will not be handled. When this exception exits from the <code>with</code> statement that created the process pool, a complete clean-up will be finished and no zombie processes will be left running.</p>
<p>Now that we’ve looked at the acceptance test that defines proper behavior, we can look at the RESTful API server application. </p>


<h3 data-number="16.3.2">12.3.2  RESTful API app</h3>
<p>The RESTful API application can be built with any of the available frameworks. Since a previous chapter (<a href="ch008.xhtml#x1-780004"><em>Chapter</em><em> 4</em></a>, <a href="ch008.xhtml#x1-780004"><em>Data Acquisition Features: Web APIs and</em> <em>Scraping</em></a>) used the Bottle framework, you can continue with this small framework. Because Bottle is very much like Flask, when additional features are needed, the upgrade to Flask isn’t horribly complicated.</p>
<p>One of the advantages of using Flask for this application is an integrated client for writing unit test cases. The Bottle project can do everything that’s required, but it lacks a test client. When looking at unit testing, we’ll also look at unit test tools for the Bottle framework.</p>
<p>In <a href="#x1-2810001"><em>OpenAPI 3 specification</em></a> we looked at the OpenAPI specification for a specific path. Here’s how that specification can be implemented:</p>
<div><div><pre class="source-code">from bottle import response, get

@get(’/api/2023.02/series’)
def series_list():
    series_metadata = [
        {"name": series.stem, "elements": series_size(series)}
        for series in DATA_PATH.glob("*.ndj")
    ]
    response.status = 200
    response.body = json.dumps(series_metadata, indent=2)
    response.content_type = "application/json"
    return response</pre>
</div>
</div>
<p>This function builds a sequence of metadata dictionaries. Each item has a series name, which is used in a separate request to get the data. The size is computed by a small function to read the series and find the number of samples.</p>
<p>The <code>response</code> object is not always manipulated as shown in this example. This is an extreme case, where the value to be returned is not a Python dictionary. If the return value is a dictionary, the Bottle framework will convert it to JSON, and the content type will be set to <code>application/json</code> automatically. In this case, the result is a list of dictionaries; the Bottle framework will not automatically serialize the object in JSON notation.</p>
<p>An important part of the design is a cache to retain <code>Future</code> objects until the processing completes, and the data is available. One way to handle this is with a dataclass that keeps the parameters of the request, the <code>Future</code> object that will produce the results, and the assigned job identifier.</p>
<p>This structure for each <code>Future</code> object might look like the following example:</p>
<div><div><pre class="source-code">from conccurrent import futures
from dataclasses import dataclass, field
from pathlib import Path
import secrets

@dataclass
class AcquireJob:
    series: str
    source_path: Path
    output_path: Path
    future: futures.Future = field(init=False)
    job_id: str = field(default_factory=lambda:
    \secrets.token_urlsafe(nbytes=12))</pre>
</div>
</div>
<p>This keeps the parameters for the request as well as the processing details. The values for <code>series</code>, <code>source_path</code>, and <code>output_path</code> are built from the parameters provided when making an initial request. The paths are built from supplied names and include the base path for the working directory the server is using. In this example, the user’s input is limited to the series name and the data source. These come from a small domain of valid values, making it relatively easy to validate these values.</p>
<p>The RESTful API can then create the output path within the appropriate directory of cleaned data.</p>
<p>The value for the <code>job_id</code> attribute is computed automatically when an instance of the <code>AcquireJob</code> class is created.</p>
<p>The value for the <code>future</code> attribute is set when the <code>submit()</code> method is used to submit a processing request to process a pool of waiting workers.</p>
<p>The worker pool needs to be created before any work can be done by the RESTful API. The startup can look like the following:</p>
<pre class="source-code">from conccurrent import futures
import urllib.parse

WORKERS: futures.ProcessPoolExecutor

# Definitions of all of the routes

if __name__ == "__main__":
	# Defaults...
	acquire_uri = "http://localhost:8080"
	# Parse a configuration, here; possibly overriding defaults
    uri = urllib.parse.urlparse(acquire_uri)
	with futures.ProcessPoolExecutor() as WORKERS:
        run(host=uri.hostname, port=uri.port)</pre>
<p>Each route is handled by a separate function. Because of this, the Bottle (as well as the Flask) framework expects the worker pool to be a global object shared by all of the route-handling functions. In the event of a multi-threaded server, a lock must be used before a write access to the <code>WORKERS</code> global.</p>
<p>Similarly, the cache of <code>AcquireJob</code> instances is also expected to be a global object. This is updated only by the route-handling function to handle initiating a processing request. This cache will be queried by a route that shows the status of a processing request. In the event of a multi-threaded server, a lock must be used before adding a new item to the global cache of working jobs.</p>
<p>In some cases, where the load is particularly heavy, thread-local storage may be needed for any processing done by the various functions in the RESTful API implementation. The <code>request</code> and <code>response</code> objects, in particular, are already in thread-local storage. Ideally, there is very little processing done by these functions, minimizing the number of objects that need to be created and kept in an instance of <code>threading.local</code>.</p>
<p>There are a few special considerations for the unit tests for this project. We’ll look at those in the next section. </p>


<h3 data-number="16.3.3">12.3.3  Unit test cases</h3>
<p>Some frameworks — like <strong>Flask </strong>— offer a test client that can be used to exercise an application without the overheads of starting a server and a worker pool.</p>
<p>The <strong>Bottle </strong>framework doesn’t offer a test client. An associated project, <strong>boddle</strong>, offers a way to build a mock <code>request</code> object to support unit testing. See <a class="url" href="https://github.com/keredson/boddle">https://github.com/keredson/boddle</a>.</p>
<p>The <strong>WebTest </strong>project is an alternative for writing unit tests. A <strong>WebTest </strong>fixture contains the Bottle application and provides requests and responses through the internal WSGI interface. This avoids the need to start a complete server. It also permits some monkey-patching of the Bottle application to mock components. See <a class="url" href="https://docs.pylonsproject.org/projects/webtest/en/latest/">https://docs.pylonsproject.org/projects/webtest/en/latest/</a>.</p>
<p>It seems best to use the very sophisticated <code>WebTest</code> client that’s part of the <strong>Pylons </strong>framework. This client can execute the unit tests.</p>
<p>It’s sometimes helpful to note that functions with decorators are composite objects. This means the “unit” test isn’t testing the decoration and the function in isolation from each other. This lack of separate testing can sometimes lead to difficulty in debugging the root cause of a test case failure. A problem may be in the function, it may be the <code>@route</code> decorator, or it may be any authorization decorator that’s also part of the composite function being tested.</p>
<p>It seems easier to test the composite route functions, using appropriate log messages for debugging. While this doesn’t follow the strict idea of testing each component in isolation, it does work well for testing each route with appropriate mocks. For example, we can mock the worker pool, avoiding the overhead of starting a subprocess when testing.</p>
<p>Here’s an example of a test function using <strong>WebTest </strong>to exercise a <strong>Bottle</strong> route:</p>
<div><div><pre class="source-code">from unittest.mock import sentinel, Mock, call
from pytest import fixture, MonkeyPatch
from webtest import TestApp
import service

def test_test(monkeypatch: MonkeyPatch) -&gt; None:
    monkeypatch.setitem(service.ACCESS, "unit-test", "unit-test")
    app = TestApp(service.app)
    app.authorization = (
        "Basic", ("unit-test", "unit-test")
    )
    response = app.get("/api/2023.02/test")
    assert response.status_code == 200
    assert response.json[’status’] == "OK"</pre>
</div>
</div>
<p><code>service.app</code> is the global <code>app</code> object in the RESTful API application. This is an instance of the <code>Bottle</code> class. <code>service.ACCESS</code> is the global list of usernames and their expected API keys. This is monkey-patched by the test to force in a specific test username and test API Key. This initial setup is something that might be used by a number of tests and should be defined as a reusable fixture.</p>
<p>When the <code>app.get()</code> request is made, the test harness will execute the <code>route</code> function and collect the response for examination by the <code>test</code> method. This makes a direct function call, avoiding the overhead of a network request.</p>
<p>One of the reasons for choosing to use <strong>Flask </strong>instead of <strong>Bottle </strong>is the availability of a test client that can simplify some of this test setup. </p>



<h2 data-number="16.4">12.4  Summary</h2>
<p>This chapter integrated a number of application programs under the cover of a single RESTful API. To build a proper API, there were several important groups of skills:</p>
<ul>
<li><p>Creating an OpenAPI specification.</p></li>
<li><p>Writing a web service application to implement the OpenAPI specification.</p></li>
<li><p>Using a processing pool to delegate long-running background tasks. In this example, we used <code>concurrent.futures</code> to create a future promise of results, and then compute those results.</p></li>
</ul>
<p>The number of processes involved can be quite daunting. In addition to the web service, there is a processing pool, with a number of sub-processes to do the work of acquiring and cleaning data.</p>
<p>In many cases, additional tools are built to monitor the API to be sure it’s running properly. Further, it’s also common to allocate dedicated servers to this work, and configure <code>supervisord</code> to start the overall service and ensure the service continues to run properly. </p>


<h2 data-number="16.5">12.5  Extras</h2>
<p>Here are some ideas for you to add to these projects. </p>

<h3 data-number="16.5.1">12.5.1  Add filtering criteria to the POST request</h3>
<p>The <strong>POST </strong>request that initiates acquire processing is quite complicated. See <a href="#x1-2830003"><em>A</em> <em>POST request starts processing</em></a> to see the processing it does.</p>
<p>We might name the function for this route <code>creation_job_post()</code> to make it clear that this creates jobs to acquire data in response to an HTTP POST request.</p>
<p>The list of tasks in this function includes the following:</p>
<ol>
<li><div><p>Check the user’s permissions.</p>
</div></li>
<li><div><p>Validate the parameters.</p>
</div></li>
<li><div><p>Build an <code>AcquireJob</code> instance with the parameters.</p>
</div></li>
<li><div><p>Update the <code>AcquireJob</code> instance with the <code>Future</code> object. The future will evaluate the <code>acquire_series()</code> function that does the work of acquiring and cleaning the data.</p>
</div></li>
<li><div><p>Return a JSON object with details of the submitted job, as well as headers and a status code to redirect to a request to get the job’s status.</p>
</div></li>
</ol>
<p>Some RESTful APIs will have even more complicated parameters. For example, users may want to filter the data to create a subset before downloading. This improves the UX by providing only the required data. It also allows analysts to share subsets of data without having to share the filtering code within the analyst community.</p>
<p>It can also improve the UX by performing filtering on larger, powerful servers. It can prevent having to download and filter data on a local laptop.</p>
<p>This is emphatically <strong>not </strong>a feature of the RESTful API. This must <strong>first </strong>be built as a feature of an application that reads and filters the clean data. This new application will create a new dataset, ready for download. The data set name might be a UUID, and an associated metadata file would contain the filter parameters.</p>
<p>The implementation requires the <code>creation_job_post()</code> function to now also validate the filter criteria. It must include the filter criteria in the <code>AcquireJob</code> instance that is built, and provide the filter criteria to the underlying <code>acquire_series()</code> function.</p>
<p>The <code>acquire_series()</code> function will have the most dramatic changes. It will run the acquire, clean, and filter applications as subprocesses. You may want to consider an integrated application that runs the other applications, simplifying the RESTful API.</p>
<p>This will, of course, lead to considerably more complicated acceptance test cases to be sure the data acquisition works with — and without — these additional filter criteria. </p>

<h4 class="subsectionHead" data-number="16.5.1.1">12.5.2  Split the OpenAPI specification into two parts to use $REF for the output schema</h4>
<p>The OpenAPI specification includes a number of schema. In <a href="#x1-2810001"><em>OpenAPI 3</em> <em>specification</em></a>, we showed a few key features of this specification.</p>
<p>It’s not too difficult for an analyst to download the entire specification, and then locate the <code>components.schemas.seriesList</code> schema. This navigation through a JSON document doesn’t involve too many challenges.</p>
<p>While this is not burdensome, some users might object. An analyst focused on a business problem should not be asked to also sort out the structure of the OpenAPI specification. An alternative is to decompose the specification into pieces and serve the pieces separately.</p>
<p>Specifically, the places where <code>"$ref"</code> references appear generally use a path of the form <code>#/components/schemas/...</code>. The path is a local URL, omitting the hostname information. This can be replaced with a full URL that refers to schema details on the RESTful API server.</p>
<p>We might use <code>http://localhost:8080/api/schemas/...</code> to refer to the various schema files stored as separate JSON documents. Each individual schema definition would have a distinct URI, permitting ready access to only the relevant schema, and ignoring other aspects of the OpenAPI specification.</p>
<p>This decomposes the OpenAPI specification into the overall specification for the service and separate specifications for a schema that describes downloadable datasets. It also requires adding a path to the RESTful API service to properly download the schema in addition to downloading the overall OpenAPI specification.</p>
<p>This leads to a few extra acceptance test cases to extract the schema as well as the overall OpenAPI specification. </p>



<h3 data-number="16.5.2">12.5.3  Use Celery instead of concurrent.futures</h3>
<p>The suggestion in <a href="#x1-2800002"><em>Overall approach</em></a> is to use the <code>concurrent.futures</code> module to handle the long-running data acquisition and cleaning processes. The API requests that initiate processing create a <code>Future</code> object that reflects the state of a separate subprocess doing the actual work. The RESTful API is free to respond to additional requests while the work is being completed.</p>
<p>Another popular package for implementing this kind of background processing is <code>celery</code>. See <a class="url" href="https://docs.celeryq.dev/en/stable/getting-started/introduction.html">https://docs.celeryq.dev/en/stable/getting-started/introduction.html</a>.</p>
<p>This is a bit more complicated than using the <code>concurrent.futures</code> module. It also scales elegantly to allow a large number of separate computers to comprise the pool of available workers. This can permit very large processing loads to be controlled by a relatively small RESTful API application.</p>
<p>Using Celery requires creating tasks, using the <code>@task</code> decorator. It also requires starting the worker pool separately. This means the overall RESTful API now has two steps to get started:</p>
<ul>
<li><p>The celery worker pool must be running.</p></li>
<li><p>The RESTful API can then start. Once it’s running, it can delegate work to workers in the pool.</p></li>
</ul>
<p>For very large workloads, where the worker pool is spread across multiple computers, use of Celery’s sophisticated management tools are required to be sure the pools are starting and stopping appropriately.</p>
<p>The core work of submitting work to the worker pool changes from <code>pool.submit()</code> to <code>celery_app.delay()</code>. This is a small programming change that permits using a more sophisticated and scalable worker pool.</p>
<p>There aren’t any acceptance test changes for this. The features are identical.</p>
<p>The fixture definition required to start the RESTful API will be more complicated: it will have to start the <strong>Celery </strong>pool of workers before starting the RESTful API. It will also need to shut down both services. </p>


<h3 data-number="16.5.3">12.5.4  Call external processing directly instead of running a subprocess</h3>
<p>In <a href="#x1-2800002"><em>Overall approach</em></a>, we suggested the work should be done by an <code>acquire_series()</code> function. This function would be evaluated by the <code>POOL.submit()</code> function. This would delegate the work to a worker, and return a <code>Future</code> object to track the state of completion.</p>
<p>In that section, we suggested the <code>acquire_series()</code> function could use <code>subprocess.run()</code> to execute the various components of the processing pipeline. It could run the <code>src/acquire.py</code> application, and then run the <code>src/clean.py</code> application, using the <code>subprocess</code> module.</p>
<p>This isn’t the only way it could work. The alternative is to import these application modules, and evaluate their <code>main()</code> functions directly.</p>
<p>This means replacing the <code>subprocess.run()</code> function with the <code>acquire.main()</code> and <code>clean.main()</code> functions. This avoids a tiny overhead in Linux. It can be a conceptual simplification to see how the <code>acquire_series()</code> function creates the data using other Python modules.</p>
<p>This involves no changes to the acceptance test cases. It does involve some changes to the unit test cases. When using <code>subprocess.run()</code>, the unit test must monkey-patch the <code>subprocess</code> module with a mock that captures the argument values and returns a useful result. When replacing this processing with the <code>acquire.main()</code> and <code>clean.main()</code> functions, these two modules must be monkey patched with mocks that capture the argument values and return useful results. </p>



</body>
</html>
