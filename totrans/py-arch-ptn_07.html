<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer221">&#13;&#13;
    <h1 class="chapterNumber">5</h1>&#13;&#13;
    <h1 id="_idParaDest-100" class="chapterTitle">The Twelve-Factor App Methodology</h1>&#13;&#13;
    <p class="normal">When designing a software system, it's not a good idea to reinvent the wheel each time for each <a id="_idIndexMarker324"/>new project. Certain parts of software are common to most web service projects. Learning some of the known practices that have proven successful over time is important to avoid making easily fixed mistakes.</p>&#13;&#13;
    <p class="normal">In this chapter, we will focus on the Twelve-Factor App methodology. This methodology is a series of recommendations that are well proven for web services that are deployed on the web.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">The Twelve-Factor App has its origins in Heroku, a company that provides easy access to deployments. Some of the factors are more general than others, and everything should be considered general advice and not necessarily an imposition. The methodology is less applicable outside of web cloud services, but it's still a good idea to review it and try to extract useful information.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">We will present the base details for this methodology during the chapter and will spend some time describing in more detail some of the most important factors that this methodology covers.</p>&#13;&#13;
    <p class="normal">In this chapter, we'll cover the following topics:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet">Intro to the Twelve-Factor App</li>&#13;&#13;
      <li class="bullet">Continuous Integration</li>&#13;&#13;
      <li class="bullet">Scalability</li>&#13;&#13;
      <li class="bullet">Configuration</li>&#13;&#13;
      <li class="bullet">The Twelve factors</li>&#13;&#13;
      <li class="bullet">Containerized Twelve-Factor Apps</li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">Let's start by introducing the basic concepts of the Twelve-Factor App.</p>&#13;&#13;
    <h1 id="_idParaDest-101" class="title">Intro to the Twelve-Factor App</h1>&#13;&#13;
    <p class="normal">The Twelve-Factor App <a id="_idIndexMarker325"/>is a methodology with 12 different aspects or factors that cover good practices to follow while designing a web system. They aim to provide clarity and simplify some of the possibilities, detailing patterns that are known to work.</p>&#13;&#13;
    <p class="normal">The factors are generic enough to not be prescriptive in how to implement them or force the use of specific tools, and at the same time, give clear direction. The Twelve-Factor App Methodology is opinionated in the sense that it aims to cover cloud services in a scalable way, and also <a id="_idIndexMarker326"/>promotes the idea of <strong class="keyword">Continuous Integration</strong> (<strong class="keyword">CI</strong>) as a critical aspect of <a id="_idIndexMarker327"/>these kinds of operations. This also leads to a reduction in the differences between a local, development environment and a production environment. </p>&#13;&#13;
    <p class="normal">These two aspects, consistency between local and production deployments, and CI, interact, as it allows the system to be tested in a consistent way, both in a development environment and while running the tests in a CI system.</p>&#13;&#13;
    <p class="normal">Scalability is <a id="_idIndexMarker328"/>another key element. As cloud services require working with a variable workload, we need to allow our service to be capable of growing and be able to process more requests coming into the system without any issues.</p>&#13;&#13;
    <p class="normal">A third general problem that we will cover, and which is also central to the Twelve-Factor App, is the challenge of configuration. Configuration allows the same code to be set up in different environments, while also tweaking some features to adjust them in certain situations.</p>&#13;&#13;
    <h1 id="_idParaDest-102" class="title">Continuous Integration</h1>&#13;&#13;
    <p class="normal">Continuous Integration, or CI, is the practice of automating the running of tests when new code is <a id="_idIndexMarker329"/>submitted to a central repository. Whereas, when originally introduced back in 1991, it could be understood as running a "nightly build", as running the tests took time and was expensive, these days, it is commonly understood as running a set of tests with each new code submission.</p>&#13;&#13;
    <p class="normal">The objective is to produce code that always works. After all, if it's not, it is detected quickly by the failing tests. This fast feedback loop helps developers to increase their speed and create a safety net that allows them to focus on whatever feature they are implementing and leave it to the CI system to run the totality of tests. The discipline of running the tests automatically and on every single test greatly helps to ensure high-quality code, as any error is detected quickly.</p>&#13;&#13;
    <p class="normal">This is also dependent on the quality of the tests that are run, so in order to have a good CI system, it is important to understand the importance of good tests and to refine the testing procedure regularly, both to ensure that it gives us an adequate level of confidence and that it runs fast enough not to cause a problem.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">Fast enough, when dealing with a CI system can vary. Keep in mind that the tests will run in the background, automatically, without the involvement of a developer, so they may take a while to return a result, compared with the quick feedback that a developer will expect when debugging a problem. As a very general approximation, aim to have your test pipeline finished in around 20 minutes or less, if that is possible.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">CI is based on <a id="_idIndexMarker330"/>the capacity of automating whatever system is used as a central repository for code, so tests are launched as soon as new changes are forthcoming from a developer. It is very common to use a source control system like <code class="Code-In-Text--PACKT-">git</code>, and add a hook that automatically runs the tests.</p>&#13;&#13;
    <p class="normal">In a more <a id="_idIndexMarker331"/>practical approach, <code class="Code-In-Text--PACKT-">git</code> is normally used under a cloud system like GitHub (<a href="https://github.com/"><span class="url">https://github.com/</span></a>) or GitLab (<a href="https://about.gitlab.com/"><span class="url">https://about.gitlab.com/</span></a>). Both of them <a id="_idIndexMarker332"/>have other services that integrate with them and allow operations to be run automatically through some configuration. Examples include TravisCI (<a href="https://www.travis-ci.com/"><span class="url">https://www.travis-ci.com/</span></a>) and CircleCI (<a href="https://circleci.com/"><span class="url">https://circleci.com/</span></a>). In the case of GitHub, they <a id="_idIndexMarker333"/>have their own native system called GitHub Actions. All of <a id="_idIndexMarker334"/>these are based on the idea of adding a special file to configure the service, thereby simplifying the setup and run of a pipeline.</p>&#13;&#13;
    <p class="normal">A CI pipeline is a succession of steps that are run in order. If there's an error, it will stop the execution of the pipeline and report whatever problem has been detected, allowing for early detection and feedback for developers. Typically, we build the software into a testable state and then run the tests. If there are different kinds of tests, such as unit and integration tests, run them both, either one after the other or in parallel.</p>&#13;&#13;
    <p class="normal">A typical pipeline to run tests could do the following:</p>&#13;&#13;
    <ol>&#13;&#13;
      <li class="numbered" value="1">As it starts in a new, empty environment, install the required dependency tools to run the tests; for example, a particular version of Python and a compiler, or a static analysis tool that will be used in <em class="italic">step 3</em>.</li>&#13;&#13;
      <li class="numbered">Perform any build command to prepare the code, such as compiling or packetizing.</li>&#13;&#13;
      <li class="numbered">Run static analysis tools like <code class="Code-In-Text--PACKT-">flake8</code> to detect style problems. If the results reveal problems, stop here and report.</li>&#13;&#13;
      <li class="numbered">Run the unit tests. If the results are incorrect, stop here and show the errors.</li>&#13;&#13;
      <li class="numbered">Prepare and run other tests, such as integration or system tests.</li>&#13;&#13;
    </ol>&#13;&#13;
    <p class="normal">These stages may be run, in certain cases, in parallel. For example, <em class="italic">steps 3</em> and <em class="italic">4</em> may run at the same time as there is no dependency between the cases, whereas <em class="italic">step 2</em> needs to be completed before moving on to <em class="italic">step 3</em>. These steps can be described in some CI systems to allow for faster execution.</p>&#13;&#13;
    <p class="normal">The keyword in <a id="_idIndexMarker335"/>a CI pipeline is <strong class="keyword">automation</strong>. To allow the pipeline to be executed, all the steps need to be able to be run automatically, without any manual intervention. This requires that <a id="_idIndexMarker336"/>any dependency is also able to be set up automatically. For example, elements like databases or other dependencies, if required for tests, need to be allocated. </p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">A common pattern is that CI tools allocate a virtual machine that allows a database to start up so that it's available in the environment, including the usual suspects such as MySQL, PostgreSQL, and MongoDB. Keep in mind that the database will start empty, and if test data needs to be seeded, it will need to be done during the setting up of the environment. Check the documentation for your specific tool for more details.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">One possibility is to use Docker to build one or more containers that will standardize the process and make all dependencies explicit in the building process. This is becoming an increasingly common option.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">We will talk more about Docker in <em class="chapterRef">Chapter 8</em>, <em class="italic">Advanced Event-Driven Structures</em>.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Some of the factors of the Twelve-Factor App play a part in the setup of a CI pipeline, as they aim to have code that is easy to build, to be deployed either for testing or operating and configuration.</p>&#13;&#13;
    <h1 id="_idParaDest-103" class="title">Scalability</h1>&#13;&#13;
    <p class="normal">Cloud systems <a id="_idIndexMarker337"/>are expected to behave correctly under high loads, or at least to adjust between different loads. This requires the software to be <strong class="keyword">scalable</strong>. Scalability is the ability of the software to be allowed to grow and accept more requests, mostly by increasing resources.</p>&#13;&#13;
    <p class="normal">There are two types of scalability:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet">Vertical scalability: Increasing resources to each node, making them more powerful. This <a id="_idIndexMarker338"/>is the equivalent of buying a <a id="_idIndexMarker339"/>more powerful computer; adding more RAM, more hard drive space, a faster CPU…</li>&#13;&#13;
      <li class="bullet">Horizontal scalability: Adding <a id="_idIndexMarker340"/>more nodes to the system, without them being necessarily <a id="_idIndexMarker341"/>more powerful. For example, instead of having two web servers, increase them to five.</li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">In general, horizontal scalability is considered more desirable. In a cloud system, the capacity of adding and removing nodes can be automated, allowing for deployments to adjust automatically based on the number of current requests flowing into the system. Compared <a id="_idIndexMarker342"/>with the traditional way of operating, where the system had to be dimensioned for the moment of maximum system load, this can greatly reduce costs since, most of the time, the system will be underutilized.</p>&#13;&#13;
    <p class="normal">For example, let's compare a situation where, at noon, the system requires 11 servers, when most customers are connected. At midnight, the system is at its lowest utilization point, and only 2 servers are required. </p>&#13;&#13;
    <p class="normal">The following diagram shows a typical situation when the number of servers grows based on the load:</p>&#13;&#13;
    <figure class="mediaobject"><img src="Images/B17580_05_01.png" alt="Chart, histogram&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="292"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 5.1: Service scaling up and down over time</p>&#13;&#13;
    <p class="normal">The traditional situation will make use of 264 cost units (11 servers * 24 hours), while automatically scaling uses approximately 166 cost units, saving a considerable number of resources. </p>&#13;&#13;
    <p class="normal">Even more so, a traditional system requires extra headroom to allow for unexpected spikes that could occur. Normally, a system will be set up to allow at least a 30% extra load, maybe even more. In that case, the cost is permanently added.</p>&#13;&#13;
    <p class="normal">To allow a <a id="_idIndexMarker343"/>system to be horizontally scalable, it needs to be stateless. This means that each node is indistinguishable. Each request will be allocated to a node in some sort of rotation, distributing the load across all nodes. All state from each request needs to come either from the request itself (input parameters) or from an external storage source. From the point of view of the application, each request comes in an empty space and cannot be carried over in any event. That means not storing anything in the local hard drive or local memory between requests.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">Storing information intra-request, for example, composing a file with information from the database to return it in the request is OK, although keeping it in memory, if possible, will likely be faster than using the hard drive.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">The external storage source will typically be a database, but it's also common to use storage services more oriented to store files or other big blobs of binary data, for example, AWS S3. </p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">AWS S3 is a <a id="_idIndexMarker344"/>web service that allows a file to be stored and retrieved from a URL. It allows the creation of a <em class="italic">bucket</em>, which will contain a number of <em class="italic">keys</em> or paths; for example, accessing a URL similar to <code class="Code-In-Text--PACKT-">https://s3.amazonaws.com/mybucket/path/to/file</code> so it can upload and download file-like objects. There are also plenty of libraries to help deal with the service, such as <code class="Code-In-Text--PACKT-">boto3</code> for Python.</p>&#13;&#13;
      <p class="Tip--PACKT-">This service is very useful for working with files in a scalable way, and it allows configuration in such a way that access for reading can be done publicly, enabling the pattern of storing the data through your system, and then allowing the user to read it from the public URL, thereby simplifying the system.</p>&#13;&#13;
      <p class="Tip--PACKT-">Refer to <a id="_idIndexMarker345"/>the AWS documentation for more information: <a href="https://aws.amazon.com/s3/"><span class="url">https://aws.amazon.com/s3/</span></a></p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">A cache should also be kept outside of each individual node, using tools such as Riak or memcached. Internal caches, using local memory, have the problem that they likely won't be used, as the next relevant request will likely be served by another node in the system. Using <a id="_idIndexMarker346"/>an external service allows all nodes to access the cache and improves the general performance of the system.</p>&#13;&#13;
    <p class="normal">Keep in mind that the whole system cannot be stateless. In particular, the storage elements, such as databases and caches, require a different way of operating, as they are the ones storing the data. We discussed how to scale storage systems in <em class="chapterRef">Chapter 3</em>,<em class="italic"> Data Modeling</em>.</p>&#13;&#13;
    <h1 id="_idParaDest-104" class="title">Configuration</h1>&#13;&#13;
    <p class="normal">One of the basic ideas of the Twelve-Factor App is that the code is unique, but it can be adjusted <a id="_idIndexMarker347"/>through configuration. This enables the same code to be used and deployed in different environments.</p>&#13;&#13;
    <p class="normal">The use of different environments allows testing environments to be set up, where tests can be run without affecting production data. They are a more controlled place for experimenting or trying to replicate real problems in a sandbox. There's also another environment that is not typically thought of as such, which is the local development environment, where developers are able to check that the system works.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">Creating a comprehensive and easy-to-use local environment is a critical aspect of developer productivity. When working with a single service or process, such as a web server, it is relatively easy to set up, as most projects will allow starting in a dev mode, but once there are more elements, it becomes more difficult to set up.</p>&#13;&#13;
      <p class="Tip--PACKT-">Complex settings have been quite common for years. There has been a relatively recent push to use virtual machines that could be set up from scratch, and more recently, containerization to ensure that it's easy to start it from a known point.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Configuring the system is more difficult than it appears at first sight. There's always a growing number of parameters to take care of. In complex systems, it is important to structure <a id="_idIndexMarker348"/>parameters in certain ways to allow them to be divided into more manageable parts.</p>&#13;&#13;
    <p class="normal">Configuration parameters can be divided into two main categories: </p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet"><strong class="keyword">Operational configuration</strong>: These are parameters that connect different parts of the system <a id="_idIndexMarker349"/>or that are related <a id="_idIndexMarker350"/>to monitoring; for example, the address and credentials for the database, the URL to use to access an external API, or setting the level of logging to <code class="Code-In-Text--PACKT-">INFO</code>. These config parameters are only changed when there's a change in the cluster, but the external behavior of the application doesn't change; for example, a change to log only <code class="Code-In-Text--PACKT-">WARNING</code> logs or higher, or the credentials are replaced to rotate them.</li>&#13;&#13;
      <li class="bullet">These parameters are under the control of operations and are normally changed transparently or during maintenance. A misconfiguration in these parameters is normally a serious problem as it can affect the functionality of the system.</li>&#13;&#13;
      <li class="bullet"><strong class="keyword">Feature configuration</strong>: These parameters change external behavior, enabling or disabling <a id="_idIndexMarker351"/>features or changing <a id="_idIndexMarker352"/>aspects of the software; for example, theming parameters to set the color and header images; or enabling the premium feature to allow a charge for premium access, or updating the parameters of a mathematical model that changes how the internal calculation of orbits are performed.<p class="bullet-para">These parameters are irrelevant as regards the operation of the software. A misconfiguration here will likely not cause problems, as it will continue to operate normally. Changes here are more under the control of developers or even business managers to enable a feature at a particular point in time.</p>&#13;&#13;
      </li>&#13;&#13;
    </ul>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">Configuration parameters that aim to activate or deactivate a full feature are known as <em class="italic">feature flags</em>. They are used to produce a "business release" at a particular time, deploying new code into a production environment without the feature, while the feature is being worked on internally. </p>&#13;&#13;
      <p class="Information-Box--PACKT-">Once the feature is ready for release, after thoroughly testing it, the code can be deployed beforehand in production, and the full feature can be activated just by changing the proper config parameter.</p>&#13;&#13;
      <p class="Information-Box--PACKT-">This allows us to keep working in small increases toward a big feature, such as a revamp of the user interface, while at the same time building and releasing small increments frequently. Once the feature is released, the code can be refactored to remove the parameter.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">These two categories have different aims and, normally, are maintained by different people. While the operational configuration parameters are tightly related to a single environment and require parameters that are correct for the environment, the feature configuration normally moves between the local development to test it until it is changed in the production one with the same value.</p>&#13;&#13;
    <p class="normal">Traditionally, the configuration <a id="_idIndexMarker353"/>has been stored in one or more files, typically grouped by environment. This creates a file called <code class="Code-In-Text--PACKT-">production.cnf</code> and another one called <code class="Code-In-Text--PACKT-">staging.cnf</code> that are attached to the code base, and depending on the environment, one or the other is used. This entails certain problems:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet">Making a configuration change is, de facto, a code change. This limits the speed of changes that can be performed and cause problems with scope.</li>&#13;&#13;
      <li class="bullet">When the number of environments grows, the number of files grows at the same time. This can cause errors as a result of duplication; for example, a mistake that changes the wrong file is not reverted and is unexpectedly deployed later. Old files may also not be removed.</li>&#13;&#13;
      <li class="bullet">Centralizing control among developers. As we've seen, some of these parameters are not necessarily under the control of developers, but ops teams. Storing all the data in the code base makes it more difficult to create a division between jobs, requiring both teams to access the same files. While this is fine for small teams, over time, it makes sense to try to reduce the need to have big groups of people accessing the same file to only care about half of it.</li>&#13;&#13;
      <li class="bullet">Storing sensitive parameters such as passwords in files and storing them in the code repo is an obvious security risk, as anyone with access to the repo can use these credentials to access all environments, including production.</li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">These problems render it unadvisable to store the configuration directly as files inside the code base. We will see how the Twelve-Factor App deals with it specifically in the <em class="italic">Configuration</em> factor.</p>&#13;&#13;
    <h1 id="_idParaDest-105" class="title">The Twelve Factors</h1>&#13;&#13;
    <p class="normal">The factors <a id="_idIndexMarker354"/>for Twelve-Factor Apps are as follows:</p>&#13;&#13;
    <ol>&#13;&#13;
      <li class="numbered" value="1"><strong class="keyword">Code base</strong>. Store the code in a single repo and differentiate only by configuration.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Dependencies</strong>. Declare them explicitly and clearly.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Config</strong>. Config through the environment.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Backing</strong> <strong class="keyword">services</strong>. Any backing service should be treated as an attached resource.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Build, release, run</strong>. Differentiate between build and run states.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Processes</strong>. Execute the app as a stateless process.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Port binding</strong>. Expose services through ports.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Concurrency</strong>. Set up the services as processes.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Disposability</strong>. Fast start and graceful shutdown.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Dev/prod parity</strong>. All environments should be as similar as possible.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Logs</strong>. Send logs to event streams.</li>&#13;&#13;
      <li class="numbered"><strong class="keyword">Admin processes</strong>. Run one-off admin processes independently.</li>&#13;&#13;
    </ol>&#13;&#13;
    <p class="normal">The factors can be grouped around different concepts: </p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet"><em class="italic">Code base</em>,<em class="italic"> Build, release, run</em>,<em class="italic"> </em>and<em class="italic"> Dev/prod parity</em> work around the idea of generating a single application that runs in different environments, differentiating only through configuration</li>&#13;&#13;
      <li class="bullet"><em class="italic">Config</em>, <em class="italic">Dependencies</em>,<em class="italic"> Port binding</em>, and <em class="italic">Backing services </em>work around the configuration and connectivity of different services</li>&#13;&#13;
      <li class="bullet"><em class="italic">Processes</em>, <em class="italic">Disposability</em>, and <em class="italic">Concurrency</em> are related to the scalability concept</li>&#13;&#13;
      <li class="bullet"><em class="italic">Logs</em> and <em class="italic">Admin processes </em>are practical ideas involved with monitoring and one-off processes</li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">Let's take a look at all four of these groups.</p>&#13;&#13;
    <h2 id="_idParaDest-106" class="title">Build once, run multiple times</h2>&#13;&#13;
    <p class="normal">One of the key concepts around the Twelve-Factor App is that it's easy to build and manage, but <a id="_idIndexMarker355"/>at the same time, it's a unified system. This means that there's no ad hoc code that's changed from one version to another, just configurable options.</p>&#13;&#13;
    <p class="normal">The aim of the <em class="italic">Code base</em> factor is that all the software for an app is a single repo, with a single state, without special branches for each customer, or a special functionality that's only available in a particular environment.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">Very specific environments are typically called <em class="italic">snowflake environments</em>. Anyone that has dealt with them knows how painfully difficult they are to maintain, and that's why the objective for the Twelve-Factor App is to remove them, or at least make them change based just on the configuration.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">This means that the code to deploy is always the same, and only the configuration changes. This allows easy testing of all the configuration changes and does not introduce blind spots.</p>&#13;&#13;
    <p class="normal">Note that a single system may have multiple projects, living in multiple repos, that individually fulfill the Twelve-Factor App and work together. Other factors talk about interoperation on applications.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">Keeping multiple applications working together, through coordinated APIs, is always a challenge and requires good coordination across teams. Some companies adopt the monorepo approach, where there's a single repository with all the company projects living in multiple subdirectories, to be sure that there's a complete view of the whole system and a single state across the whole organization.</p>&#13;&#13;
      <p class="Information-Box--PACKT-">This also has its own challenges, and requires greater coordination across teams and can present big challenges for big repos.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">A single code base allows a strict differentiation of the stages in the <em class="italic">Build, release, run</em> factor. This factor ensures that there are three distinct stages: </p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet">The build stage transforms the content of the code repo into a package or executable that will be run later</li>&#13;&#13;
      <li class="bullet">The release stage uses this built package, combines it with the proper configuration for the selected environment, and sets it ready for execution</li>&#13;&#13;
      <li class="bullet">The run stage finally executes the package in the selected environment</li>&#13;&#13;
    </ul>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">As we discussed previously, the configuration lives in a different place to the code base. This separation makes sense, and it could be also under source control. It may be stored as files, but the access can then be separated by environment, something that makes sense, as some environments, like production, are more critical than others. Storing the configuration as part of the code base makes it difficult to perform that separation.</p>&#13;&#13;
      <p class="Information-Box--PACKT-">Keep in mind that more than one file can be combined, allowing the parameters to be separated into feature and operational configurations.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Because stages are strictly divided, it's not possible to change the configuration or the code after the code is deployed. This requires a new release in any case. This makes the releases very explicit, and each one should be executed independently. Note that the run stage may <a id="_idIndexMarker356"/>need to be executed again in case there's a new server or the server crashes, so the aim should be for this to be as easy to do as possible. As we are seeing, a common thread through the Twelve-Factor App is strict separation, so that each element is easy to recognize and to operate. We will check how to define the configuration in other factors.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">Performing tests after the build stage also ensures that the code remains without changes between the tests and the release and operation.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Because of this strict separation, in particular, in the build stage, it's easy to follow the <em class="italic">Dev/prod parity</em>. In essence, a development environment is the same as a production one, as they use the same building stage, but with proper configuration to run locally. This factor also makes it possible to use the same (or as close as possible) backing services, like databases or queues, to ensure that local development is as representative as a production environment. Container tools such as Docker, or provisioning tools such as Chef or Puppet, can also help in automatically setting up environments that contain all the required dependencies.</p>&#13;&#13;
    <p class="normal">Obtaining a fast and easy process to develop, build, and deploy is critical for speeding up the cycle and adjusting quickly.</p>&#13;&#13;
    <h2 id="_idParaDest-107" class="title">Dependencies and configurations</h2>&#13;&#13;
    <p class="normal">The Twelve-Factor App advocates the explicit definition of dependencies and configuration and, at the same time, is opinionated in terms of how to do them and provides <a id="_idIndexMarker357"/>solid standards that are proven.</p>&#13;&#13;
    <p class="normal">That is why, in the <em class="italic">Config</em> factor, it talks about storing all the configuration for the system in <strong class="keyword">environment</strong> <strong class="keyword">variables</strong>. Environment variables are independent from code, which allows <a id="_idIndexMarker358"/>retention of the strict differentiation that we talked about in the <em class="italic">Build, release, run factor</em> and avoidance of the problems that we described previously in storing them in files inside the code base. They are also language- and OS-independent, and easy to work with. Injecting environment variables into a new environment is also easy.</p>&#13;&#13;
    <p class="normal">This is preferred to other alternatives, such as setting different files into the code base describing environments like <code class="Code-In-Text--PACKT-">staging</code> or <code class="Code-In-Text--PACKT-">production</code>, because they allow more granularity, and because this kind of handling ends up creating too many files and changing the code for environments that are not affected; for example, having to update the code base for a <code class="Code-In-Text--PACKT-">demo</code> environment that is short-lived.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">Although the Twelve-Factor App encourages dealing with configurations in a variable-independent way, the reality of the work means that there are a limited number of environments and their configuration should be stored somewhere. The key element is storing it in a different place to the code base, managed only on the <em class="italic">release</em> stage. This allows plenty of flexibility.</p>&#13;&#13;
      <p class="Tip--PACKT-">Keep in mind that for local development, these environment variables may need to be changed independently to test or debug different features.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Configuration can be obtained in configuration files directly from the environment using standard libraries; for example, in Python:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> os&#13;&#13;
PARAMETER = os.environ['PATH']&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">This code will store in the constant <code class="Code-In-Text--PACKT-">PARAMETER</code> the value of the <code class="Code-In-Text--PACKT-">PATH</code> environment variable. Be careful as the lack of a <code class="Code-In-Text--PACKT-">PATH</code> environment variable will generate a <code class="Code-In-Text--PACKT-">KeyError</code> as it won't be present in the <code class="Code-In-Text--PACKT-">environ</code> dictionary. </p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">For the following examples, keep in mind that the defined environment variables need to be defined in your environment. These definitions are not included, to simplify the explanation. You can run Python, adding a local environment, by running <code class="Code-In-Text--PACKT-">$ MYENVVAR=VALUE python3</code>.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">To allow for optional environment variables, and protect against them going missing, use <code class="Code-In-Text--PACKT-">.get</code> to set up a default value:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">PARAMETER = os.environ.get('MYENVVAR', 'DEFAULT VALUE')&#13;&#13;
</code></pre>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">As a general recommendation, it's better to raise an exception because there's a missing configuration variable than to continue with a default parameter. This makes configuration problems easier to spot, as it will stop when the process starts, failing loudly. Remember, following the Twelve-Factor App ideas, you want to describe things explicitly and any problem should fail as early as possible in order to be able to fix it correctly instead of passing without detection.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Note <a id="_idIndexMarker359"/>that environment variables are always defined as text. If the value needs to be in a different format, it needs to be converted, for example:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">NUMBER_PARAMETER = <span class="hljs-built_in">int</span>(os.environ['ENVINTEGERPARAMETER'])&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">This presents a common problem when defining a <code class="Code-In-Text--PACKT-">Boolean</code> value. Defining this translation code as follows is incorrect:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">BOOL_PARAMETER = <span class="hljs-built_in">bool</span>(os.environ['ENVBOOLPARAMETER'])&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">If the value of <code class="Code-In-Text--PACKT-">ENVPARAMETER</code> is <code class="Code-In-Text--PACKT-">"TRUE"</code>, the value of <code class="Code-In-Text--PACKT-">BOOL_PARAMETER</code> is <code class="Code-In-Text--PACKT-">True</code> (Boolean). But if the value of <code class="Code-In-Text--PACKT-">ENVPARAMETER</code> is <code class="Code-In-Text--PACKT-">"FALSE"</code>, the value of <code class="Code-In-Text--PACKT-">BOOL_PARAMETER</code> is also <code class="Code-In-Text--PACKT-">True</code>.<code class="Code-In-Text--PACKT-"> </code>This is because the string <code class="Code-In-Text--PACKT-">"FALSE"</code> is a non-empty string and gets converted into <code class="Code-In-Text--PACKT-">True</code>. Instead, the standard library package, <code class="Code-In-Text--PACKT-">distutils</code>, can be used:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> os&#13;&#13;
<span class="hljs-keyword">from</span> distutils.util <span class="hljs-keyword">import</span> strtobool&#13;&#13;
BOOL_PARAMETER = strtobool(os.environ['ENVBOOLPARAMETER'])&#13;&#13;
</code></pre>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-"><code class="Code-In-Text--PACKT-">strtobool</code> returns not <code class="Code-In-Text--PACKT-">True</code> or <code class="Code-In-Text--PACKT-">False</code> as <code class="Code-In-Text--PACKT-">Booleans</code>, but <code class="Code-In-Text--PACKT-">0</code> or <code class="Code-In-Text--PACKT-">1</code> as integers. This normally works correctly, but if you need strict <code class="Code-In-Text--PACKT-">Boolean</code> values, add <code class="Code-In-Text--PACKT-">bool</code> like this: <code class="Code-In-Text--PACKT-">bool(strtobool(os.environ['ENVPARAMETER']))</code></p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Environment variables also allow the injection of sensitive values such as secrets without storing them in the code base. Keep in mind that the secret will be available to inspect in the environment of the execution, but typically that's protected so only authorized team members can access it through <code class="Code-In-Text--PACKT-">ssh</code> or similar in the environment. </p>&#13;&#13;
    <p class="normal">As part of this configuration, any <em class="italic">backing services</em> should be defined as well as environment variables. Backing services are external services that the app uses over the network. They could be databases, queues, caching systems, or suchlike. They can be local to the same network or external services, such as APIs handled by an external company or AWS services.</p>&#13;&#13;
    <p class="normal">From <a id="_idIndexMarker360"/>the point of view of the app, this differentiation should be irrelevant. The resources should be accessed by a URI and credentials, and, as part of the configuration, can be changed based on the environment. This makes the resources loosely coupled, and means they can be replaced easily. If there is a migration and the database needs to be moved between two networks, we can start the new database, perform a new release with a configuration change, and the app will point to the new database. This can be done with no code changes.</p>&#13;&#13;
    <p class="normal">To allow the concatenation of multiple applications, the <em class="italic">Port binding</em> factor ensures that any service exposed is a port, which may be different depending on the service. This makes it easy to consider each app a backing service. Preferably, it should be exposed in HTTP as this makes it very standard to connect to.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">For applications, use HTTP over port <code class="Code-In-Text--PACKT-">80</code> when possible. This makes all connections easy with URLs such as <code class="Code-In-Text--PACKT-">http://service-a.local/</code>.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Some applications require the combination of several processes working in conjunction. For example, it is typical for a web server for a Python application, such as Django, to use an application server like uWSGI to run it, and then a web server like nginx or Apache to serve it and the static files.</p>&#13;&#13;
    <figure class="mediaobject"><img src="Images/B17580_05_02.png" alt="Diagram&#13;&#10;&#13;&#10;Description automatically generated" width="826" height="223"/></figure>&#13;&#13;
    <p class="packt_figref">Figure 5.2: Connecting a web server and application server</p>&#13;&#13;
    <p class="normal">They all connect by exposing a known port and protocol, which makes the setup easy.</p>&#13;&#13;
    <p class="normal">On <a id="_idIndexMarker361"/>the same note, for clarity, all library <em class="italic">dependencies</em> should be explicitly set up and not rely on the pre-installation of certain packages in the existing operating system. The dependencies should be described through a dependency declaration, like a <code class="Code-In-Text--PACKT-">requisites.txt</code> pip file for Python. </p>&#13;&#13;
    <p class="normal">Dependencies should then be installed as part of the build stage, with commands such as <code class="Code-In-Text--PACKT-">pip install -r requirements.txt</code>.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">Keep in mind that the specific Python version is also a dependency that should be controlled tightly. The same is true of other required OS dependencies. Ideally, the OS environment should be created from scratch with the dependencies specified.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Even more so, dependencies should be isolated to ensure that there are no implicit dependencies that are not tightly controlled. Dependencies should also be defined as tightly as possible, to avoid the problem of different versions of dependencies being installed if new versions are released upstream.</p>&#13;&#13;
    <p class="normal">For example, in a pip file, a dependency can be described in different ways:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">requests&#13;&#13;
requests&gt;=v2.22.0&#13;&#13;
requests==v2.25.1&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">The first way accepts any version, so it will typically use the latest. The second describes a minimum (and optionally maximum) version. The third version pins a specific version.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">This is equivalent to other package management systems in operative systems, like <code class="Code-In-Text--PACKT-">apt</code> in Ubuntu. You can install a specific version with <code class="Code-In-Text--PACKT-">apt-get install dependency=version</code>.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Using <a id="_idIndexMarker362"/>very explicit dependencies makes the builds repeatable and deterministic. It ensures a lack of unknown changes during the build stage because a new version has been released. While most new packages will be compatible, it may also <em class="italic">sometimes</em> introduce changes that affect the behavior of the system. Even worse, those changes will be introduced <strong class="keyword">inadvertently</strong>, causing severe problems.</p>&#13;&#13;
    <h2 id="_idParaDest-108" class="title">Scalability</h2>&#13;&#13;
    <p class="normal">We talked earlier in the chapter about the why's of scalability. The Twelve-Factor App also talks <a id="_idIndexMarker363"/>about how to successfully grow or reduce the system.</p>&#13;&#13;
    <p class="normal">The <em class="italic">Processes</em> factor talks about making sure that the run stage consists of starting one or more processes. These processes should be stateless and share nothing, meaning that all the data needs to be retrieved from an external backing service like a database. A temporal local disk can be used for temporal data within the same request, although their use should be kept to a minimum.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">For example, a file upload may use the local hard drive to store a temporal copy and then process the data. After the data is processed, the file should be deleted from the disk.</p>&#13;&#13;
      <p class="Tip--PACKT-">If possible, try to use memory for this temporal storage as it will make this distinction more strict.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">The next property that processes need to fulfill is their <em class="italic">disposability</em>. The processes need to be able to be started and stopped quickly, and at any time. </p>&#13;&#13;
    <p class="normal">Starting quickly allows the system to react quickly to releases or restarts. The aim should be to take not more than a few seconds to have the process up and running. Quick turnaround is also important to allow rapid growth of the system in case more processes are being added for scale purposes.</p>&#13;&#13;
    <p class="normal">The opposite is to allow the graceful shutdown of the process. This can be required for scale-down situations, to be sure that any request is not interrupted in this case. By convention, processes should be stopped by sending the <code class="Code-In-Text--PACKT-">SIGTERM</code> signal.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">Working with Docker containers automatically uses this convection by sending a <code class="Code-In-Text--PACKT-">SIGTERM</code> signal to the main process whenever the container needs to be stopped. If the process doesn't stop itself after a grace period, it will be killed instead. The grace period can be configured if necessary.</p>&#13;&#13;
      <p class="Information-Box--PACKT-">Be sure that the main process for the container can receive <code class="Code-In-Text--PACKT-">SIGTERM</code> and deal with it properly to ensure a graceful stopping of the container.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">For example, for a web request, a graceful shutdown first will curtail the acceptance of any new <a id="_idIndexMarker364"/>requests, will finish any requests in the queue, and finally, will shut down the process. Web requests are typically quick to answer, but for other processes, such as long asynchronous tasks, it may take a long time to stop if they need to finish the current task.</p>&#13;&#13;
    <p class="normal">Instead, long task workers should return the job to the queue and cancel the execution. This way, the task will be performed again, and to ensure that this doesn't duplicate actions, we need to ensure that all tasks can be canceled by waiting until the end of it to save its results and wrapping them into a transaction or similar.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">In some cases, it may be necessary to distinguish between the bulk of the preparation job and the saving of results part. We either want to wait, if the job is saving the results at the time of shut down, or stop execution and return the task to the queue. Some save operations may require calling systems that don't accept transactions. The acceptable time for shutting down long-running processes may be longer than for web servers.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Processes should also be robust against unexpected stoppages. These stoppages could be caused by bugs, hardware errors, or, in general, unexpected surprises that always appear in software. Creating a resilient queue system that can retry in case a task is interrupted will help greatly in these instances.</p>&#13;&#13;
    <p class="normal">Because the system is created through processes, based on that, we can scale out by creating more of them. Processes are independent and can be run at the same time on the same server or others. This is the basis of the <em class="italic">Concurrency</em> factor. </p>&#13;&#13;
    <p class="normal">Keep in mind that the same application can use multiple processes that coordinate among them to handle different tasks and each process may have a different number of copies. In our <a id="_idIndexMarker365"/>previous example above, with an nginx server and uWSGI one, the optimal number may be to have a single nginx process for many more times the number of uWSGI workers.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">The traditional deployment process was to set up a physical server (or virtual machine) for a node and fit a number of elements, which normally included tailoring the number of workers until finding the optimal figure to make proper use of the hardware. </p>&#13;&#13;
      <p class="Information-Box--PACKT-">With containers, this process is somehow reversed. Containers tend to be more lightweight and more can be created. While the optimization process is still required, with containers, it's more about creating a unit and then checking how many of them a single node can fit, as containers can be moved around nodes more easily, and the resulting apps tend to be smaller. Instead of finding out what is the proper size of the application for a given server, we figure out how many copies of a small application fit in a server, knowing that we can use different server sizes or add more servers with ease.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Adding more nodes, as they are independent and stateless, becomes an easy operation under a Twelve-Factor App. That allows the size of the entire operation to be adjusted to the load of the system. This can be a manual operation, to slowly add new nodes as the system grows in load and requests, or it can be done automatically, as we described earlier in the chapter.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">The Twelve-Factor App doesn't demand that this scale is done automatically, but definitively enables it. Automating the adjustment should be treated with care, as it requires careful metrics on the load of the system. Allow time to perform tests to make the proper adjustments.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">The Twelve-factor App processes should also be run by some sort of operating system process manager, like <code class="Code-In-Text--PACKT-">upstart</code> or <code class="Code-In-Text--PACKT-">systemd</code>. These systems ensure that the processes remain running, even in the event of a crash, handle graceful manual restarts, and also manage output streams gracefully. We will talk more about output streams as part of logs.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">When working with containers, this changes a bit, as the equivalent is mostly handling containers more than processes. Instead of an operating system process manager, the work is performed by a container orchestrator that ensures that the containers are running properly and capturing any output stream. Inside the container, the processes can start without being under the control of a manager. The container will stop if the process is stopped.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Restarting the processes automatically, combined with a quick start up time and resilience in shutdown situations, makes the app dynamic and capable of self-repairing in case <a id="_idIndexMarker366"/>there is an unexpected problem that causes a process to crash. It also allows controlled shutdowns to be used as part of a general operation to avoid long-running processes and act as a contingency plan for memory leaks or other kinds of long-running problems.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">This is equivalent to the old trick of turning it off and then turning it back on! If it can be done very quickly, it can save a lot of situations!</p>&#13;&#13;
    </div>&#13;&#13;
    <h2 id="_idParaDest-109" class="title">Monitoring and admin</h2>&#13;&#13;
    <p class="normal">A comprehensive monitoring system is important for detecting problems and analyzing the <a id="_idIndexMarker367"/>operation of the system. While it's not the only monitoring tool, logs are a critical part of any monitoring system.</p>&#13;&#13;
    <p class="normal">Logs are text strings that provide visibility of the behavior of a running app. They should always include a timestamp on when they were generated. They are generated as the code is being executed, giving information on the different actions as they happen. The specifics about what to log can vary significantly by application, but typically frameworks will automatically create logs based on common practices.</p>&#13;&#13;
    <p class="normal">For example, any web-related software will log requests received, something like this, for example:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code">[16/May/2021 13:32:16] "GET /path HTTP/1.1" 200 10697&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">Note that it includes:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet">A timestamp for when it was generated <code class="Code-In-Text--PACKT-">[16/May/2021 13:32:16]</code></li>&#13;&#13;
      <li class="bullet">The HTTP <code class="Code-In-Text--PACKT-">GET</code> method and the <code class="Code-In-Text--PACKT-">HTTP/1.1</code> protocol</li>&#13;&#13;
      <li class="bullet">The accessed path – <code class="Code-In-Text--PACKT-">/path</code></li>&#13;&#13;
      <li class="bullet">The returned status code – <code class="Code-In-Text--PACKT-">200</code></li>&#13;&#13;
      <li class="bullet">The size of the request – <code class="Code-In-Text--PACKT-">10697</code></li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">This kind of log is called an access log and will be generated in different formats. At the very least, it should always include the timestamp, HTTP method, path, and status code, but it <a id="_idIndexMarker368"/>can be configured to return extra information, such as the IP of the client making the request, or the time that it took to process the request.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">Access logs are also generated by web servers including nginx and Apache. Configuring them properly to adjust the information produced is important for operational purposes.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Access logs are not the only useful ones. Application logs are also very useful. Application logs are generated inside the code and can be used to communicate significant milestones or errors. Web frameworks prepare the logs, so it's easy to generate new ones. For example, in Django, you can create logs this way:</p>&#13;&#13;
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> logging&#13;&#13;
logger = logging.getLogger(__name__)&#13;&#13;
...&#13;&#13;
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">view</span><span class="hljs-function">(</span><span class="hljs-params">request, arg</span><span class="hljs-function">):</span>&#13;&#13;
    logger.info('Testing condition')&#13;&#13;
    <span class="hljs-keyword">if</span> something_bad:&#13;&#13;
        logger.warning('Something bad happened')&#13;&#13;
</code></pre>&#13;&#13;
    <p class="normal">This will generate logs like these:</p>&#13;&#13;
    <pre class="programlisting con"><code class="hljs-con">2021-05-16 14:01:37,269 INFO Testing condition&#13;&#13;
2021-05-16 14:01:37,269 WARNING Something bad happened&#13;&#13;
</code></pre>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">We will get into more details about logs in <em class="chapterRef">Chapter 11</em>, <em class="italic">Package Management</em>.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">The <em class="italic">Logs</em> factor suggests that logs shouldn't be managed by the process itself. Instead, logs should be printed in their own standard output without any intermediate step. The environment surrounding the process, like the operating system process manager described in the <em class="italic">Concurrency</em> factor, should be charged with receiving the logs, combining them, and routing them properly to a long-term archival and monitoring system. Note that this configuration is totally out of the application's control. </p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">For local development, just showing the logs in a terminal may be enough for development purposes. </p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">This is in contrast to storing the logs as log files in the hard drive. This has the problem of requiring the logs to be rotated and ensure that there's enough space. This also requires <a id="_idIndexMarker369"/>the different processes to coordinate in terms of having a similar policy for log rotation and storage. Instead, standard outputs can be combined and aggregated together for a whole image of the system, and not a single process.</p>&#13;&#13;
    <p class="normal">The logs can also be directed <a id="_idIndexMarker370"/>toward an external log indexing system, such as the ELK Stack (Elasticsearch, Kibana, and Logstash: <a href="https://www.elastic.co/products/"><span class="url">https://www.elastic.co/products/</span></a>), which will capture logs and provide analytic tools to search <a id="_idIndexMarker371"/>through them. External tools are also available, including Loggly (<a href="https://www.loggly.com/"><span class="url">https://www.loggly.com/</span></a>) or Splunk (<a href="https://www.splunk.com/"><span class="url">https://www.splunk.com/</span></a>) to avoid maintenance. All these <a id="_idIndexMarker372"/>tools allow standard output logs to be captured and redirected to their solutions.</p>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">In the container world, this recommendation makes even more sense. Docker orchestration tools can easily capture the standard output from the containers and then redirect them to somewhere else. </p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">These other tools can provide capabilities like searching and finding specific events in a particular time window, observing trends such as changes in the number of requests per hour, and even creating automatic alerts based on certain rules, such as an increase in the number of <code class="Code-In-Text--PACKT-">ERROR</code> logs over a period of time over and above a certain value.</p>&#13;&#13;
    <p class="normal">The <em class="italic">Admin processes</em> factor covers some processes that sometimes need to be run for specific operations, but are not part of the app's normal operation. Examples include the following:</p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet">Database migrations</li>&#13;&#13;
      <li class="bullet">The production of ad hoc reports, such as generating a one-off report for certain sales or detecting how many records are affected by a bug</li>&#13;&#13;
      <li class="bullet">Running a console for debugging purposes</li>&#13;&#13;
    </ul>&#13;&#13;
    <div class="packt_tip">&#13;&#13;
      <p class="Tip--PACKT-">Executing commands in a console in a production environment should be used only when no other alternative is available, and not as a way of removing the need to create specific scripts for recurring operations. Extreme caution should apply. Keep in mind that an error in a production environment can create a serious problem. Treat your production environment with the proper respect.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">These operations are not part of the day-to-day operation, but may need to be run. The interface <a id="_idIndexMarker373"/>is clearly different. To execute them, they should run in the same environment as the regular processes, using the same code base and configuration. These admin operations should be included as part of the code base to avoid problems with mismatched code.</p>&#13;&#13;
    <p class="normal">In traditional environments, it may be necessary to log in to a server through <code class="Code-In-Text--PACKT-">ssh</code> to allow the execution of this process. In container environments, a full container can be started exclusively to execute the process.</p>&#13;&#13;
    <p class="normal">This is very common in cases of migrations, for example. A preparation command may consist of running the build to execute migrations. </p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">This should be done before the actual release, to ensure that the database is migrated. Refer to <em class="chapterRef">Chapter 4</em> for more details on migrations.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">To run these admin commands in containers, the container image should be the same one that runs the application, but called with a different command, so the code and environment are the same as in the running application. </p>&#13;&#13;
    <h1 id="_idParaDest-110" class="title">Containerized Twelve-Factor Apps</h1>&#13;&#13;
    <p class="normal">Although the Twelve-Factor App methodology is older than the current trend toward containerization <a id="_idIndexMarker374"/>using Docker and related tools, it's very aligned. Both tools are oriented toward scalable services in the cloud, and containers help to create patterns that match the ones described in the Twelve-Factor methodology.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">We will talk more about Docker containers in <em class="chapterRef">Chapter 8</em>, <em class="italic">Advanced Event-Driven Structures</em>.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">The most important, arguably, is the fact that the creation of an invariant container image that then gets run works very well with the <em class="italic">Build, release, run</em> factor and with being very explicit with <em class="italic">Dependencies</em>, as the whole image will include details such as the specific OS to use and any library. Including the build process as part of the repository also helps in the implementation of the <em class="italic">Code base</em> factor. </p>&#13;&#13;
    <p class="normal">Each container also works as a <em class="italic">Process</em>, which allows scaling by creating multiple copies of the same container, using the <em class="italic">Concurrency</em> model.</p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">While containers are usually thought of conceptually as lightweight virtual machines, it's better to think of them as a process wrapped in its own filesystem. This is closer to the way they operate.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">The concept of containers makes them easy to start and stop, leaning into the <em class="italic">Disposability</em> factor, and connecting one to another through an orchestration tool such as Kubernetes makes it easy to also set up the <em class="italic">Backing services</em> factor, and it's also easy to share services between specific ports in containers following the <em class="italic">Port binding</em> factor. In most cases, however, they'll be shared as web interfaces on the standard port <code class="Code-In-Text--PACKT-">80</code>.</p>&#13;&#13;
    <p class="normal">In Docker and orchestrator tools like Kubernetes, it is very easy to set up different environments injecting environment variables, thereby fulfilling the <em class="italic">Configuration</em> factor. This environment configuration, as well as a description of the cluster, can be stored in files, which allow multiple environments to be created easily. It also includes tools for handling properly secrets, so they are properly encrypted and are not stored in the configuration files to avoid leaking secrets.</p>&#13;&#13;
    <p class="normal">Another critical advantage of containers is the fact that a cluster can be replicated easily locally, as the same image that runs in production can run in a local environment, with only small changes in its configuration. This helps greatly in ensuring that the different environments are kept up to date, as demanded by the <em class="italic">Dev/Prod parity</em> factor. </p>&#13;&#13;
    <div class="note">&#13;&#13;
      <p class="Information-Box--PACKT-">In general, the container approach works toward defining a cluster and instigating a clear separation between different services and containers in a consistent manner. This brings together different environments, as the development environment can replicate the production setup on a small scale.</p>&#13;&#13;
    </div>&#13;&#13;
    <p class="normal">Sending information to standard output as per the <em class="italic">Logs</em> factor is also a great way to store logs as container tools will receive and deal with or redirect those logs adequately.</p>&#13;&#13;
    <p class="normal">Finally, the <em class="italic">Admin processes</em> can be handled by launching the same container image with a different command that runs the specific admin command. This can be handled by the <a id="_idIndexMarker375"/>orchestrator if it needs to happen regularly, such as running the migrations prior to a deployment, or if it's a periodic task.</p>&#13;&#13;
    <p class="normal">As we can see, working with containers is a great way of following the recommendations for the Twelve-Factor App, as the tools work in the same direction. This doesn't mean that they are done for free, but that there's a significant degree of alignment between the methodology and the ideas behind containers.</p>&#13;&#13;
    <p class="normal">This is not surprising as both come from a similar background, dealing with web services that need to be run in the cloud.</p>&#13;&#13;
    <h1 id="_idParaDest-111" class="title">Summary</h1>&#13;&#13;
    <p class="normal">In this chapter, we saw that it's good to have solid and reliable patterns to build software to be sure that we stand over the shoulder of tested decisions that we can use to shape new designs. For web services living in the cloud, we can use the Twelve-Factor App methodology as a guideline for a lot of useful advice.</p>&#13;&#13;
    <p class="normal">We discussed how the Twelve-Factor App is aligned with two main ideas – CI and scalability.</p>&#13;&#13;
    <p class="normal">CI is the practice of constantly validating any new code by running tests automatically after the code is shared. This creates a safety net that enables developers to move quickly, although it requires discipline to properly add automated tests as new features are being developed.</p>&#13;&#13;
    <p class="normal">We also discussed the concept of scalability, or the capacity for software to allow more load by adding more resources. We talked about why it is important to allow the software to grow and reduce based on the load, even to the point to be able to adjust dynamically. We also saw how making the system stateless is key to achieving scalable software.</p>&#13;&#13;
    <p class="normal">We saw the challenges for configuration, something that the Twelve-Factor App also deals with, and how not every configuration parameter is equal. We described how configuration can be divided into Operational configuration and Feature configuration, which can help divide and give the proper context to each parameter. </p>&#13;&#13;
    <p class="normal">We went through each of the factors for the Twelve-Factor App, and divided them into four different groups, relating them, and explaining how the different factors support each other. We divided the factors into groups: </p>&#13;&#13;
    <ul>&#13;&#13;
      <li class="bullet">Build once, run multiple times, based on the idea of generating a single package that runs in a different environment</li>&#13;&#13;
      <li class="bullet">Dependencies and configuration, around the configuration and software and service dependencies of the application</li>&#13;&#13;
      <li class="bullet">Scalability, to achieve the scalability that we talked about before</li>&#13;&#13;
      <li class="bullet">Monitoring and admin with other elements to deal with the operation of the software while in operation</li>&#13;&#13;
    </ul>&#13;&#13;
    <p class="normal">Finally, we spent some time talking about how the Twelve-Factor App ideas are very much in line with what containerization is about, and how different Docker features and concepts allow us to easily create Twelve-Factor Apps.</p>&#13;&#13;
  </div>&#13;&#13;
</div></body></html>