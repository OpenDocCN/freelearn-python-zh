- en: Chapter 13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Project 4.1: Visual Analysis Techniques'
  prefs: []
  type: TYPE_NORMAL
- en: When doing **exploratory data analysis** (**EDA**), one common practice is to
    use graphical techniques to help understand the nature of data distribution. The
    US **National Institute of Standards and Technology** (**NIST**) has an *Engineering
    Statistics Handbook* that strongly emphasizes the need for graphic techniques.
    See [https://doi.org/10.18434/M32189](https://doi.org/10.18434/M32189).
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will create some additional Jupyter notebooks to present a few
    techniques for displaying univariate and multivariate distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll focus on some important skills for creating diagrams
    for the cleaned data:'
  prefs: []
  type: TYPE_NORMAL
- en: Additional Jupyter Notebook techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using **PyPlot** to present data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit testing for Jupyter Notebook functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter has one project, to build the start of a more complete analysis
    notebook. A notebook can be saved and exported as a PDF file, allowing an analyst
    to share preliminary results for early conversations. In the next chapter, we’ll
    expand on the notebook to create a presentation that can be shared with colleagues.
  prefs: []
  type: TYPE_NORMAL
- en: Looking further down the road, a notebook can help to identify important aspects
    of the data that need ongoing monitoring. The computations created here will often
    become the basis for more fully automated reporting tools and notifications. This
    analysis activity is an important step toward understanding the data and designing
    a model for the data.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start with a description of an analysis notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 13.1 Description
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapters, the sequence of projects created a pipeline to acquire
    and then clean the raw data. The intent is to build automated data gathering as
    Python applications.
  prefs: []
  type: TYPE_NORMAL
- en: We noted that ad hoc data inspection is best done with a notebook, not an automated
    CLI tool. Similarly, creating command-line applications for analysis and presentation
    can be challenging. Analytical work seems to be essentially exploratory, making
    it helpful to have immediate feedback from looking at results.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, analytical work transforms raw data into information, and possibly
    even insight. Analytical results need to be shared to create significant value.
    A Jupyter notebook is an exploratory environment that can create readable, helpful
    presentations.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the first things to do with raw data is to create diagrams to illustrate
    the distribution of univariate data and the relationships among variables in multivariate
    data. We’ll emphasize the following common kinds of diagrams:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Histograms** A histogram summarizes the distribution of values for a variable
    in a dataset. The histogram will have data values on one axis and frequency on
    the other axis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scatter Plots** A scatter plot summarizes the relationships between values
    for two variables in a dataset. The visual clustering can be apparent to the casual
    observer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For small datasets, each relationship in a scatter plot can be a single dot.
    For larger datasets, where a number of points have similar relationships, it can
    be helpful to create “bins” that reflect how many points have the same relationship.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of ways of showing the size of these bins. This includes
    using a color code for more popular combinations. For some datasets, the size
    of an enclosing circle can show the relative concentration of similarly-valued
    data. The reader is encouraged to look at alternatives to help emphasize the interesting
    relationships among the attributes of the various samples.
  prefs: []
  type: TYPE_NORMAL
- en: The use of **Seaborn** to provide colorful styles is also important when working
    with diagrams. You are encouraged to explore various color palettes to help emphasize
    interesting data.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2 Overall approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll take some guidance from the C4 model ( [https://c4model.com](https://c4model.com))
    when looking at our approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Context**: For this project, the context diagram has two use cases: the acquire-to-clean
    process and this analysis notebook.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Containers**: There’s one container for analysis application: the user’s
    personal computer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Components**: The software components include the existing analysis models
    that provide handy definitions for the Python objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code**: The code is scattered in two places: supporting modules as well as
    the notebook itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A context diagram for this application is shown in [*Figure 13.1*](#13.1).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1: Context diagram ](img/file55.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.1: Context diagram'
  prefs: []
  type: TYPE_NORMAL
- en: The analyst will often need to share their analytical results with stakeholders.
    An initial notebook might provide confirmation that some data does not conform
    to the null hypothesis, suggesting an interesting relationship that deserves deeper
    exploration. This could be part of justifying a budget allocation to do more analysis
    based on preliminary results. Another possible scenario is sharing a notebook
    to confirm the null hypothesis is likely true, and that the variations in the
    data have a high probability of being some kind of measurement noise. This could
    be used to end one investigation and focus on alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [*Chapter** 6*](ch010.xhtml#x1-1460006), [*Project 2.1: Data Inspection
    Notebook*](ch010.xhtml#x1-1460006), the data inspection notebook was described.
    The use of a single acquisition model module for the data was mentioned, but the
    details of the Python implementation weren’t emphasized. The raw data module often
    provides little useful structure to the data when doing inspections.'
  prefs: []
  type: TYPE_NORMAL
- en: Moving forward into more complicated projects, we’ll see the relationship between
    the notebooks and the modules that define the data model become more important.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this analysis notebook, the analysis data model, created in [*Chapter** 9*](ch013.xhtml#x1-2080009),
    [*Project 3.1: Data Cleaning Base Application*](ch013.xhtml#x1-2080009), will
    be a central part of the notebook for doing analysis. This will be imported and
    used in the analysis notebook. The analysis process may lead to changes to the
    analysis model to reflect lessons learned.'
  prefs: []
  type: TYPE_NORMAL
- en: A technical complication arises from the directory structure. The data acquisition
    and cleaning applications are in the `src` directory, where the notebooks are
    kept in a separate `notebooks` directory.
  prefs: []
  type: TYPE_NORMAL
- en: When working with a notebook in the `notebooks` directory, it is difficult to
    make the Python `import` statement look into the adjacent `src` directory. The
    `import` statement scans a list of directories defined by the `sys.path` value.
    This value is seeded from some defined rules, the current working directory, and
    the value of the `PYTHONPATH` environment variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to make the `import` statement load modules from the adjacent
    `src` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: Put `../src` into the `PYTHONPATH` environment variable before starting JupyterLab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Put the absolute path to `../src` into the `sys.path` list after starting JupyterLab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The two are equivalent. The first can be done by updating one’s `~/.zshrc` file
    to make sure the `PYTHONPATH` environment variable is set each time a terminal
    session starts. There are other files appropriate for other shells; for example,
    `~/.bashrc` or `./rc` for the classic `sh` shell. For Windows, there’s a dialog
    that allows one to edit the system’s environment variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The alternative is to update `sys.path` with a cell containing code like the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This cell will add the peer `../src` directory to the system path. After this
    is done, the `import` statement will bring in modules from the `../src` directory
    as well as bringing in built-in standard library modules, and modules installed
    with **conda** or **pip**.
  prefs: []
  type: TYPE_NORMAL
- en: An initialization module can be defined as part of the IPython startup. This
    module can alter the `sys.path` value in a consistent way for a number of related
    notebooks in a project.
  prefs: []
  type: TYPE_NORMAL
- en: While some developers object to tinkering with `sys.path` in a notebook, it
    has the advantage of being explicit.
  prefs: []
  type: TYPE_NORMAL
- en: Setting `PYTHONPATH` in one’s `~/.zshrc` file is a very clean and reliable solution.
    It then becomes necessary to put a reminder in a `README` file so that new team
    members can also make this change to their personal home directory.
  prefs: []
  type: TYPE_NORMAL
- en: When sharing notebooks, it becomes imperative to make sure all stakeholders
    have access to the entire project the notebook depends on. This can lead to a
    need to create a Git repository that contains the notebook being shared along
    with reminders, test cases, and needed modules.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the path defined properly, the notebook can share classes and functions
    with the rest of the applications. We’ll move on to looking at one possible organization
    of an analysis notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2.1 General notebook organization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An analytical notebook is often the primary method for presenting and sharing
    results. It differs from a “lab” notebook. It’s common for lab notebooks to contain
    a number of experiments, some of which are failures, and some of which have more
    useful results. Unlike a lab notebook, an analytical notebook needs to have a
    tidy organization with carefully-written Markdown cells interspersed with data
    processing cells. In effect, an analysis notebook needs to tell a kind of story.
    It needs to expose actors and actions and the consequences of those actions.
  prefs: []
  type: TYPE_NORMAL
- en: It’s essential that the notebook’s cells execute correctly from beginning to
    end. The author should be able to restart the kernel and run all of the cells
    at any time to redo the computations. While this may be undesirable for a particularly
    long-running computation, it still must be true.
  prefs: []
  type: TYPE_NORMAL
- en: A notebook may have preliminary operations that aren’t relevant to most readers
    of the report. A specific example is setting the `sys.path` to import modules
    from an adjacent `../src` directory. It can be helpful to make use of JupyterLab’s
    ability to collapse a cell as a way to set some of the computation details aside
    to help the reader focus on the key concepts.
  prefs: []
  type: TYPE_NORMAL
- en: It seems sensible to formalize this with Markdown cells to explain the preliminaries.
    The remaining cells in this section can be collapsed visually to minimize distractions.
  prefs: []
  type: TYPE_NORMAL
- en: The preliminaries can include technical and somewhat less technical aspects.
    For example, setting `sys.path` is purely technical, and few stakeholders will
    need to see this. On the other hand, reading the `SeriesSample` objects from an
    ND JSON format file is a preliminary step that’s somewhat more relevant to the
    stakeholder’s problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the preliminaries, the bulk of the notebook can focus on two topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Summary statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll look at the summary statistics in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2.2 Python modules for summarizing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For initial reports, Python’s `statistics` module offers a few handy statistical
    functions. This module offers `mean()`, `median()`, `mode()`, `stdev()`, `variance()`.
    There are numerous other functions here the reader is encouraged to explore.
  prefs: []
  type: TYPE_NORMAL
- en: These functions can be evaluated in a cell, and the results will be displayed
    below the cell. In many cases, this is all that’s required.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a few cases, though, results need to be truncated to remove meaningless
    trailing digits. In other cases, it can help to use an f-string to provide a label
    for a result. A cell might look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This provides a label, and truncates the output to two places to the right of
    the decimal point.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, we might want to incorporate computed values into markdown cells.
    The **Python Markdown** extension provides a tidy way to incorporate computed
    values into markdown content.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/python-markdown/readme.html](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/python-markdown/readme.html).
  prefs: []
  type: TYPE_NORMAL
- en: The most important part of the notebook is the graphic visualization of the
    data, we’ll turn to that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2.3 PyPlot graphics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **matplotlib** package works well for creating images and diagrams. Within
    this extensive, sophisticated graphic library is a smaller library, `pyplot`,
    that’s narrowly focused on data visualizations. Using the `pyplot` library permits
    a few lines of code to create a useful display of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The module is often renamed to make it easier to type. The common convention
    is shown in the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This lets us use `plt` as a namespace to refer to functions defined in the `pyplot`
    module of the `matplotlib` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, JupyterLab may not have the `matplotlib` library prepared for
    interactive use. (This will be clear when the plotted images are not shown in
    the notebook.) In these cases, the interactive use of the `matplotlib` library
    needs to be enabled. Use the following magic commands in a cell of the notebook
    to enable interactive use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The first command enables the `matplotlib` library to create graphics immediately
    in the notebook. It won’t create separate files or pop-up windows. The second
    command produces readily-shared PNG output files. It also helps **MAC OS X** users
    to optimize the graphics for their high-resolution displays.
  prefs: []
  type: TYPE_NORMAL
- en: This isn’t always required. It’s needed only for those installations that didn’t
    configure the `matplotlib` library for interactive use in a Jupyter notebook.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, the `pyplot` library expects simple sequences of values for the
    various plotting functions. The *x* and *y* values of a scatter plot, for example,
    are expected to be two parallel lists of the same length. This will lead to a
    few extra cells to restructure data.
  prefs: []
  type: TYPE_NORMAL
- en: The data cleaning applications from previous chapters produced a single sequence
    of compound sample objects. Each object was a separate sample, with the related
    values for all of the variables. We’ll need to convert from this sample record
    organization to parallel sequences of values for the individual variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can involve something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'An alternative is to use the `operator.attrgetter()` function. It looks like
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We’ll start with a histogram to show the distribution of values for a single
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: Data frequency histograms
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Often, a document — like a book — has individual figures. A figure may contain
    a single plot. Or, it may contain a number of “subplots” within a single figure.
    The `pyplot` library provides support for creating a single figure that contains
    many subplots. The idea of a figure with a single plot can be seen as a special
    case of this generalized approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'A figure with a single plot can be prepared with a statement like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `fig` object is the figure as a whole. The `ax` object is the set of axes
    for the subplot within the figure. While the explicit `ax` object can seem unnecessary,
    it’s part of a more general approach that allows figures with related plots to
    be built.
  prefs: []
  type: TYPE_NORMAL
- en: 'The more general case stacks multiple subplots within a figure. The `sublots()`
    function can return axes for each subplot. The call to create a two-plot figure
    might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here we’ve stated we’ll have 1 row with 2 subplots stacked next to each other.
    The `fig` object is the figure as a whole. The `ax_0` and `ax_1` objects are the
    sets of axes for each of these two subplots within the figure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of creating a single histogram from the `y` values of one
    of the four Anscombe’s quartet series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For this example, the `y` variable must be a list of *y* attribute values from
    Series I. The series data must be read from the cleaned source file.
  prefs: []
  type: TYPE_NORMAL
- en: The `_`` =`` ax.hist(...)` statement assigns the results of the `hist()` function
    to the variable `_` as a way to suppress displaying the result value in this cell.
    Without this assignment statement, the notebook will show the result of the `hist()`
    function, which isn’t very interesting and clutters up the output. Since each
    series has both an *x* and a *y* value, it helps to stack two histograms that
    shows the distribution of these values. The reader is encouraged to develop a
    figure with two stacked subplots.
  prefs: []
  type: TYPE_NORMAL
- en: The number of options for color and borders on the histogram bars are breathtaking
    in their complexity. It helps to try several variants in a single notebook and
    then delete the ones that aren’t helpful.
  prefs: []
  type: TYPE_NORMAL
- en: The comparison between values is often shown in a scatter plot that shows each
    (*x,y*) pair. We’ll look at this next.
  prefs: []
  type: TYPE_NORMAL
- en: X-Y scatter plot
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A scatter plot is one of many ways to show the relationship between two variables.
    Here’s an example of creating a single plot from the `x` and `y` values of one
    of the four Anscombe’s quartet series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `_`` =`` ax.scatter(...)` statement assigns the results of the `scatter()`
    function to the variable `_` as a way to suppress displaying the value. This keeps
    the output focused on the figure.
  prefs: []
  type: TYPE_NORMAL
- en: 'The above example presumes the data have been extracted from a sequence of
    `SeriesSample` instances using code like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This, in turn, presumes the value for `series_1` was read from the clean data
    created by the **acquire** and **clean** applications.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an approach to building the notebook, we can address the way
    notebooks tend to evolve.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2.4 Iteration and evolution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A notebook is often built iteratively. Cells are added, removed, and modified
    as the data is understood.
  prefs: []
  type: TYPE_NORMAL
- en: On a purely technical level, the Python programming in the cells needs to evolve
    from a good idea to software that’s testable. It’s often easiest to do this by
    rewriting selected cells into functions. For example, define a function to acquire
    the ND JSON data. This can be supplemented by `doctest` comments to confirm the
    function works as expected.
  prefs: []
  type: TYPE_NORMAL
- en: A collection of functions can be refactored into a separate, testable module
    if needed. This can permit wider reuse of good ideas in multiple notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: Equally important is to avoid “over-engineering” a notebook. It’s rarely worth
    the time and effort to carefully specify the contents of a notebook, and then
    write code that meets those specifications. It’s far easier to create — and refine
    — the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: In some large organizations, a senior analyst may direct the efforts of junior
    analysts. In this kind of enterprise, it can be helpful to provide guidance to
    junior analysts. When formal methods are needed, the design guidance can take
    the form of a notebook with markdown cells to explain the desired goal.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an approach to building the notebook, we can enumerate the
    deliverables for this project.
  prefs: []
  type: TYPE_NORMAL
- en: 13.3 Deliverables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This project has the following deliverables:'
  prefs: []
  type: TYPE_NORMAL
- en: A `requirements-dev.txt` file that identifies the tools used, usually `jupyterlab==3.5.3`
    and `matplotlib==3.7.0`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation in the `docs` folder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit tests for any new application modules in the `tests` folder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any new application modules in the `src` folder with code to be used by the
    inspection notebook.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A notebook to summarize the clean data. In the case of Anscombe’s quartet, it’s
    essential to show the means and variances are nearly identical, but the scatter
    plots are dramatically different.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll look at a few of these deliverables in a little more detail.
  prefs: []
  type: TYPE_NORMAL
- en: 13.3.1 Unit test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two distinct kinds of modules that can require testing:'
  prefs: []
  type: TYPE_NORMAL
- en: The notebook with any function or class definitions. All of these definitions
    require unit tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If functions are factored from the notebook into a supporting module, this module
    will need unit tests. Many previous projects have emphasized these tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A notebook cell with a computation cell is notoriously difficult to test. The
    visual output from the `hist()` or `scatter()` functions seems almost impossible
    to test in a meaningful way.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, there are numerous usability tests that can’t be automated. Poor
    choice of colors, for example, can obscure an important relationship. Consider
    the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Is it informative?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it relevant?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it misleading in any way?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In many cases, these questions are difficult to quantify and difficult to test.
    As a consequence, it’s best to focus automated testing on the Python programming.
  prefs: []
  type: TYPE_NORMAL
- en: It’s imperative to avoid testing the internals of `matplotlib.pyplot`.
  prefs: []
  type: TYPE_NORMAL
- en: What’s left to test?
  prefs: []
  type: TYPE_NORMAL
- en: The data loading.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any ad hoc transformations that are part of the notebook.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data loading should be reduced to a single function that creates a sequence
    of `SeriesSample` instances from the lines in an ND JSON file of clean data. This
    loading function can include a test case.
  prefs: []
  type: TYPE_NORMAL
- en: 'We might define the function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This permits testing by adding a cell to the notebook that includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This cell will find the functions defined by the notebook, extract any doctest
    cases from the docstrings in the function definitions, and confirm the doctest
    cases pass.
  prefs: []
  type: TYPE_NORMAL
- en: For more complicated numerical processing, the **hypothesis** library is helpful.
    See [*Hypothesis testing*](ch014.xhtml#x1-2600001) in [*Chapter** 10*](ch014.xhtml#x1-22900010),
    [*Data Cleaning Features*](ch014.xhtml#x1-22900010) for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 13.3.2 Acceptance test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An automated acceptance test is difficult to define for a notebook. It’s hard
    to specify ways in which a notebook is helpful, meaningful, or insightful in the
    simple language of Gherkin scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: The `jupyter`` execute`` <filename>` command will execute an `.ipynb` notebook
    file. This execution is entirely automated, allowing a kind of sanity check to
    be sure the notebook runs to completion. If there is a problem, the command will
    exit with a return code of 1, and the cell with the error will be displayed in
    detail. This can be handy for confirming the notebook isn’t trivially broken.
  prefs: []
  type: TYPE_NORMAL
- en: The `.ipynb` file is a JSON document. An application (or a step definition for
    **Behave**) can read the file to confirm some of its properties. An acceptance
    test case might look for error messages, for example, to see if the notebook failed
    to work properly.
  prefs: []
  type: TYPE_NORMAL
- en: Cells with `"type":`` "code"` will also have `"outputs"`. If one of the outputs
    has `"output_type":`` "error"`; this cell indicates a problem in the notebook.
    The notebook did not run to completion, and the acceptance test should be counted
    as a failure.
  prefs: []
  type: TYPE_NORMAL
- en: We can use projects like **Papermill** to automate notebook refresh with new
    data. This project can execute a template notebook and save the results as a finalized
    output notebook with values available and computations performed.
  prefs: []
  type: TYPE_NORMAL
- en: For more information, see [https://papermill.readthedocs.io](https://papermill.readthedocs.io).
  prefs: []
  type: TYPE_NORMAL
- en: 13.4 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This project begins the deeper analysis work on clean data. It emphasizes several
    key skills, including:'
  prefs: []
  type: TYPE_NORMAL
- en: More advanced Jupyter Notebook techniques. This includes setting the `PYTHONPATH`
    to import modules and creating figures with plots to visualize data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using **PyPlot** to present data. The project uses popular types of visualizations:
    histograms and scatter plots.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit testing for Jupyter Notebook functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we’ll formalize the notebook into a presentation “slide
    deck” that can be shown to a group of stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: 13.5 Extras
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here are some ideas for the reader to add to these projects.
  prefs: []
  type: TYPE_NORMAL
- en: 13.5.1 Use Seaborn for plotting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An alternative to the **pyplot** package is the **Seaborn** package. This package
    also provides statistical plotting functions. It provides a wider variety of styling
    options, permitting more colorful (and perhaps more informative) plots.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://seaborn.pydata.org](https://seaborn.pydata.org) for more information.
  prefs: []
  type: TYPE_NORMAL
- en: This module is based on `matplotlib`, making it compatible with JupyterLab.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the **Seaborn** package can work directly with a list-of-dictionary
    structure. This matches the ND JSON format used for acquiring and cleaning the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Using a list-of-dictionary type suggests it might be better to avoid the analysis
    model structure, and stick with dictionaries created by the **clean** application.
    Doing this might sacrifice some model-specific processing and validation functionality.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the `pydantic` package offers a built-in `dict()` method
    that covers a sophisticated analysis model object into a single dictionary, amenable
    to use with the **Seaborn** package. This seems to be an excellent way to combine
    these packages. We encourage the reader to explore this technology stack.
  prefs: []
  type: TYPE_NORMAL
- en: 13.5.2 Adjust color palettes to emphasize key points about the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Both the **pyplot** package and the **Seaborn** package have extensive capabilities
    for applying color to the plot. A choice of colors can sometimes help make a distinction
    visible, or it can obscure important details.
  prefs: []
  type: TYPE_NORMAL
- en: You can consider alternative styles to see which seems more useful.
  prefs: []
  type: TYPE_NORMAL
- en: In some enterprise contexts, there are enterprise communications standards,
    with colors and fonts that are widely used. An important technique when using
    Seaborn is to create a style that matches enterprise communication standards.
  prefs: []
  type: TYPE_NORMAL
- en: A number of websites provide website color schemes and design help. Sites like
    [https://paletton.com](https://paletton.com) or [colordesigner.io](https://colordesigner.io)
    provide complementary color palettes. With some effort, we can take these kinds
    of designs for color palettes and create Seaborn styles that permit a consistent
    and unique presentation style.
  prefs: []
  type: TYPE_NORMAL
