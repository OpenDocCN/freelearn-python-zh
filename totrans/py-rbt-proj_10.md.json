["```py\ngit clone https://github.com/opencv/opencv/tree/master/data/haarcascades\n```", "```py\nimport cv2\nimport numpy as np\n\nface_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n\ncap = cv2.VideoCapture(0)\n\nwhile True:\n\n        ret, img = cap.read()\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        faces = face_cascade.detectMultiScale(gray)\n\n        for (x,y,w,h) in faces:\n           cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n\n        cv2.imshow('img',img)\n\n        k = cv2.waitKey(1) & 0xff\n        if k == ord(‘q’):\n                break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nface_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n```", "```py\ncap = cv2.VideoCapture(0)\n```", "```py\n        ret, img = cap.read()\n```", "```py\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n```", "```py\n        faces = face_cascade.detectMultiScale(gray)\n```", "```py\n        for (x,y,w,h) in faces:\n           cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n```", "```py\n        cv2.imshow('img',img)\n```", "```py\n        k = cv2.waitKey(1) & 0xff\n        if k == ord(‘q’):\n                break\n```", "```py\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nimport cv2\nimport numpy as np\n\nfaceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\ncam = cv2.VideoCapture(0)\n\nsampleNum = 0\n\nid = raw_input('enter user id')\n\nwhile True:\n        ret,img = cam.read()\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        faces = faceDetect.detectMultiScale(gray,1.3,5)\n\n        for (x,y,w,h) in faces:\n                sampleNum = sampleNum + 1\n                cv2.imwrite(\"dataSet/User.\"+str(id)+\".\"+str(sampleNum)+\".jpg\",  gray[y:y+h, x:x+w])\n\n                cv2.rectangle(img, (x,y), (x+w,y+h), (0,0,255), 2)\n                cv2.waitKey(100)\n        cv2.imshow(\"Face\", img)\n        cv2.waitKey(1)\n        if sampleNum>20:\n\n                break\ncam.release()\ncv2.destroyAllWindows()\n```", "```py\nfaceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\ncam = cv2.VideoCapture(0)\n```", "```py\nid = raw_input('enter user id')\n```", "```py\n        ret,img = cam.read()\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n```", "```py\n        faces = faceDetect.detectMultiScale(gray,1.3,5)\n```", "```py\n        for (x,y,w,h) in faces:\n                sampleNum = sampleNum + 1\n                cv2.imwrite(\"dataSet/User.\"+str(id)+\".\"+str(sampleNum)+\".jpg\",  gray[y:y+h, x:x+w])\n```", "```py\ncv2.inwrite('dataSet/User.\"+str(id)+\".\"+str(sampleNum)+\".jpg\",gray[y:y+h,x:x+w])\n```", "```py\nsudo -H pip install pillow\n```", "```py\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image\n\nrecognizer = cv2.face.LBPHFaceRecognizer_create()\n\npath = 'dataSet'\n\ndef getImageID(path):\n    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]\n\n    faces=[]\n    IDs=[]\n\n    for imagePath in imagePaths:\n        faceImg = Image.open(imagePath).convert('L')\n\n       faceNp = np.array(faceImg, 'unit8')\n\n        ID = int(os.path.split(imagePath)[-1].split('.')[1])\n\n        faces.append(faceNp)\n        print ID\n        IDs.append(ID)\n\n    return IDs, faces\n\nIds, faces = getImageID(path)\nrecognizer.train(faces, np.array(Ids))\nrecognizer.save('recognizer/trainningData.yml')\n\ncv2.destroyAllWindows()\n```", "```py\nrecognizer = cv2.face.LBPHFaceRecognizer_create()\n```", "```py\npath = 'dataSet'\n```", "```py\ndef getImageID(path):\n    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]\n```", "```py\n    for imagePath in imagePaths:\n        faceImg = Image.open(imagePath).convert('L')\n```", "```py\nfaceNp = np.array(faceImg, 'unit8')\n```", "```py\n        ID = int(os.path.split(imagePath)[-1].split('.')[1])\n```", "```py\n        faces.append(faceNp)\n        print ID\n        IDs.append(ID)\n```", "```py\n    return IDs, faces\n```", "```py\nIds, faces = getImageID(path)\nrecognizer.train(faces, np.array(Ids))\nrecognizer.save('recognizer/trainningData.yml')\n```", "```py\nimport numpy as np\nimport cv2\n\nfaceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n\ncam = cv2.VideoCapture(0)\nrec = cv2.face.LBPHFaceRecognizer_create()\n\nrec.read(\"recognizer/trainningData.yml\")\nid = 0\nfont = cv2.FONT_HERSHEY_SIMPLEX\n\nwhile True:\n\n   ret, img = cam.read()\n   gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n   faces = faceDetect.detectMultiScale(gray,1.3,5)\n\n   for (x,y,w,h) in faces:\n       cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,255), 2)\n       id, conf = rec.predict(gray[y:y+h, x:x+w])\n\n       if id==1:\n           id = \"BEN\"\n       cv2.putText(img, str(id), (x,y+h),font,2, (255,0,0),1,)\n\n    cv2.imshow(\"face\", img)\n\n    if cv2.waitKey(1)==ord('q'):\n       break\n\ncam.release()\ncv2.destroyAllWindows()\n```", "```py\nfont = cv2.FONT_HERSHEY_SIMPLEX\n```", "```py\nid, conf = rec.predict(gray[y:y+h, x:x+w])\n```", "```py\n       if id==1:\n           id = \"BEN\"\n```", "```py\n     cv2.putText(img, str(id), (x,y+h),font,2, (255,0,0),1,)\n```", "```py\nimport numpy as np\nimport cv2\nImport RPi.GPIO as GPIO\n\nMotor1F = 20\nMotor1R = 21\nMotor2F = 2\nMotor2R = 3\nBuzzer = 24\n\nGPIO.setmode(GPIO.BCM)  \nGPIO.setwarnings(False)\nGPIO.setup(Motor1a,GPIO.OUT)\nGPIO.setup(Motor1b,GPIO.OUT)\nGPIO.setup(Motor2a,GPIO.OUT)\nGPIO.setup(Motor2b,GPIO.OUT)\nGPIO.setup(Buzzer, GPIO.OUT)\n\ndef forward():\n\n        GPIO.output(Motor1F,1)\n        GPIO.output(Motor1R,0)\n        GPIO.output(Motor2F,1)\n        GPIO.output(Motor2R,0)\n\ndef backward():\n\n        GPIO.output(Motor1F,0)\n        GPIO.output(Motor1R,1)\n        GPIO.output(Motor2F,0)\n        GPIO.output(Motor2R,1)\n\ndef stop():\n\n        GPIO.output(Motor1F,0)\n        GPIO.output(Motor1R,0)\n        GPIO.output(Motor2F,0)\n        GPIO.output(Motor2R,0)\n\nfaceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n\ncam = cv2.VideoCapture(0)\nrec = cv2.face.LBPHFaceRecognizer_create()\nrec.read(\"recognizer/trainningData.yml\")\n\nid = 0\nfont = cv2.FONT_HERSHEY_SIMPLEX\n\nwhile True:\n\n ret, img = cam.read()\n gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n faces = faceDetect.detectMultiScale(gray,1.3,5)\n\n for (x,y,w,h) in faces:\n     cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,255), 2)\n     id, conf = rec.predict(gray[y:y+h, x:x+w])\n\n     if id==1:\n         id = \"BEN\"\n\n         forward()\n         time.sleep(1)\n         stop()\n         time.sleep(5)\n         backward()\n         time.sleep(1)\n\n     else :\n\n         GPIO.output(Buzzer, 1)\n         time.sleep(5)\n\n     cv2.putText(img, str(id), (x,y+h),font,2, (255,0,0),1,cv2.LINE_AA)\n     cv2.imshow(\"face\", img)\n\n id = 0 \n if cv2.waitKey(1)==ord('q'):\n break\n\ncam.release()\ncv2.destroyAllWindows()\n```", "```py\ndef forward():\n\n        GPIO.output(Motor1a,0)\n        GPIO.output(Motor1b,1)\n        GPIO.output(Motor2a,0)\n        GPIO.output(Motor2b,1)\n\ndef backward():\n\n        GPIO.output(Motor1a,1)\n        GPIO.output(Motor1b,0)\n        GPIO.output(Motor2a,1)\n        GPIO.output(Motor2b,0)\n\ndef stop():\n\n        GPIO.output(Motor1a,0)\n        GPIO.output(Motor1b,0)\n        GPIO.output(Motor2a,0)\n        GPIO.output(Motor2b,0)\n```", "```py\nfaceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n```", "```py\n for (x,y,w,h) in faces:\n     cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,255), 2)\n     id, conf = rec.predict(gray[y:y+h, x:x+w])\n\n     if id==1:\n         id = \"BEN\"\n\n         forward()\n         time.sleep(1)\n         stop()\n         time.sleep(5)\n         backward()\n         time.sleep(1)\n\n     else :\n\n         GPIO.output(Buzzer, 1)\n         time.sleep(5)\n```"]