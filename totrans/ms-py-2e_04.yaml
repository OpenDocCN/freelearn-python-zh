- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pythonic Design Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter covered a lot of guidelines for what to do and what to
    avoid in Python. Next, we will explore a few examples of how to work in a Pythonic
    way using the modules included with Python.
  prefs: []
  type: TYPE_NORMAL
- en: Design patterns are largely dependent on storing data; for this, Python comes
    bundled with several very useful collections. The most basic collections such
    as `list`, `tuple`, `set`, and `dict` will already be familiar to you, but Python
    also comes bundled with more advanced collections. Most of these simply combine
    the basic types for more powerful features. In this chapter, I will explain how
    to use these data types and collections in a Pythonic fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Before we can properly discuss data structures and related performance, a basic
    understanding of time complexity (and specifically the big O notation) is required.
    The concept is really simple, but without it, I cannot easily explain the performance
    characteristics of operations and why seemingly nice-looking code can perform
    horribly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, once the big O notation is clear, we will discuss some data
    structures and I will show you some example design patterns, along with how to
    use them. We will start with the following basic data structures:'
  prefs: []
  type: TYPE_NORMAL
- en: '`list`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dict`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`set`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tuple`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Building on the basic data structures, we will continue with more advanced
    collections, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dictionary-like types:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ChainMap`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Counter`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Defaultdict`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OrderedDict`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'List types: `heapq`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tuple types: `dataclass`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other types: `enum`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time complexity – The big O notation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we can begin with this chapter, there is a simple notation that you need
    to understand. This chapter uses the big O notation to indicate the time complexity
    for an operation. Feel free to skip this section if you are already familiar with
    this notation. While the notation sounds really complicated, the concept is actually
    quite simple.
  prefs: []
  type: TYPE_NORMAL
- en: The big O letter refers to the capital version of the Greek letter Omicron,
    which means small-o (micron o).
  prefs: []
  type: TYPE_NORMAL
- en: When we say that a function takes `O(1)` time, it means that it generally only
    takes `1` step to execute. Similarly, a function with `O(n)` time would take `n`
    steps to execute, where `n` is generally the size (or length) of the object. This
    time complexity is just a basic indication of what to expect when executing the
    code, as it is generally what matters most.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to O, several other characters might pop up in literature. Here’s
    an overview of the characters used:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Ο` Big Omicron: The upper bound/worst-case scenario.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Ω` Big Omega: The lower bound/best-case scenario.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Θ` Big Theta: The tight bound, which means both O and Ω are identical.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good example of an algorithm where these differ a lot is the quicksort algorithm.
    The quicksort algorithm is one of the most widely used sorting algorithm, which
    is surprising if you only look at time complexity according to the (big) O. The
    worst case for quicksort is `O(n**2)` and the best case is either `Ω(n log n)`
    or `Ω(n)`, depending on the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Given the worst case of `O(n**2)`, you might not expect the algorithm to be
    used a lot, but it has been the default sorting algorithm for many programming
    languages. Within C, it is still the default; for Java, it was the default up
    to Java 6; and Python used it up to 2002\. So, why is/was quicksort so popular?
    For quicksort, it is very important to look at the average case, which is far
    more likely to occur than the worst case. Indeed, the average case is `O(n log
    n)`, which is really good for a sorting algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of the big O notation is to indicate the approximate performance
    of an operation based on the number of steps that need to be executed. A piece
    of code that executes a single step 1,000 times faster but needs to execute `O(2**n)`
    steps will still be slower than another version of it that takes only `O(n)` steps
    for a value of `n` equal to 10 or more.
  prefs: []
  type: TYPE_NORMAL
- en: This is because `2**n` for `n=10` is `2**10=1024`, which is 1,024 steps to execute
    the same code. This makes choosing the right algorithm very important, even when
    using languages such as `C`/`C++`, which are generally expected to perform better
    than Python with the CPython interpreter. If the code uses the wrong algorithm,
    it will still be slower for a non-trivial `n`.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose you have a list of 1,000 items and you walk through them.
    This will take `O(n)` time because there are `n=1000` items. Checking to see whether
    an item exists in a list means silently walking through the items in a similar
    way, which means it also takes `O(n)`, so that’s 1,000 steps.
  prefs: []
  type: TYPE_NORMAL
- en: If you do the same with a `dict` or `set` that has 1,000 keys/items, it will
    only take `O(1)` step because of how a `dict`/`set` is structured. How the `dict`
    and `set` are structured internally will be covered later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: This means that if you want to check the existence of 100 items in that `list`
    or `dict`, it will take you `100*O(n)` for the `list` and `100*O(1)` for the `dict`
    or `set`. That is the difference between 100 steps and 100,000 steps, which means
    that the `dict`/`set` is `n` or 1,000 times faster in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though the code seems very similar, the performance characteristics vary
    enormously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To illustrate `O(1)`, `O(n)`, and `O(n**2)` functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To illustrate this, we will look at some slower-growing functions first:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_04_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1: Time complexity of slow-growing functions with n=1 to n=10,000'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the `O(log(n))` function scales really well with larger numbers;
    this is why a binary search is so incredibly fast, even for large datasets. Later
    in this chapter, you will see an example of a binary search algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `O(n*log(n))` result shows a rather fast growth, which is undesirable,
    but better than some of the alternatives, as you can see in *Figure 4.2* with
    faster-growing functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15882_04_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: Time complexity of fast-growing functions with n=1 to n=10'
  prefs: []
  type: TYPE_NORMAL
- en: Looking at these charts, the `O(n*log(n))` looks quite good by comparison. As
    you will see later in this chapter, many sorting algorithms use `O(n*log(n))`
    functions and some use `O(n**2)`.
  prefs: []
  type: TYPE_NORMAL
- en: These algorithms quickly grow to an incalculable size; the `O(2**n)` function,
    for example, already takes 1,024 steps with 10 items and doubles with every step.
    A famous example of this is the current solution to the Towers of Hanoi problem,
    where `n` is the number of disks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `O(n!)` factorial function is far worse and becomes impossibly large after
    just a few steps. One of the most famous examples of this is the Traveling Salesman
    problem: finding the shortest route covering a list of cities exactly once.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll dive into core collections.
  prefs: []
  type: TYPE_NORMAL
- en: Core collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we can look at the more advanced combined collections later in this chapter,
    you need to understand the workings of the core Python collections. This is not
    just about their usage; it is also about the time complexities involved, which
    can strongly affect how your application will behave as it grows. If you are well
    versed in the time complexities of these objects and know the possibilities of
    Python 3’s tuple packing and unpacking by heart, then feel free to jump to the
    *Advanced collections* section.
  prefs: []
  type: TYPE_NORMAL
- en: list – A mutable list of items
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `list` is most likely the container structure that you’ve used most in Python.
    It is simple in terms of its usage, and for most cases, it exhibits great performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'While you may already be very familiar with the usage of `list`, you might
    not be aware of the time complexities of the `list` object. Luckily, many of the
    time complexities of `list` are very low; `append`, get operations, set operations,
    and `len` all take `O(1)` time—the best possible. However, you may not know that
    `remove` and `insert` have `O(n)` worst-case time complexity. So, to delete a
    single item out of 1,000 items, Python might have to walk through 1,000 items.
    Internally, the `remove` and `insert` operations execute something along these
    lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: To remove or insert a single item from/into the list, Python needs to shift
    the rest of the list after the insertion/deletion point. For a large `list`, this
    can become a performance burden and, if possible, should be avoided by using `append`
    instead of `insert`. When executing this only once, it is, of course, not all
    that bad. But when executing a large number of `remove` operations, a `filter`
    or `list` comprehension is a much faster solution because, if properly structured,
    it needs to copy the list only once.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose we wish to remove a specific set of numbers from the list.
    We have quite a few options for this. The first is a solution using `remove`,
    which becomes slower if the number of items to remove becomes larger.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next up is constructing a new list, a list comprehension, or a `filter` statement.
    *Chapter 5*, *Functional Programming – Readability Versus Brevity*, will explain
    `list` comprehensions and the `filter` statement in more detail. But first, let’s
    check out some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The latter two examples are much faster for large lists of items. This is because
    the operations are much faster. To compare using `n=len(items)` and `m=len(primes)`,
    the first example takes `O(m*n)=5*10=50` operations, whereas the latter two take
    `O(n*1)=10*1=10` operations.
  prefs: []
  type: TYPE_NORMAL
- en: The first method is actually slightly better than stated because `n` decreases
    during the loop. So, it’s effectively `10+9+8+7+6=40`, but this is an effect that
    is negligible enough to ignore. In the case of `n=1000`, that would be the difference
    between `1000+999+998+997+996=4990` and `5*1000=5000`, which makes no real-world
    difference.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, `min`, `max`, and `in` all take `O(n)` as well, but that is expected
    for a structure that is not optimized for these types of lookups.
  prefs: []
  type: TYPE_NORMAL
- en: 'They can be implemented like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: With these examples, it’s also clear that the `in` operator is a good example
    of where the best, worst, and average cases are vastly different. The best case
    is `O(1)`, which is being lucky and finding our value at the first item. The worst
    case is `O(n)` because it might not exist or it could be the last item. From this,
    you might expect the average case to be `O(n/2)`, but you would be wrong. The
    average case is still `O(n)` since there is a large likelihood of the item not
    existing in the list at all.
  prefs: []
  type: TYPE_NORMAL
- en: dict – A map of items
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `dict` is probably the container structure you will choose to use the most.
    You might not realize that you are using it constantly without explicitly using
    `dict`. Every function call and variable access goes through a `dict` to look
    up the name from the `local()` or `global()` scope dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: The `dict` is fast, simple to use, and very effective for a wide range of use
    cases. The average time complexity is `O(1)` for the `get`, `set`, and `delete`
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: There are exceptions to this time complexity that you need to be aware of, however.
    The way a `dict` works is by converting the key into a hash using the `hash` function
    (which calls the `__hash__` method of the object given as a key) and storing it
    in a hash table.
  prefs: []
  type: TYPE_NORMAL
- en: Magic methods such as `__hash__` are called either **magic methods** or **dunder
    methods**, where **dunder** is short for double-underscore.
  prefs: []
  type: TYPE_NORMAL
- en: There are two problems with hash tables, however. The first and the most obvious
    is that the items will be sorted by hash, which appears at random in most cases.
    The second problem with hash tables is that they can have hash collisions, and
    the result of a hash collision is that in the worst case, all the former operations
    can take `O(n)` instead. Hash collisions are not all that likely to occur, but
    they can occur, and if a large `dict` performs below par, that is the place to
    look.
  prefs: []
  type: TYPE_NORMAL
- en: Since Python 3.6, the default `dict` implementation in CPython has changed to
    a version that is sorted by insertion. Since Python 3.7, this is guaranteed behavior
    since other Python versions such as Jython and PyPy could use different implementations
    before version 3.7.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how this actually works in practice. For the sake of this example,
    I will use one of the simplest hashing algorithms I can think of, which uses the
    most significant digit of a number. So, for the case of `12345`, this hashing
    function will return `1`, and for `56789`, it will return `5`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will emulate a `dict` using a `list` of lists with this hashing method.
    We know that our hashing method can only return numbers from `0` to `9`, so we
    need only 10 buckets in our list. Now, we will add a few values and see how a
    `contains` function could work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This code is obviously not identical to the `dict` implementation, but it is
    similar. Since we can just get item `1` for a value of `123` by simple indexing,
    we have only `O(1)` lookup costs in the general case. However, since both keys,
    `123` and `101`, are within the `1` bucket, the runtime can actually increase
    to `O(n)` in the worst case, where all keys have the same hash. As mentioned,
    that is a hash collision. To alleviate hash collisions beyond what the `hash()`
    function already does, the Python `dict` uses a probing sequence to automatically
    shift hashes if needed. The details of this method are well explained in the `dictobject.c`
    file of the Python source.
  prefs: []
  type: TYPE_NORMAL
- en: To debug hash collisions, you can use the `hash()` function paired with `collections.Counter`.
    This will quickly show you where hash collisions occur but it does not take the
    `dict` probing sequence into consideration.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the hash collision performance problem, there is another behavior
    that might surprise you. When deleting items from a dictionary, it won’t actually
    resize the dictionary in memory. The result is that both copying and iterating
    over the entire dictionary take `O(m)` time (where `m` is the maximum size of
    the dictionary); `n`, the current number of items, is not used. So, if you add
    1,000 items to a `dict` and remove 999, iterating and copying will still take
    1,000 steps. The only way to work around this issue is by recreating the dictionary,
    which is something that both the `copy` and `insert` operations do. Note that
    recreation during an `insert` operation is not guaranteed and depends on the number
    of free slots available internally.
  prefs: []
  type: TYPE_NORMAL
- en: set – Like a dict without values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A `set` is a structure that uses the `hash()` function to get a unique collection
    of values. Internally, it is very similar to a `dict`, with the same hash collision
    problem, but there are a few handy features of `set` that need to be shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The first few are pretty much as expected. When we get to the operators, it
    gets interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Expression** | **Output** | **Explanation** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `spam` | `amps` | All unique items. A `set` doesn’t allow for duplicates.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `eggs` | `egs` |'
  prefs: []
  type: TYPE_TB
- en: '| `spam & eggs` | `s` | Every item in both. |'
  prefs: []
  type: TYPE_TB
- en: '| `spam &#124; eggs` | `aegmps` | Every item in either or both. |'
  prefs: []
  type: TYPE_TB
- en: '| `spam ^ eggs` | `aegmp` | Every item in either but not in both. |'
  prefs: []
  type: TYPE_TB
- en: '| `spam - eggs` | `amp` | Every item in the first but not the latter. |'
  prefs: []
  type: TYPE_TB
- en: '| `eggs - spam` | `eg` |'
  prefs: []
  type: TYPE_TB
- en: '| `spam > eggs` | `False` | True if every item in the latter is in the first.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `eggs > spam` | `False` |'
  prefs: []
  type: TYPE_TB
- en: '| `spam > sp` | `True` |'
  prefs: []
  type: TYPE_TB
- en: '| `spam < sp` | `False` | True if every item in the first is contained in the
    latter. |'
  prefs: []
  type: TYPE_TB
- en: 'One useful example of `set` operations is calculating the differences between
    two objects. For example, let’s assume we have two lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '`current_users`: The current users in a group'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`new_users`: The new list of users in a group'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In permission systems, this is a very common scenario—mass adding and/or removing
    users from a group. Within many permission databases, it’s not easily possible
    to set the entire list at once, so you need a list to insert and a list to delete.
    This is where `set` comes in really handy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have lists of all users who were added, removed, and unchanged. Note
    that `sorted` is only needed for consistent output, since a `set` has no predefined
    sort order.
  prefs: []
  type: TYPE_NORMAL
- en: tuple – The immutable list
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A `tuple` is another object that you probably use very often without even noticing
    it. When you look at it initially, it seems like a useless data structure. It’s
    like a list that you can’t modify, so why not just use a `list`? In fact, there
    are a few cases where a `tuple` offers some really useful functionalities that
    a `list` does not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, they are hashable. This means that you can use a `tuple` as a key
    in a `dict` or as an item of a `set`, which is something a `list` can’t do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'However, tuples can contain more than simple numbers. You can use nested tuples,
    strings, numbers, and anything else for which the `hash()` function returns a
    consistent result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: You can make these as complex as you need. As long as all the parts of the tuple
    are hashable, you will have no problem hashing the tuple as well. You can still
    construct a tuple containing a `list` or any other unhashable type without a problem,
    but that will make the tuple unhashable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps even more useful is the fact that tuples also support tuple packing
    and unpacking:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to regular packing and unpacking, from Python 3 onward, we can
    actually pack and unpack objects with a variable number of items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Packing and unpacking can be applied to function arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'They are equally useful when returning from a function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now that you have seen the core Python collections and their limitations, you
    should understand a bit better when certain collections are a good (or bad) idea.
    And more importantly, if a data structure doesn’t perform as you expect it to,
    you will understand why.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, often real-world problems are not as simple as the ones you
    have seen in this chapter, so you will have to weigh up the pros and the cons
    of the data structures and choose the best solution for your case. Alternatively,
    you can build a more advanced data structure by combining a few of these structures.
    Before you start building your own structures, however, keep reading because we
    will now dive into more advanced collections that do just that: combine the core
    collections.'
  prefs: []
  type: TYPE_NORMAL
- en: Pythonic patterns using advanced collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following collections are mostly just extensions of base collections; some
    of them are fairly simple, while others are a bit more advanced. For all of them,
    though, it is important to know the characteristics of the underlying structures.
    Without understanding them, it will be difficult to comprehend the characteristics
    of the collections.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few collections that are implemented in native C code for performance
    reasons, but all of them can easily be implemented in pure Python as well. The
    following examples will show you not only the features and characteristics of
    these collections, but also a few example design patterns where they can be useful.
    Naturally, this is not an exhaustive list, but it should give you an idea of the
    possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: Smart data storage with type hinting using dataclasses
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most useful recent additions to Python (since 3.5) is type hinting.
    With the type annotations, you can give type hints to your editor, documentation
    generator, and others reading your code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within Python, we are generally expected to be “consenting adults,” which means
    the hints are not enforced in any way. This is similar to how private and protected
    variables in Python are not enforced. This means that we can easily give a completely
    different type from what our hint would suggest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Even with the `int` type hint, we can still insert a `str` if we want to.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `dataclasses` module, which was introduced in Python 3.7 (backports available
    for Python 3.6), uses the type hinting system to automatically generate classes,
    including documentation and constructors based on these types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The basic class looks quite simple and like it’s nothing special, but if you
    look carefully, the `dataclass` has generated multiple methods for us. Which ones
    are generated becomes obvious when looking at the `dataclass` arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `dataclass` has several Boolean flags that decide what to generate.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the `init` flag tells `dataclass` to create an `__init__` method that
    looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Further, `dataclass` has flags for:'
  prefs: []
  type: TYPE_NORMAL
- en: '`repr`: This generates a `__repr__` magic function that generates a nice and
    readable output like `Sandwich(spam=1, eggs=2)` instead of something like `<__main__.Sandwich
    object at 0x...>`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eq`: This generates an automatic comparison method that compares two instances
    of `Sandwich` by their value when doing `if sandwich_a == sandwich_b`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`order`: This generates a whole range of methods so that comparison operators
    such as `>=` and `<` work by comparing the output of `dataclasses.astuple`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unsafe_hash`: This will force the generation of a `__hash__` method so that
    you use the `hash()` function on it. By default, a `__hash__` function is only
    generated when all parts of the object are considered immutable. The reason for
    this is that `hash()` should *always* be consistent. If you wish to store an object
    in a `set`, it needs to have a consistent hash. Since a `set` uses `hash()` to
    decide which memory address to use, if the object changes, the `set` would need
    to move the object as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`frozen`: This will prevent changes after the instance has been created. The
    main use for this is to make sure the `hash()` of the object remains consistent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`slots`: This automatically adds a `__slots__` attribute which makes attribute
    access and storage faster and more efficient. More about slots in *Chapter 12*,
    *Performance – Tracking and Reducing Your Memory and CPU Usage*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The only flag that adds validation is the `frozen` flag, which makes everything
    read-only and prevents us from changing the `__setattr__` and `__getattr__` methods,
    which could be used to modify the instance otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: The type hinting system still only provides hints; however, these hints are
    not enforced in any way. In *Chapter 6*, *Decorators – Enabling Code Reuse by
    Decorating*, you will see how we can add these types of enforcements to our code
    using custom decorators.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a more useful example that includes dependence, let’s say that we have
    some users who all belong to one or multiple groups in a system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In addition to linking dataclasses to each other, this also shows how to create
    a collection as a field and how to have recursive definitions. As you can see,
    the `Group` class references its own definition as a parent.
  prefs: []
  type: TYPE_NORMAL
- en: These dataclasses are especially useful when used for reading data from databases
    or CSV files. You can easily extend the behavior of dataclasses to include custom
    methods, which makes them a very useful basis for storing your custom data models.
  prefs: []
  type: TYPE_NORMAL
- en: Combining multiple scopes with ChainMap
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Introduced in Python 3.3, `ChainMap` allows you to combine multiple mappings
    (dictionaries, for example) into one. This is especially useful when combining
    multiple contexts. For example, when looking for a variable in your current scope,
    by default, Python will search in `locals()`, `globals()`, and, lastly, `builtins`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To explicitly write code to do this, we could do something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This works, but it’s ugly to say the least. We can make it prettier by removing
    some of the repeated code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'That’s a lot better! Moreover, this can actually be considered a nice solution.
    But since Python 3.3, it’s even easier. Now, we can simply use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `ChainMap` class is automatically coalescing the requested
    value through every given `dict` until it finds a match. And if the value is not
    available, a `KeyError` is raised since it behaves like a `dict`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is very useful for reading configurations from multiple sources and simply
    getting the first matching item. For a command-line application, this could start
    with the command-line arguments, followed by the local configuration file, followed
    by the global configuration file, and lastly the defaults. To illustrate a bit
    of code similar to what I use in small command-line scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The inheritance can clearly be seen here. When a specific command-line argument
    is given (`-vv`), that result is used. Otherwise, the code falls back to the one
    in `DEFAULTS` or any other available variable.
  prefs: []
  type: TYPE_NORMAL
- en: Default dictionary values using defaultdict
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `defaultdict` is one of my favorite objects in the `collections` package.
    Before it was added to the core, I wrote similar objects several times. While
    it is a fairly simple object, it is extremely useful for all sorts of design patterns.
    Instead of having to check for the existence of a key and adding a value every
    time, you can just declare the default from the beginning, and there is no need
    to worry about the rest.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let’s say we are building a very basic graph structure from a list
    of connected nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is our list of connected nodes (one way):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s put this graph into a normal dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Some variations are possible, of course, such as using `setdefault`. However,
    they remain more complex than they need to be.
  prefs: []
  type: TYPE_NORMAL
- en: 'The truly Pythonic version uses `defaultdict` instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Isn’t that a beautiful bit of code? The `defaultdict` can also be used as a
    basic version of the `Counter` object. It’s not as fancy and doesn’t have all
    the bells and whistles that `Counter` has, but it does the job in many cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The default value for `defaultdict` needs to be a callable object. In the previous
    cases, these were `int` and `list`, but you can easily define your own functions
    to use as a default value. That’s what the following example uses, although I
    don’t recommend production usage since it lacks a bit of readability. I do believe,
    however, that it is a beautiful example of the power of Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how we create a `tree` in a single line of Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Brilliant, isn’t it? Here’s how we can actually use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The nice thing is that you can make it go as deep as you like. Because of the
    `defaultdict` base, it generates itself recursively.
  prefs: []
  type: TYPE_NORMAL
- en: enum – A group of constants
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `enum` package introduced in Python 3.4 is quite similar in its workings
    to enums in many other programming languages, such as C and C++. It helps to create
    reusable constants for your module so you can avoid arbitrary constants. A basic
    example is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: A few of the handy features of the `enum` package are that the objects are iterable,
    accessible through both numeric and textual representation of the values, and,
    with proper inheritance, even comparable to other classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the usage of a basic API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: One of the lesser-known possibilities of the `enum` package is that you can
    make value comparisons work in addition to the identity comparisons you would
    normally use. And this works for every type—not just integers but (your own) custom
    types as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'With a regular `enum`, only an identity check (that is, `a is b`) works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'When we make the `enum` inherit `str` as well, it starts comparing the values
    in addition to the identity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to the preceding examples, the `enum` package has a few other variants
    such as `enum.Flag` and `enum.IntFlag`, which allow for bitwise operations. These
    can be useful for representing permissions as follows: `permissions = Perm.READ
    | Perm.Write`.'
  prefs: []
  type: TYPE_NORMAL
- en: Whenever you have a list of constants that can be grouped together, consider
    using the `enum` package. It makes validation much cleaner than having to use
    `if/elif/elif/else` several times.
  prefs: []
  type: TYPE_NORMAL
- en: Sorting collections using heapq
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `heapq` module is a great little module that makes it very easy to create
    a priority queue in Python. It is a data structure that will always make the smallest
    (or largest, depending on the implementation) item available with minimum effort.
    The API is quite simple, and one of the best examples of its usage can be seen
    in the `OrderedDict` object. While you might not need it often, it is a very useful
    structure if you need it. And understanding the inner workings is important if
    you wish to understand the workings of classes such as `OrderedDict`.
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking for a structure to keep your list always sorted, try the
    `bisect` module instead, which is covered in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic usage of `heapq` is simple but somewhat confusing initially:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: One important thing to note here—something that you have probably already understood
    from the preceding example—is that the `heapq` module does not create a special
    object. It consists of a few methods to treat a regular list as a `heap`. That
    doesn’t make it less useful, but it is something to take into consideration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The really confusing part, at first glance, is the sort order. The array is
    actually sorted but not as a list; it is sorted as a tree. To illustrate this,
    take a look at the following tree, which shows how the tree is supposed to be
    read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The smallest number is always at the top and the biggest numbers are always
    at the bottom row of the tree. Because of that, it’s really easy to find the smallest
    number, but finding the largest is not as easy. To get the sorted version of the
    heap, we simply need to keep removing the top of the tree until all the items
    are gone. Therefore, the heapsort algorithm can be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: With `heapq` doing the heavy lifting, it becomes incredibly easy to write your
    own version of the `sorted()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Since the `heappush` and `heappop` functions both have `O(log(n))` time complexity,
    they can be considered really fast. Combining those for the `n` items in the preceding
    iterable gives us `O(n*log(n))` for the `heapsort` function. The `heappush` method
    uses `list.append()` internally and swaps the items in the `list` to avoid the
    `O(n)` time complexity of `list.insert()`.
  prefs: []
  type: TYPE_NORMAL
- en: The `log(n)` refers to the base 2 logarithm function. To calculate this value,
    the `math.log2()` function can be used. This results in an increase of 1 every
    time the number doubles in size. For `n=2`, the value of `log(n)` is `1`, and
    consequently for `n=4` and `n=8`, the log values are `2` and `3`, respectively.
    And `n=1024` results in a log of only `10`.
  prefs: []
  type: TYPE_NORMAL
- en: This means that a 32-bit number, which is `2**32 = 4294967296`, has a log of
    `32`.
  prefs: []
  type: TYPE_NORMAL
- en: Searching through sorted collections using bisect
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `heapq` module in the previous section gave us an easy way to sort a structure
    and keep it sorted. But what if we want to search through a sorted collection
    to see whether the item exists? Or what’s the next biggest/smallest item if it
    doesn’t? That’s where the `bisect` algorithm helps us.
  prefs: []
  type: TYPE_NORMAL
- en: The `bisect` module inserts items in an object in such a way that they stay
    sorted and are easily searchable. If your primary purpose is searching, then `bisect`
    should be your choice. If you’re modifying your collection a lot, `heapq` might
    be better for you.
  prefs: []
  type: TYPE_NORMAL
- en: As is the case with `heapq`, `bisect` does not really create a special data
    structure. The `bisect` module expects a `list` and expects that `list` to always
    be sorted. It is important to understand the performance implications of this.
    While appending items to a `list` has `O(1)` time complexity, inserting has `O(n)`
    time complexity, making it a very heavy operation. Effectively, creating a sorted
    list using bisect takes `O(n*n)`, which is quite slow, especially because creating
    the same sorted list using `heapq` or `sorted()` takes `O(n*log(n))` instead.
  prefs: []
  type: TYPE_NORMAL
- en: If you have a sorted structure and you only need to add a single item, then
    the `bisect` algorithm can be used for insertion. Otherwise, it’s generally faster
    to simply append the items and call `list.sort()` or `sorted()` afterward.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate, we have these lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: For a small number of items, the difference is negligible, but the number of
    operations needed to sort using `bisect` quickly grows to a point where the difference
    will be large. For `n=4`, the difference is just between `4 * 1 + 8 = 12` and
    `1 + 2 + 3 + 4 = 10`, making the `bisect` solution faster. But if we were to insert
    1,000 items, it would be `1000 + 1000 * log(1000) = 10966` versus `1 + 2 + … 1000
    = 1000 * (1000 + 1) / 2 = 500500`. So, be very careful while inserting many items.
  prefs: []
  type: TYPE_NORMAL
- en: 'Searching within the list is very fast, though; because it is sorted, we can
    use a very simple binary search algorithm. For example, what if we want to check
    whether a few numbers exist within the list? The simplest algorithm, shown as
    follows, simply loops through the list and checks all items, resulting in `O(n)`
    worst-case performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'With the `bisect` algorithm, though, there is no need to walk through the entire
    list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The `bisect_left` function tries to find the position at which the number is
    supposed to be. This is actually what `bisect.insort` does as well; it inserts
    the number at the correct position by searching for the location of the number.
  prefs: []
  type: TYPE_NORMAL
- en: 'The biggest difference between these methods is that `bisect` does a binary
    search internally, which means that it starts in the middle and jumps to the middle
    of the left or right section, depending on whether the value in the list is bigger
    or smaller than the value we are looking for. To illustrate, we will search for
    `4` in a list of numbers from `0` to `14`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, after only four steps, we have found the number we searched
    for. Depending on the number (`7`, for example), it may go faster, but it will
    never take more than `O(log(n))` steps to find a number.
  prefs: []
  type: TYPE_NORMAL
- en: With a regular list, a search will simply walk through all the items until it
    finds the desired item. If you’re lucky, it could be the first number you encounter,
    but if you’re unlucky, it could be the last item. In the case of 1,000 items,
    that would be the difference between 1,000 steps and `log(1000) = 10` steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'While very fast and efficient, the `bisect` module doesn’t feel Pythonic at
    all. Let’s fix that by creating our own `SortedList` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: While functional, this implementation is obviously still a tad limited. But
    it’s certainly a nice starting point in case you need a structure like this.
  prefs: []
  type: TYPE_NORMAL
- en: Global instances using Borg or Singleton patterns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most programmers will be familiar with the Singleton pattern, which ensures
    that only a single instance of a class will ever exist. Within Python, a common
    alternative solution to this is the Borg pattern, named after the Borg in Star
    Trek. Where a Singleton enforces a single instance, the Borg pattern enforces
    a single state for all instances and subclasses as well. Due to the way class
    creation works in Python, the Borg pattern is a tiny bit easier to implement and
    modify than the Singleton pattern as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate an example of both:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Borg class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The Singleton class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The Borg pattern works by overriding the `__dict__` of the instance that contains
    the instance state. The Singleton overrides the `__new__` (note, not `__init__`)
    method so that we only ever return a single instance of the class.
  prefs: []
  type: TYPE_NORMAL
- en: No need for getters and setters with properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Within many languages (notably Java), a common design pattern for accessing
    instance variables is using getters and setters so that you can modify the behavior
    when needed in the future. Within Python, we can transparently change the behavior
    of attributes for existing classes without the need to touch the calling code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The calling code doesn’t need to be changed at all. We can simply change the
    behavior of the property in a completely transparent way.
  prefs: []
  type: TYPE_NORMAL
- en: Dict union operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is not actually a separate advanced collection, but it is advanced usage
    of the `dict` collection. Since Python 3.9, we have a few easy options for combining
    multiple `dict` instances. The “old” solution was to use `dict.update()`, possibly
    combined with `dict.copy()` to create a new instance. While that works fine, it
    is rather verbose and a tad clunky.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this is a case where a few examples are much more useful than just explanation,
    let’s see how the old solution works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'That solution works great, but with Python 3.9 and above we can do it in a
    much easier and shorter way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a feature that can be very convenient when specifying arguments to
    a function, especially if you want to automatically fill in keyword arguments
    with default arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Now that you have seen a few of the more advanced collections bundled with Python,
    you should have a pretty good idea of when to apply which type of collection.
    You may also have learned about a few new Python design patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In addition to enhancing the examples in this chapter, there are many other
    exercises:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a `SortedDict` collection that takes a `keyfunc` to decide the sort order.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a `SortedList` collection that has `O(log(n))` inserts and always returns
    a sorted list during each iteration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a Borg pattern that has a state per subclass.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example answers for these exercises can be found on GitHub: [https://github.com/mastering-python/exercises](Chapter_4.xhtml).
    You are encouraged to submit your own solutions and learn about alternative solutions
    from others.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is a bit unlike other languages in some aspects and several design patterns
    that are common in other languages make little sense in Python. In this chapter,
    you have seen some common Python design patterns, but many more patterns exist.
    Before you start implementing your own collections based on these patterns, quickly
    search the web to see whether there is an existing solution already. In particular,
    the `collections` module receives a lot of updates, so it is possible that your
    problem has already been solved.
  prefs: []
  type: TYPE_NORMAL
- en: If you are ever wondering how these structures work, have a look at the following
    source:[https://github.com/python/cpython/blob/master/Lib/collections/__init__.py](https://github.com/python/cpython/blob/master/Lib/collections/__init__.py).
  prefs: []
  type: TYPE_NORMAL
- en: After finishing this chapter, you should be aware of the time complexities of
    the basic Python structures. You should also be familiar with a few Pythonic methods
    of tackling certain problems. Many of these examples use the `collections` module,
    but this chapter does not list all of the classes in the `collections` module.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting the correct data structure within your applications is by far the
    most important performance factor for your code. This makes basic knowledge about
    performance characteristics essential for any serious programmer.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will continue with functional programming, which covers
    `lambda` functions, `list` comprehensions, `dict` comprehensions, `set` comprehensions,
    and an array of related topics. Additionally, you will learn about the mathematic
    background of functional programming.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers: [https://discord.gg/QMzJenHuJf](https://discord.gg/QMzJenHuJf)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code156081100001293319171.png)'
  prefs: []
  type: TYPE_IMG
