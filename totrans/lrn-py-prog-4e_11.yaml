- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Debugging and Profiling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ”If debugging is the process of removing software bugs, then programming must
    be the process of putting them in.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: – Edsger W. Dijkstra
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the life of a professional coder, debugging and troubleshooting take up a
    significant amount of time. All but the most trivial software is guaranteed to
    have bugs. Humans are not perfect; we make mistakes. Therefore, the code we produce
    is also not perfect. As developers, we spend a large portion of our time reading
    code that was written by other people. In our opinion, a good software developer
    is someone who keeps an eye out for potential bugs, even when they are reading
    code that is not reported to be wrong or buggy.
  prefs: []
  type: TYPE_NORMAL
- en: Being able to debug code efficiently and quickly is a skill that every coder
    needs to keep improving. Like testing, debugging is a skill that is best learned
    through experience. There are guidelines you can follow, but there is no book
    that will teach you everything you need to know to become good at this.
  prefs: []
  type: TYPE_NORMAL
- en: We feel that on this subject, we have learned the most from our colleagues.
    It amazes us to observe someone who is very skilled attacking a problem. We enjoy
    seeing the steps they take, the things they verify to exclude potential causes,
    and how they select the path that eventually leads them to a solution.
  prefs: []
  type: TYPE_NORMAL
- en: Every colleague we work with can teach us something or surprise us with a fantastic
    guess that turns out to be the right one. When that happens, do not just remain
    in wonderment (or worse, in envy), but seize the moment and ask them how they
    got to that guess and why. The answer will allow you to see whether there is something
    you can study in depth later so that, next time, you will be the one who finds
    the bug.
  prefs: []
  type: TYPE_NORMAL
- en: Some bugs are easy to spot. They come out of mistakes and, once you see the
    effects of those mistakes, it is easy to find a solution to the problem. But there
    are other bugs that are much more subtle and require true expertise and a great
    deal of creativity and out-of-the-box thinking to be dealt with. The worst bugs
    of all are the non-deterministic ones. These sometimes happen, and sometimes do
    not. Some happen only in a particular environment but not in another seemingly
    identical environment.
  prefs: []
  type: TYPE_NORMAL
- en: In a professional setting, we often need to debug our code in highly stressful
    situations. If a website is down, or customers are upset, the business is losing
    money. As a result, there is often a lot of pressure on developers to find and
    fix the problem immediately. In such situations, it is crucial to be able to keep
    calm. That’s the most important skill to have if you want to be able to fight
    bugs effectively. Stress negatively impacts the creative thinking and problem-solving
    abilities that we need to find and fix bugs. So, take a deep breath, sit properly,
    and focus.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will try to demonstrate some useful techniques that you
    can employ according to the severity of the bug, and a few suggestions that will
    hopefully boost your weapons against bugs and issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we are going to look at the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Debugging techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting guidelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, we will introduce you to some of the techniques we use most often.
    This is not an exhaustive list, but it should give you some useful ideas for where
    to start when debugging your own Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging with print
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key to understanding any bug is to understand what your code is doing at
    the point where the bug occurs. For this reason, we will be looking at a few different
    techniques for inspecting the state of a program while it is running.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest technique of all is to add `print()` calls at various points in
    your code. This allows you to easily see which parts of your code are executed,
    and what the values of key variables are at different points during execution.
    For example, if you are developing a Django website and what happens on a page
    is not what you would expect, you can fill the view with prints and keep an eye
    on the console while you reload the page.
  prefs: []
  type: TYPE_NORMAL
- en: There are several drawbacks and limitations to using `print()` for debugging.
    To use this technique, you need to be able to modify the source code and run it
    in a terminal where you can see the output of your `print()` function calls. This
    is not a problem in your development environment on your own machine, but it does
    limit the usefulness of this technique in other environments.
  prefs: []
  type: TYPE_NORMAL
- en: When you scatter calls to `print()` in your code, you can easily end up duplicating
    a lot of debugging code. For example, you may want to print timestamps (like we
    did when we were measuring how fast list comprehensions and generators were),
    or somehow build up a string with the information that you want to display. Another
    disadvantage of this technique is that it is easy to forget calls to `print()`
    in your code.
  prefs: []
  type: TYPE_NORMAL
- en: For these reasons, we sometimes prefer to use a custom debugging function rather
    than just bare calls to `print()` . Let us see how.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging with a custom function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having a custom debugging function saved in a file somewhere that you can quickly
    grab and paste into the code can be particularly useful. If you are fast, you
    can also code one on the fly. The important thing is to write it in such a way
    that it will not leave anything behind when you eventually remove the calls and
    their definitions. Therefore, *it is important to code it in a way that is completely
    self-contained* . Another good reason for this requirement is that it will avoid
    potential name clashes with the rest of the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us see an example of such a function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we are using a keyword-only argument to be able to print a separator,
    which is a line of 40 dashes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function just passes whatever is in `msg` to a call to `print()` and, if
    `print_separator` is `True` , it prints a line separator. Running the code will
    show the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, there is no separator after the last line.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is just one easy way to augment a simple call to the `print()` function.
    Let us see how we can calculate a time difference between calls, using one of
    Python’s tricky features to our advantage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This is a bit more complicated. First, notice that we used an `import` statement
    *inside* the `debug()` function to import the `time()` function from the `time`
    module. This allows us to avoid having to add that `import` outside the function
    and risk forgetting to remove it.
  prefs: []
  type: TYPE_NORMAL
- en: Look at how we defined `timestamp` . It is a function parameter with a list
    as its default value. In *Chapter 4* , *Functions, the Building Blocks of Code*
    , we warned against using mutable defaults for parameters because the default
    value is initialized when Python parses the function, and the same object persists
    across different calls to the function. Most of the time, this is not the behavior
    you want. In this case, however, we are taking advantage of this feature to store
    a timestamp from the previous call to the function, without having to use an external
    global variable. We borrowed this trick from our studies on **closures** , a technique
    that we encourage you to read about.
  prefs: []
  type: TYPE_NORMAL
- en: After printing the message, we inspect the content of the only item in `timestamp`
    . If it is `None` , we have no previous timestamp, so we set the value to the
    current time ( `#1` ). On the other hand, if we have a previous timestamp, we
    can calculate a difference (which we neatly format to three decimal digits), and
    finally, we put the current time in `timestamp` ( `#2` ).
  prefs: []
  type: TYPE_NORMAL
- en: 'Running this code outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using a custom debug function solves some of the problems associated with just
    using `print()` . It reduces duplication of debugging code and makes it easier
    to remove all your debugging code when you no longer need it. However, it still
    requires modifying the code and running it in a console where you can inspect
    the output. Later in this chapter, we will see how we can overcome those difficulties
    by adding logging to our code.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Python debugger
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another effective way of debugging Python is to use an interactive debugger.
    The Python standard library module `pdb` provides such a debugger; however, we
    usually prefer to use the third-party `pdbpp` package. `pdbpp` is a drop-in replacement
    for `pdb` , with a somewhat friendlier user interface and some handy additional
    tools, our favorite of which is *sticky mode* , which allows you to see a whole
    function while you step through its instructions.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few different ways to activate the debugger (if you have the `pdbpp`
    package installed, it will be loaded instead of the standard `pdb` debugger).
    The most common approach is to add a call invoking the debugger to your code.
    This is known as adding a **breakpoint** to the code.
  prefs: []
  type: TYPE_NORMAL
- en: When the code is run and the interpreter reaches the breakpoint, execution is
    suspended, and you get console access to an interactive debugger session. You
    can then inspect all the names in the current scope, and step through the program
    one line at a time. You can also alter data on the fly to change the flow of the
    program.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a toy example, suppose we have a program that receives a dictionary and
    a tuple of keys as input. It then processes the dictionary items with the given
    keys. The program is raising a `KeyError` because one of the keys is missing from
    the dictionary. Suppose we cannot control the input (perhaps it comes from a third-party
    API), but we want to get past the error so that we can verify that our program
    would behave correctly on valid input. Let us see how we could use the debugger
    to interrupt the program, inspect and fix the data, and then allow execution to
    proceed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, this code will break when `key` gets the value `"third"` ,
    which is missing from the dictionary. Remember, we’re pretending that both `d`
    and `keys` come from an input source that we cannot control. If we run the code
    as it is, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We see that that `key` is missing from the dictionary, but since every time
    we run this code, we may get a different dictionary or `keys` tuple, this information
    does not really help us. We want to inspect and modify the data while the program
    is running, so let us insert a breakpoint just before the `for` loop. In modern
    versions of Python, the simplest way of doing this is to call the built-in `breakpoint()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Before Python 3.7, you would have needed to import the `pdb` module and call
    the `pdb.set_trace()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Note that we have used a semi-colon to separate multiple statements on the same
    line. PEP 8 discourages this, but it is quite common when setting a breakpoint
    like this, as there are fewer lines to remove when you no longer need the breakpoint.
  prefs: []
  type: TYPE_NORMAL
- en: The `breakpoint()` function calls `sys.breakpointhook()` , which, in turn, calls
    `pdb.set_trace()` . You can override the default behavior of `sys.breakpointhook()`
    by setting the `PYTHONBREAKPOINT` environment variable to point to an alternative
    function to import and call instead of `pdb.set_trace()` .
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this example is in the `pdebugger_pdb.py` module. If we now run
    this code, things get interesting (note that your output may vary a little and
    that all the comments in this output were added by us):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: First, note that when you reach a breakpoint, you are served a console that
    tells you where you are (the Python module) and which line is the next one to
    be executed. You can, at this point, perform some exploratory actions, such as
    inspecting the code before and after the next line, printing a stack trace, and
    interacting with the objects. In our case, we first inspect the `keys` tuple.
    We also inspect the keys of `d` . We see that `'third'` is missing, so we put
    it in ourselves (could this be dangerous? Think about it.). Finally, now that
    all the keys are in, we type `c` to continue normal execution.
  prefs: []
  type: TYPE_NORMAL
- en: The debugger also gives you the ability to execute your code one line at a time
    using the `n` command (for next). You can use the `s` command to step into a function
    for deeper analysis or set additional breakpoints with the `b` command. For a
    complete list of commands, please refer to the documentation (which you can find
    at [https://docs.python.org/3.12/library/pdb.html](https://docs.python.org/3.12/library/pdb.html)
    ) or type `h` (for help) in the debugger console.
  prefs: []
  type: TYPE_NORMAL
- en: You can see, from the output of the preceding run, that we could finally get
    to the end of the validation.
  prefs: []
  type: TYPE_NORMAL
- en: '`pdb` (or `pdbpp` ) is an invaluable tool that we use every day. So, please
    experiment with it. Set a breakpoint somewhere and try to inspect it, follow the
    official documentation, and try the commands in your code to see their effect
    and learn them well.'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that, in this example, we have assumed you installed `pdbpp` . If that
    is not the case, then you might find that some commands behave a bit differently
    in plain `pdb` . One example is the letter *d* , which `pdb` interprets as the
    *down* command. To get around that, you would have to add an `!` in front of `d`
    to tell `pdb` that it is meant to be interpreted literally, and not as a command.
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another way of debugging a misbehaving application is to inspect its logs. A
    **log** is an ordered list of events that occurred or actions that were taken
    during the running of an application. If a log is written to a file on disk, it
    is known as a **log file** .
  prefs: []
  type: TYPE_NORMAL
- en: Using logs for debugging is, in some ways, similar to adding `print()` calls
    or using a custom debug function. The key difference is that we typically add
    logging to our code from the start to aid future debugging, rather than adding
    it during debugging and then removing it again. Another difference is that logging
    can easily be configured to output to a file or a network location. These two
    aspects make logging ideal for debugging code that is running on a remote machine
    that you might not have direct access to.
  prefs: []
  type: TYPE_NORMAL
- en: The fact that logging is usually added to the code before a bug has occurred
    does pose the challenge of deciding what to log. We would typically expect to
    find entries in the logs corresponding to the start and completion (and potentially
    also intermediate steps) of any important process that takes place within the
    application. The values of important variables should be included in these log
    entries. Errors also need to be logged so that if a problem occurs, we can inspect
    the logs to find out what went wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nearly every aspect of logging in Python can be configured in various ways.
    This gives us a lot of power, as we can change where logs are output to, which
    log messages are output, and how log messages are formatted, simply by changing
    the logging configuration and without changing any other code. The four main types
    of objects involved in logging in Python are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Loggers** : Expose the interface that the application code uses directly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handlers** : Send the log records (created by loggers) to the appropriate
    destination'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filters** : Provide a finer-grained facility for determining which log records
    to output'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Formatters** : Specify the layout of the log records in the final output'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging is performed by calling methods on instances of the `Logger` class.
    Each line you log has a severity level associated with it. The most commonly used
    levels are `DEBUG` , `INFO` , `WARNING` , `ERROR` , and `CRITICAL` . Loggers use
    these levels to determine which log messages to output. Anything below the logger’s
    level will be ignored. This means that you must take care to log at the appropriate
    level. If you log everything at the `DEBUG` level, you will need to configure
    your logger at (or below) the `DEBUG` level to see any of your messages. This
    can quickly result in your log files becoming extremely large. A similar problem
    occurs if you log everything at the `CRITICAL` level.
  prefs: []
  type: TYPE_NORMAL
- en: Python gives you several choices of where to log to. You can log to a file,
    a network location, a queue, a console, your operating system’s logging facilities,
    and so on. Where you send your logs will typically depend very much on the context.
    For example, when you run your code in your development environment, you will
    typically log to your terminal. If your application runs on a single machine,
    you might log to a file or send your logs to the operating system’s logging facilities.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if your application uses a distributed architecture that
    spans multiple machines (such as in the case of service-oriented or microservice
    architectures), it is better to implement a centralized solution for logging so
    that all log messages coming from each service can be stored and investigated
    in a single place. This makes debugging much easier because trying to correlate
    giant files from multiple sources to figure out what went wrong can become truly
    challenging.
  prefs: []
  type: TYPE_NORMAL
- en: A **service-oriented architecture** ( **SOA** ) is an architectural pattern
    in software design in which application components provide services to other components
    via a communications protocol, typically over a network. The beauty of this system
    is that, when coded properly, each service can be written in the most appropriate
    language to serve its purpose. The only thing that matters is the communication
    with the other services, which needs to happen via a common format so that data
    exchange can be done.
  prefs: []
  type: TYPE_NORMAL
- en: '**Microservice architectures** are an evolution of SOAs but follow a different
    set of architectural patterns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The downside of the configurability of Python’s logging is that the logging
    machinery is somewhat complex. Fortunately, the defaults are often sufficient,
    and you only need to override settings when you have a specific need for customization.
    Let us see a simple example of logging a few messages to a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: First, we import the `logging` module, then we set up a basic configuration.
    We specify a filename, configure the logger to output any log messages with the
    level `DEBUG` or higher, and set the message format. We want to log the date and
    time information, the level, and the message.
  prefs: []
  type: TYPE_NORMAL
- en: With the configuration in place, we can start logging. We start by logging an
    `info` message that tells us we are about to process our list. Inside the loop,
    we will log the value at each position (we use the `debug()` function to log at
    the `DEBUG` level). We use `debug()` here so that we can filter out these logs
    in the future (by configuring the logger’s `level` to `logging.INFO` or more)
    because we might have to handle large lists, and we do not want to always log
    all the values.
  prefs: []
  type: TYPE_NORMAL
- en: If we get `IndexError` (and we do, since we are looping over `range(4)` ), we
    call `logging.exception()` , which logs at the `ERROR` level, but also outputs
    the exception traceback.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the end of the code, we log another `info` message to say that we are done.
    After running this code, we will have a new `ch11.log` file with the following
    content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This is precisely what we need to be able to debug an application that is running
    on a remote machine, rather than our own development environment. We can see what
    our code did, the traceback of any exception raised, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to modify the logging levels in the previous example, both the code
    and the configuration. This way, you’ll be able to see how the output changes
    according to your setup.
  prefs: []
  type: TYPE_NORMAL
- en: 'The example presented here only scratches the surface of logging. For a more
    in-depth explanation, you can find information in the *Python HOWTOs* section
    of the official Python documentation: *Logging HOWTO* and *Logging Cookbook* .'
  prefs: []
  type: TYPE_NORMAL
- en: Logging is an art. You need to find a good balance between logging everything
    and logging nothing. Ideally, you should log anything that you need to make sure
    your application is working correctly, and possibly all errors or exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Other techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will end this section on debugging by briefly mentioning a couple of other
    techniques that you may find useful.
  prefs: []
  type: TYPE_NORMAL
- en: Reading tracebacks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Bugs often manifest as unhandled exceptions. The ability to interpret an exception
    traceback is therefore a crucial skill for successful debugging. Make sure that
    you have read and understood the section on tracebacks in *Chapter 7* , *Exceptions
    and Context Managers* . If you are trying to understand why an exception happened,
    it is often useful to inspect the state of your program (using the techniques
    we discussed above) at the lines mentioned in the traceback.
  prefs: []
  type: TYPE_NORMAL
- en: Assertions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Bugs are often the result of incorrect assumptions in our code. Assertions
    can be helpful for validating those assumptions. If our assumptions are valid,
    the assertions pass and execution proceeds normally. If they are not, we get an
    exception telling us which of our assumptions are incorrect. Sometimes, instead
    of inspecting with a debugger or `print()` statements, it is quicker to drop a
    couple of assertions in the code just to exclude possibilities. Let us see an
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we pretend that `mylist` comes from some external source that
    we do not control (maybe user input). The `for` loop assumes that `mylist` has
    four elements and we have added an assertion to validate that assumption. When
    we run the code, the result is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This tells us exactly where the problem is.
  prefs: []
  type: TYPE_NORMAL
- en: Running a program with the `-O` flag active will cause Python to ignore all
    assertions. This is something to keep in mind if our code depends on assertions
    to work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assertions also allow for a longer format that includes a second expression,
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The second expression is passed to the `AssertionError` exception raised by
    the statement. It is typically a string with an error message. For example, if
    we changed the assertion in the last example to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'the result would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Where to find information
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The official Python documentation contains a section dedicated to debugging
    and profiling. There, you can read about the `bdb` debugger framework and about
    modules such as `faulthandler` , `timeit` , `trace` , `tracemalloc` , and `pdb`
    .
  prefs: []
  type: TYPE_NORMAL
- en: Let us now explore some troubleshooting guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting guidelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this short section, we would like to give you a few tips that come from our
    troubleshooting experience.
  prefs: []
  type: TYPE_NORMAL
- en: Where to inspect
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our first suggestion concerns where to place your debugging breakpoints. Regardless
    of whether you are using `print()` , a custom function, `pdb` , or logging, you
    still have to choose where to place the calls that provide you with the information.
    Some places are definitely better than others, and there are ways to handle the
    debugging progression that are better than others.
  prefs: []
  type: TYPE_NORMAL
- en: We normally avoid placing a breakpoint inside an `if` clause. If the branch
    containing the breakpoint is not executed, we lose the chance to get the information
    we want. Sometimes, it can be difficult to reproduce a bug, or it may take a while
    for your code to reach the breakpoint, so think carefully before placing them.
  prefs: []
  type: TYPE_NORMAL
- en: Another important thing is where to start. Imagine that you have 100 lines of
    code that handle your data. Data comes in at line 1, and somehow, it is wrong
    at line 100. You do not know where the bug is, so what do you do? You can place
    a breakpoint at line 1 and patiently step through all 100 lines, checking your
    data at every step. In the worst-case scenario, 99 lines (and many cups of coffee)
    later, you spot the bug. So, consider using a different approach.
  prefs: []
  type: TYPE_NORMAL
- en: Start at line 50 and inspect. If the data is good, it means the bug happens
    later, in which case you place your next breakpoint at line 75. If the data at
    line 50 is already bad, you go on by placing a breakpoint at line 25. Then, you
    repeat. Each time, you move either backward or forward, by half the jump you did
    last time.
  prefs: []
  type: TYPE_NORMAL
- en: In our worst-case scenario, your debugging would go from 1, 2, 3, ..., 99, in
    a linear fashion, to a series of jumps such as 50, 75, 87, 93, 96, ..., 99, which
    is much faster. In fact, it is logarithmic. This searching technique is called
    **binary search** ; it is based on a divide-and-conquer approach, and it is highly
    effective, so try to master it.
  prefs: []
  type: TYPE_NORMAL
- en: Using tests to debug
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In *Chapter 10* , *Testing* , we briefly introduced you to **test-driven development**
    ( **TDD** ). One TDD practice that you really should adopt, even if you do not
    subscribe to TDD as a whole, is writing tests that reproduce a bug before you
    start changing your code to fix the bug. There are several reasons for this. If
    you have a bug and all tests are passing, it means something is wrong or missing
    in your test code base.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding these tests will help you ensure that you really do fix the bug: the
    tests should only pass if the bug is gone. Finally, having these tests will protect
    you from inadvertently reintroducing the same bug again.'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Monitoring is also important. Software applications can sometimes behave in
    unexpected ways in edge-case situations, such as the network being down, a queue
    being full, or an external component being unresponsive. In these cases, it is
    important to have an idea of what the big picture was when the problem occurred
    and be able to correlate it to something related to it in a subtle, perhaps mysterious,
    way.
  prefs: []
  type: TYPE_NORMAL
- en: You can monitor API endpoints, processes, web pages’ availability and load times,
    and everything that you can code. In general, when starting an application from
    scratch, it can be helpful to think about how you want to monitor it from the
    earliest design stages.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us move on to see how we can profile Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Profiling means having the application run while keeping track of several different
    parameters, such as the number of times a function is called, and the amount of
    time spent inside it.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling is closely related to debugging. Although the tools and processes
    used are quite different, both activities involve probing and analyzing your code
    to understand where the root of a problem lies, and then making changes to fix
    it. The difference is that instead of incorrect output or crashing, the problem
    we are trying to solve is poor performance.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, profiling will point to where the performance bottleneck is, at which
    point you will need to use the debugging techniques we discussed earlier in this
    chapter to understand why a particular piece of code does not perform as well
    as it should. For example, faulty logic in a database query might result in loading
    thousands of rows from a table instead of just hundreds. Profiling might show
    you that a particular function is called many more times than expected, at which
    point you would need to use your debugging skills to work out why that is and
    address the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few ways to profile a Python application. If you look at the Profiling
    section in the standard library official documentation, you will see that there
    are two different implementations of the same profiling interface, `profile` and
    `cProfile` :'
  prefs: []
  type: TYPE_NORMAL
- en: '`cProfile` is written in C and adds comparatively little overhead, which makes
    it suitable for profiling long-running programs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`profile` is implemented in pure Python and, as a result, adds significant
    overhead to profiled programs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This interface does **deterministic profiling** , which means that all function
    calls, function returns, and exception events are monitored, and precise timings
    are made for the intervals between these events. Another approach, called **statistical
    profiling** , randomly samples the program’s call stack at regular intervals and
    deduces where time is being spent.
  prefs: []
  type: TYPE_NORMAL
- en: The latter usually involves less overhead but provides only approximate results.
    Moreover, because of the way the Python interpreter runs the code, deterministic
    profiling does not add as much overhead as one would think, so we will show you
    a simple example using `cProfile` from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: There are situations where even the relatively low overhead of `cProfile` is
    not acceptable, for example, if you need to profile code on a live production
    web server because you cannot reproduce the performance problem in your development
    environment. For such cases, you really do need a statistical profiler. If you
    are interested in statistical profiling for Python, we suggest you look at `py-spy`
    ( [https://github.com/benfred/py-spy](https://github.com/benfred/py-spy) ).
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to calculate Pythagorean triples again, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The script is simple; we iterate over the interval `[1,` `mx]` with `a` and
    `b` (avoiding repetition of pairs by setting `b >= a` ) and we check whether they
    belong to a right triangle. We use `calc_hypotenuse()` to get `hypotenuse` for
    `a` and `b` , and then, with `is_int()` , we check whether it is an integer, which
    means `(a, b, hypotenuse)` is a Pythagorean triple.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we profile this script, we get information in a tabular form. The columns
    are `ncalls` (the number of calls to the function), `tottime` (the total time
    spent in each function), `percall` (the average time spent in each function per
    call), `cumtime` (the cumulative time spent in a function plus all functions it
    calls), `percall` (the average cumulative time spent per call), and `filename:lineno(function)`
    . Here is the result we got (to save space, we are omitting the two `percall`
    columns):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Even with this limited amount of data, we can still infer some useful information
    about this code. First, we can see that the time complexity of the algorithm we
    have chosen grows with the square of the input size. The number of calls to `calc_hypotenuse()`
    is exactly *mx (mx + 1) / 2* . We ran the script with `mx = 1000,` and we got
    exactly 500,500 calls. Three main things happen inside the loop: we call `calc_hypotenuse()`
    , we call `is_int()` , and, if the condition is met, we append it to the `triples`
    list.'
  prefs: []
  type: TYPE_NORMAL
- en: Taking a look at the cumulative times in the profiling report, we notice that
    the program spent 0.147 seconds inside `is_int()` , compared to 0.102 seconds
    spent inside `calc_hypotenuse()` . These functions were called the same number
    of times, so our first target for optimization should be the more expensive `is_int()`
    .
  prefs: []
  type: TYPE_NORMAL
- en: If we look at the `tottime` column, we see that the program spent 0.087 seconds
    `in` `is_int()` . This excludes the 0.060 seconds spent in calls from `is_int()`
    to the `is_integer()` method of `float` objects. However, `is_int()` does not
    do anything other than call the `is_integer()` method of its parameter `n` . This
    means that just the additional function call adds an overhead of 87 milliseconds.
    In this program, there is not much benefit to having the `is_int()` function,
    so we can gain 87 milliseconds by just calling `hypotenuse.is_integer()` directly
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we rerun the profiling, we see that we now spend more time in `calc_hypotenuse()`
    than in the `is_integer()` method. Let us see if we can improve that as well.
    As we mentioned in *Chapter 5* , *Comprehensions and Generators* , using the `**`
    power operator to calculate the square of a number is more expensive than multiplying
    it by itself. With that in mind, we can try to improve performance by changing
    `calc_hypotenuse()` to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'After rerunning the profiling again, we find that the program now spends 0.084
    seconds in the `calc_hypotenuse()` function. We have gained only 18 milliseconds.
    We could potentially gain more by eliminating the overhead of the call to `calc_hypotenuse()`
    and calculating the hypotenuse directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Profiling this version shows that we can gain up to 100 milliseconds in this
    way. However, we think that, in this case, the benefits of readability, maintainability,
    and testability that the function gives us outweigh the performance improvement
    of removing it.
  prefs: []
  type: TYPE_NORMAL
- en: You will find all four versions of this program in the source code for the book.
    We encourage you to run the profiling yourself and experiment with other changes
    to the code to see what impact they have on performance (for example, you could
    try to convert `calc_triples()` into a generator function).
  prefs: []
  type: TYPE_NORMAL
- en: This example was trivial, of course, but enough to show you how you could profile
    an application. Having the number of calls that are made to a function helps us
    better understand the time complexity of our algorithms. For example, many coders
    fail to see that those two `for` loops run proportionally to the square of the
    input size.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen profiling of functions, but it is also possible to go to an even
    higher level of granularity and profile each line of a piece of code, if necessary.
    The average Python programmer will not need to do much profiling in their career,
    but it might happen, so it is good to know the options we have.
  prefs: []
  type: TYPE_NORMAL
- en: 'One thing to mention: the results of profiling will quite likely differ depending
    on what system you are running on. Therefore, it is important to be able to profile
    software on a system that is as close as possible to the one the software is deployed
    on, if not actually on it.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have focused on profiling and optimizing the running time
    of a program. Profiling can also be used to analyze and optimize memory usage.
    One of the most popular tools for memory profiling in Python is memray. You can
    read more about it at [https://bloomberg.github.io/memray/](https://bloomberg.github.io/memray/)
    .
  prefs: []
  type: TYPE_NORMAL
- en: When to profile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to know when it is appropriate to profile, and what to do with
    the results we get. Donald Knuth once said, “ *Premature optimization is the root
    of all evil* ,” and, although we wouldn’t have put it quite so strongly, we do
    agree with him. For example, it is seldom worth sacrificing readability or maintainability
    for the sake of gaining a few milliseconds in speed.
  prefs: []
  type: TYPE_NORMAL
- en: Your primary concern should always be *correctness* . You want your code to
    deliver the correct results, therefore write tests, find edge cases, and stress
    your code in every way you think makes sense. Do not be protective; do not put
    things in the back of your brain for later because you think they are not likely
    to happen. Be thorough.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, take care of coding *best practices* . Remember the following: readability,
    extensibility, loose coupling, modularity, and design. Apply OOP principles: encapsulation,
    abstraction, single responsibility, open/closed, and so on. Read up on these concepts.
    They will open horizons for you, and they will expand the way you think about
    code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Third, *refactor* . The Boy Scouts rule says:'
  prefs: []
  type: TYPE_NORMAL
- en: Always leave the campground cleaner than you found it.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Apply this rule to your code.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, when all of this has been taken care of, then and only then take care
    of optimizing and profiling.
  prefs: []
  type: TYPE_NORMAL
- en: Run your profiler and identify bottlenecks. When analyzing the profiling results,
    focus on the functions that were called the most. As we mentioned in *Chapter
    5* , *Comprehensions and Generators* , you will often gain more from even a small
    improvement to a function that is called a million times than from trying to improve
    a function that is only called a few times. When you have an idea of the bottlenecks
    you need to address, start with the worst one first. Sometimes, fixing a bottleneck
    causes a ripple effect that will expand and change the way the rest of the code
    works. Sometimes, this is only a little, and sometimes, it is a bit more, depending
    on how your code was designed and implemented. Therefore, start with the biggest
    issue first.
  prefs: []
  type: TYPE_NORMAL
- en: One of the reasons Python is so popular is that it is possible to extend it
    with modules written in faster, compiled languages like C or C++. So, if you have
    some critical piece of code and you simply cannot achieve the performance you
    need in pure Python, you always have the option of rewriting part of it in C.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring execution time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we finish this chapter, we want to briefly touch on the topic of measuring
    the execution time of code. Sometimes, it is helpful to measure the performance
    of small pieces of code to compare their performance. For example, if you have
    different ways of implementing some operation and you really need the fastest
    version, you may want to compare their performance without profiling your entire
    application.
  prefs: []
  type: TYPE_NORMAL
- en: We have already seen some examples of measuring and comparing execution times
    earlier in this book, for example, in *Chapter 5* , *Comprehensions and Generators*
    , when we compared the performance of `for` loops, list comprehensions, and the
    `map()` function. At this point, we would like to introduce you to a better approach,
    using the `timeit` module. This module uses techniques such as timing many repeated
    executions of the code to improve measurement accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `timeit` module can be a bit tricky to use. We recommend that you read
    about it in the official Python documentation and experiment with the examples
    there until you understand how to use it. Here, we will just give a brief demonstration
    of using the command-line interface to time our two different versions of `calc_hypotenuse()`
    from the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are running the `timeit` module, initializing variables `a = 2` and
    `b = 3` , before timing the execution of `(a**2 + b**2) ** .5` . In the output,
    we can see that `timeit` ran 5 repetitions timing 5,000,000 loop iterations executing
    our calculation. Out of those 5 repetitions, the best average execution time over
    5,000,000 iterations was 91 nanoseconds. Let us see how the alternative calculation,
    `(a*a + b*b) ** .5` , performs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This time, we get an average of 72.8 nanoseconds per loop. This confirms again
    that the second version is slightly faster.
  prefs: []
  type: TYPE_NORMAL
- en: The `timeit` module automatically chooses the number of iterations to ensure
    the total running time is at least 0.2 seconds. This helps to improve accuracy
    by reducing the relative impact of measurement overhead.
  prefs: []
  type: TYPE_NORMAL
- en: For further information about measuring Python performance, make sure you check
    out `pyperf` ( [https://github.com/psf/pyperf](https://github.com/psf/pyperf)
    ) and `pyperformance` ( [https://github.com/python/pyperformance](https://github.com/python/pyperformance)
    ).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this short chapter, we looked at different techniques and suggestions for
    debugging, troubleshooting, and profiling our code. Debugging is an activity that
    is always part of a software developer’s work, so it is important to be good at
    it.
  prefs: []
  type: TYPE_NORMAL
- en: If approached with the correct attitude, it can be fun and rewarding.
  prefs: []
  type: TYPE_NORMAL
- en: We explored techniques to inspect our code using custom functions, logging,
    debuggers, traceback information, profiling, and assertions. We saw simple examples
    of most of them. We also discussed some guidelines that will help when it comes
    to facing the fire.
  prefs: []
  type: TYPE_NORMAL
- en: Remember always to *stay calm and focused* , and debugging will be much easier.
    This, too, is a skill that needs to be learned and it is the most important. An
    agitated and stressed mind cannot work properly, logically, and creatively. Therefore,
    if you do not strengthen it, it will be difficult for you to put all your knowledge
    to good use. So, when facing a difficult bug, if you have the opportunity, make
    sure you go for a short walk or take a power nap—relax. Often, the solution presents
    itself after a good break.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to explore type hinting and the use of static
    type checkers, which can be useful for reducing the likelihood of certain types
    of bugs.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://discord.com/invite/uaKmaz7FEC](Chapter_11.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '![img](img/QR_Code119001106417026468.png)'
  prefs: []
  type: TYPE_IMG
