- en: Deploying Flask Apps
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have reached the last chapter of the book, and have a fully functioning
    web app made in Flask, the final step in our development cycle is to make the
    app available for the world. There are many different approaches for hosting your
    Flask app, each of them with its own pros and cons. This chapter will cover the
    best solutions and guide you through situations in which you should choose one
    over the other.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: A brief introduction to the most commonly used web servers and gateway interfaces
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to deploy on various cloud services
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to build Docker images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to describe services using Docker compose
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to describe your infrastructure using AWS CloudFormation (IaC)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to set up and work with a CI/CD system to easily build, test, review, and
    deploy our application
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web servers and gateway interfaces
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will make a quick introduction to the most commonly used
    web servers and **Web Server Gateway Interfaces** (**WSGI**), and their differences
    and configuration. A WSGI is an application-agnostic layer between the web server
    and the python application itself.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Gevent
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The simplest option to get a web server up and running is to use a Python library,
    named `gevent`, to host your application. `Gevent` is a Python library that adds
    an alternative way of doing concurrent programming,called co-routines, outside
    of the Python threading library. Gevent has an interface to run WSGI applications
    that is both simple and has good performance. A simple gevent server can easily
    handle hundreds of concurrent users, which is 99% more than the users of websites
    on the internet will ever have. The downside to this option is that its simplicity
    means a lack of configuration options. There is no way, for example, to add rate
    limiting to the server, or to add HTTPS traffic. This deployment option is purely
    for sites that you don''t expect to receive a huge amount of traffic. Remember
    YAGNI: only upgrade to a different web server if you really need to.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Co-routines are a bit outside of the scope of this book, but a good explanation
    can be found at [https://en.wikipedia.org/wiki/Coroutine](https://en.wikipedia.org/wiki/Coroutine).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'To install `gevent`, we will use `pip` with the following command:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the root of the project directory, in a new file named `gserver.py`, add
    the following:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To run the server with supervisor, just change the command value to the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now when you deploy, `gevent` will automatically be installed for you by running
    your `requirements.txt` on every deployment; that is, if you are properly pip
    freezing after every new dependency is added.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Tornado
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Tornado** is another very simple way to deploy WSGI apps purely with Python.
    Tornado is a web server that is designed to handle thousands of simultaneous connections.
    If your application needs real-time data, Tornado also supports WebSockets for
    continuous, long-lived connections to the server.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Do not use Tornado in production on a Windows server. The Windows version of
    Tornado is not only slower—it is also considered beta-stage quality software.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 不要在Windows服务器上以生产模式使用Tornado。Tornado的Windows版本不仅速度较慢，而且被认为是处于测试阶段的软件。
- en: 'To use Tornado with our application, we will use Tornado''s `WSGIContainer`
    in order to wrap the application object to make it Tornado-compatible. Then, Tornado
    will start to listen on port *80* for requests until the process is terminated.
    In a new file, named `tserver.py`, add the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Tornado与我们的应用程序一起使用，我们将使用Tornado的`WSGIContainer`来包装应用程序对象，使其与Tornado兼容。然后，Tornado将开始监听端口*80*上的请求，直到进程终止。在新的文件`tserver.py`中添加以下内容：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To run the Tornado with supervisor privileges, just change the command value
    to the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要以管理员的权限运行Tornado，只需更改命令值为以下内容：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Nginx and uWSGI
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Nginx和uWSGI
- en: 'If you need better performance or more options for customization, the most
    popular way to deploy a Python web application is to use a Nginx web server as
    a frontend for the WSGI-based uWSGI server by using a reverse proxy. A *reverse
    proxy* is a program in networks that retrieves contents for a client from a server,
    as if it returned from the proxy itself. This process is shown in the following
    diagram:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要更好的性能或更多自定义选项，最流行的部署Python网络应用程序的方式是使用Nginx网络服务器作为基于WSGI的uWSGI服务器的代理前端。*反向代理*是一种网络程序，它从服务器获取客户端的内容，就像它从代理本身返回一样。这个过程在以下图中展示：
- en: '![](img/6547d721-3adc-45eb-baa1-850483f73ff3.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6547d721-3adc-45eb-baa1-850483f73ff3.png)'
- en: '**Nginx** and **uWSGI** are used like this, because this way, we get the power
    of the Nginx frontend, while having the customization of uWSGI.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**Nginx**和**uWSGI**的使用方式是这样的，因为这样我们既获得了Nginx前端的强大功能，又具有uWSGI的定制性。'
- en: '**Nginx** is a very powerful web server that became popular by providing the
    best combination of speed and customization. Nginx is consistently faster than
    other web severs, such as Apache''s httpd, and has native support for WSGI applications.
    It achieves this speed thanks to the developers taking several good architecture
    decisions, as well as not going to try to cover a large amount of use cases, as
    Apache does. The latter point here was a decision taken early on in development
    of Nginx. Having a smaller feature set makes it much easier to maintain and optimize
    the code. From a programmer''s perspective, it is also much easier to configure
    Nginx, as there is no giant default configuration file (`httpd.conf`) that can
    be overridden with `.htaccess` files in each of your project directories.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**Nginx**是一个非常强大的网络服务器，因其提供了速度和定制的最佳组合而变得流行。Nginx始终比其他网络服务器，如Apache的httpd，要快，并且具有对WSGI应用程序的原生支持。它之所以能够达到这种速度，是因为开发者做出了几个良好的架构决策，并且没有像Apache那样试图覆盖大量用例。后一点是在Nginx开发早期就做出的决定。具有较小的功能集使得维护和优化代码变得更加容易。从程序员的视角来看，配置Nginx也更容易，因为没有巨大的默认配置文件（`httpd.conf`），每个项目目录中都可以用`.htaccess`文件覆盖。'
- en: '**uWSGI** is a web server that supports several different types of server interfaces,
    including WSGI. uWSGI handles the severing of the application content, as well
    as things such as the load balancing of traffic across several different processes
    and threads.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**uWSGI**是一个支持多种不同类型服务器接口的网络服务器，包括WSGI。uWSGI处理应用程序内容的提供，以及诸如在多个不同进程和线程之间进行流量负载均衡等事情。'
- en: 'To install uWSGI, we will use a `pip` command, as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装uWSGI，我们将使用以下`pip`命令：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In order to run our application, uWSGI needs a file with an accessible WSGI
    application. In a file named `wsgi.py` in the top level of the project directory.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行我们的应用程序，uWSGI需要一个包含可访问WSGI应用程序的文件。在项目目录顶层名为`wsgi.py`的文件中。
- en: 'To test uWSGI, we can run it from the **command-line interface** (**CLI**)
    with the following commands:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试uWSGI，我们可以通过以下命令从**命令行界面**（**CLI**）运行它：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you are running this on your server, you should be able to access port 8080
    and see your app (if you don't have a firewall, that is).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在自己的服务器上运行此程序，您应该能够访问端口8080并看到您的应用程序（如果您没有防火墙的话）。
- en: What this command does is load the app object from the `wsgi.py` file, and make
    it accessible from `localhost` on port *8080*. It also spawns four different processes
    with two threads each, which are automatically load balanced by a master process.
    This amount of processes is overkill for the vast majority of websites. To start
    off, use a single process with two threads and scale up from there.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令的作用是从 `wsgi.py` 文件中加载 app 对象，并使其在 `localhost` 的端口 *8080* 上可访问。它还启动了四个不同的进程，每个进程有两个线程，这些进程由主进程自动负载均衡。对于绝大多数网站来说，这样的进程数量是过度的。为了开始，使用一个进程和两个线程，然后根据需要扩展。
- en: 'Instead of adding all of the configuration options on the CLI, we can create
    a text file to hold our configuration, which gives us the same benefits for configuration
    that were listed in the *Gevent *section, about supervisor. In the root of the
    project directory, create a file named `uwsgi.ini` and add the following code:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不必在 CLI 上添加所有配置选项，可以创建一个文本文件来保存我们的配置，这为我们提供了与 *Gevent* 部分中提到的 supervisor 相同的配置优势。在项目目录的根目录下创建一个名为
    `uwsgi.ini` 的文件，并添加以下代码：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: uWSGI supports hundreds of configuration options, as well as several official
    and unofficial plugins. To leverage the full power of uWSGI, you can explore the
    documentation at [http://uwsgi-docs.readthedocs.org/](http://uwsgi-docs.readthedocs.org/).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI 支持数百个配置选项，以及一些官方和非官方插件。要充分利用 uWSGI 的全部功能，您可以查阅 [http://uwsgi-docs.readthedocs.org/](http://uwsgi-docs.readthedocs.org/)
    上的文档。
- en: 'Let''s now run the server from supervisor:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从 supervisor 运行服务器：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Because we are installing Nginx from the OS's package manager, the OS will handle
    the running of Nginx for us.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们是从操作系统的软件包管理器中安装 Nginx，操作系统将为我们处理 Nginx 的运行。
- en: At the time of writing, the Nginx version in the official Debian package manager
    is several years old. To install the most recent version, follow the instructions
    available at [http://wiki.nginx.org/Install](http://wiki.nginx.org/Install).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，官方 Debian 软件包管理器中的 Nginx 版本已经过时好几年。要安装最新版本，请遵循 [http://wiki.nginx.org/Install](http://wiki.nginx.org/Install)
    上提供的说明。
- en: 'Next, we need to create an Nginx configuration file, and then, when we push
    the code, we need to copy the configuration file to the `/etc/nginx/sites-available/`
    directory. In the root of the project directory, create a new file named `nginx.conf`,
    and add the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建一个 Nginx 配置文件，然后，当我们推送代码时，我们需要将配置文件复制到 `/etc/nginx/sites-available/`
    目录。在项目目录的根目录下创建一个名为 `nginx.conf` 的新文件，并添加以下内容：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: What this configuration file does is tells Nginx to listen for incoming requests
    on port *80*, and forwards all requests to the WSGI application that is listening
    on port *8080*. Also, it makes an exception for any requests for static files,
    and instead sends those requests directly to the file system. Bypassing uWSGI
    for static files gives a great boost to performance, as Nginx is really good at
    serving static files quickly.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置文件的作用是告诉 Nginx 监听端口 *80* 上的传入请求，并将所有请求转发到监听端口 *8080* 的 WSGI 应用程序。此外，它为静态文件请求设置了一个例外，并将这些请求直接发送到文件系统。绕过
    uWSGI 处理静态文件可以极大地提高性能，因为 Nginx 在快速服务静态文件方面非常出色。
- en: Apache and uWSGI
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache 和 uWSGI
- en: 'Using Apache httpd with uWSGI mostly requires the same setup. First off, we
    need an Apache configuration file, so let''s create a new file, named `apache.conf`,
    in the root of our project directory, and add the following code:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Apache httpd 与 uWSGI 的设置基本上是相同的。首先，我们需要一个 Apache 配置文件，因此让我们在我们的项目目录根目录下创建一个名为
    `apache.conf` 的新文件，并添加以下代码：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This file simply tells Apache to pass all requests on port *80* to the uWSGI
    web server listening on port *8080*. However, this functionality requires an extra
    Apache plugin from uWSGI, named `mod-proxy-uwsgi`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件仅告知 Apache 将所有端口 *80* 上的请求转发到监听端口 *8080* 的 uWSGI 网络服务器。然而，此功能需要从 uWSGI 获取一个额外的
    Apache 插件，名为 `mod-proxy-uwsgi`。
- en: Next, we will cover several solutions for deploying our application on **Platform
    as a Service** (**PaaS**) and **Infrastructure as a Service** (**IaaS**) utilities.
    You will learn how to create several types of environments and make our example
    Blog application available to the world.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍几种在 **平台即服务**（**PaaS**）和 **基础设施即服务**（**IaaS**）工具上部署我们的应用程序的解决方案。您将学习如何创建几种不同类型的环境，并使我们的示例
    Blog 应用程序对全世界可用。
- en: Deploying on Heroku
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Heroku 上部署
- en: '**Heroku** is the first of the **Platform as a Service** (**PaaS**) providers
    that this chapter will cover. PaaS is a service given to web developers that allows
    them to host their websites on a platform that is controlled and maintained by
    someone else. At the cost of some freedom, you gain assurances that your website
    will automatically scale with the number of users your site has, with no extra
    work on your part. Using PaaS utilities may, however, tend to be more expensive
    than running your own servers.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**Heroku** 是本章将要介绍的第一个 **平台即服务**（**PaaS**）提供商。PaaS 是一种服务，提供给网络开发者，使他们能够将网站托管在由他人控制和维护的平台之上。以牺牲一些自由为代价，你可以获得保证，你的网站将自动根据网站的用户数量进行扩展，而无需你做额外的工作。然而，使用
    PaaS 工具可能会比运行自己的服务器更昂贵。'
- en: Heroku is a PaaS utility that aims to provide ease of use to web developers
    by hooking into already existing tools, and not requiring any large changes in
    the app. Heroku works by reading a file named `Procfile`, which contains commands
    that your Heroku dyno (basically a virtual machine sitting on a server) will run.
    Before we begin, you will need a Heroku account. If you wish to just experiment,
    there is a free account available.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Heroku 是一种 PaaS 工具，旨在通过挂钩到现有的工具来为网络开发者提供易用性，而不需要应用程序进行任何大的更改。Heroku 通过读取名为 `Procfile`
    的文件来工作，该文件包含你的 Heroku dyno（基本上是位于服务器上的虚拟机）将要运行的命令。在我们开始之前，你需要一个 Heroku 账户。如果你只想进行实验，有一个免费账户可供使用。
- en: 'In the root of the directory, in a new file named `Procfile`, we have the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在目录的根目录下，在名为 `Procfile` 的新文件中，我们有以下内容：
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This tells Heroku that we have a process named `web`, which will run the uWSGI
    command and pass the `uwsgi.ini` file. Heroku also needs a file named `runtime.txt`,
    which will tell Heroku what Python runtime you wish to use—at the time of writing,
    the latest Python release is 3.7.0:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉 Heroku 我们有一个名为 `web` 的进程，该进程将运行 uWSGI 命令并传递 `uwsgi.ini` 文件。Heroku 还需要一个名为
    `runtime.txt` 的文件，该文件将告诉 Heroku 你希望使用哪个 Python 运行时——在撰写本文时，最新的 Python 版本是 3.7.0：
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Next, make sure that **uwsgi** is present in the `requirements.txt` file.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，确保 **uwsgi** 已存在于 `requirements.txt` 文件中。
- en: 'Finally, we need to make some modifications to the `uwsgi.ini` file that we
    made earlier:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要对之前创建的 `uwsgi.ini` 文件进行一些修改：
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We set the port on which uWSGI listens to the environment variable port, because
    Heroku does not directly expose the dyno to the internet. Instead, it has a very
    complicated load balancer and reverse proxy system, so we need to have uWSGI listening
    on the port that Heroku needs us to listen on. Also, we set die-on-term to true,
    so that uWSGI listens for a signal termination event from the OS correctly.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 uWSGI 监听的端口设置为环境变量 port，因为 Heroku 并不会直接将 dyno 暴露给互联网。相反，它有一个非常复杂的负载均衡器和反向代理系统，因此我们需要让
    uWSGI 监听 Heroku 需要我们监听的端口。此外，我们还设置了 die-on-term 为 true，以便 uWSGI 能够正确地监听来自操作系统的信号终止事件。
- en: To work with Heroku's command-line tools, we first need to install them, which
    can be done from [https://toolbelt.heroku.com](https://toolbelt.heroku.com).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Heroku 的命令行工具，我们首先需要安装它们，这可以通过 [https://toolbelt.heroku.com](https://toolbelt.heroku.com)
    完成。
- en: 'Next, you need to log in to your account:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要登录到你的账户：
- en: '[PRE14]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can test our setup to make sure that it will work on Heroku before we deploy
    it, by using the `foreman` command:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署之前，我们可以使用 `foreman` 命令测试我们的设置，以确保它将在 Heroku 上正常工作：
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `foreman` command simulates the same production environment that Heroku
    uses to run our app. To create the dyno, which will run the application on Heroku''s
    servers, we will use the `create` command. Then, we can push Heroku to the remote
    branch on our Git repository to have Heroku servers automatically pull down our
    changes:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`foreman` 命令模拟了 Heroku 用来运行我们的应用程序的相同生产环境。为了创建将在 Heroku 服务器上运行应用程序的 dyno，我们将使用
    `create` 命令。然后，我们可以将 Heroku 推送到 Git 仓库上的远程分支，以便 Heroku 服务器自动拉取我们的更改：'
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If everything went well, you should now have a working application on your
    new Heroku dyno. You can open a new tab to your new web application with the following
    command:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，你现在应该有一个在新的 Heroku dyno 上运行的应用程序。你可以使用以下命令打开新标签页，访问你的新网络应用程序：
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To see the app in action in a Heroku deployment, visit [https://mastering-flask.herokuapp.com/](https://mastering-flask.herokuapp.com/).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看在 Heroku 部署中的应用程序运行情况，请访问 [https://mastering-flask.herokuapp.com/](https://mastering-flask.herokuapp.com/).
- en: Using Heroku Postgres
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Heroku Postgres
- en: 'Maintaining a database properly is a full-time job. Thankfully, we can use
    one of Heroku''s built-in features in order to automate this process for us. Heroku
    Postgres offers a database that is maintained and hosted entirely by Heroku. Because
    we are using SQLAlchemy, using Heroku Postgres is trivial. In your dyno''s dashboard,
    there is a link to your Heroku Postgres information. By clicking on it, you will
    be taken to a page similar to the following screenshot:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d7d77ee8-61c8-46ff-9354-bea69d15beca.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
- en: By clicking on the URL field, you will be given an SQLAlchemy URL, which you
    can copy directly to your production configuration object.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Using Celery on Heroku
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have our production web server and database set up, but we still need to
    set up Celery. Using one of Heroku''s many plugins, we can host a RabbitMQ instance
    in the cloud, while running the Celery worker on the dyno. The first step is to
    tell Heroku to run your Celery worker in `Procfile`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, to install the Heroku RabbitMQ plugin with the free plan (the `lemur`
    plan), use the following command:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: To get the full list of Heroku add-ons, go to [https://elements.heroku.com/addons](https://elements.heroku.com/addons).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'At the same location on the dashboard where Heroku Postgres was listed, you
    will now find CloudAMQP:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a0579d3f-1e34-4b2f-b01d-5b8ebfb9ac06.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
- en: 'Clicking on CloudAMQP will also give you a screen with a URL, which you can
    copy and paste into your production configuration:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ed113cc9-8bb1-4a24-b6be-0dce512a0284.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
- en: Deploying on Amazon Web Services
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Amazon Web Services** (**AWS**) is a collection of services maintained by
    Amazon, and built on top of the same infrastructure that runs Amazon.com. To deploy
    our Flask code, we will be using Amazon Elastic Beanstalk in this section, while
    the database will be hosted on Amazon''s **Relational Database Service** (**RDS**),
    and our messaging queue for Celery will be hosted on Amazon''s **Simple Queue
    Service** (**SQS**).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Using Flask on Amazon Elastic Beanstalk
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Elastic Beanstalk is a platform for web applications that offers many powerful
    features for developers, so they don't have to worry about maintaining servers.
    For example, your Elastic Beanstalk application will automatically scale by utilizing
    more and more servers as the number of people using your app at once grows. For
    Python apps, Elastic Beanstalk uses Apache, in combination with `mod_wsgi`, to
    connect to WSGI applications—if your deployment is simple with mid-to-low load,
    there is no extra configuration needed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we begin, you will need an Amazon.com account to log in to the console.
    Next, you need to install **awscli** and configure it with your credentials—you
    must generate an AWS access key and secret: go to the AWS console, choose IAM
    service, choose your user, then choose the Security Credentials tab, and click
    on the Create access key. Next, we need to install awsebcli to manage Elastic
    Beanstalk from the CLI:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next, from the root directory of our project, we are going to configure the
    CLI and create a new Elastic Beanstalk application:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，从我们项目的根目录开始，我们将配置 CLI 并创建一个新的 Elastic Beanstalk 应用程序：
- en: '[PRE21]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Elastic Beanstalk looks for a file named `application.py` in your project directory,
    and it expects to find a WSGI application, named `application`, in that file:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Beanstalk 会查找项目目录中的 `application.py` 文件，并期望在该文件中找到一个名为 `application`
    的 WSGI 应用程序：
- en: '[PRE22]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Next, we are going to create a development environment. Each Elastic Beanstalk
    application can contain one or many environments. But as things currently stand,
    our application will fail—we need to tell Elastic Beanstalk how to install Flask-YouTube
    on Python's virtual environment and initialize the database. To do this, we need
    to extend the default setup.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个开发环境。每个 Elastic Beanstalk 应用程序可以包含一个或多个环境。但就目前情况来看，我们的应用程序将会失败——我们需要告诉
    Elastic Beanstalk 如何在 Python 的虚拟环境中安装 Flask-YouTube 并初始化数据库。为此，我们需要扩展默认设置。
- en: 'In the root directory, we need a directory named `.ebextensions`. This is where
    we create a lot of extra configuration and setup scripts. In `.ebextensions`,
    we create two shell scripts that will run in the post-deploy phase. So, in the `.ebextensions/10_post_deploy.config` file,
    add the following code:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在根目录下，我们需要一个名为 `.ebextensions` 的目录。这是我们在其中创建大量额外配置和设置脚本的地方。在 `.ebextensions`
    中，我们创建两个将在部署后阶段运行的 shell 脚本。因此，在 `.ebextensions/10_post_deploy.config` 文件中，添加以下代码：
- en: '[PRE23]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Using YAML notation here, we tell Elastic Beanstalk to create two shell scripts
    to install Flask-YouTube and create or migrate the database. The location of these
    files is special—`/opt/elasticbeanstalk/hooks/appdeploy/post` is where we can
    drop scripts to be executed after deploying. These scripts are executed in alphabetic
    order. Also, take note of the following locations:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 YAML 语法，我们告诉 Elastic Beanstalk 创建两个 shell 脚本来安装 Flask-YouTube 并创建或迁移数据库。这些文件的位置是特殊的——`/opt/elasticbeanstalk/hooks/appdeploy/post`
    是我们可以放置在部署后执行的脚本的地方。这些脚本按字母顺序执行。同时，请注意以下位置：
- en: '`/opt/python/current/app`: This is the deploy location of the application.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/opt/python/current/app`: 这是应用程序的部署位置。'
- en: '`/opt/python/current/env`: This is a file containing defined environment variables
    on Elastic Beanstalk.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/opt/python/current/env`: 这是一个包含 Elastic Beanstalk 上定义的环境变量的文件。'
- en: '`/opt/python/run/venv`: This is python''s `virtualenv`, and is where Elastic
    Beanstalk installed all our defined dependencies.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/opt/python/run/venv`: 这是指定的 Python 的 `virtualenv`，也是 Elastic Beanstalk 安装所有定义的依赖项的地方。'
- en: 'Now, for our environment creation, run the following commands:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了创建我们的环境，运行以下命令：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Finally, after the environment has finished provisioning the infrastructure
    and deployment, we can check out our application using the following command:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在环境完成基础设施和部署配置后，我们可以使用以下命令检查我们的应用程序：
- en: '[PRE25]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To deploy new versions of our application, we just have to run this command:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署我们应用程序的新版本，我们只需运行此命令：
- en: '[PRE26]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note that our development environment uses SQLite, so the database is on a file
    on the web server itself. On each deployment or instance recreation, this database
    is recreated.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们的开发环境使用 SQLite，因此数据库位于 Web 服务器上的一个文件中。在每次部署或实例重建时，此数据库都会被重新创建。
- en: Using Amazon RDS
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon RDS
- en: '**Amazon RDS** is a database-hosting platform in the cloud that automatically
    manages several things, such as recovery on node failure, scheduled backups, and
    master/slave setups.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon RDS** 是一个云数据库托管平台，它自动管理多个方面，例如节点故障时的恢复、计划备份和主/从设置。'
- en: To use RDS, go to the Services tab on the AWS console and click on Relational
    Database Service.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 RDS，请转到 AWS 控制台的“服务”选项卡，并点击“关系数据库服务”。
- en: Now, create and configure a new database—make sure that on the Publicly accessible option,
    you choose No. Choose the same VPC as the instances, and register your admin credentials
    carefully. Now, wait a few minutes for the instance creation. After that, choose
    your instance, go to the details configuration, and find the field for the **endpoint**—it
    should look something like `myblog.c7pdwgffmbqdm.eu-central-1.rds.amazonaws.com`.
    Our production configuration uses system environment variables to set up the database
    URI, so we have to configure Elastic Beanstalk to set the `DB_URI` environment
    variable.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建并配置一个新的数据库——确保在**公开访问**选项中选择否。选择与实例相同的 VPC，并仔细登记您的管理员凭证。现在，等待几分钟以创建实例。之后，选择您的实例，转到详细配置，并找到**端点**字段——它应该看起来像
    `myblog.c7pdwgffmbqdm.eu-central-1.rds.amazonaws.com`。我们的生产配置使用系统环境变量来设置数据库 URI，因此我们必须配置
    Elastic Beanstalk 以设置 `DB_URI` 环境变量。
- en: 'To use these environment variables, we need to change our blog''s `config.py` file
    to use the actual OS environment variables, as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这些环境变量，我们需要将博客的 `config.py` 文件更改为使用实际的 OS 环境变量，如下所示：
- en: '[PRE27]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Make sure your instances can connect to the database. If you chose the security
    group default options and RDS creation, then the wizard will have created a security
    group for you (the default name is '`rds-launch-wizard`'). On EC2, edit this security
    group and open port 3306 to your instances' VPC CIDR.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您的实例可以连接到数据库。如果您选择了安全组默认选项和 RDS 创建，那么向导将为您创建一个安全组（默认名称为 '`rds-launch-wizard`'）。在
    EC2 上，编辑此安全组并打开 3306 端口到您的实例的 VPC CIDR。
- en: 'In `.ebextensions`, take a look at the `01_env.config`—this is where we set
    our environment variables:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `.ebextensions` 中查看 `01_env.config`——这是我们设置环境变量的地方：
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Finally, let''s create the production environment with the following command:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们使用以下命令创建生产环境：
- en: '[PRE29]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Using Celery with Amazon SQS
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Celery 和 Amazon SQS
- en: In order to use Celery on AWS, we need to have our Elastic Beanstalk instance
    run our Celery worker in the background, as well as set up an SQS messaging queue.
    For Celery to support SQS, it needs to install a helper library from `pip`. Once
    more, verify that our `requirements.txt` file contains the **boto3** package.
    Elastic Beanstalk will look at this file and create a virtual environment from
    it.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 AWS 上使用 Celery，我们需要让我们的 Elastic Beanstalk 实例在后台运行 Celery 工作进程，并设置 SQS 消息队列。为了使
    Celery 支持 SQS，它需要从 `pip` 安装一个辅助库。再次确认我们的 `requirements.txt` 文件包含 **boto3** 包。Elastic
    Beanstalk 将查看此文件并从中创建一个虚拟环境。
- en: 'Setting up a new messaging queue on SQS is very easy. Go to the Services tab
    and click on Simple Queue Service in the applications tab, then click on **Create
    New Queue**. After a very short configuration screen, you should see a screen
    much like the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SQS 上设置新的消息队列非常简单。转到“服务”选项卡，然后在“应用程序”选项卡中点击“简单队列服务”，然后点击**创建新队列**。在非常简短的配置屏幕后，你应该会看到一个类似于以下屏幕的界面：
- en: '![](img/f22c7501-612e-4e62-b7cc-0f12df21d56a.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f22c7501-612e-4e62-b7cc-0f12df21d56a.png)'
- en: Next, we have to give our instances access to the newly created SQS. The easiest
    way to do this is editing the Elastic Beanstalk default instance profile (this
    is not recommended, however—you should create a separate instance profile and
    associate all your instances with it using `.ebextensions` option settings). The
    default IAM instance profile is named [aws-elasticbeanstalk-ec2-role](https://console.aws.amazon.com/iam/home#/roles/aws-elasticbeanstalk-ec2-role).
    Go to IAM service, then roles, then choose the [aws-elasticbeanstalk-ec2-role](https://console.aws.amazon.com/iam/home#/roles/aws-elasticbeanstalk-ec2-role) role.
    Next, click on Add inline policy and follow the wizard to give access to the newly
    created SQS.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须让我们的实例访问新创建的 SQS。最简单的方法是编辑 Elastic Beanstalk 默认实例配置文件（不过这并不推荐——您应该创建一个单独的实例配置文件，并使用
    `.ebextensions` 选项设置将所有实例与其关联）。默认 IAM 实例配置文件名为 [aws-elasticbeanstalk-ec2-role](https://console.aws.amazon.com/iam/home#/roles/aws-elasticbeanstalk-ec2-role)。转到
    IAM 服务，然后选择角色，然后选择 [aws-elasticbeanstalk-ec2-role](https://console.aws.amazon.com/iam/home#/roles/aws-elasticbeanstalk-ec2-role)
    角色。接下来，点击**添加内联策略**并按照向导为新建的 SQS 提供访问权限。
- en: 'Now we have to change our `CELERY_BROKER_URL` to the new URL, which takes the
    following format:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须将我们的 `CELERY_BROKER_URL` 改为新 URL，其格式如下：
- en: '[PRE30]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Change the `AWS_ACCOUNT_ID` value to your AWS account ID.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `AWS_ACCOUNT_ID` 的值更改为您的 AWS 账户 ID。
- en: 'Finally, we need to tell Elastic Beanstalk to run a Celery worker in the background.
    Once more, we can do this in `.ebextensions`. Create a file named `11_celery_start.config`,
    and insert the following code into it:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要告诉Elastic Beanstalk在后台运行Celery工作进程。再一次，我们可以在`.ebextensions`中这样做。创建一个名为`11_celery_start.config`的文件，并将以下代码插入其中：
- en: '[PRE31]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Note that this kind of Celery worker deployment lives on the web server (which
    is not recommended), and will also scale along with the web servers in line with
    demand. A better option would be to explore the worker feature from Elastic Beanstalk,
    but this would imply a complete rework of the feature, and we'd suffer from subsequent
    vendor lock-in.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这种Celery工作部署存在于Web服务器上（这并不推荐），并且会随着Web服务器按需扩展。更好的选择是探索Elastic Beanstalk的工作功能，但这将意味着对功能进行彻底的重构，我们可能会遭受后续的供应商锁定。
- en: Using Docker
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker
- en: Docker is a container-based technology created in 2013 by Docker, Inc. Container
    technology is not new, and has been around for some time on Unix OS, with chroot
    created in 1982, Solaris Zones in 2004, and WPAR available on AIX or OS400 systems
    (although WPAR is more of a virtualization technology than a container). Later,
    two important features were integrated on Linux: **namespaces**, which isolate
    OS function names, and **cgroups**, a collection of processes that are bound by
    configuration and resource limits. These new features gave birth to Linux containers,
    so why use Docker?
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 是 Docker, Inc. 在 2013 年创建的一种基于容器的技术。容器技术并不新鲜，Unix 操作系统上已经存在一段时间了，1982
    年就有 chroot，2004 年有 Solaris Zones，AIX 或 OS400 系统上也有 WPAR（尽管 WPAR 更像是一种虚拟化技术而不是容器）。后来，Linux
    集成了两个重要的特性：**namespaces**，它隔离了 OS 功能名称，以及 **cgroups**，这是一个受配置和资源限制约束的进程集合。这些新特性催生了
    Linux 容器，那么为什么还要使用 Docker 呢？
- en: Mainly, because Docker made configuration definitions simple. Using a very easy-to-write
    Dockerfile, you can describe how to provision your container and create a new
    image with it. Each Dockerfile line will create a new FS layer using UnionFS,
    which makes changes very quick to apply, and it's equally easy to roll back and
    forward between changes. Also Docker, Inc. created an open image repository, where
    you can find quality images of almost any Linux software available . We have already
    used some of these for Redis and RabbitMQ in [Chapter 9](5672073f-7a18-4865-9800-a2124147042c.xhtml),
    *Creating Asynchronous Tasks with Celery*.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 主要是因为Docker使配置定义变得简单。使用非常容易编写的Dockerfile，您可以描述如何配置您的容器并使用它创建一个新的镜像。每个Dockerfile行都会使用UnionFS创建一个新的文件系统层，这使得更改非常快速地应用，并且同样容易回滚和前进到更改。此外，Docker,
    Inc. 创建了一个开放的镜像仓库，您可以在其中找到几乎所有Linux软件的质量镜像。我们已经在[第9章](5672073f-7a18-4865-9800-a2124147042c.xhtml)，*使用Celery创建异步任务*中使用了一些这些镜像。
- en: 'Docker has gained enormous traction and hype. Some of its best features are
    the following:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 已经获得了巨大的关注和炒作。其中一些最好的特性如下：
- en: 'Solving dependency issues from the OS: Since we are packing a thin OS with
    your container image, it is safe to assume that what runs on your laptop will
    run on production as well.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决来自操作系统的依赖问题：由于我们正在将一个薄的操作系统打包到您的容器镜像中，因此可以安全地假设在您的笔记本电脑上运行的内容在生产环境中也能运行。
- en: Containers are very light, and users are able to run multiple containers on
    the same VM or hardware host, which can reduce operations costs and increase efficiency.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器非常轻量，用户可以在同一虚拟机或硬件主机上运行多个容器，这可以降低运营成本并提高效率。
- en: Containers bootstrap very quickly, enabling your infrastructure to scale equally
    quickly, if, for example, you needed to address an increase in workload.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器启动非常快，使您的基础设施能够快速扩展，例如，如果您需要处理工作负载的增加。
- en: Developers can easily share their application with other developers using containers.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发者可以轻松地使用容器与其他开发者共享他们的应用程序。
- en: 'Docker supports DevOps principles: developers and operations can and should
    work together on the image and architecture definition, using Dockerfile or Docker
    Compose.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 支持DevOps原则：开发者和运维人员可以在镜像和架构定义上共同工作，使用Dockerfile或Docker Compose。
- en: 'If we consider the differences in features on offer from Docker containers
    versus VMs, let''s remember that containers share the same kernel and normally
    run a single process, while VMs run a fully featured guest OS:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑Docker容器与虚拟机提供的功能差异，让我们记住容器共享相同的内核并且通常运行单个进程，而虚拟机运行一个完整的客户操作系统：
- en: '![](img/5ef2a593-2af8-4fb8-9282-79e7c50ac68a.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ef2a593-2af8-4fb8-9282-79e7c50ac68a.png)'
- en: This architecture makes containers very lightweight and quick to spawn.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构使容器非常轻量且快速启动。
- en: Creating Docker images
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout the previous chapters, our Blog application has grown from a simple
    three-tier architecture to a multi-tier one. We now need to address a web server,
    database, cache system, and queue. We are going to define each of these layers
    as Docker containers.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: First, let's begin with our web server and Flask application. For this, we will
    be using an Nginx frontend, and a WSGI, called uWSGI, for the backend.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'A Dockerfile is a text file that contains special instructions with which we
    use to specify our Docker image and how it should be run. The build process is
    going to execute the commands one by one, creating a new layer on each one. Some
    of the most used Dockerfile commands include the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '`FROM`**: **Specifies the base image that our new image is based upon. We can
    start from a really thin OS, such as Alpine, or directly from an RabbitMQ image.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EXPOSE`:Informs Docker that the container listens on a specified network port/protocol.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ENV`:Sets environment variables.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WORKDIR`: Establishes the base directory for the Dockerfile.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RUN`:Runs bash Linux commands on a new layer. This is normally used to install
    additional packages.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`COPY`:Copies files or directories from local filesystem to the Docker image.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CMD`:There can be only one instance of CMD. It specifies how the container
    should be run.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ENTRYPOINT`: This has the same objective as CMD, but is a script in Docker.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a full reference of Dockerfile commands, check out the documentation at [https://docs.docker.com/engine/reference/builder/#usage](https://docs.docker.com/engine/reference/builder/#usage).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'Our directory structure for Docker deploy is going to be the following:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The images we are going to create will be used with Docker Compose (more on
    this later in this chapter), so they will not work on a standalone basis. If you
    don't want to use Docker Compose, very few modification are needed for the images
    to work—you just have to change the `prod.env` file.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s create a Dockerfile for our web server. We will use a previous
    image that already contains NGINX and uWSGI, saving us the work to install and
    configure them. Our `Dockerfile_frontend` is the Dockerfile containing the definition
    for creating frontend images:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: First, in the preceding snippet, we base our image on `uwsgi-nginx:python3.6`,
    which means we are going to use Python 3.6\. Next, we create and set the directory
    where our application will live—this will be in `/srv/app`. Then we copy all our
    local content (myblog code) to the image itself using the `COPY . .`. Next, we
    copy the configuration file for our WSGI, finally configuring the number of workers
    that NGINX will use. At the end, we inform Docker that this image will be listening
    on port 80, using `EXPOSE 80`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s take a look at our Celery worker Dockerfile:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This time, our base image is going to be Ubuntu (in particular, a really thin
    Ubuntu version for Docker). We are going to use the **supervisor** Python package
    to monitor and launch our Celery process, so if Celery crashes for some reason,
    supervisor will restart it. So, at the OS level, we are installing the supervisor,
    Python 3, and MySQL client packages. Take a look at the `worker_entrypoint.sh` shell
    script in the preceding code block, where we are doing some interesting things:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: We are waiting for MySQL to become available. When using Docker Compose, we
    can define the order that each task (that is, each Docker container) is launched,
    but we don't have a way to know if the service is already available.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we use the Flask CLI and Alembic to create or migrate our database.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we insert test data to our database (simply because it's nice to have
    for the readers), so that when you launch the app, it's in a workable state with
    some fake post data already present.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To build and create our images, execute the following Docker commands on the
    shell in the root directory of our project:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This will create an image named **myblog **with the tag **latest**. As part
    of production best practices, you should tag your images with your project version,
    also using a **git **tag. This way, we can always be sure what code is in which
    images; for example, what changed between `myblog:1.0` and `myblog:1.1`.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, create the Celery worker image with the following command:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Now that we have our custom images created, we are ready to go to the next section,
    where we are going define our of all infrastructure and link the containers to
    each other.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Docker Compose
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Docker Compose** is a tool for defining our multi-layer application. This
    is where we define all the services needed to run our application, configure them,
    and link them together.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker Compose is based on YAML files, which is where all the definition happens,
    so let''s dive right into it and take a look at the `deploy/docker/docker-compose.yaml` file:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In Docker Compose, we have defined the following services:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '**mysql**: This is based on the Docker Hub community image for MySQL 5.7\.
    All the custom configuration happens with environment variables, as defined in
    the `prod.env` file.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rmq**: Rabbit MQ is based on the Docker Hub community image, customized by
    us to create user credentials, cookies, and VHOST. This will install the management
    interface as well, which can be accessed on `http://localhost:15672`.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**redis**: This is the Redis service for our cache.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**worker**: This uses our previously built `myblog_worker` Docker image.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**frontend**: This uses our previously built `myblog_worker` Docker image.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a very simple composer definition. Note `depends_on`, where we define
    which services depend on other services. So, for example, our frontend service
    is going to depend on the database and Rabbit MQ. The `ports` key is a list of
    exposed ports; in this case, the frontend port 80 is going to be exposed by the
    Docker host on port 80 also. This way, we can access our application on the Docker
    host IP port 80, or by using a load balancer in front of the Docker hosts. On
    your machine with Docker already installed, you can access the application on ` http://localhost`.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: The use of the `prod.env` file is important, because this way, we can define
    different configurations for different environments and still use the same compose
    file. Using the same compose file across environments obeys another Twelve-Factor
    App rule about making the infrastructure components the same across all environments.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the `prod.env` file:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This file environment variables will set actual OS-level environment variables
    so that it's simple to use them on the configuration file for our application.
    This will comply with another of the Twelve-Factor App rules from `https://12factor.net/`.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: At the top, we set our application environment for production configuration
    using `WEBAPP_ENV=Prod`.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: The `MYSQL_*` variables is where we configure the MySQL 5.7 container. We set
    the root password and an initial database to create (if necessary) a user and
    password for this database.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: It's important to note that the `REDIS_HOST` , `DB_URI`, `CELERY_BROKER_URL` variables
    are using the actual host names that each container will use to communicate with
    the other containers. By default, these are the service names, which makes everything
    pretty simple. So, the frontend container accesses the database using the `db` network
    hostname.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s start our application:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Wait for all the containers to start up, then open your browser and go to `http://localhost`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Docker containers on AWS
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To deploy on AWS, we are going to use the **Amazon Elastic Container Service**
    (**ECS**). ECS is a service that provides a scalable cluster for Docker, without
    the need to install any software to orchestrate your containers. It's based on
    **AWS Auto Scaling Groups** (**ASG**), which scale instances up or down with Docker
    installed. This scaling is triggered by monitoring metrics, such as CPU usage
    or network load. ECS also migrates all containers from an instance that, for some
    reason, terminates, or gets its service impaired. ECS thus acts as a cluster.
    After this, the ASG will spawn a new instance to replace the faulty one.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: CloudFormation Basics
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS provides many services, each of which has many configuration options. You
    also need to wire these services up. To effectively and reliably create, configure,
    update, or destroy these services, we are going to show you how to use an **IaC**
    (**Infrastructure as code**) technology from AWS, called CloudFormation. **CloudFormation**
    is not a complex technology, but follows the extension of all AWS services and
    configuration options. The details and operation of CloudFormation could be subject
    to a book on its own.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: 'CloudFormation is an extended data structure that you write using JSON or YAML.
    I say extended, because it''s possible to use references, functions, and conditions.
    A CloudFormation file is composed of the following sections:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s take a quick look at the provided CloudFormation file in `./deploy/docker/cfn_myblog.yml`.
    We are going to follow all the CloudFormation sections, one be one. First, let''s
    examine the **Parameters** section:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Without going into much detail, in this file, an input parameter is defined
    by a name, and may contain a description, a type, a default value, and rules for
    accepted values. All these values will be referenced later when configuring our
    infrastructure. These values are going to be filled when deploying or updating
    the CloudFormation stack.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, look at the **Mappings** section:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This is simply a convenient data structure for mapping AWS regions into AMIs.
    An AMI is a base OS image that we are using for our Docker VMs. Each AMI has a
    different identification in each region, so we need to map them out to make our
    stack deployable on any AWS region. On our case, we will be using Amazon ECS-optimized
    Linux.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s consider the **Metadata** section:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Here, we are declaring an `Interface` to group our parameters. This is just
    to make the parameters display in a nicer way to whomever is going to deploy the
    stack. Remember that the parameters section is a dictionary, and that dictionary
    keys have no order.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: 'The main, and more important section is **Resources**. We are not going to
    go into full detail on this, rather, we''ll just quickly highlight the main infrastructure
    resources we are going to create and how they are wired. First, for the database,
    we are going to use another AWS service, called **RDS**, and create a MySQL server:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Each resource has a type. For RDS, this is `AWS::RDS:DBInstance`. Each type
    has its own specific set of properties. Also, notice how `!Ref` declares values
    that are references from other resources or parameters. `DBUsername` and `DBPassword` are
    parameters, but `DBSubnetGroup` and `DBSecurityGroup` are resources created by
    CloudFormation to set up the network ACL and subnet placement for our database.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: 'The ECS cluster resource declaration is as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: All these definitions belong to the ECS cluster. This cluster can be used to
    provision many different applications, so it would make sense to declare these
    definitions on a separate CloudFormation file, or use nested stacks. To simplify
    the deployment, we will use a single file to create our application. First, we
    create the ECS cluster, and set its name to be a concatenation with the `Environment` and `ApplicationName` parameters. This
    is done using the `!Sub` CloudFormation function.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Next, we declare the **Auto Scaling Group** (**ASG**) for our cluster, and set
    up the way AWS is going to provision each instance that belongs to this ASG. These
    are the `ECSAutoScalingGroup` and `ECSLaunchConfiguration` resources. Finally,
    `ECSRole`, `ECSInstanceProfile`, and `ECSServiceRole` are used to set up the security
    permissions needed for the ECS cluster to fetch Docker images, work with AWS load
    balancers (ELB), S3, and so on. These permissions are the standard used by AWS
    as an example, and can be most certainly be downgraded.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, for our application, we are going to define ECS services and ECS task
    definitions. A task definition is where we define one or more container definitions
    that reference the Docker image to use, along with environment variables. Then,
    the ECS service references an ECS task definition, and may tie it up with a load
    balancer and set up deployment configuration options, such as performance limits
    and auto scaling options (yes, the ECS cluster can scale up or down on load shifts,
    but our containers may scale up or down independently as well):'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This is the task definition for our frontend containers. You may notice that
    this is the CloudFormation version of the Docker Compose service that we''ve already
    seen. We declare a name for our container, `Name: "frontend"`, that will later
    be referenced in the load balancers. Next, the image: `!Ref DockerFrontEndImageArn` is
    a reference to an input parameter. This will allow us to easily deploy new versions
    of our blog application. The port mappings for Docker are declared in `PortMappings`.
    This is a list of key values, repeating the keys for `ContainerPort` and `HostPort`.
    The environment is, once again, a list of key values, and here we make the "wiring"
    for DB, RMQ, and Redis from other resources we are creating. For example, here
    is how we use `DB_URI`:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This `Value` is where we construct the URI for the database, using our already
    known `!Sub` function and a reference for `DBUsername` and `DBPassword`. The `DB.Endpoint.Address` is
    how we can reference the DNS name that AWS created for our newly created MySQL
    server.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'In the service definition, we tie our container to an AWS Elastic Load Balancer,
    and make some deployment configuration:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'First, we declare that this service will run on our newly created ECS cluster,
    using `Cluster: !Ref ECSCluster`. Then, using the `DeploymentConfiguration` and `DesiredCount`,
    we say that this service will start with two containers (for high availability)
    and allow it to scale up and down between 4 and 1\. This obeys the following formulas:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: The maximum number of containers = DesiredCount * (MaximumPercent / 100)
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The minimum number of containers = DesiredCount * (MinimumPercent / 100)
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, applying the formulas to our case gives us the following:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 4 = 2 * (200/100)
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 = 2 * (50/100)
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With `TaskDefinition: !RefFrontEndTask`, we say that this service uses our previous
    frontend task definition. And finally, with the `LoadBalancers` key property,
    we tie our service with a load balancer. This means that our two newly created
    containers will evenly receive requests from the users, and new containers will
    automatically be registered on the load balancer as they are created, as well.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s look at the load balancer definition:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'This is an AWS classic ELB definition, where we associate the ELB with a network
    security group, which serves more or less like a firewall. This is done with the `SecurityGroups` key
    property. Next, we define in which subnets the ELB is going to serve. Each subnet
    is created in a different AWS availability zone, each of which represent a data
    center in an AWS region (each region contains two or more data centers, or availability
    zones). Then, we define that this ELB is going to be exposed to the internet using `Scheme:
    internet-facing`. For `Listeners`, we say that port 80 of the ELB is mapped to
    port 80 of the Docker host. And finally, we define a health check for the service,
    and the period for which this will occur.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Check out more details on ELB CloudFormation definitions at [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'We further create the following resources in the `./deploy/docker/cfn_myblog.yml` YAML
    file provided by CloudFormation:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Several security groups for ELBs and Docker hosts
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Task definition and the respective service for our myblog Celery workers
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Task definition and the respective service for our RabbitMQ container
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Task definition and the respective service for our Redis container
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balancer for the Redis container
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balancer for RabbitMQ
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a load balancer for RabbitMQ is a cheap way to get service discovery functionality—it's
    strange to balance load on a single instance, but if the Docker host, located
    where our RabbitMQ is, crashes for some reason, then the RabbitMQ container is
    going to be created on another Docker host, and the application needs to be able
    to find it dynamically.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Create and update a CloudFormation stack
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can create and deploy our CloudFormation stack using the console or the
    CLI. To create it using the console, choose the AWS CloudFormation service, and
    then click on the Create Stack button. You will see the following form:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/462ffb4f-b781-49f1-8851-98dfca713ea6.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
- en: 'Choose the Upload a template to Amazon S3 option, then choose the `deploy/docker/cfn_myblog.yaml`
    file from the provided code, and click Next. Now, we need to fill the stack parameters
    as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: 'Stack Name: Provide a name to identify this stack; use whatever you want.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Environment: Choose the environment of this stack for production, staging,
    and development.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ApplicationName: Here, use whatever you want to identify the ECS cluster.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'VPC: Choose an AWS VPC.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Subnets: From the drop-down menu, choose all the subnets that belong to the
    VPC (if you have public and private subnets, choose only public subnets, remember
    that the ELB''s are internet facing).'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ClusterSize: This is the ECS cluster size; leave the default setting of `2`
    here.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'InstanceType: This is the AWS instance type for the Docker hosts.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'KeyName: This is the AWS key pair, and needs to be one that we created previously.
    We can use the private key to SSH to the Docker hosts.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DockerFrontEndImageArn: This is the ARN of the ECR repository to which we uploaded
    our Docker image for the frontend.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DockerWorkerImageArn: This is the ARN of the ECR repository to which we uploaded
    our Docker image for the worker.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DBUsername, DBPassword, RMQUsername, and RMQPassword: These are all the credentials
    for the database and RabbitMQ; choose whatever values you want.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After filing all the parameters, click Next. An Options form is presented—just
    click Next again. A review page is presented with our parameters and possible
    stack changes. Here, we need to check the **I acknowledge that AWS CloudFormation
    might create IAM resources with custom names.** option, and click Create. The
    creation of all the resources is going to take a few minutes—wait for the CREATE_COMPLETED state.
    To check out our application, just go to the Output tab and click on the URL.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see how easily we can develop and deploy a code change. First,
    make a simple code change. For example, in the `webapp/templates/head.html` file,
    find the following line:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, change the preceding line to the following:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then create a new Docker image, and tag it with `v2`, as shown here:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Next, push this image to AWS ECR using the following command:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Then, go to AWS console and choose our previously created stack. On Actions,
    choose Update Stack. On the first form, choose Use current template. Then, in
    the input parameters, we need to change `DockerFrontEndImageArn`—update it with
    the new tag, and postfix it with `:v2`. The new ARN should look something like
    this: `XXXXXXXX.dkr.ecr.eu-central-1.amazonaws.com/myblog:v2`**. **Then, click
    Next, and on the Options forms click Next again. On the preview form, notice how,
    in the Preview your Changes section, the updater identifies exactly what needs
    to be updated. In this case, `FrontEndTask` and `MyBlogFrontendService` are selected
    for updates, so let's update them. While we wait for the UPDATE_COMPLETE state,
    just keep using the application—notice how no downtime occurs. After one to two
    minutes. notice how our Blog displays the main title as My Blog v2.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see how to integrate this approach with a modern
    CI/CD system to build, run tests, check code quality, and deploy on different
    environments.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Building and deploying highly available applications readily
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whether our web app is on the cloud or in a data center, we should aim for reliability.
    Reliability can impact the user is various ways, either by downtime, data loss,
    application error, response time degradation, or even on user deploy delay. Next,
    we are going to cover some aspects to help you think about architecture and reliability,
    to help you plan ahead to handle issues, such as failures or increased load. First
    of all, we will cover the necessary steps for you to deploy rapidly and, of course,
    reliably.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: Building and deploying reliably
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With today's demanding markets, we need to build and deploy easily and quickly.
    But the speed of our deployment must also deliver reliability. One of the steps
    needed to achieve this is to use automation via scripts, or with CI/CD tools.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: To help us set up the entire process, we should use a CI/CD tool, such as Jenkins,
    Bamboo, TeamCity, or Travis. First, what exactly is CI/CD?
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '**CI** stands for **Continuous Integration**, and is the process defined for
    integrating software changes, made by many developers, into a main repository—and,
    of course, doing so quickly and reliably. Let''s enumerate what we need, from
    bottom to top:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: First, it is imperative to use a source control and versioning system, such
    as Git, along with a well established and internally defined branching model,
    such as **GitFlow**. This will give us a clear view of code changes, along with
    the ability to accept and test them, at either feature or hotfix level. This will
    also make it easy to rollback to a previous version.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before approving any merges proposed by pull requests, make sure to set up automated
    triggering of tests and reviewing of code. Pull-request reviewers can then make
    more informed decisions before approving a merge. Failed tests are certainly a
    warning sign that we want to see before merging code that will end up on production.
    Fail fast, and don't be afraid to fail often.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As was said previously, we have several tools to automate this process. One
    easy way to do this is to use GitHub with Travis and landscape.io. You can freely
    create an account on all three of them and try them out. After this, just create
    the following two files on your repository.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `.travis.yml` file, which should contain the following:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: This is all we need to have automated tests running on every commit. Also, our
    tests will run independently using Python versions 3.6, 3.3, and 2.7\. GitHub
    and Travis integration will also give us the result of these tests on every pull
    request.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: For code quality control, landscape.io is very easy to use with GitHub (other
    tools include flake8, Sonarqube, and Codacy, for example).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up landscape.io, we just have to create the following `.landscape.yml` file
    at the root of our project:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Further automation can be achieved by merging every branch automatically to
    the develop branch, for example, but we need a third tool to automate this process
    on GitHub.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '**CD** stands for** Continuous Delivery**,and is based on reduced cycles of
    development and the actual delivery of changes. This must be done quickly and
    reliably, and rollback should always be accounted for. To help us define and execute
    this process, we can use **Jenkins/Blue Ocean pipelines.**'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 'Using Jenkins pipelines, we can define the entire pipeline process, from build
    to deployment. This process is defined using a `Jenkinsfile` at the root of our
    project. First, let''s create and start our Jenkins CI server from the CLI, as
    follows:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'On start, the Docker output will show the following:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Copy the password from your output and open Jenkins in your browser by going
    to `http://localhost:8080`. On startup, Jenkins will ask for a one-time password—paste
    in the password provided by the Docker output. Next, Jenkins will ask you for
    some initial configuration. This consists of creating an Admin user, and installing
    plugins (for our example, you can simply accept the suggested plugins).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: To set up an automated approach to build and deploy our Docker images to AWS
    ECR, we need an extra plugin called Amazon ECR. To install this plugin, go to Manage
    Jenkins, then choose Manage Plugins, and click on the Available Tab for a list
    of available and not-yet-installed plugins. From this list, choose the Amazon
    ECR plugin, and finally click on the Install without restart option.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we must configure a set of credentials, so that Jenkins can authenticate
    on AWS and push our newly built Docker images. For this, on the left-hand menu,
    choose Credentials, then choose Jenkins credential scope and Global credentials.
    Now, on the left-hand panel, choose Add credentials and fill the form with the
    following info:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: 'Kind: AWS Credentials'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scope: Global'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ID: ecr-credentials
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Description: ecr-credentials
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Access Key ID: Use the AWS Access Key ID that you already created in the previous
    section for pushing your Docker images'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secret Access key:  Use the AWS Secret Access Key that you already created in
    the previous section for pushing your Docker images
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For security reasons, it's better to choose the IAM role approach. However,
    for the sake of simplicity, we are using AWS keys here. If you still want to use
    AWS keys, remember to never use your personal keys on automation processes—instead,
    create a specific user for the process with contained and managed privileges.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are ready to create our first CI/CD pipeline. Follow these steps:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: On the main page, choose the Create new Jobs link
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the input box for "nter an item name, write `myblog`
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the Multibranch pipeline option. Then click Ok
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the Jobs configuration, you need to fill in the following fields:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: 'Branch Sources: Create new Jenkins'' credentials for your GitHub account, or
    set up using your own credentials from your private Git repository. Then, choose
    the GitHub repository for this book, or use your private repository URL.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, for now, remove all behaviors except "Discover branches", as shown here:'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/2fd29995-b9d8-4b05-af7d-6d2cdf3e6895.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
- en: On the "Build Configuration" job section, change the "Script Path" to `Chapter-13/Jenkinsfile` if
    you're using this book's GitHub repository. This is required because the repository
    is organised by chapters, and the `Jenkinsfile` is not at the root of the repository.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: 'This is all it takes, because the heavy lifting is done using the `Jenkinsfile`
    pipeline definition. Let''s take a look at this file:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The Jenkins pipeline definition gives you a huge amount of configuration options.
    We can even use Groovy scripts embedded in it. Please take a look at the documentation
    for more details, available at [https://jenkins.io/doc/book/pipeline/jenkinsfile/](https://jenkins.io/doc/book/pipeline/jenkinsfile/).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: On the `pipeline` main section, we have created a manual parameter for you to
    fill out the AWS ECR URL to which the images should be pushed. This section also
    configures some necessary environment variable to make our stages more dynamic.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s take a look at the pipeline stages section:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The `stages` section will hold all the stages necessary to build, test, check,
    and deploy our application. The build declared with `stage('Build')` just executes
    a checkout of our repository using `checkout scm`.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: In the *Style* stage, we will check the code style using **flake8**. We are
    assuming that a critical style problem is enough to make the pipeline fail, and
    never deploy the application. To run it, we tell Jenkins to run a Docker container
    with Python 3 by using the `docker 'python:3'` command, and inside, we install
    all the necessary dependencies and run **flake8 **against our code.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: Next you will find a *Test* stage, which very similar to the St*y*le stage.
    Notice that we can easily define tests for Python 3 and 2.7 using specific Docker
    containers to run it.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: 'The Docker build stage is as follows:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: In this stage, we use Groovy to build our images for the frontend and Celery
    workers. The images will be produced and tagged with the Jenkins build identification,
    which we can use as an `env.BUILD_ID` environment variable.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: 'In the final stage, we push the newly created images to the AWS ECR Docker
    image repository as follows:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Finally, to run our job, choose the "myblog" job, then "master," and on the
    left panel, choose "Build with parameters." Fill in your AWS ECR URL (this URL
    takes the form `http://<ACCOUNT_NUMBER>.dkr.ecr.<REGION>.amazonaws.com`), and
    then click Build. After the build is done, we just have to update our CloudFormation
    with the newly created Docker images.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: 'A great final stage would be to update the previously deployed CloudFormation,
    scripting the process with what we''ve already tested in this book, in the previous
    *Create and Update a CloudFormation Stack* section. For this, we could use the
    "pipeline: AWS steps" plugin.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Creating highly available applications that scale
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**High availability** (**HA**) and scalability is an ever more important subject.
    It should be taken into consideration from the development phase, all the way
    up to the release stage. Monolithic architectures, where all the features and
    services that comprise your application can''t be separated or are installed on
    one single instance, will not resist failure, and won''t scale either. Vertical
    scaling will only go so far, and in case of failure, will increase recovery times,
    as well as the impact on the user. This is an important and complex subject and,
    as you may have guessed, there is no single solution to solve it.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: To think about HA, we have to be pessimistic. Remember—failure can't be eliminated,
    but failure points can be identified, and recovery plans should be put in place
    so that downtime takes seconds or minutes, instead of hours or even days.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s think about all the components that our Blog application has,
    and identify the stateless ones:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '**Frontend**: Webserver and uWSGI – stateless'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Celery workers**: Celery – stateless'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message queue**: RabbitMQ or AWS SQS – state'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cache**: Redis – state'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Database**: SQL or NoSQL – state'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our first goal is to identify all the **Single Points of Failure** (**SPOF**)
    in our application, and try to eliminate them. For this, we have to think about
    redundancy:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: '**Frontend**: This is a stateless service that receives direct requests from
    the users. We can balance these requests using a load balancer, and by always
    having at least two instances. If one fails, the other immediately starts receiving
    all the load. Looks good? Maybe, but can a single instance support all the load?
    Huge response times are a failure too, so think about it—maybe you need at least
    three instances. Next, can your load balancer fail too? This is not a problem
    when using some sort of cloud-based load balancer, such as AWS ELB or ALB, but
    if you aren''t using these, then set up redundancy on this layer as well.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Celery workers**: Workers are stateless, and a complete failure does not
    have an immediate impact on users. You can have at least one instance, as long
    as recovery is done automatically, or failure can be easily identified and a failed
    instance can rapidly be replaced with a new one.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message queue**: If using AWS SQS or CloudMQ, failure is already accounted
    for. If not, a clustered RabbitMQ can be an option, or you can make sure that
    message loss is an option, and that RabbitMQ replacement is automatic, or can
    at least be rapidly executed.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cache: **Make sure you have more then one memcached instance (using cluster
    key sharding), or your application can gracefully account for failure. Remember
    that a memcached replacement comes with a cold cache, which can have a huge impact
    on the database, depending on your load.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Database**: Make sure you have an SQL or NoSQL slave/cluster in place, ready
    to replace writes from the failed master.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Layers that contain state are more problematic, and a small failure (seconds
    or milliseconds) may be inevitable. Hot standbys or cold standbys should be accounted
    for. It's very useful to test system failures of all your services while load
    testing. Redundancy is like a software feature—if not tested, it's probably broken.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: Scaling can be verified with load tests. It's a very good idea to include it
    somewhere along the way in your production pipeline release. **Locust** is an
    excellent Python tool to implement highly configurable load tests that can scale
    to any load level you want. These kinds of tests are a great opportunity to verify
    your high availability setup. Take down instances while simulating your expected
    load, and load test until you break your stack. This way you will know your limits—knowing
    what will break first *before* it breaks on production will help you test performance
    tuning.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: Locust python package documentation is available at [https://docs.locust.io/en/stable/](https://docs.locust.io/en/stable/).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Scaling using cloud infrastructure, such as AWS, Azure, and GCP, is all about
    automation. You need to set up your instances automatically, so that monitoring
    metrics can automatically trigger the creation of new VMs or Dockers containers.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Finally, please make sure you backup your database periodically. The delta time
    between backups is a point of possible data loss, so identify it and report back.
    Also, it's very important to restore your production backups—again, if not tested,
    then they're probably broken.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and collecting logs
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitor all your systems and components, collect OS level metrics, and produce
    application metrics. You have great tools for doing this, including DataDog; NewRelic;
    a combination of StatsD, Graphana, InfluxDB, and Prometheus; and ELK.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Set up alarms on failures based on metric thresholds. It's very important not
    to go overboard on the amount of alarms you create—make sure that a critical alarm
    really implies that the system is down or severely impaired. Set up time charts
    so that you can identify issues or upscale necessities early.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: Collect logs from OS, applications, and cloud services. Parsing, structuring,
    and adding metadata to your logs enriches your data, and enables proper log aggregation,
    filtering, and charting. Being able to easily filter all of your logs relative
    to a specific user, IP, or country is a step forward.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: 'Log collection has become more critical on the cloudc and even more so on containers,
    because they are short-lived and break your applications down into microservices,
    so that by the time something happens, your logs may no longer exist, or you may
    have to manually go through dozens, if not thousands, of log files to find out
    what was and is happening. This is increasingly becoming impossible to do. There
    are many good solutions out there, however: you can use ELK (ElasticSearch, logstash,
    and Kibana) or EFK (ElasticSearch, Fluentd, and Kibana) stacks, Sumo logic, or
    DataDog.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-356
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As this chapter explained, there are many different options for hosting your
    application, each with their own pros and cons. Deciding on one depends on the
    amount of time and money you are willing to spend, as well as the total number
    of users you expect.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: Now, we have reached the conclusion of the book. I hope that this book was helpful
    in building your understanding of Flask, and how it can be used to create applications
    of any degree of complexity with both ease and simple maintainability.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: Web application development is a fast paced area that touches different technologies
    and concepts. Don't stop here—keep improving your Python skills, read about UX
    design, improve your knowledge on CSS and HTML, master SQL and query performance,
    and develop a single page application using Flask and Javascript. Each chapter
    of this book is an invitation for further knowledge.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
