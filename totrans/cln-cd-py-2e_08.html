<html><head></head><body>
  <div id="_idContainer092">
    <h1 class="chapterNumber">8</h1>
    <h1 id="_idParaDest-210" class="chapterTitle">Unit Testing and Refactoring</h1>
    <p class="normal">The ideas explored in this chapter are fundamental pillars in the global context of the book because of their importance to our ultimate goal: to write better and more maintainable software.</p>
    <p class="normal">Unit tests (and any form of automatic tests, for that matter) are critical to software maintainability, and therefore something that cannot be missing from any quality project. It is for that reason that this chapter is dedicated exclusively to aspects of automated testing as a key strategy, to safely modify the code, and iterate over it, in incrementally better versions.</p>
    <p class="normal">After this chapter, we will have gained more insight into the following:</p>
    <ul>
      <li class="bullet">Why automated tests are critical for a project's success</li>
      <li class="bullet">How unit tests work as a heuristic of the quality of the code</li>
      <li class="bullet">What frameworks and tools are available to develop automated tests and set up quality gates</li>
      <li class="bullet">Taking advantage of unit tests to understand the domain problem better and document code</li>
      <li class="bullet">Concepts related to unit testing, such as test-driven development</li>
    </ul>
    <p class="normal">In the previous chapters, we have seen Python-specific traits and how we can leverage them to achieve more maintainable code. We have also explored how general design principles of software engineering can be applied to Python using its peculiarities. Here we'll also revisit an important concept of software engineering, such as automatic testing, but with the use of tools, some of them available in the standard library (such as the <code class="Code-In-Text--PACKT-">unittest </code>module), and some others that are external packages (such as <code class="Code-In-Text--PACKT-">pytest</code>). We begin this journey by exploring how software design relates to unit testing.</p>
    <h1 id="_idParaDest-211" class="title">Design principles and unit testing</h1>
    <p class="normal">In this section, we are<a id="_idIndexMarker536"/> first going to take a look at<a id="_idIndexMarker537"/> unit testing from a conceptual point of view. We will revisit some of the software engineering principles we discussed in the previous chapter to get an idea of how this is related to clean code.</p>
    <p class="normal">After that, we will discuss in more detail how to put these concepts into practice (at the code level), and what frameworks and tools we can make use of.</p>
    <p class="normal">First, we quickly define what unit testing is about. Unit tests are code in charge of validating other parts of the code. Normally, anyone would be tempted to say that unit tests validate the "core" of the application, but such a definition regards unit tests as secondary, which is not the way they are thought of in this book. Unit tests are core, and a critical component of the software and they should be treated with the same considerations as the business logic.</p>
    <p class="normal">A unit test<a id="_idIndexMarker538"/> is a piece of code that imports parts of the code with the business logic, and exercises its logic, asserting several scenarios with the idea of guaranteeing certain conditions. There are some traits that unit tests must have, such as:</p>
    <ul>
      <li class="bullet">Isolation: Unit tests should<a id="_idIndexMarker539"/> be completely independent from any other external agent, and they have to focus only on the business logic. For this reason, they do not connect to a database, they don't perform HTTP requests, and so on. Isolation also means that the tests are independent among themselves: they must be able to run in any order, without depending on any previous state.</li>
      <li class="bullet">Performance: Unit<a id="_idIndexMarker540"/> tests must run quickly. They are intended to be run multiple times, repeatedly.</li>
      <li class="bullet">Repeatability: Unit tests <a id="_idIndexMarker541"/>should be able to objectively assess the status of the software in a deterministic way. This means the results yielded by the tests should be repeatable. Unit tests assess the status of the code: if a test fails, it must keep on failing until the code is fixed. If a test passes, and no changes in the code are made, it should continue to pass. Tests shouldn't be flaky or randomized.</li>
      <li class="bullet">Self-validating: The<a id="_idIndexMarker542"/> execution of a unit test determines its result. There should be no extra step required to interpret the unit test (much less manual intervention).</li>
    </ul>
    <p class="normal">More concretely, in Python, this means that we will have new <code class="Code-In-Text--PACKT-">*.py</code> files where we are going to place our unit tests, and they are going to be called by some tool. These files will have <code class="Code-In-Text--PACKT-">import</code> statements, to take what we need from our business logic (what we intend to test), and inside this file, we program the tests themselves. Afterward, a tool will collect our unit tests and run them, giving a result.</p>
    <p class="normal">This last part is what self-validation actually means. When the tool calls our files, a Python process will be launched, and our tests will be running on it. If the tests fail, the process will have exited with an error code (in a Unix environment, this can be any number other than <code class="Code-In-Text--PACKT-">0</code>). The standard is that the tool runs the test, and prints a dot (<code class="Code-In-Text--PACKT-">.</code>) for every successful test; an <code class="Code-In-Text--PACKT-">F</code> if the test failed (the condition of the test was not satisfied), and an <code class="Code-In-Text--PACKT-">E</code> if there was an exception.</p>
    <h2 id="_idParaDest-212" class="title">A note about other forms of automated testing</h2>
    <p class="normal">Unit tests are <a id="_idIndexMarker543"/>intended to verify very small units of code, for example, a function, or a method. We want our unit tests to reach a very detailed level of granularity, testing as much code as possible. To test something bigger, such as a class, we would not want to use just unit tests, but rather a test suite, which is a collection of unit tests. Each one of them will be testing something more specific, like a method of that class.</p>
    <p class="normal">Unit tests aren't the only<a id="_idIndexMarker544"/> available mechanism of automatic testing, and we shouldn't expect them to catch all possible errors. There are also <em class="italic">acceptance </em>and <em class="italic">integration </em>tests, both beyond the scope of this book.</p>
    <p class="normal">In an integration test, we want to<a id="_idIndexMarker545"/> test multiple components at once. In this case, we want to validate if collectively, they work as expected. In this case, it is acceptable (more than that, desirable) to have side effects, and to forget about isolation, meaning that we will want to issue HTTP requests, connect to databases, and so on. While we'd want our integration tests to actually run as the production code would, there are some dependencies we would still want to avoid. For example, if your service connects to another external dependency via the Internet, then that part would indeed be omitted.</p>
    <p class="normal">Let's say you have your application that uses a database and connects to some other internal services. The application will have different configuration files for different environments, and of course, in production you'll have the configuration set for the real services. However, for an integration test, you'll want to mock the database with a Docker container that's built specifically for those tests, and this will be configured in a specific configuration file. As for the dependencies, you'll want to mock them with Docker services, whenever that's possible.</p>
    <p class="normal">Mocking as<a id="_idIndexMarker546"/> part of unit testing will be covered later on in this chapter. When it comes to mocking dependencies to <a id="_idIndexMarker547"/>perform <em class="italic">component</em> testing, this will be covered in <em class="chapterRef">Chapter 10</em>, <em class="italic">Clean Architecture</em>, when we mention components in the context of software architecture.</p>
    <p class="normal">An acceptance test<a id="_idIndexMarker548"/> is an automated form of testing that tries to validate the system from the perspective of a user, typically executing use cases.</p>
    <p class="normal">These last two forms of testing lose another nice trait compared to unit tests: speed. As you can imagine, they will take more time to run, and therefore they will be run less frequently.</p>
    <p class="normal">In a good development environment, the programmer will have the entire test suite and will run unit tests all the time, repeatedly, while making changes to the code, iterating, refactoring, and so on. Once the changes are ready, and the pull request is open, the continuous integration service will run the build for that branch, where the unit tests will run as long as the integration or acceptance tests that might exist. Needless to say, the status of the build should be successful (green) before merging, but the important part is the difference between the kinds of tests: we want to run unit tests all the time, and those tests that take longer less frequently.</p>
    <p class="normal">For this reason, we want to have a lot of small unit tests, and a few automated tests, strategically designed to cover as much as possible of where the unit tests could not reach (the use of the database, for instance).</p>
    <p class="normal">Finally, a word to the wise. Remember <a id="_idIndexMarker549"/>that this book encourages pragmatism. Besides these definitions given, and the points made about unit tests at the beginning of the section, the reader has to keep in mind that the best solution according to your criteria and context should predominate. Nobody knows your system better than you, which means if, for some reason, you have to write a unit test that needs to launch a Docker container to test against a database, go for it. As we have repeatedly remembered throughout the book, <em class="italic">practicality beats purity</em>.</p>
    <h2 id="_idParaDest-213" class="title">Unit testing and agile software development</h2>
    <p class="normal">In modern software development, we <a id="_idIndexMarker550"/>want to deliver value constantly, and as quickly as possible. The rationale behind these goals is that the earlier we get feedback, the less the impact, and the easier it will be to change. These are not new ideas at all; some of them resemble principles from decades ago, and others (such as the idea of getting feedback from<a id="_idIndexMarker551"/> stakeholders as soon as possible and iterating upon it) you can find in essays such as <strong class="keyword">The Cathedral and the Bazaar</strong> (abbreviated as <strong class="keyword">CatB</strong>).</p>
    <p class="normal">Therefore, we want to be able to respond effectively to changes, and for that, the software we write will have to change. As I mentioned in previous chapters, we want our software to be adaptable, flexible, and extensible.</p>
    <p class="normal">The code alone (regardless of how well written and designed it is) cannot guarantee us that it's flexible enough to be changed, if there's no formal proof that it will keep on running correctly after it was modified.</p>
    <p class="normal">Let's say we design a piece of software following the SOLID principles, and in one part we actually have a set of components that comply with the open/closed principle, meaning that we can easily extend them without affecting too much existing code. Assume further that the code is written in a way that favors refactoring, so we could change it as required. What's to<a id="_idIndexMarker552"/> say that when we make these changes, we aren't introducing any bugs? How do we know that existing functionality is preserved (and there are no regressions)? Would you feel confident enough releasing that to your users? Will they believe that the new version works just as expected?</p>
    <p class="normal">The answer to all of these questions is that we can't be sure unless we have a formal proof of it. And unit tests are just that: formal proof that the program works according to the specifications.</p>
    <p class="normal">Unit (or automated) tests, therefore, work as a safety net that gives us the confidence to work on our code. Armed with these tools, we can efficiently work on our code, and therefore this is what ultimately determines the velocity (or capacity) of the team working on the software product. The better the tests, the more likely it is that we can deliver value quickly without being stopped by bugs every now and then.</p>
    <h2 id="_idParaDest-214" class="title">Unit testing and software design</h2>
    <p class="normal">This is the other face of the coin<a id="_idIndexMarker553"/> when it comes to the relationship between the main code and unit testing. Besides the pragmatic reasons explored in the previous section, it comes down to the fact that good software is testable software.</p>
    <p class="normal"><strong class="keyword">Testability</strong> (the quality <a id="_idIndexMarker554"/>attribute that determines how easy to test software is) is not just nice to have, but a driver for clean code.</p>
    <p class="normal">Unit tests aren't just something complementary to the main code base, but rather something that has a direct impact and real influence on how the code is written. There are many levels of this, from the very beginning, when we realize that the moment we want to add unit tests for some parts of our code, we have to change it (resulting in a better version of it), to its ultimate expression (explored near the end of this chapter) when the entire code (the design) is driven by the way it's going to be <a id="_idIndexMarker555"/>tested via <strong class="keyword">test-driven design</strong>.</p>
    <p class="normal">Starting off with a simple example, I'll show you a small use case in which tests (and the need to test our code) lead to improvements in the way our code ends up being written.</p>
    <p class="normal">In the following example, we will simulate a process that requires sending metrics to an external system about the results obtained at each particular task (as always, details won't make any difference as long as we focus on the code). We have a <code class="Code-In-Text--PACKT-">Process</code> object that represents a task on the domain problem, and it uses a <code class="Code-In-Text--PACKT-">metrics</code> client (an external dependency and therefore something we don't control) to send the actual metrics to the external entity (this could be <a id="_idIndexMarker556"/>sending data to <code class="Code-In-Text--PACKT-">syslog</code>, or <code class="Code-In-Text--PACKT-">statsd</code>, for instance):</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">MetricsClient</span><span class="hljs-class">:</span>
    <span class="hljs-stri">"""3rd-party metrics client"""</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">send</span><span class="hljs-function">(</span><span class="hljs-params">self, metric_name, metric_value</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isinstance(metric_name, str):
            <span class="hljs-keyword">raise</span> TypeError(<span class="hljs-stri">"expected type str for metric_name"</span>)
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isinstance(metric_value, str):
            <span class="hljs-keyword">raise</span> TypeError(<span class="hljs-stri">"expected type str for metric_value"</span>)
        logger.info(<span class="hljs-stri">"sending %s = %s"</span>, metric_name, metric_value)
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">Process</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.client = MetricsClient() <span class="hljs-comment"># A 3rd-party metrics client</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">process_iterations</span><span class="hljs-function">(</span><span class="hljs-params">self, n_iterations</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n_iterations):
            result = self.run_process()
            self.client.send(<span class="hljs-stri">f"iteration.{i}"</span>, str(result))
</code></pre>
    <p class="normal">In the simulated version of the third-party client, we put the requirement that the parameters provided must be of string type. Therefore, if the <code class="Code-In-Text--PACKT-">result</code> of the <code class="Code-In-Text--PACKT-">run_process</code> method is not a string, we might expect it to fail, and indeed it does:</p>
    <pre class="programlisting code"><code class="hljs-code">Traceback (most recent call last):
...
    <span class="hljs-keyword">raise</span> TypeError(<span class="hljs-stri">"expected type str for metric_value"</span>)
TypeError: expected type str <span class="hljs-keyword">for</span> metric_value
</code></pre>
    <p class="normal">Remember that this validation is out of our hands and we cannot change the code, so we must provide the method with parameters of the correct type before proceeding. But since this is a bug we detected, we first want to write a unit test to make sure it will not happen again. We do this to prove that we fixed the issue, and to protect against this bug in the future, regardless of how many times the code is changed.</p>
    <p class="normal">It would be possible to test <a id="_idIndexMarker557"/>the code as is by mocking the client of the <code class="Code-In-Text--PACKT-">Process</code> object (we will see how to do so in the <em class="italic">Mock objects</em> section, when we explore the tools for unit testing), but doing so runs more code than is needed (notice how the part we want to test is nested in the code). Moreover, it's good that the method is relatively small, because if it weren't, the test would have to run even more undesired parts that we might also need to mock. This is another example of good design (small, cohesive functions or methods), that relates to testability.</p>
    <p class="normal">Finally, we decide not to go to much trouble and test just the part that we need to, so instead of interacting with the <code class="Code-In-Text--PACKT-">client</code> directly on the <code class="Code-In-Text--PACKT-">main</code> method, we delegate to a <code class="Code-In-Text--PACKT-">wrapper</code> method, and the new class looks like this:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">WrappedClient</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.client = MetricsClient()
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">send</span><span class="hljs-function">(</span><span class="hljs-params">self, metric_name, metric_value</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">return</span> self.client.send(str(metric_name), str(metric_value))
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">Process</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.client = WrappedClient()
    ... <span class="hljs-comment"># rest of the code remains unchanged</span>
</code></pre>
    <p class="normal">In this case, we opted for creating our own version of the <code class="Code-In-Text--PACKT-">client</code> for metrics, that is, a wrapper around the third-party library one we used to have. To do this, we place a class that (with the same interface) will make the conversion of the types accordingly.</p>
    <p class="normal">This way of using composition resembles the adapter design pattern (we'll explore design patterns in the next chapter, so, for now, it's just an informative message), and since this is a new object in our domain, it can have its respective unit tests. Having this object will make things simpler to test, but more importantly, now that we look at it, we realize that this is probably the way the code should have been written in the first place. Trying to write a unit test for our code made us realize that we were missing an important abstraction entirely!</p>
    <p class="normal">Now that we have separated<a id="_idIndexMarker558"/> the method as it should be, let's write the actual unit test for it. The details pertaining to the <code class="Code-In-Text--PACKT-">unittest</code> module used in this example will be explored in more detail in the part of the chapter where we explore testing tools and libraries, but for now, reading the code will give us a first impression on how to test it, and it will make the previous concepts a little less abstract:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> unittest
<span class="hljs-keyword">from</span> unittest.mock <span class="hljs-keyword">import</span> Mock
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">TestWrappedClient</span><span class="hljs-class">(</span><span class="hljs-params">unittest.TestCase</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_send_converts_types</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        wrapped_client = WrappedClient()
        wrapped_client.client = Mock()
        wrapped_client.send(<span class="hljs-stri">"value"</span>, <span class="hljs-number">1</span>)
        wrapped_client.client.send.assert_called_with(<span class="hljs-stri">"value"</span>, <span class="hljs-stri">"1"</span>)
</code></pre>
    <p class="normal"><code class="Code-In-Text--PACKT-">Mock</code> is a type that's available in the <code class="Code-In-Text--PACKT-">unittest.mock</code> module, which is a convenient object to ask about all sorts of things. For example, in this case, we're using it in place of the third-party library (mocked into the boundaries of the system, as commented on in the next section) to check that it's called as expected (and once again, we're not testing the library itself, only that it is called correctly). Notice how we run a call like the one in our <code class="Code-In-Text--PACKT-">Process</code> object, but we expect the parameters to be converted to strings.</p>
    <p class="normal">This is an example of how a unit test helps us in terms of the design of our code: by trying to test the code, we came up with a better version of it. We can go even further and say that this test isn't good enough, because of how the unit test is overriding an internal collaborator of the wrapper client in the second line. In an attempt to fix this, we might say that the actual client must be provided by a parameter (using dependency injection), instead of creating it in its initialization method. And once again, the unit test made us think of a better implementation.</p>
    <p class="normal">The corollary of the previous example should be that the testability of a piece of code also speaks to its quality. In other words, if the code is hard to test, or its tests are complicated, then it probably needs to be improved.</p>
    <blockquote class="packt_quote">"There are no tricks to writing tests; there are only tricks to writing testable code" <p style="text-align: right" class="cite">– Miško Hevery</p>
    </blockquote>
    <h2 id="_idParaDest-215" class="title">Defining the boundaries of what to test</h2>
    <p class="normal">Testing requires effort. And if we are not careful when deciding what to test, we will never end testing, hence wasting a lot of effort without achieving much.</p>
    <p class="normal">We should scope the testing to the <a id="_idIndexMarker559"/>boundaries of our code. If we don't, we would have to also test the dependencies (external/third-party libraries or modules) in our code, and then their respective dependencies, and so on in a never-ending journey. It's not our responsibility to test dependencies, so we can assume that these projects have tests of their own. It would be enough just to test that the correct calls to external dependencies are done with the correct parameters (and that might even be an acceptable use of patching), but we shouldn't put more effort in than that.</p>
    <p class="normal">This is another instance where good software design pays off. If we have been careful in our design, and clearly defined the boundaries of our system (that is, we designed toward interfaces, instead of concrete implementations that will change, hence inverting the dependencies over external components to reduce temporal coupling), then it will be much easier to mock these interfaces when writing unit tests.</p>
    <p class="normal">In good unit testing, we want to patch on the boundaries of our system and focus on the core functionality to be exercised. We don't test external libraries (third-party tools installed via <code class="Code-In-Text--PACKT-">pip</code>, for instance), but instead, we check that they are called correctly. When we explore <code class="Code-In-Text--PACKT-">mock</code> objects later on in this chapter, we will review techniques and tools for performing these types of assertion.</p>
    <h1 id="_idParaDest-216" class="title">Tools for testing</h1>
    <p class="normal">There are a lot of<a id="_idIndexMarker560"/> tools we can use for writing our unit tests, all of them with pros and cons and serving different purposes. I'll present the two most common libraries used for unit testing in Python. They cover most (if not all) use cases, and they're very popular, so knowing how to use them comes in handy.</p>
    <p class="normal">Along with testing frameworks and test running libraries, it's often common to find projects that configure code coverage, which they use as quality metrics. Since coverage (when used as a metric) is misleading, after seeing how to create unit tests, we'll discuss why it's not to be taken lightly.</p>
    <p class="normal">The next section starts by introducing the main libraries we're going to use in this chapter for unit testing.</p>
    <h2 id="_idParaDest-217" class="title">Frameworks and libraries for unit testing</h2>
    <p class="normal">In this section, we will discuss two frameworks for writing and running unit tests. The first one, <code class="Code-In-Text--PACKT-">unittest</code>, is <a id="_idIndexMarker561"/>available in the standard library of Python, while the second one, <code class="Code-In-Text--PACKT-">pytest</code>, has to<a id="_idIndexMarker562"/> be installed externally via <code class="Code-In-Text--PACKT-">pip</code>:</p>
    <ul>
      <li class="bullet"><code class="Code-In-Text--PACKT-">unittest</code>: <a href="https://docs.python.org/3/library/unittest.html"><span class="url">https://docs.python.org/3/library/unittest.html</span></a></li>
      <li class="bullet"><code class="Code-In-Text--PACKT-">pytest</code>: <a href="https://docs.pytest.org/en/latest/"><span class="url">https://docs.pytest.org/en/latest/</span></a></li>
    </ul>
    <p class="normal">When it comes to covering testing scenarios for our code, <code class="Code-In-Text--PACKT-">unittest</code> alone will most likely suffice, since it has plenty of helpers. However, for more complex systems on which we have multiple dependencies, connections to external systems, and probably the need to patch objects, define fixtures, and parameterize test cases, then <code class="Code-In-Text--PACKT-">pytest</code> looks like a more complete option.</p>
    <p class="normal">We will use a small program as an example to show you how it could be tested using both options, which, in the end, will help us to get a better picture of how the two of them compare.</p>
    <p class="normal">The example demonstrating testing tools is a simplified version of a version control tool that supports code reviews in merge requests. We will start with the following criteria:</p>
    <ul>
      <li class="bullet">A merge request is <code class="Code-In-Text--PACKT-">rejected</code> if at least one person disagrees with the changes.</li>
      <li class="bullet">If nobody has disagreed, and the merge request is good for at least two other developers, it's <code class="Code-In-Text--PACKT-">approved</code>.</li>
      <li class="bullet">In any other case, its status is <code class="Code-In-Text--PACKT-">pending</code>.</li>
    </ul>
    <p class="normal">And here is what the code might look like:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> enum <span class="hljs-keyword">import</span> Enum
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">MergeRequestStatus</span><span class="hljs-class">(</span><span class="hljs-params">Enum</span><span class="hljs-class">):</span>
    APPROVED = <span class="hljs-stri">"approved"</span>
    REJECTED = <span class="hljs-stri">"rejected"</span>
    PENDING = <span class="hljs-stri">"pending"</span>
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">MergeRequest</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self._context = {
            <span class="hljs-stri">"upvotes"</span>: set(),
            <span class="hljs-stri">"downvotes"</span>: set(),
        }
<span class="hljs-meta">    @property</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">status</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">if</span> self._context[<span class="hljs-stri">"downvotes"</span>]:
            <span class="hljs-keyword">return</span> MergeRequestStatus.REJECTED
        <span class="hljs-keyword">elif</span> len(self._context[<span class="hljs-stri">"upvotes"</span>]) &gt;= <span class="hljs-number">2</span>:
            <span class="hljs-keyword">return</span> MergeRequestStatus.APPROVED
        <span class="hljs-keyword">return</span> MergeRequestStatus.PENDING
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">upvote</span><span class="hljs-function">(</span><span class="hljs-params">self, by_user</span><span class="hljs-function">):</span>
        self._context[<span class="hljs-stri">"downvotes"</span>].discard(by_user)
        self._context[<span class="hljs-stri">"upvotes"</span>].add(by_user)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">downvote</span><span class="hljs-function">(</span><span class="hljs-params">self, by_user</span><span class="hljs-function">):</span>
        self._context[<span class="hljs-stri">"upvotes"</span>].discard(by_user)
        self._context[<span class="hljs-stri">"downvotes"</span>].add(by_user)
</code></pre>
    <p class="normal">Using this code as a base, let's see how it can be unit tested using both of the libraries presented in this chapter. The idea is not only to learn about how to use each library, but also to identify some differences.</p>
    <h3 id="_idParaDest-218" class="title">unittest</h3>
    <p class="normal">The <code class="Code-In-Text--PACKT-">unittest</code> module <a id="_idIndexMarker563"/>is a great option with which to start writing unit tests because it provides a rich API to write all kinds of testing conditions, and since it's available in the standard library, it's quite versatile and convenient.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">unittest</code> module is based on the concepts of JUnit (from Java), which, in turn, is also based on the original ideas of unit testing that come from Smalltalk (perhaps this is the reason behind the naming convention of the methods on this module), so it's object-oriented in nature. For this reason, tests are written through classes, where the checks are verified by methods, and it's common to group tests by scenarios in classes.</p>
    <p class="normal">To start writing unit tests, we have to create a test class that inherits from <code class="Code-In-Text--PACKT-">unittest.TestCase</code>, and define the conditions we want to stress on its methods. These methods should start with <code class="Code-In-Text--PACKT-">test_*</code>, and can internally use any of the methods inherited from <code class="Code-In-Text--PACKT-">unittest.TestCase</code> to check conditions that must hold true.</p>
    <p class="normal">Some examples of conditions we might want to verify for our case are as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">TestMergeRequestStatus</span><span class="hljs-class">(</span><span class="hljs-params">unittest.TestCase</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_simple_rejected</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        merge_request = MergeRequest()
        merge_request.downvote(<span class="hljs-stri">"maintainer"</span>)
        self.assertEqual(merge_request.status, MergeRequestStatus.REJECTED)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_just_created_is_pending</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.assertEqual(MergeRequest().status, MergeRequestStatus.PENDING)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_pending_awaiting_review</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        merge_request = MergeRequest()
        merge_request.upvote(<span class="hljs-stri">"core-dev"</span>)
        self.assertEqual(merge_request.status, MergeRequestStatus.PENDING)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_approved</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        merge_request = MergeRequest()
        merge_request.upvote(<span class="hljs-stri">"dev1"</span>)
        merge_request.upvote(<span class="hljs-stri">"dev2"</span>)
        self.assertEqual(merge_request.status, MergeRequestStatus.APPROVED)
</code></pre>
    <p class="normal">The API for unit <a id="_idIndexMarker564"/>testing provides many useful methods for comparison, the most common one being <code class="Code-In-Text--PACKT-">assertEqual(&lt;actual&gt;, &lt;expected&gt;[, message])</code>, which can be used to compare the result of the operation against the value we were expecting, optionally using a message that will be shown in the case of an error.</p>
    <p class="normal">I named the parameters using the order (<code class="Code-In-Text--PACKT-">&lt;actual&gt;, &lt;expected&gt;</code>), because that's the order I've found most of the times in my experience. Even though I believe this is the most common form (as a convention) to use in Python, there are no recommendations or guidelines regarding this. In fact, some projects (such as gRPC) use the inverse form (<code class="Code-In-Text--PACKT-">&lt;expected&gt;,</code> <code class="Code-In-Text--PACKT-">&lt;actual&gt;</code>), and this is actually a convention in other languages (for example, Java and Kotlin). The key is to be consistent and respect the form that's already been used in your project.</p>
    <p class="normal">Another useful testing method allows us to check whether a certain exception was raised or not (<code class="Code-In-Text--PACKT-">assertRaises</code>). </p>
    <p class="normal">When something exceptional happens, we raise an exception in our code to prevent further processing under the wrong assumptions, and also to inform the caller that something is wrong with the call as it was performed. This is the part of the logic that ought to be tested, and that's what this method is for.</p>
    <p class="normal">Imagine that we are now extending our logic a little bit further to allow users to close their merge requests, and once this happens, we don't want any more votes to take place (it wouldn't make sense to evaluate a merge request once this was already closed). To prevent this from happening, we extend our code, and we raise an exception on the unfortunate event that someone tries to cast a vote on a closed merge request.</p>
    <p class="normal">After adding two <a id="_idIndexMarker565"/>new statuses (<code class="Code-In-Text--PACKT-">OPEN</code> and <code class="Code-In-Text--PACKT-">CLOSED</code>), and a new <code class="Code-In-Text--PACKT-">close()</code> method, we modify the previous methods for the voting to handle this check first:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">MergeRequest</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self._context = {
            <span class="hljs-stri">"upvotes"</span>: set(),
            <span class="hljs-stri">"downvotes"</span>: set(),
        }
        self._status = MergeRequestStatus.OPEN
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">close</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self._status = MergeRequestStatus.CLOSED
    ...
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">_cannot_vote_if_closed</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">if</span> self._status == MergeRequestStatus.CLOSED:
            <span class="hljs-keyword">raise</span> MergeRequestException(
                <span class="hljs-stri">"can't vote on a closed merge request"</span>
            )
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">upvote</span><span class="hljs-function">(</span><span class="hljs-params">self, by_user</span><span class="hljs-function">):</span>
        self._cannot_vote_if_closed()
        self._context[<span class="hljs-stri">"downvotes"</span>].discard(by_user)
        self._context[<span class="hljs-stri">"upvotes"</span>].add(by_user)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">downvote</span><span class="hljs-function">(</span><span class="hljs-params">self, by_user</span><span class="hljs-function">):</span>
        self._cannot_vote_if_closed()
        self._context[<span class="hljs-stri">"upvotes"</span>].discard(by_user)
        self._context[<span class="hljs-stri">"downvotes"</span>].add(by_user)
</code></pre>
    <p class="normal">Now, we want to check that this validation indeed works. For this, we're going to use the <code class="Code-In-Text--PACKT-">asssertRaises</code> and <code class="Code-In-Text--PACKT-">assertRaisesRegex</code> methods:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_cannot_upvote_on_closed_merge_request</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.merge_request.close()
        self.assertRaises(
            MergeRequestException, self.merge_request.upvote, <span class="hljs-stri">"dev1"</span>
        )
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_cannot_downvote_on_closed_merge_request</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.merge_request.close()
        self.assertRaisesRegex(
            MergeRequestException,
            <span class="hljs-stri">"can't vote on a closed merge request"</span>,
            self.merge_request.downvote,
            <span class="hljs-stri">"dev1"</span>,
        )
</code></pre>
    <p class="normal">The former will expect that the<a id="_idIndexMarker566"/> exception provided is raised when calling the callable in the second argument, with the arguments (<code class="Code-In-Text--PACKT-">*args</code> and <code class="Code-In-Text--PACKT-">**kwargs</code>) on the rest of the function, and if that's not the case it will fail, saying that the exception that was expected to be raised wasn't. The latter does the same, but it also checks that the exception that was raised contains the message matching the regular expression that was provided as a parameter. Even if the exception is raised, but with a different message (not matching the regular expression), the test will fail.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Try to check for the error message, as not only will the exception, as an extra check, be more accurate and ensure that it is actually the exception we want that is being triggered, it will check whether another one of the same types got there by chance.</p>
    </div>
    <p class="normal">Note how these methods can be used as context managers as well. In its first form (the one used in previous examples), the method takes the exception, then the callable, and finally the list of arguments to use in that callable). But we could also pass the exception as a parameter of the method, use it as a context manager, and evaluate our code inside the block of that context manager, in this format:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">with</span> self.assertRaises(MyException):
   test_logic()
</code></pre>
    <p class="normal">This second form is generally more useful (and sometimes, the only option); for example, if the logic we need to test can't be expressed as a single callable.</p>
    <p class="normal">In some cases, you'll notice that we need to run the same test case, but with different data. Instead of repeating, and generating duplicated tests, we can build a single one and exercise its condition with different values. This is<a id="_idIndexMarker567"/> called <strong class="keyword">parameterized tests</strong>, and we'll start exploring these in the next section. Later on, we'll revisit parameterized tests with <code class="Code-In-Text--PACKT-">pytest</code>.</p>
    <h4 class="title">Parameterized tests</h4>
    <p class="normal">Now, we would like to test how <a id="_idIndexMarker568"/>the threshold acceptance for the merge request works, just by providing data samples of what the <code class="Code-In-Text--PACKT-">context</code> looks like without needing the entire <code class="Code-In-Text--PACKT-">MergeRequest</code> object. We want to test the part of the <code class="Code-In-Text--PACKT-">status</code> property that is after the line that checks whether it's closed, but independently.</p>
    <p class="normal">The best way to achieve this is to separate that component into another class, use composition, and then move on to test this new abstraction with its own test suite:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">AcceptanceThreshold</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, merge_request_context: dict</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        self._context = merge_request_context
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">status</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">if</span> self._context[<span class="hljs-stri">"downvotes"</span>]:
            <span class="hljs-keyword">return</span> MergeRequestStatus.REJECTED
        <span class="hljs-keyword">elif</span> len(self._context[<span class="hljs-stri">"upvotes"</span>]) &gt;= <span class="hljs-number">2</span>:
            <span class="hljs-keyword">return</span> MergeRequestStatus.APPROVED
        <span class="hljs-keyword">return</span> MergeRequestStatus.PENDING
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">MergeRequest</span><span class="hljs-class">:</span>
    ...
<span class="hljs-meta">    @property</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">status</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">if</span> self._status == MergeRequestStatus.CLOSED:
            <span class="hljs-keyword">return</span> self._status
        return AcceptanceThreshold(self._context).status()
</code></pre>
    <p class="normal">With these changes, we can run the tests again and verify that they pass, meaning that this small refactor didn't break anything of the current functionality (unit tests ensure regression). With this, we can proceed with our goal to write tests that are specific to the new class:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">TestAcceptanceThreshold</span><span class="hljs-class">(</span><span class="hljs-params">unittest.TestCase</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">setUp</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.fixture_data = (
            (
                {<span class="hljs-stri">"downvotes"</span>: set(), <span class="hljs-stri">"upvotes"</span>: set()},
                MergeRequestStatus.PENDING
            ),
            (
                {<span class="hljs-stri">"downvotes"</span>: set(), <span class="hljs-stri">"upvotes"</span>: {<span class="hljs-stri">"dev1"</span>}},
                MergeRequestStatus.PENDING,
            ),
            (
                {<span class="hljs-stri">"downvotes"</span>: <span class="hljs-stri">"dev1"</span>, <span class="hljs-stri">"upvotes"</span>: set()},
                MergeRequestStatus.REJECTED,
            ),
            (
                {<span class="hljs-stri">"downvotes"</span>: set(), <span class="hljs-stri">"upvotes"</span>: {<span class="hljs-stri">"dev1"</span>, <span class="hljs-stri">"dev2"</span>}},
                MergeRequestStatus.APPROVED,
            ),
        )
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_status_resolution</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">for</span> context, expected <span class="hljs-keyword">in</span> self.fixture_data:
            <span class="hljs-keyword">with</span> self.subTest(context=context):
                status = AcceptanceThreshold(context).status()
                self.assertEqual(status, expected)
</code></pre>
    <p class="normal">Here, in the <code class="Code-In-Text--PACKT-">setUp()</code> method, we <a id="_idIndexMarker569"/>define the data fixture to be used throughout the tests. In this case, it's not actually needed, because we could have put it directly on the method, but if we expect to run some code before any test is executed, this is the place to write it, because this method is called once before every test is run.</p>
    <p class="normal">In this particular case, we could have defined this tuple as a class attribute, because it's a constant (static) value. If we needed to run some code, and perform some computation (such as building objects or using a factory), then the <code class="Code-In-Text--PACKT-">setUp()</code> method is our only alternative.</p>
    <p class="normal">By writing this new version of the code, the parameters under the code being tested are clearer and more compact. </p>
    <p class="normal">To simulate that we're running all of the parameters, the test iterates over all the data, and exercises the code with each instance. One interesting helper here is the use of <code class="Code-In-Text--PACKT-">subTest</code>, which in this case we use to mark the test condition being called. If one of these iterations failed, <code class="Code-In-Text--PACKT-">unittest</code> would report it with the corresponding value of the variables that were passed to the <code class="Code-In-Text--PACKT-">subTest</code> (in this case, it was named <code class="Code-In-Text--PACKT-">context</code>, but any series of keyword arguments would work just the same). For example, one error occurrence might look like this:</p>
    <pre class="programlisting code"><code class="hljs-code">FAIL: (context={<span class="hljs-stri">'downvotes'</span>: set(), <span class="hljs-stri">'upvotes'</span>: {<span class="hljs-stri">'dev1'</span>, <span class="hljs-stri">'dev2'</span>}})
----------------------------------------------------------------------
Traceback (most recent call last):
  File <span class="hljs-stri">""</span> test_status_resolution
    self.assertEqual(status, expected)
AssertionError: &lt;MergeRequestStatus.APPROVED: <span class="hljs-stri">'approved'</span>&gt; != &lt;MergeRequestStatus.REJECTED: <span class="hljs-stri">'rejected'</span>&gt;
</code></pre>
    <div class="note">
      <p class="Information-Box--PACKT-">If you choose to parameterize tests, try to provide the context of each instance of the parameters with as much information as possible to make debugging easier.</p>
    </div>
    <p class="normal">The idea behind <a id="_idIndexMarker570"/>parameterized tests is to run the same test condition over different sets of data. The idea is that you first identify the equivalence classes of the data to test upon, and then you pick the value's representative of each class (more details on this later in the chapter). Then you'd like to know for which equivalence class your test failed, and the context provided by the <code class="Code-In-Text--PACKT-">subTest</code> context manager is helpful in this case.</p>
    <h3 id="_idParaDest-219" class="title">pytest</h3>
    <p class="normal">Pytest is a great testing <a id="_idIndexMarker571"/>framework and can be installed via <code class="Code-In-Text--PACKT-">pip install pytest</code>. One difference with respect to <code class="Code-In-Text--PACKT-">unittest</code> is that, while it's still possible to classify test scenarios in classes and create object-oriented models of our tests, this is not actually mandatory, and it's possible to write unit tests with less boilerplate by just checking the conditions we want to verify in simple functions with the <code class="Code-In-Text--PACKT-">assert</code> statement.</p>
    <p class="normal">By default, making comparisons with an <code class="Code-In-Text--PACKT-">assert</code> statement will be enough for <code class="Code-In-Text--PACKT-">pytest</code> to identify a unit test and report its result accordingly. More advanced uses, such as those seen in the previous section, are also possible, but they require the use of specific functions from the package.</p>
    <p class="normal">A nice feature is that the <code class="Code-In-Text--PACKT-">pytests</code> command will run all the tests that it can discover, even if they were written with <code class="Code-In-Text--PACKT-">unittest</code>. This compatibility makes it easier to transition from <code class="Code-In-Text--PACKT-">unittest</code> to <code class="Code-In-Text--PACKT-">pytest</code> gradually.</p>
    <h4 class="title">Basic test cases with pytest</h4>
    <p class="normal">The conditions we<a id="_idIndexMarker572"/> tested in the previous section can be rewritten in simple functions with <code class="Code-In-Text--PACKT-">pytest</code>.</p>
    <p class="normal">Some examples with simple assertions are as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_simple_rejected</span><span class="hljs-function">():</span>
    merge_request = MergeRequest()
    merge_request.downvote(<span class="hljs-stri">"maintainer"</span>)
    <span class="hljs-keyword">assert</span> merge_request.status == MergeRequestStatus.REJECTED
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_just_created_is_pending</span><span class="hljs-function">():</span>
    <span class="hljs-keyword">assert</span> MergeRequest().status == MergeRequestStatus.PENDING
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_pending_awaiting_review</span><span class="hljs-function">():</span>
    merge_request = MergeRequest()
    merge_request.upvote(<span class="hljs-stri">"core-dev"</span>)
    <span class="hljs-keyword">assert</span> merge_request.status == MergeRequestStatus.PENDING
</code></pre>
    <p class="normal">Boolean equality comparisons don't require more than a simple <code class="Code-In-Text--PACKT-">assert</code> statement, whereas other kinds of checks, such as the ones for the exceptions, do require that we use some functions:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_invalid_types</span><span class="hljs-function">():</span>
    merge_request = MergeRequest()
    pytest.raises(TypeError, merge_request.upvote, {<span class="hljs-stri">"invalid-object"</span>})
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_cannot_vote_on_closed_merge_request</span><span class="hljs-function">():</span>
    merge_request = MergeRequest()
    merge_request.close()
    pytest.raises(MergeRequestException, merge_request.upvote, <span class="hljs-stri">"dev1"</span>)
    <span class="hljs-keyword">with</span> pytest.raises(
        MergeRequestException,
        match=<span class="hljs-stri">"can't vote on a closed merge request"</span>,
    ):
        merge_request.downvote(<span class="hljs-stri">"dev1"</span>)
</code></pre>
    <p class="normal">In this case, <code class="Code-In-Text--PACKT-">pytest.raises</code> is the equivalent of <code class="Code-In-Text--PACKT-">unittest.TestCase.assertRaises</code>, and it also accepts that it be called both as a method and as a context manager. If we want to check the message of the exception, instead of a different method (such as <code class="Code-In-Text--PACKT-">assertRaisesRegex</code>), the same function has to be used, but as a context manager, and by providing the <code class="Code-In-Text--PACKT-">match</code> parameter with the expression we would like to identify.</p>
    <p class="normal"><code class="Code-In-Text--PACKT-">pytest</code> will also wrap the<a id="_idIndexMarker573"/> original exception into a custom one that can be expected (by checking some of its attributes, such as <code class="Code-In-Text--PACKT-">.value</code>, for instance) in case we want to check for more conditions, but this use of the function covers the vast majority of cases.</p>
    <h4 class="title">Parameterized tests</h4>
    <p class="normal">Running parameterized<a id="_idIndexMarker574"/> tests with <code class="Code-In-Text--PACKT-">pytest</code> is better, not only because it provides a cleaner API, but also because each combination of the test with its parameters generates a new test case (a new function).</p>
    <p class="normal">To work with this, we have to use the <code class="Code-In-Text--PACKT-">pytest.mark.parametrize</code> decorator on our test. The first parameter of the decorator is a string indicating the names of the parameters to pass to the <code class="Code-In-Text--PACKT-">test</code> function, and the second has to be iterable with the respective values for those parameters.</p>
    <p class="normal">Notice how the body of the testing function is reduced to one line (after removing the internal <code class="Code-In-Text--PACKT-">for</code> loop, and its nested context manager), and the data for each test case is correctly isolated from the body of the function, making it easier to extend and maintain:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.mark.parametrize("context,expected_status", (</span>
    (
        {<span class="hljs-stri">"downvotes"</span>: set(), <span class="hljs-stri">"upvotes"</span>: set()},
        MergeRequestStatus.PENDING
    ),
    (
        {<span class="hljs-stri">"downvotes"</span>: set(), <span class="hljs-stri">"upvotes"</span>: {<span class="hljs-stri">"dev1"</span>}},
        MergeRequestStatus.PENDING,
    ),
    (
        {<span class="hljs-stri">"downvotes"</span>: <span class="hljs-stri">"dev1"</span>, <span class="hljs-stri">"upvotes"</span>: set()},
        MergeRequestStatus.REJECTED,
    ),
    (
        {<span class="hljs-stri">"downvotes"</span>: set(), <span class="hljs-stri">"upvotes"</span>: {<span class="hljs-stri">"dev1"</span>, <span class="hljs-stri">"dev2"</span>}},
        MergeRequestStatus.APPROVED,
    ),
),)
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_acceptance_threshold_status_resolution</span><span class="hljs-function">(</span><span class="hljs-params">context, expected_status</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">assert</span> AcceptanceThreshold(context).status() == expected_status
</code></pre>
    <div class="note">
      <p class="Information-Box--PACKT-">Use <code class="Code-In-Text--PACKT-">@pytest.mark.parametrize</code> to eliminate repetition, keep the body of the test as cohesive as possible, and make the parameters (test inputs or scenarios) that the code must support explicitly.</p>
    </div>
    <p class="normal">An important <a id="_idIndexMarker575"/>recommendation when using parametrization is that each parameter (every iteration) should correspond to only one testing scenario. That means you should not mix different test conditions into the same parameter. If you need to test for the combination of different parameters, then use different parameterizations stacked up. Stacking up this decorator will create as many test conditions as the cartesian product of all the values in the decorators.</p>
    <p class="normal">For example, a test configured like this:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.mark.parametrize("x", (1, 2))</span>
<span class="hljs-meta">@pytest.mark.parametrize("y", ("a", "b"))</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">my_test</span><span class="hljs-function">(</span><span class="hljs-params">x, y</span><span class="hljs-function">):</span>
   …
</code></pre>
    <p class="normal">Will run for the values <code class="Code-In-Text--PACKT-">(x=1, y=a)</code>,<code class="Code-In-Text--PACKT-"> (x=1, y=b)</code>, <code class="Code-In-Text--PACKT-">(x=2, y=a)</code>, and <code class="Code-In-Text--PACKT-">(x=2, y=b)</code>.</p>
    <p class="normal">This is a better approach as each test is smaller, and each parametrization more specific (cohesive). It will allow you to stress the code with the explosion of all the possible combinations in an easier way.</p>
    <p class="normal">Data parameters work well when you have the data you need to test, or you know how to build it easily, but in some cases, you need specific objects to be constructed for a test, or you find yourself writing or building the same objects repeatedly. To help with this, we can use fixtures, as we will see in the next section.</p>
    <h4 class="title">Fixtures</h4>
    <p class="normal">One of the great things <a id="_idIndexMarker576"/>about <code class="Code-In-Text--PACKT-">pytest</code> is how it facilitates creating reusable features so that we can feed our tests with data or objects to test more effectively and without repetition.</p>
    <p class="normal">For example, we might want to create a <code class="Code-In-Text--PACKT-">MergeRequest</code> object in a particular state and use that object in multiple tests. We define our object as a fixture by creating a function and applying the <code class="Code-In-Text--PACKT-">@pytest.fixture</code> decorator. The tests that want to use that fixture will have to have a parameter with the same name as the function that's defined, and <code class="Code-In-Text--PACKT-">pytest</code> will make sure that it's provided:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">rejected_mr</span><span class="hljs-function">():</span>
    merge_request = MergeRequest()
    merge_request.downvote(<span class="hljs-stri">"dev1"</span>)
    merge_request.upvote(<span class="hljs-stri">"dev2"</span>)
    merge_request.upvote(<span class="hljs-stri">"dev3"</span>)
    merge_request.downvote(<span class="hljs-stri">"dev4"</span>)
    <span class="hljs-keyword">return</span> merge_request
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_simple_rejected</span><span class="hljs-function">(</span><span class="hljs-params">rejected_mr</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">assert</span> rejected_mr.status == MergeRequestStatus.REJECTED
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_rejected_with_approvals</span><span class="hljs-function">(</span><span class="hljs-params">rejected_mr</span><span class="hljs-function">):</span>
    rejected_mr.upvote(<span class="hljs-stri">"dev2"</span>)
    rejected_mr.upvote(<span class="hljs-stri">"dev3"</span>)
    <span class="hljs-keyword">assert</span> rejected_mr.status == MergeRequestStatus.REJECTED
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_rejected_to_pending</span><span class="hljs-function">(</span><span class="hljs-params">rejected_mr</span><span class="hljs-function">):</span>
    rejected_mr.upvote(<span class="hljs-stri">"dev1"</span>)
    <span class="hljs-keyword">assert</span> rejected_mr.status == MergeRequestStatus.PENDING
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_rejected_to_approved</span><span class="hljs-function">(</span><span class="hljs-params">rejected_mr</span><span class="hljs-function">):</span>
    rejected_mr.upvote(<span class="hljs-stri">"dev1"</span>)
    rejected_mr.upvote(<span class="hljs-stri">"dev2"</span>)
    <span class="hljs-keyword">assert</span> rejected_mr.status == MergeRequestStatus.APPROVED
</code></pre>
    <p class="normal">Remember that tests affect the main code as well, so the principles of clean code apply to them as well. In this case, the <strong class="keyword">Don't Repeat Yourself</strong> (<strong class="keyword">DRY</strong>) principle that <a id="_idIndexMarker577"/>we explored in previous chapters appears once again, and we can achieve it with the help of <code class="Code-In-Text--PACKT-">pytest</code> fixtures.</p>
    <p class="normal">Besides creating multiple objects or exposing data that will be used throughout the test suite, it's also possible to use them to set up some conditions, for example, to globally patch some functions that we don't want to be called, or when we want patch objects to be used instead.</p>
    <h3 id="_idParaDest-220" class="title">Code coverage</h3>
    <p class="normal">Tests runners support <a id="_idIndexMarker578"/>coverage plugins (to be installed via <code class="Code-In-Text--PACKT-">pip</code>) that provide useful information about what lines in the code have been executed as tests ran. This information is of great help so that we know which parts of the code need to be covered by tests, as well identifying improvements to be made (both in the production code and in the tests). What I mean by this is that detecting lines of our production code that are uncovered will force us to write a test for that part of the code (because remember that code that doesn't have tests should be considered broken). In that attempt of covering the code, several things can happen:</p>
    <ul>
      <li class="bullet">We might realize we were missing a test scenario completely.</li>
      <li class="bullet">We'll try to come up with more unit tests or unit tests that cover more lines of code.</li>
      <li class="bullet">We'll try to simplify our production code, removing redundancies, and making it more compact, meaning it's easier to be covered.</li>
      <li class="bullet">We might even realize that the lines of code we're trying to cover are unreachable (perhaps there was a mistake in the logic) and can be safely removed.</li>
    </ul>
    <p class="normal">Keep in mind that even though these are positive points, coverage should never be a target, only a metric. This means trying to achieve a high coverage, just to reach 100%, won't be productive or effective. We should understand code coverage as a unit to identify obvious parts of the code that need testing and see how we can improve that. We can, however, set a minimum threshold of say 80% (a generally accepted value) as the minimum level of desired coverage to know that the project has a reasonable number of tests.</p>
    <p class="normal">Moreover, thinking that a high degree of code coverage is a sign of a healthy code base is also dangerous: keep in mind that most of the coverage tools will report on production lines of code that have been executed. That a line has been called doesn't mean that it has been properly tested (only that it ran). A single statement might encapsulate multiple logical conditions, each of which needs to be tested separately.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Don't be misguided by a high degree of code coverage, and keep thinking about ways for testing the code, including those lines that are already covered. </p>
    </div>
    <p class="normal">One of the most widely used libraries for <a id="_idIndexMarker579"/>this is <code class="Code-In-Text--PACKT-">coverage</code> (<a href="https://pypi.org/project/coverage/"><span class="url">https://pypi.org/project/coverage/</span></a>). We'll explore how to set up this tool in the next section.</p>
    <h4 class="title">Setting up rest coverage</h4>
    <p class="normal">In the case of <code class="Code-In-Text--PACKT-">pytest</code>, we can install <a id="_idIndexMarker580"/>the <code class="Code-In-Text--PACKT-">pytest-cov</code> package. Once installed, when the tests are run, we have to tell the <code class="Code-In-Text--PACKT-">pytest</code> runner that <code class="Code-In-Text--PACKT-">pytest-cov</code> will also run, and which package (or packages) should be<a id="_idIndexMarker581"/> covered (among other parameters and configurations).</p>
    <p class="normal">This package supports multiple configurations, including different sorts of output formats, and it's easy to integrate it with any CI tool, but among all these features, a highly recommended option is to set the flag that will tell us which lines haven't been covered by tests yet, because this is what's going to help us diagnose our code and allow us to start writing more tests.</p>
    <p class="normal">To show you an example of what this would look like, use the following command:</p>
    <pre class="programlisting code"><code class="hljs-code">PYTHONPATH=src pytest \
    --cov-report term-missing \
    --cov=coverage_1 \
    tests/test_coverage_1.py
</code></pre>
    <p class="normal">This will produce an output similar to the following:</p>
    <pre class="programlisting code"><code class="hljs-code">test_coverage_1.py ................ [<span class="hljs-number">100</span>%]
----------- coverage: platform linux, python <span class="hljs-number">3.6.5</span>-final<span class="hljs-number">-0</span> -----------
Name         Stmts Miss Cover Missing
---------------------------------------------
coverage_1.py <span class="hljs-number">39</span>      <span class="hljs-number">1</span>  <span class="hljs-number">97</span>%    <span class="hljs-number">44</span>
</code></pre>
    <p class="normal">Here, it's telling us that there is a line that doesn't have unit tests so that we can take a look and see how to write a unit test for it. This is a common scenario where we realize that to cover those missing lines, we need to refactor the code by creating smaller methods. As a result, our code will look much better, as in the example we saw at the beginning of this chapter.</p>
    <p class="normal">The problem lies in the inverse situation—can we trust the high coverage? Does this mean our code is correct? Unfortunately, having good test coverage is a necessary but insufficient condition for clean code. Not having tests for parts of the code is clearly something bad. Having tests is actually very good, but we can only say this for the tests that do exist. However, we don't know much about what tests we are missing, and we might be missing lots of conditions even when code coverage is high.</p>
    <p class="normal">These are some of the caveats of <a id="_idIndexMarker582"/>test coverage, which we will mention in the next section.</p>
    <h4 class="title">Caveats of test coverage</h4>
    <p class="normal">Python is interpreted and, at a very <a id="_idIndexMarker583"/>high level, coverage tools take advantage of this to identify the lines that were interpreted (run) while the tests were running. It will then report this at the end. The fact that a line was interpreted does not mean that it was properly tested, and this is why we should be careful about reading the final coverage report and trusting what it says.</p>
    <p class="normal">This is actually true for any language. The fact that a line was exercised does not mean at all that it was stressed with all its possible combinations. The fact that all branches run successfully with the provided data only means that the code supported that combination, but it doesn't tell us anything about any other possible combinations of parameters that would make the program crash (fuzzy testing).</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Use coverage as a tool to find blind spots in the code, but not as a metric or target goal.</p>
    </div>
    <p class="normal">To illustrate this with a simple example, consider the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">my_function</span><span class="hljs-function">(</span><span class="hljs-params">number: int</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">return</span> <span class="hljs-stri">"even"</span> <span class="hljs-keyword">if</span> number % <span class="hljs-number">2</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-stri">"odd"</span>
</code></pre>
    <p class="normal">Now, let's say we write the following test for it:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.mark.parametrize("number,expected", [(2, "even")])</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_my_function</span><span class="hljs-function">(</span><span class="hljs-params">number, expected</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">assert</span> my_function(number) == expected
</code></pre>
    <p class="normal">If we run the tests with coverage, the report will give us a flashy 100% of coverage. Needless to say, we're missing a test for half of the conditions of the single statement that executed. Even more troubling is the fact that since the <code class="Code-In-Text--PACKT-">else</code> clause of the statement didn't run, we don't know in which ways our code might break (to make this example even more exaggerated, imagine there was an incorrect statement, such as <code class="Code-In-Text--PACKT-">1/0</code> instead of the string <code class="Code-In-Text--PACKT-">"odd"</code>, or that there's a function call).</p>
    <p class="normal">Arguably, we might go a step further and think that this is only the "happy path" because we're providing good values to the function. But what about incorrect types? How should the function defend against that?</p>
    <p class="normal">As you see, even a single and innocent-looking statement might trigger lots of questions and testing conditions that we need to be prepared for.</p>
    <p class="normal">It's a good idea to<a id="_idIndexMarker584"/> check how covered our code is, and even configure code coverage thresholds as part of the CI build, but we have to keep in mind that this is just another tool for us. And just like previous tools that we have explored (linters, code checkers, formatters, and suchlike), it's useful only in the context of more tools and a good environment prepared for a clean code base.</p>
    <p class="normal">Another tool that will help us in our testing efforts is the use of mock objects. We explore these in the next section.</p>
    <h3 id="_idParaDest-221" class="title">Mock objects</h3>
    <p class="normal">There are cases where <a id="_idIndexMarker585"/>our code is not the only thing that will be present in the context of our tests. After all, the systems we design and build have to do something real, and that usually means connecting to external services (databases, storage services, external APIs, cloud services, and so on). Because they need to have those side effects, they're inevitable. As much as we abstract our code, program toward interfaces, and isolate code from external factors to minimize side effects, they will be present in our tests, and we need an effective way to handle that.</p>
    <p class="normal"><code class="Code-In-Text--PACKT-">Mock</code> objects are one of the best tactics used to protect our unit tests against undesirable side effects (as seen earlier in this chapter). Our code might need to perform an HTTP request or send a notification email, but we surely don't want that to happen in our unit tests. Unit tests should target the logic of our code, and run quickly, as we want to run them quite often, which means we cannot afford latency. Therefore, real unit tests don't use any actual service—they don't connect to any database, they don't issue HTTP requests, and basically, they do nothing other than exercise the logic of the production code.</p>
    <p class="normal">We need tests that do such things, but they aren't units. Integration tests are supposed to test functionality with a broader perspective, almost mimicking the behavior of a user. But they aren't fast. Because they connect to external systems and services, they take longer and are more expensive to run. In general, we would like to have lots of unit tests that run quickly in order to run them all the time and have integration tests run less often (for instance, on any new merge request).</p>
    <p class="normal">While mock objects are useful, abusing them ranges between a code smell or an anti-pattern. This is the first issue we discuss in the next section, before moving into the details of using mocks.</p>
    <h4 class="title">A fair warning about patching and mocks</h4>
    <p class="normal">I said before that unit tests help us write better code, because the moment we start thinking about how to test our code, we'll realize how it can be improved to make it testable. And usually, as the code becomes more testable, it becomes cleaner (more cohesive, granular, divided into smaller, components, and so on). </p>
    <p class="normal">Another interesting gain is that testing will help us notice code smells in parts where we thought our code was correct. One of the main warnings that our code has code smells is whether we find ourselves trying to monkey patch (or mock) a lot of different things just to cover a simple test case.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">unittest</code> module provides a tool for patching our objects at <code class="Code-In-Text--PACKT-">unittest.mock.patch</code>.</p>
    <p class="normal">Patching <a id="_idIndexMarker586"/>means that the original code (given by a string denoting its location at import time) will be replaced by something else, other than its original code. If no replacement object is provided, the default is a standard mock object that will simply accept all method calls or attributes is asked about.</p>
    <p class="normal">The patching function replaces the code at runtime and has the disadvantage that we are losing contact with the original code that was there in the first place, making our tests a little shallower. It also carries performance considerations because of the overhead that imposes modifying objects in the interpreter at runtime, and it's something that might require future changes if we refactor our code and move things around (because the strings declared in the patching function will no longer be valid).</p>
    <p class="normal">Using monkey patching or <a id="_idIndexMarker587"/>mocks in our tests might be acceptable, and by itself it doesn't represent an issue. On the other hand, abuse in monkey patching is indeed a red flag telling us that something has to be improved in our code.</p>
    <p class="normal">For example, in the same way that encountering difficulties while testing a function might give us the idea that that function is probably too big and should be broken down into smaller pieces, trying to test a piece of code that requires a very invasive monkey patch should tell us that perhaps the code is relying too heavily on hard dependencies, and that dependency injection should be used instead.</p>
    <h4 class="title">Using mock objects</h4>
    <p class="normal">In unit testing terminology, there are <a id="_idIndexMarker588"/>several types of object that fall into the category named <strong class="keyword">test doubles</strong>. A test double<a id="_idIndexMarker589"/> is a type of object that will take the place of a real one in our test suite for different kinds of reasons (maybe we don't need the actual production code, but just a dummy object would work, or maybe we can't use it because it requires access to services or it has side effects that we don't want in our unit tests, and so on).</p>
    <p class="normal">There are different types of test double, such as dummy objects, stubs, spies, or mocks. </p>
    <p class="normal">Mocks are the most general type of object, and since they're quite flexible and versatile, they are appropriate for all cases without needing to go into much detail about the rest of them. It is for this reason that the standard library also includes an object of this kind, and it is common in most Python programs. That's the one we are going to be using here: <code class="Code-In-Text--PACKT-">unittest.mock.Mock</code>.</p>
    <p class="normal">A <strong class="keyword">mock</strong> is a type of <a id="_idIndexMarker590"/>object created to a specification (usually resembling the object of a production class) and some configured responses (that is, we can tell the mock what it should return upon certain calls, and what its behavior should be). The <code class="Code-In-Text--PACKT-">Mock</code> object will then record, as part of its internal status, how it was called (with what parameters, how many times, and so on), and we can use that information to verify the behavior of our application at a later stage.</p>
    <p class="normal">In the case of Python, the <code class="Code-In-Text--PACKT-">Mock</code> object that's available from the standard library provides a nice API to make all sorts of behavioral assertions, such as checking how many times the mock was called, with what parameters, and so on.</p>
    <h5 class="title">Types of mocks</h5>
    <p class="normal">The standard<a id="_idIndexMarker591"/> library provides <code class="Code-In-Text--PACKT-">Mock</code> and <code class="Code-In-Text--PACKT-">MagicMock</code> objects in the <code class="Code-In-Text--PACKT-">unittest.mock</code> module. The former is a test double that can be configured to return any value and will keep track of the calls that were made to it. The latter does the same, but it also supports magic methods. This means that, if we have written idiomatic code that uses magic methods (and parts of the code we are testing will rely on that), it's likely that we will have to use a <code class="Code-In-Text--PACKT-">MagicMock</code> instance instead of just a <code class="Code-In-Text--PACKT-">Mock</code>.</p>
    <p class="normal">Trying to use <code class="Code-In-Text--PACKT-">Mock</code> when our code needs to call magic methods will result in an error. See the following code for an example of this:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">GitBranch</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, commits: List[Dict]</span><span class="hljs-function">):</span>
        self._commits = {c[<span class="hljs-stri">"id"</span>]: c <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> commits}
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__getitem__</span><span class="hljs-function">(</span><span class="hljs-params">self, commit_id</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">return</span> self._commits[commit_id]
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__len__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">return</span> len(self._commits)
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">author_by_id</span><span class="hljs-function">(</span><span class="hljs-params">commit_id, branch</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">return</span> branch[commit_id][<span class="hljs-stri">"author"</span>]
</code></pre>
    <p class="normal">We want to test this function; however, another test needs to call the <code class="Code-In-Text--PACKT-">author_by_id</code> function. For some reason, since we're not testing that function, any value provided to that function (and returned) will be good:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_find_commit</span><span class="hljs-function">():</span>
    branch = GitBranch([{<span class="hljs-stri">"id"</span>: <span class="hljs-stri">"123"</span>, <span class="hljs-stri">"author"</span>: <span class="hljs-stri">"dev1"</span>}])
    <span class="hljs-keyword">assert</span> author_by_id(<span class="hljs-stri">"123"</span>, branch) == <span class="hljs-stri">"dev1"</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_find_any</span><span class="hljs-function">():</span>
    author = author_by_id(<span class="hljs-stri">"123"</span>, Mock()) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>
    <span class="hljs-comment"># ... rest of the tests..</span>
</code></pre>
    <p class="normal">As anticipated, this <a id="_idIndexMarker592"/>will not work:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">author_by_id</span><span class="hljs-function">(</span><span class="hljs-params">commit_id, branch</span><span class="hljs-function">):</span>
    &gt; <span class="hljs-keyword">return </span>branch[commit_id][<span class="hljs-stri">"author"</span>]
    E TypeError: <span class="hljs-stri">'Mock'</span> object <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> subscriptable
</code></pre>
    <p class="normal">Using <code class="Code-In-Text--PACKT-">MagicMock</code> instead will work. We can even configure the magic method of this type of mock to return something we need in order to control the execution of our test:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_find_any</span><span class="hljs-function">():</span>
    mbranch = MagicMock()
    mbranch.__getitem__.return_value = {<span class="hljs-stri">"author"</span>: <span class="hljs-stri">"test"</span>}
    <span class="hljs-keyword">assert</span> author_by_id(<span class="hljs-stri">"123"</span>, mbranch) == <span class="hljs-stri">"test"</span>
</code></pre>
    <h5 class="title">A use case for test doubles</h5>
    <p class="normal">To see a possible use <a id="_idIndexMarker593"/>of mocks, we need to add a new component to our application that will be in charge of notifying the merge request of the <code class="Code-In-Text--PACKT-">status</code> of the <code class="Code-In-Text--PACKT-">build</code>. When a <code class="Code-In-Text--PACKT-">build</code> is finished, this object will be called with the ID of the merge request and the <code class="Code-In-Text--PACKT-">status</code> of the <code class="Code-In-Text--PACKT-">build</code>, and it will update the <code class="Code-In-Text--PACKT-">status</code> of the merge request with this information by sending an HTTP <code class="Code-In-Text--PACKT-">POST</code> request to a particular fixed endpoint:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># mock_2.py</span>
<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> constants <span class="hljs-keyword">import</span> STATUS_ENDPOINT
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">BuildStatus</span><span class="hljs-class">:</span>
    <span class="hljs-stri">"""The CI status of a pull request."""</span>
<span class="hljs-meta">    @staticmethod</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">build_date</span><span class="hljs-function">() -&gt; str:</span>
        <span class="hljs-keyword">return</span> datetime.utcnow().isoformat()
<span class="hljs-meta">    @classmethod</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">notify</span><span class="hljs-function">(</span><span class="hljs-params">cls, merge_request_id, status</span><span class="hljs-function">):</span>
        build_status = {
            <span class="hljs-stri">"id"</span>: merge_request_id,
            <span class="hljs-stri">"status"</span>: status,
            <span class="hljs-stri">"built_at"</span>: cls.build_date(),
        }
        response = requests.post(STATUS_ENDPOINT, json=build_status)
        response.raise_for_status()
        <span class="hljs-keyword">return</span> response
</code></pre>
    <p class="normal">This class has many side effects, but one of them is an important external dependency that is hard to surmount. If we try to write a test over it without modifying anything, it will fail with a connection error as soon as it tries to perform the HTTP connection.</p>
    <p class="normal">As a testing goal, we just want to make sure that the information is composed correctly, and that library requests are being called with the appropriate parameters. Since this is an external dependency, we don't want to test the <code class="Code-In-Text--PACKT-">requests</code> module; just checking that it's called correctly will be enough.</p>
    <p class="normal">Another problem we will face <a id="_idIndexMarker594"/>when trying to compare data being sent to the library is that the class is calculating the current timestamp, which is impossible to predict in a unit test. Patching <code class="Code-In-Text--PACKT-">datetime</code> directly is not possible, because the module is written in C. Some external libraries that can do that (<code class="Code-In-Text--PACKT-">freezegun</code>, for example), but they come with a performance penalty, and for this example, this would be overkill. Therefore, we opt to wrap the functionality we want in a static method that we will be able to patch.</p>
    <p class="normal">Now that we have established the points that need to be replaced in the code, let's write the unit test:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># test_mock_2.py</span>
<span class="hljs-keyword">from</span> unittest <span class="hljs-keyword">import</span> mock
<span class="hljs-keyword">from</span> constants <span class="hljs-keyword">import</span> STATUS_ENDPOINT
<span class="hljs-keyword">from</span> mock_2 <span class="hljs-keyword">import</span> BuildStatus
<span class="hljs-meta">@mock.patch("mock_2.requests")</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_build_notification_sent</span><span class="hljs-function">(</span><span class="hljs-params">mock_requests</span><span class="hljs-function">):</span>
    build_date = <span class="hljs-stri">"2018-01-01T00:00:01"</span>
    <span class="hljs-keyword">with</span> mock.patch(
        <span class="hljs-stri">"mock_2.BuildStatus.build_date"</span>, 
        return_value=build_date
    ):
        BuildStatus.notify(<span class="hljs-number">123</span>, <span class="hljs-stri">"OK"</span>)
    expected_payload = {
<span class="hljs-stri">        "id"</span>: <span class="hljs-number">123</span>, 
<span class="hljs-stri">        "status"</span>: <span class="hljs-stri">"OK"</span>, 
<span class="hljs-stri">        "built_at"</span>: build_date
    }
    mock_requests.post.assert_called_with(
        STATUS_ENDPOINT, json=expected_payload
    )
</code></pre>
    <p class="normal">First, we use <code class="Code-In-Text--PACKT-">mock.patch</code> as a<a id="_idIndexMarker595"/> decorator to replace the <code class="Code-In-Text--PACKT-">requests</code> module. The result of this function will create a <code class="Code-In-Text--PACKT-">mock</code> object that will be passed as a parameter to the test (named <code class="Code-In-Text--PACKT-">mock_requests</code> in this example). Then, we use this function again, but this time as a context manager to change the return value of the method of the class that computes the date of the <code class="Code-In-Text--PACKT-">build</code>, replacing the value with one we control, which we will use in the assertion.</p>
    <p class="normal">Once we have all of this in place, we can call the class method with some parameters, and then we can use the <code class="Code-In-Text--PACKT-">mock</code> object to check how it was called. In this case, we are using the method to see whether <code class="Code-In-Text--PACKT-">requests.post</code> was indeed called with the parameters as we wanted them to be composed.</p>
    <p class="normal">This is a nice feature of mocks—not only do they put some boundaries around all external components (in this case to prevent actually sending some notifications or issuing HTTP requests), but they also provide a useful API to verify the calls and their parameters.</p>
    <p class="normal">While, in this case, we were able to test the code by setting the respective <code class="Code-In-Text--PACKT-">mock</code> objects in place, it's also true that we had to patch quite a lot in proportion to the total lines of code for the main functionality. There is no rule about the ratio of pure productive code being tested versus how many parts of that code we have to mock, but certainly, by using common sense, we can see that, if we had to patch quite a lot of things in the same parts, something is not clearly abstracted, and it looks like a code smell.</p>
    <p class="normal">The patching of external dependencies can be used in combination with fixtures to apply some global configurations. For example, it's usually a good idea to prevent all the unit tests from performing HTTP calls, so within the subdirectory for unit tests, we can add a fixture in the configuration file of <code class="Code-In-Text--PACKT-">pytest</code> (<code class="Code-In-Text--PACKT-">tests/unit/conftest.py</code>):</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.fixture(autouse=True)</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">no_requests</span><span class="hljs-function">():</span>
    <span class="hljs-keyword">with</span> patch("requests.post"):
        <span class="hljs-keyword">yield</span>
</code></pre>
    <p class="normal">This function will be invoked <a id="_idIndexMarker596"/>automatically in all unit tests (because of <code class="Code-In-Text--PACKT-">autouse=True</code>), and when it does, it will patch the <code class="Code-In-Text--PACKT-">post</code> function in the <code class="Code-In-Text--PACKT-">requests</code> module. This is just an idea you can adapt to your projects to add some extra safety and make sure your unit tests are free of side effects.</p>
    <p class="normal">In the next section, we will explore how to refactor code to overcome this issue.</p>
    <h1 id="_idParaDest-222" class="title">Refactoring</h1>
    <p class="normal">Refactoring means <a id="_idIndexMarker597"/>changing the structure of the code by rearranging its internal representation without modifying its external behavior.</p>
    <p class="normal">One example would be if you identify a class that has lots of responsibilities and very long methods, and then decide to change it by using smaller methods, creating new internal collaborators, and distributing responsibilities into new, smaller objects. As you do that, you're careful not to change the original interface of that class, keep all its public methods as before, and not change any signature. To an external observer of that class, it might look like nothing happened (but we know otherwise).</p>
    <p class="normal"><strong class="keyword">Refactoring</strong> is a critical activity in software maintenance, yet something that can't be done (at least not correctly) without having unit tests. This is because, as each change gets made, we need to know that our code is still correct. In a sense, you can think of our unit tests as the "external observer" for our code, making sure the contract doesn't break.</p>
    <p class="normal">Every now and then, we need to support a new feature or use our software in unintended ways. The only way to accommodate such requirements is by first refactoring our code, to make it more generic or flexible.</p>
    <p class="normal">Typically, when refactoring our code, we want to improve its structure and make it better, sometimes more generic, more readable, or more flexible. The challenge is to achieve these goals while at the same time preserving the exact same functionality it had prior to the modifications that were made. This constraint of having to support the same functionalities as before, but with a different version of the code, implies that we need to run regression tests on code that was modified. The only cost-effective way of running regression tests is if those tests are automatic. The most cost-effective version of automatic tests is unit testing.</p>
    <h2 id="_idParaDest-223" class="title">Evolving our code</h2>
    <p class="normal">In the previous example, we were able to <a id="_idIndexMarker598"/>separate out the side effects from our code to make it testable by patching those parts of the code that depended on things we couldn't control on the unit test. This is a good approach since, after all, the <code class="Code-In-Text--PACKT-">mock.patch</code> function comes in handy for these sorts of tasks and replaces the objects we tell it to, giving us back a <code class="Code-In-Text--PACKT-">Mock</code> object.</p>
    <p class="normal">The downside of that is that we have to provide the path of the object we are going to mock, including the module, as a string. This is a bit fragile, because if we refactor our code (let's say we rename the file or move it to some other location), all the places with the patch will have to be updated, or the test will break.</p>
    <p class="normal">In the example, the fact that the <code class="Code-In-Text--PACKT-">notify()</code> method directly depends on an implementation detail (the <code class="Code-In-Text--PACKT-">requests</code> module) is a design issue; that is, it is taking its toll on the unit tests as well with the aforementioned fragility that is implied.</p>
    <p class="normal">We still need to replace those methods with doubles (mocks), but if we refactor the code, we can do it in a better way. Let's separate these methods into smaller ones, and most importantly inject the dependency rather than keep it fixed. The code now applies the dependency inversion principle, and it expects to work with something that supports an interface (in this example, an implicit one), such as the one that the <code class="Code-In-Text--PACKT-">requests</code> module provides:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime
<span class="hljs-keyword">from</span> constants <span class="hljs-keyword">import</span> STATUS_ENDPOINT
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">BuildStatus</span><span class="hljs-class">:</span>
    endpoint = STATUS_ENDPOINT
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, transport</span><span class="hljs-function">):</span>
        self.transport = transport
<span class="hljs-meta">    @staticmethod</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">build_date</span><span class="hljs-function">() -&gt; str:</span>
        <span class="hljs-keyword">return</span> datetime.utcnow().isoformat()
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">compose_payload</span><span class="hljs-function">(</span><span class="hljs-params">self, merge_request_id, status</span><span class="hljs-function">) -&gt; dict:</span>
        <span class="hljs-keyword">return</span> {
            <span class="hljs-stri">"id"</span>: merge_request_id,
            <span class="hljs-stri">"status"</span>: status,
            <span class="hljs-stri">"built_at"</span>: self.build_date(),
        }
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">deliver</span><span class="hljs-function">(</span><span class="hljs-params">self, payload</span><span class="hljs-function">):</span>
        response = self.transport.post(self.endpoint, json=payload)
        response.raise_for_status()
        <span class="hljs-keyword">return</span> response
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">notify</span><span class="hljs-function">(</span><span class="hljs-params">self, merge_request_id, status</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">return</span> self.deliver(self.compose_payload(merge_request_id, status))
</code></pre>
    <p class="normal">We separate the <a id="_idIndexMarker599"/>methods (note how notify is now compose <code class="Code-In-Text--PACKT-">+</code> deliver), make <code class="Code-In-Text--PACKT-">compose_payload()</code> a new method (so that we can replace, without the need to patch the class), and require the <code class="Code-In-Text--PACKT-">transport</code> dependency to be injected. Now that <code class="Code-In-Text--PACKT-">transport</code> is a dependency, it is much easier to change that object for any double we want.</p>
    <p class="normal">It is even possible to expose a fixture of this object, with the doubles replaced as required:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">build_status</span><span class="hljs-function">():</span>
    bstatus = BuildStatus(Mock())
    bstatus.build_date = Mock(return_value=<span class="hljs-stri">"2018-01-01T00:00:01"</span>)
    <span class="hljs-keyword">return</span> bstatus
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_build_notification_sent</span><span class="hljs-function">(</span><span class="hljs-params">build_status</span><span class="hljs-function">):</span>
    build_status.notify(<span class="hljs-number">1234</span>, <span class="hljs-stri">"OK"</span>)
    expected_payload = {
        <span class="hljs-stri">"id"</span>: <span class="hljs-number">1234</span>,
        <span class="hljs-stri">"status"</span>: <span class="hljs-stri">"OK"</span>,
        <span class="hljs-stri">"built_at"</span>: build_status.build_date(),
    }
    build_status.transport.post.assert_called_with(
        build_status.endpoint, json=expected_payload
    )
</code></pre>
    <p class="normal">As mentioned in the first chapter, the goal of having clean code is to have maintainable code, code that we can refactor so that it can evolve and extend to more requirements. To this end, tests are <a id="_idIndexMarker600"/>a great help. But since tests are so important, we also need to refactor them so that they can also maintain their relevance and usefulness as the code evolves. This is the topic of discussion of the next section.</p>
    <h2 id="_idParaDest-224" class="title">Production code isn't the only one that evolves</h2>
    <p class="normal">We keep saying that unit tests are as important as production code. And if we are careful enough with the production code to create the best possible abstraction, why wouldn't we do the same for unit tests?</p>
    <p class="normal">If the code for unit tests is as important as the main code, then it's wise to design it with extensibility in mind and make it as maintainable as possible. After all, this is the code that will have to be maintained by an engineer other than its original author, so it has to be readable.</p>
    <p class="normal">The reason why we pay so<a id="_idIndexMarker601"/> much attention to the code's flexibility is that we know requirements change and evolve over time, and eventually, as domain business rules change, our code will have to change as well to support these new requirements. Since the production code changed to support new requirements, in turn, the testing code will have to change as well to support the newer version of the production code.</p>
    <p class="normal">In one of the first examples we used, we created a series of tests for the merge request object, trying different combinations and checking the status at which the merge request was left. This is a good first approach, but we can do better than that.</p>
    <p class="normal">Once we understand the problem better, we can start creating better abstractions. With this, the first idea that comes to mind is that we can create a higher-level abstraction that checks for particular conditions. For example, if we have an object that is a test suite that specifically targets the <code class="Code-In-Text--PACKT-">MergeRequest</code> class, we know its functionality will be limited to the behavior of this class (because it should comply to the SRP), and therefore we could create specific testing methods on this testing class. These will only make sense for this class, but that will be helpful in reducing a lot of boilerplate code.</p>
    <p class="normal">Instead of repeating assertions that follow the exact same structure, we can create a method that encapsulates this and reuse it across all of the tests:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">TestMergeRequestStatus</span><span class="hljs-class">(</span><span class="hljs-params">unittest.TestCase</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">setUp</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.merge_request = MergeRequest()
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">assert_rejected</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.assertEqual(
            self.merge_request.status, MergeRequestStatus.REJECTED
        )
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">assert_pending</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.assertEqual(
            self.merge_request.status, MergeRequestStatus.PENDING
        )
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">assert_approved</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.assertEqual(
            self.merge_request.status, MergeRequestStatus.APPROVED
        )
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_simple_rejected</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.merge_request.downvote(<span class="hljs-stri">"maintainer"</span>)
        self.assert_rejected()
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_just_created_is_pending</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        self.assert_pending()
</code></pre>
    <p class="normal">If something changes with how<a id="_idIndexMarker602"/> we check the status of a merge request (or let's say we want to add extra checks), there is only one place (the <code class="Code-In-Text--PACKT-">assert_approved()</code> method) that will have to be modified. More importantly, by creating these higher-level abstractions, the code that started as merely unit tests starts to evolve into what could end up being a testing framework with its own API or domain language, making testing more declarative.</p>
    <h1 id="_idParaDest-225" class="title">More about testing</h1>
    <p class="normal">With the concepts we have<a id="_idIndexMarker603"/> revisited so far, we know how to test our code, think about our design in terms of how it is going to be tested, and configure the tools in our project to run the automated tests that will give us some degree of confidence regarding the quality of the software we have written.</p>
    <p class="normal">If our confidence in the code is determined by the unit tests written on it, how do we know that they are enough? How could we be sure that we have been through enough on the test scenarios and that we are not missing some tests? Who says that these tests are correct? Meaning, who tests the tests?</p>
    <p class="normal">The first part of the question, about being thorough in terms of the tests we write, is answered by going beyond in our testing efforts through property-based testing.</p>
    <p class="normal">The second part of the question<a id="_idIndexMarker604"/> might have multiple answers from different points of view, but we are going to briefly mention mutation testing as a means of determining that our tests are indeed correct. In this sense, we are thinking that the unit tests check our main productive code, and this works as a control for the unit tests as well.</p>
    <h2 id="_idParaDest-226" class="title">Property-based testing</h2>
    <p class="normal">Property-based testing<a id="_idIndexMarker605"/> consists of generating data for tests cases to find scenarios <a id="_idIndexMarker606"/>that will make the code fail, which weren't covered by our previous unit tests.</p>
    <p class="normal">The main library for this is <code class="Code-In-Text--PACKT-">hypothesis</code> which, configured along with our unit tests, will help us find problematic data that will make our code fail.</p>
    <p class="normal">We can imagine that what this library does is find counterexamples for our code. We write our production code (and unit tests for it!), and we claim it's correct. Now, with this library, we define a <code class="Code-In-Text--PACKT-">hypothesis</code> that must hold for our code, and if there are some cases where our assertions don't hold, <code class="Code-In-Text--PACKT-">hypothesis</code> will provide a set of data that causes the error.</p>
    <p class="normal">The best thing about unit tests is that they make us think harder about our production code. The best thing about <code class="Code-In-Text--PACKT-">hypothesis</code> is that it makes us think harder about our unit tests.</p>
    <h2 id="_idParaDest-227" class="title">Mutation testing</h2>
    <p class="normal">We know that<a id="_idIndexMarker607"/> tests are the formal <a id="_idIndexMarker608"/>verification method we have to ensure that our code is correct. And what makes sure that the test is correct? The production code, you might think, and yes, in a way this is correct. We can think of the main code as a counterbalance for our tests.</p>
    <p class="normal">The point in writing unit tests is that we are protecting ourselves against bugs and testing for failure scenarios we don't want to happen in production. It's good that the tests pass, but it would be bad if they pass for the wrong reasons. That is, we can use unit tests as an automatic regression tool—if someone introduces a bug in the code, later on, we expect at least one of our tests to catch it and fail. If this doesn't happen, either there is a test missing, or the ones we had are not doing the right checks.</p>
    <p class="normal">This is the idea <a id="_idIndexMarker609"/>behind mutation testing. With a mutation testing tool, the code will be modified to new versions (called <strong class="keyword">mutants</strong>) that<a id="_idIndexMarker610"/> are variations of the original code, but with some of its logic altered (for example, operators are swapped, conditions are inverted). </p>
    <p class="normal">A good test suite should catch these mutants and kill them, in<a id="_idIndexMarker611"/> which case it means we can rely on the tests. If some mutants survive the experiment, it's usually a bad sign. Of course, this is not entirely precise, so there are intermediate states we might want to ignore.</p>
    <p class="normal">To quickly show you how this works and to allow you to get a practical idea of this, we are going to use a different version of the code that computes the status of a merge request based on the number of approvals and rejections. This time, we have changed the code for a simple version that, based on these numbers, returns the result. We have moved the enumeration with the constants for the statuses to a separate module so that it now looks more compact:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># File mutation_testing_1.py</span>
<span class="hljs-keyword">from</span> mrstatus <span class="hljs-keyword">import</span> MergeRequestStatus <span class="hljs-keyword">as</span> Status
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">evaluate_merge_request</span><span class="hljs-function">(</span><span class="hljs-params">upvote_count, downvotes_count</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">if</span> downvotes_count &gt; <span class="hljs-number">0</span>:
        <span class="hljs-keyword">return</span> Status.REJECTED
    <span class="hljs-keyword">if</span> upvote_count &gt;= <span class="hljs-number">2</span>:
        <span class="hljs-keyword">return</span> Status.APPROVED
    <span class="hljs-keyword">return</span> Status.PENDING
</code></pre>
    <p class="normal">And now will we add a simple unit test, checking one of the conditions and its expected <code class="Code-In-Text--PACKT-">result</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># file: test_mutation_testing_1.py</span>
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">TestMergeRequestEvaluation</span><span class="hljs-class">(</span><span class="hljs-params">unittest.TestCase</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_approved</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        result = evaluate_merge_request(<span class="hljs-number">3</span>, <span class="hljs-number">0</span>)
        self.assertEqual(result, Status.APPROVED)
</code></pre>
    <p class="normal">Now, we will install <code class="Code-In-Text--PACKT-">mutpy</code>, a mutation testing tool for Python, with <code class="Code-In-Text--PACKT-">pip install mutpy</code>, and tell it to run the mutation testing for this module with these tests. The following code runs for different cases, which are distinguished by changing the <code class="Code-In-Text--PACKT-">CASE</code> environment variable:</p>
    <pre class="programlisting code"><code class="hljs-code">$ PYTHONPATH=src mut.py \
    --target src/mutation_testing_${CASE}.py \
    --unit-test tests/test_mutation_testing_${CASE}.py \
    --operator AOD `<span class="hljs-comment"># delete arithmetic operator</span>`<span class="hljs-comment">\</span>
    --operator AOR `<span class="hljs-comment"># replace arithmetic operator</span>`<span class="hljs-comment"> \</span>
    --operator COD `<span class="hljs-comment"># delete conditional operator</span>`<span class="hljs-comment"> \</span>
    --operator COI<span class="hljs-comment"> </span>`<span class="hljs-comment"># insert conditional operator</span>`<span class="hljs-comment"> \</span>
    --operator CRP `<span class="hljs-comment"># replace constant</span>`<span class="hljs-comment"> \</span>
    --operator ROR `<span class="hljs-comment"># replace relational operator</span>`<span class="hljs-comment"> \</span>
    --show-mutants
</code></pre>
    <p class="normal">If you run the previous<a id="_idIndexMarker612"/> command for case 2 (which is also possible to run as <code class="Code-In-Text--PACKT-">make mutation CASE=2</code>), the result is going to look something similar to this:</p>
    <pre class="programlisting code"><code class="hljs-code">[*] Mutation score [<span class="hljs-number">0.04649</span> s]: <span class="hljs-number">100.0</span>%
   - all: <span class="hljs-number">4</span>
   - killed: <span class="hljs-number">4</span> (<span class="hljs-number">100.0</span>%)
   - survived: <span class="hljs-number">0</span> (<span class="hljs-number">0.0</span>%)
   - incompetent: <span class="hljs-number">0</span> (<span class="hljs-number">0.0</span>%)
   - timeout: <span class="hljs-number">0</span> (<span class="hljs-number">0.0</span>%)
</code></pre>
    <p class="normal">This is a good<a id="_idIndexMarker613"/> sign. Let's take a particular instance to analyze what happened. One of the lines on the output shows the following mutant:</p>
    <pre class="programlisting code"><code class="hljs-code"> - [<span class="hljs-comment"># 1] ROR mutation_testing_1:11 : </span>
------------------------------------------------------
  <span class="hljs-number">7</span>: <span class="hljs-keyword">from</span> mrstatus <span class="hljs-keyword">import</span> MergeRequestStatus <span class="hljs-keyword">as</span> Status
  <span class="hljs-number">8</span>: 
  <span class="hljs-number">9</span>: 
 <span class="hljs-number">10</span>: <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">evaluate_merge_request</span><span class="hljs-function">(</span><span class="hljs-params">upvote_count, downvotes_count</span><span class="hljs-function">):</span>
~<span class="hljs-number">11</span>:     <span class="hljs-keyword">if</span> downvotes_count &lt; <span class="hljs-number">0</span>:
 <span class="hljs-number">12</span>:         <span class="hljs-keyword">return</span> Status.REJECTED
 <span class="hljs-number">13</span>:     <span class="hljs-keyword">if</span> upvote_count &gt;= <span class="hljs-number">2</span>:
 <span class="hljs-number">14</span>:         <span class="hljs-keyword">return</span> Status.APPROVED
 <span class="hljs-number">15</span>:     <span class="hljs-keyword">return</span> Status.PENDING
------------------------------------------------------
[<span class="hljs-number">0.00401</span> s] killed by test_approved (test_mutation_testing_1.TestMergeRequestEvaluation)
</code></pre>
    <p class="normal">Notice that this mutant consists of the original version with the operator changed in line <code class="Code-In-Text--PACKT-">11</code> (<code class="Code-In-Text--PACKT-">&gt;</code> for <code class="Code-In-Text--PACKT-">&lt;</code>), and the result is telling us that this mutant was killed by the tests. This means that with this version of the code (let's imagine that someone makes this change by mistake), then the result of the function would have been <code class="Code-In-Text--PACKT-">APPROVED</code>, and since the test expects it to be <code class="Code-In-Text--PACKT-">REJECTED</code>, it fails, which is a good sign (the test caught the bug that was introduced).</p>
    <p class="normal">Mutation testing is a good way to<a id="_idIndexMarker614"/> assure the quality of the unit tests, but it requires some effort and careful analysis. By using this tool in complex environments, we will have to take some time analyzing each scenario. It is also true that it is expensive to run these tests because it requires multiple runs of different versions of the code, which might take up too <a id="_idIndexMarker615"/>many resources and may take longer to complete. However, it would be even more expensive to have to make these checks manually and will require much more effort. Not doing these checks at all might be even riskier because we would be jeopardizing the quality of the tests.</p>
    <h2 id="_idParaDest-228" class="title">Common themes in testing</h2>
    <p class="normal">I'd like to briefly touch on<a id="_idIndexMarker616"/> some topics that are usually good to keep in mind when thinking of ways of how to test our code because they're recurrent and helpful.</p>
    <p class="normal">These are points you'll usually want to think about when trying to come up with tests for the code because they lead to ruthless testing. When you're writing unit tests, your mindset has to be all about breaking the code: you want to make sure you find errors so that you can fix them, and that they don't slip into production (which will be much worse).</p>
    <h3 id="_idParaDest-229" class="title">Boundaries or limit values</h3>
    <p class="normal">Boundary values<a id="_idIndexMarker617"/> are usually a great source of trouble in the code, so that's probably a good starting place. Take <a id="_idIndexMarker618"/>a look at the code and inspect for conditions set around some values. Then, add tests to make sure you include these values.</p>
    <p class="normal">For example, in a line of code such as this:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">if</span> remaining_days &gt; <span class="hljs-number">0</span>: ...
</code></pre>
    <p class="normal">Add explicit tests for the zero, because this seems to be a special case in the code.</p>
    <p class="normal">More generally, in a condition that checks for a range of values, check both ends of the interval. If the code deals with data structures (such as a list or a stack), check for an empty list, or a full stack, and make sure the indexes are always set correctly, even for values on their limits.</p>
    <h3 id="_idParaDest-230" class="title">Classes of equivalence</h3>
    <p class="normal">An equivalence class<a id="_idIndexMarker619"/> is a partition over a set, such that all elements in that partition are equivalent with respect to some function. Because all elements inside this partition are equivalent, we only need one of them as a representative in order to test that condition.</p>
    <p class="normal">To give a simple example, let's recap our previous code used in the section to demonstrate code coverage:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">my_function</span><span class="hljs-function">(</span><span class="hljs-params">number: int</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">return</span> <span class="hljs-stri">"even"</span> <span class="hljs-keyword">if</span> number % <span class="hljs-number">2</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-stri">"odd"</span>
</code></pre>
    <p class="normal">Here, the function has a single <code class="Code-In-Text--PACKT-">if</code> statement and is returning different data depending on that condition.</p>
    <p class="normal">If we wanted to simplify the testing for this function by stipulating that the set of values for input testing, <code class="Code-In-Text--PACKT-">S</code>, is the set of integers, we could argue that it can be partitioned into two: even and odd numbers.</p>
    <p class="normal">Because this code does something for even numbers, and something else for odd ones, we can say that these are our testing conditions. Namely, we only need one element of each sub-set to test the entire condition, no more than that. In other words, testing with 2 is the same as testing with 4 (the same logic is exercised in both cases), so we don't need both, but only one (any) of them. The same goes for 1, and 3 (or any other odd number).</p>
    <p class="normal">We can separate these representative elements into different parameters, and run the same test by using the <code class="Code-In-Text--PACKT-">@pytest.mark.parametrize</code> decorator. The important thing is to make sure we cover all the cases, and that we're not repeating elements (that is, that we're not adding two different parametrizations with elements of the same partition, because that doesn't add any value).</p>
    <p class="normal">Testing by classes of equivalence has two benefits: on the one hand, we test effectively by not repeating new values that don't add anything to our testing scenario, and on the other hand, if we exhaust all classes, then we have good coverage of the scenarios to test for.</p>
    <h3 id="_idParaDest-231" class="title">Edge cases</h3>
    <p class="normal">Finally, try to add<a id="_idIndexMarker620"/> specific tests for all edge cases you can think of. This pretty much depends on the business logic and the peculiarities of the code you're writing, and there's some overlap with the idea of testing around boundary values.</p>
    <p class="normal">For example, if part of your code deals with dates, make sure you test for leap years, the 29<sup class="Superscript--PACKT-">th</sup> of February, and in or around the new year.</p>
    <p class="normal">So far, we have assumed we're writing the tests after the code. This is a typical case. After all, most of the time, you'll find yourself working on an already existing code base, rather than starting it from scratch.</p>
    <p class="normal">There's an alternative, which is writing the test prior to the code. That might be because you're starting a new project or feature, and you want to see what it will look like before writing the actual production code. Or it might be because there's a defect on the code base, and you first want to write a test to reproduce it, before jumping into the fix. This is called <strong class="keyword">Test-Driven Design</strong> (<strong class="keyword">TDD</strong>) and is<a id="_idIndexMarker621"/> discussed in the next section.</p>
    <h2 id="_idParaDest-232" class="title">A brief introduction to test-driven development</h2>
    <p class="normal">There are entire books <a id="_idIndexMarker622"/>dedicated only to TDD, so it would not be realistic to try and cover this topic comprehensively in this book. However, it's such an important topic that it has to be mentioned.</p>
    <p class="normal">The idea behind TDD is that tests should be written before production code in a way that the production code is only written to respond to tests that are failing due to that missing implementation of the functionality.</p>
    <p class="normal">There are multiple reasons why we would like to write the tests first and then the code. From a pragmatic point of view, we would be covering our production code quite accurately. Since all of the production code was written to respond to a unit test, it would be highly unlikely that there are tests missing for functionality (that doesn't mean that there is 100% coverage of course, but at least all the main functions, methods, or components will have their respective tests, even if they aren't completely covered).</p>
    <p class="normal">The workflow is simple and, at a high level, consist of three steps:</p>
    <ol>
      <li class="numbered">Write a unit test that describes how the code should behave. That can either be new functionality that still doesn't exist or current code that is broken, in which case the test describes the desired scenario. Running this test for the first time must fail.</li>
      <li class="numbered">Make the minimal changes in the code to make that test pass. The test should now pass.</li>
      <li class="numbered">Improve (refactor) the code and<a id="_idIndexMarker623"/> run the test again, making sure it still works.</li>
    </ol>
    <p class="normal">This cycle has been popularized as the<a id="_idIndexMarker624"/> famous <strong class="keyword">red-green-refactor</strong>, meaning that in the beginning, the tests fail (red), then we make them pass (green), and then we proceed to refactor the code and iterate it.</p>
    <h1 id="_idParaDest-233" class="title">Summary</h1>
    <p class="normal">Unit testing is a really interesting and deep topic, but more importantly, it is a critical part of the clean code. Ultimately, unit tests are what determine the quality of the code. Unit tests often act as a mirror for the code—when the code is easy to test, it's clear and correctly designed, and this will be reflected in the unit tests.</p>
    <p class="normal">The code for the unit tests is as important as production code. All principles that apply to production code also apply to unit tests. This means that they should be designed and maintained with the same effort and thoughtfulness. If we don't care about our unit tests, they will start to have problems and become defective (or problematic) and, as a result of that, useless. If this happens, and they are hard to maintain, they become a liability, which makes things even worse, because people will tend to ignore them or disable them entirely. This is the worst scenario because once this happens, the entire production code is in jeopardy. Moving forward blindly (without unit tests) is a recipe for disaster.</p>
    <p class="normal">Luckily, Python provides many tools for unit testing, both in the standard library and available through <code class="Code-In-Text--PACKT-">pip</code>. They are of great help and investing time in configuring them pays off in the long run.</p>
    <p class="normal">We have seen how unit tests work as the formal specification of the program, and the proof that a piece of software works according to the specification, and we also learned that when it comes to discovering new testing scenarios, there is always room for improvement and we can always create more tests. In this sense, expanding our unit tests with different approaches (such as property-based testing or mutation testing) is a good investment.</p>
    <p class="normal">In the next chapter, we'll learn about design patterns and their applicability in Python.</p>
    <h1 id="_idParaDest-234" class="title">References</h1>
    <p class="normal">Here is a list of information you can refer to:</p>
    <ul>
      <li class="bullet">The <code class="Code-In-Text--PACKT-">unittest</code> module of the Python standard library contains comprehensive documentation on how to start building a test suite: <a href="https://docs.python.org/3/library/unittest.html"><span class="url">https://docs.python.org/3/library/unittest.html</span></a></li>
      <li class="bullet">Hypothesis: <a href="https://hypothesis.readthedocs.io/en/latest/"><span class="url">https://hypothesis.readthedocs.io/en/latest/</span></a></li>
      <li class="bullet"><code class="Code-In-Text--PACKT-">Pytest's</code> official documentation: <a href="https://docs.pytest.org/en/latest/"><span class="url">https://docs.pytest.org/en/latest/</span></a></li>
      <li class="bullet"><em class="italic">The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary (CatB)</em>, written by Eric S. Raymond (publisher: O'Reilly Media, 1999)</li>
      <li class="bullet">Refactoring: <a href="https://refactoring.com/"><span class="url">https://refactoring.com/</span></a></li>
      <li class="bullet"><em class="italic">The art of software testing</em>, written by <em class="italic">Glenford J. Myers</em> (publisher: Wiley; 3<sup class="Superscript--PACKT-">rd</sup> edition, November 8, 2011)</li>
      <li class="bullet">Writing testable code: <a href="https://testing.googleblog.com/2008/08/by-miko-hevery-so-you-decided-to.html"><span class="url">https://testing.googleblog.com/2008/08/by-miko-hevery-so-you-decided-to.html</span></a></li>
    </ul>
  </div>
</body></html>