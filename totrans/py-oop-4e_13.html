<html><head></head><body>
  <div id="_idContainer195">
    <h1 class="chapterNumber">13</h1>
    <h1 id="_idParaDest-277" class="chapterTitle">Testing Object-Oriented Programs</h1>
    <p class="normal">Skilled Python programmers agree that testing is one of the most important aspects of software development. Even though this chapter is placed near the end of the book, it is not an afterthought; everything we have studied so far will help us when writing tests. In this chapter, we'll look at the following topics:</p>
    <ul>
      <li class="bullet">The importance of unit testing and test-driven development</li>
      <li class="bullet">The standard library <code class="Code-In-Text--PACKT-">unittest</code> module</li>
      <li class="bullet">The <code class="Code-In-Text--PACKT-">pytest</code> tool</li>
      <li class="bullet">The <code class="Code-In-Text--PACKT-">mock</code> module</li>
      <li class="bullet">Code coverage</li>
    </ul>
    <p class="normal">In the case study for this chapter, we'll focus – no surprise – on writing some tests for the case study examples.</p>
    <p class="normal">We'll start with some of the fundamental reasons why automated software testing is so important.</p>
    <h1 id="_idParaDest-278" class="title">Why test?</h1>
    <p class="normal">Many programmers<a id="_idIndexMarker956"/> already know how important it is to test their code. If you're among them, feel free to skim this section. You'll find the next section – where we actually see how to create tests in Python – much more scintillating. </p>
    <p class="normal">If you're not convinced of the importance of testing, we remind you that without any tests, code will be broken, and no one has any way to know it. Read on!</p>
    <p class="normal">Some people argue that testing is more important in Python code because of its dynamic nature; compiled languages such as Java and C++ are occasionally thought to be somehow <em class="italic">safer</em> because they enforce type checking at compile time. However, Python tests rarely check types. They check values. They make sure that the right attributes have been set at the right time or that the sequence has the right length, order, and values. These higher-level concepts need to be tested in any language. The real reason Python programmers test more than programmers of other languages is that it is so easy to test in Python!</p>
    <p class="normal">But why test? Do we really need to test? What if we didn't test? To answer those questions, reflect on the last time you wrote any code. Did it run correctly the first time? Free of syntax errors? Free of logic problems? It's possible, in principle, to type in code that's perfect once in a while. As a practical matter, the number of obvious syntax errors that had to be corrected is an indicator that perhaps there are more subtle logic errors that also had to be corrected.</p>
    <p class="normal">We don't need a formal, separate test to make sure our code works. Running the program, as we generally do, and fixing the errors is a crude form of testing. Python's interactive interpreter and near-zero compile times makes it easy to write a few lines of code and run the program to make sure those lines are doing what is expected. While acceptable at the beginning of a project, this turns into a liability that grows over time. Attempting to change a few lines of code can affect parts of the program that we haven't realized will be influenced by the changes, and without tests, we don't know what we broke. Attempts <a id="_idIndexMarker957"/>at redesigns or even small optimization rewrites can be plagued with problems. Furthermore, as a program grows, the number of paths that the interpreter can take through that code also grows, and it quickly becomes impossible or a crude manual test to exercise all of them.</p>
    <p class="normal">To assure ourselves and others that our software works, we write automated tests. These are programs that automatically run certain inputs through other programs or parts of programs. We can run these test programs in seconds and cover far more potential input situations than one programmer would think to test every time they change something.</p>
    <blockquote class="packt_quote">Software features that can't be demonstrated by automated tests simply don't exist.</blockquote>
    <blockquote class="packt_quote">- Extreme Programming Explained, Kent Beck</blockquote>
    <p class="normal">There are four main reasons to write tests:</p>
    <ul>
      <li class="bullet">To ensure that code is working the way the developer thinks it should</li>
      <li class="bullet">To ensure that code continues working when we make changes</li>
      <li class="bullet">To ensure that the developer understood the requirements</li>
      <li class="bullet">To ensure that the code we are writing has a maintainable interface</li>
    </ul>
    <p class="normal">When we have automated tests, we can run them every time we change code, whether it is during initial development or maintenance releases. Testing can confirm that we didn't inadvertently break anything when adding or extending features.</p>
    <p class="normal">The last two of the preceding points have interesting consequences. When we write tests, it helps us design the API, interface, or pattern that code takes. Thus, if we misunderstood the requirements, writing a test can help highlight the misunderstanding. From the other side, if we're not certain how we want to design a class, we can write a test that interacts with that class so we have an idea of the most natural way to confirm that the interface works. In fact, it is often beneficial to write the tests before we write<a id="_idIndexMarker958"/> the code we are testing.</p>
    <p class="normal">There are some other interesting consequences of focusing on software testing. We'll look at three of these consequences:</p>
    <ul>
      <li class="bullet">Using tests to drive development</li>
      <li class="bullet">Managing different objectives for testing</li>
      <li class="bullet">Having a consistent pattern for test scenarios</li>
    </ul>
    <p class="normal">Let's start with using tests to drive the development effort.</p>
    <h2 id="_idParaDest-279" class="title">Test-driven development</h2>
    <p class="normal"><em class="italic">Write tests first</em> is the<a id="_idIndexMarker959"/> mantra of test-driven development. Test-driven development takes the <em class="italic">untested code is broken code</em> concept one step further and suggests that only unwritten code should be untested. We don't write any code until after we have written the tests that will prove it works. The first time we run a test, it should fail, since the code hasn't been written. Then, we write the code that ensures the test passes, and then write another test for the next segment of code.</p>
    <p class="normal">Test-driven development can be fun; it allows us to build little puzzles to solve. Then, we implement the code to solve those puzzles. After that, we make a more complicated puzzle, and we write code that solves the new puzzle without unsolving the previous one.</p>
    <p class="normal">There are two goals of the test-driven methodology. The first is to ensure that tests really get written.</p>
    <p class="normal">Secondly, writing tests first forces us to consider exactly how the code will be used. It tells us what methods objects need to have and how attributes will be accessed. It helps us break up the initial problem into smaller, testable problems, and then recombine the tested solutions into larger, also tested, solutions. Writing tests can thus become a part of the design process. Often, when we're writing a test for a new object, we discover anomalies in the design that force us to consider new aspects of the software.</p>
    <p class="normal">Testing makes software better. Writing tests before we release the software makes it better before the final code is written.</p>
    <p class="normal">All of the code <a id="_idIndexMarker960"/>examined in the book has been run through an automated test suite. It's the only way to be absolutely sure the examples are rock-solid, working code.</p>
    <h2 id="_idParaDest-280" class="title">Testing objectives</h2>
    <p class="normal">We have a number<a id="_idIndexMarker961"/> of distinct objectives for running tests. These are often called types of testing, but the word "type" is heavily overused in the software industry. In this chapter, we'll look at only two of these testing goals:</p>
    <ul>
      <li class="bullet"><strong class="keyword">Unit tests</strong> confirm that<a id="_idIndexMarker962"/> software components work in isolation. We'll focus on this first, since Fowler's Test Pyramid seems to suggest unit testing creates the most value. If the various classes and functions each adhere to their interfaces and produce the expected results, then integrating them is also going to work nicely and have relatively few surprises. It's common to use the <strong class="keyword">coverage</strong> tool<a id="_idIndexMarker963"/> to be sure all the lines of code are exercised as part of the unit test suite.</li>
      <li class="bullet"><strong class="keyword">Integration tests</strong> – unsurprisingly – confirm software <a id="_idIndexMarker964"/>components work when integrated. Integration tests are sometimes called system tests, functional tests, and acceptance tests, among others. When an integration test fails, it often means an interface wasn't defined properly, or a unit test didn't include some edge case that's exposed through the integration with other components. Integration testing seems to depend on having good unit testing, making it secondary in importance.</li>
    </ul>
    <p class="normal">We note that "unit" isn't formally defined by the Python language. This is an intentional choice. A unit of code is often a single function or a single class. It can be a single module, also. The definition gives us a little flexibility to identify isolated, individual units of code.</p>
    <p class="normal">While there are many distinct objectives for tests, the techniques used tend to be similar. For additional material, see <a href="https://www.softwaretestinghelp.com/types-of-software-testing/"><span class="url">https://www.softwaretestinghelp.com/types-of-software-testing/</span></a> for a list of over 40 different types of testing objectives; this is overwhelming, which is why we will only focus on unit tests and integration tests. All tests have a common pattern to them, and we'll look at a general pattern of testing next.</p>
    <h2 id="_idParaDest-281" class="title">Testing patterns</h2>
    <p class="normal">Writing code is<a id="_idIndexMarker965"/> often challenging. We need to figure out what the internal state of the object is, what state changes it undergoes, and determine the other objects it collaborates with. Throughout the book, we've provided a number of common patterns for designing classes.</p>
    <p class="normal">Tests, in a way, are simpler than class definitions, and all have essentially the same pattern:</p>
    <pre class="programlisting con"><code class="hljs-con">GIVEN some precondition(s) for a scenario
WHEN we exercise some method of a class
THEN some state change(s) or side effect(s) will occur that we can confirm
</code></pre>
    <p class="normal">In some cases, the preconditions can be complex or perhaps the state changes or side effects are complex. They might be so complex that we have to break them into multiple steps. What's important about this three-part pattern is how it disentangles the setup, execution, and expected results from each other. This model applies to a wide variety of tests. If we want to make sure the water's hot enough to make another cup of tea, we'll follow a similar set of steps:</p>
    <ul>
      <li class="bullet"><code class="Code-In-Text--PACKT-">GIVEN</code> a kettle of water on the stove</li>
      <li class="bullet"><code class="Code-In-Text--PACKT-">AND</code> the burner is off</li>
      <li class="bullet"><code class="Code-In-Text--PACKT-">WHEN</code> we flip open the lid on the kettle</li>
      <li class="bullet"><code class="Code-In-Text--PACKT-">THEN</code> we see steam escaping</li>
    </ul>
    <p class="normal">This pattern is quite handy for making sure we have a clear setup and an observable result.</p>
    <p class="normal">Let's say we need to write a function to compute an average of a list of numbers, excluding <code class="Code-In-Text--PACKT-">None</code> values that might be in the sequence. We might start out like this:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">average</span><span class="hljs-function">(</span><span class="hljs-params">data: </span><span class="hljs-built_in">list</span><span class="hljs-params">[Optional[</span><span class="hljs-built_in">int</span><span class="hljs-params">]]</span><span class="hljs-function">) -&gt; float:</span>
    <span class="hljs-string">"""</span>
<span class="hljs-string">    GIVEN a list, data = [1, 2, None, 3, 4]</span>
<span class="hljs-string">    WHEN we compute m = average(data)</span>
<span class="hljs-string">    THEN the result, m, is 2.5</span>
<span class="hljs-string">    """</span>
    <span class="hljs-keyword">pass</span>
</code></pre>
    <p class="normal">We've roughed out a definition of the function, with a summary of how we think it should behave. The GIVEN step defines some data for our test case. The WHEN step defines precisely what we're going to be doing. Finally, the THEN step describes the expected results. The automated test tool can compare actual results against the stated expectation and report back if the test fails. We can then refine this into a separate test class or function using our preferred test framework. The ways unittest and pytest implement the concept differ slightly, but the core concept remains in both frameworks. Once that's done, the test should fail and we can start implementing the real code, given this test as a clear goal line we want to cross.</p>
    <p class="normal">Some techniques that <a id="_idIndexMarker966"/>can<a id="_idIndexMarker967"/> help design test cases are <strong class="keyword">equivalence partitioning</strong> and <strong class="keyword">boundary value analysis</strong>. These help us decompose the domain of all possible inputs to a method or function into partitions. A common example is locating two partitions, "valid data" and "invalid data." Given the partitions, the values at the boundaries of the partitions become interesting values to use in test cases. See <a href="https://www.softwaretestinghelp.com/what-is-boundary-value-analysis-and-equivalence-partitioning/"><span class="url">https://www.softwaretestinghelp.com/what-is-boundary-value-analysis-and-equivalence-partitioning/</span></a> for more information.</p>
    <p class="normal">We'll start by<a id="_idIndexMarker968"/> looking at the built-in testing framework, <code class="Code-In-Text--PACKT-">unittest</code>. It has a disadvantage of being a bit wordy and complicated looking. It has the advantage of being built-in and usable immediately; no further installs are required.</p>
    <h1 id="_idParaDest-282" class="title">Unit testing with unittest</h1>
    <p class="normal">Let's start <a id="_idIndexMarker969"/>our <a id="_idIndexMarker970"/>exploration with Python's built-in test library. This library provides a common object-oriented interface for <em class="italic">unit tests</em>. The Python library for this is called, unsurprisingly, <code class="Code-In-Text--PACKT-">unittest</code>. It provides several tools for creating and running unit tests, the most important being the <code class="Code-In-Text--PACKT-">TestCase</code> class. (The names follow a Java naming style, so many of the method names don't look very Pythonic.) The <code class="Code-In-Text--PACKT-">TestCase</code> class provides a set of methods that allow us to compare values, set up tests, and clean up when they have finished.</p>
    <p class="normal">When we want to write a set of unit tests for a specific task, we create a subclass of <code class="Code-In-Text--PACKT-">TestCase</code> and write individual methods to do the actual testing. These methods must all start with the name <code class="Code-In-Text--PACKT-">test</code>. When this convention is followed, the tests automatically run as part of the test process. For simple examples, we can bundle the <code class="Code-In-Text--PACKT-">GIVEN</code>, <code class="Code-In-Text--PACKT-">WHEN</code>, and <code class="Code-In-Text--PACKT-">THEN</code> concepts into the test method. Here's a very simple example:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> unittest
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">CheckNumbers</span><span class="hljs-class">(</span><span class="hljs-params">unittest.TestCase</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_int_float</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        self.assertEqual(<span class="hljs-number">1</span>, <span class="hljs-number">1.0</span>)
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    unittest.main()
</code></pre>
    <p class="normal">This code subclasses the <code class="Code-In-Text--PACKT-">TestCase</code> class and adds a method that calls the <code class="Code-In-Text--PACKT-">TestCase.assertEqual()</code> method. The <code class="Code-In-Text--PACKT-">GIVEN</code> step is a pair of values, 1 and 1.0. The <code class="Code-In-Text--PACKT-">WHEN</code> step is a kind of degenerate example because there's no new object created and no state change happening. The <code class="Code-In-Text--PACKT-">THEN</code> step is the assertion that the two values will test as equal.</p>
    <p class="normal">When we run the test case, this method will either succeed silently or it will raise an exception, depending on whether the two parameters are equal. If we run this code, the <code class="Code-In-Text--PACKT-">main</code> function from <code class="Code-In-Text--PACKT-">unittest</code> will give us the following output:</p>
    <pre class="programlisting con"><code class="hljs-con">.
--------------------------------------------------------------
Ran 1 test in 0.000s
OK  
</code></pre>
    <p class="normal">Did you<a id="_idIndexMarker971"/> know<a id="_idIndexMarker972"/> that floats and integers can be compared as equal?</p>
    <p class="normal">Let's add a failing test, as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_str_float</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span> 
        self.assertEqual(<span class="hljs-number">1</span>, <span class="hljs-string">"1"</span>) 
</code></pre>
    <p class="normal">The output of this code is more sinister, as integers and strings are not considered equal:</p>
    <pre class="programlisting con"><code class="hljs-con">.F
============================================================
FAIL: test_str_float (__main__.CheckNumbers)
--------------------------------------------------------------
Traceback (most recent call last):
  File "first_unittest.py", line 9, in test_str_float
    self.assertEqual(1, "1")
AssertionError: 1 != '1'
--------------------------------------------------------------
Ran 2 tests in 0.001s
FAILED (failures=1)  
</code></pre>
    <p class="normal">The dot on the first line indicates that the first test (the one we wrote before) passed successfully; the letter <code class="Code-In-Text--PACKT-">F</code> after it shows that the second test failed. Then, at the end, it gives us some informative summary telling us how and where the test failed, along with a count of the number of failures.</p>
    <p class="normal">Even the OS-level return code provides a useful summary. The return code is zero if all tests pass and non-zero if any tests fail. This helps when building continuous integration tools: if the <code class="Code-In-Text--PACKT-">unittest</code> run fails, the proposed change shouldn't be permitted.</p>
    <p class="normal">We can have as many test methods on one <code class="Code-In-Text--PACKT-">TestCase</code> class as we like. As long as the method name begins with <code class="Code-In-Text--PACKT-">test</code>, the test runner will execute each one as a separate, isolated test.</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">Each test should be completely independent of other tests.</p>
      <p class="Tip--PACKT-">Results or calculations from a test should have no impact on any other test.</p>
    </div>
    <p class="normal">In order to <a id="_idIndexMarker973"/>keep tests <a id="_idIndexMarker974"/>isolated from each other, we may have several tests with a common <code class="Code-In-Text--PACKT-">GIVEN</code>, implemented by a common <code class="Code-In-Text--PACKT-">setUp()</code> method. This suggests that we'll often have classes that are similar, and we'll need to use inheritance to design the tests so they can share features and still remain completely independent.</p>
    <p class="normal">The key to writing good unit tests is keeping each test method as short as possible, testing a small unit of code with each test case. If our code does not seem to naturally break up into small, testable units, it's probably a sign that the code needs to be redesigned. The <em class="italic">Imitating objects using Mocks</em> section, later in this chapter, provides a way to isolate objects for testing purposes.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">unittest</code> module imposes a requirement to structure tests as a class definition. This is – in some ways – a bit of overhead. The <code class="Code-In-Text--PACKT-">pytest</code> package has slightly more clever test discovery and a slightly more flexible way to construct tests as functions instead of methods of a class. We'll look at <code class="Code-In-Text--PACKT-">pytest</code> next.</p>
    <h1 id="_idParaDest-283" class="title">Unit testing with pytest</h1>
    <p class="normal">We can<a id="_idIndexMarker975"/> create<a id="_idIndexMarker976"/> unit tests using a library that provides a common framework for the test scenarios, along with a test runner to execute the tests and log results. Unit tests focus on testing the least amount of code possible in any one test. The standard library includes the <code class="Code-In-Text--PACKT-">unittest</code> package. While widely used, this package tends to force us to create a fair amount of boilerplate code for each test case.</p>
    <p class="normal">One of the more popular alternatives to the standard library <code class="Code-In-Text--PACKT-">unittest</code> is <code class="Code-In-Text--PACKT-">pytest</code>. This has the advantage of letting us write smaller, and more clear, test cases. The lack of overheads makes this a desirable alternative.</p>
    <p class="normal">Since <code class="Code-In-Text--PACKT-">pytest</code> is not part of the standard library, you'll need to download and install it yourself. You can get it from the <code class="Code-In-Text--PACKT-">pytest</code> home page at <a href="https://docs.pytest.org/en/stable/"><span class="url">https://docs.pytest.org/en/stable/</span></a>. You can install it with any of the installers.</p>
    <p class="normal">In a Terminal window, activate the virtual environment you're working in. (If you're using venv, for example, you might use <code class="Code-In-Text--PACKT-">python -m venv c:\path\to\myenv</code>.) Then, use an OS command like the following:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">%</span><span class="bash"> python -m  pip install pytest</span>
</code></pre>
    <p class="normal">The Windows command should be the same as the command on macOS and Linux.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">pytest</code> tool can use a substantially different test layout from the <code class="Code-In-Text--PACKT-">unittest</code> module. It doesn't <a id="_idIndexMarker977"/>require test cases to be subclasses of <code class="Code-In-Text--PACKT-">unittest.TestCase</code>. Instead, it takes advantage of the<a id="_idIndexMarker978"/> fact that Python functions are first-class objects and allows any properly named function to behave like a test. Rather than providing a bunch of custom methods for asserting equality, it uses the <code class="Code-In-Text--PACKT-">assert</code> statement to verify results. This makes tests simpler, more readable, and, consequently, easier to maintain.</p>
    <p class="normal">When we run <code class="Code-In-Text--PACKT-">pytest</code>, it starts in the current folder and searches for any modules or sub packages with names beginning with the characters <code class="Code-In-Text--PACKT-">test_</code>. (Including the <code class="Code-In-Text--PACKT-">_</code> character.) If any functions in this module also start with <code class="Code-In-Text--PACKT-">test</code> (no <code class="Code-In-Text--PACKT-">_</code> required), they will be executed as individual tests. Furthermore, if there are any classes in the module whose name starts with <code class="Code-In-Text--PACKT-">Test</code>, any methods on that class that start with <code class="Code-In-Text--PACKT-">test_</code> will also be executed in the test environment.</p>
    <p class="normal">It also searches in a folder named – unsurprisingly – <code class="Code-In-Text--PACKT-">tests</code>. Because of this, it's common to have code broken up into two folders: the <code class="Code-In-Text--PACKT-">src/</code> directory contains the working module, library, or application, while the <code class="Code-In-Text--PACKT-">tests/</code> directory contains all the test cases.</p>
    <p class="normal">Using the following code, let's port the simple <code class="Code-In-Text--PACKT-">unittest</code> example we wrote earlier to <code class="Code-In-Text--PACKT-">pytest</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_int_float</span><span class="hljs-function">() -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span> 
    <span class="hljs-keyword">assert</span> <span class="hljs-number">1</span> == <span class="hljs-number">1.0</span> 
</code></pre>
    <p class="normal">For the same test, we've written two lines of more readable code, in comparison to the six lines required in our first <code class="Code-In-Text--PACKT-">unittest</code> example.</p>
    <p class="normal">However, we are not forbidden from writing class-based tests. Classes can be useful for grouping related tests together or for tests that need to access related attributes or methods on the class. The following example shows an extended class with a passing and a failing test; we'll see that the error output is more comprehensive than that provided by the <code class="Code-In-Text--PACKT-">unittest</code> module:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">TestNumbers</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_int_float</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        <span class="hljs-keyword">assert</span> <span class="hljs-number">1</span> == <span class="hljs-number">1.0</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_int_str</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        <span class="hljs-keyword">assert</span> <span class="hljs-number">1</span> == <span class="hljs-string">"1"</span>
</code></pre>
    <p class="normal">Notice that the <a id="_idIndexMarker979"/>class doesn't have to extend any special objects to be<a id="_idIndexMarker980"/> discovered as a test case (although <code class="Code-In-Text--PACKT-">pytest</code> will run standard <code class="Code-In-Text--PACKT-">unittest TestCases</code> just fine). If we run <code class="Code-In-Text--PACKT-">python -m pytest tests/&lt;filename&gt;</code>, the output looks as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">%</span><span class="bash"> python -m pytest tests/test_with_pytest.py</span>
======================== test session starts ========================
platform darwin -- Python 3.9.0, pytest-6.2.2, py-1.10.0, pluggy-0.13.1
rootdir: /path/to/ch_13
collected 2 items                                                   
tests/test_with_pytest.py .F                                  [100%]
============================= FAILURES ==============================
_____________________ TestNumbers.test_int_str ______________________
self = &lt;test_with_pytest.TestNumbers object at 0x7fb557f1a370&gt;
    def test_int_str(self) -&gt; None:
<span class="hljs-con-meta">&gt;</span><span class="bash">       assert 1 == </span><span class="hljs-con-string">"1"</span>
E       AssertionError: assert 1 == "1"
tests/test_with_pytest.py:15: AssertionError
====================== short test summary info ======================
FAILED tests/test_with_pytest.py::TestNumbers::test_int_str - Asse...
==================== 1 failed, 1 passed in 0.07s ====================
</code></pre>
    <p class="normal">The output starts with some useful information about the platform and interpreter. This can be useful for sharing or discussing bugs across disparate systems. The third line tells us the name of the file being tested (if there are multiple test modules picked up, they will all be displayed), followed by the familiar <code class="Code-In-Text--PACKT-">.F</code> we saw in the <code class="Code-In-Text--PACKT-">unittest</code> module; the <code class="Code-In-Text--PACKT-">.</code> character indicates a passing test, while the letter <code class="Code-In-Text--PACKT-">F</code> demonstrates a failure.</p>
    <p class="normal">After all tests have run, the error output for each of them is displayed. It presents a summary of local variables (there is only one in this example: the <code class="Code-In-Text--PACKT-">self</code> parameter passed into the function), the source code where the error occurred, and a summary of the error message. In addition, if an exception other than an <code class="Code-In-Text--PACKT-">AssertionError</code> is raised, <code class="Code-In-Text--PACKT-">pytest</code> will present us with a complete traceback, including source code references.</p>
    <p class="normal">By default, <code class="Code-In-Text--PACKT-">pytest</code> suppresses output from <code class="Code-In-Text--PACKT-">print()</code> if the test is successful. This is useful for test debugging; when a test is failing, we can add <code class="Code-In-Text--PACKT-">print()</code> statements to the test to check the values of specific variables and attributes as the test runs. If the test fails, these values are output to help with diagnosis. However, once the test is successful, the <code class="Code-In-Text--PACKT-">print()</code> output is not displayed, and they are easily ignored. We don't have to clean up the test output by removing <code class="Code-In-Text--PACKT-">print()</code>. If the tests ever fail again, due to future changes, the <a id="_idIndexMarker981"/>debugging <a id="_idIndexMarker982"/>output will be immediately available.</p>
    <p class="normal">Interestingly, this use of the <code class="Code-In-Text--PACKT-">assert</code> statement exposes a potential problem to <strong class="" style="font-style: italic;">mypy</strong>. When we use the <code class="Code-In-Text--PACKT-">assert</code> statement, <strong class="" style="font-style: italic;">mypy</strong> can examine the types, and will alert us to a potential problem with <code class="Code-In-Text--PACKT-">assert 1 == "1"</code>. This code is unlikely to be right, and it will not only fail as a unit test, but will also fail a <strong class="" style="font-style: italic;">mypy</strong> inspection.</p>
    <p class="normal">We've looked at how <code class="Code-In-Text--PACKT-">pytest</code> supports the <code class="Code-In-Text--PACKT-">WHEN</code> and <code class="Code-In-Text--PACKT-">THEN</code> steps of a test using a function and the <code class="Code-In-Text--PACKT-">assert</code> statement. Now, we need to look more closely at how to handle <code class="Code-In-Text--PACKT-">GIVEN</code> steps. There are two ways to establish the <code class="Code-In-Text--PACKT-">GIVEN</code> precondition for a test; we'll start with one that works for simple cases.</p>
    <h2 id="_idParaDest-284" class="title">pytest's setup and teardown functions</h2>
    <p class="normal"><code class="Code-In-Text--PACKT-">pytest</code> supports<a id="_idIndexMarker983"/> setup <a id="_idIndexMarker984"/>and teardown capabilities, similar to the methods used in <code class="Code-In-Text--PACKT-">unittest</code>, but it provides even more flexibility. We'll discuss these general functions briefly; <code class="Code-In-Text--PACKT-">pytest</code> provides us with a powerful fixtures capability, which we'll discuss in the next section.</p>
    <p class="normal">If we are writing class-based tests, we can use two methods called <code class="Code-In-Text--PACKT-">setup_method()</code> and <code class="Code-In-Text--PACKT-">teardown_method()</code>. They are called before and after each test method in the class to perform setup and cleanup duties, respectively.</p>
    <p class="normal">In addition, <code class="Code-In-Text--PACKT-">pytest</code> provides other setup and teardown functions to give us more control over when preparation and cleanup code is executed. The <code class="Code-In-Text--PACKT-">setup_class()</code> and <code class="Code-In-Text--PACKT-">teardown_class()</code> methods are expected to be class methods; they accept a single argument representing the class in question (there is no <code class="Code-In-Text--PACKT-">self</code> argument because there's no instance; instead, the class is provided). These methods are run by <code class="Code-In-Text--PACKT-">pytest</code> when the class is initiated rather than on each test run.</p>
    <p class="normal">Finally, we have the <code class="Code-In-Text--PACKT-">setup_module()</code> and <code class="Code-In-Text--PACKT-">teardown_module()</code> functions, which are run by <code class="Code-In-Text--PACKT-">pytest</code> immediately before and after all tests (in functions or classes) in that module. These can be useful for <em class="italic">one-time</em> setup, such as creating a socket or database connection that will be used by all tests in the module. Be careful with this one, as it can accidentally introduce dependencies between tests if some object state isn't correctly cleaned up between tests.</p>
    <p class="normal">That short<a id="_idIndexMarker985"/> description doesn't do a great job of explaining exactly when these<a id="_idIndexMarker986"/> methods are called, so let's look at an example that illustrates exactly when it happens:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> annotations
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Any, Callable
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">setup_module</span><span class="hljs-function">(</span><span class="hljs-params">module: Any</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    print(<span class="hljs-string">f"setting up MODULE </span><span class="hljs-subst">{module.__name__}</span><span class="hljs-string">"</span>)
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">teardown_module</span><span class="hljs-function">(</span><span class="hljs-params">module: Any</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    print(<span class="hljs-string">f"tearing down MODULE </span><span class="hljs-subst">{module.__name__}</span><span class="hljs-string">"</span>)
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_a_function</span><span class="hljs-function">() -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    print(<span class="hljs-string">"RUNNING TEST FUNCTION"</span>)
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">BaseTest</span><span class="hljs-class">:</span>
<span class="hljs-meta">    @classmethod</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">setup_class</span><span class="hljs-function">(</span><span class="hljs-params">cls: </span><span class="hljs-built_in">type</span><span class="hljs-params">[</span><span class="hljs-string">"BaseTest"</span><span class="hljs-params">]</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        print(<span class="hljs-string">f"setting up CLASS </span><span class="hljs-subst">{cls.__name__}</span><span class="hljs-string">"</span>)
<span class="hljs-meta">    @classmethod</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">teardown_class</span><span class="hljs-function">(</span><span class="hljs-params">cls: </span><span class="hljs-built_in">type</span><span class="hljs-params">[</span><span class="hljs-string">"BaseTest"</span><span class="hljs-params">]</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        print(<span class="hljs-string">f"tearing down CLASS </span><span class="hljs-subst">{cls.__name__}</span><span class="hljs-string">\n"</span>)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">setup_method</span><span class="hljs-function">(</span><span class="hljs-params">self, method: Callable[[], </span><span class="hljs-literal">None</span><span class="hljs-params">]</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        print(<span class="hljs-string">f"setting up METHOD </span><span class="hljs-subst">{method.__name__}</span><span class="hljs-string">"</span>)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">teardown_method</span><span class="hljs-function">(</span><span class="hljs-params">self, method: Callable[[], </span><span class="hljs-literal">None</span><span class="hljs-params">]</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        print(<span class="hljs-string">f"tearing down METHOD </span><span class="hljs-subst">{method.__name__}</span><span class="hljs-string">"</span>)
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">TestClass1</span><span class="hljs-class">(</span><span class="hljs-params">BaseTest</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_method_1</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        print(<span class="hljs-string">"RUNNING METHOD 1-1"</span>)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_method_2</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        print(<span class="hljs-string">"RUNNING METHOD 1-2"</span>)
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">TestClass2</span><span class="hljs-class">(</span><span class="hljs-params">BaseTest</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_method_1</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        print(<span class="hljs-string">"RUNNING METHOD 2-1"</span>)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_method_2</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        print(<span class="hljs-string">"RUNNING METHOD 2-2"</span>)
</code></pre>
    <p class="normal">The sole <a id="_idIndexMarker987"/>purpose<a id="_idIndexMarker988"/> of the <code class="Code-In-Text--PACKT-">BaseTest</code> class is to extract four methods that are otherwise identical to the two test classes, and use inheritance to reduce the amount of duplicate code. So, from the point of view of <code class="Code-In-Text--PACKT-">pytest</code>, the two subclasses have not only two test methods each, but also two setup and two teardown methods (one at the class level, one at the method level).</p>
    <p class="normal">If we run these tests using <code class="Code-In-Text--PACKT-">pytest</code> with the <code class="Code-In-Text--PACKT-">print()</code> function output suppression disabled (by passing the <code class="Code-In-Text--PACKT-">-s</code> or <code class="Code-In-Text--PACKT-">--capture=no</code> flag), they show us when the various functions are called in relation to the tests themselves:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">%</span><span class="bash"> python -m pytest --capture=no tests/test_setup_teardown.py</span>
========================= test session starts ==========================
platform darwin -- Python 3.9.0, pytest-6.2.2, py-1.10.0, pluggy-0.13.1
rootdir: /…/ch_13
collected 5 items                                                      
tests/test_setup_teardown.py setting up MODULE test_setup_teardown
RUNNING TEST FUNCTION
.setting up CLASS TestClass1
setting up METHOD test_method_1
RUNNING METHOD 1-1
.tearing down METHOD test_method_1
setting up METHOD test_method_2
RUNNING METHOD 1-2
.tearing down METHOD test_method_2
tearing down CLASS TestClass1
setting up CLASS TestClass2
setting up METHOD test_method_1
RUNNING METHOD 2-1
.tearing down METHOD test_method_1
setting up METHOD test_method_2
RUNNING METHOD 2-2
.tearing down METHOD test_method_2
tearing down CLASS TestClass2
tearing down MODULE test_setup_teardown
========================== 5 passed in 0.01s ===========================
</code></pre>
    <p class="normal">The setup and teardown methods for the module as a whole are executed at the beginning<a id="_idIndexMarker989"/> and <a id="_idIndexMarker990"/>end of the session. Then, the lone module-level test function is run. Next, the setup method for the first class is executed, followed by the two tests for that class. These tests are each individually wrapped in separate <code class="Code-In-Text--PACKT-">setup_method()</code> and <code class="Code-In-Text--PACKT-">teardown_method()</code> calls. After the tests have executed, the teardown method on the class is called. The same sequence happens for the second class, before the <code class="Code-In-Text--PACKT-">teardown_module()</code> method is finally called, exactly once.</p>
    <p class="normal">While these function names provide a lot of options for testing, we'll often have setup conditions that are shared across multiple test scenarios. These can be reused via a composition-based design; <code class="Code-In-Text--PACKT-">pytest</code> calls these designs "fixtures." We'll look at fixtures next.</p>
    <h2 id="_idParaDest-285" class="title">pytest fixtures for setup and teardown</h2>
    <p class="normal">One of the<a id="_idIndexMarker991"/> most<a id="_idIndexMarker992"/> common uses for the various setup functions is to ensure the GIVEN step of a test is prepared. This often involves creating objects and making sure certain class or module variables have known values before a test method is run.</p>
    <p class="normal">In addition to a set of special method names for a test class, <code class="Code-In-Text--PACKT-">pytest</code> offers a completely different way of doing this, using what are known as <strong class="keyword">fixtures</strong>. Fixtures are functions to build the <code class="Code-In-Text--PACKT-">GIVEN</code> condition, prior to a test's <code class="Code-In-Text--PACKT-">WHEN</code> step. </p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">pytest</code> tool has a number of built-in fixtures, we can define fixtures in a configuration file and reuse them, and we can define unique fixtures as part of our tests. This allows us to separate configuration from the execution of tests, allowing fixtures to be used across multiple classes and modules.</p>
    <p class="normal">Let's look at<a id="_idIndexMarker993"/> a class that does a few computations<a id="_idIndexMarker994"/> that we need to test:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> List, Optional
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">StatsList</span><span class="hljs-class">(</span><span class="hljs-params">List[Optional[</span><span class="hljs-built_in">float</span><span class="hljs-params">]]</span><span class="hljs-class">):</span>
    <span class="hljs-string">"""Stats with None objects rejected"""</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">mean</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; float:</span>
        clean = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-literal">None</span>, self))
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(clean) / <span class="hljs-built_in">len</span>(clean)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">median</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; float:</span>
        clean = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-literal">None</span>, self))
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(clean) % <span class="hljs-number">2</span>:
            <span class="hljs-keyword">return</span> clean[<span class="hljs-built_in">len</span>(clean) // <span class="hljs-number">2</span>]
        <span class="hljs-keyword">else</span>:
            idx = <span class="hljs-built_in">len</span>(clean) // <span class="hljs-number">2</span>
            <span class="hljs-keyword">return</span> (clean[idx] + clean[idx - <span class="hljs-number">1</span>]) / <span class="hljs-number">2</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">mode</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; list[float]:</span>
        freqs: DefaultDict[<span class="hljs-built_in">float</span>, <span class="hljs-built_in">int</span>] = collections.defaultdict(<span class="hljs-built_in">int</span>)
        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> <span class="hljs-built_in">filter</span>(<span class="hljs-literal">None</span>, self):
            freqs[item] += <span class="hljs-number">1</span>
        mode_freq = <span class="hljs-built_in">max</span>(freqs.values())
        modes = [item 
            <span class="hljs-keyword">for</span> item, value <span class="hljs-keyword">in</span> freqs.items() 
            <span class="hljs-keyword">if</span> value == mode_freq]
        <span class="hljs-keyword">return</span> modes
</code></pre>
    <p class="normal">This class extends the built-in <code class="Code-In-Text--PACKT-">list</code> class to add three statistical summary methods, <code class="Code-In-Text--PACKT-">mean()</code>, <code class="Code-In-Text--PACKT-">median()</code>, and <code class="Code-In-Text--PACKT-">mode()</code>. For each method, we need to have some set of data we can use; this configuration of a <code class="Code-In-Text--PACKT-">StatsList</code> with known data is the fixture we'll be testing.</p>
    <p class="normal">To use a fixture to create the <code class="Code-In-Text--PACKT-">GIVEN</code> precondition, we add the fixture name as a parameter to our test function. When a test runs, the names of a test function's parameters will be located in the collection of fixtures, and those fixture-creating functions will be executed for us automatically. </p>
    <p class="normal">For example, to test the <code class="Code-In-Text--PACKT-">StatsList</code> class, we will <a id="_idIndexMarker995"/>want to repeatedly provide a list <a id="_idIndexMarker996"/>of valid integers. We can write our tests as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">from</span> stats <span class="hljs-keyword">import</span> StatsList
<span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">valid_stats</span><span class="hljs-function">() -&gt; StatsList:</span>
    <span class="hljs-keyword">return</span> StatsList([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_mean</span><span class="hljs-function">(</span><span class="hljs-params">valid_stats: StatsList</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">assert</span> valid_stats.mean() == <span class="hljs-number">2.5</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_median</span><span class="hljs-function">(</span><span class="hljs-params">valid_stats: StatsList</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">assert</span> valid_stats.median() == <span class="hljs-number">2.5</span>
    valid_stats.append(<span class="hljs-number">4</span>)
    <span class="hljs-keyword">assert</span> valid_stats.median() == <span class="hljs-number">3</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_mode</span><span class="hljs-function">(</span><span class="hljs-params">valid_stats: StatsList</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">assert</span> valid_stats.mode() == [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]
    valid_stats.remove(<span class="hljs-number">2</span>)
    <span class="hljs-keyword">assert</span> valid_stats.mode() == [<span class="hljs-number">3</span>]
</code></pre>
    <p class="normal">Each of the three test functions accepts a parameter named <code class="Code-In-Text--PACKT-">valid_stats</code>; this parameter is created by <code class="Code-In-Text--PACKT-">pytest</code> automatically calling the <code class="Code-In-Text--PACKT-">valid_stats</code> function for us. The function was decorated with <code class="Code-In-Text--PACKT-">@pytest.fixture</code> so it could be used in this special way by <code class="Code-In-Text--PACKT-">pytest</code>.</p>
    <p class="normal">And yes, the names must match. The <strong class="keyword">pytest</strong> runtime looks for functions with the <code class="Code-In-Text--PACKT-">@fixture</code> decorator that match the parameter name.</p>
    <p class="normal">Fixtures can do a lot more than return simple objects. A <code class="Code-In-Text--PACKT-">request</code> object can be passed into the fixture factory to provide extremely useful methods and attributes to modify the fixture's behavior. The <code class="Code-In-Text--PACKT-">module</code>, <code class="Code-In-Text--PACKT-">cls</code>, and <code class="Code-In-Text--PACKT-">function</code> attributes of the <code class="Code-In-Text--PACKT-">request</code> object allow us to see exactly which test is requesting the fixture. The <code class="Code-In-Text--PACKT-">config</code> attribute of the <code class="Code-In-Text--PACKT-">request</code> object allows us to check command-line arguments and a great deal of other configuration data.</p>
    <p class="normal">If we implement the fixture as a generator, it can also run cleanup code after each test is run. This provides the equivalent of a teardown method on a per-fixture basis. We can use it to clean up files, close connections, empty lists, or reset queues. For unit tests, where items are isolated, a mock object is a better idea than performing a teardown on a stateful object. See the <em class="italic">Imitating objects using Mocks</em> section, later in this chapter, for a simpler approach that's ideal for unit testing.</p>
    <p class="normal">For integration tests, we might want to test some code that creates, deletes, or updates files. We'll often use the <code class="Code-In-Text--PACKT-">pytest</code> <code class="Code-In-Text--PACKT-">tmp_path</code> fixture to write these to directories that can be deleted later, saving us from having to do a teardown in a test. While rarely needed for unit testing, a teardown is helpful for stopping subprocesses or removing database changes that are part of an integration test. We'll see this a little later in this section. First, let's<a id="_idIndexMarker997"/> look <a id="_idIndexMarker998"/>at a small example of a fixture with setup and teardown capabilities.</p>
    <p class="normal">To get started on the concept of a fixture that does both setup and teardown, here's a little bit of code that makes a backup copy of a file and writes a new file with a checksum of an existing file:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> tarfile
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-keyword">import</span> hashlib
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">checksum</span><span class="hljs-function">(</span><span class="hljs-params">source: Path, checksum_path: Path</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">if</span> checksum_path.exists():
        backup = checksum_path.with_stem(<span class="hljs-string">f"(old) </span><span class="hljs-subst">{checksum_path.stem}</span><span class="hljs-string">"</span>)
        backup.write_text(checksum_path.read_text())
    checksum = hashlib.sha256(source.read_bytes())
    checksum_path.write_text(<span class="hljs-string">f"</span><span class="hljs-subst">{source.name}</span><span class="hljs-string"> </span><span class="hljs-subst">{checksum.hexdigest()}</span><span class="hljs-string">\n"</span>)
</code></pre>
    <p class="normal">There are two scenarios:</p>
    <ul>
      <li class="bullet">The source file exists; a new checksum is added to the directory</li>
      <li class="bullet">The source file and a checksum file both exist; in this case, the old checksum is copied to a backup location and a new checksum is written</li>
    </ul>
    <p class="normal">We won't test both scenarios, but we will show how a fixture can create – and then delete – the files required for a test sequence. We'll focus on the second scenario because it's more complex. We'll break the testing into two parts, starting with the fixture:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> annotations
<span class="hljs-keyword">import</span> checksum_writer
<span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Iterator
<span class="hljs-keyword">import</span> sys
<span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">working_directory</span><span class="hljs-function">(</span><span class="hljs-params">tmp_path: Path</span><span class="hljs-function">) -&gt; Iterator[tuple[Path, Path]]:</span>
    working = tmp_path / <span class="hljs-string">"some_directory"</span>
    working.mkdir()
    source = working / <span class="hljs-string">"data.txt"</span>
    source.write_bytes(<span class="hljs-string">b"Hello, world!\n"</span>)
    checksum = working / <span class="hljs-string">"checksum.txt"</span>
    checksum.write_text(<span class="hljs-string">"data.txt Old_Checksum"</span>)
    <span class="code-highlight"><strong class="hljs-slc">yield source, checksum</strong></span>
    checksum.unlink()
    source.unlink()
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">yield</code> statement<a id="_idIndexMarker999"/> is<a id="_idIndexMarker1000"/> the secret for making this work. Our fixture is really a generator that produces one result and then waits for the next request of a value. The first result that's created follows a number of steps: a working directory is created, a source file is created in the working directory, and then an old checksum file is created. The <code class="Code-In-Text--PACKT-">yield</code> statement provides two paths to the test and waits for the next request. This work completes the <code class="Code-In-Text--PACKT-">GIVEN</code> condition setup for the test. </p>
    <p class="normal">When the test function finishes, <code class="Code-In-Text--PACKT-">pytest</code> will try to get one final item from this fixture. This lets the function unlink the files, removing them. There's no return value, which signals the end of the iteration. In addition to leveraging the generator protocol, the <code class="Code-In-Text--PACKT-">working_directory</code> fixture relies on the <code class="Code-In-Text--PACKT-">tmp_path</code> fixture of <code class="Code-In-Text--PACKT-">pytest</code> to create a temporary working location for this test.</p>
    <p class="normal">Here's the test that uses this <code class="Code-In-Text--PACKT-">working_directory</code> fixture:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.mark.skipif(</span>
<span class="hljs-params">    sys.version_info &lt; (</span><span class="hljs-number">3</span><span class="hljs-params">, </span><span class="hljs-number">9</span><span class="hljs-params">), reason=</span><span class="hljs-string">"requires python3.9 feature"</span><span class="hljs-meta">)</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_checksum</span><span class="hljs-function">(</span><span class="hljs-params">working_directory: </span><span class="hljs-built_in">tuple</span><span class="hljs-params">[Path, Path]</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    source_path, old_checksum_path = working_directory
    checksum_writer.checksum(source_path, old_checksum_path)
    backup = old_checksum_path.with_stem(
        <span class="hljs-string">f"(old) </span><span class="hljs-subst">{old_checksum_path.stem}</span><span class="hljs-string">"</span>)
    <span class="hljs-keyword">assert</span> backup.exists()
    <span class="hljs-keyword">assert</span> old_checksum_path.exists()
    name, checksum = old_checksum_path.read_text().rstrip().split()
    <span class="hljs-keyword">assert</span> name == source_path.name
    <span class="hljs-keyword">assert </span>(
<span class="hljs-keyword">        </span>checksum ==<span class="hljs-keyword"> </span><span class="hljs-string">"d9014c4624844aa5bac314773d6b689a"</span>
<span class="hljs-keyword">        </span><span class="hljs-string">"d467fa4e1d1a50a1b8a99d5a95f72ff5"</span>
<span class="hljs-keyword">    </span>)
</code></pre>
    <p class="normal">The test is marked with a <code class="Code-In-Text--PACKT-">skipif</code> condition because this test won't work in Python 3.8; the <code class="Code-In-Text--PACKT-">with_stem()</code> method of a <code class="Code-In-Text--PACKT-">Path</code> isn't part of the older <code class="Code-In-Text--PACKT-">pathlib</code> implementation. This assures us that the test is counted but noted as inappropriate for a specific Python release. We'll return<a id="_idIndexMarker1001"/> to<a id="_idIndexMarker1002"/> this in the <em class="italic">Skipping tests with pytest</em> section, later in this chapter.</p>
    <p class="normal">The reference to the <code class="Code-In-Text--PACKT-">working_directory</code> fixture forces <code class="Code-In-Text--PACKT-">pytest</code> to execute the fixture function, providing the test scenario with two paths to be used as part of the GIVEN condition prior to testing. The WHEN step evaluates the <code class="Code-In-Text--PACKT-">checksum_writer.checksum()</code> function with these two paths. The THEN steps are a sequence of <code class="Code-In-Text--PACKT-">assert</code> statements to make sure the files are created with the expected values. After the test is run, <code class="Code-In-Text--PACKT-">pytest</code> will use <code class="Code-In-Text--PACKT-">next()</code> to get another item from the fixture; this action executes the code after the <code class="Code-In-Text--PACKT-">yield</code>, resulting in a teardown after the test.</p>
    <p class="normal">When testing components in isolation, we won't often need to use the teardown feature of a fixture. For integration tests, however, where a number of components are used in concert, it may be necessary to stop processes or remove files. In the next section, we'll look at a more sophisticated fixture. This kind of fixture can be used for more than a single test scenario.</p>
    <h2 id="_idParaDest-286" class="title">More sophisticated fixtures</h2>
    <p class="normal">We can <a id="_idIndexMarker1003"/>pass a <code class="Code-In-Text--PACKT-">scope</code> parameter to create a fixture that lasts longer than one test. This is useful when setting up an expensive operation that can be reused by multiple tests, as long as the resource reuse doesn't break the atomic or unit nature of the test: one unit test should not rely on, and should not be impacted by, any other unit test.</p>
    <p class="normal">As an example, we'll define a server that's part of a client-server application. We want multiple web servers to send their log messages to a single, centralized log. In addition to isolated unit tests, we need to have an integration test. This test makes sure the web server and the log collector properly integrate with each other. The integration test will need to start and stop this log collection server.</p>
    <p class="normal">There are at least three levels to the testing pyramid. Unit tests are the foundation, exercising each component in isolation. Integration tests are the middle of the pyramid, making sure the components integrate properly with each other. A system test or acceptance test is the top of the pyramid, making sure the entire suite of software does what it claims.</p>
    <p class="normal">We'll look at a log collection server that accepts messages and writes them to a single, central file. These messages are defined by the <code class="Code-In-Text--PACKT-">logging</code> module's <code class="Code-In-Text--PACKT-">SocketHandler</code>. We can depict each message as a block of bytes with a header and a payload. In the following table, we've <a id="_idIndexMarker1004"/>shown the structure using slices of the block of bytes. </p>
    <p class="normal">Here's how a message is defined:</p>
    <table id="table001-6" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Slice start</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Slice stop</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Meaning</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Python module and function for parsing</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">4</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">payload_size</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><code class="Code-In-Text--PACKT-">struct.unpack("&gt;L", bytes)</code></p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">4</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">payload_size+4</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">payload</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><code class="Code-In-Text--PACKT-">pickle.loads(bytes)</code></p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">The size of the header is shown as a four-byte slice, but the size shown here can be misleading. The header is formally and officially defined by a format string used by the <code class="Code-In-Text--PACKT-">struct</code> module, <code class="Code-In-Text--PACKT-">"&gt;L"</code>. The <code class="Code-In-Text--PACKT-">struct</code> module has a function, <code class="Code-In-Text--PACKT-">calcsize()</code>, to compute the actual length from the format string. Instead of using a literal 4, which is derived from the size of the "<code class="Code-In-Text--PACKT-">&gt;L</code>" format, our code will derive the size, <code class="Code-In-Text--PACKT-">size_bytes</code>, from the size format string, <code class="Code-In-Text--PACKT-">size_format</code>. Using one proper source, <code class="Code-In-Text--PACKT-">size_format</code>, for both pieces of information follows the design principle of Don't Repeat Yourself.</p>
    <p class="normal">Here's an example buffer with a message from the <code class="Code-In-Text--PACKT-">logging</code> module embedded in it. The first line is the header with the payload size, a four-byte value. The next lines are the pickled data for a log message:</p>
    <pre class="programlisting con"><code class="hljs-con">b'\x00\x00\x02d' b'}q\x00(X\x04\x00\x00\x00nameq\x01X\x03\x00\x00\x00appq\x02X\x03\x00\x00\x00msgq\x03X\x0b\x00\x00\x00Factorial 
…
\x19X\n\x00\x00\x00MainThreadq\x1aX\x0b\x00\x00\x00processNameq\x1bX\x0b\x00\x00\x00MainProcessq\x1cX\x07\x00\x00\x00processq\x1dMcQu.'
</code></pre>
    <p class="normal">To read these messages, we'll need to collect the payload size bytes first. Then, we can consume the payload that follows. Here's the socket server that reads the headers and the payloads and <a id="_idIndexMarker1005"/>writes them to a file:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from </span>__future__<span class="hljs-keyword"> import </span>annotations
<span class="hljs-keyword">import</span> json
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-keyword">import</span> socketserver
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> TextIO
<span class="hljs-keyword">import</span> pickle
<span class="hljs-keyword">import</span> struct
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">LogDataCatcher</span><span class="hljs-class">(</span><span class="hljs-params">socketserver.BaseRequestHandler</span><span class="hljs-class">):</span>
    log_file: TextIO
    count: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span>
    size_format = <span class="hljs-string">"&gt;L"</span>
    size_bytes = struct.calcsize(size_format)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">handle</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        size_header_bytes = self.request.recv(LogDataCatcher.size_bytes)
        <span class="hljs-keyword">while</span> size_header_bytes:
            payload_size = struct.unpack(
                LogDataCatcher.size_format, size_header_bytes)
            payload_bytes = self.request.recv(payload_size[<span class="hljs-number">0</span>])
            payload = pickle.loads(payload_bytes)
            LogDataCatcher.count += <span class="hljs-number">1</span>
            self.log_file.write(json.dumps(payload) + <span class="hljs-string">"\n"</span>)
            <span class="hljs-keyword">try</span>:
                size_header = self.request.recv(
                    LogDataCatcher.size_bytes)
            <span class="hljs-keyword">except</span> (ConnectionResetError, BrokenPipeError):
                <span class="hljs-keyword">break</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function">(</span><span class="hljs-params">host: </span><span class="hljs-built_in">str</span><span class="hljs-params">, port: </span><span class="hljs-built_in">int</span><span class="hljs-params">, target: Path</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">with</span> target.<span class="hljs-built_in">open</span>(<span class="hljs-string">"w"</span>) <span class="hljs-keyword">as</span> unified_log:
        LogDataCatcher.log_file = unified_log
        <span class="hljs-keyword">with</span> socketserver.TCPServer(
                (host, port), LogDataCatcher) <span class="hljs-keyword">as</span> server:
            server.serve_forever()
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">socketserver.TCPServer</code> object will listen for connection requests from a client. When a client connects, it will create an instance of the <code class="Code-In-Text--PACKT-">LogDataCatcher</code> class and evaluate the <code class="Code-In-Text--PACKT-">handle()</code> method of that object to gather data from that client. The <code class="Code-In-Text--PACKT-">handle()</code> method decodes the size and payload with a two-step dance. First, it reads a few bytes to find the size of the payload. It uses <code class="Code-In-Text--PACKT-">struct.unpack()</code> to decode those bytes into a useful number, <code class="Code-In-Text--PACKT-">payload_size</code>, and then reads the given number of bytes to get the payload. The <code class="Code-In-Text--PACKT-">pickle.loads()</code> will load a Python object from the payload bytes. This is serialized into JSON notation using <code class="Code-In-Text--PACKT-">json.dumps()</code> and written to the open file. Once a message has been handled, we can try to read the next few bytes to see if there's more data waiting. This server will absorb messages from the client until the connection is dropped, leading to an error in the read and an exit from the <code class="Code-In-Text--PACKT-">while</code> statement.</p>
    <p class="normal">This log collection server can absorb logging messages from an application anywhere in a network. This example implementation is single-threaded, meaning it only handles one client at a time. We can use additional mixins to create a multithreaded server that will accept <a id="_idIndexMarker1006"/>messages from multiple sources. In this example, we want to focus on testing a single application that depends on this server.</p>
    <p class="normal">For completeness, here's the main script that starts the server running:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    HOST, PORT = <span class="hljs-string">"localhost"</span>, <span class="hljs-number">18842</span>
    main(HOST, PORT, Path(<span class="hljs-string">"one.log"</span>))
</code></pre>
    <p class="normal">We provide a host IP address, a port number, and the file to which we want all the messages written. As a practical matter, we might consider using the <code class="Code-In-Text--PACKT-">argparse</code> module and the <code class="Code-In-Text--PACKT-">os.environ</code> dictionary to provide these values to the application. For now, we've hardcoded them.</p>
    <p class="normal">Here's the <code class="Code-In-Text--PACKT-">remote_logging_app.py</code> application, which transmits log records to the log-catching server:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from </span>__future__<span class="hljs-keyword"> import </span>annotations
<span class="hljs-keyword">import</span> logging
<span class="hljs-keyword">import</span> logging.handlers
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> factorial
logger = logging.getLogger(<span class="hljs-string">"app"</span>)
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">work</span><span class="hljs-function">(</span><span class="hljs-params">i: </span><span class="hljs-built_in">int</span><span class="hljs-function">) -&gt; int:</span>
    logger.info(<span class="hljs-string">"Factorial %d"</span>, i)
    f = factorial(i)
    logger.info(<span class="hljs-string">"Factorial(%d) = %d"</span>, i, f)
    <span class="hljs-keyword">return</span> f
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    HOST, PORT = <span class="hljs-string">"localhost"</span>, <span class="hljs-number">18842</span>
    socket_handler = logging.handlers.SocketHandler(HOST, PORT)
    stream_handler = logging.StreamHandler(sys.stderr)
    logging.basicConfig(
        handlers=[socket_handler, stream_handler], 
        level=logging.INFO)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):
        work(i)
    logging.shutdown()
</code></pre>
    <p class="normal">This application<a id="_idIndexMarker1007"/> creates two logging handlers. The <code class="Code-In-Text--PACKT-">SocketHandler</code> instance will open a socket on the given server and port number, and start writing bytes. The bytes will include headers and payloads. The <code class="Code-In-Text--PACKT-">StreamHandler</code> instance will write to the terminal window; this is the default log handler that we would get if we didn't create any special handlers. We configure our logger with both handlers so each log message goes both to our console and to the stream server collecting the messages. The actual work? A little bit of math to compute the factorial of a number. Each time we run this application, it should blast out 20 log messages.</p>
    <p class="normal">To test the integrated client and server, we need to start the server in a separate process. We don't want to start and stop it many times (that takes a while), so we will start it once and use it in multiple tests. We'll break this into two sections, starting with the two fixtures:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> annotations
<span class="hljs-keyword">import</span> subprocess
<span class="hljs-keyword">import</span> signal
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">import</span> logging
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> remote_logging_app
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Iterator, Any
<span class="hljs-meta">@pytest.fixture(</span><span class="hljs-params">scope=</span><span class="hljs-string">"session"</span><span class="hljs-meta">)</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">log_catcher</span><span class="hljs-function">() -&gt; Iterator[</span><span class="hljs-keyword">None</span><span class="hljs-function">]:</span>
    print(<span class="hljs-string">"loading server"</span>)
    p = subprocess.Popen(
        [<span class="hljs-string">"python3"</span>, <span class="hljs-string">"src/log_catcher.py"</span>],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=<span class="hljs-literal">True</span>,
    )
    time.sleep(<span class="hljs-number">0.25</span>)
    <span class="code-highlight"><strong class="hljs-slc">yield</strong></span>
    p.terminate()
    p.wait()
    <span class="hljs-keyword">if</span> p.stdout:
        print(p.stdout.read())
    <span class="hljs-keyword">assert</span> (
        p.returncode == -signal.SIGTERM.value
    ), <span class="hljs-string">f"Error in watcher, returncode=</span><span class="hljs-subst">{p.returncode}</span><span class="hljs-string">"</span>
<span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">logging_config</span><span class="hljs-function">() -&gt; Iterator[</span><span class="hljs-keyword">None</span><span class="hljs-function">]:</span>
    HOST, PORT = <span class="hljs-string">"localhost"</span>, <span class="hljs-number">18842</span>
    socket_handler = logging.handlers.SocketHandler(HOST, PORT)
    remote_logging_app.logger.addHandler(socket_handler)
    <span class="hljs-keyword">yield</span>
    socket_handler.close()
    remote_logging_app.logger.removeHandler(socket_handler)
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">log_catcher</code> fixture<a id="_idIndexMarker1008"/> will start the <code class="Code-In-Text--PACKT-">log_catcher.py</code> server as a subprocess. This has a scope set to <code class="Code-In-Text--PACKT-">"session"</code> in the <code class="Code-In-Text--PACKT-">@fixture</code> decorator, which means it's done once for the whole testing session. The scope can be one of the strings <code class="Code-In-Text--PACKT-">"function"</code>, <code class="Code-In-Text--PACKT-">"class"</code>, <code class="Code-In-Text--PACKT-">"module"</code>, <code class="Code-In-Text--PACKT-">"package"</code>, or <code class="Code-In-Text--PACKT-">"session"</code>, providing distinct places where the fixture is created and reused. The startup involves a tiny pause (250 ms) to make sure the other process has started properly. When this fixture reaches the <code class="Code-In-Text--PACKT-">yield</code> statement, this part of the <code class="Code-In-Text--PACKT-">GIVEN</code> test setup is done.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">logging_config</code> fixture will tweak the log configuration for the <code class="Code-In-Text--PACKT-">remote_logging_app</code> module that's being tested. When we look at the <code class="Code-In-Text--PACKT-">work()</code> function in the <code class="Code-In-Text--PACKT-">remote_logging_app.py</code> module, we can see that it expects a module-level <code class="Code-In-Text--PACKT-">logger</code> object. This test fixture creates a <code class="Code-In-Text--PACKT-">SocketHandler</code> object, adds this to the <code class="Code-In-Text--PACKT-">logger</code>, and then executes the <code class="Code-In-Text--PACKT-">yield</code> statement.</p>
    <p class="normal">Once both of these fixtures have contributed to the <code class="Code-In-Text--PACKT-">GIVEN</code> condition, we can define test cases that contain the <code class="Code-In-Text--PACKT-">WHEN</code> steps. Here are two examples for two similar scenarios:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_1</span><span class="hljs-function">(</span><span class="hljs-params">log_catcher: </span><span class="hljs-literal">None</span><span class="hljs-params">, logging_config: </span><span class="hljs-literal">None</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):
        r = remote_logging_app.work(i)
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_2</span><span class="hljs-function">(</span><span class="hljs-params">log_catcher: </span><span class="hljs-literal">None</span><span class="hljs-params">, logging_config: </span><span class="hljs-literal">None</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>):
        r = remote_logging_app.work(<span class="hljs-number">52</span> * i)
</code></pre>
    <p class="normal">These two scenarios<a id="_idIndexMarker1009"/> both require the two fixtures. The <code class="Code-In-Text--PACKT-">log_catcher</code> fixture, with a session scope, is prepared once and used for both tests. The <code class="Code-In-Text--PACKT-">logging_config</code> fixture, however, has default scope, which means it's prepared for each test function.</p>
    <p class="normal">The type hint of <code class="Code-In-Text--PACKT-">None</code> follows the definition of the fixture as <code class="Code-In-Text--PACKT-">Iterator[None]</code>. There's no value returned in the <code class="Code-In-Text--PACKT-">yield</code> statement. For these tests, the setup operation is preparing the overall runtime environment by starting a process.</p>
    <p class="normal">When a test function finishes, the <code class="Code-In-Text--PACKT-">logging_config</code> fixture resumes after the <code class="Code-In-Text--PACKT-">yield</code> statement. (This fixture is an iterator, and the <code class="Code-In-Text--PACKT-">next()</code> function is used to try to get a second value from it.) This closes and removes the handler, cleanly breaking the network connection with the log catcher process.</p>
    <p class="normal">When testing finishes overall, the <code class="Code-In-Text--PACKT-">log_catcher</code> fixture can then terminate the child process. To help with debugging, we print any output. To be sure the test worked, we check the OS return code. Because the process was terminated (via <code class="Code-In-Text--PACKT-">p.terminate()</code>), the return code should be the <code class="Code-In-Text--PACKT-">signal.SIGTERM</code> value. Other return code values, particularly a return code of one, mean the log catcher crashed and the test failed.</p>
    <p class="normal">We've omitted a detailed <code class="Code-In-Text--PACKT-">THEN</code> check, but it would also be part of the <code class="Code-In-Text--PACKT-">log_catcher</code> fixture. The existing <code class="Code-In-Text--PACKT-">assert</code> statement makes sure the log catcher terminated with the expected return code. Once the catcher in the sky has finished absorbing log messages, this fixture should also read the log file to be sure it contains the expected entries for the two scenarios.</p>
    <p class="normal">Fixtures can also be parameterized. We can use a decorator like <code class="Code-In-Text--PACKT-">@pytest.fixture(params=[some, list, of, values])</code> to create multiple copies of a fixture, which will lead to multiple tests with each of the parameter values.</p>
    <p class="normal">The sophistication of <code class="Code-In-Text--PACKT-">pytest</code> fixtures makes them very handy for a wide variety of test setup and teardown requirements. Earlier in this section, we hinted at ways to mark tests as inappropriate<a id="_idIndexMarker1010"/> for a particular version of Python. In the next section, we'll look at how we can mark tests to be skipped.</p>
    <h2 id="_idParaDest-287" class="title">Skipping tests with pytest</h2>
    <p class="normal">It is<a id="_idIndexMarker1011"/> sometimes<a id="_idIndexMarker1012"/> necessary to skip tests in <code class="Code-In-Text--PACKT-">pytest</code>, for a similar variety of reasons: the code being tested hasn't been written yet, the test only runs on certain interpreters or operating systems, or the test is time-consuming and should only be run under certain circumstances. In the previous section, one of our tests would not work in Python 3.8, and needed to be skipped.</p>
    <p class="normal">One way to skip tests is by using the <code class="Code-In-Text--PACKT-">pytest.skip()</code> function. It accepts a single argument: a string describing why it has been skipped. This function can be called anywhere. If we call it inside a test function, the test will be skipped. If we call it at the module level, all the tests in that module will be skipped. If we call it inside a fixture, all tests that reference the fixture will be skipped.</p>
    <p class="normal">Of course, in all these locations, it is often only desirable to skip tests if certain conditions have or have not been met. Since we can execute the <code class="Code-In-Text--PACKT-">skip()</code> function at any place in Python code, we can execute it inside an <code class="Code-In-Text--PACKT-">if</code> statement. We may write a test that looks as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_simple_skip</span><span class="hljs-function">() -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">if</span> sys.platform != <span class="hljs-string">"ios"</span>:
        pytest.skip(<span class="hljs-string">"Test works only on Pythonista for ios"</span>)
    <span class="hljs-keyword">import</span> location  <span class="hljs-comment"># type: ignore [import]</span>
    img = location.render_map_snapshot(<span class="hljs-number">36.8508</span>, -<span class="hljs-number">76.2859</span>)
    <span class="hljs-keyword">assert</span> img <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>
</code></pre>
    <p class="normal">This test will skip on most operating systems. It should run on the Pythonista port of Python for iOS. It shows how we can skip a scenario conditionally, and since the <code class="Code-In-Text--PACKT-">if</code> statement can check any valid conditional, we have a lot of power over when tests are skipped. Often, we check <code class="Code-In-Text--PACKT-">sys.version_info</code> to check the Python interpreter version, <code class="Code-In-Text--PACKT-">sys.platform</code> to check the operating system, or <code class="Code-In-Text--PACKT-">some_library.__version__</code> to check whether we have a recent enough version of a given module.</p>
    <p class="normal">Since skipping an individual test method or function based on a condition is one of the most common uses of test skipping, <code class="Code-In-Text--PACKT-">pytest</code> provides a convenient decorator that allows us to do this in one line. The decorator accepts a single string, which can contain any executable Python code that evaluates to a Boolean value. For example, the following test will only <a id="_idIndexMarker1013"/>run on<a id="_idIndexMarker1014"/> Python 3.9 or higher:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">import</span> sys
<span class="hljs-meta">@pytest.mark.skipif(</span>
<span class="hljs-params">    sys.version_info &lt; (</span><span class="hljs-number">3</span><span class="hljs-params">, </span><span class="hljs-number">9</span><span class="hljs-params">), </span>
<span class="hljs-params">    reason=</span><span class="hljs-string">"requires 3.9, Path.removeprefix()"</span>
<span class="hljs-meta">)</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_feature_python39</span><span class="hljs-function">() -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    file_name = <span class="hljs-string">"(old) myfile.dat"</span>
    <span class="hljs-keyword">assert</span> file_name.removeprefix(<span class="hljs-string">"(old) "</span>) == <span class="hljs-string">"myfile.dat"</span>
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">pytest.mark.xfail</code> decorator marks a test as expected to fail. If the test is successful, it will be recorded as a failure (it failed to fail!). If it fails, it will be reported as expected behavior. In the case of <code class="Code-In-Text--PACKT-">xfail</code>, the conditional argument is optional. If it is not supplied, the test will be marked as expected to fail under all conditions.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">pytest</code> framework has a ton of other features besides those described here, and the developers are constantly adding innovative new ways to make your testing experience more enjoyable. They have thorough documentation on their website at <a href="https://docs.pytest.org/"><span class="url">https://docs.pytest.org/</span></a>.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">The <code class="Code-In-Text--PACKT-">pytest</code> tool can find and run tests defined using the standard <code class="Code-In-Text--PACKT-">unittest</code> library, in addition to its own testing infrastructure. This means that if you want to migrate from <code class="Code-In-Text--PACKT-">unittest</code> to <code class="Code-In-Text--PACKT-">pytest</code>, you don't have to rewrite all your old tests.</p>
    </div>
    <p class="normal">We've looked at using a fixture to set up and tear down a complex environment for testing. This is helpful for some integration tests, but a better approach may be to imitate an expensive object or a risky operation. Additionally, any kind of teardown operation is inappropriate for unit tests. A unit test isolates each software component as a separate unit to<a id="_idIndexMarker1015"/> be tested. This means we'll often replace all of the<a id="_idIndexMarker1016"/> interface objects with<a id="_idIndexMarker1017"/> imitations, called "mocks," to isolate the unit being tested. Next, we'll turn to creating mock objects to isolate units and imitate expensive resources.</p>
    <h1 id="_idParaDest-288" class="title">Imitating objects using Mocks</h1>
    <p class="normal">Isolated problems <a id="_idIndexMarker1018"/>are easier to diagnose and solve. Figuring out<a id="_idIndexMarker1019"/> why a gasoline car won't start can be tricky because there are so many interrelated parts. If a test fails, uncovering all the interrelationships makes diagnosis of the problem difficult. We often want to isolate items by providing simplified imitations. It turns out there are two reasons to replace perfectly good code with imitation (or "mock") objects:</p>
    <ul>
      <li class="bullet">The most common case is to isolate a unit under test. We want to create collaborating classes and functions so we can test one unknown component in an environment of known, trusted test fixtures.</li>
      <li class="bullet">Sometimes, we want to test code that requires an object that is either expensive or risky to use. Things like shared databases, filesystems, and cloud infrastructures can be very expensive to set up and tear down for testing.</li>
    </ul>
    <p class="normal">In some cases, this may lead to designing an API to have a testable interface. Designing for testability often means designing a more usable interface, too. In particular, we have to expose assumptions about collaborating classes so we can inject a mock object instead of an instance of an actual application class.</p>
    <p class="normal">For example, imagine we have some code that keeps track of flight statuses in an external key-value store (such as <code class="Code-In-Text--PACKT-">redis</code> or <code class="Code-In-Text--PACKT-">memcache</code>), such that we can store the timestamp and the most recent status. The implementation will require the <code class="Code-In-Text--PACKT-">redis</code> client; it's not needed to write unit tests. The client can be installed with the <code class="Code-In-Text--PACKT-">python -m pip install redis</code> command like this:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">%</span><span class="bash"> python -m pip install redis</span>
Collecting redis
  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)
     |████████████████████████████████| 72 kB 1.1 MB/s 
Installing collected packages: redis
Successfully installed redis-3.5.3
</code></pre>
    <p class="normal">If you want to run this with a real <code class="Code-In-Text--PACKT-">redis</code> server, you'll also need to download and install <code class="Code-In-Text--PACKT-">redis</code>. This can be done as follows:</p>
    <ol>
      <li class="numbered">Download the Docker desktop to help manage this application. See <a href="https://www.docker.com/products/docker-desktop"><span class="url">https://www.docker.com/products/docker-desktop</span></a>.</li>
      <li class="numbered">Use the <code class="Code-In-Text--PACKT-">docker pull redis</code> command from a Terminal window to download a <code class="Code-In-Text--PACKT-">redis</code> server image. This image can be used to build a running Docker container.</li>
      <li class="numbered">You can then start the server with <code class="Code-In-Text--PACKT-">docker run -p 6379:6379 redis</code>. This will start a container running the <code class="Code-In-Text--PACKT-">redis</code> image. Then you can use this for integration testing.</li>
    </ol>
    <p class="normal">An alternative that avoids <strong class="keyword">docker</strong> involves a number of platform-specific steps. See <a href="https://redislabs.com/ebook/appendix-a/"><span class="url">https://redislabs.com/ebook/appendix-a/</span></a> for a number of installation scenarios. The examples that follow will assume <strong class="keyword">docker</strong> is being used; the minor changes that are required to <a id="_idIndexMarker1020"/>switch to a native installation of <code class="Code-In-Text--PACKT-">redis</code> are left as an<a id="_idIndexMarker1021"/> exercise for the reader.</p>
    <p class="normal">Here's some code that saves status in a <code class="Code-In-Text--PACKT-">redis</code> cache server:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> annotations
<span class="hljs-keyword">import</span> datetime
<span class="hljs-keyword">from</span> enum <span class="hljs-keyword">import</span> Enum
<span class="hljs-keyword">import</span> redis
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">Status</span><span class="hljs-class">(</span><span class="hljs-built_in">str</span><span class="hljs-params">, Enum</span><span class="hljs-class">):</span>
    CANCELLED = <span class="hljs-string">"CANCELLED"</span>
    DELAYED = <span class="hljs-string">"DELAYED"</span>
    ON_TIME = <span class="hljs-string">"ON TIME"</span>
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">FlightStatusTracker</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        self.redis = redis.Redis(host=<span class="hljs-string">"127.0.0.1"</span>, port=<span class="hljs-number">6379</span>, db=<span class="hljs-number">0</span>)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">change_status</span><span class="hljs-function">(</span><span class="hljs-params">self, flight: </span><span class="hljs-built_in">str</span><span class="hljs-params">, status: Status</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(status, Status):
            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f"</span><span class="hljs-subst">{status!r}</span><span class="hljs-string"> is not a valid Status"</span>)
        key = <span class="hljs-string">f"flightno:</span><span class="hljs-subst">{flight}</span><span class="hljs-string">"</span>
        now = datetime.datetime.now(tz=datetime.timezone.utc)
        value = <span class="hljs-string">f"</span><span class="hljs-subst">{now.isoformat()}</span><span class="hljs-string">|</span><span class="hljs-subst">{status.value}</span><span class="hljs-string">"</span>
        self.redis.<span class="hljs-built_in">set</span>(key, value)
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">get_status</span><span class="hljs-function">(</span><span class="hljs-params">self, flight: </span><span class="hljs-built_in">str</span><span class="hljs-function">) -&gt; tuple[datetime.datetime, Status]:</span>
        key = <span class="hljs-string">f"flightno:</span><span class="hljs-subst">{flight}</span><span class="hljs-string">"</span>
        value = self.redis.get(key).decode(<span class="hljs-string">"utf-8"</span>)
        text_timestamp, text_status = value.split(<span class="hljs-string">"|"</span>)
        timestamp = datetime.datetime.fromisoformat(text_timestamp)
        status = Status(text_status)
        <span class="hljs-keyword">return</span> timestamp, status
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">Status</code> class defines an enumeration of four string values. We've provided symbolic names like <code class="Code-In-Text--PACKT-">Status.CANCELLED</code> so that we can have a finite, bounded domain of valid status values. The actual values stored in the database will be strings like <code class="Code-In-Text--PACKT-">"CANCELLED" </code>that – for now – happen<a id="_idIndexMarker1022"/> to match the symbols we'll be using in the <a id="_idIndexMarker1023"/>application. In the future, the domain of values may expand or change, but we'd like to keep our application's symbolic names separate from the strings that appear in the database. It's common to use numeric codes with <code class="Code-In-Text--PACKT-">Enum</code>, but they can be difficult to remember.</p>
    <p class="normal">There are a lot of things we ought to test for in the <code class="Code-In-Text--PACKT-">change_status()</code> method. We check to be sure the <code class="Code-In-Text--PACKT-">status</code> argument value really is a valid instance of the <code class="Code-In-Text--PACKT-">Status</code> enumeration, but we could do more. We should check that it raises the appropriate error if the <code class="Code-In-Text--PACKT-">flight</code> argument value isn't sensible. More importantly, we need a test to prove that the key and value have the correct formatting when the <code class="Code-In-Text--PACKT-">set()</code> method is called on the <code class="Code-In-Text--PACKT-">redis</code> object.</p>
    <p class="normal">One thing we don't have to check in our unit tests, however, is that the <code class="Code-In-Text--PACKT-">redis</code> object is storing the data properly. This is something that absolutely should be tested in integration or application testing, but at the unit test level, we can assume that the <code class="Code-In-Text--PACKT-">py-redis</code> developers have tested their code and that this method does what we want it to. As a rule, unit tests should be self-contained; the unit under test should be isolated from outside resources, such as a running Redis instance.</p>
    <p class="normal">Instead of integrating with a Redis server, we only need to test that the <code class="Code-In-Text--PACKT-">set()</code> method was called the appropriate number of times and with the appropriate arguments. We can use <code class="Code-In-Text--PACKT-">Mock()</code> objects in our tests to replace the troublesome method with an object we can introspect. The following example illustrates the use of <code class="Code-In-Text--PACKT-">Mock</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> datetime
<span class="hljs-keyword">import</span> flight_status_redis
<span class="hljs-keyword">from</span> unittest.mock <span class="hljs-keyword">import</span> Mock, patch, call
<span class="hljs-keyword">import</span> pytest
<span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">mock_redis</span><span class="hljs-function">() -&gt; Mock:</span>
    mock_redis_instance = Mock(<span class="hljs-built_in">set</span>=Mock(return_value=<span class="hljs-literal">True</span>))
    <span class="hljs-keyword">return</span> mock_redis_instance
<span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">tracker</span><span class="hljs-function">(</span>
<span class="hljs-params">    monkeypatch: pytest.MonkeyPatch, mock_redis: Mock</span>
<span class="hljs-function">) -&gt; flight_status_redis.FlightStatusTracker:</span>
    fst = flight_status_redis.FlightStatusTracker()
    monkeypatch.<span class="hljs-built_in">setattr</span>(fst, <span class="hljs-string">"redis"</span>, mock_redis)
    <span class="hljs-keyword">return</span> fst
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_monkeypatch_class</span><span class="hljs-function">(</span>
<span class="hljs-params">    tracker: flight_status_redis.FlightStatusTracker, mock_redis: Mock</span>
<span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">with</span> pytest.raises(ValueError) <span class="hljs-keyword">as</span> ex:
        tracker.change_status(<span class="hljs-string">"AC101"</span>, <span class="hljs-string">"lost"</span>)
    <span class="hljs-keyword">assert</span> ex.value.args[<span class="hljs-number">0</span>] == <span class="hljs-string">"'lost' is not a valid Status"</span>
    <span class="hljs-keyword">assert</span> mock_redis.<span class="hljs-built_in">set</span>.call_count == <span class="hljs-number">0</span>
</code></pre>
    <p class="normal">This test <a id="_idIndexMarker1024"/>uses<a id="_idIndexMarker1025"/> the <code class="Code-In-Text--PACKT-">raises()</code> context manager to make sure the correct exception is raised when an inappropriate argument is passed in. In addition, it creates a <code class="Code-In-Text--PACKT-">Mock</code> object for the <code class="Code-In-Text--PACKT-">redis</code> instance that the <code class="Code-In-Text--PACKT-">FlightStatusTracker</code> will use. </p>
    <p class="normal">The mock object contains an attribute, <code class="Code-In-Text--PACKT-">set</code>, which is a mock method that will always return <code class="Code-In-Text--PACKT-">True</code>. The test, however, makes sure the <code class="Code-In-Text--PACKT-">redis.set()</code> method is never called. If it is, it means there is a bug in our exception handling code.</p>
    <p class="normal">Note the navigation into the mock object. We use <code class="Code-In-Text--PACKT-">mock_redis.set</code> to examine the mocked <code class="Code-In-Text--PACKT-">set()</code> method of a <code class="Code-In-Text--PACKT-">Mock</code> object created by the <code class="Code-In-Text--PACKT-">mock_redis</code> fixture. The <code class="Code-In-Text--PACKT-">call_count</code> is an attribute that all <code class="Code-In-Text--PACKT-">Mock</code> objects maintain.</p>
    <p class="normal">While we can use code like <code class="Code-In-Text--PACKT-">flt.redis = mock_redis</code> to replace a real object with a <code class="Code-In-Text--PACKT-">Mock</code> object during a test, there is potential for problems. Simply replacing a value or even replacing a class method can only work for objects that are destroyed and created for each test function. If we need to patch items at the module level, the module isn't going to be reimported. A much more general solution is to use a patcher to inject a <code class="Code-In-Text--PACKT-">Mock</code> object temporarily. In this example, we used the <code class="Code-In-Text--PACKT-">monkeypatch</code> fixture of <code class="Code-In-Text--PACKT-">pytest</code> to make a temporary change to the <code class="Code-In-Text--PACKT-">FlightStatusTracker</code> object. A <code class="Code-In-Text--PACKT-">monkeypatch</code> has its own automatic teardown at the end of a test, allowing us to use monkeypatched modules and classes without breaking other tests.</p>
    <p class="normal">This test case will be flagged by <strong class="" style="font-style: italic;">mypy</strong>. The <strong class="" style="font-style: italic;">mypy</strong> tool will object to using a string argument value for the status parameter of the <code class="Code-In-Text--PACKT-">change_status()</code> function; this clearly must be an<a id="_idIndexMarker1026"/> instance<a id="_idIndexMarker1027"/> of the <code class="Code-In-Text--PACKT-">Status</code> enumeration. A special comment can be added to silence the <strong class="" style="font-style: italic;">mypy</strong> argument type check, <code class="Code-In-Text--PACKT-"># type: ignore [arg-type]</code>.</p>
    <h2 id="_idParaDest-289" class="title">Additional patching techniques</h2>
    <p class="normal">In some cases, we<a id="_idIndexMarker1028"/> only need to inject a special function or method for the duration of a single test. We may not really be creating a sophisticated <code class="Code-In-Text--PACKT-">Mock</code> object that's used in multiple tests. We may only need a small <code class="Code-In-Text--PACKT-">Mock</code> for a single test. In this case, we may not need to use all the features of the <code class="Code-In-Text--PACKT-">monkeypatch</code> fixture, either. For example, if we want to test the timestamp formatting in the <code class="Code-In-Text--PACKT-">Mock</code> method, we need to know exactly what <code class="Code-In-Text--PACKT-">datetime.datetime.now()</code> is going to return. However, this value changes from run to run. We need some way to pin it to a specific datetime value so we can test it deterministically.</p>
    <p class="normal">Temporarily setting a library function to a specific value is one place where patching is essential. In addition to the <code class="Code-In-Text--PACKT-">monkeypatch</code> fixture, the <code class="Code-In-Text--PACKT-">unittest.mock</code> library provides a <code class="Code-In-Text--PACKT-">patch</code> context manager. This context manager allows us to replace attributes on existing libraries with mock objects. When the context manager exits, the original attribute is automatically restored so as not to impact other test cases. Here's an example:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def </span><span class="hljs-title">test_patch_class</span><span class="hljs-function">(</span>
<span class="hljs-keyword">    </span><span class="hljs-params">tracker: flight_status_redis.FlightStatusTracker, mock_redis: Mock</span>
<span class="hljs-function">) -&gt;</span><span class="hljs-keyword"> None</span><span class="hljs-function">:</span>
<span class="hljs-keyword">    </span>fake_now = datetime.datetime<span class="hljs-keyword">(</span><span class="hljs-number">2020</span>,<span class="hljs-keyword"> </span><span class="hljs-number">10</span>,<span class="hljs-keyword"> </span><span class="hljs-number">26</span>,<span class="hljs-keyword"> </span><span class="hljs-number">23</span>,<span class="hljs-keyword"> </span><span class="hljs-number">24</span>,<span class="hljs-keyword"> </span><span class="hljs-number">25</span><span class="hljs-keyword">)</span>
<span class="hljs-keyword">    </span>utc = datetime.timezone.utc
<span class="hljs-keyword">    with </span>patch(<span class="hljs-string">"flight_status_redis.datetime"</span>)<span class="hljs-keyword"> as </span>mock_datetime:
<span class="hljs-keyword">        </span>mock_datetime.datetime = Mock(now=Mock(return_value=fake_now))
<span class="hljs-keyword">        </span>mock_datetime.timezone = Mock(utc=utc)
<span class="hljs-keyword">        </span>tracker.change_status(<span class="hljs-keyword">
        </span><span class="hljs-string">"AC101"</span>, flight_status_redis.Status.ON_TIME)
<span class="hljs-keyword">    </span>mock_datetime.datetime.now.assert_called_once_with(tz=utc)
<span class="hljs-keyword">    </span>expected =<span class="hljs-keyword"> </span><span class="hljs-string">f"2020-10-26T23:24:25|ON TIME"</span>
<span class="hljs-keyword">    </span>mock_redis.<span class="hljs-built_in">set</span>.assert_called_once_with(<span class="hljs-string">"flightno:AC101"</span>, expected)
</code></pre>
    <p class="normal">We don't want our test results to depend on the computer's clock, so we built the <code class="Code-In-Text--PACKT-">fake_now</code> object with a specific date and time we can expect to see in our test results. This kind of replacement is very common in unit tests.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">patch()</code> context manager returns a <code class="Code-In-Text--PACKT-">Mock</code> object that was used to replace some other object. In this case, the object being replaced is the entire <code class="Code-In-Text--PACKT-">datetime</code> module inside the <code class="Code-In-Text--PACKT-">flight_status_redis</code> module. When we assigned <code class="Code-In-Text--PACKT-">mock_datetime.datetime</code>, we replaced the <code class="Code-In-Text--PACKT-">datetime</code> class inside the mocked <code class="Code-In-Text--PACKT-">datetime</code> module with our own <code class="Code-In-Text--PACKT-">Mock</code> object; this new <code class="Code-In-Text--PACKT-">Mock</code> defines one attribute, <code class="Code-In-Text--PACKT-">now</code>. Because the <code class="Code-In-Text--PACKT-">utcnow</code> attribute is a <code class="Code-In-Text--PACKT-">Mock</code> that returns a value, it behaves like a method and returns a fixed, known value, <code class="Code-In-Text--PACKT-">fake_now</code>. When the interpreter exits the <code class="Code-In-Text--PACKT-">patch</code> context manager, the original <code class="Code-In-Text--PACKT-">datetime</code> functionality is restored.</p>
    <p class="normal">After calling our <code class="Code-In-Text--PACKT-">change_status()</code> method with known values, we use the <code class="Code-In-Text--PACKT-">assert_called_once_with()</code> method of the <code class="Code-In-Text--PACKT-">Mock</code> object to ensure that the <code class="Code-In-Text--PACKT-">now()</code> function was indeed called exactly once with the expected arguments (no arguments, in this case). We also use the <code class="Code-In-Text--PACKT-">assert_called_once_with()</code> method on the <code class="Code-In-Text--PACKT-">Mock</code> <code class="Code-In-Text--PACKT-">redis.set</code> method to make sure it called with arguments that were formatted as we expected them to be. In addition to the "called once with," we can also check the exact list of <a id="_idIndexMarker1029"/>mock calls that were made. This sequence is available in the <code class="Code-In-Text--PACKT-">mock_calls</code> attribute of a <code class="Code-In-Text--PACKT-">Mock</code> object.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Mocking dates so you can have deterministic test results is a common patching scenario. The technique applies to any stateful object, but is particularly important for external resources (like the clock) that exist outside our application.</p>
      <p class="Information-Box--PACKT-">For the special case of <code class="Code-In-Text--PACKT-">datetime</code> and <code class="Code-In-Text--PACKT-">time</code>, packages like <code class="Code-In-Text--PACKT-">freezegun</code> can simplify the monkeypatching required so that a known, fixed date is available.</p>
    </div>
    <p class="normal">The patches we made in this example are intentionally sweeping. We replaced the entire <code class="Code-In-Text--PACKT-">datetime</code> module with a <code class="Code-In-Text--PACKT-">Mock</code> object. This will tend to expose unexpected uses of datetime features; if any method not specifically mocked (like the <code class="Code-In-Text--PACKT-">now()</code> method was mocked) gets used, it will return <code class="Code-In-Text--PACKT-">Mock</code> objects that are likely to crash code under test.</p>
    <p class="normal">The previous example also shows how testability needs to guide our API design. The <code class="Code-In-Text--PACKT-">tracker</code> fixture has an interesting problem: it creates a <code class="Code-In-Text--PACKT-">FlightStatusTracker</code> object, which constructs a Redis connection. After the Redis connection is built, we replace it. When we run tests for this code, however, we will discover that each test will create an unused Redis connection. Some tests may fail if there is no Redis server running. Because this test requires external resources, it's not a proper unit test. There are two possible layers of failure: the code doesn't work, or the unit tests don't work because of some hidden external dependency. This can become a nightmare to sort out.</p>
    <p class="normal">We could solve this problem by mocking the <code class="Code-In-Text--PACKT-">redis.Redis</code> class. A <code class="Code-In-Text--PACKT-">Mock</code> for this class can return a mock instance in a <code class="Code-In-Text--PACKT-">setUp</code> method. A better idea, however, might be to rethink our implementation more fundamentally. Instead of constructing the <code class="Code-In-Text--PACKT-">redis</code> instance inside <code class="Code-In-Text--PACKT-">__init__</code>, we should allow the user to pass one in, as in the following example:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span>
<span class="hljs-params">        self, </span>
<span class="hljs-params">        redis_instance: Optional[redis.Connection] = </span><span class="hljs-literal">None</span>
<span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    self.redis = (
        redis_instance
        <span class="hljs-keyword">if</span> redis_instance
        <span class="hljs-keyword">else</span> redis.Redis(host=<span class="hljs-string">"127.0.0.1"</span>, port=<span class="hljs-number">6379</span>, db=<span class="hljs-number">0</span>)
    )
</code></pre>
    <p class="normal">This allows us<a id="_idIndexMarker1030"/> to pass a connection in when we are testing so that the <code class="Code-In-Text--PACKT-">Redis</code> method never gets constructed. Additionally, it allows any client code that talks to <code class="Code-In-Text--PACKT-">FlightStatusTracker</code> to pass in their own <code class="Code-In-Text--PACKT-">redis</code> instance. There are a variety of reasons they might want to do this: they may have already constructed one for other parts of their code; they may have created an optimized implementation of the <code class="Code-In-Text--PACKT-">redis</code> API; perhaps they have one that logs metrics to their internal monitoring systems. By writing a unit test, we've uncovered a use case that makes our API more flexible from the start, rather than waiting for clients to demand we support their exotic needs.</p>
    <p class="normal">This has been a brief introduction to the wonders of mocking code. Mock objects have been part of the standard <code class="Code-In-Text--PACKT-">unittest</code> library since Python 3.3. As you see from these examples, they can also be used with <code class="Code-In-Text--PACKT-">pytest</code> and other test frameworks. Mock objects have other, more advanced features that you may need to take advantage of as your code becomes more complicated. For example, you can use the <code class="Code-In-Text--PACKT-">spec</code> argument to invite a mock to imitate an existing class, so that it raises an error if code tries to access an attribute that does not exist on the imitated class. You can also construct mock methods that return different arguments each time they are called by passing a list as the <code class="Code-In-Text--PACKT-">side_effect</code> argument. The <code class="Code-In-Text--PACKT-">side_effect</code> parameter is quite versatile; you can also use it to execute arbitrary functions when the mock is called or to raise an exception.</p>
    <p class="normal">The point of unit testing is to be sure that each "unit" works in isolation. Often, a unit is an individual class, and we'll need to mock the collaborators. In some cases, there's a composition of classes or a Façade for which a number of application classes can be tested together as a "unit." There's a clear boundary, however, when applying mocks inappropriately. If we need to look inside some external module or class (one we didn't write) to see how to mock its dependencies, we've taken a step too far.</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">Don't examine the implementation details of classes outside your application to see how to mock their collaborators; instead, mock the entire class you depend on.</p>
      <p class="Tip--PACKT-">This generally leads to providing a mock for an entire database or external API.</p>
    </div>
    <p class="normal">We can extend this idea of imitating objects one step further. There's a specialized fixture we use <a id="_idIndexMarker1031"/>when we want to ensure data has been left untouched. We'll look at this next.</p>
    <h2 id="_idParaDest-290" class="title">The sentinel object</h2>
    <p class="normal">In many designs, we'll have a class with attribute <a id="_idIndexMarker1032"/>values that can be provided as parameters to other objects, without really doing any processing on those objects. For example, we may provide a <code class="Code-In-Text--PACKT-">Path</code> object to a class, and the class then provides this <code class="Code-In-Text--PACKT-">Path</code> object to an OS function; the class we designed doesn't do anything more than save the object. From a unit testing perspective, the object is "opaque" to the class we're testing – the class we're writing doesn't look inside the object at state or methods.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">unittest.mock</code> module provides a handy object, the <code class="Code-In-Text--PACKT-">sentinel</code>, that can be used to create opaque objects that we can use in test cases to be sure that the application stored and forwarded the object untouched.</p>
    <p class="normal">Here's a class, <code class="Code-In-Text--PACKT-">FileChecksum</code>, that saves an object computed by the <code class="Code-In-Text--PACKT-">sha256()</code> function of the <code class="Code-In-Text--PACKT-">hashlib</code> module:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">FileChecksum</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, source: Path</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        self.source = source
        self.checksum = hashlib.sha256(source.read_bytes())
</code></pre>
    <p class="normal">We can isolate this code from the other modules for unit testing purposes. We'll create a <code class="Code-In-Text--PACKT-">Mock</code> for the <code class="Code-In-Text--PACKT-">hashlib</code> module, and we'll use a <code class="Code-In-Text--PACKT-">sentinel</code> for the result:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> unittest.mock <span class="hljs-keyword">import</span> Mock, sentinel
<span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">mock_hashlib</span><span class="hljs-function">(</span><span class="hljs-params">monkeypatch</span><span class="hljs-function">) -&gt; Mock:</span>
    mocked_hashlib = Mock(sha256=Mock(return_value=sentinel.checksum))
    monkeypatch.<span class="hljs-built_in">setattr</span>(checksum_writer, <span class="hljs-string">"hashlib"</span>, mocked_hashlib)
    <span class="hljs-keyword">return</span> mocked_hashlib
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_file_checksum</span><span class="hljs-function">(</span><span class="hljs-params">mock_hashlib, tmp_path</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    source_file = tmp_path / <span class="hljs-string">"some_file"</span>
    source_file.write_text(<span class="hljs-string">""</span>)
    cw = checksum_writer.FileChecksum(source_file)
    <span class="hljs-keyword">assert</span> cw.source == source_file
    <span class="hljs-keyword">assert</span> cw.checksum == sentinel.checksum
</code></pre>
    <p class="normal">Our <code class="Code-In-Text--PACKT-">mocked_hashlib</code> object provides a method, <code class="Code-In-Text--PACKT-">sha256</code>, that returns the unique <code class="Code-In-Text--PACKT-">sentinel.checksum</code> object. This is an object, created by the <code class="Code-In-Text--PACKT-">sentinel</code> object, with very few methods or attributes. Any attribute name can be created as a unique object; we've chosen "checksum" here. The resulting object is designed for equality checks and nothing else. A <code class="Code-In-Text--PACKT-">sentinel</code> in a test case is a way to be sure the <code class="Code-In-Text--PACKT-">FileChecksum</code> class doesn't do anything wrong or unexpected with<a id="_idIndexMarker1033"/> the objects it was given.</p>
    <p class="normal">The test case creates a <code class="Code-In-Text--PACKT-">FileChecksum</code> object. The test confirms that the file was the provided argument value, <code class="Code-In-Text--PACKT-">source_file</code>. The test also confirms that the checksum matched the original <code class="Code-In-Text--PACKT-">sentinel</code> object. This confirms that the <code class="Code-In-Text--PACKT-">FileChecksum</code> instance stored the checksum results properly and presented the result as the value of the <code class="Code-In-Text--PACKT-">checksum</code> attribute.</p>
    <p class="normal">If we change the implementation of the <code class="Code-In-Text--PACKT-">FileChecksum</code> class to – for example – use properties instead of direct access to the attribute, the test will confirm the checksum was treated as an opaque object that came from the <code class="Code-In-Text--PACKT-">hashlib.sha256()</code> function and was not processed in any other way.</p>
    <p class="normal">We've looked at two unit testing frameworks: the built-in <code class="Code-In-Text--PACKT-">unittest</code> package and the external <code class="Code-In-Text--PACKT-">pytest</code> package. They both provide ways for us to write clear, simple tests that can confirm that our application works. It's important to have a clear objective defining the required amount of testing. Python has an easy-to-use coverage package that gives us one objective measure of test quality.</p>
    <h1 id="_idParaDest-291" class="title">How much testing is enough?</h1>
    <p class="normal">We've already <a id="_idIndexMarker1034"/>established that untested code is broken code. But how can we tell how well our code is tested? How do we know how much of our code is actually being tested and how much is broken? The first question is the more important one, but it's hard to answer. Even if we know we have tested every line of code in our application, we do not know that we have tested it properly. For example, if we write a <code class="Code-In-Text--PACKT-">stats</code> test that only checks what happens when we provide a list of integers, it may still fail spectacularly if used on a list of floats, strings, or self-made objects. The onus of designing complete test suites still lies with the programmer.</p>
    <p class="normal">The second question – how much of our code is actually being tested – is easy to verify. <strong class="keyword">Code coverage</strong> is a count of the number of lines of code that are executed by a program. From the number of lines that are in the program as a whole, we know what percentage of the code was really tested or covered. If we additionally have an indicator that tells us which lines were not tested, we can more easily write new tests to ensure those lines are less likely to harbor problems.</p>
    <p class="normal">The most popular tool for testing code coverage is called, memorably enough, <code class="Code-In-Text--PACKT-">coverage.py</code>. It can be installed like most other third-party libraries, using the <code class="Code-In-Text--PACKT-">python -m pip install coverage</code> command.</p>
    <p class="normal">We don't have space to cover all the details of the coverage API, so we'll just look at a few typical examples. If we have a Python script that runs all our unit tests for us (this could be using <code class="Code-In-Text--PACKT-">unittest.main</code>,  <code class="Code-In-Text--PACKT-">unittest</code> <code class="Code-In-Text--PACKT-">discover</code>, or <code class="Code-In-Text--PACKT-">pytest</code>), we can use the following command to perform coverage analysis for a specific unit test file:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">%</span><span class="bash"> </span><span class="hljs-con-built_in">export</span><span class="bash"> PYTHONPATH=$(</span><span class="hljs-con-built_in">pwd</span><span class="bash">)/src:</span><span class="hljs-con-variable">$PYTHONPATH</span>
<span class="hljs-con-meta">%</span><span class="bash"> coverage run -m pytest tests/test_coverage.py</span>
</code></pre>
    <p class="normal">This command will create a file named <code class="Code-In-Text--PACKT-">.coverage</code>, which holds the data from the run.</p>
    <p class="normal">Windows Powershell users can do the following:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;</span><span class="bash"> </span><span class="hljs-con-variable">$ENV</span><span class="bash">:PYTHONPATH = </span><span class="hljs-con-string">"</span><span class="hljs-con-variable">$pwd</span><span class="hljs-con-string">\src"</span><span class="bash"> + </span><span class="hljs-con-string">";"</span><span class="bash"> + </span><span class="hljs-con-variable">$PYTHONPATH</span>
<span class="hljs-con-meta">&gt;</span><span class="bash"> coverage run -m pytest tests/test_coverage.py</span>
</code></pre>
    <p class="normal">We can now use the <code class="Code-In-Text--PACKT-">coverage report</code> command to get an analysis of the code coverage:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">%</span><span class="bash"> coverage report</span>
</code></pre>
    <p class="normal">The resulting output should be as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">Name                     Stmts   Miss  Cover
--------------------------------------------
src/stats.py                19     11    42%
tests/test_coverage.py       7      0   100%
--------------------------------------------
TOTAL                       26     11    58%
</code></pre>
    <p class="normal">This report lists the files that were executed (our unit test and the module it imported), the number of lines of code in each file, and the number of lines of code that were executed by the test. The two numbers are then combined to show the amount of code coverage. Not surprisingly, the entire test was executed, but only a fraction of the <code class="Code-In-Text--PACKT-">stats</code> module was exercised.</p>
    <p class="normal">If we pass the <code class="Code-In-Text--PACKT-">-m</code> option to the <code class="Code-In-Text--PACKT-">report</code> command, it will add a column that identifies the lines that are missing from the test execution. The output looks as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">Name                     Stmts   Miss  Cover   Missing
------------------------------------------------------
src/stats.py                19     11    42%   18-23, 26-31
tests/test_coverage.py       7      0   100%
------------------------------------------------------
TOTAL                       26     11    58%
</code></pre>
    <p class="normal">The ranges of lines<a id="_idIndexMarker1035"/> listed here identify the lines in the <code class="Code-In-Text--PACKT-">stats</code> module that were not executed during the test run.</p>
    <p class="normal">The example code uses the same <code class="Code-In-Text--PACKT-">stats</code> module we created earlier in this chapter. However, it deliberately uses a single test that fails to test a lot of code in the file. Here's the test:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">from</span> stats <span class="hljs-keyword">import</span> StatsList
<span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">valid_stats</span><span class="hljs-function">() -&gt; StatsList:</span>
    <span class="hljs-keyword">return</span> StatsList([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_mean</span><span class="hljs-function">(</span><span class="hljs-params">valid_stats: StatsList</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    <span class="hljs-keyword">assert</span> valid_stats.mean() == <span class="hljs-number">2.5</span>
</code></pre>
    <p class="normal">This test doesn't test the median or mode functions, which correspond to the line numbers that the coverage output told us were missing.</p>
    <p class="normal">The textual report provides sufficient information, but if we use the <code class="Code-In-Text--PACKT-">coverage html</code> command, we can get an even more useful interactive HTML report, which we can view in a web browser. The interactive report has a number of useful filters we can enable. The web page even highlights which lines in the source code were and were not tested.</p>
    <p class="normal">Here's how<a id="_idIndexMarker1036"/> it looks:</p>
    <figure class="mediaobject"><img src="../Images/B17070_13_01.png" alt="A picture containing graphical user interface  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.1: Interactive HTML coverage report</p>
    <p class="normal">We created the HTML report using the <code class="Code-In-Text--PACKT-">coverage</code> module with <code class="Code-In-Text--PACKT-">pytest</code>. To do this, we previously installed the <code class="Code-In-Text--PACKT-">pytest</code> plugin for code coverage, using <code class="Code-In-Text--PACKT-">python -m pip install pytest-cov</code>. The plugin adds several command-line options to <code class="Code-In-Text--PACKT-">pytest</code>, the most useful being <code class="Code-In-Text--PACKT-">--cover-report</code>, which can be set to <code class="Code-In-Text--PACKT-">html</code>, <code class="Code-In-Text--PACKT-">report</code>, or <code class="Code-In-Text--PACKT-">annotate</code> (the latter actually modifies the original source code to highlight any lines that were not covered).</p>
    <p class="normal">It can be helpful to include more than the <code class="Code-In-Text--PACKT-">src</code> directory tree in coverage analysis. A large project may have a complex tests directory, including additional tools and supporting libraries. As the project evolves, there may be some test or support code that's obsolete, but hasn't been cleaned up yet.</p>
    <p class="normal">Unfortunately, if we could somehow run a coverage report on this section of the chapter, we'd find that we have not covered most of what there is to know about code coverage! It is possible to use the coverage API to manage code coverage from within our own programs (or test suites), and <code class="Code-In-Text--PACKT-">coverage.py</code> accepts numerous configuration options that we haven't touched on. We also haven't discussed the difference between statement coverage and branch coverage (the latter is much more useful and is the default in recent versions of <code class="Code-In-Text--PACKT-">coverage.py</code>), or other styles of code coverage.</p>
    <p class="normal">Bear in mind that while 100 percent code coverage is a goal that we should all strive for, 100 percent coverage is not enough! Just because a statement was tested does not mean that it was<a id="_idIndexMarker1037"/> tested properly for all possible inputs. The boundary value analysis technique includes looking at five values to bracket the edge cases: a value below the minimum, the minimum, in the middle somewhere, the maximum, and a value above the maximum. For non-numeric types, there may not be a tidy range, but the advice can be adapted to other data structures. For lists and mappings, for example, this advice often suggests testing with empty lists or mapping with unexpected<a id="_idIndexMarker1038"/> keys. The Hypothesis package (<a href="https://pypi.org/project/hypothesis/"><span class="url">https://pypi.org/project/hypothesis/</span></a>) can help with more sophisticated test cases.</p>
    <p class="normal">It's difficult to emphasize how important testing is. The test-driven development approach encourages us to describe our software via visible, testable objectives. We have to decompose complex problems into discrete, testable solutions. It's not uncommon to have more lines of test code than actual application code. A short but confusing algorithm is sometimes best explained through examples, and each example should be a test case.</p>
    <h1 id="_idParaDest-292" class="title">Testing and development</h1>
    <p class="normal">One of the <a id="_idIndexMarker1039"/>many ways these unit tests can help is when debugging application problems. When each unit seems to work in isolation, any remaining problems will often be the result of an improperly used interface between components. When searching for the root cause of a problem, a suite of passing tests acts as a set of signposts, directing the developer into the wilderness of untested features in the borderlands between components.</p>
    <p class="normal">When a problem is found, the cause is often one of the following:</p>
    <ul>
      <li class="bullet">Someone writing a new class failed to understand an interface with an existing class and used it incorrectly. This indicates a need for a new unit test to reflect the right way to use the interface. This new test should cause the new code to fail its expanded test suite. An integration test is also helpful, but not as important as the new unit test focused on interface details.</li>
      <li class="bullet">The interface was not spelled out in enough detail, and both parties using the interface need to reach an agreement on how the interface should be used. In this case, both sides of the interface will need additional unit tests to show what the interface should be. Both classes should fail these new unit tests; they can then be fixed. Additionally, an integration test can be used to confirm that the two classes agree.</li>
    </ul>
    <p class="normal">The idea here is to<a id="_idIndexMarker1040"/> use test cases to drive the development process. A "bug" or an "incident" needs to be translated into a test case that fails. Once we have a concrete expression of a problem in the form of a test case, we can create or revise software until all the tests pass.</p>
    <p class="normal">If bugs do occur, we'll often follow a test-driven plan, as follows:</p>
    <ol>
      <li class="numbered" value="1">Write a test (or multiple tests) that duplicates or proves the bug in question is occurring. This test will, of course, fail. In more complex applications, it may be difficult to find the exact steps to recreate a bug in an isolated unit of code; finding this is valuable work, since it requires knowledge of the software, and captures the knowledge as a test scenario.</li>
      <li class="numbered">Then, write the code to make the tests stop failing. If the tests were comprehensive, the bug will be fixed, and we will know we didn't break something new while attempting to fix something.</li>
    </ol>
    <p class="normal">Another benefit of test-driven development is the value of the test cases for further enhancement. Once the tests have been written, we can improve our code as much as we like and be confident that our changes didn't break anything we have been testing for. Furthermore, we know exactly when our refactor is finished: when the tests all pass.</p>
    <p class="normal">Of course, our tests may not comprehensively test everything we need them to; maintenance or code refactoring can still cause undiagnosed bugs that don't show up in testing. Automated tests are not foolproof. As E. W. Dijkstra said, "Program testing can be used to show the presence of bugs, but never to show their absence!" We need to have good reasons why our algorithm is correct, as well as test cases to show that it doesn't have any problems.</p>
    <h1 id="_idParaDest-293" class="title">Case study</h1>
    <p class="normal">We'll return to some material from an earlier chapter and apply some careful testing to be sure we've got a good, workable implementation. Back in <em class="chapterRef">Chapter 3</em>, <em class="italic">When Objects Are Alike</em>, we looked at the distance computations that are part of the <em class="italic">k</em>-nearest neighbors classifier. In that chapter, we looked at several computations that produced slightly different results:</p>
    <ul>
      <li class="bullet"><strong class="keyword">Euclidean distance</strong>: This <a id="_idIndexMarker1041"/>is the direct line from one sample to another.</li>
      <li class="bullet"><strong class="keyword">Manhattan distance</strong>: This<a id="_idIndexMarker1042"/> follows streets-and-avenues around a grid (like the city of Manhattan), adding up the steps required along a series of straight-line paths.</li>
      <li class="bullet"><strong class="keyword">Chebyshev distance</strong>: This is <a id="_idIndexMarker1043"/>the largest of the streets-and-avenues distances.</li>
      <li class="bullet"><strong class="keyword">Sorensen distance</strong>: This<a id="_idIndexMarker1044"/> is a variation of the Manhattan distance that weights nearby steps more heavily than distant steps. It tends to magnify small distances, making more subtle discriminations.</li>
    </ul>
    <p class="normal">These algorithms all produce distinct results from the same inputs; they all involve complex-looking math, and they all need to be tested in isolation to ensure we have implemented them correctly. We'll start with unit tests of the distances.</p>
    <h2 id="_idParaDest-294" class="title">Unit testing the distance classes</h2>
    <p class="normal">We need<a id="_idIndexMarker1045"/> to<a id="_idIndexMarker1046"/> create some test cases for each distance computation algorithm. When we look at the various equations, we can see that there are four pairs of relevant values from two samples: the sepal length and width, and the petal length and width. To be extremely thorough, we could create at least 16 distinct cases for each algorithm:</p>
    <ul>
      <li class="bullet"><strong class="keyword">Case 0</strong>: All four values are the same; the distance should be zero.</li>
      <li class="bullet"><strong class="keyword">Cases 1-4</strong>: One of the four values is different between the two samples. For example, a test sample might have measurements of <code class="Code-In-Text--PACKT-">("sepal_length": 5.1, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2</code>), where as a training sample might have measurements of (<code class="Code-In-Text--PACKT-">"sepal_length": 5.2, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2</code>); only one of these values is distinct.</li>
      <li class="bullet"><strong class="keyword">Cases 5-10</strong>: A pair of values is different.</li>
      <li class="bullet"><strong class="keyword">Cases 11-14</strong>: Three values are different between the two samples.</li>
      <li class="bullet"><strong class="keyword">Case 15</strong>: All four values are different.</li>
    </ul>
    <p class="normal">In addition, the concepts of equivalence partitioning and boundary value analysis suggest that we also need to locate values where there is a profound state change. For example, invalid values will raise exceptions, something that should also be tested. This can create a number of sub-cases within each of the cases enumerated above.</p>
    <p class="normal">We won't create all 16 cases for each of the four algorithms in this part of the case study. Instead, we'll take a close look at whether or not all 16 cases are really required. To get started, we'll limit ourselves to one case for each distance algorithm. This will be an example of case 15, where all four values of the two samples are different.</p>
    <p class="normal">With mathematical results, we need to compute the expected answers outside the software we're building. We can, of course, try to compute the expected answers with pencil and paper or a spreadsheet.</p>
    <p class="normal">One trick <a id="_idIndexMarker1047"/>that <a id="_idIndexMarker1048"/>can be helpful when working with more advanced math is to use the <code class="Code-In-Text--PACKT-">sympy</code> package as a way to check the math more carefully.</p>
    <p class="normal">For example, the Euclidean distance between a known sample, <em class="italic">k</em>, and an unknown sample, <em class="italic">u</em>, has the following formal definition:</p>
    <figure class="mediaobject"><img src="../Images/B17070_13_001.png" alt="" style="height: 3.5em;"/></figure>
    <p class="normal">This computes the distance among all four measurements. For example, the known sepal length is <em class="italic">k</em><sub class="" style="font-style: italic;">sl</sub>. The other attributes have similar names.</p>
    <p class="normal">While <code class="Code-In-Text--PACKT-">sympy</code> can do a great many things, we want to use it for two specific purposes:</p>
    <ol>
      <li class="numbered" value="1">To confirm that our Python version of the formula really is correct</li>
      <li class="numbered">To compute the expected results using specific variable substitutions</li>
    </ol>
    <p class="normal">We do this by using <code class="Code-In-Text--PACKT-">sympy</code> to perform the operations symbolically. Instead of plugging in specific floating-point values, we want to transform the Python expression into conventional mathematical notation.</p>
    <p class="normal">This is a test case that's applied to the design, not the implementation. It confirms the code's design is very likely to match the original intent. We've translated the nicely typeset names like <em class="italic">k</em><sub class="" style="font-style: italic;">sl</sub> for "known sepal length" into a Pythonic (but not as easy to read) <code class="Code-In-Text--PACKT-">k_sl</code>. Here's our interaction with <code class="Code-In-Text--PACKT-">sympy</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span><span class="python"> sympy </span><span class="hljs-con-keyword">import</span><span class="python"> *</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">ED, k_sl, k_pl, k_sw, k_pw, u_sl, u_pl, u_sw, u_pw = symbols(</span>
<span class="hljs-con-meta">...</span> <span class="python">    </span><span class="hljs-con-string">"ED, k_sl, k_pl, k_sw, k_pw, u_sl, u_pl, u_sw, u_pw"</span><span class="python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">ED = sqrt( (k_sl-u_sl)**</span><span class="hljs-con-number">2</span><span class="python"> + (k_pl-u_pl)**</span><span class="hljs-con-number">2</span><span class="python"> + (k_sw-u_sw)**</span><span class="hljs-con-number">2</span><span class="python"> + (k_pw-u_pw)**</span><span class="hljs-con-number">2</span><span class="python"> )</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">ED</span>
sqrt((k_pl - u_pl)**2 + (k_pw - u_pw)**2 + (k_sl - u_sl)**2 + (k_sw - u_sw)**2)
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">print(pretty(ED, use_unicode=</span><span class="hljs-con-literal">False</span><span class="python">))</span>
   ___________________________________________________________________
  /              2                2                2                2 
\/  (k_pl - u_pl)  + (k_pw - u_pw)  + (k_sl - u_sl)  + (k_sw - u_sw)  
</code></pre>
    <p class="normal">We imported <code class="Code-In-Text--PACKT-">sympy</code> and defined the batch of symbols that match the original formula. We need to<a id="_idIndexMarker1049"/> define <a id="_idIndexMarker1050"/>these objects so <code class="Code-In-Text--PACKT-">sympy</code> will work with them as mathematical symbols, not ordinary Python objects. Then, we did our best to translate the Euclidean distance formula from math into Python. It seems right, but we'd like to be sure.</p>
    <p class="normal">Note that when we asked for the value of <code class="Code-In-Text--PACKT-">ED</code>, we didn't see the results of a Python computation. Because we've defined the variables as symbols, <code class="Code-In-Text--PACKT-">sympy</code> builds a representation of the equation that we can work with.</p>
    <p class="normal">When we used the <code class="Code-In-Text--PACKT-">pretty()</code> function from <code class="Code-In-Text--PACKT-">sympy</code>, it displayed an ASCII art version of our expression, which looks a lot like the original. We used the <code class="Code-In-Text--PACKT-">use_unicode=False</code> option because that looked the best in this book. When printed with an appropriate font, the <code class="Code-In-Text--PACKT-">use_unicode=True</code> version may be easier to read.</p>
    <p class="normal">The formula is something we can share with experts to be sure our test cases really do properly describe the behavior of this particular class. Because the formula looks right, we can evaluate it with concrete values:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">e = ED.subs(</span><span class="hljs-con-built_in">dict</span><span class="python">(</span>
<span class="hljs-con-meta">...</span> <span class="python">    k_sl=</span><span class="hljs-con-number">5.1</span><span class="python">, k_sw=</span><span class="hljs-con-number">3.5</span><span class="python">, k_pl=</span><span class="hljs-con-number">1.4</span><span class="python">, k_pw=</span><span class="hljs-con-number">0.2</span><span class="python">,</span>
<span class="hljs-con-meta">...</span> <span class="python">    u_sl=</span><span class="hljs-con-number">7.9</span><span class="python">, u_sw=</span><span class="hljs-con-number">3.2</span><span class="python">, u_pl=</span><span class="hljs-con-number">4.7</span><span class="python">, u_pw=</span><span class="hljs-con-number">1.4</span><span class="python">,</span>
<span class="hljs-con-meta">...</span> <span class="python">))</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">e.evalf(</span><span class="hljs-con-number">9</span><span class="python">)</span>
4.50111097
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">subs()</code> method substitutes values for the symbols in the formula. We then use the <code class="Code-In-Text--PACKT-">evalf()</code> method to evaluate the result as a floating-point number. We can use this to create a unit test case for the class.</p>
    <p class="normal">Before we look at the test case, here's an implementation of the Euclidean distance class. As an optimization, this uses <code class="Code-In-Text--PACKT-">math.hypot()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">ED</span><span class="hljs-class">(</span><span class="hljs-params">Distance</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">distance</span><span class="hljs-function">(</span><span class="hljs-params">self, s1: Sample, s2: Sample</span><span class="hljs-function">) -&gt; float:</span>
        <span class="hljs-keyword">return</span> hypot(
            s1.sepal_length - s2.sepal_length,
            s1.sepal_width - s2.sepal_width,
            s1.petal_length - s2.petal_length,
            s1.petal_width - s2.petal_width,
        )
</code></pre>
    <p class="normal">It seems like<a id="_idIndexMarker1051"/> this implementation matches the math. The best way to check <a id="_idIndexMarker1052"/>is to create an automated test. Recall that tests often have a <code class="Code-In-Text--PACKT-">GIVEN</code>-<code class="Code-In-Text--PACKT-">WHEN</code>-<code class="Code-In-Text--PACKT-">THEN</code> outline. We can expand this to the following conceptual scenario:</p>
    <pre class="programlisting con"><code class="hljs-con">Scenario: Euclidean Distance Computation
  Given an unknown sample, U, and a known sample, K
   When we compute the Euclidean Distance between them
   Then we get the distance, ED.
</code></pre>
    <p class="normal">We can provide the values used in the symbolic computation for <code class="Code-In-Text--PACKT-">U</code>, <code class="Code-In-Text--PACKT-">K</code>, and the expected distance. We'll start with a test fixture that supports the <code class="Code-In-Text--PACKT-">GIVEN</code> step:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">known_unknown_example_15</span><span class="hljs-function">() -&gt; Known_Unknown:</span>
    known_row: Row = {
        <span class="hljs-string">"species"</span>: <span class="hljs-string">"Iris-setosa"</span>,
        <span class="hljs-string">"sepal_length"</span>: <span class="hljs-number">5.1</span>,
        <span class="hljs-string">"sepal_width"</span>: <span class="hljs-number">3.5</span>,
        <span class="hljs-string">"petal_length"</span>: <span class="hljs-number">1.4</span>,
        <span class="hljs-string">"petal_width"</span>: <span class="hljs-number">0.2</span>,
    }
    k = TrainingKnownSample(**known_row)
    unknown_row = {
        <span class="hljs-string">"sepal_length"</span>: <span class="hljs-number">7.9</span>,
        <span class="hljs-string">"sepal_width"</span>: <span class="hljs-number">3.2</span>,
        <span class="hljs-string">"petal_length"</span>: <span class="hljs-number">4.7</span>,
        <span class="hljs-string">"petal_width"</span>: <span class="hljs-number">1.4</span>,
    }
    u = UnknownSample(**unknown_row)
    <span class="hljs-keyword">return</span> k, u
</code></pre>
    <p class="normal">We've created a <code class="Code-In-Text--PACKT-">TrainingKnownSample</code> and an <code class="Code-In-Text--PACKT-">UnknownSample</code> object that we can use in subsequent tests. This fixture definition<a id="_idIndexMarker1053"/> depends on a number of important type hints and <a id="_idIndexMarker1054"/>definitions:</p>
    <pre class="programlisting code"><code class="hljs-code">From __future__ <span class="hljs-keyword">import</span> annotations
<span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> TrainingKnownSample, UnknownSample
<span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> CD, ED, MD, SD
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Tuple, TypedDict
Known_Unknown = Tuple[TrainingKnownSample, UnknownSample]
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">Row</span><span class="hljs-class">(</span><span class="hljs-params">TypedDict</span><span class="hljs-class">):</span>
    species: <span class="hljs-built_in">str</span>
    sepal_length: <span class="hljs-built_in">float</span>
    sepal_width: <span class="hljs-built_in">float</span>
    petal_length: <span class="hljs-built_in">float</span>
    petal_width: <span class="hljs-built_in">float</span>
</code></pre>
    <p class="normal">We can provide the distance computation as a <code class="Code-In-Text--PACKT-">WHEN</code> step, and a final <code class="Code-In-Text--PACKT-">THEN</code> comparison in an <code class="Code-In-Text--PACKT-">assert</code> statement. We need to use an <code class="Code-In-Text--PACKT-">approx</code> object for comparison because we're working with floating-point values, and exact comparisons rarely work out well.</p>
    <p class="normal">For this application, the number of decimal places in the test case seems excessive. We've left all the digits so the values will fit with the defaults used by <code class="Code-In-Text--PACKT-">approx</code>, which is a relative error of 1 x 10<sup class="Superscript--PACKT-">-6</sup>, or <code class="Code-In-Text--PACKT-">1e-6</code> in Python notation. Here's the rest of the test case:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_ed</span><span class="hljs-function">(</span><span class="hljs-params">known_unknown_example_15: Known_Unknown</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    k, u = known_unknown_example_15
    <span class="hljs-keyword">assert</span> ED().distance(k, u) == pytest.approx(<span class="hljs-number">4.50111097</span>)
</code></pre>
    <p class="normal">This is pleasantly short and to the point. Given two samples, the distance result should match what we computed by hand, or computed using <code class="Code-In-Text--PACKT-">sympy</code>.</p>
    <p class="normal">Each of the distance classes needs a test case. Here are two other distance computations. The expected results come from validating the formula and providing concrete values, as we did previously:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_cd</span><span class="hljs-function">(</span><span class="hljs-params">known_unknown_example_15: Known_Unknown</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    k, u = known_unknown_example_15
    <span class="hljs-keyword">assert</span> CD().distance(k, u) == pytest.approx(<span class="hljs-number">3.3</span>)
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_md</span><span class="hljs-function">(</span><span class="hljs-params">known_unknown_example_15: Known_Unknown</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    k, u = known_unknown_example_15
    <span class="hljs-keyword">assert</span> MD().distance(k, u) == pytest.approx(<span class="hljs-number">7.6</span>)
</code></pre>
    <p class="normal">For the Chebyshev and Manhattan distances, we're adding the individual steps for each of the four attributes and computing the sum or finding the largest individual distance. We can work these out by hand and be confident that our expected answer is right.</p>
    <p class="normal">The Sorensen distance, however, is a little more complex and can benefit from a comparison <a id="_idIndexMarker1055"/>with <a id="_idIndexMarker1056"/>the symbolic results. Here's the formal definition:</p>
    <figure class="mediaobject"><img src="../Images/B17070_13_002.png" alt="" style="height: 4em;"/></figure>
    <p class="normal">Here's the symbolic definition that we can use to compare our implementation against the definition. The equation displayed looks a lot like the formal definition, giving us the confidence to use it to compute expected values. Here's a definition extracted from the code that we'd like to check:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">SD = </span><span class="hljs-con-built_in">sum</span><span class="python">(</span>
<span class="hljs-con-meta">...</span> <span class="python">    [</span><span class="hljs-con-built_in">abs</span><span class="python">(k_sl - u_sl), </span><span class="hljs-con-built_in">abs</span><span class="python">(k_sw - u_sw), </span><span class="hljs-con-built_in">abs</span><span class="python">(k_pl - u_pl), </span><span class="hljs-con-built_in">abs</span><span class="python">(k_pw - u_pw)]</span>
<span class="hljs-con-meta">...</span> <span class="python"> ) / </span><span class="hljs-con-built_in">sum</span><span class="python">( </span>
<span class="hljs-con-meta">...</span> <span class="python">    [k_sl + u_sl, k_sw + u_sw, k_pl + u_pl, k_pw + u_pw])</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">print(pretty(SD, use_unicode=</span><span class="hljs-con-literal">False</span><span class="python">))</span>
|k_pl - u_pl| + |k_pw - u_pw| + |k_sl - u_sl| + |k_sw - u_sw|
-------------------------------------------------------------
    k_pl + k_pw + k_sl + k_sw + u_pl + u_pw + u_sl + u_sw    
</code></pre>
    <p class="normal">The ASCII-art version of the formula looks a lot like the formal definition, giving us a lot of confidence that we can use <code class="Code-In-Text--PACKT-">sympy</code> to compute expected answers. We'll substitute specific example values to see what the expected results should be:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">e = SD.subs(</span><span class="hljs-con-built_in">dict</span><span class="python">(</span>
<span class="hljs-con-meta">...</span> <span class="python">    k_sl=</span><span class="hljs-con-number">5.1</span><span class="python">, k_sw=</span><span class="hljs-con-number">3.5</span><span class="python">, k_pl=</span><span class="hljs-con-number">1.4</span><span class="python">, k_pw=</span><span class="hljs-con-number">0.2</span><span class="python">,</span>
<span class="hljs-con-meta">...</span> <span class="python">    u_sl=</span><span class="hljs-con-number">7.9</span><span class="python">, u_sw=</span><span class="hljs-con-number">3.2</span><span class="python">, u_pl=</span><span class="hljs-con-number">4.7</span><span class="python">, u_pw=</span><span class="hljs-con-number">1.4</span><span class="python">,</span>
<span class="hljs-con-meta">...</span> <span class="python">))</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="python">e.evalf(</span><span class="hljs-con-number">9</span><span class="python">)</span>
0.277372263
</code></pre>
    <p class="normal">Now that we're sure we have valid expected results, we can plug this expectation into a unit test case. Here's how the test case looks:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_sd</span><span class="hljs-function">(</span><span class="hljs-params">known_unknown_example_15: Known_Unknown</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    k, u = known_unknown_example_15
    <span class="hljs-keyword">assert</span> SD().distance(k, u) == pytest.approx(<span class="hljs-number">0.277372263</span>)
</code></pre>
    <p class="normal">We've used <code class="Code-In-Text--PACKT-">sympy</code> as a <a id="_idIndexMarker1057"/>design aid to help us create unit test cases. It's not <a id="_idIndexMarker1058"/>run as a regular part of the testing process. We only want to use it for the obscure cases where we aren't sure we can trust ourselves to compute an expected answer with paper and pencil.</p>
    <p class="normal">As we noted at the beginning of this chapter's case study, there are 16 different combinations of values where the known and the unknown sample attributes are different. We've provided only one of the 16 combinations.</p>
    <p class="normal">Using the <code class="Code-In-Text--PACKT-">coverage</code> tool, we can see that all of the relevant code is tested with this one case. Do we really need the other 15 cases? There are two viewpoints:</p>
    <ul>
      <li class="bullet">From a "black box" point of view, we don't know what's in the code, and we need to test all the combinations. This kind of black box testing relies on the assumption that the values could have some complex interdependency that can only be found through patient examination of all cases.</li>
      <li class="bullet">From a "white box" point of view, we can look at the various distance function implementations and see that all four attributes are treated uniformly. An examination of the code tells us a single case is sufficient.</li>
    </ul>
    <p class="normal">For Python applications, we suggest following white box testing unless there's a compelling reason to avoid looking at the code. We can use the coverage report to confirm that one case really has tested the relevant code.</p>
    <p class="normal">Instead of creating 16 different test cases for the various distance algorithms, we can focus our efforts on making sure the application is reliable and uses minimal computing resources. We can <a id="_idIndexMarker1059"/>also focus on testing other parts of the application. We'll<a id="_idIndexMarker1060"/> look at the <code class="Code-In-Text--PACKT-">Hyperparameter</code> class next, because it depends on the <code class="Code-In-Text--PACKT-">Distance</code> computation class hierarchy.</p>
    <h2 id="_idParaDest-295" class="title">Unit testing the Hyperparameter class</h2>
    <p class="normal">The <code class="Code-In-Text--PACKT-">Hyperparameter</code> class<a id="_idIndexMarker1061"/> relies on a distance computation. We <a id="_idIndexMarker1062"/>have two strategies for testing a complex class like this:</p>
    <ul>
      <li class="bullet">An integration test that uses the distance computations already tested</li>
      <li class="bullet">A unit test that isolates the <code class="Code-In-Text--PACKT-">Hyperparameter</code> class from any of the distance computations to be sure the class works</li>
    </ul>
    <p class="normal">As a general rule of thumb, every line of code needs to be exercised by at least one unit test. After that, integration tests can also be used to ensure that the interface definitions are honored by all of the modules, classes, and functions. The spirit of "test everything" is more important than "make the number come out right"; counting lines is one way to ensure that we've tested everything.</p>
    <p class="normal">We'll look at testing the <code class="Code-In-Text--PACKT-">classify()</code> method of the <code class="Code-In-Text--PACKT-">Hyperparameter</code> class using <code class="Code-In-Text--PACKT-">Mock</code> objects to isolate the <code class="Code-In-Text--PACKT-">Hyperparameter</code> class from any of the distance computations. We'll also mock the <code class="Code-In-Text--PACKT-">TrainingData</code> object to further isolate an instance of this class.</p>
    <p class="normal">Here's the relevant code we'll be testing:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">Hyperparameter</span><span class="hljs-class">:</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span>
<span class="hljs-params">            self, </span>
<span class="hljs-params">            k: </span><span class="hljs-built_in">int</span><span class="hljs-params">, </span>
<span class="hljs-params">            algorithm: </span><span class="hljs-string">"Distance"</span><span class="hljs-params">, </span>
<span class="hljs-params">            training: </span><span class="hljs-string">"TrainingData"</span>
<span class="hljs-params">    </span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
        self.k = k
        self.algorithm = algorithm
        self.data: weakref.ReferenceType[<span class="hljs-string">"TrainingData"</span>] = \
            weakref.ref(training)
        self.quality: <span class="hljs-built_in">float</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">classify</span><span class="hljs-function">(</span>
<span class="hljs-params">            self, </span>
<span class="hljs-params">            sample: Union[UnknownSample, TestingKnownSample]</span><span class="hljs-function">) -&gt; str:</span>
        <span class="hljs-string">"""The k-NN algorithm"""</span>
        training_data = self.data()
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> training_data:
            <span class="hljs-keyword">raise</span> RuntimeError(<span class="hljs-string">"No TrainingData object"</span>)
        distances: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">float</span>, TrainingKnownSample]] = <span class="hljs-built_in">sorted</span>(
            (self.algorithm.distance(sample, known), known)
            <span class="hljs-keyword">for</span> known <span class="hljs-keyword">in</span> training_data.training
        )
        k_nearest = (known.species <span class="hljs-keyword">for</span> d, known <span class="hljs-keyword">in</span> distances[: self.k])
        frequency: Counter[<span class="hljs-built_in">str</span>] = collections.Counter(k_nearest)
        best_fit, *others = frequency.most_common()
        species, votes = best_fit
        <span class="hljs-keyword">return</span> species
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">algorithm</code> attribute of the <code class="Code-In-Text--PACKT-">Hyperparameter</code> class is a reference to an instance of one of the distance computation objects. When we replace this, the <code class="Code-In-Text--PACKT-">Mock</code> object must be callable and must return an appropriate sortable number.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">data</code> attribute<a id="_idIndexMarker1063"/> is a reference to a <code class="Code-In-Text--PACKT-">TrainingData</code> object. The <code class="Code-In-Text--PACKT-">Mock</code> to <a id="_idIndexMarker1064"/>replace the <code class="Code-In-Text--PACKT-">data</code> object must provide a <code class="Code-In-Text--PACKT-">training</code> attribute that is a list of mocked samples. Since these values are provided to another mock without any intermediate processing, we can use a <code class="Code-In-Text--PACKT-">sentinel</code> object to confirm that the training data was provided to the mocked distance function.</p>
    <p class="normal">The idea can be summarized as watching the <code class="Code-In-Text--PACKT-">classify()</code> method "go through the motions." We provide mocks and sentinels to confirm that requests are made and the results of those requests are captured.</p>
    <p class="normal">For the more complex test, we'll need some mock sample data. This will rely on <code class="Code-In-Text--PACKT-">sentinel</code> objects. The objects will be passed through to a mocked distance computation. Here's the definition of some mocked sample objects we'll use:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> annotations
<span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> Hyperparameter
<span class="hljs-keyword">from</span> unittest.mock <span class="hljs-keyword">import</span> Mock, sentinel, call
<span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">sample_data</span><span class="hljs-function">() -&gt; list[Mock]:</span>
    <span class="hljs-keyword">return</span> [
        Mock(name=<span class="hljs-string">"Sample1"</span>, species=sentinel.Species3),
        Mock(name=<span class="hljs-string">"Sample2"</span>, species=sentinel.Species1),
        Mock(name=<span class="hljs-string">"Sample3"</span>, species=sentinel.Species1),
        Mock(name=<span class="hljs-string">"Sample4"</span>, species=sentinel.Species1),
        Mock(name=<span class="hljs-string">"Sample5"</span>, species=sentinel.Species3),
    ]
</code></pre>
    <p class="normal">This fixture is a list of mocks for <code class="Code-In-Text--PACKT-">KnownSamples</code>. We've provided a unique name for each sample to help with debugging. We've provided a <code class="Code-In-Text--PACKT-">species</code> attribute, since that's the attribute used by the <code class="Code-In-Text--PACKT-">classify()</code> method. We didn't provide any other attributes, because they aren't used by the unit under test. We will use this <code class="Code-In-Text--PACKT-">sample_data</code> fixture to create a <code class="Code-In-Text--PACKT-">Hyperparameter</code> instance that will have a mock distance computation and this mock<a id="_idIndexMarker1065"/> collection <a id="_idIndexMarker1066"/>of data. Here's the test fixture we'll use:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">@pytest.fixture</span>
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">hyperparameter</span><span class="hljs-function">(</span><span class="hljs-params">sample_data: </span><span class="hljs-built_in">list</span><span class="hljs-params">[Mock]</span><span class="hljs-function">) -&gt; Hyperparameter:</span>
    mocked_distance = Mock(distance=Mock(side_effect=[<span class="hljs-number">11</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">13</span>]))
    mocked_training_data = Mock(training=sample_data)
    mocked_weakref = Mock(
        return_value=mocked_training_data)
    fixture = Hyperparameter(
        k=<span class="hljs-number">3</span>, algorithm=mocked_distance, training=sentinel.Unused)
    fixture.data = mocked_weakref
    <span class="hljs-keyword">return</span> fixture
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">mocked_distance</code> object will provide a sequence of results that look like the results of distance computations. The distance computations are tested separately, and we've isolated the <code class="Code-In-Text--PACKT-">classify()</code> method from the specific distance computations with this <code class="Code-In-Text--PACKT-">Mock</code>. We've provided the list of mocked <code class="Code-In-Text--PACKT-">KnownSample</code> instances via a <code class="Code-In-Text--PACKT-">Mock</code> object that will behave like a weak reference; the training attribute of this mock object will be the given sample data.</p>
    <p class="normal">To be sure the <code class="Code-In-Text--PACKT-">Hyperparameter</code> instance makes the right requests, we evaluate the <code class="Code-In-Text--PACKT-">classify()</code> method. Here's the entire scenario, including these two final THEN steps:</p>
    <ul>
      <li class="bullet"><code class="Code-In-Text--PACKT-">GIVEN</code> a sample data fixture with five instances reflecting two species</li>
      <li class="bullet"><code class="Code-In-Text--PACKT-">WHEN</code> we apply the <em class="italic">k</em>-NN algorithm</li>
      <li class="bullet"><code class="Code-In-Text--PACKT-">THEN</code> the result is the species with the closest three distances</li>
      <li class="bullet"><code class="Code-In-Text--PACKT-">AND</code> the mock distance computation was invoked with all of the training data</li>
    </ul>
    <p class="normal">Here's the final test, using the above fixtures:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">test_hyperparameter</span><span class="hljs-function">(</span><span class="hljs-params">sample_data: </span><span class="hljs-built_in">list</span><span class="hljs-params">[Mock], hyperparameter: Mock</span><span class="hljs-function">) -&gt; </span><span class="hljs-keyword">None</span><span class="hljs-function">:</span>
    s = hyperparameter.classify(sentinel.Unknown)
    <span class="hljs-keyword">assert</span> s == sentinel.Species1
    <span class="hljs-keyword">assert</span> hyperparameter.algorithm.distance.mock_calls == [
        call(sentinel.Unknown, sample_data[<span class="hljs-number">0</span>]),
        call(sentinel.Unknown, sample_data[<span class="hljs-number">1</span>]),
        call(sentinel.Unknown, sample_data[<span class="hljs-number">2</span>]),
        call(sentinel.Unknown, sample_data[<span class="hljs-number">3</span>]),
        call(sentinel.Unknown, sample_data[<span class="hljs-number">4</span>]),
    ]
</code></pre>
    <p class="normal">This test case checks the distance algorithm to make sure the entire training set of data was used. It also confirms that the nearest neighbors were used to locate the resulting species for the unknown sample.</p>
    <p class="normal">Since we tested the distance computations separately, we have a great deal of confidence in<a id="_idIndexMarker1067"/> running an integration test that combines these <a id="_idIndexMarker1068"/>various classes into a single, working application. For debugging purposes, it is very helpful to isolate each component into a separately tested unit.</p>
    <h1 id="_idParaDest-296" class="title">Recall</h1>
    <p class="normal">In this chapter, we've looked at a number of topics related to testing applications written in Python. These topics include the following:</p>
    <ul>
      <li class="bullet">We described the importance of unit testing and test-driven development as a way to be sure our software does what is expected.</li>
      <li class="bullet">We started by using the <code class="Code-In-Text--PACKT-">unittest</code> module because it's part of the standard library and readily available. It seems a little wordy, but otherwise works well for confirming that our software works.</li>
      <li class="bullet">The <code class="Code-In-Text--PACKT-">pytest</code> tool requires a separate installation, but it seems to produce tests that are slightly simpler than those written with the <code class="Code-In-Text--PACKT-">unittest</code> module. More importantly, the sophistication of the fixture concept lets us create tests for a wide variety of scenarios.</li>
      <li class="bullet">The <code class="Code-In-Text--PACKT-">mock</code> module, part of the <code class="Code-In-Text--PACKT-">unittest</code> package, lets us create mock objects to better isolate the unit of code being tested. By isolating each piece of code, we can narrow our focus on being sure it works and has the right interface. This makes it easier to combine components.</li>
      <li class="bullet">Code coverage is a helpful metric to ensure that our testing is adequate. Simply adhering to a numeric goal is no substitute for thinking, but it can help to confirm that efforts were made to be thorough and careful when creating test scenarios.</li>
    </ul>
    <p class="normal">We've been looking at several kinds of tests with a variety of tools:</p>
    <ul>
      <li class="bullet">Unit tests with the <code class="Code-In-Text--PACKT-">unittest</code> package or the <code class="Code-In-Text--PACKT-">pytest</code> package, often using <code class="Code-In-Text--PACKT-">Mock</code> objects to isolate the fixture or unit being tested.</li>
      <li class="bullet">Integration tests, also with <code class="Code-In-Text--PACKT-">unittest</code> and <code class="Code-In-Text--PACKT-">pytest</code>, where more complete integrated collections of components are tested.</li>
      <li class="bullet">Static analysis can use <strong class="" style="font-style: italic;">mypy</strong> to examine the data types to be sure they're used properly. This is a kind of test to ensure the software is acceptable. There are other kinds of static tests, and tools like <code class="Code-In-Text--PACKT-">flake8</code>, <code class="Code-In-Text--PACKT-">pylint</code>, and <code class="Code-In-Text--PACKT-">pyflakes</code> can be used for these additional analyses.</li>
    </ul>
    <p class="normal">Some research will turn up scores of additional types of tests. Each distinct type of test has a distinct objective or approach to confirming the software works. A performance test, for example, seeks to establish the software is fast enough and uses an acceptable number of resources.</p>
    <p class="normal">We can't emphasize enough how important testing is. Without automated tests, software can't be considered complete, or even usable. Starting from test cases lets us define the expected behavior in a way that's specific, measurable, achievable, results-based, and trackable: SMART.</p>
    <h1 id="_idParaDest-297" class="title">Exercises</h1>
    <p class="normal">Practice test-driven development. That is your first exercise. It's easier to do this if you're starting a new project, but if you have existing code you need to work on, you can start by writing tests for each new feature you implement. This can become frustrating as you become more enamored with automated tests. The old, untested code will start to feel rigid and tightly coupled, and will become uncomfortable to maintain; you'll start feeling like changes you make are breaking the code and you have no way of knowing, for lack of tests. But if you start small, adding tests to the code base improves it over time. It's not unusual for there to be more test code than application code!</p>
    <p class="normal">So, to get your feet wet with test-driven development, start a fresh project. Once you've started to appreciate the benefits (you will) and realize that the time spent writing tests is quickly regained in terms of more maintainable code, you'll want to start writing tests for existing code. This is when you should start doing it, not before. Writing tests for code that we <em class="italic">know </em>works is boring. It is hard to get interested in the project until we realize just how broken the code we thought was working really is.</p>
    <p class="normal">Try writing the same set of tests using both the built-in <code class="Code-In-Text--PACKT-">unittest</code> module and <code class="Code-In-Text--PACKT-">pytest</code>. Which do you prefer? <code class="Code-In-Text--PACKT-">unittest</code> is more similar to test frameworks in other languages, while <code class="Code-In-Text--PACKT-">pytest</code> is arguably more Pythonic. Both allow us to write object-oriented tests and test object-oriented programs with ease.</p>
    <p class="normal">We used <code class="Code-In-Text--PACKT-">pytest</code> in our case study, but we didn't touch on any features that wouldn't have been easily testable using <code class="Code-In-Text--PACKT-">unittest</code>. Try adapting the tests to use test skipping or fixtures. Try the various setup and teardown methods. Which feels more natural to you?</p>
    <p class="normal">Try running a coverage report on the tests you've written. Did you miss testing any lines of code? Even if you have 100 percent coverage, have you tested all the possible inputs? If you're doing test-driven development, 100 percent coverage should follow quite naturally, as you will write a test before the code that satisfies that test. However, if you're writing tests for existing code, it is more likely that there will be edge conditions that go untested.</p>
    <p class="normal">Getting the case study code to 100 percent coverage can be tricky, since we've been skipping around and implementing some aspects of the case study in several different ways. It may be necessary to write several similar tests for alternative implementations of case study classes. It can help to make reusable fixtures so that we can provide consistent testing among the alternative implementations.</p>
    <p class="normal">When creating test cases, it can help to think carefully about the values that are somehow different, such as the following, for example:</p>
    <ul>
      <li class="bullet">Empty lists when you expect full ones</li>
      <li class="bullet">Negative numbers, zero, one, or infinity compared to positive integers</li>
      <li class="bullet">Floats that don't round to an exact decimal place</li>
      <li class="bullet">Strings when you expected numerals</li>
      <li class="bullet">Unicode strings when you expected ASCII</li>
      <li class="bullet">The ubiquitous <code class="Code-In-Text--PACKT-">None</code> value when you expected something meaningful</li>
    </ul>
    <p class="normal">If your tests cover such edge cases, your code will be in good shape.</p>
    <p class="normal">The numeric methods for distance computations are something that might be better tested using the Hypothesis project. Check out the documentation here: <a href="https://hypothesis.readthedocs.io/en/latest/"><span class="url">https://hypothesis.readthedocs.io/en/latest/</span></a>. We can use Hypothesis to easily confirm that the order of operands in a distance computation doesn't matter; that is, <code class="Code-In-Text--PACKT-">distance(s1, s2) == distance(s2, s1)</code>, given any two samples. It's often helpful to include Hypothesis testing to confirm that the essential <em class="italic">k</em>-nearest neighbors classifier algorithm works for randomly shuffled data; this will ensure there's no bias for the first or last item in the training set.</p>
    <h1 id="_idParaDest-298" class="title">Summary</h1>
    <p class="normal">We have finally covered the most important topic in Python programming: automated testing. Test-driven development is considered a best practice. The standard library <code class="Code-In-Text--PACKT-">unittest</code> module provides a great out-of-the-box solution for testing, while the <code class="Code-In-Text--PACKT-">pytest</code> framework has some more Pythonic syntaxes. Mocks can be used to emulate complex classes in our tests. Code coverage gives us an estimate of how much of our code is being run by our tests, but it does not tell us that we have tested the right things.</p>
    <p class="normal">In the next chapter, we'll jump into a completely different topic: concurrency.</p>
  </div>
</body></html>