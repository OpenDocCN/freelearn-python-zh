- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Improving Data Storage with SQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As weeks have passed by, there is a growing problem at the lab: CSV files are
    everywhere! Conflicting copies, missing files, records getting changed by non-data
    entry staff, and other CSV-related frustrations are plaguing the project. Unfortunately,
    the password protection in the application does nothing meaningful to prevent
    anyone from editing the files and corrupting data. It''s clear that the current
    data storage solution is not working out. Something better is needed!'
  prefs: []
  type: TYPE_NORMAL
- en: The facility has an older Linux server with a PostgreSQL database installed.
    You've been asked to update your program so that it stores data in the PostgreSQL
    database rather than in the CSV files, and authenticates users against the database.
    This way there can be one authoritative source of data to which the support staff
    can easily manage access. In addition, the SQL database will help enforce correct
    data types and allow for more complex data relationships than the simple flat
    file. This promises to be a major update to your application!
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you''ll learn the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: In *PostgreSQL*, we'll install and configure the PostgreSQL database system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In *Modeling relational data*, we'll discuss the art of structuring data in
    a database for good performance and reliability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In *Creating the ABQ database*, we'll build a SQL database for the ABQ Data
    Entry application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In *Connecting to PostgreSQL with psycopg2*, we'll use the `psycopg2` library
    to connect our program to PostgreSQL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, in *Integrating SQL into our application*, we'll update ABQ Data Entry
    to utilize the new SQL database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter assumes you have a basic knowledge of SQL. If you don't, please
    see *Appendix B*, *A Quick SQL Tutorial*.
  prefs: []
  type: TYPE_NORMAL
- en: PostgreSQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python can interact with a wide variety of relational databases, including Microsoft
    SQL Server, Oracle, MariaDB, MySQL, and SQLite; in this book, we're going to focus
    on a very popular choice in the Python world, PostgreSQL. PostgreSQL (usually
    pronounced post-gress, with the "QL" silent) is a free, open source, cross-platform
    relational database system. It runs as a network service with which you can communicate
    using client programs or software libraries. At the time of writing, version 13
    is the current stable.
  prefs: []
  type: TYPE_NORMAL
- en: Although ABQ has provided a PostgreSQL server that is already installed and
    configured, you'll need to download and install the software on your workstation
    for development purposes. Let's take a look at how we can get our workstation
    ready for PostgreSQL development.
  prefs: []
  type: TYPE_NORMAL
- en: Shared production resources such as databases and web services should never
    be used for testing or development. Always set up a separate development copy
    of these resources on your own workstation or a separate server machine.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring PostgreSQL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To download PostgreSQL, visit [https://www.postgresql.org/download](https://www.postgresql.org/download)
    and download an installation package for your operating system. Installation packages
    are provided for Windows, macOS, Linux, BSD, and Solaris by EnterpriseDB, a commercial
    entity that provides paid support for PostgreSQL. These installers include the
    server, command-line client, and **pgAdmin** graphical client all in one package.
    To install the software, launch the installer using an account with administrative
    rights and follow the screens in the installation wizard. During installation,
    you'll be asked to set a password for the `postgres` superuser account; make sure
    to take note of this password.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring PostgreSQL using the GUI utility
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once installed, you can configure and interact with PostgreSQL using the **pgAdmin**
    graphical utility. Go ahead and launch pgAdmin from your application menu and
    follow these steps to create a new admin user for yourself:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Servers** from the **Browser** pane on the left. You'll be prompted
    for your superuser password.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once authenticated, select **Object** | **Create** | **Login/Group Role**. Enter
    a username to use for database access on the **General** tab. Then visit the **Privileges**
    tab to check **Superuser** and **Can Login**, and the **Definition** tab to set
    a password.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Save** button at the bottom of the window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we need to create a database. To do that, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Object** | **Create** | **Database** from the menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name the database `abq`, and set your new user account as the owner.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Save** button at the bottom of the window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your database is now ready to work with. You can begin entering SQL to run against
    your database by selecting the database in the **Browser** pane and clicking on
    **Tools** | **Query Tool** in the menu.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring PostgreSQL using the command line
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you prefer to work directly in the command line, PostgreSQL includes several
    command-line utilities, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Command | Description |'
  prefs: []
  type: TYPE_TB
- en: '| `createuser` | Create PostgreSQL user accounts |'
  prefs: []
  type: TYPE_TB
- en: '| `dropuser` | Delete PostgreSQL user accounts |'
  prefs: []
  type: TYPE_TB
- en: '| `createdb` | Create PostgreSQL databases |'
  prefs: []
  type: TYPE_TB
- en: '| `dropdb` | Delete PostgreSQL databases |'
  prefs: []
  type: TYPE_TB
- en: '| `psql` | Command-line SQL shell |'
  prefs: []
  type: TYPE_TB
- en: 'For example, on macOS or Linux, we can complete the configuration of our database
    with the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: These three commands create the user, create the database, and open a SQL shell
    where queries can be entered. Note that we use the `sudo` command to run these
    as the `postgres` user. Remember that this is the superuser account you set up
    during installation.
  prefs: []
  type: TYPE_NORMAL
- en: Although EnterpriseDB provides binary installers for Linux, most Linux users
    will prefer to use packages supplied by their distribution. You may end up with
    a slightly older version of PostgreSQL, but that won't matter for most basic use
    cases. Be aware that pgAdmin is usually part of a separate package, and also may
    be at a slightly older version. Regardless, you should have no trouble following
    this chapter with the older version.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling relational data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our application currently stores data in a single CSV file; a file like this
    is often called a **flat file**, because the data has been flattened to two dimensions.
    While this format works acceptably for our application and could be translated
    directly to a SQL table, a more accurate and useful data model requires more complexity.
    In this section, we're going to go through some concepts of data modeling that
    will help us convert our CSV data into effective relational tables.
  prefs: []
  type: TYPE_NORMAL
- en: Primary keys
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every table in a relational database should have something called a **primary
    key**. The primary key is a value, or set of values, that uniquely identifies
    a record in the table; as such, it should be a value or set of values that is
    unique and non-null for every row in a table. Other tables in the database can
    use this field to reference particular rows of the table. This is called a **foreign
    key** relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we figure out what the primary key is for a set of data? Consider this
    table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Fruit | Classification |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Berry |'
  prefs: []
  type: TYPE_TB
- en: '| Kiwi | Berry |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Citrus |'
  prefs: []
  type: TYPE_TB
- en: '| Lemon | Citrus |'
  prefs: []
  type: TYPE_TB
- en: In this table, each row represents a type of fruit. It would make no sense for
    the `Fruit` column to be empty in this table, or for two rows to have the same
    value for `Fruit`. This makes the column a perfect candidate for a primary key.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now consider a different table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Fruit | Variety | Quantity |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Cavendish | 452 |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Red | 72 |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Navel | 1023 |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Red | 875 |'
  prefs: []
  type: TYPE_TB
- en: In this table, each row represents a subvariety of fruit; however, there is
    no one field that uniquely defines a single variety of a single fruit. Instead,
    it requires both the `Fruit` and `Variety` fields. When we need multiple fields
    to determine the primary key, we call this a **composite primary key**. In this
    case, our composite primary key uses both the `Fruit` and `Variety` fields.
  prefs: []
  type: TYPE_NORMAL
- en: Using surrogate primary keys
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Consider this table of `employees`:'
  prefs: []
  type: TYPE_NORMAL
- en: '| First | Last | Title |'
  prefs: []
  type: TYPE_TB
- en: '| Bob | Smith | Manager |'
  prefs: []
  type: TYPE_TB
- en: '| Alice | Jones | Analyst |'
  prefs: []
  type: TYPE_TB
- en: '| Pat | Thompson | Developer |'
  prefs: []
  type: TYPE_TB
- en: Suppose this table were to use `First` and `Last` as a composite primary key,
    and suppose that other tables in the database reference rows using the primary
    keys. Leaving aside the obvious problem that two people can have the same first
    and last name, what would happen if Bob Smith decided he would prefer to be called
    Robert, or if Alice Jones married and took a new last name? Remember that other
    tables use the primary key value to reference rows in the table; if we change
    the contents of the primary key field, all the tables referencing these employees
    would either have to be updated as well or they would be unable to locate the
    record in the `employees` table.
  prefs: []
  type: TYPE_NORMAL
- en: 'While using actual data fields to build a primary key value is arguably the
    most theoretically pure approach, there are two big downsides that come up when
    you start relating tables using foreign keys:'
  prefs: []
  type: TYPE_NORMAL
- en: You have to duplicate the data in every table that needs to reference your table.
    This can particularly become onerous if you have a composite key of many fields.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can't change the values in the original table without breaking foreign key
    references.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For this reason, database engineers may opt for using **surrogate keys**. These
    are typically integer or **globally unique identifier** (**GUID**) values stored
    in an **identity column** that are automatically added to a record when it is
    inserted into a table. In the case of the `employees` table, we could simply add
    an `ID` field containing an auto-incrementing integer value, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ID | First | Last | Title |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Bob | Smith | Manager |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Alice | Jones | Analyst |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Pat | Thompson | Developer |'
  prefs: []
  type: TYPE_TB
- en: Now other tables can simply refer to `employees.ID=1`, or `employees.ID=2`,
    leaving `Bob` and `Alice` free to change their names without consequence.
  prefs: []
  type: TYPE_NORMAL
- en: The use of surrogate keys arguably breaks the theoretical purity of a database;
    it also may require us to manually specify uniqueness or non-null constraints
    on columns that are implicit when they are used as a primary key. Sometimes, though,
    the practical advantages of surrogate keys outweigh these concerns. You will need
    to evaluate which option works best with your application and its data.
  prefs: []
  type: TYPE_NORMAL
- en: 'One rule of thumb in making this determination is to consider whether the data
    you propose to use as a key **describes** or **defines** the item represented
    by the row. For example, a name does not define a person: a person can change
    their name and still be the same person. On the other hand, the plot checks stored
    in our CSV files are defined by the date, time, lab, and plot values. Change any
    one of those values and you are referring to a different plot check.'
  prefs: []
  type: TYPE_NORMAL
- en: Normalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The process of breaking out a flat data file into multiple tables is called
    **normalization**. The normalization process is broken into a series of levels
    called **normal forms**, which progressively remove duplication and create a more
    precise model of the data we're storing. Although there are many normal forms,
    most issues encountered in common business data can be handled by conforming to
    the first three.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of conforming data to these forms is to eliminate the potential
    for redundant, conflicting, or undefined data situations. Let's briefly look at
    each of the first three normal forms, and what kind of issues it prevents.
  prefs: []
  type: TYPE_NORMAL
- en: First normal form
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **first normal form** requires that each field contains only one value,
    and that repeating columns must be eliminated. For example, suppose we have a
    flat file that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Fruit | Varieties |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Cavendish, Red, Apple |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Navel, Valencia, Blood, Cara Cara |'
  prefs: []
  type: TYPE_TB
- en: 'The `Varieties` field in this table has multiple values in a single column,
    so this table is not in the first normal form. We might try to fix it like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Fruit | Variety_1 | Variety_2 | Variety_3 | Variety_4 |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Cavendish | Red | Apple |  |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Navel | Valencia | Blood | Cara Cara |'
  prefs: []
  type: TYPE_TB
- en: This is an improvement, but it's still not in the first normal form, because
    we have **repeating columns**. All of the `Variety_` columns represent the same
    attribute (the variety of fruit), but have been arbitrarily broken out into distinct
    columns. One way to tell if you have repeating columns is if the data is equally
    valid whether it goes in one column or the other; for example, `Cavendish` could
    just as well go in the `Variety_2`, `Variety_3`, or `Variety_4` columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider some of the problems with this format:'
  prefs: []
  type: TYPE_NORMAL
- en: What would it mean if we had the same data in multiple `Variety` fields; for
    example, if the `Banana` row had `Cavendish` for `Variety_1` and `Variety_4`?
    Or what would it indicate for `Variety_1` to be blank, but `Variety_2` to have
    a value? These ambiguous situations are known as **anomalies** and can lead to
    conflicting or confusing data in the database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How complex would it be to query the table to see if two fruits share a variety
    name? We would have to check each `Variety_` field against every other `Variety_`
    field. What if we needed more than four varieties for a particular fruit? We would
    have to add columns, meaning our query would get exponentially more complex.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To bring this table to the first normal form, we would need to create one `Fruit`
    and one `Variety` column, something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Fruit | Variety |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Cavendish |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Red |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Apple |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Navel |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Valencia |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Blood |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Cara Cara |'
  prefs: []
  type: TYPE_TB
- en: Note that this changes the nature of our table, as it's no longer one row per
    `Fruit`, but rather one row per `Fruit-Variety` combination. In other words, the
    primary key has changed from `Fruit` to `Fruit + Variety`. What if there are additional
    fields in the table that relate specifically to the `Fruit` type without respect
    to `Variety`? We'll address that as we look at the second normal form.
  prefs: []
  type: TYPE_NORMAL
- en: Second normal form
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **second normal form** requires the first normal form, and additionally
    that *every value must be dependent on the entire primary key*. In other words,
    if a table has primary key fields A, B, and C, and the value of column X depends
    solely on the value of column A without respect to B or C, the table violates
    the second normal form. For example, suppose we added a `Classification` field
    to our table, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Fruit | Variety | Classification |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Cavendish | Berry |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Red | Berry |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Navel | Citrus |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Valencia | Citrus |'
  prefs: []
  type: TYPE_TB
- en: 'In this table, `Fruit` and `Variety` comprise the primary key of each row.
    `Classification` only depends on `Fruit`, though, since all bananas are berries,
    and all oranges are citrus. Consider the problems with this format:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we have a data redundancy, since every `Fruit` type is going to have
    its `Classification` listed multiple times (once each time the `Fruit` value is
    repeated).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The redundancy creates the potential for an anomaly where the same `Fruit` value
    has a different `Classification` value in different rows. This would make no sense.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To address this, we'd need to break our table into two tables; one containing
    `Fruit` and `Classification`, with a primary key of `Fruit`, and one containing
    `Fruit` and `Variety`, with both fields comprising the primary key.
  prefs: []
  type: TYPE_NORMAL
- en: Third normal form
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **third normal form** requires the second normal form, and additionally
    that *every value in the table is dependent only on the primary key*. In other
    words, given a table with primary key A, and data fields X and Y, the value of
    Y can't depend on the value of X. It can only depend on A.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider this table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Fruit | Leading Export Country | Leading Export Continent |'
  prefs: []
  type: TYPE_TB
- en: '| Banana | Ecuador | South America |'
  prefs: []
  type: TYPE_TB
- en: '| Orange | Brazil | South America |'
  prefs: []
  type: TYPE_TB
- en: '| Apples | China | Asia |'
  prefs: []
  type: TYPE_TB
- en: 'This table complies with the second normal form, because both columns are distinct
    to the primary key – each fruit can only have one leading export country, and
    one leading export continent. However, the `Leading Export Continent` value depends
    on the `Leading Export Country` value (a non-primary key field), because a country
    is on a continent without any respect to its fruit exports. The problems with
    this format are:'
  prefs: []
  type: TYPE_NORMAL
- en: There is data redundancy, as any country appearing multiple times would result
    in its continent appearing multiple times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once again, the redundancy creates the potential for an anomaly, where the same
    country could have two different continents listed. That makes no sense.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To bring this to the third normal form, we would need to create a separate table
    of countries that could contain the continent column and any other column that
    depended on the country.
  prefs: []
  type: TYPE_NORMAL
- en: More normalization forms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Database theorists propose other higher normalization forms that can help further
    eliminate ambiguities and redundancies in data, but for this book the first three
    should suffice to organize our data. Be aware that it is possible to **over-normalize**
    data for an application. Deciding what constitutes over-normalization really depends
    on the data and the users.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you have a contacts database that contains the columns `telephone_1`
    and `telephone_2`, the first normal form would dictate that you put telephone
    numbers in their own table to eliminate the repeating field. But if your users
    never need more than two fields, rarely use the second one, and never do complex
    queries on the data, it may not be worth complicating your database and application
    to conform to a theoretically pure model.
  prefs: []
  type: TYPE_NORMAL
- en: Entity-relationship diagrams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One effective way to help normalize our data and prepare it for a relational
    database is to create an **entity-relationship diagram**, or **ERD**. An ERD is
    a way of diagramming the things that our database is storing information about
    and the relationships between those things.
  prefs: []
  type: TYPE_NORMAL
- en: Those "things" are called **entities**. An entity is a uniquely identifiable
    object; it corresponds to a single row of a single table. Entities have **attributes**,
    which correspond to the columns of a table. Entities also have **relationships**
    with other entities, which correspond to the foreign key relationships we define
    in SQL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the entities in our lab scenario with their attributes and
    relationships:'
  prefs: []
  type: TYPE_NORMAL
- en: There are **labs**. Each lab has a name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are **plots**. Each plot belongs to a lab and has a number. A single seed
    sample is planted in each plot.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are **lab technicians**, who each have a name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are **lab checks**, which are performed by a lab tech at a given lab.
    Each lab check has a date and time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are **plot checks**, which are the data gathered at a single plot during
    a lab check. Each plot check has various plant and environmental data recorded
    on it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows these entities and their relationships:'
  prefs: []
  type: TYPE_NORMAL
- en: '![An Entity-relationship diagram of our ABQ data](img/B17578_12_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.1: An entity-relationship diagram of our ABQ data'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this diagram, the entities are represented by rectangles. We have five entities:
    `Lab`, `Plot`, `Lab Tech`, `Lab Check`, and `Plot Check`. Each entity has attributes,
    represented by the ovals. The relationships between entities are represented by
    diamonds, with the words describing the left-to-right relationship. For example,
    a `Lab Tech` performs a `Lab Check`, and a `Lab Check` is performed in a `Lab`.
    Note the small *1* and *n* characters around the relationship: these show the
    **cardinality** of the relationship. There are three types of cardinality commonly
    seen in a database:'
  prefs: []
  type: TYPE_NORMAL
- en: A **one-to-many** (1 to n) relationship, where one row in the left table is
    related to many rows in the right table. For example, one `Lab Tech` performs
    many `Lab Checks`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **many-to-one** (n to 1) relationship, where many rows in the left table are
    related to the same row in the right. For example, multiple `Lab Checks` are performed
    in the same `Lab`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **many-to-many** (n to n) relationship, where many rows in the left table
    are related to many rows in the right. For example, if we needed to update our
    database to allow more than one tech to work on the same lab check, then one lab
    tech would still perform many checks, but one check would have multiple techs
    (fortunately, we don't need to implement this!).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This diagram represents a reasonably normalized structure for our data. To
    implement it in SQL, we''d just make a table for each entity, a column for each
    attribute, and a foreign key relationship for each relationship. Before we can
    do that, though, let''s consider one more thing: SQL data types.'
  prefs: []
  type: TYPE_NORMAL
- en: Assigning data types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Standard SQL defines 16 data types, including types for integers and floating-point
    numbers of various sizes, ASCII or Unicode strings of either fixed or variable
    sizes, date and time types, and single-bit types. In addition to implementing
    standard types, nearly every SQL engine extends this list with yet more types
    to accommodate things like binary data, JSON data, currency values, network addresses,
    and other special types of strings or numbers. Many data types seem a little redundant,
    and several have aliases that may be different between implementations. Choosing
    data types for your columns can be surprisingly confusing!
  prefs: []
  type: TYPE_NORMAL
- en: 'For PostgreSQL, the following chart provides some reasonable choices:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Data being stored | Recommended type | Notes |'
  prefs: []
  type: TYPE_TB
- en: '| Fixed-length strings | `CHAR` | Requires a length, for example, `CHAR(256)`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Short-to-medium strings | `VARCHAR` | Requires a max length argument, for
    example, `VARCHAR(256)`. |'
  prefs: []
  type: TYPE_TB
- en: '| Long, freeform text | `TEXT` | Unlimited length, slower performance. |'
  prefs: []
  type: TYPE_TB
- en: '| Smaller integers | `SMALLINT` | Up to ±32,767. |'
  prefs: []
  type: TYPE_TB
- en: '| Most integers | `INT` | Up to around ±2.1 billion. |'
  prefs: []
  type: TYPE_TB
- en: '| Larger integers | `BIGINT` | Up to around ±922 quadrillion. |'
  prefs: []
  type: TYPE_TB
- en: '| Decimal numbers | `NUMERIC` | Takes optional length and precision arguments.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Integer primary key | `SERIAL, BIGSERIAL` | Auto-incrementing integers or
    big integers. |'
  prefs: []
  type: TYPE_TB
- en: '| Boolean | `BOOLEAN` | Can be TRUE, FALSE, or NULL. |'
  prefs: []
  type: TYPE_TB
- en: '| Date and time | `TIMESTAMP WITH TIMEZONE` | Stores date, time, and timezone.
    Accurate to 1 µs. |'
  prefs: []
  type: TYPE_TB
- en: '| Date without time | `DATE` | Stores date. |'
  prefs: []
  type: TYPE_TB
- en: '| Time without date | `TIME` | Can be with or without time zone. |'
  prefs: []
  type: TYPE_TB
- en: These types will probably meet the vast majority of your needs in most applications,
    and we'll be using a subset of these for our ABQ database. As we create our tables,
    we'll refer to our data dictionary and choose appropriate data types for our columns.
  prefs: []
  type: TYPE_NORMAL
- en: Be careful not to choose overly specific or restrictive data types. Any data
    can ultimately be stored in a `TEXT` field; the purpose of choosing more specific
    types is mainly to enable the use of operators, functions, or sorting specific
    to that type of data. If those aren't required, consider a more generic type.
    For example, phone numbers and U.S. social security numbers can be represented
    purely with digits, but that's no reason to make them `INTEGER` or `NUMERIC` fields;
    after all, you wouldn't do arithmetic with them!
  prefs: []
  type: TYPE_NORMAL
- en: Creating the ABQ database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we've modeled our data and gotten a feel for the data types available,
    it's time to build our database. Make sure you've installed PostgreSQL and created
    the `abq` database as described in the first section of this chapter, and let's
    begin writing SQL to create our database structure.
  prefs: []
  type: TYPE_NORMAL
- en: Under your project root folder, create a new directory called `sql`. Inside
    the `sql` folder, create a file called `create_db.sql`. We'll start writing our
    table definition queries in this file.
  prefs: []
  type: TYPE_NORMAL
- en: Creating our tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The order in which we create our tables is significant. Any table referred to
    in a foreign key relationship will need to exist before the relationship is defined.
    Because of this, it's best to start with your lookup tables and follow the chain
    of one-to-many relationships until all the tables are created. In our ERD, that
    takes us from roughly the upper left to the lower right.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the lookup tables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We need to create the following three lookup tables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`labs`: This lookup table will contain the ID strings for our laboratories.
    Since the names of the labs aren''t going to change, we''ll just use the single-letter
    names as the primary key values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lab_techs`: This lookup table will have the names of the lab technicians.
    Since we don''t want to use employee names for primary keys, we''ll create a column
    for the employee ID number and use it for the primary key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`plots`: This lookup table will have one row for each physical plot, identified
    by lab and plot numbers. It will also keep track of the current seed sample planted
    in the plot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Add the SQL query for creating these tables to `create_db.sql`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Once created, the three tables look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| lab_id |'
  prefs: []
  type: TYPE_TB
- en: '| A |'
  prefs: []
  type: TYPE_TB
- en: '| B |'
  prefs: []
  type: TYPE_TB
- en: '| C |'
  prefs: []
  type: TYPE_TB
- en: The labs table
  prefs: []
  type: TYPE_NORMAL
- en: '| id | name |'
  prefs: []
  type: TYPE_TB
- en: '| 4291 | J Simms |'
  prefs: []
  type: TYPE_TB
- en: '| 4319 | P Taylor |'
  prefs: []
  type: TYPE_TB
- en: The lab_techs table
  prefs: []
  type: TYPE_NORMAL
- en: '| lab_id | plot | current_seed_sample |'
  prefs: []
  type: TYPE_TB
- en: '| A | 1 | AXM477 |'
  prefs: []
  type: TYPE_TB
- en: '| A | 2 | AXM478 |'
  prefs: []
  type: TYPE_TB
- en: '| A | 3 | AXM479 |'
  prefs: []
  type: TYPE_TB
- en: The plots table
  prefs: []
  type: TYPE_NORMAL
- en: While these tables may seem very simple, they will help enforce data integrity
    and make it simple to build an interface dynamically from the database. For example,
    since we'll be populating our `Labs` widget from the database, adding a new lab
    to the application is simply a matter of adding a row to the database.
  prefs: []
  type: TYPE_NORMAL
- en: The lab_checks table
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The rows of the `lab_checks` table each represent an instance of a technician
    checking all the plots of a lab at a given time on a given date. We will define
    it using the following SQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'When created and populated, the table will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| date | time | lab_id | lab_tech_id |'
  prefs: []
  type: TYPE_TB
- en: '| 2021-10-01 | 8:00 | A | 4291 |'
  prefs: []
  type: TYPE_TB
- en: The lab_checks table
  prefs: []
  type: TYPE_NORMAL
- en: The `date`, `time`, and `lab_id` columns together uniquely identify a lab check,
    and so we designate them collectively as the primary key. The ID of the lab technician
    performing the check is the lone attribute in this table, and creates a foreign
    key relationship to the `lab_techs` table.
  prefs: []
  type: TYPE_NORMAL
- en: The plot_checks table
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Plot checks are the actual data records collected at individual plots. These
    each belong to a lab check, and so must refer back to an existing lab check using
    the three key values, `date`, `time`, and `lab_id`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll begin with the primary key columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `plot_checks` primary key is essentially the primary key of a `lab_check`
    table with the addition of a plot number; its key constraints look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we''ve defined the key columns, we can add the attribute columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'When created and populated, the first several columns of the table look something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| date | time | lab | plot | seed_sample | humidity | light | (etc...) |'
  prefs: []
  type: TYPE_TB
- en: '| 2021-10-01 | 08:00:00 | A | 1 | AXM477 | 24.19 | 0.97 |  |'
  prefs: []
  type: TYPE_TB
- en: '| 2021-10-01 | 08:00:00 | A | 2 | AXM478 | 23.62 | 1.03 |  |'
  prefs: []
  type: TYPE_TB
- en: The plot_checks table
  prefs: []
  type: TYPE_NORMAL
- en: Notice our use of data types and the `CHECK` constraint to duplicate the limits
    defined in the specification's data dictionary. Using these, we've leveraged the
    power of the database to safeguard against invalid data. This completes our table
    definitions for the ABQ database.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a view
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we finish our database design, we're going to create a **view** that
    will simplify access to our data. A view behaves like a table in most respects,
    but contains no actual data; it's really just a stored `SELECT` query. We'll create
    a view called `data_record_view` to rearrange our data for easier interaction
    with the GUI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Views are created using the `CREATE VIEW` command, which begins like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, inside the parentheses, we put the `SELECT` query that will return the
    table data we want in our view:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We're selecting the `plot_checks` table, and joining it to `lab_checks` and
    `lab_techs` by way of our foreign key relationships. Notice that we've aliased
    these tables by using the `AS` keyword. Short aliases like this can help make
    a large query more readable. We're also aliasing each field to the name used in
    the application's data structures. These must be enclosed in double quotes to
    allow for the use of spaces and to preserve casing. By making the column names
    match the data dictionary keys in our application, we won't need to translate
    field names in our application code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first several columns of the view look like this; compare this to the raw
    `plot_checks` table above:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Date | Time | Technician | Lab | Plot | Seed Sample | Humidity | Light |'
  prefs: []
  type: TYPE_TB
- en: '| 2021-10-01 | 8:00 | J Simms | A | 1 | AXM477 | 24.19 | 0.97 |'
  prefs: []
  type: TYPE_TB
- en: '| 2021-10-01 | 8:00 | J Simms | A | 2 | AXM478 | 23.62 | 1.03 |'
  prefs: []
  type: TYPE_TB
- en: SQL database engines such as PostgreSQL are highly efficient at joining and
    transforming tabular data. Whenever possible, leverage this power and make the
    database do the work of formatting the data for the convenience of your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'This completes our database creation script. Run this script in your PostgreSQL
    client and verify that the four tables and the view have been created. To execute
    the script in pgAdmin, first open the **Query Tool** from **Tools** | **Query
    Tool**, then open the file by clicking the folder icon above the **Query Editor**
    window. Once the file is opened, click the play button icon to execute it. To
    run the script at the command line, execute the following at a terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Populating the lookup tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Although the tables are all created, the lookup tables will need to be populated
    before we can use them; specifically:'
  prefs: []
  type: TYPE_NORMAL
- en: '`labs` should have values `A` through `C`, representing the three labs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lab_techs` needs the name and ID number for our four lab technicians: J Simms
    (4291), P Taylor (4319), Q Murphy (4478), and L Taniff (5607).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`plots` needs all 60 of the plots, numbers 1 through 20 for each lab. The seed
    sample rotates between four values such as AXM477, AXM478, AXM479, and AXM480.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can populate these tables by hand using pgAdmin, or by using the `lookup_populate.sql`
    script included with the example code. Execute it just as you did the `create_db.sql`
    script.
  prefs: []
  type: TYPE_NORMAL
- en: Now our database is ready to use with the application. Let's get the application
    ready to work with the database!
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to PostgreSQL with psycopg2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a nice database to work with, how do we get our application
    to use it? To make SQL queries from our application, we'll need to install a Python
    library that can talk directly to our database. In Python, each different SQL
    product has one or more libraries available that can be used to integrate with
    it.
  prefs: []
  type: TYPE_NORMAL
- en: For PostgreSQL, the most popular choice is `psycopg2`. The `psycopg2` library
    is not a part of the Python standard library, so you'll need to install it on
    any machine running your application. You can find the most current installation
    instructions at [http://initd.org/psycopg/docs/install.html](http://initd.org/psycopg/docs/install.html);
    however, the preferred method is to use `pip`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Windows, macOS, and Linux, the following command should work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: If that doesn't work, or if you'd rather install it from the source, check the
    requirements on the website. Take note that the `psycopg2` library is written
    in C, not Python, so it requires a C compiler and a few other development packages
    to install from source.
  prefs: []
  type: TYPE_NORMAL
- en: Linux users can usually install `psycopg2` from their distribution's package
    management system.
  prefs: []
  type: TYPE_NORMAL
- en: psycopg2 basics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The essential workflow of using `psycopg2` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we create a `Connection` object using `psycopg2.connect()`. This object
    represents our connection to the database engine and is used to manage our login
    session.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we create a `Cursor` object from our connection using the `Connection`
    object's `cursor()` method. A **cursor** is our point of interaction with the
    database engine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can run queries by passing SQL strings to the cursor's `execute()` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If our queries return data, we can retrieve the data using the cursor's `fetchone()`
    or `fetchall()` methods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following script demonstrates the basic use of `psycopg2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We begin by importing `psycopg2` and aliasing it to `pg` for brevity's sake;
    we also import `getpass` for prompting the user for a password. Next, we generate
    a connection object, `cx`, using the `connect()` function, passing in all the
    details required to locate the database server and authenticate to it. These details
    include the host name of the server, the name of the database, and the authentication
    credentials. The `host` argument can be the server name, IP address, or fully
    qualified domain name of the system running the PostgreSQL server. Since we're
    running PostgreSQL on our local system, we've used `localhost` here, which points
    back to our local system.
  prefs: []
  type: TYPE_NORMAL
- en: From the connection, we create a cursor object, `cur`. Finally, we've used the
    cursor's `execute()` method to execute two SQL queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s retrieve some data from the database, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: You might expect that the data retrieved from the query is found in the return
    value of `execute()`; however, that's not how it works. Instead, we execute the
    query, then use cursor methods and attributes to retrieve the data and the metadata
    about the execution. In this case, we've used `fetchall()` to retrieve all the
    rows of data at once. We have also used the `rowcount` attribute of the cursor
    to see how many rows were returned from the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'PostgreSQL is a **transactional database**, meaning that modification operations
    (like our `CREATE` and `INSERT` statements) are not automatically saved to disk.
    To do that, we need to **commit** our transaction. We can do this in `psycopg2`
    using the connection object''s `commit()` method, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If we do not commit, the changes we make will not be saved when our connection
    exits. The connection will exit automatically when our application or script quits,
    but we can also explicitly exit using the connection''s `close()` method, like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: You can specify `autocommit=True` when creating a `Connection` object to have
    `psycopg2` implicitly commit the transaction after every query. This is a handy
    convenience, especially when working with PostgreSQL in the shell.
  prefs: []
  type: TYPE_NORMAL
- en: Parameterized queries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Quite often, we need to include runtime data, such as that entered by our users,
    in a SQL query. You might be tempted to do this using Python''s powerful string-formatting
    capabilities, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*Never, never do this!* While it initially works, it creates a vulnerability
    known as a **SQL injection vulnerability**. In other words, it will allow a user
    of the program to enter any SQL command they wish. For example, we could execute
    our script and add malicious data like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we've executed the program and entered a string that closes
    our coded SQL statement and adds on a `DROP TABLE` statement. It then adds a partial
    `SELECT` statement to avoid a syntax error from the SQL engine. The result is
    that the `test` table is deleted, and we get an exception trying to query data
    from it!
  prefs: []
  type: TYPE_NORMAL
- en: 'SQL injection vulnerabilities have plagued applications for decades and been
    the source of many high-profile hacking disasters. Fortunately, `psycopg2` gives
    us a way to avoid this by using **parameterized queries**. A parameterized version
    of the previous code looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: To parameterize a query, we use the `%s` string to stand in for values we want
    to be inserted into the query. The values themselves are passed into `execute()`
    as a second argument. For multiple values, the parameter values should be passed
    in as a list or tuple, and will replace the `%s` occurrences in order.
  prefs: []
  type: TYPE_NORMAL
- en: 'For complicated queries, we can also give each parameter a name, and pass in
    a dictionary to match up the values; for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The parameter's name is put in parentheses between the percent sign and `s`
    character. The name will then be matched to a key in the parameters value dictionary
    and substituted when the query is executed by the database.
  prefs: []
  type: TYPE_NORMAL
- en: The `s` in this parameter string is called a **format specifier**, and derives
    from the original Python syntax for string substitution. It is required and should
    *always* be `s`. If your parameterized query causes an Invalid Format Specifier
    error, it's because you have forgotten the `s` or used a different character.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameterized queries take care of properly escaping and sanitizing our data
    so that SQL injection attacks are largely impossible. For example, if we try our
    previous hack with the parameterized code, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Not only do parameterized queries protect us from SQL injection, but they also
    perform automatic conversion of certain Python types to SQL values; for example,
    Python `date` and `datetime` objects are automatically converted to strings that
    SQL will recognize as dates, and `None` is automatically converted to SQL `NULL`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that parameters only work for *data values*; there is no way to parameterize
    other query content like table names or commands.
  prefs: []
  type: TYPE_NORMAL
- en: Special cursor classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By default, `Cursor.fetchall()` returns our query results as a list of tuples.
    This might be acceptable if we have a table of one or two columns, but for large
    tables like those in our ABQ database, it quickly becomes a problem remembering
    which tuple index corresponds to which field. Ideally, we'd like to be able to
    reference a field by name.
  prefs: []
  type: TYPE_NORMAL
- en: 'To accommodate this, `psycopg2` allows us to specify a **cursor factory** class
    for our connection object that allows us to use cursor objects with customized
    behavior. One such custom cursor class included with `psycop2` is the `DictCursor`
    class. We use it like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '`DictCursor` is found in the `psycopg2.extras` module, so we have to import
    it separately from the main module. Once imported, we pass it to the `connect()`
    function''s `cursor_factory` argument. Now, rows will be returned as `DictRow`
    objects, which can be treated just like dictionaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This is much handier when dealing with a large number of columns.
  prefs: []
  type: TYPE_NORMAL
- en: More information about the use of `psycopg2` can be found in its official documentation
    at [https://www.psycopg.org/docs/](https://www.psycopg.org/docs/).
  prefs: []
  type: TYPE_NORMAL
- en: Integrating SQL into our application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Converting our application to a SQL backend will be no small task. The application
    was built around the assumption of the CSV files, and although we've taken care
    to separate our concerns, many things are going to need to change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s break down the steps we''ll need to take:'
  prefs: []
  type: TYPE_NORMAL
- en: We'll need to create a new model to interface with the SQL database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our `Application` class will need to use the SQL model, and may need to adjust
    some behaviors as a result.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The record form will need to be reordered to prioritize our key fields, use
    the new lookup tables, and auto-populate using information in the database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The record list will need to be adjusted to work with the new data model and
    primary keys.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll start in `models.py` by importing `psycopg2` and `DictCursor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As you learned in the previous section, `DictCursor` will allow us to fetch
    results in a Python dictionary rather than the default tuples, which is easier
    to work with in our application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, begin a new model class called `SQLModel` and copy over the `fields` property
    from the `CSVModel`, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We need to make a few changes to this dictionary, however. First, our valid
    Lab and Plot values are going to be pulled from the database rather than being
    hardcoded here, so we'll specify them as empty lists and populate them in the
    initializer. Also, the Technician field will become a drop-down select, also populated
    from the database, so we need to make it a `string_list` type with an empty list
    for the `values` argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'Those three entries should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we write our initializer, let''s create a method to encapsulate a lot
    of the boilerplate code around querying and retrieving data. We''ll call this
    method `query()`; add it to the `SQLModel` class like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This method takes a query string and, optionally, a sequence of parameters.
    Inside the method, we begin by opening a context block using the `Connection`
    object. Using the connection this way means that `psycopg2` will automatically
    commit the transaction if the query is successful. Next, we generate our `Cursor`
    object, also using a context manager. By using the cursor as a context manager,
    `psycopg2` will automatically **roll back** our transaction if an exception is
    thrown by the `execute()` method. Rolling back is the opposite of committing the
    database: instead of saving the changes, we throw them away and start with the
    database as it was the last time we committed (or the beginning of the session,
    if we haven''t called `commit()` yet). After rolling back, the exception will
    be re-raised so that we can handle it in our calling code, and, in either case,
    the cursor will be closed when the block exits. Essentially, it''s equivalent
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: If we successfully execute the query and it returns data, the method will need
    to return that data. To determine if data was returned, we check the cursor.`description`
    property. The `cursor.description` property returns a list of the headers for
    the table returned by our query; in the event that our query returns no data (such
    as an `INSERT` query), it is set to `None`. It's important to realize that `fetchall()`
    will raise an exception if there is no data returned from the query, so we should
    check `description` before executing it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have this method, we can easily retrieve results from our database
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'To see how we can use the query method, let''s go ahead and add an initializer
    method to this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `__init__()` method takes the database connection details and establishes
    a connection to the database using `psycopg2.connect()`, setting the `cursor_factory`
    to `DictCursor`. Then, we use our new `query()` method to query the database for
    the pertinent columns in our three lookup tables, using a list comprehension to
    flatten the results of each query for the respective `values` list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to write the methods that the application calls to retrieve data
    from the model. We''ll start with `get_all_records()`, which looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Since our users are used to working with only the current day's data, we'll
    only show that data by default, but add an optional flag should we ever need to
    retrieve all data for all time. To retrieve the current date in PostgreSQL, we
    can use the `CURRENT_DATE` constant, which always holds the current date according
    to the server. Note that we use a prepared query to pass the `all_dates` value
    to the query.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s create `get_record()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This method represents a change in interface from the `CSVModel` class. We're
    no longer dealing in row numbers; instead, rows are identified by their primary
    key values. In the case of our records (that is, plot checks), we need Date, Time,
    Lab, and Plot to identify a record. For convenience, we'll be passing this value
    around as a tuple in the format (`date`, `time`, `lab`, `plot`). Thus, the first
    thing our method does is extract the `rowkey` tuple into those four values.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have these values, we can use a prepared query to retrieve all the record
    data from the view we created. Keep in mind that, even when the query results
    are a single row, the `query()` method is going to return the results in a list.
    However, our application expects a single dictionary of data from `get_record()`,
    so our `return` statement extracts the first item in `result` if the list is not
    empty, or an empty dictionary if it is.
  prefs: []
  type: TYPE_NORMAL
- en: 'Retrieving a lab check record is very similar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: In this query, we're using a join to make sure we have the technician name available
    and not just the ID. This method did not exist in `CSVModel`, because we had not
    yet normalized the data; but it will come in handy in our `save_record()` method
    and in our form automation methods.
  prefs: []
  type: TYPE_NORMAL
- en: Saving data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Saving data in our SQL model is a little more complex than the CSV, since each
    data record is represented by rows in two different tables: the `lab_checks` and
    the `plot_checks` tables. When we try to save a record, there are three possibilities
    that we need to account for:'
  prefs: []
  type: TYPE_NORMAL
- en: Neither a lab check nor a plot check record exists for the given date, time,
    lab, and plot. In this case, both the lab check and plot check records will need
    to be created.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The lab check exists for the given date, time, and lab, but no corresponding
    plot check exists for the given plot. In this case, the lab check record will
    need to be updated (in case the user wants to correct the technician value), and
    the plot check record will need to be added.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both the lab check and plot check exist. In this case, both will need to be
    updated with the submitted non-primary key values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `save_record()` method we implement will need to check for these conditions
    and run the appropriate `INSERT` or `UPDATE` queries on each table.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to consider the possibility that a user will update one of the
    primary key fields when editing an existing record. What should the model do in
    this case? Let''s consider:'
  prefs: []
  type: TYPE_NORMAL
- en: From the user's point of view, each record they fill out in the application
    corresponds to a plot check.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A plot check is associated with a lab check on the basis of its date, time,
    and lab.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thus, if a user alters one of those key fields, their intention is most likely
    to associate the plot check record with a different lab check, rather than to
    alter the lab check record it is already associated with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since, from a GUI standpoint, the user is updating an existing record rather
    than adding a new one, though, it makes sense to update the plot check identified
    by the pre-change date, time, lab, and plot values with the newly entered values
    for those fields.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, when we're determining whether to run our `INSERT` or `UPDATE` queries,
    we should determine this based on the *entered data* for the lab check, but the
    *key data* for the plot check.
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin implementing this logic by writing our queries, which we will store
    in class variables to keep our `save_record()` method more concise.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll start with the lab check queries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: These queries are fairly straightforward, though note our use of a subquery
    to populate `lab_tech_id` in each case. Our application will have no idea what
    a lab tech's ID is, so we'll need to look the ID up by name. Also, take note that
    our parameter names match the names used in our model's `fields` dictionary. This
    will save us from having to reformat the record data acquired from our form.
  prefs: []
  type: TYPE_NORMAL
- en: 'The plot check queries are longer but not any more complicated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Note that the parameter names used in the `UPDATE` query's `WHERE` clause are
    prefixed with `key_`; this will allow us to update the record identified by the
    date, time, lab, and plot values from the row key, as explained previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the queries in place, we can start writing the `save_record()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The `CSVModel.save_record()` method took a record dictionary and an integer
    value, `rownum`, to determine which record would be updated (or `None` if it was
    a new record). In our database, we're using a compound key to identify a plot
    check, which we'll expect as a tuple of the date, time, lab, and plot. Therefore,
    if a `rowkey` is passed in, we'll extract its values to variables and add them
    to the record dictionary so that we can pass them to the queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to determine what kind of query to run for the lab check table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: If there is an existing lab check record with the entered date, time, and lab,
    we'll just update it (which will really just change the technician value to what
    was entered). If there is not, we'll create one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s determine which plot check operation to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This time we only need to know if a row key tuple was given to the method. If
    it was, this should be an existing record and we just want to update it. If not,
    we'll need to insert a new record.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we finish off the method by just running the two queries, passing in the
    `record` dictionary as the parameter list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Note that `psycopg2` has no problem with us passing a dictionary with extra
    parameters that aren't referenced in the query, so we don't need to bother with
    filtering unneeded items from `record`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the current seed sample for the plot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There is one last method this model needs; since our database knows what seed
    sample is currently in each plot, we want our form to populate this automatically
    for the user. We'll need a method that takes a `lab` and `plot_id` and returns
    the seed sample name.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll call it `get_current_seed_sample()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: This time, our `return` statement is not just extracting the first row of results,
    but the value of the `current_seed_sample` column from that first row. If there's
    no result, we return an empty string.
  prefs: []
  type: TYPE_NORMAL
- en: That completes our model class; now let's incorporate it into the application.
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting the Application class for the SQL backend
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before it can create a `SQLModel` instance, the `Application` class will need
    the database connection information to pass to the model: the server name, database
    name, user, and password. The host and database names aren''t going to change
    often, if at all, so we don''t need to make the user enter those each time. Instead,
    we can just add them as settings in the `SettingsModel`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: These can be saved in our JSON config file, which can be edited to switch from
    development to production, but the username and password used for authentication
    will need to be entered by the user. For that, we can use our login dialog.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing SQL logins
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The login dialog currently authenticates using hardcoded credentials in the
    `Application._simple_login()` method. This is far from ideal, so we''re going
    to use our PostgreSQL server as a production-quality authentication backend. To
    start, let''s create a new `Application` method called `_database_login()`, like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This method is analogous to our `_simple_login()` method, in that the `Application._show_login()`
    method will call it to authenticate the credentials entered by the user. Unlike
    `_simple_login()`, however, this method is an instance method, as it needs access
    to the settings and needs to save the `SQLModel` instance that it creates.
  prefs: []
  type: TYPE_NORMAL
- en: The method begins by pulling the database host and database name from the `settings`
    dictionary, then attempts to create a `SQLModel` instance using them. A `psycopg2.OperationalError`
    indicates a failure to connect to the database, most likely due to failed credentials;
    in this case, we'll return `False` from the method. Otherwise, if the connection
    is successful, we'll return `True`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we print the error message to the console. Since other problems could
    potentially cause an `OperationalError`, it would be smart to log the exception
    or otherwise make it accessible for debugging, rather than just silencing it.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use this login backend, we need only change a single line in the `_show_login()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The last change we need for SQL logins is in the `Application` class''s initializer.
    We need to make sure that the `settings` dictionary is available *before* we show
    the login dialog, since our database logins depend on the `db_host` and `db_name`
    settings. Simply move the lines that load the settings to the top of `__init__()`,
    just after calling `super().__init__()`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Updating the Application._on_save() method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since our record keys have changed from a single integer to a tuple, we need
    to make some small adjustments to our `_on_save()` method. Thanks to our efforts
    to keep the model object's interface intact, the core functionality of this method
    actually works just fine. However, when it comes to saving references to the rows
    that have been changed or updated, we can no longer rely on calculating the row
    numbers; we'll have to rely on the keys instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting in the second half of the `Application._on_save()` method, just after
    the `if errors:` block, change the code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: First, we've changed the `rownum` variable to `rowkey` to make it more descriptive
    of what the variable contains. Second, when we have a new record, we construct
    a new row key using the Date, Time, Lab, and Plot values that were passed in with
    the record. Note that now the contents of the `RecordList` widget's `_updated`
    and `_inserted` lists will be tuples rather than integers, so we'll need to update
    its code as well. We'll do that later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Removing file-based code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before we move on from the `Application` class, we need to remove some of the
    file-based code that we''ll no longer need. Delete or comment out the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: In `__init__()`, remove the line that creates the `CSVModel` instance. We no
    longer want to do this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also in `__init__()`, remove the `<<FileSelect>>` event from the `event_callbacks`
    dictionary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove the `self._on_file_select()` method definition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, over in `mainmenu.py`, we can comment out calls to the `_add_file_open()`
    method in each of our menu classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now the `Application` object is ready for SQL, let's check out our view code.
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting the DataRecordForm for SQL data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Currently our `DataRecordForm` keeps track of its record using a row number.
    This is no longer going to work, since records are identified by a compound primary
    key. We'll need to adjust the way records are loaded, and how the record form
    is labeled, so that we can accurately identify the row we're working on. We also
    need to reorder the fields so that the key values are entered first, which will
    help the auto-populate to work more smoothly.
  prefs: []
  type: TYPE_NORMAL
- en: Also, our database presents us with new possibilities for auto-filling data.
    Once we know enough to identify a Lab Check record, we can auto-fill the Technician
    field, and once we know which plot we're working with, we can auto-fill the Seed
    Sample field.
  prefs: []
  type: TYPE_NORMAL
- en: Reordering fields
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first change we can make to `DataRecordForm` is the simplest. We just need
    to reorder the fields so that the key fields Date, Time, Lab, and Plot appear
    first.
  prefs: []
  type: TYPE_NORMAL
- en: 'The updated calls (with some arguments left out) should be ordered like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Note that you need to change the `row` and `column` arguments of the `grid()`
    method calls, not just the ordering of the `LabelInput` calls.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing the load_record() method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `load_record()` method only needs two adjustments. First, we''ll replace
    the `rownum` variable with `rowkey`, to be consistent with the `Application` class.
    Second, we need to update the title text generated to identify the record, like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Once again, we have extracted the `date`, `time`, `lab`, and `plot` values from
    the key and used them to identify which record the user is currently editing.
    The remainder of the method can stay the same.
  prefs: []
  type: TYPE_NORMAL
- en: Improving auto-fill
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are two auto-population callbacks we want to have for our record form.
    First, when the user enters a `lab` and `plot` value, we want to automatically
    populate the Seed Sample field with the seed value that is currently planted in
    that `plot`. Second, when the `date`, `time`, and `lab` values have been entered,
    and we have an existing lab check that matches, we should populate the name of
    the lab tech who did that check. Of course, if our user prefers not to have data
    auto-filled, we shouldn't do either of these things.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the seed sample callback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: We begin by checking whether or not the user wants data auto-filled. If not,
    we return from the method. If they do, we fetch the Plot and Lab values from the
    form's control variables dictionary. If we have both, we use them to fetch the
    Seed Sample value from the model and set it in the form accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll do something similar with the Technician value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This time, we use the form's `date`, `time`, and `lab` values to fetch the lab
    check record, then set the Technician value from the results (or a blank string
    if there are no results). Note that we've added error handling around the `date`
    value; that's because we plan to trigger these methods from a variable trace.
    `Lab` and `Time` are both selected from `Combobox` widgets, so they will only
    change to a complete value, but `Date` is a text-entry field, so it's possible
    we'll be getting a partially entered date. There's no point in running a SQL query
    (a relatively time-consuming operation) if the `date` string isn't valid, so we've
    used `datetime.fromisoformat()` to determine if the entered `date` string is valid.
    If it's not, we just return from the method since there's nothing more to do.
  prefs: []
  type: TYPE_NORMAL
- en: 'To complete this functionality, we just need to add triggers to run the methods
    whenever the appropriate variables are updated. Add this code to `DataRecordForm.__init__()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Using a `for` loop, we've added a trace to each variable involved in determining
    the Seed Sample and Technician values. Now, these fields should get auto-populated
    whenever sufficient information is entered to determine their values.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the RecordList for the SQLModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of our `RecordList` object's most important features is the ability to select
    a record so that the `Application` object can open it in the `DataRecordForm`
    view. To do this, we have to store each record's key in its respective `Treeview`
    item's IID value. This worked easily with integer row number values, but now there
    is a problem. Recall from *Chapter 8*, *Navigating Records with Treeview and Notebook*,
    that an IID value *must be a string*. We cannot use a tuple.
  prefs: []
  type: TYPE_NORMAL
- en: To solve this problem, we just need to come up with a consistent way to connect
    our row key tuple to a string value that can be used as an IID. We'll create a
    dictionary as an instance variable that will map row keys to IID values.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `RecordList.__init__()`, add this line that creates our mapping:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to update the `populate()` method to utilize the dictionary rather
    than integer values. First, at the beginning of the method just after deleting
    the existing rows, let''s clear the dictionary of any current information, like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, find the `for` loop in this method that populates the `Treeview` and
    let''s edit the code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Since row numbers are no longer in the picture, we can remove the `enumerate()`
    call and just deal with the row data. It so happens that the four columns in the
    `cids` list are the same four that make up the key, and in the same order. So,
    we can just convert that list to a `tuple` object to create our `rowkey`. Note
    that we do need to convert each item in the key to a string; they come out of
    the database as Python objects like `date` and `int`, and we need to match them
    against the keys in the _`inserted` and _`updated` lists. Those values, pulled
    from our `DataRecordForm`, are all string values.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the key, we check if it is in one of the lists and set the `tag`
    value appropriately. Then, we'll save the output from `Treeview.insert()` as `iid`.
    When `insert()` is called without an explicit IID value, one is generated automatically
    and returned by the method. We then add our `rowkey` value to the mapping dictionary
    using the generated IID value as a key.
  prefs: []
  type: TYPE_NORMAL
- en: After the `for` loop, the last part of this method focuses the first row for
    keyboard users. To focus the first row before, we relied on the fact that the
    first IID was always `0`. Now the first IID will be an automatically generated
    value that we cannot predict before the data is loaded, so we'll have to retrieve
    the IID before we can set the selection and focus.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can do this by using the `Treeview.identify_row()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: The `identify_row()` method takes a row number and returns the IID of that row.
    Once we have that, we can pass it to `selection_set()` and `focus()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve taken care of mapping the row keys to our IIDs; now we need to update
    the `selected_id()` property method so that it returns a row key tuple. Update
    that method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Just as before, we're retrieving the selected IID using the `self.treeview.selection()`
    method. This time, though, we need to look up the row key value in the mapping
    dictionary before returning it.
  prefs: []
  type: TYPE_NORMAL
- en: The last change to `RecordList` needs to be done in the initializer. Currently,
    our first column, `Row`, displays the IID on the pretext that it is the row number.
    That's no longer the case, and as our updated call to `insert()` did not specify
    a value to display, the column is just empty. So, the best thing we can do is
    remove this column.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, that''s not possible. The `#0` column is required and cannot be removed.
    It *can*, however, be hidden. To do that, we need to set the `Treeview` widget''s
    `show` property, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The `show` property essentially determines if the `#0` column will be displayed
    or not. It can be set to `tree`, in which case the column will be shown, or `headings`,
    in which case it will be hidden. The default is `tree`, so we've changed this
    to `headings`. Now only our four data columns will be shown.
  prefs: []
  type: TYPE_NORMAL
- en: We're done!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Phew! That was quite a journey, but our SQL conversion is more or less complete.
    You should be able to launch the application, log in using your PostgreSQL credentials,
    and load and save records using the database. This represents a huge improvement
    in the application and a major shift from a simple script to append a file to
    a full-blown database application.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, of course, we aren't quite done here. Unit tests and documentation
    would all need to be updated to reflect the new model layer and other code changes.
    In addition, existing data may need to be imported into the database and users
    would need retraining to adjust to the move away from flat files. We won't be
    addressing all this in the book, but keep it in mind if you're undertaking a change
    like this in a real production environment!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to work with a relational SQL database. You
    installed and configured PostgreSQL. You converted a flat-file dataset into relational
    tables by identifying the primary key fields, choosing correct data types, and
    normalizing the data structure to reduce the possibility of inconsistencies, redundancies,
    and anomalies. You learned how to install and work with the `psycopg2` library
    for retrieving and storing data in PostgreSQL. Finally, you went through the arduous
    task of building a SQL database to hold your ABQ data, building a database model
    class to interface with the database, and converting the application code to use
    the new SQL backend.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll be reaching out to the cloud. We'll need to contact
    some remote servers using different networking protocols to exchange data. You'll
    learn about the Python standard library's module for working with HTTP, as well
    as third-party packages for connecting with REST services and transferring files
    over SFTP.
  prefs: []
  type: TYPE_NORMAL
