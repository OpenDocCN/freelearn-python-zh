<html><head></head><body>
  <div id="_idContainer266" class="Basic-Text-Frame">
    <h1 class="chapterNumber">9</h1>
    <h1 id="_idParaDest-181" class="chapterTitle">Graphs and Algorithms</h1>
    <p class="normal">Graphs<a id="_idIndexMarker730"/> are a non-linear data structure, in which the problem is represented as a network by connecting a set of nodes with edges, like a telephone network or social network. For example, in a graph, nodes can represent different cities while the links between them represent edges. Graphs are one of the most important data structures; they are used to solve many computing problems, especially when the problem is represented in the form of objects and their connection, e.g. to find out the shortest path from one city to another city. Graphs are useful data structures for solving real-world problems in which the problem can be represented as a network-like structure. In this chapter, we will be discussing the most important and popular concepts related to graphs.</p>
    <p class="normal">In this chapter, we will learn about the following concepts:</p>
    <ul>
      <li class="bulletList">The concept of the graph data structure</li>
      <li class="bulletList">How to represent a graph and traverse it</li>
      <li class="bulletList">Different operations and their implementation on graphs</li>
    </ul>
    <p class="normal">First, we will be looking into the different types of graphs.</p>
    <h1 id="_idParaDest-182" class="heading-1">Graphs</h1>
    <p class="normal">A graph<a id="_idIndexMarker731"/> is a set of a finite number of vertices (also known as nodes) and edges, in which the edges are the links between vertices, and each edge in a graph joins two distinct nodes. Moreover, a graph is a formal mathematical representation of a network, i.e. a graph <strong class="keyWord">G</strong> is an ordered pair of a set <strong class="keyWord">V</strong> of vertices and a set <strong class="keyWord">E</strong> of edges, given as <code class="inlineCode">G = (V, E)</code> in formal mathematical notation.</p>
    <p class="normal">An example<a id="_idIndexMarker732"/> of a graph is shown in <em class="italic">Figure 9.1</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_01.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.1: An example of a graph</p>
    <p class="normal">The graph <code class="inlineCode">G = (V, E)</code> in <em class="italic">Figure 9.1</em> can be described as below:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">V = {A, B, C, D, E}</code></li>
      <li class="bulletList"><code class="inlineCode">E = {{A, B}, {A, C}, {B, C}, {B, D}, {C, D}, {D, D}, {B, E}, {D, E}}</code></li>
      <li class="bulletList"><code class="inlineCode">G = (V, E)</code></li>
    </ul>
    <p class="normal">Let’s discuss some of the important definitions of a graph:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Node or vertex</strong>: A point <a id="_idIndexMarker733"/>or node<a id="_idIndexMarker734"/> in a graph is called a <a id="_idIndexMarker735"/>vertex. In the <a id="_idIndexMarker736"/>preceding diagram, the vertices or nodes are <strong class="keyWord">A</strong>, <strong class="keyWord">B</strong>, <strong class="keyWord">C</strong>, <strong class="keyWord">D</strong>, and <strong class="keyWord">E</strong> and are denoted by a dot.</li>
      <li class="bulletList"><strong class="keyWord">Edge</strong>: This is a <a id="_idIndexMarker737"/>connection between two vertices. The line connecting <strong class="keyWord">A</strong> and <strong class="keyWord">B</strong> is an example of an <a id="_idIndexMarker738"/>edge.</li>
      <li class="bulletList"><strong class="keyWord">Loop</strong>: When <a id="_idIndexMarker739"/>an edge from a node is returned to itself , that edge forms<a id="_idIndexMarker740"/> a loop, e.g. <strong class="keyWord">D </strong>node.</li>
      <li class="bulletList"><strong class="keyWord">Degree of a vertex/node</strong>: The total number of edges that are incidental on a given <a id="_idIndexMarker741"/>vertex is called the degree<a id="_idIndexMarker742"/> of that vertex. For example, the degree of the <strong class="keyWord">B</strong> vertex in the previous diagram is <code class="inlineCode">4</code>.</li>
      <li class="bulletList"><strong class="keyWord">Adjacency</strong>: This refers to <a id="_idIndexMarker743"/>the connection(s) between any two <a id="_idIndexMarker744"/>nodes; thus, if there is a connection between any two vertices or nodes, then they are said to be adjacent to each other. For example, the C node is adjacent to the A node because there is an edge between them.</li>
      <li class="bulletList"><strong class="keyWord">Path</strong>: A sequence <a id="_idIndexMarker745"/>of vertices and edges between any two nodes represents a <a id="_idIndexMarker746"/>path. For example, <strong class="keyWord">CABE</strong> represents a path from the <strong class="keyWord">C</strong> node to the <strong class="keyWord">E</strong> node.</li>
      <li class="bulletList"><strong class="keyWord">Leaf vertex</strong> (also called <em class="italic">pendant vertex</em>): A vertex or <a id="_idIndexMarker747"/>node is called a<a id="_idIndexMarker748"/> leaf vertex<a id="_idIndexMarker749"/> or pendant vertex if it has exactly one degree.</li>
    </ul>
    <p class="normal">Now, we shall take a look at the different types of graphs.</p>
    <h2 id="_idParaDest-183" class="heading-2">Directed and undirected graphs</h2>
    <p class="normal">Graphs are represented by the edges between the nodes. The connecting edges can be considered <a id="_idIndexMarker750"/>directed or undirected. If the connecting edges in a graph are <a id="_idIndexMarker751"/>undirected, then the graph is called an undirected graph, and if the <a id="_idIndexMarker752"/>connecting edges in a graph are directed, then it is called a <a id="_idIndexMarker753"/>directed graph. An undirected graph simply represents edges as lines between the nodes. There is no additional information about the relationship between the nodes, other than the fact that they are connected. For example, in <em class="italic">Figure 9.2</em>, we demonstrate an undirected graph of four nodes, <strong class="keyWord">A</strong>, <strong class="keyWord">B</strong>, <strong class="keyWord">C</strong>, and <strong class="keyWord">D</strong>, which are connected using edges: </p>
    <figure class="mediaobject"><img src="../Images/B17217_09_02.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.2: An example of an undirected graph</p>
    <p class="normal">In a <a id="_idIndexMarker754"/>directed graph, the edges provide information on the direction of connection between<a id="_idIndexMarker755"/> any two nodes in a graph. If an edge from <strong class="keyWord">A</strong> node to <strong class="keyWord">B</strong> is said to be directed, then the edge (<strong class="keyWord">A</strong>, <strong class="keyWord">B</strong>) would not be equal to the edge (<strong class="keyWord">B</strong>, <strong class="keyWord">A</strong>). The directed edges are drawn as lines with arrows, which will point in whichever direction the edge connects the two nodes. </p>
    <p class="normal">For example, in <em class="italic">Figure 9.3</em>, we show a directed graph where many nodes are connected using directed edges:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_03.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.3: An example of a directed graph</p>
    <p class="normal">The arrow of an edge determines the flow of direction. One can only move from <strong class="keyWord">A</strong> to <strong class="keyWord">B</strong>, as shown in the preceding diagram—not <strong class="keyWord">B</strong> to <strong class="keyWord">A</strong>. In a directed graph, each node (or vertex) has an indegree and an outdegree. Let’s have a look at what these are:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Indegree</strong>: The <a id="_idIndexMarker756"/>total number of edges that come into a vertex in the graph is called the indegree<a id="_idIndexMarker757"/> of that vertex. For example, in the previous diagram, the <strong class="keyWord">E</strong> node has <code class="inlineCode">1</code> indegree, due to edge <strong class="keyWord">CE</strong> coming into the <strong class="keyWord">E</strong> node.</li>
      <li class="bulletList"><strong class="keyWord">Outdegree</strong>: The <a id="_idIndexMarker758"/>total number of edges that go out from a vertex in the graph is called the outdegree<a id="_idIndexMarker759"/> of that vertex. For example, the <strong class="keyWord">E</strong> node in the previous diagram has an outdegree of <code class="inlineCode">2</code>, as it has two edges, <strong class="keyWord">EF</strong> and <strong class="keyWord">ED</strong>, going out of that node.</li>
      <li class="bulletList"><strong class="keyWord">Isolated vertex</strong>: A <a id="_idIndexMarker760"/>node or vertex is called an isolated vertex<a id="_idIndexMarker761"/> when it has a degree of zero, as shown as <strong class="keyWord">G</strong> node in <em class="italic">Figure 9.3</em>.</li>
      <li class="bulletList"><strong class="keyWord">Source vertex</strong>: A <a id="_idIndexMarker762"/>vertex is called a source vertex<a id="_idIndexMarker763"/> if it has an indegree of zero. For example, in the previous diagram, the <strong class="keyWord">A</strong> node is the source vertex.</li>
      <li class="bulletList"><strong class="keyWord">Sink vertex</strong>: A <a id="_idIndexMarker764"/>vertex is a sink vertex<a id="_idIndexMarker765"/> if it has an outdegree of zero. For example, in the previous diagram, the <strong class="keyWord">F</strong> node is the sink vertex.</li>
    </ul>
    <p class="normal">Now that we understand how directed graphs work, we can look into directed acyclic graphs.</p>
    <h2 id="_idParaDest-184" class="heading-2">Directed acyclic graphs</h2>
    <p class="normal">A <strong class="keyWord">directed acyclic graph</strong> (<strong class="keyWord">DAG</strong>) is a <a id="_idIndexMarker766"/>directed graph with no cycles; in a<a id="_idIndexMarker767"/> DAG all the edges are directed from one node to another node so that the sequence of edges never forms a closed loop. A cycle in a graph is formed when the starting node of the first edge is equal to the ending node of the last edge in a sequence.</p>
    <p class="normal">A DAG is shown in <em class="italic">Figure 9.4</em> in which all the edges in the graph are directed and the graph does not have any cycles:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_04.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.4: An example of a directed acyclic graph</p>
    <p class="normal">So, in a <a id="_idIndexMarker768"/>directed acyclic graph, if we start on any path from a given node, we<a id="_idIndexMarker769"/> never find a path that ends on the same node. A DAG has many applications, such as in job scheduling, citation graphs, and data compression.</p>
    <p class="normal">Next, we will discuss weighted graphs.</p>
    <h2 id="_idParaDest-185" class="heading-2">Weighted graphs</h2>
    <p class="normal">A weighted graph<a id="_idIndexMarker770"/> is a graph that has a numeric weight associated with the edges in<a id="_idIndexMarker771"/> the graph. A weighted graph can be either a directed or an undirected graph. The numeric weight can be used to indicate distance or cost, depending on the purpose of the graph: </p>
    <figure class="mediaobject"><img src="../Images/B17217_09_05.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.5: An example of a weighted graph</p>
    <p class="normal">Let’s consider an example – <em class="italic">Figure 9.5</em> indicates different ways to reach from <strong class="keyWord">A</strong> node to <strong class="keyWord">D</strong> node. There are two possible paths, such as from <strong class="keyWord">A</strong> node to <strong class="keyWord">D</strong> node, or it can be nodes <strong class="keyWord">A-B-C-D</strong> through <strong class="keyWord">B</strong> node and <strong class="keyWord">C</strong> node. Now, depending on the weights associated with the edges, any one of the paths can be considered better than the others for the journey – e.g. assume the weights in this graph represent the distance between two nodes, and we want to find out the shortest path between <strong class="keyWord">A-D</strong> nodes; then one possible path <strong class="keyWord">A-D</strong> has an associated cost of 40, and another possible path <strong class="keyWord">A-B-C-D</strong> has an associated cost of 25. In this case, the better path is <strong class="keyWord">A-B-C-D</strong>, which has a lower distance.</p>
    <p class="normal">Next, we will discuss bipartite graphs.</p>
    <h2 id="_idParaDest-186" class="heading-2">Bipartite graphs</h2>
    <p class="normal">A <a id="_idIndexMarker772"/>bipartite graph (also known as a bigraph) is a special graph in which all the nodes of the<a id="_idIndexMarker773"/> graph can be divided into two sets in such a way that edges connect the nodes from one set to the nodes of another set. See <em class="italic">Figure 9.6</em> for a sample bipartite graph; all the nodes of the graphs are divided into two independent sets, i.e., set U and set V, so that each edge in the graph has one end in set U and another end in set V (e.g. in edge (<em class="italic">A, B</em>), one end or one vertex is from set U, and another end or another vertex is from set V). </p>
    <p class="normal">In bipartite graphs, no edge will connect to the nodes of the same set:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_06.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.6: An example of a bipartite graph</p>
    <p class="normal">Bipartite graphs are useful when we need to model a relationship between two different classes of objects, for example, a graph of applicants and jobs, in which we may need to model the relationship between these two different groups; another example may be a bipartite graph of football players and clubs in which we may need to model if a player has played for a particular club or not.</p>
    <p class="normal">Next, we will discuss different graph representation techniques.</p>
    <h1 id="_idParaDest-187" class="heading-1">Graph representations</h1>
    <p class="normal">A graph representation<a id="_idIndexMarker774"/> technique means how we store the graph in memory, i.e., how we store the vertices, edges, and weights (if the graph is a weighted graph). Graphs can be represented with two methods, i.e. (1) an adjacency list, and (2) an adjacency matrix.</p>
    <p class="normal">An adjacency list representation is based on a linked list. In this, we represent the graph by maintaining a list of neighbors (also called an adjacent node) for every vertex (or node) of the graph. In an adjacency matrix representation of a graph, we maintain a matrix that represents which node is adjacent to which other node in the graph; i.e., the adjacency matrix has the information of every edge in the graph, which is represented by cells of the matrix.</p>
    <p class="normal">Either of these two<a id="_idIndexMarker775"/> representations can be used; however, our choice depends on the application where we will be using the graph representation. An adjacency list is preferable when we expect that the graph is going to be sparse and we will have a smaller number of edges; e.g. if a graph of 200 nodes has say 100 edges, it is better to store this kind of graph in an adjacency list, because if we use an adjacency matrix, the size of the matrix will be 200x200 with a lot of zero values. The adjacency matrix is preferable when we expect the graph to have a lot of edges, and the matrix will be dense. In the adjacency matrix, the lookup and check for the presence or absence of an edge are very easy compared to adjacency list representation.</p>
    <p class="normal">We will be discussing adjacency matrices in detail in subsequent sections. First, we will take a look at adjacency lists.</p>
    <h2 id="_idParaDest-188" class="heading-2">Adjacency lists</h2>
    <p class="normal">In this representation, all the nodes<a id="_idIndexMarker776"/> directly connected to a node x <a id="_idIndexMarker777"/>are listed in its adjacent list of nodes. The graph is represented by displaying the adjacent list for all the nodes of the graph.</p>
    <p class="normal">Two nodes, <code class="inlineCode">A</code> and <code class="inlineCode">B</code>, in the graph shown in <em class="italic">Figure 9.7</em>, are said to be adjacent if there is a direct connection between them:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_07.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.7: A sample graph of five nodes</p>
    <p class="normal">A linked list<a id="_idIndexMarker778"/> can be <a id="_idIndexMarker779"/>used to implement the adjacency list. In order to represent the graph, we need the number of linked lists equal to the total number of nodes in the graph. At each index, the adjacent nodes to that vertex are<a id="_idIndexMarker780"/> stored. For example, consider the adjacency list shown in <em class="italic">Figure 9.8</em> corresponding to the sample graph shown in <em class="italic">Figure 9.7:</em></p>
    <figure class="mediaobject"><img src="../Images/B17217_09_08.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.8: Adjacency list for the graph shown in Figure 9.7</p>
    <p class="normal">Here, the first node represents the <code class="inlineCode">A</code> vertex of the graph, with its adjacent nodes being <code class="inlineCode">B</code> and <code class="inlineCode">C</code>. The second node represents the <code class="inlineCode">B</code> vertex of the graph, with its adjacent nodes of <code class="inlineCode">E</code>, <code class="inlineCode">C</code>, and <code class="inlineCode">A</code>. Similarly, the other vertices, <code class="inlineCode">C</code>, <code class="inlineCode">E</code>, and <code class="inlineCode">F</code>, of the graph are represented with their adjacent nodes, as shown in the previous <em class="italic">Figure 9.8</em>.</p>
    <p class="normal">Using a <code class="inlineCode">list</code> for<a id="_idIndexMarker781"/> the representation is quite restrictive, because we lack the<a id="_idIndexMarker782"/> ability to directly use the vertex labels. So, to implement a graph efficiently using Python, a <code class="inlineCode">dictionary</code> data structure is used since it is more suitable to represent the graph. To implement the same graph using a dictionary data structure, we can use the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">graph = <span class="hljs-built_in">dict</span>()
graph[<span class="hljs-string">'A'</span>] = [<span class="hljs-string">'B'</span>, <span class="hljs-string">'C'</span>]
graph[<span class="hljs-string">'B'</span>] = [<span class="hljs-string">'E'</span>,<span class="hljs-string">'C'</span>, <span class="hljs-string">'A'</span>]
graph[<span class="hljs-string">'C'</span>] = [<span class="hljs-string">'A'</span>, <span class="hljs-string">'B'</span>, <span class="hljs-string">'E'</span>,<span class="hljs-string">'F'</span>]
graph[<span class="hljs-string">'E'</span>] = [<span class="hljs-string">'B'</span>, <span class="hljs-string">'C'</span>]
graph[<span class="hljs-string">'F'</span>] = [<span class="hljs-string">'C'</span>]
</code></pre>
    <p class="normal">Now we can easily establish that the <code class="inlineCode">A</code> vertex has the adjacent vertices of <code class="inlineCode">B</code> and <code class="inlineCode">C</code>. The <code class="inlineCode">F</code> vertex has the <code class="inlineCode">C</code> vertex as its only neighbor. Similarly, the <code class="inlineCode">B</code> vertex has adjacent vertices of <code class="inlineCode">E</code>, <code class="inlineCode">C</code>, and <code class="inlineCode">A</code>.</p>
    <p class="normal">The adjacency list is a preferable graph representation technique when the graph is going to be sparse and we may need to add or delete the nodes in the graph frequently. However, it is very difficult to check whether a given edge is present in the graph or not using this technique.</p>
    <p class="normal">Next, we will discuss another method of graph representation, i.e., the adjacency matrix.</p>
    <h2 id="_idParaDest-189" class="heading-2">Adjacency matrix</h2>
    <p class="normal">Another approach to <a id="_idIndexMarker783"/>representing a graph is to use an adjacency <a id="_idIndexMarker784"/>matrix. In this, the graph is represented by showing the nodes and their interconnections through edges. Using this method, the dimensions (<code class="inlineCode">V x V</code>) of a matrix are used to represent the graph, where each cell denotes an edge in the graph. A matrix<a id="_idIndexMarker785"/> is a two-dimensional array. So, the idea here is to represent the cells of the matrix with a <code class="inlineCode">1</code> or a <code class="inlineCode">0</code>, depending on whether two nodes are connected by an edge or not. We show an example graph, along with its corresponding adjacency matrix, in <em class="italic">Figure 9.9</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_09.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.9: Adjacency matrix for a given graph</p>
    <p class="normal">An <a id="_idIndexMarker786"/>adjacency matrix<a id="_idIndexMarker787"/> can be implemented using the given adjacency list. To implement the adjacency matrix, let’s take the previous dictionary-based implementation of the graph. Firstly, we have to obtain the key elements of the adjacency matrix. It is important to note that these matrix elements are the vertices of the graph. We can get the key elements by sorting the keys of the graph. The code snippet for this is as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">matrix_elements = <span class="hljs-built_in">sorted</span>(graph.keys())
cols = rows = <span class="hljs-built_in">len</span>(matrix_elements)
</code></pre>
    <p class="normal">Next, the length of the keys of the graph will be the dimensions of the adjacency matrix, which are stored in <code class="inlineCode">cols</code> and <code class="inlineCode">rows</code>. The values of the <code class="inlineCode">cols</code> and <code class="inlineCode">rows</code> are equal.</p>
    <p class="normal">So, now, we create an empty adjacency matrix of the dimensions <code class="inlineCode">cols</code> by <code class="inlineCode">rows</code>, initially filling all the values with zeros. The code snippet to initialize an empty adjacency matrix is as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">adjacency_matrix = [[<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(rows)] <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cols)]
edges_list = []
</code></pre>
    <p class="normal">The <code class="inlineCode">edges_list</code> variable will store the tuples that form the edges in the graph. For example, an edge between the A and B nodes will be stored as (<code class="inlineCode">A</code>, <code class="inlineCode">B</code>). The multidimensional array is filled using a nested <code class="inlineCode">for</code> loop:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> matrix_elements:
    <span class="hljs-keyword">for</span> neighbor <span class="hljs-keyword">in</span> graph[key]:
        edges_list.append((key, neighbor))
<span class="hljs-built_in">print</span>(edges_list)
</code></pre>
    <p class="normal">The neighbors of a vertex are obtained by <code class="inlineCode">graph[key]</code>. The key, in combination with the <code class="inlineCode">neighbor</code>, is then used to create the tuple stored in <code class="inlineCode">edges_list</code>.</p>
    <p class="normal">The output of the<a id="_idIndexMarker788"/> preceding Python code for storing the edges of the<a id="_idIndexMarker789"/> graph is as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">[('A', 'B'), ('A', 'C'), ('B', 'E'), ('B', 'C'), ('B', 'A'), ('C', 'A'), ('C', 'B'), ('C', 'E'), ('C', 'F'), ('E', 'B'), ('E', 'C'), ('F', 'C')]
</code></pre>
    <p class="normal">The next step in implementing the adjacency matrix is to fill it, using <code class="inlineCode">1</code> to denote the presence of an edge in the graph. This can be done with the <code class="inlineCode">adjacency_matrix[index_of_first_vertex][index_of_second_vertex] = 1</code> statement. The full code snippet that marks the presence of edges of the graph is as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> edge <span class="hljs-keyword">in</span> edges_list:
    index_of_first_vertex = matrix_elements.index(edge[<span class="hljs-number">0</span>])
    index_of_second_vertex = matrix_elements.index(edge[<span class="hljs-number">1</span>])
    adjacency_matrix[index_of_first_vertex][index_of_second_vertex] = <span class="hljs-number">1</span> 
<span class="hljs-built_in">print</span>(adjacency_matrix)
</code></pre>
    <p class="normal">The <code class="inlineCode">matrix_elements</code> array has its <code class="inlineCode">rows</code> and <code class="inlineCode">cols</code>, starting from <code class="inlineCode">A</code> to all other vertices with indices of <code class="inlineCode">0</code> to <code class="inlineCode">5</code>. The <code class="inlineCode">for</code> loop iterates through the list of tuples and uses the <code class="inlineCode">index</code> method to get the corresponding index where an edge is to be stored.</p>
    <p class="normal">The output of the preceding code is the adjacency matrix for the sample graph shown previously in <em class="italic">Figure 9.9</em>. The adjacency matrix produced looks like the following:</p>
    <pre class="programlisting con"><code class="hljs-con">[0, 1, 1, 0, 0]
[1, 0, 0, 1, 0]
[1, 1, 0, 1, 1]
[0, 1, 1, 0, 0]
[0, 0, 1, 0, 0]
</code></pre>
    <p class="normal">At row <code class="inlineCode">1</code> and column <code class="inlineCode">1</code>, <code class="inlineCode">0</code> represents the absence of an edge between <strong class="keyWord">A</strong> and <strong class="keyWord">A</strong>. Similarly, at row <code class="inlineCode">3</code> and column <code class="inlineCode">2</code> there is a value of <code class="inlineCode">1</code> that denotes the edge between the <strong class="keyWord">C</strong> and <strong class="keyWord">B</strong> vertices in the graph.</p>
    <p class="normal">The use of the <a id="_idIndexMarker790"/>adjacency matrix for graph representation <a id="_idIndexMarker791"/>is suitable when we have to frequently look up and check the presence or absence of an edge between two nodes in the graph, e.g. in creating routing tables in networks, searching routes in public transport applications and navigation systems, etc. Adjacency matrices are not suitable when nodes are frequently added or deleted within a graph, in those situations, the adjacency list is a better technique.</p>
    <p class="normal">Next, let us discuss different graph traversal methods in which we visit all the nodes of the given graph.</p>
    <h1 id="_idParaDest-190" class="heading-1">Graph traversals</h1>
    <p class="normal">A graph traversal<a id="_idIndexMarker792"/> means to visit all the vertices of the graph while keeping track of which nodes or vertices have already been visited and which ones have not. A graph traversal algorithm is efficient if it traverses all the nodes of the graph in the minimum possible time. Graph traversal, also known as a graph search algorithm, is quite similar to the tree traversal algorithms like <code class="inlineCode">preorder</code>, <code class="inlineCode">inorder</code>, <code class="inlineCode">postorder</code>, and level order algorithms; similar to them, in a graph search algorithm we start with a node and traverse through edges to all other nodes in the graph.</p>
    <p class="normal">A common strategy of graph<a id="_idIndexMarker793"/> traversal is to follow a path until a dead end is reached, then traverse back up until there is a point where we meet an alternative path. We can also iteratively move from one node to another in order to traverse the full graph or part of it. Graph traversal algorithms are very important in answering many fundamental problems—they can be useful to determine how to get from one vertex to another in a graph, and which path from <strong class="keyWord">A</strong> node to <strong class="keyWord">B</strong> node in a graph is better than other paths. For example, graph traversal algorithms can be useful in finding out the shortest route from one city to another in a network of cities.</p>
    <p class="normal">In the next section, we will discuss two important graph traversal algorithms: <strong class="keyWord">breadth-first search</strong> (<strong class="keyWord">BFS</strong>) and <strong class="keyWord">depth-first search</strong> (<strong class="keyWord">DFS</strong>).</p>
    <h2 id="_idParaDest-191" class="heading-2">Breadth-first traversal</h2>
    <p class="normal"><strong class="keyWord">Breadth-first search</strong> (<strong class="keyWord">BFS</strong>) works <a id="_idIndexMarker794"/>very similarly to how a level order traversal algorithm <a id="_idIndexMarker795"/>works in a tree data structure. The BFS algorithm also works level by level; it starts by visiting the root node at level 0, and then all the nodes at the first level directly connected to the root node are visited at level 1. The level 1 node has a distance of 1 from the root node. After visiting all the nodes at level 1, the level 2 nodes are visited next. Likewise, all the nodes in the graph are traversed level by level until all the nodes are visited. So, breadth-first traversal algorithms work breadthwise in the graph.</p>
    <p class="normal">A queue data structure is used to store the information of vertices that are to be visited in a graph. We begin with the starting node. Firstly, we visit that node, and then we look up all of its neighboring, or adjacent, vertices. We first visit these adjacent vertices one by one, while adding their neighbors to the list of vertices that are to be visited. We follow this process until we have visited all the vertices of the graph, ensuring that no vertex is visited twice.</p>
    <p class="normal">Let’s consider an example to better understand the working of the breadth-first traversal for graphs, using the sample shown in <em class="italic">Figure 9.10</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_10.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.10: A sample graph </p>
    <p class="normal">In <em class="italic">Figure 9.10</em>, we have a graph of five nodes on the left, and on the right, a queue data structure to store the vertices to be visited. We start visiting the first node, i.e., <strong class="keyWord">A</strong> node, and then we add all its adjacent vertices, <strong class="keyWord">B</strong>, <strong class="keyWord">C</strong>, and <strong class="keyWord">E</strong>, to the queue. Here, it is important to note that there are multiple ways of adding the adjacent nodes to the queue since there are three nodes, <strong class="keyWord">B</strong>, <strong class="keyWord">C</strong>, and <strong class="keyWord">E</strong>, that can be added to the queue as either <strong class="keyWord">BCE</strong>, <strong class="keyWord">CEB</strong>, <strong class="keyWord">CBE</strong>, <strong class="keyWord">BEC</strong>, or <strong class="keyWord">ECB</strong>, each of which would give us different tree traversal results.</p>
    <p class="normal">All of these possible solutions to the graph traversal are correct, but in this example, we add the nodes in alphabetical order just to keep things simple in the queue, i.e., <strong class="keyWord">BCE</strong>. The <strong class="keyWord">A</strong> node is visited as shown in <em class="italic">Figure 9.11</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_11.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.11: Node A is visited in breadth-first traversal</p>
    <p class="normal">Once we<a id="_idIndexMarker796"/> have visited the <strong class="keyWord">A</strong> vertex, next, we visit its first adjacent<a id="_idIndexMarker797"/> vertex, <strong class="keyWord">B</strong>, and add those adjacent vertices of vertex <strong class="keyWord">B</strong> that are not already added in the queue or not visited. In this case, we have to add the <strong class="keyWord">D</strong> vertex (since it has two vertices, <strong class="keyWord">A</strong> and <strong class="keyWord">D</strong> nodes, out of which <strong class="keyWord">A</strong> is already visited) to the queue, as shown in <em class="italic">Figure 9.12</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_12.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.12: Node B is visited in breadth-first traversal</p>
    <p class="normal">Now, after visiting the <strong class="keyWord">B</strong> vertex, we visit the next vertex from the queue—the <strong class="keyWord">C</strong> vertex. And again, add those adjacent vertices that have not already been added to the queue. In this case, there are no unrecorded vertices left, as shown in <em class="italic">Figure 9.13</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_13.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.13: Node C is visited in breadth-first traversal</p>
    <p class="normal">After <a id="_idIndexMarker798"/>visiting the <strong class="keyWord">C</strong> vertex, we visit the next vertex from the queue, the <strong class="keyWord">E</strong> vertex, as <a id="_idIndexMarker799"/>shown in <em class="italic">Figure 9.14</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_14.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.14: Node E is visited in breadth-first traversal</p>
    <p class="normal">Similarly, after visiting the <strong class="keyWord">E</strong> vertex, we visit the <strong class="keyWord">D</strong> vertex in the last step, as shown in <em class="italic">Figure 9.15</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_15.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.15: D node is visited in breadth-first traversal</p>
    <p class="normal">Therefore, the <a id="_idIndexMarker800"/>BFS algorithm for traversing the preceding graph <a id="_idIndexMarker801"/>visits the vertices in the order of <strong class="keyWord">A-B-C-E-D</strong>. This is one of the possible solutions to the BFS traversal for the preceding graph, but we can get many possible solutions, depending on how we add the adjacent nodes to the queue.</p>
    <p class="normal">To understand the implementation of this algorithm in Python, we will use another example of an undirected graph, as shown in <em class="italic">Figure 9.16</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_16.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.16: An undirected sample graph</p>
    <p class="normal">The adjacency list for the graph shown in <em class="italic">Figure 9.16</em> is as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">graph = <span class="hljs-built_in">dict</span>()
graph[<span class="hljs-string">'A'</span>] = [<span class="hljs-string">'B'</span>, <span class="hljs-string">'G'</span>, <span class="hljs-string">'D'</span>]
graph[<span class="hljs-string">'B'</span>] = [<span class="hljs-string">'A'</span>, <span class="hljs-string">'F'</span>, <span class="hljs-string">'E'</span>]
graph[<span class="hljs-string">'C'</span>] = [<span class="hljs-string">'F'</span>, <span class="hljs-string">'H'</span>]
graph[<span class="hljs-string">'D'</span>] = [<span class="hljs-string">'F'</span>, <span class="hljs-string">'A'</span>]
graph[<span class="hljs-string">'E'</span>] = [<span class="hljs-string">'B'</span>, <span class="hljs-string">'G'</span>]
graph[<span class="hljs-string">'F'</span>] = [<span class="hljs-string">'B'</span>, <span class="hljs-string">'D'</span>, <span class="hljs-string">'C'</span>]
graph[<span class="hljs-string">'G'</span>] = [<span class="hljs-string">'A'</span>, <span class="hljs-string">'E'</span>]
graph[<span class="hljs-string">'H'</span>] = [<span class="hljs-string">'C'</span>]
</code></pre>
    <p class="normal">After storing the<a id="_idIndexMarker802"/> graph using the adjacency list, the implementation of the <a id="_idIndexMarker803"/>BFS algorithm is as follows, which we will discuss with an example in detail:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> deque
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">breadth_first_search</span><span class="hljs-function">(</span><span class="hljs-params">graph, root</span><span class="hljs-function">):</span>
    visited_vertices = <span class="hljs-built_in">list</span>()
    graph_queue = deque([root])
    visited_vertices.append(root)
    node = root
    <span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(graph_queue) &gt; <span class="hljs-number">0</span>:
        node = graph_queue.popleft()
        adj_nodes = graph[node]
        remaining_elements = <span class="hljs-built_in">set</span>(adj_nodes).difference(<span class="hljs-built_in">set</span>(visited_vertices))
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(remaining_elements) &gt; <span class="hljs-number">0</span>:
             <span class="hljs-keyword">for</span> elem <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(remaining_elements):
                 visited_vertices.append(elem)
                 graph_queue.append(elem)
    <span class="hljs-keyword">return</span> visited_vertices
</code></pre>
    <p class="normal">To traverse this graph using the breadth-first algorithm, we first initialize the queue and the source node. We start traversal from <strong class="keyWord">A</strong> node. Firstly, <strong class="keyWord">A</strong> node is queued and added to the list of visited nodes. Afterward, we use a <code class="inlineCode">while</code> loop to affect the traversal of the graph. In the first iteration of the <code class="inlineCode">while</code> loop, node A is dequeued.</p>
    <p class="normal">Next, all the unvisited adjacent nodes of <strong class="keyWord">A</strong> node, which are <strong class="keyWord">B</strong>, <strong class="keyWord">D</strong>, and <strong class="keyWord">G</strong>, are sorted in alphabetical order and queued up. The queue now contains nodes <strong class="keyWord">B</strong>, <strong class="keyWord">D</strong>, and <strong class="keyWord">G</strong>. This is shown in <em class="italic">Figure 9.17</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_17.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.17: Node A is visited using the BFS algorithm</p>
    <p class="normal">For<a id="_idIndexMarker804"/> implementation, we add all these nodes (<strong class="keyWord">B</strong>, <strong class="keyWord">D</strong>, <strong class="keyWord">G</strong>) to the<a id="_idIndexMarker805"/> list of visited nodes, and then we add the adjacent/neighboring nodes of these nodes. At this point, we start another iteration of the <code class="inlineCode">while</code> loop. After visiting <strong class="keyWord">A</strong> node, <strong class="keyWord">B</strong> node is dequeued. Out of its adjacent nodes (<strong class="keyWord">A</strong>, <strong class="keyWord">E</strong>, and <strong class="keyWord">F</strong>), <strong class="keyWord">A</strong> node has already been visited. Therefore, we only queue the <strong class="keyWord">E</strong> and <strong class="keyWord">F</strong> nodes in alphabetical order, as shown in <em class="italic">Figure 9.18</em>.</p>
    <p class="normal">When we want to find out whether a set of nodes is in the list of visited nodes, we use the <code class="inlineCode">remaining_elements = set(adj_nodes).difference(set(visited_vertices))</code> statement. This uses the <code class="inlineCode">set</code> object’s <code class="inlineCode">difference</code> method to find the nodes that are in <code class="inlineCode">adj_nodes</code>, but not in <code class="inlineCode">visited_vertices</code>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_18.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.18: Node B is visited using the BFS algorithm</p>
    <p class="normal">The queue <a id="_idIndexMarker806"/>now holds the following nodes at this point—<strong class="keyWord">D</strong>, <strong class="keyWord">G</strong>, <strong class="keyWord">E</strong>, and <strong class="keyWord">F</strong>. The <strong class="keyWord">D</strong> node is dequeued, but all of its adjacent nodes have been visited, so we<a id="_idIndexMarker807"/> simply dequeue it. The next node at the front of the queue is <strong class="keyWord">G</strong>. We dequeue the <strong class="keyWord">G</strong> node, but we also find out that all its adjacent nodes have been visited because they are in the list of visited nodes. So, the <strong class="keyWord">G</strong> node is also dequeued. We dequeue the <strong class="keyWord">E</strong> node too because all of its adjacent nodes have also been visited. The only node in the queue now is the <strong class="keyWord">F</strong> node; this is shown in <em class="italic">Figure 9.19</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_19.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.19: Node E is visited using the BFS algorithm</p>
    <p class="normal">The <strong class="keyWord">F</strong> node is dequeued, and we see that out of its adjacent nodes, <strong class="keyWord">B</strong>, <strong class="keyWord">D</strong>, and <strong class="keyWord">C</strong>, only <strong class="keyWord">C</strong> has not been visited. We then enqueue the <strong class="keyWord">C</strong> node and add it to the list of visited nodes, as shown in <em class="italic">Figure 9.20</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_20.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.20: Node E is visited using the BFS algorithm</p>
    <p class="normal">Then, the <strong class="keyWord">C</strong> node is dequeued. <strong class="keyWord">C</strong> has the adjacent nodes of <strong class="keyWord">F</strong> and <strong class="keyWord">H</strong>, but <strong class="keyWord">F</strong> has already been visited, leaving the <strong class="keyWord">H</strong> node. The <strong class="keyWord">H</strong> node is enqueued and added to the list of visited nodes. Finally, the<a id="_idIndexMarker808"/> last iteration of the <code class="inlineCode">while</code> loop will lead to the <strong class="keyWord">H</strong> node <a id="_idIndexMarker809"/>being dequeued. </p>
    <p class="normal">Its only adjacent node, <strong class="keyWord">C</strong>, has already been visited. Once the queue is empty, the loop breaks. This is shown in <em class="italic">Figure 9.21</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_21.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.21: Final node H is visited using the BFS algorithm</p>
    <p class="normal">The output of the traversal of the given graph using the BFS algorithm is <strong class="keyWord">A</strong>, <strong class="keyWord">B</strong>, <strong class="keyWord">D</strong>, <strong class="keyWord">G</strong>, <strong class="keyWord">E</strong>, <strong class="keyWord">F</strong>, <strong class="keyWord">C</strong>, and <strong class="keyWord">H</strong>.</p>
    <p class="normal">When we run the above BFS code on the graph shown in <em class="italic">Figure 9.16</em> using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(breadth_first_search(graph, <span class="hljs-string">'A'</span>))
</code></pre>
    <p class="normal">We get the following sequence of nodes when we traverse the graph shown in <em class="italic">Figure 9.16</em>:</p>
    <pre class="programlisting con"><code class="hljs-con">['A', 'B', 'D', 'G', 'E', 'F', 'C', 'H']
</code></pre>
    <p class="normal">In the worst-case scenario, each node and the edge will need to be traversed, and hence each node will be enqueued and dequeued at least once. The time taken for each enqueue and dequeue operation is O(1), so the total time for this is O(V). Further, the time spent scanning the adjacency list for every vertex is O(E). So, the total time complexity of the BFS algorithm is <code class="inlineCode">O(|V| + |E|)</code>, where <code class="inlineCode">|V|</code> is the number of vertices or nodes, while <code class="inlineCode">|E|</code> is the number of edges in the graph.</p>
    <p class="normal">The <a id="_idIndexMarker810"/>BFS algorithm is very useful for constructing the shortest path traversal in a<a id="_idIndexMarker811"/> graph with minimal iterations. As for some of the real-world applications of BFS, it can be used to create an efficient web crawler in which multiple levels of indexes can be maintained for search engines, and it can maintain a list of closed web pages from a source web page. BFS can also be useful for navigation systems in which neighboring locations can be easily retrieved from a graph of different locations.</p>
    <p class="normal">Next, we will discuss another graph traversal algorithm, i.e., the depth-first search algorithm.</p>
    <h2 id="_idParaDest-192" class="heading-2">Depth-first search</h2>
    <p class="normal">As the name<a id="_idIndexMarker812"/> suggests, the <strong class="keyWord">depth-first search</strong> (<strong class="keyWord">DFS</strong>) or traversal algorithm traverses the graph similar to how<a id="_idIndexMarker813"/> the <code class="inlineCode">preorder</code> traversal algorithm works in trees. In the DFS algorithm, we traverse the tree in the depth of any particular path in the graph. As such, child nodes are visited first before sibling nodes.</p>
    <p class="normal">In this, we start with the root node; firstly we visit it, and then we see all the adjacent vertices of the current node. We start visiting one of the adjacent nodes. If the edge leads to a visited node, we backtrack to the current node. And, if the edge leads to an unvisited node, then we go to that node and continue processing from that node. We continue the same process until we reach a dead end when there is no unvisited node; in that case, we backtrack to previous nodes, and we stop when we reach the root node while backtracking.</p>
    <p class="normal">Let’s take an example to understand the working of the DFS algorithm using the graph shown in <em class="italic">Figure 9.22</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_22.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.22: An example graph for understanding the DFS algorithm</p>
    <p class="normal">We start by <a id="_idIndexMarker814"/>visiting the <strong class="keyWord">A</strong> node, and then we look at the neighbors of <a id="_idIndexMarker815"/>the <strong class="keyWord">A</strong> vertex, then a neighbor of that neighbor, and so on. After visiting the <strong class="keyWord">A</strong> vertex, we visit one of its neighbors, <strong class="keyWord">B</strong> (in our example, we sort alphabetically; however, any neighbor can be added), as shown in <em class="italic">Figure 9.23</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_23.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.23: Nodes A and B are visited in depth-first traversal </p>
    <p class="normal">After visiting the <strong class="keyWord">B</strong> vertex, we look at another neighbor of <strong class="keyWord">A</strong>, that is, <strong class="keyWord">S</strong>, as there is no vertex connected to <strong class="keyWord">B</strong> that can be visited. Next, we look for the neighbors of the <strong class="keyWord">S</strong> vertex, which are the <strong class="keyWord">C</strong> and <strong class="keyWord">G</strong> vertices. We visit <strong class="keyWord">C</strong> as shown in <em class="italic">Figure 9.24</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_24.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.24: Node C is visited in depth-first traversal</p>
    <p class="normal">After<a id="_idIndexMarker816"/> visiting the <strong class="keyWord">C</strong> node, we visit its neighboring vertices, <strong class="keyWord">D</strong> and <strong class="keyWord">E</strong>, as <a id="_idIndexMarker817"/>shown in <em class="italic">Figure 9.25</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_25.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.25: D and E nodes are visited in depth-first traversal</p>
    <p class="normal">Similarly, after <a id="_idIndexMarker818"/>visiting the <strong class="keyWord">E</strong> vertex, we visit the <strong class="keyWord">H</strong> and <strong class="keyWord">G</strong> vertices, as<a id="_idIndexMarker819"/> shown in <em class="italic">Figure 9.26</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_26.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.26: H and F nodes are visited in depth-first traversal</p>
    <p class="normal">Finally, we visit the <strong class="keyWord">F</strong> node, as shown in <em class="italic">Figure 9.27</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_27.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.27: F node is visited in depth-first traversal</p>
    <p class="normal">The output of <a id="_idIndexMarker820"/>the DFS traversal is <strong class="keyWord">A-B-S-C-D-E-H-G-F</strong>.</p>
    <p class="normal">To implement <a id="_idIndexMarker821"/>DFS, we start with the adjacency list of the given graph. Here is the adjacency list of the preceding graph:</p>
    <pre class="programlisting code"><code class="hljs-code">graph = <span class="hljs-built_in">dict</span>()
graph[<span class="hljs-string">'A'</span>] = [<span class="hljs-string">'B'</span>, <span class="hljs-string">'S'</span>]
graph[<span class="hljs-string">'B'</span>] = [<span class="hljs-string">'A'</span>]
graph[<span class="hljs-string">'S'</span>] = [<span class="hljs-string">'A'</span>,<span class="hljs-string">'G'</span>,<span class="hljs-string">'C'</span>]
graph[<span class="hljs-string">'D'</span>] = [<span class="hljs-string">'C'</span>]
graph[<span class="hljs-string">'G'</span>] = [<span class="hljs-string">'S'</span>,<span class="hljs-string">'F'</span>,<span class="hljs-string">'H'</span>]
graph[<span class="hljs-string">'H'</span>] = [<span class="hljs-string">'G'</span>,<span class="hljs-string">'E'</span>]
graph[<span class="hljs-string">'E'</span>] = [<span class="hljs-string">'C'</span>,<span class="hljs-string">'H'</span>]
graph[<span class="hljs-string">'F'</span>] = [<span class="hljs-string">'C'</span>,<span class="hljs-string">'G'</span>]
graph[<span class="hljs-string">'C'</span>] = [<span class="hljs-string">'D'</span>,<span class="hljs-string">'S'</span>,<span class="hljs-string">'E'</span>,<span class="hljs-string">'F'</span>]
</code></pre>
    <p class="normal">The implementation of the DFS algorithm begins with creating a list to store the visited nodes. The <code class="inlineCode">graph_stack</code> stack variable is used to aid the traversal process. We are using a Python list as a stack. </p>
    <p class="normal">The starting node, called <code class="inlineCode">root</code>, is passed with the graph’s adjacency matrix, <code class="inlineCode">graph</code>. Firstly, the <code class="inlineCode">root</code> is pushed onto the stack. The statement <code class="inlineCode">node = root</code> is for holding the first node in the stack:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">depth_first_search</span><span class="hljs-function">(</span><span class="hljs-params">graph, root</span><span class="hljs-function">):</span>
    visited_vertices = <span class="hljs-built_in">list</span>()
    graph_stack = <span class="hljs-built_in">list</span>()
    graph_stack.append(root)
    node = root
        <span class="hljs-keyword">while</span> graph_stack: 
            <span class="hljs-keyword">if</span> node <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> visited_vertices: 
                visited_vertices.append(node) 
            adj_nodes = graph[node] 
            <span class="hljs-keyword">if</span> <span class="hljs-built_in">set</span>(adj_nodes).issubset(<span class="hljs-built_in">set</span>(visited_vertices)): 
                graph_stack.pop() 
                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(graph_stack) &gt; <span class="hljs-number">0</span>: 
                    node = graph_stack[-<span class="hljs-number">1</span>] 
                <span class="hljs-keyword">continue</span> 
            <span class="hljs-keyword">else</span>: 
                remaining_elements = <span class="hljs-built_in">set</span>(adj_nodes).difference(<span class="hljs-built_in">set</span>(visited_vertices)) 
            first_adj_node = <span class="hljs-built_in">sorted</span>(remaining_elements)[<span class="hljs-number">0</span>] 
            graph_stack.append(first_adj_node) 
            node = first_adj_node 
        <span class="hljs-keyword">return</span> visited_vertices 
</code></pre>
    <p class="normal">The body <a id="_idIndexMarker822"/>of the <code class="inlineCode">while</code> loop will be executed, provided the stack is <a id="_idIndexMarker823"/>not empty. If the <code class="inlineCode">node</code> under consideration is not in the list of visited nodes, we add it. All adjacent nodes of <code class="inlineCode">node</code> are collected by <code class="inlineCode">adj_nodes = graph[node]</code>. If all the adjacent nodes have been visited, we pop the top node from the stack and set <code class="inlineCode">node</code> to <code class="inlineCode">graph_stack[-1]</code>. Here, <code class="inlineCode">graph_stack[-1]</code> is the top node on the stack. The <code class="inlineCode">continue</code> statement jumps back to the beginning of the <code class="inlineCode">while</code> loop’s test condition.</p>
    <p class="normal">If, on the other hand, not all the adjacent nodes have been visited, then the nodes that are yet to be visited are obtained by finding the difference between the <code class="inlineCode">adj_nodes</code> and <code class="inlineCode">visited_vertices</code> with the <code class="inlineCode">remaining_elements = set(adj_nodes).difference(set(visited_vertices))</code> statement.</p>
    <p class="normal">The first item within <code class="inlineCode">sorted(remaining_elements)</code> is assigned to <code class="inlineCode">first_adj_node</code>, and pushed onto the stack. We then point the top of the stack to this node.</p>
    <p class="normal">When the <code class="inlineCode">while</code> loop exits, we will return <code class="inlineCode">visited_vertices</code>.</p>
    <p class="normal">We will now explain the working of the source code by relating it to the previous example. The <strong class="keyWord">A</strong> node is chosen as our starting node. <strong class="keyWord">A</strong> is pushed onto the stack and added to the <code class="inlineCode">visited_vertices</code> list. In doing so, we mark it as having been visited. The <code class="inlineCode">graph_stack</code> stack is implemented with a simple Python list. Our stack now has <strong class="keyWord">A</strong> as its only element. We examine the <strong class="keyWord">A</strong> node’s adjacent nodes, <strong class="keyWord">B</strong> and <strong class="keyWord">S</strong>. To test whether all the adjacent nodes of <strong class="keyWord">A</strong> have been visited, we use the <code class="inlineCode">if</code> statement:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword">if</span> <span class="hljs-built_in">set</span>(adj_nodes).issubset(<span class="hljs-built_in">set</span>(visited_vertices)):
        graph_stack.pop()
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(graph_stack) &gt; <span class="hljs-number">0</span>:
            node = graph_stack[-<span class="hljs-number">1</span>]
        <span class="hljs-keyword">continue</span>
</code></pre>
    <p class="normal">If all the <a id="_idIndexMarker824"/>nodes have been visited, we pop the top of the stack. If <a id="_idIndexMarker825"/>the <code class="inlineCode">graph_stack</code> stack is not empty, we assign the node on top of the stack to <code class="inlineCode">node</code>, and start the beginning of another execution of the body of the <code class="inlineCode">while</code> loop. The <code class="inlineCode">set(adj_nodes).issubset(set(visited_vertices))</code> statement will evaluate to <code class="inlineCode">True</code> if all the nodes in <code class="inlineCode">adj_nodes</code> are a subset of <code class="inlineCode">visited_vertices</code>. If the <code class="inlineCode">if</code> statement fails, it means that some nodes remain to be visited. We obtain that list of nodes with <code class="inlineCode">remaining_elements = set(adj_nodes).difference(set(visited_vertices))</code>.</p>
    <p class="normal">Referring to the diagram, the <strong class="keyWord">B</strong> and <strong class="keyWord">S</strong> nodes will be stored in <code class="inlineCode">remaining_elements</code>. We will access the list in alphabetical order as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">    first_adj_node = <span class="hljs-built_in">sorted</span>(remaining_elements)[<span class="hljs-number">0</span>]
    graph_stack.append(first_adj_node)
    node = first_adj_node
</code></pre>
    <p class="normal">We sort <code class="inlineCode">remaining_elements</code> and return the first node to <code class="inlineCode">first_adj_node</code>. This will return <strong class="keyWord">B</strong>. We push the <strong class="keyWord">B</strong> node onto the stack by appending it to the <code class="inlineCode">graph_stack</code>. We prepare the <strong class="keyWord">B</strong> node for access by assigning it to <code class="inlineCode">node</code>.</p>
    <p class="normal">On the next iteration of the <code class="inlineCode">while</code> loop, we add the <strong class="keyWord">B</strong> node to the list of <code class="inlineCode">visited nodes</code>. We discover that the only adjacent node to <strong class="keyWord">B</strong>, which is <strong class="keyWord">A</strong>, has already been visited. Because all the adjacent nodes of <strong class="keyWord">B</strong> have been visited, we pop it off the stack, leaving <strong class="keyWord">A</strong> as the only element on the stack. We return to <strong class="keyWord">A</strong> and examine whether all of its adjacent nodes have been visited. The <strong class="keyWord">A</strong> node now has <strong class="keyWord">S</strong> as the only unvisited node. We push <strong class="keyWord">S</strong> to the stack and begin the whole process again.</p>
    <p class="normal">The output of the traversal is <code class="inlineCode">A-B-S-C-D-E-H-G-F</code>.</p>
    <p class="normal">The time complexity of DFS is O(V+E) when we use an adjacency list, and O(V<sup class="superscript">2</sup>) when we use an adjacency matrix for graph representation. The time complexity of DFS with the adjacency list is lower because getting the adjacent nodes is easier, whereas it is not efficient with the adjacency matrix.</p>
    <p class="normal">DFS can be <a id="_idIndexMarker826"/>applied to solving maze problems, finding connected<a id="_idIndexMarker827"/> components, cycle detection in graphs, and finding the bridges of a graph, among other use cases.</p>
    <p class="normal">We have discussed very important graph traversal algorithms; now let us discuss some more useful graph-related algorithms for finding the spanning tree from the given graph. Spanning trees are useful for several real-world problems such as the traveling salesman problem.</p>
    <h1 id="_idParaDest-193" class="heading-1">Other useful graph methods</h1>
    <p class="normal">It is very often that we need to<a id="_idIndexMarker828"/> use graphs for finding a path between two nodes. Sometimes, it is necessary to find all the paths between nodes, and in some situations, we might need to find the shortest path between nodes. For example, in routing applications, we generally use various algorithms to determine the shortest path from the source node to the destination node. For an unweighted graph, we would simply determine the path with the lowest number of edges between them. If a weighted graph is given, we have to calculate the total weight of passing through a set of edges.</p>
    <p class="normal">Thus, in a different situation, we may have to find the longest or shortest path using different algorithms, such as a <strong class="keyWord">Minimum Spanning Tree</strong>, which we look into in the next section.</p>
    <h2 id="_idParaDest-194" class="heading-2">Minimum Spanning Tree</h2>
    <p class="normal">A <strong class="keyWord">Minimum Spanning Tree</strong> (<strong class="keyWord">MST</strong>) is a<a id="_idIndexMarker829"/> subset of the edges of the connected graph <a id="_idIndexMarker830"/>with an edge-weighted graph that connects all the nodes of the graph, with the lowest possible total edge weights and no cycle. More formally, given a connected graph G, where G = (V, E) with real-valued edge weights, an MST is a subgraph with a subset of the edges <img src="../Images/B17217_09_001.png" alt="" style="height: 1.2em !important; vertical-align: -0.10em !important;"/> so that the sum of edge weights is minimum and there is no cycle. There are many possible spanning trees that can connect all the nodes of the graph without any cycle, but the the minimum weight spanning tree is a spanning tree that has the lowest total edge weight (also called cost) among all other possible spanning trees. An example graph is shown in <em class="italic">Figure 9.28</em> along with its corresponding MST (on the right) in which we can observe that all the nodes are connected and have a subset of edges taken from the original graph (on the left). </p>
    <p class="normal">The MST has the lowest total weight of all the edges, i.e. (1+4+2+4+5 = 16) among all the other possible spanning trees:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_28.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.28: A sample graph with the corresponding Minimum Spanning Tree</p>
    <p class="normal">The <a id="_idIndexMarker831"/>MST has diverse real-world applications. They are mainly <a id="_idIndexMarker832"/>used in network design for road congestion, hydraulic cables, electric cable networks, and even cluster analysis.</p>
    <p class="normal">First, let us discuss Kruskal’s minimum spanning tree algorithm.</p>
    <h2 id="_idParaDest-195" class="heading-2">Kruskal’s Minimum Spanning Tree algorithm</h2>
    <p class="normal">Kruskal’s algorithm is a<a id="_idIndexMarker833"/> widely used algorithm for <a id="_idIndexMarker834"/>finding the spanning tree from a given weighted, connected, and undirected graph. It is based on the greedy approach, as we firstly find the edge with the lowest weight and add it to the tree, and then in each iteration, we add the edge with the lowest weight to the spanning tree so that we do not form a cycle. In this algorithm, initially, we treat all the vertices of the graph as a separate tree, and then in each iteration we select edge with the lowest weight in such a way that it does not form a cycle. These separate trees are combined, and it grows to form a spanning tree. We repeat this process until all the nodes are processed. The algorithm works as follows:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Initialize an empty MST (M) with zero edges</li>
      <li class="numberedList">Sort all the edges according to their weights</li>
      <li class="numberedList">For each edge from the sorted list, we add them one by one to the MST (M) in such a way that it does not form a cycle</li>
    </ol>
    <p class="normal">Let’s consider an example.</p>
    <p class="normal">We start by <a id="_idIndexMarker835"/>selecting the edge with the lowest weight (weight 1), as represented by the dotted line shown in <em class="italic">Figure 9.29</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_29.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.29: Selecting the first edge with the lowest weight in the spanning tree</p>
    <p class="normal">After selecting the <a id="_idIndexMarker836"/>edge with weight 1, we select the edge with weight 2 and then the edge with weight 3, since these are the next lowest weights, as shown in <em class="italic">Figure 9.30</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_30.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.30: Selecting edges with wieghts 2 and 3 in the spanning tree</p>
    <p class="normal">Similarly, we <a id="_idIndexMarker837"/>select the next edges with <a id="_idIndexMarker838"/>weights 4 and 5 respectively as shown in <em class="italic">Figure 9.31</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_31.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.31: Selecting edges with weights 4 and 5 in the spanning tree</p>
    <p class="normal">Next, we select the next edge with weight 6 and make it a dotted line. After that, we see that the lowest weight is 7 but if we select it, it makes a cycle, so we ignore it. Next, we check the edge with weight 8, and then 9, which are also ignored because they will also form a cycle. So, the next edge with the lowest weight, 10, is selected. This is shown in <em class="italic">Figure 9.32</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_32.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.32: Selecting edges with weights 6 and 10 in the spanning tree</p>
    <p class="normal">Finally, we <a id="_idIndexMarker839"/>see the following spanning tree <a id="_idIndexMarker840"/>using Kruskal’s algorithm, as shown in <em class="italic">Figure 9.33</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_33.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.33: The final spanning tree created using Kruskal’s algorithm</p>
    <p class="normal">Kruskal’s algorithm has many real-world applications, such as solving the traveling salesman problem (TSP), in which starting from one city, we have to visit all the different cities in a network with the minimum total cost and without visiting the same city twice. There are many other applications, such as TV networks, tour operations, LAN networks, and electric grids. </p>
    <p class="normal">The time <a id="_idIndexMarker841"/>complexity of Kruskal’s algorithm is O (E log (E)) or O (E log(V)), where E is the number of edges and V is the number of <a id="_idIndexMarker842"/>vertices.</p>
    <p class="normal">Now, let us discuss one more popular MST algorithm in the next section.</p>
    <h2 id="_idParaDest-196" class="heading-2">Prim’s Minimum Spanning Tree algorithm</h2>
    <p class="normal">Prim’s <a id="_idIndexMarker843"/>algorithm is also based on a greedy <a id="_idIndexMarker844"/>approach to find the minimum cost spanning tree. Prim’s algorithm is very similar to the Dijkstra algorithm for finding the shortest path in a graph. In this algorithm, we start with an arbitrary node as a starting point, and then we check the outgoing edges from the selected nodes and traverse through the edge that has the lowest cost (or weights). The terms cost and weight are used interchangeably in this algorithm. So, after starting from the selected node, we grow the tree by selecting the edges, one by one, that have the lowest weight and do not form a cycle. The algorithm works as follows:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">Create a dictionary that holds all the edges and their weights</li>
      <li class="numberedList">Get the edges, one by one, that have the lowest cost from the dictionary and grow the tree in such a way that the cycle is not formed</li>
      <li class="numberedList">Repeat step 2 until all the vertices are visited</li>
    </ol>
    <p class="normal">Let us consider an example to understand the working of Prim’s algorithm. Assuming that we arbitrarily select <strong class="keyWord">A</strong> node, we then check all the outgoing edges from <strong class="keyWord">A</strong>. Here, we have two options, <strong class="keyWord">AB</strong> and <strong class="keyWord">AC</strong>; we select edge <strong class="keyWord">AC</strong> since it has less cost/weight (weight 1), as shown in <em class="italic">Figure 9.34</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_34.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.34: Selecting edge AC in constructing the spanning tree using Prim’s algorithm</p>
    <p class="normal">Next, we check the lowest outgoing edges from edge <strong class="keyWord">AC</strong>. We have options <strong class="keyWord">AB</strong>, <strong class="keyWord">CD</strong>, <strong class="keyWord">CE</strong>, <strong class="keyWord">CF</strong>, out of which we select edge <strong class="keyWord">CF</strong>, which has the lowest weight of 2. Likewise, we grow the tree, and next we select the lowest weighted edge, i.e., <strong class="keyWord">AB</strong>, as shown in <em class="italic">Figure 9.35</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_35.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.35: Selecting edge AB in constructing the spanning tree using Prim’s algorithm</p>
    <p class="normal">Afterward, we<a id="_idIndexMarker845"/> select edge <strong class="keyWord">BD</strong>, which has a <a id="_idIndexMarker846"/>weight of 3, and similarly, next, we select edge <strong class="keyWord">DG</strong>, which has the lowest weight of 4. This is shown in <em class="italic">Figure 9.36</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_36.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.36: Selecting edges BD and DG in constructing the spanning tree using Prim’s algorithm</p>
    <p class="normal">Next, we select edges <strong class="keyWord">FE</strong> and <strong class="keyWord">GH</strong>, which have weights of 6 and 10 respectively, as shown in <em class="italic">Figure 9.37</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_37.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.37: Selecting edges FE and GH in constructing the spanning tree using Prim’s algorithm</p>
    <p class="normal">Next, whenever we try to include any more edges, a cycle is formed, so we ignore those edges. Finally, we obtain the spanning tree, which is shown below in <em class="italic">Figure 9.38</em>:</p>
    <figure class="mediaobject"><img src="../Images/B17217_09_38.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.38: The final spanning tree using Prim’s algorithm</p>
    <p class="normal">Prim’s <a id="_idIndexMarker847"/>algorithm also has many real-world<a id="_idIndexMarker848"/> applications. For all the applications where we can use Kruskal’s algorithm, we can also use Prim’s algorithm. Other applications include road networks, game development, etc.</p>
    <p class="normal">Since both Kruskal’s and Prim’s MST algorithms are used for the same purpose, which one should be used? In general, it depends on the structure of the graph. For a graph with <strong class="keyWord">C</strong> vertices and <strong class="keyWord">E</strong> edges, Kruskal’s algorithm’s worst-case time complexity is O(E logV), and Prim’s algorithm has a time complexity of O(E + V logV). So, we can observe that Prim’s algorithm works better when we have a dense graph, whereas Kruskal’s algorithm is better when we have a sparse graph.</p>
    <h1 id="_idParaDest-197" class="heading-1">Summary</h1>
    <p class="normal">A graph is a non-linear data structure, which is very important due to the large number of real-world applications it has. In this chapter, we have discussed different ways to represent a graph in Python, using lists and dictionaries. Further, we learned two very important graph traversal algorithms, i.e., depth-first search (DFS) and breadth-first search (BFS). Moreover, we also discussed two very important algorithms for finding an MST, i.e. Kruskal’s algorithm and Prim’s algorithm.</p>
    <p class="normal">In the next chapter, we will discuss searching algorithms and the various methods using which we can efficiently search for items in lists.</p>
    <h1 id="_idParaDest-198" class="heading-1">Exercises</h1>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">What is the maximum number of edges (without self-loops) possible in an undirected simple graph with five nodes?</li>
      <li class="numberedList">What do we call a graph in which all the nodes have equal degrees?</li>
      <li class="numberedList">Explain what cut vertices are and identify the cut vertices in the given graph:</li>
    </ol>
    <figure class="mediaobject"><img src="../Images/B17217_09_39.png" alt=""/></figure>
    <p class="packt_figref">Figure 9.39: A sample graph</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="4">Assuming a graph G of order n, what will be the maximum number of cut vertices possible in graph G? </li>
    </ol>
    <h1 class="heading-1">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with the author and other readers: <a href="https://packt.link/MEvK4"><span class="url">https://packt.link/MEvK4</span></a></p>
    <p class="normal"><img src="../Images/QR_Code14212497725512230621.png" alt=""/></p>
  </div>
</body></html>