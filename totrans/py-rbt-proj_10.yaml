- en: Making a Guard Robot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I am sure you must have seen the movie *I, Robot* or *Chappie*. After watching
    the movie, a lot of people would be intrigued by the idea of making a robot that
    would work to protect and guard you. However, the security systems that are the
    state of the art can hardly be classified as a robot. In this chapter, we will
    take a step ahead in the lane of vision processing and make a guard robot. Its
    purpose would be to guard your gate and if an unknown person comes over to the
    gate it would start to trigger an alarm. However, the interesting thing is that
    the robot would not trigger any alarm if a known person comes home. What's more
    is that it would clear the way and get out of the door area to let you in. Once
    you are inside, it will automatically be back in its position to guard and get
    back to work yet again.
  prefs: []
  type: TYPE_NORMAL
- en: How cool would that be? So let's get going and make this robot a reality.
  prefs: []
  type: TYPE_NORMAL
- en: Face detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, before we go ahead and detect faces, we need to tell the robot what a face
    is and what it looks like. Raspberry Pi does not know how exactly to classify
    a face from a pumpkin. So firstly, we would be using a dataset to tell the robot
    what our face looks like; thereafter, we will start recognizing the faces as we
    go. So let's go ahead and see how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, you need to install a dependency called Haar-cascade. This is a cascade-dependent algorithm
    that is used to detect objects rapidly. To do this, go ahead and run the following
    syntax on your terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This will save the `haarcascades` file onto your Raspberry Pi and you will
    be ready to use it. Once you are done, see the following code but write it over
    your Raspberry only after you have seen the following explanation line by line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, this might look like something out of our world and pretty much every
    thing is new, so let''s understand what we are doing here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have installed Haar-cascade, we are basically taking in the data which
    is already trained onto our Raspberry Pi. In this line, we are opening a classifier,
    which is reading the data from a file named `haarcascade_frontalface_default.xml`.
    This is the file that will tell Raspberry Pi whether the image captured is a frontal
    face or not. This file has a trained dataset to enable the Raspberry to do so.
    Now, we are using a function of OpenCV called `CascadeClassifier()`, which uses
    this learned data from the file mentioned and then classifies the images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This will capture the video from the camera with the port number `0`. So whenever
    the data needs to be captured, the variable `cap` can be used instead of writing
    the whole program.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We have understood this line in the previous chapter. It is simply capturing
    the image from the camera and saving it in the variable called `img` and then `ret`
    will return true if the capture is done or false if there is an error.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We have used this line previously as well. What it is doing is, it is simply
    converting the captured image using the `cv2.cvtColour()` function. The arguments
    passed in it are the following `img`, which will basically tell which image needs
    to be converted. Thereafter, `cv2.COLOR_BGR2GRAY` will tell from which image type
    it has to be converted into what.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `face_cascade.detectMultiScale()` function is a function of `face_cascade`.
    It detects the objects of various sizes and creates a rectangle of a similar size
    around it. The values returned to the variable faces would be the `x` and `y`
    coordinates of the object detected along with the width and height of the object
    as well. Hence, we need to define the size and position of the detected object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In the previous line of code, we have taken the values of the position and the
    height of the rectangle. However, we still haven't drawn one in the actual picture.
    What this `for` loop will do is, it'll add a rectangle to the image using the
    `cv2.rectangle()` function. `img` is telling which image needs to be worked on. `(x,y)`
    is defining the starting coordinates of the position of the object. The value
    `(x+w, y+h)` is defining the end point of the rectangle. The value `(255,0,0)`
    is defining the color and argument `2` is defining the thickness of the line.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ec518dd5-ca51-4f9f-8be4-289922921837.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In this line of code, we simply use the `imshow()` function to give the final
    output, which will have the image overlayed by the rectangle we just drew. This
    will indicate that we have successfully identified the image. The `'img'` argument will
    tell the name of the window and the second `img` will tell the function which
    image needs to be shown.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This line is simply waiting to take the key press of `q`. Whenever the user
    presses the `q` key, the `if` statement would become true, which will thereby
    break the infinite loop.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we are releasing the cameras using `cap.release()` and then closing
    all the windows using `cv2.destoryAllWindows()`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, go ahead and run the code and see whether it is able to detect your face
    or not. Good luck!
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the face
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All right, we have detected the face by using a few lines of code, but I would
    not consider it to be a very big victory as we were fighting using the sword made
    by other developers. The learning set imported was a generic face learned set.
    However, in this chapter, we will go ahead and make our very own learning set
    to recognize a specific human face. This is really a cool thing and I'm sure you
    will love doing it.
  prefs: []
  type: TYPE_NORMAL
- en: So, let's get started. As you did earlier, go through the explanation first
    and then write the code so that you understand it very well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, we are using the program to capture the images of the object that
    needs to be detected. In our case, this object will be a person and his face.
    So, let''s see what we need to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As you have seen earlier, we are using the preceding two lines of code to import
    the learned dataset and also to start the camera.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'As we will be training the system to learn a specific face, it is very important
    that the program knows who it is detecting either by name or ID. This will help
    us clarify who we have detected. So, to go ahead and detect a person by face,
    we need to provide his ID, which is being done in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This is exactly the same as we did in the previous section of code. Refer to
    it if you need explanation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now, this line of code might also sound to you like a repetition; however, there
    is an addition to it. In this function, two arguments have been passed instead
    of one. The first is `grey` and the second is the minimum and maximum size of
    the object that can be detected. This is important to make sure that the object
    detected is big enough for the learning process to happen.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are using the same `for` loop to perform the following condition.
    So the loop will only be true when the face is detected. Whenever it is detected,
    the `sampleNum` variable would be incremented by `1` by counting the number of
    faces detected. Further, to capture the images onto our system, we need the following
    line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: What it does is, it simply saves the image onto a folder by the name `dataSet/User`.
    It is very important to be able to make a folder by this name yourself. If you
    don't do this, then it would go haywire when it does not find the folder where
    it is supposed to save. `+str(id)` will save the name by the ID of the person
    and increment it with the number of samples counted using `+str(sampleNum)`. Furthermore,
    we have mentioned that the image would be saved by the format `.jpg` and finally `gray[y:y+h,
    x:x+w]` is selecting the part of the image that contains the face.
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the program beyond this point is self explanatory and I suspect
    you can understand it on your own. In very simple English, this would save the
    images in a folder and will keep doing so, until it reaches 20 images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have captured the images, it''s time to make the system learn the
    images and understand how to recognize them. To do this, we need to install something
    called the `pillow` library. Installing it is easy. All you need to do is, write
    the following line in the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This `pillow` library would help us read the dataset. We will understand more
    in a moment. Once this is installed, let''s go ahead and see how we are doing
    the learning part. So go ahead and understand the following code and then let''s
    get going:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Alien might be the word which might come in your head after seeing this code,
    but it sure won''t be alien after you have gone through this explanation. So let''s
    see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: It is creating a recognizer using the `cv2.face.LBPHFaceRecognizer_create()` function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This line here tells where the captured data is stored in Raspberry Pi. We have
    already made a folder by this name and it contains the images that we have stored
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here we are defining the function named `getImageID(path)`.
  prefs: []
  type: TYPE_NORMAL
- en: This join function will join the path with `f`. Now, `f` is a variable containing
    the filename as it loops through the list of files inside the folder defined as
    path using `os.listdir(path)`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The `for` loop in this line will be true for every image that we have and will
    run the code inside of it. What `Image.open(imagePath).convert('L')` does is,
    it simply covers the image in monochrome format. Using this line, every image
    that we are having would be converted into monochrome.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: OpenCV works with `numpy` array; hence, we need to convert the images to the
    desired format. To do this, we are using a `faceNp` variable to call the `np.array()`
    function. This function converts the images into `numpy` array of name `faceImg`
    and with 8-bit integer value, as we have passed the argument `unit8`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In this line, we are using a variable to call the `int()` function, which will
    split the path name for the images being captured. Why are we doing this? This
    is done to extract the ID number from the actual filename. Hence, we are doing
    this using the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Here, using `faces.append(faceNp)`, we are adding the data into the array by
    the name of `faces` and the data being added is `faceNp`. Then, we are printing
    the `ID` of that image.
  prefs: []
  type: TYPE_NORMAL
- en: Once done, `IDs.append(ID)` will add the `ID` to the array `IDs`. This whole
    process is being done as the function that we would be using for training would
    only take in the values in the form of an array. So we have to convert the entire
    data in the form of an array and fetch it to the trainer.
  prefs: []
  type: TYPE_NORMAL
- en: So the entire explanation so far was defining the function named `getImageId(Path)`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now this line would return the values of `IDs` of the faces which will be further
    used to train the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In the first line here, the `getImageID(path)` function would take in the path
    of the any image and return the `Ids` of the images. Then, `faces` would have
    the array data of the images.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in `recognizer.train(faces, np.array(Ids))`, we are using a function
    of `recognizer` called `train` to train the system based on their images. The
    arguments passed here are that `faces` has the array of the images. Furthermore, `np.array(Ids)`
    is the array, which is returned by the function defined by the name `getImageID()`.
  prefs: []
  type: TYPE_NORMAL
- en: Once the system is trained using the following program, we would save the trained
    data to a file. This is done using the `recognizer.save()` function. The argument
    passed in it is the name and the extension of the file saved.
  prefs: []
  type: TYPE_NORMAL
- en: It can be a little intense and sometimes confusing as well. However, it will
    seem easy once you do it. Now, it's time that you go ahead and make the system
    learn about your face and its data.
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing the face
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have learned how to make our system learn, it''s time to use that
    learned data and recognize the face. So without much talking, let''s go ahead
    and understand how this would be done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: In this code, there are not a lot of new things that you might encounter. It
    is very similar to the first code that we started with in this chapter. Essentially,
    it is also doing the same work. The only difference is that it recognizes the
    person by his ID. So, let's see what is different and how well it performs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, most of the code is repetitive. So instead of going through all of it,
    I will only touch on the ones which are new. Here we go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Like last time, we were drawing a rectangle over an identified image. However,
    this time there are places where overlay has to be done with some text as well.
    So here we are choosing the font that we need to use in this program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: With this line, the prediction is taking place using the function of the recognizer
    called `predict()`. This predicts the images and returns the `id` of the detected
    image.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Now, finally, if the `id` is equal to `1`, then the value of `id` would be changed
    to `BEN`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The `putText()` function will put a text on the detected object. The definition
    of each of the arguments is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`img`: This is the image on which the text has to be put.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`str(id)`: This is the string that needs to be printed, in our case it would
    print the ID of the person.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(x, y+h)`: This is the position where the text would be printed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`font`: This is the font of the printed text. In our case, it would be the
    value of the font defined earlier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2`: This is the font scale, that is, how big the font would be. This can be
    similar to magnification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(255,0,0)`: This is the color of the font.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`1`: This is the thickness of the font.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this program, we would be able to find out if the learning set is working
    as per our requirement. Once you have written the code, try identifying the people
    with it and see whether it works accurately. If the accuracy is not satisfactory,
    then you may want to take more than 20 samples for learning. Conduct a few trials
    and I am sure you would reach perfection very soon.
  prefs: []
  type: TYPE_NORMAL
- en: Making the guard robot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have understood how the learning works and how the learned data
    can be used to identify people, it''s time to put it to use. As the name of the
    chapter suggests, we will be making a guard robot using this technology. Now,
    let''s have a look at the following program. Before you start programming, take
    out the robotic vehicle you had and make the connection like we did before in
    [Chapter 6](17f222ca-2716-430f-a87b-0b37352f5ae0.xhtml), *Bluetooth-Controlled
    Robotic Car*. Attach the motor, motor driver, and Raspberry Pi. Once you have
    done that, then write the following code. This code is utilizing all the learning
    of the previous programs in the chapter and we would be able to distinguish between
    an intruder and a resident of the house based on vision processing. So let''s
    get going:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9a88f57-272e-415d-a2b4-222f672bcaf4.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As always, we will only be looking at the peculiar changes in the program, a
    lot of it will be carried over from the previous chapter. So we will try not to
    repeat the explanation unless necessary.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Just as a recap, we are defining two functions, namely, `backwards`, `reverse`,
    and `stop`. These functions will help us move the vehicle in the direction in
    which we want.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This line is importing the previously learned dataset by the name of `harrcascade_frontalface_default.xml`.
    This will help us recognize any face that comes in front of the camera.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: In this piece of the code, we are identifying the face and taking decisions
    based on it. As we have done earlier, if the face is detected, then its corresponding
    ID would be given by the program. However, no ID would be given if the face is
    not detected by the previously learned dataset in which any face could be detected.
    Hence, according to the program, if the `id == 1`, then the robotic vehicle would
    move forward moving away from the path, thereafter it would stop for `5` seconds
    and get back to where it was earlier. In case the ID generated is anything except
    `1`, then the Buzzer would be turned on for `5` seconds alerting the user.
  prefs: []
  type: TYPE_NORMAL
- en: By using this system, anyone who is identified can be let inside the premises;
    however, if the person is not identified, then the alarm would be triggered.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned how to detect objects using a prelearned dataset.
    We also learned how to make our very own learned dataset for a specific object.
    Finally, we have used all of that learning to make a guard robot, who will guard
    our home using the power of vision processing.
  prefs: []
  type: TYPE_NORMAL
