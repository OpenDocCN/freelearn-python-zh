# 为什么要进行GPU编程？

事实证明，除了能够为视频游戏渲染图形外，**图形处理单元**（**GPU**）还为普通消费者提供了一种便捷的方式进行*大规模并行* *计算*——现在普通人可以在当地的电子商店购买一张价值2000美元的现代GPU卡，将其插入家中的个人电脑，几乎立即就可以用于计算能力，而这种计算能力在5年或10年前只能在顶级公司和大学的超级计算实验室中获得。近年来，GPU的开放可访问性在许多方面已经显而易见，这可以通过简要观察新闻来揭示——加密货币挖矿者使用GPU生成比特币等数字货币，遗传学家和生物学家使用GPU进行DNA分析和研究，物理学家和数学家使用GPU进行大规模模拟，人工智能研究人员现在可以编程GPU来撰写剧本和作曲，而主要的互联网公司，如谷歌和Facebook，使用带有GPU的服务器*农场*进行大规模机器学习任务……等等。

本书主要旨在让您迅速掌握GPU编程，以便您也可以尽快开始使用它们的强大功能，无论您的最终目标是什么。我们旨在涵盖如何编程GPU的核心要点，而不是提供GPU工作的复杂技术细节和原理图。在本书的末尾，我们将提供更多资源，以便您可以进一步专门化，并应用您对GPU的新知识。（有关特定所需的技术知识和硬件的进一步细节，请参阅本节后面的内容。）

在本书中，我们将使用**CUDA**，这是NVIDIA推出的**通用GPU**（**GPGPU**）编程框架，最早发布于2007年。虽然CUDA专为NVIDIA GPU而设计，但它是一个成熟稳定的平台，相对容易使用，提供了一套无与伦比的第一方加速数学和人工智能相关库，并且在安装和集成方面几乎没有麻烦。此外，还有现成的标准化Python库，如PyCUDA和Scikit-CUDA，使得渴望成为GPU程序员的人更容易接触GPGPU编程。出于这些原因，我们选择在本书中使用CUDA。

CUDA始终发音为coo-duh，而不是缩写C-U-D-A！CUDA最初代表“计算统一设备架构”，但Nvidia已经放弃了这个缩写，现在将CUDA作为一个大写的专有名词。

我们现在将开始介绍GPU编程的旅程，并概述**阿姆达尔定律**。阿姆达尔定律是一种简单但有效的方法，用于估计将程序或算法转移到GPU上可以获得的潜在速度增益；这将帮助我们确定是否值得重新编写我们的代码以利用GPU。然后，我们将简要回顾如何使用*cProfile*模块对我们的Python代码进行分析，以帮助我们找到代码中的瓶颈。

本章的学习成果如下：

+   了解阿姆达尔定律

+   在代码的上下文中应用阿姆达尔定律

+   使用*cProfile*模块对Python代码进行基本分析

# 技术要求

本章建议安装Anaconda Python 2.7：

[https://www.anaconda.com/download/](https://www.anaconda.com/download/)

本章的代码也可以在GitHub上找到：

[https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)

有关先决条件的更多信息，请查看本书的前言；有关软件和硬件要求，请查看[https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)中的README部分。

# 并行化和阿姆达尔定律

在我们深入了解并发解锁GPU的潜力之前，我们首先要意识到它们的计算能力相对于现代英特尔/AMD中央处理单元（CPU）的优势并不在于它的时钟速度比CPU更高，也不在于单个核心的复杂性或特定设计。一个单独的GPU核心实际上相当简单，并且与现代单个CPU核心相比处于劣势，后者使用了许多花哨的工程技巧，比如分支预测来减少计算的**延迟**。**延迟**指的是执行单个计算的开始到结束的持续时间。

GPU的强大之处在于它的核心比CPU多得多，这意味着**吞吐量**有了巨大的提升。这里的**吞吐量**指的是可以同时执行的计算数量。让我们使用一个类比来更好地理解这意思。GPU就像一条非常宽的城市道路，设计成可以同时处理许多行驶缓慢的汽车（高吞吐量，高延迟），而CPU就像一条狭窄的高速公路，一次只能容纳几辆车，但可以更快地将每辆车送到目的地（低吞吐量，低延迟）。

我们可以通过查看这些新GPU有多少核心来了解吞吐量的增加。举个例子，普通的英特尔或AMD CPU只有2到8个核心，而入门级的消费级NVIDIA GTX 1050 GPU有640个核心，而新的顶级NVIDIA RTX 2080 Ti有4,352个核心！我们可以利用这种大规模的吞吐量，只要我们知道如何正确地**并行化**任何我们希望加速的程序或算法。通过**并行化**，我们的意思是重写程序或算法，以便我们可以将工作负载并行地在多个处理器上同时运行。让我们从现实生活中想一个类比。

假设你正在建造一座房子，你已经准备好了所有的设计和材料。你雇了一个劳工，你估计需要100个小时来建造这座房子。假设这个特定的房子可以以这样的方式建造，即每增加一个劳工，工作就可以完美地分配给他们，也就是说，两个劳工需要50个小时，四个劳工需要25个小时，十个劳工需要10个小时来建造这座房子——建造你的房子所需的时间将是100除以你雇佣的劳工数量。这是一个**可并行化的任务**的例子。

我们注意到，这个任务对于两个劳工来说完成的速度是原来的两倍，对于十个劳工来说完成的速度是原来的十倍（也就是说，**并行**完成），而不是一个劳工独自建造房子（也就是说，**串行**完成）——也就是说，如果*N*是劳工的数量，那么速度将是*N*倍。在这种情况下，*N*被称为我们的任务并行化速度的**加速比**。

在我们开始编写给定算法的并行版本之前，我们经常首先估计一下并行化对我们任务可能带来的*潜在* *加速*。这可以帮助我们确定是否值得花费资源和时间来编写我们程序的并行版本。因为现实生活比我们在这里给出的例子更复杂，很明显我们不可能始终完美地并行化每个程序——大多数情况下，我们的程序只有一部分可以很好地并行化，而其余部分将不得不串行运行。

# 使用阿姆达尔定律

我们现在将推导**阿姆达尔定律**，这是一个简单的算术公式，用于估计将一部分串行程序代码并行化到多个处理器上可能带来的潜在速度增益。我们将继续使用我们之前建造房子的类比来做这件事。

上次，我们只考虑了房子的实际物理建造作为整个时间持续时间，但现在，我们还将把设计房子所需的时间考虑在内。假设世界上只有一个人有能力设计你的房子——也就是你——并且你需要100小时来设计你的房子的计划。世界上没有其他人能够与你的建筑才华相比，因此这部分任务无法在其他建筑师之间分配，因此无论你拥有什么资源或可以雇佣多少人，设计你的房子都需要100小时。因此，如果你只有一名劳工来建造你的房子，建造你的房子所需的整个时间将是200小时——你设计它需要100小时，一名劳工建造它需要100小时。如果我们雇佣两名劳工，这将需要150小时——设计房子的时间仍然是100小时，而建造将需要50小时。很明显，建造房子所需的总时间将是100 + 100 / *N*，其中*N*是我们雇佣的劳工数量。

现在，让我们退一步思考一下，如果我们只雇用一名劳工来建造房子需要多少时间——我们最终使用这个来确定我们雇用额外劳工时的加速度；也就是说，这个过程变得快了多少倍。如果我们只雇用一名劳工，我们会发现设计和建造房子需要相同的时间——100小时。因此，我们可以说，设计所花费的时间是.5（50%），建造房子所花费的时间也是.5（50%）——当然，这两部分加起来是1，也就是100%。当我们增加劳工时，我们想要与这个进行比较——如果我们有两名劳工，建造的时间减半，因此与我们任务的原始串行版本相比，这将花费.5 + .5/2 = .75（75%）的时间，原始任务的.75 x 200小时是150小时，因此我们可以看到这是有效的。此外，我们可以看到，如果我们有*N*名劳工，我们可以使用公式.5 + .5 / N来计算我们*并行化*的建造所需的时间百分比。

现在，让我们确定通过增加额外的劳工我们获得的*加速度*。如果有两名劳工，建造一座房子只需要75%的时间，我们可以取.75的倒数来确定我们并行化的加速度——也就是说，加速度将是1 / .75，比我们只有一名劳工时快大约1.33倍。在这种情况下，我们可以看到，如果有*N*名劳工，加速度将是1 / (.5 + .5 / *N*)。

我们知道，随着我们增加越来越多的劳工，.5 / N会缩小到接近0，因此我们可以看到在并行化这个任务时，你可以获得的加速度总是有一个上限，即1 / (.5 + 0) = 2。我们可以将原始串行时间除以估计的最大加速度，以确定此任务将花费的绝对最短时间——200 / 2 = 100小时。

我们刚刚应用的用于确定并行编程中加速度的原则被称为**阿姆达尔定律**。它只需要知道原始串行程序中可并行执行时间的比例，即*p*，以及我们可用的处理器核心数*N*。

在这种情况下，不可并行化代码的执行时间比例始终为*1-p*，因此我们只需要知道*p*。

我们现在可以使用**阿姆达尔定律**来计算加速度，如下所示：

![](assets/6cadaf5b-8271-4a68-97f5-c0ef0c7ce418.png)

总之，Amdahl's Law是一个简单的公式，允许我们粗略（非常粗略）地估计一个可以至少部分并行化的程序的潜在加速。这可以提供一个大致的想法，即是否值得编写特定串行程序的并行版本，前提是我们知道我们可以并行化代码的比例（*p*），以及我们可以在其上运行并行化代码的核心数（*N*）。

# Mandelbrot集

我们现在准备看一个非常标准的并行计算示例，我们将在本文中稍后重新讨论——一个生成*Mandelbrot集*图像的算法。让我们首先确切地定义我们的意思。

对于给定的复数*c*，我们为![](assets/dd84683c-b705-45c0-9e1c-38a047267cc3.png)定义一个递归序列，其中![](assets/c18dfdf9-11a0-4f03-bc42-fe6b3eb9bd04.png)和![](assets/28ea6645-7e3f-4dfe-abd3-218ad0efc60d.png)对于![](assets/432f297f-deb2-4c14-a670-d20f5651a213.png)。如果|*z[n]*|随着*n*增加到无穷大仍然受到2的限制，那么我们将说*c*是Mandelbrot集的成员。

回想一下，我们可以将复数可视化为驻留在二维笛卡尔平面上，其中*x*轴代表实部分量，y轴代表虚部分量。因此，我们可以很容易地用一个非常吸引人（并且众所周知）的图形来可视化Mandelbrot集。在这里，我们将在复数笛卡尔平面上用浅色表示Mandelbrot集的成员，用深色表示非成员，如下所示：

![](assets/9808a92f-5a3b-42e2-bf31-ee4297cd94ea.png)

现在，让我们考虑如何在Python中生成这个集合。首先，我们必须考虑一些事情——因为显然我们无法检查每一个复数是否在Mandelbrot集中，我们必须选择一个特定的范围进行检查；我们必须确定我们将考虑每个范围内的多少点（*宽度，高度*）；以及我们将检查的|*z[n]*|的最大值（`max_iters`）。我们现在可以准备实现一个生成Mandelbrot集图形的函数——在这里，我们通过在*串行*中迭代图中的每一个点来实现这一点。

我们将首先导入NumPy库，这是一个我们在本文中将大量使用的数值库。我们在`simple_mandelbrot`函数中实现这里。我们首先使用NumPy的`linspace`函数生成一个将充当离散复平面的格点（接下来的代码应该相当简单）：

```py
import numpy as np

def simple_mandelbrot(width, height, real_low, real_high, imag_low, imag_high, max_iters):

     real_vals = np.linspace(real_low, real_high, width)
     imag_vals = np.linspace(imag_low, imag_high, height)

     # we will represent members as 1, non-members as 0.

     mandelbrot_graph = np.ones((height,width), dtype=np.float32)

     for x in range(width):

         for y in range(height):

             c = np.complex64( real_vals[x] + imag_vals[y] * 1j  )           
             z = np.complex64(0)

             for i in range(max_iters):

                 z = z**2 + c

                 if(np.abs(z) > 2):
                     mandelbrot_graph[y,x] = 0
                     break

     return mandelbrot_graph
```

现在，我们想要添加一些代码来将Mandelbrot集的图像转储到PNG格式文件中，所以让我们在开头添加适当的标头：

```py
from time import time
import matplotlib
# the following will prevent the figure from popping up
matplotlib.use('Agg')
from matplotlib import pyplot as plt
```

现在，让我们添加一些代码来生成Mandelbrot集并将其转储到文件中，并使用时间函数来计算这两个操作的时间：

```py
if __name__ == '__main__':

     t1 = time()
     mandel = simple_mandelbrot(512,512,-2,2,-2,2,256, 2)
     t2 = time()
     mandel_time = t2 - t1

     t1 = time()
     fig = plt.figure(1)
     plt.imshow(mandel, extent=(-2, 2, -2, 2))
     plt.savefig('mandelbrot.png', dpi=fig.dpi)
     t2 = time()

     dump_time = t2 - t1

     print 'It took {} seconds to calculate the Mandelbrot graph.'.format(mandel_time)
     print 'It took {} seconds to dump the image.'.format(dump_time)
```

现在让我们运行这个程序（这也可以在GitHub存储库的文件夹`1`中的`mandelbrot0.py`文件中找到）：

![](assets/c06de047-84d9-45c7-b526-fa42221273bf.png)

生成Mandelbrot集大约需要14.62秒，转储图像大约需要0.11秒。正如我们所看到的，我们逐点生成Mandelbrot集；不同点的值之间没有相互依赖，因此，这是一个固有的可并行化函数。相比之下，转储图像的代码无法并行化。

现在，让我们从Amdahl's Law的角度来分析这个问题。如果我们在这里并行化我们的代码，我们可以得到什么样的加速？总的来说，程序的两部分共计大约需要14.73秒才能运行；因为我们可以并行化Mandelbrot集的生成，我们可以说可并行化代码的执行时间部分是 *p* = 14.62 / 14.73 = .99。这个程序有99%的可并行性！

我们可能会得到什么样的加速？嗯，我目前正在使用一台配有640个核心的入门级GTX 1050 GPU的笔记本电脑；因此，当我们使用这个公式时，我们的*N*将是640。我们计算速度提升如下：

![](assets/28a9b78a-7113-4023-bfeb-6538e158f111.png)

这绝对非常好，这表明我们值得努力编程使我们的算法使用GPU。请记住，阿姆达尔定律只是一个非常粗略的估计！当我们将计算卸载到GPU时，将会有其他考虑因素，比如CPU发送和接收数据到GPU的额外时间；或者卸载到GPU的算法只能部分并行化。

# 对代码进行性能分析

在前面的例子中，我们看到我们可以使用Python中的标准`time`函数来分别计时不同的函数和组件。虽然这种方法对我们的小例子程序效果很好，但对于调用许多不同函数的大型程序来说，这种方法并不总是可行，其中一些函数可能值得我们投入精力并行化，或者甚至在CPU上进行优化。我们的目标是找到程序的瓶颈和热点，即使我们在每个函数调用周围使用`time`，我们可能会错过一些东西，或者可能有一些系统或库调用我们甚至没有考虑到，这些调用可能会拖慢速度。在我们考虑重写代码在GPU上运行之前，我们必须始终遵循著名的美国计算机科学家唐纳德·克努斯的智慧话语：过早优化是万恶之源。

我们使用所谓的**分析器**来找到代码中的热点和瓶颈。**分析器**将方便地让我们看到程序花费最多时间的地方，并让我们相应地进行优化。

# 使用cProfile模块

我们将主要使用*cProfile*模块来检查我们的代码。这个模块是一个标准库函数，包含在每个现代Python安装中。我们可以从命令行运行分析器，使用`-m cProfile`，并指定我们要按每个函数花费的累积时间来组织结果，然后用`>`操作符将输出重定向到文本文件中。

这将在Linux Bash或Windows PowerShell命令行上都可以使用。

现在让我们试一试：

![](assets/9c107054-44a8-4242-804f-a40a43808776.png)

我们现在可以用我们喜欢的文本编辑器查看文本文件的内容。让我们记住，程序的输出将包含在文件的开头：

![](assets/374abc78-403e-4068-b78f-3e019bd0638c.png)

现在，由于我们没有删除原始示例中对`time`的引用，我们在开头的前两行看到了它们的输出。然后我们可以看到在程序中进行的函数调用总数，以及运行它所花费的累积时间。

随后，我们有一个程序中调用的函数列表，按照累积耗时最长的函数到最短的顺序排列；第一行是程序本身，而第二行是我们程序中的`simple_mandelbrot`函数。（请注意，这里的时间与我们用`time`命令测量的时间一致）。之后，我们可以看到许多与将Mandelbrot图形转储到文件相关的库和系统调用，所有这些调用所花费的时间相对较少。我们使用*cProfile*的输出来推断给定程序中的瓶颈在哪里。

# 总结

使用GPU而不是CPU的主要优势是其增加的吞吐量，这意味着我们可以在GPU上同时执行更多*并行*代码，而不是在CPU上；GPU无法使递归算法或非并行化算法变得更快。我们看到一些任务，比如建房子的例子，只能部分并行化——在这个例子中，我们无法加快*设计*房子的过程（在这种情况下本质上是*串行*的），但我们可以通过雇佣更多的工人来加快*施工*的过程（在这种情况下是可并行化的）。

我们使用这个类比来推导阿姆达尔定律，这是一个公式，可以在我们知道可并行代码执行时间百分比以及我们将运行此代码所需的处理器数量时，给出程序潜在加速的粗略估计。然后，我们应用了阿姆达尔定律来分析一个生成曼德勃罗集并将其转储到图像文件的小程序，并且我们确定这将是一个很好的候选者，可以并行化到GPU上。最后，我们以简要概述使用*cPython*模块对代码进行性能分析结束；这使我们能够看到程序中的瓶颈在哪里，而无需显式计时函数调用。

现在我们已经有了一些基本概念，并且有了学习GPU编程的动力，我们将在下一章中设置基于Linux或Windows 10的GPU编程环境。然后我们将立即进入GPU编程的世界，在接下来的章节中，我们将实际编写一个基于GPU的曼德勃罗程序的版本，这是我们在本章中看到的。

# 问题

1.  本章的曼德勃罗示例中有三个`for`语句；然而，我们只能并行化前两个。为什么我们不能在所有的`for`循环上并行化呢？

1.  当我们将阿姆达尔定律应用于将串行CPU算法卸载到GPU时，有什么是阿姆达尔定律没有考虑到的吗？

1.  假设您独家获得了三个全新的绝密GPU，它们在所有方面都相同，只是核心数量不同——第一个有131,072个核心，第二个有262,144个核心，第三个有524,288个核心。如果您将曼德勃罗示例并行化并卸载到这些GPU上（生成一个512 x 512像素的图像），第一个GPU和第二个GPU之间的计算时间会有区别吗？第二个GPU和第三个GPU之间呢？

1.  在阿姆达尔定律的背景下，您能想到指定某些算法或代码块为*可并行化*存在什么问题吗？

1.  为什么我们应该使用性能分析器而不只是使用Python的`time`函数？
