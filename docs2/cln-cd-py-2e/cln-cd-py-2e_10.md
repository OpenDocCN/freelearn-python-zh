# 10

# 清洁架构

在本章的最后，我们关注的是整个系统设计中的所有部分是如何相互配合的。这更偏向于理论性的章节。鉴于主题的性质，深入探讨更底层的细节会过于复杂。此外，目的正是要避开这些细节，假设在前几章中探索的所有原则都已吸收，并专注于大规模系统的设计。

本章的主要目标如下：

+   设计长期可维护的软件系统

+   通过维护质量属性有效地进行软件项目工作

+   研究所有应用于代码的概念如何与系统总体相关联

本章探讨了清洁代码如何演变成清洁架构，反之亦然，清洁代码也是良好架构的基石。一个软件解决方案如果具有质量，则是有效的。架构需要通过实现质量属性（性能、可测试性、可维护性等）来实现这一点。但代码也需要在每个组件上实现这一点。

第一部分首先探讨代码与架构之间的关系。

# 从清洁代码到清洁架构

本节讨论了在前几章中强调的概念，当我们考虑大型系统的方面时，它们以略微不同的形式再次出现。这与适用于更详细设计以及代码的概念也适用于大型系统和架构有有趣的相似之处。

在前几章中探讨的概念与单一应用程序相关，通常是一个项目，可能是一个源代码版本控制系统（Git）的单个存储库（或几个）。这并不是说那些设计理念只适用于代码，或者它们在考虑架构时没有用处，原因有两个：代码是架构的基础，而且如果代码编写不仔细，无论架构考虑得多周全，系统都会失败。

其次，一些在前几章中提到的原则不仅适用于代码，而是设计理念。最明显的例子来自设计模式。它们是高级抽象。有了它们，我们可以快速了解我们的架构中某个组件可能的样子，而不必深入了解代码的细节。

但大型企业系统通常由许多这样的应用程序组成，现在是时候开始从更大设计的角度思考，即分布式系统。

在接下来的章节中，我们将讨论本书中已经讨论过的主要主题，但现在是从整个系统的角度来考虑。

如果软件架构有效，那么它就是好的。在好的架构中，最常见的方面是所谓的质量属性（如可扩展性、安全性、性能和耐用性是最常见的）。这很有道理；毕竟，你希望你的系统能够处理负载的增加而不会崩溃，并且能够在不需要维护的情况下连续工作不定期的时间，同时也能够扩展以支持新的需求。

但架构的操作方面也使其变得清晰。如可操作性、持续集成以及发布变更的难易程度等因素也会影响系统的整体质量。

## 关注点分离

在一个应用程序内部，存在多个组件。它们的代码被划分为其他子组件，如模块或包，模块被划分为类或函数，类被划分为方法。在整个书中，我们一直强调将这些组件保持尽可能小，尤其是在函数的情况下——函数应该只做一件事，并且要小。

提出了几个理由来证明这一论点。小的函数更容易理解、跟踪和调试。它们也更容易测试。我们代码中的块越小，编写单元测试就越容易。

对于每个应用程序的组件，我们希望有不同的特性，主要是高内聚和低耦合。通过将组件划分为更小的单元，每个单元都拥有单一且定义明确的职责，我们实现了更好的结构，使得变更更容易管理。面对新的需求时，将只有一个正确的地方进行变更，其余的代码可能不会受到影响。

当我们谈论代码时，我们用“组件”来指代这些内聚单元之一（例如，它可能是一个类）。在谈论架构时，组件意味着系统中任何可以被视为工作单元的东西。组件这个术语本身相当模糊，因此在软件架构中并没有一个普遍接受的定义来更具体地说明这意味着什么。工作单元的概念可能因项目而异。组件应该能够独立于系统其余部分进行发布或部署。

对于 Python 项目来说，一个组件可能是一个包，但一个服务也可以是一个组件。注意，两种不同概念，不同粒度级别，可以被视为同一类别。以一个例子来说明，我们在前几章中使用的事件系统可以被视为一个组件。它们是一个具有明确目的的工作单元（用于丰富从日志中识别的事件）。它们可以独立于其他部分部署（无论是作为 Python 包，还是如果我们公开其功能，作为服务；关于这一点稍后还会详细介绍），并且它们是整个系统的一部分，但不是整个应用程序本身。

在前几章的示例中，我们看到了惯用的代码，我们也强调了良好设计对我们代码的重要性，具有单一、明确职责的对象被隔离、正交，并且更容易维护。这个适用于详细设计（函数、类、方法）的标准，同样适用于软件架构的组件。

在考虑大局时，请记住良好的设计原则。

对于一个大型系统来说，仅仅是一个组件可能是不理想的。单体应用程序将作为系统的单一真相来源，负责系统中的所有内容，这将带来许多不希望看到的结果（更难隔离和识别变更，难以有效测试，等等）。

同样，如果我们不小心将所有内容都放在一个地方，我们的代码将更难维护，如果应用程序的组件没有得到同样的关注，它将面临类似的问题。

在系统中创建内聚组件的想法可以有不止一种实现方式，这取决于我们所需的抽象级别。

一个选择是将可能被多次重用的通用逻辑识别出来，并将其放置在一个 Python 包中（我们将在本章后面讨论细节）。

另一个选择是将应用程序分解成多个更小的服务，采用微服务架构。其理念是拥有单一且定义明确的职责的组件，并通过这些服务之间的合作和信息交换来实现与单体应用程序相同的功能。

## 单体应用程序和微服务

上一节最重要的观点是关注点的分离概念：不同的职责应该分布在不同的组件中。正如在我们的代码（更详细的设计级别）中，不应该有一个知道所有东西的巨大对象一样，在我们的架构中，不应该有一个拥有所有东西的单个组件。

然而，有一个重要的区别。不同的组件不一定意味着不同的服务。可以将应用程序划分为更小的 Python 包（我们将在本章后面讨论打包），并创建一个由许多依赖项组成的单一服务。

将职责分离到不同的服务中是一个好主意，它带来了一些好处，但也伴随着成本。

如果有代码需要在多个其他服务中重用，一个典型的做法是将这部分代码封装成一个微服务，以便公司内的其他许多服务调用。但这并不是重用代码的唯一方法。考虑将这种逻辑打包成库，以便其他组件导入。当然，这只有在所有其他组件都使用相同语言的情况下才可行；否则，是的，微服务模式是唯一的选择。

微服务架构具有完全解耦的优势：不同的服务可以用不同的语言或框架编写，甚至可以独立部署。它们也可以单独进行测试。这也有代价。它们还需要强大的客户端合同来了解如何与该服务交互，并且它们也分别受到**服务级别协议**（**SLAs**）和**服务级别目标**（**SLOs**）的约束。

它们也会产生更高的延迟：需要调用外部服务来获取数据（无论是通过 HTTP 还是 gRPC）都会对整体性能产生影响。

由较少服务组成的程序更加僵化，无法独立部署。它甚至可能更加脆弱，因为它可能成为单一故障点。另一方面，它可能更有效率（因为我们避免了昂贵的 I/O 调用），并且我们可以通过使用 Python 包来实现良好的组件分离。

本节的思考点是考虑在创建新服务或使用 Python 包之间选择合适的架构风格。

## 抽象

这就是封装再次出现的地方。当我们谈到我们的系统（就像我们对代码所做的那样）时，我们希望用领域问题的术语来谈论，并尽可能隐藏实现细节。

就像代码必须具有表现力（几乎达到自文档化的程度）并具有正确的抽象来揭示基本问题的解决方案（最小化意外复杂性）一样，架构应该告诉我们系统是关于什么的。诸如用于在磁盘上持久化数据的解决方案、选择的 Web 框架、用于连接外部代理的库以及系统之间的交互等细节并不相关。相关的是系统做什么。一个如尖叫架构（SCREAM）这样的概念反映了这一想法。

**依赖倒置原则**（**DIP**），在第四章“SOLID 原则”中解释，在这方面非常有帮助；我们不想依赖于具体的实现，而是抽象。在代码中，我们在边界处放置抽象（或接口），即依赖项，那些我们无法控制且可能在未来发生变化的程序部分。我们这样做是因为我们想要反转依赖关系，并让它们适应我们的代码（通过必须遵守接口），而不是反过来。

创建抽象和反转依赖是良好的实践，但它们还不够。我们希望我们的整个应用程序独立且与不受我们控制的事物隔离。而且这甚至比仅仅用对象进行抽象还要更进一步——我们需要抽象层。

这与详细设计相比是一个微妙但重要的区别。在依赖倒置原则（DIP）中，建议创建一个接口，该接口可以用标准库中的`abc`模块实现，例如。因为 Python 使用鸭子类型，虽然使用抽象类可能会有所帮助，但它不是强制性的，只要它们符合所需接口，我们就可以轻松地用常规对象实现相同的效果。

Python 的动态类型特性允许我们有这些替代方案。从架构的角度思考，没有这样的东西。随着以下示例的进一步说明，我们需要完全抽象依赖项，Python 没有为我们做到这一点的特性。

有些人可能会争辩：“嗯，对象关系映射器（ORM）是数据库的一个很好的抽象，不是吗？”不。ORM 本身是一个依赖项，因此它不受我们控制。创建一个介于 ORM API 和我们的应用程序之间的中间层，一个适配器，会更好。

这意味着我们不仅仅用对象关系映射器（ORM）来抽象数据库；我们使用我们在其之上创建的抽象层来定义属于我们领域自己的对象。如果这个抽象恰好使用 ORM 作为底层，那只是一个巧合；领域层（我们的业务逻辑所在）不应该关心它。

我们自己的抽象给了我们更多的灵活性和对应用程序的控制。我们甚至可能后来决定我们根本不需要 ORM（比如说，因为我们想更多地控制我们使用的数据库引擎），如果我们把应用程序与特定的 ORM（或任何库）耦合起来，将来改变这一点会更难。想法是隔离我们应用程序的核心，使其不受我们无法控制的依赖项的影响。

应用程序随后导入这个组件，并使用这一层提供的实体，但反之则不然。抽象层不应该了解我们应用程序的逻辑；甚至更确切地说，数据库不应该了解应用程序本身。如果是那样的话，数据库就会与我们的应用程序耦合。目标是反转依赖关系——这一层提供了一个 API，任何想要连接的存储组件都必须符合这个 API。这是*六边形架构*（HEX）的概念。

在下一节中，我们将分析具体工具，这些工具将帮助我们创建用于我们架构的组件。

# 软件组件

我们现在有一个庞大的系统，我们需要对其进行扩展。它还必须易于维护。在这个阶段，问题不仅仅是技术性的，还包括组织性的。这意味着这不仅仅是管理软件仓库；每个仓库很可能会属于一个应用程序，并且将由拥有该系统部分的所有团队进行维护。

这要求我们牢记如何将大型系统划分为不同的组件。这可以有许多阶段，从创建 Python 包的非常简单的方法，到微服务架构中的更复杂场景。

当涉及不同的语言时，情况可能会更加复杂，但在这个章节中，我们将假设它们都是 Python 项目。

这些组件需要相互交互，就像团队一样。要在规模上有效工作，唯一的方法是所有部分都同意一个接口，一个合同。

## 包

Python 包是分发软件和以更通用方式重用代码的便捷方式。构建好的包可以发布到工件仓库（如公司内部的 PyPi 服务器），然后其他需要这些包的应用程序将从中下载。

这种方法的动机有很多方面——它关乎代码的重用，也关乎概念完整性。

在这里，我们讨论将 Python 项目打包成可以在仓库中发布的基本知识。默认仓库可能是 PyPi（Python 包索引，[`pypi.org/`](https://pypi.org/)），但也可能是内部的；或者自定义设置也可以使用相同的原理。

我们将模拟我们已经创建了一个小型库，并将使用它作为例子来回顾需要考虑的主要点。

除了所有可用的开源库之外，有时我们可能需要一些额外的功能——也许我们的应用程序反复使用特定的习语，或者非常依赖某个函数或机制，并且团队已经为这些特定需求设计了一个更好的函数。为了更有效地工作，我们可以将这个抽象放入库中，并鼓励所有团队成员使用它提供的习语，因为这样做将有助于避免错误并减少 bug。

这通常是你拥有某个服务及其客户端库时的情况。你不想让客户端直接调用你的 API，所以相反，你为他们提供一个客户端库。这个库的代码将被封装成 Python 包并通过内部包管理系统进行分发。

可能存在无限多的例子可以适应这种情况。也许应用程序需要提取大量的`.tar.gz`文件（以特定格式），并且过去在恶意文件中遇到了路径遍历攻击的安全问题。

作为一种缓解措施，抽象自定义文件格式安全性的功能被放入了一个库中，该库包装了默认的库并添加了一些额外的检查。这听起来是个好主意。

或者可能需要编写或解析特定格式的配置文件，这需要遵循许多步骤；再次，创建一个辅助函数来封装这个操作，并在所有需要它的项目中使用它，这是一种很好的投资，不仅因为它节省了大量代码重复，而且还因为它使得出错的可能性更小。

获得的收益不仅符合 DRY 原则（避免代码重复，鼓励重用），而且抽象的功能代表了一个单一的参考点，说明了事情应该如何完成，从而有助于实现概念完整性。

通常，库的最小布局看起来像这样：

```py
├── Makefile
├── README.rst
├── setup.py
├── src
│   └── apptool
│   ├── common.py
│   ├── __init__.py
│   └── parse.py
└── tests
    ├── integration
    └── unit 
```

重要的是 `setup.py` 文件，它包含包的定义。在这个文件中，指定了项目的重要定义（其需求、依赖项、名称、描述等）。

`src` 下的 `apptool` 目录是我们正在工作的库的名称。这是一个典型的 Python 项目，因此我们将所有需要的文件都放在这里。

`setup.py` 文件的示例可能如下：

```py
from setuptools import find_packages, setup
with open("README.rst", "r") as longdesc:
    long_description = longdesc.read()
setup(
    name="apptool",
    description="Description of the intention of the package",
    long_description=long_description,
    author="Dev team",
    version="0.1.0",
    packages=find_packages(where="src/"),
    package_dir={"": "src"},
) 
```

这个最小示例包含了项目的关键元素。`setup` 函数中的 `name` 参数用于指定包在仓库中的名称（使用此名称运行安装命令；在这种情况下，它是 `pip install apptool`）。它并不严格要求它与项目目录的名称（`src/apptool`）匹配，但强烈推荐这样做，这样用户使用起来更方便。

在这种情况下，由于两个名称匹配，因此更容易看到 `pip install apptool` 和我们代码中的 `from apptool import myutil` 之间的关系。但后者对应于 `src/` 目录下的名称，而前者对应于在 `setup.py` 文件中指定的名称。

版本很重要，可以保持不同版本的发布，并指定包。通过使用 `find_packages()` 函数，我们可以自动发现所有是包的内容，在这种情况下是在 `src/` 目录下。在目录下搜索有助于避免将超出项目范围之外的文件混合在一起，例如，意外发布测试或项目结构的损坏。

通过运行以下命令构建包，假设它在已安装依赖项的虚拟环境中运行：

```py
python –m venv env
source env/bin/activate
$VIRTUAL_ENV/bin/pip install -U pip wheel
$VIRTUAL_ENV/bin/python setup.py sdist bdist_wheel 
```

这会将工件放置在 `dist/` 目录中，从这里可以稍后将其发布到 PyPi 或公司的内部包仓库。

打包 Python 项目的关键点包括：

+   测试和验证安装是否与平台无关，并且不依赖于任何本地设置（这可以通过将源文件放在 `src/` 目录下实现）。这意味着构建的包不应依赖于您本地机器上的文件，并且在分发时（或在自定义目录结构中）将不可用。

+   确保单元测试不是作为正在构建的包的一部分进行分发。这是针对生产的。在生产环境中运行的 Docker 镜像不需要非严格必需的额外文件（例如，固定装置）。

+   分离依赖项——项目严格需要的运行内容与开发者需要的并不相同。

+   创建最常需要的命令的入口点是个好主意。

`setup.py`文件支持多种其他参数和配置，并且可以以更复杂的方式受到影响。如果我们的包需要安装几个操作系统库，那么在`setup.py`文件中编写一些逻辑来编译和构建所需的扩展是个好主意。这样，如果出现问题，它将在安装过程的早期失败，如果包提供了一个有用的错误消息，用户将能够更快地修复依赖项并继续。

安装这样的依赖项是使应用程序无处不在且任何开发者都能轻松运行（无论他们选择什么平台）的另一个困难步骤。克服这个障碍的最佳方法是通过创建 Docker 镜像来抽象平台，正如我们将在下一节中讨论的那样。

### 管理依赖项

在描述我们将如何利用 Docker 容器交付我们的应用程序之前，重要的是要审视一个**软件配置管理**（**SCM**）问题，即：我们如何列出应用程序的依赖项，以便它们是可重复的？

请记住，软件问题可能不仅来自我们的代码。外部依赖项也会影响最终交付。在任何时候，你都想了解所交付的完整包列表及其版本。这被称为基线。

理念是，如果在任何时候引入的依赖项给我们的软件带来了问题，你希望能够快速定位它。更重要的是，你还希望你的构建是可重复的：在所有其他内容不变的情况下，新的构建应该产生与上一个构建完全相同的工件。

软件通过遵循开发管道被交付到生产环境中。这个过程从第一个环境开始，然后在该环境中运行测试（集成、验收等），接着通过持续集成和持续部署，它将穿过管道的不同阶段（例如，如果你有一个 beta 测试环境，或者在生产之前有一个预生产环境）。

Docker 擅长确保沿管道移动的图像完全相同，但无法保证如果你再次通过管道运行相同的代码版本（例如，相同的`git commit`），你会得到相同的结果。这项工作是我们自己的，也是我们在本节中要探讨的。

假设我们的网络包的`setup.py`文件如下所示：

```py
from setuptools import find_packages, setup

with open("README.rst", "r") as longdesc:
    long_description = longdesc.read()
install_requires = ["sanic>=20,<21"]
setup(
    name="web",
    description="Library with helpers for the web-related functionality",
    long_description=long_description,
    author="Dev team",
    version="0.1.0",
    packages=find_packages(where="src/"),
    package_dir={"": "src"},
    install_requires=install_requires,
) 
```

在这种情况下，只有一个依赖项（在 `install_requires` 参数中声明），它控制着一个版本区间。这通常是一个好的实践：我们希望至少使用特定版本的包，但我们也对不超过下一个主要版本感兴趣（因为主要版本可能包含向后不兼容的更改）。

我们这样设置版本是因为我们对我们依赖项的更新感兴趣（有像 `Dependabot` ([`dependabot.com/`](https://dependabot.com/)) 这样的工具，它可以自动检测依赖项的新版本发布，并可以打开一个新的 `pull` 请求），但我们仍然想了解任何给定时间安装的确切版本。

此外，我们还想跟踪完整的依赖项树，这意味着应该列出传递依赖项。

实现这一点的其中一种方法是通过使用 pip-tools ([`github.com/jazzband/pip-tools`](https://github.com/jazzband/pip-tools)) 并编译 `requirements.txt` 文件。

策略是使用此工具从 `setup.py` 文件生成需求文件，如下所示：

```py
pip-compile setup.py 
```

这将生成一个 `requirements.txt` 文件，我们将使用它来在 `Dockerfile` 中安装依赖项。

为了确保从版本控制的角度来看构建的可确定性，始终应从 `requirements.txt` 文件安装 `Dockerfile` 中的依赖项。

列出需求项的文件应置于版本控制之下，每次我们想要升级依赖项时，我们再次使用带有 `–U` 标志的命令，并跟踪需求文件的新版本。

列出所有依赖项不仅有利于可重复性，还能增加清晰度。如果你使用了许多依赖项，可能会出现版本冲突的情况，如果我们知道哪个包导入了哪个库（以及其版本），这将更容易被发现。但再次强调，这仅仅是问题的一部分。在处理依赖项时，我们还需要考虑更多因素。

### 管理依赖项时的其他考虑因素

默认情况下，在安装依赖项时，`pip` 将使用互联网上的公共仓库（[`pypi.org/`](https://pypi.org/)）。也可以从其他索引或版本控制系统安装。

这有一些问题和局限性。首先，您将依赖于这些服务的可用性。还有这样的限制，您无法在公共仓库上发布包含您公司知识产权的内部软件包。最后，还有一个问题，我们并不真正确信一些作者在保持工件版本准确和安全方面的可靠性和可信度（例如，一些作者可能想要以相同的版本号重新发布不同版本的代码，这显然是错误的，也是不允许的，但所有系统都有缺陷）。我不记得在 Python 中遇到过这样的特定问题，但几年前我确实记得在 JavaScript 社区中发生过这样的事情，有人从 NPM 注册表中删除了一个软件包（REGISTER01），通过取消发布这个库，许多其他构建都失败了。即使 PyPi 不允许这样做，我们也不想受制于他人的善意（或恶意）。

解决方案很简单：您的公司必须有一个用于依赖项的内部服务器，并且所有构建都必须针对这个内部仓库。无论这是如何实现的（本地、云上、使用开源工具或外包给提供商），想法是必须将新的、所需的依赖项添加到这个仓库中，内部软件包也在这里发布。

确保这个内部仓库得到更新，并配置所有仓库在您的依赖项有新版本可用时接收升级。请记住，这也是技术债务的另一种形式。这里有几个原因。正如我们在前面的章节中讨论的那样，技术债务不仅仅是关于代码编写得不好。当新技术可用时，您会错过那些特性，这意味着您可能能够更好地利用可用的技术。更重要的是，软件包可能存在随着时间的推移而被发现的漏洞，因此您希望升级以确保您的软件得到修补。

使用过时的依赖项版本是另一种形式的技术债务。养成使用您依赖项最新版本的习惯。

在升级依赖项之前不要让太多时间过去，因为您等待的时间越长，追赶上就越困难。毕竟，这就是持续集成的全部意义：您希望以增量方式持续集成更改（包括新的依赖项），前提是您有作为构建一部分运行的自动化测试，并作为回归的安全网。

配置一个工具，它会自动为新版本的依赖项发送拉取请求，并配置对它们的自动安全检查。

这个工作流程应该需要最少的工作。想法是，你配置你的项目的 `setup.py` 文件以一系列版本，并拥有需求文件。当有新版本可用时，你为你的仓库配置的工具将重建需求文件，该文件将列出所有包及其新版本（这些新版本将显示在工具打开的 `pull` 请求的差异中）。如果构建是绿色的，且 `pull` 请求显示的差异中没有可疑之处，你可以继续进行 `merge`，相信持续集成已经捕获了问题。另一方面，如果构建失败，这将需要你介入调整。

### 工件版本

在稳定性和前沿软件之间有一个权衡。拥有最新版本通常是积极的，因为这意味着我们只需升级就能获得最新的特性和错误修复。这就是新版本不会带来不兼容的更改（缺点）。因此，软件以具有明确意义的版本进行管理。

当我们确定所需版本的范围时，我们希望获得升级，但同时又不要太激进，以免破坏应用程序。

如果我们只升级依赖项并编写新的需求文件版本，我们应该发布我们工件的新版本（毕竟，我们在交付新的东西，因此是不同的）。这可以是一个小版本或微版本，但重要的是我们必须遵守与第三方库发布我们自己的定制工件时相同的规则。

在 Python 中，PEP-440 ([`www.python.org/dev/peps/pep-0440/`](https://www.python.org/dev/peps/pep-0440/)) 是一个很好的参考，它描述了如何在 `setup.py` 文件中设置我们库的版本号。

在下一节中，我们将探讨一种不同的技术，它也将帮助我们创建组件以交付我们的代码。

## Docker 容器

本章专门讨论架构，因此“容器”一词指的是与第二章“Pythonic 代码”中探讨的 Python 容器（具有 `__contains__` 方法的对象）完全不同的东西。容器是在操作系统下以具有某些限制和隔离考虑的组运行的过程。具体来说，我们指的是 `Docker` 容器，它允许将应用程序（服务或进程）作为独立组件进行管理。

容器代表了另一种软件交付的方式。创建考虑了上一节内容的 Python 包更适合用于库或框架，在这些场景中，目标是重用代码并利用将特定逻辑集中在一个地方的优势。

在容器的情况下，目标不是创建库而是应用程序（大多数时候）。然而，一个应用程序或平台并不一定意味着一个完整的服务。构建容器的想法是创建代表具有小而明确目的的服务的小型组件。

在本节中，当我们讨论容器时，我们会提到 Docker，并探讨如何为 Python 项目创建 Docker 镜像和容器的基础知识。请记住，这并不是将应用程序部署到容器中的唯一技术，而且它与 Python 完全独立。

Docker 容器需要有一个镜像来运行，而这个镜像是由其他基础镜像创建的。但我们创建的镜像本身也可以作为其他容器的基镜像。我们希望在应用程序中存在一个共同的基，可以在许多容器之间共享的情况下这样做。一个潜在的使用案例是创建一个基镜像，按照我们在上一节中描述的方式安装一个包（或多个），以及所有依赖项，包括操作系统级别的依赖项。正如在第九章“通用设计模式”中讨论的那样，我们创建的包不仅可能依赖于其他 Python 库，也可能依赖于特定的平台（特定的操作系统），以及在该操作系统中预先安装的特定库，没有这些库，包将无法安装并会失败。

容器是这一点的绝佳便携工具。它们可以帮助我们确保我们的应用程序将以标准化的方式运行，并且它们也将极大地简化开发过程（在各个环境中重现场景、复制测试、接纳新团队成员等）。

Docker 帮助避免平台依赖问题。其理念是将我们的 Python 应用程序打包成一个 Docker 容器镜像，这对于本地开发和测试以及在生产环境中部署我们的软件都非常有用。

通常，在过去，Python 的部署很困难，因为它的本质。由于它是一种解释型语言，你编写的代码将在生产主机上的 Python 虚拟机上运行。因此，你需要确保目标平台将具有你期望的解析器版本。此外，依赖项的打包也很困难：这是通过将所有内容打包到虚拟环境中并运行来完成的。如果你有平台相关的特定需求，并且一些依赖项使用了 C 扩展，事情会变得更复杂。而且我甚至还没有提到 Windows 或 Linux；有时，即使是不同的 Linux 版本（基于 Debian 与基于 Red Hat）也需要不同的 C 库版本，以便代码能够运行，所以唯一真正测试你的应用程序并确保它能够正确运行的方法是使用虚拟机，并针对正确的架构编译一切。在现代应用程序中，这些痛苦中的大多数都应该消失。现在你将在根目录中有一个`Dockerfile`，其中包含构建该应用程序的指令。并且你的应用程序在生产中也是通过在 Docker 中运行来交付的。

正如包是我们在代码中重用和统一标准的方式一样，容器代表了创建应用程序不同服务的方式。它们符合架构中**关注点分离**（**SoC**）原则背后的标准。每个服务都是另一种类型的组件，它将独立于应用程序的其他部分封装一组功能。这些容器应该设计得有利于可维护性——如果责任划分清晰，服务中的任何更改都不应影响应用程序的任何其他部分。

我们将在下一节中介绍如何从 Python 项目创建 Docker 容器的基础知识。

## 用例

作为我们可能如何组织应用程序组件的例子，以及先前概念如何在实践中工作的例子，我们提供了一个以下简单的示例。

用例是这样的：有一个用于送餐的应用程序，并且这个应用程序有一个特定服务，用于跟踪每个配送在不同阶段的状况。我们将只关注这个特定的服务，而不管应用程序的其他部分可能看起来如何。这个服务必须非常简单——一个 REST API，当询问特定订单的状态时，将返回一个包含描述性信息的 JSON 响应。

我们将假设每个特定订单的信息存储在数据库中，但这个细节根本不重要。

我们的服务目前有两个主要关注点：获取有关特定订单的信息（无论这些信息可能存储在哪里），以及以有用的方式向客户端展示这些信息（在这种情况下，以 JSON 格式交付结果，作为 Web 服务公开）。

由于应用程序必须可维护和可扩展，我们希望尽可能隐藏这两个关注点，并专注于主要逻辑。因此，这两个细节被抽象化和封装到主应用程序将使用的 Python 包中，如图*10.1*所示：

![图片](img/16567_10_01.png)

图 10.1：一个服务应用程序（命名为“Web 服务”），它使用了两个 Python 包，其中一个连接到数据库。

在接下来的章节中，我们将简要展示代码可能的样子，主要是关于包的，以及如何从这些包中创建服务，以便最终看到我们可以得出什么结论。

### 代码

在这个例子中创建 Python 包的想法是为了说明如何创建抽象化和隔离的组件，以便有效地工作。实际上，并没有真正需要它们成为 Python 包；我们可以在“交付服务”项目中创建正确的抽象，同时保持正确的隔离，这样它将没有任何问题。

当存在将要重复的逻辑并且预期将在许多其他应用程序（将从中导入这些包）中使用时，创建包更有意义，因为我们希望优先考虑代码重用。在这个特定的情况下，没有这样的要求，所以它可能超出了设计的范围，但这种区分仍然使“可插拔架构”或组件的概念更加清晰，这实际上是一个封装技术细节的包装器，我们根本不想处理，更不用说依赖了。

`storage`包负责检索所需的数据并以方便的格式将其呈现给下一层（交付服务），这对于业务规则来说是合适的。主应用程序现在应该知道这些数据来自哪里，其格式是什么，等等。这就是我们为什么在中间有一个这样的抽象的原因，这样应用程序就不直接使用行或 ORM 实体，而是使用可操作的东西。

### 领域模型

以下定义适用于业务规则的类。请注意，它们旨在成为纯业务对象，不与特定事物绑定。它们不是 ORM 的模型，也不是外部框架的对象，等等。应用程序应与这些对象（或具有相同标准的对象）一起工作。

在每种情况下，文档字符串根据业务规则记录了每个类的目的：

```py
from typing import Union
class DispatchedOrder:
    """An order that was just created and notified to start its delivery."""
    status = "dispatched"
    def __init__(self, when):
        self._when = when
    def message(self) -> dict:
        return {
            "status": self.status,
            "msg": "Order was dispatched on {0}".format(
                self._when.isoformat()
            ),
        }
class OrderInTransit:
    """An order that is currently being sent to the customer."""
    status = "in transit"
    def __init__(self, current_location):
        self._current_location = current_location
    def message(self) -> dict:
        return {
            "status": self.status,
            "msg": "The order is in progress (current location: {})".format(
                self._current_location
            ),
        }
class OrderDelivered:
    """An order that was already delivered to the customer."""
    status = "delivered"
    def __init__(self, delivered_at):
        self._delivered_at = delivered_at
    def message(self) -> dict:
        return {
            "status": self.status,
            "msg": "Order delivered on {0}".format(
                self._delivered_at.isoformat()
            ),
        }
class DeliveryOrder:
    def __init__(
        self,
        delivery_id: str,
        status: Union[DispatchedOrder, OrderInTransit, OrderDelivered],
    ) -> None:
        self._delivery_id = delivery_id
        self._status = status
    def message(self) -> dict:
        return {"id": self._delivery_id, **self._status.message()} 
```

从这段代码中，我们已能对应用程序的外观有一个大致的了解——我们希望有一个`DeliveryOrder`对象，它将有自己的状态（作为一个内部合作者），一旦我们有了这个，我们就会调用它的`message()`方法将此信息返回给用户。

### 从应用程序调用

这些对象将在应用程序中使用。请注意，这取决于之前的包（`web`和`storage`），而不是反过来：

```py
from storage import DBClient, DeliveryStatusQuery, OrderNotFoundError
from web import NotFound, View, app, register_route
class DeliveryView(View):
    async def _get(self, request, delivery_id: int):
        dsq = DeliveryStatusQuery(int(delivery_id), await DBClient())
        try:
            result = await dsq.get()
        except OrderNotFoundError as e:
             raise NotFound(str(e)) from e
        return result.message()
register_route(DeliveryView, "/status/<delivery_id:int>") 
```

在前一部分中展示了`domain`对象，而在这里展示了应用程序的代码。我们是不是遗漏了什么？当然，但我们现在真的需要知道这些吗？不一定。

`storage`和`web`包内的代码被故意省略了（尽管读者被鼓励查看它——本书的仓库包含了完整的示例）。此外，这也是故意为之的，这些包的名称被选择得不会泄露任何技术细节——`storage`和`web`。

再次查看前一部分中的代码。你能说出使用了哪些框架吗？它是否说明了数据来自文本文件、数据库（如果是的话，是什么类型的？SQL？不是 SQL？）或另一个服务（例如，网络）？假设它来自关系数据库。是否有任何线索表明如何检索这些信息（手动 SQL 查询？通过 ORM？）？

那网络呢？我们能猜出使用了哪些框架吗？

我们无法回答这些问题的事实可能是一个好兆头。这些都是细节，而细节应该被封装起来。除非我们查看那些包内部的内容，否则我们无法回答这些问题。

另一种回答上述问题的方法是以一个问题本身的形式出现：我们为什么需要知道这个？查看代码，我们可以看到有一个`DeliveryOrder`，它使用一个交付的标识符创建，并且它有一个`get()`方法，该方法返回表示交付状态的对象。如果所有这些信息都是正确的，那么这就是我们应该关心的全部。它如何完成有什么区别呢？

我们创建的抽象使我们的代码具有声明性。在声明式编程中，我们声明我们想要解决的问题，而不是我们想要如何解决它。这与命令式相反，在命令式中，我们必须明确所有必要的步骤才能得到某些结果（例如，连接到数据库，运行此查询，解析结果，将其加载到该对象中，等等）。在这种情况下，我们声明我们只想知道由某个标识符给出的交付状态。

这些包负责处理细节并以方便的格式呈现应用程序所需的内容，即前一部分中展示的那种类型的对象。我们只需要知道`storage`包包含一个对象，给定一个交付的 ID 和一个存储客户端（为了简单起见，这个依赖项被注入到这个例子中，但其他替代方案也是可能的），它将检索`DeliveryOrder`，然后我们可以要求它组合消息。

这种架构提供了便利，并使它更容易适应变化，因为它保护了业务逻辑的核心免受可能改变的外部因素的影响。

想象一下，如果我们想要改变信息检索的方式，那会难到什么程度？应用程序依赖于一个 API，如下所示：

```py
dsq = DeliveryStatusQuery(int(delivery_id), await DBClient()) 
```

因此，这仅仅涉及到改变 `get()` 方法的工作方式，将其适配到新的实现细节。我们需要的只是这个新对象在其 `get()` 方法上返回 `DeliveryOrder`，这就足够了。我们可以更改查询、ORM、数据库等，在所有情况下，应用程序中的代码都不需要更改！

### 适配器

仍然，即使不查看包中的代码，我们也可以得出结论，它们作为应用程序技术细节的接口工作。

事实上，由于我们从高层次的角度看待应用程序，而不需要查看代码，我们可以想象在这些包内部必须有适配器设计模式的实现（在第九章 *常见设计模式* 中介绍）。一个或多个这些对象正在将外部实现适配到应用程序定义的 API。这样，想要与应用程序一起工作的依赖项必须遵守 API，并且必须创建一个适配器。

尽管如此，在应用程序的代码中有一个关于这个适配器的线索。注意视图是如何构建的。它继承自来自我们的 `web` 包的 `View` 类。我们可以推断出这个 `View` 是一个从可能正在使用的某个 Web 框架中派生出来的类，通过继承创建了一个适配器。需要注意的是，一旦完成这个操作，唯一重要的对象就是我们的 `View` 类，因为从某种意义上说，我们正在创建自己的框架，这个框架基于对现有框架的适配（但再次强调，改变框架只会改变适配器，而不是整个应用程序）。

从下一节开始，我们将查看服务内部的结构。

## 服务

为了创建服务，我们将在 Docker 容器中启动 Python 应用程序。从基础镜像开始，容器必须安装应用程序运行所需的依赖项，这些依赖项也具有操作系统级别的依赖项。

这实际上是一个选择，因为它取决于依赖项的使用方式。如果我们使用的包在安装时需要操作系统上的其他库来编译，我们可以通过为我们的平台构建库的 wheel 并直接安装来避免这种情况。如果库在运行时需要，那么别无选择，只能将它们作为容器镜像的一部分。

现在，我们将讨论准备 Python 应用程序在 Docker 容器中运行的各种方法之一。这是将 Python 项目打包到容器中的众多替代方案之一。首先，我们来看看目录结构是什么样的：

```py
├── Dockerfile
├── libs
│   ├── README.rst
│   ├── storage
│   └── web
├── Makefile
├── README.rst
├── setup.py
└── statusweb
    ├── __init__.py
    └── service.py 
```

`libs` 目录可以被忽略，因为它只是放置依赖项的地方（在这里显示是为了在 `setup.py` 文件中引用它们时记住它们，但它们可以放在不同的仓库中，并通过 `pip` 远程安装）。

我们有一个包含一些辅助命令的`Makefile`，然后是`setup.py`文件，以及位于`statusweb`目录中的应用程序本身。在打包应用程序和库之间的一个常见区别是，后者在`setup.py`文件中指定它们的依赖项，而前者有一个`requirements.txt`文件，依赖项通过`pip install -r requirements.txt`安装。通常，我们会在`Dockerfile`中做这件事，但为了使事情更简单，在这个特定的例子中，我们将假设从`setup.py`文件中获取依赖项就足够了。这是因为除了这个考虑之外，还有许多其他考虑因素需要考虑，例如冻结包的版本、跟踪间接依赖项、使用额外的工具如`pipenv`，以及更多超出本章范围的话题。此外，为了保持一致性，通常也会使`setup.py`文件从`requirements.txt`读取。

现在我们有了`setup.py`文件的内容，它声明了应用程序的一些详细信息：

```py
from setuptools import find_packages, setup
with open("README.rst", "r") as longdesc:
    long_description = longdesc.read()
install_requires = ["web==0.1.0", "storage==0.1.0"]
setup(
    name="delistatus",
    description="Check the status of a delivery order",
    long_description=long_description,
    author="Dev team",
    version="0.1.0",
    packages=find_packages(),
    install_requires=install_requires,
    entry_points={
        "console_scripts": [
            "status-service = statusweb.service:main",
        ],
    },
) 
```

我们首先注意到的是，应用程序声明了它的依赖项，即我们创建并放置在`libs/`下的包，即`web`和`storage`，它们抽象和适应了一些外部组件。这些包反过来也会有依赖项，因此我们必须确保在创建镜像时容器安装所有必需的库，以便它们可以成功安装，然后安装这个包。

我们注意到的第二件事是传递给`setup`函数的`entry_points`关键字参数的定义。这并不是强制性的，但创建一个入口点是个好主意。当包在一个虚拟环境中安装时，它共享这个目录以及所有其依赖项。虚拟环境是一个包含给定项目依赖项的目录结构。它有许多子目录，但最重要的几个是：

+   `<virtual-env-root>/lib/<python-version>/site-packages`

+   `<virtual-env-root>/bin`

第一个包含在该虚拟环境中安装的所有库。如果我们用这个项目创建一个虚拟环境，那么这个目录将包含`web`和`storage`包，以及所有其依赖项，还有一些额外的基本包，以及当前项目本身。

第二个是`/bin/`，它包含在虚拟环境激活时可用二进制文件和命令。默认情况下，它将只是 Python 版本、`pip`和一些其他基本命令。当我们创建控制台入口点时，将放置一个声明了该名称的二进制文件，因此，当环境激活时，我们就有可运行的该命令。当调用此命令时，它将运行指定了所有虚拟环境上下文的函数。这意味着这是一个我们可以直接调用的二进制文件，无需担心虚拟环境是否激活，或者依赖项是否安装在了当前运行的路径中。

定义如下：

```py
"status-service = statusweb.service:main" 
```

等号左边的部分声明了入口点的名称。在这种情况下，我们将有一个名为`status-service`的命令可用。等号右边的部分声明了该命令应该如何运行。它需要定义函数的包，然后是冒号`.`之后的函数名称。在这种情况下，它将运行在`statusweb/service.py`中声明的`main`函数。

这之后是对`Dockerfile`的定义：

```py
FROM python:3.9-slim-buster
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        python-dev \
        gcc \
        musl-dev \
        make \
    && rm -rf /var/lib/apt/lists/*
WORKDIR /app
ADD . /app
RUN pip install /app/libs/web /app/libs/storage
RUN pip install /app
EXPOSE 8080
CMD ["/usr/local/bin/status-service"] 
```

镜像是基于安装了 Python 的轻量级 Linux 镜像构建的，然后安装了操作系统依赖项，以便我们可以部署我们的库。根据之前的考虑，这个`Dockerfile`只是简单地复制了库，但也可以相应地从`requirements.txt`文件中安装。在所有`pip install`命令准备就绪后，它将复制工作目录中的应用程序，并且 Docker 的入口点（`CMD`命令，不要与 Python 的混淆）调用我们放置函数启动进程的包的入口点。对于本地开发，我们仍然会使用`Dockerfile`，并结合一个包含所有服务定义（包括数据库等依赖项）、基础镜像以及它们如何链接和相互关联的`docker-compose.yml`文件。

现在我们已经启动了容器，我们可以启动它并在其上运行一个小测试，以了解其工作原理：

```py
$ curl http://localhost:5000/status/1
{"id":1,"status":"dispatched","msg":"Order was dispatched on 2018-08-01T22:25:12+00:00"} 
```

让我们分析到目前为止看到的代码的架构特性，从下一节开始。

### 分析

从之前的实现中可以得出许多结论。虽然这可能看起来是一个好的方法，但随之而来的缺点与好处一样明显；毕竟，没有架构或实现是完美的。这意味着这种解决方案并不适用于所有情况，所以它将很大程度上取决于项目的环境、团队、组织等等。

虽然解决方案的主要思想是尽可能抽象细节，正如我们将看到的，有些部分不能完全抽象掉，而且各层之间的合同意味着抽象泄露。

最终，技术总是悄悄地渗透进来。例如，如果我们要把我们的实现从 REST 服务更改为通过 GraphQL 提供数据，我们就必须调整应用程序服务器的配置和构建方式，但即便如此，我们仍然应该能够拥有一个非常类似的前一个结构。即使我们想要进行更激进的改变，将我们的服务转变为 gRPC 服务器，我们当然被迫要调整一些粘合代码，但我们仍然应该尽可能多地使用我们的包。所需的变化应保持在最小。

### 依赖关系流

注意，随着它们接近位于业务规则所在的核心，依赖关系只流向一个方向。这可以通过查看`import`语句来追踪。应用程序从存储中导入它所需的一切，例如，在没有任何部分是这种反转的。

违反这条规则会创建耦合。现在代码的排列方式意味着应用程序和存储之间存在弱依赖。API 是这样的，我们需要一个具有`get()`方法的对象，任何想要连接到应用程序的存储都需要根据这个规范实现这个对象。因此，依赖关系被反转——每个存储都必须实现这个接口，以便创建一个符合应用程序期望的对象。

### 局限性

并不是所有东西都可以抽象化。在某些情况下，这是不可能的，在其他情况下，可能不方便。让我们从方便性方面开始。

在这个例子中，有一个将所选网络框架适配到干净 API 的适配器，以便向应用程序展示。在更复杂的场景中，这样的改变可能不可行。即使有了这种抽象，库的一部分仍然对应用程序可见。完全与网络框架隔离并不是一个完全的问题，因为迟早我们需要它的某些功能或技术细节。

这里重要的收获不是适配器，而是尽可能隐藏技术细节的想法。这意味着在应用程序代码列表上显示的最好的事情不是我们的网络框架版本和实际版本之间存在适配器的事实，而是后者在可见代码的任何部分都没有被提及。服务已经明确指出`web`只是一个依赖（一个被导入的细节）并揭示了其背后的意图。目标是揭示意图（如在代码中），尽可能推迟细节。

关于那些无法隔离的事物，它们是最接近代码的元素。在这种情况下，网络应用程序正在以异步方式使用它们内部的这些对象。这是一个我们无法规避的硬性约束。确实，`storage` 包内的任何内容都可以被更改、重构和修改，但无论这些修改可能是什么，它仍然需要保留接口，这包括异步接口。

### 测试性

再次，就像代码一样，架构可以从将部分分离成更小的组件中受益。依赖关系现在被隔离并由单独的组件控制，这使得主应用程序的设计更加清晰，现在更容易忽略边界，专注于测试应用程序的核心。

我们可以为依赖关系创建补丁，编写更简单的单元测试（它们不需要数据库），或者启动整个网络服务，例如。与纯`domain`对象一起工作意味着将更容易理解代码和单元测试。甚至适配器也不需要太多测试，因为它们的逻辑应该非常简单。

请记住第八章中提到的软件测试金字塔，即*单元测试和重构*。我们希望拥有大量的单元测试，然后是较少的组件测试，最后甚至更少的集成测试。将我们的架构分为不同的组件对于组件测试大有裨益：我们可以模拟我们的依赖关系，并单独测试一些组件。

这既便宜又快，但这并不意味着我们不应该进行任何集成测试。为了确保我们的最终应用程序按预期工作，我们需要进行集成测试，这将测试我们架构的所有组件（无论是微服务还是包），协同工作。

### 意图揭示

意图揭示是我们代码中的一个关键概念——每个名称都必须明智选择，清楚地传达它应该做什么。每个函数都应该讲述一个故事。我们应该保持函数简短，关注点分离，依赖关系隔离，并在代码的每个部分赋予抽象正确的含义。

良好的架构应该揭示它所包含系统的意图。它不应提及它所使用的工具；这些都是细节，正如我们详细讨论的那样，细节应该被隐藏和封装。

# 摘要

良好软件设计的原则适用于所有层次。正如我们希望编写可读的代码，并为此需要记住代码的意图揭示方面一样，架构也必须表达它试图解决的问题的意图。

所有这些想法都是相互关联的。确保我们的架构以领域问题定义的意图揭示同样也引导我们尽可能抽象细节，创建抽象层，反转依赖关系，并分离关注点。

当谈到代码重用时，Python 包是一个优秀且灵活的选择。在决定创建包时，最重要的考虑因素是内聚性和单一职责原则。与具有内聚性和较少职责的组件相一致，微服务概念应运而生，为此，我们已经看到如何从打包的 Python 应用程序开始，在 Docker 容器中部署一个服务。

就像软件工程中的所有事情一样，都有局限性和例外。我们不可能像我们希望的那样抽象出所有事物，或者完全隔离依赖。有时，可能根本不可能（或不切实际）遵守书中解释的原则。但读者可能应该从书中吸取的最佳建议是——它们只是原则，而不是法律。如果无法或实际上无法从框架中抽象出来，这不应该成为问题。记住，书中引用了*Python 之禅*本身——*实用性胜于纯洁性*。

# 参考文献

这里有一些您可以参考的信息列表：

+   *SCREAM*: *Screaming Architecture* ([`8thlight.com/blog/uncle-bob/2011/09/30/Screaming-Architecture.html`](https://8thlight.com/blog/uncle-bob/2011/09/30/Screaming-Architecture.html))

+   *CLEAN-01*: *Clean Architecture* ([`8thlight.com/blog/uncle-bob/2012/08/13/the-clean-architecture.html`](https://8thlight.com/blog/uncle-bob/2012/08/13/the-clean-architecture.html))

+   *HEX*: *Hexagonal Architecture* ([`staging.cockburn.us/hexagonal-architecture/`](https://staging.cockburn.us/hexagonal-architecture/))

+   *PEP-508*: Python 软件包的依赖规范 ([`www.python.org/dev/peps/pep-0508/`](https://www.python.org/dev/peps/pep-0508/))

+   在 Python 中打包和分发项目：[`python-packaging-user-guide.readthedocs.io/guides/distributing-packages-using-setuptools/#distributing-packages`](https://python-packaging-user-guide.readthedocs.io/guides/distributing-packages-using-setuptools/#di)

+   *PEP-440*: [`www.python.org/dev/peps/pep-0440/`](https://www.python.org/dev/peps/pep-0440/)

+   *REGISTER01*: [`www.theregister.com/2016/03/23/npm_left_pad_chaos/`](https://www.theregister.com/2016/03/23/npm_left_pad_chaos/)

+   Python 打包用户指南：[`packaging.python.org/`](https://packaging.python.org/)

+   AWS 构建者库：*通过持续交付加速* ([`aws.amazon.com/builders-library/going-faster-with-continuous-delivery/`](https://aws.amazon.com/builders-library/going-faster-with-continuous-delivery/))

# 总结

本书的内容是一个参考，是一个通过遵循提到的标准来实现软件解决方案的可能方式。这些标准通过示例进行解释，并展示了每个决策的合理性。读者可能会非常不同意示例中采取的方法。

事实上，我鼓励你提出不同的意见：观点越多，辩论就越丰富。但无论意见如何，重要的是要明确，这里所呈现的内容绝对不是一项强制的指令，不是必须严格遵循的东西。恰恰相反；这是一种展示解决方案和一系列可能对你有帮助的想法的方式。

如开头所述，这本书的目标不是给你提供可以直接应用的食谱或公式，而是培养你的批判性思维。习语和语法特性会来来去去；它们会随时间而变化。但思想和核心软件概念是永恒的。有了这些工具和提供的例子，你应该对什么是干净的代码有更好的理解。

我真诚地希望这本书能帮助你成为比开始阅读时更好的开发者，并祝愿你在项目中取得巨大成功。

**分享你的经验**

感谢您抽出时间阅读这本书。如果您喜欢这本书，请帮助他人找到它。在以下链接留下评论：[`www.amazon.com/dp/1800560214`](https://www.amazon.com/dp/1800560214)
