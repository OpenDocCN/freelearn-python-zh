- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Solving Numerical, Symbolic, and Graphical Problems
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决数值、符号和图形问题
- en: Microservice architecture is not only used to build fine-grained, optimized,
    and scalable applications in the banking, insurance, production, human resources,
    and manufacturing industries. It is also used to develop scientific and computation-related
    research and scientific software prototypes for applications such as **laboratory
    information management systems** (**LIMSs**), weather forecasting systems, **geographical
    information systems** (**GISs**), and healthcare systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构不仅用于在银行、保险、生产、人力资源和制造业中构建细粒度、优化和可扩展的应用程序。它还用于开发科学和计算相关的研究和科学软件原型，例如 **实验室信息管理系统**（**LIMSs**）、天气预报系统、**地理信息系统**（**GISs**）和医疗保健系统。
- en: FastAPI is one of the best choices in building these granular services since
    they usually involve highly computational tasks, workflows, and reports. This
    chapter will highlight some transactions not yet covered in the previous chapters,
    such as symbolic computations using `sympy`, solving linear systems using `numpy`,
    plotting mathematical models using `matplotlib`, and generating data archives
    using `pandas`. This chapter will also show you how FastAPI is flexible when solving
    workflow-related transactions by simulating some Business Process Modeling Notation
    (BPMN) tasks. For developing big data applications, a portion of this chapter
    will showcase GraphQL queries for big data applications and Neo4j graph databases
    for graph-related projects with the framework.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: FastAPI 是构建这些细粒度服务中最佳选择之一，因为它们通常涉及高度计算的任务、工作流和报告。本章将突出一些在前几章中未涉及的交易，例如使用 `sympy`
    进行符号计算，使用 `numpy` 求解线性系统，使用 `matplotlib` 绘制数学模型，以及使用 `pandas` 生成数据存档。本章还将向您展示
    FastAPI 如何通过模拟一些业务流程建模符号（BPMN）任务来灵活解决与工作流相关的交易。对于开发大数据应用程序，本章的一部分将展示用于大数据应用程序的
    GraphQL 查询和用于图形相关项目的框架 Neo4j 图数据库。
- en: The main objective of this chapter is to introduce the FastAPI framework as
    a tool for providing microservice solutions for scientific research and computational
    sciences.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要目标是介绍 FastAPI 框架作为提供科学研究与计算科学微服务解决方案的工具。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Setting up the projects
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置项目
- en: Implementing the symbolic computations
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现符号计算
- en: Creating arrays and DataFrames
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建数组和 DataFrame
- en: Performing statistical analysis
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行统计分析
- en: Generating CSV and XLSX reports
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成 CSV 和 XLSX 报告
- en: Plotting data models
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绘制数据模型
- en: Simulating a BPMN workflow
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模拟 BPMN 工作流
- en: Using GraphQL queries and mutations
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GraphQL 查询和突变
- en: Utilizing the Neo4j graph database
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用 Neo4j 图数据库
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter provides the base skeleton of a `ch10` project.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了 `ch10` 项目的基骨架。
- en: Setting up the projects
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置项目
- en: 'The PCCS project has two versions: `ch10-relational`, which uses a PostgreSQL
    database with Piccolo ORM as the data mapper, and `ch10-mongo`, which saves data
    as MongoDB documents using Beanie ODM.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: PCCS 项目有两个版本：`ch10-relational`，它使用 PostgreSQL 数据库和 Piccolo ORM 作为数据映射器，以及 `ch10-mongo`，它使用
    Beanie ODM 将数据保存为 MongoDB 文档。
- en: Using the Piccolo ORM
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Piccolo ORM
- en: '`ch10-relational` uses a fast Piccolo ORM that can support both sync and async
    CRUD transactions. This ORM was not introduced in [*Chapter 5*](B17975_05.xhtml#_idTextAnchor107)*,
    Connecting to a Relational Database*, because it is more appropriate for computational,
    data science-related, and big data applications. The Piccolo ORM is different
    from other ORMs because it scaffolds a project containing the initial project
    structure and templates for customization. But before creating the project, we
    need to install the `piccolo` module using `pip`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`ch10-relational` 使用一个快速的 Piccolo ORM，它可以支持同步和异步 CRUD 事务。这个 ORM 在 [*第 5 章*](B17975_05.xhtml#_idTextAnchor107)*，连接到关系型数据库*
    中没有介绍，因为它更适合计算、数据科学相关和大数据应用程序。Piccolo ORM 与其他 ORM 不同，因为它为项目构建了一个包含初始项目结构和自定义模板的项目框架。但在创建项目之前，我们需要使用
    `pip` 安装 `piccolo` 模块：'
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Afterward, install the `piccolo-admin` module, which provides helper classes
    for the GUI administrator page of its projects:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，安装 `piccolo-admin` 模块，它为其项目提供辅助类，用于 GUI 管理员页面：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, we can create a project inside a newly created root project folder by
    running `piccolo asgi new`, a CLI command that scaffolds the Piccolo project directory.
    The process will ask for the API framework and application server to utilize,
    as shown in the following screenshot:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过运行 CLI 命令 `piccolo asgi new` 在新创建的根项目文件夹内创建一个项目，该命令用于搭建 Piccolo 项目目录。该过程将询问要使用的
    API 框架和应用服务器，如以下截图所示：
- en: '![Figure 10.1 – Scaffolding a Piccolo ORM project'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.1 – 为 Piccolo ORM 项目搭建框架'
- en: '](img/Figure_10.01_B17975.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.01_B17975.jpg)'
- en: Figure 10.1 – Scaffolding a Piccolo ORM project
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 为 Piccolo ORM 项目搭建框架
- en: 'You must use FastAPI for the application framework and `uvicorn` is the recommended
    ASGI server. Now, we can add Piccolo applications inside the project by running
    the `piccolo app new` command inside the project folder. The following screenshot
    shows the main project directory, where we execute the CLI command to create a
    Piccolo application:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须使用 FastAPI 作为应用程序框架，`uvicorn` 是推荐的 ASGI 服务器。现在，我们可以在项目文件夹内运行 `piccolo app
    new` 命令来添加 Piccolo 应用程序。以下截图显示了主项目目录，我们在其中执行 CLI 命令创建 Piccolo 应用程序：
- en: '![Figure 10.2 – Piccolo project directory'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.2 – Piccolo 项目目录'
- en: '](img/Figure_10.02_B17975.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.02_B17975.jpg)'
- en: Figure 10.2 – Piccolo project directory
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – Piccolo 项目目录
- en: 'The scaffolded project always has a default application called `home`, but
    it can be modified or even deleted. Once removed, the Piccolo platform allows
    you to replace `home` by adding a new application to the project by running the
    `piccolo app new` command inside the project folder, as shown in the preceding
    screenshot. A Piccolo application contains the ORM models, BaseModel, services,
    repository classes, and API methods. Each application has an auto-generated `piccolo_app.py`
    module where we need to configure an `APP_CONFIG` variable to register all the
    ORM details. The following is the configuration of our project’s survey application:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 搭建好的项目总是有一个默认的应用程序名为 `home`，但可以进行修改或删除。一旦删除，Piccolo 平台允许你通过在项目文件夹内运行 `piccolo
    app new` 命令来添加一个新的应用程序替换 `home`，如前一张截图所示。一个 Piccolo 应用包含 ORM 模型、BaseModel、服务、仓库类和
    API 方法。每个应用程序都有一个自动生成的 `piccolo_app.py` 模块，其中我们需要配置一个 `APP_CONFIG` 变量来注册所有的 ORM
    详细信息。以下是我们项目调查应用的配置：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For the ORM platform to recognize the new Piccolo application, its `piccolo_app.py`
    must be added to `APP_REGISTRY` of the main project’s `piccolo_conf.py` module.
    The following is the content of the `piccolo_conf.py` file of our `ch10-piccolo`
    project:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让 ORM 平台识别新的 Piccolo 应用，必须在主项目的 `piccolo_conf.py` 模块的 `APP_REGISTRY` 中添加 `piccolo_app.py`
    文件。以下是我们 `ch10-piccolo` 项目的 `piccolo_conf.py` 文件内容：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `piccolo_conf.py` file is also the module where we establish the PostgreSQL
    database connection. Aside from PostgreSQL, the Piccolo ORM also supports SQLite
    databases.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`piccolo_conf.py` 文件也是我们建立 PostgreSQL 数据库连接的模块。除了 PostgreSQL，Piccolo ORM 还支持
    SQLite 数据库。'
- en: Creating the data models
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建数据模型
- en: 'Like in Django ORM, Piccolo ORM has migration commands to generate the database
    tables based on model classes. But first, we need to create model classes by utilizing
    its `Table` API class. It also has helper classes to establish column mappings
    and foreign key relationships. The following are some data model classes that
    comprise our database `pccs`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Django ORM 类似，Piccolo ORM 有迁移命令可以根据模型类生成数据库表。但首先，我们需要利用其 `Table` API 类创建模型类。它还提供了辅助类来建立列映射和外键关系。以下是我们数据库
    `pccs` 中的一些数据模型类：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: After creating the model classes, we can update the database by creating the
    migrations files. Migration is a way of updating the database of a project. In
    the Piccolo platform, we can run the `piccolo migrations new <app_name>` command
    to generate files in the `piccolo_migrations` folder. These are called migration
    files and they contain migration scripts. But to save time, we will include the
    `--auto` option for the command to let the ORM check the recently executed migration
    files and auto-generate the migration script containing the newly reflected schema
    updates. Check the newly created migration file first before running the `piccolo
    migrations forward <app_name>` command to execute the migration script. This last
    command will auto-create all the tables in the database based on the model classes.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建模型类之后，我们可以通过创建迁移文件来更新数据库。迁移是更新项目数据库的一种方式。在 Piccolo 平台上，我们可以运行 `piccolo migrations
    new <app_name>` 命令来在 `piccolo_migrations` 文件夹中生成文件。这些被称为迁移文件，它们包含迁移脚本。但为了节省时间，我们将为命令包含
    `--auto` 选项，让 ORM 检查最近执行的迁移文件并自动生成包含新反映的架构更新的迁移脚本。在运行 `piccolo migrations forward
    <app_name>` 命令执行迁移脚本之前，首先检查新创建的迁移文件。这个最后的命令将根据模型类自动创建数据库中的所有表。
- en: Implementing the repository layer
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现存储库层
- en: 'Creating the repository layer comes after performing all the necessary migrations.
    Piccolo’s CRUD operations are like those in the Peewee ORM. It is swift, short,
    and easy to implement. The following code shows an implementation of the `insert_respondent()`
    transaction, which adds a new respondent profile:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行所有必要的迁移之后创建存储库层。Piccolo 的 CRUD 操作类似于 Peewee ORM 中的操作。它快速、简洁且易于实现。以下代码展示了
    `insert_respondent()` 事务的实现，该事务添加一个新的受访者资料：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Like Peewee, Piccolo’s model classes can persist records, as shown by `insert_respondent()`,
    which implements an asynchronous `INSERT` transaction. On the other hand, `get_all_respondent()`
    retrieves all respondent profiles and has the same approach as Peewee, as shown
    here:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Peewee 一样，Piccolo 的模型类可以持久化记录，如 `insert_respondent()` 所示，它实现了一个异步的 `INSERT`
    事务。另一方面，`get_all_respondent()` 获取所有受访者资料，其方法与 Peewee 相同，如下所示：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The remaining Peewee-like `DELETE` and `UPDATE` respondent transactions are
    created in the project’s `/survey/repository/respondent.py` module.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 项目中的 `/survey/repository/respondent.py` 模块创建了类似 Peewee 的 `DELETE` 和 `UPDATE`
    受访者事务。
- en: The Beanie ODM
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Beanie ODM
- en: The second version of the PCCS project, `ch10-mongo`, utilizes a MongoDB datastore
    and uses the Beanie ODM to implement its asynchronous CRUD transactions. We covered
    Beanie in [*Chapter 6*](B17975_06.xhtml#_idTextAnchor155)*, Using a Non-Relational
    Database*. Now, let us learn how to apply FastAPI in symbolic computations. We
    will be using the `ch10-piccolo` project for this.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: PCCS 项目的第二个版本 `ch10-mongo` 使用 MongoDB 数据存储库，并使用 Beanie ODM 来实现其异步 CRUD 事务。我们已经在
    [*第 6 章*](B17975_06.xhtml#_idTextAnchor155)*，使用非关系型数据库* 中介绍了 Beanie。现在，让我们学习如何将
    FastAPI 应用于符号计算。我们将使用 `ch10-piccolo` 项目来完成这项工作。
- en: Implementing symbolic computations
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现符号计算
- en: '`sympy` module using the `pip` command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `pip` 命令安装 `sympy` 模块：
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let us now start creating our first symbolic expressions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在开始创建我们的第一个符号表达式。
- en: Creating symbolic expressions
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建符号表达式
- en: 'One way of implementing the FastAPI endpoint that performs symbolic computation
    is to create a service that accepts a mathematical model or equation as a string
    and converts that string into a `sympy` symbolic expression. The following `substitute_eqn()`
    processes an equation in `str` format and converts it into valid linear or nonlinear
    bivariate equations with the `x` and `y` variables. It also accepts values for
    `x` and `y` to derive the solution of the expression:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 实现执行符号计算的 FastAPI 端点的一种方法是为接受一个数学模型或方程作为字符串的服务创建一个服务，并将该字符串转换为 `sympy` 符号表达式。以下
    `substitute_eqn()` 处理 `str` 格式的方程，并将其转换为包含 `x` 和 `y` 变量的有效线性或非线性二元方程。它还接受 `x`
    和 `y` 的值来推导表达式的解：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Before converting a string equation into a `sympy` expression, we need to define
    the `x` and `y` variables as `Symbols` objects using the `symbols()` utility.
    This method accepts a string of comma-delimited variable names and returns a tuple
    of symbols equivalent to the variables. After creating all the needed `Symbols()`
    objects, we can convert our equation into `sympy` expressions by using any of
    the following `sympy` methods:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在将字符串方程转换为 `sympy` 表达式之前，我们需要使用 `symbols()` 工具将 `x` 和 `y` 变量定义为 `Symbols` 对象。此方法接受一个以逗号分隔的变量名字符串，并返回一个与变量等价的符号元组。在创建所有需要的
    `Symbols()` 对象之后，我们可以使用以下任何 `sympy` 方法将我们的方程转换为 `sympy` 表达式：
- en: '`sympify()`: This uses `eval()` to convert the string equation into a valid
    `sympy` expression with all Python types converted into their `sympy` equivalents'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sympify()`: 此方法使用 `eval()` 将字符串方程转换为有效的 `sympy` 表达式，并将所有 Python 类型转换为它们的 `sympy`
    等价物'
- en: '`parse_expr()`: A full-fledged expression parser that transforms and modifies
    the tokens of the expression and converts them into their `sympy` equivalents'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`parse_expr()`: 一个完整的表达式解析器，它转换和修改表达式的标记，并将它们转换为它们的 `sympy` 等价物'
- en: Since the `substitute_bivar_eqn()` service utilizes the `sympify()` method,
    the string expression needs to be sanitized from unwanted code before sympifying
    to avoid any compromise.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `substitute_bivar_eqn()` 服务使用 `sympify()` 方法，因此在 `sympify()` 之前需要对字符串表达式进行清理，以避免任何妥协。
- en: On the other hand, the `sympy` expression object has a `subs()` method to substitute
    values to derive the solution. Its resulting object must be converted into `str`
    format for `Response` to render the data. Otherwise, `Response` will raise `ValueError`,
    regarding the result as non-iterable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`sympy` 表达式对象有一个 `subs()` 方法来替换值以推导出解。其结果对象必须转换为 `str` 格式，以便 `Response`
    渲染数据。否则，`Response` 将引发 `ValueError`，将结果视为非可迭代对象。
- en: Solving linear expressions
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决线性表达式
- en: 'The `sympy` module allows you to implement services that solve multivariate
    systems of linear equations. The following API service highlights an implementation
    that accepts two bivariate linear models in string format with their respective
    solutions:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`sympy` 模块允许你实现解决多元线性方程组的服务的功能。以下API服务突出显示了一个实现，它接受两个以字符串格式表示的双变量线性模型及其相应的解：'
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `solve_linear_bivar_eqns()` service accepts two bivariate linear equations
    and their respective outputs (or intercepts) and aims to establish a system of
    linear equations. First, it registers the `x` and `y` variables as `sympy` objects
    and then uses the `parser_expr()` method to transform the string expressions into
    their `sympy` equivalents. Afterward, the service needs to establish linear equality
    of these equations using the `Eq()` solver, which maps each `sympy` expression
    to its solution. Then, the API service passes all these linear equations to the
    `solve()` method to derive the `x` and `y` values. The result of `solve()` also
    needs to be rendered as a string, like in the substitution.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`solve_linear_bivar_eqns()` 服务接受两个双变量线性方程及其相应的输出（或截距）并旨在建立一个线性方程组。首先，它将 `x`
    和 `y` 变量注册为 `sympy` 对象，然后使用 `parser_expr()` 方法将字符串表达式转换为它们的 `sympy` 等价物。之后，该服务需要使用
    `Eq()` 求解器建立这些方程的线性等式，该求解器将每个 `sympy` 表达式映射到其解。然后，API服务将所有这些线性方程传递给 `solve()`
    方法以推导出 `x` 和 `y` 的值。`solve()` 的结果也需要像替换一样以字符串形式呈现。'
- en: Aside from the `solve()` method, the API also uses the `Poly()` utility to create
    a polynomial object from an expression to be able to access essential properties
    of an equation, such as `is_linear()`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `solve()` 方法之外，API 还使用 `Poly()` 工具从表达式创建多项式对象，以便能够访问方程的基本属性，例如 `is_linear()`。
- en: Solving non-linear expressions
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决非线性表达式
- en: 'The previous `solve_linear_bivar_eqns()` can be reused to solve non-linear
    systems. The tweak is to shift the validation from filtering the linear equations
    to any non-linear equations. The following script highlights this code change:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的 `solve_linear_bivar_eqns()` 可以重用来解决非线性系统。调整是将验证从过滤线性方程更改为任何非线性方程。以下脚本突出了此代码更改：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Solving linear and non-linear inequalities
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决线性和非线性不等式
- en: 'The `sympy` module supports solving solutions for both linear and non-linear
    inequalities but on univariate equations only. The following is an API service
    that accepts a univariate string expression with its output or intercepts, and
    extracts the solution using the `solve()` method:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`sympy`模块支持解决线性和非线性不等式，但仅限于单变量方程。以下是一个API服务，它接受一个带有其输出或截距的单变量字符串表达式，并使用`solve()`方法提取解：'
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `sympy` module has `Gt()` or `StrictGreaterThan`, `Lt()` or `StrictLessThan`,
    `Ge()` or `GreaterThan`, and `Le()` or `LessThan` solvers, which we can use to
    create inequality. But first, we need to convert the `str` expression into a `Symbols()`
    object using the `parser_expr()` method before passing them to these solvers.
    The preceding service uses the `GreaterThan` solver, which creates an equation
    where the left-hand side of the expression is generally larger than the left.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`sympy`模块有`Gt()`或`StrictGreaterThan`、`Lt()`或`StrictLessThan`、`Ge()`或`GreaterThan`、`Le()`或`LessThan`求解器，我们可以使用它们来创建不等式。但首先，我们需要使用`parser_expr()`方法将`str`表达式转换为`Symbols()`对象，然后再将它们传递给这些求解器。前面的服务使用`GreaterThan`求解器，它创建一个方程，其中表达式的左侧通常大于右侧。'
- en: Most applications designed and developed for mathematical modeling and data
    science use `sympy` to create complex mathematical models symbolically, plot data
    directly from the `sympy` equation, or generate results based on datasets or live
    data. Now, let us proceed to the next group of API services, which deals with
    data analysis and manipulation using `numpy`, `scipy`, and `pandas`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数用于数学建模和数据科学的应用程序设计和开发都使用`sympy`来创建复杂的数学模型符号，直接从`sympy`方程中绘制数据，或根据数据集或实时数据生成结果。现在，让我们继续到下一组API服务，这些服务涉及使用`numpy`、`scipy`和`pandas`进行数据分析和处理。
- en: Creating arrays and DataFrames
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建数组和DataFrame
- en: When numerical algorithms require some arrays to store data, a module called
    **NumPy**, short for **Numerical Python**, is a good resource for utility functions,
    objects, and classes that are used to create, transform, and manipulate arrays.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当数值算法需要一些数组来存储数据时，一个称为**NumPy**（代表**Numerical Python**）的模块是一个很好的资源，用于创建、转换和操作数组的实用函数、对象和类。
- en: The module is best known for its n-dimensionalarrays or ndarrays, which consume
    less memory storage than the typical Python lists. An `ndarray` incurs less overhead
    when performing data manipulation than executing the list operations in totality.
    Moreover, `ndarray` is strictly heterogeneous, unlike Python’s list collections.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 该模块最著名的是其n维数组或ndarrays，它们比典型的Python列表消耗更少的内存存储。在执行数据操作时，`ndarray`产生的开销比执行列表操作的总开销要小。此外，`ndarray`是严格异构的，与Python的列表集合不同。
- en: 'But before we start our NumPy-FastAPI service implementation, we need to install
    the `numpy` module using the `pip` command:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们开始NumPy-FastAPI服务实现之前，我们需要使用`pip`命令安装`numpy`模块：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Our first API service will process some survey data and return it in `ndarray`
    form. The following `get_respondent_answers()` API retrieves a list of survey
    data from PostgreSQL through Piccolo and transforms the list of data into an `ndarray`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个API服务将处理一些调查数据，并以`ndarray`形式返回。以下`get_respondent_answers()` API通过Piccolo从PostgreSQL检索调查数据列表，并将数据列表转换为`ndarray`：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Depending on the size of the data retrieved, it would be faster if we apply
    the `ujson` or `orjson` serializers and de-serializers to convert `ndarray` into
    JSON data. Even though `numpy` has data types such as `uint`, `single`, `double`,
    `short`, `byte`, and `long`, JSON serializers can still manage to convert them
    into their standard Python equivalents. Our given API sample prefers `ujson` utilities
    to convert the array into a JSON-able response.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 根据检索到的数据大小，如果我们应用`ujson`或`orjson`序列化和反序列化器将`ndarray`转换为JSON数据，将会更快。尽管`numpy`有`uint`、`single`、`double`、`short`、`byte`和`long`等数据类型，但JSON序列化器仍然可以成功地将它们转换为标准的Python等效类型。我们的API示例样本更喜欢使用`ujson`工具将数组转换为可序列化为JSON的响应。
- en: 'Aside from NumPy, `pandas` is another popular module that’s used in data analysis,
    manipulation, transformation, and retrieval. But to use pandas, we need to install
    NumPy, followed by the `pandas`, `matplotlib`, and `openpxyl` modules:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 除了NumPy之外，`pandas`是另一个在数据分析、操作、转换和检索中广泛使用的流行模块。但为了使用pandas，我们需要安装NumPy，然后是`pandas`、`matplotlib`和`openpyxl`模块：
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Let us now discuss about the ndarray in numpy module.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下numpy模块中的ndarray。
- en: Applying NumPy’s linear system operations
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用NumPy的线性系统操作
- en: 'Data manipulation in an `ndarray` is easier and faster, unlike in a list collection,
    which requires list comprehension and loops. The vectors and matrices created
    by `numpy` have operations to manipulate their items, such as scalar multiplication,
    matrix multiplication, transposition, vectorization, and reshaping. The following
    API service shows how the product between a scalar gradient and an array of survey
    data is derived using the `numpy` module:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ndarray`中进行数据处理更容易、更快，与列表集合相比，后者需要列表推导和循环。`numpy`创建的向量和矩阵具有操作其项的功能，例如标量乘法、矩阵乘法、转置、向量化以及重塑。以下API服务展示了如何使用`numpy`模块推导出标量梯度与调查数据数组之间的乘积：
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As shown in the previous scripts, all `ndarray` instances resulting from any
    `numpy` operations can be serialized as JSON-able components using various JSON
    serializers. There are other linear algebraic operations that `numpy` can implement
    without sacrificing the performance of the microservice application. Let us take
    a look now on panda's DataFrame.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述脚本所示，所有由任何`numpy`操作产生的`ndarray`实例都可以使用各种JSON序列化器序列化为可JSON化的组件。`numpy`还可以执行其他线性代数操作，而不会牺牲微服务应用程序的性能。现在，让我们看看pandas的DataFrame。
- en: Applying the pandas module
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用pandas模块
- en: 'In this module, datasets are created as a `DataFrame` object, similar to in
    Julia and R. It contains rows and columns of data. FastAPI can render these DataFrames
    using any JSON serializers. The following API service retrieves all survey results
    from all survey locations and creates a DataFrame from these datasets:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在此模块中，数据集被创建为一个`DataFrame`对象，类似于Julia和R。它包含数据行和列。FastAPI可以使用任何JSON序列化器渲染这些DataFrame。以下API服务从所有调查地点检索所有调查结果，并从这些数据集创建一个DataFrame：
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `DataFrame` object has a `to_json()` utility method, which returns a JSON
    object with an option to format the resulting JSON according to the desired type.
    On another note, `pandas` can also generate time series, a one-dimensional array
    depicting a column of a DataFrame. Both DataFrames and time series have built-in
    methods that are useful for adding, removing, updating, and saving the datasets
    to CSV and XLSX files. But before we discuss pandas’ data transformation processes,
    let us look at another module that works with `numpy` in many statistical computations,
    differentiation, integration, and linear optimizations: the `scipy` module.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataFrame`对象有一个`to_json()`实用方法，它返回一个JSON对象，可以选择根据所需类型格式化生成的JSON。另一方面，`pandas`还可以生成时间序列，这是一个表示DataFrame列的一维数组。DataFrame和时间序列都内置了用于添加、删除、更新以及将数据集保存到CSV和XLSX文件的有用方法。但在我们讨论pandas的数据转换过程之前，让我们看看另一个与`numpy`在许多统计计算（如微分、积分和线性优化）中协同工作的模块：`scipy`模块。'
- en: Performing statistical analysis
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行统计分析
- en: 'The `scipy` module uses `numpy` as its base module, which is why installing
    `scipy` requires `numpy` to be installed first. We can use the `pip` command to
    install the module:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`scipy`模块使用`numpy`作为其基础模块，这就是为什么安装`scipy`之前需要先安装`numpy`。我们可以使用`pip`命令来安装模块：'
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Our application uses the module to derive the declarative statistics of the
    survey data. The following `get_respondent_answers_stats()` API service computes
    the mean, variance, skewness, and kurtosis of the dataset using the `describe()`
    method from `scipy`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的应用程序使用该模块来推导调查数据的声明性统计信息。以下`get_respondent_answers_stats()`API服务使用`scipy`的`describe()`方法计算数据集的均值、方差、偏度和峰度：
- en: '[PRE18]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `describe()` method returns a `DescribeResult` object, which contains all
    the computed results. To render all the statistics as part of `Response`, we can
    invoke the `as_dict()` method of the `DescribeResult` object and serialize it
    using the JSON serializer.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`describe()`方法返回一个`DescribeResult`对象，其中包含所有计算结果。为了将所有统计信息作为`Response`的一部分渲染，我们可以调用`DescribeResult`对象的`as_dict()`方法，并使用JSON序列化器进行序列化。'
- en: Our API sample also uses additional utilities such as the `chain()` method from
    `itertools` to flatten the list of data and a custom converter, `ConvertPythonInt`,
    to convert NumPy’s `int32` types into Python `int` types. Now, let us explore
    how to save data to CSV and XLSX files using the `pandas` module.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的API示例还使用了额外的实用工具，例如来自`itertools`的`chain()`方法来展平数据列表，以及自定义转换器`ConvertPythonInt`，将NumPy的`int32`类型转换为Python
    `int`类型。现在，让我们探索如何使用`pandas`模块将数据保存到CSV和XLSX文件中。
- en: Generating CSV and XLSX reports
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成CSV和XLSX报告
- en: 'The `DataFrame` object has built-in `to_csv()` and `to_excel()` methods that
    save its data in CSV or XLSX files, respectively. But the main goal is to create
    an API service that will return these files as responses. The following implementation
    shows how a FastAPI service can return a CSV file containing a list of respondent
    profiles:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataFrame`对象具有内置的`to_csv()`和`to_excel()`方法，分别将数据保存到CSV或XLSX文件中。但主要目标是创建一个API服务，该服务将返回这些文件作为响应。以下实现展示了FastAPI服务如何返回包含受访者列表的CSV文件：'
- en: '[PRE19]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We need to create a `dict()` containing columns of data from the repository
    to create a `DataFrame` object. From the given script, we store each data column
    in a separate `list()`, add all the lists in `dict()` with keys as column header
    names, and pass `dict()` as a parameter to the constructor of `DataFrame`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要创建一个包含来自存储库的数据列的`dict()`，以创建`DataFrame`对象。从给定的脚本中，我们将每个数据列存储在一个单独的`list()`中，将所有列表添加到`dict()`中，键为列标题名称，并将`dict()`作为参数传递给`DataFrame`构造函数。
- en: After creating the `DataFrame` object, invoke the `to_csv()` method to convert
    its columnar dataset into a text stream, `io.StringIO`, which supports Unicode
    characters. Finally, we must render the `StringIO` object through FastAPI’s `StreamResponse`
    with the `Content-Disposition` header set to rename the default filename of the
    CSV object.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建`DataFrame`对象后，调用`to_csv()`方法将其列数据集转换为文本流`io.StringIO`，该流支持Unicode字符。最后，我们必须通过FastAPI的`StreamResponse`渲染`StringIO`对象，并将`Content-Disposition`头设置为重命名CSV对象的默认文件名。
- en: 'Instead of using the pandas `ExcelWriter`, our Online Survey application opted
    for another way of saving `DataFrame` through the `xlsxwriter` module. This module
    has a `Workbook` class, which creates a workbook containing worksheets where we
    can plot all column data per row. The following API service uses this module to
    render XLSX content:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的在线调查应用程序没有使用pandas的`ExcelWriter`，而是选择了通过`xlsxwriter`模块保存`DataFrame`的另一种方式。此模块有一个`Workbook`类，它创建一个包含工作表的电子表格，我们可以按行绘制所有列数据。以下API服务使用此模块来渲染XLSX内容：
- en: '[PRE20]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The given `create_respondent_report_xlsx()` service retrieves all the respondent
    records from the database and plots each profile record per row in the worksheet
    from the newly created `Workbook`. Instead of writing to a file, `Workbook` will
    store its content in a byte stream, `io.ByteIO`, which will be rendered by `StreamResponse`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 给定的`create_respondent_report_xlsx()`服务从数据库中检索所有受访者记录，并将每个个人资料记录按行绘制在新创建的`Workbook`的工作表中。而不是写入文件，`Workbook`将内容存储在字节流`io.ByteIO`中，该流将由`StreamResponse`渲染。
- en: 'The `pandas` module can also help FastAPI services read CSV and XLSX files
    for rendition or data analysis. It has a `read_csv()` that reads data from a CSV
    file and converts it into JSON content. The `io.StringIO` stream object will contain
    the full content, including its Unicode characters. The following service retrieves
    the content of a valid CSV file and returns JSON data:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`模块还可以帮助FastAPI服务读取CSV和XLSX文件进行渲染或数据分析。它有一个`read_csv()`，可以从CSV文件中读取数据并将其转换为JSON内容。`io.StringIO`流对象将包含完整内容，包括其Unicode字符。以下服务检索有效CSV文件的内容并返回JSON数据：'
- en: '[PRE21]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'There are two ways to handle `multipart` file uploads in FastAPI:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在FastAPI中处理`multipart`文件上传有两种方式：
- en: Use `bytes` to contain the file
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`bytes`包含文件
- en: Use `UploadFile` to wrap the file object
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`UploadFile`包装文件对象
- en: '[*Chapter 9*](B17975_09.xhtml#_idTextAnchor266)*, Utilizing Other Advanced
    Features*, introduced the `UploadFile` class for capturing uploaded files because
    it supports more Pydantic features and has built-in operations that can work with
    coroutines. It can handle large file uploads without raising an change to - exception
    when the uploading process reaches the memory limit, unlike using the `bytes`
    type for file content storage. Thus, the given `read-csv()` service uses `UploadFile`
    to capture any CSV files for data analysis with `orjson` as its JSON serializer.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第9章*](B17975_09.xhtml#_idTextAnchor266)*，利用其他高级功能*，介绍了用于捕获上传文件的`UploadFile`类，因为它支持更多的Pydantic功能，并且具有与协程一起工作的内置操作。它可以在上传过程达到内存限制时不会引发异常的情况下处理大文件上传，与使用`bytes`类型存储文件内容不同。因此，给定的`read-csv()`服务使用`UploadFile`来捕获任何CSV文件，并使用`orjson`作为其JSON序列化器进行数据分析。'
- en: 'Another way to handle file upload transactions is through Jinja2 form templates.
    We can use `TemplateResponse` to pursue file uploading and render the file content
    using the Jinja2 templating language. The following service reads a CSV file using
    `read_csv()` and serializes it into HTML table-formatted content:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 处理文件上传事务的另一种方式是通过Jinja2表单模板。我们可以使用 `TemplateResponse` 来实现文件上传，并使用Jinja2模板语言渲染文件内容。以下服务使用
    `read_csv()` 读取CSV文件，并将其序列化为HTML表格格式的文本：
- en: '[PRE22]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Aside from `to_json()` and `to_html()`, the `TextFileReader` object also has
    other converters that can help FastAPI render various content types, including
    `to_latex()`, `to_excel()`, `to_hdf()`, `to_dict()`, `to_pickle()`, and `to_xarray()`.
    Moreover, the `pandas` module has a `read_excel()` that can read XLSX content
    and convert it into any rendition type, just like its `read_csv()` counterpart.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `to_json()` 和 `to_html()`，`TextFileReader` 对象还有其他转换器可以帮助FastAPI渲染各种内容类型，包括
    `to_latex()`、`to_excel()`、`to_hdf()`、`to_dict()`、`to_pickle()` 和 `to_xarray()`。此外，`pandas`
    模块有一个 `read_excel()` 可以读取XLSX内容并将其转换为任何版本类型，就像它的 `read_csv()` 对应物一样。
- en: Now, let us explore how FastAPI services can plot charts and graphs and output
    their graphical result through `Response`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探索FastAPI服务如何绘制图表和图形，并通过 `Response` 输出它们的图形结果。
- en: Plotting data models
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制数据模型
- en: 'With the help of the `numpy` and `pandas` modules, FastAPI services can generate
    and render different types of graphs and charts using the `matplotlib` utilities.
    Like in the previous discussions, we will utilize an `io.ByteIO` stream and `StreamResponse`
    to generate graphical results for the API endpoints. The following API service
    retrieves survey data from the repository, computes the mean for each data strata,
    and returns a line graph of the data in PNG format:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `numpy` 和 `pandas` 模块的帮助下，FastAPI服务可以使用 `matplotlib` 工具生成和渲染不同类型的图表和图形。就像之前的讨论一样，我们将使用
    `io.ByteIO` 流和 `StreamResponse` 为API端点生成图形结果。以下API服务从存储库检索调查数据，计算每个数据层的平均值，并以PNG格式返回数据的折线图：
- en: '[PRE23]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `plot_answers_mean()` service utilizes the `plot()` method of the `matplotlib`
    module to plot the app’s mean survey results per location on a linegraph. Instead
    of saving the file to the filesystem, the service stores the image in the `io.ByteIO`
    stream using the module’s `savefig()` method. The stream is rendered using `StreamResponse`,
    like in the previous samples. The following figure shows the rendered stream image
    in PNG format through `StreamResponse`:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`plot_answers_mean()` 服务利用 `matplotlib` 模块的 `plot()` 方法，在折线图中绘制每个位置的APP平均调查结果。该服务不是将文件保存到文件系统，而是使用模块的
    `savefig()` 方法将图像存储在 `io.ByteIO` 流中。流使用 `StreamResponse` 渲染，就像之前的示例一样。以下图显示了通过
    `StreamResponse` 渲染的流图像，格式为PNG：'
- en: '![Figure 10.3 – Line graph from StreamResponse'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.3 – StreamResponse生成的折线图]'
- en: '](img/Figure_10.03_B17975.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.03 – B17975.jpg]'
- en: Figure 10.3 – Line graph from StreamResponse
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 10.3 – StreamResponse生成的折线图
- en: 'The other API services of our app, such as `plot_sparse_data()`, create a bar
    chart image in JPEG format of some simulated or derived data:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们APP的其他API服务，例如 `plot_sparse_data()`，会创建一些模拟或派生数据的条形图图像，格式为JPEG：
- en: '[PRE24]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The approach is the same as our line graph rendition. With the same strategy,
    the following service creates a pie chart that shows the percentage of male and
    female respondents that were surveyed:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 方法与我们的折线图版本相同。使用相同的策略，以下服务创建了一个饼图，显示了被调查的男性和女性受访者的百分比：
- en: '[PRE25]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The responses generated by the `plot_sparse_data()` and `plot_pie_gender()`
    services are as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`plot_sparse_data()` 和 `plot_pie_gender()` 服务生成的响应如下：'
- en: '![Figure 10.4 – The bar and pie charts generated by StreamResponse'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.4 – StreamResponse生成的条形图和饼图]'
- en: '](img/Figure_10.04_B17975.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.04 – B17975.jpg]'
- en: Figure 10.4 – The bar and pie charts generated by StreamResponse
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 10.4 – StreamResponse生成的条形图和饼图
- en: This section will introduce an approach to creating API endpoints that produce
    graphical results using `matplotlib`. But there are other descriptive, complex,
    and stunning graphs and charts that you can create in less time using `numpy`,
    `pandas`, `matplotlib`, and the FastAPI framework. These extensions can even solve
    complex mathematical and data science-related problems, given the right hardware
    resources.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍一种创建API端点的方法，这些端点使用 `matplotlib` 生成图形结果。但你可以使用 `numpy`、`pandas`、`matplotlib`
    和FastAPI框架在更短的时间内创建其他描述性、复杂和令人惊叹的图表和图形。这些扩展甚至可以在适当的硬件资源下解决复杂的数学和数据科学相关的问题。
- en: Now, let us shift our focus to the other project, `ch10-mongo`, to tackle topics
    regarding workflows, GraphQL, and Neo4j graph database transactions and how FastAPI
    can utilize them.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将注意力转向另一个项目 `ch10-mongo`，以解决有关工作流程、GraphQL、Neo4j 图数据库事务以及 FastAPI 如何利用它们的问题。
- en: Simulating a BPMN workflow
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟 BPMN 工作流程
- en: Although the FastAPI framework has no built-in utilities to support its workflows,
    it is flexible and fluid enough to be integrated into other workflow tools such
    as Camunda and Apache Airflow through extension modules, middleware, and other
    customizations. But this section will only focus on the raw solution of simulating
    BPMN workflows using Celery, which can be extended to a more flexible, real-time,
    and enterprise-grade approach such as Airflow integration.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 FastAPI 框架没有内置的实用工具来支持其工作流程，但它足够灵活和流畅，可以通过扩展模块、中间件和其他自定义来集成到其他工作流程工具，如 Camunda
    和 Apache Airflow。但本节将仅关注使用 Celery 模拟 BPMN 工作流程的原始解决方案，这可以扩展为一个更灵活、实时和面向企业的方法，如
    Airflow 集成。
- en: Designing the BPMN workflow
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计 BPMN 工作流程
- en: 'The `ch10-mongo` project has implemented the following BPMN workflow design
    using Celery:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`ch10-mongo` 项目使用 Celery 实现了以下 BPMN 工作流程设计：'
- en: 'A sequence of service tasks that derives the percentage of the survey data
    result, as shown in the following diagram:'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列服务任务，用于推导调查数据结果的百分比，如下所示图所示：
- en: '![Figure 10.5 – Percentage computation workflow design'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.5 – 百分比计算工作流程设计'
- en: '](img/Figure_10.05_B17975.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.05_B17975.jpg)'
- en: Figure 10.5 – Percentage computation workflow design
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – 百分比计算工作流程设计
- en: 'A group of batch operations that saves data to CSV and XLSX files, as shown
    in the following diagram:'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组批处理操作，将数据保存到 CSV 和 XLSX 文件中，如下所示图所示：
- en: '![Figure 10.6 – Data archiving workflow design'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.6 – 数据归档工作流程设计'
- en: '](img/Figure_10.06_B17975.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.06_B17975.jpg)'
- en: Figure 10.6 – Data archiving workflow design
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 – 数据归档工作流程设计
- en: 'A group of chained tasks that operates on each location''s data independently,
    as shown in the following diagram:'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组链式任务，独立地对每个位置的数据进行操作，如下所示图所示：
- en: '![Figure 10.7 – Workflow design for stratified survey data analysis'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.7 – 分层调查数据分析工作流程设计'
- en: '](img/Figure_10.07_B17975.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.07_B17975.jpg)'
- en: Figure 10.7 – Workflow design for stratified survey data analysis
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7 – 分层调查数据分析工作流程设计
- en: There are many ways to implement the given design, but the most immediate solution
    is to utilize the Celery setup that we used in [*Chapter 7*](B17975_07.xhtml#_idTextAnchor190)*,
    Securing the REST APIs*.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 实现给定设计的方法有很多，但最直接的方法是利用我们在 [*第 7 章*](B17975_07.xhtml#_idTextAnchor190)*，Securing
    the REST APIs* 中使用的 Celery 设置。
- en: Implementing the workflow
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现工作流程
- en: 'Celery’s `chain()` method implements a workflow of linked task executions,
    as depicted in *Figure 10.5*, where every parent task returns the result to the
    first parameter of next task. The chained workflow works if each task runs successfully
    without encountering any exceptions at runtime. The following is the API service
    in `/api/survey_workflow.py` that implements the chained workflow:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Celery 的 `chain()` 方法实现了一个链式任务执行的工作流程，如图 10.5 所示，其中每个父任务将结果返回给下一个任务的第一个参数。链式工作流程在运行时每个任务都成功执行且未遇到任何异常的情况下工作。以下是在
    `/api/survey_workflow.py` 中实现的 API 服务，它实现了链式工作流程：
- en: '[PRE26]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`compute_sum_results()`, `compute_avg_results()`, and `derive_percentile()`
    are bound tasks. Bound tasks are Celery tasks that are implemented to have the
    first method parameter allocated to the task instance itself, thus the `self`
    keyword appearing in its parameter list. Their task implementation always has
    the `@celery.task(bind=True)` decorator. The Celery task manager prefers bound
    tasks when applying workflow primitive signatures to create workflows. The following
    code shows the bound tasks that are used in the chained workflow design:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`compute_sum_results()`、`compute_avg_results()` 和 `derive_percentile()` 是绑定任务。绑定任务是
    Celery 任务，实现时将第一个方法参数分配给任务实例本身，因此在参数列表中出现了 `self` 关键字。它们的任务实现总是带有 `@celery.task(bind=True)`
    装饰器。Celery 任务管理器在将工作流程原语签名应用于创建工作流程时更喜欢绑定任务。以下代码显示了在链式工作流程设计中使用的绑定任务：'
- en: '[PRE27]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`compute_sum_results()` computes the total survey result per state, while `compute_avg_results()`consumes
    the sum computed by `compute_sum_results()` to derive the mean value:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`compute_sum_results()` 计算每个州的调查结果总和，而 `compute_avg_results()` 消耗 `compute_sum_results()`
    计算出的总和以得出平均值：'
- en: '[PRE28]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'On the other hand, `derive_percentile()` consumes the mean values produced
    by `compute_avg_results()` to return a percentage value:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`derive_percentile()` 消耗 `compute_avg_results()` 生成的平均值，以返回一个百分比值：
- en: '[PRE29]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The given `derive_percentile()` consumes the mean values produced by `compute_avg_results()`
    to return a percentage value.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 给定的 `derive_percentile()` 消耗 `compute_avg_results()` 生成的平均值，以返回一个百分比值。
- en: 'To implement the gateway approach, Celery has a `group()` primitive signature,
    which is used to implement parallel task executions, as depicted in *Figure 10.6*.
    The following API shows the implementation of the workflow structure with parallel
    executions:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现网关方法，Celery 有一个 `group()` 原始签名，用于实现并行任务执行，如图 *图 10.6* 所示。以下 API 展示了具有并行执行的流程结构实现：
- en: '[PRE30]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The workflow shown in *Figure 10.7* depicts a mix of grouped and chained workflows.
    It is common for many real-world microservice applications to solve workflow-related
    problems with a mixture of different Celery signatures, including `chord()`, `map()`,
    and `starmap()`. The following script implements a workflow with mixed signatures:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10.7* 中所示的工作流程展示了分组和链式工作流程的混合。在许多现实世界的微服务应用程序中，使用不同 Celery 签名（包括 `chord()`、`map()`
    和 `starmap()`）的混合来解决与工作流程相关的问题是很常见的。以下脚本实现了一个具有混合签名的流程：'
- en: '[PRE31]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The Celery signature plays an essential role in building workflows. A `signature()`
    method or `s()` that appears in the construct manages the execution of the task,
    which includes accepting the initial task parameter value(s) and utilizing the
    queues that the Celery worker uses to load tasks. As discussed in [*Chapter 7*](B17975_07.xhtml#_idTextAnchor190)*,
    Securing the REST APIs*, `apply_async()` triggers the whole workflow execution
    and retrieves the result.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Celery 签名在构建工作流程中起着至关重要的作用。在构造中出现的 `signature()` 方法或 `s()` 管理任务的执行，包括接受初始任务参数值（s）并利用
    Celery 工作者使用的队列来加载任务。如[*第 7 章*](B17975_07.xhtml#_idTextAnchor190)*，*保护 REST API*所述，`apply_async()`
    触发整个工作流程执行并检索结果。
- en: Aside from workflows, the FastAPI framework can also use the GraphQL platform
    to build CRUD transactions, especially when dealing with a large amount of data
    in a microservice architecture.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 除了工作流程之外，FastAPI 框架还可以使用 GraphQL 平台来构建 CRUD 事务，尤其是在处理微服务架构中的大量数据时。
- en: Using GraphQL queries and mutations
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 GraphQL 查询和变更
- en: GraphQL is an API standard that implements REST and CRUD transactions at the
    same time. It is a high-performing platform that’s used in building REST API endpoints
    that only need a few steps to set up. Its objective is to create endpoints for
    data manipulation and query transactions.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: GraphQL 是一个同时实现 REST 和 CRUD 事务的 API 标准。它是一个高性能平台，用于构建只需几步即可设置的 REST API 端点。其目标是创建用于数据操作和查询事务的端点。
- en: Setting up the GraphQL platform
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 GraphQL 平台
- en: Python extensions such as Strawberry, Ariadne, Tartiflette, and Graphene support
    GraphQL-FastAPI integration. This chapter introduces the use of the new Ariadne
    3.x to build CRUD transactions for this `ch10-mongo` project with MongoDB as the
    repository.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Python 扩展，如 Strawberry、Ariadne、Tartiflette 和 Graphene，支持 GraphQL-FastAPI 集成。本章介绍了使用新的
    Ariadne 3.x 版本为以 MongoDB 作为存储库的 `ch10-mongo` 项目构建 CRUD 事务。
- en: 'First, we need to install the latest `graphene` extension using the `pip` command:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要使用 `pip` 命令安装最新的 `graphene` 扩展：
- en: '[PRE32]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Among the GraphQL libraries, Graphene is the easiest to set up, with fewer decorators
    and methods to override. It easily integrates with the FastAPI framework without
    requiring additional middleware and too much auto-wiring.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GraphQL 库中，Graphene 是设置最简单的，具有更少的装饰器和需要覆盖的方法。它很容易与 FastAPI 框架集成，无需额外的中间件和过多的自动连接。
- en: Creating the record insertion, update, and deletion
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建记录插入、更新和删除
- en: 'Data manipulation operations are always part of GraphQL’s mutation mechanism.
    This is a GraphQL feature that modifies the server-side state of the application
    and returns arbitrary data as a sign of a successful change in the state. The
    following is an implementation of a GraphQL mutation that inserts, deletes, and
    updates records:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 数据操作操作始终是 GraphQL 变更机制的一部分。这是一个 GraphQL 功能，它修改应用程序的服务器端状态，并返回任意数据作为状态成功变更的标志。以下是一个
    GraphQL 变更的实现，用于插入、删除和更新记录：
- en: '[PRE33]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '`CreateLoginData` is a mutation that adds a new login record to the data store.
    The inner class, `Arguments`, indicates the record fields that will comprise the
    new login record for insertion. These arguments must appear in the overridden
    `mutate()` method to capture the values of these fields. This method will also
    call the ORM, which will persist the newly created record.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`CreateLoginData`是一个突变，它将新的登录记录添加到数据存储中。内部类`Arguments`指示将组成新登录记录以插入的记录字段。这些参数必须在重写的`mutate()`方法中出现，以捕获这些字段的值。此方法还将调用ORM，以持久化新创建的记录。'
- en: After a successful insert transaction, `mutate()` must return the class variables
    defined inside a mutation class such as `ok` and the `loginData` object. These
    returned values must be part of the mutation instance.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功插入事务后，`mutate()`必须返回突变类内部定义的类变量，如`ok`和`loginData`对象。这些返回值必须是突变实例的一部分。
- en: 'Updating a login attribute has a similar implementation to `CreateLoginData`
    except the arguments need to be exposed. The following is a mutation class that
    updates the `password` field of a login record that’s been retrieved using its
    `username`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 更新登录属性与`CreateLoginData`的实现类似，除了需要公开参数。以下是一个更新使用其`username`检索到的登录记录的`password`字段的突变类：
- en: '[PRE34]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Similarly, the delete mutation class retrieves a record through an `id` and
    deletes it from the data store:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，删除突变类通过`id`检索记录并将其从数据存储中删除：
- en: '[PRE35]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, we can store all our mutation classes in an `ObjectType` class that exposes
    these transactions to the client. We assign field names to each `Field` instance
    of the given mutation classes. These field names will serve as the query names
    of the transactions. The following code shows the `ObjectType` class, which defines
    our `CreateLoginData`, `ChangeLoginPassword`, and `DeleteLoginData` mutations:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将所有突变类存储在一个`ObjectType`类中，该类将这些事务暴露给客户端。我们将字段名分配给给定突变类的每个`Field`实例。这些字段名将作为事务的查询名称。以下代码显示了定义我们的`CreateLoginData`、`ChangeLoginPassword`和`DeleteLoginData`突变的`ObjectType`类：
- en: '[PRE36]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Implementing the query transactions
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现查询事务
- en: 'GraphQL query transactions are implementations of the `ObjectType` base class.
    Here, `LoginQuery` retrieves all login records from the data store:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: GraphQL查询事务是`ObjectType`基类的实现。在这里，`LoginQuery`从数据存储中检索所有登录记录：
- en: '[PRE37]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The class must have a query field name, such as `get_login`, that will serve
    as its query name during query execution. The field name must be part of the `resolve_*()`
    method name for it to be registered under the `ObjectType` class. A class variable,
    such as `login_list`, must be declared for it to contain all the retrieved records.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 该类必须有一个查询字段名，例如`get_login`，它在查询执行期间将作为其查询名称。字段名必须是`resolve_*()`方法名的一部分，以便在`ObjectType`类下注册。必须声明一个类变量，例如`login_list`，以便它包含所有检索到的记录。
- en: Running the CRUD transactions
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行CRUD事务
- en: 'We need a GraphQL schema to integrate the GraphQL components and register the
    mutation and query classes for the FastAPI framework before running the GraphQL
    transactions. The following script shows the instantiation of GraphQL’s `Schema`
    class with `LoginQuery` and `LoginMutations`:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行GraphQL事务之前，我们需要一个GraphQL模式来集成GraphQL组件并注册FastAPI框架的突变和查询类。以下脚本显示了使用`LoginQuery`和`LoginMutations`实例化GraphQL的`Schema`类：
- en: '[PRE38]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We set the `auto_camelcase` property of the `Schema` instance to `False` to
    maintain the use of the original field names with an underscore and avoid the
    camel case notation approach.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`Schema`实例的`auto_camelcase`属性设置为`False`，以保持使用带下划线的原始字段名，并避免使用驼峰命名法。
- en: 'Afterward, we use the schema instance to create the `GraphQLApp()` instance.
    GraphQLApp is equivalent to an application that needs mounting to the FastAPI
    framework. We can use the `mount()` utility of FastAPI to integrate the `GraphQLApp()`
    instance with its URL pattern and the chosen GraphQL browser tool to run the API
    transactions. The following code shows how to integrate the GraphQL applications
    with Playground as the browser tool to run the APIs:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们使用模式实例创建`GraphQLApp()`实例。GraphQLApp相当于一个需要挂载到FastAPI框架中的应用程序。我们可以使用FastAPI的`mount()`实用工具将`GraphQLApp()`实例与其URL模式以及选择的GraphQL浏览器工具集成，以运行API事务。以下代码显示了如何将GraphQL应用程序与Playground作为浏览器工具集成以运行API：
- en: '[PRE39]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can use the left-hand side panel to insert a new record through a JSON script
    containing the field name of the `CreateLoginData` mutation, which is `create_login`,
    along with passing the necessary record data, as shown in the following screenshot:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用左侧面板通过包含 `CreateLoginData` 事务字段名 `create_login` 的 JSON 脚本插入新的记录，并传递必要的记录数据，如下面的屏幕截图所示：
- en: '![Figure 10.8 – Running the create_login mutation'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.8 – 运行 create_login 事务'
- en: '](img/Figure_10.08_B17975.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.08_B17975.jpg)'
- en: Figure 10.8 – Running the create_login mutation
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 – 运行 create_login 事务
- en: 'To perform query transactions, we must create a JSON script with a field name
    of `LoginQuery`, which is `get_login`, together with the record fields needed
    to be retrieved. The following screenshot shows how to run the `LoginQuery` transaction:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行查询事务，我们必须创建一个具有 `LoginQuery` 字段名的 JSON 脚本，该字段为 `get_login`，以及需要检索的记录字段。以下屏幕截图显示了如何运行
    `LoginQuery` 事务：
- en: '![Figure 10.9 – Running the get_login query transaction'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.9 – 运行 get_login 查询事务'
- en: '](img/Figure_10.09_B17975.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.09_B17975.jpg)'
- en: Figure 10.9 – Running the get_login query transaction
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 – 运行 get_login 查询事务
- en: GraphQL can help consolidate all the CRUD transactions from different microservices
    with easy setup and configuration. It can serve as an API Gateway where all GraphQLApps
    from multiple microservices are mounted to create a single façade application.
    Now, let us integrate FastAPI into a graph database.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: GraphQL 可以通过简单的设置和配置帮助整合来自不同微服务的所有 CRUD 事务。它可以作为 API 网关，将来自多个微服务的所有 GraphQLApps
    挂载以创建单个门面应用程序。现在，让我们将 FastAPI 集成到图数据库中。
- en: Utilizing the Neo4j graph database
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用 Neo4j 图数据库
- en: 'For an application that requires storage that emphasizes relationships among
    data records, a graph database is an appropriate storage method to use. One of
    the platforms that use graph databases is Neo4j. FastAPI can easily integrate
    with Neo4j, but we need to install the `Neo4j` module using the `pip` command:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要强调数据记录之间关系的数据存储的应用程序，图数据库是合适的存储方法之一。使用图数据库的平台之一是 Neo4j。FastAPI 可以轻松地与 Neo4j
    集成，但我们需要使用 `pip` 命令安装 `Neo4j` 模块：
- en: '[PRE40]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Neo4j is a NoSQL database with a flexible and powerful data model that can manage
    and connect different enterprise-related data based on related attributes. It
    has a semi-structured database architecture with simple ACID properties and a
    non-JOIN policy that make its operations fast and easy to execute.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j 是一个灵活且强大的 NoSQL 数据库，可以根据相关属性管理和连接不同的企业相关数据。它具有半结构化数据库架构，具有简单的 ACID 属性和非
    JOIN 策略，这使得其操作快速且易于执行。
- en: Note
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: ACID, which stands for atomicity, consistency, isolation, and durability, describes
    a database transaction as a group of operations that performs as a single unit
    with correctness and consistency.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ACID，即原子性、一致性、隔离性和持久性，描述数据库事务为一组作为单个单元执行的正确性和一致性的操作。
- en: Setting the Neo4j database
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 Neo4j 数据库
- en: 'The `neo4j` module includes `neo4j-driver`, which is needed to establish a
    connection with the graph database. It needs a URI that contains the `bolt` protocol,
    server address, and port. The default database port to use is `7687`. The following
    script shows how to create Neo4j database connectivity:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`neo4j` 模块包括 `neo4j-driver`，这是建立与图数据库连接所需的。它需要一个包含 `bolt` 协议、服务器地址和端口的 URI。默认数据库端口为
    `7687`。以下脚本显示了如何创建 Neo4j 数据库连接：'
- en: '[PRE41]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Creating the CRUD transactions
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 CRUD 事务
- en: 'Neo4j has a declarative graph query language called Cypher that allows CRUD
    transactions of the graph database. These Cypher scripts need to be encoded as
    `str` SQL commands to be executed by its query runner. The following API service
    adds a new database record to the graph database:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j 有一种称为 Cypher 的声明式图查询语言，允许执行图数据库的 CRUD 事务。这些 Cypher 脚本需要编码为 `str` SQL 命令，以便由其查询运行器执行。以下
    API 服务将新的数据库记录添加到图数据库：
- en: '[PRE42]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '`create_survey_loc()` adds new survey location details to the Neo4j database.
    A record is considered a node in the graph database with a name and attributes
    equivalent to the record fields in the relational databases. We use the connection
    object to create a session that has a `run()` method to execute Cypher scripts.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`create_survey_loc()` 将新的调查位置详细信息添加到 Neo4j 数据库。在图数据库中，记录被视为具有名称和属性与关系数据库中记录字段等效的节点。我们使用连接对象创建一个会话，该会话具有
    `run()` 方法以执行 Cypher 脚本。'
- en: 'The command to add a new node is `CREATE`, while the syntax to update, delete,
    and retrieve nodes can be added with the `MATCH` command. The following `update_node_loc()`
    service searches for a particular node based on the node’s name and performs the
    `SET` command to update the given fields:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 添加新节点的命令是 `CREATE`，而更新、删除和检索节点的语法可以通过 `MATCH` 命令添加。以下 `update_node_loc()` 服务根据节点的名称搜索特定节点，并执行
    `SET` 命令来更新指定的字段：
- en: '[PRE43]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Likewise, the delete transaction uses the `MATCH` command to search for the
    node to be deleted. The following service implements `Location` node deletion:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，删除事务使用 `MATCH` 命令搜索要删除的节点。以下服务实现了 `Location` 节点的删除：
- en: '[PRE44]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'When retrieving nodes, the following service retrieves all the nodes from the
    database:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 当检索节点时，以下服务从数据库中检索所有节点：
- en: '[PRE45]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The following service only retrieves a single node based on the node’s `id`:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 以下服务仅基于节点的 `id` 检索单个节点：
- en: '[PRE46]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Our implementation will not be complete if we have no API endpoint that will
    link nodes based on attributes. Nodes are linked to each other based on relationship
    names and attributes that are updatable and removable. The following API endpoint
    creates a node relationship between the `Location` nodes and `Respondent` nodes:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有将节点基于属性链接的 API 端点，我们的实现将不会完整。节点基于可更新和可删除的关系名称和属性相互链接。以下 API 端点创建 `Location`
    节点和 `Respondent` 节点之间的节点关系：
- en: '[PRE47]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The FastAPI framework can easily integrate into any database platform. The previous
    chapters have proven that FastAPI can deal with relational database transactions
    with ORM and document-based NoSQL transactions with ODM, while this chapter has
    proven the same for the Neo4j graph database due to its easy configurations.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: FastAPI 框架可以轻松集成到任何数据库平台。前几章已经证明 FastAPI 可以通过 ORM 处理关系型数据库事务，并通过 ODM 处理基于文档的
    NoSQL 事务，而本章已经证明了 Neo4j 图数据库同样可以轻松配置，证明了这一点。
- en: Summary
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter introduced the scientific side of FastAPI by showing that API services
    can provide numerical computation, symbolic formulation, and graphical interpretation
    of data via the `numpy`, `pandas`, `sympy`, and `matplotlib` modules. This chapter
    also helped us understand how far we can integrate FastAPI with new technology
    and design strategies to provide new ideas for the microservice architecture,
    such as using GraphQL to manage CRUD transactions and Neo4j for real-time and
    node-based data management. We also introduced the basic approach that FastAPI
    can apply to solve various BPMN workflows using Celery tasks. With this, we have
    started to understand the power and flexibility of the framework in building microservice
    applications.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 本章通过展示 API 服务可以通过 `numpy`、`pandas`、`sympy` 和 `matplotlib` 模块提供数值计算、符号公式和数据的图形解释，介绍了
    FastAPI 的科学方面。本章还帮助我们理解我们可以将 FastAPI 与新技术和设计策略集成到何种程度，以提供微服务架构的新思路，例如使用 GraphQL
    来管理 CRUD 事务，使用 Neo4j 进行实时和基于节点的数据管理。我们还介绍了 FastAPI 可以应用于解决各种 BPMN 工作流的基本方法，即使用
    Celery 任务。有了这些，我们开始理解框架在构建微服务应用中的强大功能和灵活性。
- en: The next chapter will cover the last set of topics to complete our deep dive
    into FastAPI. We will cover some deployment strategies, Django and Flask integrations,
    and other microservice design patterns that haven’t been discussed in the previous
    chapters.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将涵盖最后一组主题，以完成我们对 FastAPI 的深入研究。我们将介绍一些部署策略、Django 和 Flask 集成，以及前几章未讨论的其他微服务设计模式。
