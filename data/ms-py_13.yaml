- en: Chapter 13. Multiprocessing – When a Single CPU Core Is Not Enough
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章。多进程-当单个CPU核心不够用时
- en: In the previous chapter, we discussed factors that influence performance and
    some methods to increase performance. This chapter can actually be seen as an
    extension to the list of performance tips. In this chapter, we will discuss the
    multiprocessing module, a module that makes it very easy to make your code run
    on multiple CPU cores and even on multiple machines. This is an easy way to work
    around the **Global Interpreter Lock** (**GIL**) that was discussed in the previous
    chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了影响性能的因素以及一些提高性能的方法。这一章实际上可以看作是性能提示列表的扩展。在本章中，我们将讨论多进程模块，这是一个使您的代码非常容易在多个CPU核心甚至多台机器上运行的模块。这是一个绕过前一章中讨论的**全局解释器锁**（**GIL**）的简单方法。
- en: 'To summarize, this chapter will cover:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，本章将涵盖：
- en: Local multiprocessing
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地多进程
- en: Remote multiprocessing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 远程多进程
- en: Data sharing and synchronization between processes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程之间的数据共享和同步
- en: Multithreading versus multiprocessing
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程与多进程
- en: Within this book we haven't really covered multithreading yet, but you have
    probably seen multithreaded code in the past. The big difference between multithreading
    and multiprocessing is that with multithreading everything is still executed within
    a single process. That effectively limits your performance to a single CPU core.
    It actually limits you even further because the code has to deal with the GIL
    limitations of CPython.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们还没有真正涵盖多线程，但您可能以前看到过多线程代码。多线程和多进程之间的最大区别在于，多线程中的所有内容仍然在单个进程中执行。这实际上将性能限制在单个CPU核心。它实际上甚至限制了您的性能，因为代码必须处理CPython的GIL限制。
- en: Note
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The GIL is the global lock that Python uses for safe memory access. It is discussed
    in more detail in [Chapter 12](ch12.html "Chapter 12. Performance – Tracking and
    Reducing Your Memory and CPU Usage"), *Performance – Tracking and Reducing Your
    Memory and CPU Usage*, about performance.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: GIL是Python用于安全内存访问的全局锁。关于性能，它在[第12章](ch12.html "第12章。性能-跟踪和减少内存和CPU使用情况")中有更详细的讨论，*性能-跟踪和减少内存和CPU使用情况*。
- en: 'To illustrate that multithreading code doesn''t help performance in all cases
    and can actually be slightly slower than single threaded code, look at this example:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明多线程代码并不总是有助于性能，并且实际上可能比单线程代码稍慢，请看这个例子：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'With Python 3.5, which has the new and improved GIL implementation (introduced
    in Python 3.2), the performance is quite comparable but there is no improvement:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python 3.5，它具有新的改进的GIL实现（在Python 3.2中引入），性能相当可比，但没有改进：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'With Python 2.7, which still has the old GIL, the performance is a lot better
    in the single threaded variant:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用仍然具有旧GIL的Python 2.7，单线程变体的性能要好得多：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: From this test we can conclude that Python 2 is faster in some cases while Python
    3 is faster in other cases. What you should take from this is that there is no
    performance reason to choose between Python 2 or Python 3 specifically. Just note
    that Python 3 is at least as fast as Python 2 in most cases and if that is not
    the case, it will be fixed soon.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个测试中，我们可以得出结论，Python 2在某些情况下更快，而Python 3在其他情况下更快。你应该从中得出的结论是，没有性能原因特别选择Python
    2还是Python 3。只需注意，Python 3在大多数情况下至少与Python 2一样快，如果不是这种情况，很快就会得到解决。
- en: Regardless, for CPU-bound operations, threading does not offer any performance
    benefit since it executes on a single processor core. For I/O bound operations
    however, the `threading` library does offer a clear benefit, but in that case
    I would recommend trying `asyncio` instead. The biggest problem with `threading`
    is that if one of the threads blocks, the main process blocks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，对于CPU绑定的操作，线程不提供任何性能优势，因为它在单个处理器核心上执行。但是对于I/O绑定的操作，`threading`库确实提供了明显的好处，但在这种情况下，我建议尝试`asyncio`。`threading`的最大问题是，如果其中一个线程阻塞，主进程也会阻塞。
- en: The `multiprocessing` library offers an API that is very similar to the `threading`
    library but utilizes multiple processes instead of multiple threads. The advantages
    are that the GIL is no longer an issue and that multiple processor cores and even
    multiple machines can be used for processing.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`库提供了一个与`threading`库非常相似的API，但是利用多个进程而不是多个线程。优点是GIL不再是问题，可以利用多个处理器核心甚至多台机器进行处理。'
- en: 'To illustrate the performance difference, let''s repeat the test while using
    the `multiprocessing` module instead of `threading`:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明性能差异，让我们重复使用`multiprocessing`模块而不是`threading`进行测试：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When running it, we see a huge improvement:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时，我们看到了巨大的改进：
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note that this was run on a quad core processor, which is why I chose four processes.
    The `multiprocessing` library defaults to `multiprocessing.cpu_count()` which
    counts the available CPU cores, but that method fails to take CPU hyper-threading
    into account. Which means it would return 8 in my case and that is why I hardcoded
    it to 4 instead.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是在四核处理器上运行的，这就是为什么我选择了四个进程。`multiprocessing`库默认为`multiprocessing.cpu_count()`，它计算可用的CPU核心数，但该方法未考虑CPU超线程。这意味着在我的情况下它会返回8，这就是为什么我将其硬编码为4的原因。
- en: Note
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It's important to note that because the `multiprocessing` library uses multiple
    processes, the code needs to be imported from the sub processes. The result is
    that the `multiprocessing` library does not work within the Python or IPython
    shells. As we will see later in this chapter, IPython has its own provisions for
    multiprocessing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，因为`multiprocessing`库使用多个进程，代码需要从子进程中导入。结果是`multiprocessing`库无法在Python或IPython
    shell中工作。正如我们将在本章后面看到的那样，IPython有自己的多进程处理方式。
- en: Hyper-threading versus physical CPU cores
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超线程与物理CPU核心
- en: 'In most cases, hyper-threading is very useful and improves performance, but
    when you truly maximize CPU usage it is generally better to only use the physical
    processor count. To demonstrate how this affects the performance, we will run
    the tests from the previous section again. This time with 1, 2, 4, 8, and 16 processes
    to demonstrate how it affects the performance. Luckily, the `multiprocessing`
    library has a nice `Pool` class to manage the processes for us:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，超线程非常有用并提高了性能，但当您真正最大化CPU使用率时，通常最好只使用物理处理器数量。为了演示这如何影响性能，我们将再次运行上一节中的测试。这次使用1、2、4、8和16个进程来演示它如何影响性能。幸运的是，`multiprocessing`库有一个很好的`Pool`类来为我们管理进程：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The pool code makes starting a pool of workers and processing a queue a bit
    simpler as well. In this case we used `map` but there are several other options
    such as `imap`, `map_async`, `imap_unordered`, `apply`, `apply_async`, `starmap`,
    and `starmap_async`. Since these are very similar to how the similarly named `itertools`
    methods work, there won't be specific examples for all of them.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 池代码使得启动一组工作进程和处理队列变得更加简单。在这种情况下，我们使用了`map`，但还有其他几个选项，如`imap`，`map_async`，`imap_unordered`，`apply`，`apply_async`，`starmap`和`starmap_async`。由于这些方法与同名的`itertools`方法工作方式非常相似，因此不会为所有这些方法提供具体示例。
- en: 'But now, the tests with varying amounts of processes:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在，测试不同数量的进程：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You probably weren't expecting these results, but this is exactly the problem
    with hyper-threading. As soon as the single processes actually use 100 percent
    of a CPU core, the task switching between the processes actually reduces performance.
    Since there are only `4` physical cores, the other `4` have to fight to get something
    done on the processor cores. This fight takes time which is why the `4` process
    version is slightly faster than the `8` process version. Additionally, the scheduling
    effect can be seen in the runs using `1` and `2` cores as well. If we look at
    the single core version, we see that it took `5.3` seconds, which means that `4`
    cores should do it in `5.3 / 4 = 1.325` seconds instead of the `1.48` seconds
    it actually took. The `2` core version has a similar effect, `2.7 / 2 = 1.35`
    seconds which is still faster than `4` core version.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能没有预料到这些结果，但这正是超线程的问题所在。一旦单个进程实际上使用了CPU核心的100%，进程之间的任务切换实际上会降低性能。由于只有`4`个物理核心，其他`4`个核心必须争夺处理器核心上的任务。这场争斗需要时间，这就是为什么`4`个进程版本比`8`个进程版本稍快的原因。此外，调度效果也可以在使用`1`和`2`个核心的运行中看到。如果我们看单核版本，我们会发现它花了`5.3`秒，这意味着`4`个核心应该在`5.3
    / 4 = 1.325`秒内完成，而实际上花了`1.48`秒。`2`核版本也有类似的效果，`2.7 / 2 = 1.35`秒，仍然比`4`核版本快。
- en: If you are truly pressed for performance with a CPU-bound problem then matching
    the physical CPU cores is the best solution. If you do not expect to maximize
    all cores all the time, then I recommend leaving it to the default as hyper-threading
    definitely has some performance benefits in other scenarios.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您真的需要处理CPU绑定问题的性能，那么匹配物理CPU核心是最佳解决方案。如果您不希望始终最大化所有核心的使用，那么我建议将其保留为默认设置，因为超线程在其他情况下确实具有一些性能优势。
- en: 'It all depends on your use-case however and the only way to know for certain
    is to test for your specific scenario:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 但这一切取决于您的用例，确切的方法是测试您特定情况的唯一方法：
- en: Disk I/O bound? A single process is most likely your best bet.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 磁盘I/O绑定？单个进程很可能是您最好的选择。
- en: CPU bound? The amount of physical CPU cores is your best bet.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU绑定？物理CPU核心数量是您最好的选择。
- en: Network I/O bound? Start with the defaults and tune if needed.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络I/O绑定？从默认值开始，如果需要，进行调整。
- en: No obvious bound but many parallel processes are needed? Perhaps you should
    try `asyncio` instead of `multiprocessing`.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有明显的限制，但需要许多并行进程？也许您应该尝试`asyncio`而不是`multiprocessing`。
- en: Note that the creation of multiple processes is not free in terms of memory
    and open files, whereas you could have a nearly unlimited amount of coroutines
    this is not the case for processes. Depending on your operating system configuration,
    it could max out long before you even reach a hundred, and even if you reach those
    numbers, CPU scheduling will be your bottleneck instead.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，创建多个进程在内存和打开文件方面并不是免费的，而您可以拥有几乎无限数量的协程，但对于进程来说并非如此。根据您的操作系统配置，它可能在您甚至达到一百之前就达到最大值，即使您达到这些数字，CPU调度也将成为瓶颈。
- en: Creating a pool of workers
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个工作进程池
- en: Creating a processing pool of worker processes is generally a difficult task.
    You need to take care of scheduling jobs, processing the queue, handling the processes,
    and the most difficult part, handling synchronization between the processes without
    too much overhead.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个工作进程的处理池通常是一个困难的任务。您需要注意调度作业，处理队列，处理进程，以及最困难的部分是在进程之间处理同步而不会产生太多开销。
- en: 'With `multiprocessing` however, these problems have been solved already. You
    can simply create a process pool with a given number of processes and just add
    tasks to it whenever you need to. The following is an example of a multiprocessing
    version of the map operator and demonstrates that processing will not stall the
    application:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用`multiprocessing`，这些问题已经得到解决。您只需创建一个具有给定进程数的进程池，并在需要时添加任务即可。以下是`map`操作符的多进程版本的示例，并演示了处理不会使应用程序停滞：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The processing itself is pretty straightforward. The point is that the pool
    stays available and you are not required to wait for it. Just add jobs whenever
    you need to and use the asynchronous results as soon as they are available:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 处理本身非常简单。关键是池保持可用，您不需要等待它。只需在需要时添加作业，并在异步结果可用时使用它们：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Sharing data between processes
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在进程之间共享数据
- en: 'This is really the most difficult part about multiprocessing, multithreading,
    and distributed programming - which data to pass along and which data to skip.
    The theory is really simple, however: whenever possible don''t transfer any data,
    don''t share anything, and keep everything local. Essentially the functional programming
    paradigm, which is why functional programming mixes really well with multiprocessing.
    In practice, regrettably, this is simply not always possible. The `multiprocessing`
    library has several options to share data: `Pipe`, `Namespace`, `Queue`, and a
    few others. All these options might tempt you to share your data between the processes
    all the time. This is indeed possible, but the performance impact is, in many
    cases, more than what the distributed calculation will offer as extra power. All
    data sharing options come at the price of synchronization between all processing
    kernels, which takes a lot of time. Especially with distributed options, these
    synchronizations can take several milliseconds or, if executed globally, cause
    hundreds of milliseconds of latency.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是多进程、多线程和分布式编程中最困难的部分——要传递哪些数据，要跳过哪些数据。然而，理论上非常简单：尽可能不传输任何数据，不共享任何东西，保持一切本地。本质上是函数式编程范式，这就是为什么函数式编程与多进程非常搭配。不幸的是，在实践中，这并不总是可能的。`multiprocessing`库有几种共享数据的选项：`Pipe`、`Namespace`、`Queue`和其他一些选项。所有这些选项可能会诱使您一直在进程之间共享数据。这确实是可能的，但在许多情况下，性能影响要比分布式计算提供的额外性能更大。所有数据共享选项都需要在所有处理内核之间进行同步，这需要很长时间。特别是在分布式选项中，这些同步可能需要几毫秒，或者如果在全局范围内执行，可能会导致数百毫秒的延迟。
- en: 'The multiprocessing namespace behaves just as a regular object would work,
    with one small difference that all the actions are safe for multiprocessing. With
    all this power, namespaces are still very easy to use:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程命名空间的行为与常规对象的工作方式相同，只是有一个小差异，即所有操作都对多进程是安全的。有了这么多功能，命名空间仍然非常容易使用：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: A pipe is not that much more interesting either. It's just a bidirectional communication
    endpoint which allows both reading and writing. In this regard, it simply offers
    you a reader and a writer, and because of that, you can combine multiple processes/endpoints.
    The only thing you must always keep in mind when synchronizing data is that locking
    takes time. For a proper lock to be set, all the parties need to agree that the
    data is locked, which is a process that takes time. And that simple fact slows
    down execution much more than most people would expect.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 管道也没有那么有趣。它只是一个双向通信端点，允许读和写。在这方面，它只是为您提供了一个读取器和一个写入器，因此您可以组合多个进程/端点。在同步数据时，您必须始终记住的唯一一件事是，锁定需要时间。为了设置适当的锁，所有参与方都需要同意数据已被锁定，这是一个需要时间的过程。这个简单的事实比大多数人预期的要慢得多。
- en: On a regular hard disk setup, the database servers aren't able to handle more
    than about 10 transactions per second on the same row due to locking and disk
    latency. Using lazy file syncing, SSDs, and battery backed RAID cache, that performance
    can be increased to handle, perhaps, a 100 transactions per second on the same
    row. Those are simple hardware limitations, because you have multiple processes
    trying to write to a single target you need to synchronize the actions between
    the processes and that takes a lot of time.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规硬盘设置上，由于锁定和磁盘延迟，数据库服务器无法处理同一行上超过大约10个事务每秒。使用延迟文件同步、固态硬盘和带电池备份的RAID缓存，该性能可以增加到，也许，每秒处理同一行上的100个事务。这些都是简单的硬件限制，因为您有多个进程尝试写入单个目标，您需要在进程之间同步操作，这需要很长时间。
- en: Note
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The "database servers" statistic is a common statistic for all database servers
    that offer safe and consistent data storage.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: “数据库服务器”统计数据是所有提供安全和一致数据存储的数据库服务器的常见统计数据。
- en: Even with the fastest hardware available, synchronization can lock all the processes
    and produce enormous slowdowns, so if at all possible, try to avoid sharing data
    between multiple processes. Put simply, if all the processes are reading and writing
    from/to the same object, it is generally faster to use a single process instead.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用最快的硬件，同步也可能锁定所有进程并导致巨大的减速，因此如果可能的话，尽量避免在多个进程之间共享数据。简而言之，如果所有进程都从/向同一对象读取和写入，通常使用单个进程会更快。
- en: Remote processes
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 远程进程
- en: So far, we have only executed our scripts on multiple local processors, but
    we can actually expand this further. Using the `multiprocessing` library, it's
    actually very easy to execute jobs on remote servers, but the documentation is
    currently still a bit cryptic. There are actually a few ways of executing processes
    in a distributed way, but the most obvious one isn't the easiest one. The `multiprocessing.connection`
    module has both the `Client` and `Listener` classes, which facilitate secure communication
    between the clients and servers in a simple way. Communication is not the same
    as process management and queue management however, those features requires some
    extra effort. The multiprocessing library is still a bit bare in this regard,
    but it's most certainly possible given a few different processes.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只在多个本地处理器上执行了我们的脚本，但实际上我们可以进一步扩展。使用`multiprocessing`库，实际上非常容易在远程服务器上执行作业，但文档目前仍然有点晦涩。实际上有几种以分布式方式执行进程的方法，但最明显的方法并不是最容易的方法。`multiprocessing.connection`模块具有`Client`和`Listener`类，可以以简单的方式促进客户端和服务器之间的安全通信。然而，通信并不同于进程管理和队列管理，这些功能需要额外的努力。在这方面，多进程库仍然有点简陋，但鉴于一些不同的进程，这是完全可能的。
- en: Distributed processing using multiprocessing
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用多进程进行分布式处理
- en: 'First of all, we will start with a module with containing a few constants which
    should be shared between all clients and the server, so the secret password and
    the hostname of the server are available to all. In addition to that, we will
    add our prime calculation functions, which we will be using later. The imports
    in the following modules will expect this file to be stored as `constants.py,`
    but feel free to call it anything you like as long as you modify the imports and
    references:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从一个包含一些常量的模块开始，这些常量应该在所有客户端和服务器之间共享，因此所有人都可以使用服务器的秘密密码和主机名。除此之外，我们将添加我们的质数计算函数，稍后我们将使用它们。以下模块中的导入将期望将此文件存储为`constants.py`，但是只要您修改导入和引用，可以随意将其命名为任何您喜欢的名称：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now it''s time to create the actual server which links the functions and the
    job queue:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候创建实际的服务器，将函数和作业队列链接起来了。
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After creating the server, we need to have a script that sends the jobs, which
    will actually be a regular client. It''s simple enough really and a regular client
    can also function as a processor, but to keep things sensible we will use them
    as separate scripts. The following script will add 0 to 999 to the queue for processing:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 创建服务器后，我们需要一个发送作业的脚本，实际上将是一个常规客户端。这真的很简单，一个常规客户端也可以作为处理器，但为了保持事情合理，我们将它们用作单独的脚本。以下脚本将将0添加到999以进行处理：
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Lastly, we need to create a client to actually process the queue:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要创建一个客户端来实际处理队列：
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'From the preceding code you can see how we pass along functions; the manager
    allows registering of functions and classes which can be called from the clients
    as well. With that we pass along a queue from the multiprocessing class which
    is safe for both multithreading and multiprocessing. Now we need to start the
    processes themselves. First the server which keeps on running:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，您可以看到我们如何传递函数；管理器允许注册可以从客户端调用的函数和类。通过这样，我们可以传递一个队列，从多进程类中，这对多线程和多进程都是安全的。现在我们需要启动进程本身。首先是保持运行的服务器：
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'After that, run the producer to generate the prime generation requests:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，运行生产者生成质数生成请求：
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And now we can run multiple clients on multiple machines to get the first 1000
    primes. Since these clients now print the first 1000 primes, the output is a bit
    too lengthy to show here, but you can simply run this in parallel on multiple
    machines to generate your output:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在多台机器上运行多个客户端，以获得前1000个质数。由于这些客户端现在打印出前1000个质数，输出有点太长，无法在这里显示，但您可以简单地在多台机器上并行运行此操作以生成您的输出：
- en: '[PRE16]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Instead of printing, you can obviously use queues or pipes to send the output
    to a different process if you'd like. As you can see verify though, it's still
    a bit of work to process things in parallel and it requires some code synchronization
    to work. There are a few alternatives available, such as **ØMQ**, **Celery**,
    and **IPyparallel**. Which of these is the best and most suitable depends on your
    use case. If you are simply looking for processing tasks on multiple CPUs, then
    multiprocessing and IPyparallel are probably your best choices. If you are looking
    for background processing and/or easy offloading to multiple machines, then ØMQ
    and Celery are better choices.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用队列或管道将输出发送到不同的进程，而不是打印。但是，正如您所看到的，要并行处理事物仍然需要一些工作，并且需要一些代码同步才能正常工作。还有一些可用的替代方案，例如**ØMQ**、**Celery**和**IPyparallel**。哪种是最好和最合适的取决于您的用例。如果您只是想在多个CPU上处理任务，那么多进程和IPyparallel可能是您最好的选择。如果您正在寻找后台处理和/或轻松地将任务卸载到多台机器上，那么ØMQ和Celery是更好的选择。
- en: Distributed processing using IPyparallel
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用IPyparallel进行分布式处理
- en: 'The IPyparallel module (previously, IPython Parallel) is a module that makes
    it really easy to process code on multiple computers at the same time. The library
    supports more features than you are likely to need, but the basic usage is important
    to know just in case you need to do heavy calculations which can benefit from
    multiple computers. First let''s start with installing the latest IPyparallel
    package and all the IPython components:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: IPyparallel模块（以前是IPython Parallel）是一个模块，使得在多台计算机上同时处理代码变得非常容易。该库支持的功能比您可能需要的要多，但了解基本用法非常重要，以防您需要进行可以从多台计算机中受益的大量计算。首先，让我们从安装最新的IPyparallel包和所有IPython组件开始：
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Especially on Windows, it might be easier to install IPython using Anaconda
    instead, as it includes binaries for many science, math, engineering, and data
    analysis packages. To get a consistent installation, the Anaconda installer is
    also available for OS X and Linux systems.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是在Windows上，使用Anaconda安装IPython可能更容易，因为它包含了许多科学、数学、工程和数据分析软件包的二进制文件。为了获得一致的安装，Anaconda安装程序也适用于OS
    X和Linux系统。
- en: 'Secondly, we need a cluster configuration. Technically this is optional, but
    since we are going to create a distributed IPython cluster, it is much more convenient
    to configure everything using a specific profile:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们需要一个集群配置。从技术上讲，这是可选的，但由于我们将创建一个分布式IPython集群，使用特定配置来配置一切会更方便：
- en: '[PRE18]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: These configuration files contain a huge amount of options so I recommend searching
    for a specific section instead of walking through them. A quick listing gave me
    about 2500 lines of configuration in total for these five files. The filenames
    already provide hint about the purpose of the configuration files, but we'll explain
    them in a little more detail since they are still a tad confusing.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这些配置文件包含大量的选项，因此我建议搜索特定部分而不是逐个浏览它们。快速列出给我总共约2500行配置，分布在这五个文件中。文件名已经提供了关于配置文件目的的提示，但由于它们仍然有点令人困惑，我们将更详细地解释它们。
- en: ipython_config.py
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipython_config.py
- en: 'This is the generic IPython configuration file; you can customize pretty much
    everything about your IPython shell here. It defines how your shell should look,
    which modules should be loaded by default, whether or not to load a GUI, and quite
    a bit more. For the purpose of this chapter not all that important but it''s definitely
    worth a look if you''re going to use IPython more often. One of the things you
    can configure here is the automatic loading of extensions, such as `line_profiler`
    and `memory_profiler` discussed in the previous chapter. For example:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通用的IPython配置文件；您可以在这里自定义关于您的IPython shell的几乎所有内容。它定义了您的shell应该如何显示，哪些模块应该默认加载，是否加载GUI等等。对于本章的目的并不是很重要，但如果您要经常使用IPython，那么它绝对值得一看。您可以在这里配置的一件事是自动加载扩展，比如在上一章中讨论的`line_profiler`和`memory_profiler`。
- en: '[PRE19]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ipython_kernel_config.py
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipython_kernel_config.py
- en: This file configures your IPython kernel and allows you to overwrite/extend
    `ipython_config.py`. To understand its purpose, it's important to know what an
    IPython kernel is. The kernel, in this context, is the program that runs and introspects
    the code. By default this is `IPyKernel`, which is a regular Python interpreter,
    but there are also other options such as `IRuby` or `IJavascript` to run Ruby
    or JavaScript respectively.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件配置了您的IPython内核，并允许您覆盖/扩展`ipython_config.py`。要理解它的目的，重要的是要知道什么是IPython内核。在这个上下文中，内核是运行和审查代码的程序。默认情况下，这是`IPyKernel`，它是一个常规的Python解释器，但也有其他选项，如`IRuby`或`IJavascript`分别运行Ruby或JavaScript。
- en: One of the more useful options is the possibility to configure the listening
    port(s) and IP addresses for the kernel. By default the ports are all set to use
    a random number, but it is important to note that if someone else has access to
    the same machine while you are running your kernel, they will be able to connect
    to your IPython kernel which can be dangerous on shared machines.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个更有用的选项是配置内核的监听端口和IP地址的可能性。默认情况下，端口都设置为使用随机数，但重要的是要注意，如果其他人在您运行内核时访问同一台机器，他们将能够连接到您的IPython内核，这在共享机器上可能是危险的。
- en: ipcontroller_config.py
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipcontroller_config.py
- en: '`ipcontroller` is the master process of your IPython cluster. It controls the
    engines and the distribution of tasks, and takes care of tasks such as logging.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`ipcontroller`是您的IPython集群的主进程。它控制引擎和任务的分发，并负责诸如日志记录之类的任务。'
- en: The most important parameter in terms of performance is the `TaskScheduler`
    setting. By default, the `c.TaskScheduler.scheme_name` setting is set to use the
    Python LRU scheduler, but depending on your workload, others such as `leastload`
    and `weighted` might be better. And if you have to process so many tasks on such
    a large cluster that the scheduler becomes the bottleneck, there is also the `plainrandom`
    scheduler that works surprisingly well if all your machines have similar specs
    and the tasks have similar durations.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能方面最重要的参数是`TaskScheduler`设置。默认情况下，`c.TaskScheduler.scheme_name`设置为使用Python
    LRU调度程序，但根据您的工作负载，其他调度程序如`leastload`和`weighted`可能更好。如果您必须在如此大的集群上处理如此多的任务，以至于调度程序成为瓶颈，那么还有`plainrandom`调度程序，如果您的所有计算机具有类似的规格并且任务具有类似的持续时间，它会出奇地有效。
- en: For the purpose of our test we will set the IP of the controller to *, which
    means that **all** IP addresses will be accepted and that every network connection
    will be accepted. If you are in an unsafe environment/network and/or don't have
    any firewalls which allow you to selectively enable certain IP addresses, then
    this method is **not** recommended! In such cases, I recommend launching through
    more secure options, such as `SSHEngineSetLauncher` or `WindowsHPCEngineSetLauncher`
    instead.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了我们的测试目的，我们将控制器的IP设置为*，这意味着将接受**所有**IP地址，并且将接受每个网络连接。如果您处于不安全的环境/网络，并且/或者没有任何允许您有选择地启用某些IP地址的防火墙，那么**不建议**使用这种方法！在这种情况下，我建议通过更安全的选项启动，例如`SSHEngineSetLauncher`或`WindowsHPCEngineSetLauncher`。
- en: 'But, assuming your network is indeed safe, set the factory IP to all the local
    addresses:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，假设您的网络确实是安全的，将工厂IP设置为所有本地地址：
- en: '[PRE20]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now start the controller:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在启动控制器：
- en: '[PRE21]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Pay attention to the files that were written to the security directory of the
    profile directory. They have the authentication information which is used by `ipengine`
    to find `ipcontroller`. It contains the ports, encryption keys, and IP address.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意已写入配置文件目录的安全目录中的文件。它包含了`ipengine`用于找到`ipcontroller`的身份验证信息。它包含端口、加密密钥和IP地址。
- en: ipengine_config.py
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipengine_config.py
- en: '`ipengine` is the actual worker process. These processes run the actual calculations,
    so to speed up the processing you will need these on as many machines as you have
    available. You probably won''t need to change this file, but it can be useful
    if you want to configure centralized logging or need to change the working directory.
    Generally, you don''t want to start the `ipengine` process manually since you
    will most likely want to launch multiple processes per computer. That''s where
    our next command comes in, the `ipcluster` command.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`ipengine`是实际的工作进程。这些进程运行实际的计算，因此为了加快处理速度，您需要在尽可能多的计算机上运行这些进程。您可能不需要更改此文件，但如果您想配置集中式日志记录或需要更改工作目录，则可能会有用。通常情况下，您不希望手动启动`ipengine`进程，因为您很可能希望在每台计算机上启动多个进程。这就是我们下一个命令`ipcluster`的用处。'
- en: ipcluster_config.py
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ipcluster_config.py
- en: The `ipcluster` command is actually just an easy shorthand to start a combination
    of `ipcontroller` and `ipengine` at the same time. For a simple local processing
    cluster, I recommend using this, but when starting a distributed cluster, it can
    be useful to have the control that the separate use of `ipcontroller` and `ipengine`
    offers. In most cases the command offers enough options, so you might have no
    need for the separate commands.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`ipcluster`命令实际上只是一个简单的快捷方式，可以同时启动`ipcontroller`和`ipengine`的组合。对于简单的本地处理集群，我建议使用这个，但是在启动分布式集群时，单独使用`ipcontroller`和`ipengine`可以很有用。在大多数情况下，该命令提供了足够的选项，因此您可能不需要单独的命令。'
- en: The most important configuration option is `c.IPClusterEngines.engine_launcher_class`,
    as this controls the communication method between the engines and the controller.
    Along with that, it is also the most important component for secure communication
    between the processes. By default it's set to `ipyparallel.apps.launcher.LocalControllerLauncher`
    which is designed for local processes but `ipyparallel.apps.launcher.SSHEngineSetLauncher`
    is also an option if you want to use SSH to communicate with the clients. Or `ipyparallel.apps.launcher.WindowsHPCEngineSetLauncher`
    for Windows HPC.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的配置选项是`c.IPClusterEngines.engine_launcher_class`，因为它控制了引擎和控制器之间的通信方法。除此之外，它也是安全通信的最重要组件。默认情况下，它设置为`ipyparallel.apps.launcher.LocalControllerLauncher`，适用于本地进程，但如果您想要使用SSH与客户端通信，也可以选择`ipyparallel.apps.launcher.SSHEngineSetLauncher`。或者对于Windows
    HPC，可以选择`ipyparallel.apps.launcher.WindowsHPCEngineSetLauncher`。
- en: Before we can create the cluster on all machines, we need to transfer the configuration
    files. Your options are to transfer all the files or to simply transfer the files
    in your IPython profile's `security` directory.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有机器上创建集群之前，我们需要传输配置文件。您可以选择传输所有文件，也可以选择仅传输IPython配置文件的`security`目录中的文件。
- en: 'Now it''s time to start the cluster, since we already started the `ipcontroller`
    separately, we only need to start the engines. On the local machine we simply
    need to start it, but the other machines don''t have the configuration yet. One
    option is copying the entire IPython profile directory, but the only file that
    really needs copying is `security/ipcontroller-engine.json`. After creating the
    profile using the profile creation command that is. So unless you are going to
    copy the entire IPython profile directory, you need to execute the profile creation
    command again:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候启动集群了，因为我们已经单独启动了`ipcontroller`，所以我们只需要启动引擎。在本地机器上，我们只需要启动它，但其他机器还没有配置。一种选择是复制整个IPython配置文件目录，但实际上只需要复制`security/ipcontroller-engine.json`文件。在使用配置文件创建命令创建配置文件之后。因此，除非您打算复制整个IPython配置文件目录，否则需要再次执行配置文件创建命令：
- en: '[PRE22]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'After that, simply copy the `ipcontroller-engine.json` file and you''re done.
    Now we can start the actual engines:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，只需复制`ipcontroller-engine.json`文件，就完成了。现在我们可以启动实际的引擎了：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note that the `4` here was chosen for a quad-core processor, but any number
    would do. The default will use the amount of logical processor cores, but depending
    on the workload it might be better to match the amount of physical processor cores
    instead.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这里的`4`是为四核处理器选择的，但任何数字都可以。默认情况下将使用逻辑处理器核心的数量，但根据工作负载，最好匹配物理处理器核心的数量。
- en: 'Now we can run some parallel code from our IPython shell. To demonstrate the
    performance difference, we will use a simple sum of all the numbers from 0 to
    10,000,000\. Not an extremely heavy task, but when performed 10 times in succession,
    a regular Python interpreter takes a while:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以从IPython shell运行一些并行代码。为了演示性能差异，我们将使用从0加到10,000,000的所有数字的简单总和。虽然不是非常繁重的任务，但连续执行10次时，常规的Python解释器需要一段时间：
- en: '[PRE24]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This time however, to illustrate the difference, we will run it a 100 times
    to demonstrate how fast a distributed cluster is. Note that this is with only
    three machines cluster, but it''s still quite a bit faster:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这一次，为了说明差异，我们将运行100次以演示分布式集群有多快。请注意，这只是一个三台机器集群，但速度仍然相当快：
- en: '[PRE25]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'More fun however is the definition of parallel functions in IPyParallel. With
    just a simple decorator, a function is marked as parallel:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，更有趣的是在IPyParallel中定义并行函数。只需一个简单的装饰器，一个函数就被标记为并行：
- en: '[PRE26]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The IPyParallel library offers many more useful features, but that is outside
    the scope of this book. Even though IPyParallel is a separate entity from the
    rest of Jupyter/IPython, it does integrate well, which makes combining them easy
    enough.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: IPyParallel库提供了许多其他有用的功能，但这超出了本书的范围。尽管IPyParallel是Jupyter/IPython的独立实体，但它与之整合良好，这使得它们很容易结合起来。
- en: 'One of the most convenient ways of using IPyParallel is through the Jupyter/IPython
    Notebooks. To demonstrate, we first have to make sure to enable the parallel processing
    in the Jupyter Notebook since IPython notebooks execute single threaded by default:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用IPyParallel最方便的方法之一是通过Jupyter/IPython笔记本。为了演示，我们首先必须确保在Jupyter Notebook中启用并行处理，因为IPython笔记本默认情况下是单线程执行的：
- en: '[PRE27]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'After that we can start the `notebook` and see what it''s all about:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们可以启动`notebook`，看看它是怎么回事：
- en: '[PRE28]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'With the Jupyter Notebook you can create scripts in your web browser which
    can easily be shared with others later. It is really very useful for sharing scripts
    and debugging your code, especially since web pages (as opposed to command line
    environments) can display images easily. This helps a lot with graphing data.
    Here''s a screenshot of our Notebook:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Jupyter Notebook，您可以在Web浏览器中创建脚本，稍后可以轻松与他人共享。这对于共享脚本和调试代码非常有用，特别是因为Web页面（与命令行环境相反）可以轻松显示图像。这对于绘制数据有很大帮助。这是我们笔记本的屏幕截图：
- en: '![ipcluster_config.py](images/4711_13_01.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![ipcluster_config.py](images/4711_13_01.jpg)'
- en: Summary
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter has shown us how multiprocessing works, how we can pool a lot of
    jobs, and how we should share data between multiple processes. But more interestingly,
    it has also shown how we can distribute processing across multiple machines which
    helps a lot in speeding up heavy calculations.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向我们展示了多进程的工作原理，我们如何可以汇集大量的工作，并且我们应该如何在多个进程之间共享数据。但更有趣的是，它还展示了我们如何可以在多台机器之间分发处理，这在加速繁重的计算方面非常有帮助。
- en: The most important lesson you can learn from this chapter is that you should
    always try to avoid data sharing and synchronisation between multiple processes
    or servers, as it is slow and will thus slow down your applications a lot. Whenever
    possible, keep your calculations and data local.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从本章中学到的最重要的一课是，您应该尽量避免在多个进程或服务器之间共享数据和同步，因为这样做会很慢，从而大大减慢应用程序的速度。在可能的情况下，保持计算和数据本地。
- en: In the next chapter we will learn about creating extensions in C/C++ to increase
    performance and allow low-level access to memory and other hardware resources.
    While Python will generally protect you from silly mistakes, C and C++ most certainly
    won't.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何在C/C++中创建扩展，以提高性能并允许对内存和其他硬件资源进行低级访问。虽然Python通常会保护您免受愚蠢的错误，但C和C++肯定不会。
- en: '|   | *"C makes it easy to shoot yourself in the foot; C++ makes it harder,
    but when you do, it blows away your whole leg."* |   |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|   | “C使得自己踩到脚趾头很容易；C++让这变得更难，但一旦你踩到了，它会把整条腿都炸掉。” |   |'
- en: '|   | --*Bjarne Stroustrup (the creator of C++)* |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Bjarne Stroustrup（C++的创造者）* |'
