- en: Chapter 5. Writing Applications That Scale
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。编写可扩展的应用程序
- en: Imagine the checkout counter of a supermarket on a Saturday evening, the usual
    rush-hour time. It is common to see long queues of people waiting to check out
    with their purchases. What could a store manager do to reduce the rush and waiting
    time?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下超市的收银台在一个周六晚上，通常是高峰时间。常见的是看到长队的人在等待结账购物。店长可以做些什么来减少拥挤和等待时间呢？
- en: A typical manager would try a few approaches, including telling those manning
    the checkout counters to pick up their speed, and to try and redistribute people
    to different queues so that each queue roughly has the same waiting time. In other
    words, he would manage the current load with available resources by *optimizing
    the performance* of the existing resources.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的经理会尝试一些方法，包括告诉那些操作结账柜台的人加快速度，并尝试重新分配人员到不同的队列，以便每个队列大致等待时间相同。换句话说，他将通过*优化现有资源的性能*来管理当前负载与可用资源。
- en: However, if the store has existing counters that are not in operation—and enough
    people at hand to manage them—the manager could enable those counters, and move
    people to these new counters. In other words, he would add resources to the store
    to *scale* the operation.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果商店有未使用的柜台，并且有足够的人手来管理它们，经理可以启用这些柜台，并将人员移动到这些新柜台。换句话说，他将向商店添加资源以*扩展*操作。
- en: Software systems too scale in a similar way. An existing software application
    can be scaled by adding compute resources to it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 软件系统也以类似的方式扩展。可以通过向现有软件应用程序添加计算资源来扩展它。
- en: When the system scales by either adding or making better use of resources inside
    a compute node, such as CPU or RAM, it is said to *scale vertically* or *scale
    up*. On the other hand, when a system scales by adding more compute nodes to it,
    such as a creating a load-balanced cluster of servers, it is said to *scale horizontally*
    or *scale out*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当系统通过添加或更好地利用计算节点内的资源（如CPU或RAM）来扩展时，它被称为*垂直扩展*或*向上扩展*。另一方面，当系统通过向其添加更多计算节点（例如创建负载平衡的服务器集群）来扩展时，它被称为*水平扩展*或*向外扩展*。
- en: The degree to which a software system is able to scale when compute resources
    are added is called its *scalability*. Scalability is measured in terms of how
    much the system's performance characteristics, such as throughput or latency,
    improve with respect to the addition of resources. For example, if a system doubles
    its capacity by doubling the number of servers, it is scaling linearly.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算资源增加时，软件系统能够扩展的程度称为其*可扩展性*。可扩展性是指系统的性能特征，如吞吐量或延迟，随着资源的增加而改善的程度。例如，如果一个系统通过增加服务器数量来扩展其容量，它就是线性扩展的。
- en: Increasing the concurrency of a system often increases its scalability. In the
    supermarket example given earlier, the manager is able to scale out his operations
    by opening additional counters. In other words, he increases the amount of concurrent
    processing done in his store. Concurrency is the amount of work that gets done
    simultaneously in a system.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 增加系统的并发通常会增加其可扩展性。在前面给出的超市例子中，经理能够通过开设额外的柜台来扩展他的业务。换句话说，他增加了商店中同时进行的工作量。并发是系统中同时完成的工作量。
- en: In this chapter, we look at the different techniques of scaling a software application
    with Python.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨使用Python扩展软件应用程序的不同技术。
- en: We will be following the approximate sketch of the topics below in our discussion
    in this chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将按照下面的主题大致讨论。
- en: Scalability and Performance
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展性和性能
- en: Concurrency
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发
- en: Concurrency and Parallelism
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发性和并行性
- en: Concurrency in Python - Multi-threading
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python中的并发性 - 多线程
- en: Thumbnail generator
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 缩略图生成器
- en: Thumbnail generator – producer/consumer architecture
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 缩略图生成器 - 生产者/消费者架构
- en: Thumbnail generator – program end condition
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 缩略图生成器 - 程序结束条件
- en: Thumbnail generator – resource constraint using locks
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 缩略图生成器 - 使用锁的资源约束
- en: Thumbnail generator – resource constraint using semaphores
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 缩略图生成器 - 使用信号量的资源约束
- en: Resource constraint – semaphore vs lock
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 资源约束 - 信号量 vs 锁
- en: Thumbnail generator – url rate controller using conditions
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 缩略图生成器 - 使用条件控制器的URL速率控制器
- en: Multi-threading – Python and GIL
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程 - Python和GIL
- en: Concurrency in Python – Multi-processing
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python中的并发性 - 多进程
- en: A primality checker
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 素性检查器
- en: Sorting disk files
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 排序磁盘文件
- en: Sorting disk files – using a counter
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 排序磁盘文件 - 使用计数器
- en: Sorting disk files – using multi-processing
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 排序磁盘文件 - 使用多进程
- en: Multi-threading vs Multi-processing
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多线程 vs 多进程
- en: Concurrency in Python – Asynchronous Execution
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python中的并发性 - 异步执行
- en: Pre-emptive vs Co-operative multitasking
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 抢占式 vs 协作式多任务处理
- en: Asyncio in Python
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的Asyncio
- en: Waiting for future – async and await
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 等待未来 - 异步和等待
- en: Concurrent futures – high level concurrent processing
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 并发未来 - 高级并发处理
- en: Concurrency Options - how to choose ?
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发选项 - 如何选择？
- en: Parallel Processing libraries
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行处理库
- en: joblib
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: joblib
- en: PyMP
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyMP
- en: Fractals – The Mandelbrot Set
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 分形 - 曼德布洛特集
- en: Fractals – Scaling the Mandelbrot Set implementation
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 分形 - 缩放曼德布洛特集实现
- en: Scaling for the Web
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为Web扩展
- en: Scaling workflows – message queues and task queues
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展工作流程 - 消息队列和任务队列
- en: Celery – a distributed task queue
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Celery - 分布式任务队列
- en: The Mandelbrot Set - Using Celery
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 曼德布洛特集 - 使用Celery
- en: Serving Python on the Web – WSGI
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Web上提供Python - WSGI
- en: uWSGI – WSGI middleware on steroids
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI - WSGI中间件的超级版
- en: gunicorn – unicorn for WSGI
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: gunicorn - WSGI的独角兽
- en: gunicorn vs uWSGI
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: gunicorn vs uWSGI
- en: Scalability Architectures
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展性架构
- en: Vertical scalability Architectures
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垂直可扩展性架构
- en: Horizontal scalability Architectures
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 水平可扩展性架构
- en: Scalability and performance
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可扩展性和性能
- en: How do we measure the scalability of a system? Let's take an example, and see
    how this is done.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何衡量系统的可扩展性？让我们举个例子，看看如何做到这一点。
- en: Let's say our application is a simple report generation system for employees.
    It is able to load employee data from a database, and generate a variety of reports
    in bulk, such as pay slips, tax deduction reports, employee leave reports, and
    so on.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的应用是一个简单的员工报告生成系统。它能够从数据库中加载员工数据，并批量生成各种报告，如工资单、税收扣除报告、员工请假报告等。
- en: The system is able to generate 120 reports per minute—this is the *throughput*
    or *capacity* of the system expressed as the number of successfully completed
    operations in a given unit of time. Let's say the time it takes to generate a
    report at the server side (latency) is roughly 2 seconds.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 系统能够每分钟生成120份报告——这是系统吞吐量或容量的表达，表示在给定时间内成功完成的操作数量。假设在服务器端生成报告所需的时间（延迟）大约为2秒。
- en: Let us say, the architect decides to scale up the system by doubling the RAM
    on its server
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 假设架构师决定通过在服务器上加倍RAM来扩展系统
- en: Once this is done, a test shows that the system is able to increase its throughput
    to 180 reports per minute. The latency remains the same at 2 seconds.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此操作后，测试显示系统能够将吞吐量提高到每分钟180份报告。延迟保持在2秒。
- en: 'So at this point, the system has scaled *close to linear* in terms of the memory
    added. The scalability of the system expressed in terms of throughput increase
    is as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，此时系统在增加的内存方面实现了“接近线性”的扩展。系统的可伸缩性以吞吐量增加的方式表达如下：
- en: Scalability (throughput) = *180/120 = 1.5X*
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可伸缩性（吞吐量）= 180/120 = 1.5倍
- en: 'As a second step, the architect decides to double the number of servers on
    the backend—all with the same memory. After this step, he finds that the system''s
    performance throughput has now increased to 350 reports per minute. The scalability
    achieved by this step is given as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第二步，架构师决定在后端将服务器数量加倍，所有服务器的内存相同。此步骤后，他发现系统的性能吞吐量现在增加到每分钟350份报告。此步骤实现的可伸缩性如下：
- en: Scalability (throughput) = *350/180 = 1.9X*
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 可伸缩性（吞吐量）= 350/180 = 1.9倍
- en: The system has now responded much better with a close to linear increase in
    scalability.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 系统现在以接近线性的方式做出了更好的响应，提高了可伸缩性。
- en: After further analysis, the architect finds that by rewriting the code that
    was processing reports on the server to run in multiple processes instead of a
    single process, he is able to reduce the processing time at the server, and hence,
    the latency of each request by roughly 1 second per request at peak time. The
    latency has now gone down from 2 seconds to 1 second.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 经过进一步分析，架构师发现通过重写在服务器上处理报告的代码，使其在多个进程中运行而不是单个进程，他能够在高峰时期将每个请求的处理时间减少约1秒。延迟现在从2秒降至1秒。
- en: The system's performance with respect to latency has become better by
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的性能在延迟方面已经变得更好
- en: 'Performance (latency): *X = 2/1 = 2X*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 性能（延迟）：X = 2/1 = 2倍
- en: How does this improve scalability? Since the time taken to process each request
    is lesser now, the system overall will be able to respond to similar loads at
    a faster rate than what it was able to earlier. With the exact same resources,
    the system's throughput performance, and hence, scalability has increased assuming
    other factors remain the same.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这如何改善可伸缩性？由于现在处理每个请求所需的时间更短，系统整体将能够以比之前更快的速度响应类似的负载。在其他因素保持不变的情况下，系统的吞吐性能和因此可伸缩性已经提高。
- en: 'Let''s summarize what we discussed so far as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下我们迄今讨论的内容：
- en: In the first step, the architect increased the throughput of a single system
    by scaling it up by adding extra memory as a resource, which increased the overall
    scalability of the system. In other words, he scaled the performance of a single
    system by *scaling up*, which boosted the overall performance of the whole system.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步中，架构师通过增加额外内存作为资源来扩展单个系统的吞吐量，从而增加了系统的整体可伸缩性。换句话说，他通过“纵向扩展”来扩展单个系统的性能，从而提高了整个系统的性能。
- en: In the second step, he added more nodes to the system, and hence, its ability
    to perform work concurrently, and found that the system responded well by rewarding
    him with a near-linear scalability factor. In other words, he increased the throughput
    of the system by scaling its resource capacity. Thus, he increased scalability
    of the system by *scaling out*, that is, by adding more compute nodes.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二步中，他向系统添加了更多节点，因此系统能够同时执行工作，并发现系统以接近线性的可伸缩性因子回报他。换句话说，他通过增加计算节点来扩展系统的资源容量，从而提高了系统的可伸缩性。因此，他通过“横向扩展”来增加了系统的可伸缩性，即通过添加更多计算节点。
- en: In the third step, he made a critical fix by running a computation in more than
    one process. In other words, he increased the *concurrency* of a single system
    by dividing the computation to more than one part. He found that this increased
    the performance characteristic of the application by reducing its *latency*, potentially
    setting up the application to handle workloads better at high stress.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三步中，他通过在多个进程中运行计算来进行关键修复。换句话说，他通过将计算分成多个部分来增加单个系统的并发性。他发现这提高了应用程序的性能特征，通过减少其延迟，潜在地使应用程序能够更好地处理高压工作负载。
- en: 'We find that there is a relation between Scalability, Performance, Concurrency,
    and Latency. This can be explained as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现可伸缩性、性能、并发性和延迟之间存在关系。这可以解释如下：
- en: When performance of one of the components in a system goes up, generally the
    performance of the overall system goes up.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当系统中某个组件的性能提高时，通常整个系统的性能也会提高。
- en: When an application scales in a single machine by increasing its concurrency,
    it has the potential to improve performance, and hence, the net scalability of
    the system in deployment.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当应用程序通过增加并发性在单台机器上扩展时，它有潜力提高性能，从而提高部署系统的净可伸缩性。
- en: When a system reduces its performance time, or its latency, at the server, it
    positively contributes to scalability.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当系统减少其性能时间或服务器端的延迟时，这对可伸缩性是积极的贡献。
- en: 'We have captured these relationships in the following table:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在以下表格中捕捉到了这些关系：
- en: '| Concurrency | Latency | Performance | Scalability |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 并发性 | 延迟 | 性能 | 可扩展性 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| High | Low | High | High |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 高 | 低 | 高 | 高 |'
- en: '| High | High | Variable | Variable |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 高 | 高 | 可变 | 可变 |'
- en: '| Low | High | Poor | Poor |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 低 | 高 | 差 | 差 |'
- en: An ideal system is one that has good concurrency and low latency; such a system
    has high performance, and would respond better to scaling up and/or scaling out.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 理想的系统是具有良好并发性和低延迟的系统；这样的系统具有高性能，并且对于扩展和/或横向扩展会有更好的响应。
- en: A system with high concurrency, but also high latency, would have variable characteristics—its
    performance, and hence, scalability would be potentially very sensitive to other
    factors such as current system load, network congestion, geographical distribution
    of compute resources and requests, and so on.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 具有高并发性但也有高延迟的系统将具有可变的特征——其性能，因此，可扩展性可能对其他因素非常敏感，例如当前系统负载、网络拥塞、计算资源和请求的地理分布等。
- en: A system with low concurrency and high latency is the worst case—it would be
    difficult to scale such a system, as it has poor performance characteristics.
    The latency and concurrency issues should be addressed before the architect decides
    to scale the system horizontally or vertically.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 低并发和高延迟的系统是最糟糕的情况——很难扩展这样的系统，因为它具有较差的性能特征。在架构师决定横向或纵向扩展系统之前，应该先解决延迟和并发性问题。
- en: Scalability is always described in terms of variation in performance throughput.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性总是以性能吞吐量的变化来描述。
- en: Concurrency
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发性
- en: A system's concurrency is the degree to which the system is able to perform
    work simultaneously instead of sequentially. An application written to be concurrent
    in general, can execute more units of work in a given time than one which is written
    to be sequential or serial.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的并发性是系统能够同时执行工作而不是顺序执行的程度。一般来说，编写为并发的应用程序在给定时间内可以执行更多的工作单位，而不是编写为顺序或串行的应用程序。
- en: When one makes a serial application concurrent, one makes the application better
    utilize the existing compute resources in the system—CPU and/or RAM—at a given
    time. Concurrency, in other words, is the cheapest way of making an application
    scale inside a machine in terms of the cost of compute resources.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当将串行应用程序并发化时，可以更好地利用系统中现有的计算资源——CPU和/或RAM——在给定时间内。换句话说，并发性是以计算资源成本为代价，使应用程序在机器内扩展的最便宜的方式。
- en: 'Concurrency can be achieved using different techniques. The common ones include
    the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 并发可以通过不同的技术实现。常见的包括以下几种：
- en: '**Multithreading**: The simplest form of concurrency is to rewrite the application
    to perform parallel tasks in different threads. A thread is the simplest sequence
    of programming instructions that can be performed by a CPU. A program can consist
    of any number of threads. By distributing tasks to multiple threads, a program
    can execute more work simultaneously. All threads run inside the same process.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多线程**：并发的最简单形式是将应用程序重写为在不同线程中执行并行任务。线程是CPU可以执行的最简单的编程指令序列。一个程序可以包含任意数量的线程。通过将任务分配给多个线程，程序可以同时执行更多的工作。所有线程都在同一个进程内运行。'
- en: '**Multiprocessing**: Another way to concurrently scale up a program is to run
    it in multiple processes instead of a single process. Multiprocessing involves
    more overhead than multithreading in terms of message passing and shared memory.
    However, programs that perform a lot of CPU-intensive computations can benefit
    more from multiple processes than multiple threads.'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多进程**：将程序并发地扩展到多个进程而不是单个进程是另一种方法。多进程在消息传递和共享内存方面的开销比多线程更大。然而，执行大量CPU密集型计算的程序比多线程更适合多进程。'
- en: '**Asynchronous Processing**: In this technique, operations are performed asynchronously
    with no specific ordering of tasks with respect to time. Asynchronous processing
    usually picks tasks from a queue of tasks, and schedules them to execute at a
    future time, often receiving the results in callback functions or special future
    objects. Asynchronous processing usually happens in a single thread.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**异步处理**：在这种技术中，操作是异步执行的，没有特定的任务顺序与时间有关。异步处理通常从任务队列中选择任务，并安排它们在将来的某个时间执行，通常在回调函数或特殊的future对象中接收结果。异步处理通常发生在单个线程中。'
- en: There are other forms of concurrent computing, but in this chapter, we will
    focus our attention on only these three.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他形式的并发计算，但在本章中，我们将只关注这三种。
- en: Python, especially Python 3, has built-in support for all these types of concurrent
    computing techniques in its standard library. For example, it supports multi-threading
    via its *threading* module, and multiple processes via its *multiprocessing* module.
    Asynchronous execution support is available via the *asyncio* module. A form of
    concurrent processing that combines asynchronous execution with threads and processes
    is available via the *concurrent.futures* module.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Python，特别是Python 3，在其标准库中内置支持所有这些类型的并发计算技术。例如，它通过其*threading*模块支持多线程，并通过其*multiprocessing*模块支持多进程。异步执行支持可通过*asyncio*模块获得。一种将异步执行与线程和进程结合起来的并发处理形式可通过*concurrent.futures*模块获得。
- en: In the coming sections we will take a look at each of these in turn with sufficient
    examples.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将逐个查看每个，并提供足够的示例。
- en: Note
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'NOTE: The asyncio module is available only in Python 3'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：asyncio模块仅在Python 3中可用
- en: Concurrency versus parallelism
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发与并行
- en: We will take a brief look at the concept of concurrency and its close cousin,
    namely parallelism.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将简要介绍并发概念及其近亲并行概念。
- en: Both concurrency and parallelism are about executing work simultaneously rather
    than sequentially. However, in concurrency, the two tasks need not be executed
    at the exact same time; instead, they just need to be scheduled to be executed
    simultaneously. Parallelism, on the other hand, requires that both the tasks execute
    together at a given moment in time.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 并发和并行都是关于同时执行工作而不是顺序执行。然而，在并发中，两个任务不需要在完全相同的时间执行；相反，它们只需要被安排同时执行。另一方面，并行性要求两个任务在给定的时间点同时执行。
- en: 'To take a real-life example, let''s say you are painting two exterior walls
    of your house. You have employed just one painter, and you find that he is taking
    a lot more time than you thought. You can solve the problem in these two ways:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 举一个现实生活的例子，假设你正在为你房子的两面外墙涂漆。你只雇用了一个画家，你发现他花的时间比你想象的要多。你可以通过以下两种方式解决问题：
- en: Instruct the painter to paint a few coats on one wall before switching to the
    next wall, and doing the same there. Assuming he is efficient, he will work on
    both the walls simultaneously (though not at the same time), and achieve the same
    degree of finish on both walls for a given time. This is a *concurrent* solution.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指示画家在切换到下一面墙之前在一面墙上涂几层，然后在另一面墙上做同样的事情。假设他很有效，他将同时（虽然不是在同一时间）在两面墙上工作，并在给定的时间内达到相同的完成度。这是一个*并发*解决方案。
- en: Employ one more painter. Instruct the first painter to paint the first wall,
    and the second painter to paint the second wall. This is a *parallel* solution.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再雇用一个画家。指示第一个画家涂第一面墙，第二个画家涂第二面墙。这是一个*并行*解决方案。
- en: Two threads are performing bytecode computations in a single core CPU do not
    exactly perform parallel computation, as the CPU can accommodate only one thread
    at a time. However, they are concurrent from a programmer's perspective, since
    the CPU scheduler performs fast switching in and out of the threads so that they
    appear to run in parallel.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 两个线程在单核CPU中执行字节码计算并不完全进行并行计算，因为CPU一次只能容纳一个线程。然而，从程序员的角度来看，它们是并发的，因为CPU调度程序快速地在线程之间进行切换，使它们看起来是并行运行的。
- en: However, on a multi-core CPU, two threads can perform parallel computations
    at any given time in its different cores. This is true parallelism.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在多核CPU上，两个线程可以在不同的核心上同时进行并行计算。这是真正的并行。
- en: Parallel computation requires that the computation resources increase at least
    linearly with respect to its scale. Concurrent computation can be achieved by
    using the techniques of multitasking, where work is scheduled and executed in
    batches, making better use of existing resources.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 并行计算要求计算资源至少与其规模成线性增长。通过使用多任务处理技术，可以实现并发计算，其中工作被安排并批量执行，更好地利用现有资源。
- en: Note
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: In this chapter, we will use the term *concurrent* uniformly to indicate both
    types of execution. In some places, it may indicate concurrent processing in the
    traditional way, and in some other, it may indicate true parallel processing.
    Use the context to disambiguate.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将统一使用术语*并发*来指示两种类型的执行。在某些地方，它可能表示传统方式的并发处理，而在其他地方，它可能表示真正的并行处理。使用上下文来消除歧义。
- en: Concurrency in Python – multithreading
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python中的并发 - 多线程
- en: We will start our discussion of concurrent techniques in Python with multithreading.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从Python中的多线程开始讨论并发技术。
- en: 'Python supports multiple threads in programming via its *threading* module.
    The threading module exposes a `Thread` class, which encapsulates a thread of
    execution. Along with this, it also exposes the following synchronization primitives:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Python通过其*threading*模块支持多线程编程。线程模块公开了一个`Thread`类，它封装了一个执行线程。除此之外，它还公开了以下同步原语：
- en: A `Lock` object, which is useful for synchronized protected access to share
    resources, and its cousin `RLock`.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个`Lock`对象，用于同步保护对共享资源的访问，以及它的表兄弟`RLock`。
- en: A Condition object, which is useful for threads to synchronize while waiting
    for arbitrary conditions.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个Condition对象，用于线程在等待任意条件时进行同步。
- en: An `Event` object, which provides a basic signaling mechanism between threads.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Event`对象，它提供了线程之间的基本信号机制。'
- en: A `Semaphore` object, which allows synchronized access to limited resources.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个`Semaphore`对象，它允许对有限资源进行同步访问。
- en: A `Barrier` object, which allows a fixed set of threads to wait for each other,
    synchronize to a particular state, and proceed.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个`Barrier`对象，它允许一组固定的线程等待彼此，同步到特定状态，然后继续。
- en: Thread objects in Python can be combined with the synchronized `Queue` class
    in the queue module for implementing thread-safe producer/consumer workflows.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的线程对象可以与队列模块中的同步`Queue`类结合使用，用于实现线程安全的生产者/消费者工作流程。
- en: Thumbnail generator
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缩略图生成器
- en: Let us start our discussion of multi-threading in Python with the example of
    a program used to generate thumbnails of image URLs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个用于生成图像URL缩略图的程序的例子开始讨论Python中的多线程。
- en: 'In the example, we are using **Pillow**, a fork of the **Python Imaging Library**
    (**PIL**) to perform this operation:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用**Pillow**，它是**Python Imaging Library**（**PIL**）的一个分支，来执行这个操作：
- en: '[PRE0]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding code works very well for single URLs.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码对单个URL非常有效。
- en: 'Let us say we want to convert five image URLs to their thumbnails:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要将五个图像URL转换为它们的缩略图：
- en: '[PRE1]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s see how such a function performs with respect to time taken in the following
    screenshot:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这样一个函数在所花费的时间方面的表现：
- en: '![Thumbnail generator](../Images/image00433.jpeg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![缩略图生成器](../Images/image00433.jpeg)'
- en: Response time of serial thumbnail converter for 5 URLs
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 对于5个URL的串行缩略图转换的响应时间
- en: The function took approximately 1.7 seconds per URL.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数大约每个URL花费了1.7秒的时间。
- en: 'Let us now scale the program to multiple threads so we can perform the conversions
    concurrently. Here is the rewritten code to run each conversion in its own thread:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将程序扩展到多个线程，这样我们就可以同时进行转换。以下是重写的代码，以便在每个转换中运行自己的线程：
- en: '[PRE2]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The timing that this last program now gives is shown in this screenshot:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这个最后一个程序的时间显示在这个截图中：
- en: '![Thumbnail generator](../Images/image00434.jpeg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![缩略图生成器](../Images/image00434.jpeg)'
- en: Response time of threaded thumbnail converter for 5 URLs
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 5 个 URL 的线程缩略图转换的响应时间
- en: With this change, the program returns in 1.76 seconds, almost equal to the time
    taken by a single URL in serial execution before. In other words, the program
    has now linearly scaled with respect to the number of threads. Note that, we had
    to make no change to the function itself to get this scalability boost.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个改变，程序返回时间为 1.76 秒，几乎等于串行执行之前单个 URL 所花费的时间。换句话说，程序现在与线程数量成线性关系。请注意，我们无需对函数本身进行任何更改即可获得这种可伸缩性提升。
- en: Thumbnail generator – producer/consumer architecture
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缩略图生成器 - 生产者/消费者架构
- en: In the previous example, we saw a set of image URLs being processed by a thumbnail
    generator function concurrently by using multiple threads. With the use of multiple
    threads, we were able to achieve near linear scalability as compared to serial
    execution.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们看到一组图像 URL 被缩略图生成器函数并发处理，使用多个线程。通过使用多个线程，我们能够实现接近线性的可伸缩性，与串行执行相比。
- en: However, in real life, rather than processing a fixed list of URLs, it is more
    common for the URL data to be produced by some kind of URL producer. It could
    be fetching this data from a database, a **comma separated value** (**CSV**) file
    or from a TCP socket for example.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在现实生活中，与其处理固定的 URL 列表，更常见的是 URL 数据由某种 URL 生产者生成。例如，可以从数据库、逗号分隔值（CSV）文件或 TCP
    套接字中获取这些数据。
- en: In such a scenario, creating one thread per URL would be a tremendous waste
    of resources. It takes a certain overhead to create a thread in the system. We
    need some way to reuse the threads we create.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，为每个 URL 创建一个线程将是一种巨大的资源浪费。在系统中创建线程需要一定的开销。我们需要一种方法来重用我们创建的线程。
- en: 'For such systems that involve a certain set of threads producing data and another
    set of threads consuming or processing data, the producer/consumer model is an
    ideal fit. Such a system has the following features:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于涉及一定数量的线程生成数据和另一组线程消耗或处理数据的系统，生产者/消费者模型是一个理想的选择。这样的系统具有以下特点：
- en: Producers are a specialized class of workers (threads) producing the data. They
    may receive the data from a specific source(s), or generate the data themselves.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生产者是一种专门的工作者（线程）类，用于生成数据。它们可以从特定来源接收数据，或者自己生成数据。
- en: Producers add the data to a shared synchronized queue. In Python, this queue
    is provided by the `Queue` class in the aptly named `queue` module.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生产者将数据添加到共享的同步队列中。在 Python 中，这个队列由名为 `queue` 的模块中的 `Queue` 类提供。
- en: Another set of specialized class of workers, namely consumers, wait on the queue
    to get (consume) the data. Once they get the data, they process it and produce
    the results.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一组专门的工作者类，即消费者，等待队列获取（消费）数据。一旦获取数据，他们就会处理它并产生结果。
- en: The program comes to an end when the producers stop generating data and the
    consumers are starved of data. Techniques like timeouts, polling, or poison pills
    can be used to achieve this. When this happens, all threads exit, and the program
    completes.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当生产者停止生成数据并且消费者无法获取数据时，程序结束。可以使用超时、轮询或毒丸等技术来实现这一点。当发生这种情况时，所有线程退出，程序完成。
- en: We have rewritten our thumbnail generator to a producer consumer architecture.
    The resulting code is given next. Since this is a bit detailed, we will discuss
    each class one by one.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将我们的缩略图生成器重写为生产者消费者架构。接下来是生成的代码。由于这有点详细，我们将逐个讨论每个类。
- en: 'First, let''s look at the imports—these are pretty self-explanatory:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看一下导入部分 - 这些都相当容易理解：
- en: '[PRE3]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next is the code for the producer class:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是生产者类的代码：
- en: '[PRE4]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let''s analyze the producer class code:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析生产者类的代码：
- en: The class is named `ThumbnailURL_Generator`. It generates the URLs (by using
    the service of a website named [http://dummyimage.com](http://dummyimage.com))
    of different sizes, foreground, and background colors. It inherits from the `threading.Thread`
    class.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类名为 `ThumbnailURL_Generator`。它生成不同尺寸、前景和背景颜色的 URL（通过使用名为 [http://dummyimage.com](http://dummyimage.com)
    的网站的服务）。它继承自 `threading.Thread` 类。
- en: It has a `run` method, which goes in a loop, generates a random image URL, and
    pushes it to the shared queue. Every time, the thread sleeps for a fixed time,
    as configured by the `sleep_time` parameter.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它有一个 `run` 方法，进入循环，生成一个随机图像 URL，并将其推送到共享队列。每次，线程都会休眠一段固定的时间，由 `sleep_time` 参数配置。
- en: The class exposes a `stop` method, which sets the internal flag to `False` causing
    the loop to break and the thread to finish its processing. This can be called
    externally by another thread, typically, the main thread.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类公开了一个 `stop` 方法，它将内部标志设置为 `False`，导致循环中断并且线程完成其处理。这通常可以由另一个线程外部调用，通常是主线程。
- en: 'Now, the URL consumer class that consumes the thumbnail URLs and creates the
    thumbnails:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，URL 消费者类消耗缩略图 URL 并创建缩略图：
- en: '[PRE5]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here''s the analysis of the consumer class:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是消费者类的分析：
- en: The class is named `ThumbnailURL_Consumer`, as it consumes URLs from the queue,
    and creates thumbnail images of them.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类名为 `ThumbnailURL_Consumer`，它从队列中获取 URL，并创建其缩略图图像。
- en: The `run` method of this class goes in a loop, gets a URL from the queue, and
    converts it to thumbnail by passing it to the `thumbnail_image` method. (Note
    that this code is exactly the same as that of the `thumbnail_image` function we
    created earlier.)
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类的 `run` 方法进入循环，从队列中获取一个 URL，并通过将其传递给 `thumbnail_image` 方法将其转换为缩略图。（请注意，此代码与我们之前创建的
    `thumbnail_image` 函数完全相同。）
- en: The `stop` method is very similar, checking for a stop flag every time in the
    loop, and ending once the flag has been unset.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`stop` 方法非常相似，每次在循环中检查停止标志，并在标志被取消后结束。'
- en: 'Here is the main part of the code—setting up a couple of producers and consumers
    each, and running them:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码的主要部分 - 设置一对生产者和消费者，并运行它们：
- en: '[PRE6]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here is a screenshot of the program in action:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这是程序运行的屏幕截图：
- en: '![Thumbnail generator – producer/consumer architecture](../Images/image00435.jpeg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![缩略图生成器-生产者/消费者架构](../Images/image00435.jpeg)'
- en: Running the thumbnail producer/consumer program with 4 threads, 2 of each type
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用4个线程运行缩略图生产者/消费者程序，每种类型2个
- en: In the above program, since the producers keeps generating random data without
    any end, the consumers will keep consuming it without any end. Our program has
    no proper end condition.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述程序中，由于生产者不断生成随机数据而没有结束，消费者将继续消耗它而没有结束。我们的程序没有适当的结束条件。
- en: Hence this program will keep running forever till the network requests are denied
    or timed out or the disk space of the machine runs out because of thumbnails.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，该程序将一直运行，直到网络请求被拒绝或超时，或者由于缩略图而使机器的磁盘空间耗尽。
- en: However, a program solving a real world problem should end in some way which
    is predictable.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，解决真实世界问题的程序应该以可预测的方式结束。
- en: This could be due to a number of external constraints
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是由于许多外部约束造成的。
- en: It could be a timeout introduced where the consumers wait for data for a certain
    maximum time, and then exit if no data is available during that time. This, for
    example, can be configured as a timeout in the `get` method of the queue.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以引入一个超时，在这种情况下，消费者等待一定的最大时间获取数据，如果在此期间没有可用数据，则退出。例如，这可以在队列的`get`方法中配置为超时。
- en: Another technique would be to signal program end after a certain number of resources
    are consumed or created. In this program, for example, it could be a fixed limit
    to the number of thumbnails created.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一种技术是在消耗或创建一定数量的资源后发出程序结束信号。例如，在该程序中，可以限制创建的缩略图数量。
- en: In the following section, we will see how to enforce such resource limits by
    using threading synchronization primitives such as Locks and Semaphores.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将看到如何通过使用线程同步原语（如Locks和Semaphores）来强制执行此类资源限制。
- en: Note
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You may have observed that we start a thread using its `start` method, though
    the overridden method in the Thread subclass is `run`. This is because, in the
    parent `Thread` class, the `start` method sets up some state, and then calls the
    `run` method internally. This is the right way to call the thread's run method.
    It should never be called directly.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，我们使用`start`方法启动线程，尽管线程子类中的重写方法是`run`。这是因为在父`Thread`类中，`start`方法设置了一些状态，然后在内部调用`run`方法。这是调用线程的运行方法的正确方式。它不应该直接调用。
- en: Thumbnail generator – resource constraint using locks
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缩略图生成器-使用锁的资源约束
- en: In the earlier section, we saw how to rewrite the thumbnail generator program
    moulded in the producer/consumer architecture. However, our program had a problem—it
    would run endlessly till it ran out of disk space or network bandwidth.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，我们看到了如何重写生产者/消费者架构中的缩略图生成器程序。然而，我们的程序有一个问题——它会无休止地运行，直到磁盘空间或网络带宽耗尽。
- en: In this section, we will see how to modify the program using a `Lock`, a synchronization
    primitive to implement a counter that will limit the number of images created
    as a way to end the program.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到如何使用`Lock`来修改程序，`Lock`是一种同步原语，用于实现限制创建图像数量的计数器，以结束程序。
- en: Lock objects in Python allows exclusive access by threads to a shared resource.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的Lock对象允许线程对共享资源进行独占访问。
- en: 'The pseudo-code would be as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 伪代码如下：
- en: '[PRE7]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'However, Lock objects support context-managers via the with statement, so this
    is more commonly written as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Lock对象支持上下文管理器，通过`with`语句更常见地编写如下：
- en: '[PRE8]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To implement a fixed number of images per run, our code needs to be supported
    to add a counter. However, since multiple threads would check and increment this
    counter, it needs to be synchronized via a `Lock` object.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现每次运行固定数量的图像，我们的代码需要支持添加一个计数器。然而，由于多个线程将检查和增加此计数器，因此需要通过`Lock`对象进行同步。
- en: This is our first implementation of the resource counter class using Locks.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们使用Locks实现的资源计数器类的第一个实现。
- en: '[PRE9]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Since this modifies the consumer class as well, it makes sense to discuss both
    changes together. Here is the modified consumer class to accommodate the extra
    counter needed to keep track of the images:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这也修改了消费者类，因此讨论这两个更改是有意义的。这是修改后的消费者类，以适应需要跟踪图像的额外计数器：
- en: '[PRE10]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Let's analyze both these classes. First the new class, `ThumbnailImageSaver`.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析这两个类。首先是新类`ThumbnailImageSaver`。
- en: This class derives from the `object`. In other words, it is not a `Thread`.
    It is not meant to be one.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个类派生自`object`。换句话说，它不是一个`Thread`。它不是一个`Thread`。
- en: It initializes a lock object and a counter dictionary in its initializer method.
    The lock is for synchronizing access to the counter by threads. It also accepts
    a `limit` parameter equal to the number of images it should save.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它在初始化方法中初始化了一个锁对象和一个计数器字典。锁用于线程同步访问计数器。它还接受一个等于应保存的图像数量的`limit`参数。
- en: The `thumbnail_image` method moves to here from the consumer class. It is called
    from a `save` method, which encloses the call in a synchronized context using
    the lock.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`thumbnail_image`方法从消费者类移动到这里。它从一个使用锁的上下文中的`save`方法调用。'
- en: The `save` method first checks if the count has crossed the configured limit;
    when this happens, the method returns `False`. Otherwise, the image is saved with
    a call to `thumbnail_image`, and the image filename is added to the counter, effectively
    incrementing the count.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`save`方法首先检查计数是否超过了配置的限制；当这种情况发生时，该方法返回`False`。否则，通过调用`thumbnail_image`保存图像，并将图像文件名添加到计数器，有效地增加计数。'
- en: Next, the modified `ThumbnailURL_Consumer` class.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是修改后的`ThumbnailURL_Consumer`类。
- en: The class's initializer is modified to accept an instance of the `ThumbnailImageSaver`
    as a `saver` argument. The rest of the arguments remain the same.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类的初始化程序已修改为接受`ThumbnailImageSaver`的实例作为`saver`参数。其余参数保持不变。
- en: The `thumbnail_image` method no longer exists in this class, as it is moved
    to the new class.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个类中，`thumbnail_image`方法不再存在，因为它已经移动到新的类中。
- en: The `run` method is much simplified. It makes a call to the `save` method of
    the saver instance. If it returns `False`, it means the limit has been reached,
    the loop breaks, and the consumer thread exits.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`run`方法大大简化。它调用保存程序实例的`save`方法。如果返回`False`，则表示已达到限制，循环中断，消费者线程退出。'
- en: We also have modified the `__str__` method to return a unique ID per thread,
    which is set in the initializer using the `uuid` module. This helps to debug threads
    in a real-life example.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还修改了`__str__`方法，以返回每个线程的唯一ID，该ID在初始化时使用`uuid`模块设置。这有助于在实际示例中调试线程。
- en: 'The calling code also changes a bit, as it needs to set up the new object,
    and configure the consumer threads with it:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 调用代码也稍有更改，因为它需要设置新对象，并配置消费者线程：
- en: '[PRE11]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following are the main points to be noted here:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是需要注意的主要要点：
- en: We create an instance of the new `ThumbnailImageSaver` class, and pass it on
    to the consumer threads when creating them.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了新的`ThumbnailImageSaver`类的实例，并在创建消费者线程时将其传递给它们。
- en: We wait on consumers first. Note that, the main thread doesn't call `stop`,
    but `join` on them. This is because the consumers exit automatically when the
    limit is reached, so the main thread should just wait for them to stop.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先等待消费者。请注意，主线程不调用`stop`，而是对它们调用`join`。这是因为当达到限制时，消费者会自动退出，因此主线程应该等待它们停止。
- en: We stop the producers after the consumers exit—explicitly so—since they would
    otherwise keep working forever, since there is no condition for the producers
    to exit.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在消费者退出后，我们明确地停止生产者-因为否则它们将永远工作，因为没有条件让生产者退出。
- en: We use a dictionary instead of an integer as because of the nature of the data.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用字典而不是整数，因为数据的性质。
- en: Since the images are randomly generated, there is a minor chance of one image
    URL being same as another one created previously, causing the filenames to clash.
    Using a dictionary takes care of such possible duplicates.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像是随机生成的，因此有可能一个图像URL与之前创建的另一个图像URL相同，导致文件名冲突。使用字典可以解决这种可能的重复情况。
- en: 'The following screenshot shows a run of the program with a limit of 100 images.
    Note that we can only show the last few lines of the console log, since it produces
    a lot of output:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了使用100张图像限制运行程序的情况。请注意，我们只能显示控制台日志的最后几行，因为它会产生大量输出：
- en: '![Thumbnail generator – resource constraint using locks](../Images/image00436.jpeg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![缩略图生成器-使用锁的资源约束](../Images/image00436.jpeg)'
- en: Run of the thumbnail generator program with a limit of 100 images using a Lock
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 使用锁限制100张图像的缩略图生成程序的运行
- en: You can configure this program with any limit of the images, and it will always
    fetch exactly the same count—nothing more or less.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将此程序配置为任何图像限制，并且它将始终获取完全相同的数量-既不多也不少。
- en: In the next section, we will get familiarized with another synchronization primitive,
    namely *Semaphore*, and learn how to implement a resource limiting class in a
    similar way using the semaphore.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将熟悉另一个同步原语，即*信号量*，并学习如何使用信号量以类似的方式实现资源限制类。
- en: Thumbnail generator – resource constraint using semaphores
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用信号量的缩略图生成器-资源约束
- en: Locks aren't the only way to implement synchronization constraints and write
    logic on top of them such as to limit resources used/generated by a system.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 锁不是实现同步约束和在其上编写逻辑的唯一方法，例如限制系统使用/生成的资源。
- en: A `Semaphore`, one of the oldest synchronization primitives in computer science,
    is ideally suited for such use cases.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 信号量是计算机科学中最古老的同步原语之一，非常适合这种用例。
- en: 'A semaphore is initialized with a value greater than zero:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 信号量是用大于零的值初始化的：
- en: When a thread calls `acquire` on a semaphore that has a positive internal value,
    the value gets decremented by one, and the thread continues on its way.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当线程在具有正内部值的信号量上调用`acquire`时，该值会减少一个，并且线程会继续进行。
- en: When another thread calls `release` on the semaphore, the value is incremented
    by 1.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当另一个线程在信号量上调用`release`时，该值会增加1。
- en: Any thread calling `acquire` once the value has reached zero is blocked on the
    semaphore till it is woken up by another thread calling *release*.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦值达到零，任何线程调用`acquire`都会在信号量上被阻塞，直到另一个线程调用*release*唤醒它。
- en: Due to this behavior, a semaphore is perfectly suited for implementing a fixed
    limit on shared resources.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种行为，信号量非常适合在共享资源上实现固定限制。
- en: 'In the following code example, we will implement another class for resource
    limiting our thumbnail generator program, this time using a semaphore:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码示例中，我们将使用信号量实现另一个用于限制缩略图生成器程序资源的类：
- en: '[PRE12]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Since the new semaphore-based class keeps the exact same interface as the previous
    lock-based class—with a save method—there is no need to change any code on the
    consumer!
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 由于基于信号量的新类保持与基于锁的先前类完全相同的接口-具有保存方法-因此不需要更改任何消费者代码！
- en: Only the calling code needs to be changed.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 只有调用代码需要更改。
- en: 'This line in the previous code which initialized the `ThumbnailImageSaver`
    instance:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的代码中初始化了`ThumbnailImageSaver`实例的这一行：
- en: '[PRE13]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding line needs to be replaced with the following one:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 前一行需要替换为以下行：
- en: '[PRE14]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The rest of the code remains exactly the same.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 其余代码保持完全相同。
- en: 'Let us quickly discuss the new class using the semaphore before seeing this
    code in action:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到这段代码之前，让我们快速讨论一下使用信号量的新类：
- en: The `acquire` and `release` methods are simple wrappers over the same methods
    on the semaphore.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`acquire`和`release`方法只是对信号量上相同方法的简单包装。'
- en: We initialize the semaphore with a value equal to the image limit in the initializer.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在初始化程序中使用图像限制的值来初始化信号量。
- en: In the save method, we call the `acquire` method. If the semaphore's limit is
    reached, it will return `False`. Otherwise, the thread saves the image and returns
    `True`. In the former case, the calling thread quits.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在保存方法中，我们调用`acquire`方法。如果信号量的限制已达到，它将返回`False`。否则，线程保存图像并返回`True`。在前一种情况下，调用线程退出。
- en: Note
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The internal count attribute of this class is only there for debugging. It doesn't
    add anything to the logic of limiting images.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类的内部计数属性只用于调试。它对限制图像的逻辑没有任何添加。
- en: 'This class behaves in a way similar way to the previous one, and limits resources
    exactly. The following is an example with a limit of 200 images:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类的行为方式与前一个类似，并且确切地限制资源。以下是一个限制为200张图片的示例：
- en: '![Thumbnail generator – resource constraint using semaphores](../Images/image00437.jpeg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![使用信号量的缩略图生成器-资源约束](../Images/image00437.jpeg)'
- en: Run of the thumbnail generator program with a limit of 200 images using a Semaphore
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 使用信号量运行缩略图生成程序，限制为200张图片
- en: Resource constraint – semaphore versus lock
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源约束-信号量与锁
- en: We saw two competing versions of implementing a fixed resource constraint in
    the previous two examples—one using `Lock` and another using `Semaphore`.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两个示例中，我们看到了两个实现固定资源约束的竞争版本——一个使用`Lock`，另一个使用`Semaphore`。
- en: 'The differences between the two versions are as follows:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 两个版本之间的区别如下：
- en: The version using Lock protects all the code that modifies the resource—in this
    case, checking the counter, saving the thumbnail, and incrementing the counter—to
    make sure that there are no data inconsistencies.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用锁的版本保护了所有修改资源的代码——在这种情况下，检查计数器、保存缩略图和增加计数器——以确保没有数据不一致。
- en: The Semaphore version is implemented more like a gate—a door that is open while
    the count is below the limit, and through which any number of threads can pass,
    and that only closes when the limit is reached. In other words, it doesn't mutually
    exclude threads from calling the thumbnail saving function.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 信号量版本更像是一个门，当计数低于限制时门是打开的，任意数量的线程可以通过，只有当达到限制时才关闭。换句话说，它不会互斥地排除线程调用缩略图保存函数。
- en: Hence, the effect is that the Semaphore version would be faster than the version
    using Lock.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，信号量版本的效果将比使用锁的版本更快。
- en: How much faster? The following timing example for a run of 100 images gives
    an idea.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 有多快？以下是一个运行100张图片的计时示例。
- en: 'This screenshot shows the time it takes for the Lock version to save 100 images:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这个截图显示了使用锁版本保存100张图片所需的时间：
- en: '![Resource constraint – semaphore versus lock](../Images/image00438.jpeg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![资源约束-信号量与锁](../Images/image00438.jpeg)'
- en: Timing the run of the thumbnail generator program—the Lock version—for 100 images
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 计时缩略图生成程序的运行——锁版本——100张图片
- en: 'The following screenshot shows the time for the Semaphore version to save a
    similar number:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了使用信号量版本保存类似数量的时间：
- en: '![Resource constraint – semaphore versus lock](../Images/image00439.jpeg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![资源约束-信号量与锁](../Images/image00439.jpeg)'
- en: Timing the run of the thumbnail generator program—the Semaphore version—for
    100 images
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 计时缩略图生成程序的运行——信号量版本——100张图片
- en: By a quick calculation you can see that the semaphore version is about 4 times
    faster than the lock version for the same logic. In other words, it *scales 4
    times better*.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 通过快速计算，您可以看到信号量版本比锁版本快大约4倍，逻辑相同。换句话说，它*扩展4倍*。
- en: Thumbnail generator – URL rate controller using conditions
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缩略图生成器-使用条件控制URL速率
- en: In this section, we will briefly see the application of another important synchronization
    primitive in threading, namely the `Condition` object.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要介绍线程中另一个重要的同步原语的应用，即`Condition`对象。
- en: First, we will get a real life example of using a `Condition` object. We will
    implement a throttler for our thumbnail generator to manage the rate of URL generation.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将得到一个使用`Condition`对象的现实生活示例。我们将为我们的缩略图生成器实现一个节流器，以管理URL生成的速率。
- en: 'In the producer/consumer systems in real life, the following three kinds of
    scenario can occur with respect to the rate of data production and consumption:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实生活中的生产者/消费者系统中，关于数据生产和消费速度，可能会出现以下三种情况：
- en: Producers produce data at a faster pace than consumers can consume. This causes
    the consumers to always play catch up with the producers. Excess data by the producers
    can accumulate in the queue, which causes the queue to consume a higher memory
    and CPU usage in every loop causing the program to slow down.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生产者产生的数据速度比消费者消耗的速度快。这导致消费者总是在追赶生产者。生产者产生的多余数据可能会积累在队列中，导致队列消耗更多的内存和CPU使用率，从而使程序变慢。
- en: Consumers consume data at a faster rate than producers. This causes the consumers
    to always wait on the queue—for data. This, in itself, is not a problem as long
    as the producers don't lag too much. In the worst case, this leads to half of
    the system, that is, the consumers, remaining idle, while the other half—the producers—try
    to keep up with the demand.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 消费者以比生产者更快的速度消耗数据。这导致消费者总是在队列上等待数据。这本身并不是问题，只要生产者不落后太多。在最坏的情况下，这会导致系统的一半，即消费者，保持空闲，而另一半——生产者——试图满足需求。
- en: Both producers and consumers work at nearly the same pace keeping the queue
    size within limits. This is the ideal scenario.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生产者和消费者以几乎相同的速度工作，保持队列大小在限制范围内。这是理想的情况。
- en: 'There are many ways to solve this problem. Some of them are as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以解决这个问题。其中一些如下：
- en: '**Queue with a fixed size** – Producers would be forced to wait till data is
    consumed by a consumer once the queue size limit is reached. However this would
    almost always keeps the queue full.'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**具有固定大小的队列**——一旦队列大小限制达到，生产者将被迫等待，直到数据被消费者消耗。然而，这几乎总是使队列保持满状态。'
- en: '**Provide the workers with timeouts plus other responsibilities**: Rather than
    remain blocked on the queue, producers and/or consumers can use a timeout to wait
    on the queue. When they time out they can either sleep or perform some other responsibilities
    before coming back and waiting on the queue.'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**为工作线程提供超时和其他职责**：生产者和/或消费者可以使用超时在队列上等待，而不是保持阻塞状态。当超时时，它们可以在返回并等待队列之前睡眠或执行其他职责。'
- en: '**Dynamically configure the number of workers**: This is an approach where
    the worker pool size automatically increases or decreases upon demand. If one
    class of workers is ahead, the system will launch just the required number of
    workers of the opposite class to keep the balance.'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**动态配置工作线程的数量**：这是一种方法，其中工作线程池的大小会根据需求自动增加或减少。如果某一类工作线程领先，系统将启动相反类别的所需数量的工作线程以保持平衡。'
- en: '**Adjust the data generation rate**: In this approach, we statically or dynamically
    adjust the data generation rate by the producers. For example, the system can
    be configured to produce data at a fixed rate, say, 50 URLs in a minute or it
    can calculate the rate of consumption by the consumers, and adjust the data production
    rate of the producers dynamically to keep things in balance.'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**调整数据生成速率**：在这种方法中，我们通过生产者静态或动态地调整数据生成速率。例如，系统可以配置为以固定速率生成数据，比如每分钟50个URL，或者它可以计算消费者的消费速率，并动态调整生产者的数据生成速率以保持平衡。'
- en: In the following example, we will implement the last approach—to limit the production
    rate of URLs to a fixed limit using `Condition` objects.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们将实现最后一种方法 - 使用`Condition`对象将URL的生产速率限制为固定限制。
- en: 'A `Condition` object is a sophisticated synchronization primitive that comes
    with an implicit built-in lock. It can wait on an arbitrary condition till it
    becomes True. The moment the thread calls `wait` on the condition, the internal
    lock is released, but the thread itself becomes blocked:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '`Condition`对象是一种复杂的同步原语，带有隐式内置锁。它可以等待任意条件直到条件变为True。当线程在条件上调用`wait`时，内部锁被释放，但线程本身变为阻塞状态：'
- en: '[PRE15]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, another thread can wake up this preceding thread by setting the condition
    to True, and then calling `notify` or `notify_all` on the condition object. At
    this point, the preceding blocked thread is woken up, and continues on its way:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，另一个线程可以通过将条件设置为True来唤醒前面的线程，然后在条件对象上调用`notify`或`notify_all`。此时，前面被阻塞的线程被唤醒，并继续执行：
- en: '[PRE16]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here is our new class namely `ThumbnailURLController` which implements the rate
    control of URL production using a condition object.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的新类，即`ThumbnailURLController`，它使用条件对象实现URL生成的速率控制。
- en: '[PRE17]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s discuss the preceding code before we discuss the changes in the producer
    class that will make use of this class:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论生产者类中的更改之前，让我们先讨论上述代码：
- en: The class is an instance of `Thread`, so it runs in its own thread of execution.
    It also holds a Condition object.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类是`Thread`的一个实例，因此它在自己的执行线程中运行。它还持有一个Condition对象。
- en: It has a `calc_rate` method, which calculates the rate of generation of URLs
    by keeping a counter and using timestamps.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它有一个`calc_rate`方法，通过保持计数器和使用时间戳来计算URL生成的速率。
- en: In the `run` method, the rate is checked. If it's below the configured limit,
    the condition object notifies all threads waiting on it.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`run`方法中，检查速率。如果低于配置的限制，条件对象会通知所有等待它的线程。
- en: 'Most importantly, it implements a `throttle` method. This method uses the current
    rate, calculated via `calc_rate`, and uses it to throttle and adjust the sleep
    times of the producers. It mainly does these two things:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最重要的是，它实现了一个`throttle`方法。该方法使用通过`calc_rate`计算的当前速率，并用它来限制和调整生产者的睡眠时间。它主要做这两件事：
- en: If the rate is more than the configured limit, it causes the calling thread
    to wait on the condition object till the rate levels off. It also calculates an
    extra sleep time that the thread should sleep in its loop to adjust the rate to
    the required level.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果速率高于配置的限制，则导致调用线程在条件对象上等待，直到速率稳定下来。它还计算了线程在循环中应该睡眠的额外时间，以调整速率到所需水平。
- en: If the rate is less than the configured limit, then the thread needs to work
    faster and produce more data, so it calculates the sleep difference and lowers
    the sleep limit accordingly.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果速率低于配置的限制，则线程需要更快地工作并产生更多数据，因此它计算睡眠差并相应地降低睡眠限制。
- en: 'Here is the code of the producer class to incorporate the changes:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是生产者类的代码，以包含这些更改：
- en: '[PRE18]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s see how this last code works:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这段最后的代码是如何工作的：
- en: The class now accepts an additional controller object in its initializer. This
    is the instance of the controller class given earlier.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类现在在初始化时接受一个额外的控制器对象。这是之前给出的控制器类的实例。
- en: After putting a URL, it increments the count on the controller. Once the count
    reaches a minimum limit (set as 5 to avoid early throttling of the producers),
    it calls `throttle` on the controller, passing itself as the argument.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 放置URL后，它会增加控制器上的计数。一旦计数达到最小限制（设置为5以避免过早地限制生产者），它会在控制器上调用`throttle`，并将自身作为参数传递。
- en: 'The calling code also needs quite a few changes. The modified code is shown
    as follows:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 调用代码也需要进行相当多的更改。修改后的代码如下所示：
- en: '[PRE19]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The main changes here are the ones listed next:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的主要更改如下所列：
- en: The controller object is created – with the exact number of producers that will
    be created. This helps the correct calculation of sleep time per thread.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制器对象被创建 - 具有将要创建的生产者的确切数量。这有助于正确计算每个线程的睡眠时间。
- en: The producer threads themselves are passed the instance of the controller in
    their initializer.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生产者线程本身在初始化时会传入控制器的实例。
- en: The controller is started as a thread before all other threads.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制器在所有其他线程之前作为一个线程启动。
- en: Here is a run of the program configured with 200 images at the rate of 50 images
    per minute. We show two images of the running program's output, one at the beginning
    of the program and one towards the end.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这是以每分钟50张图片的速率配置了200张图片的程序运行。我们展示了运行程序输出的两张图片，一张是程序开始时的，另一张是接近结束时的。
- en: '![Thumbnail generator – URL rate controller using conditions](../Images/image00440.jpeg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![缩略图生成器 - 使用条件的URL速率控制器](../Images/image00440.jpeg)'
- en: Starting the thumbnail program with URL rate controller—at 50 URLs per minute
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 以每分钟50个URL的速率启动缩略图程序
- en: You will find that, when the program starts, it almost immediately slows down,
    and nearly comes to a halt, since the original rate is high. What happens here
    is that the producers call on the `throttle` method, and since the rate is high,
    they all get blocked on the condition object.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现，当程序启动时，几乎立即变慢，几乎停止，因为原始速率很高。这里发生的是，生产者调用`throttle`方法，由于速率很高，它们都被阻塞在条件对象上。
- en: After a few seconds, the rate comes down to the prescribed limit, since no URLs
    are generated. This is detected by the controller in its loop, and it calls `notify_all`
    on the threads, waking them up.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 几秒钟后，速率下降到规定的限制，因为没有生成URL。这在控制器的循环中被检测到，并调用`notify_all`唤醒它们。
- en: After a while you will see that the rate is getting settled around the set limit
    of 50 URLs per minute.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 过一会儿，你会发现速率稳定在每分钟50个URL的设定限制周围。
- en: '![Thumbnail generator – URL rate controller using conditions](../Images/image00441.jpeg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![缩略图生成器 - 使用条件的URL速率控制器](../Images/image00441.jpeg)'
- en: The thumbnail program with URL rate controller 5-6 seconds after start
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 带有URL速率控制器的缩略图程序在启动后5-6秒
- en: 'Towards the end of the program, you will see that the rate has almost settled
    to the exact limit:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在程序接近结束时，你会发现速率几乎已经稳定在确切的限制上：
- en: '![Thumbnail generator – URL rate controller using conditions](../Images/image00442.jpeg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![缩略图生成器 - 使用条件的URL速率控制器](../Images/image00442.jpeg)'
- en: The thumbnail program with URL rate controller towards the end
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 朝着结束的方向，带有URL速率控制器的缩略图程序
- en: We are coming towards the end of our discussion on threading primitives and
    how to use them in improving the concurrency of your programs and in implementing
    shared resource constraints and controls.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将结束我们关于线程原语的讨论，以及如何在程序中提高并发性和实现共享资源约束和控制时使用它们。
- en: Before we conclude, we will look at an aspect of Python threads which prevents
    multi-threaded programs from making full use of the CPU in Python – namely the
    GIL or Global Interpreter Lock.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束之前，我们将看一下Python线程的一个方面，它阻止多线程程序在Python中充分利用CPU的能力 - 即GIL或全局解释器锁。
- en: Multithreading – Python and GIL
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程 - Python和GIL
- en: In Python there is, a global lock that prevents multiple threads from executing
    native bytecode at once. This lock is required, since the memory management of
    CPython (the native implementation of Python) is not thread-safe.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，有一个全局锁，防止多个线程同时执行本机字节码。这个锁是必需的，因为CPython（Python的本机实现）的内存管理不是线程安全的。
- en: This lock is called **Global Interpreter Lock** or just **GIL**.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这个锁被称为**全局解释器锁**或**GIL**。
- en: 'Python cannot execute bytecode operations concurrently on CPUs due to the GIL.
    Hence, Python becomes nearly unsuitable for the following cases:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 由于全局解释器锁（GIL），Python无法在CPU上并发执行字节码操作。因此，Python几乎不适用于以下情况：
- en: When the program depends on a number of heavy bytecode operations, which it
    wants to run concurrently
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当程序依赖于一些重型字节码操作，希望并发运行时
- en: When the program uses multithreading to utilize the full power of multiple CPU
    cores on a single machine
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当程序使用多线程在单台机器上充分利用多个CPU核心的全部性能
- en: I/O calls and long-running operations typically occur outside the GIL. So multithreading
    is efficient in Python only when it involves some amount of I/O or such operations-
    such as image processing.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: I/O调用和长时间运行的操作通常发生在GIL之外。因此，在Python中，多线程只有在涉及一定量的I/O或类似操作（如图像处理）时才有效。
- en: In such cases, scaling your program to concurrently scale beyond a single process
    becomes a handy approach. Python makes this possible via its `multiprocessing`
    module, which is our next topic of discussion.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，将程序扩展到超出单个进程的并发扩展是一个方便的方法。Python通过其`multiprocessing`模块实现了这一点，这是我们下一个讨论的主题。
- en: Concurrency in Python – multiprocessing
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python中的并发性 - 多进程
- en: The Python standard library provides a multiprocessing module, which allows
    a programmer to write programs that scale concurrently using multiple processes
    instead of threads.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: Python标准库提供了一个多进程模块，允许程序员编写使用多个进程而不是线程并发扩展的程序。
- en: Since multi-processing scales computation across multiple processes, it effectively
    removes any issues with the GIL in Python. Programs can make use of multiple CPU
    cores efficiently using this module.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 由于多进程可以跨多个进程扩展计算，它有效地消除了Python中的GIL问题。程序可以有效地利用多个CPU核心使用这个模块。
- en: The main class exposed by this module is the `Process` class, the analog to
    the `Thread` class in the threading module. It also provides a number of synchronization
    primitives, which are almost exact counterparts of their cousins in the threading
    module.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 此模块公开的主要类是`Process`类，它是线程模块中`Thread`类的类似物。它还提供了一些同步原语，几乎与线程模块中的同类相对应。
- en: We will get started by using an example using the `Pool` object provided by
    this module. It allows a function to execute in parallel over multiple inputs
    using processes.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过使用此模块提供的`Pool`对象来开始一个示例。它允许一个函数在多个输入上并行执行进程。
- en: A primality checker
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个素数检查器
- en: 'The following function is a simple checker function for primality, that is,
    whether the input number is prime or not:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数是一个简单的素数检查函数，即输入的数字是否为素数：
- en: '[PRE20]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following is a threaded class that uses this last function to check numbers
    from a queue for primality:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个使用上述函数从队列中检查素数的线程类：
- en: '[PRE21]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We will test it with 1,000 large prime numbers. In order to save space for
    the list represented here, what we''ve done is to take 10 of these numbers and
    multiply the list with 100:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用1000个大素数进行测试。为了节省这里表示的列表的空间，我们做的是取其中的10个数字并将列表乘以100：
- en: '[PRE22]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We''ve used four threads for this test. Let''s see how the program performs,
    in the following screenshot:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经为这个测试使用了四个线程。让我们看看程序的表现，如下截图所示：
- en: '![A primality checker](../Images/image00443.jpeg)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![一个素数检查器](../Images/image00443.jpeg)'
- en: Primality checker of 1,000 numbers using a pool of 4 threads
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 使用4个线程的1000个数字的素数检查器
- en: 'Now, here is the equivalent code using the multiprocessing `Pool` object:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这是使用多进程`Pool`对象的等效代码：
- en: '[PRE23]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following screenshot shows its performance over the same set of numbers:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示了它在相同一组数字上的表现：
- en: '![A primality checker](../Images/image00444.jpeg)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![一个素数检查器](../Images/image00444.jpeg)'
- en: Primality checker of 1,000 numbers using a multiprocessing Pool of 4 processes
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 使用4个进程的多进程池的1000个数字的素数检查器
- en: 'We learn the following by comparing these numbers:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 通过比较这些数字，我们得出以下结论：
- en: The real time, that is, the wall clock time spent by the process pool version
    at 1 minute 9.6 seconds (69.6 seconds) is nearly 50% lesser than that of the thread
    pool version at 2 minute 12 seconds (132 seconds).
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进程池版本的实际时间，即1分9.6秒（69.6秒）的挂钟时间，几乎比线程池版本的2分12秒（132秒）少了50%。
- en: However, notice that the user time—that is, the time spent inside the CPU for
    user code—for the process pool version at 4 minute 22 seconds (262 seconds ) is
    nearly two times more than that of the thread pool version at 2 minutes 12 seconds
    (132 seconds).
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 但是，请注意，进程池版本的用户时间——即在CPU内部用于用户代码的时间——为4分22秒（262秒），几乎是线程池版本的2分12秒（132秒）的两倍。
- en: The real and user CPU time of the thread pool version is exactly the same at
    2 minutes 12 seconds. This is a clear indication that the threaded version was
    able to execute effectively, only in one of the CPU cores.
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程池版本的真实CPU时间和用户CPU时间完全相同，都是2分12秒。这清楚地表明，线程版本只能在一个CPU核心中有效地执行。
- en: This means that the process pool version was able to better make use of all
    the CPU cores, since for the 50% of the real time of the thread pool version,
    it was able to make use of the CPU time twice over.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着进程池版本能够更好地利用所有的CPU核心，因为对于线程池版本的实际时间的50%，它能够利用CPU时间两倍。
- en: 'Hence, the real performance boost in terms of CPU time/real time for the two
    programs is as follows:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，两个程序在CPU时间/实际时间方面的真正性能提升如下：
- en: Threaded version → 132 seconds/132 seconds = 1
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程版本 → 132秒/132秒 = 1
- en: Process version → 262 seconds/69.6 seconds = 3.76 ~= 4
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进程版本 → 262秒/69.6秒 = 3.76约等于4
- en: 'The real performance ratio of the process version to the threaded version is,
    hence, given as follows:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，进程版本相对于线程版本的真实性能比率如下：
- en: 4/1 = 4
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 4/1 = 4
- en: The machine on which the program was executed has a four-core CPU. This clearly
    shows that the multiprocess version of the code was able to utilize all the four
    cores of the CPU nearly equally.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 程序执行的机器具有四核CPU。这清楚地表明，代码的多进程版本能够几乎平均利用CPU的所有四个核心。
- en: This is because the threaded version is being restricted by the GIL, whereas
    the process version has no such restriction and can freely make use of all the
    cores.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为线程版本受到了GIL的限制，而进程版本没有这样的限制，可以自由地利用所有的核心。
- en: In the next section, let us get on to a more involved problem—that of sorting
    disk-based files.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们来解决一个更复杂的问题——对基于磁盘的文件进行排序。
- en: Sorting disk files
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排序磁盘文件
- en: Imagine you have hundreds of thousands of files on the disk, each containing
    a certain fixed number of integers in a given range. Let's say we need the files
    to be sorted and merged into a single file.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你在磁盘上有数十万个文件，每个文件包含一定数量的整数，范围在给定范围内。假设我们需要对这些文件进行排序并合并成一个单一的文件。
- en: If we decide to load all this data into memory, it will need large amounts of
    RAM. Let's do a quick calculation for a million files, each containing around
    100 integers in the range of 1 to 10,000 for a total of 1,00,000,000 or 100 million
    integers.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们决定将所有这些数据加载到内存中，将需要大量的RAM。让我们快速计算一下，对于一百万个文件，每个文件包含大约100个整数，范围在1到10,000之间，总共1亿个整数。
- en: Let's assume each of the files is loaded as a list of integers from the disk—we
    will ignore string processing, and the like for the time being.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 假设每个文件都作为一个整数列表从磁盘加载——我们暂时忽略字符串处理等。
- en: 'Using `sys.getsizeof`, we can get a rough calculation going:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`sys.getsizeof`，我们可以进行一个粗略的计算：
- en: '[PRE24]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: So, the entire data will take close to 800 MB if loaded into memory at once.
    Now this may not look like a large memory footprint at first, but the larger the
    list, the more system resources it takes to sort it in memory as one large list.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果一次性加载到内存中，整个数据将占用接近800MB。现在乍一看，这可能并不像是一个很大的内存占用，但是列表越大，将其作为一个大列表在内存中排序所需的系统资源就越多。
- en: 'Here is the simplest code for sorting of all the integers present in the disk
    files after loading them into memory:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 这是将所有加载到内存中的磁盘文件中的所有整数进行排序的最简单的代码：
- en: '[PRE25]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This preceding code loads a certain number of files from the disk, each containing
    100 integers in the range 1 to 10,000\. It reads each file, maps it to a list
    of integers, and adds each list to a cumulative list. Finally, the list is sorted
    and written to a file.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码从磁盘加载了一定数量的文件，每个文件包含1到10,000范围内的100个整数。它读取每个文件，将其映射到一个整数列表，并将每个列表添加到一个累积列表中。最后，对列表进行排序并写入文件。
- en: 'The following table shows the time taken to sort a certain number of disk files:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了对一定数量的磁盘文件进行排序所需的时间：
- en: '| Number of files (n) | Time taken for sorting |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 文件数量（n）| 排序所需时间 |'
- en: '| --- | --- |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1000 | 17.4 seconds |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 1000 | 17.4秒 |'
- en: '| 10000 | 101 seconds |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 10000 | 101秒 |'
- en: '| 100000 | 138 seconds |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 100000 | 138秒 |'
- en: '| 1000000 | NA |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 1000000 | 不适用 |'
- en: As you can see, the time taken scales pretty reasonably—less than *O(n)*. However,
    this is one problem where more than the time, it is the space—in terms of memory
    and operations on it—that matters.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，所花费的时间相当合理 - 小于*O(n)*。但是，这是一个更多关于空间 - 即内存及其上的操作 - 而不是时间的问题。
- en: For example, in the machine that was used to conduct the test, an 8-GB RAM,
    4-core CPU laptop with 64-bit Linux, the test with a million numbers didn't finish.
    Instead, it caused the system to hang, so it was not completed.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在用于进行测试的机器上，一台配备8GB RAM、4核CPU和64位Linux的笔记本电脑上，百万个数字的测试没有完成。相反，它导致系统挂起，因此未完成。
- en: Sorting disk files – using a counter
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 排序磁盘文件 - 使用计数器
- en: If you look at the data, you find that there is an aspect that allows us to
    treat the problem as more about space than time. This is the observation that
    the integers are in a fixed range with a maximum limit of 10,000.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看数据，会发现有一个方面使我们可以将问题视为更多关于空间而不是时间。这是观察到整数处于固定范围内，最大限制为10,000。
- en: Hence, instead of loading all the data as separate lists and merging them, one
    can use a data structure like a counter.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可以使用计数器之类的数据结构，而不是将所有数据加载为单独的列表并将它们合并。
- en: 'Here is the basic idea of how this works:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的基本工作原理：
- en: Initialize a data structure—a counter, where each integer starts from 1… 10,000
    the maximum entry is initialized to zero.
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个数据结构 - 一个计数器，其中每个整数从1… 10,000开始，最大条目初始化为零。
- en: Load each file and convert the data to a list. For any number found in the list,
    increment its count in the counter data structure initialized in Step 1.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载每个文件并将数据转换为列表。对于列表中找到的任何数字，在第1步初始化的计数器数据结构中递增其计数。
- en: 'Finally, loop through the counter, and output each number with a count greater
    than zero *so many times*, and save the output to a file. The output is your merged
    and sorted single file:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，循环遍历计数器，并输出每个计数大于零的数字*如此多次*，并将输出保存到文件中。输出即为合并和排序后的单个文件：
- en: '[PRE26]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In the preceding code, we use a `defaultdict` from the collections module as
    the counter. Whenever we encounter an integer, we increment its count. In the
    end, the counter is looped through, and each item is output as many times as it
    was found.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，我们使用了来自collections模块的`defaultdict`作为计数器。每当遇到一个整数，我们就会递增其计数。最后，循环遍历计数器，并将每个项目输出多次，就像它被找到的次数一样。
- en: The sort and merge happen due to the way we have converted the problem from
    one of sorting integers to one of keeping a count and outputting in a naturally
    sorted order.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 排序和合并是由于我们将问题从整数排序问题转换为计数并以自然排序顺序输出的方式而发生的。
- en: 'The following table summarizes the time taken for sorting of numbers against
    the size of the input – in terms of number of disk files:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表总结了排序数字所需的时间，以及输入大小（以磁盘文件数量表示）：
- en: '| Number of files (n) | Time taken for sorting |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: 文件数量（n）| 排序所需时间
- en: '| --- | --- |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1000 | 16.5 seconds |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 1000 | 16.5秒 |'
- en: '| 10000 | 83 seconds |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 10000 | 83秒 |'
- en: '| 100000 | 86 seconds |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 100000 | 86秒 |'
- en: '| 1000000 | 359 seconds |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 1000000 | 359秒 |'
- en: Though the performance for the smallest case – that of 1,000 files is similar
    to that for the in-memory sort, the performance becomes better as the size of
    the input increases. This code also manages to finish the sorting of a million
    files or 100 million integers - in about 5m 59s.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最小情况下的性能 - 即1,000个文件的情况与内存排序相似，但随着输入大小的增加，性能会变得更好。该代码还能够在大约5分59秒内完成对100万个文件或1亿个整数的排序。
- en: Note
  id: totrans-374
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'In timing measurements for processes that read files, there is always the effect
    of buffer caches in the kernel. You will find that running the same performance
    test successively shows a tremendous improvement, as Linux caches the contents
    of the files in its buffer cache. Hence, subsequent tests for the same input size
    should be done after clearing the buffer cache. In Linux, this can be done by
    the following command:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在对读取文件的进程进行时间测量时，总会受到内核缓冲区缓存的影响。您会发现，连续运行相同的性能测试会显示巨大的改进，因为Linux会将文件的内容缓存在其缓冲区缓存中。因此，应在清除缓冲区缓存后进行相同输入大小的后续测试。在Linux中，可以通过以下命令完成：
- en: '[PRE27]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In our tests for successive numbers, we *don't* reset the buffer caches as shown
    before. This means that runs for higher numbers enjoy a performance boost from
    the caches created during the previous runs. However, since this is done uniformly
    for each test, the results are comparable. The cache is reset before starting
    the test suite for a specific algorithm.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对连续数字的测试中，*不*像之前所示那样重置缓冲区缓存。这意味着对于更高的数字，可以从先前运行期间创建的缓存中获得性能提升。但是，由于这对每个测试都是统一进行的，因此结果是可比较的。在针对特定算法的测试套件开始之前，会重置缓存。
- en: This algorithm also requires much lesser memory, since for each run, the memory
    requirements are *the same* since we are using an array of integers upto MAXINT
    and just incrementing the count.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每次运行的内存需求都是*相同*的，因此这种算法还需要更少的内存，因为我们使用的是一个整数数组，最多到MAXINT，并且只是递增计数。
- en: Here is the memory usage of the sort in-memory program for 100,000 files using
    the *memory_profiler*, which we have encountered in the previous chapter.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用*memory_profiler*对100,000个文件的内存排序程序的内存使用情况，我们在上一章中已经遇到过。
- en: '![Sorting disk files – using a counter](../Images/image00445.jpeg)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![使用计数器对磁盘文件进行排序](../Images/image00445.jpeg)'
- en: Memory usage of in-memory sort program for an input of 100,000 files
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 100,000个文件输入的内存排序程序的内存使用情况
- en: 'And the following screenshot shows the memory usage for the sort counter for
    the same number of files:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了相同数量文件的计数器排序的内存使用情况：
- en: '![Sorting disk files – using a counter](../Images/image00446.jpeg)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![使用计数器对磁盘文件进行排序](../Images/image00446.jpeg)'
- en: Memory usage of counter sort program for an input of 100,000 files
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 100,000个文件输入的计数器排序程序的内存使用情况
- en: The memory usage of the in-memory sort program at 465 MB is more than six times
    that of the counter sort program at 70 MB. Also note that the sorting operation
    itself takes extra memory of nearly 10 MB in the in-memory version.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 内存使用率在内存排序程序中为465MB，比70MB的计数排序程序高出六倍多。还要注意，在内存版本中，排序操作本身需要额外的近10MB内存。
- en: Sorting disk files – using multiprocessing
  id: totrans-386
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用多进程对磁盘文件进行排序
- en: In this section, we rewrite the counter sorting program using multiple processes.
    The approach is to scale the processing input files for more than one process
    by splitting the list of file paths to a pool of processes – and planning to take
    advantage of the resulting data parallelism.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们使用多个进程重写计数排序程序。方法是通过将文件路径列表拆分为进程池，以便为多个进程扩展处理输入文件，并计划利用由此产生的数据并行性。
- en: 'Here is the rewrite of the code:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是代码的重写：
- en: '[PRE28]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'It is exactly the same code as earlier with the following changes:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这与之前的代码完全相同，只有以下更改：
- en: Instead of processing all the files as a single list, the filenames are put
    in batches, with batches equaling the size of the pool.
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文件名分批处理，每批大小等于池的大小，而不是将所有文件作为单个列表处理。
- en: We use a sorter function, which accepts the list of filenames, processes them,
    and returns a dictionary with the counts.
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用一个排序函数，该函数接受文件名列表，处理它们，并返回一个包含计数的字典。
- en: The counts are summed for each integer in the range from 1 to MAXINT, and so
    many numbers are written to the sorted file.
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于1到MAXINT范围内的每个整数，计数都被求和，因此许多数字被写入排序文件。
- en: 'The following table shows the data for processing a different number of files
    for a pool sizes of 2 and 4 respectively:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了不同文件数量的处理数据，分别为池大小为2和4：
- en: '| Number of files (n) | Pool size | Time taken for sorting |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| 文件数量（n）| 池大小 | 排序所需时间 |'
- en: '| --- | --- | --- |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1,000 | 2 | 18 seconds |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 1,000 | 2 | 18秒 |'
- en: '| 4 | 20 seconds |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 20秒 |'
- en: '| 10,000 | 2 | 92 seconds |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 10,000 | 2 | 92秒 |'
- en: '| 4 | 77 seconds |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 77秒 |'
- en: '| 100,000 | 2 | 96 seconds |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 100,000 | 2 | 96秒 |'
- en: '| 4 | 86 seconds |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 86秒 |'
- en: '| 1,000,000 | 2 | 350 seconds |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 1,000,000 | 2 | 350秒 |'
- en: '| 4 | 329 seconds |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 329秒 |'
- en: 'The numbers tell an interesting story:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数字讲述了一个有趣的故事：
- en: The multiple process version one with 4 processes (equal to number of cores
    in the machine) has better numbers overall when compared to the one with 2 processes
    and the single process one.
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 具有4个进程的多进程版本整体上比具有2个进程和单进程的版本效果更好。
- en: However, the multiple-process version doesn't seem to offer much of a performance
    benefit when compared to the single-process version. The performance numbers are
    very similar and any improvement is within bounds of error and variation. For
    example, for 1 million number input the multiple process with 4 processes has
    just a 8% improvement over the single-process one.
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然而，与单进程版本相比，多进程版本似乎并没有提供太多性能优势。性能数字非常相似，任何改进都在误差和变化范围内。例如，对于100万个数字输入，具有4个进程的多进程版本仅比单进程版本提高了8%。
- en: This is because the bottleneck here is the processing time it takes to load
    the files into memory – in file I/O - not the computation (sorting), as the sorting
    is just an increment in the counter. Hence the single process version is pretty
    efficient as it is able to load all the file data in the same address space. The
    multiple-process ones are able to improve this a bit by loading the files in multiple
    address spaces, but not by a lot.
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是因为瓶颈在于加载文件到内存所需的处理时间，而不是计算（排序）的时间，因为排序只是计数的增量。因此，单进程版本非常高效，因为它能够将所有文件数据加载到相同的地址空间。多进程版本能够通过在多个地址空间中加载文件来稍微改善这一点，但改善并不多。
- en: This example shows that in situations where there is not much computation done
    but the bottleneck is disk or file I/O, the impact of scaling by multi-processing
    is much lesser.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子表明，在没有太多计算但瓶颈是磁盘或文件I/O的情况下，通过多进程进行扩展的影响要小得多。
- en: Multithreading versus multiprocessing
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程与多进程
- en: Now that we have come to the end of our discussion on multi-processing, it is
    a good time to compare and contrast the scenarios where one needs to choose between
    scaling using threads in a single process or using multiple processes in Python.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们讨论多进程的内容结束了，现在是比较和对比在Python中选择使用单进程中的线程扩展还是使用多个进程的情况的好时机。
- en: Here are some guidelines.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些指导方针。
- en: 'Use multithreading in the following cases:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下情况下使用多线程：
- en: The program needs to maintain a lot of shared states, especially mutable ones.
    A lot of the standard data structures in Python, such as lists, dictionaries,
    and others, are thread-safe, so it costs much less to maintain a mutable shared
    state using threads than via processes.
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序需要维护大量共享状态，特别是可变状态。Python中的许多标准数据结构，如列表、字典等，都是线程安全的，因此使用线程维护可变共享状态的成本要低得多，而不是通过进程。
- en: The program needs to keep a low memory foot-print.
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序需要保持低内存占用。
- en: The program spends a lot of time doing I/O. Since the GIL is released by threads
    doing I/O, it doesn't affect the time taken by the threads to perform I/O.
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序花费大量时间进行I/O。由于线程执行I/O时GIL被释放，因此它不会影响线程执行I/O所需的时间。
- en: The program doesn't have a lot of data parallel operations which it can scale
    across multiple processes
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序没有太多可以跨多个进程扩展的数据并行操作
- en: 'Use multiprocessing in these scenarios:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下使用多进程：
- en: 'The program performs a lot of CPU-bound heavy computing: byte-code operations,
    number crunching, and the like on reasonably large inputs.'
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序执行大量的CPU密集型计算：字节码操作、数值计算等，处理相当大的输入。
- en: The program has inputs which can be parallelized into chunks and whose results
    can be combined afterwards – in other words, the input of the program yields well
    to data-parallel computations.
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序有输入，可以并行化成块，然后在之后合并结果——换句话说，程序的输入很适合数据并行计算。
- en: The program doesn't have any limitations on memory usage, and you are on a modern
    machine with a multicore CPU and large enough RAM.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序对内存使用没有限制，并且您使用的是具有多核CPU和足够大内存的现代计算机。
- en: There is not much shared mutable state between processes that need to be synchronized—this
    can slow down the system, and offset any benefits gained from multiple processes.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在需要同步的进程之间没有太多共享的可变状态-这可能会减慢系统的速度，并抵消多进程带来的任何好处。
- en: Your program is not heavily dependent on I/O—file or disk I/O or socket I/O.
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的程序不太依赖I/O-文件或磁盘I/O或套接字I/O。
- en: Concurrecy in Python - Asynchronous Execution
  id: totrans-424
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python中的并发-异步执行
- en: We have seen two different ways to perform concurrent execution using multiple
    threads and multiple processes. We saw different examples of using threads and
    their synchronization primitives. We also saw a couple of examples using multi-processing
    with slightly varied outcomes.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了使用多个线程和多个进程进行并发执行的两种不同方式。我们看到了使用线程及其同步原语的不同示例。我们还看到了使用多进程的几个示例，结果略有不同。
- en: Apart from these two ways to do concurrent programming, another common technique
    is that of asynchronous programming or asynchronous I/O.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这两种并发编程的方式，另一种常见的技术是异步编程或异步I/O。
- en: In an asynchronous model of execution, tasks are picked to be executed from
    a queue of tasks by a scheduler, which executes these tasks in an interleaved
    manner. There is no guarantee that the tasks will be executed in any specific
    order. The order of execution of tasks depend upon how much processing time a
    task is willing to *yield* to another task in the queue. Put in other words, asynchronous
    execution happens through co-operative multitasking.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行的异步模型中，调度程序从任务队列中选择要执行的任务，并以交错的方式执行这些任务。不能保证任务将按任何特定顺序执行。任务的执行顺序取决于任务愿意向队列中的另一个任务*yield*多少处理时间。换句话说，异步执行是通过合作式多任务处理来实现的。
- en: Asynchronous execution usually happens in a single thread. This means no true
    data parallelism or true parallel execution can happen. Instead, the model only
    provides a semblance of parallelism.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 异步执行通常发生在单个线程中。这意味着没有真正的数据并行性或真正的并行执行。相反，该模型只提供了一种类似并行的外观。
- en: As execution happens out of order, asynchronous systems need a way to return
    the results of function execution to the callers. This usually happens with *callbacks*,
    which are functions to be called when the results are ready or using special objects
    that receive the results, often called *futures*.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 由于执行是无序的，异步系统需要一种方法将函数执行的结果返回给调用者。这通常通过*回调*来实现，这些是在结果准备好时要调用的函数，或者使用接收结果的特殊对象，通常称为*future*。
- en: Python 3 provides support for this kind of execution via its *asyncio* module
    using coroutines. Before we go on to discuss this, we will spend some time understanding
    pre-emptive multitasking versus cooperative multitasking, and how we can implement
    a simple cooperative multitasking scheduler in Python using generators.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3通过其*asyncio*模块使用协程提供了对这种执行的支持。在讨论这个之前，我们将花一些时间了解抢占式多任务处理与合作式多任务处理，以及如何使用生成器在Python中实现一个简单的合作式多任务处理调度程序。
- en: Pre-emptive versus cooperative multitasking
  id: totrans-431
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抢占式与合作式多任务处理
- en: The programs we wrote earlier using multiple threads were examples of concurrency.
    However, we didn't have to worry about how and when the operating system chose
    to run the thread—we just had to prepare the threads (or processes), provide the
    target function, and execute them. The scheduling is taken care of by the operating
    system.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前使用多个线程编写的程序是并发的示例。然而，我们不必担心操作系统选择何时以及如何运行线程，我们只需要准备好线程（或进程），提供目标函数，并执行它们。调度由操作系统处理。
- en: Every few ticks of the CPU clock, the operating system pre-empts a running thread,
    and replaces it with another one in a particular core. This can happen due to
    different reasons, but the programmer doesn't have to worry about the details.
    He just creates the threads, sets them up with the data they need to process,
    uses the correct synchronization primitives, and starts them. The operating system
    does the rest including switching and scheduling.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: CPU时钟的每几个滴答声，操作系统会抢占一个正在运行的线程，并在特定的核心中用另一个线程替换它。这可能是由于不同的原因，但程序员不必担心细节。他只需创建线程，为它们设置它们需要处理的数据，使用正确的同步原语，并启动它们。操作系统会处理剩下的工作，包括切换和调度。
- en: This is how almost all modern operating systems work. It guarantees each thread
    a fair share of the execution time, all other things being equal. This is known
    as **pre-emptive multitasking**.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 这几乎是所有现代操作系统的工作方式。在所有其他条件相等的情况下，它保证每个线程公平分享执行时间。这被称为**抢占式多任务处理**。
- en: There is another type of scheduling which is the opposite of pre-emptive multitasking.
    This is called as co-operative multitasking, where the operating system plays
    no role in deciding the priority and execution of competing threads or processes.
    Instead, a process or thread willingly yields control for another process or thread
    to run. Or a thread can replace another thread which is idling (sleeping) or waiting
    for I/O.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种调度类型，与抢占式多任务处理相反。这被称为合作式多任务处理，操作系统不参与决定竞争线程或进程的优先级和执行。相反，一个进程或线程自愿放弃控制权，让另一个进程或线程运行。或者一个线程可以取代另一个正在空闲（睡眠）或等待I/O的线程。
- en: This is the technique used in the asynchronous model of concurrent execution
    using co-routines. A function, while waiting for data, say a call on the network
    that is yet to return, can yield control for another function or task to run.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用协程进行并发执行的异步模型中使用的技术。一个函数在等待数据时，比如等待尚未返回的网络调用，可以将控制权让给另一个函数或任务运行。
- en: Before we go to discuss actual co-routines using `asyncio` let us write our
    own co-operative multitasking scheduler using simple Python generators. It is
    not very difficult to do this as you can see below.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论使用`asyncio`的实际协程之前，让我们使用简单的Python生成器编写我们自己的协作式多任务调度器。如下所示，这并不是很难做到。
- en: '[PRE29]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Let''s analyze the preceding code:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析前面的代码：
- en: We have four functions—three generators, since they use the `yield` keyword
    to return the data, and a scheduler, which runs a certain set of tasks
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有四个函数 - 三个生成器，因为它们使用`yield`关键字返回数据，以及一个调度器，它运行一定的任务
- en: The `square_mapper` function accepts an iterator, which returns integers iterating
    through it, and yields the squares of the members
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`square_mapper`函数接受一个迭代器，返回整数并通过它进行迭代，并产生成员的平方'
- en: The `prime_filter` function accepts a similar iterator, and filters out numbers
    that are not prime, yielding only prime numbers
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prime_filter`函数接受一个类似的迭代器，并过滤掉非质数，只产生质数'
- en: The `number_generator` function acts as the input iterator to both these functions,
    providing them with an input stream of integers
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`number_generator`函数作为这两个函数的输入迭代器，为它们提供整数的输入流'
- en: Let us now look at the calling code which ties all the four functions together.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看将所有四个函数联系在一起的调用代码。
- en: '[PRE30]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here is an analysis of the calling code:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是调用代码的分析：
- en: The number generator is initialized with a count, which is received via the
    command-line argument. It is passed to the `square_mapper` function. The combined
    function is added as a task to the `tasks` list.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字生成器初始化为一个计数，通过命令行参数接收。它传递给`square_mapper`函数。组合函数被添加为`tasks`列表的一个任务。
- en: A similar operation is performed for the `prime_filter` function.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`prime_filter`函数也执行类似的操作。
- en: The `scheduler` method is run by passing the task list to it, which it runs
    by iterating through a `for` loop, running each task one after another. The results
    are appended to a dictionary using the function's name as the key, and returned
    at the end of execution.
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将任务列表传递给`scheduler`方法来运行它，它通过`for`循环迭代运行每个任务，一个接一个地运行。结果被附加到一个字典中，使用函数的名称作为键，并在执行结束时返回。
- en: We print the last prime number's value to verify correct execution, and also
    the time taken for the scheduler to process.
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们打印最后一个质数的值来验证正确执行，还有调度器处理所花费的时间。
- en: 'Let''s see the output of our simple cooperative multitasking scheduler for
    a limit of `10`. This allows to capture all the input in a single command window,
    as seen in the following screenshot:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的简单协作式多任务调度器在限制为`10`时的输出。这允许在单个命令窗口中捕获所有输入，如下面的屏幕截图所示：
- en: '![Pre-emptive versus cooperative multitasking](../Images/image00447.jpeg)'
  id: totrans-452
  prefs: []
  type: TYPE_IMG
  zh: '![抢占式与协作式多任务](../Images/image00447.jpeg)'
- en: Output of the simple co-operative multitasking program example for an input
    of 10
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输入为10的简单协作式多任务程序示例的输出
- en: 'Let''s analyze the output:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析输出：
- en: The output of the `square_mapper` and `prime_filter` functions alternates on
    the console. This is because the scheduler switches between them in the `for`
    loop. Each of the functions are co-routines (generators) so they *yield* execution
    – that is the control is passed from one function to the next – and vice-versa.
    This allows both functions to run concurrently, while maintaining state and producing
    output.
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`square_mapper`和`prime_filter`函数的输出在控制台上交替显示。这是因为调度器在`for`循环中在它们之间切换。每个函数都是协程（生成器），因此它们*yield*执行
    - 即控制从一个函数传递到下一个函数 - 反之亦然。这允许两个函数同时运行，同时保持状态并产生输出。'
- en: Since we used generators here, they provide a natural way of generating the
    result plus yielding control in one go, using the *yield* keyword.
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们在这里使用了生成器，它们提供了一种自然的方式来生成结果并一次性地让出控制，使用`yield`关键字。
- en: The asyncio module in Python
  id: totrans-457
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python中的asyncio模块
- en: The `asyncio` module in Python provides support for writing concurrent, single-threaded
    programs using co-routines. It is available only in Python 3.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的`asyncio`模块支持使用协程编写并发的单线程程序。它仅在Python 3中可用。
- en: 'A co-routine using the `asyncio` module is one that uses either of the following
    approaches:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`asyncio`模块的协程是使用以下方法之一的协程：
- en: Using the `async def` statement for defining functions
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`async def`语句来定义函数
- en: Being decorated using the `@asyncio.coroutine` expression
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`@asyncio.coroutine`表达式进行装饰
- en: Generator-based co-routines use the second technique, and they yield from expressions.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 基于生成器的协程使用第二种技术，并从表达式中产生。
- en: Co-routines created using the first technique typically use the `await <future>`
    expression to wait for the future to be completed.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 使用第一种技术创建的协程通常使用`await <future>`表达式等待未来完成。
- en: Co-routines are scheduled for execution using an `event` loop, which connects
    the objects and schedules them as tasks. Different types of event loop are provided
    for different operating systems.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 协程通过`事件`循环进行调度执行，它连接对象并将它们安排为任务。为不同的操作系统提供了不同类型的事件循环。
- en: 'The following code rewrites our earlier example of a simple cooperative multitasking
    scheduler to use the `asyncio` module:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码重新编写了我们之前的一个简单协作式多任务调度器的示例，使用了`asyncio`模块：
- en: '[PRE31]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here is how this last code works:'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最后一段代码的工作原理：
- en: The `number_generator` function is a co-routine that yields from the sub-generator
    `range(m, n+1)`, which is an iterator. This allows this co-routine to be called
    in other co-routines.
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`number_generator`函数是一个协程，从子生成器`range(m, n+1)`中产生，它是一个迭代器。这允许其他协程调用这个协程。'
- en: The `square_mapper` function is a co-routine of the first type using the `async
    def` keyword. It returns a list of squares using numbers from the number generator.
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`square_mapper`函数是使用`async def`关键字的第一种类型的协程。它使用数字生成器返回一个平方数列表。'
- en: The `prime_filter` function is of the same type. It also uses the number generator,
    and appends prime numbers to a list and returns it.
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`prime_filter`函数也是相同类型的函数。它也使用数字生成器，将质数附加到列表并返回。'
- en: Both co-routines yield to the other by sleeping using the *asyncio.sleep* function
    and waiting on it. This allows both co-routines to work concurrently in an interleaved
    fashion.
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个协程通过使用*asyncio.sleep*函数进入睡眠并等待。这允许两个协程以交错的方式同时工作。
- en: 'Here is the calling code with the `event` loop and the rest of the plumbing:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是带有`event`循环和其余管道的调用代码：
- en: '[PRE32]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Here is the output of the program. Observe how the results of each of the task
    is getting printed in an interleaved fashion.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 这是程序的输出。请注意每个任务的结果是如何以交错的方式打印出来的。
- en: '![The asyncio module in Python](../Images/image00448.jpeg)'
  id: totrans-475
  prefs: []
  type: TYPE_IMG
  zh: '![Python中的asyncio模块](../Images/image00448.jpeg)'
- en: Result of executing the asyncio task calculating prime numbers and squares
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 执行计算素数和平方的asyncio任务的结果
- en: 'Let us analyze how the preceding code worked line by line, while following
    a top-to-bottom approach:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐行分析前面的代码是如何工作的，按照自上而下的方式：
- en: We first get an asyncio event `loop` using the `factory` function `asyncio.get_event_loop`.
    This returns the default event loop implementation for the operating system.
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先使用`factory`函数`asyncio.get_event_loop`获取一个asyncio事件`loop`。这会返回操作系统的默认事件循环实现。
- en: We set up an asyncio `future` object by using the `gather` method of the module.
    This method is used to aggregate results from a set of co-routines or futures
    passed as its argument. We pass both the `prime_filter` and the `square_mapper`
    to it.
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过使用模块的`gather`方法设置了一个asyncio `future`对象。这个方法用于聚合作为其参数传递的一组协程或futures的结果。我们将`prime_filter`和`square_mapper`都传递给它。
- en: A callback is added to the `future` object—the `print_result` function. It will
    be automatically called once the future's execution is completed.
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个回调被添加到`future`对象 - `print_result`函数。一旦future的执行完成，它将自动被调用。
- en: The loop is run until the future's execution is completed. At this point the
    callback is called and it prints the result. Note how the output appears interleaved
    – as each task yields to the other one using the *sleep* function of the asyncio
    module.
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环运行直到future的执行完成。在这一点上，回调被调用并打印结果。请注意输出是交错的 - 每个任务使用asyncio模块的*sleep*函数让步给另一个任务。
- en: The loop is closed and terminates is operation.
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环被关闭并终止其操作。
- en: Waiting for a future – async and await
  id: totrans-483
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 等待future - async和await
- en: We discussed how one could wait for data from a future inside a co-routine using
    await. We saw an example that uses await to yield control to other co-routines.
    Let's now look at an example that waits for I/O completion on a future, which
    returns data from the web.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了如何在协程内部使用await等待来自future的数据。我们看到了一个使用await让控制权让给其他协程的示例。现在让我们看一个等待来自网络的future的I/O完成的示例。
- en: For this example, you need the `aiohttp` module which provides an HTTP client
    and server to work with the asyncio module and supports futures. We also need
    the `async_timeout` module which allows timeouts on asynchronous co-routines.
    Both these modules can be installed using pip.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，您需要`aiohttp`模块，它提供了一个HTTP客户端和服务器，可以与asyncio模块一起使用，并支持futures。我们还需要`async_timeout`模块，它允许在异步协程上设置超时。这两个模块都可以使用pip安装。
- en: 'Here is the code—this is a co-routine that fetches a URL using a timeout and
    awaits the future, that is, the result of the operation:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码 - 这是一个使用超时获取URL的协程，并等待future的结果的示例：
- en: '[PRE33]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following is the calling code with the event loop:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是带有事件循环的调用代码：
- en: '[PRE34]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: What are we doing in the preceding code?
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中我们在做什么？
- en: We create an event loop and a list of URLs to be fetched. We also create an
    instance of `aiohttp ClientSession` object which is a helper for fetching URLs.
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个事件循环和要获取的URL列表。我们还创建了`aiohttp ClientSession`对象的实例，它是获取URL的辅助程序。
- en: We create a map of tasks by mapping the `fetch_page` function to each of the
    URLs. The session object is passed as first argument to the *fetch_page* function.
  id: totrans-492
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过将`fetch_page`函数映射到每个URL来创建一个任务映射。会话对象作为*fetch_page*函数的第一个参数传递。
- en: The tasks are passed to the wait method of `asyncio` with a timeout of `120`
    seconds.
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任务被传递给`asyncio`的等待方法，并设置了`120`秒的超时时间。
- en: The loop is run until complete. It returns two sets of futures—`done` and `pending`.
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环运行直到完成。它返回两组futures - `done`和`pending`。
- en: We iterate through the future that is done, and print the response by fetching
    it using the `result` method of the `future`.
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们遍历完成的future，并通过使用`future`的`result`方法获取响应并打印它。
- en: 'You can see the result of the operation (first few lines as many lines are
    output) in the following screenshot:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下截图中看到操作的结果（前几行，因为输出了很多行）：
- en: '![Waiting for a future – async and await](../Images/image00449.jpeg)'
  id: totrans-497
  prefs: []
  type: TYPE_IMG
  zh: '![等待future - async和await](../Images/image00449.jpeg)'
- en: Output of program doing an async fetch of URLs for 5 URLs
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 进行5个URL的异步获取程序的输出
- en: As you can see we are able to print the responses in terms of the a simple summary.
    How about processing the response to get more details about it such as the actual
    response text, the content length, status code, and so on?
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们能够以简单的摘要打印响应。那么如何处理响应以获取更多关于它的细节，比如实际的响应文本、内容长度、状态码等呢？
- en: The function below parses a list of *done* futures – waiting for the response
    data via *await* on the *read* method of the response*.* This returns the data
    for each response asynchronously.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的函数解析了一个*done* futures列表 - 通过在响应的*read*方法上使用*await*等待响应数据。这会异步返回每个响应的数据。
- en: '[PRE35]'
  id: totrans-501
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The details of the `response` object—the final URL, status code, and length
    of data—are output by this method for each response before closing the response.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '`response`对象的细节 - 最终的URL、状态码和数据长度 - 在关闭响应之前，通过这个方法输出每个响应。'
- en: We only need to add one more processing step on the list of completed responses
    for this to work.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要在完成的响应列表上再添加一个处理步骤，这样就可以工作。
- en: '[PRE36]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Note how we chain the co-routines together. The final link in the chain is the
    `parse_response` co-routine, which processes the list of done futures before the
    loop ends.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意我们如何将协程链接在一起。链中的最后一个链接是`parse_response`协程，在循环结束之前处理完成的futures列表。
- en: 'The following screenshot shows the output of the program:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了程序的输出：
- en: '![Waiting for a future – async and await](../Images/image00450.jpeg)'
  id: totrans-507
  prefs: []
  type: TYPE_IMG
  zh: '![等待future - async和await](../Images/image00450.jpeg)'
- en: Output of program doing fetching and response processing of 5 URLs asynchronously
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 程序异步获取和处理5个URL的输出
- en: A lot of complex programming can be done using the `asyncio` module. One can
    wait for futures, cancel their execution, and run `asyncio` operations from multiple
    threads. A full discussion is beyond the scope of this chapter.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`asyncio`模块可以完成许多复杂的编程。可以等待futures，取消它们的执行，并从多个线程运行`asyncio`操作。本章讨论的范围之外。
- en: We will move on to another model for executing concurrent tasks in Python, namely
    the `concurrent.futures` module.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续介绍Python中执行并发任务的另一个模块，即`concurrent.futures`模块。
- en: Concurrent futures – high-level concurrent processing
  id: totrans-511
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发futures - 高级并发处理
- en: The `concurrent.futures` module provides high-level concurrent processing using
    either threads or processes, while asynchronously returning data using future
    objects.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: '`concurrent.futures`模块提供了使用线程或进程进行高级并发处理的功能，同时使用future对象异步返回数据。'
- en: 'It provides an executor interface which exposes mainly two methods, which are
    as follows:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了一个执行器接口，主要暴露了两种方法，如下所示：
- en: '`submit`: Submits a callable to be executed asynchronously, returning a `future`
    object representing the execution of the callable.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`submit`：提交一个可调用对象以异步执行，返回代表可调用对象执行的`future`对象。'
- en: '`map`: Maps a callable to a set of iterables, scheduling the execution asynchronously
    in the `future` object. However, this method returns the results of processing
    directly instead of returning a list of futures.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`map`：将可调用对象映射到一组可迭代对象，以`future`对象异步调度执行。但是，该方法直接返回处理结果，而不是返回futures列表。'
- en: 'There are two concrete implementations of the executor interface: `ThreadPoolExecutor`
    executes the callable in a pool of threads, and `ProcessPoolExecutor` does so
    in a pool of processes.'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 执行器接口有两个具体的实现：`ThreadPoolExecutor`在线程池中执行可调用对象，而`ProcessPoolExecutor`在进程池中执行可调用对象。
- en: 'Here is a simple example of a `future` object that calculates the factorial
    of a set of integers asynchronously:'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个异步计算一组整数阶乘的`future`对象的简单示例：
- en: '[PRE37]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The following is a detailed explanation of the preceding code:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面代码的详细解释：
- en: The `factorial` function computes the factorial of a given number iteratively
    by using `functools.reduce` and the multiplication operator
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`factorial`函数通过使用`functools.reduce`和乘法运算符迭代计算给定数字的阶乘。'
- en: We create an executor with two workers, and submit the numbers (from 10 to 20)
    to it via its `submit` method
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们创建了一个具有两个工作线程的执行器，并通过其`submit`方法将数字（从10到20）提交给它。
- en: The submission is done via a dictionary comprehension, returning a dictionary
    with the future as the key and the number as the value
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过字典推导式进行提交，返回一个以future为键、数字为值的字典
- en: We iterate through the completed futures, which have been computed, using the
    `as_completed` method of the `concurrent.futures` module
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过`concurrent.futures`模块的`as_completed`方法迭代已计算完成的futures。
- en: The result is printed by fetching the future's result via the `result` method
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`result`方法获取future的结果并打印结果
- en: 'When executed, the program prints its output, rather in order, as shown in
    the next screenshot:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行时，程序按顺序打印其输出，如下一个截图所示：
- en: '![Concurrent futures – high-level concurrent processing](../Images/image00451.jpeg)'
  id: totrans-526
  prefs: []
  type: TYPE_IMG
  zh: '![并发futures - 高级并发处理](../Images/image00451.jpeg)'
- en: Output of concurrent futures factorial program
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 并发futures阶乘程序的输出
- en: Disk thumbnail generator
  id: totrans-528
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 磁盘缩略图生成器
- en: In our earlier discussion of threads, we used the example of the generation
    of thumbnails for random images from the Web to demonstrate how to work with threads,
    and process information.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前关于线程的讨论中，我们使用了从Web中随机图像生成缩略图的示例，以演示如何使用线程和处理信息。
- en: In this example, we will do something similar. Here, rather than processing
    random image URLs from the Web, we will load images from disk, and convert them
    to thumbnails using the `concurrent.futures` function.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将做类似的事情。在这里，我们不是从Web处理随机图像URL，而是从磁盘加载图像，并使用`concurrent.futures`函数将它们转换为缩略图。
- en: We will reuse our thumbnail creation function from before. On top of that, we
    will add concurrent processing.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重用之前的缩略图创建函数。除此之外，我们将添加并发处理。
- en: 'First, here are the imports:'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这里是导入：
- en: '[PRE38]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Here is our familiar thumbnail creation function:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们熟悉的缩略图创建函数：
- en: '[PRE39]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We will process images from a specific folder—in this case, the `Pictures`
    subdirectory of the `home` folder. To process this, we will need an iterator that
    yields image filenames. We have written one next with the help of the `os.walk`
    function:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将处理特定文件夹中的图像 - 在这种情况下，是`home`文件夹的`Pictures`子目录。为了处理这个，我们需要一个迭代器来产生图像文件名。我们已经使用`os.walk`函数编写了一个。 '
- en: '[PRE40]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: As you can see, the preceding function is a generator.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，前面的函数是一个生成器。
- en: 'Here is the main calling code, which sets up an executor and runs it over the
    folder:'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是主要的调用代码，它设置了一个执行器并在文件夹上运行它：
- en: '[PRE41]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The preceding code uses the same technique of submitting arguments to a function
    asynchronously, saving the resultant futures in a dictionary and then processing
    the result as and when the futures are finished, in a loop.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码使用了相同的技术，异步地向函数提交参数，将结果的futures保存在字典中，然后在futures完成时处理结果。
- en: To change the executor to use processes, one simply needs to replace `ThreadPoolExecutor`
    with `ProcessPoolExecutor`; the rest of the code remains the same. We have provided
    a simple command-line flag, `--process`, to make this easy.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 要将执行器更改为使用进程，只需将`ThreadPoolExecutor`替换为`ProcessPoolExecutor`；代码的其余部分保持不变。我们提供了一个简单的命令行标志`--process`，以便轻松实现这一点。
- en: Here is an output of a sample run of the program using both thread and process
    pools on the `~/Pictures` folder – generating around 2000+ images in roughly the
    same time.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 这是程序在`~/Pictures`文件夹上使用线程池和进程池的样本运行输出-在大约相同的时间内生成了大约2000张图像。
- en: '![Disk thumbnail generator](../Images/image00452.jpeg)'
  id: totrans-544
  prefs: []
  type: TYPE_IMG
  zh: '![磁盘缩略图生成器](../Images/image00452.jpeg)'
- en: Output of concurrent futures disk thumbnail program—using thread and process
    executor
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 并发future磁盘缩略图程序的输出-使用线程和进程执行器
- en: Concurrency options – how to choose?
  id: totrans-546
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发选项-如何选择？
- en: We are at the end of our discussion of concurrency techniques in Python. We
    discussed threads, processes, asynchronous I/O, and concurrent futures. Naturally,
    a question arises—when to pick what?
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了Python中的并发技术。我们讨论了线程、进程、异步I/O和并发future。自然而然地，一个问题出现了-何时选择什么？
- en: This question has been already answered for the choice between threads and processes,
    where the decision is mostly influenced by the GIL.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题已经在选择线程和进程之间得到了解答，决定主要受GIL的影响。
- en: Here are somewhat rough guidelines for picking your concurrency options.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择并发选项时，以下是一些粗略的指南。
- en: '**Concurrent futures vs Multi-processing:** Concurrent futures provide an elegant
    way to parallelize your tasks using either a thread or process pool executor.
    Hence, it is ideal if the underlying application has similar scalability metrics
    with either threads or processes, since it''s very easy to switch from one to
    the other as we''ve seen in a previous example. Concurrent futures can be chosen
    also when the result of the operation needn''t be immediately available. Concurrent
    futures is a good option when the data can be finely parallelized and the operation
    can be executed asynchronously, and when the operations involve simple callables
    without requiring complex synchronization techniques.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并发future vs多处理：**并发future提供了一种优雅的方式，使用线程或进程池执行并行化任务。因此，如果底层应用程序具有与线程或进程类似的可伸缩性指标，那么它是理想的选择，因为从一个到另一个的切换非常容易，就像我们在之前的例子中看到的那样。当操作的结果不需要立即可用时，也可以选择并发future。当数据可以被细粒度地并行化，并且操作可以异步执行时，并且操作涉及简单的可调用而不需要复杂的同步技术时，并发future是一个不错的选择。'
- en: Multi-processing should be chosen if the concurrent execution is more complex,
    and not just based on data parallelism, but has aspects like synchronization,
    shared memory, and so on. For example, if the program requires processes, synchronization
    primitives, and IPC, the only way to truly scale up then is to write a concurrent
    program using the primitives provided by the multiprocessing module.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 如果并发执行更复杂，并不仅仅基于数据并行性，而是涉及同步、共享内存等方面，则应选择多处理。例如，如果程序需要进程、同步原语和IPC，则唯一真正扩展的方法是使用多处理模块提供的原语编写并发程序。
- en: Similarly when your muti-threaded logic involves simple parallelization of data
    across multiple tasks, one can choose concurrent futures with a thread pool. However
    if there is a lot of shared state to be managed with complex thread synchronization
    objects – one has to use thread objects and switch to multiple threads using `threading`
    module to get finer control of the state.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，当您的多线程逻辑涉及跨多个任务并行化数据时，可以选择使用线程池的并发future。但是，如果有大量共享状态需要使用复杂的线程同步对象进行管理，则必须使用线程对象，并使用`threading`模块切换到多个线程以更好地控制状态。
- en: '**Asynchronous I/O vs Threaded concurrency:** When your program doesn''t need
    true concurrency (parallelism), but is dependent more on asynchronous processing
    and callbacks, then `asyncio` is the way to go. Asyncio is a good choice when
    there are lot of waits or sleep cycles involved in the application, such as waiting
    for user input, waiting for I/O, and so on, and one needs to take advantage of
    such wait or sleep times by yielding to other tasks via co-routines. Asyncio is
    not suitable for CPU-heavy concurrent processing, or for tasks involving true
    data parallelism.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异步I/O vs线程并发：**当您的程序不需要真正的并发（并行），而更依赖于异步处理和回调时，`asyncio`是一个不错的选择。当应用程序中涉及大量等待或休眠周期时，例如等待用户输入、等待I/O等，需要通过协程让其他任务利用这些等待或休眠时间时，Asyncio是一个不错的选择。Asyncio不适用于CPU密集型并发处理，或涉及真正数据并行性的任务。'
- en: AsyncIO seems to be suitable for request-response loops- where a lot of I/O
    happens - so its good for writing web application servers which doesn't have real-time
    data requirements.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO似乎适用于请求-响应循环，其中发生大量I/O操作，因此适用于编写不需要实时数据要求的Web应用服务器。
- en: You can use these points just listed as rough guidelines when deciding on the
    correct concurrency package for your applications.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定正确的并发包时，您可以使用上述列出的这些要点作为粗略的指南。
- en: Parallel processing libraries
  id: totrans-556
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行处理库
- en: Apart from the standard library modules that we've discussed so far, Python
    is also rich in its ecosystem of third-party libraries, which support parallel
    processing in a **symmetric multi-processing** (**SMP**) or multi-core systems.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们迄今讨论过的标准库模块外，Python还拥有丰富的第三方库生态系统，支持在对称多处理（SMP）或多核系统中进行并行处理。
- en: We will take a look at a couple of such packages, that are somewhat distinct
    and present some interesting features.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看一下几个这样的包，它们有些不同，并且具有一些有趣的特性。
- en: Joblib
  id: totrans-559
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Joblib
- en: '`joblib` is a package that provides a wrapper over multiprocessing to execute
    code in loops in parallel. The code is written as a generator expression, and
    interpreted to execute in parallel over CPU cores using multi-processing module
    behind the scenes.'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: '`joblib`是一个提供了对多处理的包装器，用于在循环中并行执行代码。代码被编写为生成器表达式，并使用多处理模块在CPU核心上并行执行。'
- en: 'For example, take the following code which calculates square roots for first
    10 numbers:'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，取以下代码，计算前10个数字的平方根：
- en: '[PRE42]'
  id: totrans-562
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'This preceding code can be converted to run on two CPU cores by the following:'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码可以通过以下方式转换为在两个CPU核心上运行：
- en: '[PRE43]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Here is another example: this is our primality checker that we had written
    earlier to run using multiprocessing rewritten to use the `joblib` package:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是另一个例子：这是我们之前编写的用于使用多处理重写为使用`joblib`包的素性检查器：
- en: '[PRE44]'
  id: totrans-566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: If you execute and time the preceding code, you will find the performance metrics
    very similar to that of the version using multi-processing.
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你执行并计时前面的代码，你会发现性能指标与使用多处理版本的性能非常相似。
- en: PyMP
  id: totrans-568
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyMP
- en: '`OpenMP` is an open API, which supports shared memory multi-processing in C/C++
    and Fortran. It uses special work-sharing constructs such as pragmas (special
    instructions to compilers) indicating how to split work among threads or processes.'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: '`OpenMP`是一个开放的API，支持C/C++和Fortran中的共享内存多处理。它使用特殊的工作共享结构，比如指示如何在线程或进程之间分割工作的编译器特殊指令（称为pragma）。'
- en: 'For example, the following C code using the `OpenMP` API indicates that the
    array should be initialized in parallel using multiple threads:'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下C代码使用`OpenMP` API指示应该使用多个线程并行初始化数组：
- en: '[PRE45]'
  id: totrans-571
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '`PyMP` is inspired by the idea behind `OpenMP`, but uses the `fork` system
    call to parallelize code executing in expressions like for loops across processes.
    For this, `PyMP` also provides support for shared data structures like lists and
    dictionaries, and also provides a wrapper for `numpy` arrays.'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '`PyMP`受到`OpenMP`背后的想法的启发，但使用`fork`系统调用来并行化在表达式中执行的代码，比如在循环中。为此，`PyMP`还提供了对共享数据结构（如列表和字典）的支持，并为`numpy`数组提供了一个包装器。'
- en: We will look at an interesting and exotic example—that of fractals—to illustrate
    how `PyMP` can be used to parallelize code and obtain performance improvement.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看一个有趣而奇异的例子——分形图——来说明`PyMP`如何用于并行化代码并获得性能改进。
- en: Note
  id: totrans-574
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'NOTE: The PyPI package for PyMP is named pymp-pypi so make sure you use this
    name when trying to install it via pip. Also note that it doesn''t do a good job
    of pulling its dependencies such as numpy, so these have to be installed separately.'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：PyMP的PyPI软件包名为pymp-pypi，因此在尝试使用pip安装时，请确保使用此名称。还要注意，它在拉取其依赖项（如numpy）方面做得不好，因此这些必须单独安装。
- en: Fractals – the Mandelbrot set
  id: totrans-576
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分形图——Mandelbrot集
- en: 'The following is the code listing of a very popular class of complex numbers,
    which when plotted, produces very interesting fractal geometries: namely, the
    **Mandelbrot set**:'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个非常受欢迎的复数类的代码列表，当绘制时，会产生非常有趣的分形几何图形：即**Mandelbrot集**：
- en: '[PRE46]'
  id: totrans-578
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The preceding code calculates a Mandelbrot set using a certain number of `c`
    and a variable geometry (*width x height*). It is complete with argument parsing
    to produce fractal images of varying geometries, and supports different iterations.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码使用一定数量的`c`和可变的几何形状（*宽x高*）计算了Mandelbrot集。它完整地解析了参数，以产生不同几何形状的分形图像，并支持不同的迭代次数。
- en: Note
  id: totrans-580
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For simplicity's sake, and for producing rather beautiful pics than what Mandelbrot
    usually does, the code takes some liberties, and uses the color scheme of a related
    fractal class, namely, Julia sets.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，以及为了产生比Mandelbrot通常做的更美丽的图片，代码做了一些自由，并使用了一个相关分形类的颜色方案，即Julia集。
- en: How does it work ? Here is an explanation of the code .
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 它是如何工作的？这里是代码的解释。
- en: The `mandelbrot_calc_row` function calculates a row of the Mandelbrot set for
    a certain value of the *y* coordinate for a certain number of maximum iterations.
    The pixel color values for the entire row, from `0` to width `w` for the *x* coordinate,
    is calculated. The pixel values are put into the `Image` object that is passed
    to this function.
  id: totrans-583
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`mandelbrot_calc_row`函数计算了Mandelbrot集的一行，对于特定的*y*坐标值和最大迭代次数。计算了整行的像素颜色值，从*x*坐标的`0`到宽度`w`。像素值被放入传递给这个函数的`Image`对象中。'
- en: The `mandelbrot_calc_set` function calls the `mandelbrot_calc_row` function
    for all values of the *y* coordinate ranging from `0` to the height `h` of the
    image. An `Image` object (via the **Pillow library**) is created for the given
    geometry (*width x height*), and filled with pixel values. Finally, we save this
    image to a file, and we've got our fractal!
  id: totrans-584
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`mandelbrot_calc_set`函数调用`mandelbrot_calc_row`函数，对从`0`到图像高度`h`的*y*坐标的所有值进行计算。为给定的几何形状（*宽x高*）创建了一个`Image`对象（通过**Pillow库**），并填充了像素值。最后，我们将这个图像保存到文件中，我们得到了我们的分形图！'
- en: Without further ado, let us see the code in action.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 不多说了，让我们看看代码的运行情况。
- en: Here is the image that our Mandelbrot program produces for the default number
    of iterations namely 1000.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的Mandelbrot程序为默认迭代次数1000生成的图像。
- en: '![Fractals – the Mandelbrot set](../Images/image00453.jpeg)'
  id: totrans-587
  prefs: []
  type: TYPE_IMG
  zh: '![分形图——Mandelbrot集](../Images/image00453.jpeg)'
- en: Mandelbrot set fractal image for 1000 iterations
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 1000次迭代的Mandelbrot集分形图像
- en: Here is the time it takes to create this image.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 这是创建这个图像所需的时间。
- en: '![Fractals – the Mandelbrot set](../Images/image00454.jpeg)'
  id: totrans-590
  prefs: []
  type: TYPE_IMG
  zh: '![分形图——Mandelbrot集](../Images/image00454.jpeg)'
- en: Timing of single process Mandelbrot program—for 1000 iterations
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 单进程Mandelbrot程序的时间——1000次迭代
- en: 'However if you increase the number of iterations – the single process version
    slows down quite a bit. Here is the output when we increase the number of iterations
    by 10X – for 10000 iterations.:'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果增加迭代次数，单进程版本的速度会慢下来很多。当我们将迭代次数增加10倍时，即10000次迭代时，输出如下：
- en: '![Fractals – the Mandelbrot set](../Images/image00455.jpeg)'
  id: totrans-593
  prefs: []
  type: TYPE_IMG
  zh: '![分形图——Mandelbrot集](../Images/image00455.jpeg)'
- en: Timing of single process Mandelbrot program—for 10,000 iterations
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 单进程Mandelbrot程序的时间——10000次迭代
- en: If we look at the code, we can see that there is an outer for loop in the `mandelbrot_calc_set`
    function, which sets things in motion. It calls `mandelbrot_calc_row` for each
    row of the image ranging from `0` to the height of the function, varied by the
    *y* coordinate.
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看一下代码，我们会发现`mandelbrot_calc_set`函数中有一个外部的for循环，它启动了一切。它为图像的每一行调用`mandelbrot_calc_row`，范围从`0`到函数的高度，由*y*坐标变化。
- en: Since each invocation of the `mandelbrot_calc_row` function calculates one row
    of the image, it naturally fits into a data parallel problem, and can be parallelized
    sufficiently easily.
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每次调用`mandelbrot_calc_row`函数计算图像的一行，它自然适用于数据并行问题，并且可以相当容易地并行化。
- en: In the next section, we will see how to do this using PyMP.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到如何使用PyMP来实现这一点。
- en: Fractals – Scaling the Mandelbrot set implementation
  id: totrans-598
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分形图 - 缩放曼德勃罗集实现
- en: We will use `PyMP` to parallelize the outer for loop across many processes in
    a rewrite of the previous simple implementation of the Mandelbrot set, to take
    advantage of the inherent data parallelism in the solution.
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`PyMP`来并行化前一个简单实现曼德勃罗集的外部for循环，以利用解决方案中固有的数据并行性。
- en: Here is the `PyMP` version of the two functions of the mandelbrot program. The
    rest of the code remains the same.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是曼德勃罗程序的两个函数的`PyMP`版本。其余代码保持不变。
- en: '[PRE47]'
  id: totrans-601
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The rewrite mainly involved converting the code to one that builds the mandelbrot
    image line by line, each line of data being computed separately and in a way that
    it can be computed in parallel – in a separate process.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 重写主要涉及将代码转换为逐行构建曼德勃罗图像的代码，每行数据都是单独计算的，并且以可以并行计算的方式进行计算 - 在一个单独的进程中。
- en: In the single process version, we put the pixel values directly in the image
    in the `mandelbrot_calc_row` function. However, since the new code executes this
    function in parallel processes, we cannot modify the image data in it directly.
    Instead, the new code passes a shared dictionary to the function, and it sets
    the pixel color values in it using the location as `key` and the pixel RGB value
    as `value`.
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在单进程版本中，我们直接在`mandelbrot_calc_row`函数中将像素值放入图像中。然而，由于新代码在并行进程中执行此函数，我们不能直接修改其中的图像数据。相反，新代码将一个共享字典传递给函数，并且它使用位置作为`key`，像素RGB值作为`value`来设置像素颜色值。
- en: A new shared data structure—a shared dictionary—is hence added to the `mandelbrot_calc_set`
    function, which is finally iterated over, and the pixel data, filled, in the `Image`
    object, which is then saved to the final output.
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，在`mandelbrot_calc_set`函数中添加了一个新的共享数据结构 - 共享字典，最终对其进行迭代，并在`Image`对象中填充像素数据，然后保存到最终输出中。
- en: We use four `PyMP` parallel processes, as the machine has four CPU cores, using
    a with context and enclosing the outer for loop inside it. This causes the code
    to execute in parallel in four cores, each core calculating approximately 25%
    of the rows. The final data is written to the image in the main process.
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用了四个`PyMP`并行进程，因为该机器有四个CPU核心，使用了一个上下文和将外部for循环封装在其中。这使得代码在四个核心中并行执行，每个核心计算大约25%的行。最终的数据写入主进程中的图像。
- en: 'Here is the result timing of the `PyMP` version of the code:'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是代码的`PyMP`版本的结果时间：
- en: '![Fractals – Scaling the Mandelbrot set implementation](../Images/image00456.jpeg)'
  id: totrans-607
  prefs: []
  type: TYPE_IMG
  zh: '![分形图 - 缩放曼德勃罗集实现](../Images/image00456.jpeg)'
- en: Timing of parallel process mandelbrot program using PyMP—for 10000 iterations
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PyMP进行10000次迭代的并行进程曼德勃罗程序的时间
- en: The program is about 33% faster in real time. In terms of CPU usage, you can
    see that the `PyMP` version has a higher ratio of user CPU time to real CPU time,
    indicating a higher usage of the CPU by the processes than the single process
    version.
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序在实时方面快了大约33%。在CPU使用方面，您可以看到“PyMP”版本的用户CPU时间与实际CPU时间的比率更高，表明进程对CPU的使用比单进程版本更高。
- en: Note
  id: totrans-610
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'NOTE: We can write an even more efficient version of the program by avoiding
    the shared data structure image_rows which is used to keep the pixel values of
    the image. This version however uses that to show the features of PyMP. The code
    archives of this book contain two more versions of the program – one that uses
    multiprocessing and another that uses PyMP without the shared dictionary.'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们可以通过避免使用共享数据结构image_rows来编写程序的更高效版本，该数据结构用于保存图像的像素值。然而，这个版本使用了PyMP的特性来展示。本书的代码存档中包含程序的另外两个版本，一个使用了多进程，另一个使用了PyMP但没有共享字典。
- en: 'This is the output fractal image produced by this run of the program:'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 这是程序运行产生的分形图像输出：
- en: '![Fractals – Scaling the Mandelbrot set implementation](../Images/image00457.jpeg)'
  id: totrans-613
  prefs: []
  type: TYPE_IMG
  zh: '![分形图 - 缩放曼德勃罗集实现](../Images/image00457.jpeg)'
- en: Mandelbrot set fractal image for 10000 iterations using PyMP
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PyMP进行10000次迭代的曼德勃罗集分形图像
- en: You can observe that the colors are different, and this image provides more
    detail and a finer structure than the previous one due to the increased number
    of iterations.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以观察到颜色不同，这张图片由于迭代次数增加，提供了更多的细节和更精细的结构。
- en: Scaling for the Web
  id: totrans-616
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络扩展
- en: So far, all the scalability and concurrency techniques we discussed were involved
    with scalability within the confines of a single server or machine—in other words,
    scaling up. In real world, applications also scale by scaling out, that is, by
    spreading their computation over multiple machines. This is how most real-world
    web applications run and scale at present.
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论的所有可扩展性和并发技术都涉及在单个服务器或机器的范围内进行可扩展性 - 换句话说，扩展。在现实世界中，应用程序也通过扩展其计算到多台机器上来进行扩展。这是大多数现实世界的Web应用程序目前的运行和扩展方式。
- en: We will look at a few techniques, scaling out an application in terms of scaling
    communications/workflows, scaling computation, and horizontal scaling using different
    protocols.
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究一些技术，包括在通信/工作流程方面扩展应用程序、扩展计算和使用不同协议进行水平扩展。
- en: Scaling workflows – message queues and task queues
  id: totrans-619
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展工作流程 - 消息队列和任务队列
- en: One important aspect of scalability is to reducing coupling between systems.
    When two systems are tightly coupled, they prevent each other from scaling beyond
    a certain limit.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性的一个重要方面是减少系统之间的耦合。当两个系统紧密耦合时，它们会阻止彼此在一定限制之上进行扩展。
- en: For example, a code written serially, where data and computation is tied into
    the same function, prevents the program from taking advantage of the existing
    resources like multiple CPU cores. When the same program is rewritten to use multiple
    threads (or processes) and a message passing system like a queue in between, we
    find it scales well to multiple CPUs. We've seen such examples aplenty in our
    concurrency discussion.
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，串行编写的代码，其中数据和计算绑定到同一个函数中，阻止程序利用多个CPU核心等现有资源。当同一个程序被重写以使用多个线程（或进程）和消息传递系统，如队列之间，我们发现它可以很好地扩展到多个CPU。在我们的并发讨论中，我们已经看到了很多这样的例子。
- en: In a much similar way, systems over the Web scale better when they are decoupled.
    The classic example is the client/server architecture of the Web itself, where
    clients interact via well-known RestFUL protocols like HTTP, with servers located
    in different places across the world.
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，通过Web进行系统扩展时，解耦会更好。经典的例子是Web本身的客户端/服务器架构，客户端通过HTTP等众所周知的RestFUL协议与世界各地的服务器进行交互。
- en: Message queues are systems that allow applications to communicate in a decoupled
    manner by sending messages to each other. The applications typically run in different
    machines or servers connected to the Internet, and communicate via queuing protocols.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 消息队列是允许应用程序以解耦方式相互通信的系统，通过向彼此发送消息。这些应用程序通常在连接到互联网的不同机器或服务器上运行，并通过排队协议进行通信。
- en: One can think of a message queue as a scaled-up version of the multi-threaded
    synchronized queue, with applications on different machines replacing the threads,
    and a shared, distributed queue replacing the simple in-process queue.
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将消息队列看作是多线程同步队列的放大版本，不同机器上的应用程序取代了线程，共享的分布式队列取代了简单的进程内队列。
- en: Message queues carry packets of data called messages, which are delivered from
    the **Sending Applications** to the **Receiving Applications**. Most **Message
    Queue** provide **store and forward** semantics, where the message is stored on
    the queue till the receiver is available to process the message.
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 消息队列携带称为消息的数据包，这些数据包从**发送应用程序**传递到**接收应用程序**。大多数**消息队列**提供**存储和转发**语义，即消息存储在队列中，直到接收者可以处理消息为止。
- en: 'Here is a simple schematic model of a **Message Queue**:'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的**消息队列**的示意模型：
- en: '![Scaling workflows – message queues and task queues](../Images/image00458.jpeg)'
  id: totrans-627
  prefs: []
  type: TYPE_IMG
  zh: '![扩展工作流程-消息队列和任务队列](../Images/image00458.jpeg)'
- en: Schematic model of a distributed message queue
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式消息队列的示意模型
- en: The most popular and standardized implementation of a message queue or **message-oriented
    middleware** (**MoM**) is the **Advanced Message Queuing Protocol** (**AMQP**).
    AMQP provides features such as queuing, routing, reliable delivery, and security.
    The origins of AMQP are in the financial industry, where reliable and secure message
    delivery semantics are of critical importance.
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 最流行和标准化的消息队列或**消息导向中间件**（**MoM**）的实现是**高级消息队列协议**（**AMQP**）。AMQP提供了排队、路由、可靠传递和安全等功能。AMQP的起源在金融行业，可靠和安全的消息传递语义至关重要。
- en: The most popular implementations of AMQP (version 1.0) are Apache Active MQ,
    RabbitMQ, and Apache Qpid.
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: AMQP（版本1.0）的最流行的实现是Apache Active MQ、RabbitMQ和Apache Qpid。
- en: RabbitMQ is a MoM written in Erlang. It provides libraries in many languages
    including Python. In RabbitMQ, a message is always delivered via exchanges via
    routing keys which indicate the queues to which the message should be delivered.
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ是用Erlang编写的MoM。它提供了许多语言的库，包括Python。在RabbitMQ中，消息总是通过交换机通过路由键传递，这些键指示消息应传递到的队列。
- en: We won't be discussing RabbitMQ in this section anymore, but will move on to
    a related, but slightly different, middleware with a varying focus, namely, Celery.
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不再在本节讨论RabbitMQ，而是转向一个相关但略有不同的中间件，即Celery。
- en: Celery – a distributed task queue
  id: totrans-633
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Celery – 一个分布式任务队列
- en: Celery is a distributed task queue written in Python, which works using distributed
    messages. Each execution unit in celery is called a **task**. A task can be executed
    concurrently on one or more servers using processes called **workers**. By default,
    celery achieves this using `multiprocessing`, but it can also use other backend
    such as gevent, for example.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: Celery是一个用Python编写的分布式任务队列，使用分布式消息进行工作。Celery中的每个执行单元称为**任务**。任务可以使用称为**工作者**的进程在一个或多个服务器上并发执行。默认情况下，Celery使用`multiprocessing`来实现这一点，但也可以使用其他后端，例如gevent。
- en: Tasks can be executed synchronously or asynchronously with results available
    in the future, like objects. Also, task results can be stored in storage backend
    such as Redis, databases, or in files.
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 任务可以同步或异步执行，结果可以在将来像对象一样可用。此外，任务结果可以存储在后端存储中，如Redis、数据库或文件中。
- en: Celery differs from message queues in that the basic unit in celery is an executable
    task—a callable in Python—rather than just a message.
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: Celery与消息队列的不同之处在于，Celery的基本单元是可执行任务-在Python中可调用-而不仅仅是一条消息。
- en: Celery, however, can be made to work with message queues. In fact, the default
    broker for passing messages in celery is RabbitMQ, the popular implementation
    of AMQP. Celery can also work with Redis as the broker backend.
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Celery可以与消息队列一起工作。事实上，Celery传递消息的默认代理是RabbitMQ，这是AMQP的流行实现。Celery也可以使用Redis作为代理后端。
- en: Since Celery takes a task, and scales it over multiple workers; over multiple
    servers, it is suited to problems involving data parallelism as well as computational
    scaling. Celery can accept messages from a queue and distribute it over multiple
    machines as tasks for implementing a distributed e-mail delivery system, for example,
    and achieve horizontal scalability. Or, it can take a single function and perform
    parallel data computation by splitting the data over multiple processes, achieving
    parallel data processing.
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Celery接受一个任务，并在多个工作进程上扩展它；在多台服务器上，它适用于涉及数据并行性以及计算扩展的问题。Celery可以接受来自队列的消息，并将其作为任务分发到多台机器上，以实现分布式电子邮件传递系统，例如，实现水平扩展。或者，它可以接受单个函数，并通过将数据分割到多个进程中实现并行数据计算，实现并行数据处理。
- en: In the following example, we will take our Mandelbrot fractal program and, rewrite
    it to work with Celery. We will try to scale the program by performing data parallelism,
    in terms of computing the rows of the Mandelbrot set over multiple celery workers—in
    a similar way to what we did with `PyMP`.
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们将把我们的Mandelbrot分形程序重写为与Celery一起工作。我们将尝试通过在多个celery工作进程中计算Mandelbrot集的行来扩展程序，类似于我们在`PyMP`中所做的方式。
- en: The Mandelbrot set using Celery
  id: totrans-640
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Celery的Mandelbrot集
- en: For implementing a program to take advantage of Celery, it needs to be implemented
    as a task. This is not as difficult as it sounds. Mostly, it just involves preparing
    an instance of the celery app with a chosen broker backend, and decorating the
    callable we want to parallelize – using the special decorator `@app.task` where
    *app* is an instance of Celery.
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现一个利用Celery的程序，它需要被实现为一个任务。这并不像听起来那么困难。大多数情况下，它只涉及准备一个celery应用程序的实例，选择一个经纪后端，并使用特殊的装饰器`@app.task`装饰我们想要并行化的可调用对象-其中*app*是Celery的一个实例。
- en: 'We will look at this program listing step by step, since it involves a few
    new things. The software requirements for this session are as follows:'
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐步查看此程序清单，因为它涉及一些新内容。本次会话的软件要求如下：
- en: Celery
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Celery
- en: An AMQP backend; RabbitMQ is preferred
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AMQP后端；首选RabbitMQ
- en: Redis as a result storage backend
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redis作为结果存储后端
- en: 'First we will provide the listing for the Mandelbrot tasks module:'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将提供Mandelbrot任务模块的清单：
- en: '[PRE48]'
  id: totrans-647
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Let us analyze this preceding code:'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下前面的代码：
- en: We first do the imports required for celery. This requires importing the `Celery`
    class from the `celery` module.
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们首先导入了celery所需的导入。这需要从`celery`模块中导入`Celery`类。
- en: We prepare an instance of the `Celery` class as the celery app using AMQP as
    the message broker and Redis as the result backend. The AMQP configuration will
    use whatever AMQP MoM is available on the system (in this case, it is RabbitMQ).
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们准备了一个`Celery`类的实例作为celery应用程序，使用AMQP作为消息代理和Redis作为结果后端。AMQP配置将使用系统上可用的任何AMQP
    MoM（在本例中是RabbitMQ）。
- en: We have a modified version of `mandelbrot_calc_row`. In the `PyMP` version,
    the `image_rows` dictionary was passed as an argument to the function. Here, the
    function calculates it locally and returns a value. We will use this return value
    at the receiving side to create our image.
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有一个修改过的`mandelbrot_calc_row`版本。在`PyMP`版本中，`image_rows`字典作为参数传递给函数。在这里，函数在本地计算并返回一个值。我们将在接收端使用此返回值来创建我们的图像。
- en: We decorated the function using `@app.task`, where app is the `Celery` instance.
    This makes it ready to be executed as a celery task by the celery workers.
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`@app.task`装饰函数，其中app是`Celery`实例。这使得它可以被celery工作进程执行为celery任务。
- en: 'Next is the main program, which calls the task for a range of `y` input values
    and creates the image:'
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是主程序，它调用一系列`y`输入值的任务并创建图像：
- en: '[PRE49]'
  id: totrans-654
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The argument parser is the same so is not reproduced here.
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 参数解析器是相同的，因此这里不再重复。
- en: 'This last bit of code introduces some new concepts in celery, so needs some
    explanation. Let us analyze the code in some detail:'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的最后一部分介绍了一些新概念，因此需要一些解释。让我们详细分析一下代码：
- en: The `mandelbrot_main` function is similar to the previous `mandelbrot_calc_set`
    function in its arguments.
  id: totrans-657
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`mandelbrot_main`函数与先前的`mandelbrot_calc_set`函数在其参数上是相似的。'
- en: This function sets up a group of tasks, each performing `mandelbrot_calc_row`
    execution on a given `y` input over the entire range of `y` inputs from `0` to
    the height of the image. It uses the `group` object of celery to do this. A group
    is a set of tasks which can be executed together.
  id: totrans-658
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此函数设置了一组任务，每个任务在给定的`y`输入上执行`mandelbrot_calc_row`，覆盖从`0`到图像高度的整个`y`输入范围。它使用celery的`group`对象来执行此操作。组是一组可以一起执行的任务。
- en: The tasks are executed by calling the `apply_async` function on the group. This
    executes the tasks asynchronously in the background in multiple workers. We get
    an async `result` object in return—the tasks are not completed yet.
  id: totrans-659
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在组上调用`apply_async`函数来执行任务。这将在多个工作进程中异步执行任务。我们得到一个异步的`result`对象作为返回值-任务尚未完成。
- en: We then wait on this result object by calling `join` on it, which returns the
    results—the rows of the image as a dictionary from each single execution of the
    `mandelbrot_calc_row` task. We loop through this, and do integer conversions for
    the values, since celery returns data as strings, and put the pixel values in
    the image.
  id: totrans-660
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过在其上调用`join`等待此结果对象，返回结果-图像的行作为字典，来自`mandelbrot_calc_row`任务的单次执行。我们遍历这个，对值进行整数转换，因为celery返回数据为字符串，并将像素值放入图像中。
- en: Finally, the image is saved in the output file.
  id: totrans-661
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，图像保存在输出文件中。
- en: 'So how does celery execute the tasks? This needs the celery program to run,
    processing the tasks module with a certain number of workers. Here is how we start
    it in this case:'
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Celery如何执行任务呢？这需要celery程序运行，处理具有一定数量工作进程的任务模块。在这种情况下，这是我们启动它的方式：
- en: '![The Mandelbrot set using Celery](../Images/image00459.jpeg)'
  id: totrans-663
  prefs: []
  type: TYPE_IMG
  zh: '![使用Celery的Mandelbrot集](../Images/image00459.jpeg)'
- en: Celery console—workers starting up with the Mandelbrot task as target
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: Celery控制台-使用Mandelbrot任务作为目标启动工作人员
- en: The command starts celery with tasks loaded from the module `mandelbrot_tasks.py`
    with a set of 4 worker processes. Since the machine has 4 CPU cores, we have chosen
    this as the concurrency.
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令使用从模块`mandelbrot_tasks.py`加载的任务启动celery，并使用一组4个工作进程。由于机器有4个CPU核心，我们选择了这个并发性。
- en: Note
  id: totrans-666
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that Celery will automatically default the workers to the number of cores
    if not specifically configured.
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果没有特别配置，Celery将自动将工作进程默认为核心数。
- en: The program ran under 15 seconds, twice as faster than the single-process version
    and also the `PyMP` version.
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 程序在15秒内运行，比单进程版本和`PyMP`版本快了一倍。
- en: 'If you observe the celery console, you will find a lot of messages getting
    echoed, since we configured celery with the `INFO` log level. All these are info
    messages with data on the tasks and their results:'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您观察celery控制台，您会发现有很多消息被回显，因为我们将celery配置为`INFO`日志级别。所有这些都是包含有关任务及其结果的信息消息：
- en: 'The following screenshot shows the result of the run for `10000` iterations.
    This performance is slightly better than that of the similar run by the `PyMP`
    version earlier, by around 20 seconds:'
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示了对`10000`次迭代的运行结果。这个性能比之前的`PyMP`版本稍好一些，大约快了20秒：
- en: '![The Mandelbrot set using Celery](../Images/image00460.jpeg)'
  id: totrans-671
  prefs: []
  type: TYPE_IMG
  zh: '![使用Celery绘制Mandelbrot集](../Images/image00460.jpeg)'
- en: Celery Mandelbrot program for a set of 10000 iterations.
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: Mandelbrot程序的Celery版本，迭代10000次。
- en: Celery is used in production systems in many organizations. It has plugins for
    some of the more popular Python web application frameworks. For example, celery
    supports Django out-of-the-box with some basic plumbing and configuration. There
    are also extension modules such as `django-celery-results`, which allow the programmer
    to use the Django ORM as celery results backend.
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: Celery在许多组织的生产系统中使用。它为一些更受欢迎的Python Web应用程序框架提供了插件。例如，celery支持Django，具有一些基本的管道和配置。还有一些扩展模块，如`django-celery-results`，允许程序员使用Django
    ORM作为celery结果后端。
- en: It is beyond the scope of this chapter and book to discuss this in detail so
    the reader is suggested to refer to the documentation available on this on the
    celery project website.
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: 本章和本书的范围不包括详细讨论这个问题，因此建议读者参考celery项目网站上提供的文档。
- en: Serving with Python on the Web—WSGI
  id: totrans-675
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Python在Web上提供WSGI服务
- en: '**Web Server Gateway Interface** (**WSGI**) is a specification for a standard
    interface between Python web application frameworks and web servers.'
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: '**Web服务器网关接口**（**WSGI**）是Python Web应用程序框架和Web服务器之间标准接口的规范。'
- en: In the early days of Python web applications, there was a problem of connecting
    web application frameworks to web servers, since there was no common standard.
    Python web applications were designed to work with one of the existing standards
    of CGI, FastCGI, or `mod_python` (Apache). This meant that an application written
    to work with one web server might not be able to work with another. In other words,
    interoperability between the uniform application and web server was missing.
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python Web应用程序的早期，存在将Web应用程序框架连接到Web服务器的问题，因为没有共同的标准。Python Web应用程序被设计为与CGI、FastCGI或`mod_python`（Apache）的现有标准之一配合使用。这意味着为一个Web服务器编写的应用程序可能无法在另一个Web服务器上运行。换句话说，统一应用程序和Web服务器之间的互操作性是缺失的。
- en: WSGI solved this problem by specifying a simple, but uniform, interface between
    servers and web application frameworks to allow for portable web application development.
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: WSGI通过规定一个简单但统一的接口来解决了这个问题，允许可移植的Web应用程序开发。
- en: 'WSGI specifies two sides: the server (or gateway) side, and the application
    or framework side. A WSGI request gets processed as follows:'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: WSGI规定了两个方面：服务器（或网关）方面和应用程序或框架方面。WSGI请求的处理如下：
- en: The server side executes the application, providing it with an environment and
    a callback function
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器端执行应用程序，为其提供环境和回调函数
- en: The application processes the request, and returns the response to the server
    using the provided callback function
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序处理请求，并使用提供的回调函数将响应返回给服务器
- en: 'Here is a schematic diagram showing the interaction between a web server and
    web application using WSGI:'
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示意图，显示了Web服务器和Web应用程序使用WSGI的交互：
- en: '![Serving with Python on the Web—WSGI](../Images/image00461.jpeg)'
  id: totrans-683
  prefs: []
  type: TYPE_IMG
  zh: '![使用Python在Web上提供WSGI服务](../Images/image00461.jpeg)'
- en: Schematic diagram showing WSGI protocol interaction
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: 显示WSGI协议交互的示意图
- en: 'Following is the simplest function that is compatible with the application
    or framework side of WSGI is:'
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是与WSGI应用程序或框架兼容的最简单的函数：
- en: '[PRE50]'
  id: totrans-686
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The preceding function can be explained as follows:'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数可以解释如下：
- en: The `environ` variable is a dictionary of environment variables passed from
    the server to the application as defined by the **Common Gateway Interface** (**CGI**)
    specification. WSGI makes a few of these environment variables mandatory in its
    specification.
  id: totrans-688
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`environ`变量是一个字典，包含从服务器传递到应用程序的环境变量，由**公共网关接口**（**CGI**）规范定义。WSGI在其规范中强制要求其中的一些环境变量。'
- en: The `start_response` is a callable provided as a callback from the server side
    to the application side to start response processing on the server side. It must
    take two positional arguments. The first should be a status string with an integer
    status code, and the second, a list of (`header_name`, `header_value`), tuples
    describing the HTTP response header.
  id: totrans-689
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`start_response`是一个可调用的回调函数，由服务器端提供给应用程序端，用于在服务器端启动响应处理。它必须接受两个位置参数。第一个参数应该是一个带有整数状态码的状态字符串，第二个参数是一个描述HTTP响应头的（`header_name`，`header_value`）元组列表。'
- en: Note
  id: totrans-690
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more details, the reader can refer to the WSGI specification v1.0.1, which
    is published on the Python language website as PEP 3333.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多详细信息，读者可以参考Python语言网站上发布的WSGI规范v1.0.1，即PEP 3333。
- en: Note
  id: totrans-692
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Python Enhancement Proposal** (**PEP**) is a design document on the Web,
    that describes a new feature or feature suggestion for Python, or provides information
    to the Python community about an existing feature. The Python community uses PEPs
    as a standard process for describing, discussing, and adopting new features and
    enhancements to the Python programming language and its standard library.'
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python Enhancement Proposal** (**PEP**) 是一个Web上的设计文档，描述了Python的新功能或功能建议，或者向Python社区提供有关现有功能的信息。Python社区使用PEPs作为描述、讨论和采纳Python编程语言及其标准库的新功能和增强的标准流程。'
- en: 'WSGI middleware components are software that implement both sides of the specification,
    and hence, provide capabilities such as the following:'
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: WSGI中间件组件是实现规范两端的软件，因此提供以下功能：
- en: Load balancing of multiple requests from a server to an application
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从服务器到应用程序的多个请求的负载均衡
- en: Remote processing of requests by forwarding requests and responses over a network
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 远程处理请求，通过在网络上传递请求和响应
- en: Multi-tenancy or co-hosting of multiple servers and/or applications in the same
    process
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在同一进程中多租户或共托管多个服务器和/或应用程序
- en: URL-based routing of requests to different application objects
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于URL的请求路由到不同的应用程序对象
- en: The middleware sits in between the server and application. It forwards requests
    from server to the application and responses from application to the server.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 中间件位于服务器和应用程序之间。它将请求从服务器转发到应用程序，将应用程序的响应转发到服务器。
- en: There are a number of WSGI middleware an architect can choose from. We will
    briefly look at two of the most popular ones, namely, uWSGI and Gunicorn.
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 架构师可以选择多种WSGI中间件。我们将简要介绍两种最流行的中间件，即uWSGI和Gunicorn。
- en: uWSGI – WSGI middleware on steroids
  id: totrans-701
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: uWSGI – WSGI中间件的超级版本
- en: uWSGI is an open source project and application, which aims to build a full
    stack for hosting services. The WSGI of the uWSGI project stems from the fact
    that the WSGI interface plugin for Python was the first one developed in the project.
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI是一个旨在构建托管服务的完整堆栈的开源项目和应用程序。uWSGI项目的WSGI源于该项目中开发的Python的WSGI接口插件是第一个。
- en: Apart from WSGI, the uWSGI project also supports **Perl Webserver Gateway Interface**
    (**PSGI**) for Perl web applications, and the rack web server interface for Ruby
    web applications. It also provides gateways, load balancers, and routers for requests
    and responses. The Emperor plugin of uWSGI provides management and monitoring
    of multiple uWSGI deployments of your production system across servers.
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: 除了WSGI，uWSGI项目还支持Perl Webserver Gateway Interface（PSGI）用于Perl Web应用程序，以及Rack
    Web服务器接口用于Ruby Web应用程序。它还提供网关、负载均衡器和请求和响应的路由器。uWSGI的Emperor插件提供了对生产系统中多个uWSGI部署的管理和监控。
- en: The components of uWSGI can run in preforked, threaded, asynchronous. or green-thread/co-routine
    modes.
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI的组件可以以预分叉、线程、异步或绿色线程/协程模式运行。
- en: uWSGI also comes with a fast and in-memory caching framework, which allows the
    responses of the web applications to be stored in multiple caches on the uWSGI
    server. The cache can also be backed with a persistence store such as a file.
    Apart from a multitude of other things, uWSGI also supports virtualenv based deployments
    in Python.
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI还配备了一个快速的内存缓存框架，允许Web应用程序的响应存储在uWSGI服务器上的多个缓存中。缓存也可以备份到文件等持久存储。除了其他功能外，uWSGI还支持基于Python的virtualenv部署。
- en: uWSGI also provides a native protocol, that is used by the uWSGI server. uWSGI
    version 1.9 also adds native support for the web sockets.
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI还提供了一个本地协议，被uWSGI服务器使用。uWSGI 1.9版本还增加了对Web套接字的本地支持。
- en: 'Here is a typical example of a uWSGI configuration file:'
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是uWSGI配置文件的典型示例：
- en: '[PRE51]'
  id: totrans-708
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'A typical deployment architecture with uWSGI looks like what is depicted in
    the following diagram. In this case, the web server is Nginx, and the web application
    framework is Django. uWSGI is deployed in a reverse-proxy configuration with Nginx,
    forwarding request and responses between Nginx and Django:'
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI的典型部署架构如下图所示。在这种情况下，Web服务器是Nginx，Web应用程序框架是Django。uWSGI以反向代理配置与Nginx部署，转发请求和响应之间的Nginx和Django：
- en: '![uWSGI – WSGI middleware on steroids](../Images/image00462.jpeg)'
  id: totrans-710
  prefs: []
  type: TYPE_IMG
  zh: '![uWSGI – WSGI中间件的超级版本](../Images/image00462.jpeg)'
- en: uWSGI deployment with Nginx and Django
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx和Django的uWSGI部署
- en: Note
  id: totrans-712
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The Nginx web server supports a native implementation of the uWSGI protocol
    since version 0.8.40\. There is also a proxy module support for uWSGI in Apache
    named `mod_proxy_uwsgi`.
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx Web服务器自0.8.40版本以来支持uWSGI协议的本地实现。Apache中也有一个名为`mod_proxy_uwsgi`的uWSGI代理模块支持。
- en: uWSGI is an ideal choice for Python web application production deployments where
    one needs a good balance of customization with high performance and features.
    It is the swiss-army-knife of components for WSGI web application deployments.
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI是Python Web应用程序生产部署的理想选择，其中需要在高性能和功能之间取得良好的平衡。它是WSGI Web应用程序部署的瑞士军刀组件。
- en: Gunicorn – unicorn for WSGI
  id: totrans-715
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Gunicorn – WSGI的独角兽
- en: The Gunicorn project is another popular WSGI middleware implementation, which
    is opensource. It uses a preforked model, and is a ported version from the unicorn
    project of Ruby. There are different worker types in Gunicorn, like uWSGI supporting
    synchronous and asynchronous handling of requests. The asynchronous workers make
    use of the `Greenlet` library which is built on top of gevent.
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: Gunicorn项目是另一个流行的WSGI中间件实现，是开源的。它使用预分叉模型，并且是从Ruby的unicorn项目移植过来的。Gunicorn有不同的工作类型，如uWSGI支持请求的同步和异步处理。异步工作进程使用构建在gevent之上的`Greenlet`库。
- en: There is a master process in Gunicorn that runs an event loop, processing and
    reacting to various signals. The master manages the workers, and the workers process
    the requests, and send responses.
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: Gunicorn中有一个主进程，运行一个事件循环，处理和响应各种信号。主进程管理工作进程，工作进程处理请求并发送响应。
- en: Gunicorn versus uWSGI
  id: totrans-718
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Gunicorn与uWSGI
- en: 'Here are a few guidelines when choosing whether to go with Gunicorn or uWSGI
    for your Python web application deployments:'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择是使用Gunicorn还是uWSGI进行Python Web应用程序部署时，有一些指导原则：
- en: For simple application deployments which don't need a lot of customization,
    gunicorn is a good choice. uWSGI has a bigger learning curve when compared to
    Gunicorn, and takes a while to get used to. The defaults in Gunicorn work pretty
    well for most deployments.
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于不需要大量定制的简单应用程序部署，Gunicorn是一个不错的选择。与Gunicorn相比，uWSGI的学习曲线更陡，需要一段时间才能适应。Gunicorn的默认设置对大多数部署都非常有效。
- en: If your deployment is homogenously Python, then Gunicorn is a good choice. On
    the other hand, uWSGI allows you to perform heterogeneous deployments due to its
    support for other stacks such as PSGI and Rack.
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的部署是同质的Python，那么Gunicorn是一个不错的选择。另一方面，uWSGI允许您执行异构部署，因为它支持其他堆栈，如PSGI和Rack。
- en: If you want a more full-featured WSGI middleware, which is heavily customizable,
    then uWSGI is a safe bet. For example, uWSGI makes Python virtualenv-based deployments
    simple, whereas, Gunicorn doesn't natively support virtualenv; instead, Gunicorn
    itself has to be deployed in the virtual environment.
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您希望使用更全面的WSGI中间件，并且具有很高的可定制性，那么uWSGI是一个安全的选择。例如，uWSGI使基于Python的虚拟环境部署变得简单，而Gunicorn并不原生支持虚拟环境；相反，Gunicorn本身必须部署在虚拟环境中。
- en: Since Nginx supports uWSGI natively, it is very commonly deployed along with
    Nginx on production systems. Hence, if you use Nginx, and want a full-featured
    and highly customizable WSGI middleware with caching, uWSGI is the default choice.
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于Nginx本身原生支持uWSGI，因此它在生产系统上非常常见。因此，如果您使用Nginx，并且希望具有全功能且高度可定制的WSGI中间件与缓存，uWSGI是默认选择。
- en: With respect to performance, both Gunicorn and uWSGI score similarly on different
    benchmarks published on the Web.
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在性能方面，根据Web上发布的不同基准测试，Gunicorn和uWSGI在不同基准测试中得分相似。
- en: Scalability architectures
  id: totrans-725
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性架构
- en: As discussed, a system can scale vertically, or horizontally, or both. In this
    section, we will briefly look at a few of the architectures that an architect
    can choose from when deploying his systems to production to take advantage of
    the scalability options.
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: 正如讨论的那样，系统可以垂直扩展，也可以水平扩展，或者两者兼而有之。在本节中，我们将简要介绍一些架构，架构师在将系统部署到生产环境中时可以选择，以利用可扩展性选项。
- en: Vertical scalability architectures
  id: totrans-727
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 垂直可扩展性架构
- en: 'Vertical scalability techniques comes in the following two flavors:'
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: 垂直可扩展性技术有以下两种类型：
- en: '**Adding more resources to an existing system**: This could mean adding more
    RAM to a physical or virtual machine, adding more vCPUs to a virtual machine or
    VPS, and so on. However, none of these options are dynamic, as they require stopping,
    reconfiguring, and restarting the instance.'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向现有系统添加更多资源**：这可能意味着向物理或虚拟机器添加更多RAM，向虚拟机器或VPS添加更多vCPU等。然而，这些选项都不是动态的，因为它们需要停止、重新配置和重新启动实例。'
- en: '**Making better use of existing resources in the system**: We have spent a
    lot of this chapter discussing this approach. This is when an application is rewritten
    to make use of the existing resources, such as multiple CPU cores, more effectively
    by concurrency techniques such as threading, multiple processes, and/or asynchronous
    processing. This approach scales dynamically, since no new resource is added to
    the system, and hence, there is no need for a stop/start.'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更好地利用系统中现有资源**：我们在本章中花了很多时间讨论这种方法。这是当应用程序被重写以更有效地利用现有资源，如多个CPU核心，通过并发技术如线程、多进程和/或异步处理。这种方法可以动态扩展，因为系统中没有添加新资源，因此不需要停止/启动。'
- en: Horizontal scalability architectures
  id: totrans-731
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 水平可扩展性架构
- en: 'Horizontal scalability involves a number of techniques that an architect can
    add to his tool box, and pick and choose from. They include the ones listed next:'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: 水平可扩展性涉及一系列技术，架构师可以添加到其工具箱中，并进行选择。它们包括下面列出的技术：
- en: '**Active redundancy**: This is the simplest technique of scaling out, which
    involves adding multiple, homogenous processing nodes to a system typically fronted
    with a load balancer. This is a common practice for scaling out web application
    server deployments. Multiple nodes make sure that an even if one or a few of the
    systems fail, the remaining systems continue to carry out request processing,
    ensuring no downtime for your application.'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主动冗余**：这是扩展的最简单技术，涉及向系统添加多个同类处理节点，通常由负载均衡器前置。这是扩展Web应用程序服务器部署的常见做法。多个节点确保即使其中一个或几个系统失败，其余系统仍然继续进行请求处理，确保应用程序没有停机时间。'
- en: In a redundant system, all the nodes are actively in operation, though only
    one or a few of them may be responding to requests at a specific time.
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 在冗余系统中，所有节点都处于活动状态，尽管在特定时间只有一个或几个节点可能会响应请求。
- en: '**Hot standby**: A hot standby (hot spare) is a technique used to switch to
    a system that is ready to server requests, but is not active till the moment the
    main system go down. A hot spare is in many ways exactly similar to the main node(s)
    that is serving the application. In the event of a critical failure, the load
    balancer is configured to switch to the hot spare.'
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 热备份：热备份（热备用）是一种技术，用于切换到一个准备好为请求提供服务的系统，但在主系统宕机之前并不活动。热备用在许多方面与正在提供应用程序服务的主节点（节点）完全相似。在发生关键故障时，负载均衡器被配置为切换到热备用系统。
- en: The hot spare itself may be a set of redundant nodes instead of just a single
    node. Combining redundant systems with a hot spare ensures maximum reliability
    and failover.
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 热备用本身可能是一组冗余节点，而不仅仅是单个节点。将冗余系统与热备用结合起来，确保最大的可靠性和故障转移。
- en: Note
  id: totrans-737
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A variation of a hot standby is a software standby, which provides a mode in
    the application that switches the system to a minimum **Quality of Service** (**QoS**)
    instead of offering the full feature at extreme load. An example is a web application
    that switches to the read-only mode under high loads, serving most users but not
    allowing writes.
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 热备份的变种是软件备份，它提供了一种模式，可以在极端负载下将系统切换到最低的**服务质量**（**QoS**），而不是提供完整的功能。例如，一个Web应用程序在高负载下切换到只读模式，为大多数用户提供服务，但不允许写入。
- en: '**Read replicas**: The response of a system that is dependent on read-heavy
    operations on a database can be improved by adding read-replicas of the database.
    Read replicas are essentially database nodes that provide hot backups (online
    backups), which constantly sync from the main database node. Read replicas, at
    a given point of time, may not be exactly consistent with the main database node,
    but they provide eventual consistency with SLA guarantees.'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**读取副本**: 依赖于数据库上读取密集型操作的系统的响应可以通过添加数据库的读取副本来改善。读取副本本质上是提供热备份（在线备份）的数据库节点，它们不断地与主数据库节点同步。在某一时间点上，读取副本可能与主数据库节点不完全一致，但它们提供具有SLA保证的最终一致性。'
- en: Cloud service providers such as Amazon make their RDS database service available
    with a choice of read replicas. Such replicas can be distributed geographically
    closer to your active user locations to ensure less response time and failover
    in case the master node goes down, or doesn't respond.
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商如亚马逊提供了RDS数据库服务，并提供了读取副本的选择。这些副本可以在地理位置更接近活跃用户的地方分布，以确保更少的响应时间和故障转移，以防主节点崩溃或无响应。
- en: Read replicas basically offer your system a kind of data redundancy.
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 读取副本基本上为您的系统提供了一种数据冗余。
- en: '**Blue-green deployments**: This is a technique where two separate systems
    (labeled `blue` and `green` in the literature) are run side by side. At any given
    moment, only one of the systems is active and is serving requests. For example,
    blue is *active*, green is *idle*.'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**蓝绿部署**: 这是一种技术，其中两个单独的系统（在文献中标记为`蓝色`和`绿色`）并行运行。在任何给定的时刻，只有一个系统是活动的并提供服务。例如，蓝色是*活动的*，绿色是*空闲的*。'
- en: When preparing a new deployment, it is done on the idle system. Once the system
    is ready, the load balancer is switched to the idle system (green), and away from
    the active system (blue). At this point, green is active, and blue is idle. The
    positions are reversed again in the next switch.
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备新部署时，它是在空闲系统上完成的。一旦系统准备就绪，负载均衡器就会切换到空闲系统（绿色），远离活动系统（蓝色）。此时，绿色是活动的，蓝色是空闲的。在下一次切换时，位置会再次颠倒。
- en: Blue-green deployments, if done correctly, ensure zero to minimum downtime of
    your production applications.
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: 如果正确执行，蓝绿部署可以确保生产应用的零到最小停机时间。
- en: '**Failure monitoring and/or restart**: A failure monitor is a system that detects
    failure of critical components—software or hardware—of your deployments, and either
    notifies you, and/or takes steps to mitigate the downtime.'
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**故障监控和/或重启**: 故障监视器是一种检测部署的关键组件（软件或硬件）故障的系统，它会通知您，并/或采取措施减轻停机时间。'
- en: For example, you can install a monitoring application on your server that detects
    when a critical component, say, a celery or rabbitmq server, goes down, sends
    an e-mail to the DevOps contact, and also tries to restart the daemon.
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以在服务器上安装一个监控应用程序，当关键组件（例如celery或rabbitmq服务器）崩溃时，它会发送电子邮件给DevOps联系人，并尝试重新启动守护程序。
- en: Heartbeat monitoring is another technique where a software actively sends pings
    or heartbeats to a monitoring software or hardware, which could be in the same
    machine or another server. The monitor will detect the downtime of the system
    if it fails to send the heartbeat after a certain interval, and could then inform
    and/or try to restart the component.
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: 心跳监控是另一种技术，其中软件主动向监控软件或硬件发送ping或心跳，这可以在同一台机器或另一台服务器上。如果在一定时间间隔后未能发送心跳，监视器将检测系统的停机，并通知和/或尝试重新启动组件。
- en: Nagios is an example of a common production monitoring server, usually deployed
    in a separate environment, and monitors your deployment servers. Other examples
    of system-switch monitors and restart components are **Monit** and **Supervisord**.
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: Nagios是一个常见的生产监控服务器的例子，通常部署在一个单独的环境中，并监控您的部署服务器。其他系统切换监视器和重启组件的例子包括**Monit**和**Supervisord**。
- en: 'Apart from these techniques, the following best practices should be followed
    when performing system deployments to ensure scalability, availability, and redundancy/failover:'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些技术之外，在执行系统部署时应遵循以下最佳实践，以确保可伸缩性、可用性和冗余/故障转移：
- en: '**Cache it**: Use caches, and if possible, distributed caches, in your system
    as much as possible. Caches can be of various types. The simplest possible cache
    is caching static resources on the **content delivery network** (**CDN**) of your
    application service provider. Such a cache ensures geographic distribution of
    resources closer to your users, which reduces response, and hence, page-load times.'
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓存**: 在系统中尽可能多地使用缓存，如果可能的话，使用分布式缓存。缓存可以有各种类型。最简单的缓存是在应用服务提供商的**内容传送网络**（**CDN**）上缓存静态资源。这样的缓存可以确保资源在用户附近地理分布，从而减少响应时间和页面加载时间。'
- en: A second kind of cache is your application's cache, where it caches responses
    and database query results. Memcached and Redis are commonly used for these scenarios,
    and they provide distributed deployments, typically, in master/slave modes. Such
    caches should be used to load and cache most commonly requested content from your
    application with proper expiry times to ensure that the data is not too stale.
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种缓存是应用程序的缓存，它缓存响应和数据库查询结果。Memcached和Redis通常用于这些场景，并且它们提供分布式部署，通常是主/从模式。应该使用这样的缓存来加载和缓存应用程序中最常请求的内容，并设置适当的过期时间，以确保数据不会太陈旧。
- en: 'Effective and well-designed caches minimize system load, and avoid multiple,
    redundant operations that can artificially increase load on a system and decrease
    performance:'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: 有效且设计良好的缓存可以最小化系统负载，并避免多次冗余操作，这些操作可能会人为增加系统负载并降低性能：
- en: '**Decouple**: As much as possible, decouple your components to take advantage
    of the shared geography of your network. For example, a message queue may be used
    to decouple components in an application that need to publish and subscribe data
    instead of using a local database or sockets in the same machine. When you decouple,
    you automatically introduce redundancy and data backup to your system, since the
    new components you add for decoupling—message queues, task queues, and distributed
    caches—typically come with their own stateful storage and clustering.'
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解耦**：尽可能解耦组件，以充分利用网络的共享地理位置。例如，消息队列可用于解耦应用程序中需要发布和订阅数据的组件，而不是使用本地数据库或同一台机器上的套接字。解耦时，您自动引入了冗余和数据备份到系统中，因为您为解耦添加的新组件（消息队列、任务队列和分布式缓存）通常都带有自己的有状态存储和集群。'
- en: The added complexity of decoupling is the configuration of the extra systems.
    However, in this day and age, with most systems being able to perform auto configuration
    or providing simple web-based configurations, this is not an issue.
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 解耦的额外复杂性在于额外系统的配置。然而，在当今时代，大多数系统都能够执行自动配置或提供简单的基于Web的配置，这不是问题。
- en: 'You can refer to literature for application architectures that provide effective
    decoupling, such as observer patterns, mediators, and other such middleware:'
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考文献，了解提供有效解耦的应用架构，例如观察者模式、中介者和其他中间件：
- en: '**Gracefully degrade**: Rather than being unable to answer a request and providing
    timeouts, arm your systems with graceful degradation behaviors. For example, a
    write-heavy web application can switch to the read-only mode under heavy load
    when it finds that the database node is not responding. Another example is when
    a system which provides heavy, JS-dependent dynamic web pages could switch to
    a similar static page under heavy loads on the server when the JS middleware is
    not responding well.'
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优雅降级**：与无法回答请求并提供超时相比，为系统提供优雅降级行为更为重要。例如，当写入密集型Web应用程序发现数据库节点未响应时，可以在负载过重时切换到只读模式。另一个例子是，当提供大量依赖JS的动态网页的系统在服务器负载过重时，可以在JS中间件响应不佳时切换到类似的静态页面。'
- en: Graceful degradation can be configured on the application itself, or on the
    load balancers, or both. It is a good idea to prepare your application itself
    to provide a gracefully downgraded behavior, and configure the load balancer to
    switch to that route under heavy loads.
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: 优雅降级可以在应用程序本身或负载均衡器上进行配置，也可以两者兼而有之。为应用程序本身提供优雅降级行为，并配置负载均衡器在负载过重时切换到该路由是一个好主意。
- en: '**Keep data close to the code:** A golden rule of performance-strong software
    is to provide data closer to where the computation is. For example, if your application
    is making 50 SQL queries to load data from a remote database for every request,
    then you are not doing this correctly.'
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将数据靠近代码**：性能强大的软件的黄金法则是将数据提供给计算所在的地方。例如，如果您的应用程序每次请求都要从远程数据库加载数据进行50次SQL查询，那么您的做法就不正确。'
- en: Providing data close to the computation reduces data access and transport times,
    and hence, processing times, decreasing latency in your application, and making
    it more scalable.
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据靠近计算可以减少数据访问和传输时间，从而减少处理时间，降低应用程序的延迟，并使其更具可扩展性。
- en: 'There are different techniques for this: caching, as discussed earlier, is
    a favored technique. Another one is to split your database to a local and remote
    one, where most of the reads happen from the local read replica, and writes (which
    can take time) happen to a remote write master. Note that local in this sense
    may not mean the same machine, but typically, the same data center, sharing the
    same subnet if possible.'
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的技术可以实现这一点：如前所述，缓存是一种受欢迎的技术。另一种技术是将数据库分为本地和远程两部分，其中大部分读取操作都来自本地读取副本，而写入（可能需要时间）则发生在远程写入主机上。需要注意的是，在这种情况下，本地可能并不意味着同一台机器，但通常指的是同一数据中心，如果可能的话，共享同一子网。
- en: Also, common configurations can be loaded from an on-disk database like SQLite
    or local JSON files, reducing the time it takes for preparing the application
    instances.
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，常见配置可以从磁盘数据库（如SQLite）或本地JSON文件中加载，从而减少准备应用实例所需的时间。
- en: Another technique is to not store any transactional state in the application
    tier or the frontend, but to move the state closer to the backend where the computation
    is. Since this makes all application server nodes equal in terms of not having
    any intermediate state, it also allows you to front them with a load-balancer,
    and provide a redundant cluster of equals, any of which can serve a given request.
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种技术是不在应用程序层或前端存储任何事务状态，而是将状态移至计算所在的后端。由于这使得所有应用服务器节点在中间状态上都是相等的，因此可以使用负载均衡器对其进行前置，并提供一个相等的冗余集群，其中任何一个都可以处理特定请求。
- en: '**Design according to SLAs**: It is very important for an architect to understand
    the guarantees that the application provides to its users, and design the deployment
    architecture accordingly.'
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**根据SLA设计**：对于架构师来说，了解应用程序向用户提供的保证，并相应地设计部署架构非常重要。'
- en: The CAP theorem ensures that if a network partition in a distributed system
    fails, the system can guarantee only one of consistency or availability at a given
    time. This groups distributed systems into two common types, namely, CP and AP
    systems.
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: CAP定理确保在分布式系统中发生网络分区故障时，系统只能在特定时间内保证一致性或可用性。这将分布式系统分为两种常见类型，即CP和AP系统。
- en: Most web applications in today's world are AP. They ensure availability, but
    data is only eventually consistent, which means they will serve stale data to
    users in case one of the systems in the network partition, say the master DB node,
    fails.
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
  zh: 当今世界上大多数网络应用都是AP。它们确保可用性，但数据只是最终一致，这意味着它们会向用户提供过时的数据，例如在网络分区中的一个系统（比如主数据库节点）发生故障时。
- en: On the other hand. a number of businesses such as banking, finance, and healthcare
    need to ensure consistent data even if there is a network partition failure. These
    are CP systems. The data in such systems should never be stale, so, in case of
    a choice between availability and consistent data, they will chose the latter.
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，许多企业，如银行、金融和医疗保健，需要确保即使存在网络分区故障，数据也是一致的。这些是CP系统。这些系统中的数据不应该过时，因此，在可用性和一致性数据之间做出选择时，它们会选择后者。
- en: The choice of software components, application architecture, and the final deployment
    architecture are influenced by these constraints. For example, an AP system can
    work with NoSQL databases which guarantee eventual consistent behavior. It can
    make better use of caches. A CP system, on the other hand, may need ACID guarantees
    provided by **Relational Database Systems** (**RDBMs**).
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: 软件组件的选择、应用架构和最终部署架构受到这些约束的影响。例如，AP系统可以使用保证最终一致行为的NoSQL数据库。它可以更好地利用缓存。另一方面，CP系统可能需要**关系数据库系统**（**RDBMs**）提供的ACID保证。
- en: Summary
  id: totrans-768
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we reused a lot of ideas and concepts that you learned in the
    previous chapter on performance.
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们重复使用了您在上一章关于性能的许多想法和概念。
- en: We started with a definition of scalability, and looked at its relation with
    other aspects like concurrency, latency, and performance. We briefly compared
    and contrasted concurrency and its close cousin parallelism.
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从可扩展性的定义开始，并研究了它与并发、延迟和性能等其他方面的关系。我们简要比较和对比了并发及其近亲并行性。
- en: We then went on to discuss various concurrency techniques in Python with detailed
    examples and performance comparisons. We used a thumbnail generator with random
    URLs from the Web as an example to illustrate the various techniques of implementing
    concurrency using multi-threading in Python. You also learned and saw an example
    of the producer/consumer pattern, and using a couple of examples, learned how
    to implement resource constraints and limits using synchronization primitives.
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们继续讨论了Python中各种并发技术，包括详细的示例和性能比较。我们以来自网络的随机URL的缩略图生成器为例，来说明使用Python中的多线程实现并发的各种技术。您还学习并看到了生产者/消费者模式的示例，并使用了一些示例来学习如何使用同步原语来实现资源约束和限制。
- en: Next we discussed how to scale applications using multi-processing and saw a
    couple of examples using the `multiprocessing` module – such as a primality checker
    which showed us the effects of `GIL` on multiple threads in Python and a disk
    file sorting program which showed the limits of multi-processing when it comes
    to scaling programs using a lot disk I/O .
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们讨论了如何使用多进程来扩展应用程序，并看到了使用`multiprocessing`模块的一些示例，比如一个素数检查器，它向我们展示了`GIL`对Python中多线程的影响，以及一个磁盘文件排序程序，它展示了在处理大量磁盘I/O时，多进程在扩展程序方面的限制。
- en: We looked at asynchronous processing as the next technique of concurrency. We
    saw a generator based co-operative multitasking scheduler and also its counterpart
    using `asyncio`. We saw couple of examples using asyncio and learned how to perform
    URL fetches using the aiohttp module asynchronously. The section on concurrent
    processing compared and contrasted concurrent futures with other options on concurrency
    in Python while sketching out a couple of examples.
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将异步处理作为并发的下一个技术。我们看到了基于生成器的协作式多任务调度程序，以及使用`asyncio`的对应部分。我们看了一些使用asyncio的示例，并学习了如何使用aiohttp模块异步执行URL获取。并发处理部分比较和对比了并发未来与Python中其他并发选项，同时勾勒了一些示例。
- en: We used Mandelbrot fractals as an example to show how to implement data parallel
    programs and showed an example of using `PyMP` to scale a mandelbrot fractal program
    across multiple processes and hence multiple cores.
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以Mandelbrot分形作为示例，展示了如何实现数据并行程序，并展示了使用`PyMP`来在多个进程和多个核心上扩展mandelbrot分形程序的示例。
- en: Next we went on to discuss how to scale your programs out on the Web. We briefly
    discussed the theoretical aspect of message queues and task queues. We looked
    at celery, the Python task queue library, and rewrote the Mandelbrot program to
    scale using celery workers, and did performance comparisons.
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们讨论了如何在网络上扩展您的程序。我们简要讨论了消息队列和任务队列的理论方面。我们看了一下celery，Python任务队列库，并重新编写了Mandelbrot程序，使用celery工作者进行扩展，并进行了性能比较。
- en: WSGI, Python's way of serving web applications over web servers, was the next
    topic of discussion. We discussed the WSGI specification, and compared and contrasted
    two popular WSGI middleware, namely, uWSGI and Gunicorn.
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: WSGI，Python在Web服务器上提供Web应用程序的方式，是接下来讨论的话题。我们讨论了WSGI规范，并比较和对比了两个流行的WSGI中间件，即uWSGI和Gunicorn。
- en: Towards the end of the chapter, we discussed scalability architectures, and
    looked at the different options of scaling vertically and horizontally on the
    Web. We also discussed at some best practices an architect should follow while
    designing, implementing, and deploying distributed applications on the web for
    achieving high scalability.
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后，我们讨论了可扩展性架构，并研究了在网络上垂直和水平扩展的不同选项。我们还讨论了一些最佳实践，架构师在设计、实施和部署分布式应用程序时应遵循，以实现高可扩展性。
- en: In the next chapter, we discuss the aspect of Security in software architecture
    and discuss aspects of security the architect should be aware of and strategies
    for making your applications secure.
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论软件架构中的安全性，并讨论架构师应该了解的安全性方面以及使应用程序安全的策略。
