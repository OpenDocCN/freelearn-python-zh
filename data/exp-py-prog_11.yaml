- en: Chapter 11. Optimization – General Principles and Profiling Techniques
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章。优化-一般原则和分析技术
- en: '|   | *"We should forget about small efficiencies, say about 97% of the time:
    premature optimization is the root of all evil."* |   |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '|   | *"我们应该忘记小的效率，大约有97%的时间：过早的优化是万恶之源。"* |   |'
- en: '|   | --*Donald Knuth* |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|   | --*唐纳德·克努斯* |'
- en: This chapter is about optimization and provides a set of general principles
    and profiling techniques. It gives the three rules of optimization every developer
    should be aware of and provides guidelines on optimization. Last, it focuses on
    how to find bottlenecks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了优化，并提供了一套通用原则和分析技术。它提供了每个开发人员都应该了解的三条优化规则，并提供了优化指南。最后，它着重介绍了如何找到瓶颈。
- en: The three rules of optimization
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化的三条规则
- en: 'Optimization has a price, no matter what the results are. When a piece of code
    works, it might be better (sometimes) to leave it alone than to try making it
    faster at all costs. There are a few rules to keep in mind when doing any kind
    of optimization:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 优化是有代价的，无论结果如何。当一段代码工作时，也许最好（有时）是不要试图不惜一切代价使其更快。在进行任何优化时，有一些规则需要牢记：
- en: Make it work first
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先使其工作
- en: Work from the user's point of view
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从用户的角度出发
- en: Keep the code readable
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持代码可读
- en: Make it work first
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 首先使其工作
- en: A very common mistake is to try to optimize the code while you are writing it.
    This is mostly pointless because the real bottlenecks are often located where
    you would have never thought they would be.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常常见的错误是在编写代码时尝试对其进行优化。这在大多数情况下是毫无意义的，因为真正的瓶颈通常出现在你从未想到的地方。
- en: An application is usually composed of very complex interactions, and it is impossible
    to get a full picture of what is going on before it is really used.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序通常由非常复杂的交互组成，在真正使用之前，很难完全了解发生了什么。
- en: Of course, this is not a reason to write a function or a method without trying
    to make it as fast as possible. You should be careful to lower its complexity
    as much as possible and avoid useless repetition. But the first goal is to make
    it work. This goal should not be hindered by optimization efforts.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这并不是不尝试尽快使其运行的原因。您应该小心尽量降低其复杂性，并避免无用的重复。但第一个目标是使其工作。这个目标不应该被优化努力所阻碍。
- en: For line-level code, the Python philosophy is that there's one, and preferably
    only one, way to do it. So, as long as you stick with a Pythonic syntax, described
    in [Chapter 2](ch02.html "Chapter 2. Syntax Best Practices – below the Class Level"),
    *Syntax Best Practices – below the Class Level*, and [Chapter 3](ch03.html "Chapter 3. Syntax
    Best Practices – above the Class Level"), *Syntax Best Practices – above the Class
    Level*, your code should be fine. Often, writing less code is better and faster
    than writing more code.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代码的每一行，Python的哲学是有一种，最好只有一种方法来做。因此，只要你遵循Pythonic的语法，描述在[第2章](ch02.html "第2章。语法最佳实践-类级别以下")和[第3章](ch03.html
    "第3章。语法最佳实践-类级别以上")中描述的*语法最佳实践*，你的代码应该没问题。通常情况下，写更少的代码比写更多的代码更好更快。
- en: 'Don''t do any of these things until you have gotten your code working and you
    are ready to profile:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的代码能够工作并且你准备进行分析之前，不要做任何这些事情：
- en: Start to write a global dictionary to cache data for a function
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先编写一个全局字典来缓存函数的数据
- en: Think about externalizing a part of the code in C or hybrid languages such as
    Cython
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑将代码的一部分外部化为C或Cython等混合语言
- en: Look for external libraries to do some basic calculation
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找外部库来进行基本计算
- en: For very specialized areas, such as scientific calculation or games, the usage
    of specialized libraries and externalization might be unavoidable from the beginning.
    On the other hand, using libraries like NumPy might ease the development of specific
    features and produce simpler and faster code at the end. Furthermore, you should
    not rewrite a function if there is a good library that does it for you.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非常专业的领域，如科学计算或游戏，从一开始就使用专门的库和外部化可能是不可避免的。另一方面，使用像NumPy这样的库可能会简化特定功能的开发，并在最后产生更简单更快的代码。此外，如果有一个很好的库可以为你完成工作，你就不应该重写一个函数。
- en: For instance, Soya 3D, which is a game engine on top of OpenGL (see [http://home.gna.org/oomadness/en/soya3d/index.html](http://home.gna.org/oomadness/en/soya3d/index.html)),
    uses C and Pyrex for fast matrix operations when rendering real-time 3D.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Soya 3D是一个基于OpenGL的游戏引擎（参见[http://home.gna.org/oomadness/en/soya3d/index.html](http://home.gna.org/oomadness/en/soya3d/index.html)），在渲染实时3D时使用C和Pyrex进行快速矩阵运算。
- en: Note
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Optimization is carried out on programs that already work.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 优化是在已经工作的程序上进行的。
- en: As Kent Beck says, "Make it work, then make it right, then make it fast."
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Kent Beck所说，“先让它工作，然后让它正确，最后让它快。”
- en: Work from the user's point of view
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从用户的角度出发
- en: I have seen teams working on optimizing the startup time of an application server
    that worked really fine when it was already up and running. Once they finished
    speeding it, they promoted that work to their customers. They were a bit frustrated
    to notice that the customers didn't really care about it. This was because the
    speed-up work was not motivated by the user feedback but by the developer's point
    of view. The people who built the system were launching the server multiple times
    every day. So the startup time meant a lot to them but not to their customers.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾见过一些团队致力于优化应用服务器的启动时间，而当服务器已经运行良好时，他们可能更好（有时）是不要尝试不惜一切代价使其更快。在进行任何优化时，有一些规则需要牢记：
- en: 'While making a program start faster is a good thing from an absolute point
    of view, teams should be careful to prioritize the optimization work and ask themselves
    the following questions:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使程序启动更快从绝对角度来看是件好事，但团队应该谨慎地优先考虑优化工作，并问自己以下问题：
- en: Have I been asked to make it faster?
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我被要求使其更快了吗？
- en: Who finds the program slow?
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁发现程序运行缓慢？
- en: Is it really slow, or acceptable?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真的很慢，还是可以接受？
- en: How much will it cost to make it go faster and is it worth it?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使其更快需要多少成本，是否值得？
- en: What parts need to be fast?
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些部分需要快？
- en: Remember that optimization has a cost and that the developer's point of view
    is meaningless to customers, unless you are writing a framework or a library and
    the customer is a developer too.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，优化是有成本的，开发人员的观点对客户来说毫无意义，除非您正在编写一个框架或库，而客户也是开发人员。
- en: Note
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Optimization is not a game. It should be done only when necessary.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 优化不是一场游戏。只有在必要时才应该进行。
- en: Keep the code readable and maintainable
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保持代码可读和易于维护
- en: Even if Python tries to make the common code patterns the fastest, optimization
    work might obfuscate your code and make it really hard to read. There's a balance
    to keep between producing readable, and therefore maintainable, code and defacing
    it in order to make it faster.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 即使Python试图使常见的代码模式运行得最快，优化工作可能会使您的代码变得难以阅读。在产生可读且易于维护的代码与破坏代码以提高速度之间需要保持平衡。
- en: When you have reached 90% of your optimization objectives and the 10% left to
    be done makes your code completely unreadable, it might be a good idea to stop
    the work there or to look for other solutions.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当您达到90%的优化目标，并且剩下的10%使您的代码完全无法阅读时，最好停止工作或寻找其他解决方案。
- en: Note
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Optimization should not make your code unreadable. If it happens, you should
    look for alternative solutions such as externalization or redesign. Look for a
    good compromise between readability and speed.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 优化不应该使您的代码难以阅读。如果发生这种情况，您应该寻找替代解决方案，比如外部化或重新设计。要在可读性和速度之间寻找一个好的折衷方案。
- en: Optimization strategy
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化策略
- en: Let's say your program has a real speed problem you need to resolve. Do not
    try to guess how to make it faster. Bottlenecks are often hard to find by looking
    at the code, and a set of tools is needed to find the real problem.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您的程序存在真正的速度问题需要解决。不要试图猜测如何使其更快。瓶颈通常很难通过查看代码来找到，需要一组工具来找到真正的问题。
- en: 'A good optimization strategy can start with three steps:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个良好的优化策略可以从以下三个步骤开始：
- en: '**Find another culprit**: Make sure a third-party server or resource is not
    faulty'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**找到另一个罪魁祸首**：确保第三方服务器或资源没有故障'
- en: '**Scale the hardware**: Make sure the resources are sufficient'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展硬件**：确保资源足够'
- en: '**Write a speed test**: Create a scenario with speed objectives'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编写速度测试**：创建具有速度目标的场景'
- en: Find another culprit
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 找到另一个罪魁祸首
- en: Often, a performance problem occurs at production level and the customer alerts
    you that it is not working as it used to when the software was being tested. Performance
    problems might occur because the application was not planned to work in the real
    world with a high number of users and an increase of data size.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，性能问题发生在生产级别，客户通知您它的工作方式与软件测试时不同。性能问题可能是因为应用程序没有计划在现实世界中与大量用户和数据大小增加的情况下运行。
- en: But if the application interacts with other applications, the first thing to
    do is to check if the bottlenecks are located on those interactions. For instance,
    a database server or an LDAP server might be responsible for extra overhead and
    might make everything slower.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果应用程序与其他应用程序进行交互，首先要做的是检查瓶颈是否位于这些交互上。例如，数据库服务器或LDAP服务器可能会导致额外的开销，并使一切变慢。
- en: The physical links between applications should also be considered. Maybe the
    network link between your application server and another server in the intranet
    is really slow due to a misconfiguration or congestion.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序之间的物理链接也应该被考虑。也许您的应用程序服务器与内部网络中的另一台服务器之间的网络链接由于错误配置或拥塞而变得非常缓慢。
- en: The design documentation should provide a diagram of all interactions and the
    nature of each link to get an overall picture of the system and offer help when
    trying to resolve a speed problem.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 设计文档应提供所有交互的图表和每个链接的性质，以便全面了解系统并在尝试解决速度问题时提供帮助。
- en: Note
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If your application uses third-party servers of resources, every interaction
    should be audited to make sure the bottleneck is not located there.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的应用程序使用第三方服务器或资源，每次交互都应该经过审计，以确保瓶颈不在那里。
- en: Scale the hardware
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展硬件
- en: When there is no more volatile memory available, the system starts to use the
    hard disk to store data. This is swapping.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当没有更多的易失性内存可用时，系统开始使用硬盘来存储数据。这就是交换。
- en: This involves a lot of overhead and the performances drop drastically. From
    a user's point of view, the system is considered dead at this stage. So, it is
    important to scale the hardware to prevent this.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这会带来很多额外开销，并且性能会急剧下降。从用户的角度来看，系统在这个阶段被认为已经死机。因此，扩展硬件以防止这种情况发生非常重要。
- en: While having enough memory on a system is important, it is also important to
    make sure that the applications are not acting crazy and eating too much memory.
    For instance, if a program works on big video files that can weigh in at several
    hundreds of megabytes, it should not load them entirely in memory but rather work
    on chunks or use disk streams.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然系统上有足够的内存很重要，但确保应用程序不会表现出异常行为并占用过多内存也很重要。例如，如果一个程序处理几百兆大小的大型视频文件，它不应该完全将它们加载到内存中，而是应该分块处理或使用磁盘流。
- en: Disk usage is also important. A full partition might really slow down your application
    if the I/O errors are hidden in the code that tries to write repeatedly on the
    disk. Furthermore, even if the code only tries to write once, the hardware and
    OS might try to write multiple times.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 磁盘使用也很重要。如果I/O错误隐藏在试图反复写入磁盘的代码中，分区已满可能会严重减慢应用程序。此外，即使代码只尝试写入一次，硬件和操作系统也可能尝试多次写入。
- en: Note that scaling up the hardware (vertical scaling) has some obvious limitations.
    You cannot fit an infinite amount of hardware to a single rack. Also, highly efficient
    hardware is extremely expensive (law of diminishing returns), so there is also
    an economical bound to this approach. From this point of view, it is always better
    to have the system that can be scaled by adding new computation nodes or workers
    (horizontal scaling). This allows you to scale out your service with commodity
    software that has the best performance/price ratio.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，升级硬件（垂直扩展）有一些明显的限制。你无法将无限量的硬件放入一个机架中。此外，高效的硬件价格极其昂贵（收益递减定律），因此这种方法也有经济上的限制。从这个角度来看，总是更好的是拥有可以通过添加新的计算节点或工作节点（水平扩展）来扩展的系统。这样可以使用性价比最高的商品软件来扩展服务。
- en: Unfortunately, designing and maintaining highly scalable distributed systems
    is both hard and expensive. If your system cannot be easily scaled horizontally
    or it is faster and cheaper to scale it vertically, it may be better to do so
    instead of wasting time and resources on a total redesign of your system architecture.
    Remember that hardware invariably tends to be faster and cheaper with time. Many
    products stay in this sweet spot where their scaling needs align with the trend
    of raising hardware performance.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，设计和维护高度可扩展的分布式系统既困难又昂贵。如果你的系统不能轻松地进行水平扩展，或者垂直扩展更快更便宜，那么最好选择这种方法，而不是在系统架构的全面重新设计上浪费时间和资源。请记住，硬件的性能和价格总是随时间变得更快更便宜。许多产品都处于这种甜蜜点，它们的扩展需求与提高硬件性能的趋势相一致。
- en: Writing a speed test
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写速度测试
- en: When starting with optimization work, it is important to work using a workflow
    similar to test-driven development rather than running some manual tests continuously.
    A good practice is to dedicate a test module in the application where the sequence
    of calls that are to be optimized is written. Having this scenario will help you
    to track your progress while you are optimizing the application.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始优化工作时，重要的是使用类似于测试驱动开发的工作流程，而不是不断地运行一些手动测试。一个好的做法是在应用程序中专门设置一个测试模块，其中编写了需要优化的调用序列。有了这种情景，您在优化应用程序时将有助于跟踪您的进展。
- en: 'You can even write a few assertions where you set some speed objectives. To
    prevent speed regression, these tests can be left after the code has been optimized:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至可以编写一些断言，设置一些速度目标。为了防止速度回归，这些测试可以在代码优化后留下：
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Measuring the execution speed depends on the power of the CPU used. But we will
    see in the next section how to write universal duration measures.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 测量执行速度取决于所使用的CPU的性能。但是我们将在下一节中看到如何编写通用的持续时间测量。
- en: Finding bottlenecks
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 找到瓶颈
- en: 'Finding bottlenecks is done by:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下方式找到瓶颈：
- en: Profiling CPU usage
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析CPU使用情况
- en: Profiling memory usage
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析内存使用情况
- en: Profiling network usage
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析网络使用情况
- en: Profiling CPU usage
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析CPU使用情况
- en: The first source of bottlenecks is your code. The standard library provides
    all the tools needed to perform code profiling. They are based on a deterministic
    approach.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 瓶颈的第一个来源是你的代码。标准库提供了执行代码分析所需的所有工具。它们基于确定性方法。
- en: A **deterministic profiler** measures the time spent in each function by adding
    a timer at the lowest level. This introduces a bit of overhead but provides a
    good idea on where the time is consumed. A **statistical profiler**, on the other
    hand, samples the instruction pointer usage and does not instrument the code.
    The latter is less accurate but allows running the target program at full speed.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**确定性分析器**通过在最低级别添加计时器来测量每个函数中花费的时间。这会引入一些开销，但可以很好地了解时间消耗在哪里。另一方面，**统计分析器**对指令指针的使用进行采样，不会对代码进行仪器化。后者不够准确，但允许以全速运行目标程序。'
- en: 'There are two ways to profile the code:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以对代码进行分析：
- en: '**Macro-profiling**: This profiles the whole program while it is being used
    and generates statistics'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 宏观分析：在程序运行时对整个程序进行分析并生成统计数据
- en: '**Micro-profiling**: This measures a precise part of the program by instrumenting
    it manually'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微观分析：通过手动对程序的精确部分进行仪器化来测量
- en: Macro-profiling
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 宏观分析
- en: 'Macro-profiling is done by running the application in a special mode where
    the interpreter is instrumented to collect statistics on the code usage. Python
    provides several tools for this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 宏观分析是通过以特殊模式运行应用程序来完成的，解释器被仪器化以收集代码使用统计信息。Python提供了几种工具来实现这一点：
- en: '`profile`: This is a pure Python implementation'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`profile`：这是一个纯Python实现'
- en: '`cProfile`: This is a C implementation that provides the same interface as
    that of the `profile` tool but has less overhead'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cProfile`：这是一个C实现，提供了与`profile`工具相同的接口，但开销较小'
- en: The recommended choice for most Python programmers is `cProfile` due to its
    reduced overhead. Anyway, if you need to extend the profiler in some way, then
    `profile` will probably be a better choice because it does not use C extensions.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对大多数Python程序员来说，由于其开销较小，推荐的选择是`cProfile`。无论如何，如果需要以某种方式扩展分析器，那么`profile`可能是更好的选择，因为它不使用C扩展。
- en: 'Both tools have the same interface and usage, so we will use only one of them
    to show how they work. The following is a `myapp.py` module with a main function
    that we are going to test with `cProfile`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种工具具有相同的接口和用法，因此我们将只使用其中一个来展示它们的工作原理。以下是一个`myapp.py`模块，其中包含一个我们将使用`cProfile`测试的主函数：
- en: '[PRE1]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The module can be called directly from the prompt and the results are summarized
    here:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 该模块可以直接从提示符中调用，并在此处总结结果：
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The statistics provided are a print view of a statistic object filled by the
    profiler. A manual invocation of the tool can be:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的统计数据是由分析器填充的统计对象的打印视图。可以手动调用该工具：
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The statistics can also be saved in a file and then read by the `pstats` module.
    This module provides a class that knows how to handle profile files and gives
    a few helpers to play with them invocation:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 统计数据也可以保存在文件中，然后由`pstats`模块读取。该模块提供了一个知道如何处理分析文件并提供一些辅助功能的类的调用：
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'From there, you can browse the code by printing out the callers and callees
    for each function:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，您可以通过打印每个函数的调用者和被调用者来浏览代码：
- en: '[PRE5]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Being able to sort the output allows working on different views to find the
    bottlenecks. For instance, consider the following scenarios:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 能够对输出进行排序可以在不同的视图上查找瓶颈。例如，考虑以下情景：
- en: When the number of calls is really high and takes up most of the global time,
    the function or method is probably in a loop. Possible optimization may be done
    by moving this call to different scope in order to reduce number of operations
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当调用次数非常高并且占用大部分全局时间时，该函数或方法可能在循环中。通过将此调用移动到不同的范围以减少操作次数，可能可以进行可能的优化
- en: When one function is taking very long time, a cache might be a good option,
    if possible
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当一个函数执行时间很长时，如果可能的话，缓存可能是一个不错的选择
- en: 'Another great way to visualize bottlenecks from profiling data is to transform
    them into diagrams (see *Figure 1*). **Gprof2Dot** ([https://github.com/jrfonseca/gprof2dot](https://github.com/jrfonseca/gprof2dot))
    can be used to turn profiler data into a dot graph. You can download this simple
    script PyPI using `pip` and use it on the stats as long as Graphviz (see [http://www.graphviz.org/](http://www.graphviz.org/))
    is installed in your environment:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从分析数据中可视化瓶颈的另一个好方法是将它们转换成图表（见*图1*）。**Gprof2Dot**（[https://github.com/jrfonseca/gprof2dot](https://github.com/jrfonseca/gprof2dot)）可以将分析器数据转换为点图。您可以使用`pip`从PyPI下载这个简单的脚本，并在安装了Graphviz（参见[http://www.graphviz.org/](http://www.graphviz.org/)）的环境中使用它：
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The advantage of `gprof2dot` is that it tries to be language agnostic. It is
    not limited to Python `profile` or `cProfile` output and can read from multiple
    other profiles such as Linux perf, xperf, gprof, Java HPROF, and many others.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`gprof2dot`的优势在于它试图成为一种语言无关的工具。它不仅限于Python `profile`或`cProfile`的输出，还可以从多个其他配置文件中读取，比如Linux
    perf、xperf、gprof、Java HPROF等等。'
- en: '![Macro-profiling](graphics/B05295_11_01.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![宏观分析](graphics/B05295_11_01.jpg)'
- en: Figure 1 An example of profiling overview diagram generated with gprof2dot
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图1 使用gprof2dot生成的分析概览图的示例
- en: Macro-profiling is a good way to detect the function that has a problem, or
    at least its neighborhood. When you have found it, you can jump to micro-profiling.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 宏观分析是检测有问题的函数或者它的周边的一个好方法。当你找到它之后，你可以转向微观分析。
- en: Micro-profiling
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微观分析
- en: When the slow function is found, it is sometimes necessary to do more profiling
    work that tests just a part of the program. This is done by manually instrumenting
    a part of the code in a speed test.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当找到慢函数时，有时需要进行更多的分析工作，测试程序的一部分。这是通过手动在代码的一部分进行仪器化速度测试来完成的。
- en: 'For instance, the `cProfile` module can be used from a decorator:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，可以使用`cProfile`模块作为装饰器：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This approach allows testing parts of the application and sharpens the statistics
    output. But at this stage, having a list of callees is probably not interesting,
    as the function has already been pointed out as the one to optimize. The only
    interesting information is to know how fast it is, and then enhance it.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法允许测试应用程序的部分，并锐化统计输出。但在这个阶段，拥有一个调用者列表可能并不有趣，因为函数已经被指出为需要优化的函数。唯一有趣的信息是知道它有多快，然后加以改进。
- en: '`timeit` fits this need better by providing a simple way to measure the execution
    time of a small code snippet with the best underlying timer the host system provides
    (`time.time` or `time.clock`):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`timeit`更适合这种需求，它提供了一种简单的方法来测量小代码片段的执行时间，使用主机系统提供的最佳底层计时器（`time.time`或`time.clock`）：'
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The module allows you to repeat the call and is oriented to try out isolated
    code snippets. This is very useful outside the application context, in a prompt,
    for instance, but is not really handy to use within an existing application.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 该模块允许您重复调用，并且旨在尝试独立的代码片段。这在应用程序上下文之外非常有用，比如在提示符中，但在现有应用程序中使用起来并不方便。
- en: Note
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注
- en: A deterministic profiler will provide results depending on what the computer
    is doing, and so results may vary each time. Repeating the same test multiple
    times and making averages provides more accurate results. Furthermore, some computers
    have special CPU features, such as **SpeedStep**, that might change the results
    if the computer is idling when the test is launched (see [http://en.wikipedia.org/wiki/SpeedStep](http://en.wikipedia.org/wiki/SpeedStep)).
    So, continually repeating the test is a good practice for small code snippets.
    There are also various caches to keep in mind such as DNS caches or CPU caches.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 确定性分析器将根据计算机正在执行的操作提供结果，因此结果可能每次都会有所不同。多次重复相同的测试并进行平均值计算可以提供更准确的结果。此外，一些计算机具有特殊的CPU功能，例如**SpeedStep**，如果计算机在启动测试时处于空闲状态，可能会改变结果（参见[http://en.wikipedia.org/wiki/SpeedStep](http://en.wikipedia.org/wiki/SpeedStep)）。因此，对小代码片段进行持续重复测试是一个好的做法。还有一些其他缓存需要记住，比如DNS缓存或CPU缓存。
- en: 'But the results of `timeit` should be used with caution. It is a very good
    tool to objectively compare two short snippets of code but it also allows you
    to easily make dangerous mistakes that will lead you to confusing conclusions.
    Here, for example, is the comparison of two innocent snippets of code with the
    `timeit` module that could make you think that string concatenation by addition
    is faster than the `str.join()` method:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 但`timeit`的结果应该谨慎使用。它是一个非常好的工具，可以客观比较两个短代码片段，但也容易让您犯下危险的错误，导致令人困惑的结论。例如，使用`timeit`模块比较两个无害的代码片段，可能会让您认为通过加法进行字符串连接比`str.join()`方法更快：
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'From [Chapter 2](ch02.html "Chapter 2. Syntax Best Practices – below the Class
    Level"), *Syntax Best Practices – below the Class Level*, we know that string
    concatenation by addition in not a good pattern. Despite there are some minor
    CPython micro-optimizations designed exactly for such use case, it will eventually
    lead to quadratic run time. The problem lies in nuances about the `setup` argument
    of `timeit` (`-s` parameter in the command line) and how the range in Python 3
    works. I won''t discuss the details of the problem but will leave it to you as
    an exercise. Anyway, here is the correct way to compare string concatenation in
    addition with the `str.join()` idiom under Python 3:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 从[第2章](ch02.html "第2章。类级别以下的语法最佳实践") *语法最佳实践 - 类级别以下*，我们知道通过加法进行字符串连接不是一个好的模式。尽管有一些微小的CPython微优化专门为这种用例设计，但最终会导致二次运行时间。问题在于`timeit`的`setup`参数（命令行中的`-s`参数）以及Python
    3中范围的工作方式的细微差别。我不会讨论问题的细节，而是留给您作为练习。无论如何，以下是在Python 3中使用`str.join()`习惯用法来比较字符串连接的正确方法：
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Measuring Pystones
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测量Pystones
- en: When measuring execution time, the result depends on the computer hardware.
    To be able to produce a universal measure, the simplest way is to benchmark the
    speed of a fixed sequence of code and calculate a ratio out of it. From there,
    the time taken by a function can be translated to a universal value that can be
    compared on any computer.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在测量执行时间时，结果取决于计算机硬件。为了能够产生一个通用的度量，最简单的方法是对一段固定的代码序列进行速度基准测试，并计算出一个比率。从那里，函数所花费的时间可以转换为一个通用值，可以在任何计算机上进行比较。
- en: Note
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注
- en: A lot of generic benchmarking tools for the measurement of computer performance
    are available. Surprisingly, some of them that were created many years ago are
    still used today. For instance, Whetstone was created in 1972, and back then it
    provided a computer performance analyzer in Algol 60 (see [http://en.wikipedia.org/wiki/Whetstone_%28benchmark%29](http://en.wikipedia.org/wiki/Whetstone_%28benchmark%29)).
    It is used to measure the **Millions Of Whetstone Instructions Per Second** (**MWIPS**).
    A table of results for old and modern CPUs is maintained at [http://freespace.virgin.net/roy.longbottom/whetstone%20results.htm](http://freespace.virgin.net/roy.longbottom/whetstone%20results.htm).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多用于测量计算机性能的通用基准测试工具。令人惊讶的是，一些很多年前创建的工具今天仍在使用。例如，Whetstone是在1972年创建的，当时它提供了一种Algol
    60的计算机性能分析器。它用于测量**每秒Whetstone百万条指令**（**MWIPS**）。在[http://freespace.virgin.net/roy.longbottom/whetstone%20results.htm](http://freespace.virgin.net/roy.longbottom/whetstone%20results.htm)上维护了一张旧CPU和现代CPU的结果表。
- en: 'Python provides a benchmark utility in its `test` package that measures the
    duration of a sequence of well-chosen operations. The result is a number of **pystones**
    per second the computer is able to perform and the time used to perform the benchmark,
    which is generally around one second on modern hardware:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Python在其`test`包中提供了一个基准测试工具，用于测量一系列精心选择的操作的持续时间。结果是计算机每秒能够执行的**pystones**数量，以及执行基准测试所用的时间，通常在现代硬件上大约为一秒：
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The rate can be used to translate a profile duration into a number of pystones:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 速率可以用来将配置持续时间转换为一定数量的pystones：
- en: '[PRE12]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `seconds_to_kpystones` returns the number of **kilo pystones**. This conversion
    can be included in your test if you want to code some speed assertions.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`seconds_to_kpystones`返回**千pystones**的数量。如果您想对执行速度进行编码，这种转换可以包含在您的测试中。'
- en: Having pystones will allow you to use this decorator in tests so that you can
    set assertions on execution times. These tests will be runnable on any computer
    and will allow developers to prevent speed regressions. When a part of the application
    has been optimized, they will be able to set its maximum execution time in tests
    and make sure it won't be breached by further changes. This approach is, of course,
    not ideal and 100% accurate, but it is at least better than hardcoding execution
    time assertions in raw values expressed as seconds.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有pystones将允许您在测试中使用这个装饰器，以便您可以对执行时间进行断言。这些测试将在任何计算机上都可以运行，并且将允许开发人员防止速度回归。当应用程序的一部分被优化后，他们将能够在测试中设置其最大执行时间，并确保它不会被进一步的更改所违反。这种方法当然不是理想的，也不是100%准确的，但至少比将执行时间断言硬编码为以秒为单位的原始值要好。
- en: Profiling memory usage
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存使用情况
- en: Another problem you may encounter when optimizing an application is memory consumption.
    If a program starts to eat so much memory that the system begins to swap, there
    is probably a place in your application where too many objects are created or
    objects that you don't intend to keep are still kept alive by some unintended
    reference. This is often easy to detect through classical profiling because consuming
    enough memory to make a system swap involves a lot of CPU work that can be detected.
    But sometimes it is not obvious and the memory usage has to be profiled.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 优化应用程序时可能遇到的另一个问题是内存消耗。如果程序开始占用太多内存，以至于系统开始交换，那么您的应用程序中可能存在太多对象被创建的地方，或者您并不打算保留的对象仍然被一些意外的引用保持活动。这通常很容易通过经典的分析来检测，因为消耗足够的内存使系统交换涉及到很多可以被检测到的CPU工作。但有时候这并不明显，内存使用情况必须进行分析。
- en: How Python deals with memory
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python如何处理内存
- en: Memory usage is probably the hardest thing to profile in Python when you use
    the CPython implementation. While languages such as C allow you to get the memory
    size of any element, Python will never let you know how much a given object consumes.
    This is due to the dynamic nature of the language, and the fact that memory management
    is not directly accessible to the language user.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用CPython实现时，内存使用可能是Python中最难进行分析的事情。虽然像C这样的语言允许您获取任何元素的内存大小，但Python永远不会让您知道给定对象消耗了多少内存。这是由于语言的动态性质，以及内存管理不直接可访问给语言用户。
- en: Some raw details of memory management were already explained in [Chapter 7](ch07.html
    "Chapter 7. Python Extensions in Other Languages"), *Python Extensions in Other
    Languages*. We already know that CPython uses reference counting to manage object
    allocation. This is the deterministic algorithm which ensures that object deallocation
    will be triggered when the reference count of the object goes to zero. Despite
    being deterministic, this process is not easy to track manually and to reason
    about in complex codebases. Also, the deallocation of objects on a reference count
    level does not necessarily mean that the actual process heap memory is freed by
    the interpreter. Depending on CPython interpreter compilation flags, system environment,
    or runtime context, the internal memory manager layer might decide to leave some
    blocks of free memory for future reallocation instead of releasing it completely.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 内存管理的一些原始细节已经在[第7章](ch07.html "第7章。其他语言中的Python扩展")中解释过了，*其他语言中的Python扩展*。我们已经知道CPython使用引用计数来管理对象分配。这是一种确定性算法，可以确保当对象的引用计数降至零时，将触发对象的释放。尽管是确定性的，但这个过程不容易在复杂的代码库中手动跟踪和推理。此外，根据CPython解释器的编译标志、系统环境或运行时上下文，内部内存管理器层可能决定留下一些空闲内存块以便将来重新分配，而不是完全释放它。
- en: Additional micro-optimizations in CPython implementation also make it even harder
    to predict actual memory usage. For instance, two variables that point to the
    same short string or small integer value might or might not point to the same
    object instance in memory.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: CPython实现中的额外微优化也使得预测实际内存使用变得更加困难。例如，指向相同短字符串或小整数值的两个变量可能指向内存中的同一个对象实例，也可能不是。
- en: 'Despite being quite scary and seemingly complex, memory management in Python
    is very well documented (refer to [https://docs.python.org/3/c-api/memory.html](https://docs.python.org/3/c-api/memory.html)).
    Note that, micro-optimizations mentioned earlier can, in most cases, be ignored
    when debugging memory issues. Also, reference counting is roughly based on a simple
    statement—if a given object is not referenced anymore, it is removed. In other
    words, all local references in a function are removed after the interpreter:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管看起来相当可怕和复杂，但Python中的内存管理有很好的文档记录（参考[https://docs.python.org/3/c-api/memory.html](https://docs.python.org/3/c-api/memory.html)）。请注意，在调试内存问题时，大多数情况下可以忽略之前提到的微优化。此外，引用计数基本上是基于一个简单的陈述——如果给定对象不再被引用，它就会被移除。换句话说，在解释器之后，函数中的所有局部引用都会被移除。
- en: Leaves the function
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离开函数
- en: Makes sure the object is not being used anymore
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保对象不再被使用
- en: 'So, objects that remain in memory are:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，仍然在内存中的对象有：
- en: Global objects
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全局对象
- en: Objects that are still referenced in some way
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仍然以某种方式被引用的对象
- en: 'Be careful with the **argument** **inbound** **outbound** edge case. If an
    object is created within the arguments, the argument reference will still be alive
    if the function returns the object. This can lead to unexpected results if it
    is used as a default value:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要小心**参数** **入站** **出站**的边缘情况。如果在参数中创建了一个对象，如果函数返回该对象，则参数引用仍然存在。如果将其用作默认值，可能会导致意外结果：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'That is why nonmutable objects should always be used, like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么应该始终使用不可变对象的原因，就像这样：
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Reference counting in Python is handy and frees you from the obligation of manually
    tracking object references of objects, and therefore you don't have to manually
    destroy them. Although this introduces another problem, since developers never
    clean up instances in memory, it might grow in an uncontrolled way if developers
    don't pay attention to the way they use their data structures.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的引用计数很方便，可以免除手动跟踪对象引用和手动销毁对象的义务。尽管这引入了另一个问题，即开发人员从不清理内存中的实例，如果开发人员不注意使用数据结构的方式，它可能会以不受控制的方式增长。
- en: 'The usual memory eaters are:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的内存占用者有：
- en: Caches that grow uncontrolled
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不受控制地增长的缓存
- en: Object factories that register instances globally and do not keep track of their
    usage, such as a database connector creator used on the fly every time a query
    is called
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全局注册实例的对象工厂，并且不跟踪它们的使用情况，比如每次调用查询时都会使用的数据库连接器创建者
- en: Threads that are not properly finished
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程没有正确完成
- en: Objects with a `__del__` method and involved in a cycle are also memory eaters.
    In older versions of Python (prior to 3.4 version), the garbage collector will
    not break the cycle since it cannot be sure which object should be deleted first.
    Hence, you will leak memory. Using this method is a bad idea in most cases.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有`__del__`方法并涉及循环的对象也会占用内存。在Python的旧版本（3.4版本之前），垃圾收集器不会打破循环，因为它无法确定应该先删除哪个对象。因此，会造成内存泄漏。在大多数情况下，使用这种方法都是一个坏主意。
- en: Unfortunately, the management of reference counts must be done manually in C
    extensions using Python/C API with `Py_INCREF()` and `Py_DECREF()` macros. We
    discussed caveats of handling reference counts and reference ownership earlier
    in [Chapter 7](ch07.html "Chapter 7. Python Extensions in Other Languages"), *Python
    Extensions in Other Languages*, so you should already know that it is a pretty
    hard topic riddled with various pitfalls. This is the reason why most memory issues
    are caused by C extensions that are not written properly.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在使用Python/C API的C扩展中，必须手动管理引用计数和引用所有权，使用`Py_INCREF()`和`Py_DECREF()`宏。我们在[第7章](ch07.html
    "第7章。其他语言中的Python扩展")中已经讨论了处理引用计数和引用所有权的注意事项，所以你应该已经知道这是一个充满各种陷阱的相当困难的话题。这就是为什么大多数内存问题是由没有正确编写的C扩展引起的。
- en: Profiling memory
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存分析
- en: Before starting to hunt down memory issues in Python, you should know that the
    nature of memory leaks in Python is quite special. In some of the compiled languages
    such as C and C++, the memory leaks are almost exclusively caused by allocated
    memory blocks that are no longer referenced by any pointer. If you don't have
    reference to memory, you cannot release it, and this very situation is called
    a *memory leak*. In Python, there is no low level memory management available
    for the user, so we rather deal with leaking references—references to objects
    that are not needed anymore but were not removed. This stops the interpreter from
    releasing resources but is not the same situation as a memory leak in C. Of course,
    there is always the exceptional case of C extensions, but they are a different
    kind of beast that need completely different tool chains and cannot be easily
    inspected from Python code.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始解决Python中的内存问题之前，您应该知道Python中内存泄漏的性质是非常特殊的。在一些编译语言如C和C++中，内存泄漏几乎完全是由不再被任何指针引用的分配的内存块引起的。如果您没有对内存的引用，就无法释放它，这种情况被称为*内存泄漏*。在Python中，用户没有低级内存管理，所以我们更多地处理泄漏的引用——对不再需要但未被移除的对象的引用。这会阻止解释器释放资源，但与C中的内存泄漏情况不同。当然，也总是有C扩展的特殊情况，但它们是一种完全不同类型的东西，需要完全不同的工具链，而且不能轻易从Python代码中检查。
- en: So, memory issues in Python are mostly caused by unexpected or unplanned resource
    acquiring patterns. It happens very rarely that this is an effect of real bugs
    caused by the mishandling of memory allocation and deallocation routines. Such
    routines are available to the developer only in CPython when writing C extension
    with Python/C APIs and you will deal with them very rarely, if ever. Thus, most
    so-called memory leaks in Python are mostly caused by the overblown complexity
    of the software and minor interactions between its components that are really
    hard to track. In order to spot and locate such deficiencies of your software,
    you need to know how an actual memory usage looks in the program.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Python中的内存问题主要是由意外或非计划的资源获取模式引起的。很少情况下，这是由于内存分配和释放例程的错误处理引起的真正错误。这样的例程只在CPython中在使用Python/C
    API编写C扩展时才对开发人员可用，而且很少会遇到。因此，Python中所谓的内存泄漏主要是由软件的过度复杂性和其组件之间的次要交互引起的，这些问题很难追踪。为了发现和定位软件的这些缺陷，您需要了解程序中实际内存使用的情况。
- en: Getting information about how many objects are controlled by the Python interpreter
    and about their real size is a bit tricky. For instance, knowing how much a given
    object weighs in bytes would involve crawling down all its attributes, dealing
    with cross-references and then summing up everything. It's a pretty difficult
    problem if you consider the way objects tend to refer to each other. The `gc`
    module does not provide high-level functions for this, and it would require Python
    to be compiled in debug mode to have a full set of information.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 获取有关由Python解释器控制的对象数量及其实际大小的信息有点棘手。例如，要知道给定对象的大小需要遍历其所有属性，处理交叉引用，然后将所有内容相加。如果考虑到对象相互引用的方式，这是一个相当困难的问题。`gc`模块没有为此提供高级函数，而且需要Python以调试模式编译才能获得完整的信息。
- en: Often, programmers just ask the system about the memory usage of their application
    after and before a given operation has been performed. But this measure is an
    approximation and depends a lot on how the memory is managed at system level.
    Using the `top` command under Linux or the Task Manager under Windows, for instance,
    makes it possible to detect memory problems when they are obvious. But this approach
    is laborious and makes it really hard to track down the faulty code block.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，程序员在执行给定操作之后和之前会询问系统关于其应用程序的内存使用情况。但这种测量是一种近似值，很大程度上取决于系统级别的内存管理方式。例如，在Linux下使用`top`命令或在Windows下使用任务管理器，可以在内存问题明显时检测到内存问题。但这种方法很费力，使得很难追踪到有问题的代码块。
- en: Fortunately, there are a few tools available to make memory snapshots and calculate
    the number and size of loaded objects. But let's keep in mind that Python does
    not release memory easily, preferring to hold on to it in case it is needed again.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有一些工具可以创建内存快照并计算加载对象的数量和大小。但让我们记住，Python不会轻易释放内存，它更愿意保留内存以防再次需要。
- en: 'For some time, one of most popular tools to use when debugging memory issues
    and usage in Python was Guppy-PE and its Heapy component. Unfortunately, it seems
    to be no longer maintained and it lacks Python 3 support. Luckily, there are some
    other alternatives that are Python 3 compatible to some extent:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 有一段时间，调试Python中的内存问题和使用情况时最流行的工具之一是Guppy-PE及其Heapy组件。不幸的是，它似乎已不再维护，并且缺乏Python
    3支持。幸运的是，还有一些其他替代方案在某种程度上与Python 3兼容：
- en: '**Memprof** ([http://jmdana.github.io/memprof/](http://jmdana.github.io/memprof/)):
    It is declared to work on Python 2.6, 2.7, 3.1, 3.2, and 3.3 and some POSIX-compliant
    systems (Mac OS X and Linux)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Memprof** ([http://jmdana.github.io/memprof/](http://jmdana.github.io/memprof/))：宣称可在Python
    2.6、2.7、3.1、3.2和3.3以及一些符合POSIX标准的系统（Mac OS X和Linux）上运行'
- en: '**memory_profiler** ([https://pypi.python.org/pypi/memory_profiler](https://pypi.python.org/pypi/memory_profiler)):
    It is declared to support the same Python versions and systems as Memprof'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**memory_profiler** ([https://pypi.python.org/pypi/memory_profiler](https://pypi.python.org/pypi/memory_profiler))：宣称支持与Memprof相同的Python版本和系统'
- en: '**Pympler** ([http://pythonhosted.org/Pympler/](http://pythonhosted.org/Pympler/)):
    It is declared to support Python 2.5, 2.6, 2.7, 3.1, 3.2, 3.3, and 3.4 and to
    be OS independent'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pympler** ([http://pythonhosted.org/Pympler/](http://pythonhosted.org/Pympler/))：宣称支持Python
    2.5、2.6、2.7、3.1、3.2、3.3和3.4，并且与操作系统无关'
- en: Note that the preceding information is based purely on trove classifiers used
    by the latest distributions of featured packages. This could easily change in
    the time after this book was written. Nevertheless, there is one package that
    currently supports the widest spectrum of Python versions and is also known to
    work flawlessly under Python 3.5\. It is `objgraph`. Its APIs seem to be a bit
    clumsy and have a very limited set of functionalities. But it works, does well
    what it needs to and is really easy to use. Memory instrumentation is not a thing
    that is added to the production code permanently, so this tool does not need to
    be pretty. Because of its wide support of Python versions in OS independence,
    we will focus only on `objgraph` when discussing examples of memory profiling.
    The other tools mentioned in this section are also exciting pieces of software
    but you need to research them by yourself.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面的信息纯粹基于最新版本的特色软件包使用的trove分类器。这可能会在本书编写后的时间内轻松更改。尽管如此，目前有一个软件包支持最广泛的Python版本，并且也已知在Python
    3.5下完美运行。它就是`objgraph`。它的API似乎有点笨拙，并且功能集非常有限。但它工作正常，做了它需要做的事情，并且非常容易使用。内存检测不是永久添加到生产代码中的东西，因此这个工具不需要很漂亮。由于它在OS独立性中支持Python版本的广泛支持，我们在讨论内存分析示例时将只关注`objgraph`。本节提到的其他工具也是令人兴奋的软件，但您需要自行研究它们。
- en: objgraph
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: objgraph
- en: '`objgraph` (refer to [http://mg.pov.lt/objgraph/](http://mg.pov.lt/objgraph/))
    is a simple tool for creating diagrams of object references that should be useful
    when hunting memory leaks in Python. It is available on PyPI but it is not a completely
    standalone tool and requires Graphviz in order to create memory usage diagrams.
    For developer-friendly systems like Mac OS X or Linux, you can easily obtain it
    using your preferred system package manager. For Windows, you need to download
    the Graphviz installer from the project page (refer to [http://www.graphviz.org/](http://www.graphviz.org/))
    and install it manually.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`objgraph`（参见[http://mg.pov.lt/objgraph/](http://mg.pov.lt/objgraph/)）是一个简单的工具，用于创建对象引用的图表，应该在查找Python内存泄漏时非常有用。它可以在PyPI上找到，但它不是一个完全独立的工具，需要Graphviz来创建内存使用图表。对于像Mac
    OS X或Linux这样的开发人员友好的系统，您可以使用您喜欢的系统包管理器轻松获取它。对于Windows，您需要从项目页面（参见[http://www.graphviz.org/](http://www.graphviz.org/)）下载Graphviz安装程序并手动安装。'
- en: '`objgraph` provides multiple utilities that allow you to list and print various
    statistics about memory usage and object counts. An example of such utilities
    in use is shown in the following transcript of interpreter session.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`objgraph` 提供了多种实用工具，允许您列出和打印有关内存使用和对象计数的各种统计信息。以下是一个使用这些实用程序的示例，显示了解释器会话的转录。'
- en: '[PRE15]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As already said, `objgraph` allows you to create diagrams of memory usage patterns
    and cross-references that link all the objects in the given namespace. The most
    useful diagramming utilities of that library are `objgraph.show_refs()` and `objgraph.show_backrefs()`.
    They both accept reference to the object being inspected and save a diagram image
    to file using the Graphviz package. Examples of such graphs are presented in *Figure
    2* and *Figure 3*.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`objgraph`允许您创建内存使用模式和交叉引用的图表。该库最有用的图表工具是`objgraph.show_refs()`和`objgraph.show_backrefs()`。它们都接受对被检查对象的引用，并使用Graphviz包将图表图像保存到文件中。这些图的示例在*图2*和*图3*中呈现。
- en: 'Here is the code that was used to create these diagrams:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是用于创建这些图表的代码：
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*Figure 2* shows the diagram of all references hold by `x` and `y` objects.
    From top to bottom and left to right it presents exactly four objects:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2*显示了由`x`和`y`对象持有的所有引用的图表。从上到下，从左到右，它确切地呈现了四个对象：'
- en: '`y = [x, [x], dict(x=x)]` list instance'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y = [x, [x], dict(x=x)]` 列表实例'
- en: '`dict(x=x)` dictionary instance'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dict(x=x)` 字典实例'
- en: '`[x]` list instance'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[x]` 列表实例'
- en: '`x = []` list instance'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x = []` 列表实例'
- en: '![objgraph](graphics/B05295_11_02.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![objgraph](graphics/B05295_11_02.jpg)'
- en: Figure 2 An example result of the show_refs() diagram from the example() function
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图2 `show_refs()` 函数的示例结果
- en: '*Figure 3* shows not only references between `x` and `y` but also all the objects
    that hold references to these two instances. There are so-called back references
    and are really helpful in finding objects that stop other objects from being deallocated.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3*不仅显示了`x`和`y`之间的引用，还显示了所有持有对这两个实例的引用的对象。这些被称为反向引用，对于找到阻止其他对象被释放的对象非常有帮助。'
- en: '![objgraph](graphics/B05295_11_03.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![objgraph](graphics/B05295_11_03.jpg)'
- en: Figure 3 An example result of the show_backrefs() diagram from the example()
    function
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图3 `show_backrefs()` 函数的示例结果
- en: 'In order to show how `objgraph` may be used in practice, let''s review some
    practical examples. As we have already noted a few times in this book, CPython
    has its own garbage collector that exists independently from its reference counting
    method. It''s not used for general purpose memory management but only to solve
    the problem of cyclic references. In many situations, objects may reference each
    other in a way that would make it impossible to remove them using simple techniques
    based on tracking the number of references. Here is the most simple example:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示`objgraph`如何在实践中使用，让我们回顾一些实际的例子。正如我们在本书中已经多次提到的，CPython有自己的垃圾收集器，它独立于其引用计数方法存在。它不用于一般的内存管理，而仅用于解决循环引用的问题。在许多情况下，对象可能以一种使得使用简单的基于跟踪引用数量的技术无法删除它们的方式相互引用。以下是最简单的例子：
- en: '[PRE17]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Such a situation is visually presented in *Figure 4*. In the preceding case,
    even if all external references to `x` and `y` objects will be removed (for instance,
    by returning from local scope of a function), these two objects cannot be removed
    because there are still two cross-references owned by these two objects. This
    is the situation where Python garbage collector steps in. It can detect cyclic
    references to objects and trigger their deallocation if there are no other valid
    references to these objects outside the cycle.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况在*图4*中以可视化方式呈现。在前面的情况下，即使所有对`x`和`y`对象的外部引用都将被移除（例如，通过从函数的局部范围返回），这两个对象也不能被移除，因为这两个对象仍然拥有的两个交叉引用。这是Python垃圾收集器介入的情况。它可以检测到对象的循环引用并在循环外没有其他有效引用时触发它们的释放。
- en: '![objgraph](graphics/B05295_11_04.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![objgraph](graphics/B05295_11_04.jpg)'
- en: Figure 4 An example diagram of cyclic references between two objects
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图4 两个对象之间循环引用的示例图表
- en: 'The real problem starts when at least one of the objects in such a cycle has
    the custom `__del__()` method defined. It is a custom deallocation handler that
    will be called when the object''s reference count finally goes to zero. It can
    execute any arbitrary Python code and so can also create new references to featured
    object. This is the reason why garbage collector prior to Python 3.4 version could
    not break reference cycles if at least one of the objects provided the custom
    `__del__()` method implementation. PEP 442 introduced safe object finalization
    to Python and became a part of the standard starting from Python 3.4\. Anyway,
    this may still be a problem for packages that worry about backwards compatibility
    and target a wide spectrum of Python interpreter versions. The following snippet
    of code shows you the differences in behavior of cyclic garbage collector in different
    Python versions:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当这样的循环中至少有一个对象定义了自定义的`__del__()`方法时，真正的问题开始。这是一个自定义的释放处理程序，当对象的引用计数最终变为零时将被调用。它可以执行任意的Python代码，因此也可以创建对特色对象的新引用。这就是为什么在Python
    3.4版本之前的垃圾收集器无法打破引用循环的原因，如果其中至少有一个对象提供了自定义的`__del__()`方法实现。PEP 442引入了对Python的安全对象最终化，并成为Python
    3.4版本开始的标准的一部分。无论如何，这对于担心向后兼容性并针对广泛的Python解释器版本的软件包仍可能是一个问题。以下代码片段向您展示了不同Python版本中循环垃圾收集器行为的差异：
- en: '[PRE18]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output of the preceding code, when executed under Python 3.3, shows that
    the cyclic garbage collector in the older versions of Python cannot collect objects
    that have the `__del__()` method defined:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python 3.3下执行上述代码的输出显示，旧版本的Python中的循环垃圾收集器无法收集定义了`__del__()`方法的对象：
- en: '[PRE19]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'With a newer version of Python, the garbage collector can safely deal with
    finalization of objects even if they have the `__del__()` method defined:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在较新版本的Python中，垃圾收集器可以安全地处理对象的最终化，即使它们定义了`__del__()`方法：
- en: '[PRE20]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Although custom finalization is no longer tricky in the latest Python releases,
    it still poses a problem for applications that need to work under different environments.
    As mentioned earlier, the `objgraph.show_refs()` and `objgraph.show_backrefs()`
    functions allow you to easily spot problematic class instances. For instance,
    we can easily modify the `main()` function to show all back references to the
    `WithDel` instances in order to see if we have leaking resources:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在最新的Python版本中自定义最终化不再棘手，但对于需要在不同环境下工作的应用程序仍然是一个问题。如前所述，`objgraph.show_refs()`和`objgraph.show_backrefs()`函数允许您轻松地发现有问题的类实例。例如，我们可以轻松修改`main()`函数以显示对`WithDel`实例的所有反向引用，以查看是否存在泄漏资源：
- en: '[PRE21]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Running the preceding example under Python 3.3 will result in a diagram (see
    *Figure 5*), which shows that `gc.collect()` could not succeed in removing `x`,
    `y`, and `z` object instances. Additionally, `objgraph` highlights all the objects
    that have the custom `__del__()` method defined to make spotting such issues easier.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python 3.3下运行上述示例将导致一个图表（见*图5*），显示`gc.collect()`无法成功移除`x`、`y`和`z`对象实例。此外，`objgraph`突出显示了所有定义了自定义`__del__()`方法的对象，以便更容易地发现此类问题。
- en: '![objgraph](graphics/B05295_11_05.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![objgraph](graphics/B05295_11_05.jpg)'
- en: Figure 5 The diagram showing an example of cyclic references that can't be picked
    by the Python garbage collector prior to version 3.4
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图5 显示在Python 3.4版本之前无法被Python垃圾收集器捕获的循环引用的示例图表
- en: C code memory leaks
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C代码内存泄漏
- en: If the Python code seems perfectly fine and the memory still increases when
    you loop through the isolated function, the leak might be located on the C side.
    This happens, for instance, when a `Py_DECREF` call is missing.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Python代码看起来完全正常，当您循环执行隔离的函数时内存仍然增加，那么泄漏可能发生在C端。例如，当缺少`Py_DECREF`调用时会发生这种情况。
- en: The Python core code is pretty robust and tested for leaks. If you use packages
    that have C extensions, they might be a good place to look first. Because you
    will be dealing with code operating on a much lower level of abstraction than
    Python, you need to use completely different tools to resolve such memory issues.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Python核心代码非常健壮，并经过泄漏测试。如果您使用具有C扩展的软件包，它们可能是首先要查看的地方。因为您将处理的代码比Python的抽象级别低得多，您需要使用完全不同的工具来解决此类内存问题。
- en: 'Memory debugging is not easy in C, so before diving into extension internals
    make sure to properly diagnose the source of your problem. It is a very popular
    approach to isolate a suspicious package with code similar in nature to unit tests:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在C中进行内存调试并不容易，因此在深入研究扩展内部之前，请确保正确诊断问题的根源。隔离一个可疑的包并使用类似于单元测试的代码是一个非常流行的方法：
- en: Write a separate test for each API unit or functionality of an extension you
    are suspecting to leak memory
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为您怀疑泄漏内存的扩展的每个API单元或功能编写单独的测试
- en: Perform the test in a loop for an arbitrarily long time in isolation (one test
    per run)
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在隔离中进行测试循环（每次运行一个测试）
- en: Observe from outside which of the tested functionalities increase memory usage
    over time
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从外部观察被测试功能中哪些会随时间增加内存使用量
- en: Using such an approach, you can isolate the faulty part of the extension and
    this will reduce the time required later to inspect and fix its code. This process
    may seem burdensome because it requires a lot of additional time and coding, but
    it really pays off in the long run. You can always ease your work by reusing some
    testing tools introduced in [Chapter 10](ch10.html "Chapter 10. Test-Driven Development"),
    *Test-Driven Development*. Utilities such as tox were perhaps not designed exactly
    for this case, but they can at least reduce the time required to run multiple
    tests in isolated environments.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，您可以隔离扩展的故障部分，这将减少以后检查和修复其代码所需的时间。这个过程可能看起来很繁重，因为它需要大量额外的时间和编码，但从长远来看，它真的很值得。您可以通过重用一些测试工具来简化工作，这些工具在[第10章](ch10.html
    "第10章。测试驱动开发")中介绍，*测试驱动开发*。像tox这样的实用程序也许并不是专门为这种情况设计的，但它们至少可以减少在隔离环境中运行多个测试所需的时间。
- en: Hopefully, you have isolated the part of the extension that is leaking memory
    and can finally start actual debugging. If you're lucky, a simple manual inspection
    of the source code may give the desired results. In many cases, the problem is
    as simple as adding the missing `Py_DECREF` call. Nevertheless, in most cases,
    our work is not that simple. In such situations, you need to bring out some bigger
    guns. One of the notable generic tools for fighting memory leaks in compiled code
    that should be in every programmer's toolbelt is **Valgrind**. It is a whole instrumentation
    framework for building dynamic analysis tools. Because of this, it may not be
    easy to learn and master, but you should definitely know the basics.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您已经隔离了扩展中泄漏内存的部分，并最终可以开始实际调试。如果您很幸运，对源代码进行简单的手动检查可能会得到期望的结果。在许多情况下，问题就像添加丢失的`Py_DECREF`调用一样简单。然而，在大多数情况下，我们的工作并不那么简单。在这种情况下，您需要使用一些更强大的工具。在编译代码中对抗内存泄漏的一个显著通用工具是**Valgrind**，它应该是每个程序员的工具包中的一部分。它是一个用于构建动态分析工具的整个仪器框架。因此，它可能不容易学习和掌握，但您绝对应该了解基础知识。
- en: Profiling network usage
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析网络使用情况
- en: As I said earlier, an application that communicates with third-party programs
    such as databases, caches, web services, or an LDAP server can be slowed down
    when those applications are slow. This can be tracked with a regular code profiling
    method on the application side. But if the third-party software works fine on
    its own, the culprit is probably the network.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前所说，与数据库、缓存、Web服务或LDAP服务器等第三方程序通信的应用程序在这些应用程序运行缓慢时可能会变慢。这可以通过应用程序端的常规代码分析方法进行跟踪。但是，如果第三方软件单独运行良好，那么问题很可能是网络。
- en: The problem might be a misconfigured hub, a low-bandwidth network link, or even
    a high number of traffic collisions that make computers send the same packets
    several times.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 问题可能是配置错误的中心、低带宽网络链接，甚至是大量的流量碰撞，导致计算机多次发送相同的数据包。
- en: 'Here are a few elements to get you in. To find out what is going on, there
    are three fields to investigate at first:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些要素，可以帮助您了解正在发生什么，首先需要调查三个领域：
- en: 'Watch the network traffic using tools such as:'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用诸如以下工具监视网络流量：
- en: '`ntop`: [http://www.ntop.org](http://www.ntop.org) (Linux only)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ntop`：[http://www.ntop.org](http://www.ntop.org)（仅限Linux）'
- en: '`wireshark`: [www.wireshark.org](http://www.wireshark.org) (previously named
    Ethereal)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wireshark`：[www.wireshark.org](http://www.wireshark.org)（以前称为Ethereal）'
- en: Track down unhealthy or misconfigured devices with `net-snmp` ([http://www.net-snmp.org](http://www.net-snmp.org)).
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`net-snmp`（[http://www.net-snmp.org](http://www.net-snmp.org)）跟踪不健康或配置错误的设备。
- en: Estimate the bandwidth between two computers using `Pathrate`, a statistical
    tool. See [http://www.cc.gatech.edu/~dovrolis/bw-est/pathrate.html](http://www.cc.gatech.edu/~dovrolis/bw-est/pathrate.html).
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用统计工具`Pathrate`估算两台计算机之间的带宽。参见[http://www.cc.gatech.edu/~dovrolis/bw-est/pathrate.html](http://www.cc.gatech.edu/~dovrolis/bw-est/pathrate.html)。
- en: If you want to go further on network performance issues, you might also want
    to read *Network Performance Open Source Toolkit*, *Wiley*, by Richard Blum. This
    book exposes strategies to tune the applications that are heavily using the network
    and provides a tutorial to scan complex network problems.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想进一步了解网络性能问题，您可能还想阅读*网络性能开源工具包*，作者Richard Blum，*Wiley*。这本书介绍了调整大量使用网络的应用程序的策略，并提供了扫描复杂网络问题的教程。
- en: '*High Performance MySQL*, *O''Reilly Media*, by Jeremy Zawodny is also a good
    book to read when writing an application that uses MySQL.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*高性能MySQL*，*O''Reilly Media*，作者Jeremy Zawodny在编写使用MySQL的应用程序时也是一本不错的书。'
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we have seen:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经看到：
- en: 'The three rules of optimization:'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化的三个规则：
- en: Make it work first
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先让它工作
- en: Take the user's point of view
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以用户的角度看问题
- en: Keep the code readable
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持代码可读性
- en: An optimization strategy based on writing a scenario with speed objectives
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于编写具有速度目标的场景的优化策略
- en: How to profile CPU or memory usage and a few tips for network profiling
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何分析CPU或内存使用情况以及一些网络分析的技巧
- en: Now that you know how to locate your performance problems, the next chapter
    provides some popular and generic strategies to get rid of them.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您知道如何定位性能问题，下一章将介绍一些流行和通用的策略来摆脱这些问题。
